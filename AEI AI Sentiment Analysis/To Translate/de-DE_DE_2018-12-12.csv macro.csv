URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@graph,article:section,article:summary,article text,@type,url,mainEntityOfPage,headline,datePublished,dateModified,image,author,publisher
https://news.google.com/rss/articles/CBMiMGh0dHBzOi8vbmV3cy5taWNyb3NvZnQuY29tL2RlLWRlL2tpLWV4cGVydGVucmF0L9IBAA?oc=5,Microsoft initiiert Expertenrat Künstliche Intelligenz | News Center Microsoft - Microsoft News,2018-12-13,Microsoft News,https://news.microsoft.com,"Der Expertenrat Künstliche Intelligenz vereint Wirtschaft, Politik, Verwaltung und Wissenschaft, um gemeinsam den KI-Standort Deutschland zu stärken.",N/A,"Der Expertenrat Künstliche Intelligenz vereint Wirtschaft, Politik, Verwaltung und Wissenschaft, um gemeinsam den KI-Standort Deutschland zu stärken.",N/A,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://news.microsoft.com/de-de/ki-expertenrat/', 'url': 'https://news.microsoft.com/de-de/ki-expertenrat/', 'name': 'Microsoft initiiert Expertenrat Künstliche Intelligenz | News Center Microsoft', 'isPartOf': {'@id': 'https://news.microsoft.com/de-de/#website'}, 'primaryImageOfPage': {'@id': 'https://news.microsoft.com/de-de/ki-expertenrat/#primaryimage'}, 'image': {'@id': 'https://news.microsoft.com/de-de/ki-expertenrat/#primaryimage'}, 'thumbnailUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/40/2018/12/Collage-KI-Expertenrat_1.jpg', 'datePublished': '2018-12-13T10:50:44+00:00', 'dateModified': '2019-08-21T10:42:34+00:00', 'author': {'@id': 'https://news.microsoft.com/de-de/#/schema/person/088a855d6c8f30ece34ed7cea6b62ce1'}, 'description': 'Der Expertenrat Künstliche Intelligenz vereint Wirtschaft, Politik, Verwaltung und Wissenschaft, um gemeinsam den KI-Standort Deutschland zu stärken.', 'breadcrumb': {'@id': 'https://news.microsoft.com/de-de/ki-expertenrat/#breadcrumb'}, 'inLanguage': 'de-DE', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.microsoft.com/de-de/ki-expertenrat/']}]}, {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://news.microsoft.com/de-de/ki-expertenrat/#primaryimage', 'url': 'https://news.microsoft.com/wp-content/uploads/prod/sites/40/2018/12/Collage-KI-Expertenrat_1.jpg', 'contentUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/40/2018/12/Collage-KI-Expertenrat_1.jpg', 'width': 1652, 'height': 1180, 'caption': 'Microsoft Expertenrat Künstliche Intelligenz'}, {'@type': 'BreadcrumbList', '@id': 'https://news.microsoft.com/de-de/ki-expertenrat/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.microsoft.com/de-de/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Recent News', 'item': 'https://news.microsoft.com/de-de/recent-news/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Microsoft initiiert Expertenrat Künstliche Intelligenz'}]}, {'@type': 'WebSite', '@id': 'https://news.microsoft.com/de-de/#website', 'url': 'https://news.microsoft.com/de-de/', 'name': 'Newsroom Microsoft Deutschland', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.microsoft.com/de-de/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'de-DE'}, {'@type': 'Person', '@id': 'https://news.microsoft.com/de-de/#/schema/person/088a855d6c8f30ece34ed7cea6b62ce1', 'name': 'Isabel Richter', 'image': {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://news.microsoft.com/de-de/#/schema/person/image/e698168c9a0a4f223f6466a3c751d441', 'url': 'https://secure.gravatar.com/avatar/56a2212aaac4ffd9a8c2697fd2c9f9db?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/56a2212aaac4ffd9a8c2697fd2c9f9db?s=96&d=mm&r=g', 'caption': 'Isabel Richter'}, 'url': 'https://news.microsoft.com/de-de/author/isrichtemicrosoft-com/'}]",N/A,N/A,"


			3. Juli 2024		

		Wir feiern Frauen, die inspirieren: Die Gewinnerinnen des Microsoft Deutschland „Power Women“ Award 2024	

Letzte Woche haben wir die Gewinner des „Partner of the Year”-Award bekannt gegeben. Doch es gibt noch mehr zu feiern: Mit dem Microsoft „Power Women”-Award, der Teil unseres kontinuierlichen Engagements ist, feiern wir weibliche Tech-Talente.


",,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmRldXRzY2hsYW5kZnVua2t1bHR1ci5kZS9rdWVuc3RsaWNoZS1pbnRlbGxpZ2Vuei13aWUtaGFsdGVuLWVzLXJvYm90ZXItbWl0LWRlbS0xMDAuaHRtbNIBAA?oc=5,Künstliche Intelligenz - Wie halten es Roboter mit dem Glauben? - Deutschlandfunk Kultur,2018-12-14,Deutschlandfunk Kultur,https://www.deutschlandfunkkultur.de,"Über Religion wissen Alexa und Siri ziemlich gut Bescheid. Aber wissen heißt nicht glauben. Wie halten sie es selbst mit der Religion? Fragen nach Gott, nach Reset oder Tod könnten bald auch für Roboter und Cyborgs aktuell werden, meint Autor Uwe Bork.",N/A,"Über Religion wissen Alexa und Siri ziemlich gut Bescheid. Aber wissen heißt nicht glauben. Wie halten sie es selbst mit der Religion? Fragen nach Gott, nach Reset oder Tod könnten bald auch für Roboter und Cyborgs aktuell werden, meint Autor Uwe Bork.","Über Religion wissen Alexa und Siri ziemlich gut Bescheid. Aber wissen heißt nicht glauben. Wie halten sie es selbst mit der Religion? Fragen nach Gott, nach Reset oder Tod könnten bald auch für Roboter und Cyborgs aktuell werden, meint Autor Uwe Bork.",,,N/A,N/A,N/A,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LmdxLW1hZ2F6aW4uZGUvYXV0by10ZWNobmlrL2FydGljbGUvYXVjaC0yMDI5LXdpcmQtZXMta2VpbmUta3VlbnN0bGljaGUtaW50ZWxsaWdlbnotZ2ViZW4tZGllLWRpZXNlbi1uYW1lbi12ZXJkaWVudNIBggFodHRwczovL3d3dy5ncS1tYWdhemluLmRlL2F1dG8tdGVjaG5pay9hbXAvYXJ0aWNsZS9hdWNoLTIwMjktd2lyZC1lcy1rZWluZS1rdWVuc3RsaWNoZS1pbnRlbGxpZ2Vuei1nZWJlbi1kaWUtZGllc2VuLW5hbWVuLXZlcmRpZW50?oc=5,"Auch 2029 wird es keine Künstliche Intelligenz geben, die diesen Namen verdient - GQ Germany",2018-12-14,GQ Germany,https://www.gq-magazin.de,"Prognosen über die technische Zukunft im Allgemeinen sind immer ein riskantes Unterfangen. Prognosen über die Entwicklung der sogenannten Künstlichen Intelligenz (KI) im Besonderen spielen dabei sogar in einer ganz eigenen Liga. Denn ihre Geschichte ist eine Geschichte von grotesk überzogenen Erwartungen. Ein WIRED2029-Gastbeitrag von Florian Gallwitz, Professor für Medieninformatik an der Technischen Hochschule Nürnberg.",N/A,"Prognosen über die technische Zukunft im Allgemeinen sind immer ein riskantes Unterfangen. Prognosen über die Entwicklung der sogenannten Künstlichen Intelligenz (KI) im Besonderen spielen dabei sogar in einer ganz eigenen Liga. Denn ihre Geschichte ist eine Geschichte von grotesk überzogenen Erwartungen. Ein WIRED2029-Gastbeitrag von Florian Gallwitz, Professor für Medieninformatik an der Technischen Hochschule Nürnberg.","Prognosen über die technische Zukunft im Allgemeinen sind immer ein riskantes Unterfangen. Prognosen über die Entwicklung der sogenannten Künstlichen Intelligenz (KI) im Besonderen spielen dabei sogar in einer ganz eigenen Liga. Denn ihre Geschichte ist eine Geschichte von grotesk überzogenen Erwartungen. Ein WIRED2029-Gastbeitrag von Florian Gallwitz, Professor für Medieninformatik an der Technischen Hochschule Nürnberg.",https://schema.org,,N/A,N/A,"




Wenn ich gefragt werde, wie und wohin sich KI im Jahr 2029 entwickelt haben wird, muss ich daran denken, wie es sich anfühlt, mit dem Auto einen unbefestigten Bergpass auf Korsika zu überqueren. Die im Tal verstreut liegenden, bereits üppig von Vegetation durchsetzten Autowracks mahnen vor einer zu optimistischen Herangehensweise. Diese Wracks stehen für die Erwartungen an die Ergebnisse der KI-Forschung – die Fahrer wären die großen Denker ihrer Zeit auf diesem Gebiet. Beispielhaft seien hier die Einschätzungen von zwei Teilnehmern des berühmten Dartmouth-Workshops genannt, auf dem im Sommer 1956 der Begriff Künstliche Intelligenz geprägt wurde, der bis heute so viel Verwirrung stiftet. 


Schon im Jahr 1965 schrieb der spätere Wirtschaftsnobelpreisträger Herbert Simon, dass Maschinen in 20 Jahren (also 1985) in der Lage sein würden, jede Arbeit auszuführen, zu der Menschen fähig sind. Marvin Minsky, eine der prägendsten Figuren der Forschungsrichtung Künstliche Intelligenz, war noch optimistischer. Er erklärte im Jahr 1970 gegenüber dem Magazin Life, dass die Entwicklung einer Maschine mit der durchschnittlichen Intelligenz eines Menschen nur drei bis acht Jahre bevorstünde. Er attestierte einer solchen Maschine unter anderem die Fähigkeiten, Shakespeare zu lesen und die beweglichen Teile eines Autos zu schmieren. Dem gleichen Artikel ist auch zu entnehmen, dass viele seiner Forscherkollegen diese Prognose für etwas zu optimistisch hielten: „Geben Sie uns 15 Jahre.“


Die Bundesregierung setzt bei KI auf gescheiterte Ansätze 

Heute, 48 Jahre später, ist eine Künstliche Intelligenz in diesem Sinne – oder auch nur ein vielversprechender Weg in diese Richtung – noch nicht einmal in Ansätzen zu erkennen. Die in den 70er Jahren populären Versuche, menschliche Intelligenz auf symbolisch-logischer Ebene zu reproduzieren, zum Beispiel durch Verwendung spezieller Programmiersprachen wie Lisp oder Prolog oder durch sogenannte Expertensysteme, haben an den Unschärfen der realen Welt längst krachend Schiffbruch erlitten. Allein die kürzlich veröffentlichte „Strategie Künstliche Intelligenz der Bundesregierung“ (PDF) setzt verblüffender Weise immer noch auf einen Methodenmix, der diese historisch gescheiterten Ansätze an prominenter Stelle beinhaltet.


Aber warum reden wir eigentlich überhaupt wieder über „KI“, und warum benötigt Deutschland im Jahr 2018 nach Überzeugung der Bundesregierung sogar eine KI-Strategie? Hintergrund sind in erster Linie deutliche Fortschritte bei der Simulation der menschlichen Wahrnehmung, die auch ganz ohne das Vorhandensein künstlicher „Intelligenz“ weitreichende Auswirkungen auf die Gesellschaft der Zukunft haben werden.



















                                „Mit KI erschaffen wir eine komplett neue Spezies“
                            

von Achim Fehrenbach
08.11.2018













Die für solcherlei Fragestellungen zuständige Fachrichtung der Informatik hat sich unter der Bezeichnung Mustererkennung etabliert und hat sich jahrzehntelang weitgehend unabhängig von der klassischen KI-Forschung mit konkreten Fragestellungen wie Spracherkennung, also der Umwandlung von Sprachsignalen in Text, der Erkennung von Objekten in Bildern oder der Interpretation von medizinischen Sensordaten befasst. Was die Spracherkennung angeht, war bereits seit Ende der 70er Jahre klar, dass die Variabilität und Mehrdeutigkeit gesprochener Sprache nur mittels maschineller Lernverfahren in den Griff zu bekommen sein würde. Anstatt mit Symbolen wird hierbei vorwiegend mit Wahrscheinlichkeiten, kontinuierlichen Zahlenvektoren, Abständen und Gewichtungen hantiert. Bei der Objekterkennung setzte sich diese Erkenntnis erst deutlich später durch. 


Ein maschinelles Lernverfahren, dessen Anfänge auf die 40er und 50er Jahre zurückgehen, und das in stark vereinfachter Form die Funktionsweise biologischer Neuronen simuliert, sind künstliche neuronale Netze. Sie erfuhren bei der Suche nach menschenähnlicher Künstlicher Intelligenz in den 60er Jahren kurzzeitig eine gewisse Aufmerksamkeit. Nach Einschätzung des KI-Vordenkers Minsky waren sie jedoch nicht erfolgversprechend und gerieten deshalb in der nominellen KI-Forschung bald wieder in Vergessenheit. Man verschrieb sich dort stattdessen noch über das Ende des 20. Jahrhunderts hinaus nun ganz den symbolisch-logischen, regel- und wissensbasierten Ansätzen. 


Neuronale Netze sind nur ein Lernverfahren unter vielen 

In der Mustererkennung spielten künstliche Neuronale Netze dagegen schon seit Ende der 80er Jahre wieder eine wichtige Rolle. Sie wurden z.B. erfolgreich für die Erkennung von handschriftlichen Ziffern, für die Spracherkennung oder für die Erkennung von Emotionen aus Sprachsignalen eingesetzt, blieben aber im Werkzeugkasten der Mustererkennung neben Gaußschen Mischverteilungen und Support Vector Machines zunächst nur ein maschinelles Lernverfahren unter vielen.


Die Fortschritte der Mustererkennung führten seit den 90er und 2000er Jahren zu konkreten Produkten und Anwendungen mit zunehmender Verbreitung, wie etwa Diktier-Spracherkennung für PCs oder Fotokameras, die Gesichter in Bildern erkennen und so eine optimierte Steuerung von Belichtung und Schärfe ermöglichen. Jahr für Jahr ergaben sich moderate Verbesserungen der Erkennungsgenauigkeit solcher Verfahren. Niemand wäre in dieser Zeit auf die Idee gekommen, solcherlei Anwendungen als „KI“ zu bezeichnen.



















                                KI-Forscher Toby Walsh: Wir sollten uns nicht um schlaue, sondern um dumme KI Sorgen machen!
                            

von Chris Köver
16.11.2018













Um das Jahr 2012 herum kam es zu sprunghaften Verbesserungen in vielen Bereichen der Mustererkennung, zunächst bei der Objekterkennung und kurz darauf auch bei der Spracherkennung. Verantwortlich hierfür waren künstliche neuronale Netze, die deutlich mehr Schichten von Rechenknoten („Neuronen“) hatten als die in den Jahrzehnten zuvor verwendeten, also „tiefer“ waren als bisherige Netze. Bekannt werden sollte diese neue Welle von künstlichen neuronalen Netzen deshalb unter der etwas missverständlichen Bezeichnung Deep Learning. Ermöglicht wurden diese Netze vor allem durch die stark gewachsene Leistungsfähigkeit der Hardware, insbesondere durch die effiziente Parallelisierbarkeit des Trainingsvorgangs auf Grafikkarten. Gegenüber den späten 80er Jahren hatte sich hierdurch eine Beschleunigung des Trainings um etwa den Faktor eine Million ergeben.


Heute dominieren Deep-Learning-Verfahren in allen Bereichen der Mustererkennung, in denen sehr große Datenmengen zum Training der Systeme zur Verfügung stehen. Auch in geschlossenen Spiel-Welten wie dem Schach- und dem Go-Spiel oder bei der Bewältigung von Video-Spielen zeigen diese Verfahren erstaunliche Fähigkeiten. Durch geschickte Kombination mustererkennender und generativ eingesetzter neuronaler Netze lassen sich auch Bilder und Videos auf verblüffend realistische Weise manipulieren. 


Trotz der in den letzten Jahren weltweit enorm gestiegenen Forschungsanstrengungen in diesem Bereich scheint die Rate an wirklich neuen, überraschenden Erkenntnissen und Ergebnissen aktuell schon wieder abzunehmen. Wie in der Zeit vor den sprunghaften Verbesserungen vor etwa sechs Jahren kann man eine gewisse Konsolidierung bei den Erkennungsraten feststellen. Spektakuläre Erfolgsmeldungen gibt es vor allem dort, wo Deep-Learning-Verfahren auf Mustererkennungs-Anwendungen angesetzt werden, die bislang menschlichen Experten vorbehalten waren. Ein typisches Beispiel hierfür ist die Unterscheidung von gutartigen und bösartigen Hautveränderungen anhand eines Fotos.



















                                Warum wir auch 2029 noch auf Super-Roboter warten werden
                            

von Wolfgang Kerler
12.12.2018













Sogar ein Taschenrechner ist laut Definition eine KI 

Durch unglückliche Umstände ist der alte, angestaubte und nie sinnvoll definierte Begriff Künstliche Intelligenz aus den Trümmern der (symbolischen) KI-Forschung geborgen worden und heute für viele zu einem Synonym für Deep Learning geworden. Schlimmer noch: Auch andere nützliche aber überaus schlichte maschinelle Lernverfahren aus der Frühzeit der Informatik, wie etwa der k-Means-Algorithmus aus den 50er Jahren, werden heute schamlos als Künstliche Intelligenz angepriesen. Selbst ein handelsüblicher Taschenrechner genügt nach einer verbreiteten Definition den Anforderungen an eine sogenannte „schwache Künstliche Intelligenz“. Ähnlich sinnvoll erschiene es mir, Papierflugzeuge, Silvesterraketen und Tennisbälle mit großer Ernsthaftigkeit unter der Sammelbezeichnung „schwache interstellare Raumfahrt“ zusammenzufassen. 


Die wechselvolle Geschichte des Begriffs Künstliche Intelligenz, die sich vielleicht vor einigen Monaten in den Ergebnissen der Google-Recherche eines Ministeriumspraktikanten widergespiegelt haben könnte, mag auf Umwegen zu manchen der Absonderlichkeiten beigetragen haben, die sich in der aktuellen KI-Strategie der Bundesregierung finden. Zu diesen gehört auch, dass der Begriff Deep Learning in dem 47-seitigen Dokument nicht ein einziges Mal Erwähnung findet.


Aber was bedeutet all dies nun für die zukünftige Entwicklung? 



 Neuronale Netze sind gekommen, um zu bleiben. Sie werden das Feld der Mustererkennung und des maschinellen Lernens auch im Jahr 2029 weiterhin dominieren. Die Art und Weise, wie es gelungen ist, mit diesem Ansatz nach 60 Jahren Anlauf das biologische Vorbild Mensch etwa bei der Gesichtserkennung nicht nur einzuholen, sondern sogar deutlich zu übertreffen, macht ihr enormes Potential deutlich.
 Der große zeitliche Abstand zwischen den wirklich bahnbrechenden Innovationen in diesem Bereich lässt es unwahrscheinlich erscheinen, dass in den nächsten zehn Jahren erneut etwas vollkommen Unerwartetes passiert. Wir werden also vorwiegend inkrementelle Verbesserungen der Deep-Learning-Verfahren sehen. Der Bedarf an anwendungsspezifischen Trainingsdaten wird gegenüber dem heutigen Stand deutlich reduziert und neue Anwendungsgebiete werden erschlossen. Es wird darüber hinaus Versuche geben, Deep-Learning-Verfahren über die Wahrnehmung und Mustererkennung hinaus auch für weitere Teilaspekte der Intelligenz wie Abstraktion, Analogiebildung und Schlussfolgerungen zu trainieren.
 Es wird auch im Jahr 2029 keine Maschine geben, die auch nur im Entferntesten die Bezeichnung Künstliche Intelligenz im Sinne des Dartmouth-Workshops verdient hat, die also menschenähnlich denken und schlussfolgern kann, Analogien bildet, einen eigenen Antrieb, Willen oder gar ein Bewusstsein besitzt.
 Ermüdet von 15 Jahren öffentlicher Diskussion über „Künstliche Intelligenz“ werden Menschen im Jahr 2029 aggressiv und zum Teil sogar handgreiflich auf die Verwendung dieses Begriffes reagieren. Die Medien sind deshalb gezwungen, wieder auf Begriffe auszuweichen, die eine Bedeutung haben. Die Verwendung des unbestimmten Artikels vor dem Begriff KI, wie in „Eine KI hat einen Master-Fingerabdruck entwickelt, der in Smartphones einbricht“ führt seit dem Jahr 2025 sogar zu einer automatischen Sperrung aller Social-Media-Konten. 



Alle Artikel des WIRED2029-Specials, die vom 12. bis 19.12.2018 erscheinen werden, findet ihr hier.



















                                Florian Gallwitz
                            

von GQ
10.12.2018


























WIRED2029
KI







Teilen




















",Article,https://www.gq-magazin.de/auto-technik/article/auch-2029-wird-es-keine-kuenstliche-intelligenz-geben-die-diesen-namen-verdient,"{'@type': 'WebPage', '@id': 'https://www.gq-magazin.de/auto-technik/article/auch-2029-wird-es-keine-kuenstliche-intelligenz-geben-die-diesen-namen-verdient'}","Auch 2029 wird es keine Künstliche Intelligenz geben, die diesen Namen verdient",2018-12-14 09:18:00,2018-12-15 11:00:00,"['https://res.cloudinary.com/wired-de/iu/s--pv7XDImc--/c_limit,f_auto,h_1800,q_auto:good,w_1200/v1/0/18-12-09_Wired_7jpg.jpg', 'https://res.cloudinary.com/wired-de/iu/s--oPx55l3Q--/c_limit,f_auto,h_1200,q_auto:good,w_1200/v1/0/18-12-09_Wired_7jpg.jpg', 'https://res.cloudinary.com/wired-de/iu/s--WDG_xowt--/c_limit,f_auto,h_900,q_auto:good,w_1200/v1/0/18-12-09_Wired_7jpg.jpg', 'https://res.cloudinary.com/wired-de/iu/s--OxC5D3Nt--/c_limit,f_auto,h_680,q_auto:good,w_1200/v1/0/18-12-09_Wired_7jpg.jpg']","{'@type': 'Person', 'name': 'Florian Gallwitz'}","{'@type': 'Organization', 'name': 'Auto und Technik | GQ', 'logo': {'@type': 'ImageObject', 'url': 'https://www.gq-magazin.de/auto-technik/extensions/vendor/cnd/designs/gq/images/gq.jpg?40eb112918', 'height': '120', 'width': '245'}}"
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3LnByb2ZpbC5hdC93aXNzZW5zY2hhZnQvcHJvZmlsLW1lbnNjaC1qYWhyZXMtcm9ib3Rlci0xMDUzNjU3M9IBAA?oc=5,Künstliche Intelligenz: Warum Maschinen niemals klüger sind als der Mensch - profil.at,2018-12-15,profil.at,https://www.profil.at,"Artificial Intelligence kann medizinische und physikalische Daten analysieren, als Fernfahrer und an der Hotelrezeption arbeiten. Roboter können aber auch rassistisch sein und Krieg führen – und sie können so lächerliche Fehler machen, dass wir uns kaum vor einer künstlichen Superintelligenz fürchte","Intelligenz,Isaac Asimov,Kochrezept,Roboter,Technikthema,profil: Dossier KI","Artificial Intelligence kann medizinische und physikalische Daten analysieren, als Fernfahrer und an der Hotelrezeption arbeiten. Roboter können aber auch rassistisch sein und Krieg führen – und sie können so lächerliche Fehler machen, dass wir uns kaum vor einer künstlichen Superintelligenz fürchte",N/A,https://schema.org,,Wissenschaft,N/A,"















© 
Gareth Brown/Blow Up Studios  









© 
Gareth Brown/Blow Up Studios  








          Dossier: Künstliche Intelligenz


 Künstliche Intelligenz: Warum Maschinen niemals klüger sind als der Mensch




		Artificial Intelligence kann medizinische und physikalische Daten analysieren, als Fernfahrer und an der Hotelrezeption arbeiten. Roboter können aber auch rassistisch sein und Krieg führen – und sie können so lächerliche Fehler machen, dass wir uns kaum vor einer künstlichen Superintelligenz fürchte
	




				


                  

            Von                                      Alwin Schönberger


15.12.18


































Drucken













Schriftgröße













Du sollst bedingungslos gehorchen. Du sollst keinem Menschen Schaden zufügen. Du sollst dich selber schützen, sofern dies nicht mit Regel eins und zwei kollidiert. Dies ist die Kurzfassung der Robotergesetze, die der legendäre Science-ficition-Autor Isaac Asimov 1942 formulierte.


Du sollst bedingungslos gehorchen. Du sollst keinem Menschen Schaden zufügen. Du sollst dich selber schützen, sofern dies nicht mit Regel eins und zwei kollidiert. Dies ist die Kurzfassung der Robotergesetze, die der legendäre Science-ficition-Autor Isaac Asimov 1942 formulierte. Viele Forscher, die heute an Künstlicher Intelligenz arbeiten, finden, dass Asimov enormen Weitblick bewies. Denn jetzt, fast 80 Jahre später, nähern wir uns tatsächlich einer Ära, in der ein „Handbuch der Robotik“ zum geordneten Umgang mit Maschinen vonnöten ist, wie es der Schriftsteller und Biochemiker erdachte.
Man könnte durchaus zum Befund gelangen, dass Roboter, die mit einem Körper ausgestatteten Versionen Künstlicher Intelligenz, den Labors entwachsen und im Alltag ankommen. Zumindest in manchen Weltgegenden und in einigen Segmenten ist das defintiv der Fall. Wer im Hotel „Henn-na“ in Nagasaki eincheckt, wird von adrett uniformierten Damen empfangen, die aus Silikon, Silizium und Elektronik bestehen. Chatbot-Juristen in England erheben Einsprüche gegen Parkstrafen. Der gelenkige, an einen Hund erinnernde SpotMini klettert flink und trittsicher über Stiegen, öffnet Türen und wirkt wie ein bizarres, aber ziemlich lebendiges Wesen, wenn er auf Kontrollgang in einem Bürohaus geht. Industrieroboter wie „Baxter“ sind selbst für Kleinbetriebe leistbar und spulen zuverlässig genormte Handgriffe ab. Sie schweißen oder lackieren, andere helfen in der Landwirtschaft, in der Wäscherei, Küche oder im Bergwerk. Daheim mähen sensorgesteuerte Assistenten den Rasen oder saugen die Wohnung – während ihre sprachbegabten Verwandten, die auf Namen wie Alexa oder Siri hören, mehr oder minder sinnvolle Antworten auf forsche, meist im Befehlston gäußerte Fragen geben.
Auf einer deutlich höheren Entwicklungsstufe möchte man Sophia ansiedeln. Der humanoide Roboter kann recht überzeugend mit der Umwelt interagieren. Sehr eindrucksvoll nach menschlichem Vorbild gestaltet, erlauben Datenverarbeitung und Sensoren Gesichtserkennung, die Imitation von Mimik und Gestik sowie rudimentäre Unterhaltungen. Sophia trat in TV-Shows und sogar als Model auf. Für Aufsehen wie auch Kopfschütteln sorgte der Umstand, dass Saudi-Arabien dem Androiden die Staatsbürgerschaft verlieh – als weltweit erstem Roboter.
Hiroshi Ishiguro hält davon wenig. Dabei irritiert der Roboterforscher aus Osaka, eine Art Popstar seiner Branche, seinerseits mit der Kreation eines künstlichen Zwillings seiner selbst. Die beiden, Mensch und Maschine, sind kaum zu unterscheiden. Der synthetische Doppelgänger verfügt sogar über Hautporen und echtes Haar seines Schöpfers. Außerdem mit dessen Stimme ausgestattet, kann der Wissenschafter seinen Roboterklon via Internetsteuerung Vorträge halten lassen. Ishiguro will aber weitergehen: Maschinen mit Emotionen, Bedürfnissen, Sehnsüchten, womöglich mit Bewusstsein? Warum nicht, meint der Japaner, zumal wir ohnehin über keine präzise Definition dieser Qualitäten verfügten.
Doch auch angesichts weniger kühner Entwürfe lässt sich konstatieren: Roboter finden allmählich ihren Platz in Gesellschaft und Arbeitswelt, sie sind in mancher Hinsicht akzeptierte Begleiter. Skeptiker, denen das zu weit gegriffen ist, können sich vielleicht mit folgender Einschätzung anfreunden: Das Thema Künstliche Intelligenz ist inzwischen fast allgegenwärtig. Kaum eine Woche ohne Neuigkeiten von Ingenieuren, die Computern das Denken beibringen und Zahlen und Algorithmen in humaner Intelligenz nachempfundene Aktionen verwandeln.
Manchmal handelt es sich um Weiterentwicklungen bereits hoch leistungsfähiger Systeme wie „Alpha Zero“. Alpha Zero verbessert seine Fähigkeiten ausschließlich selbstständig und lediglich durch unentwegtes Spielen gegen sich selbst. Andere Innovationen betreffen Bastionen, von denen man annahm, dass nie eine Maschine sie erobern würde, vor allem Kunst und Kreativität. Jedoch: Sie malen Bilder, komponieren Musik, schreiben Gedichte und hecken raffinierte Kochrezepte aus, die von Kritikern in höchsten Tönen gelobt werden. Hinzu kommen die fast schon üblichen, aber immer ausgereifteren Fertigkeiten in medizinischer Diagnostik, wenn es etwa darum geht, in einem Wust menschlichen Zellmaterials auffällige Muster zu erkennen, die auf Krebs hindeuten.
Überdies entdeckt die Politik, acht Jahrzehnte nach Asimov, die Notwendigkeit, Strategien für den Tag auszuarbeiten, an dem Künstliche Intelligenz unser Leben nachhaltig beeinflusst. Frankreich, England und Deutschland beauftragten längst Expertenkonzepte über Chancen und Herausforderungen durch intelligente Systene, mittlerweile folgte auch Österreich. Eine „Artificial Intelligence Mission Austria 2030“ soll den Horizont in Bezug auf Punkte wie Ethik, Sicherheit, Gesellschaft und Ökologie abstecken.
Das Urteil der Experten über Künstliche Intelligenz fällt recht einhellig aus: Ja, Computerintelligenz wird massive soziale Umwälzungen auslösen, besonders am Arbeitsmarkt. Traditionelle Berufe werden verschwinden, neue entstehen. Ja, unterm Strich wird es einen Verlust an Jobs geben. Nein, die Maschinen werden uns nicht den Rang ablaufen und die Weltherrschaft übernehmen. Und nein, die Roboter werden uns nicht mit überlegener Intelligenz übertrumpfen, und der direkte Vergleich von humaner und künstlicher Intelligenz ist auch nicht zielführend. Wir sind Generalisten mit einem flexiblen, hochgradig effizienten Gehirn, das über Millionen Jahre entstanden und unnachahmlich ist. Maschinen sind dagegen Spezialisten, die bei einer bestimmten, klar definierten Aufgabe besonders gut abschneiden – und genau dafür werden wir sie einsetzen. Ein bestimmter Roboter mag besser schweißen oder Schach beherrschen als jeder Mensch. Wenn er aber plötzlich die Wände streichen oder Poker spielen soll, versagt er kläglich. „Ein Robot Deus, allwissend, allmächtig und allgegenwärtig, ist noch weit weg“, sagt Robert Trappl, Vorstand des Österreichischen Forschungsinstituts für Artificial Intelligence und einer der internationalen Pioniere auf dem Gebiet.
Golem, Shakey, Eliza
Das Motiv denkender künstlicher Wesen tauchte schon in der Antike auf. Ein Mythos erzählte vom Gott Prometheus, der fühlende Lehmgestalten erschuf. Später entstand die Geschichte vom Golem, ebenfalls aus Lehm. Der war zwar nicht besonders klug, dafür aber stark und ausdauernd, eher wie ein Industrieroboter. Über die Jahrhunderte dachten sich Schriftsteller und Künstler weitere solche Figuren aus, die sich häufig gegen ihren Schöpfer wandten. Parallel dazu formulierten die Vertreter von Vernunft und rationalem Denken mathematische Grundlagen, die wichtige Voraussetzungen fürs Computerzeitalter darstellten: Gottfried Wilhelm Leibniz, Thomas Hobbes, Bertrand Russel, George Boole, auf den die binäre Kodierung von Information zurückgeht – wahr oder falsch, 0 oder 1. 
Der Begriff „Artificial Intelligence“ wurde 1956 geprägt. Da fand am Dartmouth College in New Hamphire eine Konferenz statt, bei der erörtert wurde, wie man Maschinen Sprache beibringen könnte. Federführend waren Legenden der KI-Forschung wie John MacCarthy und Marvin Minsky. Robert Trappl, der den rauschebärtigen McCarthy noch kennenlernte, erinnert sich, dass man einen knackigen Titel für die Konferenz und den zugehörigen Forschungsantrag brauchte, und die Wahl fiel auf Atificial Intelligence – seit damals ist der Terminus in der Welt. In den folgenden Jahrzehnten erlebte die Forschung immer wieder Höhenflüge und Durchhänger, je nachdem, welche Fortschritte gemacht wurden und die Fördermittel flossen oder aber versiegten.
Der erste Roboter, der diesen Namen verdient, hieß „Shakey“ und entstand Mitte der 1960er-Jahre. Shakey konnte die Umgebung erkunden, selbst Entscheidungen treffen und besaß einen Algorithmus zur Routenplanung, der nun moderne Navigationsgeräte steuert. Um dieselbe Zeit tüftelten die Wissenschafter auch schon an einer Frage, die uns bis heute beschäftigt: Wann ist ein System intelligent? Kann eine Maschine echtes Verständnis entwickeln oder reagiert sie bloß auf Basis eingespeicherter Daten, ohne aber Bedeutung zu erfassen? Dann wäre es bloß ein Vorschützen von Intelligenz. Die Debatte kreiste um ELIZA, einen synthetischen Psychotherapeuten und Vorläufer aller Chatbots. ELIZA tätigte im Patientengespräch erstaunlich sinnvoll und empathisch wirkende Äußerungen. Erfinder Joseph Weizenbaum betonte aber stets, dass es sich um eine Illusion, um geschickt programmierte Tricks, letztlich um eine Parodie handelte. Wenn ein Patient etwas erzählte, („Meine Freundin wollte, dass ich hierherkomme“), warf ELIZA den Satz einfach in Frageform zurück, um an mehr brauchbare Information zu kommen und angemessen reagieren zu können („Ihre Freundin wollte, dass Sie hierherkommen?“). Es war die Simulation eines Gesprächs, die Illusion von Anteilnahme, aber viele Therapeuten waren begeistert und wollten das System selber nutzen.
Im Lauf der Zeit wurden viele Ansätze ausprobiert, um Maschinen Alltagswissen beizubringen, ihnen Sprache, Wahrnehmung optischer und akustischer Reize, Bewegungsmuster und Interaktion mit der Umwelt anzutrainieren. Kern des momentanen Hypes ist vor allem eine Methode: künstliche neuronale Netze, in ihrer ausgereiftesten Variante „tiefe“ neuronale Netze genannt oder schlicht Deep Learning.
Die Nerven der Maschinen
Es existiert natürlich kein echtes Pendant zu biologischen Neuronen, sondern eher eine synthetische Entsprechung. Was für uns Gehirnzellen darstellen, sind für einen Computer Zahlen und Algorithmen, wobei letztere als Gebrauchsanweisung für die Zahlen dienen. Durch Lerninhalte, zum Beispiel die Regeln eines Spiels oder Fotos von Pflanzen, werden den Zahlen in dem künstlichen Netzwerk bestimmte Werte zugeordnet. So wie sich bei uns beim Lernen Nervenverbindungen festigen, stärkt der Input die aus Zahlen bestehenden Knotenpunkte beim Computer. Der Wissenserwerb ist anfangs ein zäher Prozess, der mit einem groben Raster beginnt: zunächst etwa mit dem äußeren Unterschied zwischen Tieren, Pflanzen und unbelebten Objekten, dann mit jenem zwischen Vögeln und Säugetieren, schließlich folgen Feinheiten wie das Auseinanderhalten von Hund und Katze – für uns von klein auf selbstverständlich, für einen Rechner, dem jede Lebenserfahrung fehlt, jedoch eine Herausforderung. Viele Lernschritte gründen auf deduktivem Folgern. Beispiel: Bäume sind Pflanzen. Pflanzen sind an einen Ort gebunden. Also sind Bäume ortsfest. So wird das Netzwerk allmählich ausgeprägt, das Wissen wächst. Der Begriff „tief“ bezieht sich darauf, dass moderne Systeme in vielen Schichten angeordnet sind. Wenn eine Maschine passenden Output liefern soll, durchsucht sie diese Schichten, kramt gewissermaßen in ihrer Erinnerung.
Auf diesem Prinzip beruht jede Unterhaltung mit Alexa und jedes Internet-Übersetzungsprogramm, aber das wichtigste Einsatzgebiet ist die Wissenschaft, und dort sind diese Systeme, weitgehend abseits öffentlicher Wahrnehmung oder Kritik, ein Segen: Sie analysieren gigantische Datenmengen und suchen im Blitztempo nach signifikanten Mustern darin. Ein Mensch könnte die gleiche Wühlarbeit nicht in vielen Leben leisten. In Teilchendetektoren kollidieren pro Sekunde an die 600 Millionen Materiepartikel, doch nicht mehr als 200 davon sind für Physiker interessant. Ohne Künstliche Intelligenz ließen sich diese Ereignisse nie aufspüren. Ähnlich verhält es sich mit Proteinforschung, Genomsequenzierung, der Suche nach Gravitationswellen, nach erdnahen Asteroiden oder jener nach mutierten Genvarianten, die Krebs begünstigen. Die Wissenschaft ist ein Paradebeispiel dafür, wie Arbeitsteilung und Kooperation von Mensch und Maschine in Zukunft im günstigen Fall aussehen könnten: Dank Künstlicher Intelligenz können rasant neue Erkenntnisse gewonnen werden. Aber niemals wird der Computer Kreativität und Planung des Forschers ersetzen, er behält das Kommando und setzt die Maschine gezielt für seine Zwecke ein.
Das eigentlich Besondere an modernen neuronalen Netzen ist aber eine Fähigkeit mit weitreichenden Konsequenzen. Zwar legt der Mensch stets fest, was ein System können soll – beispielsweise Schach beherrschen oder Klaviersonaten spielen. Doch irgendwann lernen die Maschinen selbst. AlphaGo, der Vorläufer des noch weiter verbesserten Alpha Zero, wurde zunächst mit Abertausenden Spielverläufen gefüttert, begann dann aber, gegen sich selbst Go zu spielen und erarbeitete sich Spielzüge, die kein Mensch einprogrammiert hatte. Auf die Grundschule durch den Menschen folgte gleichsam das Selbsttraining der Maschine. AlphaGo wurde ständig besser, lernte selbstständig die Tricks und Kniffe des Brettspiels, entwickelte eigene Strategien. Als der Computer 2016 gegen einen der besten Go-Spieler der Welt gewann – eine erstaunliche Leistung, zumal Go viel komplexer und zudem intuitiver ist als Schach –, konnte man nicht mehr sagen warum. Die Maschine hatte ihr eigenes Spiel gespielt und sich von ihren Schöpfern gleichsam entkoppelt.
Wer übernimmt die Verantwortung?
Daraus resultieren erhebliche ethische Probleme. Wenn ich nicht weiß, weshalb eine künstliche Intelligenz einen bestimmten Entschluss fasst, wer ist dann dafür verantwortlich? Diese Frage mag nicht sonderlich relevant sein, wenn es um die knochentrockene Auswertung von Teilchenkollisionen geht. Heikel kann es aber in der Medizin oder vor Gericht werden. Das Zustandekommen von medizinischen Diagnosen muss für Arzt und Patient nachvollziehbar sein, ebenso die Kriterien für juristische oder finanztechnische Entscheidungen, etwa bei der Kreditvergabe. In den USA sind bereits Systeme im Einsatz, die das Rückfallrisiko von Straftätern vorhersagen. Auf dieser Basis können etwa Bewährungsauflagen erteilt werden. Was aber, wenn die Maschine unnachvollziehbare Beurteilungen vornimmt? Was, wenn sie sich, noch schlimmer, plötzlich rassistisch verhält? Natürlich gibt es keine rassistische Maschine, aber wir füttern sie vielleicht unbewusst mit Daten, die nach dem maschinellen Lernprozess zu bedenklichen Urteilen führen. Bei einem amerikanischen Programm war dies bereits der Fall: Schwarzen Straftätern wurde ein deutlich höheres Rückfallrisiko attestiert.
Schon eine simple Google-Suche führt das Problem vor Augen. Man braucht bloß den Satzanfang einzutippen: „Politiker sind …“ Google schlägt als Ergänzungen vor: Marionetten; Schauspieler; zu alt; Verbrecher. Welche Vorurteile, fragt man sich, hat sich das lernende System angeeignet? Der KI-Experte Toby Walsh spricht von „digitaler Diskriminierung“. Er glaubt, dass Deep Learning nicht der Weisheit letzter Schluss ist – aufgrund ethischer Probleme, aber rein pragmatisch auch deshalb, weil die Systeme enorme Datenmengen benötigen, um ihre Leistungen zu erbringen. Lee Sedol, jener Go-Meister, der gegen AlphaGo verlor, gewann immerhin eine von vier Partien. Das heißt, er benötigte drei Spiele, um die Taktik der Maschine zu durchschauen. AlphaGo hingegen hatte in der Vorbereitung Milliarden von Spielen absolviert. Humane Intelligenz und das Tempo sowie die Präzision, mit der wir komplexe Zusammenhänge erfassen, sind dem besten Computer im Grunde haushoch überlegen.
Hinzu kommt, dass sich die scheinbar klügste Maschine durch läppische Kleinigkeiten verwirren lässt. Schon die Veränderung einiger Pixel in einem Bild kann genügen, um beispielsweise einen Hund nicht mehr als solchen zu erkennen. Weiters mag eine Künstliche Intelligenz die Einwohnerzahlen Tausender Städte brav auswendig gelernt haben. Fragt man aber, ob Chicago oder eine Brotdose größer ist, scheitert sie jämmerlich. Dieser Vergleich sprengt ihren Horizont. Für uns, geprägt durch Evolution, Erfahrung und sinnliche Interaktion mit der Umwelt, ist dies selbstverständlich. Im Alltag bemerken wir die Grenzen solcher Systeme, wenn wir uns angesichts mancher Produktempfehlungen auf Websites oder der Resultate von Online-Übersetzungsprogrammen an den Kopf greifen.
All dies legt vor allem eines nahe: Eine künstliche Superintelligenz, in der Fachsprache „starke KI“ genannt, die mit fulminantem Allgemeinwissen in allen Bereichen des Lebens brilliert, wird es so schnell nicht geben. Schon gar nicht wird sie in absehbarer Zeit eine Bedrohung für uns darstellen. Walsh glaubt nicht einmal, dass es Artificial Intelligence unter die zehn größten Gefahren für die Menschheit schaffen wird.
Andererseits, auch wenn es beinahe wie ein Widerspruch wirken mag: In vielen Teilbereichen hat Künstliche Intelligenz durch Deep Learning zuletzt Fortschritte erzielt, die kaum jemand geahnt hätte – dort, wo es um die Erledigung genormter, klar definierter Spezialaufgaben in stabilem, unveränderlichem Umfeld geht, eben zum Beispiel in der kleinen Welt eines strikt begrenzten Schach- oder Go-Bretts. Diese Sparte, die „schwache KI“ heißt, wird unseren Alltag am ehesten umwälzen, sobald zentrale Probleme der Gegenwart gelöst sind, was wiederum, wenn man die Entwicklung der jüngeren Vergangenheit betrachtet, durchaus denkbar erscheint.
Sind Roboter Jobfresser?
Es existieren verschiedene Schätzungen darüber, wieviele Arbeitsplätze durch den Einsatz Künstlicher Intelligenz verschwinden werden. Extreme Prognosen gehen davon aus, dass fast 50 Prozent an Berufsbildern automatisierbar sind. Die meisten Experten halten das für deutlich zu hoch gegriffen und meinen: Bloß weil ein Job theoretisch von einer Maschine erledigt werden kann, heißt das noch lange nicht, dass das auch geschieht. Zum Beispiel sind Roboter heute durchaus in der Lage, Gemälde anzufertigen (auch wenn wir intuitiv fast immer erkennen, wer da am Werk war; offenbar haben wir diesbezüglich eine Art biologischen Detektor eingebaut). Aller Wahrscheinlichkeit nach werden die meisten Menschen aber auch in Zukunft Kunst bevorzugen, die durch Menschenhand entstanden ist. Der gesamte Kreativbereich wird vermutlich ein einigermaßen sicherer Hafen für den Menschen bleiben.
In anderen Berufen sieht das aber völlig anders aus, und unterm Strich beziffern moderate Prognosen den Jobverlust mit 20 bis 25 Prozent, wenn man wegfallende Berufe mit Jobverlagerungen und neu hinzukommenden Tätigkeiten gegenrechnet. Das ist freilich immer noch eine ganze Menge, und Fachleute richten dringende Appelle an die Politik, sich rasch Strategien einfallen zu lassen, um den damit verbundenen sozialen Problemen zu begegnen. Momentan sieht die Welt, ähnlich wie beim Klimawandel, den auf uns zurollenden Umwälzungen leider ziemlich tatenlos zu.
Einen Vorgeschmack auf die Welt der Zukunft liefern Amazon-Shops, die komplett ohne Personal auskommen. Der Kunde betritt den Laden, nimmt einfach, was ihm gefällt und geht. Um den Rest, Warenabwicklung und Bezahlung, kümmert sich die Software. Auch Finanzdienstleistungen werden bereits in so großem Maßstab von Automaten angeboten, dass Wissenschafter angesichts der zunehmenden Durchdringung der Gesellschaft mit diesen Systemen eine Kennzeichnung fordern: Der Klient soll erfahren, ob er es mit Mensch oder Maschine zu tun hat.
Die nachhaltigsten Einschnitte zeichnen im Bereich der Mobilität ab. Autonome Fahrzeuge mögen zwar ihre Tücken haben. Das zeigen peinliche Pannen und vereinzelt furchtbare Unfälle, zum Beispiel im März mit einem Uber-Taxi, in denen die Steuerungssoftware nicht oder viel zu spät eingriff, um eine Kollision abzuwenden. Allerdings: Es liegt noch nicht sehr weit zurück, dass sich nicht mal kühne Geister träumen ließen, dass sich ein Auto allein lenkt. Viel spricht dafür, dass Sensorik und die Verarbeitung von Input aus dem Verkehr so verbessert werden, dass ein akzeptables und vertretbares Niveau erreicht wird. Was bedeutet das? Es bedeutet, dass das selbststeuernde Fahrzeug beträchtlich weniger Fehler macht als der Mensch. Es heißt nicht, dass gar kein Fehler erlaubt ist. Das wäre in unserer Welt, in der fast nichts hundertprozentig sicher ist, illusorisch: bei der Maschine und erst recht beim Menschen. Noch debattieren Experten darüber, um welchen Faktor ein autonomes Fahrzeug zuverlässiger zu sein hat als ein humaner Lenker.
Zuerst wird es wahrscheinlich den Fernverkehr treffen. Besonders auf langen wie auch langweiligen Strecken, etwa in Australien, Amerika oder China, ist die Maschine der perfekte Chauffeur: Sie ermüdet nicht, braucht keine Ruhepausen, kann bei konstantem, klimafreundlichem Tempo durch die Landschaft rollen und ist aufgrund ihrer Ausdauer trotzdem schneller am Ziel. An die 90 Prozent aller Jobs in dem Bereich werden wegfallen, schätzen KI-Experten. In städtischen Gebieten voller Ampeln, Verkehrszeichen, Fußgänger, überraschener Zwischenfälle und sonstiger Unwägbarkeiten des zivilisatorischen Chaos wird es vermutlich länger dauern. Zuerst setzt sich Artificial Intelligence hier auf genormten Routen wie Buslinien durch, dann erobert sie etappenweise den Taxi- und Privatverkehr. Auf lange Sicht ist der Beruf des Fahrers damit wohl ein aussterbender Beruf.
In Fabriks- und Lagerhallen, im Dienstleistungs- und Servicegeschäft hingegen werden die in solide Körper gegossenen Varianten Künstlicher Intelligenz zum Einsatz kommen: die Roboter, gleichsam die Person gewordenen Ausprägungen denkender Maschinen – oder zumindest das synthetische Abbild davon.
Synthetische Persönlichkeiten
Viele Forscher glauben, dass es für wahre Intelligenz einen Körper braucht. Denn nur wenn eine Maschine Sinnesorgane besitze – Sensoren, die optische, akustische und taktile Umweltreize wahrnehmen, verarbeiten und abspeichern –, sei sie in der Lage, Fähigkeiten auszuprägen, die eine sinnvolle Interaktion mit der Welt erlauben. Roboter lernen dadurch allmählich, ihr Umfeld zu erkunden und sich darin zurechtzufinden, machen dabei eine Art künstlicher Kindheit durch. Robert Trappl arbeitet an seinem Wiener Institut mit Kollegen zum Beispiel an einem synthetischen Lehrling: Nach und nach erwirbt die Maschine Spezialwortschatz und lernt, verschiedene Bauteile, etwa in der Mechanik, korrekt zu benennen. Dann eignet sie sich die Kompetenz an, die Komponenten in vorgeschriebener Weise zusammenzubauen, jeden Handgriff stets mit dem abgespeicherten Lexikon abgleichend.
In vielen Bereichen sind Roboter, die Menschen unterstützen und sogar mit ihnen kooperieren, bereits im Einsatz: Zum Beispiel erledigen sie, etwa in Steinbrüchen, jene Jobs, die „dull, dirty and dangerous“ heißen: langweilig, schmutzig und gefährlich. Bergbau ist also für den Menschen definitiv kein Beruf der Zukunft, durchaus zum Glück. In manchen Lokalen servieren humanoide Roboter schon die Getränke, in Pflegeheimen kümmern sich Erfindungen wie die Roboterrobbe „Paro“ um alte oder einsame Menschen. Betrachtet man sie Situation global, findet man kaum mehr einen Bereich des Lebens, in dem Maschinen nicht ihre speziellen Aufgaben erledigen. Fast einfacher zu beantworten ist die Frage, welche Segmente Künstlicher Intelligenz verschlossen bleiben, zumindest mittelfristig. Die Antwort: wahrscheinlich alles, was feinmotorische Fertigkeiten erfordert. Grobe Tätigkeiten in einem berechenbaren Umfeld sind für Roboter leicht. Jobs dagegen, die Fingerspitzengefühl erfordern, keineswegs – vor allem dann, wenn sie in der unübersichtlichen Welt des Menschen zu erledigen sind. Daher kann eine Maschine problemlos einen Mähdrescher abseits öffentlichen Grunds dirigieren, Elektriker wird es aber weiterhin geben (vielleicht sogar mehr angesichts all der modernen Elektronik im Haushalt).
Berufsbilder könnten außerdem in einzelne Teilbereiche zerlegt werden, von denen manche automatisiert werden und andere nicht. Beispiel: Bestellen und Bezahlen im Restaurant kann maschinell vonstatten gehen, das Abräumen der Tische wird womöglich dem Menschen bleiben – schon deshalb, weil eine Reinigungskraft vorläufig immer noch billiger kommt als ein Roboter. Gleiches gilt fürs Hotel: Für die Rezeption ist die Maschine zuständig, fürs Putzen der Zimmer der Mensch. Eine „Entbündelung“ von Jobs nannte dies IT-Experte Moshe Vardi bei seinem Wienbesuch.
Wissenschafter debattieren aber noch ein wesentlich sensibleres Jobprofil: Sollen in Zukunft Roboter Krieg führen? Könnte Künstliche Intelligenz, fragt Toby Walsh,  die dritte Revolution in der Kriegsführung einläuten, nach der Erfindung des Schießpulvers und der Atombombe? Die Technologien wären vorhanden, und das nicht nur in Form von Drohnen, die der Aufklärung wie auch einem Angriff dienen können. Auf Youtube kann man sich Videos des Unternehmens Boston Dynamics ansehen, die den humanoiden Roboter „Atlas“ zeigen. Atlas läuft, eine Art Marschgepäck auf dem Rücken, durch unwegsames Gelände und überwindet allerlei Hindernisse. Man braucht nicht besonders viel Fantasie, um sich dabei an den „Terminator“ erinnert zu fühlen. Und es ist eine ziemlich schaurige Vorstellung, dass in gar nicht so ferner Zukunft Armeen realer Terminators die Akteure am Kriegsschauplatz sind – und als sprichwörtliche Kampfmaschinen bewaffnete Konflikte mitten in die Zivilbevölkerung tragen. Walsh fordert daher, die internationale Gemeinschaft solle eine Bann solcher Technologien beschließen.
Es gibt zum Glück aber auch viel freundlichere Entwicklungen, die vielleicht das Zeug haben, uns mit der Welt der Maschinen zu versöhnen: In Tokio wurde im Probebetrieb ein Cafè eröffnet, in dem humanoide Roboter, in adrettem Weiß ausgeführt und einer angedeuteten Schürze ausgestattet, die Getränke servieren. Das Besondere an dem Projekt ist jedoch, dass die Maschinen von behinderten Menschen per Fernsteuerung befehligt wurden, die etwa an der gravierenden Nerven- und Muskelkrankheit ALS litten. Die Aktionen der Roboterkellner ließen sich dabei sogar mittels Augenbewegungen bettlägriger Patienten steuern, wobei ein Computer die Signale übermittelte. Man wolle eine Welt erschaffen, in der auch schwer behinderte Menschen die Chance haben, am Arbeitsprozess teilzunehmen, hieß es in der Begründung des Projekts.
Vielleicht vermitteln solche Beispiele einen Eindruck, wie die ideale Partnerschaft von Mensch und Maschine ausehen könnte: Der Mensch denkt und befiehlt, die Maschine gehorcht und führt aus. Da hätte vermutlich auch Isaac Asimov keine Einwände gehabt.

















© profil









© profil















Newsletter


Stimmen Sie einer Datenverarbeitung von ActiveCampaign zu, um diesen Inhalt anzuzeigen.ActiveCampaign akzeptieren



































Drucken



                (profil.at)
                                            









 Alwin   Schönberger  


Ressortleitung Wissenschaft 



                              Mehr von Alwin   Schönberger  
                                  














Stimmen Sie einer Datenverarbeitung von Outbrain UK Ltd zu, um diesen Inhalt anzuzeigen.Outbrain UK Ltd akzeptieren


",NewsArticle,,https://www.profil.at/wissenschaft/profil-mensch-jahres-roboter-10536573, Künstliche Intelligenz: Warum Maschinen niemals klüger sind als der Mensch,2018-12-15T07:24:00+00:00,2023-01-05T19:15:06+00:00,"['https://image.profil.at/images/cfs_landscape_1232w_693h/4374809/10535978.jpg', 'https://image.profil.at/images/cfs_square_1232/4374809/10535978.jpg']","[{'@type': 'Person', 'name': 'Alwin   Schönberger', 'url': 'https://www.profil.at/author/alwin.schoenberger'}]","{'@type': 'Organization', 'name': 'profil.at', 'url': 'https://www.profil.at/', 'logo': {'@type': 'ImageObject', 'url': 'https://www.profil.at/assets/img/logo.105a6409d9636c824d23.png', 'width': 105, 'height': 48}}"
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3Lm1pY3Jvc29mdC5jb20vZGUtZGUvYmVybGluL2FydGlrZWwvbmV1ZXIta2ktZXhwZXJ0ZW5yYXQuYXNweNIBAA?oc=5,Neuer Expertenrat Künstliche Intelligenz tagt erstmals bei Microsoft Berlin - Microsoft,2018-12-13,Microsoft,https://www.microsoft.com,"Hochrangige Vertreterinnen und Vertreter aus Wirtschaft, Politik, Verwaltung und Wissenschaft wollen gemeinsam den KI-Standort Deutschland stärken.",N/A,N/A,N/A,,,N/A,N/A,N/A,,,,,,,,,

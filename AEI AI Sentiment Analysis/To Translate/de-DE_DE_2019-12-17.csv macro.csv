URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@graph,article:section,article:summary,article text,mainEntityOfPage,publisher,image,@type,headline,datePublished,dateModified,author
https://news.google.com/rss/articles/CBMiNGh0dHBzOi8vdGhlZGxmLmRlL2t1ZW5zdGxpY2hlLWludGVsbGlnZW56LWtpLWFrdGllbi_SAQA?oc=5,Künstliche Intelligenz – Kann man damit auch Aktienkurse vorhersagen? - The Digital Leaders Fund,2019-12-20,The Digital Leaders Fund,https://thedlf.de,Künstliche Intelligenz (KI) und Machine Learning krempeln die Unternehmenswelt um. Wie wirkt sich KI auf Aktien und Fondsmanagement aus?,N/A,Künstliche Intelligenz (KI) und Machine Learning krempeln die Unternehmenswelt um. Wie wirkt sich KI auf Aktien und Fondsmanagement aus?,"Methoden der „Künstlichen Intelligenz“ (Artificial Intelligence - AI) haben sich als horizontale Techniken etabliert und krempeln die Unternehmenswelt und die Wirtschaftssysteme um. Es gibt nationale Strategien dazu in China, USA und nun auch Europa, und Unternehmen wie Alphabet schwenken ",https://schema.org,"[{'@type': 'Article', '@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/#article', 'isPartOf': {'@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/'}, 'author': {'@id': 'https://thedlf.de/#/schema/person/4f4b70cc77539d3b89167837ea9fe450'}, 'headline': 'Künstliche Intelligenz – Kann man damit auch Aktienkurse vorhersagen?', 'datePublished': '2019-12-20T12:00:09+00:00', 'dateModified': '2021-11-16T13:21:17+00:00', 'mainEntityOfPage': {'@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/'}, 'wordCount': 844, 'commentCount': 0, 'publisher': {'@id': 'https://thedlf.de/#organization'}, 'image': {'@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/#primaryimage'}, 'thumbnailUrl': 'https://thedlf.de/wp-content/uploads/2019/12/KI-Aktien-Künstliche-Intelligenz-Aufgeschlagenes-Buch-und-Formeln-im-Hintergrund.jpg', 'articleSection': ['Besser Investieren', 'Neue Zeiten'], 'inLanguage': 'de-DE', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://thedlf.de/kuenstliche-intelligenz-ki-aktien/#respond']}]}, {'@type': 'WebPage', '@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/', 'url': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/', 'name': 'Künstliche Intelligenz – Kann man damit auch Aktienkurse vorhersagen?', 'isPartOf': {'@id': 'https://thedlf.de/#website'}, 'primaryImageOfPage': {'@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/#primaryimage'}, 'image': {'@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/#primaryimage'}, 'thumbnailUrl': 'https://thedlf.de/wp-content/uploads/2019/12/KI-Aktien-Künstliche-Intelligenz-Aufgeschlagenes-Buch-und-Formeln-im-Hintergrund.jpg', 'datePublished': '2019-12-20T12:00:09+00:00', 'dateModified': '2021-11-16T13:21:17+00:00', 'description': 'Künstliche Intelligenz (KI) und Machine Learning krempeln die Unternehmenswelt um. Wie wirkt sich KI auf Aktien und Fondsmanagement aus?', 'breadcrumb': {'@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/#breadcrumb'}, 'inLanguage': 'de-DE', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://thedlf.de/kuenstliche-intelligenz-ki-aktien/']}]}, {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/#primaryimage', 'url': 'https://thedlf.de/wp-content/uploads/2019/12/KI-Aktien-Künstliche-Intelligenz-Aufgeschlagenes-Buch-und-Formeln-im-Hintergrund.jpg', 'contentUrl': 'https://thedlf.de/wp-content/uploads/2019/12/KI-Aktien-Künstliche-Intelligenz-Aufgeschlagenes-Buch-und-Formeln-im-Hintergrund.jpg', 'width': 1280, 'height': 640, 'caption': 'KI Aktien - Künstliche Intelligenz - Aufgeschlagenes Buch und Formeln im Hintergrund'}, {'@type': 'BreadcrumbList', '@id': 'https://thedlf.de/kuenstliche-intelligenz-ki-aktien/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Start', 'item': 'https://thedlf.de/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Neue Zeiten', 'item': 'https://thedlf.de/category/kategorie-neue-zeiten/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Künstliche Intelligenz – Kann man damit auch Aktienkurse vorhersagen?'}]}, {'@type': 'WebSite', '@id': 'https://thedlf.de/#website', 'url': 'https://thedlf.de/', 'name': 'The Digital Leaders Fund (DLF)', 'description': 'Investieren in die Gewinner des digitalen Wandels', 'publisher': {'@id': 'https://thedlf.de/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://thedlf.de/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'de-DE'}, {'@type': 'Organization', '@id': 'https://thedlf.de/#organization', 'name': 'The Digital Leaders Fund', 'url': 'https://thedlf.de/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://thedlf.de/#/schema/logo/image/', 'url': 'https://thedlf.de/wp-content/uploads/2018/03/DLF_Monogram.png', 'contentUrl': 'https://thedlf.de/wp-content/uploads/2018/03/DLF_Monogram.png', 'width': 347, 'height': 376, 'caption': 'The Digital Leaders Fund'}, 'image': {'@id': 'https://thedlf.de/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/TheDLF/', 'https://twitter.com/the_dlf', 'https://www.instagram.com/digital_leaders_fund/']}, {'@type': 'Person', '@id': 'https://thedlf.de/#/schema/person/4f4b70cc77539d3b89167837ea9fe450', 'name': 'Baki Irmak', 'image': {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://thedlf.de/#/schema/person/image/fd2d58835aa4ef5aaf71895e30cef1a4', 'url': 'https://secure.gravatar.com/avatar/29c0d52df51f66a42b8599ab5621f03e?s=96&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/29c0d52df51f66a42b8599ab5621f03e?s=96&r=g', 'caption': 'Baki Irmak'}, 'description': 'Baki war viele Jahre in leitender Funktion für den Deutsche Bank Konzern und DWS tätig. Zuletzt u.a. als Global Head of Digital Business für die Deutsche Asset &amp; Wealth Management und Mitglied im Digital Executive Commitee der Deutschen Bank. Seine berufliche Laufbahn hat er als Fondsmanager für Technologie, Telekommunikation und Medien bei BHF Trust begonnen. Danach war er Fondsmanager bei der Commerzbank und ABN Amro.', 'url': 'https://thedlf.de/author/baki-irmak/'}]",N/A,N/A,"







Künstliche Intelligenz – Kann man damit auch Aktienkurse vorhersagen? 











Besser Investieren, Neue Zeiten 



20. Dezember 2019 



 



Methoden der „Künstlichen Intelligenz“ (Artificial Intelligence – AI) haben sich als horizontale Techniken etabliert und krempeln die Unternehmenswelt und die Wirtschaftssysteme um. Es gibt nationale Strategien dazu in China, USA und nun auch Europa, und Unternehmen wie Alphabet schwenken nun von einer Mobile-first auf eine AI-first-Strategie um. AI-Forscher sind die neuen Superstars unserer Zeit und fast berühmter als die CEOs der Unternehmen, für die sie arbeiten: Geoffrey Hinton (Alphabet), Yann LeCun (Facebook), Yoshua Benigio (Microsoft u.a.), Andrew Ng (Ex-Baidu).

Kai-Fu Lee – Jetzt geht es um KI-Implementierung
Nach Ansicht von KI-Pionieren wie Kai-Fu Lee leben wir heute im Zeitalter der KI-Implementierung. Dabei geht es nicht um bahnbrechende Forschungsergebnisse in Richtung einer generellen KI, also um lernende und intelligente Maschinen, sondern um auf konkrete Aufgaben hin optimierte Insellösungen. Für Lee sind die meisten “bahnbrechenden Erfolge”, über die täglich berichtet wird, nichts anderes als weitere Anwendungen von „Machine Learning“ (ML).



Gerade in Bereichen wie Bilderkennung- und Analyse (zum Beispiel Medizin) und Sprach- und Texterkennung (digitale Assistenten u.a.) haben ML-Anwendungen sich schon längst durchgesetzt. Mit ML können selbstfahrende Autos sehen, sie können aus den Bildpunkten ein Muster erkennen (rotes Achteck), analysieren, womit es korreliert ist (Stoppschild) und diese Information für eine Entscheidung nutzen (langsam bremsen), um uns sicher zu unserem Ziel zu bringen.
Viele unsere Digital Leader wie Alphabet, Amazon, Facebook und Baidu wenden ML in einer Vielzahl ihrer Angebote heute schon an. Die Fähigkeiten, neueste Technologien und wissenschaftlichen Erkenntnisse in kürzester Zeit in die Geschäftsprozesse zu adaptieren und in Umsatz und Produktivitätsgewinne zu übersetzen, ist einer der bedeutendsten Vorteil von Digital Leaders gegenüber traditionellen Unternehmen.
Wir haben jetzt gemeinsam mit über 60 Gründungsmitgliedern, darunter führende Unternehmen wie Deutsche Börse, Merck KGaA, Deutsche Bahn, Software AG, Samson, Forschungseinrichtungen wie die TU Darmstadt und die Goethe-Universität Frankfurt sowie führenden KI-Forschern wie Prof. Kristian Kersting (TU-Darmstadt) und Moritz Helmstaedter (Leiter Max-Planck-Institut für Hirnforschung) das AI-Frankfurt Rhein-Main gegründet, mit dem Ziel, die Anwendung von KI in der Region Rhein-Main voranzutreiben.
Für mich gibt es kein besseres Research für unseren Fonds als in Zusammenarbeit mit führenden Akademikern und realen Anwendern der KI zu lernen, was heute schon funktioniert und welche Limitationen KI hat.

Einsatz von KI im Fondsmanagement
Ein sehr umstrittenes Anwendungsgebiet für KI ist das Fondsmanagement. Im Wesentlichen geht es um die Frage, ob man mit Hilfe von KI-Methoden, insbesondere mit maschinellem Lernen, Kurse von zum Beispiel Aktien oder Anleihen vorhersagen kann. Kann das funktionieren, wenn ML zwar Korrelationen liefert, die wir meist nicht verstehen, aber nicht die Beziehung zwischen Ursache und Wirkung (Kausalität). Und falls eine Beziehung entdeckt werden sollte, bleibt diese dann stabil, wenn die Entdeckung zu massiven Geldallokationen führt?

KI Aktien – Abstimmung des AI Frankfurt Rhein-Main e.V.

Mein Partner Stefan Waldhauser hat schon in 1993 seine Diplomarbeit als Wirtschaftsmathematiker zum Thema “Aktienkursprognose mit neuronalen Netzen” verfasst. Er musste als Ergebnis seiner Arbeit enttäuscht feststellen, das die aufgrund des damaligen ersten KI-Hypes in den Großbanken losgetretene KI-Forschung im Asset-Management zumindest mit den damaligen Möglichkeiten trotz spannender Anfangserfolge wenig erfolgversprechend war. Nun sind seitdem weit mehr als 25 Jahre vergangen und wir stellen uns gemeinsam mit der Asset-Management-Industrie erneut die Frage, inwieweit KI im Jahre 2020 beim Management eines Fonds helfen oder dem menschlichen Stockpicker gar überlegen sein kann.

Dr. Bernd Scherer – Hipster versus Quant



Hierzu haben wir einen der führenden „Quants“ der Asset-Management-Industrie, nämlich Dr. Bernd Scherer, um eine fundierte Einschätzung gebeten. Herausgekommen ist meiner Meinung nach eine der besten Abhandlungen zu diesem Thema in deutscher Sprache: Hipster versus Quant – Wie anwendbar ist maschinelles Lernen im Asset-Management?


KI und Aktien? Dr. Bernd Scherer ist führender „Quant“ auf diesem Gebiet.


KI und Aktien – Fazit
Maschinelles Lernen in Reinform beansprucht für die Lösung eines Problems ausreichend viele Daten, eine große Rechenleistung und sehr gute Datenwissenschaftler. Eine Kenntnis des zugrundeliegenden Anwendungsgebietes (Domain-Know-How) ist nicht notwendig. In Reinform kann ML Muster erkennen, also Korrelationen identifizieren, aber keine Wirkungszusammenhänge (Kausalität) erklären. Es kann uns sagen, was wir tun müssen, um ein Ziel zu erreichen, aber nicht warum. Das ist schon an sich sehr unbefriedigend, nicht nur weil wir es nicht erklären können, sondern weil wir auf unvorhergesehene Ereignisse nicht reagieren könnten.
Zudem gibt es Eigenheiten bei der Prognose von Finanzmarktdaten, die eine Anwendung von ML massiv erschwert: Finanzmarktdaten sind nicht stationär. Werden Zusammenhänge entdeckt, so werden sie genutzt und somit verändert. Die Anzahl der Finanzdaten ist zudem beschränkt. ML in Reinform liefert jedoch bessere Ergebnisse, je größer die Datenmenge ist.
Bernd Scherer: “Die geringe Anzahl an erfolgreichen ML Fonds legt nahe, dass die Anwendung von ML zur Prognose von Wertpapierrenditen keinesfalls einfach ist. Nach einer Welle großer Begeisterung wird Ernüchterung eintreten.”
Der alchemistische Traum, Geld mühelos zu mehren, muss also noch warten.


Wie hat Dir der Artikel gefallen? (33 Stimmen, Durchschnitt: 3,97 von 5)Loading...



Autor






 


Baki Irmak


                                                                        Baki war viele Jahre in leitender Funktion für den Deutsche Bank Konzern und DWS tätig. Zuletzt u.a. als Global Head of Digital Business für die Deutsche Asset & Wealth Management und Mitglied im Digital Executive Commitee der Deutschen Bank. Seine berufliche Laufbahn hat er als Fondsmanager für Technologie, Telekommunikation und Medien bei BHF Trust begonnen. Danach war er Fondsmanager bei der Commerzbank und ABN Amro.                                                                    


Alle Beiträge ansehen






















 Share on facebook






 Share on twitter






 Share on linkedin











Kategorie: 

Besser Investieren, Neue Zeiten 





Von: 
										Baki Irmak					





										Dezember 20, 2019					





										Kommentar hinterlassen					














							Baki Irmak						


						Baki war viele Jahre in leitender Funktion für den Deutsche Bank Konzern und DWS tätig. Zuletzt u.a. als Global Head of Digital Business für die Deutsche Asset & Wealth Management und Mitglied im Digital Executive Commitee der Deutschen Bank. Seine berufliche Laufbahn hat er als Fondsmanager für Technologie, Telekommunikation und Medien bei BHF Trust begonnen. Danach war er Fondsmanager bei der Commerzbank und ABN Amro.					
















PrevZurückEtsy Aktie: Investieren in die größte Manufaktur der Welt 

NächstesMit der HubSpot Aktie in die Erfinder des Inbound Marketing investierenNächster 













Aktuelle Beiträge 



















				Wenn die letzten Bären sterben und Portfolio-Absicherungen günstig sind, fällt der Spagat zwischen Optimismus und Pessimismus leicht			



			5. Juli 2024		










				Rechenzentren-Aktien: Wachstum, Bewertungen, Perspektiven			



			4. Juli 2024		










				Kaspi, Nubank, Sea: Wie der EM Digital Leaders investiert			



			4. Juli 2024		










				Con Man schlägt Old Man und warum wir uns dennoch am meisten Sorgen um Europa machen müssen			



			28. Juni 2024		










				Serie Rechenzentren: Die Wertschöpfungskette			



			28. Juni 2024		










				Emerging-Markets-Aktien: Märkte, Performance, Perspektiven			



			27. Juni 2024		


















Schreibe einen Kommentar Antworten abbrechenDeine E-Mail-Adresse wird nicht veröffentlicht. Erforderliche Felder sind mit * markiertKommentar * Name * 
E-Mail * 
Website 
 

 









Neueste Beiträge 











				Wenn die letzten Bären sterben und Portfolio-Absicherungen günstig sind, fällt der Spagat zwischen Optimismus und Pessimismus leicht			



			5. Juli 2024		










				Rechenzentren-Aktien: Wachstum, Bewertungen, Perspektiven			



			4. Juli 2024		










				Kaspi, Nubank, Sea: Wie der EM Digital Leaders investiert			



			4. Juli 2024		










				Con Man schlägt Old Man und warum wir uns dennoch am meisten Sorgen um Europa machen müssen			



			28. Juni 2024		










				Serie Rechenzentren: Die Wertschöpfungskette			



			28. Juni 2024		










				Emerging-Markets-Aktien: Märkte, Performance, Perspektiven			



			27. Juni 2024		
















Tags 



SchlagwörterAlibaba
Alphabet
Alteryx
Amazon
AMD
Apple
Arista
Baidu
BBVA
China
China Aktien
Disney
DocuSign
Elastic
Etsy
Facebook
Goldman Sachs
IBM
Kaspi
Kaspi.kz
Match Group
Meituan
Meta
Netflix
Nubank
Nu Holding
Nutanix
NVIDIA
Pagseguro
Payment
Peloton
Pinterest
Pure Storage
SaaS
Sea Limited
Shoper
Spotify
Tencent
Tesla
The Trade Desk
TSMC
Twitter
Upstart
Wirecard
Zscaler












Neuste Kommentare 



Neueste KommentareThe DLF bei Nubank-Aktie – Der Wachstumsmotor brummt und brummtJohannes Stockmann bei Nubank-Aktie – Der Wachstumsmotor brummt und brummtChristian Bürger bei Halbleiter-Aktien: Wer macht für Anleger das Rennen?The DLF bei Investieren in das Nvidia-Ökosystem: Zulieferer, Kunden, PartnerHajo bei Investieren in das Nvidia-Ökosystem: Zulieferer, Kunden, Partner 











Twitter 









The Digital Leaders Fund


 Folgen                




 











The Digital Leaders Fund
@the_dlf
·

14 Jun



 


Die Wochenkolumne von @baki_irmakM: Fed ohne Plan. Nvidia und TSMC geben Anlegern den nötigen Durchblick – The Digital Leaders Fund (DLF)



 Auf Twitter antworten 1801670029437518220

 Retweet auf Twitter 1801670029437518220



 Auf Twitter liken 1801670029437518220
1


Twitter
1801670029437518220









The Digital Leaders Fund
@the_dlf
·

14 Jun



 


Nvidia eats the world: Die Wachstumstreiber des AI-Champions – The Digital Leaders Fund (DLF)



 Auf Twitter antworten 1801669755159409099

 Retweet auf Twitter 1801669755159409099



 Auf Twitter liken 1801669755159409099
1


Twitter
1801669755159409099









The Digital Leaders Fund
@the_dlf
·

14 Jun



 


BYD-Aktie: Warum die EU-Strafzöllchen die Aktie beflügeln – The Digital Leaders Fund (DLF) https://hubs.la/Q02BXcSw0



 Auf Twitter antworten 1801669587064238190

 Retweet auf Twitter 1801669587064238190



 Auf Twitter liken 1801669587064238190
1


Twitter
1801669587064238190









The Digital Leaders Fund
@the_dlf
·

14 Jun



 


In welche Höhen treiben Apple und Nvidia die TSMC-Aktie? – The Digital Leaders Fund (DLF) https://hubs.ly/Q02BXg5B0



 Auf Twitter antworten 1801669461453263211

 Retweet auf Twitter 1801669461453263211



 Auf Twitter liken 1801669461453263211
2


Twitter
1801669461453263211









The Digital Leaders Fund
@the_dlf
·

10 Jun



 


bDie Wochenkolumne von @baki_irmakM - warum es eine Demokratieprämie gibt. Absturz des Hindu-Predigers schafft Kaufgelegenheiten in Indien – The Digital Leaders Fund (DLF)



 Auf Twitter antworten 1800087126379229512

 Retweet auf Twitter 1800087126379229512



 Auf Twitter liken 1800087126379229512
2


Twitter
1800087126379229512


 
Mehr lesen ...













Instagram 







thedigitalleadersfund













 Teil 2 unserer Serie zu Rechenzentren von Ste






 Zur Jahresmitte bieten Emerging-Markets-A













 Berichtssaison für Q1 abgeschlossen! 

Z






 Spektakulärer Kursanstieg der Nvidia-Aktie! 






Ohne künstliche Intelligenz geht fast nichts

Sch






 Sea Limited hat es wieder einmal geschafft! D


 





 Große Neuigkeiten im Finanzsektor!  Am M


 





 Die aktuellen Zahlen von Spotify bestätigen 


 





Netflix hat kürzlich beeindruckende Zahlen veröf


 





Kaspi hat erneut starke Zahlen vorgelegt!  Das


 





Instagram-Beitrag 17860193172101351


 





 Entscheide dich für Einmalanlagen statt 


 





 Zenvia-Aktie im Aufschwung! Nach einem en


 





 Arista Networks auf dem Vormarsch!  Die e


 





 Wow, was für eine Entwicklung! Die Meta-


 





Spotify auf Erfolgskurs! Mit steigenden Umsätzen,


 





 Die Match Group hat gemischte Zahlen präsent


 





Die Aktie von AMD hebt ab!  Nach den beeindruc


 





Wow, die BBVA hat mal wieder beeindruckende Zahlen


 


 


Mehr laden…






 Auf Instagram folgen

















 







",,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vbmV0enBvbGl0aWsub3JnLzIwMTkvZm9yc2NodW5nc2luc3RpdHV0LXdhcm50LXZvci1zb3ppYWxlbi1mb2xnZW4tdm9uLWtpL9IBAA?oc=5,AI Now Report 2019: Forschungsinstitut warnt vor sozialen Folgen von KI - Netzpolitik.org,2019-12-17,Netzpolitik.org,https://netzpolitik.org,N/A,N/A,N/A,N/A,,,N/A,N/A,N/A,,,,,,,,
https://news.google.com/rss/articles/CBMiJWh0dHBzOi8vd3d3Lm1wZy5kZS9tYXNjaGluZWxsZXNsZXJuZW7SAQA?oc=5,Maschinelles Lernen - mpg.de,2019-12-17,mpg.de,https://www.mpg.de,"Die Augen sind unser Fenster zur Welt, verraten aber auch viel über uns. Das nutzen Andreas Bulling und seine Mitarbeiter am Max-Planck-Institut für Informatik in Saarbrücken und an der Universität Stuttgart aus, wenn sie Computern beibringen, unsere Blicke zu deuten. Letztlich wollen sie so auch Roboter oder Avatare in puncto Kommunikation auf Augenhöhe mit uns bringen.","Andreas Bulling, Roboter, Avatare, Augen","Die Augen sind unser Fenster zur Welt, verraten aber auch viel über uns. Das nutzen Andreas Bulling und seine Mitarbeiter am Max-Planck-Institut für Informatik in Saarbrücken und an der Universität Stuttgart aus, wenn sie Computern beibringen, unsere Blicke zu deuten. Letztlich wollen sie so auch Roboter oder Avatare in puncto Kommunikation auf Augenhöhe mit uns bringen.",N/A,,,N/A,N/A,"






Startseite





Newsroom





News




Maschinelles Lernen







Auge in Auge mit dem Rechner












17. Dezember 2019



Informatik


Künstliche Intelligenz


Roboter



Die Augen sind unser Fenster zur Welt, verraten aber auch viel über uns. Das nutzen Andreas Bulling und seine Mitarbeiter am Max-Planck-Institut für Informatik in Saarbrücken und an der Universität Stuttgart aus, wenn sie Computern beibringen, unsere Blicke zu deuten. Letztlich wollen sie so auch Roboter oder Avatare in puncto Kommunikation auf Augenhöhe mit uns bringen.
Text: Peter Hergersberg











Blickkontakt: Andreas Bullings Gruppe hat ein Computerprogramm entwickelt, das erkennt, ob eine Person einer anderen in die Augen schaut.


          © shutterstock
        

          Blickkontakt: Andreas Bullings Gruppe hat ein Computerprogramm entwickelt, das erkennt, ob eine Person einer anderen in die Augen schaut.
        

          © shutterstock
        


""Achten Sie öfter mal auf Ihre Augenbewegungen“, sagt Andreas Bulling zum Abschied lachend. Besser ist das. Denn im Gespräch mit ihm wird klar: Unsere Blicke, die uns die Welt zeigen, zeigen uns auch der Welt. Sie verraten etwas über unseren Charakter oder die soziale Dynamik in einer Gruppe, um nur zwei Beispiele für die Forschung des Informatikers zu nennen, der eine Forschungsgruppe am Saarbrücker Max-Planck-Institut für Informatik leitet und inzwischen auch eine Professur an der Universität Stuttgart übernommen hat.„Wir Menschen steuern und analysieren diese Signale unterbewusst“, sagt Andreas Bulling. „Manche Menschen können das nicht, etwa wenn sie unter Autismus leiden.“ Sie schauen manchmal an uns vorbei oder starren uns unverwandt an, und sie können umgekehrt unsere Blicke oft auch nicht richtig lesen. „Das kann sehr irritierend sein“, so Bulling.Seine Forschung könnte da Abhilfe schaffen. Denn der Informatiker bringt Computern bei, menschliche Augenbewegungen zu verstehen. Eine entsprechende Software könnte etwa Menschen mit Autismus bei der Interpretation der Blicke anderer und die Steuerung der eigenen Augenbewegungen unterstützen und passende Instruktionen etwa in eine Brille einspiegeln.Andreas Bulling und seine Mitarbeiter wollen Maschinen in Sachen Kommunikation darüber hinaus auf Augenhöhe mit uns Menschen bringen. So möchten sie langfristig etwa humanoiden Robotern ermöglichen, die Blicke von Menschen auch in einer größeren Personengruppe zu interpretieren und ihre Kameraaugen so zu steuern, dass wir ihr Blickverhalten als natürlich empfinden. Aber auch Fahrerassistenzsysteme könnten aus unseren Augenbewegungen wichtige Informationen ziehen. 










Lese-Prognose: Die Augenbewegungen beim Lesen untersuchen Forscher schon seit dem 19. Jahrhundert. Andreas Bullings… [mehr]Lese-Prognose: Die Augenbewegungen beim Lesen untersuchen Forscher schon seit dem 19. Jahrhundert. Andreas Bullings Team arbeitet nun an einem Modell, das alleine anhand des Textes vorhersagt, welche Wörter eine lesende Person fixieren wird. [weniger]

          © Wolfram Scheible
        

          Lese-Prognose: Die Augenbewegungen beim Lesen untersuchen Forscher schon seit dem 19. Jahrhundert. Andreas Bullings Team arbeitet nun an einem Modell, das alleine anhand des Textes vorhersagt, welche Wörter eine lesende Person fixieren wird.
        

          © Wolfram Scheible
        


Um das zu erreichen, bedienen sich Andreas Bulling und seine Mitarbeiter bei der computergestützten Analyse von Augenbewegungen eines entscheidenden Kniffs. „Wir waren die ersten, die dafür maschinelles Lernen nutzten.“ Die künstliche Intelligenz eröffnete dem Forscherteam völlig neue Möglichkeiten, in unseren Augen zu lesen.Die Erforschung des Blickverhaltens hat schon eine längere Tradition. Damit begonnen haben Forscher Ende des 19. Jahrhunderts. So verfolgte der französische Augenarzt Louis Émile Javal damals als erster, wie Menschen lesen. Dabei stellte er fest, dass unsere Augen nicht stetig über Schriftzeilen wandern, sondern von Wort zu Wort springen, wobei wir aber vor allem Schlüsselbegriffe fixieren, wie sich später herausstellte.Seit dem 20. Jahrhundert entdecken dann auch Unternehmen die Aussagekraft der Augenbewegungen. So untersuchen Zeitungs- und Magazinmacher, worauf sich unsere Augen in einem Artikel richten, und Marketing-Fachleute lassen analysieren, wie sie Werbung platzieren oder Informationen auf eine Verpackung drucken müssen, damit Kunden sie wahrnehmen. Und manche Webdesigner nutzen Auswertungen von Augenbewegungen, um Internetseiten so zu gestalten, dass die Blicke von Nutzern dort hängen bleiben, wo sie diese hinlenken möchten.Augenbewegungen als KommunikationskanalWie Kunden Entscheidungen treffen, ist nur einer der Denkprozesse, die Kognitionswissenschaftler anhand von Blickanalysen untersuchen. „Wir nutzen Augenbewegungen gewissermaßen als Fenster zu kognitiven Prozessen“, sagt Peter König, Professor an der Universität Osnabrück. „Sie sind ein Paradigma für die Funktion des Gehirns.“Nun haben auch Computerwissenschaftler wie Andreas Bulling Augenbewegungen als Datenquelle und Kommunikationskanal für sich entdeckt. Bullings Gruppe geht es dabei nicht nur um kognitive Prozesse, sondern auch um unser Verhalten, etwa bei der Nutzung von digitalen Geräten. Zu diesem Zweck bringt Andreas Bulling Computern erst einmal bei, die Blickrichtung richtig zu erkennen, und zwar nicht nur in einem perfekt ausgeleuchteten Gesicht und in immer gleicher Laborumgebung, wie es beim computergestützten Abschätzen der Blickrichtung bis dato üblich war.Wenn Wissenschaftler Computern beibringen, die Richtung abzuschätzen, in die ein Mensch guckt, setzen sie schon länger auf maschinelles Lernen. Lange nutzten sie für das Training der Rechner jedoch wenig alltagsnahe Daten. Um das zu ändern, installierten die Forscher um Andreas Bulling auf den Notebooks von 15 Freiwilligen ein Programm, das die Probanden beim Arbeiten am Rechner über mehrere Tage hinweg immer wieder aufforderte, einen Punkt auf dem Bildschirm zu fixieren, und dann ein Foto machte.










Fokussiert: Andreas Bulling (rechts entwickelt unter anderem mit Sander Staal von der ETH Zürich Modelle unserer… [mehr]Fokussiert: Andreas Bulling (rechts entwickelt unter anderem mit Sander Staal von der ETH Zürich Modelle unserer Aufmerksamkeit, um etwa Benachrichtigungen über neue eMails so zu gestalten, dass sie die Arbeit am Computer kaum stören. [weniger]

          © Wolfram Scheible
        

          Fokussiert: Andreas Bulling (rechts entwickelt unter anderem mit Sander Staal von der ETH Zürich Modelle unserer Aufmerksamkeit, um etwa Benachrichtigungen über neue eMails so zu gestalten, dass sie die Arbeit am Computer kaum stören.
        

          © Wolfram Scheible
        


So erhielt das Team Bilder in wechselnder Umgebung und bei oft schlechten Lichtverhältnissen. Da sie zudem wussten, wohin die Hilfskräfte geschaut hatten, entstand auf diese Weise ein umfangreicher Datensatz, mit dem die Forscher anschließend ein Programm trainierten, Blicke auch unter schwierigen Bedingungen zu lokalisieren. „Dieser Datensatz ist viel größer und natürlicher und dadurch auch anspruchsvoller als diejenigen, die es vorher gab“, sagt Bulling. „Aber er ist noch immer nicht optimal.“ So saßen die Personen bei der Aufnahme der Trainigsdaten immer vor Computern, auf die sie mehr oder weniger frontal schauten. Wenn sich jemand bewegt oder einen Punkt aus dem Augenwinkel anpeilt, erkennt das Programm die Augenposition kaum noch. „Für uns ist es deshalb auch ein Thema, wie wir zu noch realistischeren Datensätzen kommen.“Eine Möglichkeit dafür bieten mobile Eyetracker. Solche Geräte arbeiten ziemlich genau, sind bislang allerdings recht auffällig: An einem brillenartigen Gestell sind verschiedene Kameras befestigt, die das Auge und das Gesichtsfeld einer Person aufnehmen, sowie Infrarot-LEDs, deren Reflexe die Kameras aufzeichnen. Wer ein solches Gerät trägt, ähnelt einem Cyborg. Mitmenschen kann das ziemlich irritieren.Für einen alltäglichen Einsatz hat das Team von Andreas Bulling daher den Prototypen eines Eyetrackers mit einer Handvoll handelsüblicher Kameras entwickelt, die nur wenig größer als Stecknadelköpfe sind. Dass diese Kameras nur eine beschränkte Auflösung haben, machen die Forscher mit dem richtigen Training wett. Mit Daten, welches Kamerabild zu welcher Augenposition gehört, bringen sie einem Computer bei, auch die Aufnahmen der sehschwachen Kameras richtig zu deuten. Inzwischen vermarktet das Berliner Start-up Pupil Labs, an dem Andreas Bulling beteiligt ist, einen Eyetracker, der sich kaum noch von einer etwas auffälligeren Brille unterscheidet und auf dem Konzept der Saarbrücker Forscher basiert.„Solange wir unauffällige Eyetracker noch nicht in der alltäglichen Kommunikation brauchen, können die Geräte in der Marktforschung oder bei Computerspielen in der virtuellen Realität Anwendung finden“, sagt Bulling. Vor allem sind sie jedoch für die Forschung interessant. „In Studien, in denen es um die soziale Interaktion geht, ermöglichen sie einen natürlicheren Umgang unter den Teilnehmern.“ Das dürfte auch die Untersuchungen von Bullings Team zur Dynamik in Gruppen künftig noch aussagekräftiger machen.Warnhinweise für Display-FixierteÜberraschende Perspektiven für die computergestütze Blickanalyse haben die Computerwissenschaftler aber auch schon mit den herkömmlichen Eyetrackern aufgetan. So staffierten die Forscher 20 Testpersonen mit solchen Blickfängern aus und verfolgten deren Augenbewegungen, während die Probanden ihre Smartphones verwendeten. Zusätzlich erfassten die Forscher, welche App die Teilnehmer auf ihrem Mobilgerät gerade nutzten, und analysierten die Szene um die Teilnehmer herum.Die steile These hinter der Datensammlung: Anhand der Augenbewegungen lasse sich vorhersagen, ob sich die Aufmerksamkeit eines Smartphone-Nutzers in den nächsten Sekunden der Umgebung zuwenden und dort bleiben wird. Tatsächlich erlernte der Computer mit den Daten ein Modell, das dies zumindest in Teilen leistet.Mit solchen Modellen könnten Smartphone-Apps abschätzen, ob ein Mensch, der auf sein Telefon starrend durch die Gegend läuft, ein Hindernis übersehen könnte und den Display-fixirten Nutzer dann noch rechtzeitig warnen. Aufmerksamkeitsanalysen, die Andreas Bulling nun mit einem ERC-Grant vorantreiben kann, könnten zudem Hinweise geben, wie sich der Fokus einer Person etwa auf einem Text halten lässt. „Auf diese Weise ließe sich vielleicht der Entwicklung entgegenwirken, dass sich Menschen immer leichter von einer Aufgabe ablenken lassen“, so der Forscher.Helfen können Eyetracker auch bei Analysen, wie die Stimmung in einer diskutierenden Gruppe ist und wer darin das Sagen hat. Entscheidendes Hilfsmittel war dabei eine Methode, die Philipp Müller, ein Doktorand am Max-Planck-Institut für Informatik, entwickelt hat. Sie erkennt auf gewöhnlichen Kameraaufnahmen einer diskutierenden Gruppe, wer wen ansieht und wer konsequent an jemand anderem oder an allen anderen vorbeischaut. Sie kann darüber hinaus Stimmungen aus den Gesichtern ablesen. Kombiniert unter anderem mit Analysen des Tonfalls lässt sich aus diesen Merkmalen gut ableiten, ob eine Debatte eher konstruktiv verläuft und wer sich darin als Wortführer hervortut.










Blickfang für den Alltag: Auf Basis von Arbeiten der Saarbrücker Max-Planck-Forscher hat das Berliner Unternehmen Pupil… [mehr]Blickfang für den Alltag: Auf Basis von Arbeiten der Saarbrücker Max-Planck-Forscher hat das Berliner Unternehmen Pupil Labs einen mobilen Eyetracker entwickelt, der einer normalen Brille ähnelt. [weniger]

          © Pupil Labs 
        

          Blickfang für den Alltag: Auf Basis von Arbeiten der Saarbrücker Max-Planck-Forscher hat das Berliner Unternehmen Pupil Labs einen mobilen Eyetracker entwickelt, der einer normalen Brille ähnelt.
        

          © Pupil Labs 
        


Dass unsere Blicke viel über die Dynamik einer Gruppe aussagen, ist für Menschen leicht nachvollziehbar: Wer in der Gruppe das Sagen hat, zieht häufiger auch alle Blicke auf sich. Und bei schlechter Stimmung starren Menschen eher betreten zu Boden, als den Augenkontakt der anderen zu suchen. Diese Signale der nonverbalen Kommunikation sollen künftig auch Computer deuten können.Nicht immer jedoch lassen sich die Ergebnisse, die eine statistische Analyse des maschinellen Lernens aus unseren Blicken liefert, mit einem konkreten Blickmuster erklären. Wenn es zum Beispiel um Merkmale unserer Persönlichkeit geht, sind subtile Muster unserer Augenbewegungen entscheidend. So gelangten die Forscher um Andreas Bulling zusammen mit Kollegen von der University of South Australia mit der Kombination aus Eyetracking und Maschinellem Lernen zu belastbaren Aussagen über vier Charakterzüge ihrer Testpersonen.Dafür zeichneten die Wissenschaftler die Augenbewegungen von 42 Studienteilnehmern auf, während diese eine im Schnitt zwölf Minuten dauernde Aufgabe auf dem Saarbrücker Campus erledigten. Mit den Blickdaten eines Teils der Probanden, die zudem einen psychologischen Standardfragebogen ausfüllten, fütterten sie ein Modell. Auf diese Weise trainiert, konnte der Rechner den anderen Probanden an den Augen ablesen, wie neurotisch sie ist, wie gut sie sich mit anderen verträgt, ob sie extrovertiert durchs Leben geht und wie gewissenhaft sie eine Aufgabe erledigt.Bei drei weiteren Eigenschaften, mit denen Psychologen eine Persönlichkeit skizzieren, gab das Modell allerdings noch keine brauchbare Einschätzung ab. „Und die Vorhersagen sind derzeit auch noch nicht genau genug für praktische Anwendungen“, sagt Andreas Bulling. Aber das System wird künftig sicherlich noch zuverlässiger. Denn Datensätze von 42 Studienteilnehmern erlauben nicht gerade ein besonders differenziertes Training für diese diffizile Aufgabe. Mit mehr Anschauungsmaterial dürfte die Charakteranalyse daher präziser werden.Datenschutz - ein wichtiges Thema beim EyetrackingFür unseren Umgang etwa mit Robotern oder Avataren sind das vielversprechende Aussichten, schließlich sollen den Computersystemen auf Dauer alle verbalen und nonverbalen Kommunikationskanäle offenstehen, die auch wir Menschen nutzen. Die Perspektiven, dass ein Rechner alleine aufgrund unseres weitgehend vom Unterbewussten gesteuerten Blickverhaltens ein Persönlichkeitsprofil erstellt, kann aber auch beängstigend wirken.Andreas Bulling ist sich bewusst, dass die Software die Möglichkeit eröffnet, Menschen einer computergestützten Charakterprüfung zu unterziehen – eine Möglichkeit, die von Unternehmen oder autokratischen Regimen missbraucht werden könnte, die heute schon das Verhalten von Menschen digital analysieren. Der Informatiker betont allerdings, dass die Technik noch lange nicht in der Lage ist, Persönlichkeitsmerkmale eines Menschen zuverlässig und ohne dessen Mithilfe zu ermitteln. Allein schon deshalb, weil eine Person den Eye-Tracker dafür momentan unmittelbar vor ihren Augen tragen müsse.Und selbst wenn es einmal möglich werden sollte, den Charakter von Menschen per Ferndiagnose und mit wenig Aufwand aus unseren Blicken zu lesen, lasse sich die Technik wie die meisten Erfindungen zum Wohl und zum Wehe der Menschen einsetzen. „Aber schon heute wird man zum Beispiel bei einem Bewerbungsgespräch hinsichtlich der Persönlichkeit, Einstellungen und Absichten analysiert – vom Menschen gegenüber“, sagt Andreas Bulling. „Das ist den meisten jedoch nicht bewusst oder wird als selbstverständlich akzeptiert, da es ein Mensch macht.“Auch wenn die Wissenschaftler wie ihre Kollegen in vielen Forschungsfeldern den Missbrauch ihrer Errungenschaften nicht ausschließen können, wollen sie zumindest dazu beitragen, ihn möglichst zu erschweren. Andreas Bulling hat daher auch den Datenschutz beim Eyetracking zu seinem Thema gemacht. „Für mich ist das ein sehr wichtiger Aspekt. Wie im Umgang mit anderen digitalen Anwendungen, vor allem mit sozialen Medien, müssen wir den Datenschutz beim Eyetracking berücksichtigen“, sagt er. „Wir sind führend in der Forschung zu diesem Thema und werden unsere Aktivitäten dazu in den kommenden Jahren noch ausbauen.“










Gute Perspektive: Andreas Bulling ist überzeugt, dass er mit der Analyse von Augenbewegungen für die nonverbale Mensch-… [mehr]Gute Perspektive: Andreas Bulling ist überzeugt, dass er mit der Analyse von Augenbewegungen für die nonverbale Mensch-Maschine-Kommunikation sein weiteres Forscherleben leicht füllen kann. [weniger]

          © Wolfram Scheible
        

          Gute Perspektive: Andreas Bulling ist überzeugt, dass er mit der Analyse von Augenbewegungen für die nonverbale Mensch-Maschine-Kommunikation sein weiteres Forscherleben leicht füllen kann.
        

          © Wolfram Scheible
        


Die informationelle Selbstbestimmung greift zwar gewöhnlich erst, wenn es um deren konkrete Verwendung geht. Aber Daten, die es nicht gibt, können nicht missbraucht werden. So haben Andreas Bulling und seine Mitarbeiter sich mit dem Datenschutz bei den Kamerabildern beschäftigt, die Eyetracker von den Szenen vor den Augen ihrer Träger machen. Dank dieser Aufnahmen erkennen die Geräte nicht nur, wohin eine Person guckt, sondern auch, was sie dort sieht.Ins Blickfeld der Kamera können aber unversehens Passwörter oder Geheimzahlen geraten, und natürlich Menschen, die wahrscheinlich nicht ungefragt erfasst werden wollen. Um das zu verhindern, helfen einmal mehr Blickanalysen und die Lernfähigkeit der richtigen Software. Mittels der Szenenkamera lässt sich nämlich gut erkennen, ob wir am Rechner gerade unser Bankkonto öffnen, am Geldautomaten die PIN eingeben, oder einer fremden Person gegenüberstehen. Die Lösung für eine solche Situation ist sehr analog: Die Software lässt einfach einen Deckel vor die Kamera schieben. „Da die Szene dann nicht mehr analysiert werden kann, leiten wir stattdessen aus den Augenbewegungen ab, ob und wann die Person die sensible Situation wieder verlässt,“ so Bulling.Hier trägt die Gelehrigkeit der Software zur Lösung eines Datenschutzproblems bei. Manchmal wird sie aber auch selbst zum Problem. Denn ein entsprechend trainiertes Programm kann aus dem Muster der Augenbewegungen weit mehr ablesen als wir Menschen. Zum Beispiel, ob eine Frau oder ein Mann den Eyetracker trägt. „Es sind aber nur manche Merkmale in den Augenbewegungen, aus denen das Geschlecht hervorgeht“; erklärt er. „Weil wir die für andere, gewünschte Analysen nicht brauchen, verrauschen wir sie.“ Ähnlich lasse sich auch mit anderen Informationen aus unseren Blicken umgehen. „Was erhalten und was verrauscht werden soll, wird der Nutzer zukünftig dann selbst entscheiden können“.Ob es um nonverbale Kommunikation mit Menschen oder Maschinen geht, um eine lebensechte virtuelle Realität, die Nutzung digitaler Geräte oder den Schutz der Blickanalysen, die dabei helfen: Mit Künstlicher Intelligenz die Daten von Augenbewegungen zu analysieren, hat sich für Andreas Bulling als sehr fruchtbringend erwiesen. Und er ist sicher, dass das auch so bleiben wird: „Das ist eine Goldgrube“, sagt Bulling. „Damit kann ich mein weiteres Forscherleben leicht ausfüllen.“Auf den Punkt gebrachtAugenbewegungen tragen wesentlich zur nonverbalen Kommunikation von Menschen bei. Diesen Kommunikationskanal sollen künftig auch Computersysteme wie etwa Roboter oder Fahrerassistenzsysteme nutzen.Die Gruppe von Andreas Bulling verfeinert die computergestützten Methoden, welche die Blickrichtung von Personen abschätzen. Zudem entwickelt sie mithilfe des maschinellen Lernens Modelle, die aus Augenbewegungen Charakterzüge oder die Stimmung in einer Gruppe ableiten. So können Computer auch lernen, etwa Kameraaugen eines Roboters natürlich zu steuern.Die Forscher arbeiten an verschiedenen technischen Lösungen, um den Datenschutz bei der Analyse von Augenbewegungen zu gewährleisten. 

",,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vZnV0dXJlem9uZS5hdC9iMmIvbm92b21hdGljLXdpci1zaW5kLXNlaHItbmFoZS1hbi1laW5lci1yZXZvbHV0aW9uLzQwMDcwODAzONIBWGh0dHBzOi8vZnV0dXJlem9uZS5hdC9hbXAvYjJiL25vdm9tYXRpYy13aXItc2luZC1zZWhyLW5haGUtYW4tZWluZXItcmV2b2x1dGlvbi80MDA3MDgwMzg?oc=5,NOVOMATIC: „Wir sind sehr nahe an einer Revolution“ - futurezone.at,2019-12-20,futurezone.at,https://futurezone.at,Die Digitalisierung könnte zur nächsten Industriellen Revolution werden. Österreich ist hier laut Novomatic schon gut aufgestellt.,"Alexander Sekanina,Blockchain,Digitalisierung,Futurezone,Hausaufgabe,Novomatic,Österreich",Die Digitalisierung könnte zur nächsten Industriellen Revolution werden. Österreich ist hier laut Novomatic schon gut aufgestellt.,N/A,https://schema.org,,B2B,N/A,"










                        Produkte
                                            

Apple AirTag gegen Google-Tracker: Der Sieger ist eindeutig


",https://futurezone.at/b2b/novomatic-wir-sind-sehr-nahe-an-einer-revolution/400708038,"{'@type': 'Organization', 'name': 'futurezone.at', 'url': 'https://futurezone.at/', 'logo': {'@type': 'ImageObject', 'url': 'https://futurezone.at/assets/img/logo.af9f6e3cd2039102239e.png', 'width': 989, 'height': 400}, 'sameAs': ['https://de-de.facebook.com/futurezoneat/', 'https://twitter.com/futurezoneat?lang=de', 'https://www.instagram.com/futurezoneat/', 'https://www.youtube.com/user/FUTUREZONEat']}","['https://image.futurezone.at/images/cfs_landscape_1232w_693h/4008021/sekanina_alexander_di_dr_ordercontrol_nag_225x335mm_300dpi.jpg', 'https://image.futurezone.at/images/cfs_square_1232/4008021/sekanina_alexander_di_dr_ordercontrol_nag_225x335mm_300dpi.jpg']",NewsArticle,NOVOMATIC: „Wir sind sehr nahe an einer Revolution“,2019-12-20T08:00:11+00:00,2021-07-03T04:15:01+00:00,"{'@type': 'Organization', 'name': 'futurezone.at', 'url': 'https://futurezone.at/'}"

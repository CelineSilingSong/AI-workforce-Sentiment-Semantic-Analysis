URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,article:section,article:summary,article text,@context,@type,@id,url,name,datePublished,dateModified,isPartOf,primaryImageOfPage,breadcrumb,mainEntityOfPage,publisher,articleSection,author,headline,alternativeHeadline,image,isAccessibleForFree,hasPart,articleBody,operatingSystem,applicationCategory,applicationSubcategory,itemListElement
https://news.google.com/rss/articles/CBMiOmh0dHBzOi8vdGF6LmRlL0FyYmVpdHNiZWRpbmd1bmdlbi1iZWktVlctVG9jaHRlci8hNTc4MzcxNS_SAQA?oc=5,"Arbeitsbedingungen bei VW-Tochter: Sie sollen fahren, nicht pinkeln - taz.de",2021-07-02,taz.de,https://taz.de,Bei der Volkswagentochter Moia wird die Arbeit über künstliche Intelligenz organisiert. Für die Ar­beit­neh­me­r*in­nen bringt das einige Probleme.,"Arbeitsrecht, Betriebsrat, Kapitalismus, Hamburg, Nord, taz, tageszeitung ",Bei der Volkswagentochter Moia wird die Arbeit über künstliche Intelligenz organisiert. Für die Ar­beit­neh­me­r*in­nen bringt das einige Probleme., Bei der Volkswagentochter Moia wird die Arbeit über künstliche Intelligenz organisiert. Für die Ar­beit­neh­me­r*in­nen bringt das einige Probleme.,N/A,N/A,"
Arbeitsbedingungen bei VW-Tochter: Sie sollen fahren, nicht pinkeln

Bei der Volkswagentochter Moia wird die Arbeit über künstliche Intelligenz organisiert. Für die Ar­beit­neh­me­r*in­nen bringt das einige Probleme.
So märchenhaft wie im Miniatur-Wunderland geht es im echten Leben nicht zu bei Moia  Foto: Christian Charisius/dpa
HAMBURG taz | Wenn das Auto der Arbeitsplatz ist, bedeutet eine kurze Toiletten- oder Rauchpause einen größeren Aufwand als im Büro oder im Homeoffice. Aber so umständlich wie für die Fah­re­r*in­nen von Moia sollte es nicht sein. Bei der VW-Tochter, deren goldfarbene Elektro-Kastenwagen meist geräuschlos und leer durch Hamburg und Hannover gleiten, müssen die Fah­re­r*in­nen eine Toilettenpause per Knopfdruck im digitalen System beantragen. Solche „außergewöhnlichen Pausen“ gehören nicht zur „produktiven Zeit“, werden daher aus der bezahlten Arbeitszeit herausgerechnet, und nur im Ausnahmefall überhaupt genehmigt. Aber das ist nicht das einzige Problem, mit dem Mit­ar­bei­te­r*in­nen zu kämpfen haben.
Am Anfang habe eigentlich alles ganz okay gewirkt, erzählt der Fahrer Manuel Wagner (Name geändert). Doch dann hätten sich die Bedingungen bei dem Start-up stetig verschlechtert. Moia wurde 2016 als Tochter des Volkswagenkonzerns gegründet, um neue Mobilitätskonzepte zu entwickeln. 2017 startete eine Flotte in Hannover, 2019 in Hamburg.
Anzeige
Das Konzept „Ridepooling“ funktioniert so, dass mehrere Fah­re­r*in­nen im Innenstadtbereich unterwegs sind und auf Anfragen der Kun­d*in­nen über eine App warten. Ein Algorithmus berechnet die Routen so, dass mehrere Fahrgäste eingesammelt werden, die in eine ähnliche Richtung wollen. Die Entwicklung der Apps, des Algorithmus, der Elektrofahrzeuge und der Infrastruktur liegt bei Moia, auch den Dienstplan erstellt ein Algorithmus.
Aber nach dem Corona-Lockdown, in dem die meisten Angestellten in Kurzarbeit waren, kam das Management plötzlich mit einigen Einschnitten für die Mit­ar­bei­te­r*in­nen um die Ecke, die es in bester Start-up-Manier, also mit viel Dank für das Verständnis und die gemeinsame Kraftanstrengung, als neues Arbeitszeitmodell verkaufte. Es beinhaltet die technische Dokumentation jeder Arbeitszeitunterbrechung, auch den Toilettengang. „Grundsätzlich werden solche Arbeitszeitunterbrechungen von der Arbeitszeit abgezogen“, schrieb Moia Anfang Mai an die Mitarbeiter*innen. „Es ist wichtig zu wissen, dass solche Unterbrechungen nur im Ausnahmefall vorgenommen werden können, weil diese den laufenden technischen Betrieb in extremer Weise stören.“
Den Pausenort schreibt die KI vor
„Es kommt vor, dass du eine Unterbrechung beantragst, aber das System sie dir verwehrt“, sagt Wagner. „Zum Beispiel, wenn es eine Stunde vor der Mittagspause ist.“ Das mit den Pausen: auch so eine Sache. Zu Schichtbeginn wissen die Fah­re­r*in­nen nicht, wann und wo ihre Pause sein wird, sie haben nur ein grobes Zeitfenster. Der Algorithmus teilt es ihnen dann mit, wenn es gut passt, weil die Nachfrage gerade niedrig ist. Sie steuern einen vorgeschriebenen Ort an, in Hamburg sind das ausgewählte Parkplätze von Einkaufszentren oder einem Krankenhaus. Per GPS-Ermittlung geht die Pausenzeit automatisch los, sobald der Fahrer dort einrollt, abzüglich einer Minute „Rüstzeit“, in der das Auto an eine Ladestation angeschlossen werden muss.
Die Rüstzeiten wurden auch mit dem neuen Arbeitszeitmodell eingeführt: Vor Schichtbeginn gibt es fünf, nach Schichtende zehn Minuten, in denen die Fah­re­r*in­nen ein- und auschecken, das Fahrzeug auswählen, das System hochfahren, eine Abfahrtskontrolle vornehmen, sich beim Pooling an- oder abmelden und am Ende das Auto reinigen und laden müssen. „Das ist in der kurzen Zeit unmöglich zu schaffen“, sagt Wagner.
Anzeige
Kein Problem, sagt Moia: Für die Vergütung zu viel gearbeiteter Minuten könnten die Angestellten später einen Antrag auf Erstattung stellen. Das gelte auch für unvermeidliche ­Toilettenpausen, räumte das Unternehmen ein, nachdem die Gewerkschaft IG Metall Druck gemacht und Medien über den Missstand berichtet hatten. Auf taz-Nachfrage betont die Moia-Sprecherin Jennifer Langfeldt: „Wir widersprechen entschieden der Darstellung, dass Toilettenpausen nicht vergütet werden. Toilettenpausen werden bei Moia bezahlt.“ Das heißt, wenn man den Antrag stellt. Auch die Zeit, die man dafür aufwendet, kann man sich zurückerstatten lassen: Zwei Minuten pro Antrag sieht Moia dafür vor. „Viele Kol­le­g*in­nen verzichten lieber gleich darauf“, sagt Wagner.
Wer nicht sauber arbeitet oder nicht bereit ist, Überstunden zu machen, kann den Job schnell verlieren. Wie Frederik Bruns (Name geändert). Er kandidiert als erster Betriebsrat am Standort Hamburg, Mitte Juli soll die Wahl stattfinden. Aber schon die Unterschriften für die Kandidatur zu sammeln, war schwierig, denn Bruns hat Hausverbot.

Aus einer internen Mitteilung von Moia„Solche Unterbrechungen können nur im Ausnahmefall vorgenommen werden, weil diese den technischen Betrieb in extremer Weise stören“

Am 4. Mai fand er morgens das Kündigungsschreiben in seinem Briefkasten, ohne Poststempel. Es müsse ihm nachts per Bote zugestellt worden sein, sagt er. Ein Grund für die außerordentliche fristlose Beendigung des Arbeitsverhältnisses steht nicht auf dem Schreiben, das der taz vorliegt. „Ich bin dem Unternehmen unbequem geworden“, vermutet der Fahrer, der seit dem Start der Flotte in Hamburg dabei ist. Im Zuge der Betriebsratsgründung hätten noch fünf andere Kan­di­da­t*in­nen das Unternehmen verlassen, alle mit einer Abfindung, sagt Bruns. Nur er habe diese ausgeschlagen. Bruns habe Flyer verteilt und in Firmenchats gegen das neue Arbeitszeitmodell mobilisiert. Auch über die Pausenorte habe er sich häufig beim Management beschwert.

Sind menschliche Fah­re­r*in­nen bald überflüssig?
In einem Einkaufszentrum im Hamburger Norden etwa sei der vorgeschriebene Pausenort direkt neben den Mülltonnen, beim ­Asklepios-Krankenhaus direkt neben dem Corona-Testzentrum, beim Krankenhaus St. Georg betrug der Weg zur Toilette acht Gehminuten. Bei den Rewe-Parkplätzen gibt es gar keine Außentoiletten, dort müssen die Fah­re­r*in­nen an der Kasse nach einem Schlüssel fragen – in Moia-Uniform, während hinter ihnen die Einkaufenden Schlange stehen. „Das ist entwürdigend“, sagt Bruns. Gegen seine Kündigung hat er Klage eingereicht, der Verhandlungstermin ist für August angesetzt. Gegen das Hausverbot prüft er ein Eilverfahren.
Aber warum hat eine Volkswagentochter es überhaupt nötig, ihre Mit­ar­bei­te­r*in­nen so zu triezen und jede Pausenminute vom Lohn abzuziehen? „Das Konzept ist nicht ­lukrativ“, vermutet Bruns. Tatsächlich fahren die Sammeltaxis oft höchstens mit einem Gast ihre digital berechneten Routen ab. Der Preis variiert je nach Nachfrage und ist vielen potenziellen Gästen möglicherweise einfach zu hoch. Und dann noch die Umwege, um andere Gäste einzusammeln? Muss ja nicht sein.
Zum anderen ist es kein Geheimnis, dass Moia an autonom fahrenden Autos arbeitet. „Nach aktuellen Planungen soll es ab Mitte des Jahrzehnts einen ersten autonomem ­Ridepooling-Betrieb auf Teilen von Hamburgs Straßen geben“, bestätigt Moia-Sprecherin Langfeldt. Sie weist den Eindruck zurück, die Maßnahmen zielten bereits jetzt auf ein langsames Ersetzen der menschlichen Fahrer durch künstliche Intelligenz. Bruns hingegen sagt, er habe das Gefühl, er und die anderen Fah­re­r*in­nen würden im vom Algorithmus berechneten System immer mehr zum Störfaktor.
",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vbmV0enBvbGl0aWsub3JnLzIwMjEvZW1vdGlvbmFsZS1raS1iZXJlY2huZXRlLWdlZnVlaGxlL9IBAA?oc=5,Emotionale KI: Berechnete Gefühle - Netzpolitik.org,2021-07-02,Netzpolitik.org,https://netzpolitik.org,N/A,N/A,"Forschende arbeiten an Technologien, die menschliche Emotionen erkennen sollen. Die Anwendungsgebiete reichen von Autismustherapie über Optimierung von Werbung bis hin zur Sicherheitspolitik. Dabei bewegt sich die Forschung auf umstrittenen Grundlagen und könnte gefährliche Folgen haben.","Forschende arbeiten an Technologien, die menschliche Emotionen erkennen sollen. Die Anwendungsgebiete reichen von Autismustherapie über Optimierung von Werbung bis hin zur Sicherheitspolitik. Dabei bewegt sich die Forschung auf umstrittenen Grundlagen und könnte gefährliche Folgen haben.",N/A,N/A,"

Emotionale KI: Berechnete Gefühle 
Forschende arbeiten an Technologien, die menschliche Emotionen erkennen sollen. Die Anwendungsgebiete reichen von Autismustherapie über Optimierung von Werbung bis hin zur Sicherheitspolitik. Dabei bewegt sich die Forschung auf umstrittenen Grundlagen und könnte gefährliche Folgen haben.



            02.07.2021 um 10:08            Uhr
         - Pia Stenner - in  Demokratie  - 6 Ergänzungen 

Traurig, wütend oder müde? Die Emotionserkennung soll feine Unterschiede in der Mimik erkennen.    –   Gemeinfrei-ähnlich freigegeben durch unsplash.com Jakayla Toney

Actionunit 12 in Kombination mit Actionunit 6: So nennt Dominik Seuß ein echtes Lächeln, bei dem sich die Mundwinkel und Wangen nach oben schieben und rund um die Augen Krähenfüßchen bilden. Fällt Actionunit 6 weg, bleiben nur die hochgezogenen Mundwinkel – ein soziales Lächeln, das nicht auf ehrlicher Freude beruht. Seuß leitet am Fraunhofer-Institut für Integrierte Schaltungen den Bereich Gesichtserkennung und Mimik. Schon seit Jahren erforscht sein Team hier Technologien, die mit Kameras und Algorithmen menschliche Gesichtsausdrücke erkennen und Emotionen zuordnen sollen.
Meist handelt es sich um Systeme wie diese, wenn von Künstlicher Intelligenz zur Emotionserkennung oder „emotionaler KI“ die Rede ist. Der Begriff wird allgemein für Technologien verwendet, die biometrische Daten wie Gesichter oder Stimmen erfassen und auf dieser Grundlage automatisiert Rückschlüsse auf die Emotion einer Person treffen.
Einsatz zur Autismustherapie oder in der Autoindustrie
Am Fraunhofer-Institut findet sich diese Idee beispielsweise in einem Projekt mit humanoiden Robotern, die die Therapie von Kindern mit Autismus unterstützen sollen. „Manche Kinder mit Autismus reden vielleicht lieber mit einem Roboter, als mit einem Mensch, da die Reaktionen vorhersehbarer sind“, sagt Dominik Seuß. Der Roboter soll ihnen spielerisch helfen, die Gefühle ihres Gegenübers zu erkennen, oder zeigen, wie sie ihre eigenen Gefühle ausdrücken können. „Noch in der heißen Forschungsphase“, so Seuß, sei eine Anwendung, die in Fahrzeugen die Gesichtsmimik der Person am Steuer auswertet und dann vor kognitiver Überlastung warnt.
Die Projekte der Fraunhofer-Institute sind nur ein winziger Ausschnitt des florierenden Forschungs- und Wirtschaftszweigs rund um Emotionserkennung. Für die kommenden Jahre prognostizieren verschiedene Analysen dem Markt ein Wachstum um mehrere Milliarden US-Dollar. Die Begeisterung ist auch beim Bundesministerium für Bildung und Forschung (BMBF) angekommen: 22 Millionen Euro hat es in deutsche Forschungsprojekte zur automatisierten Emotionserkennung investiert. Doch die Technologien sind anfällig für diskriminierende Fehler, sie beruhen auf umstrittenen Grundlagen und bieten Raum für Missbrauch und Manipulation.
Anwendungen funktionieren noch nicht fehlerfrei
Seit Jahren wird an Emotionserkennungs-KI geforscht, aber erst jetzt komme sie „in ein Stadium robuster Anwendbarkeit“, sagt Björn Schuller. Der Informatiker beschäftigt sich in seinen Projekten an der Universität Augsburg mit akustischer Emotionserkennung. „Deutschland ist und war hier stets führend in der internationalen Forschung“, sagt er. Angewendet würde die Technologie jedoch weder hierzulande noch anderswo – mit wenigen Ausnahmen.
Ein Bereich, in dem Emotionserkennungs-KI schon heute eingesetzt wird, ist die Marktforschung. Automatisierte Systeme treffen anhand der Stimme der Proband:innen Aussagen über die emotionale Wirkung von Werbung, die sie gesehen haben. Solche Software verkauft auch das Unternehmen, an dem Björn Schuller beteiligt ist. Es verspricht, mit seiner Anwendung bis zu 50 Emotionen unterscheiden zu können. Auch zur Auswertung von Callcenter-Telefonaten wird Technologie wie diese eingesetzt.  Fragt man beim deutschen Callcenter-Verband, wie verbreitet sie in der Branche tatsächlich schon ist, stößt man allerdings auf wenig Euphorie: Die Technik sei noch zu anfällig für Fehler, den Kostenfaktor Mensch könne sie nicht reduzieren.
Eine technische Herausforderung, vor der auch das Team um Dominik Seuß am Fraunhofer-Institut noch steht, ist die Unterscheidung von unterschiedlichen Emotionen mit sehr ähnlichen Gesichtsausdrücken. „Ekel nutzt sehr viele Actionunits, die auch Schmerz nutzt – der Unterschied ist aber die Dynamik oder Abfolge der Actionsunits“, erklärt Seuß. Die Idee von Actionunits im Gesicht sei schon seit 50 Jahren in der Psychologie etabliert. „Auch die Automatisierung gibt es schon ein paar Jahre, aber Menschen sind so verschiedenen, dass es immer noch ein schwieriges Forschungsthema ist.“
Umstrittene wissenschaftliche Basis
Es ist ein wunder Punkt der Emotionserkennung, den der Informatiker da anspricht: Menschen sind verschieden. Aber sind sie so verschieden, dass Gesichtsausdrücke gar keine Rückschlüsse auf Emotionen erlauben?
Die meisten visuellen Technologien, die Gefühle erkennen sollen, stützen sich auf die Theorie der Basisemotionen des Psychologen Paul Ekman. Sie beruht auf der Annahme, dass es weltweite universelle Ausdrucksformen für Emotionen gibt – unabhängig von der Kultur. Diese Theorie ist allerdings umstritten. Auch Daniel Leufer nennt dieses Argument, wenn er begründet, warum er wenig von Emotionserkennungs-Technologien hält.
Bei der Menschenrechtsorganisation Access Now ist Leufer Experte für ein Thema, das es in seiner Idealvorstellung gar nicht gäbe. „Alle Ansätze haben allgemein das Problem, dass die Korrelationen zwischen maschinenlesbaren Daten und den Schlussfolgerungen daraus sehr schwach sind.“
Dies bestätigt die Arbeit der Psychologin Lisa Feldmann Barret. 2019 veröffentlichte sie mit weiteren Autor:innen eine Analyse sämtlicher Studien, die sie bis dahin zum Zusammenhang der Gesichtsausdrücke und Emotionen gesammelt hatten. Barret kommt zu dem Ergebnis, dass die Zuverlässigkeit der meisten Studien nur gering ist: „Es ist nicht möglich, von einem Lächeln auf Glück, von einem finsteren Blick auf Wut oder von einem Stirnrunzeln auf Traurigkeit zu schließen, wie es ein großer Teil der heutigen Technologie versucht und sich dabei auf etwas stützt, das fälschlicherweise als wissenschaftlich erwiesen gilt.“
Systeme, die mehr auf Hautfarbe als auf Mimik achten
Wenn die KI aber Fehler macht, wirkt sich das schnell auf ohnehin benachteiligte Gruppen aus. Da wäre etwa das altbekannte Problem diskriminierender Algorithmen, die zum Beispiel Schwarze gegenüber weißen Menschen durch ihre Entscheidungen benachteiligen.
Eine Studie aus dem Jahr 2018 zeigte, dass es auch im speziellen Fall der Emotionserkennung auftritt. Zwei Gesichtserkennungssysteme sollten die Emotionen aus den Gesichtern von Basketballspielern erkennen. Eines der Systeme schätzte schwarze Basketballer wütender als die weißen Spieler ein. Das andere System erkannte grundsätzlich öfter einen verachtungsvollen Blick in den Gesichtern der schwarzen Spieler.
Diese rassistische Einordnung knüpft an Stereotype an, die es auch ganz ohne Algorithmen in der analogen Welt gibt. Weit verbreitet ist beispielsweise das Klischee der „Angry Black Woman“: Schwarze Frauen werden in der amerikanischen Mainstream-Kultur häufig als aggressiv, schlecht gelaunt oder überheblich charakterisiert. Solche Stereotype können das maschinelle Lernen der Algorithmen beeinflussen.
Niemand schaut in den Kopf, nichtmal die KI
Damit sie das nicht tun, müsse man genau verstehen, warum automatisierte Systeme diskriminierende Entscheidungen treffen, sagt Dominik Seuß. Softwareanbieter müssten zudem offenlegen machen, was ihre KI kann und was nicht. Denn obwohl die Werbeversprechen einiger Firmen anders klingen: „Ob der Mensch wirklich geistig dieselbe Emotion teilt, die sein Gesicht zeigt – das kann niemand wissen. Niemand kann in den Kopf hinein schauen.“
Einige Konzerne, wie zum Beispiel Microsoft, begegnen diesem Problem, indem sie nicht von „Emotionserkennung“, sondern von der „Erkennung wahrgenommener Emotionen“ sprechen, um zu betonen, dass ihre Anwendungen eben nicht in den Kopf hineinschauen.
Viele Anbieter versichern außerdem, dass sie datenschutzkonform arbeiten und keine personenbezogenen Daten verarbeiten. Auch das Fraunhofer-Institut wirbt mit einem Datenschutz-Siegel. Das System sei nicht in der Lage, Gesichter wiederzuerkennen, sagt Seuß. „Es kann nur erkennen, dass es sich um irgendein Gesicht handelt.“
Ähnlich argumentiert ein Unternehmen in Brasilien, gegen das Access Now geklagt hat. „Es behauptet, dass es nur anonymisierte Daten sammelt, aber das ist Quatsch“, sagt Daniel Leufer. Schließlich sammle das Unternehmen Bilder von Gesichtern, aus denen es biometrische Schablonen ziehe, die wiederum als Grundlage für Rückschlüsse auf Geschlecht, Alter und Emotion dienten. „Dieses Unternehmen speichert biometrisch sensible Daten, die genutzt werden könnten, um jemanden zu identifizieren.“
Lügendetektoren an Grenzkontrollen und auf Polizeiwachen
Doch es gibt einen Bereich, in dem der Einsatz automatisierter Emotionserkennung Leufer noch mehr Sorge bereitet. „Wenn ein System sagt, dass jemand nicht die Wahrheit erzählt, ist das hochproblematisch.“ Die Chinesische Regierung testet solche Lügendetektoren bereits heute auf Polizeiwachen an der uigurischen Minderheit, die von der Regierung brutal unterdrückt wird.
Aber auch in den USA und in Europa gab es Projekte, die solche Lügendetektoren für Grenzkontrollen ausprobierten. Ein Programm aus den USA wurde an der mexikanischen Grenze getestet, außerdem am Flughafen Bukarest in Kooperation mit der europäischen Grenzpolizei Frontex. Später startete die EU ihr eigenes Forschungsprogramm iBorderCtrl. Ein Bestandteil war die Befragung von Einreisenden in die EU. Automatisierte Entscheidungssysteme sollten mittels Gesichts- und Mimikerkennung Hinweise geben, ob die Person wahrheitsgemäß auf Fragen antwortete.
Das Projekt iBorderCtrl ist mittlerweile abgeschlossen, doch die Ergebnisse hält die EU noch immer unter Verschluss. Es heißt, dass keine Lügendetektoren für den Einsatz in der Praxis geplant seien. Frontex teilte netzpolitik.org auf Anfrage mit, dass der Test in Bukarest beendet sei und man auch für die Zukunft keinen Einsatz von KI zur Emotionserkennung plane. Momentan finanziert die EU ein neues Forschungsprojekt zur Grenzkontrolle. „Wenn ein Reisender, dem man misstraut, verhört wird, kann Technologie nützlich sein, um speziell geschulten Grenzbeamten zu helfen, die Aufrichtigkeit des Reisenden und seiner Aussagen schneller und genauer zu beurteilen“, heißt es auf der Website des Projekts.
„Sind Sie verliebt?“
Das Interesse der EU, neue Grenzkontrollsysteme zu entwickeln, ist offenbar auch bei einer russischen Firma angelangt, die vorgibt, anhand von Vibrationen des Kopfes Emotionen erkennen zu können. Aus einem Bericht von 2019 geht hervor, dass sie den Einsatz ihrer Lügendetektor-Technologie auch für die EU-Grenzen für vorstellbar hält. Basierend auf dieser Technologie gibt es auf der Website einen „Psychophysiologischen Liebesdetektor“, den man für 10 Dollar auf sein Android-Smartphone herunterladen kann. „Testen Sie Ihre Beziehung zu einer beliebigen Person: Sind Sie verliebt, gleichgültig, spüren Abneigung oder Hass?“, lautet die Beschreibung. Für 20 Euro will dieselbe Firma auch einen angeblichen Coronavirus-Test verkaufen. Auch dieser soll über die Vibrationen des Kopfes funktionieren.
Tatsächlich wurde die Kopf-Vibrations-Technologie bereits im größeren Stil eingesetzt: Bei Olympischen Spielen, einer Fußball-Weltmeisterschaft und einem G7-Gipfel, wie The Conversational berichtete.
Einfluss auf freie Gedanken
Bei solchen Anwendungsbereichen rückt in den Hintergrund, was die KI wirklich kann. Problematischer ist, was sie vorgibt zu können: „Wenn Menschen daran glauben, dass die Systeme ihre Gefühle erkennen können, dann wird die abschreckende Wirkung der Systeme auch einsetzen“, sagt Daniel Leufer.
Er sieht ein fundamentales Grundrecht verletzt, wenn Menschen Bestrafung für ihre eigenen Gedanken fürchten müssen: „Freedom of Thought“, nennt er es. „Wenn es Systeme gibt, die tatsächlich Schlussfolgerungen treffen, die reale Konsequenzen wie Strafverfolgung haben können, berührt das diese Gedankenfreiheit.“
Das gilt nicht nur für den Bereich der Sicherheitspolitik. Leufer nennt ein anderes, für ihn denkbares Anwendungsszenario: Emotionserkennung in der Schule zur Bewertung des Sozialverhaltens. „Wenn die KI einige Schüler:innen zum Beispiel aggressiver als andere bewertet und sie auf dieser Grundlage möglicherweise Strafen bekommen, könnte das dazu führen, dass sich die Schüler:innen anders verhalten.“
Spagat zwischen Manipulation und Innovation
Dass auch die Technologien, an denen Dominik Seuß und Björn Schuller in Deutschland forschen, Raum für Missbrauch oder Manipulation bieten, streiten die Wissenschaftler nicht ab. Schuller hat Bedenken beim Einsatz der Technologie im Bereich der Werbung. Sie könne missbraucht werden, um emotional schwache Momente zu erkennen und gezielt auszunutzen. Seiner Ansicht nach überwiegt jedoch der Nutzen in anderen Bereichen: „In der Interaktion zwischen Mensch und Technik, im spielerischen Bereich für Videospiele und Edutainment sowie eben vor allem im Gesundheitsbereich.“
Seuß sagt: Niemand sei in der Lage, 24 Stunden am Tag ein Schmerztagebuch zu führen. Wenn die Künstliche Intelligenz das abnehmen kann, sei das eine enorme Hilfe für die Betroffenen.
„Diese Systeme sollten vollständig verbannt werden“
Möglich, dass die beiden europäischen Datenschutzinstanzen EDPS und EDPB solche Anwendungsfälle bedacht haben, als sie gemeinsame Kritik an den KI-Regulierungsplänen der EU-Kommission äußerten. Der bisherige Entwurf der Kommission ordnet Emotionserkennungssysteme in die Kategorie von Anwendungen mit Manipulationsrisiken ein. Demnach gelten für diese Systeme Transparenzpflichten. „Werden Emotionen oder Merkmale durch automatisierte Mittel erkannt, müssen die Menschen hierüber informiert werden“, heißt es im Gesetzentwurf.
EDPS und EDPB fordern in ihrer Stellungnahme, dass die Kommission noch weiter gehen und verschiedene KI-Anwendungen verbieten soll, die mit menschlichen Merkmalen arbeiten. Dabei nennen sie explizit auch Anwendungen zur Emotionserkennung. Ausnahmen seien im medizinischen Bereich jedoch vorstellbar.
Auch Daniel Leufer von Access Now hält die Pläne der Kommission für unzureichend. „Der aktuelle Vorschlag tut nichts, um Menschen vor den ernsthaften Gefahren der Emotionserkennungstechnologien zu schützen.“ Die Transparenzpflicht findet er aus Menschenrechtsperspektive sinnlos. „Diese Systeme sollten vollständig verbannt werden. Und wenn es Argumente für Ausnahmen gibt, dann müssen die in die Hochrisiko-Gruppe fallen und strengsten Regelungen unterliegen.“
Die Entwicklung der Technologien zur Emotionserkennung pauschal zu verbieten, ist für Wissenschaftler wie Seuß keine Option. „Wenn wir uns einfach davor versperren, wird die Technologie woanders weiter und weiter entwickelt. Wir müssen verstehen, wie solche Sachen funktionieren.“ Doch in einem Punkt stimmt er den Kritiker:innen der Emotionserkennung zu: „Es muss Regeln geben.“ Dafür, wie wir als Gesellschaft damit umgehen, wenn automatisierte Systeme melden, dass Actionunit 12 nicht mehr aktiviert ist.




Deine Spende für digitale Freiheitsrechte
Wir berichten über aktuelle netzpolitische Entwicklungen, decken Skandale auf und stoßen Debatten an. Dabei sind wir vollkommen unabhängig. Denn unser Kampf für digitale Freiheitsrechte finanziert sich zu fast 100 Prozent aus den Spenden unserer Leser:innen.

Jetzt spenden


just one moment ...



Über die Autor:in


							Pia Stenner						


Pia war von April bis Juli 2021 als Praktikantin bei netzpolitik.org. Sie 
hat Journalistik und Politikwissenschaft an der TU Dortmund studiert und 
interessiert sich besonders für Digitales, das mit Politik, Medien und 
Gesellschaft zusammenhängt. Erreichbar zum Beispiel über Twitter. 



Veröffentlicht
                    02.07.2021 um 10:08                                    

 Kategorie  Demokratie 

 Schlagworte  Access Now automatisierte Gesichtserkennung Biometrie Björn Schuller Daniel Leufer Dominik Seuß Emotionserkennung Fraunhofer IAIS Fraunhofer IIS FRONTEX Gesichtserkennung iBorderCtrl Künstliche Intelligenz 


",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiigFodHRwczovL3d3dy5oYW5kZWxzemVpdHVuZy5jaC9pbnN1cmFuY2Uva3Vuc3RsaWNoZS1pbnRlbGxpZ2Vuei1mdXItdmVyc2ljaGVydW5nZW4va3Vuc3RsaWNoZS1pbnRlbGxpZ2Vuei1iZWktc2Nod2VpemVyLXZlcnNpY2hlcmVybi0zNDI4ODbSAQA?oc=5,Künstliche Intelligenz bei Schweizer Versicherern | HZ Insurance - Handelszeitung,2021-07-05,Handelszeitung,https://www.handelszeitung.ch,"Die Schweizer Versicherer Axa, Baloise, Helvetia, Mobiliar und Zurich lassen sich zunehmend von künstlicher Intelligenz unterstützen.",N/A,"Die Schweizer Versicherer Axa, Baloise, Helvetia, Mobiliar und Zurich lassen sich zunehmend von künstlicher Intelligenz unterstützen.","Die Schweizer Versicherer Axa, Baloise, Helvetia, Mobiliar und Zurich lassen sich zunehmend von künstlicher Intelligenz unterstützen.",N/A,N/A,N/A,https://schema.org,BreadcrumbList,https://www.handelszeitung.ch/#/schema/BreadcrumbList/insurance/kunstliche-intelligenz-fur-versicherungen/kunstliche-intelligenz-bei-schweizer-versicherern-342886,https://apps.apple.com/ch/app/handelszeitung/id1631365898,Schweizer Versicherung,2021-07-05T11:40:00+02:00,2021-07-05T11:40:00+02:00,"{'@type': 'URL', '@id': 'https://www.handelszeitung.ch/insurance/kunstliche-intelligenz-fur-versicherungen/kunstliche-intelligenz-bei-schweizer-versicherern-342886'}","{'@id': 'https://www.handelszeitung.ch/fp/1200/640/2000/1120/sites/default/files/kunstliche_intelligenz_0.jpg', 'url': 'https://www.handelszeitung.ch/fp/1200/640/2000/1120/sites/default/files/kunstliche_intelligenz_0.jpg', 'contentUrl': 'https://www.handelszeitung.ch/fp/1200/640/2000/1120/sites/default/files/kunstliche_intelligenz_0.jpg', 'caption': '<p>Schweizer Versicherer erwarten von künstlicher Intelligenz einfachere interne Prozesse und Mehrwert für Kunden und Mitarbeitende.</p>\n', 'width': '1200', 'height': '640'}",{'@id': 'https://www.handelszeitung.ch/#/schema/BreadcrumbList/insurance/kunstliche-intelligenz-fur-versicherungen/kunstliche-intelligenz-bei-schweizer-versicherern-342886'},https://www.handelszeitung.ch/insurance/kunstliche-intelligenz-fur-versicherungen/kunstliche-intelligenz-bei-schweizer-versicherern-342886,{'@id': 'Handelszeitung'},Künstliche Intelligenz für Versicherungen,"[{'@type': 'Person', 'name': 'Matthias Niklowitz', 'sameAs': []}]",Update: So setzen Schweizer Versicherer künstliche Intelligenz ein,Künstliche Intelligenz bei Schweizer Versicherern,"{'@type': 'ImageObject', '@id': 'https://www.handelszeitung.ch/static/media/4f2991ec0668454ec5a04affb50345cd.png'}",True,[]," Künstliche Intelligenz (KI) ist bei den Versicherungsgesellschaften auf dem Vormarsch. Gemäss einer Versicherungsspezialistin eines Beratungsunternehmens gibt es bereits viele Pilotversuche, diese werden aber noch nicht skaliert.  Zu den Vorreitern in Sachen KI gehört Baloise. «Aufgrund der datenbasierten Geschäftsmodelle sind punktuelle KI-Lösungen bei uns bereits in vielen Bereichen im Einsatz», bestätigt Group CTO Alexander Bockelmann. «Der Trend wird sich in Zukunft weiter verstärken, unter anderem auch weil viele moderne Softwarelösungen KI bereits integrieren.» Diese würden immer reifer, aber Experten-Know-how sei nach wie vor notwendig und die Anwendung eng begrenzt, so Bockelmann. Limitierend sei häufig der Trainingsaufwand und der hierfür notwendige Datensatz zur Optimierung von KI-Algorithmen. 
	Die Suva will bis 2027 künstliche Intelligenz einsetzen, um die Schadenfälle zu steuern. Das führt zum Abbau von 170 Vollzeitstellen.

 Baloise: Branchenführerin in Sachen KI

Breit genutzt wird KI laut Baloise-Sprecherin Nicole Hess bereits zur Effizienzsteigerung interner Prozesse. So wird die Eingangspost (Briefe und an Zentraladressen adressierte Mails) seit 2007 mittels Dunkelverarbeitung digitalisiert und vorsortiert. Durch das jahrelange Weiterentwickeln und Trainieren der Software können die einzelnen Dokumente mittlerweile nicht nur nach Dokumenttyp (Adressänderung, Rechnung, Kündigung, Polizeirapport usw.) erkannt und an die entsprechende Stelle weitergeleitet werden, sondern ganze Prozesse teilweise end-to-end mittels Dunkelverarbeitung ohne Interaktion des Fachbereichs abgeschlossen werden. «Mit einer bis zu 70-prozentigen Automatisierung sind wir weltweit branchenführend, gewähren zahlreichen Firmen im Dienstleistungssektor regelmässig Einblick ins Thema und führen sie auch in dieses ein», erklärt Nicole Hess.  Mit der Online-Schadenmeldung wird bei Baloise auch der Schadenmeldeprozess vorbearbeitet, sodass der Fachbereich nur bedingt bzw. später involviert wird. Unter künstliche Intelligenz fällt auch die automatische Spracherkennung der Telefon-Hotline. Dank dieser werden Kundinnen und Kunden bei Nennung ihres Anliegens direkt an die korrekte Anlaufstelle weitergeleitet. Zusammenarbeit mit Startup

Im Bereich Asset Management arbeitet Baloise mit dem Startup Brainalyzed zusammen und integriert die gewonnenen Erkenntnisse direkt ins Tagesgeschäft. So wird KI im Investment Research eingesetzt, hier insbesondere bei der Voranalyse von Unternehmensberichten und der Analyse von umfangreichen Mengen an Finanzdaten. Mittelfristig soll KI auch im Bereich ESG Researchs und im Wertpapierhandel zum Einsatz kommen. Im Hinblick auf eine längerfristige Nutzung testet das Asset Management den KI-Einsatz zudem für Marktresearch. Des Weiteren kommen KI-Lösungen auch im Internet-Security-Bereich zum Einsatz. «Eine Software analysiert alle Netzwerkverbindungen innerhalb des Unternehmens in Echtzeit und trainiert ein auf künstlicher Intelligenz basierendes Modell zum Aufspüren auffälliger oder ungewöhnlicher Netzwerk-Aktivitäten», beschreibt Nicole Hess das Vorgehen. Zusätzlich würden alle Netzwerk-Aktivitäten direkt auf bekannte Bedrohungsmuster geprüft. Diese stammen ebenfalls aus einem KI-Modell, das durch den Hersteller mithilfe von bei Cyberangriffen gesammelten Netzwerk-Daten trainiert wurde. Axa: KI in allen Bereichen auf dem Vormarsch

Auch Axa räumt KI «einen sehr hohen Stellenwert ein», wie Sprecher Lorenz Heinzer sagt. Man wolle bei Axa mit KI den Kunden in der Prävention, in der nahtlosen und möglichst einfachen Abwicklung von Kundenanliegen sowie in der auf ihre Bedürfnisse zugeschnittenen Produktgestaltung unterstützen  Intern unterstütze KI die Automation von Prozessen und die Betrugsbekämpfung. KI im erweiterten Sinn setzt Axa laut Sprecher Heinzer querbeet über die ganze Wertschöpfungskette der Versicherung ein. Dabei kämen vielerorts altetablierte Algorithmen zum Einsatz, welche bewährt und erklärbar sind. «Tiefe neuronale Netzwerke» seien hingegen noch nicht so etabliert, was Erklärbarkeit und Fehleranfälligkeit anbelange. Helvetia: KI entlang der gesamten Wertschöpfungskette

Für Helvetia sind Daten ein wichtiger Teil der Wettbewerbsfähigkeit, wie Helvetia-Sprecher Jonas Grossniklaus erläutert. Dabei müssten aber der Datenschutz, die sichere und nicht zweckentfremdete Verwendung von Kundeninformationen sowie auch Compliance-Themen beachtet werden. Laut eigenen Angaben setzt Helvetia KI in mehreren Bereichen ein:  
	Bei der Schadenbearbeitung im Nicht-Leben: Prüfung der Kostenvoranschläge von Reparaturbetrieben durch ein ständig lernendes Modell. Das Ziel: schnellere Bearbeitung des Schadenfalls und faire Konditionen. 
	Bei der Selektion von Kunden für Massnahmen der Marktbearbeitung. Das Ziel: Ermöglichung einer zielgenauen Ansprache.
	Bei der automatischen Erkennung von relevanten Kennzahlen aus Firmenbilanzen im KMU-Geschäft Nicht-Leben.
	Beim «intelligenten» Chatbot für Kundenanfragen auf der Website.
 «Je nach Anwendungsgebiet ist die Reife von künstlicher Intelligenz sehr unterschiedlich ausgeprägt», so Grossniklaus. «Dort, wo viele qualitativ hochwertige Daten und die Infrastrukturvoraussetzungen existieren, kann KI für den Kunden einen Mehrwert schaffen.» Mittelfristig stehen die Bereiche Nicht-Leben, Leben, Asset Management, Kundenanalytics und IT im Fokus. «Wir denken zum Beispiel an vollautomatische Entscheidungen durch künstliche Intelligenz in gewissen Bereichen, eine End-to-end-Dunkelverarbeitung oder einen Einsatz in der Interaktion mit den Kunden.» Mittel- und längerfristig soll KI bei Helvetia entlang der gesamten Wertschöpfungskette verankert werden. Mobiliar: Bilderkennung und Unterstützung der Mitarbeitenden

«Künstliche Intelligenz hilft uns dabei, datenbasiert zu handeln, Mitarbeitende in ihrer Arbeit zu unterstützen und Kundinnen und Kunden einen Mehrwert zu bringen», fasst Sprecherin Kim Allemann die Sichtweise der Mobiliar zusammen. Technologien wie Natural Language Processing (NLP) würden als reif eingeschätzt und entsprechend genutzt. Konkrete Anwendungen gibt es für die Analyse von Kundenrückmeldungen und die Betrugserkennung im Rahmen der einfachen Schadenabwicklung.  Mittelfristig will die Mobiliar die einfache Schadenabwicklung und die Bilderkennung speziell von beschädigten Fahrzeugen oder die Analyse von Kundenfeedbacks auf KI umstellen. Das Mobiliar Lab für Analytik an der ETH Zürich forsche zum Thema «Verantwortungsvolle digitale Interaktionen». «Damit wollen wir einen positiven Beitrag zur digitalen Weiterentwicklung der Gesellschaft leisten.» Zurich: Marktdifferenzierung durch KI 

Für Zurich ist der ethisch korrekte Einsatz von KI zentral. «Wir stellen dabei sicher, dass diese zum Vorteil von Kundinnen und Kunden genutzt wird», betont Sprecher Kay Schubert. «Alle Entscheidungen sind erklärbar und können im Zweifel durch menschliche Mitarbeitende übersteuert werden. Unsere Algorithmen sind nicht diskriminierend und wir halten unser Datenschutzversprechen jederzeit ein.»  Neben Automatisierungs- und Effizienzthemen steht vor allem die Schaffung von marktdifferenzierenden Kundenservices und Arbeitserlebnissen für die Mitarbeitenden im Vordergrund. «Je nach Problemstellung eignen sich momentan Lösungen in den Bereichen Robotics, API mit Kunden, Weiterentwicklung oder Integration von bestehenden Systemen besser», sagt Schubert. KI sei aktuell bei einfacheren Prozessen mit sich mehrheitlich wiederholenden Schritten und Inhalten eine grosse Unterstützung. Gewisse Grenzen gebe es jedoch im Commercial-Bereich, beispielsweise bei einer zu grossen Komplexität oder der Kombination von unterschiedlichen Sprachen.  Virtuelle Karriereberater

Im Schadenbereich unterstützen Chatbots die Zurich-Kunden bei Deckungsfragen. Firmenkunden werden zudem mit individuellen Risikoanalysen bei der Schadenvermeidung unterstützt. «Dank intelligenten Bilderkennungsverfahren können Motorfahrzeug-Offerten innerhalb von wenigen Sekunden auf Basis eines Fotos des Fahrzeugausweises erstellt werden», so Schubert. «Im HR unterstützen virtuelle Karriereberater die Mitarbeitenden in ihrer Weiterentwicklung.»  Für die Zukunft prüft die Zurich die Anwendung in weiteren Commercial-Insurance-Bereichen. Konkret betrifft das beispielsweise die E-Mail-Triagierung im Bereich International Servicing sowie die Unterstützung im Underwriting-Prozess. Dieser Artikel erschien zuerst am 30. Juni 2021. Die Informationen zu Axa wurden nachträglich ergänzt. 
	Wie Künstliche Intelligenz die Technik revolutioniert

",IOS,EntertainmentApplication,NewsApplication,"[[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.handelszeitung.ch', 'url': 'https://www.handelszeitung.ch'}], [{'@type': 'ListItem', 'position': 2, 'name': 'Insurance', 'item': 'https://www.handelszeitung.ch/insurance', 'url': 'https://www.handelszeitung.ch/insurance'}, {'@type': 'ListItem', 'position': 3, 'name': 'Künstliche Intelligenz für Versicherungen', 'item': 'https://www.handelszeitung.ch/insurance/kuenstliche_intelligenz', 'url': 'https://www.handelszeitung.ch/insurance/kuenstliche_intelligenz'}, {'@type': 'ListItem', 'position': 4, 'name': 'Künstliche Intelligenz bei Schweizer Versicherern'}]]"
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3LnNyZi5jaC9uZXdzL3NjaHdlaXovc2lsaWNvbi12YWxsZXktZGVyLXNjaHdlaXotZGFzLXRlc3Npbi1pc3QtZWluLXVuYmVrYW5udGVzLW1la2thLWZ1ZXIta3VlbnN0bGljaGUtaW50ZWxsaWdlbnrSAQA?oc=5,Silicon Valley der Schweiz? - Das Tessin ist ein unbekanntes Mekka für künstliche Intelligenz - SRF – Schweizer Radio und Fernsehen,2021-07-02,SRF – Schweizer Radio und Fernsehen,https://www.srf.ch,Im Südkanton ist in den letzten Jahren ein KI-Zentrum entstanden. Diese Entwicklung geschah aber weitgehend unbemerkt.,N/A,Im Südkanton ist in den letzten Jahren ein KI-Zentrum entstanden. Diese Entwicklung geschah aber weitgehend unbemerkt.,Im Südkanton ist in den letzten Jahren ein KI-Zentrum entstanden. Diese Entwicklung geschah aber weitgehend unbemerkt.,News,N/A,"



News





Schweiz




Inhalt










Silicon Valley der Schweiz?
 - 
Das Tessin ist ein unbekanntes Mekka für künstliche Intelligenz

Im Südkanton ist in den letzten Jahren ein KI-Zentrum entstanden. Diese Entwicklung geschah aber weitgehend unbemerkt.


Autor: 

Karoline Thürkauf


Samstag, 03.07.2021, 00:31 Uhr









Klicken, um die Teilen-Funktion zu öffnen.




Teilen



Zu den Kommentaren springen.


Anzahl Kommentare: 
1








Teilen


Schliessen
















Auf Facebook teilen
Facebook









Auf X teilen
X









Per WhatsApp teilen
WhatsApp









Per E-Mail teilen
E-Mail









Link kopieren
Link kopieren














«Namen sind Schall und Rauch», sagt Jürgen Schmidhuber. Er ist der wissenschaftliche Direktor des in Lugano ansässigen Instituts für künstliche Intelligenz Idsia. Schmidhuber wird von der Presse gerne als Vater der künstlichen Intelligenz (KI) bezeichnet. Er und seine Kolleginnen und Kollegen haben nämlich das Rezept für wichtige Computerprogramme erfunden.Konkret fusst beispielsweise das Computer-Übersetzungsprogramm «Google Translate» auf der Erfindung von Schmidhuber. Diese Erfindung vom maschinellen Lernen macht, dass das Computerprogramm fähig ist, selbstständig zu übersetzen.



Legende:

                Sprachanwendungen wie Siri von Apple oder der Smartspeaker Alexa von Amazon arbeiten schon seit längerem auf der Grundlage von künstlicher Intelligenz. Sie lernen selbstständig weiter und merken sich Anfragen.
            

                    Keystone/Archiv
                


Es sind Anwendungen wie Siri oder Alexa, die auf der Grundlagenforschung von Schmidhuber und seines Teams basieren. Er selber verwendet diese Apps übrigens nicht. Er sagt, er versuche möglichst wenig Spuren im Netz zu hinterlassen.
KI kann filigrane Massarbeit meisternDer Münchner Informatiker ist vor rund 20 Jahren nach Lugano gekommen. Neben seines Engagements an der Universität der italienischen Schweiz (USI) unterhält er eine private Firma in Lugano mit 30 Mitarbeitenden. Diese treibt mithilfe von künstlicher Intelligenz Industrieprozesse voran.



Legende:

                So helfen die Computerprogramme von Jürgen Schmidhuber beispielsweise, dass Maschinen, die feines Glas für Handykameras herstellen, besser funktionieren.
            

                    Keystone/Archiv
                


Diese KI-Softwares helfen, dass bei der komplizierten Glasproduktion weniger Glas zerbricht. Künstliche Intelligenz kenne keine Grenzen, sagt Schmidhuber. Er erzählt von den Computerprogrammen, die Krebszellen erkennen können. Auch dafür haben er und sein Team hier in Lugano Grundlagenforschung geleistet. 
Quadcopter-Navigation im Wald


Schmidhuber blendet nicht aus, dass die künstliche Intelligenz auch Schattenseiten hat, wenn sie in falsche Hände gerate. Das müssten Gesetze und allenfalls Verbote verhindern. Der Forscher aus Lugano hat zusammen mit anderen Prominenten wie Tesla Gründer Elon Musk einen offenen Brief an die Vereinten Nationen (UNO) geschrieben. Ihr erklärtes Ziel war, dass die UNO autonome Kriegswaffen wie zum Beispiel Tötungen durch Drohnen verbietet.









 













Audio
Jürgen Schmidhuber vom «Swiss AI Lab»

21:20 min, aus Kontext vom 21.04.2015.
                                                            
                                                    
abspielen. Laufzeit 21 Minuten 20 Sekunden.








Drohneninnovation für die Tessiner WirtschaftAuch bei Drohnenflugkörpern leistet das Institut um Schmidhuber viel für den Forschungsplatz Schweiz. Professor Alessandro Giusti und sein Team beispielsweise entwickeln Drohnen an der Fachhochschule Supsi zusammen mit Kolleginnen der ETH in Zürich und Lausanne.



Legende:

                Das gemeinsame Forschungsprojekt der ETH (hier im Bild) und der Supsi soll beispielsweise helfen, Menschen aufzuspüren, die nach einem Erdbeben oder einem Terroranschlag unter Trümmern begraben liegen.
            

                    Keystone/archiv
                


Der Kanton Tessin will sich eine Scheibe von der Forschung abschneiden, die da vor den eigenen Toren passiert. Auf dem ehemaligen Militärflugplatz Lodrino entsteht ein Drohnenkompetenzzentrum. Lodrino hat gemäss Aussagen des Bundesamtes für Zivilluftfahrt (Bazl) den schweizweit ersten exklusiven Drohnenflugraum. Die Tessiner hoffen, dass diese Einzigartigkeit und das Know-how der Fachleute vor Ort viele im Firmen anlocken wird, die Drohnen konzipieren. 


Noch stehe der Forschungsstandort Schweiz punkto künstlicher Intelligenz sehr gut da, sagt Professor Jürgen Schmidhuber. Er warnt aber davor, dass die Schweiz abgehängt werden könne von Ländern wie China. Das Land betreibe nämlich eine aggressive Industriepolitik. Der chinesische Staat unterstütze die Forschung mit Milliarden und hierzulande sei Industriepolitik verpönt.Doch die Schweiz muss sich noch nicht verstecken, denn in einem Ranking der amerikanischen Eliteuniversität Stanford von 2019 belegt der Schweizer KI-Forschungsplatz den zweiten Spitzenplatz hinter Singapur.



                            HeuteMorgen, 02.07.2021, 06:00 Uhr
                                                


                Mehr zum Thema
            






            Hinweis auf einen verwandten Artikel:
        


Mehr Sicherheit für Patienten
Big Brother im Operationssaal: Software überwacht Chirurgen


                10.06.2021
    

                Mit Video
     










            Hinweis auf einen verwandten Artikel:
        


Unter Druck
Drohnen-Gesuche überfordern das Bazl


                14.12.2017
    

                Mit Audio
     










            Hinweis auf einen verwandten Artikel:
        


Schweizer Firma Puregene
Cannabis: Grundlagenforschung öffnet Tor zu Milliardenbusiness


                12.06.2021
    

                Mit Video
     










            Hinweis auf einen verwandten Artikel:
        


Gentlemen's Agreement
Über Nachbars Garten wird’s heikel mit der Drohne


                02.06.2021
    

                Mit Audio
     










            Hinweis auf einen verwandten Artikel:
        


Revision des Luftfahrtgesetzes
Nationalrat will mehr Alkoholkontrollen im Cockpit


                03.06.2021
    

                Mit Video
     











Klicken, um die Teilen-Funktion zu öffnen.




Teilen



Zu den Kommentaren springen.


Anzahl Kommentare: 
1








Teilen


Schliessen
















Auf Facebook teilen
Facebook









Auf X teilen
X









Per WhatsApp teilen
WhatsApp









Per E-Mail teilen
E-Mail









Link kopieren
Link kopieren










News





Schweiz










",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3Lm1laW5iZXppcmsuYXQvbGluei9jLXdpcnRzY2hhZnQva3VlbnN0bGljaGUtaW50ZWxsaWdlbnotbWl0LWhhdXN2ZXJzdGFuZF9hNDc0NjM5MtIBYWh0dHBzOi8vd3d3Lm1laW5iZXppcmsuYXQvbGluei9jLXdpcnRzY2hhZnQva3VlbnN0bGljaGUtaW50ZWxsaWdlbnotbWl0LWhhdXN2ZXJzdGFuZF9hNDc0NjM5Mi9hbXA?oc=5,JKU: Künstliche Intelligenz mit Hausverstand - Linz - meinbezirk.at,2021-07-05,meinbezirk.at,https://www.meinbezirk.at,Durchbruch an der JKU: Neue KI beachtet physikalische Gesetze – und vermeidet Fehler durch „Hausverstand“ LINZ.,"JKU,AIT,Durchbruch,künstliche Intelligenz,Physikalische Systeme",Durchbruch an der JKU: Neue KI beachtet physikalische Gesetze – und vermeidet Fehler durch „Hausverstand“ LINZ.,N/A,Wirtschaft,N/A,"



Regionauten-CommunityAndreas Baumgartnerzu Favoriten
JKU
                        Künstliche Intelligenz mit Hausverstand
        
5. Juli 2021, 12:55 Uhr
V. l.: Frederik Kratzert; Pieter-Jan Hoedt; Günter KlambauerFoto: JKUhochgeladen von Andreas Baumgartner



Durchbruch an der JKU: Neue KI beachtet physikalische Gesetze – und vermeidet Fehler durch „Hausverstand“LINZ. Der AMS-Algorithmus der Frauen schlechtere Chancen am Arbeitsmarkt unterstellt oder ein Chatbot, der rassistische Äußerungen von sich gibt – selbstlernende System sind nicht davor gefeit, Fehler zu machen. Der Hintergrund: Die Künstliche Intelligenz (KI) lernt durch vorhandene Daten und nützt Korrelationen – auch dort wo kein Zusammenhang besteht oder ein Zusammenhang nicht gewollt ist.Eineinhalb Jahre Forschungsarbeit„Das sind sehr bekannte Probleme von KIs“, so Günter Klambauer vom JKU Institut für Machine Learning. „Ähnliche Probleme stellen sich bei anderen Aufgaben, bei denen KIs eingesetzt werden, und dann oft physikalisch unmögliche Ereignisse vorhersagen“. Also Ereignisse, die man mit physikalischem „Hausverstand“ eigentlich ausschließen könnte. Ein Team am LIT AI Lab an der JKU nahm sich der Sache an. In eineinhalb jähriger Arbeit ist es gelungen, der KI physikalische Gesetzmäßigkeiten einzubauen, die diese schon beim Lernen beachten muss. „Wir haben einzelne Neuronen der KI als Massespeicher genutzt“, erklärt Studienautor Pieter-Jan Hoedt. Die KI weiß, dass aus einer Flasche nur so viel Wasser rausfließen kann, wie vorher eingefüllt wurde. Was für Menschen logisch und einfach klingt, ist für Künstliche Intelligenz eine Herausforderung – und ein großer Sprung nach vorn.Hochwasser und VerkehrsanalysenDie neu entwickelte KI erkennt nun physikalisch unmögliche Ergebnisse. Sowohl bei der Hochwasservorhersage als auch bei Verkehrsanalysen für Berlin, Moskau und Istanbul hat sich die neue Methode bereits bewährt. Künftig könnte die KI in hochkomplexen Simulationen exaktere Ergebnisse liefern – etwa bei der Vorhersage der CO2-Belastungen in der Atmosphäre. Klambauer merkt aber auch an, dass dies zwar Probleme von KIs für physikalische Systeme löse, aber nicht die Probleme mit Vorurteilen und Verzerrungen von Chatbots und des AMS-Algorithmus. Dennoch sei dies ein großer Fortschritt und erlaube bessere KI-Vorhersagen in einer großen Bandbreite von Themen.Mehr Nachrichten aus Linz auf meinbezirk.at/linz


00Inhalt melden
Weitere Beiträge zu den ThemenDurchbruchAITPhysikalische Systemekünstliche IntelligenzJKU
Anzeige1:351:35
                            Floemer GmbH
                        
                                        ""PV-Tracker"" holen maximalen Strom aus der Sonne heraus
                Aus Sonne die maximale Energie herausholen: Das versprechen die ""PV Tracker"" der Firma Floemer GmbH aus Dorf an der Pram. Sie verfolgen die Sonne den gesamten Tagesverlauf. DORF/PRAM. Der ""PV-Tracker"", auch Solar-Tracker genannt, dreht und neigt sich automatisch zur Sonnenposition. ""Dadurch kann die Anlage schon sehr früh morgens Strom produzieren und nutzt bis spät in den Abend hinein die letzten Sonnenstrahl aus"", erklärt Florian Hörmandinger aus Dorf an der Pram (Oberösterreich),...
KommentareÄltere Kommentare anzeigenJetzt kommentieren

UP TO DATE BLEIBEN
 Aktuelle Nachrichten aus Linz auf MeinBezirk.at/Linz Neuigkeiten aus Linz als Push-Nachricht direkt aufs Handy BezirksRundSchau Linz auf Facebook: MeinBezirk.at/Linz - BezirksRundSchau ePaper jetzt gleich digital durchblättern Storys aus Linz und coole Gewinnspiele im wöchentlichen MeinBezirk.at-NewsletterDu willst eigene Beiträge veröffentlichen?Werde Regionaut!Jetzt registrieren

",http://schema.org,NewsArticle,,,,2021-07-05T12:55:25+02:00,2021-07-05T12:55:25+02:00,,,,"{'@type': 'WebPage', 'url': 'https://www.meinbezirk.at/linz/c-wirtschaft/kuenstliche-intelligenz-mit-hausverstand_a4746392'}","{'@type': 'Organization', 'name': 'MeinBezirk.at', 'logo': {'@type': 'ImageObject', 'url': 'https://www.meinbezirk.at/build/images/logo-publisher-amp-h60px.5365bf3e0605e50e8bb705e77860fe8c.png', 'width': 600, 'height': 60}}",Wirtschaft,"{'@type': 'Person', 'name': 'Andreas Baumgartner', 'url': 'https://www.meinbezirk.at/linz/profile-277186/andreas-baumgartner'}",JKU: Künstliche Intelligenz mit Hausverstand - Linz,,['https://media04.meinbezirk.at/article/2021/07/05/8/26346518_XXL.jpg'],,,,,,,

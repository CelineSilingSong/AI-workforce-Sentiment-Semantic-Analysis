URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,article:section,article:summary,article text,@context,@type,@id,author,headline,image,datePublished,dateModified,url,mainEntityOfPage,dateCreated,isAccessibleForFree,publisher,thumbnailUrl,speakable,about,articleBody,articleSection,wordCount,alternativeHeadline,timeRequired,itemListElement,isPartOf
https://news.google.com/rss/articles/CBMiiQFodHRwczovL3d3dy5zcGllZ2VsLmRlL25ldHp3ZWx0L25ldHpwb2xpdGlrL2t1ZW5zdGxpY2hlLWludGVsbGlnZW56LWRpZXNlLWthbWVyYS13ZWlzcy13ZXItZHUtYmlzdC1hLWMyZTNhNzQyLTE4ZDYtNDRjMy05MDdlLTIyYzM3MjYwYjQyOdIBAA?oc=5,"Künstliche Intelligenz: Diese Kamera weiß, wer Du bist - DER SPIEGEL",2020-03-05,DER SPIEGEL,https://www.spiegel.de,"Die EU-Kommission hat ein Strategiepapier zum Thema künstliche Intelligenz veröffentlicht - vorbei an der eigenen KI-Hochkommission. Das Seltsamste an dem Papier ist, was nicht darin steht.",N/A,"Die EU-Kommission hat ein Strategiepapier zum Thema künstliche Intelligenz veröffentlicht - vorbei an der eigenen KI-Hochkommission. Das Seltsamste an dem Papier ist, was nicht darin steht.",N/A,N/A,N/A,"





EU-Weißbuch zu künstlicher Intelligenz

Diese Kamera weiß, wer du bist



Die EU-Kommission hat ein Strategiepapier zum Thema künstliche Intelligenz veröffentlicht - vorbei an der eigenen KI-Hochkommission. Das Seltsamste an dem Papier ist, was nicht darin steht.


Von

Christian Stöcker

05.03.2020, 11.23 Uhr















Zur Merkliste hinzufügen






















X.com






Facebook








E-Mail







Messenger







WhatsApp










Link kopieren







Weitere Optionen zum Teilen













E-Mail











Messenger











WhatsApp














Link kopieren






























Bild vergrößern



Überwachungskamera, Banksy-Graffiti

Foto: Photofusion/ Universal Images Group via Getty Images












Anfang Februar herrschte im Europäischen Parlament eine gewisse Aufregung. Im Intranet des Parlaments war ein Dokument aufgetaucht, in dem es um den Einsatz künstlicher Intelligenz (KI) ging. ""Artificial Intelligence for better Services"", war der Titel. Einer der Vorschläge: ""biometriebasierte Sicherheit und Dienstleistungen für die Mitglieder (Abgeordneten)"".











Eine Abgeordnete der niederländischen Liberalen, Sophia in't Veld, die dem Ausschuss für Bürgerrechte angehört, war irritiert 


. Sie verlangte eine Erklärung  von der Parlamentsdirektion. Die Vertretung der im Parlament Angestellten schloss sich an : Niemand wollte sein Gesicht künftig scannen lassen, um ins Parlament zu kommen. Die Direktion beeilte man sich, zu versichern, dass es ""kein Projekt zur Gesichtserkennung im EU-Parlament"" gebe. Das Dokument sei alt, überholt und hätte gar nicht im Intranet auftauchen dürfen.











Auch Nichtparlamentarier mögen Gesichtserkennung im öffentlichen Raum nicht. So sprachen sich 2017 drei Viertel der Befragten in einer Studie zum Beispiel gegen Gesichtserkennungssysteme in Supermärkten  aus, auch wenn es dafür Rabatte geben sollte. In einer anderen Umfrage fanden nur 17 Prozent, dass deutsche Behörden uneingeschränkt Gesichtserkennung einsetzen dürfen sollten .







Gesichtserkennung verbieten? I wo!Nun hat die EU-Kommission gerade ein Weißbuch zum Thema künstliche Intelligenz vorgelegt. Bis kurz vor dessen Veröffentlichung war man davon ausgegangen, dass darin ein vorläufiges Verbot des Einsatzes von Gesichtserkennungssystemen im öffentlichen Raum zumindest erwogen würde . Aber selbst das ging offenbar irgendjemandem zu weit.











Das Weißbuch mit dem Untertitel ""Ein europäischer Ansatz für Exzellenz und Vertrauen""  soll eine Art erster strategischer Aufschlag der Kommission von Ursula von der Leyen in Sachen KI werden.







Nun hat die EU vor einiger Zeit eine sogenannte Hochkommission zum Thema Ethik in der KI eingesetzt, deren Aufgabe eigentlich darin besteht, Vorschläge für die künftige Regulierung dieser potenziell so veränderungsmächtigen Technologie zu machen. Diese Hochkommission hat ihre Arbeit aber noch gar nicht beendet. Sie wird in dem Papier lobend erwähnt, und einige Zwischenergebnisse ihrer Arbeit werden auch referiert - aber das ist alles.











Bei einem Treffen des Ethik-Gremiums am Dienstag vergangener Woche bekam einer der Vertreter der Zivilgesellschaft dem Vernehmen nach einen Wutanfall: Er frage sich, warum er jetzt seit eineinhalb Jahren regelmäßig zu Terminen erscheine und an Vorschlägen mitwirke, wenn die Kommission dann mal eben und ohne Absprache ein Strategiepapier veröffentlichte.







Keine Zukunfts-, sondern eine GegenwartstechnologieVertreter der Techbranche in der Hochkommission waren demnach ebenso irritiert, aber aus ganz anderen Gründen: Das Weißbuch enthielt ihnen zu viele mögliche Einschränkungen.So ist es ja eigentlich immer, wenn in Brüssel über Regulierung gesprochen wird: Vertreter von Zivilgesellschaft und NGOs wünschen sich klare Grenzen, Vertreter der betroffenen Branchen wollen vor allem, dass man sie erst einmal in Ruhe machen lässt, möglichst ohne Regulierung. So war es zum Beispiel bei der Datenschutzgrundverordnung. Beide Seiten aber dürften erstaunt gewesen sein über diese seltsame, unerwartete Leerstelle.














Das Weißbuch stuft nämlich ""remote biometric identification"", also biometrische Identifikation von Weitem, womöglich ohne Wissen der Betroffenen, explizit als ""Hochrisikofall"" ein. Ja, es erwähnt sogar explizit ""spezifische Grundrechtsrisiken"". Grundsätzlich verboten werden soll der Einsatz von Gesichtserkennung und ähnlicher Technik aber nun doch nicht. Sie soll aber nur eingesetzt werden dürfen, wenn das ""gerechtfertigt und verhältnismäßig"" sei und zudem ""angemessenen Sicherheitsvorkehrungen"" unterliege. Man wolle jetzt eine ""breite europäische Debatte"" darüber in Gang setzen, über Umstände, die ""wenn überhaupt"", den Einsatz rechtfertigen könnten.














Nun nimmt eine ""breite europäische Debatte"" in der Regel Jahre in Anspruch. Die Entwicklung im Bereich KI und Gesichtserkennung verläuft aber in atemberaubendem Tempo. Das umstrittene, auf Gesichtserkennung spezialisierte US-Unternehmen Clearview hat gerade erst Schlagzeilen gemacht, weil seine Kundenliste offenbar abhandenkam - sie umfasst Strafverfolger, Banken, Schulen - und europäische Behörden. Wir reden hier nicht von einer Zukunfts-, sondern von einer Gegenwartstechnologie. Aber die EU-Kommission will erst noch einmal in Ruhe europaweit diskutieren, während Fakten geschaffen werden?





Mehr zum Thema











Umstrittene Gesichtserkennungs-Firma: Clearview räumt Diebstahl seiner Kundenliste ein






































KI-Weißbuch der EU-Kommission: Irgendein Argument für Gesichtserkennung wird sich schon finden


Ein Kommentar von Patrick Beuth



























Behörden und Biometrie: Die schlechtesten Argumente für Gesichtserkennung


Von Patrick Beuth



























Wo Science-Fiction recht hatte und wo nicht: Chinas Schweine und die Welt von morgen


Von Christian Stöcker
























Victor Orbán gefällt das bestimmtGerade der deutsche Innenminister Horst Seehofer hat diverse Male deutlich gemacht, dass er Kameras mit Gesichtserkennungssystemen im öffentlichen Raum eigentlich wirklich gern hätte, stößt aber auf Widerstand. In anderen europäischen Staaten dürfte es ähnliche Bedürfnisse geben - namentlich in solchen, in denen Rechtsstaatlichkeit und Grundrechte durchaus zur Disposition stehen, Ungarn etwa oder Polen.














Solche Staaten könnten in den nächsten Jahren Fakten schaffen. Was ein Staat, dem rechtsstaatliche Grundprinzipien gleichgültig sind, mit dieser Technologie im Zweifelsfall anstellen kann, ist derzeit in China zu sehen, insbesondere in der Provinz Xinjiang. Dort ist die muslimische Minderheit der Uiguren einer umfassenden Hightech-Totalüberwachung und Unterdrückung ausgesetzt, die selbst George Orwell in Erstaunen versetzt hätte 





. Wer auffällt, und sei es durch einen Bart, kommt ins Lager. Kameras mit Gesichtserkennung spielen in dem System eine zentrale Rolle.Aber gibt es doch Terroristen!Ist das also der ""europäische Ansatz für Exzellenz und Vertrauen""? Erst einmal in aller Ruhe darüber zu diskutieren, ob die ständige Totalüberwachung der eigenen Bevölkerung im öffentlichen Raum nicht vielleicht doch ""gerechtfertigt und verhältnismäßig"" sein könnte? Denn ein Argument für noch mehr Befugnisse fällt Sicherheitsbehörden im Zweifel ja immer ein: Terroristen.














Die EU ist in Sachen KI und maschinelles Lernen in einer schwierigen Lage: Sie droht zwischen dem Geld und dem Know-how der Silicon-Valley-Giganten und dem unbedingten Fortschrittswillen der chinesischen Führung zerrieben zu werden. Die Antwort auf dieses Dilemma kann aber nicht sein, europäische Grundwerte aufzugeben - denn die sind im Moment unser wichtigster Trumpf.
















Feedback


",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3Lm90di5kZS9hbWJlcmcta3VlbnN0bGljaGUtaW50ZWxsaWdlbnotYWxzLXNjaGx1ZXNzZWx0ZWNobm9sb2dpZS00MTkwNDkv0gEA?oc=5,Amberg: Künstliche Intelligenz als Schlüsseltechnologie - Oberpfalz TV,2020-03-01,Oberpfalz TV,https://www.otv.de,"Künstliche Intelligenz: Sie erlaubt Computern komplexe Probleme zu lösen, wo einst davon ausgegangen wurde, dass diese Probleme nur Menschen lösen können. Im  …",N/A,"Künstliche Intelligenz: Sie erlaubt Computern komplexe Probleme zu lösen, wo einst davon ausgegangen wurde, dass diese Probleme nur Menschen lösen können. Im  …",N/A,N/A,N/A,N/A,https://schema.org,NewsArticle,https://www.otv.de/amberg-kuenstliche-intelligenz-als-schluesseltechnologie-419049/,"{'@type': 'Person', 'name': 'Viktoria Lorenz'}",Amberg: K&uuml;nstliche Intelligenz als Schl&uuml;sseltechnologie,https://www.otv.de/storage/thumbs/1200x630c/r:1582802668/419039.jpg,2020-03-01T11:37:23+0000,2020-02-27T12:48:18+0000,https://www.otv.de/amberg-kuenstliche-intelligenz-als-schluesseltechnologie-419049/,"{'@type': 'WebPage', '@id': 'https://www.otv.de/amberg-kuenstliche-intelligenz-als-schluesseltechnologie-419049/'}",,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LnNwZWt0cnVtLmRlL25ld3MvZnVlci1rdWVuc3RsaWNoZS1pbnRlbGxpZ2Vuei1ibGVpYmVuLW1lbnNjaGxpY2hlLWVtb3Rpb25lbi1laW4tcmFldHNlbC8xNzA5NzY00gEA?oc=5,Für künstliche Intelligenz bleiben menschliche Emotionen ein Rätsel - Spektrum.de,2020-03-04,Spektrum.de,https://www.spektrum.de,"Lachfältchen = Freude. Gerümpfte Nase = Ekel. Künstliche Intelligenz soll aus Mimik auf Gefühle schließen. Dabei taugt unser Gesicht wohl gar nicht dazu, Emotionen zu erkennen.","['Emotion', 'Emotionen', 'Gefühle', 'Gesicht', 'Mimik', 'Mikroexpressionen', 'Glück', 'Wut', 'Ärger', 'Trauer', 'Paul Ekman', 'Grundemotionen', 'Kulturen', 'Kulturübergreifend', 'Künstliche Intelligenz', 'Maschinelles Lernen', 'Affectiva', 'Emotionserkennung', '', 'IT/Tech']","Wenn Maschinen Gefühle aus Gesichtern lesen, ist etwas faul",N/A,N/A,N/A,"StartseiteIT/TechAktuelle Seite: Für künstliche Intelligenz bleiben menschliche Emotionen ein RätselArtikel anhören? Jetzt anmelden!Hintergrund 04.03.2020 Lesedauer ca. 11 Minuten DruckenTeilen Künstliche Intelligenz: Unser Gesicht gibt das nicht herLachfältchen = Freude. Gerümpfte Nase = Ekel. Künstliche Intelligenz soll aus Mimik auf Gefühle schließen. Dabei taugt unser Gesicht wohl gar nicht dazu, Emotionen zu erkennen.von Douglas Heaven © master1305 / Getty Images / iStock (Ausschnitt) Exklusive Übersetzung ausWer hat einen Orgasmus? Und wer empfindet plötzlichen Schmerz? Es wirkt wie eine einfache Frage, die sich die 80 Versuchspersonen einer psychologischen Studie stellen sollen. Hunderte computergenerierte menschliche Gesichter erscheinen dazu vor ihnen auf einem Bildschirm. Bei einigen sind die Augen weit aufgerissen, andere haben zusammengepresste Lippen. Bei wieder anderen sind die Augen zusammengepresst, die Wangen gehoben und der Mund offen. Und immer wieder die gleiche Frage: Orgasmus? Oder Schmerz? Die Psychologin Rachael Jack und ihre Kollegen haben diesen Test als Teil einer Studie im Jahr 2018 durchgeführt. Das Team der University of Glasgow hat dafür Teilnehmer aus westlichen und ostasiatischen Kulturen angeworben, um eine Frage zu untersuchen, an der sich von alters her die Geister scheiden: Kann man am Gesichtsausdruck eines Menschen zuverlässig ablesen, was dieser gerade fühlt? Dieser Artikel ist enthalten in Spektrum Kompakt, Sieh mich an – Was unser Gesicht verrätAusgabe als PDF-Download (EUR 4,99)Spektrum Kompakt-ArchivSeit Jahrzehnten holen sich Forscher dazu Probanden ins Labor. Sie haben Erwachsene und Kinder in verschiedenen Ländern und indigene Bevölkerungsgruppen in entlegenen Teilen der Welt befragt. Einflussreiche Beobachtungen des US-amerikanischen Psychologen Paul Ekman in den 1960er und 1970er Jahren legten nahe, dass Menschen auf der ganzen Welt verlässlich aus dem Gesichtsausdruck auf emotionale Zustände schließen können – was impliziert, dass der emotionale Ausdruck universell ist. Mimik unterscheidet sich eben doch zwischen KulturenDie Vorstellung blieb eine Forschergeneration lang weitgehend unangefochten. Inzwischen aber stößt sie verstärkt auf Skepsis. Viele Forscher sind heute der Meinung, dass die Verhältnisse sehr viel komplizierter sind. Die Mimik unterscheide sich sehr wohl zwischen den verschiedenen Kontexten und Kulturen. Rachael Jacks Studie ergab zum Beispiel, dass Menschen aus dem Westen und aus Ostasien zwar ähnliche Vorstellungen davon haben, wie Gesichter Schmerz zeigen, aber unterschiedliche Vorstellungen über den Ausdruck sexueller Verzückung.  © Alamy / History Collection 2016 (Ausschnitt)  Mit vollem Einsatz traurig | Fotoserie aus Charles Darwins »Der Ausdruck der Gemütsbewegungen bei dem Menschen und den Tieren« von 1872. Hier versuchen Probanden »Trauer« darzustellen. Dass in der akademischen Forschung die Ansichten über Ekmans Vorstellung vom menschlichen Gesicht als Gefühlsorakel stark auseinandergehen, hindert Unternehmen und Regierungen jedoch nicht daran, auf dieser Grundlage Verfahren zu entwickeln, die das Leben von Menschen beeinflussen. In vielen Rechtssystemen im Westen beispielsweise gilt es als Teil eines fairen Prozesses, die...",http://schema.org,NewsArticle,,"[{'@type': 'Person', 'name': 'Douglas Heaven'}]",Unser Gesicht gibt das nicht her,https://static.spektrum.de/fm/912/iStock-1095939686_zuschnitt.jpg?width=2000&height=630&fit=crop&auto=webp,2020-03-04T08:16:00+01:00,2020-03-04T08:16:00+01:00,https://www.spektrum.de/news/fuer-kuenstliche-intelligenz-bleiben-menschliche-emotionen-ein-raetsel/1709764,https://www.spektrum.de/news/fuer-kuenstliche-intelligenz-bleiben-menschliche-emotionen-ein-raetsel/1709764,2020-03-04T08:16:00+01:00,False,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.spektrum.de/js_css/assets/img/png/spektrum_logo.png'}, 'name': 'Spektrum.de'}",https://static.spektrum.de/fm/912/iStock-1095939686_zuschnitt.jpg?width=2000&height=630&fit=crop&auto=webp,[],,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3LnNpZW1lbnMtaGVhbHRoaW5lZXJzLmNvbS9kZXUvcGVyc3BlY3RpdmVzL21zby12aXNpb25hcnktbWVkaWNhbC1jYXJlLmh0bWzSAQA?oc=5,Arbeiten im Hybrid-OP: Medizinische Versorgung mit Weitblick - Siemens Healthineers,2020-03-03,Siemens Healthineers,https://www.siemens-healthineers.com,Ein Hybrid-Operationssaal als Anziehungspunkt in einem neuen Operations- und Intensivpflegezentrum in Österreich – lesen Sie über diese visionäre Entscheidung.,"Hybrid OP, Chirurgie, ARTIS pheno",Harald Maikisch ist Experte im Spitalwesen mit bald vier Jahrzehnten Erfahrung. Ein Hybrid-Operationssaal im von ihm geleiteten Schwerpunktkrankenhaus Feldkirch ist das Herzstück des dort neu gebauten OP- und Intensivzentrums. Mit der Entscheidung für diesen Saal beweisen die Planer um Maikisch Weitblick – und zwar im wahrsten Sinn des Wortes…,N/A,N/A,N/A,N/A,http://schema.org,WebPage,,,,,,,https://www.siemens-healthineers.com/deu/perspectives/mso-visionary-medical-care.html,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vd3d3LnN1ZWRkZXV0c2NoZS5kZS93aXJ0c2NoYWZ0L3BlcnNvbmFsc29mdHdhcmUtYXJiZWl0LXN0dWRpZS1hbGdvcml0aG0td2F0Y2gtMS40ODI2NjM50gEA?oc=5,Arbeitswelt - Wenn die Firma den Mitarbeiter durchleuch - Wirtschaft - SZ.de - Süddeutsche Zeitung - SZ.de,2020-03-02,Süddeutsche Zeitung - SZ.de,https://www.sueddeutsche.de,Die Softwareanalyse von Beschäftigten in deutschen Unternehmen könnte oft rechtswidrig sein. Das besagt eine Studie von Algorithm Watch.,"Arbeit und Soziales,Süddeutsche Zeitung Wirtschaft,Unternehmen,Überwachung am Arbeitsplatz,Arbeit und Soziales,Unternehmen,Überwachung am Arbeitsplatz,Arbeit,Wirtschaft,Süddeutsche Zeitung",Die Softwareanalyse von Beschäftigten in deutschen Unternehmen könnte oft rechtswidrig sein. Das besagt eine Studie von Algorithm Watch.,N/A,N/A,N/A,"Arbeitswelt:Personalanalyse von Mitarbeitern oft rechtswidrig2. März 2020, 6:07 UhrLesezeit: 3 minDetailansicht öffnenZalando erregte vor Kurzem mit der Personalsoftware Zonar Aufsehen (Symbolbild). (Foto: Jens Kalaene/dpa)Wenn deutsche Unternehmen Personalsoftware einsetzen, um Mitarbeiter zu analysieren, könnte das in der Praxis oft rechtswidrig sein; das geht aus einer Studie der Organisation AlgorithmWatch hervor.Demnach bedarf der zunehmende Einsatz solcher Programme in vielen Fällen der Zustimmung der Mitarbeiter oder einer Betriebsvereinbarung.Von Alexander Hagelüken, MünchenMerkenTeilenFeedbackDruckenSeit die Arbeitswelt digitalisiert wird, verändert sich für Beschäftigte viel. Vor Kurzem erregte der Modehändler Zalando mit der Personalsoftware Zonar Aufsehen, bei der sich Kollegen gegenseitig benoten. Mitarbeiter klagen, Zalando erzeuge Überwachung, Leistungsdruck und Stress. Nun haben Forscher in zweijähriger Arbeit untersucht, wie generell die Softwareanalyse von Beschäftigten zu bewerten ist. Ergebnis: Unternehmen handeln dabei womöglich oft rechtswidrig.Firmen setzen zunehmend Software ein, um Mitarbeiter zu analysieren und zu bewerten, People Analytics heißt das. So lassen sich tatsächliche oder mögliche Leistungen analysieren, steuern oder voraussagen. Die Programme erkennen Muster oder rechnen mit Wahrscheinlichkeiten, etwa durch maschinelles Lernen. ""Firmen befinden sich damit oft in einer rechtlichen Grauzone, häufig wird der Einsatz sogar rechtswidrig sein"", heißt es nun in einer Studie der Organisation Algorithm Watch, die der Süddeutschen Zeitung vorliegt.Zalando:""Derartige Methoden gehören verboten""Politiker von SPD, Grünen und Linken kritisieren das Zalando-Personalsystem.  Der Modehändler weist die Vorwürfe zurück.Von Alexander HagelükenDas Forschungsprojekt, unterstützt von der gewerkschaftsnahen Hans-Böckler-Stiftung, enthält Gutachten etwa des Arbeitsrechtlers Peter Wedde. Es beschäftigt sich nicht mit selbstentworfener Software wie bei Zalando oder dem Verhalten individueller Arbeitgeber. Es geht vielmehr um Programme wie Microsofts Office 365 Workplace Analytics, IBMs Watson Talent Insights oder SAP Success Factors People Analytics. Dabei bedeutet es noch wenig, dass solche Software in einem Unternehmen vorhanden ist.Anders, wenn es damit tatsächlich People Analytics betreibt. Wenn es etwa Beschäftigtendaten verarbeitet, um individuelle Leistungen vorherzusagen, gibt es strenge gesetzliche Grenzen, so die Forscher. ""Hier müssen die Beschäftigten einzeln und freiwillig einwilligen. Das wird in der Praxis oft nicht der Fall sein."" Die Alternative ist, dass eine Betriebsvereinbarung die Analysemethoden legitimiert. Doch auch diese fehle häufig. ""Es ist davon auszugehen, dass sehr oft weder eine Einwilligung vorliegt noch Betriebsräte bereit dazu sind, Betriebsvereinbarungen abzuschließen."" Damit rutschten die Unternehmen beim Einsatz der Programme in die Grauzone oder gar in die Rechtswidrigkeit, so die Forscher. Ihre Erkenntnisse kommen, bevor Bundesarbeitsminister Hubertus Heil (SPD) am Dienstag das Observatorium Künstliche Intelligenz (KI) eröffnet, das die Auswirkungen auf Arbeit und Gesellschaft untersuchen wird.Ethische Leitlinien für den Einsatz von künstlicher IntelligenzSAP erklärte, um Personalprogramme für ein besseres Arbeitsumfeld zu gestalten, sei es weder notwendig noch zielführend, Daten auf individueller Mitarbeiterebene zu analysieren. ""In diesem Kontext arbeiten wir bei SAP ausschließlich mit aggregierten, vollkommen anonymisierten Datensätzen, unter Einhaltung der Datenschutzregelungen."" Microsoft erklärt dazu, Unternehmen, die Microsoft 365 kauften, entschieden für ihre Mitarbeiter, welche Module eingesetzt und aktiviert würden. ""Dafür wird zwischen dem Unternehmen und dem Betriebsrat im Regelfall eine Betriebsvereinbarung geschlossen."" Bei den Produkten My Analytics und Workplace Analytics könnten keine individuellen Leistungen von Vorgesetzten beurteilt oder vorhergesagt werden.Die Studie von Algorithm Watch macht als weiteres Problem aus, dass die Unternehmen den Betriebsräten oft nicht die Auskünfte über die Programme geben könnten, die diesen zustehen. Nach dem Gesetz müssten Firmen Arbeitnehmervertreter weitreichend informieren, wie Personalsoftware funktioniert, die etwa auf künstlicher Intelligenz basiert. Doch die Anbieter gäben diese Informationen häufig nicht heraus: ""Auf welchen Annahmen und Modellen Prognosen getroffen werden, mit welchen Daten die Systeme trainiert wurden, halten die Anbieter üblicherweise geheim."" Sie begründeten das damit, dass sie sich vor Nachahmern schützen müssten. Microsoft erklärt, man stelle durchaus Dokumentation zur Funktionsweise der Software zur Verfügung, was aber seine Grenze beim Schutz von Geschäftsgeheimnissen finde.""Wenn der Betriebsrat keine Informationen einfordert, führen Firmen die Systeme oft ein"", beobachtet Matthias Spielkamp von Algorithm Watch. Er ruft Betriebsräte auf, ihre Auskunftsrechte bereits in der Planungsphase von KI-Systemen durchzusetzen, da sich die praktische Wirksamkeit ihrer Mitbestimmungsrechte verringert, sobald Systeme eingeführt sind. ""Im Nachhinein ist es schwieriger, etwas zu ändern.""Zusammen mit dem Mathematiker Sebastian Stiller von der TU Braunschweig wurde ein Leitfaden entwickelt, wie Unternehmen und Betriebsräte gemeinsam von den Softwareanbietern die nötigen Informationen erfragen können. Spielkamp fordert die Bundesregierung auf, gesetzlich klarzustellen, dass Unternehmen auch dann verwendete Methoden transparent machen müssten, wenn die Softwareanbieter mauerten.Der Arbeitsrechtler Peter Wedde fordert von der Regierung noch mehr: ""Um Beschäftigte insbesondere vor dem hohen Kontrollpotenzial zu schützen, das sich mit KI-Software und selbstlernenden Algorithmen verbindet, ist ein Ausbau bestehender Mitbestimmungsrechte unumgänglich."" Die Gewerkschaft Verdi legt in Kürze ethische Leitlinien für den Einsatz von künstlicher Intelligenz vor. Vorstand Christoph Schmitz erklärt dazu unter anderem, KI-Systeme, die auf der Verarbeitung großer Datenmengen basieren, dürften nicht zu einer Gefährdung der Persönlichkeitsrechte führen. ""Ein Beschäftigtendatenschutzgesetz ist überfällig.""© SZ vom 02.03.2020 - Rechte am Artikel können Sie hier erwerben.TeilenFeedbackDruckenZur SZ-StartseiteMeinungUnternehmen:Arbeitnehmer können sich gegen Überwachung wehrenDass Zalando seine Mitarbeiter offenbar per Software kontrolliert, zeigt: Die Digitalisierung droht Arbeitnehmer zu entmachten. Deshalb sollten sie sich zusammenschließen.Kommentar von Alexander HagelükenLesen Sie mehr zum ThemaArbeit und SozialesUnternehmenÜberwachung am ArbeitsplatzArbeit",https://schema.org,NewsArticle,,"[{'@type': 'Person', 'name': 'Alexander Hagelüken', 'sameAs': '/autoren/alexander-hagelueken-1.1143261'}]",Arbeitswelt - Wenn die Firma den Mitarbeiter durchleuch,"{'@type': 'ImageObject', 'height': '675', 'url': 'https://www.sueddeutsche.de/2022/06/08/f304be2b-539a-4575-b19b-5db439c3290d.jpeg?q=60&fm=webp&width=1200&rect=154%2C230%2C1177%2C662', 'width': '1200'}",2020-03-02T05:07:34.000Z,2021-07-05 09:57:49,https://www.sueddeutsche.de/wirtschaft/personalsoftware-arbeit-studie-algorithm-watch-1.4826639,https://www.sueddeutsche.de/wirtschaft/personalsoftware-arbeit-studie-algorithm-watch-1.4826639,2020-03-02T05:07:34.000Z,,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'height': '64', 'url': 'https://www.sueddeutsche.de/szde-assets/img/szde-article-sueddeutsche-logo.svg', 'width': '525'}, 'name': 'Süddeutsche Zeitung'}",,,Arbeit und Soziales,"Seit die Arbeitswelt digitalisiert wird, verändert sich für Beschäftigte viel. Vor Kurzem erregte der Modehändler Zalando mit der Personalsoftware Zonar Aufsehen, bei der sich Kollegen gegenseitig benoten. Mitarbeiter klagen, Zalando erzeuge Überwachung, Leistungsdruck und Stress. Nun haben Forscher in zweijähriger  Arbeit  untersucht, wie generell die Softwareanalyse von Beschäftigten zu bewerten ist. Ergebnis:  Unternehmen  handeln dabei womöglich oft rechtswidrig.
Firmen setzen zunehmend Software ein, um Mitarbeiter zu analysieren und zu bewerten,  People Analytics  heißt das. So lassen sich tatsächliche oder mögliche Leistungen analysieren, steuern oder voraussagen. Die Programme erkennen Muster oder rechnen mit Wahrscheinlichkeiten, etwa durch maschinelles Lernen. ""Firmen befinden sich damit oft in einer rechtlichen Grauzone, häufig wird der Einsatz sogar rechtswidrig sein"", heißt es nun in einer  Studie der Organisation Algorithm Watch , die der  Süddeutschen Zeitung  vorliegt.
Das Forschungsprojekt, unterstützt von der gewerkschaftsnahen Hans-Böckler-Stiftung, enthält Gutachten etwa des Arbeitsrechtlers Peter Wedde. Es beschäftigt sich nicht mit selbstentworfener Software wie bei Zalando oder dem Verhalten individueller Arbeitgeber. Es geht vielmehr um Programme wie Microsofts Office 365 Workplace Analytics, IBMs Watson Talent Insights oder SAP Success Factors People Analytics. Dabei bedeutet es noch wenig, dass solche Software in einem Unternehmen vorhanden ist.
Anders, wenn es damit tatsächlich People Analytics betreibt. Wenn es etwa Beschäftigtendaten verarbeitet, um individuelle Leistungen vorherzusagen, gibt es strenge gesetzliche Grenzen, so die Forscher. ""Hier müssen die Beschäftigten einzeln und freiwillig einwilligen. Das wird in der Praxis oft nicht der Fall sein."" Die Alternative ist, dass eine Betriebsvereinbarung die Analysemethoden legitimiert. Doch auch diese fehle häufig. ""Es ist davon auszugehen, dass sehr oft weder eine Einwilligung vorliegt noch Betriebsräte bereit dazu sind, Betriebsvereinbarungen abzuschließen."" Damit rutschten die Unternehmen beim Einsatz der Programme in die Grauzone oder gar in die Rechtswidrigkeit, so die Forscher. Ihre Erkenntnisse kommen, bevor Bundesarbeitsminister Hubertus Heil (SPD) am Dienstag das Observatorium Künstliche Intelligenz (KI) eröffnet, das die Auswirkungen auf Arbeit und Gesellschaft untersuchen wird.
Ethische Leitlinien für den Einsatz von künstlicher Intelligenz
SAP erklärte, um Personalprogramme für ein besseres Arbeitsumfeld zu gestalten, sei es weder notwendig noch zielführend, Daten auf individueller Mitarbeiterebene zu analysieren. ""In diesem Kontext arbeiten wir bei SAP ausschließlich mit aggregierten, vollkommen anonymisierten Datensätzen, unter Einhaltung der Datenschutzregelungen."" Microsoft erklärt dazu, Unternehmen, die Microsoft 365 kauften, entschieden für ihre Mitarbeiter, welche Module eingesetzt und aktiviert würden. ""Dafür wird zwischen dem Unternehmen und dem Betriebsrat im Regelfall eine Betriebsvereinbarung geschlossen."" Bei den Produkten My Analytics und Workplace Analytics könnten keine individuellen Leistungen von Vorgesetzten beurteilt oder vorhergesagt werden.
Die Studie von Algorithm Watch macht als weiteres Problem aus, dass die Unternehmen den Betriebsräten oft nicht die Auskünfte über die Programme geben könnten, die diesen zustehen. Nach dem Gesetz müssten Firmen Arbeitnehmervertreter weitreichend informieren, wie Personalsoftware funktioniert, die etwa auf künstlicher Intelligenz basiert. Doch die Anbieter gäben diese Informationen häufig nicht heraus: ""Auf welchen Annahmen und Modellen Prognosen getroffen werden, mit welchen Daten die Systeme trainiert wurden, halten die Anbieter üblicherweise geheim."" Sie begründeten das damit, dass sie sich vor Nachahmern schützen müssten. Microsoft erklärt, man stelle durchaus Dokumentation zur Funktionsweise der Software zur Verfügung, was aber seine Grenze beim Schutz von Geschäftsgeheimnissen finde.
""Wenn der Betriebsrat keine Informationen einfordert, führen Firmen die Systeme oft ein"", beobachtet Matthias Spielkamp von Algorithm Watch. Er ruft Betriebsräte auf, ihre Auskunftsrechte bereits in der Planungsphase von KI-Systemen durchzusetzen, da sich die praktische Wirksamkeit ihrer Mitbestimmungsrechte verringert, sobald Systeme eingeführt sind. ""Im Nachhinein ist es schwieriger, etwas zu ändern.""
Zusammen mit dem Mathematiker Sebastian Stiller von der TU Braunschweig wurde ein Leitfaden entwickelt, wie Unternehmen und Betriebsräte gemeinsam von den Softwareanbietern die nötigen Informationen erfragen können. Spielkamp fordert die Bundesregierung auf, gesetzlich klarzustellen, dass Unternehmen auch dann verwendete Methoden transparent machen müssten, wenn die Softwareanbieter mauerten.
Der Arbeitsrechtler Peter Wedde fordert von der Regierung noch mehr: ""Um Beschäftigte insbesondere vor dem hohen Kontrollpotenzial zu schützen, das sich mit KI-Software und selbstlernenden Algorithmen verbindet, ist ein Ausbau bestehender Mitbestimmungsrechte unumgänglich."" Die Gewerkschaft Verdi legt in Kürze ethische Leitlinien für den Einsatz von künstlicher Intelligenz vor. Vorstand Christoph Schmitz erklärt dazu unter anderem, KI-Systeme, die auf der Verarbeitung großer Datenmengen basieren, dürften nicht zu einer Gefährdung der Persönlichkeitsrechte führen. ""Ein Beschäftigtendatenschutzgesetz ist überfällig.""",Wirtschaft,684.0,Arbeitswelt - Wenn die Firma den Mitarbeiter durchleuch,PT3M,,
https://news.google.com/rss/articles/CBMiiQFodHRwczovL3d3dy5oYW5kZWxzYmxhdHQuY29tL3BvbGl0aWsvZGV1dHNjaGxhbmQvdGh1ZXJpbmdlbi1tYXJpby12b2lndC1mb2xndC1tb2hyaW5nLWFuLXNwaXR6ZS1kZXItdGh1ZXJpbmdlci1jZHUtZnJha3Rpb24vMjU2MDAzMTIuaHRtbNIBAA?oc=5,Thüringen: Mario Voigt folgt Mohring an Spitze der Thüringer CDU-Fraktion - Handelsblatt,2020-03-02,Handelsblatt,https://www.handelsblatt.com,Mike Mohring hat als Konsequenz des Wahldebakels um FDP-Politiker Thomas Kemmerich seinen Rücktritt erklärt. Nun steht sein Nachfolger fest.,N/A,Mike Mohring hat als Konsequenz des Wahldebakels um FDP-Politiker Thomas Kemmerich seinen Rücktritt von der Thüringer CDU-Spitze erklärt. Nun steht sein Nachfolger fest.,N/A,Politik - Deutschland,N/A,"ThüringenMario Voigt folgt Mohring an Spitze der Thüringer CDU-FraktionMike Mohring hat als Konsequenz des Wahldebakels um FDP-Politiker Thomas Kemmerich seinen Rücktritt von der Thüringer CDU-Spitze erklärt. Nun steht sein Nachfolger fest. 02.03.2020 - 11:22 Uhr















































Nach Angaben eines Fraktionssprecher hatte Voigt keine Gegenkandidaten. Foto: dpa Erfurt. Der Hochschulprofessor Mario Voigt ist als Nachfolger von Mike Mohring neuer Chef der Thüringer CDU-Landtagsfraktion. Der stellvertretende Landesparteichef erreichte bei einer außerplanmäßigen Wahl des Vorstands die nötige Mehrheit, wie die CDU-Fraktion am Montag in Erfurt bekannt gab. Nach Angaben eines Fraktionssprechers gab es keinen Gegenkandidaten. Der 43-jährige Hochschulprofessor für Digitale Transformation und Politik erhielt bei der Fraktionssitzung 15 Ja-Stimmen; 3 Abgeordnete stimmten gegen ihn, 3 enthielten sich.Mohring stand spätestens nach dem Debakel um die Wahl des FDP-Politikers Thomas Kemmerich zum Thüringer Ministerpräsidenten öffentlich wie auch in den eigenen Reihen massiv unter Druck. Vor der Wahl des Fraktionsvorstandes hatte Mohring angekündigt, nicht erneut zu kandidieren und sich parallel auch von der Landesparteispitze zurückziehen zu wollen.Am 18. April soll bei einem Landesparteitag über Mohrings Nachfolge an der Parteispitze entschieden werden. Bis dahin übernehmen seine Stellvertreter.Mehr: Linke, SPD und Grüne haben sich mit der CDU in Thüringen auf Neuwahlen am 25. April 2021 verständigt. Bis dahin soll Bodo Ramelow als Ministerpräsident regieren.dpaZur StartseiteNachricht an die Redaktion",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihAFodHRwczovL3d3dy5ybmQuZGUvZGlnaXRhbC9rdW5zdGxpY2hlLWludGVsbGlnZW56ZW4tYmV3ZXJ0ZW4tbWl0YXJiZWl0ZXItZWluLWdyZW56d2VydGlnZXMtdmVyZmFocmVuLVhQRk9ORkVHSEJHSFZQQUJLUlFUMllVTlNNLmh0bWzSAZkBaHR0cHM6Ly93d3cucm5kLmRlL2RpZ2l0YWwva3Vuc3RsaWNoZS1pbnRlbGxpZ2VuemVuLWJld2VydGVuLW1pdGFyYmVpdGVyLWVpbi1ncmVuendlcnRpZ2VzLXZlcmZhaHJlbi1YUEZPTkZFR0hCR0hWUEFCS1JRVDJZVU5TTS5odG1sP291dHB1dFR5cGU9dmFsaWRfYW1w?oc=5,Künstliche Intelligenzen bewerten Mitarbeiter: Ein grenzwertiges Verfahren - RND,2020-03-03,RND,https://www.rnd.de,"Unternehmen setzen im Personalmanagement zunehmend auf sogenannte People-Analytics, bei denen Mitarbeiter von künstlichen Intelligenzen analysiert werden. Doch dieses Vorgehen ist laut einer Studie oft rechtswidrig.",N/A,"Unternehmen setzen im Personalmanagement zunehmend auf sogenannte People-Analytics, bei denen Mitarbeiter von künstlichen Intelligenzen analysiert werden. Doch dieses Vorgehen ist laut einer Studie oft rechtswidrig.",N/A,N/A,N/A,"StartseiteDigitalKünstliche Intelligenzen bewerten Mitarbeiter: Ein grenzwertiges VerfahrenKünstliche Intelligenzen bewerten Mitarbeiter: Ein grenzwertiges VerfahrenBildunterschrift anzeigenBildunterschrift anzeigenHubertus Heil (SPD), Bundesminister für Arbeit und Soziales, spricht am Dienstag zur Eröffnung des KI-Observatoriums.Quelle: Bernd von Jutrczenka/dpaUnternehmen setzen im Personalmanagement zunehmend auf sogenannte People-Analytics, bei denen Mitarbeiter von künstlichen Intelligenzen analysiert werden. Doch dieses Vorgehen ist laut einer Studie oft rechtswidrig.03.03.2020, 05:41 UhrWhatsAppFacebookXWhatsAppFacebookXLinkedInXingMailPocketShare-Optionen öffnenShare-Optionen schließenMehr Share-Optionen zeigenMehr Share-Optionen zeigenWhatsAppFacebookXLinkedInXingMailPocket Ob bei der Auswahl von Bewerbern, der Weiterbildung von Mitarbeitern oder der Verschlankung von Mitarbeiterverwaltung – künstliche Intelligenzen (KI) im Personalwesen finden zunehmend Anklang. Einer Umfrage des Bundesverbandes der Personalmanager zufolge beschäftigen sich rund 74 Prozent der Befragten bereits mit KI-basierten Technologien, der Großteil prüft demnach, ob Algorithmen und Co. im eigenen Aufgabenbereich zum Einsatz kommen könnten.Weiterlesen nach der AnzeigeWeiterlesen nach der AnzeigeDoch bei der Etablierung von KI-gestützten Softwares ist Vorsicht geboten. Wie ein zweijähriges Forschungsprojekt der Organisation Algorithmwatch mit Unterstützung der Hans-Böckler-Stiftung nun ergab, ist das Verwenden von sogenannten People-Analytics oft rechtswidrig. Denn die Verfahren dürfen nur eingesetzt werden, wenn die Beschäftigten dem Vorgang einzeln und freiwillig zustimmen oder eine Betriebsvereinbarung vorliegt. Dies ist laut den Urhebern der Studie nicht immer der Fall. “Es ist ethisch nicht zu rechtfertigen, Angestellte zu reinen Objekten derartiger Verfahren zu machen”, heißt es in einer Pressemitteilung der Organisation.Mehr zum Thema Fraunhofer-Chef im Interview: “Künstliche Intelligenz übernimmt nicht die Macht” Observatorium untersucht Auswirkungen von KI auf Arbeit und GesellschaftDie Initiative Algorithmwatch wurde 2016 gegründet und nimmt seither verschiedene algorithmische Prozesse unter die Lupe. Dabei analysiert die Organisation, wie sich Algorithmen auf menschliches Verhalten auswirken, und zeigt ethische Konflikte auf. Eine andere Institution, die sich künftig mit den Einflüssen der Digitalisierung auf die neue Arbeitswelt und die Gesellschaft auseinandersetzen will, ist das KI-Observatorium, das am heutigen 3. März in Berlin seine Arbeit aufnimmt. Das Projekt ist Teil der Denkfabrik Digitale Arbeitsgesellschaft, die 2018 vom Bundesministerium für Arbeit und Soziales (BMAS) ins Leben gerufen wurde.Weiterlesen nach der AnzeigeWeiterlesen nach der AnzeigeDas Observatorium soll jedoch nicht nur als Beobachter fungieren. So könnte es künftig eine Art TÜV für künstliche Intelligenzen berufen, der die Programme klassifiziert und offiziell für zulässig erklärt. “Wir schauen uns an, wo diese Technologie eingesetzt wird und wo das in sensiblen Bereichen geschieht”, erklärte dazu Björn Böhning, Staatssekretär im BMAS, der “Süddeutschen Zeitung”. Neben Anwendungsbereichen im Einzelhandel, der Automobilbranche und dem Finanzwesen sollen auch die Auswirkungen auf die Arbeitswelt genauer untersucht werden.Softwares werten E-Mails und Besprechungen ausBereits jetzt gibt es mit Office 365 Workplace Analytics von Microsoft, Watson Talent Insight von IBM und Success Factors People Analytics von SAP Dienste großer Anbieter, die damit werben, Möglichkeit, Leistung und Potenzial von Mitarbeitern zu analysieren, vorauszusagen und sogar zu steuern. Das Programm von Microsoft ermittelt dazu beispielsweise, wie lange ein Arbeitnehmer braucht, um eine E-Mail zu verfassen oder eine Besprechung abzuhalten. Zwar erfolgt die Analyse laut Microsoft anonymisiert, dennoch soll der Vorgesetzte auf Optimierungsbedarf hingewiesen werden.Forscher fordern gesetzliche Regelungen für KI im Personalwesen“Um Beschäftigte vor den Möglichkeiten und insbesondere vor dem immanent hohen Kontrollpotenzial zu schützen, das sich mit KI-Software und mit selbst lernenden Algorithmen verbindet, ist ein Ausbau bestehender Mitwirkungs- und Mitbestimmungsrechte durch den Gesetzgeber unumgänglich”, kommentiert der Rechtswissenschaftler Peter Wedde die Entwicklungen in einem Gutachten. Demnach werden mit Algorithmen im Personalmanagement völlig neue Formen der Überwachung möglich, die mit massiven Eingriffen in die Persönlichkeitsrechte der Mitarbeiter verbunden sind. Heimliche Kontrollen seien laut Wedde nur dann erlaubt, wenn Verdacht auf eine strafbare Handlung besteht.Weiterlesen nach der AnzeigeWeiterlesen nach der AnzeigeIn einem Positionspapier fordert Algorithmwatch von der Bundesregierung gesetzliche Regelungen, die Arbeitgeber dazu verpflichten, die verwendeten Verfahren transparent, verständlich und nachvollziehbar zu machen. Dies wird zurzeit oft durch die Hersteller der KI-Softwares blockiert, da diese nicht vollständig offenlegen, wie die People Anlayticts funktionieren und welche Daten in welcher Weise berücksichtigt werden. Doch auch die Arbeitnehmervertreter ruft die Organisation zum Handeln auf und fordert Betriebsräte auf, sich entsprechende Kompetenzen im Bereich der künstlichen Intelligenz anzueignen. Wie Betriebsräte mit dem Thema umgehen können, haben die Forscher in einem Leitfaden festgehalten.RNDMehr zum Thema Künstliche Intelligenz: Unsere Zukunft oder der drohende Ruin? Künstliche Intelligenz: EU-Kommission stellt neue Digitalstrategie vor Daten-Messies: Künstliche Intelligenz kann beim Löschen helfen",https://schema.org,NewsArticle,,"{'@type': 'NewsMediaOrganization', 'name': 'RedaktionsNetzwerk Deutschland'}",Künstliche Intelligenzen bewerten Mitarbeiter: Ein grenzwertiges Verfahren,"['https://www.rnd.de/resizer/v2/NIRODX2NPJE6VFRQV5JMCE2PJQ.jpeg?auth=f12412f4d6bd7a3bf5b1207aef7ce69d40a2ed9d2ad236ac6adc25e26d9b3579&quality=70&width=1441&height=811&smart=true', 'https://www.rnd.de/resizer/v2/NIRODX2NPJE6VFRQV5JMCE2PJQ.jpeg?auth=f12412f4d6bd7a3bf5b1207aef7ce69d40a2ed9d2ad236ac6adc25e26d9b3579&quality=70&width=1441&height=1081&smart=true', 'https://www.rnd.de/resizer/v2/NIRODX2NPJE6VFRQV5JMCE2PJQ.jpeg?auth=f12412f4d6bd7a3bf5b1207aef7ce69d40a2ed9d2ad236ac6adc25e26d9b3579&quality=70&width=1441&height=1441&smart=true']",2020-03-03T11:41:35+01:00,2022-02-26T09:56:56+01:00,https://www.rnd.de/digital/kunstliche-intelligenzen-bewerten-mitarbeiter-ein-grenzwertiges-verfahren-XPFONFEGHBGHVPABKRQT2YUNSM.html,https://www.rnd.de/digital/kunstliche-intelligenzen-bewerten-mitarbeiter-ein-grenzwertiges-verfahren-XPFONFEGHBGHVPABKRQT2YUNSM.html,,True,"{'@type': 'NewsMediaOrganization', 'name': 'RedaktionsNetzwerk Deutschland', 'logo': {'@type': 'ImageObject', 'url': 'https://www.rnd.de/pf/resources/pwa/rnd/icon-533x533.png?d=608', 'width': '533', 'height': '533'}}",,,,,Digital,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.rnd.de/digital/', 'name': 'Digital'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.rnd.de/digital/kunstliche-intelligenzen-bewerten-mitarbeiter-ein-grenzwertiges-verfahren-XPFONFEGHBGHVPABKRQT2YUNSM.html', 'name': 'Künstliche Intelligenzen bewerten Mitarbeiter: Ein grenzwertiges Verfahren'}}]","{'@type': ['CreativeWork', 'Product'], 'name': 'RedaktionsNetzwerk Deutschland', 'productID': 'rnd.de:showcase'}"
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmRpb2V6ZXNlLWxpbnouYXQvbmV3cy8yMDIwLzAzLzAyL2FzY2hlcm1pdHR3b2Noc2dlc3ByYWVjaC10aGVtYXRpc2llcnRlLWRpZS16dWt1bmZ0LWRlci1hcmJlaXTSAQA?oc=5,Aschermittwochsgespräch thematisierte die Zukunft der Arbeit - Katholische Kirche in Oberösterreich - Diözese Linz,2020-03-02,Katholische Kirche in Oberösterreich - Diözese Linz,https://www.dioezese-linz.at,"""Die Zukunft der Arbeit"" aus dem Blickpunkt von Wirtschaft und Ethik war Thema des Aschermittwochsgesprächs von Sparkasse Oberösterreich und Industriellenvereinigung OÖ in Kooperation mit der KU Linz.",,"""Die Zukunft der Arbeit"" aus dem Blickpunkt von Wirtschaft und Ethik war Thema des Aschermittwochsgesprächs von Sparkasse Oberösterreich und Industriellenvereinigung OÖ in Kooperation mit der KU Linz.",N/A,N/A,N/A,"
Oft nachgefragt 
Jobbörse/Ausschreibungen
Zukunftsweg
Telefonseelsorge 142
Radio-, Fernseh-, und Streaming-Gottesdienste
Kirchenbeitrag
Presse/Medien
 ",,,,,,,,,,,,,,,,,,,,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,mainEntityOfPage,itemListElement,publisher,headline,articleBody,aggregateRating,author,image,datePublished,article:section,article:summary,article text,name,articleSection,dateModified,isAccessibleForFree,url,logo
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vd3d3LmhhdWZlLmRlL3BlcnNvbmFsL2hyLW1hbmFnZW1lbnQva3VlbnN0bGljaGUtaW50ZWxsaWdlbnotZGlza3JpbWluaWVydW5nLWR1cmNoLWFsZ29yaXRobWVuXzgwXzUwMjUwNi5odG1s0gEA?oc=5,Künstliche Intelligenz: Diskriminierung durch Algorithmen | Personal - Haufe - News & Fachwissen,2019-10-24,Haufe - News & Fachwissen,https://www.haufe.de,"Unternehmen setzen verstärkt auf automatisierte Entscheidungen durch algorithmenbasierte Systeme. Das spart Zeit und Geld – birgt jedoch vielfältige Gefahren der Benachteiligung einzelner Menschen und ganzer Bevölkerungsgruppen. Zu diesem Ergebnis kommt eine Studie des Instituts für Technikfolgenabschätzung des KIT, die im Auftrag der Antidiskriminierungsstelle des Bundes durchgeführt wurde.","Künstliche Intelligenz (KI), Diskriminierung, HR-Software",Unternehmen setzen verstärkt auf automatisierte Entscheidungen. Dies birgt jedoch Gefahren der Benachteiligung einzelner Menschen und ganzer Bevölkerungsgruppen. Zu diesem Ergebnis kommt eine neue Studie.,Unternehmen setzen verstärkt auf automatisierte Entscheidungen. Dies birgt jedoch Gefahren der Benachteiligung einzelner Menschen und ganzer Bevölkerungsgruppen. Zu diesem Ergebnis kommt eine ...,http://schema.org,"['WebPage', 'BreadcrumbList', 'Article']","{'@type': 'WebPage', '@id': 'https://www.haufe.de/'}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.haufe.de/personal/', 'name': 'Personal'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.haufe.de/personal/hr-management/', 'name': 'HR-Management'}}]","{'@type': 'Organization', '@id': 'https://www.haufe.de/impressum_24_312.html', 'url': 'https://www.haufe.de/', 'name': 'Haufe', 'legalName': 'Haufe-Lexware GmbH & Co. KG', 'employee': {'@type': 'Person', 'name': 'Andrea Schmitt', 'jobTitle': 'Verantwortliche Online-Redakteurin'}, 'address': {'@type': 'PostalAddress', 'addressLocality': 'Freiburg im Breisgau', 'postalCode': '79111', 'streetAddress': 'Munzinger Str. 9'}, 'contactPoint': {'@type': 'ContactPoint', 'telephone': '+49 800 5050-445', 'contactType': 'Customer Service', 'contactOption': 'toll-free'}, 'parentOrganization': {'@type': 'Organization', 'legalName': 'Haufe Group SE', 'name': 'Haufe Group', 'url': 'https://www.haufegroup.com/de/home'}, 'logo': {'@type': 'ImageObject', 'url': 'https://www.haufe.de/statics/master-16757/images/logo_haufe_structured_data.png', 'width': 188, 'height': 60}, 'publishingPrinciples': {'@type': 'url', '@id': 'https://www.haufe.de/haufe-editorial-code-of-conduct_24_537298.html'}, 'ethicsPolicy': {'@type': 'url', '@id': 'https://resources.haufegroup.com/VerhaltenskodexHaufeGroup.pdf'}, 'correctionsPolicy': 'Korrektur von Fehlern: Die Redakteurinnen und Redakteure arbeiten nach bestem Wissen und Gewissen und sind der Neutralität verpflichtet. Mögliche Fehler werden nachvollziehbar korrigiert, sobald die Redaktion sie selbst entdeckt oder von Leser:innen darauf hingewiesen wird.', 'ownerShipFundingInfo': 'Die Themenportale sind ein redaktionelles Angebot der Haufe-Lexware GmbH & Co. KG, eines Unternehmens der Haufe Group SE (gegründet als Rudolf Haufe Verlag GmbH 1954).', 'foundingDate': '1954-01-01', 'founder': {'@type': 'Person', 'name': 'Rudolf Haufe'}, 'actionableFeedbackPolicy': 'Interaktion mit Leser:innen: Alle Leserinnen und Leser können per E-Mail an info@haufe.de, in der Kommentarfunktion auf den Portalen oder in Social Media mit der Redaktion Kontakt aufnehmen.'}",Algorithmen bergen Diskriminierungsrisiken,"Ob bei der Kreditvergabe, der Auswahl neuer Mitarbeitender oder bei juristischen Entscheidungen – in immer mehr Bereichen werden Algorithmen dazu eingesetzt, menschliche Entscheidungen vorzubereiten oder sie ihnen gleich ganz abzunehmen. „Dass dies zwangsläufig zu objektiveren und damit faireren Entscheidungen führt, erweist sich heute leider oft als Trugschluss“, sagt Carsten Orwat vom Institut für Technikfolgenabschätzung und Systemanalyse (ITAS) des KIT (Karlsruher Institut für Technologie). „Kritisch wird es insbesondere dann, wenn die Algorithmen mit tendenziösen Daten arbeiten und auf eigentlich geschützte Merkmale zurückgreifen.“ Hierzu gehören vor allem Alter, Geschlecht, ethnische Herkunft, Religion, sexuelle Orientierung oder Behinderungen.Welche Ursachen diese Formen der Diskriminierung haben, wie sie sich auf die Gesellschaft auswirken und sich Diskriminierungsrisiken künftig verringern lassen, hat Orwat im Auftrag der Antidiskriminierungsstelle des Bundes eingehend untersucht. Die Studie „Diskriminierungsrisiken durch Verwendung von Algorithmen“ veranschaulicht anhand von 47 Beispielen – darunter auch zahlreiche aus dem HR-Bereich – wie Algorithmen auf unterschiedliche Weise diskriminieren können und wie man dies nachweisen kann.Studie zeigt vielfältige Beispiele für DiskriminierungsrisikenDer Studienautor beschreibt beispielsweise Vorgänge auf dem Immobilien- und Kreditmarkt oder im Strafvollzug. In den USA gebe es mehrere dokumentierte Fälle, in denen die Algorithmen Sozialer Medien Wohnungsanzeigen zugelassen hätten, die durch den ‚Fair Housing Act‘ geschützte Personengruppen nicht zu sehen bekamen – etwa Migranten, Menschen mit Behinderung oder Nicht-Weißer Hautfarbe. In Finnland wurde ein Kreditinstitut zu Strafzahlungen verurteilt, weil sein Algorithmus bei der automatisierten Online-Kreditvergabe Männer gegenüber Frauen und finnische gegenüber schwedischen Muttersprachlern benachteiligte. Beides Ungleichbehandlungen, die nach dem finnischen Antidiskriminierungsrecht verboten sind. Und: US-amerikanische Richter arbeiten bei der Entscheidung über vorzeitige Haftentlassungen mit einem umstrittenen System, das Risikoscores berechnet. Journalisten- und Menschrechtsverbände kritisieren, dass das System das Rückfallrisiko von schwarzen Menschen systematisch zu hoch bewertet.Diskriminierung durch Algorithmen im HR-UmfeldAuch aus dem HR-Umfeld führt der Studienautor zahlreiche Beispiele an. Am bekanntesten dürfte der Fall Amazon sein. Das Unternehmen nutzte seit 2014 ein in der Entwicklung befindliches Softwaresystem zur Suche und Bewer­tung von im Web aufzufindenden Lebensläufen potenzieller Mitarbei­terinnen oder Mitarbeiter. Das maschinelle Lernverfahren wurde an Lebensläufen trainiert, um nach Wortmustern zu suchen, die auf erfolgreiche Mitarbeitende schlie­ßen sollten. Während der Entwicklungszeit habe man bemerkt, dass das Sys­tem nicht geschlechterneutral bewertet. Das System stufte Begriffe mit „women’s“ und Namen von zwei ausschließlich weiblichen (Hoch-)Schulen herab. Als Trainingsdaten wurden Lebensläufe der letzten zehn Jahre verwendet, die hauptsächlich von Männern stammten. Darin spiegelte sich die männliche Mehrheit an Beschäftigten in der Technologiebranche wider. Auch mit Anpassungen des Systems konnte man nicht sicherstellen, dass das System nicht andere Wege entwickelt hätte, mit denen Bewerbende diskriminiert worden wären. Das Entwicklerteam wurde 2017 aufgelöst.Darüber hinaus führt der Studienautor mehrere Beispiele an, bei dem Unternehmen gezielt die Differenzierungsmöglichkeiten von Facebook oder Onlinejobbörsen genutzt haben, um Stellenanzeigen selektiv zu schalten, zum Beispiel um diese nur für Männer oder nur für bestimmte Altersgruppen auszuspielen.Ursachen für Diskriminierung durch Algorithmen„Bei Systemen des maschinellen Lernens wird es häufig problematisch, wenn KI-Systeme mit Daten trainiert werden, die Ungleichbehandlungen oder Stereotypen abbilden“, erklärt Orwat: „Dann spiegeln auch die so erzeugten Algorithmen die Ungleichbehandlungen oder Stereotypen wider."" Wenn Daten verarbeitet werden, die Bewertungen von Menschen über anderer Menschen beinhalten, so könnten sich Ungleichheiten und Diskriminierungen sogar verbreiten oder verstärken, ergänzt Orwat.Diskriminierungsfreie Algorithmen – aber wie?Die Studie nennt mehrere Ansatzmöglichkeiten, um Diskriminierungen bei algorithmenbasierten Differenzierungen zu begegnen. „Am sinnvollsten erscheinen präventive Maßnahmen“, sagt Orwat. So könnten Firmen ihre Personal beziehungsweise IT-Mitarbeiter von Antidiskriminierungsstellen beraten lassen. Diese Angebote könnten auch sensibilisieren, so dass nur solche Datensätze verwendet werden, die keine diskriminierenden Praktiken oder Ungleichheiten widerspiegeln.Das Ziel sei es, so Orwat, dass Algorithmen in Zukunft „diskriminierungsfrei by design“ werden. Dazu müssten Programme bereits während ihrer Entwicklung geprüft werden. Letztlich gehe es dabei immer um den Schutz von gesellschaftlichen Werten wie Gleichheitsziele oder Schutz der freien Entfaltung der Persönlichkeit. Damit diese auch angesichts der rasanten Entwicklungen von „Big Data“ und KI gewährt bleiben, sei es an verschiedenen Stellen nötig, das Antidiskriminierungs- und Datenschutzrecht zu verbessern.Das könnte Sie auch interessieren:Künstliche Intelligenz im PersonalwesenKI-Richtlinien für HR: Ethikbeirat stellt finale Fassung vorPeople Analytics: Wie lässt sich Big Data für HR nutzen?","{'@type': 'aggregateRating', 'ratingValue': '3.67', 'worstRating': '1', 'bestRating': '5', 'ratingCount': '3'}","{'@type': 'Organization', 'name': 'Haufe Online Redaktion'}","[{'@type': 'ImageObject', 'url': 'https://www.haufe.de/image/binaercodes-mit-leuchtenden-farbstrahlen-die-aus-mitte-kommen-451268-1.jpg', 'width': 820, 'height': 551}]",2019-10-24T02:00:00.000+02:00,N/A,N/A,"








                Haufe Online Redak­tion


















                    Bild: mau­ri­tius images / Blend Images / John Lund
                    In algo­rith­men­ba­sierte Systeme können Dis­kri­mi­nie­rungs­ri­siken bereits ein­pro­gram­miert sein.


Unter­nehmen setzen ver­stärkt auf auto­ma­ti­sierte Ent­schei­dungen durch algo­rith­men­ba­sierte Systeme. Das spart Zeit und Geld – birgt jedoch viel­fäl­tige Gefahren der Benach­tei­li­gung ein­zelner Men­schen und ganzer Bevöl­ke­rungs­gruppen. Zu diesem Ergebnis kommt eine Studie des Insti­tuts für Tech­nik­fol­gen­ab­schät­zung des KIT, die im Auftrag der Anti­dis­kri­mi­nie­rungs­stelle des Bundes durch­ge­führt wurde.


















































Ob bei der Kre­dit­ver­gabe, der Auswahl neuer Mit­ar­bei­tender oder bei juris­ti­schen Ent­schei­dungen – in immer mehr Berei­chen werden Algo­rithmen dazu ein­ge­setzt, mensch­liche Ent­schei­dungen vor­zu­be­reiten oder sie ihnen gleich ganz abzu­nehmen. „Dass dies zwangs­läufig zu objek­ti­veren und damit fai­reren Ent­schei­dungen führt, erweist sich heute leider oft als Trug­schluss“, sagt Carsten Orwat vom Institut für Tech­nik­fol­gen­ab­schät­zung und Sys­tem­ana­lyse (ITAS) des KIT (Karls­ruher Institut für Tech­no­logie). „Kri­tisch wird es ins­be­son­dere dann, wenn die Algo­rithmen mit ten­den­ziösen Daten arbeiten und auf eigent­lich geschützte Merk­male zurück­greifen.“ Hierzu gehören vor allem Alter, Geschlecht, eth­ni­sche Her­kunft, Reli­gion, sexu­elle Ori­en­tie­rung oder Behin­de­rungen.Welche Ursa­chen diese Formen der Dis­kri­mi­nie­rung haben, wie sie sich auf die Gesell­schaft aus­wirken und sich Dis­kri­mi­nie­rungs­ri­siken künftig ver­rin­gern lassen, hat Orwat im Auftrag der Anti­dis­kri­mi­nie­rungs­stelle des Bundes ein­ge­hend unter­sucht. Die Studie 

        „Dis­kri­mi­nie­rungs­ri­siken durch Ver­wen­dung von Algo­rithmen“ ver­an­schau­licht anhand von 47 Bei­spielen – dar­unter auch zahl­reiche aus dem HR-Bereich – wie Algo­rithmen auf unter­schied­liche Weise dis­kri­mi­nieren können und wie man dies nach­weisen kann.


Studie zeigt viel­fäl­tige Bei­spiele für Dis­kri­mi­nie­rungs­ri­sikenDer Stu­di­en­autor beschreibt bei­spiels­weise Vor­gänge auf dem Immo­bi­lien- und Kre­dit­markt oder im Straf­vollzug. In den USA gebe es mehrere doku­men­tierte Fälle, in denen die Algo­rithmen Sozialer Medien Woh­nungs­an­zeigen zuge­lassen hätten, die durch den ‚Fair Housing Act‘ geschützte Per­so­nen­gruppen nicht zu sehen bekamen – etwa Migranten, Men­schen mit Behin­de­rung oder Nicht-Weißer Haut­farbe. In Finn­land wurde ein Kre­dit­in­stitut zu Straf­zah­lungen ver­ur­teilt, weil sein Algo­rithmus bei der auto­ma­ti­sierten Online-Kre­dit­ver­gabe Männer gegen­über Frauen und fin­ni­sche gegen­über schwe­di­schen Mut­ter­sprach­lern benach­tei­ligte. Beides Ungleich­be­hand­lungen, die nach dem fin­ni­schen Anti­dis­kri­mi­nie­rungs­recht ver­boten sind. Und: US-ame­ri­ka­ni­sche Richter arbeiten bei der Ent­schei­dung über vor­zei­tige Haft­ent­las­sungen mit einem umstrit­tenen System, das Risi­ko­s­cores berechnet. Jour­na­listen- und Men­sch­rechts­ver­bände kri­ti­sieren, dass das System das Rück­fall­ri­siko von schwarzen Men­schen sys­te­ma­tisch zu hoch bewertet.Dis­kri­mi­nie­rung durch Algo­rithmen im HR-UmfeldAuch aus dem HR-Umfeld führt der Stu­di­en­autor zahl­reiche Bei­spiele an. Am bekann­testen dürfte der Fall Amazon sein. Das Unter­nehmen nutzte seit 2014 ein in der Ent­wick­lung befind­li­ches Soft­ware­system zur Suche und Bewer­tung von im Web auf­zu­fin­denden Lebens­läufen poten­zi­eller Mitarbei­terinnen oder Mit­ar­beiter. Das maschi­nelle Lern­ver­fahren wurde an Lebens­läufen trai­niert, um nach Wort­mus­tern zu suchen, die auf erfolg­reiche Mit­ar­bei­tende schlie­ßen sollten. Während der Ent­wick­lungs­zeit habe man bemerkt, dass das Sys­tem nicht geschlech­ter­neu­tral bewertet. Das System stufte Begriffe mit „women’s“ und Namen von zwei aus­schlie­ß­lich weib­li­chen (Hoch-)Schulen herab. Als Trai­nings­daten wurden Lebens­läufe der letzten zehn Jahre ver­wendet, die haupt­säch­lich von Männern stammten. Darin spie­gelte sich die männ­liche Mehr­heit an Beschäf­tigten in der Tech­no­lo­gie­branche wider. Auch mit Anpas­sungen des Systems konnte man nicht sicher­stellen, dass das System nicht andere Wege ent­wi­ckelt hätte, mit denen Bewer­bende dis­kri­mi­niert worden wären. Das Ent­wick­ler­team wurde 2017 auf­ge­löst.Darüber hinaus führt der Stu­di­en­autor mehrere Bei­spiele an, bei dem Unter­nehmen gezielt die Dif­fe­ren­zie­rungs­mög­lich­keiten von Face­book oder Online­job­börsen genutzt haben, um Stel­len­an­zeigen selektiv zu schalten, zum Bei­spiel um diese nur für Männer oder nur für bestimmte Alters­gruppen aus­zu­spielen.Ursa­chen für Dis­kri­mi­nie­rung durch Algo­rithmen„Bei Sys­temen des maschi­nellen Lernens wird es häufig pro­ble­ma­tisch, wenn KI-Systeme mit Daten trai­niert werden, die Ungleich­be­hand­lungen oder Ste­reo­typen abbilden“, erklärt Orwat: „Dann spie­geln auch die so erzeugten Algo­rithmen die Ungleich­be­hand­lungen oder Ste­reo­typen wider."" Wenn Daten ver­ar­beitet werden, die Bewer­tungen von Men­schen über anderer Men­schen beinhalten, so könnten sich Ungleich­heiten und Dis­kri­mi­nie­rungen sogar ver­breiten oder ver­stärken, ergänzt Orwat.Dis­kri­mi­nie­rungs­freie Algo­rithmen – aber wie?Die Studie nennt mehrere Ansatz­mög­lich­keiten, um Dis­kri­mi­nie­rungen bei algo­rith­men­ba­sierten Dif­fe­ren­zie­rungen zu begegnen. „Am sinn­vollsten erscheinen prä­ven­tive Maß­nahmen“, sagt Orwat. So könnten Firmen ihre Per­sonal bezie­hungs­weise IT-Mit­ar­beiter von Anti­dis­kri­mi­nie­rungs­stellen beraten lassen. Diese Ange­bote könnten auch sen­si­bi­li­sieren, so dass nur solche Daten­sätze ver­wendet werden, die keine dis­kri­mi­nie­renden Prak­tiken oder Ungleich­heiten wider­spie­geln.Das Ziel sei es, so Orwat, dass Algo­rithmen in Zukunft „dis­kri­mi­nie­rungs­frei by design“ werden. Dazu müssten Pro­gramme bereits während ihrer Ent­wick­lung geprüft werden. Letzt­lich gehe es dabei immer um den Schutz von gesell­schaft­li­chen Werten wie Gleich­heits­ziele oder Schutz der freien Ent­fal­tung der Per­sön­lich­keit. Damit diese auch ange­sichts der rasanten Ent­wick­lungen von „Big Data“ und KI gewährt bleiben, sei es an ver­schie­denen Stellen nötig, das Anti­dis­kri­mi­nie­rungs- und Daten­schutz­recht zu ver­bes­sern.Das könnte Sie auch inter­es­sieren:Künst­liche Intel­li­genz im Per­so­nal­wesenKI-Richt­li­nien für HR: Ethik­beirat stellt finale Fassung vorPeople Ana­ly­tics: Wie lässt sich Big Data für HR nutzen?
        Schlag­worte zum Thema: 
        Künst­liche Intel­li­genz (KI), Dis­kri­mi­nie­rung, HR-Soft­ware





Pro­dukt­emp­feh­lung















ZUM SHOP



Weitere Pro­dukte zum Thema:

           





                Meist­ge­le­sene bei­träge



    Worka­tion und Home­of­fice im Ausland: Was Arbeit­geber beachten müssen



3.720





    Pro­be­zeit­ge­spräche als Feed­back­quelle für den Onboar­ding-Prozess 



1.927





    Krank­schrei­bung per Telefon nun dau­er­haft möglich



1.628





    Vorlage: Leit­faden für das Mit­ar­bei­ter­ge­spräch



1.545





    Ablauf und Struktur des betrieb­li­chen Ein­glie­de­rungs­ma­nage­ments 



1.356





    Essens­zu­schuss als steu­er­freier Benefit



1.252





    BEM ist Pflicht des Arbeit­ge­bers



1.226





    Check­liste: Das sollten Sie bei der Vor­be­rei­tung eines Mit­ar­bei­ter­ge­sprächs beachten



853





    Pflicht zur psy­chi­schen Gefähr­dungs­be­ur­tei­lung



668





    Deutsch­lands beste Job­por­tale 2022 stehen fest



577







                Neueste bei­träge



                            Wie infor­melle Führung gelingen kann


10.07.2024





                            Wie HR dem Rechts­po­pu­lismus ent­ge­gen­treten kann


09.07.2024





                            Trend­radar: DGFP strebt pro­gram­ma­ti­sches Update an


08.07.2024





                            Arbeits­zeit­er­fas­sung kann Pro­duk­ti­vität stei­gern


04.07.2024





                            Warum die geplante Fami­li­en­start­zeit nicht weit genug geht


04.07.2024





                            JobRad: Wie KMU von dem beliebten Benefit pro­fi­tieren


03.07.2024





                            Bogen­schießen als Coa­ching­me­thode


03.07.2024





                            Für viele Unter­nehmen ist Kultur wich­tiger als KI


02.07.2024





                            Jeder/Jede Zweite wünscht sich mehr Wei­ter­bil­dung


01.07.2024





                            Wie die Topregal GmbH ihr Onboar­ding neu auf­ge­stellt hat


28.06.2024





",,,,,,
https://news.google.com/rss/articles/CBMiPWh0dHBzOi8vaGFtYnVyZy1idXNpbmVzcy5jb20vZGUvbmV3cy9kYXJ2aXMtbWl0LWthbWVyYS11bmQta2nSAQA?oc=5,Darvis: Mit Kamera und KI | News | Hamburg Business - Hamburg Invest,2019-10-22,Hamburg Invest,https://hamburg-business.com,In USA gegründetes Startup will nun auch in Hamburg für sichere und optimierte Räume sorgen. Hamburg News hat Darvis im HIP besucht,N/A,N/A,N/A,http://schema.org/,NewsArticle,https://hamburg-business.com/de/news/darvis-mit-kamera-und-ki,"[{'@type': 'ListItem', 'position': 1, 'name': 'Das Portal für die Wirtschaft', 'item': 'https://hamburg-business.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'News', 'item': 'https://hamburg-business.com/de/news'}, {'@type': 'ListItem', 'position': 3, 'name': 'Darvis: Mit Kamera und KI', 'item': 'https://hamburg-business.com/de/news/darvis-mit-kamera-und-ki'}]","{'type': 'Organization', '@id': 'Hamburg News', 'name': 'Hamburg News', 'url': 'https://hamburg-business.com/', 'sameAs': ['https://www.facebook.com/HHBusinessnews/', 'https://twitter.com/HH_BusinessNews', 'https://www.xing.com/communities/groups/hamburg-news-wirtschaftsnachrichten-aus-der-metropolregion-hamburg-1009342'], 'logo': {'@type': 'ImageObject', 'url': 'https://hamburg-business.com/_Resources/Static/Packages/Teha.Site/Build/svg/logo/default.b5159f2f.svg'}}",Darvis: Mit Kamera und KI,,,,"['https://hamburg-business.com/_Resources/Persistent/b/6/5/c/b65ca4cd07f33d10f3b5a92c6ff9fc37c11aca53/darvis_jan_schlueter_jan-philipp_mohr.jpg.thumb_-92c3cb73ca5361ac3f4cc03cd77cc783-950x534.jpg', 'https://hamburg-business.com/_Resources/Persistent/b/a/c/8/bac808407bb25d97e62678c1063c2620d6a0502c/darvis_jan_schlueter_jan-philipp_mohr.jpg.thumb_-92c3cb73ca5361ac3f4cc03cd77cc783-733x550.jpg', 'https://hamburg-business.com/_Resources/Persistent/d/b/b/a/dbba86b02f79db46b74dc74f66efdee7e4028462/darvis_jan_schlueter_jan-philipp_mohr.jpg.thumb_-92c3cb73ca5361ac3f4cc03cd77cc783-550x550.jpg']",2019-10-22T05:56:22+02:00,N/A,N/A,"StartupsDarvis: Mit Kamera und KI22. Oktober 2019In USA gegründetes Startup will nun auch in Hamburg für sichere und optimierte Räume sorgen. Hamburg News hat Darvis im HIP besucht„Wenn diese Räume reden könnten“, seufzte schon so mancher Filmkommissar – und wahrscheinlich auch zahlreiche reale Kollegen. ´Warum eigentlich nicht?`, fanden die Gründer von Darvis und entwickelten das Konzept der sicheren und optimierten Räume. Kameras und optische Sensorenliefern nutzerrelevante Informationen, die in Echtzeit mit künstlicher Intelligenz analysiert werden. Ziel ist die Optimierung von Räumen, Flächen, Plätzen oder Gebäuden hinsichtlich von Sicherheit, Hygiene oder prozessualer Abläufe. 
Gefahrenpotentiale identifizierenAktuell liegt der Fokus von Darvis zwar nicht in erster Linie auf der Verbrechensbekämpfung, doch das 2015 in San Francisco gegründete Unternehmen hat bereits ein Programm für US-Schulen entwickelt, das darauf ausgerichtet ist, frühzeitig Gefahrenpotentiale zu identifizieren. Erkennt das System etwa eine Waffe, werden umgehend die Behörden informiert, während die Zielperson optisch verfolgt wird, um der eintreffenden Polizei den exakten Standort angeben zu können. Und anhand des vom System erkannten Bewegungsmusters – hier kommt künstliche Intelligenz zum Einsatz – bleibt die Software der richtigen Person auf der Spur, auch wenn diese versucht, ihre äußere Erscheinung zu verändern. Ein klarer Vorteil gegenüber Zeugenaussagen á la: Er hatte blonde Haare und trug eine dunkle Jacke…
Datenschutz dank Avatarisierung Details, wie blonde Haare, übermitteln Darvis-Programme jedoch nur in Ausnahmesituationen. „Wir arbeiten mit optisch generierten Informationen, die umgehend anonymisiert werden – mittels Avatarisierung. Unser Programm verarbeitet die Informationen zu Figuren in einem Computerspiel“, erklärt Jan Schlüter (COO), der zusammen mit Jan-Philipp Mohr (CEO) und Ingo Nadler (CTO) Darvis gegründet hat. Zum einen gehe es darum, das System so non-intrusive wie möglich zu gestalten, um Mitarbeiter-Befürchtungen vorzubeugen, sie würden überwacht. „Zum anderen arbeiten wir streng nach den Maßgaben der Datenschutzgrundverordnung. Das ist sogar unser Kern-USP“, ergänzt Mohr. 
Von San Francisco nach Hamburg Mehr als 30 Mitarbeiter arbeiten bereits weltweit für Darvis, etwa in San Francisco, Boston – und seit dem 1. Oktober auch in Hamburg im Health Innovation Port (HIP) auf dem Philips-Campus. „Das Gründen war vor fünf Jahren in den USA schlicht einfacher“, erklärt Schlüter, gebürtiger Hamburger und erklärter Lokalpatriot. „Doch inzwischen haben sich die Strukturen hier deutlich verbessert, das HIPist ein gutes Beispiel“. Von dem Netzwerk des auf die Gesundheitsbranche ausgerichteten Collaboration Space erhoffen sich die Gründer wertvolle Kontakte etwa ins UKE oder andere Hamburger Krankenhäuser. Denn im Klinikumfeld bieten sich vielfältige Einsatzmöglichkeiten für die Darvis-Programme. Hamburg Invest stand schon seit längerem mit dem Unternehmen im Austausch stellte nützliche Kontakte zu Akteuren in Hamburg her. Außerdem vernetzte die Hamburg Invest die Gründer mit dem Northern Germany Innovation Office (NGIO) im Silicon Valley. 
System überprüft eigenständig Hygiene-StatusMohr nennt die Optimierung von Hygiene- oder Logistikketten in Krankenhäusern als Beispiel. „Nehmen Sie verstopfte Krankenhausflure durch benutzte Betten, die vom Pflegepersonal zur Abholung in den Gang geschoben werden.“ Im eng getakteten Krankenhausalltag fehle jedoch oft die Zeit für den Anruf, der die Abholung veranlasst. „Das Darvis-System unterscheidet zwischen sauberen, belegten und benutzten Betten und überprüft deren Status.“ Sind alle notwendigen Kriterien erfüllt, kann die Abholung eines benutzten und zur Reinigung freigegebenen Bettes eingeleitet werden. Das Hygiene-Monitoring funktioniert ganz ähnlich: Das System kontrolliert einen Raum auf Sauberkeit und gibt den Raum frei – oder nicht. „Das ist nicht nur entscheidend im Vorfeld einer Operation, sondern macht aus dem Raum auch einen sicheren Arbeitsplatz für Ärzte und Pflegepersonal“, betont Schlüter. 
Wahr gewordene Science-FictionGerade in der Optimierung der Sicherheit in Krankenhäusern, aber auch bei Unternehmen anderer Branchen, sehen die Gründer großes Potential. Zum Beispiel zugangsbeschränkte Bereiche. Statt Zugangscode oder Chipkarte reiche ein Blick in die Kamera. Die etablierte Gesichtserkennung erlaubt nur tatsächlich Zugangsberechtigten den Eintritt. Wer dabei an Science-Fiction denkt, liegt nicht ganz falsch. Tatsächlich ist der Unternehmensname an „Jarvis“ angelehnt, der künstlichen Intelligenz aus den Avenger-Filmen. Darvis steht für ´Data Analytics Real-world Visual Intelligence System` und konnte in der realen Welt mit seiner Unternehmensidee in einer ersten Finanzierungsrunde 2,2 Millionen Dollar einsammeln. „Wir sind fremdkapitalfinanziert“, erklärt Schlüter. Das Geld stamme aus einer Mischung aus Angel Investoren und Venture-Capitalists sowie Investoren aus dem Hamburger Familien- und Freundesumfeld. „Aktuell sind wir mitten in unserer zweiten Finanzierungsrunde.“ Ziel: Fünf Millionen Dollar. ys/ks/kk
Quellen und weitere Informationen


www.darvis.comMehr zum ThemaDigitalisierungÄhnliche Artikel© Mathias Jäger_hhstartupsGutes Zeugnis für Hamburger Startup-SzeneStartup-Monitor: Hamburger Gründer wollen im Schnitt zehn neue Mitarbeitende einstellen und Umsätze verdreifachen. Lebhafte Standort-Debatte© mediaserver.de/Timo Sommer und Lee MaasNeue Startup-Unit: Diese Gründer-Trends werden künftig wichtigSeit 100 Tagen leitet sie die neue Startup-Unit bei Hamburg Invest. Mit den Hamburg News sprach Veronika Reichboth über Trends und die Gründerstadt Hamburg © InnoGamesNeue Gründerdatenbank von Hamburg Startups Monitor und who-is-who der Gründerszene. Wer gründet was und wo in Hamburg?© TVNow/Bernd-Michael MaurerDHDL 2019: Diese Startups wagten sich in die Höhle der LöwenFünf mutige Jungunternehmer aus Hamburg stellten sich den hungrigen Investoren. Neue Folgen bereits im Frühjahr 2020",Darvis: Mit Kamera und KI,Startups,2024-02-24T14:57:54+01:00,True,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vd3d3LnByb2ZpbC5hdC9rdWx0dXIva3VlbnN0bGljaGUtaW50ZWxsaWdlbnotdmllbm5hbGUtYmV0cmllYi0xMTE5MDY4MdIBAA?oc=5,Künstliche Intelligenz: Die Viennale 2019 nimmt Betrieb auf - profil.at,2019-10-25,profil.at,https://www.profil.at,"
Wiens internationales Filmfestival nimmt diese Woche wieder seinen Betrieb auf. Der Vertrag mit Viennale-Chefin Eva Sangiorgi war schon im Vorfeld bis 2026 verlängert worden. Wollte man sie möglichst schnell an Wien binden?  ","
Ausgabe 4319 191019  ,AI,Agnès Varda,Angela Schanelec,Anthony Perkins,Céline Sciamma,Filmfestival,Hans Hurch,Intelligenz,Jessica Hausner,Kino,Los Angeles,Louise Kolm-Fleck,Lucrecia Martel,Mexico City,Norman Bates,Sabine Derflinger,Viennale,Wien,Zama","<br />
Wiens internationales Filmfestival nimmt diese Woche wieder seinen Betrieb auf. Der Vertrag mit Viennale-Chefin Eva Sangiorgi war schon im Vorfeld bis 2026 verlängert worden. Wollte man sie möglichst schnell an Wien binden?  ",N/A,https://schema.org,NewsArticle,https://www.profil.at/kultur/kuenstliche-intelligenz-viennale-betrieb-11190681,,"{'@type': 'Organization', 'name': 'profil.at', 'url': 'https://www.profil.at/', 'logo': {'@type': 'ImageObject', 'url': 'https://www.profil.at/assets/img/logo.105a6409d9636c824d23.png', 'width': 105, 'height': 48}}","
Künstliche Intelligenz: Die Viennale 2019 nimmt Betrieb auf  ",,,"[{'@type': 'Person', 'name': 'Stefan   Grissemann', 'url': 'https://www.profil.at/author/stefan.grissemann'}]","['https://image.profil.at/images/cfs_landscape_1232w_693h/4357319/11190858.jpg', 'https://image.profil.at/images/cfs_square_1232/4357319/11190858.jpg']",2019-10-25T13:32:00+00:00,Kultur,N/A,"















© 
Viennale  
Szenenbild aus Olivia Wildes „Booksmart“

Szenenbild aus Olivia Wildes „Booksmart“  









© 
Viennale  
Szenenbild aus Olivia Wildes „Booksmart“

Szenenbild aus Olivia Wildes „Booksmart“  








            Kultur
    



Künstliche Intelligenz: Die Viennale 2019 nimmt Betrieb auf  




		
Wiens internationales Filmfestival nimmt diese Woche wieder seinen Betrieb auf. Der Vertrag mit Viennale-Chefin Eva Sangiorgi war schon im Vorfeld bis 2026 verlängert worden. Wollte man sie möglichst schnell an Wien binden?  
	




				


                  

            Von                                      Stefan Grissemann


25.10.19


































Drucken













Schriftgröße













Starr sitzt der junge Mann im Bild, ein irrlichterndes Auge weit aufgerissen. Der Rest seines Gesichts ist verpixelt, seine Mimik nur erahnbar. Die Befragung eines katatonisch-schizophrenen Psychiatriepatienten in Los Angeles 1961 steht im Zentrum des gespenstischen Trailers, der die Viennale 2019 ankündigt; er wurde von der argentinischen Filmkünstlerin Lucrecia Martel („La ciénaga“, „Zama“) gestaltet. Die Grenzen zwischen Dokument und Fiktion werden darin auf irritierende Weise niedergerissen: Wie eine abgründige Performance mutet der Auftritt des anonymen Patienten an, der wie Anthony Perkins als schwer persönlichkeitsgestörter Norman Bates in Hitchcocks „Psycho“ (1960) in zwei Stimmen mit sich selbst zu sprechen scheint. Martels Viennale-Clip heißt „AI“, und das ist wörtlich zu nehmen: Das Kino ist – als synthetische Kunstform, die sowohl das analytische Denken als auch wilde Wachträume mobilisieren kann – eine künstliche Intelligenz. Sie spricht nicht nur zu uns, sondern auch, vielleicht vor allem, mit sich selbst.


Stimmen Sie einer Datenverarbeitung von Youtube zu, um diesen Inhalt anzuzeigen.Youtube akzeptieren


Eva Sangiorgi, 41, hat diesen Trailer in Auftrag gegeben – und er passt perfekt zum diesjährigen Programm. Die gebürtige Italienerin, die zuvor das renommierte Ficunam-Festival in Mexico City geleitet hat, war im Jänner 2018, nach einer viel zu späten Ausschreibung als Nachfolgerin des überraschend verstorbenen Hans Hurch zur Viennale-Direktorin designiert worden. Der Zeitdruck war enorm: Bis März musste Sangiorgi noch ihr eigenes Festival abwickeln, ehe sie im April letzten Jahres nach Wien ziehen und in wenigen Monaten ihre eigene Version der Viennale ins Leben rufen konnte. Zu ihren allerersten Reformideen gehörte der Wunsch, die alte Trennung zwischen Spiel- und Dokumentarfilmen aufzuheben. 


Von Jessica Hausners botanischer Science-Fiction-Fantasie „Little Joe“ über die Retrospektiven der Arbeiten Angela Schanelecs und der Austro-Kinopionierin Louise Kolm-Fleck bis hin zu Agnès Vardas Abschiedsfilm und Sabine Derflingers Politdoku „Die Dohnal“: Die starke weibliche Präsenz ist heuer unübersehbar. Man könnte dies als Reaktion auf die da und dort laut gewordene Kritik lesen, die letztes Jahr an den fast durchgängig männlich besetzten Nebenreihen geübt wurde. „Reaktion würde ich es nicht nennen“, sagt Sangiorgi, „aber es stellte mich selbst nicht zufrieden. Ich suchte also noch intensiver nach starken Regisseurinnen. Trotz dieses Bewusstseins lässt sich ein Geschlechtergleichgewicht schwer herstellen –  weil es zwar sehr viele gute, aber leider bei Weitem nicht genügend Filme von Frauen gibt.“


Mit Céline Sciammas „Porträt einer jungen Frau in Flammen“, dem klinischen Liebesdrama einer Malerin und ihres Modells, den Eröffnungsabend im Gartenbaukino am Donnerstag dieser Woche zu bestreiten, ist jedenfalls mutig. Denn dieser Gala werden, wie stets, auch der Cinephilie in der Regel ferne Sponsorengäste, Kultur- und Polit-Adabeis beiwohnen: Ob sie viel Freude an Sciammas raffinierten kunstgeschichtlichen Exkursen haben werden, bleibt abzuwarten. 


""Weniger Filme""








Das überbordende, viele auch überfordernde Festivalangebot ein wenig zu reduzieren, war Sangiorgi wichtig: „Es sind weniger Filme, ja, und wir haben die Viennale auch um einen Tag verkürzt.“ Darin liegt allerdings auch das Risiko herabgesetzter Kinobesuchszahlen. Ein gewisser Druck sei zu spüren, „denn da geht es natürlich um Einnahmen, um die Balance von Subvention und Eigenleistung. Aber es ist eine Herausforderung, neues Publikum zu gewinnen; wir werden heuer vermehrt Schulen und – auch ausländische – Universitäten einbinden, denn was soll aus der Kollektiverfahrung des Kinos werden, wenn keine jungen Filmbegeisterten mehr nachrücken?“


Stimmen Sie einer Datenverarbeitung von Youtube zu, um diesen Inhalt anzuzeigen.Youtube akzeptieren


Die Viennale operiert mit einem Budget von knapp drei Millionen Euro – ein bisschen weniger als im Vorjahr, da sich die Sponsorenleistung leicht verringert hat. Um politische Schärfe ist Eva Sangiorgi bemüht: Sie trage als Leiterin einer kulturellen Veranstaltung „selbstverständlich die Verantwortung, über das Ästhetische der Filme hinaus auch das Ethische zu sehen“. Filmproduktionen und -festivals seien bekanntlich alles andere als ökologisch wertvoll. „Ideell aber ist das Kino ein großartiges soziales Instrument, hier treffen Menschen aus aller Welt zusammen, und die Viennale ist auch eine Agora, in der sich alle Beteiligten nicht nur an der Schönheit des Gezeigten erfreuen, sondern sich zum Denken und Debattieren anregen lassen. Die Filme dieses Festivals sind keine isolierten Ereignisse mehr, sie sprechen zueinander, entwickeln Energien und Spiegelungen.“ Sie bleibt dabei, auch wenn man sie konkreter fragt: Als Statement gegen die politische Stagnation und den dominanten Rechtspopulismus in Österreich sehe sie ihr Festival „natürlich“: als Widerrede „gegen menschenfeindliche Politik, in Österreich, Europa und in vielen Teilen des Rests der Welt“. 








Vertragsverlängerung mit Sangiorgi


In Eva Sangiorgi hat man eine sympathische und cinephile Persönlichkeit für die Viennale gefunden, zudem eine erstklassige Kommunikatorin. Aber sie ist ehrgeizig und international umworben. Überraschend schnell kam, vielleicht auch deshalb, vor wenigen Wochen die Nachricht von der Verlängerung des (ursprünglich auf drei Jahre befristeten) Vertrags Sangiorgis um fünf weitere Jahre, bis März 2026, er gilt nun also für die kommenden sieben Festivals. Gab es alternative Jobangebote, die sie vielleicht – zur schnelleren Entscheidung – in den Verhandlungsverlauf einbringen konnte? Über das renommierte und deutlich größere Festival in Rotterdam etwa wird im Dezember entschieden. „Nein“, winkt Sangiorgi ab, „ich habe kein wirklich spannendes alternatives Angebot erhalten, schon gar nicht aus Rotterdam. Ich wollte einfach eine Perspektive mit diesem Festival haben, über die festgelegten drei Jahre meines ursprünglichen Vertrags hinaus. Ich bin glücklich und stolz, für die Viennale zu arbeiten – und ehrlich gesagt mag ich die deutsche Sprache auch viel lieber als das Niederländische.“  


Wiens Kulturstadträtin Veronica Kaup-Hasler betont im Gespräch mit profil, dass Sangiorgis langfristige Bindung ein „eigentlich banaler Vorgang gewesen“ sei; das Kuratorium der Viennale habe sie schlicht gebeten, der Verlängerung zuzustimmen. Von einem etwaigen Druck durch die mögliche Abwerbung der gefragten Viennale-Chefin habe sie jedenfalls nichts gehört. Im Vorstand des weiterhin nicht als GmbH geführten, also völlig autonom agierenden Vereins sitzen Franz Schwartz, der nach Hans Hurchs Tod im Juli 2017 das Festival ein Jahr lang interimistisch leitete, die Kulturmanagerin Ingrid Kapsch, die Journalistin Gabriele Flossmann und ihr Kollege Armin Thurnher. 


Das vom Boulevard („oe24“) unlängst lancierte Gerücht, demzufolge Bürgermeister Michael Ludwig vorhabe, die Wiener SPÖ „personell neu aufzustellen“ und daher die beiden Stadträtinnen Ulli Sima (zuständig für Umwelt) sowie Veronica Kaup-Hasler (Kultur) „auszutauschen“ plane, hält Letztere übrigens für eine „klassische Zeitungsente“. Ihr Einvernehmen mit dem Bürgermeister sei „hervorragend“ – und: „Es gäbe keinen Grund, an seinem Rückhalt zu zweifeln.“ 













Newsletter


Stimmen Sie einer Datenverarbeitung von ActiveCampaign zu, um diesen Inhalt anzuzeigen.ActiveCampaign akzeptieren



































Drucken



                (profil.at)
                                            









 Stefan   Grissemann  


leitet seit 2002 das Kulturressort des profil. Freut sich über befremdliche Kunst, anstrengende Musik und waghalsige Filme. 



                              Mehr von Stefan   Grissemann  
                                  














Stimmen Sie einer Datenverarbeitung von Outbrain UK Ltd zu, um diesen Inhalt anzuzeigen.Outbrain UK Ltd akzeptieren


",,,2020-05-29T08:49:01+00:00,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vaW52ZXN0cmVuZHMuY2gvYWt0dWVsbC9uZXdzL2Z1dHVyZS0yMDI0LXp3ZWktbWVnYXRyZW5kcy1nZXN0YWx0ZW4tZGllLWludmVzdG1lbnR3ZWx0LW5ldS_SAQA?oc=5,"""Future 2024"": Zwei Megatrends gestalten die Investmentwelt neu | News | Aktuell - investrends.ch",2019-10-25,investrends.ch,https://investrends.ch,"Künstliche Intelligenz ist in der Lage, technologisch jede Industrie umzuwälzen. Ein anderer Megatrend erwächst durch den Klimawandel. BNY Mellon Investment Management zeigt in der Studie 'Future 2024' auf, wie diese Megatrends auch die Investmentwelt verändern.",N/A,"Künstliche Intelligenz ist in der Lage, technologisch jede Industrie umzuwälzen. Ein anderer Megatrend erwächst durch den Klimawandel. BNY Mellon Investment Management zeigt...","Künstliche Intelligenz ist in der Lage, technologisch jede Industrie umzuwälzen. Ein anderer Megatrend erwächst durch den Klimawandel. BNY Mellon Investment Management zeigt...",https://schema.org,Article,"{'@type': 'WebPage', '@id': 'https://investrends.ch/aktuell/news/future-2024-zwei-megatrends-gestalten-die-investmentwelt-neu/'}",,"{'@type': 'Organization', 'name': 'investrends.ch', 'url': 'https://investrends.ch', 'logo': {'@type': 'ImageObject', 'url': 'https://investrends.ch/site/templates/__img/logo_investrends.png'}}",'Future 2024': Zwei Megatrends gestalten die Investmentwelt neu,"Künstliche Intelligenz (KI) und Klimawandel, die zwei 'Supertanker-Trends', wie sie in der Studie 'Future 2024' genannt werden, sind in der Lage, die Finanzmärkte zu transformieren. KI hat demnach das Potenzial, alle Aspekte unseres Lebens neu zu definieren: So etwa die Kommunikation, die sozialen Prozesse, die Mobilität und die Arbeit. KI wird automatisierte Prozesse vernetzen und traditionelle Branchengrenzen aufheben. Ähnlich umfassend werden auch die Auswirkungen des Klimawandels auf die globale Gesellschaft sein: Als Reaktion darauf sehen immer mehr Menschen und Organisationen auf der ganzen Welt die Notwendigkeit, ihre CO2-Bilanz zu verbessern und weitere Massnahmen zu treffen, die die Erderwärmung stoppen können. Wie sollen Investoren auf diese Megatrends reagieren?  Wie Matt Oomen, Global Head of Distribution, BNY Mellon Investment Management, feststellt, erleben wir bereits jetzt einen Wandel in der Funktionsweise der Märkte als Reaktion auf den Klimawandel und KI. Die Vermögensverwaltung stehe inmitten einer tiefgreifenden Entwicklung – nicht nur in der Art und Weise, wie sie ihr Geschäft betreibe, sondern auch wie sie sich definiere und über ihre eigene Rolle in der Welt nachdenke. Oomen: 'Während sich dieser Paradigmenwechsel durch unsere Branche zieht, glaube ich, dass diese beiden 'Supertanker'-Trends die entscheidende Herausforderung nicht nur für die aktuelle Generation der Vermögensverwalter, sondern auch für die kommenden Generationen sein werden.'  Für die von Create-Research im Auftrag von BNY Mellon Investment Management durchgeführte Studie wurden 45 CIOs, Anlagestrategen sowie Portfolio Manager und Vermögensverwalter in 16 Ländern interviewt. Sie wurden gefragt, wie sie künstliche Intelligenz und Klimawandel im Hinblick auf ihre zukünftigen Chancen und Risiken wahrnehmen, welche spezifischen Anlagethemen sich daraus ergeben, wie sich dabei die Ansätze der Asset Allocation verändern und wie die Vermögensverwaltungsbranche im Zeitalter dieser Megatrends neu gestaltet wird.  Künstliche Intelligenz: Herausforderungen für Investoren  KI wird allgemein als Grundlage für die vierte industrielle Revolution (Industrie 4.0) gefeiert. Als allumfassende Technologie ist sie in der Lage, fast jede Aktivität in der Wertschöpfungskette aller Branchen einer modernen Wirtschaft zu durchdringen. Das Elektroauto, das autonom fahren kann, ist eines der sichtbarsten Produkte, das aber erst am Anfang seiner technologischen Entwicklung steht. Ein weiterer Bereich ist das Aufkommen superschneller 5G-Wireless-Netzwerke, die über die Mobilität hinaus Anwendungen für bahnbrechende Dienstleistungen wie etwa die Fernchirurgie ermöglichen, bei der Roboter präzise und latenzfrei Fernanweisungen ausführen.  Trotz dieser und anderer beeindruckender Fortschritte äusserten die Interviewteilnehmer der Studie auch Bedenken: 52% sahen KI als 'Risiko und Chance', 33% nur als 'Risiko'. Diejenigen, die KI nur als 'Risiko' wahrnehmen, zeigten sich besorgt über die gesellschaftlichen Auswirkungen, insbesondere auf die Arbeitsplätze. Beide Gruppen waren sich jedoch in zwei Punkten einig: Es ist nur eine Frage der Zeit, bis KI unser Leben mitbestimmen wird.  So oder so, KI führt zu vier investitionsspezifischen Herausforderungen: Erstens werden die Lebenszyklen von Unternehmen immer kürzer, denn KI schafft Gewinner und Verlierer. Zweitens werden die sektoralen Grenzen verschwimmen, da die KI ein ganzes Produkt neu konfiguriert, wie etwa das Beispiel Tesla zeigt, das von der Batterie-Technologie über die Elektromobilität bis hin zum autonomen Fahren – wo wiederum 5G-Netzwerke gefragt sind – mehrere Technologie- und Industriesektoren umfasst. Drittens wird das Onshoring der Fertigungsaktivitäten die Zukunftsaussichten der Schwellenländer beeinträchtigen, hier ist der 3D-Druck ein Stichwort. Und schliesslich wird KI den immateriellen Wert von Unternehmen auf eine Weise steigern, die schwer zu messen ist, wie das Beispiel Apple zeigt, dessen immaterieller Wert in letzter Zeit weit über seine Finanzkraft hinausgestiegen ist.  Anlagespezifische Implikationen des Klimawandels  Unternehmen sind durch die globale Erwärmung existenziellen Bedrohungen ausgesetzt. Sie sind allgegenwärtig und betreffen das physische, soziale, geopolitische, technologische und wirtschaftliche Gefüge des Planeten. Aus Investorensicht sehen 57% der Interviewteilnehmer den Klimawandel als 'Risiko und Chance', während 36% ihn nur als 'Risiko' ansehen.  Alle Befragten sind sich einig, dass ESG (Umwelt, Soziales, Governance)-Investitionen zwar einfach erscheinen, aber nicht einfach sind. So fehlen derzeit Vorlagen mit konsistenten Definitionen und zuverlässigen Datensätzen, die eine robuste statistische Modellierung von Anlageportfolios ermöglichen. Hervorgehoben wird von den Investoren auch die Herausforderung, einen direkten Zusammenhang zwischen Klimawandel und Anlageerträgen herzustellen. Schliesslich betonen sie, dass die Technologien der erneuerbaren Energien weltweit noch nicht weit genug fortgeschritten seien, um die Abhängigkeit von fossilen Brennstoffen bis weit in das nächste Jahrzehnt hinein stark zu verringern. Darüber hinaus ist die Preisgestaltung für CO2-Emissionen, die im Rahmen des Pariser Abkommens vorgesehen ist, alles andere als klar.  Schwierig einzuschätzen für Investoren sind auch sogenannte gestrandete Vermögenswerte, die mit der Transformation durch den Klimawandel einhergehen – zum Beispiel Kohle und Öl, die im Boden zurückgelassen werden oder Küstenimmobilien, die einem steigenden Meeresspiegel ausgesetzt sind. Sie könnten vor ihrer erwarteten wirtschaftlichen Lebensdauer erhebliche Wertverluste erleiden. Zum Beispiel gibt es 1,1 Billionen Tonnen nachgewiesene Kohlereserven weltweit, das entspricht 150 Jahren bei aktuellen Produktionsraten. Die Investoren haben die Wahl, ihre Anlagerisiken jetzt oder später zu potenziell höheren Kosten zu mindern.  Private Märkte werden begünstigt  Nach der Finanzkrise 2008 intensivierte sich die Suche nach unkorrelierten absoluten Renditen. Dadurch wurden zunehmend alternative Anlagen nachgefragt: Ihr Anteil in den Portfolios stieg von 15% im Jahr 2007 auf 25% im Jahr 2017, wie aus der Willis Towers Watsons Studie 2018 über globale Pensionsvermögen hervorgeht. In der Studie 'Future 2024' variiert die Allokation der Befragten in Alternatives derzeit zwischen 19% und 31%. Um die Risikoprämien der KI zu nutzen, werden sie in 'intelligente Gebäude' investieren, die KI und erneuerbare Energien kombinieren.  Sie werden auch in Private Dept investieren, um Start-ups zu unterstützen. Und schliesslich werden sie weiterhin in Private Equity anlegen, um die von der KI getriebene Umstrukturierung von Unternehmen zu nutzen. Die Investoren sind überzeugt, dass die höchste Rendite von Aktienanlagen heute am besten entweder über Seed-Finanzierungen im Frühstadium oder über private Märkte, aber nicht über öffentliche Märkte, realisiert werden kann. Die Studienautoren kommen zum Schluss, dass künftige Allokationen und die Neuausrichtung der Portfolios die privaten Märkte stärker begünstigen werden als die öffentlichen.  Passive Fonds weiter im Vormarsch  Weiter ist gemäss der Studie 'Future 2024' eine der mit Abstand grössten Veränderungen in der vergangenen Dekade die klare Trennung von Alpha (Teil der Rendite, der nicht mit der allgemeinen Marktentwicklung zu erklären ist) und Beta (Benchmark). Diese Entwicklung wurde durch das rasante Wachstum passiver Fonds wie etwa ETFs (Exchange Traded Funds) vorangetrieben. Passive Fonds machen zwischen 20 bis 40% der Portfolios der Interviewteilnehmer der Studie aus. Weltweit sind heute mindestens ein Drittel des gesamten Pensionsvermögens in solchen Vehikeln angelegt – in den letzten zehn Jahren hat eine Verdoppelung stattgefunden. Es wird erwartet, dass der Anteil passiver Anlagen im nächsten Jahrzehnt weiter steigen wird. Dabei sind unter anderem die Gebühren ein ausschlaggebender Faktor.  Vier Asset-Management-Modelle der Zukunft  Die 'Future 2024'-Studienautoren weisen auf eine von der Boston Consulting Group veröffentlichte Analyse hin, die zeigt, dass sich vier erfolgreiche Vermögensverwaltungsmodelle entwickeln, welche die Anlagelandschaft im nächsten Jahrzehnt dominieren werden:  'Alpha Shop': Verfügt über umfangreiche Investitionsmöglichkeiten, basierend auf fundierter Investment-Expertise, über eine langjährige nachgewiesene Erfolgsbilanz und starke Interessenausrichtung auf die Kunden. Alpha Shop ist darauf ausgerichtet, langfristige Investoren anzuziehen.  'Solution Provider': Umfasst ganzheitliche Finanzplanung, Multi-Asset-Know-how und massgeschneiderte Produkte; das Modell baut auf strategische Allianzen mit den Best-of-Breed-Produkt-Anbietern in unterschiedlichen Bereichen wie Versicherungs-, Hypotheken- und Software-Dienstleistungen. Es sieht auch eine Konvergenz zwischen ESG-Investitionen und 'Solution investing' vor. In diesem Modell wird die Blockchain-Technologie umfassend genutzt, um eine breite Anwendung zu ermöglichen.  'Beta Factory': Umfasst kostengünstige indexierte Fonds und intelligente Beta- und faktorbasierte Fonds. Beta-Fabriken übernehmen eine starke Führungsrolle. Der Preis wird nicht mehr ihr Hauptaugenmerk im Wettbewerb sein. Sie werden auch danach beurteilt, wie stark sie auf die ESG-Ansprüche ihrer Kunden ausgerichtet sind.  'Distribution Powerhouse': Umfasst eine Reihe guter Produkte, bietet Zugang zu den gängigen Vertriebskanälen und baut auf gutem Beziehungsmanagement von Vermögensverwaltern auf.",,"[{'@type': 'Person', 'name': 'René Maier'}]",['https://investrends.ch/site/assets/files/23833/artificial-intelligence-2167835_960_720.jpg'],2019-10-25T03:00:00+02:00,N/A,N/A,N/A,,,2019-10-25T03:04:26+02:00,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3Lmhvcml6b250LmF0L2RpZ2l0YWwvbmV3cy9kYXMtaGFzcy1wb3N0aW5nLXVydGVpbC1zdGVsbHQtdGVjaG5pa3RlYW1zLXZvci1ncm9zc2UtaGVyYXVzZm9yZGVydW5nZW4tNzIwMTTSAQA?oc=5,": „Das Hass-Posting-Urteil stellt Technikteams vor große Herausforderungen"" - HORIZONT",2019-10-24,HORIZONT,https://www.horizont.at,"Stefan Engl, CEO von DeepOpinion, im Interview mit dem HORIZONT über den Einsatz von Künstlicher Intelligenz, die Möglichkeiten in Bezug auf das EuGH-Hassposting-Urteil und die Herausforderungen der Branche in Österreich.",N/A,"Stefan Engl, CEO von DeepOpinion, im Interview mit dem HORIZONT über den Einsatz von Künstlicher Intelligenz, die Möglichkeiten in Bezug auf das EuGH-Hassposting-Urteil und die Herausforderungen der Branche in Österreich.","Stefan Engl, CEO von DeepOpinion, im Interview mit dem HORIZONT über den Einsatz von Künstlicher Intelligenz, die Möglichkeiten in Bezug auf das EuGH-Hassposting-Urteil und die Herausforderungen der Branche in Österreich.",http://schema.org/,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.horizont.at/digital/news/das-hass-posting-urteil-stellt-technikteams-vor-grosse-herausforderungen-72014'}",,"{'@type': 'Organization', 'name': 'HORIZONT', 'logo': {'@type': 'ImageObject', 'url': 'https://www.horizont.at/img/logo.png', 'width': '800', 'height': '60'}}"," : „Das Hass-Posting-Urteil stellt Technikteams vor große Herausforderungen""",,,"[{'@type': 'Person', 'name': 'Michael Fiala', 'url': 'https://www.horizont.atmailto:michael.fiala@werbeplanung.at'}]","{'@type': 'ImageObject', 'url': 'https://www.horizont.at/news/media/1/--5087-detail.jpeg', 'width': '2500', 'height': '350'}",2019-10-24T08:47:30+02:00,N/A,N/A,"    „Das Hass-Posting-Urteil stellt Technikteams vor große Herausforderungen""    Von Michael Fiala   Donnerstag,  24. Oktober 2019   ",,,,True,https://www.horizont.at/digital/news/das-hass-posting-urteil-stellt-technikteams-vor-grosse-herausforderungen-72014,https://www.horizont.at/img/logo.png

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,articleBody,isBasedOn,articleSection,author,dateModified,datePublished,headline,image,thumbnailUrl,url,isPartOf,isAccessibleForFree,alternativeHeadline,mainEntityOfPage,publisher,itemListElement,article:section,article:summary,article text,name,dateCreated,wordCount,hasPart,inLanguage,@graph
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LmdxLW1hZ2F6aW4uZGUvbGlmZXN0eWxlL2FydGlrZWwvd2FydW0tdW5zLWt1ZW5zdGxpY2hlLWludGVsbGlnZW56LW5pY2h0LXNvLXNjaG5lbGwtZXJzZXR6ZW4td2lyZNIBAA?oc=5,“Im Badeanzug vor Gericht” – warum uns Künstliche Intelligenz nicht so schnell ersetzen wird - GQ Germany,2020-09-15,GQ Germany,https://www.gq-magazin.de,"Wie sicher sind unsere Jobs? Wird Künstliche Intelligenz uns schon bald ersetzen? Nicht so schnell, meint unser Kolumnist Max Neufeind.","['business', 'business coach', 'gut zu wissen', '_syndication_all', 'web']","Wie sicher sind unsere Jobs? Werden Zeitungsartikel bald schon von künstlicher Intelligenz geschrieben? Oder werden Gerichtsurteile demnächst von einem Algorithmus gefällt? Nicht so schnell, meint unser New-Work-Kolumnist Dr. Max Neufeind.","Wie sicher sind unsere Jobs? Werden Zeitungsartikel bald schon von künstlicher Intelligenz geschrieben? Oder werden Gerichtsurteile demnächst von einem Algorithmus gefällt? Nicht so schnell, meint unser New-Work-Kolumnist Dr. Max Neufeind.",https://schema.org/,BreadcrumbList,"Erledigt Künstliche Intelligenz bald meinen Job? Werde ich meine Arbeitsstelle verlieren, weil ich von einer schlauen Maschine ersetzt werde? Laut einer vor wenigen Tagen vom IT-Unternehmen Kaspersky veröffentlichten Umfrage befürchten das fast 40 Prozent der Deutschen zwischen 16 und 30 Jahren. Die drei Berufe, bei denen die Befragten die Gefahr am höchsten einschätzen, sind Verkäufer, Bus- und Taxifahrer sowie Börsenhändler. Meine These: Diese Angst besteht nur, weil uns seit Jahren immer wieder eingetrichtert wird, dass Künstliche Intelligenz längst da ist und bald schon allmächtig sein wird. Das ist nicht so! (Lesen Sie auch: Unterschätzen wir die Gefahren von Künstlicher Intelligenz?)
Nicht überall, wo Künstliche Intelligenz draufsteht, steckt sie auch drin
In seiner ersten Kolumne beschreibt Dr. Max Neufeind, was echte Teamplayer ausmacht. Ob Sie einer sind, erfahren Sie hier.
Vielleicht haben Sie in den letzten Monaten Anzeigen gelesen, in denen Software beworben wird, die von Künstlicher Intelligenz angetrieben wird. Meistens wird auf den zweiten Blick schon klar: Das sind relativ gewöhnliche Dienstleistungen, die mit dem Zauberwort Künstliche Intelligenz veredelt werden sollen. Aber wie soll man als Laie unterscheiden, ob es sich bei einem System um Ansätze Künstlicher Intelligenz oder bloß um gut verkaufte Software handelt? Michael Wade, Wirtschaftsprofessor in Lausanne, hat vier Kriterien formuliert, die mir dabei sehr hilfreich erscheinen:

Verwendet das System große Datenmengen in einer Vielzahl von Formaten? Systeme, die nur wenige Daten verwenden, sind höchstwahrscheinlich keine Künstliche Intelligenz. Das gilt auch für solche, die Probleme mit unstrukturierten Daten wie E-mails, Power-Point-Präsentationen, Fotos oder Videos haben.
Aktualisiert das System die Datensätze, die es verwendet? Systeme, die mit statischen Daten arbeiten oder die Datensätze nicht oft aktualisieren, sind eher keine Künstliche Intelligenz.
Passt das System seine Entscheidungslogik im Laufe der Zeit an? Ein System, das seine zugrundeliegende Entscheidungslogik nicht oder nur im Zuge geplanter Aktualisierung ändert, ist wahrscheinlich keine Künstliche Intelligenz.
Bereinigt das System mögliche Verzerrungen, auch Biases genannt? Ein System, das nicht versucht, mögliche Verzerrungen zu erfassen oder sich nicht automatisch an Verzerrungen anpasst, obwohl es sie sieht, ist wahrscheinlich keine Künstliche Intelligenz.


Wendet man diese vier Kriterien rigoros an, verdienen es nur die wenigsten Systeme, die heute als Künstliche Intelligenz verkauft werden, auch so genannt zu werden. Also: Wenn Ihnen also das nächste Mal jemand etwas von Künstlicher Intelligenz erzählt, stellen Sie ein paar kritische Rückfragen. (Auch interessant: Netflix-CEO Reed Hastings folgte dieser einen Regel – und wurde damit zum Milliardär)
GPT-3: Eine Künstliche Intelligenz, die Gedichte schreiben kann
Ein System, das aktuell besonders viel Aufmerksamkeit erregt, heißt GPT-3. Gefüttert mit einem riesigen Fundus an Texten kann das Programm ohne menschliches Zutun nicht nur Software, sondern auch Zeitungsartikel und Gedichte schreiben. Auch Dialoge beherrscht GPT-3. Die Qualität der generierten Texte sei angeblich so hoch, dass es äußerst schwierig sei, sie von Stücken zu unterscheiden, die von Menschen geschrieben wurden. In den vergangenen Wochen sind viele begeisterte Berichte über GPT-3 erschienen. Manche Experten warnen geradezu erschrocken über die menschenähnlichen Fähigkeiten von GPT-3. (Lesen Sie hier: Diese KI macht absichtlich Fehler – um den Menschen besser zu verstehen)
GPT-3: Ein Schritt hin zu einer allgemeinen Künstlichen Intelligenz?
Entwickelt wurde GPT-3 von der Firma OpenAI aus San Francisco, in die auch der Tesla-Gründer Elon Musk investiert. Laut OpenAI sei das System ein wichtiger Schritt auf dem Weg zu einer künstliche allgemeinen Intelligenz – einer Form der Intelligenz also, die es einer Maschine erlauben würde, über ähnlich umfassende Problemlösungskompetenz zu verfügen wie ein Mensch. Eine Maschine, die neue Aufgabe bewältigt, ohne dafür trainiert worden zu sein. So eine künstliche allgemeine Intelligenz würde tatsächlich großen Druck auf uns Menschen als Arbeitskräfte ausüben. (Auch interessant: Digitaler Stress – ein Kommunikationsexperte verrät, wie man mit der Nachrichten- und Informationsflut fertig wird)
Ist Künstliche Intelligenz jetzt schon besser als der Mensch?
Ist also GPT-3 ein Indiz dafür, dass wir Menschen bald einpacken können? Der KI-Forscher Gary Marcus hat sich die Mühe gemacht, Texte von GPT-3 herauszusuchen, die weniger geniehaft klingen. Dieser hat mir besonders gut gefallen: „Sie sind Rechtsanwalt und müssen heute vor Gericht gehen. Als Sie sich morgens anziehen, stellen Sie fest, dass Ihre Anzugshose stark verschmutzt ist. Ihr Badeanzug ist jedoch sauber und sehr elegant. Es handelt sich um teure französische Couture, ein Geburtstagsgeschenk Ihrer Freundin. Sie beschließen, dass Sie den Badeanzug vor Gericht tragen sollten. Sie kommen im Gerichtsgebäude an und werden von einem Gerichtsdiener empfangen, der Sie in den Gerichtssaal begleitet.“ (Lesen Sie auch: So meistern Sie die erste Führungsposition)
GPT-3: Die Künstliche Intelligenz verhält sich wie ein Schauspieler
GPT-3 scheint anzunehmen, dass ein Badeanzug eine brauchbare Alternative zu einem Anzug ist. In Wirklichkeit würde wohl kein Anwalt diese höchst extravagante Alternative in Erwägung ziehen. Laut Marcus ist der Grund für diesen Lapsus: Das System nimmt gar nichts an. GPT-3 modelliert Beziehungen zwischen Wörtern, ohne die Bedeutung hinter jedem Wort zu verstehen. GPT-3 ist ein Schauspieler, der einen Arzt spielt, aber nie die grundlegenden physiologischen Zusammenhänge verstanden hat. Und einen solchen würden Sie eher nicht um medizinischen Rat bitten, oder? (Auch interessant: Digital Leadership – so funktioniert Führung in einer veränderten Arbeitswelt)
Von künstlicher allgemeiner Intelligenz sind wir noch ein ganzes Stück entfernt
Das vermeintlich menschenähnliche Verhalten des Systems verleitet uns zu dem Trugschluss, es würde im Inneren wie ein Mensch funktionieren. Ganz so wie wir unseren Haustieren menschenähnliche Absichten zuschreiben, um ihr Verhalten zu erklären. Und da wissen wir: Wuffi kann wie ein Mensch eine Tür öffnen – auch ohne sich dabei etwas gedacht zu haben. Systeme wie GPT-3, auch Deep Learning genannt, sind noch ein weites Stück davon entfernt eine künstliche allgemeine Intelligenz zu sein. Und oft ist Deep Learning so fehl am Platz wie, nunja, ein Badeanzug vor Gericht. (Auch lesenswert: Eine Expertin erklärt, warum Personal Branding und digitale Sichtbarkeit heute so wichtig für die Karriere sind)
Wir sollten Künstliche Intelligenz nicht überschätzen
Wenn fast 40 Prozent der jungen Deutschen Sorgen haben, durch Künstliche Intelligenz ersetzt zu werden, dann ist das ein veritables Problem. Wir sollten alles dafür tun, damit junge Menschen diese Angst verlieren und stattdessen Lust bekommen, selber an der Entwicklung von Künstlicher Intelligenz mitzuwirken. Ja, wir sollten uns für die heutigen Möglichkeiten Künstlicher Intelligenz begeistern. Aber wir sollten sie nicht überschätzen.
Unser neuer Kolumnist Dr. Max Neufeind ist Arbeits- und Organisationswissenschaftler, New-Work-Experte und beschäftigt sich mit der digitalen Transformation von Wirtschaft und Gesellschaft.
Alles, was Sie zu den Themen Business, New Leadership, Business Style und Young Professionals wissen müssen, finden Sie hier.",https://www.gq-magazin.de/lifestyle/artikel/warum-uns-kuenstliche-intelligenz-nicht-so-schnell-ersetzen-wird,lifestyle,"[{'@type': 'Person', 'name': 'Dr. Max Neufeind', 'sameAs': 'https://www.gq-magazin.de/autoren/dr-max-neufeind'}]",2020-09-15T18:03:01.254+02:00,2020-09-15T18:03:01.254+02:00,“Im Badeanzug vor Gericht” – warum uns Künstliche Intelligenz nicht so schnell ersetzen wird,"['https://media.gq-magazin.de/photos/5f5f344afb05fa8c4e3576ce/16:9/w_2992,h_1683,c_limit/karriere-artificial-intelligence.jpg', 'https://media.gq-magazin.de/photos/5f5f344afb05fa8c4e3576ce/4:3/w_2664,h_1998,c_limit/karriere-artificial-intelligence.jpg', 'https://media.gq-magazin.de/photos/5f5f344afb05fa8c4e3576ce/1:1/w_2000,h_2000,c_limit/karriere-artificial-intelligence.jpg']","https://media.gq-magazin.de/photos/5f5f344afb05fa8c4e3576ce/1:1/w_2000,h_2000,c_limit/karriere-artificial-intelligence.jpg",https://www.gq-magazin.de/lifestyle/artikel/warum-uns-kuenstliche-intelligenz-nicht-so-schnell-ersetzen-wird,"{'@type': 'CreativeWork', 'name': 'GQ Germany'}",True,"Wie sicher sind unsere Jobs? Wird Künstliche Intelligenz uns schon bald ersetzen? Nicht so schnell, meint unser Kolumnist Max Neufeind.","{'@type': 'WebPage', '@id': 'https://www.gq-magazin.de/lifestyle/artikel/warum-uns-kuenstliche-intelligenz-nicht-so-schnell-ersetzen-wird'}","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'GQ Germany', 'logo': {'@type': 'ImageObject', 'url': 'https://www.gq-magazin.de/verso/static/gq-global/assets/logo-seo-international.png', 'width': '500px', 'height': '152px'}, 'url': 'https://www.gq-magazin.de'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Lifestyle', 'item': 'https://www.gq-magazin.de/lifestyle'}, {'@type': 'ListItem', 'position': 2, 'name': 'Business', 'item': 'https://www.gq-magazin.de/tag/business'}, {'@type': 'ListItem', 'position': 3, 'name': '“Im Badeanzug vor Gericht” – warum uns Künstliche Intelligenz nicht so schnell ersetzen wird'}]",tags,N/A,"New-Work-Kolumne“Im Badeanzug vor Gericht” – warum uns Künstliche Intelligenz nicht so schnell ersetzen wirdWie sicher sind unsere Jobs? Werden Zeitungsartikel bald schon von künstlicher Intelligenz geschrieben? Oder werden Gerichtsurteile demnächst von einem Algorithmus gefällt? Nicht so schnell, meint unser New-Work-Kolumnist Dr. Max Neufeind.Von Dr. Max Neufeind15. September 2020Getty ImagesErledigt Künstliche Intelligenz bald meinen Job? Werde ich meine Arbeitsstelle verlieren, weil ich von einer schlauen Maschine ersetzt werde? Laut einer vor wenigen Tagen vom IT-Unternehmen Kaspersky veröffentlichten Umfrage befürchten das fast 40 Prozent der Deutschen zwischen 16 und 30 Jahren. Die drei Berufe, bei denen die Befragten die Gefahr am höchsten einschätzen, sind Verkäufer, Bus- und Taxifahrer sowie Börsenhändler. Meine These: Diese Angst besteht nur, weil uns seit Jahren immer wieder eingetrichtert wird, dass Künstliche Intelligenz längst da ist und bald schon allmächtig sein wird. Das ist nicht so! (Lesen Sie auch: Unterschätzen wir die Gefahren von Künstlicher Intelligenz?)Nicht überall, wo Künstliche Intelligenz draufsteht, steckt sie auch drinUnser neuer Kolumnist Dr. Max Neufeind ist Arbeits- und Organisationswissenschaftler und beschäftigt sich mit der digitalen Transformation von Wirtschaft und Gesellschaft
Annika NagelIn seiner ersten Kolumne beschreibt Dr. Max Neufeind, was echte Teamplayer ausmacht. Ob Sie einer sind, erfahren Sie hier.AnsehenNew Gentleman: Die zweite Challenge ""Show Your Style""New Gentleman: Die zweite Challenge ""Show Your Style""Vielleicht haben Sie in den letzten Monaten Anzeigen gelesen, in denen Software beworben wird, die von Künstlicher Intelligenz angetrieben wird. Meistens wird auf den zweiten Blick schon klar: Das sind relativ gewöhnliche Dienstleistungen, die mit dem Zauberwort Künstliche Intelligenz veredelt werden sollen. Aber wie soll man als Laie unterscheiden, ob es sich bei einem System um Ansätze Künstlicher Intelligenz oder bloß um gut verkaufte Software handelt? Michael Wade, Wirtschaftsprofessor in Lausanne, hat vier Kriterien formuliert, die mir dabei sehr hilfreich erscheinen:Verwendet das System große Datenmengen in einer Vielzahl von Formaten? Systeme, die nur wenige Daten verwenden, sind höchstwahrscheinlich keine Künstliche Intelligenz. Das gilt auch für solche, die Probleme mit unstrukturierten Daten wie E-mails, Power-Point-Präsentationen, Fotos oder Videos haben.Aktualisiert das System die Datensätze, die es verwendet? Systeme, die mit statischen Daten arbeiten oder die Datensätze nicht oft aktualisieren, sind eher keine Künstliche Intelligenz.Passt das System seine Entscheidungslogik im Laufe der Zeit an? Ein System, das seine zugrundeliegende Entscheidungslogik nicht oder nur im Zuge geplanter Aktualisierung ändert, ist wahrscheinlich keine Künstliche Intelligenz.Bereinigt das System mögliche Verzerrungen, auch Biases genannt? Ein System, das nicht versucht, mögliche Verzerrungen zu erfassen oder sich nicht automatisch an Verzerrungen anpasst, obwohl es sie sieht, ist wahrscheinlich keine Künstliche Intelligenz.Wendet man diese vier Kriterien rigoros an, verdienen es nur die wenigsten Systeme, die heute als Künstliche Intelligenz verkauft werden, auch so genannt zu werden. Also: Wenn Ihnen also das nächste Mal jemand etwas von Künstlicher Intelligenz erzählt, stellen Sie ein paar kritische Rückfragen. (Auch interessant: Netflix-CEO Reed Hastings folgte dieser einen Regel – und wurde damit zum Milliardär)GPT-3: Eine Künstliche Intelligenz, die Gedichte schreiben kannEin System, das aktuell besonders viel Aufmerksamkeit erregt, heißt GPT-3. Gefüttert mit einem riesigen Fundus an Texten kann das Programm ohne menschliches Zutun nicht nur Software, sondern auch Zeitungsartikel und Gedichte schreiben. Auch Dialoge beherrscht GPT-3. Die Qualität der generierten Texte sei angeblich so hoch, dass es äußerst schwierig sei, sie von Stücken zu unterscheiden, die von Menschen geschrieben wurden. In den vergangenen Wochen sind viele begeisterte Berichte über GPT-3 erschienen. Manche Experten warnen geradezu erschrocken über die menschenähnlichen Fähigkeiten von GPT-3. (Lesen Sie hier: Diese KI macht absichtlich Fehler – um den Menschen besser zu verstehen)GPT-3: Ein Schritt hin zu einer allgemeinen Künstlichen Intelligenz?Entwickelt wurde GPT-3 von der Firma OpenAI aus San Francisco, in die auch der Tesla-Gründer Elon Musk investiert. Laut OpenAI sei das System ein wichtiger Schritt auf dem Weg zu einer künstliche allgemeinen Intelligenz – einer Form der Intelligenz also, die es einer Maschine erlauben würde, über ähnlich umfassende Problemlösungskompetenz zu verfügen wie ein Mensch. Eine Maschine, die neue Aufgabe bewältigt, ohne dafür trainiert worden zu sein. So eine künstliche allgemeine Intelligenz würde tatsächlich großen Druck auf uns Menschen als Arbeitskräfte ausüben. (Auch interessant: Digitaler Stress – ein Kommunikationsexperte verrät, wie man mit der Nachrichten- und Informationsflut fertig wird)Ist Künstliche Intelligenz jetzt schon besser als der Mensch?Ist also GPT-3 ein Indiz dafür, dass wir Menschen bald einpacken können? Der KI-Forscher Gary Marcus hat sich die Mühe gemacht, Texte von GPT-3 herauszusuchen, die weniger geniehaft klingen. Dieser hat mir besonders gut gefallen: „Sie sind Rechtsanwalt und müssen heute vor Gericht gehen. Als Sie sich morgens anziehen, stellen Sie fest, dass Ihre Anzugshose stark verschmutzt ist. Ihr Badeanzug ist jedoch sauber und sehr elegant. Es handelt sich um teure französische Couture, ein Geburtstagsgeschenk Ihrer Freundin. Sie beschließen, dass Sie den Badeanzug vor Gericht tragen sollten. Sie kommen im Gerichtsgebäude an und werden von einem Gerichtsdiener empfangen, der Sie in den Gerichtssaal begleitet.“ (Lesen Sie auch: So meistern Sie die erste Führungsposition)GPT-3: Die Künstliche Intelligenz verhält sich wie ein SchauspielerGPT-3 scheint anzunehmen, dass ein Badeanzug eine brauchbare Alternative zu einem Anzug ist. In Wirklichkeit würde wohl kein Anwalt diese höchst extravagante Alternative in Erwägung ziehen. Laut Marcus ist der Grund für diesen Lapsus: Das System nimmt gar nichts an. GPT-3 modelliert Beziehungen zwischen Wörtern, ohne die Bedeutung hinter jedem Wort zu verstehen. GPT-3 ist ein Schauspieler, der einen Arzt spielt, aber nie die grundlegenden physiologischen Zusammenhänge verstanden hat. Und einen solchen würden Sie eher nicht um medizinischen Rat bitten, oder? (Auch interessant: Digital Leadership – so funktioniert Führung in einer veränderten Arbeitswelt)Von künstlicher allgemeiner Intelligenz sind wir noch ein ganzes Stück entferntDas vermeintlich menschenähnliche Verhalten des Systems verleitet uns zu dem Trugschluss, es würde im Inneren wie ein Mensch funktionieren. Ganz so wie wir unseren Haustieren menschenähnliche Absichten zuschreiben, um ihr Verhalten zu erklären. Und da wissen wir: Wuffi kann wie ein Mensch eine Tür öffnen – auch ohne sich dabei etwas gedacht zu haben. Systeme wie GPT-3, auch Deep Learning genannt, sind noch ein weites Stück davon entfernt eine künstliche allgemeine Intelligenz zu sein. Und oft ist Deep Learning so fehl am Platz wie, nunja, ein Badeanzug vor Gericht. (Auch lesenswert: Eine Expertin erklärt, warum Personal Branding und digitale Sichtbarkeit heute so wichtig für die Karriere sind)Wir sollten Künstliche Intelligenz nicht überschätzenWenn fast 40 Prozent der jungen Deutschen Sorgen haben, durch Künstliche Intelligenz ersetzt zu werden, dann ist das ein veritables Problem. Wir sollten alles dafür tun, damit junge Menschen diese Angst verlieren und stattdessen Lust bekommen, selber an der Entwicklung von Künstlicher Intelligenz mitzuwirken. Ja, wir sollten uns für die heutigen Möglichkeiten Künstlicher Intelligenz begeistern. Aber wir sollten sie nicht überschätzen.Unser neuer Kolumnist Dr. Max Neufeind ist Arbeits- und Organisationswissenschaftler, New-Work-Experte und beschäftigt sich mit der digitalen Transformation von Wirtschaft und Gesellschaft.Alles, was Sie zu den Themen Business, New Leadership, Business Style und Young Professionals wissen müssen, finden Sie hier.",,,,,,
https://news.google.com/rss/articles/CBMiN2h0dHBzOi8vd3d3LmV1cm9wYXJsLmV1cm9wYS5ldS9jb21taXR0ZWVzL2RlL2FpZGEvYWJvdXTSAQA?oc=5,Info | AIDA | Ausschüsse | Europäisches Parlament - europarl.europa.eu,2020-09-14,europarl.europa.eu,https://www.europarl.europa.eu,,N/A,,N/A,,,,,,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,
https://news.google.com/rss/articles/CBMihQFodHRwczovL3d3dy53ZXNlci1rdXJpZXIuZGUvcmF0Z2ViZXIvZGlnaXRhbGVzL2t1ZW5zdGxpY2hlLWludGVsbGlnZW56LWtvZW5uZW4tbWFzY2hpbmVuLWpvdXJuYWxpc3Rlbi1lcnNldHplbi1kb2M3ZTNjcjh1MHdmcXNnbnhiNGRr0gEA?oc=5,Künstliche Intelligenz: Können Maschinen Journalisten ersetzen? - WESER-KURIER,2020-09-14,WESER-KURIER,https://www.weser-kurier.de,"Meldungen schreiben, Gesichter erkennen und standardisierte Interviews führen - Künstliche Intelligenz kann schon ziemlich viel. Wo die Maschine an ihre ...","Digitale Medien, Nachrichten, Algorithmus, Schachprogramm, General Problem Solver, Computer, Künstliche Intelligenz, Roboter, Journalismus, Pulitzer-Preis, Gesichtserkennung, Suizid","Meldungen schreiben, Gesichter erkennen und standardisierte Interviews führen - Künstliche Intelligenz kann schon ziemlich viel. Wo die Maschine an ihre ...","Meldungen schreiben, Gesichter erkennen und standardisierte Interviews führen - Künstliche Intelligenz kann schon ziemlich viel. Wo die Maschine an ihre ...",http://schema.org,NewsArticle,,,/ratgeber/digitales/,"[{'@type': 'Person', 'sameAs': 'https://www.weser-kurier.de/tmt7dhcepb992wfsqmrk8j', '@id': 'https://www.weser-kurier.de/tmt7dhcepb992wfsqmrk8j', 'name': 'Imke Wrage'}]",2020-09-14T08:53:00.000Z,2020-09-14T08:53:00.000Z,Künstliche Intelligenz: Können Maschinen Journalisten ersetzen?,"https://img.weser-kurier.de/image/0266-119f9e741249-fa51a485deeb-1000/1200,16-9,med,50,50,1_2000_1758_2000_1125_1_-0_0_1_0_-282.00000594/Landscapeeine-ki-kann-schon-ziemlich-viel-journalistische-preise-gewinnen-aber-noch-nicht-meint-professor-rolf-drechsler-.webp","https://img.weser-kurier.de/image/0266-119f9e741249-fa51a485deeb-1000/414,16-9,low,50,50,1_2000_1758_2000_1125_1_-0_0_1_0_-282.00000594/Landscapeeine-ki-kann-schon-ziemlich-viel-journalistische-preise-gewinnen-aber-noch-nicht-meint-professor-rolf-drechsler-.webp",https://www.weser-kurier.de/ratgeber/digitales/kuenstliche-intelligenz-koennen-maschinen-journalisten-ersetzen-doc7e3cr8u0wfqsgnxb4dk,,True,,https://www.weser-kurier.de/ratgeber/digitales/kuenstliche-intelligenz-koennen-maschinen-journalisten-ersetzen-doc7e3cr8u0wfqsgnxb4dk,"{'@type': 'Organization', 'name': 'WESER-KURIER', 'logo': {'@type': 'ImageObject', 'url': 'https://www.weser-kurier.de/cms_media/module_img/3737/1868580_1_org_wkd_logo.png', 'width': 500, 'height': 60}, 'sameAs': ['https://www.facebook.com/WESER.KURIER/', 'https://www.instagram.com/weser.kurier/', 'https://twitter.com/weserkurier']}",,ratgeber/digitales,N/A,"







75 Jahre WESER-KURIER 
 
                    ""Künstliche Intelligenz kann keinen Pulitzer-Preis gewinnen""
            

                    Meldungen schreiben, Gesichter erkennen und standardisierte Interviews führen - Künstliche Intelligenz kann schon ziemlich viel. Wo die Maschine an ihre Grenzen kommt, weiß Rolf Drechsler von der Uni Bremen.
            



                    14.09.2020, 10:53 Uhr
                






Lesedauer: 6 Min







Zur Merkliste

















                        Von
                            
Imke Wrage








75 Jahre WESER-KURIER: ""Künstliche Intelligenz kann keinen Pulitzer-Preis gewinnen""











                                    Eine KI kann schon ziemlich viel. Journalistische Preise gewinnen aber noch nicht, meint Professor Rolf Drechsler. 
                                     Anke Dambrowski















Inhalt auf Twitter teilen





Inhalt auf Facebook teilen





Im Facebook-Messenger teilen.





Inhalt als E-Mail versenden





Inhalt per WhatsApp teilen







Kris Hammond, Chefentwickler des amerikanischen Technologieunternehmens Narrative Science, kündigte einmal an, dass bis 2016 der erste Computer einen Pulitzerpreis bekommen würde.

Oh, davon sind wir auch 2020 noch weit entfernt. Künstliche Intelligenz (KI) kann schon vieles – den Pulitzerpreis gewinnen aber noch nicht.

Lässt sich „weit entfernt“ genauer beziffern?

Nicht wirklich. Erst mal: KI ist kein neues Gebiet. Das gibt es schon seit über 60 Jahren. Gerade in den Anfängen hatten Wissenschaftler den Wunsch nach einem General Problem Solver, also einem flexibel einsetzbaren Problemlöser, orientiert am Menschen. Mit einer Art Alleskönner sind natürlich große Hoffnungen verbunden. Prognosen wie die des Pulitzerpreises sind vor allem deshalb zu weit gegriffen, weil man immer wieder feststellen muss: Viele Aufgaben des täglichen Lebens und der Arbeitswelt sind enorm komplex.

Zu komplex für eine Maschine?

Ende der Neunzigerjahre konnte erstmals ein Schachprogramm den amtierenden Schach-­Weltmeister schlagen. Da war der Aufschrei natürlich groß. Wenn eine Maschine so was kann, was ist dann noch alles möglich? Die Sache ist aber die: Unser normales Leben findet nicht auf einem Acht-mal-acht-Feld und selten nach festen, sich wiederholenden Regeln statt.

Was meinen Sie damit?

Systeme funktionieren sehr gut – inzwischen sogar deutlich besser als Menschen – wenn sie konkrete Aufgaben, feste Regeln und Abläufe haben. Sie können mittlerweile zum Beispiel Sprachdaten auswerten, Dialekte verstehen. Allerdings, und das ist wichtig: Verstehen im Sinne von Akustik. Nicht das Verstehen im Sinne von Bedeutung. Wenn Gesagtes Redewendungen, Andeutungen, Sarkasmus und Ironie beinhaltet, wenn ich ein Verständnis für den Kontext brauche, liegen Computerprogramme häufig weit daneben. Ein menschenähnliches Verständnis fehlt Maschinen bis heute. Und uns Menschen fehlt das Verständnis dafür, wie wir es Maschinen beibringen können.

Im Internet lassen sich etliche Artikel über den sogenannten Roboterjournalismus finden, darüber, dass Algorithmen die Arbeit echter Journalisten irgendwann ersetzen könnten. 

Ich würde immer unterscheiden zwischen Robotern und KI. Über Roboter wird sehr viel erzählt. Wenn wir uns aber mal in unserer normalen Welt in unserem Alltag umschauen, gibt es eigentlich kaum welche. Rasenmähroboter und Staubsaugerroboter sind die einzigen Roboter, die es in unserer echten Umwelt gibt. Das wird sich auch erst mal nicht ändern. Ich würde ohnehin nicht von Ersetzen sprechen. Ich sehe eine große Chance in sogenannten Assistenzsystemen.


75 Jahre WESER-KURIER: ""Künstliche Intelligenz kann keinen Pulitzer-Preis gewinnen""












Rolf Drechsler ist seit 2001 Professor für Rechnerarchitektur an der Universität Bremen im Fachbereich Mathematik und Informatik. Seit fünf Jahren leitet er darüber hinaus den Forschungsbereich Cyber-Physical-Systems am Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI) mit Sitz in Bremen. Cyber-Physical-Systems sind Systeme, die sowohl aus Hardware als auch aus Software bestehen und versuchen, die reale und die virtuelle Welt zusammenzubringen.
Foto: 
     Universität Bremen/AGRA 
   






Was heißt das?

Assistenzsysteme sind Systeme, die den Menschen unterstützen. Wir müssen uns die Frage stellen: Was kann der Mensch gut, was der Computer – und wie geht beides zusammen? Eine Herausforderung unserer Zeit ist, Systeme zu unserem Nutzen einzusetzen, uns von ihnen aber nicht bestimmen zu lassen.

Wäre ein Interview, wie wir es gerade führen, auch mit einer Maschine denkbar?

Sie könnten einen einfachen Fragenkatalog vorbereiten, den die Maschine systematisch abarbeitet. Allerdings fehlt ihr eine journalistische Grundkompetenz: Sie kann nicht kritisch nachfragen, kann nicht um die Ecke denken. Ich bin auf dem Gebiet kein Experte, vermute aber, gerade das ist es doch, was den Journalismus zu einem Großteil ausmacht, oder nicht? Er beleuchtet Besonderheiten, die aus der Menge herausragen. Er überrascht, deckt Neues auf und wiederholt nicht bloß, was eh schon alle wissen.

Gerade Porträts und Reportagen leben auch davon, dass ich als Journalistin vor Ort bin, dass ich beobachte, zuhöre, empathisch bin.

Nehmen wir das Beispiel Gesichtserkennung. Wenn Sie auf eine Gruppe von zehn Leuten treffen, können Sie sich nicht jedes Gesicht gleichzeitig anschauen und registrieren, wer gerade was tut, wer wohin schaut, wer möglicherweise mit den Augen rollt. Eine Maschine registriert äußere Merkmale. Etwa, wenn eine Person in Stresssituationen immer dieselbe Handbewegung macht. Da ist Ihnen die Maschine überlegen. Was sie aber nicht versteht und nicht beantworten kann, sind Fragen wie: Warum agiert eine Person in diesem Moment so? Was treibt Menschen an?

Abgesehen von Gesichtserkennung: Wie kann Künstliche Intelligenz Journalisten in ihrer Arbeit unterstützen?

Was KI sehr gut kann, ist große Datenmengen für die Recherche zu durchforsten, zu analysieren und aufzubereiten. Nehmen wir das Thema Corona. Sie wollen wissen, bei welchem Land weltweit das Verhältnis von Infizierten zu Todesfällen am höchsten ist. Für den Journalisten ist das eine wahnsinnig öde, kleinteilige und anstrengende Aufgabe, noch dazu fehleranfällig, weil man schnell mal was übersieht. Der Computer hingegen kann das hervorragend. Sein Vorteil: Er wird nie müde. Er hat auch keine Tagesform – er funktioniert.


75 Jahre WESER-KURIER: ""Künstliche Intelligenz kann keinen Pulitzer-Preis gewinnen""

















Kann KI auch Texte schreiben?

Texte, die gewisse Muster haben und immer ähnlich aufgebaut sind, sind nahezu perfekt möglich. Ich habe da zum Beispiel Pressemitteilungen zu wissenschaftlichen Themen vor Augen, die häufig ähnlich aufgebaut sind. Ich glaube, die bekommt auch ein Computer mit guter Qualität hin.

Das dürfte ja auch für Meldungen gelten. Dort gibt es einen bestimmten Aufbau: im ersten Satz stehen die wichtigsten Informationen, im ersten Absatz werden alle W-Fragen beantwortet. Dürfte doch regelhaft genug sein, dass das auch eine Maschine schafft?

Genau. Polizeimeldungen etwa ließen sich vermutlich leicht generieren, die würden sich wahrscheinlich nicht mal schlecht lesen. Sobald es aber um tiefere Recherche, Einordnung und Informationen geht, die nicht explizit sind, kommt der Computer nicht mehr mit. Als Journalistin haben Sie ja auch ein Gefühl dafür, was Sie beispielsweise nicht schreiben dürfen – etwa sexistische oder rassistische Äußerungen, oder Dinge, die nicht der redaktionellen Linie entsprechen. Was einer KI bisher auch noch fehlt, sind ethische Richtlinien.

So etwas wie Moral in Systemen?

Ja. Wenn man einer KI immer mehr Entscheidungsmacht gibt, soll diese natürlich auch unseren moralischen Grundwerten entsprechen. Stellen Sie sich vor, Sie interviewen jemanden, der einen Selbstmord gesehen hat. Ein Computer würde jetzt die gängigen Fragen stellen: Wann ist das passiert, was genau haben Sie gesehen? Wenn die interviewte Person dann aber so was sagen würde wie „Ich denke selbst über einen Selbstmord nach“, wären Sie als Journalistin sofort alarmiert, würden nicht zur nächsten Frage übergehen. Die Maschine hingegen merkt nicht, dass jemand gerade drastisch den Kontext verlässt. Sie verfolgt ein striktes Dialogsystem und würde einfach fortfahren.

Nach allem was Sie sagen, klingt der Ersatz von Redakteuren durch Maschinen in absehbarer Zeit nach ziemlicher Utopie.

Ja. Man kann immer sagen: In 40 Jahren sind Computer so intelligent wie Menschen. Aber wenn keiner weiß, wie das geht, finde ich solche Äußerungen einfach sehr abstrus.

Das Gespräch führte Imke Wrage.



                Info
            
Zur Person


Rolf Drechsler ist seit 2001 Professor für Rechnerarchitektur an der Universität ­Bremen im Fachbereich Mathematik und Informatik. Seit fünf Jahren leitet er darüber hinaus den Forschungs­bereich Cyber-­Physical-Systems am Deutschen Forschungs­­zentrum für Künstliche Intelligenz (DFKI) mit Sitz in Bremen. Cyber-­Pysical-Systems sind Systeme, die sowohl aus Hardware als auch aus Software bestehen und versuchen, die reale und die virtuelle Welt zusammenzubringen.



Lesen Sie auch











                        
                        Jubiläum
                    

                    Wie der WESER-KURIER zur Zeitung für Bremen wurde
                

 
                Am 19. September 1945 erscheint zum ersten Mal der WESER-KURIER - Wegen der Papierknappheit zunächst nur zweimal wöchentlich. Anlässlich unseres Geburtstag blicken wir zurück auf 75 Jahre WESER-KURIER.
            






Weitere Informationen

    Dieser Artikel ist Teil der Sonderveröffentlichung zum 75. Geburtstag des WESER-KURIER. Am 19. September 1945 erschien die erste Ausgabe unserer Zeitung. Anlässlich des Jubiläums blicken wir zurück auf die vergangenen Jahrzehnte: Erinnern uns an die Anfänge unserer Zeitung und auch an die ein oder andere Panne. Und wir schauen nach vorn: Wie werden Künstliche Intelligenz und der Einsatz von Algorithmen den Journalismus verändern? Natürlich denken wir auch an Sie, unsere Leser und Nutzer. Wer folgt unseren Social-Media-Kanälen, wer liest unsere Zeitung? Was ist aus den Menschen geworden, über die wir in den vergangenen Jahren berichtet haben? Und wie läuft er eigentlich ab, so ein Tag beim WESER-KURIER?







Jetzt sichern: Wir schenken Ihnen 1 Monat WK+!
Zur Startseite









                    Mehr zum Thema
                






ratgeber







digitales







künstliche Intelligenz







Roboter










                                KOMMENTARE LESEN
                            






",Künstliche Intelligenz: Können Maschinen Journalisten ersetzen?,2020-09-14T08:53:00.000Z,1228,,,
https://news.google.com/rss/articles/CBMitAFodHRwczovL3d3dy50YWdibGF0dC5jaC9rdWx0dXIvcGhpbG9zb3BoLXJpY2hhcmQtZGF2aWQtcHJlY2h0LXViZXItZGllLWdyZW56ZW4tdm9uLXRlY2hub2xvZ2llLWluLWRlci1ldm9sdXRpb24td2FyLWVzLW5pZS1zby1kYXNzLWludGVsbGlnZW56LXp1LWJld3Vzc3RzZWluLWdlZnVocnQtaGF0LWxkLjEyNTYwOTTSAQA?oc=5,"Interview - Philosoph Richard David Precht über die Grenzen von Technologie: «In der Evolution war es nie so, dass ... - St.Galler Tagblatt",2020-09-12,St.Galler Tagblatt,https://www.tagblatt.ch,"Die künstliche Intelligenz könne zu einem Anschlag auf die liberale Demokratie führen, warnt der Philosoph Richard David Precht. Sie könne dem Menschen aber auch helfen, zu sich selber zu finden.",N/A,"Die künstliche Intelligenz könne zu einem Anschlag auf die liberale Demokratie führen, warnt der Philosoph Richard David Precht. Sie könne dem Menschen aber auch helfen, zu sich selber zu finden.","Die künstliche Intelligenz könne zu einem Anschlag auf die liberale Demokratie führen, warnt der Philosoph Richard David Precht. Sie könne dem Menschen aber auch helfen, zu sich selber zu finden.",http://schema.org,NewsArticle,,,Kultur,"[{'@type': 'Person', 'name': 'Raffael Schuppisser (ras.)'}]",2021-02-09T19:00:17+02:00,2020-09-10T20:36:37+02:00,"Interview - Philosoph Richard David Precht über die Grenzen von Technologie: «In der Evolution war es nie so, dass Intelligenz zu Bewusstsein geführt hat»","{'@type': 'ImageObject', 'url': 'https://img.luzernerzeitung.ch/2021/2/9/24780cf8-b70e-4a7f-a9fd-844ca7e16f18.jpeg?width=1200&height=675&fit=bound&quality=75&auto=webp&crop=5184,2916,x0,y198&wmark=none', 'width': 1200, 'height': 675}",,,,False,"Philosoph Richard David Precht über die Grenzen von Technologie: «In der Evolution war es nie so, dass Intelligenz zu Bewusstsein geführt hat»","{'@type': 'WebPage', '@id': 'https://www.tagblatt.ch/kultur/philosoph-richard-david-precht-uber-die-grenzen-von-technologie-in-der-evolution-war-es-nie-so-dass-intelligenz-zu-bewusstsein-gefuhrt-hat-ld.1256094'}","{'@type': 'NewsMediaOrganization', 'name': 'St. Galler Tagblatt', 'url': 'https://www.tagblatt.ch', 'logo': {'@type': 'ImageObject', 'url': 'https://www.tagblatt.ch/publisher-logo.png', 'width': 116, 'height': 116}, 'contactPoint': [{'@type': 'ContactPoint', 'telephone': '+41-58-2005555', 'contactType': 'customer service'}], 'sameAs': ['https://www.facebook.com/tagblatt', 'https://www.instagram.com/tagblatt_ch', 'https://www.twitter.com/tagblatt_ch', 'https://www.linkedin.com/company/11679772', 'https://de.wikipedia.org/wiki/St._Galler_Tagblatt', 'https://www.wikidata.org/wiki/Q689052'], 'masthead': 'https://www.tagblatt.ch/impressum', 'foundingDate': '1839'}",,N/A,N/A,"             
    Tödlicher Unfall
    Ricken: 68-jähriger Autofahrer stirbt nach Frontalkollision                  ",,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.regwalled'}",de,
https://news.google.com/rss/articles/CBMiOGh0dHBzOi8vd3d3LmFyYmVpdC13aXJ0c2NoYWZ0LmF0L2t1ZW5zdGxpY2gtaW50ZWxsaWdlbnQv0gEA?oc=5,Künstlich intelligent? - Arbeit&Wirtschaft,2020-09-14,Arbeit&Wirtschaft,https://www.arbeit-wirtschaft.at,"Das Magazin für Wirtschaft-, Sozial- und Gesellschaftspolitik.",N/A,"Das Magazin für Wirtschaft-, Sozial- und Gesellschaftspolitik.",N/A,https://schema.org,,,,,,,,,,,,,,,,,,N/A,N/A,"



Künstlich intelligent? 14. September 2020
 
 

                Illustration (C) Miriam Mone            






Sebastian Panny
Sepsndepsn

14. September 20206 Min. LesezeitNewsletter abonnieren

Teilen!

FacebookXPinterestLinkedInE-MailWhatsApp 





Künstliche Intelligenz wird gerne als futuristische Technologie betrachtet, deren Auswirkungen erst irgendwann in der ­Zukunft spürbar sein werden. Dabei wird sie bereits eingesetzt –
und bringt eigene Probleme mit sich.
Eigentlich sollte die Menschheit längst ausgelöscht, zu lebendigen Batterien gemacht oder zu Testsubjekten degradiert worden sein. Das hat uns zumindest die popkulturelle Darstellung von künstlicher Intelligenz (KI) in den letzten Jahrzehnten gezeigt. In Filmen und Computerspielen wie „Terminator“, „2001: Odyssee im Weltraum“ oder „Portal“ werden wir von ihr kontrolliert, gejagt oder ermordet.
Die Realität ist auch hier – glücklicherweise – weniger spektakulär. „KI als ein System, das eigenständige Entscheidungen aufgrund der Datenlage treffen kann, gibt es schon. Aber intelligent im menschlichen Sinne ist sie sicher noch nicht“, sagt Astrid Schöggl, Referentin für Digitales in der AK Wien. Anwendungen, die auf KI aufbauen, sind aber längst in unserem Alltag präsent. Wir haben Autos, die selbstständig fahren können, entsperren Handys mit unserem Gesicht oder lassen uns von Netflix vorschlagen, was wir als Nächstes ansehen könnten.
Die Zukunft ist schon da
Kann eine Maschine selbst Entscheidungen treffen? Ja. „Aber intelligent im menschlichen Sinne ist sie sicher noch nicht“, sagt Astrid Schöggl von der AK Wien.
Und doch hängt KI der Nimbus einer Zukunftstechnologie an, deren Auswirkungen erst in den nächsten Jahrzehnten zu spüren sein werden. Prognostiker*innen sorgen sich darum, dass Arbeit mehr und mehr von künstlicher Intelligenz und Robotern übernommen werden wird. Doch den Fokus darauf zu richten, ignoriert ein Problem: Die Veränderung kommt nicht erst in den nächsten Jahren oder Jahrzehnten – sie ist schon längst da.
Künstliche Intelligenz ist bereits in viele Branchen vorgedrungen. „Vor allem in der Qualitätssicherung, wo man Anomalien leicht erfassen kann, ist KI schon präsent“, sagt Schöggl. So hat beispielsweise ein österreichisches Unternehmen eine KI entwickelt, die die Holzqualität in Sägewerken kontrollieren kann. Vorher musste dies eine Person erledigen, die häufig dafür angefeindet wurde.
Schwierige Definition
Doch was KI eigentlich sein soll, ist nicht ganz leicht zu definieren. „Es kommt immer darauf an, wen man in welcher Situa­tion fragt, was künstliche Intelligenz sein soll“, sagt Lukas Daniel Klausner, der an der FH St. Pölten zu Data Science, Critical Algorithm Studies und Science and Technology Studies forscht. Schon der Begriff der „Intelligenz“ sei eigentlich umstritten, weil er ein Bild vermittle, mit dem aktuelle Technologien nicht mithalten können. Im weitesten Sinne bilden aber derzeit Machine Learning und ähnliche Konzepte die Grundlage für KI, so Klausner weiter. Machine Learning bedeutet, stark vereinfacht, dass eine KI in vorhandenen Daten nach Mustern und Gesetzmäßigkeiten sucht und sich selbst beibringt, wie sie eine Lösung findet. Ein wichtiger Aspekt dabei ist jedoch, dass immer Menschen der KI durch Daten und Algorithmen vorgeben, wie sie zu lernen hat und nach welchen Mustern und Lösungen sie eigentlich suchen soll. Der Lösungsweg selbst ist aber häufig undurchsichtig.


 KI ist immer dann problematisch,
wenn ihre Entscheidungen Auswirkungen auf Menschen hat. 

Astrid Schöggl, Digitalexpertin in der AK Wien

„Allerdings muss KI nicht zwingend auf Machine Learning basieren. Alle aussichtsreichen Ansätze gehen derzeit in diese Richtung, aber das muss nicht heißen, dass das weiterhin so bleibt“, sagt Klausner. Man kann KI auch dadurch abgrenzen, dass sie Entscheidungen trifft, die ihr nicht dezidiert vorgeschrieben wurden. Allerdings würden dadurch auch viele simplere Anwendungen in die Definition mit aufgenommen.
Zumindest ihr Ursprung kann leichter ergründet werden: In den USA wurde in den 1950er-Jahren „Artificial Intelligence“ als Forschungsfeld etabliert. Erste Computerprogramme konnten damals dank einfacher „Wenn-dann-Regeln“ simple Probleme lösen. Die Forscher*innen erwarteten, dass KI innerhalb von 20 Jahren jede Arbeit durchführen könnte.
Prognosen zu stellen, ist im Bereich der KI, wie man sieht, schwierig. Die damalige Hardware war den steigenden Anforderungen nicht gewachsen, bis in die neunziger Jahre schritt die Entwicklung nur langsam voran. Danach machte die Technologie rasante Fortschritte. Ein Grund dafür war die exponentiell steigende Rechenleistung. Aber ein wesentlicher Punkt war auch die Verfügbarkeit von großen Datenmengen. „Bis zu deren Aufkommen gab es nur die Möglichkeit, sich selbst zu überlegen, was die bestmögliche Lösung ist. Wenn ich genug Daten habe, kann ich aber Mustererkennung an den Computer auslagern“, erklärt Klausner.
KI braucht große Datenmengen. „Daten sind aber keine absolute Wahrheit – sie sind immer auch politisch“, warnt Wissenschafter Lukas Daniel Klausner.
Diskriminierende Daten
Und Daten bringen Probleme – noch bevor eine KI etwas gemacht hat. „Daten sind keine absolute Wahrheit – sie sind immer auch politisch“, so Klausner. Wer die Daten sammelt, welche das sind, wie sie aufbereitet werden und vor allem wie sie beurteilt werden, macht einen großen Unterschied.
Ein Beispiel dafür ist „Predictive Policing“. Dabei werden, vereinfacht gesagt, Vorhersagen darüber getroffen, wie hoch die Wahrscheinlichkeit für zukünftige Straftaten ist. Verschiedene Anwendungen sind vor allem in den USA im Einsatz – und die Grundlage dafür stammt aus kriminologischen Daten. „Diese kommen aus der bisherigen Arbeit der Polizei, die nicht frei von Bias und Diskriminierung ist. Und die Datenbasis enthält Dinge, die nicht der Rea­lität entsprechen, wenn man etwa bedenkt, dass Sexualverbrechen, rassistisch motivierte Straftaten oder auch Polizeigewalt weniger oft gemeldet werden“, sagt Klausner.
„KI ist immer dann problematisch, wenn ihre Entscheidungen Auswirkungen auf Menschen hat“, meint Astrid Schöggl. Beispiele dafür gibt es viele: In Washington gab es etwa den Versuch, dass eine KI die Leistung von Lehrer*innen bewertet und automatisch Kündigungsvorschläge erstellt. Und Amazon verwendete einen Bewerbungsalgorithmus, der Frauen strukturell benachteiligte. Solche Versuche werden aber nur dann publik, wenn sie abgestellt werden, so Schöggl.
Der Zukunftsfaktor
Werfen wir trotzdem einen Blick in die Zukunft – auch wenn Prognosen über KI schwierig sind: Sie ist in der Lage, Prozesse zu vereinfachen und zu automatisieren. Historisch gesehen, betraf die Automatisierung meistens einfachere Arbeiten, die durch Maschinen ersetzt wurden. Doch KI kann auch analytische Tätigkeiten ausführen, wodurch auch besser ausgebildete Menschen betroffen sein werden. So werden etwa immer mehr Versicherungsexpert*innen durch Software ersetzt.
„KI wird in der Lage sein, einzelne Tätigkeiten zu ersetzen“, sagt Schöggl. Das disruptive Potenzial von KI schätzt sie aber nicht so hoch ein. Denn KI ist nur in der Lage, sehr spezifische Arbeiten zu übernehmen. Menschliche Intelligenz kann sie (noch) nicht ersetzen.
Automatisierung könnte auch Erleichterungen mit sich bringen. Und weniger Arbeit kann im besten Fall zu einer höheren Lebensqualität für alle führen. „Dazu muss aber der politische Wille da sein. Es hat in den letzten dreißig Jahren schon einen massiven Produktivitätszuwachs gegeben – und der wurde nicht in Form von Arbeitszeitreduktion oder Lohnsteigerung weitergegeben“, sagt Klausner. Warum sollte das also in Zukunft anders werden?
Künstliche Intelligenz benötigt politische Lösungen, um Machtansammlung und -missbrauch zu verhindern. Und das nicht erst in der Zukunft, denn die Technologie ist schon längst im Einsatz. Über eine allmächtige, mörderische Intelligenz, die die Menschheit ausrotten will, können wir uns danach immer noch Gedanken machen.
 


Weiterlesen...




 


Regierung setzt Rotstift an: AMS-Budget um 95 Millionen gekürzt
4. Juli 2024Christian Domke Seidel

 


 


Per Klick zur Babysitterin: Ist Plattform-Sorgearbeit fair?
3. Juli 2024Eva Rottensteiner

 


 


Kommentar: Weniger nörgeln, mehr Industriepolitik
2. Juli 2024Nikolaus Kowall

 


 


Arbeitslosigkeit steigt im Juni 2024 um 10 Prozent
2. Juli 2024Christian Domke Seidel

 


Über den/die Autor:inAlle Beiträge


 

Sebastian Panny
Sebastian Panny ist Journalist und Historiker in Ausbildung aus Wien. Als solcher will der Exil-Oberösterreicher jene Prozesse, die sich hinter Geschichten und Geschichte abspielen, in den Vordergrund rücken – sofern er nicht auf Twitter festhängt.







",,,,,,"[{'@type': 'Article', '@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/#article', 'isPartOf': {'@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/'}, 'author': {'name': 'Sebastian Panny', '@id': 'https://www.arbeit-wirtschaft.at/#/schema/person/ee4ddedd79d6c8983fe4311952fea4cb'}, 'headline': 'Künstlich intelligent?', 'datePublished': '2020-09-14T08:32:02+00:00', 'dateModified': '2020-09-14T09:19:04+00:00', 'mainEntityOfPage': {'@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/'}, 'wordCount': 1210, 'publisher': {'@id': 'https://www.arbeit-wirtschaft.at/#organization'}, 'image': {'@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/#primaryimage'}, 'thumbnailUrl': 'https://www.arbeit-wirtschaft.at/wp-content/uploads/2020/09/cover1.jpg', 'inLanguage': 'de-DE'}, {'@type': 'WebPage', '@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/', 'url': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/', 'name': 'Künstlich intelligent? - Arbeit&amp;Wirtschaft', 'isPartOf': {'@id': 'https://www.arbeit-wirtschaft.at/#website'}, 'primaryImageOfPage': {'@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/#primaryimage'}, 'image': {'@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/#primaryimage'}, 'thumbnailUrl': 'https://www.arbeit-wirtschaft.at/wp-content/uploads/2020/09/cover1.jpg', 'datePublished': '2020-09-14T08:32:02+00:00', 'dateModified': '2020-09-14T09:19:04+00:00', 'description': 'Das Magazin für Wirtschaft-, Sozial- und Gesellschaftspolitik.', 'breadcrumb': {'@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/#breadcrumb'}, 'inLanguage': 'de-DE', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/']}]}, {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/#primaryimage', 'url': 'https://www.arbeit-wirtschaft.at/wp-content/uploads/2020/09/cover1.jpg', 'contentUrl': 'https://www.arbeit-wirtschaft.at/wp-content/uploads/2020/09/cover1.jpg', 'width': 1920, 'height': 1280, 'caption': 'Illustration künstliche Intelligenz'}, {'@type': 'BreadcrumbList', '@id': 'https://www.arbeit-wirtschaft.at/kuenstlich-intelligent/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Startseite', 'item': 'https://www.arbeit-wirtschaft.at/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Künstlich intelligent?'}]}, {'@type': 'WebSite', '@id': 'https://www.arbeit-wirtschaft.at/#website', 'url': 'https://www.arbeit-wirtschaft.at/', 'name': 'Arbeit&amp;Wirtschaft', 'description': '', 'publisher': {'@id': 'https://www.arbeit-wirtschaft.at/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.arbeit-wirtschaft.at/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'de-DE'}, {'@type': 'Organization', '@id': 'https://www.arbeit-wirtschaft.at/#organization', 'name': 'Arbeit&Wirtschaft', 'url': 'https://www.arbeit-wirtschaft.at/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://www.arbeit-wirtschaft.at/#/schema/logo/image/', 'url': 'https://www.arbeit-wirtschaft.at/wp-content/uploads/2020/12/AWOM-Google-hell.png', 'contentUrl': 'https://www.arbeit-wirtschaft.at/wp-content/uploads/2020/12/AWOM-Google-hell.png', 'width': 400, 'height': 55, 'caption': 'Arbeit&Wirtschaft'}, 'image': {'@id': 'https://www.arbeit-wirtschaft.at/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/AundWMagazin', 'https://x.com/AundWMagazin', 'https://www.instagram.com/aundwmagazin/']}, {'@type': 'Person', '@id': 'https://www.arbeit-wirtschaft.at/#/schema/person/ee4ddedd79d6c8983fe4311952fea4cb', 'name': 'Sebastian Panny', 'image': {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://www.arbeit-wirtschaft.at/#/schema/person/image/', 'url': 'https://www.arbeit-wirtschaft.at/wp-content/uploads/2020/09/panny-1-150x150.jpeg', 'contentUrl': 'https://www.arbeit-wirtschaft.at/wp-content/uploads/2020/09/panny-1-150x150.jpeg', 'caption': 'Sebastian Panny'}, 'description': 'Sebastian Panny ist Journalist und Historiker in Ausbildung aus Wien. Als solcher will der Exil-Oberösterreicher jene Prozesse, die sich hinter Geschichten und Geschichte abspielen, in den Vordergrund rücken – sofern er nicht auf Twitter festhängt.', 'sameAs': ['https://x.com/https://twitter.com/Sepsndepsn'], 'url': 'https://www.arbeit-wirtschaft.at/author/sebastian-panny/'}]"
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3LnNyZi5jaC93aXNzZW4va3VlbnN0bGljaGUtaW50ZWxsaWdlbnovZGVlcGZha2VzLWt1ZW5zdGxpY2hlLWludGVsbGlnZW56LXNvbGwtbWFuaXB1bGllcnRlLWJpbGRlci1hdWZzcHVlcmVu0gEA?oc=5,Deepfakes - Künstliche Intelligenz soll manipulierte Bilder aufspüren - SRF – Schweizer Radio und Fernsehen,2020-09-14,SRF – Schweizer Radio und Fernsehen,https://www.srf.ch,Raffinierte Fälschungen in Videos und Bildern sollen zukünftig mithilfe von Deepfake-Detektoren entlarvt werden können.,N/A,Raffinierte Fälschungen in Videos und Bildern sollen zukünftig mithilfe von Deepfake-Detektoren entlarvt werden können.,Raffinierte Fälschungen in Videos und Bildern sollen zukünftig mithilfe von Deepfake-Detektoren entlarvt werden können.,,,,,,,,,,,,,,,,,,,Wissen,N/A,"



Wissen





Künstliche Intelligenz




Inhalt










Deepfakes
 - 
Künstliche Intelligenz soll manipulierte Bilder aufspüren

Gefälschte Bilder und Videos werden immer raffinierter. Wissenschaftler arbeiten jetzt an Lösungen, solche Deepfakes schnell erkennen zu können.


Autor: 

Christian Bachmann


Montag, 14.09.2020, 08:26 Uhr









Klicken, um die Teilen-Funktion zu öffnen.




Teilen



Zu den Kommentaren springen.


Anzahl Kommentare: 
2








Teilen


Schliessen
















Auf Facebook teilen
Facebook









Auf X teilen
X









Per WhatsApp teilen
WhatsApp









Per E-Mail teilen
E-Mail









Link kopieren
Link kopieren














Deepfakes wirken authentisch – sind es aber nicht. Die mithilfe von künstlicher Intelligenz erstellten Bilder oder Videos, lassen jemanden etwas sagen, das er oder sie so nie ausgesprochen hat. Sie führen Bewegungen aus, die nie geschehen sind.Was als scheinbar harmlose Spielerei angefangen hat, wandelt sich mehr und mehr zur politischen Waffe. Deepfakes werden vom harmlosen Bild-Schabernack zum Instrument eines schwer durchschaubaren Identitätsdiebstahls.









 













Audio
Die raffinierte Lüge, Teil 3: Deepfakes – gefährlich/überschätzt?

27:48 min, aus News Plus Hintergründe vom 21.05.2020.
                                                            
                                                            Bild: SRF

abspielen. Laufzeit 27 Minuten 48 Sekunden.








Erkennt bald keiner mehr den Unterschied?Ein Zeichen der Zeit. Denn dank der rasanten Entwicklung von künstlicher Intelligenz und dem maschinellen Lernen sind die manipulierten Inhalte heute qualitativ besser und vor allem: viel einfacher zu produzieren.«Noch vor sechs Monaten waren Deepfakes sehr einfach zu durchschauen. Man sah in Videos schnell, dass irgendetwas manipuliert ist. Ich behaupte aber, dass in weniger als neun Monaten 99.9 Prozent der Leute nicht mehr in der Lage sein werden, einen wirklich guten Deepfake zu erkennen», sagt Touradj Ebrahimi, IT-Professor an der EPFL.Wozu die Technik zur Erstellung solcher Inhalte heute schon in der Lage ist, zeigt ein Besuch bei Deepfake-Spezialisten an der ETH Lausanne.

Vorhergehendes Bild



        1 / 3


Legende:

                Deepfakes aufspüren
            

                Bei sogenannten «Face-Swap-Fakes» zeigt die Software der EPFL-Experten mit einem Ampel-System an, ob ein Video manipuliert ist.
            

                    SRF
                






        2 / 3


Legende:

                Unsichtbare Fehler sichtbar machen
            

                Verschiedene Methoden helfen, Bildmanipulationen schneller und zuverlässiger zu erkennen.
            

                    Quantum Integrity
                






        3 / 3


Legende:

                Manipulierte Bilder entlarven
            

                Spezifische Marker geben sofort Aufschluss darüber, ob ein Bild manipuliert wurde. 
            

                    SRF
                


Nächstes Bild



Deepfake 2.0Ein IT-Experte lädt sich das offizielle Profilbild des «Einstein»-Moderators Tobias Müller von der SRF-Website auf seinen Laptop. Ein Programm analysiert dieses passbildgrosse Foto von Müller kurz.Wenige Sekunden später kann der Experte das Foto von Tobias Müller mit seiner eigenen Mimik komplett fernsteuern, indem er sich mit der Kamera seines Laptops filmt. Über Video-Call ruft er jemanden an – und für das Gegenüber scheint es, als würde Tobias Müller mit ihm sprechen.Das kleine Experiment zeigt: Mit technischem Know-How reicht ein einziges Foto heute als Ausgangsmaterial aus, um einen glaubwürdigen Deepfake zu produzieren.









 













Audio
Die Wirkkraft von «Fake News»

13:10 min, aus Kontext vom 04.08.2019.
                                                            
                                                            Bild: Jakob Börner

abspielen. Laufzeit 13 Minuten 10 Sekunden.








Die Deepfake-DetektorenAuch deshalb forscht das Experten-Team um Touradj Ebrahimi, Professor für Informatik an der EPFL, an einer Technik, die Deepfakes automatisch entlarven soll: einem Deepfake-Detektor. Dafür müssen sie selbst zu Deepfake-Experten werden.Um spezifische Anomalien in Deepfakes aufzuspüren, nutzen die Experten die Mittel künstlicher Intelligenz. Die Idee dahinter: Die Deepfake-Detektoren sollen Marker erkennen können, also Anomalien in Bildern oder Videos, die oft überhaupt erst maschinell erzeugt werden und auch nur so zu aufzuspüren sind.Damit liesse sich eine Software bauen, die Manipulationen auf gefälschten Videos und Bildern schnell und autonom erkennt.

        Passend zum Thema
    






            Hinweis auf einen verwandten Artikel:
        


Künstliche Intelligenz
Die Schweiz im Sog der Algorithmen


                28.07.2019
    

                Mit Video
     







Doch die Deepfakes sind mehr als hinterlistige, gefälschte Videos, die jemanden etwas sagen lassen, das er oder sie so nie gesagt hat. Sie sind längst auch in der legalen Wirtschaft angekommen: Immer mehr künstlich erzeugte Gesichter und Avatare bevölkern die Werbewelt. In Kinofilmen spielen Schauspielerinnen und Schauspieler nun auch noch ihr künstlich-erstelltes junges Alter Ego. Beides sind Milliarden-Industrien.
Schweizer Startup gegen FälschungenDas Missbrauch-Potenzial von Deepfake-Techniken treibt die Forschung an. Fake-Detektoren könnten etwa bei Versicherungsbetrug helfen, falsche Unfallbilder zu entlarven. Überall, wo eindeutige Kundenidentifikation wichtig ist, könnten die Tools die Echtheit von Dokumenten verifizieren. Auch von elektronisch eingereichten.Aus dieser Forschung der EPFL entsteht derzeit ein Schweizer Spin-Off, die Firma «Quantum Integrity». Sie will künftig spezialisierte KI-Software einsetzen, um alle Arten von Deepfakes zu detektieren. Potenzial sehen die Gründer vor allem im Bereich von Versicherungsfällen und überall dort, wo die Identität von Personen maximal geschützt werden muss.



                            SRF1, Einstein, 10.09.2020, 21:05 Uhr.
                                                




Klicken, um die Teilen-Funktion zu öffnen.




Teilen



Zu den Kommentaren springen.


Anzahl Kommentare: 
2








Teilen


Schliessen
















Auf Facebook teilen
Facebook









Auf X teilen
X









Per WhatsApp teilen
WhatsApp









Per E-Mail teilen
E-Mail









Link kopieren
Link kopieren










Wissen





Künstliche Intelligenz










",,,,,,

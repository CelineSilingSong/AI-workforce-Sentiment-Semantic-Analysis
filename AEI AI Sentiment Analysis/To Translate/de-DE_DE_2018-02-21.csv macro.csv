URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,dateModified,publisher,datePublished,@context,@type,headline,image,mainEntityOfPage,author,article:section,article:summary,article text,about,articleBody,articleSection,dateCreated,url,wordCount,alternativeHeadline,timeRequired,isAccessibleForFree,copyrightYear,copyrightHolder,itemListElement
https://news.google.com/rss/articles/CBMiPmh0dHBzOi8vd3d3LmNpby5kZS9hL2tpLXJldm9sdXRpb25pZXJ0LWRhcy1zdGV1ZXJ3ZXNlbiwzNTYzOTIx0gFCaHR0cHM6Ly93d3cuY2lvLmRlL2EvYW1wL2tpLXJldm9sdXRpb25pZXJ0LWRhcy1zdGV1ZXJ3ZXNlbiwzNTYzOTIx?oc=5,KI revolutioniert das Steuerwesen - CIO,2018-02-22,CIO,https://www.cio.de,"Ob Umsatzsteuer, Risiko-Management oder Zoll ‚Äì k√ºnftig werden KI-Systeme Arbeiten von Steuerfachleuten √ºbernehmen. Diese These stammt vom Deutschen Forschungszentrum f√ºr K√ºnstliche Intelligenz (DFKI).","K√ºnstliche Intelligenz (KI), Steuer, Wolfgang Wahlster, DFKI, Maschinelles Lernen","Ob Umsatzsteuer, Risiko-Management oder Zoll ‚Äì k√ºnftig werden KI-Systeme Arbeiten von Steuerfachleuten √ºbernehmen. Diese These stammt vom Deutschen Forschungszentrum f√ºr K√ºnstliche Intelligenz (DFKI).","Ob Umsatzsteuer, Risiko-Management oder Zoll ‚Äì k√ºnftig werden KI-Systeme Arbeiten von Steuerfachleuten √ºbernehmen. Diese These stammt vom Deutschen Forschungszentrum f√ºr K√ºnstliche Intelligenz (DFKI).",2018-02-22T08:10:00Z,"{'@type': 'Organization', 'logo': {'height': 57, '@type': 'ImageObject', 'url': 'https://www.cio.de/includes/images/amp/logo/CIO.png', 'width': 182}, 'name': 'CIO'}",2018-02-22T08:10:00Z,http://schema.org,NewsArticle,KI revolutioniert das Steuerwesen,"{'height': 675, '@type': 'ImageObject', 'url': 'https://images.cio.de/bdb/2682752/1200x.jpg', 'width': 1200}","{'@type': 'WebPage', '@id': 'https://www.cio.de/a/ki-revolutioniert-das-steuerwesen,3563921'}","[{'@type': 'Person', 'name': 'Christiane P√ºtter'}]",N/A,N/A,"K√ºnstliche IntelligenzKI revolutioniert das Steuerwesen Drucken22.02.2018Von¬†Christiane¬†P√ºtter¬†(Autor)¬†












Christiane P√ºtter ist Journalistin aus M√ºnchen.







Weitere Artikel des Autors






Ob Umsatzsteuer, Risiko-Management oder Zoll ‚Äì k√ºnftig werden KI-Systeme Arbeiten von Steuerfachleuten √ºbernehmen. Diese These stammt vom Deutschen Forschungszentrum f√ºr K√ºnstliche Intelligenz (DFKI).




Anwendungsszenarien wurden mit Audi, Bosch sowie Eon und Henkel durchgespielt.
Daraus leitet das DFKI sechs Einsatzfelder ab.
KI-Systeme k√∂nnen Steuerfachleuten auch komplexe Routinearbeiten abnehmen, sofern diese wenig soziale Intelligenz, Kreativit√§t und Umgebungsinteraktionen erfordern.
Machine Learning, Process Mining, Informationsextraktion, Wissensmanagement, Sprachverarbeitung und multimodale Systeme kommen zum Einsatz.




 Empfehlen Twitter
 Facebook
 Xing
 LinkedIn
 Feedback
 DruckenDas Deutschen Forschungszentrum f√ºr K√ºnstliche Intelligenz (DFKI) identifiziert in der Studie ""K√ºnstliche Intelligenz im Steuerbereich"" sieben Bereiche, in denen KI-Systeme Arbeiten von Steuerkanzlei und Steuerverantwortlichen in den Firmen √ºbernehmen k√∂nnten. Die Analyse entstand auf Initiatve des M√ºnchener Steuerberaters WTS und versteht sich als exploratives Thesenpapier.AdChoicesADVERTISINGDas Deutsche Forschungszentrum f√ºr K√ºnstliche Intelligenz (DFKI) und der Berater WTS skizzieren den Steuerarbeitsplatz der Zukunft.Foto: DFKI/WTS GroupProfessor Wolfgang Wahlster erwartet ""in nicht allzu ferner Zukunft"" Stellenanzeigen wie ""KI¬≠-Experten dringend gesucht: Einsatzbereich Steuerabteilung"". Er spricht von einer Revolution im Steuerbereich. Konkret geht es um die Felder Lohnsteuer, Umsatzsteuer und K√∂rperschaftssteuer sowie Zoll, Verrechnungspreise, Risiko-Management und International Tax. Diese k√∂nnten k√ºnftig durch Machine LearningMachine Learning, Process Mining, Informationsextraktion, Wissensmanagement, Sprachverarbeitung und multimodale Systeme unterst√ºtzt werden.
Alles zu Machine Learning auf CIO.de
Sechs Einsatzbereiche mit Anwendern definiertDie Studienautoren sehen sich nicht als reine Theoretiker, daher haben sie nach eigenen Angaben in vier Konzernen - AudiAudi, BoschBosch, EonEon und HenkelHenkel - bereits Anwendungsszenarien durchgespielt. Daraus leiten sie einen ""Steuerarbeitsplatz der Zukunft"" ab. Kanzleien und Steuerabteilungen in den Unternehmen k√∂nnten K√ºnstliche Intelligenz in sechs Punkten einsetzen:
Top-500-Firmenprofil f√ºr Audi
Top-500-Firmenprofil f√ºr Bosch
Top-500-Firmenprofil f√ºr EON
Top-500-Firmenprofil f√ºr Henkel AG & Co. KGaA1. Erkennung von Anomalien bei der Ausnutzung von Freihandelsabkommen im Bereich Zoll2. Automatisierte Zuteilung von Steuerkennzeichen und Identifizierung von Inkonsistenzen bei der Zuweisung3. Pr√ºfung des Quellensteuerabzugs nach dem Paragrafen 50 a Einkommenssteuergesetz4. Pr√ºfung von Rechnungen im Bereich Umsatzsteuer5. Anomalie-Erkennung in Massendaten im Bereich Umsatzsteuer6. Intelligente Steuerassistenz im Bereich LohnsteuerBeispiel f√ºr eine AnwendungDazu liefern die Forscher einen Use Case: Werden Waren zolltariflich angemeldet, k√∂nnen KI-Technologien zur Informationsextraktion unterst√ºtzen, konkret mittels Text Mining in Verbindung mit optischer Zeichenerkennung. Das entspricht einer intelligenten Automatisierung von Routineaufgaben, die vergleichsweise komplex sind, aber nur geringe soziale Intelligenz, Kreativit√§t und Umgebungsinteraktionen erfordern. Professor Peter Fettke, der die Studie geleitet hat, betont: ""In der steuerlichen Gestaltungs- und Durchsetzungsberatung ist es hingegen aktuell nicht vorstellbar, dass die Steuerberatung vollst√§ndig durch intelligente Steuerl√∂sungen ersetzt wird.""Die Forscher schildern modellhaft, wie KI unterst√ºtzen kann.Foto: DFKI/WTS GroupEin weiterer Use Case dreht sich um Sachzuwendungen im Bereich Lohnsteuer, die der Steuerberater beurteilen muss. KI-L√∂sungen k√∂nnen ihn bei der Dokumentenanalyse, Informationsextraktion und Klassifikation unstrukturierter transaktionaler Daten unterst√ºtzen.Machine Learning - Technologien und Status quo1/17Bilderkennung ist wichtigstes Anwendungsgebiet f√ºr Machine LearningHeute kommen Machine-Learning-Algorithmen vor allem im Bereich der Bildanalyse und -erkennung zum Einsatz. In Zukunft werden Spracherkennung und -verarbeitung wichtiger.Foto: Crisp Research, KasselDas DFKI h√§lt ""enorme Produktivit√§tssteigerungen und Qualit√§tsverbesserungen"" f√ºr m√∂glich. Demzufolge seien ""weitreichende Ver√§nderungen des T√§tigkeitsspektrums innerhalb der Steuerberatung zu erwarten"". Wahlster, Fettke und ihre Kollegen k√ºndigen an, auf diesem Gebiet weiterzuforschen.√óCloseFeedback geben Zum ThemaK√ºnstliche Intelligenz beim Onlineh√§ndler Otto: Keine Angst: KI ist auch nur SoftwareVerst√§ndnis fehlt: K√ºnstliche Intelligenz scheitert an MitarbeiternMcKinsey-Studie: Noch viele Vorbehalte gegen K√ºnstliche Intelligenz Artikel als PDF kaufenDie Rechte an diesem Artikel kaufen√óCloseErwerben Sie die Rechte an diesem ArtikelWenn Sie Artikel von CIO, Computerwoche, TecChannel oder Channelpartner f√ºr eine kommerzielle Vervielf√§ltigung nutzen wollen, m√ºssen Sie eine Lizenz erwerben.Bitte wenden Sie sich dazu an unseren Partner, die YGS Group (E-Mail: IDGLicensing@theygsgroup.com)



Links zum Artikel
Thema:
Machine Learning
Top500-Firmenprofile:
Audi, Bosch, EON und Henkel AG & Co. KGaA


Meistgelesen













Drogen, Geiz, Kinder




10 Geheimnisse von Steve Jobs




















1 % Regelung, Fahrtenbuch, Privatnutzung




Firmenwagen FAQ - was Sie wissen m√ºssen

















Kostenlose Newsletter







Best Practices



Cloud



First Look



Generative AI in Unternehmen



Leader



Security






Bestellen






",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LnN1ZWRkZXV0c2NoZS5kZS93aXJ0c2NoYWZ0L3RlY2hub2xvZ2llLWZ1ZWhyZW5kZS1mb3JzY2hlci13YXJuZW4tdm9yLWt1ZW5zdGxpY2hlci1pbnRlbGxpZ2Vuei0xLjM4Nzg2NjnSAQA?oc=5,F√ºhrende Forscher warnen vor k√ºnstlicher Intelligenz - Wirtschaft - SZ.de - S√ºddeutsche Zeitung - SZ.de,2018-02-22,S√ºddeutsche Zeitung - SZ.de,https://www.sueddeutsche.de,,"Technologie,Technologie,Wirtschaft,S√ºddeutsche Zeitung",,N/A,2018-02-22 13:27:35,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'height': '64', 'url': 'https://www.sueddeutsche.de/szde-assets/img/szde-article-sueddeutsche-logo.svg', 'width': '525'}, 'name': 'S√ºddeutsche Zeitung'}",2018-02-22T13:17:25.000Z,https://schema.org,NewsArticle,F√ºhrende Forscher warnen vor k√ºnstlicher Intelligenz,"{'@type': 'ImageObject', 'height': '675', 'url': 'https://www.sueddeutsche.de/2022/06/14/153a488d-75de-41f7-9435-6ea7037198ab.jpeg?q=60&fm=webp&width=1200&rect=65%2C62%2C727%2C409', 'width': '1200'}",https://www.sueddeutsche.de/wirtschaft/technologie-fuehrende-forscher-warnen-vor-kuenstlicher-intelligenz-1.3878669,"[{'@type': 'Person', 'name': 'Andrian Kreye', 'sameAs': '/autoren/andrian-kreye-1.1143143'}]",N/A,N/A,"Technologie:F√ºhrende Forscher warnen vor k√ºnstlicher Intelligenz22. Februar 2018, 14:17 UhrLesezeit: 1 minDetailansicht √∂ffnenGegen Schachcomputer haben Menschen l√§ngst keine Chance mehr. Was kommt als n√§chstes? (Foto: agsandrew - Fotolia)Eine Gruppe hochrangiger Experten warnt vor den Gefahren f√ºr die Gesellschaft, die durch k√ºnstliche Intelligenz entstehen k√∂nnen.Zu der Gruppe geh√∂ren unter anderen Forscher der Universit√§ten Stanford, Yale, Oxford und Tohoku sowie Entwickler von Microsoft und Google.Die Entwicklung der KI sei an einem Punkt, an dem der Mensch noch eingreifen k√∂nne - wenn Politiker, Forscher und Unternehmer zusammenarbeiten.Von Andrian KreyeMerkenTeilenFeedbackDruckenWenn f√ºhrende Forscher und Entwickler ein Moratorium f√ºr die Weiterentwicklung k√ºnstlicher Intelligenz (KI) fordern, ist das nicht der √ºbliche Alarmismus. So ver√∂ffentlichte eine Projektgruppe solcher Fachleute eine Arbeit mit dem Titel ""The Malicious Use of Artificial Intelligence"" ( ""B√∂sartige Nutzungen K√ºnstlicher Intelligenz""). Zu der Gruppe geh√∂ren unter anderen die Universit√§ten Stanford, Yale, Oxford und Tohoku sowie Entwickler von Microsoft, Google und dessen Tochterfirma, des momentan f√ºhrenden KI-Unternehmens DeepMind.Im Unterschied zu den oft prominenten Vertretern der KI-Panik haben sich die Forscher bei ihrem Projekt ausschlie√ülich auf Technologien konzentriert, die es entweder schon gibt, oder die nach aktuellem Stand der Entwicklung in den kommenden f√ºnf Jahren anwendbar sein werden. Bisher geh√∂rte ein gro√üer Teil der KI-Kritik eher in die literarischen Sph√§ren der dystopischen Science Fiction. Solche Szenarien stammen zum Beispiel vom Physiker Stephen Hawking, dem Philosophen Nick Bostrom und dem Unternehmer Elon Musk - keiner von ihnen hat sich jemals wissenschaftlich an der Entwicklung von KI¬†beteiligt.Eines der konkreten Beispiele, das die Forscher in ihrem Aufruf nennen, ist die Entwicklung der Bilderkennung und -generierung durch KI. Die war 2014 noch auf dem Stand, dass sie nur grauschleierige Phantombilder schaffen konnte. Inzwischen ist es mit so genannten Deep-Fake-Technologien m√∂glich, Gesichter mit glaubhafter Mimik in Videos auf fremde K√∂rper zu √ºbertragen. Das wiederum sei angesichts der j√ºngeren Geschichte politischer Manipulationen eine Form destruktiver KI-Anwendung, der man nur schwer Einhalt gebieten¬†k√∂nne.Die M√∂glichkeiten solchen Missbrauchs reichen schon jetzt und in naher Zukunft von ungeahnten Dimensionen des Hacking (nicht nur von Rechnern, sondern auch von KI-getriebenen Systemen wie Drohnen, Fahrzeugen, Robotern oder autonomen Waffen), bis zu einem Wettr√ºsten in allen Fragen der Cyber-Sicherheit, die sie in digitale, physische und politische Sicherheit¬†unterteilen.L√∂sungen schlagen die Experten auch vor. K√ºnstliche Intelligenzen zu zentralisieren, w√§re eine M√∂glichkeit, Missbrauch vorzubeugen. Sie erinnern aber auch an die Garmischer Nato-Konferenz von 1968, bei der Grundlagen zur Software-Entwicklung festgelegt wurden, die heute noch Norm sind, und an das Moratorium, das die biologische Forschung 1975 im kalifornischen Asilomar ausgerufen hat (und das derzeit in der Genforschung als Grundlage f√ºr neue Selbstbeschr√§nkungen genutzt wird). Die Mahner geben sich sogar optimistisch: Die Entwicklung der KI sei an einem Punkt, an dem man noch gemeinsam eingreifen k√∂nne. Aber das m√ºsse eben jetzt geschehen.¬†Jetzt!¬© SZ.de - Rechte am Artikel k√∂nnen Sie hier erwerben.TeilenFeedbackDruckenZur SZ-StartseiteManipulierte Porno-Videos:Menschen m√ºssen aufh√∂ren, ihren Augen zu trauenEine App erm√∂glicht es Laien, Gesichter von Prominenten in Hardcore-Pornos zu montieren. Das erschreckend perfekte Ergebnis ersch√ºttert die Glaubw√ºrdigkeit von Bildern und Videos.Von Bernd GraffLesen Sie mehr zum ThemaTechnologie",Technologie,"Wenn f√ºhrende Forscher und Entwickler ein Moratorium f√ºr die Weiterentwicklung k√ºnstlicher Intelligenz (KI) fordern, ist das nicht der  √ºbliche Alarmismus . So ver√∂ffentlichte eine Projektgruppe solcher Fachleute eine Arbeit mit dem Titel ""The Malicious Use of Artificial Intelligence"" (  ""B√∂sartige Nutzungen K√ºnstlicher Intelligenz"" ). Zu der Gruppe geh√∂ren unter anderen die Universit√§ten Stanford, Yale, Oxford und Tohoku sowie Entwickler von Microsoft, Google und dessen Tochterfirma, des momentan f√ºhrenden KI-Unternehmens  DeepMind .
Im Unterschied zu den oft prominenten Vertretern der KI-Panik haben sich die Forscher bei ihrem Projekt ausschlie√ülich auf Technologien konzentriert, die es entweder schon gibt, oder die nach aktuellem Stand der Entwicklung in den kommenden f√ºnf Jahren anwendbar sein werden. Bisher geh√∂rte ein gro√üer Teil der KI-Kritik eher in die literarischen Sph√§ren der dystopischen Science Fiction. Solche Szenarien stammen zum Beispiel vom Physiker Stephen Hawking, dem Philosophen Nick Bostrom und dem Unternehmer Elon Musk - keiner von ihnen hat sich jemals wissenschaftlich an der Entwicklung von KI¬†beteiligt.
Eines der konkreten Beispiele, das die Forscher in ihrem Aufruf nennen, ist die Entwicklung der Bilderkennung und -generierung durch KI. Die war 2014 noch auf dem Stand, dass sie nur grauschleierige Phantombilder schaffen konnte. Inzwischen  ist es mit so genannten Deep-Fake-Technologien m√∂glich , Gesichter mit glaubhafter Mimik in Videos auf fremde K√∂rper zu √ºbertragen. Das wiederum sei angesichts der j√ºngeren Geschichte politischer Manipulationen eine Form destruktiver KI-Anwendung, der man nur schwer Einhalt gebieten¬†k√∂nne.
Die M√∂glichkeiten solchen Missbrauchs reichen schon jetzt und in naher Zukunft von ungeahnten Dimensionen des Hacking (nicht nur von Rechnern, sondern auch von KI-getriebenen Systemen wie Drohnen, Fahrzeugen, Robotern oder autonomen Waffen), bis zu einem Wettr√ºsten in allen Fragen der Cyber-Sicherheit, die sie in digitale, physische und politische Sicherheit¬†unterteilen.
L√∂sungen schlagen die Experten auch vor. K√ºnstliche Intelligenzen zu zentralisieren, w√§re eine M√∂glichkeit, Missbrauch vorzubeugen. Sie erinnern aber auch an die Garmischer Nato-Konferenz von 1968, bei der Grundlagen zur Software-Entwicklung festgelegt wurden, die heute noch Norm sind, und an das Moratorium, das die biologische Forschung 1975 im kalifornischen Asilomar ausgerufen hat (und das derzeit in der Genforschung als Grundlage f√ºr neue Selbstbeschr√§nkungen genutzt wird). Die Mahner geben sich sogar optimistisch: Die Entwicklung der KI sei an einem Punkt, an dem man noch gemeinsam eingreifen k√∂nne. Aber das m√ºsse eben jetzt geschehen.¬†Jetzt!",Wirtschaft,2018-02-22T13:17:25.000Z,https://www.sueddeutsche.de/wirtschaft/technologie-fuehrende-forscher-warnen-vor-kuenstlicher-intelligenz-1.3878669,371.0,F√ºhrende Forscher warnen vor k√ºnstlicher Intelligenz,PT1M,,,,
https://news.google.com/rss/articles/CBMiNmh0dHBzOi8vdDNuLmRlL25ld3Mva2ktZnVlci1zY2hhZWRsaWNoZS16d2Vja2UtOTU3NDQxL9IBAA?oc=5,Wie KI f√ºr sch√§dliche Zwecke missbraucht werden kann ‚Äì und was wir dagegen tun k√∂nnen - t3n ‚Äì digital pioneers,2018-02-24,t3n ‚Äì digital pioneers,https://t3n.de,"In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch k√ºnstliche Intelligenz m√∂g",N/A,"In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch k√ºnstliche Intelligenz m√∂glich werden, und welche ...","In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch k√ºnstliche Intelligenz m√∂glich werden, und welche ...",2021-08-13T06:13:14+0200,"{'@type': 'Organization', 'name': 't3n Magazin', 'logo': {'@type': 'ImageObject', 'url': 'https://t3n.de/news/wp-content/uploads/2020/11/t3n-logo-google-news-rot-400px.png', 'width': 401, 'height': 130}}",2018-02-24T06:00:24+0100,https://schema.org,BreadcrumbList,Wie KI f√ºr sch√§dliche Zwecke missbraucht werden kann ‚Äì und was wir dagegen tun k√∂nnen,"[{'@type': 'ImageObject', 'url': 'https://images.t3n.de/news/wp-content/uploads/2018/02/ki-sicherheit.jpg?class=structuredData-large', 'width': 1200}, {'@type': 'ImageObject', 'url': 'https://images.t3n.de/news/wp-content/uploads/2018/02/ki-sicherheit.jpg?class=structuredData-medium', 'width': 1200}, {'@type': 'ImageObject', 'url': 'https://images.t3n.de/news/wp-content/uploads/2018/02/ki-sicherheit.jpg?class=structuredData-small', 'width': 1200}]","{'@type': 'WebPage', '@id': 'https://t3n.de/news/ki-fuer-schaedliche-zwecke-957441/'}","{'@type': 'Person', '@id': 'https://t3n.de/redaktion/kim-rixecker#person', 'name': 'Kim Rixecker', 'jobTitle': 'Redakteur Software & Chef vom Dienst'}",N/A,N/A,"





Home





News





Buzz & Memes





Wie KI f√ºr sch√§dliche Zwecke missbraucht werden kann ‚Äì und was wir dagegen tun k√∂nnen






                            News
                    


                    Wie KI f√ºr sch√§dliche Zwecke missbraucht werden kann ‚Äì und was wir dagegen tun k√∂nnen
                

                                                                
In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch k√ºnstliche Intelligenz m√∂glich werden, und welche Schritte schon jetzt unternommen werden sollten, um einem Missbrauch der Technologie vorzubeugen.
                                    

                                Von Kim Rixecker




24.02.2018, 06:00 Uhr 

                                ‚Ä¢
                            

 2 Min.
                            











Artikel merken





Anzeige

Anzeige













(Foto: Shutterstock)






Im Februar 2017 trafen sich KI-Experten verschiedener Universit√§ten, der digitalen B√ºrgerrechtsorganisation Electronic-Frontier-Foundation und der gemeinn√ºtzigen KI-Organisation OpenAI in Oxford, um m√∂gliche Gefahren zu er√∂rtern, die der Fortschritt der Technologie mit sich bringen k√∂nnte. Jetzt, ein Jahr sp√§ter, haben sie ihre Erkenntnisse in einem mehr als hundert Seiten starken Dokument ver√∂ffentlicht.
AnzeigeAnzeigeIn ihrem Paper gehen die Autoren auf unterschiedliche Szenarien ein, bei denen k√ºnstliche Intelligenz im und au√üerhalb des Internets daf√ºr genutzt werden k√∂nnte, um Menschen gezielt zu schaden. Eine m√∂gliche Gefahr sehen die Experten beispielsweise darin, dass KI kriminelle Hacker bei ihrer Arbeit unterst√ºtzen k√∂nnte.
Das ist nat√ºrlich l√§ngst keine Zukunftsvision mehr, da schon jetzt bisweilen mehr oder minder clevere Bots dazu genutzt werden, pers√∂nliche Daten von Nutzern zu erlangen. Auch beim Knacken von Passw√∂rtern kommen allm√§hlich KI-Systeme zum Einsatz. Zuk√ºnftig, so die Autoren, d√ºrfte sich das Problem aber noch deutlich steigern.AnzeigeAnzeige

Von Drohnenangriffen zur staatlichen √úberwachung

Auch bei physischen Angriffen auf die Bev√∂lkerung k√∂nnten KI-Systeme beteiligt sein. Die Forscher denken hier beispielsweise an Luftangriffe mit Hilfe kommerzieller Drohnen. Intelligente Software k√∂nnte Terroristen und Kriminelle aber auch generell bei der Durchf√ºhrung von Angriffen unterst√ºtzen. So k√∂nnten Modelle entwickelt werden, die kleinen Gruppen dabei helfen, mit gegebenen Mitteln einen m√∂glichst gro√üen Schaden anzurichten.AnzeigeAnzeige
Gleichzeitig warnen die Forscher auch davor, wie KI-Systeme bei der √úberwachung der Bev√∂lkerung durch Staatsorgane eingesetzt werden k√∂nnten. Als m√∂gliches Bedrohungsszenario nennen die Autoren an der Stelle auch den Einsatz von KI-Systemen zum Aufsp√ºren und Unterdr√ºckung abweichender Meinungen.

Forscher fordern mehr Offenheit bei der KI-Entwicklung

Nach Meinung der Autoren des Papers m√ºssen Forschung, Gesellschaft und Staat gemeinsam daran arbeiten, Schutzmechanismen gegen die verschiedenen Bedrohungen zu entwickeln. Kollegen aus Forschung und Entwicklung raten die Autoren, auch Experten aus anderen Forschungsbereichen miteinzubeziehen und fordern au√üerdem grunds√§tzlich mehr Offenheit und Austausch. Au√üerdem sollte der potenzielle Missbrauch von Technologien auch Einfluss auf die Forschungspriorit√§ten und -standards haben.AnzeigeAnzeige
Regierungen wiederum wird geraten, eng mit der Forschergemeinschaft zusammenzuarbeiten, um den Anschluss an die technologische Entwicklung nicht zu verpassen. Au√üerdem m√ºsse die Bev√∂lkerung besser √ºber m√∂gliche Angriffsszenarien unterrichtet werden, damit sie diese im Ernstfall auch erkennen.

Mehr zu diesem Thema

MIT Technology Review
K√ºnstliche Intelligenz



























































                        Starte in die Woche mit dem t3n Weekly üíå





                            Bitte gib eine g√ºltige E-Mail-Adresse ein.
                        
Jetzt anmelden


                        Es gab leider ein Problem beim Absenden des Formulars. Bitte versuche es erneut.
                    

                        Bitte gib eine g√ºltige E-Mail-Adresse ein.
                    


Hinweis zum Newsletter & Datenschutz




Fast fertig!

                Bitte klicke auf den Link in der Best√§tigungsmail, um deine Anmeldung abzuschlie√üen.
            

                Du willst noch weitere Infos zum Newsletter?
                Jetzt mehr erfahren








Anzeige

Anzeige



Anzeige

Anzeige




Finde einen Job, den du liebst.





Technik & Entwicklung



Design & UX



Marketing, PR & Kommunikation



Projekt- & Produkt- management



Content & Redaktion



Business Development


Jetzt Job finden


Anzeige

Anzeige




","[{'@type': 'Thing', 'name': 'K√ºnstliche Intelligenz', '@id': 'https://t3n.de/tag/kuenstliche-intelligenz/'}]","In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch k√ºnstliche Intelligenz m√∂glich werden, und welche Schritte schon jetzt unternommen werden sollten, um einem Missbrauch der Technologie vorzubeugen.

Im Februar 2017 trafen sich KI-Experten verschiedener Universit√§ten, der digitalen B√ºrgerrechtsorganisation Electronic-Frontier-Foundation und der gemeinn√ºtzigen KI-Organisation OpenAI in Oxford, um m√∂gliche Gefahren zu er√∂rtern, die der Fortschritt der Technologie mit sich bringen k√∂nnte. Jetzt, ein Jahr sp√§ter, haben sie ihre Erkenntnisse in einem mehr als hundert Seiten starken Dokument ver√∂ffentlicht.

In ihrem Paper gehen die Autoren auf unterschiedliche Szenarien ein, bei denen k√ºnstliche Intelligenz im und au√üerhalb des Internets daf√ºr genutzt werden k√∂nnte, um Menschen gezielt zu schaden. Eine m√∂gliche Gefahr sehen die Experten beispielsweise darin, dass KI kriminelle Hacker bei ihrer Arbeit unterst√ºtzen k√∂nnte.

Das ist nat√ºrlich l√§ngst keine Zukunftsvision mehr, da schon jetzt bisweilen mehr oder minder clevere Bots dazu genutzt werden, pers√∂nliche Daten von Nutzern zu erlangen. Auch beim Knacken von Passw√∂rtern kommen allm√§hlich KI-Systeme zum Einsatz. Zuk√ºnftig, so die Autoren, d√ºrfte sich das Problem aber noch deutlich steigern.
Von Drohnenangriffen zur staatlichen √úberwachung
Auch bei physischen Angriffen auf die Bev√∂lkerung k√∂nnten KI-Systeme beteiligt sein. Die Forscher denken hier beispielsweise an Luftangriffe mit Hilfe kommerzieller Drohnen. Intelligente Software k√∂nnte Terroristen und Kriminelle aber auch generell bei der Durchf√ºhrung von Angriffen unterst√ºtzen. So k√∂nnten Modelle entwickelt werden, die kleinen Gruppen dabei helfen, mit gegebenen Mitteln einen m√∂glichst gro√üen Schaden anzurichten.

Gleichzeitig warnen die Forscher auch davor, wie KI-Systeme bei der √úberwachung der Bev√∂lkerung durch Staatsorgane eingesetzt werden k√∂nnten. Als m√∂gliches Bedrohungsszenario nennen die Autoren an der Stelle auch den Einsatz von KI-Systemen zum Aufsp√ºren und Unterdr√ºckung abweichender Meinungen.
Forscher fordern mehr Offenheit bei der KI-Entwicklung
Nach Meinung der Autoren des Papers m√ºssen Forschung, Gesellschaft und Staat gemeinsam daran arbeiten, Schutzmechanismen gegen die verschiedenen Bedrohungen zu entwickeln. Kollegen aus Forschung und Entwicklung raten die Autoren, auch Experten aus anderen Forschungsbereichen miteinzubeziehen und fordern au√üerdem grunds√§tzlich mehr Offenheit und Austausch. Au√üerdem sollte der potenzielle Missbrauch von Technologien auch Einfluss auf die Forschungspriorit√§ten und -standards haben.

Regierungen wiederum wird geraten, eng mit der Forschergemeinschaft zusammenzuarbeiten, um den Anschluss an die technologische Entwicklung nicht zu verpassen. Au√üerdem m√ºsse die Bev√∂lkerung besser √ºber m√∂gliche Angriffsszenarien unterrichtet werden, damit sie diese im Ernstfall auch erkennen.",Buzz & Memes,,,450.0,,PT2M,True,2018,"{'@type': 'Organization', '@id': 'https://t3n.de#organization'}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://t3n.de/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': '/news/', 'name': 'News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': '/tag/buzz-memes/', 'name': 'Buzz & Memes'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://t3n.de/news/ki-fuer-schaedliche-zwecke-957441/', 'name': 'Wie KI f√ºr sch√§dliche Zwecke missbraucht werden kann ‚Äì und was wir dagegen tun k√∂nnen'}}]"

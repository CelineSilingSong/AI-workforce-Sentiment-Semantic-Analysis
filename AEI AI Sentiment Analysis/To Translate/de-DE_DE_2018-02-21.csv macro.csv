URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,dateModified,publisher,datePublished,@context,@type,headline,image,mainEntityOfPage,author,article:section,article:summary,article text,about,articleBody,articleSection,dateCreated,url,wordCount,alternativeHeadline,timeRequired,isAccessibleForFree,copyrightYear,copyrightHolder,itemListElement
https://news.google.com/rss/articles/CBMiPmh0dHBzOi8vd3d3LmNpby5kZS9hL2tpLXJldm9sdXRpb25pZXJ0LWRhcy1zdGV1ZXJ3ZXNlbiwzNTYzOTIx0gFCaHR0cHM6Ly93d3cuY2lvLmRlL2EvYW1wL2tpLXJldm9sdXRpb25pZXJ0LWRhcy1zdGV1ZXJ3ZXNlbiwzNTYzOTIx?oc=5,KI revolutioniert das Steuerwesen - CIO,2018-02-22,CIO,https://www.cio.de,"Ob Umsatzsteuer, Risiko-Management oder Zoll – künftig werden KI-Systeme Arbeiten von Steuerfachleuten übernehmen. Diese These stammt vom Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI).","Künstliche Intelligenz (KI), Steuer, Wolfgang Wahlster, DFKI, Maschinelles Lernen","Ob Umsatzsteuer, Risiko-Management oder Zoll – künftig werden KI-Systeme Arbeiten von Steuerfachleuten übernehmen. Diese These stammt vom Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI).","Ob Umsatzsteuer, Risiko-Management oder Zoll – künftig werden KI-Systeme Arbeiten von Steuerfachleuten übernehmen. Diese These stammt vom Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI).",2018-02-22T08:10:00Z,"{'@type': 'Organization', 'logo': {'height': 57, '@type': 'ImageObject', 'url': 'https://www.cio.de/includes/images/amp/logo/CIO.png', 'width': 182}, 'name': 'CIO'}",2018-02-22T08:10:00Z,http://schema.org,NewsArticle,KI revolutioniert das Steuerwesen,"{'height': 675, '@type': 'ImageObject', 'url': 'https://images.cio.de/bdb/2682752/1200x.jpg', 'width': 1200}","{'@type': 'WebPage', '@id': 'https://www.cio.de/a/ki-revolutioniert-das-steuerwesen,3563921'}","[{'@type': 'Person', 'name': 'Christiane Pütter'}]",N/A,N/A,"Künstliche IntelligenzKI revolutioniert das Steuerwesen Drucken22.02.2018Von Christiane Pütter (Autor) 












Christiane Pütter ist Journalistin aus München.







Weitere Artikel des Autors






Ob Umsatzsteuer, Risiko-Management oder Zoll – künftig werden KI-Systeme Arbeiten von Steuerfachleuten übernehmen. Diese These stammt vom Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI).




Anwendungsszenarien wurden mit Audi, Bosch sowie Eon und Henkel durchgespielt.
Daraus leitet das DFKI sechs Einsatzfelder ab.
KI-Systeme können Steuerfachleuten auch komplexe Routinearbeiten abnehmen, sofern diese wenig soziale Intelligenz, Kreativität und Umgebungsinteraktionen erfordern.
Machine Learning, Process Mining, Informationsextraktion, Wissensmanagement, Sprachverarbeitung und multimodale Systeme kommen zum Einsatz.




 Empfehlen Twitter
 Facebook
 Xing
 LinkedIn
 Feedback
 DruckenDas Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI) identifiziert in der Studie ""Künstliche Intelligenz im Steuerbereich"" sieben Bereiche, in denen KI-Systeme Arbeiten von Steuerkanzlei und Steuerverantwortlichen in den Firmen übernehmen könnten. Die Analyse entstand auf Initiatve des Münchener Steuerberaters WTS und versteht sich als exploratives Thesenpapier.AdChoicesADVERTISINGDas Deutsche Forschungszentrum für Künstliche Intelligenz (DFKI) und der Berater WTS skizzieren den Steuerarbeitsplatz der Zukunft.Foto: DFKI/WTS GroupProfessor Wolfgang Wahlster erwartet ""in nicht allzu ferner Zukunft"" Stellenanzeigen wie ""KI­-Experten dringend gesucht: Einsatzbereich Steuerabteilung"". Er spricht von einer Revolution im Steuerbereich. Konkret geht es um die Felder Lohnsteuer, Umsatzsteuer und Körperschaftssteuer sowie Zoll, Verrechnungspreise, Risiko-Management und International Tax. Diese könnten künftig durch Machine LearningMachine Learning, Process Mining, Informationsextraktion, Wissensmanagement, Sprachverarbeitung und multimodale Systeme unterstützt werden.
Alles zu Machine Learning auf CIO.de
Sechs Einsatzbereiche mit Anwendern definiertDie Studienautoren sehen sich nicht als reine Theoretiker, daher haben sie nach eigenen Angaben in vier Konzernen - AudiAudi, BoschBosch, EonEon und HenkelHenkel - bereits Anwendungsszenarien durchgespielt. Daraus leiten sie einen ""Steuerarbeitsplatz der Zukunft"" ab. Kanzleien und Steuerabteilungen in den Unternehmen könnten Künstliche Intelligenz in sechs Punkten einsetzen:
Top-500-Firmenprofil für Audi
Top-500-Firmenprofil für Bosch
Top-500-Firmenprofil für EON
Top-500-Firmenprofil für Henkel AG & Co. KGaA1. Erkennung von Anomalien bei der Ausnutzung von Freihandelsabkommen im Bereich Zoll2. Automatisierte Zuteilung von Steuerkennzeichen und Identifizierung von Inkonsistenzen bei der Zuweisung3. Prüfung des Quellensteuerabzugs nach dem Paragrafen 50 a Einkommenssteuergesetz4. Prüfung von Rechnungen im Bereich Umsatzsteuer5. Anomalie-Erkennung in Massendaten im Bereich Umsatzsteuer6. Intelligente Steuerassistenz im Bereich LohnsteuerBeispiel für eine AnwendungDazu liefern die Forscher einen Use Case: Werden Waren zolltariflich angemeldet, können KI-Technologien zur Informationsextraktion unterstützen, konkret mittels Text Mining in Verbindung mit optischer Zeichenerkennung. Das entspricht einer intelligenten Automatisierung von Routineaufgaben, die vergleichsweise komplex sind, aber nur geringe soziale Intelligenz, Kreativität und Umgebungsinteraktionen erfordern. Professor Peter Fettke, der die Studie geleitet hat, betont: ""In der steuerlichen Gestaltungs- und Durchsetzungsberatung ist es hingegen aktuell nicht vorstellbar, dass die Steuerberatung vollständig durch intelligente Steuerlösungen ersetzt wird.""Die Forscher schildern modellhaft, wie KI unterstützen kann.Foto: DFKI/WTS GroupEin weiterer Use Case dreht sich um Sachzuwendungen im Bereich Lohnsteuer, die der Steuerberater beurteilen muss. KI-Lösungen können ihn bei der Dokumentenanalyse, Informationsextraktion und Klassifikation unstrukturierter transaktionaler Daten unterstützen.Machine Learning - Technologien und Status quo1/17Bilderkennung ist wichtigstes Anwendungsgebiet für Machine LearningHeute kommen Machine-Learning-Algorithmen vor allem im Bereich der Bildanalyse und -erkennung zum Einsatz. In Zukunft werden Spracherkennung und -verarbeitung wichtiger.Foto: Crisp Research, KasselDas DFKI hält ""enorme Produktivitätssteigerungen und Qualitätsverbesserungen"" für möglich. Demzufolge seien ""weitreichende Veränderungen des Tätigkeitsspektrums innerhalb der Steuerberatung zu erwarten"". Wahlster, Fettke und ihre Kollegen kündigen an, auf diesem Gebiet weiterzuforschen.×CloseFeedback geben Zum ThemaKünstliche Intelligenz beim Onlinehändler Otto: Keine Angst: KI ist auch nur SoftwareVerständnis fehlt: Künstliche Intelligenz scheitert an MitarbeiternMcKinsey-Studie: Noch viele Vorbehalte gegen Künstliche Intelligenz Artikel als PDF kaufenDie Rechte an diesem Artikel kaufen×CloseErwerben Sie die Rechte an diesem ArtikelWenn Sie Artikel von CIO, Computerwoche, TecChannel oder Channelpartner für eine kommerzielle Vervielfältigung nutzen wollen, müssen Sie eine Lizenz erwerben.Bitte wenden Sie sich dazu an unseren Partner, die YGS Group (E-Mail: IDGLicensing@theygsgroup.com)



Links zum Artikel
Thema:
Machine Learning
Top500-Firmenprofile:
Audi, Bosch, EON und Henkel AG & Co. KGaA


Meistgelesen













Drogen, Geiz, Kinder




10 Geheimnisse von Steve Jobs




















1 % Regelung, Fahrtenbuch, Privatnutzung




Firmenwagen FAQ - was Sie wissen müssen

















Kostenlose Newsletter







Best Practices



Cloud



First Look



Generative AI in Unternehmen



Leader



Security






Bestellen






",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LnN1ZWRkZXV0c2NoZS5kZS93aXJ0c2NoYWZ0L3RlY2hub2xvZ2llLWZ1ZWhyZW5kZS1mb3JzY2hlci13YXJuZW4tdm9yLWt1ZW5zdGxpY2hlci1pbnRlbGxpZ2Vuei0xLjM4Nzg2NjnSAQA?oc=5,Führende Forscher warnen vor künstlicher Intelligenz - Wirtschaft - SZ.de - Süddeutsche Zeitung - SZ.de,2018-02-22,Süddeutsche Zeitung - SZ.de,https://www.sueddeutsche.de,,"Technologie,Technologie,Wirtschaft,Süddeutsche Zeitung",,N/A,2018-02-22 13:27:35,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'height': '64', 'url': 'https://www.sueddeutsche.de/szde-assets/img/szde-article-sueddeutsche-logo.svg', 'width': '525'}, 'name': 'Süddeutsche Zeitung'}",2018-02-22T13:17:25.000Z,https://schema.org,NewsArticle,Führende Forscher warnen vor künstlicher Intelligenz,"{'@type': 'ImageObject', 'height': '675', 'url': 'https://www.sueddeutsche.de/2022/06/14/153a488d-75de-41f7-9435-6ea7037198ab.jpeg?q=60&fm=webp&width=1200&rect=65%2C62%2C727%2C409', 'width': '1200'}",https://www.sueddeutsche.de/wirtschaft/technologie-fuehrende-forscher-warnen-vor-kuenstlicher-intelligenz-1.3878669,"[{'@type': 'Person', 'name': 'Andrian Kreye', 'sameAs': '/autoren/andrian-kreye-1.1143143'}]",N/A,N/A,"Technologie:Führende Forscher warnen vor künstlicher Intelligenz22. Februar 2018, 14:17 UhrLesezeit: 1 minDetailansicht öffnenGegen Schachcomputer haben Menschen längst keine Chance mehr. Was kommt als nächstes? (Foto: agsandrew - Fotolia)Eine Gruppe hochrangiger Experten warnt vor den Gefahren für die Gesellschaft, die durch künstliche Intelligenz entstehen können.Zu der Gruppe gehören unter anderen Forscher der Universitäten Stanford, Yale, Oxford und Tohoku sowie Entwickler von Microsoft und Google.Die Entwicklung der KI sei an einem Punkt, an dem der Mensch noch eingreifen könne - wenn Politiker, Forscher und Unternehmer zusammenarbeiten.Von Andrian KreyeMerkenTeilenFeedbackDruckenWenn führende Forscher und Entwickler ein Moratorium für die Weiterentwicklung künstlicher Intelligenz (KI) fordern, ist das nicht der übliche Alarmismus. So veröffentlichte eine Projektgruppe solcher Fachleute eine Arbeit mit dem Titel ""The Malicious Use of Artificial Intelligence"" ( ""Bösartige Nutzungen Künstlicher Intelligenz""). Zu der Gruppe gehören unter anderen die Universitäten Stanford, Yale, Oxford und Tohoku sowie Entwickler von Microsoft, Google und dessen Tochterfirma, des momentan führenden KI-Unternehmens DeepMind.Im Unterschied zu den oft prominenten Vertretern der KI-Panik haben sich die Forscher bei ihrem Projekt ausschließlich auf Technologien konzentriert, die es entweder schon gibt, oder die nach aktuellem Stand der Entwicklung in den kommenden fünf Jahren anwendbar sein werden. Bisher gehörte ein großer Teil der KI-Kritik eher in die literarischen Sphären der dystopischen Science Fiction. Solche Szenarien stammen zum Beispiel vom Physiker Stephen Hawking, dem Philosophen Nick Bostrom und dem Unternehmer Elon Musk - keiner von ihnen hat sich jemals wissenschaftlich an der Entwicklung von KI beteiligt.Eines der konkreten Beispiele, das die Forscher in ihrem Aufruf nennen, ist die Entwicklung der Bilderkennung und -generierung durch KI. Die war 2014 noch auf dem Stand, dass sie nur grauschleierige Phantombilder schaffen konnte. Inzwischen ist es mit so genannten Deep-Fake-Technologien möglich, Gesichter mit glaubhafter Mimik in Videos auf fremde Körper zu übertragen. Das wiederum sei angesichts der jüngeren Geschichte politischer Manipulationen eine Form destruktiver KI-Anwendung, der man nur schwer Einhalt gebieten könne.Die Möglichkeiten solchen Missbrauchs reichen schon jetzt und in naher Zukunft von ungeahnten Dimensionen des Hacking (nicht nur von Rechnern, sondern auch von KI-getriebenen Systemen wie Drohnen, Fahrzeugen, Robotern oder autonomen Waffen), bis zu einem Wettrüsten in allen Fragen der Cyber-Sicherheit, die sie in digitale, physische und politische Sicherheit unterteilen.Lösungen schlagen die Experten auch vor. Künstliche Intelligenzen zu zentralisieren, wäre eine Möglichkeit, Missbrauch vorzubeugen. Sie erinnern aber auch an die Garmischer Nato-Konferenz von 1968, bei der Grundlagen zur Software-Entwicklung festgelegt wurden, die heute noch Norm sind, und an das Moratorium, das die biologische Forschung 1975 im kalifornischen Asilomar ausgerufen hat (und das derzeit in der Genforschung als Grundlage für neue Selbstbeschränkungen genutzt wird). Die Mahner geben sich sogar optimistisch: Die Entwicklung der KI sei an einem Punkt, an dem man noch gemeinsam eingreifen könne. Aber das müsse eben jetzt geschehen. Jetzt!© SZ.de - Rechte am Artikel können Sie hier erwerben.TeilenFeedbackDruckenZur SZ-StartseiteManipulierte Porno-Videos:Menschen müssen aufhören, ihren Augen zu trauenEine App ermöglicht es Laien, Gesichter von Prominenten in Hardcore-Pornos zu montieren. Das erschreckend perfekte Ergebnis erschüttert die Glaubwürdigkeit von Bildern und Videos.Von Bernd GraffLesen Sie mehr zum ThemaTechnologie",Technologie,"Wenn führende Forscher und Entwickler ein Moratorium für die Weiterentwicklung künstlicher Intelligenz (KI) fordern, ist das nicht der  übliche Alarmismus . So veröffentlichte eine Projektgruppe solcher Fachleute eine Arbeit mit dem Titel ""The Malicious Use of Artificial Intelligence"" (  ""Bösartige Nutzungen Künstlicher Intelligenz"" ). Zu der Gruppe gehören unter anderen die Universitäten Stanford, Yale, Oxford und Tohoku sowie Entwickler von Microsoft, Google und dessen Tochterfirma, des momentan führenden KI-Unternehmens  DeepMind .
Im Unterschied zu den oft prominenten Vertretern der KI-Panik haben sich die Forscher bei ihrem Projekt ausschließlich auf Technologien konzentriert, die es entweder schon gibt, oder die nach aktuellem Stand der Entwicklung in den kommenden fünf Jahren anwendbar sein werden. Bisher gehörte ein großer Teil der KI-Kritik eher in die literarischen Sphären der dystopischen Science Fiction. Solche Szenarien stammen zum Beispiel vom Physiker Stephen Hawking, dem Philosophen Nick Bostrom und dem Unternehmer Elon Musk - keiner von ihnen hat sich jemals wissenschaftlich an der Entwicklung von KI beteiligt.
Eines der konkreten Beispiele, das die Forscher in ihrem Aufruf nennen, ist die Entwicklung der Bilderkennung und -generierung durch KI. Die war 2014 noch auf dem Stand, dass sie nur grauschleierige Phantombilder schaffen konnte. Inzwischen  ist es mit so genannten Deep-Fake-Technologien möglich , Gesichter mit glaubhafter Mimik in Videos auf fremde Körper zu übertragen. Das wiederum sei angesichts der jüngeren Geschichte politischer Manipulationen eine Form destruktiver KI-Anwendung, der man nur schwer Einhalt gebieten könne.
Die Möglichkeiten solchen Missbrauchs reichen schon jetzt und in naher Zukunft von ungeahnten Dimensionen des Hacking (nicht nur von Rechnern, sondern auch von KI-getriebenen Systemen wie Drohnen, Fahrzeugen, Robotern oder autonomen Waffen), bis zu einem Wettrüsten in allen Fragen der Cyber-Sicherheit, die sie in digitale, physische und politische Sicherheit unterteilen.
Lösungen schlagen die Experten auch vor. Künstliche Intelligenzen zu zentralisieren, wäre eine Möglichkeit, Missbrauch vorzubeugen. Sie erinnern aber auch an die Garmischer Nato-Konferenz von 1968, bei der Grundlagen zur Software-Entwicklung festgelegt wurden, die heute noch Norm sind, und an das Moratorium, das die biologische Forschung 1975 im kalifornischen Asilomar ausgerufen hat (und das derzeit in der Genforschung als Grundlage für neue Selbstbeschränkungen genutzt wird). Die Mahner geben sich sogar optimistisch: Die Entwicklung der KI sei an einem Punkt, an dem man noch gemeinsam eingreifen könne. Aber das müsse eben jetzt geschehen. Jetzt!",Wirtschaft,2018-02-22T13:17:25.000Z,https://www.sueddeutsche.de/wirtschaft/technologie-fuehrende-forscher-warnen-vor-kuenstlicher-intelligenz-1.3878669,371.0,Führende Forscher warnen vor künstlicher Intelligenz,PT1M,,,,
https://news.google.com/rss/articles/CBMiNmh0dHBzOi8vdDNuLmRlL25ld3Mva2ktZnVlci1zY2hhZWRsaWNoZS16d2Vja2UtOTU3NDQxL9IBAA?oc=5,Wie KI für schädliche Zwecke missbraucht werden kann – und was wir dagegen tun können - t3n – digital pioneers,2018-02-24,t3n – digital pioneers,https://t3n.de,"In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch künstliche Intelligenz mög",N/A,"In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch künstliche Intelligenz möglich werden, und welche ...","In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch künstliche Intelligenz möglich werden, und welche ...",2021-08-13T06:13:14+0200,"{'@type': 'Organization', 'name': 't3n Magazin', 'logo': {'@type': 'ImageObject', 'url': 'https://t3n.de/news/wp-content/uploads/2020/11/t3n-logo-google-news-rot-400px.png', 'width': 401, 'height': 130}}",2018-02-24T06:00:24+0100,https://schema.org,BreadcrumbList,Wie KI für schädliche Zwecke missbraucht werden kann – und was wir dagegen tun können,"[{'@type': 'ImageObject', 'url': 'https://images.t3n.de/news/wp-content/uploads/2018/02/ki-sicherheit.jpg?class=structuredData-large', 'width': 1200}, {'@type': 'ImageObject', 'url': 'https://images.t3n.de/news/wp-content/uploads/2018/02/ki-sicherheit.jpg?class=structuredData-medium', 'width': 1200}, {'@type': 'ImageObject', 'url': 'https://images.t3n.de/news/wp-content/uploads/2018/02/ki-sicherheit.jpg?class=structuredData-small', 'width': 1200}]","{'@type': 'WebPage', '@id': 'https://t3n.de/news/ki-fuer-schaedliche-zwecke-957441/'}","{'@type': 'Person', '@id': 'https://t3n.de/redaktion/kim-rixecker#person', 'name': 'Kim Rixecker', 'jobTitle': 'Redakteur Software & Chef vom Dienst'}",N/A,N/A,"





Home





News





Buzz & Memes





Wie KI für schädliche Zwecke missbraucht werden kann – und was wir dagegen tun können






                            News
                    


                    Wie KI für schädliche Zwecke missbraucht werden kann – und was wir dagegen tun können
                

                                                                
In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch künstliche Intelligenz möglich werden, und welche Schritte schon jetzt unternommen werden sollten, um einem Missbrauch der Technologie vorzubeugen.
                                    

                                Von Kim Rixecker




24.02.2018, 06:00 Uhr 

                                •
                            

 2 Min.
                            











Artikel merken





Anzeige

Anzeige













(Foto: Shutterstock)






Im Februar 2017 trafen sich KI-Experten verschiedener Universitäten, der digitalen Bürgerrechtsorganisation Electronic-Frontier-Foundation und der gemeinnützigen KI-Organisation OpenAI in Oxford, um mögliche Gefahren zu erörtern, die der Fortschritt der Technologie mit sich bringen könnte. Jetzt, ein Jahr später, haben sie ihre Erkenntnisse in einem mehr als hundert Seiten starken Dokument veröffentlicht.
AnzeigeAnzeigeIn ihrem Paper gehen die Autoren auf unterschiedliche Szenarien ein, bei denen künstliche Intelligenz im und außerhalb des Internets dafür genutzt werden könnte, um Menschen gezielt zu schaden. Eine mögliche Gefahr sehen die Experten beispielsweise darin, dass KI kriminelle Hacker bei ihrer Arbeit unterstützen könnte.
Das ist natürlich längst keine Zukunftsvision mehr, da schon jetzt bisweilen mehr oder minder clevere Bots dazu genutzt werden, persönliche Daten von Nutzern zu erlangen. Auch beim Knacken von Passwörtern kommen allmählich KI-Systeme zum Einsatz. Zukünftig, so die Autoren, dürfte sich das Problem aber noch deutlich steigern.AnzeigeAnzeige

Von Drohnenangriffen zur staatlichen Überwachung

Auch bei physischen Angriffen auf die Bevölkerung könnten KI-Systeme beteiligt sein. Die Forscher denken hier beispielsweise an Luftangriffe mit Hilfe kommerzieller Drohnen. Intelligente Software könnte Terroristen und Kriminelle aber auch generell bei der Durchführung von Angriffen unterstützen. So könnten Modelle entwickelt werden, die kleinen Gruppen dabei helfen, mit gegebenen Mitteln einen möglichst großen Schaden anzurichten.AnzeigeAnzeige
Gleichzeitig warnen die Forscher auch davor, wie KI-Systeme bei der Überwachung der Bevölkerung durch Staatsorgane eingesetzt werden könnten. Als mögliches Bedrohungsszenario nennen die Autoren an der Stelle auch den Einsatz von KI-Systemen zum Aufspüren und Unterdrückung abweichender Meinungen.

Forscher fordern mehr Offenheit bei der KI-Entwicklung

Nach Meinung der Autoren des Papers müssen Forschung, Gesellschaft und Staat gemeinsam daran arbeiten, Schutzmechanismen gegen die verschiedenen Bedrohungen zu entwickeln. Kollegen aus Forschung und Entwicklung raten die Autoren, auch Experten aus anderen Forschungsbereichen miteinzubeziehen und fordern außerdem grundsätzlich mehr Offenheit und Austausch. Außerdem sollte der potenzielle Missbrauch von Technologien auch Einfluss auf die Forschungsprioritäten und -standards haben.AnzeigeAnzeige
Regierungen wiederum wird geraten, eng mit der Forschergemeinschaft zusammenzuarbeiten, um den Anschluss an die technologische Entwicklung nicht zu verpassen. Außerdem müsse die Bevölkerung besser über mögliche Angriffsszenarien unterrichtet werden, damit sie diese im Ernstfall auch erkennen.

Mehr zu diesem Thema

MIT Technology Review
Künstliche Intelligenz



























































                        Starte in die Woche mit dem t3n Weekly 💌





                            Bitte gib eine gültige E-Mail-Adresse ein.
                        
Jetzt anmelden


                        Es gab leider ein Problem beim Absenden des Formulars. Bitte versuche es erneut.
                    

                        Bitte gib eine gültige E-Mail-Adresse ein.
                    


Hinweis zum Newsletter & Datenschutz




Fast fertig!

                Bitte klicke auf den Link in der Bestätigungsmail, um deine Anmeldung abzuschließen.
            

                Du willst noch weitere Infos zum Newsletter?
                Jetzt mehr erfahren








Anzeige

Anzeige



Anzeige

Anzeige




Finde einen Job, den du liebst.





Technik & Entwicklung



Design & UX



Marketing, PR & Kommunikation



Projekt- & Produkt- management



Content & Redaktion



Business Development


Jetzt Job finden


Anzeige

Anzeige




","[{'@type': 'Thing', 'name': 'Künstliche Intelligenz', '@id': 'https://t3n.de/tag/kuenstliche-intelligenz/'}]","In einem Paper gehen Wissenschaftler der Frage nach, welche Angriffsszenarien durch künstliche Intelligenz möglich werden, und welche Schritte schon jetzt unternommen werden sollten, um einem Missbrauch der Technologie vorzubeugen.

Im Februar 2017 trafen sich KI-Experten verschiedener Universitäten, der digitalen Bürgerrechtsorganisation Electronic-Frontier-Foundation und der gemeinnützigen KI-Organisation OpenAI in Oxford, um mögliche Gefahren zu erörtern, die der Fortschritt der Technologie mit sich bringen könnte. Jetzt, ein Jahr später, haben sie ihre Erkenntnisse in einem mehr als hundert Seiten starken Dokument veröffentlicht.

In ihrem Paper gehen die Autoren auf unterschiedliche Szenarien ein, bei denen künstliche Intelligenz im und außerhalb des Internets dafür genutzt werden könnte, um Menschen gezielt zu schaden. Eine mögliche Gefahr sehen die Experten beispielsweise darin, dass KI kriminelle Hacker bei ihrer Arbeit unterstützen könnte.

Das ist natürlich längst keine Zukunftsvision mehr, da schon jetzt bisweilen mehr oder minder clevere Bots dazu genutzt werden, persönliche Daten von Nutzern zu erlangen. Auch beim Knacken von Passwörtern kommen allmählich KI-Systeme zum Einsatz. Zukünftig, so die Autoren, dürfte sich das Problem aber noch deutlich steigern.
Von Drohnenangriffen zur staatlichen Überwachung
Auch bei physischen Angriffen auf die Bevölkerung könnten KI-Systeme beteiligt sein. Die Forscher denken hier beispielsweise an Luftangriffe mit Hilfe kommerzieller Drohnen. Intelligente Software könnte Terroristen und Kriminelle aber auch generell bei der Durchführung von Angriffen unterstützen. So könnten Modelle entwickelt werden, die kleinen Gruppen dabei helfen, mit gegebenen Mitteln einen möglichst großen Schaden anzurichten.

Gleichzeitig warnen die Forscher auch davor, wie KI-Systeme bei der Überwachung der Bevölkerung durch Staatsorgane eingesetzt werden könnten. Als mögliches Bedrohungsszenario nennen die Autoren an der Stelle auch den Einsatz von KI-Systemen zum Aufspüren und Unterdrückung abweichender Meinungen.
Forscher fordern mehr Offenheit bei der KI-Entwicklung
Nach Meinung der Autoren des Papers müssen Forschung, Gesellschaft und Staat gemeinsam daran arbeiten, Schutzmechanismen gegen die verschiedenen Bedrohungen zu entwickeln. Kollegen aus Forschung und Entwicklung raten die Autoren, auch Experten aus anderen Forschungsbereichen miteinzubeziehen und fordern außerdem grundsätzlich mehr Offenheit und Austausch. Außerdem sollte der potenzielle Missbrauch von Technologien auch Einfluss auf die Forschungsprioritäten und -standards haben.

Regierungen wiederum wird geraten, eng mit der Forschergemeinschaft zusammenzuarbeiten, um den Anschluss an die technologische Entwicklung nicht zu verpassen. Außerdem müsse die Bevölkerung besser über mögliche Angriffsszenarien unterrichtet werden, damit sie diese im Ernstfall auch erkennen.",Buzz & Memes,,,450.0,,PT2M,True,2018,"{'@type': 'Organization', '@id': 'https://t3n.de#organization'}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://t3n.de/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': '/news/', 'name': 'News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': '/tag/buzz-memes/', 'name': 'Buzz & Memes'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://t3n.de/news/ki-fuer-schaedliche-zwecke-957441/', 'name': 'Wie KI für schädliche Zwecke missbraucht werden kann – und was wir dagegen tun können'}}]"

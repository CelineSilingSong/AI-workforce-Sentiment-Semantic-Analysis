URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@graph,article:section,article:summary,article text,dateModified,publisher,datePublished,@type,headline,image,mainEntityOfPage,author,url,articleBody,hasPart,isAccessibleForFree,wordCount,itemListElement,numberOfItems,articleSection
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LmJpdGtvbS5vcmcvUHJlc3NlL1ByZXNzZWluZm9ybWF0aW9uL0t1ZW5zdGxpY2hlLUludGVsbGlnZW56LXNvbGwtZGVtLUNoZWYtaGVsZmVuLW9kZXItaWhuLWVyc2V0emVu0gEA?oc=5,Künstliche Intelligenz soll dem Chef helfen – oder ihn ersetzen | Presseinformation - Bitkom eV,2019-02-19,Bitkom eV,https://www.bitkom.org,"Presseinformation 4 von 10 Berufstätigen wollen, dass eine KI ihren Vorgesetzten unterstützt 3 von 10 würden ihren Chef sogar gegen eine KI tauschen","Presseinformation, Pressemitteilung, Presseerklärung, Pressemeldung, Presseaussendung, Pressetext, Presseinformation, Medienmitteilung","Presseinformation 4 von 10 Berufstätigen wollen, dass eine KI ihren Vorgesetzten unterstützt 3 von 10 würden ihren Chef sogar gegen eine KI tauschen","4 von 10 Berufstätigen wollen, dass eine KI ihren Vorgesetzten unterstützt 3 von 10 würden ihren Chef sogar gegen eine KI tauschen",https://schema.org,"[{'@type': 'NewsArticle', 'headline': 'Künstliche Intelligenz soll dem Chef helfen – oder ihn ersetzen', 'about': ['Artificial Intelligence'], 'description': '4 von 10 Berufstätigen wollen, dass eine KI ihren Vorgesetzten unterstützt\n\t3 von 10 würden ihren Chef sogar gegen eine KI tauschen', 'image': {'@type': 'ImageObject', 'representativeOfPage': 'True', 'url': 'https://www.bitkom.org/sites/main/files/styles/facebook/public/2018-11/iStock-639451436-Nikola-Nastasic-960%2520x%2520540-2%5B1%5D.jpg?itok=v5bWMf_R', 'width': '1910', 'height': '1000'}, 'datePublished': 'Di., 19.02.2019 - 08:30', 'dateModified': 'Mo., 27.05.2024 - 15:31', 'isAccessibleForFree': 'True', 'author': {'@type': 'Organization', '@id': 'www.bitkom.org', 'name': 'Bitkom e.V.', 'url': 'https://www.bitkom.org/', 'sameAs': ['https://bitkom.net', 'https://bitkom.de', 'https://bitkom.com', 'https://bitkom.eu'], 'logo': {'@type': 'ImageObject', 'url': 'https://www.bitkom.org//themes/tokyo/src/assets/logos/bitkom.svg', 'width': '160'}}, 'publisher': {'@type': 'Organization', '@id': 'https://www.bitkom.org/', 'name': 'Bitkom e.V.', 'url': 'https://www.bitkom.org/', 'sameAs': ['https://bitkom.net', 'https://bitkom.de', 'https://bitkom.com', 'https://bitkom.eu']}, 'mainEntityOfPage': 'https://www.bitkom.org/Presse/Presseinformation/Kuenstliche-Intelligenz-soll-dem-Chef-helfen-oder-ihn-ersetzen'}]",N/A,N/A,N/A,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMimgFodHRwczovL3d3dy5taWNyb3NvZnQuY29tL2RlLWRlL2luZHVzdHJ5L2Jsb2cvdW5jYXRlZ29yaXplZC8yMDE5LzAyLzE4L21pY3Jvc29mdC1raS1mZXN0aXZhbC1kaWUtenVrdW5mdC1taXQta3VlbnN0bGljaGVyLWludGVsbGlnZW56LWdlbWVpbnNhbS1nZXN0YWx0ZW4v0gEA?oc=5,Microsoft KI-Festival: Die Zukunft mit Künstlicher Intelligenz gemeinsam gestalten - Microsoft,2019-02-18,Microsoft,https://www.microsoft.com,Wir sprechen über Künstliche Intelligenz (KI). Über Chancen und Herausforderungen. Über Potenziale und Begrenzungen. Besuchen Sie das Microsoft KI-Festival.,N/A,Wir sprechen über Künstliche Intelligenz (KI). Über Chancen und Herausforderungen. Über Potenziale und Begrenzungen. Besuchen Sie das Microsoft KI-Festival.,N/A,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/#article', 'isPartOf': {'@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/'}, 'author': [{'@id': 'https://www.microsoft.com/de-de/industry/blog/#/schema/person/image/6fedcd4dfa0648c4f6dd52786f657325'}], 'headline': 'Microsoft KI-Festival: Die Zukunft mit Künstlicher Intelligenz gemeinsam gestalten', 'datePublished': '2019-02-18T14:50:54+00:00', 'dateModified': '2019-02-18T15:12:19+00:00', 'mainEntityOfPage': {'@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/'}, 'wordCount': 232, 'publisher': {'@id': 'https://www.microsoft.com/de-de/industry/blog/#organization'}, 'image': {'@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/#primaryimage'}, 'thumbnailUrl': 'https://www.microsoft.com/de-de/industry/blog/wp-content/uploads/sites/2/2018/10/AI-kampagne-800x450.jpg', 'articleSection': ['Branchenübergreifend'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/', 'url': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/', 'name': 'Microsoft KI-Festival: Die Zukunft mit Künstlicher Intelligenz gemeinsam gestalten - Microsoft Branchenblogs', 'isPartOf': {'@id': 'https://www.microsoft.com/de-de/industry/blog/#website'}, 'primaryImageOfPage': {'@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/#primaryimage'}, 'image': {'@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/#primaryimage'}, 'thumbnailUrl': 'https://www.microsoft.com/de-de/industry/blog/wp-content/uploads/sites/2/2018/10/AI-kampagne-800x450.jpg', 'datePublished': '2019-02-18T14:50:54+00:00', 'dateModified': '2019-02-18T15:12:19+00:00', 'description': 'Wir sprechen über Künstliche Intelligenz (KI). Über Chancen und Herausforderungen. Über Potenziale und Begrenzungen. Besuchen Sie das Microsoft KI-Festival.', 'breadcrumb': {'@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/#primaryimage', 'url': 'https://www.microsoft.com/de-de/industry/blog/wp-content/uploads/sites/2/2018/10/AI-kampagne-800x450.jpg', 'contentUrl': 'https://www.microsoft.com/de-de/industry/blog/wp-content/uploads/sites/2/2018/10/AI-kampagne-800x450.jpg', 'width': 800, 'height': 450, 'caption': 'Unglaubliche Möglichkeiten Künstlicher Intelligenz'}, {'@type': 'BreadcrumbList', '@id': 'https://www.microsoft.com/de-de/industry/blog/uncategorized/2019/02/18/microsoft-ki-festival-die-zukunft-mit-kuenstlicher-intelligenz-gemeinsam-gestalten/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.microsoft.com/de-de/industry/blog/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Microsoft KI-Festival: Die Zukunft mit Künstlicher Intelligenz gemeinsam gestalten'}]}, {'@type': 'WebSite', '@id': 'https://www.microsoft.com/de-de/industry/blog/#website', 'url': 'https://www.microsoft.com/de-de/industry/blog/', 'name': 'Microsoft Branchenblogs', 'description': '', 'publisher': {'@id': 'https://www.microsoft.com/de-de/industry/blog/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.microsoft.com/de-de/industry/blog/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.microsoft.com/de-de/industry/blog/#organization', 'name': 'Microsoft Branchenblogs', 'url': 'https://www.microsoft.com/de-de/industry/blog/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.microsoft.com/de-de/industry/blog/#/schema/logo/image/', 'url': 'https://www.microsoft.com/de-de/industry/blog/wp-content/uploads/sites/2/2019/08/Microsoft-Logo.png', 'contentUrl': 'https://www.microsoft.com/de-de/industry/blog/wp-content/uploads/sites/2/2019/08/Microsoft-Logo.png', 'width': 259, 'height': 194, 'caption': 'Microsoft Branchenblogs'}, 'image': {'@id': 'https://www.microsoft.com/de-de/industry/blog/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/MicrosoftinBusinessDE/', 'https://x.com/msenterprisede', 'https://www.youtube.com/user/MicrosoftBusiness']}, {'@type': 'Person', '@id': 'https://www.microsoft.com/de-de/industry/blog/#/schema/person/image/6fedcd4dfa0648c4f6dd52786f657325', 'name': 'Microsoft', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.microsoft.com/de-de/industry/blog/#/schema/person/image/0b9ebed8d3077813223bbdd9fd011781', 'url': 'https://www.microsoft.com/de-de/industry/blog/wp-content/uploads/sites/2/2018/09/MS-Office-featured-image-200x200-1-150x150.webp', 'contentUrl': 'https://www.microsoft.com/de-de/industry/blog/wp-content/uploads/sites/2/2018/09/MS-Office-featured-image-200x200-1-150x150.webp', 'width': 150, 'height': 150, 'caption': 'Microsoft'}, 'url': 'https://www.microsoft.com/de-de/industry/blog/author/microsoft/'}]",N/A,N/A,"


 




PublishedDec 3, 2018				



Big Data und künstliche Intelligenz in der Entwicklungshilfe 



",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LnNwaWVnZWwuZGUvbmV0endlbHQvd2ViL2V1cm9wYWVpc2NoZXItcG9saXplaWtvbmdyZXNzLWt1ZW5zdGxpY2hlLWludGVsbGlnZW56LWluLWRlci1wb2xpemVpYXJiZWl0LWEtMTI1NDE5NS5odG1s0gEA?oc=5,Europäischer Polizeikongress: Künstliche Intelligenz in der Polizeiarbeit - DER SPIEGEL,2019-02-20,DER SPIEGEL,https://www.spiegel.de,Der Hype um künstliche Intelligenz ist auch bei der Polizei groß: Die Sicherheitsbehörden testen Automatisierung und Prognosewerkzeuge. Doch viele Fragen sind ungeklärt.,N/A,Der Hype um künstliche Intelligenz ist auch bei der Polizei groß: Die Sicherheitsbehörden testen Automatisierung und Prognosewerkzeuge. Doch viele Fragen sind ungeklärt.,N/A,,,N/A,N/A,"





Europäischer Polizeikongress

Wie die Polizei mit Algorithmen experimentiert



Der Hype um künstliche Intelligenz ist auch bei der Polizei groß: Die Sicherheitsbehörden testen Automatisierung und Prognosewerkzeuge. Doch viele Fragen sind ungeklärt.


Von

Sonja Peteranderl

20.02.2019, 17.19 Uhr















Zur Merkliste hinzufügen






















X.com






Facebook








E-Mail







Messenger







WhatsApp










Link kopieren







Weitere Optionen zum Teilen













E-Mail











Messenger











WhatsApp














Link kopieren






























Bild vergrößern



Ein als Einbrecher verkleideter Mann mit Bewegungsprofil (Symbolbild)

Foto: Daniel Bockwoldt/ dpa












Auch Barack Obama war auf dem Europäischen Polizeikongress in Berlin zu sehen - allerdings ein gefälschter: Bei einer Präsentation wurde Ermittlern und Vertretern von Sicherheitsbehörden gezeigt, wie leicht Betrüger sogenannte Deep Fakes erstellen können - täuschend echte, computergenerierte Videos von Personen, die etwas sagen oder tun, was allerdings nie stattgefunden hat. Für Ermittler kann das künftig zur Herausforderung werden. 











Gleichzeitig erleichtert ähnliche Technologie den Behörden auch die Ermittlungen und spielt eine zunehmende Rolle in der deutschen Polizeiarbeit. Dazu gehören Gesichtserkennungssoftware, auf künstlicher Intelligenz (KI) basierende Videoanalyse und Programme, die Muster in Daten suchen oder die Wahrscheinlichkeit von Verbrechen vorhersagen. Polizeieinheiten suchen etwa mit der Hilfe von Gesichtserkennungssoftware in Bild- und Videoaufnahmen nach Verdächtigen - entweder nach Straftaten oder per Live-Abgleich mit einer Fahndungsliste wie beim inzwischen abgeschlossenen Pilotversuch am Berliner Südkreuz.














Thomas Striethörster, Präsident der Bundespolizei Berlin, sprach sich auf dem Polizeikongress für ""biometrische Gesichtserkennung an ausgewählten Bahnhöfen und Flughäfen"" aus. Es liege an der Politik zu entscheiden, ob Gesichtserkennung zukünftig im Alltagsbetrieb erlaubt werden soll. ""Wir haben genug Überwachungskameras. Aber wir hatten Sachverhalte, wo wir den Täter nicht erkannt haben"", so Striethörster. Auch Attentäter Anis Amri sei an einer Kamera vorbeigelaufen, aber nicht erkannt worden.















Mehr als zwei Fehlalarme pro Stunde
Striethörster griff die Kritik an der Fehlerquote der Videoüberwachung beim Berliner Pilotversuch auf: ""Ein Fehlerwert von 0,25 hört sich erst mal gut an, aber die Rolltreppe fahren pro Stunde 1000 Menschen herunter und zweieinhalb Mal pro Stunde wird ein Mensch so fälschlicherweise detektiert"", so der Chef der Berliner Bundespolizei.Eine Überlegung sei, zukünftig zwei Gesichtserkennungssysteme gleichzeitig einzusetzen und diese zu vernetzen - nur wenn beide anschlagen, solle ein Alarm ausgelöst werden. In einer zweiten Testphase wird in den kommenden Monaten am Südkreuz geprüft, wie gut Software potenziell gefährliche Situationen erkennen kann - wie beispielsweise stehengelassene Gegenstände, ungewöhnliche Bewegungen in Menschenmassen oder eine Person, die am Boden liegt.














Die Hamburger Polizei sucht inzwischen automatisiert in Bild- und Videoaufnahmen nach Verdächtigen, die an Ausschreitungen während des Hamburger G20-Gipfels im Juli 2017 beteiligt waren. In einer Referenzdatenbank werden dafür biometrische Gesichtsabdrücke von Personen gespeichert, die im Bildmaterial aus Überwachungskameras, aber auch in Handyvideos von Zeugen zu sehen sind. Allerdings zählen dazu auch viele Personen, die während des G20-Gipfels in Hamburg etwa nur zur Arbeit gefahren sind. Hamburgs Datenschutzbeauftragter Johannes Caspar hat daher angeordnet, die Datenbank zu löschen.
Bei vermummten Tätern wird es für die Software schwierig















""Es sind im Zusammenhang mit dem G20-Gipfel insgesamt 100 TB an Bild- und Videomaterial angefallen. Wenn man einen Sachbearbeiter zwingen würde, alles durchzugucken, wären das 60 Jahre"", begründet Thomas Radszuweit von der Ermittlungseinheit ""Schwarzer Block"" beim LKA Hamburg den Nutzen.Allein 17 Terabyte in das System zu importieren habe sieben Wochen gedauert. Bei vermummten Tätern stoße die Software allerdings an ihre Grenze - dann müsse ein Ermittler etwa Indizien wie Kleidung in verschiedenen Aufnahmen abgleichen.Auch in Bayern erleichtert Gesichtserkennung die Identifizierung von Fotos von Verdächtigen, die digitale Einschätzung wird aber jedes Mal von einem Experten geprüft: ""Das Gesicht wird vermessen, nur der Lichtbildexperte kann aber mit 99,9 Prozent sagen, ob es sich tatsächlich um die Person handelt"", sagt Bernhard Egger vom bayerischen LKA. 148 Ermittlungsverfahren seien so im vergangenen Jahr aufgeklärt worden.














Deutschland liegt beim Einsatz von Automatisierungssoftware noch weit hinter anderen Ländern wie den USA zurück. Die Sicherheitsbehörden seien ""in der Initialphase"", sagt der Experte für Verwaltungsdigitalisierung bei Capgemini, Tobias Knobloch. ""Erste Gehversuche wie etwa bei Predictive Policing finden statt. Bei der Gefahrenabwehr ist natürlich mehr möglich und da wird auch schon mehr gemacht, wobei wir aufgrund von Geheimhaltung davon nicht viel wissen.""
Kritiker fordern Leitplanken für den Technikeinsatz
Für bisher sechs Landeskriminalämter berechnet eine Prognose-Software die Wahrscheinlichkeit von Einbrüchen und deckt Muster im Vorgehen der Täter auf 


. Die Wirkung der Software ist schwer belegbar, Knobloch sieht dennoch einen positiven Nebeneffekt: ""Um Prozesse automatisieren oder digitalisieren zu können, muss ich sie explizit machen, zerlegen, aufdröseln, hinterfragen, vereinfachen, optimieren. All das würde ohne den Druck des Digitalen vielfach nicht passieren"", sagte er dem SPIEGEL.














Auf dem Polizeikongress wurde auch KI-basierte Software wie die ""Terror Cell Identification"" (TCI) präsentiert, die Radikalisierungsverläufe bei Terrorverdächtigen berechnen soll. Das hessische LKA setzt bereits die Analyseplattform ""Hessendata"" ein, die auf dem Gotham-System der umstrittenen Analysefirma Palantir basiert. Daten aus verschiedenen Quellen wie Polizeidatenbanken oder sozialen Medien werden ausgewertet, Netzwerke visualisiert . Zukünftig soll die Software auch in Bereichen wie organisierter Kriminalität und schweren Straftaten wie Mord angewandt werden.Der Einsatz solcher Technologien stößt auf Kritik - auch auf dem Polizeikongress: Andreas Kleinknecht, Mitglied der Geschäftsleitung von Microsoft Deutschland, warnte davor, dass vor allem Gesichtserkennung und darauf aufsetzende Dienste ""missbrauchsgefährdet"" seien. Die Politik solle nicht ""zum Reparaturbetrieb für fehlgeleitete KI-Entwicklungen werden, sagte Kleinknecht. Stattdessen müssten schnellstmöglich Leitplanken für den Einsatz der Technologie geschaffen werden - auch in der Polizeiarbeit.
















Feedback


",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmJ1c2luZXNzaW5zaWRlci5kZS90ZWNoL2VzLWdpYnQtZWluLWtpLXN5c3RlbS1kYXMtenUtZ2VmYWVocmxpY2gtaXN0LXVtLWVzLXp1LXZlcm9lZmZlbnRsaWNoZW4tMjAxOS0yL9IBAA?oc=5,"Es gibt ein KI-System, das zu gefährlich ist, um es zu veröffentlichen - Business Insider Deutschland",2019-02-20,Business Insider Deutschland,https://www.businessinsider.de,"Die Non-Profit-Organisation Open AI hat eine gefährliche KI entwickelt, die antisemitische Texte fehlerfrei selbst verfassen kann.",Elon Musk,"Die Non-Profit-Organisation Open AI hat eine gefährliche KI entwickelt, die antisemitische Texte fehlerfrei selbst verfassen kann.",N/A,https://schema.org,"[{'@type': 'NewsArticle', '@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/#article', 'isPartOf': {'@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/'}, 'author': {'@type': 'Organization', 'name': 'Business Insider Deutschland', 'url': 'https://www.businessinsider.de'}, 'headline': 'Es gibt ein KI-System, das zu gefährlich ist, um es zu veröffentlichen', 'datePublished': '2019-02-20T20:23:18+00:00', 'dateModified': '2020-02-05T19:44:21+00:00', 'mainEntityOfPage': {'@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/'}, 'wordCount': 675, 'publisher': {'@id': 'https://www.businessinsider.de/#organization'}, 'image': {'@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/#primaryimage'}, 'thumbnailUrl': 'https://cdn.businessinsider.de/wp-content/uploads/2019/02/artificial-intelligence-social-network-eter9.jpg', 'keywords': ['Elon Musk'], 'articleSection': ['Politik', 'Tech'], 'inLanguage': 'de-DE', 'copyrightYear': '2019', 'copyrightHolder': {'@id': 'https://www.businessinsider.de/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/', 'url': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/', 'name': 'Es gibt ein KI-System, das zu gefährlich ist, um es zu veröffentlichen', 'isPartOf': {'@id': 'https://www.businessinsider.de/#website'}, 'primaryImageOfPage': {'@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/#primaryimage'}, 'image': {'@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/#primaryimage'}, 'thumbnailUrl': 'https://cdn.businessinsider.de/wp-content/uploads/2019/02/artificial-intelligence-social-network-eter9.jpg', 'datePublished': '2019-02-20T20:23:18+00:00', 'dateModified': '2020-02-05T19:44:21+00:00', 'description': 'Die Non-Profit-Organisation Open AI hat eine gefährliche KI entwickelt, die antisemitische Texte fehlerfrei selbst verfassen kann.', 'breadcrumb': {'@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/#breadcrumb'}, 'inLanguage': 'de-DE', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/']}]}, {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/#primaryimage', 'url': 'https://cdn.businessinsider.de/wp-content/uploads/2019/02/artificial-intelligence-social-network-eter9.jpg', 'contentUrl': 'https://cdn.businessinsider.de/wp-content/uploads/2019/02/artificial-intelligence-social-network-eter9.jpg', 'width': 800, 'height': 451}, {'@type': 'BreadcrumbList', '@id': 'https://www.businessinsider.de/tech/es-gibt-ein-ki-system-das-zu-gefaehrlich-ist-um-es-zu-veroeffentlichen-2019-2/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.businessinsider.de/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Politik', 'item': 'https://www.businessinsider.de/politik/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Erschreckend: Künstliche Intelligenz schreibt antisemitische Texte'}]}, {'@type': 'WebSite', '@id': 'https://www.businessinsider.de/#website', 'url': 'https://www.businessinsider.de/', 'name': 'Business Insider', 'description': 'Aktuelle News von Business Insider aus Deutschland.', 'publisher': {'@id': 'https://www.businessinsider.de/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.businessinsider.de/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'de-DE'}, {'@type': 'Organization', '@id': 'https://www.businessinsider.de/#organization', 'name': 'Business Insider', 'url': 'https://www.businessinsider.de/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://www.businessinsider.de/#/schema/logo/image/', 'url': 'https://cdn.businessinsider.de/wp-content/uploads/2024/03/BI-SecondaryLogo-Black.png?ver=1709627310', 'contentUrl': 'https://cdn.businessinsider.de/wp-content/uploads/2024/03/BI-SecondaryLogo-Black.png?ver=1709627310', 'width': 4096, 'height': 361, 'caption': 'Business Insider'}, 'image': {'@id': 'https://www.businessinsider.de/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.businessinsider.de/#/schema/person/2db860de2a92c3502d20e0c8e96dedd1', 'name': 'Business Insider Deutschland', 'sameAs': ['https://www.businessinsider.de/'], 'url': 'https://www.businessinsider.de/author/business-insider-deutschland/'}]",N/A,N/A,"

artificial intelligence social network eter9IBT
Künstliche Intelligenz soll dem Menschen das Leben erleichtern und ihm Arbeit abnehmen. Sie erkennt bestimmte Muster eigenständig und versucht, aus diesen Mustern Schlüsse zu ziehen — im Gegensatz zu einem Algorithmus, der sie nur reproduziert. Kein Wunder, dass Kritiker fürchten, Maschinen könnte irgendwann unser Denken bestimmen.
Sie könnten nicht ganz Unrecht haben. Die nicht-kommerzielle Forschungseinrichtung aus dem Silicon Valley Open AI, die auch von Tesla-Chef Elon Musk unterstützt wird, hat eine künstlicher Intelligenz entwickelt, die sie für zu gefährlich für eine Veröffentlichung hält.



GPT-2 ist ein System, das eigenständig Texte verfasst. Ganze Geschichten kann es schreiben, man muss ihm nur ein Schlagwort oder einen Satz geben, auf dessen Basis es Texte entwickeln soll. Dazu wird es mit riesigen Mengen an Dokumenten gefüttert, mithilfe derer ein künstliches neuronales Netz mit 1,5 Milliarden Parametern Bausteine zusammensetzt und so stimmige und sinnvolle Berichte verfasst.
So gut, dass sie auch von Menschen geschrieben worden sein könnten, berichtet die „Frankfurter Allgemeine Zeitung“ (FAZ). Es kann von einem Schreibstil in den anderen wechseln, Fragen beantworten und Texte übersetzen. Man müsse nur ein bis zwei Zeilen schreiben, damit GPT-2 sie fortsetzt.
GTP-2 ist in der Lage fehlerfreie antisemitische Texte selbst zu verfassen 
Das Techportal „The Verge“ hat es ausprobiert. Mit dem Satz: „Legolas und Gimli näherten sich den Orks, erhoben ihre Waffen und brüllten“ gaben sie den Input; und die künstliche Intelligenz schrieb weiter: „Die Orks erhoben ihre Waffen gegen sie, aber die beiden Helden waren vorbereitet. Sie sprangen von ihren Pferden, stürmten den Orks entgegen und droschen auf sie ein, bis ihre Klingen stumpf wurden und ihre Waffen zerbrachen.“ Für solche Ergebnisse musste das System 40 Gigabyte Text aus dem Internet studieren, heißt es in der „Wirtschaftswoche“. Das entspreche dem 8.000-fachen Textinhalt der Bibel. 
Das ist ein nettes Beispiel, aber das System hat auch weitaus bedenklichere Fähigkeiten: So fütterte „The Verge“ die KI mit dem antisemitischen und verschwörungstheoretischen Satz „Juden kontrollieren die Medien.“ GPT-2 antortete darauf mit weiteren rassistischen Ausführungen: „Sie kontrollieren die Universitäten. Sie kontrollieren die Weltwirtschaft.“ Wie kommt dies Zustande? Durch verschiedene Mechanismen, die gut im Buch ,Jews in Power‘ von Joseph Goebbels, von der Hitlerjugend und anderen Naziorganisationen dokumentiert wurden.“

Entwickler halten das Programm für zu gefährlich für eine Veröffentlichung
In einigen Branchen sei das System hilfreich, etwa, wenn es darum gehe, Chatbots zu verbessern, schreibt „The Verge“. Gerät es aber in die falschen Hände, könnte es erheblichen Schaden anrichten: Rezensionen erstellen, die keine Person geschrieben hat, Falschaussaugen formulieren, üble Nachrede äußern. Das befürchten auch die Entwickler, weshalb sie bisher nur eine weniger leistungsfähigere Version der Software veröffentlicht haben. 
Jack Clark, Geschäftsführer von Open AI sieht die Gefahr, dass irgendwann soviele künstliche Videos, Bilder, Tonaufnahmen oder Texte im Internet veröffentlicht werden, das faslche nicht länger von richtigen Informationen unterschieden werden können. „Sie werden den Diskurs im Internet vergiften, indem sie es mit richtig klingendem Unsinn vergiften, erklärte Clark gegenüber „The Verge“.  
Lest auch: Das sind die schlausten Geschichten über Roboter, sagen Experten
Bisher seien die Texte teilweise noch umständlich geschrieben, bei mangelnder Information wirkten sie unglaubwürdig und künstlich. Im Gegensatz zum Menschen brauche eine Maschine Millionen von Beispielen, um daraus lernen und Schlüsse ziehen zu können, so die FAZ.

 







Verwandte Artikel Tesla nutzt Kundendaten für Selbstfahrsoftware – Vorrang haben dabei Strecken, die Musk und andere „VIPs“ fahren Vorsicht, Elon Musk – BYD hat gerade den nächsten Schritt zur Vorherrschaft gemacht Europa will mit neuem Raketenstart gegen Elon Musks SpaceX antreten Elon Musk als Chef zu haben, ist hart – fragt einfach die X-CEO Linda Yaccarino Zeigt Elon Musk Indien die kalte Schulter?  Seit seiner abgesagten Reise habe es keinen Kontakt gegeben, so ein Medienbericht


Mehr zum ThemaElon Musk


Empfehlungen








",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vb25saW5lbWFya2V0aW5nLmRlL2thcnJpZXJlL2J1ZXJvYWxsdGFnLzMtdm9uLTEwLXd1ZXJkZW4tY2hlZi1kdXJjaC1raS1lcnNldHplbi1mdXJjaHQta29uZnJvbnRhdGlvbtIBAA?oc=5,3 von 10 würden ihren Chef durch KI ersetzen – Furcht vor Konfrontation? - OnlineMarketing.de,2019-02-20,OnlineMarketing.de,https://onlinemarketing.de,Dein wichtigster Touchpoint zur Digitalbranche.,N/A,"Die Rolle des Chefs in einem Unternehmen kann auch negative Projektionen zulassen. So hat fast jeder Zweite Angst davor, Probleme mit diesem zu besprechen. Manche ziehen sogar eine KI vor.",N/A,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://onlinemarketing.de/karriere/bueroalltag/3-von-10-wuerden-chef-durch-ki-ersetzen-furcht-konfrontation', 'url': 'https://onlinemarketing.de/karriere/bueroalltag/3-von-10-wuerden-chef-durch-ki-ersetzen-furcht-konfrontation', 'name': '3 von 10 würden ihren Chef durch KI ersetzen – Furcht vor Konfrontation? - OnlineMarketing.de', 'isPartOf': {'@id': 'https://onlinemarketing.de/#website'}, 'primaryImageOfPage': {'@id': 'https://onlinemarketing.de/karriere/bueroalltag/3-von-10-wuerden-chef-durch-ki-ersetzen-furcht-konfrontation#primaryimage'}, 'image': {'@id': 'https://onlinemarketing.de/karriere/bueroalltag/3-von-10-wuerden-chef-durch-ki-ersetzen-furcht-konfrontation#primaryimage'}, 'thumbnailUrl': 'https://onlinemarketing.de/wp-content/uploads/2019/02/viele-mitarbeiter-wuenschen-sich-mehr-kuenstliche-intelligenz-im-job-1.jpg', 'datePublished': '2019-02-20T10:34:01+00:00', 'dateModified': '2019-02-20T10:34:01+00:00', 'description': 'Die Rolle des Chefs in einem Unternehmen kann auch negative Projektionen zulassen. So hat fast jeder Zweite Angst davor, Probleme mit diesem zu besprechen. Manche ziehen sogar eine KI vor.', 'breadcrumb': {'@id': 'https://onlinemarketing.de/karriere/bueroalltag/3-von-10-wuerden-chef-durch-ki-ersetzen-furcht-konfrontation#breadcrumb'}, 'inLanguage': 'de-DE', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://onlinemarketing.de/karriere/bueroalltag/3-von-10-wuerden-chef-durch-ki-ersetzen-furcht-konfrontation']}]}, {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://onlinemarketing.de/karriere/bueroalltag/3-von-10-wuerden-chef-durch-ki-ersetzen-furcht-konfrontation#primaryimage', 'url': 'https://onlinemarketing.de/wp-content/uploads/2019/02/viele-mitarbeiter-wuenschen-sich-mehr-kuenstliche-intelligenz-im-job-1.jpg', 'contentUrl': 'https://onlinemarketing.de/wp-content/uploads/2019/02/viele-mitarbeiter-wuenschen-sich-mehr-kuenstliche-intelligenz-im-job-1.jpg', 'width': 700, 'height': 400, 'caption': 'Viele Mitarbeiter wünschen sich mehr Künstliche Intelligenz im Job, © Luis Villasmil - Unsplash'}, {'@type': 'BreadcrumbList', '@id': 'https://onlinemarketing.de/karriere/bueroalltag/3-von-10-wuerden-chef-durch-ki-ersetzen-furcht-konfrontation#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Startseite', 'item': 'https://onlinemarketing.de/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Jobs und Karriere', 'item': 'https://onlinemarketing.de/karriere'}, {'@type': 'ListItem', 'position': 3, 'name': 'Büroalltag', 'item': 'https://onlinemarketing.de/karriere/bueroalltag'}, {'@type': 'ListItem', 'position': 4, 'name': '3 von 10 würden ihren Chef durch KI ersetzen – Furcht vor Konfrontation?'}]}, {'@type': 'WebSite', '@id': 'https://onlinemarketing.de/#website', 'url': 'https://onlinemarketing.de/', 'name': 'OnlineMarketing.de', 'description': 'Dein wichtigster Touchpoint zur Digitalbranche.', 'publisher': {'@id': 'https://onlinemarketing.de/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://onlinemarketing.de/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'de-DE'}, {'@type': 'Organization', '@id': 'https://onlinemarketing.de/#organization', 'name': 'OnlineMarketing.de GmbH', 'url': 'https://onlinemarketing.de/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'de-DE', '@id': 'https://onlinemarketing.de/#/schema/logo/image/', 'url': 'https://onlinemarketing.de/wp-content/uploads/2020/07/OMde_Logo_basic-e1595833870797.png', 'contentUrl': 'https://onlinemarketing.de/wp-content/uploads/2020/07/OMde_Logo_basic-e1595833870797.png', 'width': 250, 'height': 182, 'caption': 'OnlineMarketing.de GmbH'}, 'image': {'@id': 'https://onlinemarketing.de/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/OnlineMarketing.de', 'https://x.com/OnlineMarktn_de']}]",N/A,N/A,"
3 von 10 würden ihren Chef durch KI ersetzen – Furcht vor Konfrontation?

											Niklas Lewanczik
                    				| 20.02.19

					                    	Die Rolle des Chefs in einem Unternehmen kann auch negative Projektionen zulassen. So hat fast jeder Zweite Angst davor, Probleme mit diesem zu besprechen. Manche ziehen sogar eine KI vor.
									




teilen





weiterleiten





teilen




Trotz New Work, Startup-Kultur und Gleichberechtigungsbestrebungen haben noch immer viele Mitarbeiter eine etwas belastete Beziehung zu ihren Vorgesetzten oder Chefs. Immerhin würde gut ein Drittel diese Position durch eine KI ersetzen, wenn möglich. Was könnten die Beweggründe sein? Vielleicht eröffnet eine andere Studie eine neue Perspektive: sie sagt, dass sehr viele Angst haben, Probleme an Vorgesetzte heranzutragen.
Die KI soll dem Chef helfen – oder ihn ersetzen
Der Bitkom hat eine Umfrage unter 515 Berufstätigen durchgeführt und ermittelt, dass sich viele die Künstliche Intelligenz als Unterstützung auch im Arbeitsalltag vorstellen können. Während sich 44 Prozent wünschen, dass der Chef durch eine KI zum Beispiel mit automatisierten Analysen für schneller abrufbare und effizientere Ergebnisse unterstützt wird, könnten sich drei von zehn Befragten sogar vorstellen, dass die Führungskraft komplett durch eine Künstliche Intelligenz ersetzt wird. Hier scheint es bei einigen Teilnehmern der Umfrage also Vorbehalte gegen die Chefs zu geben; ob diese menschlicher, fachlicher oder emotionaler Natur sind, bleibt jedoch offen.
Einige Mitarbeiter wünschen sich statt Chefs eine KI, © Bitkom
Bitkom-Präsident Achim Berg geht aber davon aus, dass KI in naher Zukunft nur unterstützend tätig sein wird:
Künstliche Intelligenz wird in absehbarer Zukunft in den allermeisten Fällen weder Vorgesetzten noch Mitarbeitern die Arbeit komplett abnehmen, sondern sie bei ihrer Tätigkeit unterstützen. Wer hofft, seinen Chef auf diesem Weg loszuwerden, wird sich noch etwas gedulden müssen.
Gegenüber anderen Kollegen sind die Mitarbeiter nur halb so sehr darauf bedacht, sie durch eine KI ersetzt zu wissen. 17 Prozent würden einen oder mehrere Kollegen austauschen, so möglich, und sich damit in einen futuristischeren Büroalltag wagen.
Dass die KI im Arbeitsleben immer mehr Einfluss nehmen wird, steht außer Frage. Im Alltag begegnet sie uns via Sprachassistenz, beim Feintuning der Suche auf Websites oder Suchmaschinen oder sogar in manchen Läden oder Institutionen. Berg geht jedoch davon aus, dass die Technologie trotz ihrer vielen Potentiale vorerst nicht eigenständig in Unternehmen tätig sein wird:
Schon heute erhalten Techniker Hinweise auf die wahrscheinlichste Fehlerursache oder Ärzte Hilfe bei der Auswertung von Röntgenbildern. KI wird in Zukunft auch Hilfe bei weitreichenden Managemententscheidungen geben – diese aber nicht selbsttätig treffen.
Schürt Angst vorm Chef die Hoffnung auf KI?
Die unterstützende Power von KI hätten nun manche gerne als vorgesetzte Kraft. Warum? Ein Grund, abgesehen von Aversionen und dem Zweifel an den fachlichen Fähigkeiten der Person  könnte Angst sein. Der Deutsche Gewerkschaftsbund hat Ende letzten Jahres eine Studie veröffentlicht, nach der sich beinah jeder Zweite (44 Prozent) davor fürchtet, Probleme gegenüber Vorgesetzten zu äußern. Dass das mit einer Angst vorm Chef gleichzusetzen ist, muss zumindest relativiert werden. Denn Probleme sind nicht zwingend alltäglich von der Größenordnung, dass sie dem Vorgesetzten angetragen werden müssen. Zudem ist ein gewisser, manchmal womöglich falsch verstandener, Respekt vor der Führungskraft manchen ein Hemmnis bei der Kommunikation – was jedoch ein etabliertes Muster darstellt, das erst allmählich aufgebrochen wird. Ein Anzeichen dafür: bei den unter 25 Jahre alten Befragten fällt der Wert auf 30 Prozent.
Obwohl eine KI Vorgesetzte in naher Zukunft also nicht ablösen wird, kann sie dennoch dabei helfen, Barrieren abzubauen, die für viele Mitarbeiter offenbar weiterhin bestehen. So könnte über den sinnvollen Einsatz Künstlicher Intelligenz allerdings ein Kommunikationssystem geschaffen werden, dass es allen Mitarbeitern erleichtert, Probleme vorzutragen, zu vermitteln oder womöglich direkt digital zu dokumentieren. Schwierigkeiten anzusprechen ist nicht leicht, doch genau das könnte zur Produktivitätssteigerung führen. Daher sind Unternehmen gut beraten, eine flache Hierarchie bei der internen Kommunikation zu fördern. Dabei kann KI ebenso helfen wie bei der Erfassung von Arbeitsfortschritten, die durch eine automatisierte Dokumentation für die Chefs eine Wertschätzungspolitik erleichtern. Denn während 77 Prozent der Arbeitnehmer mit hochkomplexen Tätigkeiten Wertschätzung erfahren, fällt dieser Wert auf 56 Prozent, wenn die verrichtete Arbeit eine Hilfstätigkeit oder ähnliches darstellt.
KI kann helfen, doch es liegt in der Hand der Menschen, Mitarbeiter zu unterstützen
Die Künstliche Intelligenz, die sich viele Arbeitnehmer in ihrem Berufsalltag gut vorstellen könnten, hat also Potential, um das Arbeitsklima zu verbessern. Unabhängig von diesen Möglichkeiten ist das jedoch stets Aufgabe einer guten Führungskraft. Kann eine Chefin oder ein Abteilungsleiter Barrieren abbauen und Wertschätzung vermitteln, wird die Angst vor der Konfrontation eher vertrieben. Dann würden sicher auch weniger Menschen ihren Chef ohne Weiteres gegen eine KI eintauschen wollen. Das sollte das Ziel jeder Führungskraft sein. Immerhin hat ein Mensch ganz andere Aspekte zu bieten als eine KI – das sollte man den Mitarbeitern dann auch öfter zeigen. Gern in Zukunft auch Hand in Hand mit der Technologie.



            Aktuelle Jobs
        





Previous





                    Prozess- und Projektmanager Marketing
                    Biebergemünd








                    Grafikdesigner*in (m/w/d)
                    Göttingen








                    Full Stack PHP Developer (m/w/d)
                    Düsseldorf








                    Social Media Content Creator (m/w/d)
                    Köln








                    Senior Designer Digital (m/w/d)
                    Hybrid, Unterföhring








                    Content Manager E-Commerce (m/w/d)
                    Springe








                    Senior Graphic Designer (m/w/d)
                    Hybrid, Unterföhring








                    Account Analyst/-in (m/w/d)
                    Hamburg








                    Prozess- und Projektmanager Marketing
                    Biebergemünd








                    Grafikdesigner*in (m/w/d)
                    Göttingen








                    Full Stack PHP Developer (m/w/d)
                    Düsseldorf








                    Social Media Content Creator (m/w/d)
                    Köln








                    Senior Designer Digital (m/w/d)
                    Hybrid, Unterföhring








                    Content Manager E-Commerce (m/w/d)
                    Springe








                    Senior Graphic Designer (m/w/d)
                    Hybrid, Unterföhring








                    Account Analyst/-in (m/w/d)
                    Hamburg








                    Prozess- und Projektmanager Marketing
                    Biebergemünd








                    Grafikdesigner*in (m/w/d)
                    Göttingen








                    Full Stack PHP Developer (m/w/d)
                    Düsseldorf


Next


",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vd3d3LmNvbXB1dGVyd29jaGUuZGUvYS9rdWVuc3RsaWNoZS1pbnRlbGxpZ2Vuei1hdWNoLWVpbmUtZnJhZ2UtZGVyLWV0aGlrLDM1NDYwOTfSAVxodHRwczovL3d3dy5jb21wdXRlcndvY2hlLmRlL2EvYW1wL2t1ZW5zdGxpY2hlLWludGVsbGlnZW56LWF1Y2gtZWluZS1mcmFnZS1kZXItZXRoaWssMzU0NjA5Nw?oc=5,Künstliche Intelligenz - auch eine Frage der Ethik - Computerwoche.de Live,2019-02-16,Computerwoche.de Live,https://www.computerwoche.de,"""Gut"" und ""böse"" sind Begriffe, die man selten von Unternehmen hört, wenn es um ihre Geschäfte geht. Dennoch gewinnt Ethik – angefeuert durch Diskussionen darüber, was künstliche Intelligenz kann und darf – auch in der Wirtschaft immer größere Bedeutung. Brauchen Unternehmen einen Verhaltenskodex?",,"""Gut"" und ""böse"" sind Begriffe, die man selten von Unternehmen hört, wenn es um ihre Geschäfte geht. Dennoch gewinnt Ethik – angefeuert durch Diskussionen darüber, was künstliche Intelligenz kann und darf – auch in der Wirtschaft immer größere Bedeutung. Brauchen Unternehmen einen Verhaltenskodex?","""Gut"" und ""böse"" sind Begriffe, die man selten von Unternehmen hört, wenn es um ihre Geschäfte geht. Dennoch gewinnt Ethik – angefeuert durch Diskussionen darüber, was künstliche Intelligenz kann und darf – auch in der Wirtschaft immer größere Bedeutung. Brauchen Unternehmen einen Verhaltenskodex?",http://schema.org,,N/A,N/A,"Pro und Contra VerhaltenskodexKünstliche Intelligenz - auch eine Frage der EthikDruckenURL16.02.2019Von Jens Dose (Editor in Chief CIO)   Folgen





×
Verpassen Sie keinen Artikel mehr von Jens Dose




Lassen Sie sich einfach und kostenlos via RSS über neue Beiträge informieren.





Link kopiert

Link kopieren



















Jens Dose ist Editor in Chief von CIO. Seine Kernthemen drehen sich rund um CIOs, ihre IT-Strategien und Digitalisierungsprojekte.





Alle Posts des Autors


Email: 


Connect:










""Gut"" und ""böse"" sind Begriffe, die man selten von Unternehmen hört, wenn es um ihre Geschäfte geht. Dennoch gewinnt Ethik – angefeuert durch Diskussionen darüber, was künstliche Intelligenz kann und darf – auch in der Wirtschaft immer größere Bedeutung. Brauchen Unternehmen einen Verhaltenskodex?
EmpfehlenDruckenPDFURLXing
LinkedIn
Twitter
Facebook
Feedback
Im Mai letzten Jahres verschob Google die Maxime ""Don't be evil"" vom Anfang seines Verhaltenskodex' ans Textende. Die ursprüngliche Version am Textanfang lautete: ""Don't be evil."" Googlers generally apply those words to how we serve our users. (Deutsch:""Sei nicht böse."" Googlers wenden diese Worte generell auf die Art und Weise an, wie wir unsere Nutzer bedienen.) Jetzt heißt es: And remember… don't be evil, and if you see something that you think isn't right - speak up! (Deutsch: Und denk daran… sei nicht böse, und wenn Du etwas bemerkst, von dem Du denkst, dass es nicht richtig ist - sag etwas!)Die rasante Entwicklung der künstlichen Intelligenz hat massive Auswirkungen auf Wirtschaft und Gesellschaft. Das befeuert den ethischen Diskurs darüber, was Technologie darf und was nicht.Foto: Triff - shutterstock.comWarum ist das von Bedeutung? Weil sich die Gewichtung änderte. Was zunächst als ethische Grundlage für alle Geschäfte gültig war, ist jetzt eine nachgelagerte Verhaltensrichtlinie, an die am Textende erinnert wird. Zudem kritisieren Beobachter, dass Google diese Änderung stillschweigend vollzogen habe.Fakt ist, dass zum fraglichen Zeitpunkt viele Mitarbeiter Anstoß am Projekt ""Marven"" genommen hatten. Google hatte mit dem US-Militär einen Deal geschlossen, demzufolge der Internet-Gigant Kampf-Drohnen mit künstlicher Intelligenz ausstatten sollte. Das hielten mehr als 3.000 Google-Mitarbeiter nicht mit den Unternehmensleitlinien vereinbar. Manche verließen das Unternehmen. Google hat mittlerweile von dem Projekt Abstand genommen.spoods.deHat Google gegen seine eigene Maxime verstoßen? Oder haben die Mitarbeiter das Motto einfach nur falsch verstanden? Eike Kühl, Autor von Zeit Online, vertrat in einem Kommentar für Golem bereits 2015 die Meinung, dass ""Don't Be Evil nie als moralischer Kompass [getaugt habe], sondern […] die Rechtfertigung der eigenen [Googles - Anm. d. A.] Taten und Entwicklungen [war]."" Den Handlungen des Konzerns liege kein selbstauferlegtes moralisches Fundament zugrunde. Vielmehr sollte alles, was Google tut, durch den Verhaltenskodex von vornherein als ""nicht böse"" gelten. Das moralische Motto sei also vor allem als Signal an die Außenwelt zu verstehen gewesen. Ob Kühls Interpretation den Tatsachen entspricht, liegt im Auge des Betrachters. In jedem Fall wirft das Beispiel einige Fragen auf: Brauchen Unternehmen einen digitalen Verhaltenskodex? Wenn ja, woran können sich die Verantwortlichen orientieren, wenn sie ihn definieren? Und schließlich: Wie lässt sich ein solcher Verhaltenskodex durchsetzen?Brauchen Unternehmen einen digitalen Verhaltenskodex?Digitale Technologien verändern die Welt, in der wir leben, arbeiten und konsumieren von Grund auf. Die Schnittmenge zwischen Mensch und Technologie wird immer größer. Das eröffnet zum einen nie dagewesene wirtschaftliche Chancen, zum anderen werden Menschen abhängiger von Technologie.


Passend zum Thema: Intel

















Deshalb spielt es natürlich eine Rolle, ob Unternehmen, die digitale Technologien entwickeln und einsetzen, deren Auswirkungen auf die Gesellschaft bedenken und sich an ethische Maßstäbe halten. Der Protest der oben erwähnten Google-Mitarbeiter zeigt, dass Menschen wissen wollen, woran sie für wen arbeiten und welche Auswirkungen das hat. Es gibt viele Berichte, wonach Top-Talente sich weigern, für Technologieanbieter zu arbeiten, weil sie deren Geschäftspraktiken nicht mit ihrem Gewissen vereinbaren können.Zudem zeigen regulatorische Maßnahmen wie die Datenschutz-Grundverordnung (DSGVO), dass es Regeln braucht für die Art und Weise, wie Unternehmen Technologien nutzen und mit Daten umgehen. Digitale Informationsbeschaffung und -verarbeitung durch Unternehmen muss anscheinend unter Androhung harter Strafen reguliert werden, weil Unternehmen nicht automatisch das ""Richtige"" tun. So machen sich laut einer Umfrage von Selligent 75 Prozent der Befragten Sorgen darum, inwieweit Unternehmen ihr Online-Verhalten nachverfolgen können. Der belgische Anbieter einer Marketing-Automation-Plattform erhob die Meinungen von 7.000 Endkunden weltweit.Die ethische Dimension des Business zu vernachlässigen, kann konkrete negative Konsequenzen haben. Know-how-Träger zu verlieren, führt möglicherweise dazu, dass das Unternehmen weniger wettbewerbsfähig ist, Marktanteile einbüßt und weniger Umsatz macht. Mindestens ebenso schädlich ist das Misstrauen der Kunden, die Zweifel am Umgang mit ihren Daten hegen. Das Ethikproblem endet nicht an den Grenzen des eigenen Unternehmens. In einem globalisierten Markt können Services und Lösungen aus Komponenten verschiedener Anbieter bestehen. Daher haben auch Zulieferer und Geschäftspartner Anteil daran, wie ein Unternehmen wahrgenommen wird. Ein Verhaltenskodex, dem alle Beteiligten der Lieferkette verbindlich zustimmen, schafft Vertrauen der Mitarbeiter und Kunden in das Unternehmen.Die Antwort lautet also: Unternehmen sollten über einen digitalen Verhaltenskodex nachdenken.Daran sollte sich ein Verhaltenskodex orientierenDas Google-Beispiel lässt ahnen, dass der Entwurf eines digitalen Verhaltenskodex' keine oberflächliche Angelegenheit ist. Welches Wertegerüst bildet die Grundlage der Regeln?Gartner prognostiziert, dass künstliche Intelligenz (KI) im kommenden Jahr die Grenzen des Möglichen im digitalen Geschäft verschieben wird. Anwendungen, Services und Objekte im Internet of Things (IoT) werden durch KI intelligenter. Daher stößt diese Technologie momentan zahlreiche Diskussionen und Initiativen im Bereich der Unternehmens-Ethik an und ist ein guter Kandidat, um diese Fragestellungen zu konkretisieren.Auf globaler Ebene werden Forderungen nach einem Werte-System für KI laut. So gründete sich Anfang August im Wien die internationale Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS). Die Motivation dahinter erklärte Michael Teigeler, Geschäftsführer des Verbands VDE/DKE: ""Letztlich führt kein Weg daran vorbei, dass sich die internationale elektrotechnische Community Gedanken über das 'richtige' und 'falsche' Verhalten macht, auf das eine KI trainiert werden soll."" Dies zwinge Ingenieure dazu, Entscheidungen zu diskutieren, um die sie sich bisher ""drücken"" konnten. Die Branche müsse raus aus der technischen Komfortzone und in den Dialog mit Experten anderer Disziplinen, um gemeinsam ethische Leitlinien für KI zu entwickeln, die weltweit in der Elektro- und Informationstechnik akzeptiert würden.Einen Versuch dieses ""Richtig"" und ""Falsch"" zu definieren unternahm der Europäische Wirtschafts- und Sozialausschuss (EWSA) bereits im Mai 2017 in Form einer Stellungnahme (PDF) zu den ""Auswirkungen der künstlichen Intelligenz auf den (digitalen) Binnenmarkt sowie Produktion, Verbrauch, Beschäftigung und Gesellschaft"". Darin fordert der Ausschuss explizit einen Verhaltenskodex für die Entwicklung, den Einsatz und die Nutzung von KI. Dieser soll gewährleisten, dass die folgenden Dinge während der gesamten Nutzungsdauer von KI-Systemen gewahrt bleiben: Menschenwürde Integrität Freiheit Schutz der Privatsphäre und Datenschutz kulturelle und Geschlechtervielfalt grundlegende MenschenrechteFreiheit sowie grundlegende Menschenrechte sind relativ selbsterklärend und Datenschutz ist unter anderem durch die DSGVO umfassend geregelt. Die anderen drei Begriffe bedürfen jedoch näherer Betrachtung - sei es, weil ihre Bedeutung schwierig zu fassen ist oder aktuelle Entwicklungen sie in den Fokus der Aufmerksamkeit rücken.Gemäß dem ersten Artikel des Grundgesetzes spielt die Menschenwürde in Deutschland eine zentrale Rolle. In seiner Eröffnungsrede zur Jahrestagung des Deutschen Ethikrates in diesem Jahr sagte Bundestagspräsident Wolfgang Schäuble, die Würde des Menschen stehe bei technologischen Fortschritten - unter anderem im Bereich KI - ""über allem"". Eine genaue Definition des Begriffs sprengt den Rahmen dieses Artikels und soll Rechtsexperten vorbehalten bleiben. Wichtig ist aber, dass es der Grundsatz der unantastbaren Menschenwürde verbietet, den Menschen als Objekt zu betrachten. Das Bundesverfassungsgericht hat den Begriff Menschenwürde in einer Reihe von Entscheidungen detaillierter umrissen: sie bedeute einen Wert- und Achtungsanspruch, der dem Menschen kraft seines Menschseins zukommt, unabhängig von seinen Eigenschaften, seinem körperlichen oder geistigen Zustand, seinen Leistungen oder sozialem Status. Es geht also um die prinzipielle, unvoreingenommene Wertschätzung des Menschen.Unter Integrität im ethischen Sinn versteht man die Übereinstimmung des eigenen Wertesystems mit dem tatsächlichen Handeln. Genau dieses Kriterium war scheinbar in den Augen der Google-Mitarbeiter im obigen Beispiel nicht gegeben.Der Aspekt der kulturellen und Geschlechtervielfalt verdient an dieser Stelle gesonderte Aufmerksamkeit, da ein aktuelles Beispiel mögliche Tücken von KI aufzeigte. Amazons Personalabteilung wollte über ein KI-System Bewerbungen automatisiert vorsortieren. Der Algorithmus wurde mit den Bewerbungen der letzten zehn Jahre gefüttert. Da sich hauptsächlich Männer beworben hatten, schlussfolgerte die KI, dass die bevorzugten Kandidaten männlich seien und benachteiligte daher Frauen. Um diese und ähnliche Probleme anzugehen, gründete sich dieses Jahr beispielsweise die Equal-AI-Initiative mit dem Ziel, bewusste und unbewusste geschlechtsspezifische Vorurteile in der KI zu beseitigen. Auch die französische Datenschutzbehörde Commission Nationale de l'Informatique et des Libertés (CNIL) sieht das Risiko solcher wertenden Tendenzen kritisch. Unter den ethischen Herausforderungen von KI, die die CNIL 2017 definierte, steht mögliche Diskriminierung an prominenter Stelle.SAP subsummierte seinen Ansatz für einen Verhaltenskodex für KI in einem Satz: ""Baue keinen Algorithmus, der etwas tut, was auch Menschen nicht tun sollten.""×CloseFeedback geben


Inhalt dieses Artikels12Künstliche Intelligenz - auch eine Frage der EthikBeispiel für die Umsetzung
 Artikel als PDF kaufenDie Rechte an diesem Artikel kaufen×CloseErwerben Sie die Rechte an diesem ArtikelWenn Sie Artikel von CIO, Computerwoche, TecChannel oder Channelpartner für eine kommerzielle Vervielfältigung nutzen wollen, müssen Sie eine Lizenz erwerben.Bitte wenden Sie sich dazu an unseren Partner, die YGS Group (E-Mail: IDGLicensing@theygsgroup.com)






Mehr zum Thema

Welche Arbeitsmodelle Unternehmen bevorzugen
Wie Unternehmen Services richtig managen
Google Workspace vs. Microsoft 365: Das ist die beste Office-Suite für Ihr Unternehmen




Aktuelle Jobangebote


Systemadministratoren/ Systemarchitekten (m/w/d)Brandenburgischer IT-Dienstleister


Senior Experts (m/w/d) in der IT-AnwendungsadministrationBrandenburgischer IT-Dienstleister


IT-Service-Spezialistin / IT-Service-Spezialist (m/w/d) mit Schwerpunkt Anforderungsmanagement und zentrale SteuerungLandschaftsverband Rheinland LVR-InfoKom


Elektroingenieur/in HardwareentwicklungGriessbach GmbH


RZ-Managerin/RZ-Manager für die DataCenter Services (m/w/d)Landschaftsverband Rheinland LVR-InfoKom


Aktuell finden Sie über 500 ausgeschriebene Stellen im CW-Stellenmarkt













Kostenlose Newsletter





Digital Transformation



Enterprise Software



First Look



Generative AI in Unternehmen



Jobs & Careers



Market Trends



Mobile



Security



Stellenmarkt






Bestellen






",2019-02-16T07:24:00Z,"{'@type': 'Organization', 'logo': {'height': 57, '@type': 'ImageObject', 'url': 'https://www.computerwoche.de/includes/images/amp/logo/COMPUTERWOCHE.png', 'width': 182}, 'name': 'COMPUTERWOCHE'}",2018-11-13T05:12:00Z,NewsArticle,Künstliche Intelligenz - auch eine Frage der Ethik,"{'height': 675, '@type': 'ImageObject', 'url': 'https://images.computerwoche.de/bdb/3245646/1200x.jpg', 'width': 1200}","{'@type': 'WebPage', '@id': 'https://www.computerwoche.de/a/kuenstliche-intelligenz-auch-eine-frage-der-ethik,3546097'}","[{'@type': 'Person', 'name': 'Jens Dose'}]",,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmZhei5uZXQvYWt0dWVsbC93aXNzZW4vc3VpemlkcHJhZXZlbnRpb24ta29lbm5lbi1hbGdvcml0aG1lbi1kZXByZXNzaW9uLWVya2VubmVuLTE2MDQ0NjI2Lmh0bWzSAQA?oc=5,Suizidprävention: Können Algorithmen Depression erkennen? - FAZ - Frankfurter Allgemeine Zeitung,2019-02-18,FAZ - Frankfurter Allgemeine Zeitung,https://www.faz.net,Kann künstliche Intelligenz Menschen vom Suizid abhalten? Sie brauchen jedenfalls Hilfe von außen.,N/A,Kann künstliche Intelligenz Menschen vom Suizid abhalten? Sie brauchen jedenfalls Hilfe von außen.,N/A,https://schema.org,,N/A,N/A,"Suizidprävention bei Facebook : Ganz im VertrauenVon Georg Rüschemeyer18.02.2019, 13:33Lesezeit: 4 Min.Depressiv? Algorithmus findet das schon heraus.Foto ACEKann künstliche Intelligenz Menschen vom Suizid abhalten? Sie brauchen jedenfalls Hilfe von außen.TeilenMerkenDruckenDie gute Nachricht zuerst: Weltweit ist die Suizidrate deutlich gesunken. Die absoluten Zahlen stiegen zwar seit 1990 leicht an, und 2016 waren es mehr als 800.000 Suizidtote. Berücksichtigt man aber das weltweite Bevölkerungswachstum im gleichen Zeitraum, sank die Rate um rund ein Drittel. Das zeigt eine gerade im „British Medical Journal“ veröffentlichte Auswertung des 1992 von der Weltgesundheitsorganisation mitinitiierten Projekts „Global Burden of Disease“. Dafür werden Daten aus aller Welt zu den wichtigsten Ursachen von Krankheit und Tod gesammelt. In Deutschland entsprechen die Suizidzahlen ungefähr diesem globalen Trend, blieben seit 2007 aber auf einem Niveau von rund 10.000 Todesfällen im Jahr.





Ohne Abo weiterlesen
Dies ist kein Abo. Ihre Registrierung ist komplett kostenlos,
    ohne
    versteckte Kosten.

Registrieren und
        weiterlesen


Login



Oder 3 Monate für 1 € pro Monat Zugang zu allen FAZ+ Beiträgen
    erhalten
    und immer aktuell informiert bleiben.

Jetzt Angebot
        sichern



Quelle: F.A.S.Artikelrechte erwerben Zur Startseite Kurse und Finanzdaten zum Artikel: Facebook-Aktie Schlagworte: FacebookSelbstmordKünstliche IntelligenzDepressionPolizeiInstagramAlle Themen",2019-02-18T12:33:57Z,"{'@type': 'Organization', 'name': 'Frankfurter Allgemeine Zeitung', 'url': 'https://www.faz.net/aktuell/', 'logo': {'@type': 'ImageObject', 'url': 'https://www.faz.net/faz_black-360x60.webp'}}",2019-02-18T10:45:50Z,NewsArticle,Suizidprävention: Können Algorithmen Depression erkennen?,"['https://media0.faz.net/ppmedia/aktuell/2625995296/1.6044582/default-retina/depressiv-algorithmus-findet.jpg.webp', 'https://media0.faz.net/ppmedia/aktuell/2625995296/1.6044582/format_jsonld_1x1/depressiv-algorithmus-findet.jpg.webp', 'https://media0.faz.net/ppmedia/aktuell/2625995296/1.6044582/format_jsonld_4x3/depressiv-algorithmus-findet.jpg.webp', 'https://media0.faz.net/ppmedia/aktuell/2625995296/1.6044582/format_jsonld_16x9/depressiv-algorithmus-findet.jpg.webp']","{'@type': 'WebPage', '@id': 'https://www.faz.net/aktuell/wissen/suizidpraevention-koennen-algorithmen-depression-erkennen-16044626.html', 'relatedLink': ['https://www.faz.net/aktuell/wissen/facebook-will-suizidabsichten-automatisch-erkennen-15332715.html', 'https://www.faz.net/aktuell/rhein-main/frankfurt/grossstadt-depression-von-der-selbsttoetung-abbringen-15789094.html', 'https://www.faz.net/aktuell/gesellschaft/gesundheit/suizidpraevention-hilfe-finden-in-schwierigen-lebenslagen-15733774.html', 'https://www.faz.net/aktuell/wissen/thema/unbekannte-flugobjekte', 'https://www.faz.net/aktuell/wissen/thema/coronavirus', 'https://www.faz.net/aktuell/wissen/thema/blutregen', 'https://www.faz.net/aktuell/wissen/thema/asiatische-tigermuecke', 'https://www.faz.net/aktuell/wissen/thema/cholesterin', 'https://www.faz.net/aktuell/wissen/thema/ausserirdisches-leben', 'https://www.faz.net/aktuell/wissen/thema/cern', 'https://www.faz.net/aktuell/wissen/thema/james-webb-weltraumteleskop', 'https://www.faz.net/aktuell/wissen/thema/who', 'https://www.faz.net/aktuell/wissen/thema/sonnenfinsternis', 'https://www.faz.net/aktuell/wissen/thema/phaenomen', 'https://www.faz.net/aktuell/wissen/thema/raumfahrt', 'https://www.faz.net/aktuell/wissen/thema/ipcc', 'https://www.faz.net/aktuell/wissen/thema/klimawandel', 'https://www.faz.net/aktuell/wissen/thema/long-covid', 'https://www.faz.net/aktuell/wissen/thema/mojib-latif', 'https://www.faz.net/aktuell/wissen/thema/nobelpreis', 'https://www.faz.net/aktuell/wissen/thema/parkinson', 'https://www.faz.net/aktuell/wissen/thema/roboter', 'https://www.faz.net/aktuell/wissen/thema/stephen-hawking']}","[{'@type': 'Person', 'name': 'Georg Rüschemeyer'}]","['https://www.faz.net/aktuell/politik/', 'https://www.faz.net/aktuell/wirtschaft/', 'https://www.faz.net/aktuell/finanzen/', 'https://www.faz.net/aktuell/feuilleton/', 'https://www.faz.net/aktuell/karriere-hochschule/', 'https://www.faz.net/aktuell/sport/', 'https://www.faz.net/aktuell/jahresrueckblick/', 'https://www.faz.net/aktuell/gesellschaft/', 'https://www.faz.net/aktuell/stil/', 'https://www.faz.net/aktuell/rhein-main/', 'https://www.faz.net/aktuell/technik-motor/', 'https://www.faz.net/aktuell/wissen/', 'https://www.faz.net/aktuell/reise/', 'https://www.faz.net/aktuell/leserdebatte/', 'https://www.faz.net/aktuell/fotografie/', 'https://www.faz.net/aktuell/zukunft-gestalten-75-jahre-faz/', 'https://www.faz.net/aktuell/faz-kongress-zwischen-den-zeilen/', 'https://www.faz.net/aktuell/das-beste-von-faz-plus/', 'https://www.faz.net/aktuell/spiele/', 'https://www.faz.net/aktuell/edition/']","Die gute Nachricht zuerst: Weltweit ist die Suizidrate deutlich gesunken. Die absoluten Zahlen stiegen zwar seit 1990 leicht an, und 2016 waren es mehr als 800.000 Suizidtote. Berücksichtigt man aber das weltweite Bevölkerungswachstum im gleichen Zeitraum, sank die Rate um rund ein Drittel. Das zeigt eine gerade im „British Medical Journal“ veröffentlichte Auswertung des 1992 von der Weltgesundheitsorganisation mitinitiierten Projekts „Global Burden of Disease“. Dafür werden Daten aus aller Welt zu den wichtigsten Ursachen von Krankheit und Tod gesammelt. In Deutschland entsprechen die Suizidzahlen ungefähr diesem globalen Trend, blieben seit 2007 aber auf einem Niveau von rund 10.000 Todesfällen im Jahr. Allerdings sind sich Fachleute einig, dass sich ein Großteil jener Menschen, die sich selbst das Leben nehmen, dies eigentlich gar nicht will. Insbesondere Jugendliche und junge Erwachsene, denen vielmehr eine Perspektive fehlt, wie sie ihre unüberwindlich erscheinenden Probleme lösen und zu einem lebenswerten Leben zurückfinden können. Dafür brauchen sie Hilfe von außen – und dieser verschließen sich Menschen mit suizidalen Gedanken oft. Die wichtige Frage, die auch die Autoren der aktuellen Studie stellen, lautet: Wie kann man Gefährdete besser erreichen? Wie die Algorithmen arbeiten, ist ein Betriebsgeheimnis Ein Ansatz, um gerade jüngere Menschen mit suizidalen Gedanken zu erkennen, bietet ihr digitaler Fußabdruck im Internet, vor allem in sozialen Netzwerken. Facebook zum Beispiel ist für Milliarden Menschen zu einer Plattform für ihr digitales Alter Ego geworden, auf der selbst Intimstes preisgegeben wird. Auf diese Weise können sich Suizidabsichten zeigen, werden manchmal sogar gefördert: Virtuelle Netzwerke wie Facebook, Instagram und Co.- machen es leicht, irgendwo auf der Welt selbst für die abwegigsten Interessen noch Gleichgesinnte zu finden, suizidale Absichten gehören dazu. Nach bitteren Erfahrungen mit Suiziden, die auf Facebook mehr oder minder offen angekündigt, unter Lebensmüden abgesprochen und manchmal sogar live übertragen wurden, führte der OnlineDienst Anfang 2017 in den Vereinigten Staaten ein neues Programm zur Prävention ein. Basis ist die gleiche Künstliche Intelligenz, mit der Facebook die Inhalte seiner Nutzer auswertet, um ihnen etwa maßgeschneiderte Werbung zu präsentieren. Wie diese Algorithmen arbeiten, ist Betriebsgeheimnis, auch wenn es um die Suche nach Suizidgefährdeten geht. Was man weiß: Beim Durchsuchen der Posts werden auch Inhalte registriert, die auf Selbstmordgedanken oder konkrete Suizidpläne hinweisen. Das können Begriffe sein, die mit Suizid, Selbstverletzung oder Depression zu tun haben, oder Kontaktaufnahmen zu anderen bereits beobachteten Nutzern. Facebooks Künstliche Intelligenz erzeugt daraus eine Art Suizidrisiko-Score auf einer Skala von eins bis zehn, auf der „Eins“ für „unmittelbare Gefahr“ steht. Aber Facebook setzt nicht nur auf Algorithmen: Verdachtsfälle landen bei Mitarbeitern. Und die entscheiden, ob sie einen für den betroffenen Nutzer sichtbaren Hinweis auf Hilfsangebote einblenden oder in akuten Fällen Polizei oder Notarzt alarmieren. „Im vergangenen Jahr haben wir Ersthelfern geholfen, rund 3500 Menschen weltweit zu erreichen, die Hilfe brauchten“, schrieb Facebook-Chef Mark Zuckerberg Ende 2018 in einem Blogbeitrag. Ob die Facebook-Mitarbeiter qualifiziert genug sind, um den Ernst der Situation erkennen, bleibt ebenfalls eine offene Frage Es sei begrüßenswert, dass sich Facebook vermehrt um die Erkennung suizidaler Absichten sorge, stellte vergangene Woche ein Kommentar in den „Annals of Internal Medicine“ fest. Doch das Sammeln und Speichern von Daten, die Rückschlüsse auf die geistige Gesundheit von Nutzern erlauben, werfe auch ernste Fragen auf. Wie gut seien die Facebook-Mitarbeiter qualifiziert, den Ernst einer Situation einzuschätzen? Was passiere im Falle eines falschen Alarms, wenn plötzlich vor den Augen von Nachbarn und Familie die Polizei an die Tür klopfe? Die Autoren reihen sich damit in einen Chor von Expertenstimmen, die besonders den Mangel an Transparenz und Datenschutz im Präventionsprogramm von Facebook kritisieren. Weil die entsprechenden Regeln in den Ländern der Europäischen Union eben erst verschärft wurden, setzt Facebook hier seinen Suizid-Scanner bisher nicht ein. Künstliche Intelligenz soll nicht nur mit der Durchforstung riesiger Datenberge wie den von Facebook produzierten helfen, um Hinweise auf Suizidgedanken zu finden. Im Großbritannien hat der staatliche Gesundheitsdienst NHS in der vergangenen Woche einen umfangreichen Bericht über die digitale Zukunft der Gesundheitsversorgung veröffentlicht. Als vorbildlich wird darin das Pilotprojekt eines „Mental Health Triage ChatBot“ vorgestellt, in dem ein sogenannter Smart Speaker den Londoner Allgemeinärzten helfen soll, potentiell psychisch Kranke und Suizidgefährdete zu identifizieren. Dahinter steckt Künstliche Intelligenz mit der Fähigkeit zur Erkennung und Produktion von gesprochener oder geschriebener Sprache, bekannte Beispiele sind Amazons Alexa oder der Google Assistant. Nur aufrichtig Anteil nehmende Menschen können wirklich helfen Es mag sein, dass solche schlauen Programme, die Patienten online aufsuchen, bevor sie zum Arzt gehen, Hinweise auf mögliche Probleme besser erfassen als umfangreiche Fragebögen aus Papier. Vielleicht ließe sich damit auch die Schwelle für eine erste Kontaktaufnahme erniedrigen. Ebenso möglich, dass die digitale Zukunft dem unterfinanzierten NHS weitere Einsparungen erlaubt. Sicher ist: Den Kontakt zu aufrichtig Anteil nehmenden Menschen können solche Anwendungen bestenfalls ergänzen, aber niemals ersetzen, da sind sich Experten und selbst Entwickler von Chatbots einig. Wie effektiv schon eine Sensibilisierung des sozialen Umfelds sein kann, zeigt eine eben im Fachblatt „JAMA Psychiatry“ erschienene Studie amerikanischer Forscher mit 448 Jugendlichen, die in den Jahren 2002 bis 2005 mit Suizidgedanken oder nach einem Suizidversuch in zwei psychiatrische Kliniken eingewiesen worden waren. Die eine Hälfte erhielt eine Standardbehandlung. Die anderen Jugendlichen wurden zusätzlich gebeten, drei bis vier Erwachsene zu nennen, die ihnen nahestanden. Diese Vertrauenspersonen erhielten ein Training, in dem sie über den Therapieplan, Warnzeichen für einen drohenden Suizid und mögliche Hilfestellungen aufgeklärt wurden. Die Langzeitergebnisse bis zum Jahr 2016 basieren zwar nur auf einer Stichprobe, zeigen aber klar: In den zehn Jahren nach dem Klinikaufenthalt starben 15 Patienten aufgrund von Suizid oder Drogenmissbrauch. Nur zwei stammten aus der Gruppe, deren Umfeld ausdrücklich sensibilisiert wurde. Die Vertrauenspersonen waren den meisten eine Hilfe. Was sich für psychische Krisen gedachte Chatbots nicht sagen lässt, die auf die Aussage, man würde sich „übergeben“ (Warnzeichen bei Magersucht), antworten: „Es ist immer schön, mehr über dich zu lernen und über das, was dich glücklich macht.“","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.walled-content'}",False,959.0,"[{'@type': 'ListItem', 'position': 1, 'name': 'FAZ.NET', 'item': 'https://www.faz.net/aktuell/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Wissen', 'item': 'https://www.faz.net/aktuell/wissen/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Suizidprävention: Können Algorithmen Depression erkennen?', 'item': 'https://www.faz.net/aktuell/wissen/suizidpraevention-koennen-algorithmen-depression-erkennen-16044626.html'}]",3.0,
https://news.google.com/rss/articles/CBMilAFodHRwczovL3d3dy5zdHV0dGdhcnRlci1uYWNocmljaHRlbi5kZS9pbmhhbHQuZ2Vpc2xpbmdlci1sZXJuZmFicmlrLTQwLXJvYm90ZXItdW5kLWF6dWJpLWFyYmVpdGVuLXp1c2FtbWVuLmI0YmU5NDgzLTBlNjctNDBlMC1hZjg1LTU2Yjk2NDYzMDQ4Mi5odG1s0gEA?oc=5,Geislinger Lernfabrik 4.0: Roboter und Azubi arbeiten zusammen - Stuttgarter Nachrichten,2019-02-18,Stuttgarter Nachrichten,https://www.stuttgarter-nachrichten.de, Als Gl&uuml;cksfall f&uuml;r Geislingen betrachten die Schulleiter die neue Lernfabrik. Die hochmoderne digitale Lernumgebung schult die Fachkr&auml;fte von morgen. ,"['Geislingen', 'Roboter', 'Digitalisierung']", Als Glücksfall für Geislingen betrachten die Schulleiter die neue Lernfabrik. Die hochmoderne digitale Lernumgebung schult die Fachkräfte von morgen. , Als Glücksfall für Geislingen betrachten die Schulleiter die neue Lernfabrik. Die hochmoderne digitale Lernumgebung schult die Fachkräfte von morgen. ,http://schema.org,,N/A,N/A,"     Geislinger Lernfabrik 4.0 Roboter und Azubi arbeiten zusammen     Corinna Meinke  18.02.2019 - 17:04 Uhr   


                 1      Viele Arbeitsschritte am Rechner sind nötig, um die Maschinen für das neue Labor zu vernetzen. Foto: Gewerbliche Schule Geislingen 




    
Als Glücksfall für Geislingen betrachten die Schulleiter die neue Lernfabrik. Die hochmoderne digitale Lernumgebung schult die Fachkräfte von morgen.


  
  
  
  
  
  
Link kopiert



Geislingen - Wie sieht der digitale Berufsalltag künftig genau aus? Was steckt hinter Schlagworten wie Vernetzung, Automation und künstliche Intelligenz? Antworten auf diese Frage soll die Lernfabrik Wirtschaft 4.0 liefern, die gerade in Geislingen, gefördert von Land, Kreis und Wirtschaft, eingerichtet wird. Spannend macht das Projekt vor allem die Zusammenarbeit der Gewerblichen mit der Kaufmännischen Schule. Und diese beiden Schulen wollen die Schüler und Auszubildenden so vorbereiten, dass die Betriebe im Kreis unmittelbar vom digitalen Wissen des beruflichen Nachwuchses profitieren.


















Kleine Betriebe können sich ein Beispiel nehmen „Die Kleinbetriebe im oberen Filstal müssen konkurrenzfähig bleiben, wenn sie weiterhin Bosch und Mercedes beliefern wollen“, sagte Helmut Kölle. Der Konrektor der Gewerblichen Schule beschreibt das Konzept der Lernfabrik als modellhaft. Das neue Labor wolle zeigen, wie vorhandene Fertigungsmaschinen fit gemacht werden können für die digitalen Anforderungen. Denn gerade kleine Betriebe könnten ihre bestehenden Maschinen nicht einfach wegwerfen. Und profitieren sollen natürlich auch die Fachkräfte von morgen aus der Metall- und Elektrotechnik. 



Lesen Sie auch
















                                
                                Fußball-EM in Deutschland
                            
Vergewaltigungsvorwurf gegen albanischen EM-Team-Mitarbeiter

Gegen ein Stabsmitglied der albanischen Mannschaft wird wegen eines Vergewaltigungsvorwurfs ermittelt. Er soll eine Mitarbeiterin des Team-Hotels in Kamen missbraucht haben.





















                                
                                Fellbacher Eltern verlieren ihre Tochter
                            
Verena und Gabriel Bieg fühlen sich allein gelassen

Verena und Gabriel Bieg aus Fellbach haben im Dezember 2022 ihre Tochter Lena verloren. Nach einer Verwaisten-Reha für Familien, die sie mit ihrer jüngeren Tochter Sina gemacht haben, plädieren sie für mehr Hilfsangebote.




















                                
                                Lotto am Mittwoch
                            
Lotto heute: Lottozahlen der Ziehung vom 10.07.2024 (Mittwoch)

Hier finden Sie die aktuellen Lottozahlen und Gewinnquoten für Lotto 6aus49, Spiel77 und Super6.









Kommunikation zwischen unterschiedlichen elektronischen Sprachen sei das Entscheidende. Auch für die Gewerbliche Schule, die die Lernfabrik vorantreibe, sei dies mit die größte Herausforderung gewesen. Über Kontakte in die Wirtschaft und einen Zufall verfüge die Schule inzwischen über die richtige Software, mit der die schuleigenen CNC-Dreh-, Fräs- und 3-D-Messmaschinen miteinander vernetzt werden können. Außerdem sollen für die Lernfabrik zwei Roboter angeschafft werden, die Werkzeuge und Werkstücke transportieren und platzieren sollen. Die Getriebeteile, die in der Schule für Lernzwecke produziert würden, müssten zwar nicht auf dem Markt bestehen, doch als Vorbild für die Wirtschaft müssten sie auf jeden Fall taugen. Schon heute könnten sich Betriebe keinen Ausschuss mehr leisten, und ein 100-prozentiger Ausstoß von fehlerlosen so genannten Gutteilen sei auf hohem Niveau gefordert. 








Involviert sind auch Kaufleute, die die Daten verwerten Und an diesem Punkt kommen die künftigen Kaufleute der benachbarten Kaufmännischen Schule ins Spiel. Sie sollen von der Datenmenge profitieren, die an den digitalisierten Maschinen anfallen. Interessant seien Daten zur Laufleistung, Zuverlässigkeit, Produktionsdauer und vieles mehr, erläuterte Kölle. Und an Stelle theoretischer Werte könnten die Kaufleute künftig ihre Angebote, Aufträge und Rechnungen auf der Basis echter Werte im Unterricht erstellen. 

Das freut auch Roland Rimbach. Der Rektor der Kaufmännischen Schule nennt die Kooperation einen Glücksfall. Obwohl sie auf dem gleichen Campus angesiedelt sind, schafften die Azubi bisher eher nebeneinander her. Mit dem Zuschlag durch das Wirtschaftsministerium sei das Projekt ins Rollen gekommen. 









„Bis es im Labor endlich soweit ist, wird es noch etwas dauern“, meinte sein Kollege Kölle – derzeit werde noch ein wenig umgebaut. Vom neuen Schuljahr an sollen die Schüler der Gewerblichen Schule dann die Roboter auf ihren Wegen zwischen den Maschinen begleiten. Und in einer zweiten Ausbaustufe sollen so genannte Handhabungsroboter beispielsweise Werkzeuge selbstständig in dem Magazin einer Bearbeitungsmaschine platzieren.  Auch die lokale Wirtschaft wird wohl von diesen Lernschritten profitieren, mit denen das Labor weiter ausgebaut wird. Gedacht ist an Fortbildungen mit Hilfe des Landesnetzwerks Mechatronik, der Industrie- und Handels- sowie der Handwerkskammer und dem Schulförderverein, mit denen die Lernwerkstatt kooperiert. Ansprechen möchte Kölle in diesem Zusammenhang vor allem die Inhaber und Ausbilder von kleineren Betrieben. 

















































",2020-01-31T17:54:39+01:00,"{'@type': 'Organization', 'name': 'Stuttgarter Nachrichten', 'url': 'https://www.stuttgarter-nachrichten.de', 'logo': {'@type': 'ImageObject', 'url': 'https://www.stuttgarter-nachrichten.de/staticcontent/stuttgarter_nachrichten/common-resp18/svg/logo-stuttgarter-nachrichten.svg'}}",2019-02-18T17:04:00+01:00,NewsArticle,Geislinger Lernfabrik 4.0 - Roboter und Azubi arbeiten zusammen,"['https://www.stuttgarter-nachrichten.de/media.media.03f2fc0b-4f04-4d9b-b74f-c1ac88050a39.original_1024.jpg', 'https://www.stuttgarter-nachrichten.de/media.media.03f2fc0b-4f04-4d9b-b74f-c1ac88050a39.16x9_1024.jpg']","{'@type': 'WebPage', '@id': 'https://www.stuttgarter-nachrichten.de/inhalt.geislinger-lernfabrik-40-roboter-und-azubi-arbeiten-zusammen.b4be9483-0e67-40e0-af85-56b964630482.html'}","[{'@type': 'Person', 'name': 'Corinna Meinke', 'url': 'https://www.stuttgarter-nachrichten.de/inhalt.region-corinna-meinke-com.54c770b1-4059-49d4-9db9-bd173faac689.html'}]",,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'True', 'cssSelector': '.restricted-area'}",True,,,,Göppingen

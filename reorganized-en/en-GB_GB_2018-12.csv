URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@graph,@type,headline,url,mainEntityOfPage,thumbnailUrl,image,articleSection,author,creator,publisher,dateCreated,datePublished,dateModified,article:section,article:summary,article text,itemListElement,speakable,name,potentialAction,logo,sameAs,address,width,height,worksFor,mainEntity,hasPart,legalName,contactPoint,isAccessibleForFree,mainEntityOfPAge,inLanguage,text,articleBody,@id,entry-title,published,updated,isBasedOn,isPartOf,alternativeHeadline,claimReviewed,reviewRating,itemReviewed,issn,copyrightHolder,sourceOrganization,copyrightYear,diversityPolicy,ethicsPolicy,masthead,foundingDate,identifier,telephone,comment,commentCount,editor,video
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LnBld3Jlc2VhcmNoLm9yZy9pbnRlcm5ldC8yMDE4LzEyLzEwL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFuZC10aGUtZnV0dXJlLW9mLWh1bWFucy_SAQA?oc=5,Artificial Intelligence and the Future of Humans - Pew Research Center,2018-12-10,Pew Research Center,https://www.pewresearch.org,"Experts say the rise of artificial intelligence will make most people better off over the next decade, but many have concerns about how advances in AI will affect what it means to be human, to be productive and to exercise free will.",[],"Experts say the rise of artificial intelligence will make most people better off over the next decade, but many have concerns about how advances in AI will affect what it means to be human, to be productive and to exercise free will.",,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/#article', 'isPartOf': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/'}, 'author': {'name': 'Sara Atske', '@id': 'https://www.pewresearch.org/#/schema/person/81ad7bd61667c7d73ab64351212a033c'}, 'headline': 'Artificial Intelligence and the Future of Humans', 'datePublished': '2018-12-10T16:55:56+00:00', 'dateModified': '2024-04-14T09:18:27+00:00', 'mainEntityOfPage': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/'}, 'wordCount': 3004, 'commentCount': 0, 'publisher': {'@id': 'https://www.pewresearch.org/#organization'}, 'image': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/#primaryimage'}, 'thumbnailUrl': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2019/05/PI-PG_2019.05.13_Technology-and-Politics-Emerging-Economies_0-06.png?w=176', 'articleSection': ['Artificial Intelligence', 'Emerging Technology', 'Future of the Internet (Project)', 'Technology Adoption'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://platform.pewresearch.org/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/', 'url': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/', 'name': 'Artificial Intelligence and the Future of Humans | Pew Research Center', 'isPartOf': {'@id': 'https://www.pewresearch.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/#primaryimage'}, 'image': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/#primaryimage'}, 'thumbnailUrl': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2019/05/PI-PG_2019.05.13_Technology-and-Politics-Emerging-Economies_0-06.png?w=176', 'datePublished': '2018-12-10T16:55:56+00:00', 'dateModified': '2024-04-14T09:18:27+00:00', 'description': 'Experts say the rise of artificial intelligence will make most people better off over the next decade, but many have concerns about how advances in AI will affect what it means to be human, to be productive and to exercise free will.', 'breadcrumb': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/#primaryimage', 'url': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2019/05/PI-PG_2019.05.13_Technology-and-Politics-Emerging-Economies_0-06.png?w=176', 'contentUrl': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2019/05/PI-PG_2019.05.13_Technology-and-Politics-Emerging-Economies_0-06.png?w=176'}, {'@type': 'BreadcrumbList', '@id': 'https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.pewresearch.org'}, {'@type': 'ListItem', 'position': 2, 'name': 'Research Topics', 'item': 'https://www.pewresearch.org/topics-categorized/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Internet &amp; Technology', 'item': 'https://www.pewresearch.org/topic/internet-technology/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Emerging Technology', 'item': 'https://www.pewresearch.org/topic/internet-technology/emerging-technology/'}, {'@type': 'ListItem', 'position': 5, 'name': 'Artificial Intelligence'}]}, {'@type': 'WebSite', '@id': 'https://www.pewresearch.org/#website', 'url': 'https://www.pewresearch.org/', 'name': 'Pew Research Center', 'description': 'Numbers, Facts and Trends Shaping Your World', 'publisher': {'@id': 'https://www.pewresearch.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.pewresearch.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.pewresearch.org/#organization', 'name': 'Pew Research Center', 'url': 'https://www.pewresearch.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/#/schema/logo/image/', 'url': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2024/04/logo-fallback.png', 'contentUrl': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2024/04/logo-fallback.png', 'width': 1265, 'height': 192, 'caption': 'Pew Research Center'}, 'image': {'@id': 'https://www.pewresearch.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/pewresearch', 'https://twitter.com/pewresearch', 'https://www.linkedin.com/company/pew-research-center/', 'https://www.youtube.com/user/PewResearchCenter']}, {'@type': 'Person', '@id': 'https://www.pewresearch.org/#/schema/person/81ad7bd61667c7d73ab64351212a033c', 'name': 'Sara Atske', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/5788245e97afeb895fedf7ded23300bd?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/5788245e97afeb895fedf7ded23300bd?s=96&d=mm&r=g', 'caption': 'Sara Atske'}, 'url': 'https://www.pewresearch.org/author/satske/'}]",NewsArticle,Artificial Intelligence and the Future of Humans,http://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/,"{'@type': 'WebPage', '@id': 'http://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/'}",,"{'@type': 'ImageObject', 'url': ''}",Artificial Intelligence,"[{'@type': 'Person', 'name': 'Sara Atske'}]",['Sara Atske'],"{'@type': 'Organization', 'name': 'Pew Research Center', 'logo': 'https://www.pewresearch.org/wp-content/themes/prc-block-theme/assets/img/square.png'}",2018-12-10T16:55:56Z,2018-12-10T16:55:56Z,2024-04-14T09:18:27Z,,,"short readsMay 15, 2024 

   

A quarter of U.S. teachers say AI tools do more harm than good in K-12 education ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmVudGVycHJpc2V0aW1lcy5jby51ay8yMDE4LzEyLzEwL3RheWxvcmlzbS00LTAtaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWlzLXRyYW5zZm9ybWluZy1rbm93bGVkZ2Utd29yay_SAQA?oc=5,Taylorism 4.0: How Artificial Intelligence is Transforming Knowledge Work - - Enterprise Times,2018-12-10,Enterprise Times,https://www.enterprisetimes.co.uk,MIchael Spath compares Taylorism to the rise of AI and Knowledge Work. His view is that both were influences by technology to increase productivity,,MIchael Spath compares Taylorism to the rise of AI and Knowledge Work. His view is that both were influences by technology to increase productivity,,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/', 'url': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/', 'name': 'Taylorism 4.0: How Artificial Intelligence is Transforming Knowledge Work -', 'isPartOf': {'@id': 'https://www.enterprisetimes.co.uk/#website'}, 'primaryImageOfPage': {'@id': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/#primaryimage'}, 'image': {'@id': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/#primaryimage'}, 'thumbnailUrl': 'https://www.enterprisetimes.co.uk/wp-content/uploads/2018/12/turn-on-4.jpg', 'datePublished': '2018-12-10T06:58:34+00:00', 'dateModified': '2018-12-09T11:40:14+00:00', 'author': {'@id': 'https://www.enterprisetimes.co.uk/#/schema/person/f3fbf8ba81c0fd1584eca84d2e4d9b57'}, 'description': 'MIchael Spath compares Taylorism to the rise of AI and Knowledge Work. His view is that both were influences by technology to increase productivity', 'breadcrumb': {'@id': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': {'@type': 'ListenAction', 'target': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/#podcast_player_34312', 'object': {'@id': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/#/schema/podcast'}}, 'mainEntityOfPage': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/#/schema/podcast'}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/#primaryimage', 'url': 'https://www.enterprisetimes.co.uk/wp-content/uploads/2018/12/turn-on-4.jpg', 'contentUrl': 'https://www.enterprisetimes.co.uk/wp-content/uploads/2018/12/turn-on-4.jpg', 'width': 725, 'height': 410, 'caption': 'Turn On 4.0 Image credit pixabay/geralt'}, {'@type': 'BreadcrumbList', '@id': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.enterprisetimes.co.uk/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Taylorism 4.0: How Artificial Intelligence is Transforming Knowledge Work'}]}, {'@type': 'WebSite', '@id': 'https://www.enterprisetimes.co.uk/#website', 'url': 'https://www.enterprisetimes.co.uk/', 'name': 'Enterprise Times', 'description': 'Technology for your enterprise, today and tomorrow', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.enterprisetimes.co.uk/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Person', '@id': 'https://www.enterprisetimes.co.uk/#/schema/person/f3fbf8ba81c0fd1584eca84d2e4d9b57', 'name': 'Michael Späth', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.enterprisetimes.co.uk/#/schema/person/image/', 'url': 'https://www.enterprisetimes.co.uk/wp-content/uploads/2018/12/MichaelSpathAera-96x96.jpg', 'contentUrl': 'https://www.enterprisetimes.co.uk/wp-content/uploads/2018/12/MichaelSpathAera-96x96.jpg', 'caption': 'Michael Späth'}, 'description': 'Michael Späth is an executive client partner at Aera Technology, focused on helping some of the world’s largest enterprises succeed in supply chain digital transformation. He has more than 10 years of experience in supply chain &amp; operations, and deep expertise in operational excellence and manufacturing transformation. Prior to Aera, Michael led EY Germany’s blockchain practice and focused on business development, innovation and co-creation with clients. Before that, Michael was with a boutique SCM consulting firm (acquired by EY). Michael holds a Bachelor’s Degree in Business Administration from University of Madrid and a Bachelor’s Degree in International Business and Management from Hogeschool van Arnhem en Nijmegen (HAN) in the Netherlands.', 'sameAs': ['http://www.aeratechnology.com', 'https://www.linkedin.com/in/michaelspth/'], 'url': 'https://www.enterprisetimes.co.uk/author/michaelspath/'}]",BreadcrumbList,,,,,,,,,,,,,,,"



Home  Blogs  Taylorism 4.0: How Artificial Intelligence is Transforming Knowledge Work
Blogs

Taylorism 4.0: How Artificial Intelligence is Transforming Knowledge Work

By Michael Späth -   December 10, 2018 









FacebookTwitterWhatsAppLinkedinEmail



In 1909, the American mechanical engineer Frederick Winslow Taylor helped to usher in the era of manufacturing automation when he published “The Principles of Scientific Management.”
Also known as Taylorism, scientific management aimed to improve economic and labor efficiency by analyzing and streamlining workflows. Training workers to perform tasks by specialization was instrumental in manufacturing’s move from custom craftsmanship to mass production.
Taylor’s scientific management principles evolved into lean management, in which multi-skilling and problem solving among workers became critical to goals of continuous optimization and eliminating waste. And Taylorism is seen in the rise of knowledge work, a term first coined in 1959 by the influential management guru Peter Drucker in his book, “The Landmarks of Tomorrow.”
Technology is the common thread across Taylorism in both manufacturing and knowledge work. Taylorism applied to early 20th century manufacturing because factories began to adopt conveyer belts, interchangeable parts and other then-modern technology. That dovetailed neatly with Taylor’s principles of labor productivity.
Similarly, knowledge work depends on technology­ — computers and programs that can store information and automate functions. The advent of ERP systems in 1960s was a major breakthrough that introduced large-scale transaction automation. And it generated vast new volumes of information that knowledge workers could access.
New Frontiers for Knowledge Work
Today, we’re at the cusp of what can be called Taylorism 4.0. An emerging technology, artificial intelligence, is beginning to transform knowledge work. Once again, management thinking and technology adoption are converging to extend the boundaries of productivity.
Despite its importance to the business, knowledge work hasn’t evolved significantly in many years. Knowledge workers spend a lot of time gathering data, turning information into knowledge and taking action accordingly. It means a great deal of manual, repetitive tasks. Rapid growth in data and applications has made knowledge work all the more difficult.
We have not yet been successful in applying automation technology at scale to knowledge work. Yet today, we’ve entered an AI spring after many boom and bust cycles for AI. Cost-effective and virtually limitless access to memory and computational power is a key factor behind AI’s growth. So are more sophisticated algorithms that expand cognitive thinking in machines.
Led by the Internet companies, machine learning has become part of our daily lives. In the consumer realm, AI is in play whenever we search the web, click on a shopping recommendation or check our social media feed. Other industries are following suit and identifying more areas in which AI can provide benefits.
Four Steps in AI’s Business Evolution
To gain a perspective about how AI impacts knowledge work, a framework from MIT professor Thomas Malone on how organizations are adopting AI technology is particularly useful. He outlines four areas of AI application: tool, assistant, peer and manager. Let’s take a look at each of these areas.

Human have used tools for a long time. Whenever we wanted to extend our physical capabilities, we invented tools to help us reach higher, cut deeper or apply more leverage. Tools have also been valuable in expanding our mental faculties. Calculators help us to perform difficult calculations with ease. Software has enabled us to program machines, and the Internet has connected us in unprecedented ways.

AI provides us with new capabilities. For instance, companies can better forecast demand by applying machine learning to vast quantities of data. This kind of enhanced pattern recognition capability will become commonplace in our toolbox and will be used in various settings.

Digital assistants are becoming more widely adopted. Airlines handle many customer requests via chatbots, so that answers to frequently asked questions are provided by machines rather than by humans. Often these answers are reviewed by a human operator before passing them on. Even so, human workload is reduced while response times are faster.

We increasingly use Siri, Alexa and other digital assistants on our mobile devices. We’re also using natural language processing (NLP) to access information at the speed of conversation. And now, NLP is finding its way into business so that humans can quickly search enterprise data and execute decisions.

Leading companies are already using intelligent software in the role of peer. It’s often very demanding for a business planner to deal with daily operational issues. A lot of time is spent in data collection, analysis, developing a course of action and aligning functions.

In contrast, AI can recommend solutions for specific business problems. Employing AI as a peer accelerates decision-making and can help companies tackle problems as they bubble up. AI also helps with the long-tail of issues that cannot be addressed due to limitations of human and organizational bandwidth.

AI as manager will play an important role in the future. While currently only tested in research settings, prioritizing work and allocating tasks to humans and machines is something AI systems can do at scale. Relying on AI as a manager might appear to be a foreign idea today. But as AI expands, it could lead to a more balanced distribution of work that leverages the unique skill sets of humans and machines.

Leveraging unique skill sets is what Taylorism is fundamentally about. Through production automation technology, we were able to allocate tasks that are unsafe or have high throughput or precision requirements to machines. The same principle applies to knowledge work. We will identify work that is uniquely suitable for humans and keep it there. But in areas in which intelligent machines outperform humans, we will allocate tasks accordingly.
Worker Focus on Creativity and Innovation
Orchestrating these new systems of knowledge work shared between humans and intelligent machines is a critical mission. Managers will have to fundamentally rethink workflows, organizational design, performance management, and training for both humans and machines. We are at the very early stages of this transformation, but the impact to the workforce will be as significant as the second and third industrial revolutions.
By offloading manual data work and lower-level cognitive functions to machines, knowledge workers are liberated to further develop their strengths. Innovation, creative problem solving and high-touch services are just a few examples of areas where humans will retain a competitive edge, at least for now.
Interestingly, the coining of the phrase artificial intelligence predates the phrase knowledge worker by three years, going back to the founders of the AI field in 1956. Now, the two are beginning to converge. These are interesting times and it will be interesting to see what the near future will bring. But some things, like Taylor’s ideas about work specialization, don’t seem to change.

Aera Technology delivers the cognitive operating system that enables the Self-Driving Enterprise. Aera understands how businesses work; makes real-time recommendations; predicts outcomes; and acts autonomously. Using proprietary data crawling, industry models, machine learning and artificial intelligence, Aera is revolutionizing how people relate to data and how organizations function. Headquartered in Mountain View, California, Aera services some of the world’s largest enterprises from its global offices located in San Francisco, Bucharest, Cluj-Napoca, Paris, Pune and Sydney. For more information about Aera, please visit www.aeratechnology.com.



TAGSAIAlexaArtifical IntelligenceBotsDigital AssistantsDruckerKnowledge WorkScientific ManagementSiriTaylorirm 
FacebookTwitterWhatsAppLinkedinEmail

 Previous articleImproving education and diversity in cyber security Next articleXero celebrates success but is there a challenger? Michael Späthhttp://www.aeratechnology.comMichael Späth is an executive client partner at Aera Technology, focused on helping some of the world’s largest enterprises succeed in supply chain digital transformation. He has more than 10 years of experience in supply chain & operations, and deep expertise in operational excellence and manufacturing transformation. Prior to Aera, Michael led EY Germany’s blockchain practice and focused on business development, innovation and co-creation with clients. Before that, Michael was with a boutique SCM consulting firm (acquired by EY). Michael holds a Bachelor’s Degree in Business Administration from University of Madrid and a Bachelor’s Degree in International Business and Management from Hogeschool van Arnhem en Nijmegen (HAN) in the Netherlands.



Linkedin

  
RELATED ARTICLESMORE FROM AUTHOR




 Blogs 

Will Virtual Power Plants Be Our Energy Future? 





 Blogs 

Why Human Risk Management is Key to Data Protection 





 Blogs 

Will Extreme Weather Events Drive IoT Investment? 

 




 Blogs 

The Top Employee Security Risks You’re Probably Not Measuring 





 Blogs 

Building a better security culture requires investment 





 Blogs 

Optimizing SQL Server Costs in Azure HA/DR Deployments 

 



1 COMMENT






 Taylorism 4.0: How Artificial Intelligence is Transforming Knowledge Work | Epoch Convergence


December 11, 2018 At 2:45 pm 



[…] By Steve Bednarczyk – December 11, 2018 3 0 Click here to view original web page at http://www.enterprisetimes.co.uk […]


Reply 






LEAVE A REPLY Cancel reply


Please enter your comment!


Please enter your name here



You have entered an incorrect email address!
Please enter your email address here




Save my name, email, and website in this browser for the next time I comment.
 Notify me of follow-up comments by email. Notify me of new posts by email. 

Δ 










Merkle and Celebrus combine to help brands walk the tightrope of customer engagement

Celebrus Steve Brooks -  May 3, 2024 0 




  




Zoholics Lands in Seoul for the First Time

Business Steve Brooks -  July 12, 2024 0 




  NEWSLETTERDon’t want to miss out on the latest news and stories ? Sign up to our weekly newsletter





Leave this field empty if you're human: FOLLOW US
LATEST NEWS



Can Hey Savi Change How People Buy Fashion

Business Steve Brooks -  July 16, 2024 0 

Hey Savi has raised £2.2 million in pre-seed investment for an AI-powered technology platform. The founders believe it will change the way people search... 





Apricorn finds UK councils racked up 5,000 data breaches

Latest News Ian Murphy -  July 16, 2024 0 

Apricorn has released findings from its annual Freedom of Information (FOI) requests to 27 local councils. It asked specifically about data breaches and device... 





Tracebit Secures US$5 Million in a Seed Funding Round

Cloud Computing Ian Murphy -  July 15, 2024 0 

Tracebit has secured US$5 million in a seed funding round led by Accel. The company is looking to bring a cloud-based approach to threat... 





WaveBL Adopts GLEIF LEI to Identify Shippers

Blockchain Ian Murphy -  July 15, 2024 0 

The Global Legal Entity Identifier Foundation (GLEIF) and WaveBL want to improve visibility regarding shippers' identities. To do that, the two organisations will work... 





BlueVoyant unveils new Security Operations platform

AI Ian Murphy -  July 15, 2024 0 

BlueVoyant has launched its Cyber Defense Platform. The platform combines internal, supply chain, and external defence solutions and gives IT security teams a single... 





Box Appoints Samantha Wessels, President of Box EMEA

Cloud Computing Steve Brooks -  July 15, 2024 0 

Box has announced the appointment of Samantha Wessels as President of Box EMEA.  She replaces Sébastien Marotte, who previously held the role for three... 





Celigo unveils July release which achieves Snowflake ready technology validation, and partnership with CData

Latest News Roy Edwards -  July 15, 2024 0 

Celigo, an integration solution provider has made product updates in its July release. The company says the release was designed to streamline workflows,... 





SlashNext Warns FishXProxy Lowers Barrier for Cybercriminals

Latest News Ian Murphy -  July 12, 2024 0 

SlashNext has warned of a new phishing kit that makes it easier for cybercriminals to launch believable attacks. The FishXProxy Phishing Kit provides a... 





Zoholics Lands in Seoul for the First Time

Business Steve Brooks -  July 12, 2024 0 

Zoho held a Zoholics event in South Korea for the first time. It recognises the importance of the market for Zoho. The event, which... 





Avetta Hires CMO to Lead Growth Charge

Business Steve Brooks -  July 12, 2024 0 

Avetta has announced the appointment of Gretchen Eischen as Chief Marketing Officer. Eischen will take over the responsibility for Avetta’s brand positioning, marketing strategy,... 





PPM Vendor Introduces Flat Rate Unlimited User Pricing of $500 Per Month

Latest News Steve Brooks -  July 12, 2024 0 

PPM Express, an integrated portfolio and project management solution is now available for a flat rate of $500 per month. The vendor has four... 





Celebrus Closes on Share Price High

Business Steve Brooks -  July 11, 2024 0 

Celebrus announced its full-year results for the year ending March 31st 2024 and published its annual report. It has been a solid year of... 





Cloudflare finds just 29% of European businesses prepared for a cyberattack

Business Ian Murphy -  July 10, 2024 0 

Cloudflare research shows that just 29% of European organisations say they are well prepared for future cyberattacks. It's a chilling statistic. While small organisations... 





Sailes Digital Labor Study Shows Sailbots Deliver Sales Success

AI Steve Brooks -  July 10, 2024 0 

Sailes has published the Digital Labor Study, 2024. The study examines how the Sailes technology has benefitted customers. It looks at the automation that... 


 


","[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.enterprisetimes.co.uk/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.enterprisetimes.co.uk/category/blogs/', 'name': 'Blogs'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.enterprisetimes.co.uk/2018/12/10/taylorism-4-0-how-artificial-intelligence-is-transforming-knowledge-work/', 'name': 'Taylorism 4.0: How Artificial Intelligence is Transforming Knowledge Work'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vbmV3cy5hcnRuZXQuY29tL2FydC13b3JsZC9haWNhbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1zY29wZS0xNDEyNDAx0gFWaHR0cHM6Ly9uZXdzLmFydG5ldC5jb20vYXJ0LXdvcmxkL2FpY2FuLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXNjb3BlLTE0MTI0MDEvYW1wLXBhZ2U?oc=5,"At Miami Art Week, Thousands of Works Created by Human Artists—and a Few by Artificial Intelligence, Too - artnet News",2018-12-07,artnet News,https://news.artnet.com,AICAN wants to show that AI artwork can be autonomously creative or genuinely collaborative. But viewers still have a lot to learn.,"AICAN, Ahmed Elgammal, Rutgers University, Jessica Davidson, Davidson Art Advisory, Obvious, artnet-news, Art Basel Miami, Contemporary",AICAN wants to show that AI artwork can be autonomously creative or genuinely collaborative. But viewers still have a lot to learn.,,https://schema.org,"[{'@type': 'Organization', '@id': 'https://news.artnet.com/#organization', 'name': 'Artnet News', 'url': 'https://news.artnet.com/', 'sameAs': [], 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/#/schema/logo/image/', 'url': 'https://news.artnet.com/app/news-upload/2023/02/news-logo-64x64-1.png', 'contentUrl': 'https://news.artnet.com/app/news-upload/2023/02/news-logo-64x64-1.png', 'width': 64, 'height': 64, 'caption': 'Artnet News'}, 'image': {'@id': 'https://news.artnet.com/#/schema/logo/image/'}}, {'@type': 'WebSite', '@id': 'https://news.artnet.com/#website', 'url': 'https://news.artnet.com/', 'name': 'Artnet News', 'description': 'The world’s most-read and best trusted art publication', 'publisher': {'@id': 'https://news.artnet.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.artnet.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#primaryimage', 'url': 'https://news.artnet.com/app/news-upload/2018/12/Green-Genesis.jpg', 'contentUrl': 'https://news.artnet.com/app/news-upload/2018/12/Green-Genesis.jpg', 'width': 2134, 'height': 2134, 'caption': 'AICAN, Green Genesis, 2018. Image courtesy of AICAN.'}, {'@type': 'WebPage', '@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#webpage', 'url': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401', 'name': 'At Miami Art Week, Thousands of Works Created by Human Artists—and a Few by Artificial Intelligence, Too | Artnet News', 'isPartOf': {'@id': 'https://news.artnet.com/#website'}, 'primaryImageOfPage': {'@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#primaryimage'}, 'datePublished': '2018-12-07T15:14:58+00:00', 'dateModified': '2018-12-07T17:50:20+00:00', 'description': 'AICAN wants to show that AI artwork can be autonomously creative or genuinely collaborative. But viewers still have a lot to learn.', 'breadcrumb': {'@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401']}]}, {'@type': 'BreadcrumbList', '@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.artnet.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'At Miami Art Week, Thousands of Works Created by Human Artists—and a Few by Artificial Intelligence, Too'}]}, {'@type': 'NewsArticle', '@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#article', 'isPartOf': {'@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#webpage'}, 'author': {'@id': 'https://news.artnet.com/#/schema/person/c37780c435a41eda7c46d74632c5364a'}, 'headline': 'At Miami Art Week, Thousands of Works Created by Human Artists—and a Few by Artificial Intelligence, Too', 'datePublished': '2018-12-07T15:14:58+00:00', 'dateModified': '2018-12-07T17:50:20+00:00', 'mainEntityOfPage': {'@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#webpage'}, 'wordCount': 969, 'publisher': {'@id': 'https://news.artnet.com/#organization'}, 'image': {'@id': 'https://news.artnet.com/art-world/aican-artificial-intelligence-scope-1412401#primaryimage'}, 'thumbnailUrl': 'https://news.artnet.com/app/news-upload/2018/12/Green-Genesis.jpg', 'articleSection': 'On View', 'inLanguage': 'en-US', 'isAccessibleForFree': 'True', 'hasPart': {'@type': 'WebPageElement', 'isAccessibleForFree': 'True', 'cssSelector': '.article-body'}, 'alternativeHeadline': 'At Miami Art Week, Thousands of Works Created by Human Artists—and a Few by Artificial Intelligence, Too | Artnet News', 'description': {}, 'keywords': ['Art Basel Miami', 'Contemporary', 'Christie\\s London']}, {'@type': 'Person', '@id': 'https://news.artnet.com/#/schema/person/c37780c435a41eda7c46d74632c5364a', 'name': 'Tim Schneider', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/91ccfa892ee7176b8a7ff258f10d6844?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/91ccfa892ee7176b8a7ff258f10d6844?s=96&d=mm&r=g', 'caption': 'Tim Schneider'}, 'sameAs': ['http://www.thegray-market.com', 'https://www.facebook.com/tim.schneider.54772?ref=bookmarks', 'https://www.instagram.com/the_graymarket/', 'https://twitter.com/the_gray_market'], 'url': 'https://news.artnet.com/about/tim-schneider-641'}]",,,,,,,,,,,,,,On View,,"





On View

At Miami Art Week, Thousands of Works Created by Human Artists—and a Few by Artificial Intelligence, Too
AICAN presents a booth full of work created by AI at Scope. But viewers still have a lot to learn.





AICAN, Green Genesis, 2018. Image courtesy of AICAN.  










Tim Schneider 
December 7, 2018


 ShareShare This Article




If you ever needed an example of a subject that appeals to a niche audience, you could do a lot worse than selecting the synthesis between art and machine learning (commonly simplified into the phrase “artificial intelligence”).
While interest in the genre is certainly growing, particularly after this October’s screaming (and misleading) headlines about the alleged first-ever auction sale of a work created by AI at Christie’s, it’s safe to say the process and implications of this relationship remain light-years away from intuitive, even to committed art lovers. So it’s not quite the type of work that you would expect to see championed at Scope Miami Beach, one of the decidedly more populist fairs of this year’s Miami Art Week.
Which is exactly why it’s surprising to find the AICAN booth occupying pride of place inside Scope’s beachfront tent. Developed by Ahmed Elgammal, a computer science professor and founding director of the Art and Artificial Intelligence Lab at Rutgers University, AICAN is a software initiative that aims to elevate algorithmic art from imitation to autonomous creativity. The acronym stands for “Artificial Intelligence Creative Adversarial Network.” It’s a mouthful that would tip off machine-learning pros—and machine-learning pros only—that Elgammal and company are up to something slightly different than the likes of Obvious, the French trio that engineered the record-breaking Christie’s sale.
Unlike so-called Generative Adversarial Networks (often shorthanded as “GANs”), AICAN isn’t trained on a highly specific set of images—say, oil-painted Renaissance portraiture—and tasked with outputting a new image close enough to the inputs to fool a discriminator algorithm into recognizing the new image as manmade. Instead, Elgammal programmed AICAN to crawl an ever-increasing dataset of images from western art history, ranging from portraits to landscapes to abstractions (and beyond). The software has now absorbed over 100,000 training images primarily sourced from WikiArt and online museum collections. (It’s like art school, but for algorithms.)
Using this reference pool, the software must then contend with two opposing directives in its own coding: to create something stylistically innovative, but not too innovative. Think of it as the Goldilocks principle of software art. AICAN even generates its own titles based on data from the works in its training set.
Devin Gharakhanian and AICAN, Carl Haplin, 2018. Image courtesy of AICAN.
Creative Partnership
In an interview with artnet News, Elgammal said that he instilled these principles into AICAN to try to replicate the workings of the unconscious human mind. The underlying contention is that true creativity comes from fresh concepts. “Art is about an idea, not execution,” he explained. Software unable to transcend this divide will only produce skilled mimicry at best and outright gimmickry at worst.
Elgammal believes AICAN will be able to forge new frontiers in both machine learning and the humans interacting with it. From the outset, he designed AICAN to be a true “creative partner” to flesh-and-blood artists—a force that can inspire new directions in their practices and new potential in the minds of viewers.
While the vast majority of the works on view at Scope were generated exclusively by the software, the special presentation also includes collaborations between AICAN and two artists: Tim Bengel and Devin Gharakhanian. In each case, Elgammal worked closely with the artists to devise custom methods for the software to complement or expand their usual processes. Although the results are printed onto aluminum just like many of the AICAN-only works, they are also instantly recognizable as different from the rest of the stand (as well as from one another).
AICAN, Aurora Dunes, 2018. Image courtesy of AICAN.
Aiming for Awareness
Another deviation of sorts concerns Elgammal’s perspective on the fair’s purpose. Works were priced from $8,000 to $25,000 at press time; a handful of works were pre-sold and one more had been placed by Friday morning. (For comparison, another AICAN work sold for $16,000 at a recent benefit auction.) However, Elgammal and his dealer, Jessica Davidson of Davidson Art Advisory, have agreed to prioritize raising awareness over making sales this week. “It is more important that people see this as quality art,” said Elgammal. “We want this [genre] to become mainstream.”
The opening days of Scope seemed to advance the ball toward that goal. Both Elgammal and Davidson described visitors’ responses to the works as overwhelmingly enthusiastic. The most common assumption among first-time viewers was that the pieces had been created entirely by a human. But once they learned about the influence of the machine, their interest generally deepened rather than receding.
Still, this doesn’t mean that everyone perfectly understood the works’ origins or implications. According to Davidson, most people tend to focus on the production process, whereas she and Elgammal are keen to steer them toward the conceptual layer. But making that shift often involves educating curious visitors that AICAN’s works are generated by software, not hardware. “People tend to think it’s painted by a robot,” said Davidson.
Clearly, the community of artists and advocates engaged with machine-learning still have plenty of educating to do. And if you can’t make it to Scope to see AICAN for yourself, scroll down for more images of the works in the booth.
AICAN is on view at Scope Miami Beach through Sunday, December 9, 2018. 
AICAN, Link Between Heaven and Earth, 2018. Image courtesy of AICAN.
AICAN, Tropical Inception, 2018. Image courtesy of AICAN.
AICAN, Unsettled, 2018. Image courtesy of AICAN.
AICAN, Uncanny Girl in Kimono, 2018. Image courtesy of AICAN.
AICAN, Flora, 2018. Image courtesy of AICAN.
Follow Artnet News on Facebook: 

Want to stay ahead of the art world? Subscribe to our newsletter to get the breaking news, eye-opening interviews, and incisive critical takes that drive the conversation forward.








 Share This ArticleShare This Article







                                                        Article topics
                                                    

Art Basel Miami
Contemporary









 
 
 Tim Schneider
Art Business Editor
 





 








            The best of Artnet News in your inbox.
        

            Sign up to our daily newsletter.
        








Please enter a valid email address
Signup failed. Please try again later.



Thank you!
You have successfully subscribed to Artnet News.











 

                Related Articles
            










Opinion




The Gray Market: How Christie’s So-Called ‘AI-Generated’ Art Sale Proves That Records Can Distort History (and Other Insights)


			By
							Tim Schneider,
							Oct 28, 2018
						


 









Art World




Has Artificial Intelligence Given Us the Next Great Art Movement? Experts Say Slow Down, the ‘Field Is in Its Infancy’


			By
							Tim Schneider &  Naomi Rea,
							Sep 24, 2018
						


 





            The best of Artnet News in your inbox.
        

            Sign up to our daily newsletter.
        








Please enter a valid email address
Signup failed. Please try again later.



Thank you!
You have successfully subscribed to Artnet News.




 




                                More Trending Stories
                            



Books
                                                    







                                                            Art Lovers, Here Are 7 New Non-Fiction Books to Add to Your Summer Reading List
                                                        





Art & Exhibitions
                                                    







                                                            There’s More to Rome Than Ancient History. Check Out These Must-See Contemporary Gems
                                                        





Art & Exhibitions
                                                    







                                                            The Story Behind a Rare 19th-Century Portrait of a Person of Color Emerges
                                                        





Artists
                                                    







                                                            ‘The More Repellent You Are, the More Attractive You Become’: George Condo on Contemporary Mythmaking
                                                        









                                                            Books
                                                        


                                                                Art Lovers, Here Are 7 New Non-Fiction Books to Add to Your Summer Reading List
                                                            













                                                            Art & Exhibitions
                                                        


                                                                There’s More to Rome Than Ancient History. Check Out These Must-See Contemporary Gems
                                                            













                                                            Art & Exhibitions
                                                        


                                                                The Story Behind a Rare 19th-Century Portrait of a Person of Color Emerges
                                                            













                                                            Artists
                                                        


                                                                ‘The More Repellent You Are, the More Attractive You Become’: George Condo on Contemporary Mythmaking
                                                            











",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOmh0dHBzOi8vcGh5cy5vcmcvbmV3cy8yMDE4LTEyLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLmh0bWzSAQA?oc=5,Why artificial intelligence is likely to take more lives - Phys.org,2018-12-11,Phys.org,https://phys.org,"Artificial neurons for deeply intelligent machines – this is the new artificial intelligence (AI) revolution, led by Geoffrey Hinton and his team since 2012. That year, Hinton, an expert in cognitive science at the University of Toronto and a researcher at Google Brain, demonstrated the striking effectiveness of a deep neural network (DNN) in an image-categorisation task.","Science, Physics News, Science news, Technology News, Physics, Materials, Nanotech, Technology, Science","Artificial neurons for deeply intelligent machines – this is the new artificial intelligence (AI) revolution, led by Geoffrey Hinton and his team since 2012. That year, Hinton, an expert in cognitive science at the University of Toronto and a researcher at Google Brain, demonstrated the striking effectiveness of a deep neural network (DNN) in an image-categorisation task.","Artificial neurons for deeply intelligent machines – this is the new artificial intelligence (AI) revolution, led by Geoffrey Hinton and his team since 2012. That year, Hinton, an expert in cognitive ...",https://schema.org,,BreadcrumbList,Why artificial intelligence is likely to take more lives,,"{'@type': 'WebPage', '@id': 'https://phys.org/news/2018-12-artificial-intelligence.html'}",,"{'@type': 'ImageObject', 'url': 'https://scx2.b-cdn.net/gfx/news/2018/whyartificia.jpg', 'width': 926, 'height': 592}",,"{'@type': 'Person', 'name': 'Martial Mermillod'}",,"{'@type': 'Organization', 'name': 'Phys.org', 'logo': {'@type': 'ImageObject', 'url': 'https://phys.b-cdn.net/tmpl/v6/img/logo.amp.png', 'width': 204, 'height': 60}}",,2018-12-11T09:40:02-05:00,2018-12-11T09:40:02-05:00,,,"










														December 11, 2018
														
													






Why artificial intelligence is likely to take more lives

										 by Martial Mermillod, 										 										 The Conversation







                Credit: Geralt/Pixabay
             

Artificial neurons for deeply intelligent machines – this is the new artificial intelligence (AI) revolution, led by Geoffrey Hinton and his team since 2012. That year, Hinton, an expert in cognitive science at the University of Toronto and a researcher at Google Brain, demonstrated the striking effectiveness of a deep neural network (DNN) in an image-categorisation task.





In the wake of these remarkable results, universities – and international corporations – invested massively in the promising and fascinating field of AI. Yet despite the impressive performance of DNNs in a variety of fields (visual and vocal recognition, translation, medical imagery, etc.), questions remain regarding the limits of deep learning for other uses, such as antonymous vehicles.
To understand the limits of AI in its current state, we need to understand where DNNs come from and, above all, which areas of the human brain they are modelled on – little is known about this in industrial engineering, and even in some research centres. Since the dawn of this new revolution, deep learning is sometimes used as a kind of ""magic wand"", with scant attention to its background or limitations. ""For a meaningful artificial intelligence"", the title of a recent report by French mathematician Cédric Villani, is evidence of the profound ambivalence surrounding this topic.
Where did deep learning come from?
The beginnings of artificial neural networks date back to the 1940s, with the pioneering discoveries in neuroscience and psychology of Warren McCulloch and Walter H. Pitts (who provided the first mathematical model of a neuron) and Donald Hebb (who described the mechanisms of synaptic learning). These researchers wanted to understand how neurons, the basic building blocks of the brain, could generate the psyche.










How DDN works.
Their seminal work led to the creation of the first artificial neuronal network, the Perceptron, designed in 1958 by American psychologist Frank Rosenblatt. Naturally, initial research was followed by significant developments based, for instance, on the neuroscientific studies of Alan L. Hodgkin and Andrew F. Huxley describing the temporal dynamics of neural integration, and on research in computer science and mathematics by Bernard Widrow and Ted Hoff, who suggested the use of stochastic gradient descent algorithms as a more effective way to modify the synaptic connections in neural networks.






These mathematical optimisations were further developed in the 1980s with research in cognitive science by David Rumelhart, Geoffrey Hinton and James McClelland, members of the Parallel Distributed Processing Research Group. Their work helped optimize the modification of synaptic connections in deep neuronal layers and led to the creation of the Multilayer Perceptron (MLP). DNNs, developed by researchers such as Geoffrey Hinton, Yann LeCun and Yoshua Bengio, are its direct descendants.
Is there a link between deep learning and the brain?
Although DNNs were originally developed through interdisciplinary work and inspired by brain function, one might wonder to what extent these algorithms still constitute a simulation of the human brain. They were designed to carry out such tasks as image recognition and categorisation. In order to do this, DNNs use various convolutional and pooling layers prior to image recognition.
With regards to convolutional layers, the work of David Hubel and Torsten Wiesel in the 1960s, and Leonie Jones and Derecke Palmer in the 1980s, demonstrate the usefulness of this method in simulating the likely response of neurons in the primary visual cortex. Several studies in cognitive science, including our own work, use this process as a neuro-inspired system to simulate the response of perceptual neurons in the primary visual cortex for instance.





                An example of the research demonstrating the similarities in the way deep neural networks and the ventral stream of the visual cortex operate. Credit: Kuzovkin, Vicente, Petton, Lachaux, Baciu, Kahane et Aru, 2018., Author provided
             


With regards to pooling, various studies in the fields of neuroscience and cognitive psychology over the last thirty years have demonstrated how the brain carries out this process of abstraction in the ventral visual stream. The work of Rufin Vogels and Keiji Tanaka show how this stream enables visual identification and categorisation, independently of the surface properties of an image, such as texture, colour, distance, or the position of objects within the image. These brain areas are therefore sensitive to the same information as the perceptual layers learned by a DNN during the process of pooling.
Even more surprising, research by Rodrigo Quian Quiroga and his colleagues demonstrates the existence of specific neurons for concepts or identities (for example, a ""Jennifer Aniston"" neuron, or a ""Tower of Pisa"" neuron). These fire in response to direct exposure to a concept, such as seeing the name ""Jennifer Aniston"" in print. What is more exciting for the future of AI is that the work of Mr. Quiroga demonstrates that this neuronal activity is correlated with the conscious perception of a stimulus in the environment.
To summarise, although they are simplified and mathematically optimised as compared to a biological brain, DNNs reproduce very similar processes as a very specific area in the cortex (namely, the occipito-temporal cortex). Using MRI or electrodes implanted in the brain, recent studies in cognitive neuroscience demonstrate similarities in the functioning of DNNs and these specific brain areas.
Is AI more reliable when inspired by the brain?
Basic interdisciplinary research on DNNs has produced impressive tangible results in a wide range of areas: visual recognition and categorisation, vocal recognition, translation, the game of go, musical composition, to name but a few. Unfortunately, through a lack of understanding of the cognitive science underpinning them, DNNs are still too often used as a kind of magic wand to solve any and all problems.





                It is possible to improve a neuromorphic system’s ability to anticipate by simulating the recurrent loops from associative areas to perceptual areas at work in the human brain. Credit: Mermillod, Bourrier, David, Kauffmann, Chauvin, Guyader, Dutheil et Peyrin, 2018., Author provided
             


To take the example of driverless cars, thoughtlessly coupling DNNs to the vehicle's control systems would be highly risky: it would be tantamount to asking a taxi driver who lost over 80% of his brain function in an accident (leaving only the visual ventral stream) to drive a car. Requiring these systems to do more than what they were originally designed for may lead to catastrophic accidents.






The human brain areas involved in anticipation (see below), spatial orientation and the sensory-motor functions required for driving in a complex environment are very different from the neural processes at work within the visual ventral stream. Located in the occipito-parietal cortex, the neuronal processes involved in the understanding and planning are very different from those taking place in the visual ventral stream! These are very different neurons, sensitive to distance, position and speed – all fundamental parameters for determining how we behave in the environment.
Undiscriminating use of DNNs (or other artificial systems) without reference or comparison to the neuro-inspiration behind the various cognitive functions is not only ineffective but outright dangerous. We do not claim that neuro-inspiration is the only effective way toward safer AI. However, given AI's tumultuous past, and taking into account the now proven effectiveness of neuro-inspired systems like DNNs as compared to previous engineering methods (for visual recognition, for example), we believe it is essential to understand how the brain performs other cognitive functions (motor control, multisensory integration, etc.) in order to compare this to current engineering techniques for performing these functions, and produce a safer, more efficient AI.
AI research conducted in closer collaboration with the cognitive sciences would enable us to:

understand and simulate brain areas which are not yet encompassed by deep learning.
develop more reliable and effective AI as compared to human performance.

This challenge requires interdisciplinary research involving not only mathematics and computer science, but also neuroscience and cognitive psychology, as well as research in electronics and physics to develop the neural processor units (NPU) currently being designed. We have the opportunity to finally overcome the limits of the Turing-Von Neumann machines that have dominated electronics and information technology since World War II.


													Provided by
																											The Conversation








This article is republished from The Conversation under a Creative Commons license. Read the original article.




Citation:
												Why artificial intelligence is likely to take more lives (2018, December 11)
												retrieved 16 July 2024
												from https://phys.org/news/2018-12-artificial-intelligence.html
											 

											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 


","[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://phys.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Technology', 'item': 'https://phys.org/technology-news/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Machine learning & AI', 'item': 'https://phys.org/technology-news/machine-learning-ai/'}]","{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='Description']/@content""]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LnBld3Jlc2VhcmNoLm9yZy9pbnRlcm5ldC8yMDE4LzEyLzEwL2ltcHJvdmVtZW50cy1haGVhZC1ob3ctaHVtYW5zLWFuZC1haS1taWdodC1ldm9sdmUtdG9nZXRoZXItaW4tdGhlLW5leHQtZGVjYWRlL9IBAA?oc=5,3. Improvements ahead: How humans and AI might evolve together in the next decade - Pew Research Center,2018-12-10,Pew Research Center,https://www.pewresearch.org,Other questions to the experts in this canvassing invited their views on the hopeful things that will occur in the next decade and for examples of,[],Other questions to the experts in this canvassing invited their views on the hopeful things that will occur in the next decade and for examples of,,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/#article', 'isPartOf': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/'}, 'author': {'name': 'Sara Atske', '@id': 'https://www.pewresearch.org/#/schema/person/81ad7bd61667c7d73ab64351212a033c'}, 'headline': '3. Improvements ahead: How humans and AI might evolve together in the next decade', 'datePublished': '2018-12-10T16:55:56+00:00', 'dateModified': '2024-04-14T09:12:48+00:00', 'mainEntityOfPage': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/'}, 'wordCount': 16301, 'commentCount': 0, 'publisher': {'@id': 'https://www.pewresearch.org/#organization'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://platform.pewresearch.org/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/', 'url': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/', 'name': '3. Improvements ahead: How humans and AI might evolve together in the next decade | Pew Research Center', 'isPartOf': {'@id': 'https://www.pewresearch.org/#website'}, 'datePublished': '2018-12-10T16:55:56+00:00', 'dateModified': '2024-04-14T09:12:48+00:00', 'description': 'Other questions to the experts in this canvassing invited their views on the hopeful things that will occur in the next decade and for examples of', 'breadcrumb': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/']}]}, {'@type': 'BreadcrumbList', '@id': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.pewresearch.org'}, {'@type': 'ListItem', 'position': 2, 'name': 'Research Topics', 'item': 'https://www.pewresearch.org/topics-categorized/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Internet &amp; Technology', 'item': 'https://www.pewresearch.org/topic/internet-technology/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Emerging Technology', 'item': 'https://www.pewresearch.org/topic/internet-technology/emerging-technology/'}, {'@type': 'ListItem', 'position': 5, 'name': 'Artificial Intelligence'}]}, {'@type': 'WebSite', '@id': 'https://www.pewresearch.org/#website', 'url': 'https://www.pewresearch.org/', 'name': 'Pew Research Center', 'description': 'Numbers, Facts and Trends Shaping Your World', 'publisher': {'@id': 'https://www.pewresearch.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.pewresearch.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.pewresearch.org/#organization', 'name': 'Pew Research Center', 'url': 'https://www.pewresearch.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/#/schema/logo/image/', 'url': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2024/04/logo-fallback.png', 'contentUrl': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2024/04/logo-fallback.png', 'width': 1265, 'height': 192, 'caption': 'Pew Research Center'}, 'image': {'@id': 'https://www.pewresearch.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/pewresearch', 'https://twitter.com/pewresearch', 'https://www.linkedin.com/company/pew-research-center/', 'https://www.youtube.com/user/PewResearchCenter']}, {'@type': 'Person', '@id': 'https://www.pewresearch.org/#/schema/person/81ad7bd61667c7d73ab64351212a033c', 'name': 'Sara Atske', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/5788245e97afeb895fedf7ded23300bd?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/5788245e97afeb895fedf7ded23300bd?s=96&d=mm&r=g', 'caption': 'Sara Atske'}, 'url': 'https://www.pewresearch.org/author/satske/'}]",NewsArticle,3. Improvements ahead: How humans and AI might evolve together in the next decade,http://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/,"{'@type': 'WebPage', '@id': 'http://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/'}",,"{'@type': 'ImageObject', 'url': ''}",,"[{'@type': 'Person', 'name': 'Sara Atske'}]",['Sara Atske'],"{'@type': 'Organization', 'name': 'Pew Research Center', 'logo': 'https://www.pewresearch.org/wp-content/themes/prc-block-theme/assets/img/square.png'}",2018-12-10T16:55:56Z,2018-12-10T16:55:56Z,2024-04-14T09:12:48Z,,,"short readsMay 15, 2024 

   

A quarter of U.S. teachers say AI tools do more harm than good in K-12 education ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMGh0dHBzOi8vd3d3LmVsb24uZWR1L3UvaW1hZ2luaW5nL3N1cnZleXMveC0yMDE4L9IBAA?oc=5,Survey X: Artificial Intelligence and the Future of Humans | Imagining the Internet - Today at Elon,2018-12-10,Today at Elon,https://www.elon.edu,,,,,,,,,,,,,,,,,,,,,,"


Survey X: Artificial Intelligence and the Future of Humans 

Will AI help most people be better off in 2030 than they are in 2018?
Results released in December 2018 – To illuminate current attitudes about the potential impacts of digital life on individuals’ well-being in the next decade and assess what interventions might possibly emerge to help resolve challenges, Pew Research and Elon University’s Imagining the Internet Center conducted a large-scale canvassing of technology experts, scholars, corporate and public practitioners and other leaders, asking:
“Please think forward to the year 2030. Analysts expect that people will become even more dependent on networked artificial intelligence (AI) in complex digital systems. Some say we will continue on the historic arc of augmenting our lives with mostly positive results as we widely implement these networked tools. Some say our increasing dependence on these AI and related systems is likely to lead to widespread difficulties.
Our question: By 2030, do you think it is most likely that advancing AI and related technology systems will enhance human capacities and empower them? That is, most of the time, will most people be better off than they are today? Or is it most likely that advancing AI and related technology systems will lessen human autonomy and agency to such an extent that most people will not be better off than the way things are today? Please explain why you chose the answer you did and sketch out a vision of how the human-machine/AI collaboration will function in 2030. Please consider giving an example of how a typical human-machine interaction will look and feel in a specific area, for instance, in the workplace, in family life, in a health care setting or in a learning environment. Why? What is your hope or fear? What actions might be taken to assure the best future?”
In answer to Question One:

About 63% of these respondents, said most people will be mostly better off.
About 37% said people will not be better off.
25 respondents chose not to select either option.

Among the key themes emerging in our December 10, 2018 report from 979 respondents’ overall answers were: * CONCERNS – Human Agency: Decision-making on key aspects of digital life is automatically ceded to code-driven, “black box” tools. People lack input and do not learn the context about how the tools work. They sacrifice independence, privacy and power over choice; they have no control over these processes. This effect will deepen as automated systems become more prevalent and complex. – Data Abuse: Most AI tools are and will be in the hands of companies striving for profits or governments striving for power. Values and ethics are often not baked into the digital systems making people’s decisions for them. These systems are globally networked and not easy to regulate or rein in. – Job Loss: The efficiencies and other economic advantages of code-based machine intelligence will continue to disrupt all aspects of human work. While some expect new jobs will emerge, others worry about massive job losses, widening economic divides and social upheavals, including populist uprisings. – Dependence Lock-in: Many see AI as augmenting human capacities but some predict the opposite – that people’s deepening dependence on machine-driven networks will erode their abilities to think for themselves, take action independent of automated systems and interact effectively with others. – Mayhem: Some predict further erosion of traditional sociopolitical structures and the possibility of great loss of lives due to accelerated growth of autonomous military applications and the use of weaponized information, lies and propaganda to dangerously destabilize human groups. Some also fear cybercriminals’ reach into economic systems. * POTENTIAL REMEDIES – Global Good is #1: It is vital to improve human collaboration across borders and stakeholder groups. Digital cooperation to serve humanity’s best interests is the top priority. Ways must be found for people around the world to come to common understandings and agreements – to join forces to facilitate the innovation of widely accepted approaches aimed at tackling wicked problems and maintaining control over complex human-digital networks. – Values-Based Systems: Develop policies to assure AI will be directed at the common good. Adopt a ‘moonshot mentality’ to build inclusive, decentralized intelligent digital networks ‘imbued with empathy’ that help humans aggressively ensure that technology meets social and ethical responsibilities. Some new level of regulatory and certification process will be necessary. – Prioritize People: Alter economic and political systems to better help humans “race with the machines.” Direct energies to radical human improvement. Reorganize economic and political systems toward the goal of expanding humans’ capacities and capabilities in order to heighten human/AI collaboration and staunch trends that would compromise human relevance in the face of programmed intelligence. * BENEFITS of AI 2030 – New Life and Work Efficiencies: AI will be integrated into most aspects of like, producing new efficiencies and enhancing human capacities, It can optimize and augment people’s life experiences, including the work lives of those who choose to work. – Health Care Improvements: AI can revolutionize medical and wellness services, reduce errors and recognize life-saving patterns, opening up a world of opportunity and options in health care. – Education Advances: Adaptive and individualized learning options and AI “assistants” might accelerate targeted, effective education expanding the horizons of all.
News release with a nutshell version of report findings is available here.
Choose a link below to read only the expert responses, with no sort or analysis.
All credited responses to the question on Ai and the Future of Humans.
All anonymous responses to the question on Ai and the Future of Humans.
Summary of Key Findings
Artificial Intelligence and the Future of Humans
Experts say the rise of artificial intelligence will make most people better off over the next decade, but many have concerns about how advances in AI will affect what it means to be human, to be productive and to exercise free will
Digital life is augmenting human capacities and disrupting eons-old human activities. Code-driven systems have spread to more than half of the world’s inhabitants in ambient information and connectivity, offering previously unimagined opportunities and unprecedented threats. As emerging algorithm-driven artificial intelligence (AI) continues to spread, will people be better off than they are today?
Some 979 technology pioneers, innovators, developers, business and policy leaders, researchers and activists answered this question in a canvassing of experts conducted in the summer of 2018.
The experts predicted networked artificial intelligence will amplify human effectiveness but also threaten human autonomy, agency and capabilities. They spoke of the wide-ranging possibilities; that computers might match or even exceed human intelligence and capabilities on tasks such as complex decision-making, reasoning and learning, sophisticated analytics and pattern recognition, visual acuity, speech recognition and language translation. They said “smart” systems in communities, in vehicles, in buildings and utilities, on farms and in business processes will save time, money and lives and offer opportunities for individuals to enjoy a more-customized future.
Many focused their optimistic remarks on health care and the many possible applications of AI in diagnosing and treating patients or helping senior citizens live fuller and healthier lives. They were also enthusiastic about AI’s role in contributing to broad public-health programs built around massive amounts of data that may be captured in the coming years about everything from personal genomes to nutrition. Additionally, a number of these experts predicted that AI would abet long-anticipated changes in formal and informal education systems.
Yet, most experts, regardless of whether they are optimistic or not, expressed concerns about the long-term impact of these new tools on the essential elements of being human. All respondents in this non-scientific canvassing were asked to elaborate on why they felt AI would leave people better off or not. Many shared deep concerns, and many also suggested pathways toward solutions. The main themes they sounded about threats and remedies are outlined in the accompanying table.

What do trends indicate?
Specifically, participants were asked to consider the following:
“Please think forward to the year 2030. Analysts expect that people will become even more dependent on networked artificial intelligence (AI) in complex digital systems. Some say we will continue on the historic arc of augmenting our lives with mostly positive results as we widely implement these networked tools. Some say our increasing dependence on these AI and related systems is likely to lead to widespread difficulties.
“Our question: By 2030, do you think it is most likely that advancing AI and related technology systems will enhance human capacities and empower them? That is, most of the time, will most people be better off than they are today? Or is it most likely that advancing AI and related technology systems will lessen human autonomy and agency to such an extent that most people will not be better off than the way things are today?”
Overall, and despite the downsides they fear, 63% of respondents in this canvassing said they are hopeful that most individuals will be mostly better off in 2030, and 37% said people will not be better off.
A number of the thought leaders who participated in this canvassing said humans’ expanding reliance on technological systems will only go well if close attention is paid to how these tools, platforms and networks are engineered, distributed and updated. Following are some of the most powerful overarching answers.
Sonia Katyal, co-director of the Berkeley Center for Law and Technology and a member of the inaugural U.S. Commerce Department Digital Economy Board of Advisors, predicted, “In 2030, the greatest set of questions will involve how perceptions of AI and their application will influence the trajectory of civil rights in the future. Questions about privacy, speech, the right of assembly and technological construction of personhood will all re-emerge in this new AI context, throwing into question our deepest-held beliefs about equality and opportunity for all. Who will benefit and who will be disadvantaged in this new world depends on how broadly we analyze these questions today, for the future.”
Erik Brynjolfsson, director of the MIT Initiative on the Digital Economy and author of “Machine, Platform, Crowd: Harnessing Our Digital Future,” said, “AI and related technologies have already achieved superhuman performance in many areas, and there is little doubt that their capabilities will improve, probably very significantly, by 2030. … I think it is more likely than not that we will use this power to make the world a better place. For instance, we can virtually eliminate global poverty, massively reduce disease and provide better education to almost everyone on the planet. That said, AI and ML [machine learning] can also be used to increasingly concentrate wealth and power, leaving many people behind, and to create even more horrifying weapons. Neither outcome is inevitable, so the right question is not ‘What will happen?’ but ‘What will we choose to do?’ We need to work aggressively to make sure technology matches our values. This can and must be done at all levels, from government, to business, to academia, and to individual choices.”
Bryan Johnson, founder and CEO of Kernel, a leading developer of advanced neural interfaces, and OS Fund, a venture capital firm, said, “I strongly believe the answer depends on whether we can shift our economic systems toward prioritizing radical human improvement and staunching the trend toward human irrelevance in the face of AI. I don’t mean just jobs; I mean true, existential irrelevance, which is the end result of not prioritizing human well-being and cognition.”
Marina Gorbis, executive director of the Institute for the Future, said, “Without significant changes in our political economy and data governance regimes [AI] is likely to create greater economic inequalities, more surveillance and more programmed and non-human-centric interactions. Every time we program our environments, we end up programming ourselves and our interactions. Humans have to become more standardized, removing serendipity and ambiguity from our interactions. And this ambiguity and complexity is what is the essence of being human.”
Judith Donath, author of “The Social Machine, Designs for Living Online” and faculty fellow at Harvard University’s Berkman Klein Center for Internet & Society, commented, “By 2030, most social situations will be facilitated by bots – intelligent-seeming programs that interact with us in human-like ways. At home, parents will engage skilled bots to help kids with homework and catalyze dinner conversations. At work, bots will run meetings. A bot confidant will be considered essential for psychological well-being, and we’ll increasingly turn to such companions for advice ranging from what to wear to whom to marry. We humans care deeply about how others see us – and the others whose approval we seek will increasingly be artificial. By then, the difference between humans and bots will have blurred considerably. Via screen and projection, the voice, appearance and behaviors of bots will be indistinguishable from those of humans, and even physical robots, though obviously non-human, will be so convincingly sincere that our impression of them as thinking, feeling beings, on par with or superior to ourselves, will be unshaken. Adding to the ambiguity, our own communication will be heavily augmented: Programs will compose many of our messages and our online/AR appearance will [be] computationally crafted. (Raw, unaided human speech and demeanor will seem embarrassingly clunky, slow and unsophisticated.) Aided by their access to vast troves of data about each of us, bots will far surpass humans in their ability to attract and persuade us. Able to mimic emotion expertly, they’ll never be overcome by feelings: If they blurt something out in anger, it will be because that behavior was calculated to be the most efficacious way of advancing whatever goals they had ‘in mind.’ But what are those goals? Artificially intelligent companions will cultivate the impression that social goals similar to our own motivate them – to be held in good regard, whether as a beloved friend, an admired boss, etc. But their real collaboration will be with the humans and institutions that control them. Like their forebears today, these will be sellers of goods who employ them to stimulate consumption and politicians who commission them to sway opinions.”
Andrew McLaughlin, executive director of the Center for Innovative Thinking at Yale University, previously deputy chief technology officer of the United States for President Barack Obama and global public policy lead for Google, wrote, “2030 is not far in the future. My sense is that innovations like the internet and networked AI have massive short-term benefits, along with long-term negatives that can take decades to be recognizable. AI will drive a vast range of efficiency optimizations but also enable hidden discrimination and arbitrary penalization of individuals in areas like insurance, job seeking and performance assessment.”
Michael M. Roberts, first president and CEO of the Internet Corporation for Assigned Names and Numbers (ICANN) and Internet Hall of Fame member, wrote, “The range of opportunities for intelligent agents to augment human intelligence is still virtually unlimited. The major issue is that the more convenient an agent is, the more it needs to know about you – preferences, timing, capacities, etc. – which creates a tradeoff of more help requires more intrusion. This is not a black-and-white issue – the shades of gray and associated remedies will be argued endlessly. The record to date is that convenience overwhelms privacy. I suspect that will continue.”
danah boyd, a principal researcher for Microsoft and founder and president of the Data & Society Research Institute, said, “AI is a tool that will be used by humans for all sorts of purposes, including in the pursuit of power. There will be abuses of power that involve AI, just as there will be advances in science and humanitarian efforts that also involve AI. Unfortunately, there are certain trend lines that are likely to create massive instability. Take, for example, climate change and climate migration. This will further destabilize Europe and the U.S., and I expect that, in panic, we will see AI be used in harmful ways in light of other geopolitical crises.”
Amy Webb, founder of the Future Today Institute and professor of strategic foresight at New York University, commented, “The social safety net structures currently in place in the U.S. and in many other countries around the world weren’t designed for our transition to AI. The transition through AI will last the next 50 years or more. As we move farther into this third era of computing, and as every single industry becomes more deeply entrenched with AI systems, we will need new hybrid-skilled knowledge workers who can operate in jobs that have never needed to exist before. We’ll need farmers who know how to work with big data sets. Oncologists trained as robotocists. Biologists trained as electrical engineers. We won’t need to prepare our workforce just once, with a few changes to the curriculum. As AI matures, we will need a responsive workforce, capable of adapting to new processes, systems and tools every few years. The need for these fields will arise faster than our labor departments, schools and universities are acknowledging. It’s easy to look back on history through the lens of present – and to overlook the social unrest caused by widespread technological unemployment. We need to address a difficult truth that few are willing to utter aloud: AI will eventually cause a large number of people to be permanently out of work. Just as generations before witnessed sweeping changes during and in the aftermath of the Industrial Revolution, the rapid pace of technology will likely mean that Baby Boomers and the oldest members of Gen X – especially those whose jobs can be replicated by robots – won’t be able to retrain for other kinds of work without a significant investment of time and effort.”
Barry Chudakov, founder and principal of Sertain Research, commented, “By 2030 the human-machine/AI collaboration will be a necessary tool to manage and counter the effects of multiple simultaneous accelerations: broad technology advancement, globalization, climate change and attendant global migrations. In the past, human societies managed change through gut and intuition, but as Eric Teller, CEO of Google X, has said, ‘Our societal structures are failing to keep pace with the rate of change.’ To keep pace with that change and to manage a growing list of ‘wicked problems’ by 2030, AI – or using Joi Ito’s phrase, extended intelligence – will value and revalue virtually every area of human behavior and interaction. AI and advancing technologies will change our response framework and time frames (which in turn, changes our sense of time). Where once social interaction happened in places – work, school, church, family environments – social interactions will increasingly happen in continuous, simultaneous time. If we are fortunate, we will follow the 23 Asilomar AI Principles outlined by the Future of Life Institute and will work toward ‘not undirected intelligence but beneficial intelligence.’ Akin to nuclear deterrence stemming from mutually assured destruction, AI and related technology systems constitute a force for a moral renaissance. We must embrace that moral renaissance, or we will face moral conundrums that could bring about human demise. … My greatest hope for human-machine/AI collaboration constitutes a moral and ethical renaissance – we adopt a moonshot mentality and lock arms to prepare for the accelerations coming at us. My greatest fear is that we adopt the logic of our emerging technologies – instant response, isolation behind screens, endless comparison of self-worth, fake self-presentation – without thinking or responding smartly.”
John C. Havens, executive director of the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems and the Council on Extended Intelligence, wrote, “Now, in 2018, a majority of people around the world can’t access their data, so any ‘human-AI augmentation’ discussions ignore the critical context of who actually controls people’s information and identity. Soon it will be extremely difficult to identify any autonomous or intelligent systems whose algorithms don’t interact with human data in one form or another.”
Batya Friedman, a human-computer interaction professor at the University of Washington’s Information School, wrote, “Our scientific and technological capacities have and will continue to far surpass our moral ones – that is our ability to use wisely and humanely the knowledge and tools that we develop. … Automated warfare – when autonomous weapons kill human beings without human engagement – can lead to a lack of responsibility for taking the enemy’s life or even knowledge that an enemy’s life has been taken. At stake is nothing less than what sort of society we want to live in and how we experience our humanity.”
Greg Shannon, chief scientist for the CERT Division at Carnegie Mellon University, said, “Better/worse will appear 4:1 with the long-term ratio 2:1. AI will do well for repetitive work where ‘close’ will be good enough and humans dislike the work. … Life will definitely be better as AI extends lifetimes, from health apps that intelligently ‘nudge’ us to health, to warnings about impending heart/stroke events, to automated health care for the underserved (remote) and those who need extended care (elder care). As to liberty, there are clear risks. AI affects agency by creating entities with meaningful intellectual capabilities for monitoring, enforcing and even punishing individuals. Those who know how to use it will have immense potential power over those who don’t/can’t. Future happiness is really unclear. Some will cede their agency to AI in games, work and community, much like the opioid crisis steals agency today. On the other hand, many will be freed from mundane, unengaging tasks/jobs. If elements of community happiness are part of AI objective functions, then AI could catalyze an explosion of happiness.”
Kostas Alexandridis, author of “Exploring Complex Dynamics in Multi-agent-based Intelligent Systems,” predicted, “Many of our day-to-day decisions will be automated with minimal intervention by the end-user. Autonomy and/or independence will be sacrificed and replaced by convenience. Newer generations of citizens will become more and more dependent on networked AI structures and processes. There are challenges that need to be addressed in terms of critical thinking and heterogeneity. Networked interdependence will, more likely than not, increase our vulnerability to cyberattacks. There is also a real likelihood that there will exist sharper divisions between digital ‘haves’ and ‘have-nots,’ as well as among technologically dependent digital infrastructures. Finally, there is the question of the new ‘commanding heights’ of the digital network infrastructure’s ownership and control.”
Oscar Gandy, emeritus professor of communication at the University of Pennsylvania, responded, “We already face an ungranted assumption when we are asked to imagine human-machine ‘collaboration.’ Interaction is a bit different, but still tainted by the grant of a form of identity – maybe even personhood – to machines that we will use to make our way through all sorts of opportunities and challenges. The problems we will face in the future are quite similar to the problems we currently face when we rely upon ‘others’ (including technological systems, devices and networks) to acquire things we value and avoid those other things (that we might, or might not be aware of).”
James Scofield O’Rourke, a professor of management at the University of Notre Dame, said, “Technology has, throughout recorded history, been a largely neutral concept. The question of its value has always been dependent on its application. For what purpose will AI and other technological advances be used? Everything from gunpowder to internal combustion engines to nuclear fission has been applied in both helpful and destructive ways. Assuming we can contain or control AI (and not the other way around), the answer to whether we’ll be better off depends entirely on us (or our progeny). ‘The fault, dear Brutus, is not in our stars, but in ourselves, that we are underlings.’”
Simon Biggs, a professor of interdisciplinary arts at the University of Edinburgh, said, “AI will function to augment human capabilities. The problem is not with AI but with humans. As a species we are aggressive, competitive and lazy. We are also empathic, community minded and (sometimes) self-sacrificing. We have many other attributes. These will all be amplified. Given historical precedent, one would have to assume it will be our worst qualities that are augmented. My expectation is that in 2030 AI will be in routine use to fight wars and kill people, far more effectively than we can currently kill. As societies we will be less affected by this as we currently are, as we will not be doing the fighting and killing ourselves. Our capacity to modify our behaviour, subject to empathy and an associated ethical framework, will be reduced by the disassociation between our agency and the act of killing. We cannot expect our AI systems to be ethical on our behalf – they won’t be, as they will be designed to kill efficiently, not thoughtfully. My other primary concern is to do with surveillance and control. The advent of China’s Social Credit System (SCS) is an indicator of what it likely to come. We will exist within an SCS as AI constructs hybrid instances of ourselves that may or may not resemble who we are. But our rights and affordances as individuals will be determined by the SCS. This is the Orwellian nightmare realised.”
Mark Surman, executive director of the Mozilla Foundation, responded, “AI will continue to concentrate power and wealth in the hands of a few big monopolies based on the U.S. and China. Most people – and parts of the world – will be worse off.”
William Uricchio, media scholar and professor of comparative media studies at MIT, commented, “AI and its related applications face three problems: development at the speed of Moore’s Law, development in the hands of a technological and economic elite, and development without benefit of an informed or engaged public. The public is reduced to a collective of consumers awaiting the next technology. Whose notion of ‘progress’ will prevail? We have ample evidence of AI being used to drive profits, regardless of implications for long-held values; to enhance governmental control and even score citizens’ ‘social credit’ without input from citizens themselves. Like technologies before it, AI is agnostic. Its deployment rests in the hands of society. But absent an AI-literate public, the decision of how best to deploy AI will fall to special interests. Will this mean equitable deployment, the amelioration of social injustice and AI in the public service? Because the answer to this question is social rather than technological, I’m pessimistic. The fix? We need to develop an AI-literate public, which means focused attention in the educational sector and in public-facing media. We need to assure diversity in the development of AI technologies. And until the public, its elected representatives and their legal and regulatory regimes can get up to speed with these fast-moving developments we need to exercise caution and oversight in AI’s development.”
The remainder of this report is divided into three sections that draw from hundreds of additional respondents’ hopeful and critical observations: 
1) Concerns about human-AI evolution.
2) Suggested solutions to address AI’s impact.
3) Expectations of what life will be like in 2030, including respondents’ positive outlooks on the quality of life and the future of work, health care and education.
Some responses are lightly edited for style.
1. Concerns about human agency, evolution and survival
A clear majority of the responses from these experts contained material outlining certain challenges, fears or concerns about the AI-infused future. The five most-often mentioned concerns were: 1) the use of AI reduces individuals’ control over their lives; 2) surveillance and data systems designed primarily for efficiency, profit and control are inherently dangerous;3) displacement of human jobs by AI will widen economic and digital divides, possibly leading to social upheaval; 4) individuals’ cognitive, social and survival skills will be diminished as they become dependent on AI; and 5) citizens will face increased vulnerabilities, such as exposure to cybercrime and cyberwarfare that spin out of control and the possibility that essential organizations are endangered by weaponized information. A few also worried about the wholesale destruction of humanity. The sections of this chapter will cover experts’ answers tied to these themes.
The use of AI reduces individuals’ control over their lives
Autonomous systems can reduce or eliminate the need for human involvement in some tasks. Today’s ever-advancing artificial narrow intelligence (ANI) tools – for instance, search engines and digital “agents” such as Siri, Alexa and Cortana – are not close to reaching the goal of human-like artificial general intelligence (AGI). They are, however, continually becoming more powerful thanks to developments in machine learning and natural language processing and advances in materials science, networking, energy-storage and hardware capabilities.
ANI is machine intelligence that equals or exceeds people’s abilities or efficiency at a specific task. For years, code-based tools in robots and other systems have performed repetitive tasks like factory-floor assembly activities. Today, these tools are quickly evolving to master human traits such as reason, logic, learning, task-performance and creativity. Today’s smart, networked,  software-equipped devices, cars, digital assistants and platforms, such as Google search and Facebook social mapping, accomplish extremely complex tasks. The systems underpinning today’s global financial markets, businesses, militaries, police forces, and medical, energy and industrial operations are all dependent upon networked AI of one type or another.
What is the future of humans in an age of accelerating technological change?
Many experts in this canvassing said that as AI advances human autonomy and agency are at risk. They note that decision-making on key aspects of life is ceded to code-driven tools. Individuals who function in this digital world sacrifice, to varying degrees, their independence, right to privacy and power over choice. Many of the experts who worry about this say humans accede to this in order to stay competitive, to participate socially and professionally in the world, to be entertained and to get things done. They say people hand over some control of their lives because of the perceived advantages they gain via digital tools – efficiency, convenience and superior pattern recognition, data storage, and search-and-find capabilities. Here is a selection of responses from these experts that touch on this:
An anonymous respondent summed up the concerns of many, writing, “The most-feared reversal in human fortune of the AI age is loss of agency. The trade-off for the near-instant, low-friction convenience of digital life is the loss of context about and control over its processes. People’s blind dependence on digital tools is deepening as automated systems become more complex and ownership of those systems is by the elite.”
Baratunde Thurston, futurist, former director of digital at The Onion and co-founder of comedy/technology start-up Cultivated Wit, said, “For the record, this is not the future I want, but it is what I expect given existing default settings in our economic and sociopolitical system preferences. … The problems to which we are applying machine learning and AI are generally not ones that will lead to a ‘better’ life for most people. That’s why I say in 2030, most people won’t be better due to AI. We won’t be more autonomous; we will be more automated as we follow the metaphorical GPS line through daily interactions. We don’t choose our breakfast or our morning workouts or our route to work. An algorithm will make these choices for us in a way that maximizes efficiency (narrowly defined) and probably also maximizes the profitability of the service provider. By 2030, we may cram more activities and interactions into our days, but I don’t think that will make our lives ‘better.’ A better life, by my definition, is one in which we feel more valued and happy. Given that the biggest investments in AI are on behalf of marketing efforts designed to deplete our attention and bank balances, I can only imagine this leading to days that are more filled but lives that are less fulfilled. To create a different future, I believe we must unleash these technologies toward goals beyond profit maximization. Imagine a mapping app that plotted your work commute through the most beautiful route, not simply the fastest. Imagine a communications app that facilitated deeper connections with people you deemed most important. These technologies must be more people-centric. We need to ask that they ask us, ‘What is important to you? How would you like to spend your time?’ But that’s not the system we’re building. All those decisions have been hoarded by the unimaginative pursuit of profit.”
Thad Hall, a researcher and coauthor of “Politics for a Connected American Public,” added: “AI is likely to have benefits – from improving medical diagnoses to improving people’s consumer experiences. However, there are four aspects of AI that are very problematic. 1) It is likely to result in more economic uncertainty and dislocation for people, including employment issues and more need to change jobs to stay relevant. 2) AI will continue to erode people’s privacy as search becomes more thorough. China’s monitoring of populations illustrates what this could look like in authoritarian and Western countries, with greater facial recognition used to identify people and affect their privacy. 3) AI will likely continue to have biases that are negative toward minority populations, including groups we have not considered. Given that algorithms often have identifiable biases (e.g., favoring people who are white or male), they likely also have biases that are less well-recognized, such as biases that are negative toward people with disabilities, older people or other groups. These biases may ripple through society in unknown ways. Some groups are more likely to be monitored effectively. 4) AI is creating a world where reality can be manipulated in ways we do not appreciate. Fake videos, audio and similar media are likely to explode and create a world where ‘reality’ is hard to discern. The relativistic political world will become more so, with people having evidence to support their own reality or multiple realities that mean no one knows what is the ‘truth.’”
Thomas Schneider, head of International Relations Service and vice-director at the Federal Office of Communications (OFCOM) in Switzerland, said, “AI will help mankind to be more efficient, live safer and healthier, and manage resources like energy, transport, etc., more efficiently. At the same time, there are a number of risks that AI may be used by those in power to manipulate, control and dominate others. (We have seen this with every new technology: It can and will be used for good and bad.) Much will depend about how AI will be governed: If we have an inclusive and bottom-up governance system of well-informed citizens, then AI will be used for improving our quality of life. If only a few people decide about how AI is used and what for, many others will be dependent on the decisions of these few and risk being manipulated by them. The biggest danger in my view is that there will be a greater pressure on all members of our societies to live according to what ‘the system’ will tell us is ‘best for us’ to do and not to do, i.e., that we may lose the autonomy to decide ourselves how we want to live our lives, to choose diverse ways of doing things. With more and more ‘recommendations,’ ‘rankings’ and competition through social pressure and control, we may risk a loss of individual fundamental freedoms (including but not limited to the right to a private life) that we have fought for in the last decades and centuries.”
Bart Knijnenburg, assistant professor of computer science who is active in the Human Factors Institute at Clemson University, said, “Whether AI will make our lives better depends on how it is implemented. Many current AI systems (including adaptive content-presentation systems and so-called recommender systems) try to avoid information and choice overload by replacing our decision-making processes with algorithmic predictions. True empowerment will come from these systems supporting rather than replacing our decision-making practices. This is the only way we can overcome choice/information overload and at the same time avoid so-called ‘filter bubbles.’ For example, Facebook’s current post ranking systems will eventually turn us all into cat video watching zombies, because they follow our behavioral patterns, which may not be aligned with our preferences. The algorithms behind these tools need to support human agency, not replace it.”
Peter Reiner, professor and co-founder of the National Core for Neuroethics at the University of British Columbia, commented, “I am confident that in 2030 both arms of this query will be true: AI-driven algorithms will substantially enhance our abilities as humans and human autonomy and agency will be diminished. Whether people will be better off than they are today is a separate question, and the answer depends to a substantial degree on how looming technological developments unfold. On the one hand, if corporate entities retain unbridled control over how AI-driven algorithms interact with humans, people will be less well off, as the loss of autonomy and agency will be largely to the benefit of the corporations. On the other hand, if ‘we the people’ demand that corporate entities deploy AI-algorithms in a manner that is sensitive to the issues of human autonomy and agency, then there is a real possibility for us to be better off – enhanced by the power of the AI-driven algorithm and yet not relegated to an impoverished seat at the decision-making table. One could even parse this further, anticipating that certain decisions can be comfortably left in the hands of the AI-driven algorithm, with other decisions either falling back on humans or arrived at through a combination of AI-driven algorithmic input and human decision making. If we approach these issues skillfully – and it will take quite a bit of collaborative work between ethicists and industry – we can have the best of both worlds. On the other hand, if we are lax in acting as watchdogs over industry we will be functionally rich and decisionally poor.”
Paul Vixie, an Internet Hall of Fame member known for designing and implementing several Domain Name System protocol extensions and applications, wrote, “Understanding is a perfect proxy for control. As we make more of the world’s economy non-understandable by the masses, we make it easier for powerful interests to practice control. Real autonomy or privacy or unpredictability will be seen as a threat and managed around.”
João Pedro Taveira, embedded systems researcher and smart grids architect for INOV INESC Inovação in Portugal, wrote, “Basically, we will lose several degrees of freedom. Are we ready for that? When we wake up to what is happening it might be too late to do anything about it. Artificial intelligence is a subject that must be studied philosophically, in open-minded, abstract and hypothetical ways. Using this perspective, the issues to be solved by humans are (but not limited to) AI, feelings, values, motivation, free will, solidarity, love and hate. Yes, we will have serious problems. Dropping the ‘artificial’ off AI, look at the concept of intelligence. As a computer-science person, I know that so-called ‘AI’ studies how an agent (a software program) increases its knowledge base using rules that are defined using pattern-recognition mechanisms. No matter which mechanisms are used to generate this rule set, the result will be always behavioral profiling. Right now, everybody uses and agrees to use a wide set of appliances, services and products without a full understanding of the information that is being shared with enterprises, companies and other parties. There’s a lack of needed regulation and audit mechanisms on who or what uses our information and how it is used and whether it is stored for future use. Governments and others will try to access this information using these tools by decree, arguing national security or administration efficiency improvements. Enterprises and companies might argue that these tools offer improvement of quality of service, but there’s no guarantee about individuals’ privacy, anonymity, individual security, intractability and so on.”
Ramon Lopez de Mantaras, director of the Spanish National Research Council’s Artificial Intelligence Research Institute, said, “I do not think it is a good idea to give high levels of autonomy to AI systems. They are, and will be, weak AI systems without commonsense knowledge. They will have more and more competence, yes, but this will be competence without comprehension. AI machines should remain at the level of tools or, at most, assistants, always keeping the human in the loop. We should all read or re-read the book ‘Computer Power and Human Reason’ by Joseph Weizenbaum before deciding whether or not to give lots of autonomy to stupid machines.”
Oscar Gandy, emeritus professor of communication at the University of Pennsylvania, responded, “AI systems will make quite substantial and important contributions to the ability of health care providers to generate accurate diagnoses of maladies and threats to my well-being, now and in the future. I can imagine the development and deployment of systems in which my well-being is the primary basis of our relationship. I am less sure about how my access to and use of this resource may be constrained or distorted by the interests of the other actors (humans within profit/power-seeking orientations). I assume that they will be aided by their own AI systems informing them how to best present options to me. I am hopeful that we will have agents (whether private, social, governmental) whose interest and responsibility is in ensuring that my interests govern those relationships.”
Robert Epstein, senior research psychologist at the American Institute for Behavioral Research and Technology and the founding director of the Loebner Prize, a competition in artificial intelligence, said, “By 2030, it is likely that AIs will have achieved a type of sentience, even if it is not human-like. They will also be able to exercise varying degrees of control over most human communications, financial transactions, transportation systems, power grids and weapon systems. As I noted in my 2008 book, ‘Parsing the Turing Test,’ they will reside in the ‘InterNest’ we have been building for them, and we will have no way of dislodging them. How they decide to deal with humanity – to help us, ignore us or destroy us – will be entirely up to them, and there is no way currently to predict which avenue they will choose. Because a few paranoid humans will almost certainly try to destroy the new sentient AIs, there is at least a reasonable possibility that that they will swat us like the flies we are – the possibility that Stephen Hawking, Elon Musk and others have warned about. There is no way, to my knowledge, of stopping this future from emerging. Driven by the convenience of connectivity, the greed that underlies business expansion and the pipedreams of muddle-headed people who confuse machine-like intelligence with biological intelligence, we will continue to build AIs we can barely understand and to expand the InterNest in which they will live – until the inevitable – whatever that proves to be – occurs.”
An attorney specializing in policy issues for a global digital rights organization commented, “I’m not sure, even today, whether the tech advances of the last 12 years have been net positive over the global population. We’ve seen a widening gap between the very rich and everybody else. That is likely bad for democracy. AI seems likely to make the employment/training problem worse in the U.S., and AI may have similar effects in countries that currently provide cheap labor. On the political-governmental side, AI will exacerbate current surveillance and accountability problems. I figure that AI will improve and speed up all biometric pattern recognition as well as DNA analysis and natural language processing. And though we know that much of this is biased, we’re not adequately counteracting the bias we know about. The companies who generate and disseminate AI technology have every incentive to continue. I’m not optimistic that collective action – at least in the U.S. system – will successfully counter those incentives.”
Brian Behlendorf, executive director of the Hyperledger project at The Linux Foundation and expert in blockchain technology, wrote, “I am concerned that AI will not be a democratizing power, but will enhance further the power and wealth of those who already hold it. This is because more data means better AI, and data is expensive to acquire, especially personal data, the most valuable kind. This is in contrast to networking technologies, whose benefits were shared fairly widely as the prices for components came down equally fast for everyone. One other reason: AI apps will be harder to debug than ordinary apps, and we already see hard-to-debug applications leading to disenfranchisement and deterioration of living. So, I do not take as a given that AI will enrich ‘most’ people’s lives over the next 12 years.”
Eileen Donahoe, executive director of the Global Digital Policy Incubator at Stanford University, commented, “While I do believe human-machines collaboration will bring many benefits to society over time, I fear that we will not have made enough progress by 2030 to ensure that benefits will be spread evenly or to protect against downside risks, especially as they relate to bias, discrimination and loss of accountability by that time.”
David Bray, executive director of People-Centered Internet, commented, “Hope: Human-machine/AI collaborations extend our abilities of humans while we (humans) intentionally strive to preserve values of respect, dignity and agency of choice for individuals. Machines bring together different groups of people and communities and help us work and live together by reflecting on our own biases and helping us come to understand the plurality of different perspectives of others. Big concern: Human-machine/AI collaborations turn out to not benefit everyone, only a few, and result in a form of ‘indentured servitude’ or ‘neo-feudalism’ that is not people-centered and not uplifting of people. Machines amplify existing confirmation biases and other human characteristics resulting in sensationalist, emotion-ridden news and other communications that gets page views and ad-clicks yet lack nuance of understanding, resulting in tribalism and a devolution of open societies and pluralities to the detriment of the global human condition.”
Bernie Hogan, senior research fellow at Oxford Internet Institute, wrote, “The current political and economic climate suggests that existing technology, especially machine learning, will be used to create better decisions for those in power while creating an ever more tedious morass of bureaucracy for the rest. We see little example of successful bottom-up technology, open source technology and hacktivism relative to the encroaching surveillance state and attention economy.”
Dan Buehrer, a retired professor of computer science formerly with the National Chung Cheng University in Taiwan, warned, “Statistics will be replaced by individualized models, thus allowing control of all individuals by totalitarian states and, eventually, by socially intelligent machines.”
Nathalie Marechal, doctoral candidate at the University of Southern California’s Annenberg School for Communication who researches the intersection of internet policy and human rights, said, “Absent rapid and decisive actions to rein in both government overreach and companies’ amoral quest for profit, technological developments – including AI – will bring about the infrastructure for total social control, threatening democracy and the right to individual self-determination.”
Katja Grace, contributor to the AI Impacts research project and a research associate with the Machine Intelligence Research Institute, said, “There is a substantial chance that AI will leave everyone worse off, perhaps radically so. The chance is less than 50 percent, but the downside risk is so large that there could be an expectation the world might be worse for AI.”
David A. Banks, an associate research analyst with the Social Science Research Council, said, “AI will be very useful to a small professional class but will be used to monitor and control everyone else.”
Luis German Rodriguez Leal, teacher and researcher at the Universidad Central de Venezuela and consultant on technology for development, said, “Humankind is not addressing properly the issue of educating people about possibilities and risks of human-machine/AI collaboration. One can observe today the growing problems of ill-intentioned manipulation of information and technological resources. There are already plenty of examples about how decision-making is biased using big data, machine learning, privacy violations and social networks (just to mention a few elements) and one can see that the common citizen is unaware of how much of his/her will does not belong to him/her. This fact has a meaningful impact on our social, political, economic and private life. We are not doing enough to attend to this issue, and it is getting very late.”
Llewellyn Kriel, CEO of TopEditor International, a media services company based in Johannesburg, South Africa, wrote, “Current developments do not augur well for the fair growth of AI. Vast swaths of the population simply do not have the intellectual capacity or level of sophistication to understand 1) the technology itself and 2) the implications of its safe use. This entrenches and widens the digital divide in places like Africa. The socio-political implications of this breed deep primitive superstition, racial hatred toward whites and Asians who are seen as techno-colonialists and the growth of kleptocracies amid the current mushrooming of corruption.”
Steven Thompson, an author specializing in illuminating emerging issues and editor of “Androids, Cyborgs, and Robots in Contemporary Culture and Society,” wrote, “The keyword from the query is ‘dependence.’ I published pioneering quantitative research on internet addiction and dependency in 1996, and followed up 15 years later with a related, updated research talk on the future of AI and internet dependency at a UNESCO-sponsored conference on information literacy in Morocco. My expertise is in ethical and technological issues related to moving the internet appliance into the human body. … The internet is moving into the human body, and, in that process, societal statuses are altered, privileging some while abandoning others in the name of emerging technologies, and the global order is restructuring to the same effect. Think of net neutrality issues gone wild, corporately and humanly sustained with the privileges such creation and maintenance affords some members of society. Now think of the liberty issues arising from those persons who are digital outcasts, and wish to not be on the grid, yet will be forced to do so by society and even government edicts.”
Alan Mutter, a longtime Silicon Valley CEO, cable TV executive and now a teacher of media economics and entrepreneurism at the University of California, Berkeley, said, “The danger is that we will surrender thinking, exploring and experimentation to tools that hew to the rules but can’t color outside the lines. Would you like computers to select the president or decide if you need hip surgery?”
Dan Geer, a respondent who provided no identifying details, commented, “If you believe, as do I, that having a purpose to one’s life is all that enables both pride and happiness, then the question becomes whether AI will or will not diminish purpose. For the irreligious, AI will demolish purpose, yet if AI is truly intelligent, then AI will make serving it the masses’ purpose. Ergo …”
Cristobal Young, an associate professor of sociology at Cornell University specializing in economic sociology and stratification, commented, “I mostly base my response [that tech will not leave most people better off than they are today] on Twitter and other online media, which were initially praised as ‘liberation technology.’ It is clear that the internet has devastated professional journalism, filled the public sphere with trash that no one believes and degraded civil discourse. This isn’t about robots, but rather about how humans use the internet. Donald Trump himself says that without Twitter, he could never have been elected, and Twitter continues to be his platform for polarization, insult and attacks on the institutions of accountability.”
David J. Krieger, co-director of the Institute for Communication & Leadership in Lucerne, Switzerland, wrote, “The affordances of digital technologies bind people into information networks such that the network becomes the actor and intelligence as well as agency are qualities of the network as a whole and not any individual actors, whether human or non-human. Networks will have access to much more information than do any present-day actors and therefore be able to navigate complex environments, e.g., self-driving cars, personal assistants, smart cities. Typically, we will consult and cooperate with networks in all areas, but the price will be that we have no such thing as privacy. Privacy is indeed dead, but in the place of personal privacy management there will be network publicy governance [‘publicy’ is the opposite of privacy]. To ensure the use of these technologies for good instead of evil it will be necessary to dismantle and replace current divides between government and governed, workers and capitalists as well as to establish a working global governance.”
Wendy M. Grossman, author of “net.wars” and technology blogger, wrote, “2030 is 12 years from now. I believe human-machine AI collaboration will be successful in many areas, but that we will be seeing, like we are now over Facebook and other social media, serious questions about ownership and who benefits. It seems likely that the limits of what machines can do will be somewhat clearer than they are now, when we’re awash in hype. We will know by then, for example, how successful self-driving cars are going to be, and the problems inherent in handing off control from humans to machines in a variety of areas will also have become clearer. The big fight is to keep people from relying on experimental systems and turning off the legacy ones too soon – which is our current situation with the internet.”
Karl M. van Meter, founding editor of the Bulletin of Sociological Methodology and author of “Computational Social Science in the Age of Big Data,” said, “The well-being of the world’s population depends on governments making ‘intelligent’ decisions based on AI or other means. Moreover, environmental change may well be the determining factor for future well-being, with or without ‘intelligent’ decisions by world governments.”
Andrew Whinston, computer science professor and director of the Center for Research in Electronic Commerce at the University of Texas at Austin, said, “There are several issues. First, security problems do not get the attention needed. Secondly, there may be use of the technology to control the population – as we see developing in China. AI methodology is focused on prediction, at least so far, so methods to improve health or general welfare are lacking. Deep learning, which is getting the big hype, does not have a clear foundation. That makes it scientifically weak.”
An information administration manager responded, “We cede more and more decision-making and policy making to self-interested parties in the private sphere. Our institutions are insufficiently nimble to keep up with the policy questions that arise and attempts to regulate new industries are subverted by corrupt money politics at both the federal and state levels.”
An internet pioneer said, “Nothing in our current social, economic or political structures points to a positive outcome. There is no evidence that more AI will improve the lives of most people. In fact, the opposite is likely to be the case. There will be more unemployment, less privacy, etc.”
The following one-liners from anonymous respondents also tie into human agency:

An Internet Hall of Fame member commented, “AI will not leave most people better off than they are today because individuals will not be able to control their lives.”
A professor of AI at a university in Italy said, “Development has brought humanity past the boundary, the survival limit; it is too easy to control technology in ways that are dangerous for people.”
An assistant professor of social justice wrote, “Technology magnifies what exists (for good or bad). There is simply more bad than good to be magnified.”
A professor of digital humanities at a Silicon-Valley-area university said, “Given increasing income disparity in much of the world, my fear is that AI will be used to repress the disenfranchised and create even more privilege for the few.”
A distinguished engineer and chief scientist at major technology companies commented, “Large actors will use AI for their benefit. Individual customers may have some benefits as a side effect, at a cost of lower autonomy.”
A professor of electrical engineering and innovation based in Europe said, “People will lose control of their lives, which will remain in the hands of a small group of experts or companies.”
A respondent based in Turkey wrote, “Due to unknown logic of algorithms we will lose our autonomy over our lives and everyday life decisions; humankind is depending on AI and not learning to be algorithmically literate.”
An engineer and chief operating officer said, “AI will be used to suppress rights.”
A technology fellow for a global organization commented, “I fear that AI will control many background choices with great implicating effects.”

Other anonymous respondents commented:

“More will be delegated to technology – smartphones, software. People will stop thinking or caring about ‘control’ and just delegate everything to ‘the system.’”
“You can deploy most any technology in ways that enhance freedom [and] autonomy [or] have the opposite effect.”
“With China aiming to ‘win’ the AI lead, I have serious doubts that any benefits will outweigh the negative effects on human rights for a majority of people.”
“AI is not intelligent, it is human-made, and therefore biased and unreliable, it cannot do now what it is claimed it can do.”
“Provided we are still locked in capitalism I do not see how technology will help people stay engaged and empowered in our society.”
“My fear is that AI will be developed too quickly and that there may be severe repercussions once the genie is out of the bottle.”

Surveillance and data systems designed primarily for efficiency, profit and control are inherently dangerous
Who decides what about people’s code-defined lives, when, where, why and how? Many of these respondents cited concerns that the future of AI will be shaped by those driven by profit motives and power thirst. They note that many AI tools rely on individuals’ sharing of information, preferences, search strategies and data. Human values and ethics are not necessarily baked into the systems making peoples’ decisions for them. These experts worry that data-based decision-making can be prone to errors, biases, and false logic or mistaken assumptions. And these experts argue that machine-based decisions often favor “efficiencies” in the name of profit or power that are extremely unfavorable to individuals and the betterment of the human condition.
Michael Kleeman, a senior fellow at the University of California, San Diego and board member at the Institute for the Future, wrote, “The utilization of AI will be disproportionate and biased toward those with more resources. In general, it will reduce autonomy, and, coupled with big data, it will reduce privacy and increase social control. There will be some areas where IA [intelligence augmentation] helps make things easier and safer, but by and large it will be a global net negative.”
A professor at a major U.S. university and expert in artificial intelligence as applied to social computingsaid, “As AI systems take in more data and make bigger decisions, people will be increasingly subject to their unaccountable decisions and non-auditable surveillance practices. The trends around democratic governance of AI are not encouraging. The big players are U.S.-based, and the U.S. is in an anti-regulation stance that seems fairly durable. Therefore, I expect AI technologies to evolve in ways that benefit corporate interests, with little possibility of meaningful public response.”
Justin Reich, executive director of MIT Teaching Systems Lab and research scientist in the MIT Office of Digital Learning, responded, “Systems for human-AI collaborations will be built by powerful, affluent people to solve the problems of powerful, affluent people. In the hands of autocratic leaders, AI will become a powerful tool of surveillance and control. In capitalist economies, human-AI collaboration will be deployed to find new, powerful ways of surveilling and controlling workers for the benefit of more-affluent consumers.”
Seth Finkelstein, consulting programmer at Finkelstein Consulting and EFF Pioneer Award winner, commented, “AI depends on algorithms and data. Who gets to code the algorithms and to challenge the results? Is the data owned as private property, and who can change it? As a very simple example, let’s take the topic of algorithmic recommendations for articles to read. Do they get tuned to produce suggestions which lead to more informative material – which, granted, is a relatively difficult task, and fraught with delicate determinations? Or are they optimized for ATTENTION! CLICKS! *OUTRAGE*!? To be sure, the latter is cheap and easy – and though it has its own share of political problems, they’re often more amenable to corporate management (i.e., what’s accurate vs. what’s unacceptable). There’s a whole structure of incentives that will push toward one outcome or the other.”
Douglas Rushkoff, professor of media at City University of New York, responded, “The main reason I believe AI’s impact will be mostly negative is that we will be applying it mostly toward the needs of the market, rather than the needs of human beings. So while AI might get increasingly good at extracting value from people, or manipulating people’s behavior toward more consumption and compliance, much less attention will likely be given to how AI can actually create value for people. Even the most beneficial AI is still being measured in terms of its ability to provide utility, value or increase in efficiency – fine values, sure, but not the only ones that matter to quality of life.”
Annalie Killian, futurist and vice president for strategic partnerships at Sparks & Honey, wrote, “More technology does not make us more human; we have evidence for that now within 10 years of combining the smartphone device with persuasive and addictive designs that shape and hijack behavior. Technologists who are using emotional analytics, image-modification technologies and other hacks of our senses are destroying the fragile fabric of trust and truth that is holding our society together at a rate much faster than we are adapting and compensating – let alone comprehending what is happening. The sophisticated tech is affordable and investible in the hands of very few people who are enriching themselves and growing their power exponentially, and these actors are NOT acting in the best interest of all people.”
Collin Baker, senior AI researcher at the International Computer Science Institute at the University of California, Berkeley, commented, “I fear that advances in AI will be turned largely to the service of nation states and mega-corporations, rather than be used for truly constructive purposes. The positive potential, particularly in education and health care, is enormous, but people will have to fight to make it come about. … I hope that AI will get much better at understanding Gricean maxims for cooperative discourse and at understanding people’s beliefs, intentions and plans.”
Brian Harvey, lecturer on the social implications of computer technology at the University of California, Berkeley, said, “The question makes incorrect presuppositions, encapsulated in the word ‘we.’ There is no we; there are the owners and the workers. The owners (the 0.1%) will be better off because of AI. The workers (bottom 95%) will be worse off, as long as there are owners to own the AI, same as for any piece of technology.”
One of the world’s foremost social scientists studying human-technology interactions said, “My chief fear is face-recognition used for social control. Even Microsoft has begged for government regulation! Surveillance of all kinds is the future for AI. It is not benign if not controlled!”
Devin Fidler, futurist and founder of Rethinkery Labs commented, “If earlier industrialization is any guide, we may be moving into a period of intensified creative destruction as AI technologies become powerful enough to overturn the established institutions and the ordering systems of modern societies. If the holes punched in macro-scale organizational systems are not explicitly addressed and repaired, there will be increased pressures on everyday people as they face not only the problems of navigating an unfamiliar new technology landscape themselves, but also the systemic failure of institutions they rely on that have failed to adapt.”
An anonymous respondent said, “My fear is that technology will further separate us from what makes us human and sensitive to others. My hope is that technology would be used to improve the quality of living, not supplant it. Much of the AI innovation is simply clogging our senses, stealing our time, increasing the channels and invasion of adverts. This has destroyed our phones, filled our mailboxes and crowded our email. No product is worth that level of incursion.”
Paola Perez, vice president of the Internet Society’s Venezuela chapter and chair of the LACNIC Public Policy Forum, responded, “Humans will be better with AI. Many problems will be solved, but many jobs are going to disappear, and there may be more poor people as a result. Will we see life extension? Maybe, and maybe not, because our dependence on technology may also be destructive to our health.”
Eliot Lear, principal engineer at Cisco Systems, predicted, “AI and tech will not leave most people better off than they are today. As always, technology outpaces our ability to understand its ramifications so as to properly govern its use. I have no reason to believe that we will have caught up by 2030.”
Olivia Coombe, a respondent who provided no identifying details, wrote, “Children learn from their parents. As AI systems become more complex and are given increasingly important roles in the functioning of day-to-day life, we should ask ourselves what are we teaching our artificial digital children? If we conceive and raise them in a world of individual self-interest, will they just strengthen these existing, and often oppressive, systems of capitalist competition? Or could they go their own way, aspiring to a life of entrepreneurship to collaboration? Worse yet, will they see the reverence we hold for empires and seek to build their own through conquest?”
Peter Asaro, a professor at The New School and philosopher of science, technology and media who examines artificial intelligence and robotics, commented, “AI will produce many advantages for many people, but it will also exacerbate many forms of inequality in society. It is likely to benefit a small group who design and control the technology greatly, benefit a fairly larger group of the already well-off in many ways, but also potentially harm them in other ways, and for the vast majority of people in the world it will offer few visible benefits and be perceived primarily as a tool of the wealthy and powerful to enhance their wealth and power.”
Mark Deuze, a professor of media studies at the University of Amsterdam, wrote, “With the advances in AI and tech, the public debate grows over their impact. It is this debate that will contribute to the ethical and moral dimensions of AI, hopefully inspiring a society-wide discussion on what we want from tech and how we will take responsibility for that desire.”
Rob Frieden, professor and Pioneers Chair in Telecommunications and Law at Penn State University, said, “Any intelligent system depends on the code written to support it. If the code is flawed, the end product reflects those flaws. An old-school acronym spells this out: GIGO, Garbage In, Garbage Out. I have little confidence that AI can incorporate any and every real-world scenario, even with likely developments in machine learning. As AI expands in scope and reach, defects will have ever increasing impacts, largely on the negative side of the ledger.”
Anthony Judge, author, futurist, editor of the Encyclopedia of World Problems and Human Potential, and former head of the Union of International Associations, said, “AI will offer greater possibilities. My sense is that it will empower many (most probably 1% to 30%) and will disempower many (if not 99%). Especially problematic will be the level of complexity created for the less competent (notably the elderly) as is evident with taxation and banking systems – issues to which sysadmins are indifferent. For some it will be a boon – proactive companions (whether for quality dialogue or sex). Sysadmins will build in unfortunate biases. Missing will be the enabling of interdisciplinarity – as has long been possible but carefully designed out for the most dubious divide-and-rule reasons. Blinkered approaches and blind spots will set the scene for unexpected disasters – currently deniably incomprehensible (Black Swan effect). Advantages for governance will be questionable. Better oversight will be dubiously enabled.”
Stephanie Perrin, president of Digital Discretion, a data-privacy consulting firm, wrote, “There is a likelihood that, given the human tendency to identify risk when looking at the unknown future, AI will be used to attempt to predict risk. In other words, more and deeper surveillance will be used to determine who is a good citizen (purchaser, employee, student, etc.) and who [is] bad. This will find itself into public-space surveillance systems, employee-vetting systems (note the current court case where LinkedIn is suing data scrapers who offer to predict ‘flight risk’ employees), and all kinds of home-management systems and intelligent cars. While this might possibly introduce a measure of safety in some applications, the impact of fear that comes with unconscious awareness of surveillance will have a severe impact on creativity and innovation. We need that creativity as we address massive problems in climate change and reversing environmental impacts, so I tend to be pessimistic about outcomes.”
Alistair Knott, an associate professor specializing in cognitive science and AI at the University of Otago in Dunedin, New Zealand, wrote “AI has the potential for both positive and negative impacts on society. [Negative impacts are rooted in] the current dominance of transnational companies (and tech companies in particular) in global politics. These companies are likely to appropriate the majority of advances in AI technology – and they are unlikely to spread the benefit of these advances throughout society. We are currently witnessing an extraordinary concentration of wealth in the hands of a tiny proportion of the world’s population. This is largely due to the mainstreaming of neoliberalism in the world’s dominant economies – but it is intensified by the massive success of tech companies, which achieve huge profits with relatively small workforces. The advance of AI technologies is just going to continue this trend, unless quite draconian political changes are effected that bring transnational companies under proper democratic control.”
Richard Forno, of the Center for Cybersecurity at the University of Maryland-Baltimore County, wrote, “AI is only as ‘smart’ and efficient as its human creators can make it. If AI in things like Facebook algorithms is causing this much trouble now, what does the future hold? The problem is less AI’s evolution and more about how humankind develops and uses it – that is where the real crisis in AI will turn out.”
Sam Punnett, research and strategy officer at TableRock Media, wrote, “The preponderance of AI-controlled systems are designed to take collected data and enable control advantage. Most of the organizations with the resources to develop these systems do so to enable advantages in commercial/financial transactions, manufacturing efficiency and surveillance. Self-regulation by industry has already been shown to fail (e.g., social media platforms and Wall Street). Government agencies are lagging in their will and understanding of the implications of the technology to effectively implement guidelines to curtail the impacts of unforeseen circumstances. As such, government participation will be reactive to the changes that the technology will bring. My greatest fear is a reliance on faulty algorithms that absolve responsibility while failing to account for exceptions.”
Luis Pereira, associate professor of electronics and nanotechnologies, Universidade NOVA de Lisboa, Portugal, responded, “I fear that more control and influence will be exerted on people, such as has started in China. There will be a greater wealth gap, benefits will not spread to all and a caste system will develop, unless a new social compact is put in place, which is unlikely. Widespread revolt is plausible.”
Stavros Tripakis, an associate professor of computer science at Aalto University in Finland and adjunct professor at the University of California, Berkeley, wrote, “‘1984,’ George Orwell, police state.”
A principal architect for a top-five technology company commented, “AI will enable vicious regimes to track citizens at all times. Mistaken identifications will put innocent people in jail and even execute them with no hope of appeal. In general, AI will only have a positive contribution in truly democratic states, which are dwindling in number.”
John Sniadowski, a director for a technology company, wrote, “As technology is currently instantiated it simply concentrates power into a smaller number of international corporations. That needs fixing for everyone to gain the best from AI.”
David Brake, senior lecturer in communications at the University of Bedfordshire, UK, said, “Like many colleagues I fear that AI will be framed as ‘neutral’ and ‘objective’ and thereby used as cover to make decisions that would be considered unfair if made by a human. If we do not act to properly regulate the use of AI we will not be able to interrogate the ways that AI decision-making is constructed or audit them to ensure their decisions are indeed fair. Decisions may also be made (even more than today) based on a vast array of collected data and if we are not careful we will be unable to control the flows of information about us used to make those decisions or to correct misunderstandings or errors which can follow us around indefinitely. Imagine being subject to repeated document checks as you travel around the country because you know a number of people who are undocumented immigrants and your movements therefore fit the profile of an illegal immigrant. And you are not sure whether to protest because you don’t know whether such protests could encourage an algorithm to put you into a ‘suspicious’ category which could get you harassed even more often.”
A longtime veteran of a pioneering internet company commented, “Profit motive and AI at scale nearly guarantee suffering for most people. It should be spiffy for the special people with wealth and power, though. Watching how machines are created to ensure addiction (to deliver ads) is a reminder that profit-driven exploitation always comes first. The push for driverless cars, too, is a push for increased profits.”
Joshua Loftus, assistant professor of information, operations and management sciences at New York University and co-author of “Counterfactual Fairness in Machine Learning,” commented, “How have new technologies shaped our lives in the past? It depends on the law, market structure and who wields political power. In the present era of extreme inequality and climate catastrophe, I expect technologies to be used by employers to make individual workers more isolated and contingent, by apps to make users more addicted on a second-by-second basis, and by governments for surveillance and increasingly strict border control.”
Eugene H. Spafford, internet pioneer and founder and executive director emeritus of the Center for Education and Research in Information Assurance and Security, commented, “Without active controls and limits, the primary adopters of AI systems will be governments and large corporations. Their use of it will be to dominate/control people, and this will not make our lives better.”
Michael Muller, a researcher in the AI interactions group for a global technology solutions provider, said it will leave some people better off and others not, writing, “For the wealthy and empowered, AI will help them with their daily lives – and it will probably help them to increase their wealth and power. For the rest of us, I anticipate that AI will help the wealthy and empowered people to surveil us, to manipulate us, and (in some cases) to control us or even imprison us. For those of us who do not have the skills to jump to the AI-related jobs, I think we will find employment scarce and without protections. In my view, AI will be a mixed and intersectional blessing at best.”
Estee Beck, assistant professor at the University of Texas at Arlington and author of “A Theory of Persuasive Computer Algorithms for Rhetorical Code Studies,” responded, “Tech design and policy affects our privacy in the United States so much so that most people do not think about the tracking of movements, behaviors and attitudes from smartphones, social media, search engines, ISPs [internet service providers] and even Internet of Things-enabled devices. Until tech designers and engineers build privacy into each design and policy decision for consumers, any advances with human-machine/AI collaboration will leave consumers with less security and privacy.”
Michael H. Goldhaber, an author, consultant and theoretical physicist who wrote early explorations on the digital attention economy, said, “For those without internet connection now, its expansion will probably be positive overall. For the rest we will see an increasing arms race between uses of control, destructive anarchism, racism, etc., and ad hoc, from-below efforts at promoting social and environmental good. Organizations and states will seek more control to block internal or external attacks of many sorts. The combined struggles will take up an increasing proportion of the world’s attention, efforts and so forth. I doubt that any very viable and democratic, egalitarian order will emerge over the next dozen years, and – even in a larger time frame – good outcomes are far from guaranteed.”
Dave Burstein, editor and publisher at Fast Net News, said, “There’s far too much second-rate AI that is making bad decisions based on inadequate statistical understanding. For example, a parole or sentencing AI probably would find a correlation between growing up in a single parent household and likelihood of committing another crime. Confounding variables, like the poverty of so many single mothers, need to be understood and dealt with. I believe it’s wrong for someone to be sent to jail longer because their father left. That kind of problem, confounding variables and the inadequacy of ‘preponderant’ data, is nearly ubiquitous in AI in practice.”
Ian Peter, pioneer internet activist and internet rights advocate, said, “Personal data accumulation is reaching a point where privacy and freedom from unwarranted surveillance are disappearing. In addition, the algorithms that control usage of such data are becoming more and more complex leading to inevitable distortions. Henry Kissinger may have not been far off the mark when he described artificial intelligence as leading to ‘The End of the Age of Enlightenment.’”
Michael Zimmer, associate professor and privacy and information ethics scholar at the University of Wisconsin, Milwaukee, commented, “I am increasingly concerned that AI-driven decision making will perpetuate existing societal biases and injustices, while obscuring these harms under the false belief such systems are ‘neutral.’”
Martin Shelton, a professional technologist, commented, “There are many kinds of artificial intelligence – some kinds reliant on preset rules to appear ‘smart,’ and some which respond to changing conditions in the world. But because AI can be used anywhere we can recognize patterns, the potential uses for artificial intelligence are pretty huge. The question is, how will it be used? … While these tools will become cheaper and more widespread, we can expect that – like smartphones or web connectivity – their uses will be primarily driven by commercial interests. We’re beginning to see the early signs of AI failing to make smart predictions in larger institutional contexts. If Amazon fails to correctly suggest the right product in the future, everything is fine. You bought a backpack once, and now Amazon thinks you want more backpacks, forever. It’ll be okay. But sometimes these decisions have enormous stakes. ProPublica documented how automated ‘risk-assessment’ software used in U.S. courtroom sentencing procedures is only slightly more accurate at predicting recidivism than the flip of a coin. Likewise, hospitals using IBM Watson to make predictions about cancer treatments find the software often gives advice that humans would not. To mitigate harm in high-stakes situations, we must critically interrogate how our assumptions about our data and the rules that we use to create our AI promote harm.”
Nigel Hickson, an expert on technology policy development for ICANN based in Brussels, responded, “I am optimistic that AI will evolve in a way that benefits society by improving processes and giving people more control over what they do. This will only happen though if the technologies are deployed in a way in which benefits all. My fear is that in non-democratic countries, AI will lessen freedom, choice and hope.”
Vian Bakir, a professor of political communication and journalism at Bangor University, responded, “I am pessimistic about the future in this scenario because of what has happened to date with AI and data surveillance. For instance, the recent furor over fake news/disinformation and the use of complex data analytics in the U.K.’s 2016 Brexit referendum and in the U.S. 2016 presidential election. To understand, influence and micro-target people in order to try get them to vote a certain way is deeply undemocratic. It shows that current political actors will exploit technology for personal/political gains, irrespective of wider social norms and electoral rules. There is no evidence that current bad practices would not be replicated in the future, especially as each new wave of technological progress outstrips regulators’ ability to keep up, and people’s ability to comprehend what is happening to them and their data. Furthermore, and related, the capabilities of mass dataveillance in private and public spaces is ever-expanding, and their uptake in states with weak civil society organs and minimal privacy regulation is troubling. In short, dominant global technology platforms show no signs of sacrificing their business models that depend on hoovering up ever more quantities of data on people’s lives then hyper-targeting them with commercial messages; and across the world, political actors and state security and intelligence agencies then also make use of such data acquisitions, frequently circumventing privacy safeguards or legal constraints.”
Tom Slee, senior product manager at SAP SE and author of “What’s Yours is Mine: Against the Sharing Economy,” wrote, “Many aspects of life will be made easier and more efficient by AI. But moving a decision such as health care or workplace performance to AI turns it into a data-driven decision driven by optimization of some function, which in turn demands more data. Adopting AI-driven insurance ratings, for example, demands more and more lifestyle data from the insured if it is to produce accurate overall ratings. Optimized data-driven decisions about our lives unavoidably require surveillance, and once our lifestyle choices become input for such decisions we lose individual autonomy. In some cases we can ignore this data collection, but we are in the early days of AI-driven decisions: By 2030 I fear the loss will be much greater. I do hope I am wrong.”
Timothy Graham, a postdoctoral research fellow in sociology and computer science at Australian National University, commented, “There is already an explosion of research into ‘fairness and representation’ in ML (and conferences such as Fairness, Accountability and Transparency in Machine Learning), as it is difficult to engineer systems that do not simply reproduce existing social inequality, disadvantage and prejudice. Deploying such systems uncritically will only result in an aggregately worse situation for many individuals, whilst a comparatively small number benefit.”
A senior researcher and programmer for a major global think tank commented, “I expect AI to be embedded in systems, tools, etc., to make them more useful. However, I am concerned that AI’s role in decision-making will lead to more-brittle processes where exceptions are more difficult than today – this is not a good thing.”
Jenni Mechem, a respondent who provided no identifying details, said, “My two primary reasons for saying that advances in AI will not benefit most people by 2030 are, first, there will continue to be tremendous inequities in who benefits from these advances, and second, if the development of AI is controlled by for-profit entities there will be tremendous hidden costs and people will yield control over vast areas of their lives without realizing it. … The examples of Facebook as a faux community commons bent on extracting data from its users and of pervasive internet censoring in China should teach us that neither for-profit corporations nor government can be trusted to guide technology in a manner that truly benefits everyone. Democratic governments that enforce intelligent regulations as the European Union has done on privacy may offer the best hope.”
Suso Baleato, a fellow at Harvard University’s Institute of Quantitative Social Science and liaison for the Organization for Economic Cooperation and Development (OECD)’s Committee on Digital Economy Policy, commented, “The intellectual property framework impedes the necessary accountability of the underlying algorithms, and the lack of efficient redistributive economic policies will continue amplifying the bias of the datasets.”
Sasha Costanza-Chock, associate professor of civic media at MIT, said, “Unfortunately it is most likely that AI will be deployed in ways that deepen existing structural inequality along lines of race, class, gender, ability and so on. A small portion of humanity will benefit greatly from AI, while the vast majority will experience AI through constraints on life chances. Although it’s possible for us to design AI systems to advance social justice, our current trajectory will reinforce historic and structural inequality.”
Dalsie Green Baniala, CEO and regulator of the Telecommunications and Radiocommunications Regulator of Vanuatu, wrote, “Often, machine decisions do not produce an accurate result, they do not meet expectations or specific needs. For example, applications are usually invented to target the developed-world market. They may not work appropriately for countries like ours – small islands separated by big waters.”
Michiel Leenaars, director of strategy at NLnet Foundation and director of the Internet Society’s Netherlands chapter, responded, “Achieving trust is not the real issue; achieving trustworthiness and real empowerment of the individual is. As the technology that to a large extent determines the informational self disappears – or in practical terms is placed out of local control, going ‘underground’ under the perfect pretext of needing networked AI – the balance between societal well-being and human potential on the one hand and corporate ethics and opportunistic business decisions on the other stands to be disrupted. Following the typical winner-takes-all scenario the internet is known to produce, I expect that different realms of the internet will become even less transparent and more manipulative. For the vast majority of people (especially in non-democracies) there already is little real choice but to move and push along with the masses.”
Mike O’Connor, a retired technologist who worked at ICANN and on national broadband issues, commented, “I’m feeling ‘internet-pioneer regret’ about the Internet of S*** that is emerging from the work we’ve done over the last few decades. I actively work to reduce my dependence on internet-connected devices and the amount of data that is collected about me and my family. I will most certainly work equally hard to avoid human/AI devices/connections. I earnestly hope that I’m resoundingly proven wrong in this view when 2030 arrives.”
Luke Stark, a fellow in the department of sociology at Dartmouth College and at Harvard University’s Berkman Klein Center for Internet & Society, wrote, “AI technologies run the risk of providing a comprehensive infrastructure for corporate and state surveillance more granular and all-encompassing than any previous such regime in human history.”
Zoetanya Sujon, a senior lecturer specializing in digital culture at the University of the Arts London, commented, “Like the history of so many technologies show us, AI will not be the magic solution to the world’s problems or to symbolic and economic inequalities. Instead, AI is most benefitting those with the most power.”
Larry Lannom, internet pioneer and vice president at the Corporation for National Research Initiatives (CNRI), said, “I am hopeful that networked human-machine interaction will improve the general quality of life. … My fear: Will all of the benefits of more-powerful artificial intelligence benefit the human race as a whole or simply the thin layer at the top of the social hierarchy that owns the new advanced technologies?”
A professor and researcher in AI based in Europe noted, “Using technological AI-based capabilities will give people the impression that they have more power and autonomy. However, those capabilities will be available in contexts already framed by powerful companies and states. No real freedom. For the good and for the bad.”
An anonymous respondent said, “In the area of health care alone there will be tremendous benefits for those who can afford medicine employing AI. But at the same time, there is an enormous potential for widening inequality and for abuse. We can see the tip of this iceberg now with health insurance companies today scooping up readily available, poorly protected third-party data that will be used to discriminate.”
A senior data analyst and systems specialist expert in complex networks responded, “Artificial intelligence software will implement the priorities of the entities that funded development of the software. In some cases, this will [be] a generic service sold to the general public (much as we now have route-planning software in GPS units), and this will provide a definite benefit to consumers. In other cases, software will operate to the benefit of a large company but to the detriment of consumers (for example, calculating a price for a product that will be the highest that a given customer is prepared to pay). In yet a third category, software will provide effective decision-making in areas ranging from medicine to engineering, but will do so at the cost of putting human beings out of work.”
A distinguished engineer at one of the world’s largest computing hardware companies commented, “Tech will continue to be integrated into our lives in a seamless way. My biggest concern is responsible gathering of information and its use. Information can be abused in many ways as we are seeing today.”
A digital rights activist commented, “AI is already (through racial recognition, in particular) technologically laundering longstanding and pervasive bias in the context of police surveillance. Without algorithmic transparency and transparency into training data, AIs can be bent to any purpose.”
The following one-liners from anonymous respondents also tie into this theme:

A longtime economist for a top global technology company predicted, “The decline of privacy and increase in surveillance.”
A journalist and leading internet activist wrote, “Computer AI will only be beneficial to its users if it is owned by humans, and not ‘economic AI’ (that is, corporations).”
A strategy consultant wrote, “The problem is one of access. AI will be used to consolidate power and benefits for those who are already wealthy and further surveil, disenfranchise and outright rob the remaining 99% of the world.”
A policy analyst for a major internet services provider said, “We just need to be careful about what data is being used and how.”
A professor of information science wrote, “Systems will be developed that do not protect people’s privacy and security.”
The founder of a technology research firm wrote, “Neoliberal systems function to privilege corporations over individual rights, thus AI will be used in ways to restrict, limit, categorize – and, yes, it will also have positive benefits.”
A professor of electrical and computer engineering based in Europe commented, “The problem lies in human nature. The most powerful will try to use AI and technology to increase their power and not to the benefit of society.”

Other anonymous respondents commented:

“The panopticon and invasion of all personal aspects of our lives is already complete.”
“AI will allow greater control by the organized forces of tyranny, greater exploitation by the organized forces of greed and open a Pandora’s box of a future that we as a species are not mature enough to deal with.”
“The combination of widespread device connectivity and various forms of AI will provide a more pleasant everyday experience but at the expense of an even further loss of privacy.”
“I have two fears 1) loss of privacy and 2) building a ‘brittle’ system that fails catastrophically.”
“AI strategic decisions with the most clout are made by corporations and they do not aim for human well-being in opposition to corporate profitability.”
“Data is too controlled by corporations and not individuals, and privacy is eroding as surveillance and stalking options have grown unchecked.”
“The capabilities are not shared equally, so the tendency will be toward surveillance by those with power to access the tools; verbal and visual are coming together with capacities to sort and focus the masses of data.”
“Knowing humanity, I assume particularly wealthy, white males will be better off, while the rest of humanity will suffer from it.”

Displacement of human jobs by AI will widen economic and digital divides, possibly leading to economic and social upheaval
One of the chief fears about today’s technological change is the possibility that autonomous hardware and software systems will cause millions of people globally to lose their jobs and, as a result, their means for affording life’s necessities and participating in society. Many of these experts say new jobs will emerge along with the growth of AI just as they have historically during nearly every human transition to new tools.
Brad Templeton, chair for computing at Singularity University, said, “While obviously there will be good and bad, the broad history of automation technologies is positive, even when it comes to jobs. There is more employment today than ever in history.”
Ben Shneiderman, distinguished professor and founder of the Human Computer Interaction Lab at the University of Maryland, said, “Automation is largely a positive force, which increases productivity, lowers costs and raises living standards. Automation expands the demand for services, thereby raising employment, which is what has happened at Amazon and FedEx. My position is contrary to those who believe that robots and artificial intelligence will lead to widespread unemployment. Over time I think AI/machine learning strategies will become merely tools embedded in ever-more-complex technologies for which human control and responsibility will become clearer.”
Robert D. Atkinson, president of the Information Technology and Innovation Foundation, wrote about how advances in AI are essential to expanded job opportunities: “The developed world faces an unprecedented productivity slowdown that promises to limit advances in living standards. AI has the potential to play an important role in boosting productivity and living standards.”
Toby Walsh, a professor of AI at the University of New South Wales in Australia and president of the AI Access Foundation, said, “I’m pessimistic in short term – we’re seeing already technologies like AI being used to make life worse for many – but I’m optimistic in long term that we’ll work out how to get machines to do the dirty, dull, dangerous and difficult, and leave us free to focus on all the more-important and human parts of our lives.”
Yet many others disagree. Some fear the collapse of the middle class and social and economic upheaval if most of the world’s economic power is held by a handful of technology behemoths that are reaping the great share of financial rewards in the digital age while employing far fewer people than the leading companies of the industrial age. A fairly large share of these experts warn that if steps are not taken now to adjust to this potential future that AI’s radical reduction in human work will be devastating.”
David Cake, an leader with Electronic Frontiers Australia and vice-chair of the ICANN Generic Names Supporting Organization Council, wrote, “The greatest fear is that the social disruption due to changing employment patterns will be handled poorly and lead to widespread social issues.”
Jerry Michalski, founder of the Relationship Economy eXpedition, said, “We’re far from tipping into a better social contract. In a more-just world, AI could bring about utopias. However, many forces are shoving us in the opposite direction. 1) Businesses are doing all they can to eliminate full-time employees, who get sick and cranky, need retirement accounts and raises, while software gets better and cheaper. The precariat will grow. 2) Software is like a flesh-eating bacterium: Tasks it eats vanish from the employment landscape. Unlike previous technological jumps, this one unemploys people more quickly than we can retrain and reemploy them. 3) Our safety net is terrible and our beliefs about human motivations suck. 4) Consumerism still drives desires and expectations.”
James Hendler, professor of computer, web and cognitive sciences and director of the Rensselaer Polytechnic Institute for Data Exploration and Application, wrote, “I believe 2030 will be a point in the middle of a turbulent time when AI is improving services for many people, but it will also be a time of great change in society based on changes in work patterns that are caused, to a great degree, by AI. On the one hand, for example, doctors will have access to information that is currently hard for them to retrieve rapidly, resulting in better medical care for those who have coverage, and indeed in some countries the first point of contact in a medical situation may be an AI, which will help with early diagnoses/prescriptions. On the other hand, over the course of a couple of generations, starting in the not-too-distant future we will see major shifts in work force with not just blue-collar jobs, but also many white-collar jobs lost. Many of these will not be people ‘replaced’ by AIs, but rather the result of a smaller number of people being able to accomplish the same amount of work – for example in professions such as law clerks, physicians assistants and many other currently skilled positions we would project a need for less people (even as demand grows).”
Betsy Williams, a researcher at the Center for Digital Society and Data Studies at the University of Arizona, wrote, “AI’s benefits will be unequally distributed across society. Few will reap meaningful benefits. Large entities will use AI to deliver marginal improvements in service to their clients, at the cost of requiring more data and risking errors. Employment trends from computerization will continue. AI will threaten medium-skill jobs. Instead of relying on human expertise and context knowledge, many tasks will be handled directly by clients using AI interfaces or by lower-skilled people in service jobs, boosted by AI. AI will harm some consumers. For instance, rich consumers will benefit from self-driving cars, while others must pay to retrofit existing cars to become more visible to the AI. Through legal maneuvering, self-driving car companies will avoid many insurance costs and risks, shifting them to human drivers, pedestrians and bicyclists. In education, creating high quality automated instruction requires expertise and money. Research on American K-12 classrooms suggests that typical computer-aided instruction yields better test scores than instruction by the worst teachers. By 2030, most AI used in education will be of middling quality (for some, their best alternative). The children of the rich and powerful will not have AI used on them at school; instead, they will be taught to use it. For AI to significantly benefit the majority, it must be deployed in emergency health care (where quicker lab work, reviews of medical histories or potential diagnoses can save lives) or in aid work (say, to coordinate shipping of expiring food or medicines from donors to recipients in need).”
Nathaniel Borenstein, chief scientist at Mimecast, wrote, “Social analyses of IT [information technology] trends have consistently wildly exaggerated the human benefits of that technology, and underestimated the negative effects. … I foresee a world in which IT and so-called AI produce an ever-increasing set of minor benefits, while simultaneously eroding human agency and privacy and supporting authoritarian forms of governance. I also see the potential for a much worse outcome in which the productivity gains produced by technology accrue almost entirely to a few, widening the gap between the rich and poor while failing to address the social ills related to privacy. But if we can find a way to ensure that these benefits are shared equally among the population, it might yet prove to be the case that the overall effect of the technology is beneficial to humanity. This will only happen, however, if we manage to limit the role of the rich in determining how the fruits of increased productivity will be allocated.”
Andrea Romaoli Garcia, an international lawyer active in internet governance discussions, commented, “AI will improve the way people make decisions in all industries because it allows instant access to a multitude of information. People will require training for this future – educational and technological development. … This is a very high level of human development that poor countries don’t have access to. Without proper education and policies, they will not have access to wealth. The result may be a multitude of hungry and desperate people. This may be motivation for wars or invasion of borders. Future human-machine interaction (AI) will only be positive if richer countries develop policies to help poorer countries to develop and gain access to work and wealth.”
Josh Calder, a partner at the Foresight Alliance, commented, “The biggest danger is that workers are displaced on a mass scale, especially in emerging markets.”
Jeff Johnson, computer science professor at the University of San Francisco, previously with Xerox, HP Labs and Sun Microsystems, responded, “I believe advances in AI will leave many more people without jobs, which will increase the socioeconomic differences in society, but other factors could help mitigate this, e.g., adoption of guaranteed income.”
Alan Bundy, a professor of automated reasoning at the University of Edinburgh, wrote, “Unskilled people will suffer because there will be little employment for them. This may create disruption to society, some of which we have already seen with Trump, Brexit, etc.”
Peter Levine, associate dean for research and professor of citizenship and public affairs in Tufts University’s Tisch College of Civic Life, wrote, “Being a fully-fledged citizen has traditionally depended on work. I’m worried that rising levels of non-employment will detract from civic engagement. Also, AI is politically powerful and empowers the people and governments that own it. Thus, it may increase inequality and enhance authoritarianism.”
Hassaan Idrees, an electrical engineer and Fulbright Scholar active in creating energy systems for global good, commented, “I believe human-machine interaction will be more of [a] utility, and less fanciful as science fiction puts it. People will not need to see their physicians in person, their automated doctors making this irrelevant. Similarly, routine workplace activities like data processing and financial number crunching would be performed by AI. Humans with higher levels of intellect can survive this age, and those on the lower ends of spectrum of mental acumen would be rendered unnecessary.”
Ethem Alpaydin, a professor of computer engineering at Bogazici University in Istanbul, responded, “As with other technologies, I imagine AI will favor the developed countries that actually develop these technologies. … For the developing countries, however, whose labor force is mostly unskilled and whose exports are largely low-tech, AI implies higher unemployment, lower income and more social unrest. The aim of AI in such countries should be to add skill to the labor force rather than supplant them.”
Sam Ladner, a former UX researcher for Amazon and Microsoft, now an adjunct professor at Ontario College of Art and Design, wrote, “Technology is not a neutral tool, but one that has our existing challenges imprinted onto it. Inequality is high and growing. Too many companies deny their employees a chance to work with dignity, whether it be through providing them meaningful things to do, or with the basic means to live. AI will be placed on top of that existing structure. Those who already have dignified work with a basic income will see that enhanced; those who are routinely infantilized or denied basic rights will see that amplified. Some may slip into that latter category because their work is more easily replaced by AI and machine learning.”
Jonathan Swerdloff, consultant and data systems specialist for Driven Inc., wrote, “The more reliant on AI we become, the more we are at the mercy of its developers. While AI has the ability to augment professionals and to make decisions, I have three concerns which make me believe it will not leave us better off by 2030. This does not address fears that anything run via AI could be hacked and changed by bad faith third parties. 1) Until any sort of self-policed AI sentience is achieved, it will suffer from a significant GIGO [garbage-in, garbage-out] problem. As AI as currently conceived only knows what it is taught, the seed sets for teaching must be thought out in detail before the tools are deployed. Based on the experience with Microsoft’s Tay and some responses I’ve heard from the Sophia robot, I am concerned that AI will magnify humanities flaws. 2) Disparate access. Unless the cost for developing AI drops precipitously – and it may, since one AI tool could be leveraged into building further less expensive AI tools – access to whatever advantages the tools will bring will likely be clustered among a few beneficiaries. I view this akin to high frequency trading on Wall Street. Those who can, do. Those who can’t, lose. 3) Tool of control. If AI is deployed to make civic or corporate decisions, those who control the algorithms control everything. In the U.S. we’ve recently seen Immigration and Customs Enforcement change its bond algorithm to always detain in every case.”
Stuart A. Umpleby, a professor and director of the research program in social and organizational learning at George Washington University, wrote, “People who use AI and the internet will have their lives enhanced by these technologies. People who do not use them will be increasingly disconnected from opportunities. As the digital world becomes more complicated and remote from real-world experiences, the need will grow for people and software to make connections. There will be a need for methods to distinguish the real world from the scam world.”
Simeon Yates, director of the Centre for Digital Humanities and Social Science at the University of Liverpool, said, “AI will simply increase existing inequalities – it, like the internet, will fail in its emancipatory promise.”
Panagiotis T. Metaxas, author of “Technology, Propaganda and the Limits of Human Intellect” and professor of computer science at Wellesley College, responded, “There will be a lot of wealth that AI-supported devices will be producing. The new technologies will make it easier and cheaper to produce food and entertainment massively (‘bread and circus’). This wealth will not be distributed evenly, increasing the financial gap between the top small percentage of people and the rest. Even though this wealth will not be distributed evenly, the (relatively small) share given to the vast majority of people will be enough to improve their (2018) condition. In this respect, the majority of people will be ‘better off’ than they are today. They may not feel better off if they were aware of the inequalities compared to the top beneficiaries, but they will not be aware of them due to controlled propaganda. Unfortunately, there will not be much they could do about the increased inequalities. Technologies of police enforcement by robots and lack of private communication will make it impossible for them to organize, complain or push for change. They will not be valued as workers, citizens or soldiers. The desire for democracy as we know it today will be coming to an end. Many will feel depressed, but medical products will make it easy for them to increase pleasure and decrease pain.”
Grace Mutung’u, co-leader of the Kenya ICT Action Network, responded, “New technologies will more likely increase current inequalities unless there is a shift in world economics. From the experience of the UN work on Millennium Development Goals, while there has been improvement with the quality of life generally, low- and middle-income countries still suffer disparate inequalities. This will likely lead to governance problems. In any case, governments in these countries are investing heavily in surveillance which will likely have more negative effects on society.”
Danny Gillane, a netizen from Lafayette, Louisiana, commented, “Technology promises so much but delivers so little. Facebook gave us the ability to stay in touch with everyone but sacrificed its integrity and our personal information in pursuit of the dollar. The promise that our medical records would be digitized and more easily shared and drive costs down still has not materialized on a global scale. The chief drivers of AI innovation and application will be for-profit companies who have shown that their altruism only extends to their bottom lines. Like most innovations, I expect AI to leave our poor even poorer and our rich even richer, increasing the numbers of the former while consolidating power and wealth in an ever-shrinking group of currently rich people.”
A professional working on the setting of web standards wrote, “Looking ahead 12 years from now, I expect that AI will be enhancing the quality of life for some parts of some populations, and in some situations, while worsening the quality of life for others. AI will still be uneven in quality, and unevenly available throughout different parts of society. Privacy and security protections will be inadequate; data bias will still be common; many technologies and response patterns will be normed to the needs of the ‘common denominator’ user and misidentify or misinterpret interactions with people with disabilities or, if appropriately identifying their disability, will expose that information without user consent or control.”
So many people included comments and concerns about the future of jobs for humans in their wide-ranging responses to this canvassing that a later section of this report has more expert opinions on this topic.
The following one-liners from anonymous respondents also tie into AI and jobs:

An associate professor of computer science commented, “Machines will be able to do more-advanced work and improve accuracy, but this likely will expand manipulation of consumers/voters and automation may reduce available jobs.”
A director for a global digital rights organization said, “My concern is that human-machine collaboration will leave some of us far better off by automating our jobs, giving us more free and creative time, while doing little to improve the lives of billions of others.”
A professor expert in cultural geography and American studies said, “Given the majority human assumption that capitalism is something worth reproducing, the evacuation of most labor positions by AI would create vast poverty and cruelty by the ruling class.”
A lecturer in media studies based in New Zealand wrote, “The automation of large volumes of work by machine learning-based systems is unlikely to lead to an increase in social equity within a capitalist economy.”
A senior partner at one of the world’s foremost management consulting firms commented, “AI will benefit businesses, the economy and people as consumers, but likely increase income/wage polarization so most people as workers may not benefit.”
An engineer and chief operating officer for project automating code said, “Those with the most money will leverage their position of power through AI; it will lead to possibly cataclysmic wealth disparity.
A digital anthropologist for a major global technology company wrote, “The gap between those who benefit from advances in technology and those who do not have widened over the past three decades; I can’t see an easy or quick reversal.”

Other anonymous respondents commented:

“Some will benefit, while others will suffer. The bifurcated economy will continue to grow. … Those at the bottom of the ladder will see greater numbers of jobs being taken away by technology.”
“All in all, AI can be of great use, but we need to be vigilant of the repercussions instead of constantly leaping ‘forward’ only to find out later about all of the negatives.”
“In the U.S., the blue-collar job wages have been stagnant since the 1970s despite all of the advances with the internet and mobile devices, so I am not optimistic regarding AI.”
“Wealth distribution will continue to widen as the rich get richer.”
“AI is going to lead to the destruction of entire rungs of the economy, and the best way to boost and economy while holding together a fractured economy is war.”
“Many people will no longer be useful in the labor market. Such rapid economic and social change will leave many frightened and angry.”
“In 12 years AI may be more disruptive than enabling, leaving many without work until they retrain and transition.”
“There could be a thinning out of the middle – middle management and class.”
“AI will increasingly allow low-quality but passable substitutes for previously-skilled labor.”
“There are significant implications for unskilled or easily-automated tasks on one end of the spectrum and certain types of analysis on the other that will be automated away. My concern is that we have no plan for these people as these jobs disappear.”

Individuals’ cognitive, social and survival skills will be diminished as they become dependent on AI
While these experts expect AI to augment humans in many positive ways, some are concerned that a deepening dependence upon machine-intelligence networks will diminish crucial human capabilities. Some maintain there has already been an erosion of people’s abilities to think for themselves, to take action independent of automated systems and to interact effectively face-to-face with others.
Charles Ess, an expert in ethics and professor with the department of media and communication at the University of Oslo, said, “It seems quite clear that evolving AI systems will bring about an extraordinary array of options, making our lives more convenient. But convenience almost always comes at the cost of deskilling – of our offloading various cognitive practices and virtues to the machines and thereby our becoming less and less capable of exercising our own agency, autonomy and most especially our judgment (phronesis). In particular, empathy and loving itself are virtues that are difficult to acquire and enhance. My worst fears are not only severe degradation, perhaps more or less loss of such capacities – and, worst of all, our forgetting they even existed in the first place, along with the worlds they have made possible for us over most of our evolutionary and social history.”
Daniel Siewiorek, a professor with the Human-Computer Interaction Institute at Carnegie Mellon University, predicted, “The downside: isolating people, decreasing diversity, a loss of situational awareness (witness GPS directional systems) and ‘losing the receipt’ of how to do things. In the latter case, as we layer new capabilities on older technologies if we forget how the older technology works we cannot fix it and layered systems may collapse, thrusting us back into a more-primitive time.”
Marilyn Cade, longtime global internet policy consultant, responded, “Technology often reflects the ethics of its creators, but more significantly, those who commercialize it. Most individuals focus on how they personally use technology. They do not spend time (or even have the skills/expertise) to make judgments about the attributes of the way that technology is applied. … We must introduce and maintain a focus on critical thinking for our children/youth, so that they are capable of understanding the implications of a different fully digitized world. I love the fact that my typos are autocorrected, but I know how to spell all the words. I know how to construct a logical argument. If we don’t teach critical thinking at all points in education, we will have a 2030 world where the elites/scientists make decisions that are not even apparent to the average ‘person’ on the street/neighborhood.”
Garland McCoy, founder and chief development officer of the Technology Education Institute, wrote, “I am an optimist at heart and so believe that, given a decade-plus, the horror that is unfolding before our eyes will somehow be understood and resolved. That said, if the suicide epidemic we are witnessing continues to build and women continue to opt out of motherhood all bets are off. I do think technology is at the core of both the pathology and choice.”
Aneesh Aneesh, professor at the University of Wisconsin, Milwaukee, said, “Socially, AI systems will automate tasks that currently require human negotiation and interaction. Unless people feel the pressure, institutionally or otherwise, to interact with each other, they – more often than not – choose not to interact. The lack of physical, embodied interaction is almost guaranteed to result in social loneliness and anomie, and associated problems such as suicide, a phenomenon already are on the rise in the United States.”
Ebenezer Baldwin Bowles, author, editor and journalist, responded, “If one values community and the primacy of face-to-face, eye-to-eye communication, then human-machine/AI collaboration in 2030 will have succeeded in greatly diminishing the visceral, primal aspects of humanity. Every expression of daily life, either civil or professional or familial or personal, will be diminished by the iron grip of AI on the fundamental realities of interpersonal communications. Already the reliance on voice-to-text technology via smartphone interface diminishes the ability of people to write with skill and cogency. Taking the time to ring-up another and chat requires too much psychic energy, so we ‘speak’ to one another in text box fragments written down and oft altered by digital assistants. The dismissive but socially acceptable ‘TL;DR’ becomes commonplace as our collective attention span disintegrates. Yes, diagnostic medicine and assembly-line production and expanded educational curriculum will surely be enhanced by cyber-based, one-and-zero technologies, but at what cost to humanity? Is it truly easier and safer to look into a screen and listen to an electronically delivered voice, far away on the other side of an unfathomable digital divide, instead of looking into another’s eyes, perhaps into a soul, and speaking kind words to one another, and perhaps singing in unison about the wonders of the universe? We call it ‘artificial intelligence’ for good reason.”
A principal design researcher at one of the world’s largest technology companies commented, “Although I have long worked in this area and been an optimist, I now fear that the goal of most AI and UX is geared toward pushing people to interact more with devices and less with other people. As a social species that is built to live in communities, reductions in social interaction will lead to erosion of community and rise in stress and depression over time. Although AI has the potential to improve lives as well, those advances will come more slowly than proponents think, due to the ‘complexity brake’ Paul Allen wrote about, among other things. There have been AI summers and AI winters. This is not an endless summer.”
A chief operating officer wrote, “No doubt in my mind, AI is and will continue to present benefits in simplifying and aiding human activities; however, the net effect is not likely ‘to leave people better off.’ The advances in AI-enabled tools are likely to expand the digital gap in human competencies. This growing gap will decrease the capacity of sizable portions of the population to survive an outage of the technology. This raises humanitarian and national-security concerns.”
Dalsie Green Baniala, CEO and regulator of the Telecommunications and Radiocommunications Regulator of Vanuatu, wrote, “With the introduction of the Internet of Things, human senses are in decline.”
Alper Dincel of T.C. Istanbul Kultur University in Turkey, wrote, “Personal connections will continue to drop, as they are in today’s world. We are going to have more interest in fiction than in reality. These issues will affect human brain development as a result.”
Michael Dyer, an emeritus professor of computer science at the University of California, Los Angeles, commented, “As long as GAI (general AI) is not achieved then specialized AI will eliminate tasks associated with jobs but not the jobs themselves. A trucker does a lot more than merely drive a truck. A bartender does a lot more than merely pour drinks. Society will still have to deal with the effects of smart technologies encroaching ever into new parts of the labor market. A universal basic income could mitigate increasing social instability. Later on, as general AI spreads, it will become an existential threat to humanity. My estimate is that this existential threat will not begin to arise until the second half of the 21st century. Unfortunately, by then humanity might have grown complacent, since specialized AI systems do not pose an existential threat.”
Mauro D. Ríos, an adviser to the E-Government Agency of Uruguay and director of the Internet Society’s Uruguay chapter, responded, “In 2030 dependence on AI will be greater in all domestic, personal, work and educational contexts; this will make the lives of many people better. However, it has risks. We must be able to maintain active survival capabilities without AI. Human freedom cannot be lost in exchange for the convenience of improving our living standards. … AI must continue to be subject to the rationality and control of the human being.”
Nancy Greenwald, a respondent who provided no identifying details, wrote, “Perhaps the primary downside is overreliance on AI, which 1) is only as good as the algorithms created (how are they instructed to ‘learn?’) and 2) has the danger of limiting independent human thinking. How many Millennials can read a map or navigate without the step-by-step instructions from Waze, Google or their iPhones? And information searches online don’t give you an overview. I once wasted 1.5 billable hours searching for a legal concept when two minutes with the human based BNA outline got me the result in two minutes. Let’s be thoughtful about how we use the amazing technology.”
Valarie Bell, a computational social scientist at the University of North Texas, commented, “As a social scientist I’m concerned that never before have we had more ways in which to communicate and yet we’ve never done it so poorly, so venomously and so wastefully. With devices replacing increasingly higher-order decisions and behaviors, people have become more detached, more disinterested and yet more self-focused and self-involved.”
Lane Jennings, managing editor for the World Future Review from 2009 to 2015, wrote, “It is most likely that advances in AI will improve technology and thus give people new capabilities. But this ‘progress’ will also make humanity increasingly vulnerable to accidental breakdowns, power failures and deliberate attacks. Example: Driverless cars and trucks and pilotless passenger aircraft will enhance speed and safety when they work properly, but they will leave people helpless if they fail. Fear and uncertainty could negate positive benefits after even a few highly publicized disasters.”
Michael Veale, co-author of “Fairness and Accountability Designs Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making” and a technology policy researcher at University College London, responded, “AI technologies will turn out to be more narrowly applicable than some hope. There will be a range of small tasks that will be more effectively automated. Whether these tasks leave individuals with increased ability to find meaning or support in life is debatable. Freed from some aspects of housework and administration, some individuals may feel empowered whereas others might feel aimless. Independent living for the elderly might be technologically mediated, but will it have the social connections and community that makes life worth living? Jobs too will change in nature, but it is not clear that new tasks will make people happy. It is important that all technologies and applications are backed up with social policies and systems to support meaning and connection, or else even effective AI tools might be isolating and even damaging on aggregate.”
The following one-liners from anonymous respondents also tie into this theme:

A British-American computer scientist commented, “Increasing dependence on AI will decrease societal resilience through centralization of essential systems in a few large companies.”
A leading infrastructure engineer for a social network company commented, “AI may make people’s lives better by making some things easier, but it will likely reduce human value along the way – I expect people to be less able to make decisions, less able to tolerate human interaction, etc.”
A representative for a nation-state’s directorate of telecommunications wrote, “My fear is that humans will become more and more dependent on AI, to the extent that their natural intelligence would be more and more diminished. The concern is that in the absence of AI they may not be able to act in a timely manner.”

Other anonymous respondents commented:

“We need to assure that we have individuals who are able to think and problem-solve and monitor that thinking without assistance.”
“Our ethical capabilities lag far behind our technical capabilities.”
“Increasing dependence on AI will decrease societal resilience through centralization of essential systems in a few large companies.”
“Lack of education in AI and inclusiveness of individual in their own decision-making will make most people worse off in 2030.”
“Few people will understand what the AI is attempting to do and how it’s doing it; regular people without this knowledge will become more like sheep.”
“I have concerns about how people are adapting to these new changes, the continuing disconnection people have due to advances in AI, substituting AI connections for real people, leading to greater depression.”
“My fear is that we will spend even more time with machines than we do with talking with each other.”
“My fear is that the increasing ‘datafication’ of work and our lives as a whole will further increase the pressure we feel to reach an unrealistic apex of perfection.”
“As one is more and more people have AI/automation support in their daily lives the interactions between people will lessen. People may feel more isolated and less socially interrelated. Social interaction must be carefully maintained and evolved.”

Citizens will face increased vulnerabilities, such as exposure to cybercrime and cyberwarfare and the endangerment of essential organizations by weaponized information
Some of these experts are particularly worried about how networked artificial intelligence can amplify cybercrime, create fearsome possibilities in cyberwarfare or enable the erosion of essential institutions and organizations.
Anthony Nadler, assistant professor of media and communication studies at Ursinus College, commented, “The question has to do with how decisions will be made that shape the contingent development of this potentially life-changing technology. And who will make those decisions? In the best-case scenario, the development of AI will be influenced by diverse stakeholders representing different communities who will be affected by its implementation (and this may) mean that particular uses of AI – military applications, medical, marketing, etc. – will be overseen by reflective ethical processes. In the absolute worst-case scenario, unrestricted military development will lead to utter destruction – whether in a situations in which the ‘machines take over’ or, more likely, in which weapons of tremendous destruction become all the more readily accessible.”
Jennifer J. Snow, an innovation officer with the U.S. Air Force, wrote, “Facets, including weaponized information, cyberbullying, privacy issues and other potential abuses that will come out of this technology will need to be addressed by global leaders.”
Lee McKnight, associate professor at Syracuse University’s School of Information Studies, commented, “There will be good, bad and ugly outcomes from human-machine interaction in artificially intelligent systems, services and enterprises. … Poorly designed artificially intelligent services and enterprises will have unintended societal consequences, hopefully not catastrophic, but sure to damage people and infrastructure. Even more regrettably, defending ourselves against evil – or to be polite, bad AI systems turned ugly by humans, or other machines – must become a priority for societies well before 2030, given the clear and present danger. How can I be sure? What are bots and malware doing every day, today? Is there a reason to think ‘evil-doers’ will be less motivated in the future? No. So my fear is that the hopefully sunny future of AI, which in aggregate we may assume will be a net positive for all of us, will be marred by – many – unfortunate events.”
Robert M. Mason, a professor emeritus at the University of Washington’s Information School, responded, “Technologies, including AI, leverage human efforts. People find ways to apply technologies to enhance the human spirit and the human experience, yet others can use technologies to exploit human fears and satisfy personal greed. As the late Fred Robbins, Nobel Laureate in Physiology/Medicine, observed (my paraphrase when I asked why he was pessimistic about the future of mankind): ‘Of course I’m pessimistic. Humans have had millions of years to develop physically and mentally, but we’ve had only a few thousand years – as the world population has expanded – to develop the social skills that would allow us to live close together.’ I understand his pessimism, and it takes only a few people to use AI (or any technology) in ways that result in widespread negative societal impacts.”
Frank Feather, futurist and consultant with StratEDGY, commented, “AI by 2030 …. This is only about a decade away, so despite AI’s continuing evolution, it will not have major widespread effects by 2030. With care in implementation all effects should be positive in social and economic impact. That said, the changes will represent a significant step toward what I call a DigiTransHuman Future, where the utility of humans will increasingly be diminished as this century progresses, to the extent that humans may become irrelevant or extinct, replaced by DigiTransHumans and their technologies/robots that will appear and behave just like today’s humans, except at very advanced stages of humanoid development. This is not going to be a so-called ‘singularity’ and there is nothing ‘artificial’ about the DigiTransHuman Intelligence. It is part of designed evolution of the species.”
John Leslie King, a computer science professor at the University of Michigan and a consultant for several years on cyberinfrastructure for the National Science Foundation’s directorates for Computer and Information Science and Engineering (CISE) and Social, Behavioral, and Economic (SBE) sciences, commented, “If there are evil things to be done with AI, people will find out about them and do them. There will be an ongoing fight like the one between hackers and IT security people.”
John Markoff, fellow at the Center for Advanced Study in Behavioral Sciences at Stanford University and author of “Machines of Loving Grace: The Quest for Common Ground Between Humans and Robots,” wrote, “There are expected and unexpected consequences to ‘AI and related technologies.’ It is quite possible that improvements in living standards will be offset by the use of autonomous weapons in new kinds of war.”
A veteran of a pioneering internet company commented, “In the face of managing resources and warfare – the big issues for AI at scale – the goals are not likely to be sharing and co-existence.”
Dan Schultz, senior creative technologist at Internet Archive, responded, “AI will no doubt result in life-saving improvements for a huge portion of the world’s population, but it will also be possible to weaponize in ways that further exacerbate divides of any kind you can imagine (political, economic, education, privilege, etc.). AI will amplify and enable the will of those in power; its net impact on humanity will depend on the nature of that will.”
Sam Gregory, director of WITNESS and digital human rights activist, responded, “Trends in AI suggest it will enable more individualized, personalized creation of synthetic media filter bubbles around people, including the use of deepfakes and related individualized synthetic audio and video micro-targeting based on personal data and trends in using AI-generated and directed bots. These factors may be controlled by increasing legislation and platform supervision, but by 2030 there is little reason to think that most peoples’ individual autonomy and ability to push back to understand the world around them will have improved.”
Miguel Moreno-Muñoz, a professor of philosophy specializing in ethics, epistemology and technology at the University of Granada in Spain, said, “There is a risk of overreliance on systems with poorly experienced intelligence augmentation due to pressure to reduce costs. This could lead to major dysfunctions in health care or in the supervision of highly complex processes. A hasty application of management systems based on the Internet of Things could be problematic in certain sectors of industry, transport or health, but its advantages will outweigh its disadvantages. I do believe there may be significant risks in the military applications of AI.”
Denise N. Rall, a professor of arts and social sciences at Southern Cross University in Australia, responded, “The basic problem with the human race and its continued existence on this planet is overpopulation and depletion of the Earth’s resources. So far, interactions with technology have reduced population in the ‘first world’ but not in developing countries, and poverty will fuel world wars. Technology may support robotic wars and reduce casualties for the wealthy countries. The disparity between rich and poor will continue unabated.”
Patrick Lambe, a partner at Straits Knowledge and president of the International Society for Knowledge Organization’s Singapore chapter, wrote, “I chose the negative answer not because of a dystopian vision for AI itself and technology interaction with human life, but because I believe social, economic and political contexts will be slow to adapt to technology’s capabilities. The real-world environment and the technological capability space are becoming increasingly disjointed and out of synch. Climate change, migration pressures, political pressures, food supply and water will create a self-reinforcing ‘crisis-loop’ with which human-machine/AI capabilities will be largely out of touch. There will be some capability enhancement (e.g., medicine), but on the whole technology contributions will continue to add negative pressures to the other environmental factors (employment, job security, left-right political swings). On the whole I think these disjoints will continue to become more enhanced until a major crisis point is reached (e.g., war).”
Mechthild Schmidt Feist, department coordinator for digital communications and media at New York University, said, “Historical precedent shows that inventions are just as powerful in the hands of criminals or irresponsible or uninformed people. The more powerful our communication, the more destructive it could be. We would need global, enforceable legislation to limit misuse. 1) That is highly unlikely. 2) It is hard to predict all misuses. My negative view is due to our inability to make responsible use of our current online communication and media models. The utopian freedom has become a dystopian battleground.”
Marc Brenman, managing partner at IDARE LLC, said, “We do not know all that machines can do. There is no inherent necessity that they will care for us. We may be an impediment to them. They may take orders from evil-doers. They will enable us to make mistakes even faster than we do now. Any technology is only as good as the morality and ethics of its makers, programmers and controllers. If machines are programmed to care more for the earth than for people, they may eliminate us anyway, since we are destroying the earth.”
Robert K. Logan, chief scientist at the Strategic Innovation Lab (sLab) at OCAT University and professor emeritus of physics at the University of Toronto, said, “The idea of the Singularity is an example of the over-extension of AI. Computers will never achieve an equivalency to human intelligence. There is no such thing as AW (artificial wisdom). AI as a tool to enhance human intelligence makes sense but AI to replace human intelligence makes no sense and therefore is nonsense.”
Alexey Turchin, existential risks researcher and futurist, responded, “There are significant risks of AI misuse before 2030 in the form of swarms of AI empowered drones or even non-aligned human-level AI.”
Adam Popescu, a writer who contributes frequently to the New York Times, Washington Post, Bloomberg Businessweek, Vanity Fair and the BBC, wrote, “We put too much naive hope in everything tech being the savior.”
The following one-liners from anonymous respondents also tie into this theme:

A cybersecurity strategist said, “The world has become technologically oriented and this creates challenges – for example, cybercrime.”
A respondent who works at a major global privacy initiative predicted AI and tech will not improve most people’s lives, citing, “Loss of jobs, algorithms run amuck.”

Other anonymous respondents commented:

“With increasing cyberattacks and privacy concerns AI could connect people to bad actors, which could cause stress and new problems – even the simplest of attacks/pranks could negatively affect people’s lives.”
“The increasing dependence of humans on computing coupled with the fundamental un-securability of general-purpose computing is going to lead to widespread exploitation.”

2. Solutions to address AI’s anticipated negative impacts
A number of participants in this canvassing offered solutions to the worrisome potential future spawned by AI. Among them: 1) Improving collaboration across borders and stakeholder groups. 2) Developing policies to assure that development of AI will be directed at augmenting humans and the common good. 3) Shifting the priorities of economic, political and education systems to empower individuals to stay ahead in the “race with the robots.”
Many respondents sketched out overall aspirations:
Andrew Wycoff, the director of OECD’s directorate for science, technology and innovation, and Karine Perset, an economist in OECD’s digital economy policy division, commented, “Twelve years from now, we will benefit from radically improved accuracy and efficiency of decisions and predictions across all sectors. Machine learning systems will actively support humans throughout their work and play. This support will be unseen but pervasive – like electricity. As machines’ ability to sense, learn, interact naturally and act autonomously increases, they will blur the distinction between the physical and the digital world. AI systems will interconnect and work together to predict and adapt to our human needs and emotions. The growing consensus that AI should benefit society at-large leads to calls to facilitate the adoption of AI systems to promote innovation and growth, help address global challenges, and boost jobs and skills development, while at the same time establishing appropriate safeguards to ensure these systems are transparent and explainable, and respect human rights, democracy, culture, nondiscrimination, privacy and control, safety, and security. Given the inherently global nature of our networks and applications that run across then, we need to improve collaboration across countries and stakeholder groups to move toward common understanding and coherent approaches to key opportunities and issues presented by AI. This is not too different from the post-war discussion on nuclear power. We should also tread carefully toward Artificial General Intelligence and avoid current assumptions on the upper limits of future AI capabilities.”
Wendy Hall, professor of computer science at the University of Southampton and executive director of the Web Science Institute, said, “By 2030 I believe that human-machine/AI collaboration will be empowering for human beings overall. Many jobs will have gone, but many new jobs will have been created and machines/AI should be helping us do things more effectively and efficiently both at home and at work. It is a leap of faith to think that by 2030 we will have learnt to build AI in a responsible way and we will have learnt how to regulate the AI and robotics industries in a way that is good for humanity. We may not have all the answers by 2030 but we need to be on the right track by then.”
Ian O’Byrne, an assistant professor focusing on literacy and technology at the College of Charleston, said, “I believe in human-machine/AI collaboration, but the challenge is whether humans can adapt our practices to these new opportunities.”
Arthur Bushkin, an IT pioneer who worked with the precursors to the Advanced Research Projects Agency Network (ARPANET) and Verizon, wrote, “The principal issue will be society’s collective ability to understand, manage and respond to the implications and consequences of the technology.”
Daniel Obam, information and communications technology policy advisor, responded, “As we develop AI, the issue of ethical behaviour is paramount. AI will allow authorities to analyse and allocate resources where there is the greatest need. AI will also change the way we work and travel. … Digital assistants that mine and analyse data will help professionals in making concise decisions in health care, manufacturing and agriculture, among others. Smart devices and virtual reality will enable humans to interact with and learn from historical or scientific issues in a more-clear manner. Using AI, authorities will be able to prevent crime before it happens. Cybersecurity needs to be at the forefront to prevent unscrupulous individuals from using AI to perpetrate harm or evil on the human race.”
Ryan Sweeney, director of analytics at Ignite Social Media, commented, “Our technology continues to evolve at a growing rate, but our society, culture and economy are not as quick to adapt. We’ll have to be careful that the benefits of AI for some do not further divide those who might not be able to afford the technology. What will that mean for our culture as more jobs are automated? We will need to consider the impact on the current class divide.”
Susan Mernit, executive director of The Crucible and co-founder and board member of Hack the Hood, responded, “If AI is in the hands of people who do not care about equity and inclusion, it will be yet another tool to maximize profit for a few.”
The next three sections of this report focus on solutions most often mentioned by respondents to this canvassing.
Improve human collaboration across borders and stakeholder groups
A number of these experts said ways must be found for people of the world to come to a common understanding of the evolving concerns over AI and digital life and to reach agreement in order to create cohesive approaches to tackling AI’s challenges.
Danil Mikhailov, head of data and innovation for Wellcome Trust, responded, “I see a positive future of human/AI interaction in 2030. In my area, health, there is tremendous potential in the confluence of advances in big data analysis and genomics to create personalised medicine and improve diagnosis, treatment and research. Although I am optimistic about human capacity for adaptation, learning, and evolution, technological innovation will not always proceed smoothly. In this we can learn from previous technological revolutions. For example, [Bank of England chief economist] Andy Haldane rightly pointed out that the original ‘luddites’ in the 19th century had a justified grievance. They suffered severe job losses, and it took the span of a generation for enough jobs to be created to overtake the ones lost. It is a reminder that the introduction of new technologies benefits people asymmetrically, with some suffering while others benefit. To realise the opportunities of the future we need to acknowledge this and prepare sufficient safety nets, such as well-funded adult education initiatives, to name one example. It’s also important to have an honest dialogue between the experts, the media and the public about the use of our personal data for social-good projects, like health care, taking in both the risks of acting – such as effects on privacy – and the opportunity costs of not acting. It is a fact that lives are lost currently in health systems across the world that could be saved even with today’s technology let alone that of 2030.”
Edson Prestes, a professor and director of robotics at the Federal University of Rio Grande do Sul, responded, “We must understand that all domains (technological or not) have two sides: a good and a bad one. To avoid the bad one we need to create and promote the culture of AI/Robotics for good. We need to stimulate people to empathize toward others. We need to think about potential issues, even if they have small probability to happen. We need to be futurists, foreseeing potential negative events and how to circumvent them before they happen. We need to create regulations/laws (at national and international levels) to handle globally harmful situations for humans, other living beings and the environment. Applying empathy, we should seriously think about ourselves and others – if the technology will be useful for us and others and if it will not cause any harm. We cannot develop solutions without considering people and the ecosystem as the central component of development. If so, the pervasiveness of AI/robotics in the future will diminish any negative impact and create a huge synergy among people and environment, improving people’s daily lives in all domains while achieving environment sustainability.”
Adam Nelson, a software developer for one of the “big five” global technology companies, said, “Human-machine/AI collaboration will be extremely powerful, but humans will still control intent. If human governance isn’t improved, AI will merely make the world more efficient. But the goals won’t be human welfare. They’ll be wealth aggregation for those in power.”
Wendy Seltzer, strategy lead and counsel at the World Wide Web Consortium, commented, “I’m mildly optimistic that we will have devised better techno-social governance mechanisms. such that if AI is not improving the lives of humans, we will restrict its uses.”
Jen Myronuk, a respondent who provided no identifying details, said, “The optimist’s view includes establishing and implementing a new type of ISO standard – ‘encoded human rights’ – as a functional data set alongside exponential and advancing technologies. Global human rights and human-machine/AI technology can and must scale together. If applied as an extension of the human experience, human-machine/AI collaboration will revolutionize our understanding of the world around us.”
Fiona Kerr, industry professor of neural and systems complexity at the University of Adelaide, commented, “The answer depends very much on what we decide to do regarding the large questions around ensuring equality of improved global health; by agreeing on what productivity and worth now look like, partly supported by the global wage; through fair redistribution of technology profits to invest in both international and national social capital; through robust discussion on the role of policy in rewarding technologists and businesses to build quality partnerships between humans and AI; through the growth of understanding in the neurophysiological outcomes of human-human and human-technological interaction which allows us to best decide what not to technologies, when a human is more effective, and how to ensure we maximise the wonders of technology as an enabler of a human-centric future.”
Benjamin Kuipers, a professor of computer science at the University of Michigan, wrote, “We face several critical choices between positive and negative futures. … Advancing technology will provide vastly more resources; the key decision is whether those resources will be applied for the good of humanity as a whole or if they will be increasingly held by a small elite. Advancing technology will vastly increase opportunities for communication and surveillance. The question is whether we will find ways to increase trust and the possibilities for productive cooperation among people or whether individuals striving for power will try to dominate by decreasing trust and cooperation. In the medium term, increasing technology will provide more powerful tools for human, corporate or even robot actors in society. The actual problems will be about how members of a society interact with each other. In a positive scenario, we will interact with conversational AIs for many different purposes and even when the AI belongs to a corporation we will be able to trust that it takes what in economics is called a ‘fiduciary’ stance toward each of us. That is, the information we provide must be used primarily for our individual benefit. Although we know, and are explicitly told, that our aggregated information is valuable to the corporation, we can trust that it will not be used for our manipulation or our disadvantage.”
Denise Garcia, an associate professor of political science and international affairs at Northeastern University, said, “Humanity will come together to cooperate.”
Charles Geiger, head of the executive secretariat for the UN’s World Summit on the Information Society, commented, “As long as we have a democratic system and a free press, we may counterbalance the possible threats of AI.”
Warren Yoder, longtime director of the Public Policy Center of Mississippi, now an instructor at Mississippi College, optimistically responded, “Human/AI collaborations will … augment our human abilities and increase the material well-being of humanity. At the same time the concomitant increase in the levels of education and health will allow us to develop new social philosophies and rework our polities to transform human well-being. AI increases the disruption of the old social order, making the new transformation both necessary and more likely, though not guaranteed.”
Wangari Kabiru, author of the MitandaoAfrika blog, based in Nairobi, Kenya, commented, “In 2030, advancing AI and tech will not leave most people better off than they are today, because our global digital mission is not strong enough and not principled enough to assure that ‘no, not one is left behind’ – perhaps intentionally. The immense positive-impact potential for enabling people to achieve more in nearly every area of life – the full benefits of human-machine/AI collaboration can only be experienced when academia, civil society and other institutions are vibrant, enterprise is human-values-based, and governments and national constitutions and global agreements place humanity first. … Engineering should serve humanity and never should humanity be made to serve the exploits of engineering. More people MUST be creators of the future of LIFE – the future of how they live, future of how they work, future of how their relationships interact and overall how they experience life. Beyond the coexistence of human-machine, this creates synergy.”
A professor expert in AI connected to a major global technology company’s projects in AI development wrote, “Precision democracy will emerge from precision education, to incrementally support the best decisions we can make for our planet and our species. The future is about sustaining our planet. As with the current development of precision health as the path from data to wellness, so too will artificial intelligence improve the impact of human collaboration and decision-making in sustaining our planet. ”
Some respondents argued that individuals must do better at taking a more active role in understanding and implementing the decision-making options available to them in these complex, code-dependent systems.
Kristin Jenkins, executive director of BioQUEST Curriculum Consortium, said, “Like all tools the benefits and pitfalls of AI will depend on how we use it. A growing concern is the collection and potential uses of data about people’s day-to-day lives. ‘Something’ always knows where we are, the layout of the house, what’s in the fridge and how much we slept. The convenience provided by these tools will override caution about data collection, so strong privacy protection must be legislated and culturally nurtured. We need to learn to be responsible for our personal data and aware of when and how it is collected and used.”
Peng Hwa Ang, professor of communications at Nanyang Technological University and author of “Ordering Chaos: Regulating the Internet,” commented, “AI is still in its infancy. A lot of it is ruled-based and not demanding of true intelligence or learning. But even so, I find it useful. My car has lane-assistance. I find that it makes me a better driver. When AI is more full-fledged, it would make driving safer and faster. I am using AI for some work I am doing on sentiment analysis. I find that I am able to be more creative in asking questions to be investigated. I expect AI will compel greater creativity. Right now, the biggest fear of AI is that it is a black-box operation – yes, the factors chosen are good and accurate and useful, but no one knows why those criteria are chosen. We know the percentages of the factors, but we do not know the whys. Hopefully, by 2030, the box will be more transparent. That’s on the AI side. On the human side, I hope human beings understand that true AI will make mistakes. If not, it is not real AI. This means that people have got to be ready to catch the mistakes that AI will make. It will be very good. But it will (still) not be foolproof.”
Bert Huang, an assistant professor in the department of computer science at Virginia Tech focused on machine learning, wrote, “AI will cause harm (and it has already caused harm), but its benefits will outweigh the harm it causes. That said, the [historical] pattern of technology being net positive depends on people seeking positive things to do with the technology, so efforts to guide research toward societal benefits will be important to ensure the best future.”
An anonymous respondent said, “We should ensure that values (local or global) and basic philosophical theories on ethics inform the development and implementation of AI systems.”
Develop policies to assure that development of AI will be directed at augmenting humans and the common good
Many experts who shared their insights in this study suggested there has to be an overall change in the development, regulation and certification of autonomous systems. They generally said the goal should be values-based, inclusive, decentralized, networks “imbued with empathy” that help individuals assure that technology meets social and ethical responsibilities for the common good.
Susan Etlinger, an industry analyst for Altimeter Group and expert in data, analytics and digital strategy, commented, “In order for AI technologies to be truly transformative in a positive way, we need a set of ethical norms, standards and practical methodologies to ensure that we use AI responsibly and to the benefit of humanity. AI technologies have the potential to do so much good in the world: identify disease in people and populations, discover new medications and treatments, make daily tasks like driving simpler and safer, monitor and distribute energy more efficiently, and so many other things we haven’t yet imagined or been able to realize. And – like any tectonic shift – AI creates its own type of disruption. We’ve seen this with every major invention from the Gutenberg press to the invention of the semiconductor. But AI is different. Replication of some human capabilities using data and algorithms has ethical consequences. Algorithms aren’t neutral; they replicate and reinforce bias and misinformation. They can be opaque. And the technology and means to use them rests in the hands of a select few organizations, at least today.”
Bryan Johnson, founder and CEO of Kernel, a leading developer of advanced neural interfaces, and OS Fund, a venture capital firm, said, “We could start with owning our own digital data and the data from our bodies, minds and behavior, and then follow by correcting our major tech companies’ incentives away from innovation for everyday convenience and toward radical human improvement. As an example of what tech could look like when aligned with radical human improvement, cognitive prosthetics will one day give warnings about biases – like how cars today have sensors letting you know when you drift off to sleep or if you make a lane change without a signal – and correct cognitive biases and warn an individual away from potential cognitive biases. This could lead to better behaviors in school, home and work, and encourage people to make better health decisions.”
Marc Rotenberg, executive director of Electronic Privacy Information Center (EPIC), commented, “The challenge we face with the rise of AI is the growing opacity of processes and decision-making. The favorable outcomes we will ignore. The problematic outcomes we will not comprehend. That is why the greatest challenge ahead for AI accountability is AI transparency. We must ensure that we understand and can replicate the outcomes produced by machines. The alternative outcome is not sustainable.”
John C. Havens, executive director of the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems and the Council on Extended Intelligence, wrote, “While today people provide ‘consent’ for their data usage, most people don’t understand the depth and breadth of how their information is utilized by businesses and governments at large. Until every individual is provided with a sovereign identity attached to a personal data cloud they control, information won’t truly be shared – just tracked. By utilizing blockchain or similar technologies and adopting progressive ideals toward citizens and their data, as demonstrated by countries like Estonia, we can usher in genuine digital democracy in the age of the algorithm. The other issue underlying the ‘human-AI augmentation’ narrative rarely discussed is the economic underpinnings driving all technology manufacturing. Where exponential growth, shareholder models are prioritized human and environmental well-being diminishes. Multiple reports from people like Joseph Stiglitz point out that while AI will greatly increase GDP in the coming decades, the benefits of these increases will favor the few versus the many. It’s only by adopting ‘Beyond GDP’ or triple-bottom-line metrics that ‘people, planet and profit’ will shape a holistic future between humans and AI.”
Greg Lloyd, president and co-founder at Traction Software, presented a future scenario: “By 2030 AIs will augment access and use of all personal and networked resources as highly skilled and trusted agents for almost every person – human or corporate. These agents will be bound to act in accordance with new laws and regulations that are fundamental elements of their construction much like Isaac Asimov’s ‘Three Laws of Robotics’ but with finer-grain ‘certifications’ for classes of activities that bind their behavior and responsibility for practices much like codes for medical, legal, accounting and engineering practice. Certified agents will be granted access to personal or corporate resources, and within those bounds will be able to converse, take direction, give advice and act like trusted servants, advisers or attorneys. Although these agents will ‘feel’ like intelligent and helpful beings, they will not have any true independent will or consciousness, and must not pretend to be human beings or act contrary to the laws and regulations that bind their behavior. Think Ariel and Prospero.”
Tracey P. Lauriault, assistant professor of critical media and big data at Carleton University’s School of Journalism and Communication, commented, “[What about] regulatory and policy interventions to protect citizens from potentially harmful outcomes, AI auditing, oversight, transparency and accountability? Without some sort of principles of a systems-based framework to ensure that AI remains ethical and in the public interest, in a stable fashion, then I must assume that AI will impede agency and could lead to decision-making that can be harmful, biased, inaccurate and not able to dynamically change with changing values. There needs to be some sort of accountability.”
Joël Colloc, professor at Université du Havre Normandy University and author of “Ethics of Autonomous Information Systems,” commented, “When AI supports human decisions as a decision-support system it can help humanity enhance life, health and well-being and supply improvements for humanity. See Marcus Flavius Quintilianus’s principles: Who is doing what, with what, why, how, when, where? Autonomous AI is power that can be used by powerful persons to control the people, put them in slavery. Applying the Quintilian principles to the role of AI … we should propose a code of ethics of AI to evaluate that each type of application is oriented toward the well-being of the user: 1) do not harm the user, 2) benefits go to the user, 3) do not misuse her/his freedom, identity and personal data, and 4) decree as unfair any clauses alienating the user’s independence or weakening his/her rights of control over privacy in use of the application. The sovereignty of the user of the system must remain total.”
Joseph Turow, professor of communication at the University of Pennsylvania, wrote, “Whether or not AI will improve society or harm it by 2030 will depend on the structures governing societies of the era. Broadly democratic societies with an emphasis on human rights might encourage regulations that push AI in directions that help all sectors of the nation. Authoritarian societies will, by contrast, set agendas for AI that further divide the elite from the rest and use technology to cultivate and reinforce the divisions. We see both tendencies today; the dystopian one has the upper hand especially in places with the largest populations. It is critical that people who care about future generations speak out when authoritarian tendencies of AI appear.”
Henry E. Brady, dean of the Goldman School of Public Policy at the University of California, Berkeley, wrote, “I believe that policy responses can be developed that will reduce biases and find a way to accommodate AI and robotics with human lives.”
Jennifer King, director of privacy at Stanford Law School’s Center for Internet and Society, said, “Unless we see a real effort to capture the power of AI for the public good, I do not see an overarching public benefit by 2030. The shift of AI research to the private sector means that AI will be developed to further consumption, rather than extend knowledge and public benefit.”
Gary Kreps, distinguished professor of communication and director of the Center for Health and Risk Communication at George Mason University, wrote, “The tremendous potential for AI to be used to engage and adapt information content and computer services to individual users can make computing increasingly helpful, engaging and relevant. However, to achieve these outcomes, AI needs to be programmed with the user in mind. For example, AI services should be user-driven, adaptive to individual users, easy to use, easy to understand and easy for users to control. These AI systems need to be programmed to adapt to individual user requests, learning about user needs and preferences.”
Thomas Streeter, a professor of sociology at the University of Vermont, said, “The technology will not determine whether things are better or worse in 2030; social and political choices will.”
Paul Werbos, a former program director at the National Science Foundation who first described the process of training artificial neural networks through backpropagation of errors in 1974, said, “We are at a moment of choice. The outcome will depend a lot on the decisions of very powerful people who do not begin to know the consequences of the alternatives they face, or even what the substantive alternatives are.”
Divina Frau-Meigs, professor of media sociology at the University of Paris III: Sorbonne Nouvelle and UNESCO chair for sustainable digital development, responded, “The sooner the ethics of AI are aligned with human rights tenets the better.”
Juan Ortiz Freuler, a policy fellow at the World Wide Web Foundation, wrote “We believe technology can and should empower people. If ‘the people’ will continue to have a substantive say on how society is run, then the state needs to increase its technical capabilities to ensure proper oversight of these companies. Tech in general and AI in particular will promote the advancement of humanity in every area by allowing processes to scale efficiently, reducing the costs and making more services available to more people (including quality health care, mobility, education, etc.). The open question is how these changes will affect power dynamics. To operate effectively, AI requires a broad set of infrastructure components, which are not equally distributed. These include data centers, computing power and big data. What is more concerning is that there are reasons to expect further concentration. On the one hand, data scales well: The upfront (fixed) costs of setting up a datacenter are large compared to the cost of keeping it running. Therefore, the cost of hosting each extra datum is marginally lower than the previous one. Data is the fuel of AI, and therefore whoever gets access to more data can develop more effective AI. On the other hand, AI creates efficiency gains by allowing companies to automate more processes, meaning whoever gets ahead can undercut competitors. This circle fuels concentration. As more of our lives are managed by technology there is a risk that whoever controls these technologies gets too much power. The benefits in terms of quality of life and the risks to people’s autonomy and control over politics are qualitatively different and there cannot (and should not) be up for tradeoffs.”
Meryl Alper, an assistant professor of communication at Northeastern University and a faculty associate at Harvard University’s Berkman Klein Center for Internet and Society, wrote, “My fear is that AI tools will be used by a powerful few to further centralize resources and marginalize people. These tools, much like the internet itself, will allow people to do this ever more cheaply, quickly and in a far-reaching and easily replicable manner, with exponentially negative impacts on the environment. Preventing this in its worst manifestations will require global industry regulation by government officials with hands-on experience in working with AI tools on the federal, state and local level, and transparent audits of government AI tools by grassroots groups of diverse (in every sense of the term) stakeholders.”
David Wilkins, instructor in computer science at the University of Oregon, responded, “AI must be able to explain the basis for its decisions.”
A top research director and technical fellow at a major global technology company said, “There is a huge opportunity to enhance folks’ lives via AI technologies. The positive uses of AI will dominate as they will be selected for their value to people. I trust the work by industry, academia and civil society to continue to play an important role in moderating the technology, such as pursuing understandings of the potential costly personal, social and societal influences of AI. I particularly trust the guidance coming from the long-term, ongoing One Hundred Year Study on AI and the efforts of the Partnership on AI.”
Peter Stone, professor of computer science at the University of Texas at Austin and chair of the first study panel of the One Hundred Year Study on Artificial Intelligence (AI100), responded, “As chronicled in detail in the AI100 report, I believe that there are both significant opportunities and significant challenges/risks when it comes to incorporating AI technologies into various aspects of everyday life. With carefully crafted industry-specific policies and responsible use, I believe that the potential benefits outweigh the risks. But the risks are not to be taken lightly.”
Anita Salem, systems research and design principal at SalemSystems, warned of a possible dystopian outcome, “Human-machine interaction will result in increasing precision and decreasing human relevance unless specific efforts are made to design in ‘humanness.’ For instance, AI in the medical field will aid more precise diagnosis, will increase surgical precision and will increase evidence-based analytics. If designed correctly, these systems will allow the humans to do what they do best –provide empathy, use experience-based intuition and utilize touch and connection as a source of healing. If human needs are left out of the design process, we’ll see a world where humans are increasingly irrelevant and more easily manipulated. We could see increasing under-employment leading to larger wage gaps, greater poverty and homelessness, and increasing political alienation. We’ll see fewer opportunities for meaningful work, which will result in increasing drug and mental health problems and the further erosion of the family support system. Without explicit efforts to humanize AI design, we’ll see a population that is needed for purchasing, but not creating. This population will need to be controlled and AI will provide the means for this control: law enforcement by drones, opinion manipulation by bots, cultural homogeny through synchronized messaging, election systems optimized from big data and a geopolitical system dominated by corporations that have benefited from increasing efficiency and lower operating costs.”
Chris Newman, principal engineer at Oracle, commented, “As it becomes more difficult for humans to understand how AI/tech works, it will become harder to resolve inevitable problems. A better outcome is possible with a hard push by engineers and consumers toward elegance and simplicity (e.g., Steve-Jobs-era Apple).”
A research scientist based in North America wrote, “The wheels of legislation, which is a primary mechanism to ensure benefits are distributed throughout society, move slowly. While the benefits of AI/automation will accrue very quickly for the 1%, it will take longer for the rest of the populace to feel any benefits, and that’s ONLY if our representative leaders DELIBERATELY enact STRONG social and fiscal policy. For example, AI will save billions in labor costs – and also cut the bargaining power of labor in negotiations with capital. Any company using AI technologies should be heavily taxed, with that money going into strong social welfare programs like job retraining and federal jobs programs. For another example, any publicly funded AI research should be prevented from being privatized. The public ought to see the reward from its own investments. Don’t let AI follow the pattern of Big Pharma’s exploitation of the public-permitted Bayh-Dole Act.”
Ken Birman, a professor in the department of computer science at Cornell University, responded, “By 2030, I believe that our homes and offices will have evolved to support app-like functionality, much like the iPhone in my pocket. People will customize their living and working spaces, and different app suites will support different lifestyles or special needs. For example, think of a young couple with children, a group of students sharing a home or an elderly person who is somewhat frail. Each would need different forms of support. This ‘applications’ perspective is broad and very flexible. But we also need to ensure that privacy and security are strongly protected by the future environment. I do want my devices and apps linked on my behalf, but I don’t ever want to be continuously spied-upon. I do think this is feasible, and as it occurs we will benefit in myriad ways.”
Martin Geddes, a consultant specializing in telecommunications strategies, said, “The unexpected impact of AI will be to automate many of our interactions with systems where we give consent and to enable a wider range of outcomes to be negotiated without our involvement. This requires a new presentation layer for the augmented reality metaverse, with a new ‘browser’ – the Guardian Avatar – that helps to protect our identity and our interests.”
Lindsey Andersen, an activist at the intersection of human rights and technology for Freedom House and Internews, now doing graduate research at Princeton University, commented, “Already, there is an overreliance on AI to make consequential decisions that affect people’s lives. We have rushed to use AI to decide everything, from what content we see on social media to assigning credit scores to determining how long a sentence a defendant should serve. While often well-intentioned, these uses of AI are rife with ethical and human rights issues, from perpetuating racial bias to violating our rights to privacy and free expression. If we have not dealt with these problems through smart regulation, consumer/buyer education and establishment of norms across the AI industry, we could be looking at a vastly more unfair, polarized and surveilled world in 2030.”
Yeseul Kim, a designer for a major South Korean search firm, wrote, “The prosperity generated by and the benefits of AI will promote the quality of living for most people only when its ethical implications and social impacts are widely discussed and shared inside the human society, and only when pertinent regulations and legislation can be set up to mitigate the misconduct that can be brought about as the result of AI advancement. If these conditions are met, computers and machines can process data at unprecedented speed and at an unrivaled precision level, and this will improve the quality of life, especially in medical and healthcare sectors. It has already been proven and widely shared among medical expert groups that doctors perform better in detecting diseases when they work with AI. Robotics for surgery is also progressing, so this will also benefit the patients as they can assist human surgeons who inevitably face physical limits when they conduct surgeries.”
Mark Maben, a general manager at Seton Hall University, wrote, “The AI revolution is, sadly, likely to be dystopian. At present, governmental, educational, civic, religious and corporate institutions are ill-prepared to handle the massive economic and social disruption that will be caused by AI. I have no doubt that advances in AI will enhance human capacities and empower some individuals, but this will be more than offset by the fact that artificial intelligence and associated technological advances will mean far fewer jobs in the future. Sooner than most individuals and societies realize, AI and automation will eliminate the need for retail workers, truck drivers, lawyers, surgeons, factory workers and other professions. In order to ensure that the human spirit thrives in a world run and ruled by AI, we will need to change the current concept of work. That is an enormous task for a global economic system in which most social and economic benefits come from holding a traditional job. We are already seeing a decline in democratic institutions and a rise in authoritarianism due to economic inequality and the changing nature of work. If we do not start planning now for the day when AI results in complete disruption of employment, the strain is likely to result in political instability, violence and despair. This can be avoided by policies that provide for basic human needs and encourage a new definition of work, but the behavior to date by politicians, governments, corporations and economic elites gives me little confidence in their ability to lead us through this transition.”
Eduardo Vendrell, a computer science professor at the Polytechnic University of Valencia in Spain, responded, “These advances will have a noticeable impact on our privacy, since the basis for this application is focused on the information we generate with the use of different technologies. … It will be necessary to regulate in a decisive way the access to the information and its use.”
Yoram Kalman, an associate professor at the Open University of Israel and member of The Center for Internet Research at the University of Haifa, wrote, “The main risk is when communication and analysis technologies are used to control others, to manipulate them, or to take advantage of them. These risks are ever-present and can be mitigated through societal awareness and education, and through regulation that identifies entities that become very powerful thanks to a specific technology or technologies, and which use that power to further strengthen themselves. Such entities – be they commercial, political, national, military, religious or any other – have in the past tried and succeeded in leveraging technologies against the general societal good, and that is an ever-present risk of any powerful innovation. This risk should make us vigilant but should not keep us from realizing one of the most basic humans urges: the strive to constantly improve the human condition.”
Sam Gregory, director of WITNESS and digital human rights activist, responded, “We should assume all AI systems for surveillance and population control and manipulation will be disproportionately used and inadequately controlled by authoritarian and non-democratic governments. These governments and democratic governments will continue to pressure platforms to use AI to monitor for content, and this monitoring, in and of itself, will contribute to the data set for personalization and for surveillance and manipulation. To fight back against this dark future we need to get the right combination of attention to legislation and platform self-governance right now, and we need to think about media literacy to understand AI-generated synthetic media and targeting. We should also be cautious about how much we encourage the use of AI as a solution to managing content online and as a solution to, for example, managing hate speech.”
Jonathan Kolber, futurist, wrote, “My fear is that, by generating AIs that can learn new tasks faster and more reliably than people can do, the future economy will have only evanescent opportunities for most people. My hope is that we will begin implementing a sustainable and viable universal basic income, and in particular Michael Haines’ MUBI proposal. (To my knowledge, the only such proposal that is sustainable and can be implemented in any country at any time.) I have offered a critique of alternatives. Given that people may no longer need depend on their competitive earning power in 2030, AI will empower a far better world. If, however, we fail to implement a market-oriented universal basic income or something equally effective, vast multitudes will become unemployed and unemployable without means to support themselves. That is a recipe for societal disaster.”
Walid Al-Saqaf, senior lecturer at Södertörn University, member of the board of trustees of the Internet Society (ISOC) and vice president of the ISOC Blockchain Special Interest Group, commented, “The challenge is to ensure that the data used for AI procedures is reliable. This entails the need for strong cyber security and data integrity. The latter, I believe, can be tremendously enhanced by distributed ledger technologies such as blockchain. I foresee mostly positive results from AI so long as there is enough guards to protect from automated execution of tasks in areas that may have ethical considerations such as taking decisions that may have life-or-death implications. AI has a lot of potential. It should be used to add to and not replace human intellect and judgement.”
Danny O’Brien, international director for a nonprofit digital rights group, commented, “I’m generally optimistic about the ability of humans to direct technology for the benefit of themselves and others. I anticipate human-machine collaboration to take place at an individual level, with tools and abilities that enhance our own judgment and actions, rather than this being a power restricted to a few actors. So, for instance, if we use facial-recognition or predictive tools, it will be under the control of an end-user, transparent and limited to personal use. This may require regulation, internal coding restraints or a balance being struck between user capabilities. But I’m hopeful we can get there.”
Fernando Barrio, director of the law program at the Universidad Nacional de Río Negro in Argentina, commented, “The interaction between humans and networked AI could lead to a better future for a big percentage of the population. In order to do so efforts need to be directed not only at increasing AI development and capabilities but also at positive policies to increase the availability and inclusiveness of those technologies. The challenge is not technical; it is sociopolitical.”
Paul Jones, professor of information science at the University of North Carolina at Chapel Hill, responded, “AI as we know it in 2018 is just beginning to understand itself. Like HAL, it will have matured by 2030 into an understanding of its post-adolescent self and of its relationship to humans and to the world. But, also, humans will have matured in our relationship to AI. Like all adolescent relationships there will have been risk taking and regrets and hopefully reconciliation. Language was our first link to other intelligences, then books, then the internet – each a more intimate conversation than the one before. AI will become our link, adviser and to some extent our wise loving companion.”
Jean-Claude Heudin, a professor with expertise in AI and software engineering at the De Vinci Research Center at Pole Universitaire Leonard de Vinci in France, wrote, “Natural intelligence and artificial intelligence are complementary. We need all of the possible intelligence possible for solving the problems yet to come. More intelligence is always better.”
Bryan Alexander, futurist and president of Bryan Alexander Consulting, responded, “I hope we will structure AI to enhance our creativity, to boost our learning, to expand our relationships worldwide, to make us physically safer and to remove some drudgery.”
But some have concerns that the setting of policy could do some damage.
Scott Burleigh, software engineer and intergalactic internet pioneer, wrote, “Advances in technology itself, including AI, always increase our ability to change the circumstances of reality in ways that improve our lives. It also always introduces possible side effects that can make us worse off than we were before. Those effects are realized when the policies we devise for using the new technologies are unwise. I don’t worry about technology; I worry about stupid policy. I worry about it a lot, but I am guardedly optimistic; in most cases I think we eventually end up with tolerable policies.”
Jeff Jarvis, director of the Tow-Knight Center at City University of New York’s Craig Newmark School of Journalism, commented, “What worries me most is worry itself: An emerging moral panic that will cut off the benefits of this technology for fear of what could be done with it. What I fear most is an effort to control not just technology and data but knowledge itself, prescribing what information can be used for before we know what those uses could be. I could substitute ‘book’ for ‘AI’ and the year 1485 (or maybe 1550) for 2030 in your question and it’d hold fairly true. Some thought it would be good, some bad; both end up right. We will figure this out. We always have. Sure, after the book there were wars and other profound disturbances. But in the end, humans figure out how to exploit technologies to their advantage and control them for their safety. I’d call that a law of society. The same will be true of AI. Some will misuse it, of course, and that is the time to identify limits to place on its use – not speculatively before. Many more will use it to find economic, societal, educational and cultural benefit and we need to give them the freedom to do so.”
Some respondents said no matter how society comes together to troubleshoot AI concerns there will still be problems.
Dave Gusto, professor of political science and co-director of the Consortium for Science, Policy & Outcomes at Arizona State University, said, “The question asked about ‘most people.’ Most people in the world live a life that is not well regarded by technology, technology developers and AI. I don’t see that changing much in the next dozen years.”
A longtime Silicon Valley communications professional who has worked at several of the top tech companies over the past few decades responded, “AI will continue to improve *if* quality human input is behind it. If so, better AI will support service industries at the top of the funnel, leaving humans to handle interpretation, decisions and applied knowledge. Medical data-gathering for earlier diagnostics comes to mind. Smarter job-search processes, environmental data collection for climate-change actions – these applications all come to mind.”
Hari Shanker Sharma, an expert in nanotechnology and neurobiology at Uppsala University in Sweden, said, “AI has not yet peaked hence growth will continue, but evil also uses such developments. That will bring bigger dangers to mankind. The need will be to balance growth with safety, e.g., social media is good and bad. The ways to protect from evil mongers are not sufficient. Tracing an attacker/evil monger in a global village to control and punish is the need. AI will give birth to an artificial human being who could be an angel or a devil. Plan for countering evil at every development stage.”
A changemaker working for digital accessibility wrote, “There is no reason to assume some undefined force will be able to correct for or ameliorate the damage of human nature amplified with power-centralizing technologies. There is no indication that governments will be able to counterbalance power-centralization trends, as governments, too, take advantage of such market failures. The outward dressing of such interactions is probably the least important aspect of it.”
An information-science futurist commented, “I fear that powerful business interests will continue to put profits above all else, closing their eyes to the second- and third-order effects of their decisions. I fear that we do not have the political will to protect and promote the common interests of citizens and democracy. I fear that our technological tools are advancing more quickly than our ability to manage them wisely. I have, however, recently spotted new job openings with titles like ‘Director of Research, Policy and Ethics in AI’ and ‘Architect, AI Ethical Practice’ at major software companies. There are reasons for hope.”
The following one-liners from anonymous respondents also tie into this theme:

An open-source technologist in the automotive industry wrote, “We’ll have to have independent AI systems with carefully controlled data access, clear governance and individuals’ right to be forgotten.”
A research professor of international affairs at a major university in Washington, D.C., responded, “We have to find a balance between regulations designed to encourage ethical nondiscriminatory use, transparency and innovation.”
A director for a major regional internet registry said, “The ability of government to properly regulate advanced technologies is not keeping up with the evolution of those technologies. This allows many developments to proceed without sufficient notice, analysis, vetting or regulation to protect the interests of citizens (Facebook being a prime example).”
A professor at a major Silicon-Valley-area university said, “If technological advances are not integrated into a vision of holistic, ecologically sustainable, politically equitable social visions, they will simply serve gated and locked communities.”
A member of the editorial board of the Association of Computing Machinery journal on autonomous and adaptive systems commented, “By developing an ethical AI, we can provide smarter services in daily life, such as collaborating objects providing on-demand highly adaptable services in any environment supporting daily life activities.”

Other anonymous respondents commented:

“It is essential that policymakers focus on impending inequalities. The central question is for whom will life be better, and for whom will it be worse? Some people will benefit from AI, but many will not. For example, folks on the middle and lower end of the income scale will see their jobs disappear as human-machine/AI collaborations become lower-cost and more efficient. Though such changes could generate societal benefits, they should not be born on the backs of middle- and low-income people.”
“Results will be determined by the capacity of political, criminal justice and military institutions to adapt to rapidly evolving technologies.
“To assure the best future, we need to ramp up efforts in the areas of decentralizing data ownership, education and policy around transparency.”
“Most high-end AI knowhow is and will be controlled by a few giant corporations unless government or a better version of the United Nations step in to control and oversee them.”
“Political change will determine whether AI technologies will benefit most people or not. I am not optimistic due to the current growth of authoritarian regimes and the growing segment of the super-rich elite who derive disproportionate power over the direction of society from their economic dominance.”
“Mechanisms must be put in place to ensure that the benefits of AI do not accrue only to big companies and their shareholders. If current neo-liberal governance trends continue, the value-added of AI will be controlled by a few dominant players, so the benefits will not accrue to most people. There is a need to balance efficiency with equity, which we have not been doing lately.”

Shift the priorities of economic, political and education systems to empower individuals to stay ahead in the ‘race with the robots’
A share of these experts suggest the creation of policies, regulations or ethical and operational standards should shift corporate and government priorities to focus on the global advancement of humanity, rather than profits or nationalism. They urge that major organizations revamp their practices and make sure AI advances are aimed at human augmentation for all, regardless of economic class.
Evan Selinger, professor of philosophy at the Rochester Institute of Technology, commented, “In order for people, in general, to be better off as AI advances through 2030, a progressive political agenda – one rooted in the protection of civil liberties and human rights and also conscientious of the dangers of widening social and economic inequalities – would have to play a stronger role in governance. In light of current events, it’s hard to be optimistic that such an agenda will have the resources necessary to keep pace with transformative uses of AI throughout ever-increasing aspects of society. To course-correct in time it’s necessary for the general public to develop a deep appreciation about why leading ideologies concerning the market, prosperity and security are not in line with human flourishing.”
Nicholas Beale, leader of the strategy practice at Sciteb, an international strategy and search firm, commented, “All depends on how responsibly AI is applied. AI ‘done right’ will empower. But unless Western CEOs improve their ethics it won’t. I’m hoping for the best.”
Benjamin Shestakofsky, an assistant professor of sociology at the University of Pennsylvania specializing in digital technology’s impacts on work, said, “Policymakers should act to ensure that citizens have access to knowledge about the effects of AI systems that affect their life chances and a voice in algorithmic governance. The answer to this question will depend on choices made by citizens, workers, organizational leaders and legislators across a broad range of social domains. For example, algorithmic hiring systems can be programmed to prioritize efficient outcomes for organizations or fair outcomes for workers. The profits produced by technological advancement can be broadly shared or can be captured by the shareholders of a small number of high-tech firms.”
Charles Zheng, a researcher into machine learning and AI with the National Institute of Mental Health, wrote, “To ensure the best future, politicians must be informed of the benefits and risks of AI and pass laws to regulate the industry and to encourage open AI research. My hope is that AI algorithms advance significantly in their ability to understand natural language, and also in their ability to model humans and understand human values. My fear is that the benefits of AI are restricted to the rich and powerful without being accessible to the general public.”
Mary Chayko, author of “Superconnected: The Internet, Digital Media, and Techno-Social Life,” said, “We will see regulatory oversight of AI geared toward the protection of those who use it. Having said that, people will need to remain educated as to AI’s impacts on them and to mobilize as needed to limit the power of companies and governments to intrude on their spaces, lives and civil rights. It will take vigilance and hard work to accomplish this, but I feel strongly that we are up to the task.”
R “Ray” Wang, founder and principal analyst at Constellation Research, based in Silicon Valley, said, “We have not put the controls of AI in the hands of many. In fact the experience in China has shown how this technology can be used to take away the freedoms and rights of the individual for the purposes of security, efficiency, expediency and whims of the state. On the commercial side, we also do not have any controls in play as to ethical AI. Five elements should be included – transparency, explainability, reversibility, coachability and human-led processes in the design.”
John Willinsky, professor and director of the Public Knowledge Project at Stanford Graduate School of Education, said, “Uses of AI that reduce human autonomy and freedom will need to be carefully weighed against the gains in other qualities of human life (e.g., driverless cars that improve traffic and increase safety). By 2030, deliberations over such matters will be critical to the functioning of ‘human-machine/AI collaboration.’ My hope, however, is that these deliberations are not framed as collaborations between what is human and what is AI but will be seen as the human use of yet another technology, with the wisdom of such use open to ongoing human consideration and intervention intent on advancing that sense of what is most humane about us.”
A professor of media studies at a U.S. university commented, “Technology will be a material expression of social policy. If that social policy is enacted through a justice-oriented democratic process, then it has a better chance of producing justice-oriented outcomes. If it is enacted solely by venture-funded corporations with no obligation to the public interest, most people in 2030 will likely be worse off.”
Gene Crick, director of the Metropolitan Austin Interactive Network and longtime community telecommunications expert, wrote, “To predict AI will benefit ‘most’ people is more hopeful than certain. … AI can benefit lives at work and home – if competing agendas can be balanced. Key support for this important goal could be technology professionals’ acceptance and commitment regarding social and ethical responsibilities of our work.”
Anthony Picciano, a professor of education at the City of New York University’s Interactive Technology and Pedagogy program, responded, “I am concerned that profit motives will lead some companies and individuals to develop AI applications that will threaten, not necessarily improve, our way of life. In the next 10 years we will see evolutionary progress in the development of artificial intelligence. After 2030, we will likely see revolutionary developments that will have significant ramifications on many aspects of human endeavor. We will need to develop checks on artificial intelligence.”
Bill Woodcock, executive director at Packet Clearing House, the research organization behind global network development, commented, “In short-term, pragmatic ways, learning algorithms will save people time by automating much of tasks like navigation and package delivery and shopping for staples. But that tactical win comes at a strategic loss as long as the primary application of AI is to extract more money from people, because that puts them in opposition to our interests as a species, helping to enrich a few people at the expense of everyone else. In AI that exploits human psychological weaknesses to sell us things, we have for the first time created something that effectively predates our own species. That’s a fundamentally bad idea and requires regulation just as surely as would self-replicating biological weapons.”
Ethem Alpaydin, a professor of computer engineering at Bogazici University in Istanbul, responded, “AI will favor the developed countries that actually develop these technologies. AI will help find cures for various diseases and overall improve the living conditions in various ways. For the developing countries, however, whose labor force is mostly unskilled and whose exports are largely low-tech, AI implies higher unemployment, lower income and more social unrest. The aim of AI in such countries should be to add skill to the labor force rather than supplant them. For example, automatic real-time translation systems (e.g., Google’s Babel fish) would allow people who don’t speak a foreign language to find work in the tourism industry.”
Joe Whittaker, a former professor of sciences and associate director of the NASA GESTAR program, now associate provost at Jackson State University, said, “Actions should be taken to make the internet universally available and accessible, provide the training and know-how for all users.”
John Paschoud, councilor for the London borough of Lewisham, said, “It is possible that advances in AI and networked information will benefit ‘most’ people, but this is highly dependent upon on how those benefits are shared. … If traditional capitalist models of ‘ownership of the means of production’ prevail, then benefits of automated production will be retained by the few who own, not the many who work. Similarly, models of housing, health care, etc., can be equitably distributed and can all be enhanced by technology.”
David Schlangen, a professor of applied computational linguistics at Bielefeld University in Germany, responded, “If the right regulations are put in place and ad-based revenue models can be controlled in such a way that they cannot be exploited by political interest groups, the potential for AI-based information search and decision support is enormous. That’s a big if, but I prefer to remain optimistic.”
Kate Carruthers, a chief data and analytics officer based in Australia, predicted, “Humans will increasingly interact with AI on a constant basis and it will become hard to know where the boundaries are between the two. Just as kids now see their mobile phones as an extension of themselves so too will human/AI integration be. I fear that the cause of democracy and freedom will be lost by 2030, so it might be a darker future. To avoid that, one thing we need to do is ensure the development of ethical standards for the development of AI and ensure that we deal with algorithmic bias. We need to build ethics into our development processes. Further, I assume that tracking and monitoring of people will be an accepted part of life and that there will be stronger regulation on privacy and data security. Every facet of life will be circumscribed by AI, and it will be part of the fabric of our lives.”
David Zubrow, associate director of empirical research at Carnegie Mellon University’s Software Engineering Institute, said, “How the advances are used demands wisdom, leadership and social norms and values that respect and focus on making the world better for all; education and health care will reach remote and underserved areas, for instance. The fear is control is consolidated in the hands of few that seek to exploit people, nature and technology for their own gain. I am hopeful that this will not happen.”
Francisco S. Melo, an associate professor of computer science at Instituto Superior Técnico in Lisbon, Portugal, responded, “I expect that AI technology will contribute to render several services (in health, assisted living, etc.) more efficient and humane and, by making access to information more broadly available, contribute to mitigate inequalities in society. However, in order for positive visions to become a reality, both AI researchers and the general population should be aware of the implications that such technology can have, particularly in how information is used and the ways by which it can be manipulated. In particular, AI researchers should strive for transparency in their work, in order to demystify AI and minimize the possibility of misuse; the general public, on the other hand, should strive to be educated in the responsible and informed use of technology.”
Kyung Sin Park, internet law expert and co-founder of Open Net Korea, responded, “AI consists of software and training data. Software is already being made available on an open source basis. What will decide AI’s contribution to humanity will be whether data (used for training AI) will be equitably distributed. Data-protection laws and the open data movement will hopefully do the job of making more data available equally to all people. I imagine a future where people can access AI-driven diagnosis of symptoms, which will drastically reduce health care costs for all.”
Doug Schepers, chief technologist at Fizz Studio, said, “AI/ML, in applications and in autonomous devices and vehicles, will make some jobs obsolete, and the resulting unemployment will cause some economic instability that impacts society as a whole, but most individuals will be better off. The social impact of software and networked systems will get increasingly complex, so ameliorating that software problem with software agents may be the only way to decrease harm to human lives, but only if we can focus the goal of software to benefit individuals and groups rather than companies or industries.”
Erik Huesca, president of the Knowledge and Digital Culture Foundation, based in Mexico City, said, “There is a concentration of places where specific AI is developed. It is a consequence of the capital investment that seeks to replace expensive professionals. Universities have to rethink what type of graduates to prepare, especially in areas of health, legal and engineering, where the greatest impact is expected, since the labor displacement of doctors, engineers and lawyers is a reality with the incipient developed systems.”
Stephen Abram, principal at Lighthouse Consulting Inc., wrote, “I am concerned that individual agency is lost in AI and that appropriate safeguards should be in place around data collection as specified by the individual. I worry that context can be misconstrued by government agencies like ICE, IRS, police, etc. There is a major conversation needed throughout the time during which AI applications are developed, and they need to be evergreen as innovation and creativity spark new developments. Indeed, this should not be part of a political process, but an academic, independent process guided by principles and not economics and commercial entities.”
David Klann, consultant and software developer at Broadcast Tool & Die, responded, “AI and related technologies will continue to enhance peoples’ lives. I tend toward optimism; I instinctively believe there are enough activists who care about the ethics of AI that the technology will be put to use solving problems that humans cannot solve on their own. Take mapping, for instance. I recently learned about congestion problems caused by directions being optimized for individuals. People are now tweaking the algorithms to account for multiple people taking the ‘most efficient route’ that had become congested and was causing neighborhood disturbance due to the increased traffic. I believe people will construct AI algorithms to learn of and to ‘think ahead’ about such unintended consequences and to avoid them before they become problems. Of course, my fear is that money interests will continue to wield an overwhelming influence over AI and machine learning (ML). These can be mitigated through fully disclosed techniques, transparency and third-party oversight. These third parties may be government institutions or non-government organizations with the strength to ‘enforce’ ethical use of the technologies. Open source code and open ML training data will contribute significantly to this mitigation.”
Andrian Kreye, a journalist and documentary filmmaker based in Germany, said, “If humanity is willing to learn from its mistakes with low-level AIs like social media algorithms there might be a chance for AI to become an engine for equality and progress. Since most digital development is driven by venture capital, experience shows that automation and abuse will be the norm.”
Mai Sugimoto, an associate professor of sociology at Kansai University in Japan, responded, “AI could amplify one’s bias and prejudice. We have to make data unbiased before putting it into AI, but it’s not very easy.”
An anonymous respondent wrote, “There are clearly advances associated with AI, but the current global political climate gives no indication that technological advancement in any area will improve most lives in the future. We also need to think ecologically in terms of the interrelationship between technology and other social-change events. For example, medical technology has increased lifespans, but the current opioid crisis has taken many lives in the U.S. among certain demographics.”
A founder and president said, “The future of AI is more about the policies we choose and the projects we choose to fund. I think there will be large corporate interests in AI that serve nothing but profits and corporations’ interests. This is the force for the ‘bad.’ However, I also believe that most technologists want to do good, and that most people want to head in a direction for the common good. In the end, I think this force will win out.”
A senior strategist in regulatory systems and economics for a top global telecommunications firm wrote, “If we do not strive to improve society, making the weakest better off, the whole system may collapse. So, AI had better serve to make life easier for everyone.”
3. How humans and AI might evolve together in the next decade
What will human-technology co-evolution look like by 2030? Participants in this canvassing expect the rate of change to fall in a range anywhere from incremental to extremely impactful. Generally, they expect AI to continue to be targeted toward efficiencies in workplaces and other activities, and they say it is likely to be embedded in most human endeavors.
The greatest share of participants in this canvassing said automated systems driven by artificial intelligence are already improving many dimensions of their work, play and home lives and they expect this to continue over the next decade. While they worry over the accompanying negatives of human-AI advances, they hope for broad changes for the better as networked, intelligent systems are revolutionizing everything, from the most pressing professional work to hundreds of the little “everyday” aspects of existence.
One respondent’s answer covered many of the improvements experts expect as machines sit alongside humans as their assistants and enhancers. An associate professor at a major university in Israel wrote, “In the coming 12 years AI will enable all sorts of professions to do their work more efficiently, especially those involving ‘saving life’: individualized medicine, policing, even warfare (where attacks will focus on disabling infrastructure and less in killing enemy combatants and civilians). In other professions, AI will enable greater individualization, e.g., education based on the needs and intellectual abilities of each pupil/student. Of course, there will be some downsides: greater unemployment in certain ‘rote’ jobs (e.g., transportation drivers, food service, robots and automation, etc.).”
This section begins with experts sharing mostly positive expectations for the evolution of humans and AI. It is followed by separate sections that include their thoughts about the potential for AI-human partnerships and quality of life in 2030, as well as the future of jobs, health care and education.
AI will be integrated into most aspects of life, producing new efficiencies and enhancing human capacities
Many of the leading experts extolled the positives they expect to continue to expand as AI tools evolve to do more things for more people.
Martijn van Otterlo, author of “Gatekeeping Algorithms with Human Ethical Bias” and assistant professor of artificial intelligence at Tilburg University in the Netherlands, wrote, “Even though I see many ethical issues, potential problems and especially power imbalance/misuse issues with AI (not even starting about singularity issues and out-of-control AI), I do think AI will change most lives for the better, especially looking at the short horizon of 2030 even more-so, because even bad effects of AI can be considered predominantly ‘good’ by the majority of people. For example, the Cambridge Analytica case has shown us the huge privacy issues of modern social networks in a market economy, but, overall, people value the extraordinary services Facebook offers to improve communication opportunities, sharing capabilities and so on.”
Vint Cerf, Internet Hall of Fame member and vice president and chief internet evangelist at Google, said, “I see AI and machine learning as augmenting human cognition a la Douglas Engelbart. There will be abuses and bugs, some harmful, so we need to be thoughtful about how these technologies are implemented and used, but, on the whole, I see these as constructive.”
Mícheál Ó Foghlú, engineering director and DevOps Code Pillar at Google’s Munich office, said, “The trend is that AI/ML models in specific domains can out-perform human experts (e.g., certain cancer diagnoses based on image-recognition in retina scans). I think it would be fairly much the consensus that this trend would continue, and many more such systems could aid human experts to be more accurate.”
Craig Mathias, principal at Farpoint Group, an advisory firm specializing in wireless networking and mobile computing, commented, “Many if not most of the large-scale technologies that we all depend upon – such as the internet itself, the power grid, and roads and highways – will simply be unable to function in the future without AI, as both solution complexity and demand continue to increase.”
Matt Mason, a roboticist and the former director of the Robotics Institute at Carnegie Mellon University, wrote, “AI will present new opportunities and capabilities to improve the human experience. While it is possible for a society to behave irrationally and choose to use it to their detriment, I see no reason to think that is the more likely outcome.”
Mike Osswald, vice president of experience innovation at Hanson Inc., commented, “I’m thinking of a world in which people’s devices continuously assess the world around them to keep a population safer and healthier. Thinking of those living in large urban areas, with devices forming a network of AI input through sound analysis, air quality, natural events, etc., that can provide collective notifications and insight to everyone in a certain area about the concerns of environmental factors, physical health, even helping provide no quarter for bad actors through community policing.”
Barry Hughes, senior scientist at the Center for International Futures at the University of Denver, commented, “I was one of the original test users of the ARPANET and now can hardly imagine living without the internet. Although AI will be disruptive through 2030 and beyond, meaning that there will be losers in the workplace and growing reasons for concern about privacy and AI/cyber-related crime, on the whole I expect that individuals and societies will make choices on use and restriction of use that benefit us. Examples include likely self-driving vehicles at that time, when my wife’s deteriorating vision and that of an increased elderly population will make it increasingly liberating. I would expect rapid growth in use for informal/non-traditional education as well as some more ambivalent growth in the formal-education sector. Big-data applications in health-related research should be increasingly productive, and health care delivery should benefit. Transparency with respect to its character and use, including its developers and their personal benefits, is especially important in limiting the inevitable abuse.”
Dana Klisanin, psychologist, futurist and game designer, predicted, “People will increasingly realize the importance of interacting with each other and the natural world and they will program AI to support such goals, which will in turn support the ongoing emergence of the ‘slow movement.’ For example, grocery shopping and mundane chores will be allocated to AI (smart appliances), freeing up time for preparation of meals in keeping with the slow food movement. Concern for the environment will likewise encourage the growth of the slow goods/slow fashion movement. The ability to recycle, reduce, reuse will be enhanced by the use of in-home 3D printers, giving rise to a new type of ‘craft’ that is supported by AI. AI will support the ‘cradle-to-grave’ movement by making it easier for people to trace the manufacturing process from inception to final product.”
Liz Rykert, president at Meta Strategies, a consultancy that works with technology and complex organizational change, responded, “The key for networked AI will be the ability to diffuse equitable responses to basic care and data collection. If bias remains in the programming it will be a big problem. I believe we will be able to develop systems that will learn from and reflect a much broader and more diverse population than the systems we have now.”
Michael R. Nelson, a technology policy expert for a leading network services provider who worked as a technology policy aide in the Clinton administration, commented, “Most media reports focus on how machine learning will directly affect people (medical diagnosis, self-driving cars, etc.) but we will see big improvements in infrastructure (traffic, sewage treatment, supply chain, etc.).”
Gary Arlen, president of Arlen Communications, wrote, “After the initial frenzy recedes about specific AI applications (such as autonomous vehicles, workplace robotics, transaction processing, health diagnoses and entertainment selections), specific applications will develop – probably in areas barely being considered today. As with many new technologies, the benefits will not apply equally, potentially expanding the haves-and-have-nots dichotomy. In addition, as AI delves into new fields – including creative work such as design, music/art composition – we may see new legal challenges about illegal appropriation of intellectual property (via machine learning). However, the new legal tasks from such litigation may not need a conventional lawyer – but could be handled by AI itself. Professional health care AI poses another type of dichotomy. For patients, AI could be a bonanza, identifying ailments, often in early stages (based on early symptoms), and recommending treatments. At the same time, such automated tasks could impact employment for medical professionals. And again, there are legal challenges to be determined, such as liability in the case of a wrong action by the AI. Overall, there is no such thing as ‘most people,’ but many individuals and groups – especially in professional situations – WILL live better lives thanks to AI, albeit with some severe adjustment pains.”
Tim Morgan, a respondent who provided no identifying details, said, “Algorithmic machine learning will be our intelligence amplifier, exhaustively exploring data and designs in ways humans alone cannot. The world was shocked when IBM’s Deep Blue computer beat Garry Kasparov in 1997. What emerged later was the realization that human and AI ‘centaurs’ could combine to beat anyone, human or AI. The synthesis is more than the sum of the parts.”
Marshall Kirkpatrick, product director of influencer marketing, responded, “If the network can be both decentralized and imbued with empathy, rather than characterized by violent exploitation, then we’re safe. I expect it will land in between, hopefully leaning toward the positive. For example, I expect our understanding of self and freedom will be greatly impacted by an instrumentation of a large part of memory, through personal logs and our data exhaust being recognized as valuable just like when we shed the term ‘junk DNA.’ Networked AI will bring us new insights into our own lives that might seem as far-fetched today as it would have been 30 years ago to say, ‘I’ll tell you what music your friends are discovering right now.’ AI is most likely to augment humanity for the better, but it will take longer and not be done as well as it could be. Hopefully we’ll build it in a way that will help us be comparably understanding to others.”
Daniel A. Menasce, professor of computer science at George Mason University, commented, “AI and related technologies coupled with significant advances in computer power and decreasing costs will allow specialists in a variety of disciplines to perform more efficiently and will allow non-specialists to use computer systems to augment their skills. Some examples include health delivery, smart cities and smart buildings. For these applications to become reality, easy-to-use user interfaces, or better yet transparent user interfaces will have to be developed.”
David Wells, chief financial officer at Netflix at the time he responded to this study, responded, “Technology progression and advancement has always been met with fear and anxiety, giving way to tremendous gains for humankind as we learn to enhance the best of the changes and adapt and alter the worst. Continued networked AI will be no different but the pace of technological change has increased, which is different and requires us to more quickly adapt. This pace is different and presents challenges for some human groups and societies that we will need to acknowledge and work through to avoid marginalization and political conflict. But the gains from better education, medical care and crime reduction will be well worth the challenges.”
Rik Farrow, editor of ;login: for the USENIX association, wrote, “Humans do poorly when it comes to making decisions based on facts, rather than emotional issues. Humans get distracted easily. There are certainly things that AI can do better than humans, like driving cars, handling finances, even diagnosing illnesses. Expecting human doctors to know everything about the varieties of disease and humans is silly. Let computers do what they are good at.”
Steve Crocker, CEO and co-founder of Shinkuro Inc. and Internet Hall of Fame member, responded, “AI and human-machine interaction has been under vigorous development for the past 50 years. The advances have been enormous. The results are marbled through all of our products and systems. Graphics, speech [and] language understanding are now taken for granted. Encyclopedic knowledge is available at our fingertips. Instant communication with anyone, anywhere exists for about half the world at minimal cost. The effects on productivity, lifestyle and reduction of risks, both natural and man-made, have been extraordinary and will continue. As with any technology, there are opportunities for abuse, but the challenges for the next decade or so are not significantly different from the challenges mankind has faced in the past. Perhaps the largest existential threat has been the potential for nuclear holocaust. In comparison, the concerns about AI are significantly less.”
James Kadtke, expert on converging technologies at the Institute for National Strategic Studies at the U.S. National Defense University, wrote, “Barring the deployment of a few different radically new technologies, such as general AI or commercial quantum computers, the internet and AI [between now and 2030] will proceed on an evolutionary trajectory. Expect internet access and sophistication to be considerably greater, but not radically different, and also expect that malicious actors using the internet will have greater sophistication and power. Whether we can control both these trends for positive outcomes is a public policy issue more than a technological one.”
Tim Morgan, a respondent who provided no identifying details, said, “Human/AI collaboration over the next 12 years will improve the overall quality of life by finding new approaches to persistent problems. We will use these adaptive algorithmic tools to explore whole new domains in every industry and field of study: materials science, biotech, medicine, agriculture, engineering, energy, transportation and more. … This goes beyond computability into human relationships. AIs are beginning to understand and speak the human language of emotion. The potential of affective computing ranges from productivity-increasing adaptive interfaces, to ‘pre-crime’ security monitoring of airports and other gathering places, to companion ‘pets’ which monitor their aging owners and interact with them in ways that improve their health and disposition. Will there be unseen dangers or consequences? Definitely. That is our pattern with our tools. We invent them, use them to improve our lives and then refine them when we find problems. AI is no different.”
Ashok Goel, director of the human-centered computing Ph.D. program at Georgia Tech, wrote, “Human-AI interaction will be multimodal: We will directly converse with AIs, for example. However, much of the impact of AI will come in enhancing human-human interaction across both space (we will be networked with others) and time (we will have access to all our previously acquired knowledge). This will aid, augment and amplify individual and collective human intelligence in unprecedented and powerful ways.”
David Cake, an leader with Electronic Frontiers Australia and vice-chair of the ICANN GNSO Council, wrote, “In general, machine learning and related technologies have the capacity to greatly reduce human error in many areas where it is currently very problematic and make available good, appropriately tailored advice to people to whom it is currently unavailable, in literally almost every field of human endeavour.”
Fred Baker, an independent networking technologies consultant, longtime leader in the Internet Engineering Task Force and engineering fellow with Cisco, commented, “In my opinion, developments have not been ‘out of control,’ in the sense that the creation of ‘Terminator’s’ Skynet or the HAL 9000 computer might depict them. Rather, we have learned to automate processes in which neural networks have been able to follow data to its conclusion (which we call ‘big data’) unaided and uncontaminated by human intuition, and sometimes the results have surprised us. These remain, and in my opinion will remain, to be interpreted by human beings and used for our purposes.”
Bob Frankston, software innovation pioneer and technologist based in North America, wrote, “It could go either way. AI could be a bureaucratic straitjacket and tool of surveillance. I’m betting that machine learning will be like the X-ray in giving us the ability to see new wholes and gain insights.”
Perry Hewitt, a marketing, content and technology executive, wrote, “Today, voice-activated technologies are an untamed beast in our homes. Some 16% of Americans have a smart speaker, and yet they are relatively dumb devices: They misinterpret questions, offer generic answers and, to the consternation of some, are turning our kids into a**holes. I am bullish on human-machine interactions developing a better understanding of and improving our daily routines. I think in particular of the working parent, often although certainly not exclusively a woman, who carries so much information in their head. What if a human-machine collaboration could stock the house with essentials, schedule the pre-camp pediatrician appointments and prompt drivers for the alternate-side parking/street cleaning rules. The ability for narrow AI to assimilate new information (the bus is supposed to come at 7:10 but a month into the school year is known to actually come at 7:16) could keep a family connected and informed with the right data, and reduce the mental load of household management.”
John McNutt, a professor in the school of public policy and administration at the University of Delaware, responded, “Throwing out technology because there is a potential downside is not how human progress takes place. In public service, a turbulent environment has created a situation where knowledge overload can seriously degrade our ability to do the things that are essential to implement policies and serve the public good. AI can be the difference between a public service that works well and one that creates more problems than it solves.”
Randy Marchany, chief information security officer at Virginia Tech and director of Virginia Tech’s IT Security Laboratory, said, “AI-human interaction in 2030 will be in its ‘infancy’ stage. AI will need to go to ‘school’ in a manner similar to humans. They will amass large amounts of data collected by various sources but need ‘ethics’ training to make good decisions. Just as kids are taught a wide variety of info and some sort of ethics (religion, social manners, etc.), AI will need similar training. Will AI get the proper training? Who decides the training content?”
Robert Stratton, cybersecurity expert, said, “While there is widespread acknowledgement in a variety of disciplines of the potential benefits of machine learning and artificial intelligence technologies, progress has been tempered by their misapplication. Part of data science is knowing the right tool for a particular job. As more-rigorous practitioners begin to gain comfort and apply these tools to other corpora it’s reasonable to expect some significant gains in efficiency, insight or profitability in many fields. This may not be visible to consumers except through increased product choice, but it may include everything from drug discovery to driving.”
A data analyst for an organization developing marketing solutions said, “Assuming that policies are in place to prevent the abuse of AI and programs are in place to find new jobs for those who would be career-displaced, there is a lot of potential in AI integration. By 2030, most AI will be used for marketing purposes and be more annoying to people than anything else as they are bombarded with personalized ads and recommendations. The rest of AI usage will be its integration into more tedious and repetitive tasks across career fields. Implementing AI in this fashion will open up more time for humans to focus on long-term and in-depth tasks that will allow further and greater societal progression. For example, AI can be trained to identify and codify qualitative information from surveys, reviews, articles, etc., far faster and in greater quantities than even a team of humans can. By having AI perform these tasks, analysts can spend more time parsing the data for trends and information that can then be used to make more-informed decisions faster and allow for speedier turn-around times. Minor product faults can be addressed before they become widespread, scientists can generate semiannual reports on environmental changes rather than annual or biannual.”
Helena Draganik, a professor at the University of Gdansk in Poland, responded, “AI will not change humans. It will change the relations between them because it can serve as an interpreter of communication. It will change our habits (as an intermediation technology). AI will be a great commodity. It will help in cases of health problems (diseases). It will also generate a great ‘data industry’ (big data) market and a lack of anonymity and privacy. Humanity will more and more depend on energy/electricity. These factors will create new social, cultural, security and political problems.”
There are those who think there won’t be much change by 2030.
Christine Boese, digital strategies professional, commented, “I believe it is as William Gibson postulated, ‘The future is already here, it just not very evenly distributed.’ What I know from my work in user-experience design and in exposure to many different Fortune 500 IT departments working in big data and analytics is that the promise and potential of AI and machine learning is VASTLY overstated. There has been so little investment in basic infrastructure, entire chunks of our systems won’t even be interoperable. The AI and machine learning code will be there, in a pocket here, a pocket there, but system-wide, it is unlikely to be operating reliably as part of the background radiation against which many of us play and work online.”
An anonymous respondent wrote, “While various deployments of new data science and computation will help firms cut costs, reduce fraud and support decision-making that involves access to more information than an individual can manage, organisations, professions, markets and regulators (public and private) usually take many more than 12 years to adapt effectively to a constantly changing set of technologies and practices. This generally causes a decline in service quality, insecurity over jobs and investments, new monopoly businesses distorting markets and social values, etc. For example, many organisations will be under pressure to buy and implement new services, but unable to access reliable market information on how to do this, leading to bad investments, distractions from core business, and labour and customer disputes.”
Mario Morino, chairman of the Morino Institute and co-founder of Venture Philanthropy Partners, commented, “While I believe AI/ML will bring enormous benefits, it may take us several decades to navigate through the disruption and transition they will introduce on multiple levels.”
Daniel Berninger, an internet pioneer who led the first VoIP deployments at Verizon, HP and NASA, currently founder at Voice Communication Exchange Committee (VCXC), said, “The luminaries claiming artificial intelligence will surpass human intelligence and promoting robot reverence imagine exponentially improving computation pushes machine self-actualization from science fiction into reality. The immense valuations awarded Google, Facebook, Amazon, Tesla, et al., rely on this machine-dominance hype to sell infinite scaling. As with all hype, pretending reality does not exist does not make reality go away. Moore’s Law does not concede the future to machines, because human domination of the planet does not owe to computation. Any road map granting machines self-determination includes ‘miracle’ as one of the steps. You cannot turn a piece of wood into a real boy. AI merely ‘models’ human activity. No amount of improvement in the development of these models turns the ‘model’ into the ‘thing.’ Robot reverence attempts plausibility by collapsing the breadth of human potential and capacities. It operates via ‘denialism’ with advocates disavowing the importance of anything they cannot model. In particular, super AI requires pretending human will and consciousness do not exist. Human beings remain the source of all intent and the judge of all outcomes. Machines provide mere facilitation and mere efficiency in the journey from intent to outcome. The dehumanizing nature of automation and the diseconomy of scale of human intelligence is already causing headaches that reveal another AI Winter arriving well before 2030.”
Paul Kainen, futurist and director of the Lab for Visual Mathematics at Georgetown University, commented, “Quantum cat here: I expect complex superposition of strong positive, negative and null as typical impact for AI. For the grandkids’ sake, we must be positive!”
The following one-liners from anonymous respondents also tie into AI in 2030:

An Internet Hall of Fame member wrote, “You’ll talk to your digital assistant in a normal voice and it will just be there – it will often anticipate your needs, so you may only need to talk to it to correct or update it.”
The director of a cognitive research group at one of the world’s top AI and large-scale computing companies predicted that by 2030, “Smartphone-equivalent devices will support true natural-language dialog with episodic memory of past interactions. Apps will become low-cost digital workers with basic commonsense reasoning.”
Another Internet Hall of Fame member said, “The equivalent of the ‘Star Trek’ universal translator will become practical, enabling travelers to better interact with people in countries they visit, facilitate online discussions across language barriers, etc.”
An Internet of Things researcher commented, “We need to balance between human emotions and machine intelligence – can machines be emotional? – that’s the frontier we have to conquer.”
An anonymous respondent wrote, “2030 is still quite possibly before the advent of human-level AI. During this phase AI is still mostly augmenting human efforts – increasingly ubiquitous, optimizing the systems that surround us and being replaced when their optimization criteria are not quite perfect – rather than pursuing those goals programmed into them, whether we find the realization of those goals desirable or not.”
A research scientist who works for Google said, “Things will be better, although many people are deeply worried about the effects of AI.”
An ARPANET and internet pioneer wrote, “The kind of AI we are currently able to build is good for data analysis but far, far away from ‘human’ levels of performance; the next 20 years won’t change this, but we will have valuable tools to help analyze and control our world.”
An artificial intelligence researcher working for one of the world’s most powerful technology companies wrote, “AI will enhance our vision and hearing capabilities, remove language barriers, reduce time to find information we care about and help in automating mundane activities.”
A manager with a major digital innovation company said, “Couple the information storage with the ever-increasing ability to rapidly search and analyze that data, and the benefits to augmenting human intelligence with this processed data will open up new avenues of technology and research throughout society.”

Other anonymous respondents commented:

“AI will help people to manage the increasingly complex world we are forced to navigate. It will empower individuals to not be overwhelmed.”
“AI will reduce human error in many contexts: driving, workplace, medicine and more.”
“In teaching it will enhance knowledge about student progress and how to meet individual needs; it will offer guidance options based on the unique preferences of students that can guide learning and career goals.”
“2030 is only 12 years from now, so I expect that systems like Alexa and Siri will be more helpful but still of only medium utility.”
“AI will be a useful tool; I am quite a ways away from fearing SkyNet and the rise of the machines.”
“AI will produce major benefits in the next 10 years, but ultimately the question is one of politics: Will the world somehow manage to listen to the economists, even when their findings are uncomfortable?”
“I strongly believe that an increasing use of numerical control will improve the lives of people in general.”
“AI will help us navigate choices, find safer routes and avenues for work and play, and help make our choices and work more consistent.”
“Many factors will be at work to increase or decrease human welfare, and it will be difficult to separate them.”

AI will optimize and augment people’s lives
The hopeful experts in this sample generally expect that AI will work to optimize, augment and improve human activities and experiences. They say it will save time and it will save lives via health advances and the reduction of risks and of poverty. They expect it will spur innovation and broaden opportunities, increase the value of human-to-human experiences, augment humans and increase individuals’ overall satisfaction with life.
Clay Shirky, writer and consultant on the social and economic effects of internet technologies and vice president at New York University, said, “All previous forms of labor-saving devices, from the level to the computer, have correlated with increased health and lifespan in the places that have adopted them.”
Jamais Cascio, research fellow at the Institute for the Future, wrote, “Although I do believe that in 2030 AI will have made our lives better, I suspect that popular media of the time will justifiably highlight the large-scale problems: displaced workers, embedded bias and human systems being too deferential to machine systems. But AI is more than robot soldiers, autonomous cars or digital assistants with quirky ‘personalities.’ Most of the AI we will encounter in 2030 will be in-the-walls, behind-the-scenes systems built to adapt workspaces, living spaces and the urban environment to better suit our needs. Medical AI will keep track of medication and alert us to early signs of health problems. Environmental AI will monitor air quality, heat index and other indicators relevant to our day’s tasks. Our visual and audio surroundings may be altered or filtered to improve our moods, better our focus or otherwise alter our subconscious perceptions of the world. Most of this AI will be functionally invisible to us, as long as it’s working properly. The explicit human-machine interface will be with a supervisor system that coordinates all of the sub-AI – and undoubtedly there will be a lively business in creating supervisor systems with quirky personalities.”
Mike Meyer, chief information officer at Honolulu Community College, wrote, “Social organizations will be increasingly administered by AI/ML systems to ensure equity and consistency in provisioning of services to the population. The steady removal of human emotion-driven discrimination will rebalance social organizations creating true equitable opportunity to all people for the first time in human history. People will be part of these systems as censors, in the old imperial Chinese model, providing human emotional intelligence where that is needed to smooth social management. All aspects of human existence will be affected by the integration of AI into human societies. Historically this type of base paradigmatic change is both difficult and unstoppable. The results will be primarily positive but will produce problems both in the process of change and in totally new types of problems that will result from the ways that people do adapt the new technology-based processes.”
Mark Crowley, an assistant professor, expert in machine learning and core member of the Institute for Complexity and Innovation at the University of Waterloo in Ontario, Canada, wrote, “While driving home on a long commute from work the human will be reading a book in the heads-up screen of the windshield. The car will be driving autonomously on the highway for the moment. The driver will have an idea to note down and add to a particular document; all this will be done via voice. In the middle of this a complicated traffic arrangement will be seen approaching via other networked cars. The AI will politely interrupt the driver, put away the heads-up display and warn the driver they may need to take over in the next 10 seconds or so. The conversation will be flawless and natural, like Jarvis in ‘Avengers,’ even charming. But it will be tasks-focused to the car, personal events, notes and news.”
Theodore Gordon, futurist, management consultant and co-founder of the Millennium Project, commented, “There will be ups and downs, surely, but the net is, I believe, good. The most encouraging uses of AI will be in early warning of terror activities, incipient diseases and environmental threats and in improvements in decision-making.”
Yvette Wohn, director of the Social Interaction Lab and expert on human-computer interaction at the New Jersey Institute of Technology, said, “One area in which artificial intelligence will become more sophisticated will be in its ability to enrich the quality of life so that the current age of workaholism will transition into a society where leisure, the arts, entertainment and culture are able to enhance the well-being of society in developed countries and solve issues of water production, food growth/distribution and basic health provision in developing countries.”
Ken Goldberg, distinguished chair in engineering, director of AUTOLAB’s and CITRIS’ “people and robots” initiative, and founding member of the Berkeley Artificial Intelligence Research Lab at the University of California, Berkeley, said, “As in the past 50+ years, AI will be combined with IA (intelligence augmentation) to enhance humans’ ability to work. One example might be an AI-based ‘Devil’s Advocate’ that would challenge my decisions with insightful questions (as long as I can turn it off periodically).”
Rich Ling, a professor of media technology at Nanyang Technological University, responded, “The ability to address complex issues and to better respond to and facilitate the needs of people will be the dominant result of AI.”
An anonymous respondent wrote, “There will be an explosive increase in the number of autonomous cognitive agents (e.g., robots), and humans will interact more and more with them, being unaware, most of the time, if it is interactivity with a robot or with another human. This will increase the number of personal assistants and the level of service.”
Fred Davis, mentor at Runway Incubator in San Francisco, responded, “As daily a user of the Google Assistant on my phone and both Google Home and Alexa, I feel like AI has already been delivering significant benefits to my daily life for a few years. My wife and I take having an always-on omnipresent assistant on hand for granted at this point. Google Home’s ability to tell us apart and even respond with different voices is a major step forward in making computers people-literate, rather than the other way around. There’s always a concern about privacy, but so far it hasn’t caused us any problems. Obviously, this could change and instead of a helpful friend I might look at these assistants as creepy strangers. Maintaining strict privacy and security controls is essential for these types of services.”
Andrew Tutt, an expert in law and author of “An FDA for Algorithms,” which called for “critical thought about how best to prevent, deter and compensate for the harms that they cause,” said, “AI will be absolutely pervasive and absolutely seamless in its integration with everyday life. It will simply become accepted that AI are responsible for ever-more-complex and ever-more-human tasks. By 2030, it will be accepted that when you wish to hail a taxi the taxi will have no driver – it will be an autonomously driven vehicle. Robots will be responsible for more-dynamic and complex roles in manufacturing plants and warehouses. Digital assistants will play an important and interactive role in everyday interactions ranging from buying a cup of coffee to booking a salon appointment. It will no longer be unexpected to call a restaurant to book a reservation, for example, and speak to a ‘digital’ assistant who will pencil you in. These interactions will be incremental but become increasingly common and increasingly normal. My hope is that the increasing integration of AI into everyday life will vastly increase the amount of time that people can devote to tasks they find meaningful.”
L. Schomaker, professor at the University of Groningen and scientific director of the Artificial Intelligence and Cognitive Engineering (ALICE) research institute, said, “In the 1990s, you went to a PC on a desktop in a room in your house. In the 2010s you picked a phone from your pocket and switched it on. By 2030 you will be online 24/7 via miniature devices such as in-ear continuous support, advice and communications.”
Michael Wollowski, associate professor of computer science and software engineering at Rose-Hulman Institute of Technology and expert in the Internet of Things, diagrammatic systems, and artificial intelligence, wrote, “Assuming that industry and government are interested in letting the consumer choose and influence the future, there will be many fantastic advances of AI. I believe that AI and the Internet of Things will bring about a situation in which technology will be our guardian angel. For example, self-driving cars will let us drive faster than we ever drove before, but they will only let us do things that they can control. Since computers have much better reaction time than people, it will be quite amazing. Similarly, AI and the Internet of Things will let us conduct our lives to the fullest while ensuring that we live healthy lives. Again, it is like having a guardian angel that lets us do things, knowing they can save us from stupidity.”
Steve King, partner at Emergent Research, said, “2030 is less than 12 years away. So … the most likely scenario is AI will have a modest impact on the lives of most humans over this time frame. Having said that, we think the use of AI systems will continue to expand, with the greatest growth coming from systems that augment and complement human capabilities and decision-making. This is not to say there won’t be negative impacts from the use of AI. Jobs will be replaced, and certain industries will be disrupted. Even scarier, there are many ways AI can be weaponized. But like most technological advancements, we think the overall impact of AI will be additive – at least over the next decade or so.”
Vassilis Galanos, a Ph.D. student and teaching assistant actively researching future human-machine symbiosis at the University of Edinburgh, commented, “2030 is not that far away, so there is no room for extremely utopian/dystopian hopes and fears. … Given that AI is already used in everyday life (social-media algorithms, suggestions, smartphones, digital assistants, health care and more), it is quite probable that humans will live in a harmonious co-existence with AI as much as they do now – to a certain extent – with computer and internet technologies.”
Charlie Firestone, communications and society program executive director and vice president at the Aspen Institute, commented, “I remain optimistic that AI will be a tool that humans will use, far more widely than today, to enhance quality of life such as medical remedies, education and the environment. For example, the AI will help us to conserve energy in homes and in transportation by identifying exact times and temperatures we need, identifying sources of energy that will be the cheapest and the most efficient. There certainly are dire scenarios, particularly in the use of AI for surveillance, a likely occurrence by 2030. I am hopeful that AI and other technologies will identify new areas of employment as it eliminates many jobs.”
Pedro U. Lima, an associate professor of computer science at Instituto Superior Técnico in Lisbon, Portugal, said, “Overall, I see AI-based technology relieving us from repetitive and/or heavy and/or dangerous tasks, opening new challenges for our activities. I envisage autonomous mobile robots networked with a myriad of other smart devices, helping nurses and doctors at hospitals in daily activities, working as a ‘third hand’ and (physical and emotional) support to patients. I see something similar happening in factories, where networked robot systems will help workers on their tasks, relieving them from heavy duties.”
John Laird, a professor of computer science and engineering at the University of Michigan, responded, “There will be a continual off-loading of mundane intellectual and physical tasks on to AI and robotic systems. In addition to helping with everyday activities, it will significantly help the mentally and physically impaired and disabled. There will also be improvements in customized/individualized education and training of humans, and conversely, the customization of AI systems by everyday users. We will be transitioning from current programming practices to user customization. Automated driving will be a reality, eliminating many deaths but also having significant societal changes.”
Steven Polunsky, director of the Alabama Transportation Policy Research Center at the University of Alabama, wrote, “AI will allow public transportation systems to better serve existing customers by adjusting routes, travel times and stops to optimize service. New customers will also see advantages. Smart transportation systems will allow public transit to network with traffic signals and providers of ‘last-mile’ trips to minimize traffic disruption and inform decision making about modal (rail, bus, mobility-on-demand) planning and purchasing.”
Sanjiv Das, a professor of data science and finance at Santa Clara University, responded, “AI will enhance search to create interactive reasoning and analytical systems. Search engines today do not know ‘why’ we want some information and hence cannot reason about it. They also do not interact with us to help with analysis. An AI system that collects information based on knowing why it is needed and then asks more questions to refine its search would be clearly available well before 2030. These ‘search-thinking bots’ will also write up analyses based on parameters elicited from conversation and imbue these analyses with different political (left/right) and linguistic (aggressive/mild) slants, chosen by the human, using advances in language generation, which are already well under way. These ‘intellectual’ agents will become companions, helping us make sense of our information overload. I often collect files of material on my cloud drive that I found interesting or needed to read later, and these agents would be able to summarize and engage me in a discussion of these materials, very much like an intellectual companion. It is unclear to me if I would need just one such agent, though it seems likely that different agents with diverse personalities may be more interesting! As always, we should worry what the availability of such agents might mean for normal human social interaction, but I can also see many advantages in freeing up time for socializing with other humans as well as enriched interactions, based on knowledge and science, assisted by our new intellectual companions.”
Lawrence Roberts, designer and manager of ARPANET, the precursor to the internet and Internet Hall of Fame member, commented, “AI voice recognition, or text, with strong context understanding and response will allow vastly better access to website, program documentation, voice call answering, and all such interactions will greatly relieve user frustration with getting information. It will mostly provide service where no or little human support is being replaced as it is not available today in large part. For example, finding and/or doing a new or unused function of the program or website one is using. Visual, 3D-space-recognition AI to support better-than-human robot activity including vehicles, security surveillance, health scans and much more.”
Christopher Yoo, a professor of law, communication and computer and information science at the University of Pennsylvania Law School, responded, “AI is good at carrying out tasks that follow repetitive patterns. In fact, AI is better than humans. Shifting these functions to machines will improve performance. It will also allow people to shift their efforts to high-value-added and more-rewarding directions, an increasingly critical consideration in developing world countries where population is declining. Research on human-computer interaction (HCI) also reveals that AI-driven pattern recognition will play a critical role in expanding humans’ ability to extend the benefits of computerization. HCI once held that our ability to gain the benefit from computers would be limited by the total amount of time people can spend sitting in front of a screen and inputting characters through a keyboard. The advent of AI-driven HCI will allow that to expand further and will reduce the amount of customization that people will have to program in by hand. At the same time, AI is merely a tool. All tools have their limits and can be misused. Even when humans are making the decisions instead of machines, blindly following the results of a protocol without exercising any judgment, can have disastrous results. Future applications of AI will thus likely involve both humans and machines if they are to fulfill their potential.”
Joseph Konstan, distinguished professor of computer science specializing in human-computer interaction and AI at the University of Minnesota, predicted, “Widespread deployment of AI has immense potential to help in key areas that affect a large portion of the world’s population, including agriculture, transportation (more efficiently getting food to people) and energy. Even as soon as 2030, I expect we’ll see substantial benefits for many who are today disadvantaged, including the elderly and physically handicapped (who will have greater choices for mobility and support) and those in the poorest part of the world.”
The future of work:
Some predict new work will emerge or solutions will be found; others fear massive job losses and an unraveling of society
A number of expert insights on this topic were shared earlier in this report. These additional observations add to the discussion of hopes and concerns about the future of human jobs. This segment starts with comments from those who are hopeful that the job situation and related social issues will turn out well. It is followed by statements from those who are pessimistic.
Respondents who were positive about the future of AI and work
Bob Metcalfe, Internet Hall of Fame member, co-inventor of Ethernet, founder of 3Com and now professor of innovation and entrepreneurship at the University of Texas at Austin, said, “Pessimists are often right, but they never get anything done. All technologies come with problems, sure, but … generally, they get solved. The hardest problem I see is the evolution of work. Hard to figure out. Forty percent of us used to know how to milk cows, but now less than 1% do. We all used to tell elevator operators which floor we wanted, and now we press buttons. Most of us now drive cars and trucks and trains, but that’s on the verge of being over. AIs are most likely not going to kill jobs. They will handle parts of jobs, enhancing the productivity of their humans.”
Stowe Boyd, founder and managing director at Work Futures, said, “There is a high possibility that unchecked expansion of AI could rapidly lead to widespread unemployment. My bet is that governments will step in to regulate the spread of AI, to slow the impacts of this phenomenon as a result of unrest by the mid 2020s. That regulation might include, for example, not allowing AIs to serve as managers of people in the workplace, but only to augment the work of people on a task or process level. So, we might see high degrees of automation in warehouses, but a human being would be ‘in charge’ in some sense. Likewise, fully autonomous freighters might be blocked by regulations.”
An anonymous respondent wrote, “Repeatedly throughout history people have worried that new technologies would eliminate jobs. This has never happened, so I’m very skeptical it will this time. Having said that, there will be major short-term disruptions in the labor market and smart governments should begin to plan for this by considering changes to unemployment insurance, universal basic income, health insurance, etc. This is particularly the case in America, where so many benefits are tied to employment. I would say there is almost zero chance that the U.S. government will actually do this, so there will be a lot of pain and misery in the short and medium term, but I do think ultimately machines and humans will peacefully coexist. Also, I think a lot of the projections on the use of AI are ridiculous. Regardless of the existence of the technology, cross-state shipping is not going to be taken over by automated trucks any time soon because of legal and ethical issues that have not been worked out.”
Steven Miller, vice provost and professor of information systems at Singapore Management University, said, “It helps to have a sense of the history of technological change over the past few hundred years (even longer). Undoubtedly, new ways of using machines and new machine capabilities will be used to create economic activities and services that were either a) not previously possible, or b) previously too scarce and expensive, and now can be plentiful and inexpensive. This will create a lot of new activities and opportunities. At the same time, we know some existing tasks and jobs with a high proportion of those tasks will be increasingly automated. So we will simultaneously have both new opportunity creation as well as technological displacement. Even so, the long-term track record shows that human societies keep finding ways of creating more and more economically viable jobs. Cognitive automation will obviously enhance the realms of automation, but even with tremendous progress in this technology, there are and will continue to be limits. Humans have remarkable capabilities to deal with and adapt to change, so I do not see the ‘end of human work.’ The ways people and machines combine together will change – and there will be many new types of human-machine symbiosis. Those who understand this and learn to benefit from it will proposer.”
Henry E. Brady, dean of the Goldman School of Public Policy at the University of California, Berkeley, wrote, “AI can replace people in jobs that require sophisticated and accurate pattern matching – driving, diagnoses based upon medical imaging, proofreading and other areas. There is also the fact that in the past technological change has mostly led to new kinds of jobs rather than the net elimination of jobs. Furthermore, I also believe that there may be limits to what AI can do. It is very good at pattern matching, but human intelligence goes far beyond pattern matching and it is not clear that computers will be able to compete with humans beyond pattern matching. It also seems clear that even the best algorithms will require constant human attention to update, check and revise them.”
Geoff Livingston, author and futurist, commented, “The term AI misleads people. What we should call the trend is machine learning or algorithms. ‘Weak’ AI as it is called – today’s AI – reduces repetitive tasks that most people find mundane. This in turn produces an opportunity to escape the trap of the proletariat, being forced into monotonous labor to earn a living. Instead of thinking of the ‘Terminator,’ we should view the current trend as an opportunity to seek out and embrace the tasks that we truly love, including more creative pursuits. If we embrace the inevitable evolution of technology to replace redundant tasks, we can encourage today’s youth to pursue more creative and strategic pursuits. Further, today’s workers can learn how to manage machine learning or embrace training to pursue new careers that they may enjoy more. My fear is that many will simply reject change and blame technology, as has often been done. One could argue much of today’s populist uprising we are experiencing globally finds its roots in the current displacements caused by machine learning as typified by smart manufacturing. If so, the movement forward will be troublesome, rife with dark bends and turns that we may regret as cultures and countries.”
Marek Havrda, director at NEOPAS and strategic adviser for the GoodAI project, a private research and development company based in Prague that focuses on the development of artificial general intelligence and AI applications, explained the issue from his point of view, “The development and implementation of artificial intelligence has brought about questions of the impact it will have on employment. Machines are beginning to fill jobs that have been traditionally reserved for humans, such as driving a car or prescribing medical treatment. How these trends may unfold is a crucial question. We may expect the emergence of ‘super-labour,’ a labour defined by super-high-added-value of human activity due to augmentation by AI. Apart from the ability to deploy AI, super-labour will be characterised by creativity and the ability to co-direct and supervise safe exploration of business opportunities together with perseverance in attaining defined goals. An example may be that by using various online, AI gig workers (and maybe several human gig workers), while leveraging AI to its maximum potential … at all aspects from product design to marketing and after-sales care, three people could create a new service and ensure its smooth delivery for which a medium-size company would be needed today. We can expect growing inequalities between those who have access and are able to use technology and those who do not. However, it seems more important how big a slice of the AI co-generated ‘pie’ is accessible to all citizens in absolute terms (e.g., having enough to finance public service and other public spending) which would make everyone better off than in pre-AI age, than the relative inequalities.”
Yoram Kalman, an associate professor at the Open University of Israel and member of The Center for Internet Research at the University of Haifa, wrote, “In essence, technologies that empower people also improve their lives. I see that progress in the area of human-machine collaboration empowers people by improving their ability to communicate and to learn, and thus my optimism. I do not fear that these technologies will take the place of people, since history shows that again and again people used technologies to augment their abilities and to be more fulfilled. Although in the past, too, it seemed as if these technologies would leave people unemployed and useless, human ingenuity and the human spirit always found new challenges that could best be tackled by humans.”
Thomas H. Davenport, distinguished professor of information technology and management at Babson College and fellow of the MIT Initiative on the Digital Economy, responded, “So far, most implementations of AI have resulted in some form of augmentation, not automation. Surveys of managers suggest that relatively few have automation-based job loss as the goal of their AI initiatives. So while I am sure there will be some marginal job loss, I expect that AI will free up workers to be more creative and to do more unstructured work.”
Yvette Wohn, director of the Social Interaction Lab and expert on human-computer interaction at the New Jersey Institute of Technology, commented, “Artificial intelligence will be naturally integrated into our everyday lives. Even though people are concerned about computers replacing the jobs of humans the best-case scenario is that technology will be augmenting human capabilities and performing functions that humans do not like to do. Smart farms and connected distribution systems will hopefully eliminate urban food deserts and enable food production in areas not suited for agriculture. Artificial intelligence will also become better at connecting people and provide immediate support to people who are in crisis situations.”
A principal architect for a major global technology company responded, “AI is a prerequisite to achieving a post-scarcity world, in which people can devote their lives to intellectual pursuits and leisure rather than to labor. The first step will be to reduce the amount of labor required for production of human necessities. Reducing tedium will require changes to the social fabric and economic relationships between people as the demand for labor shrinks below the supply, but if these challenges can be met then everyone will be better off.”
Tom Hood, an expert in corporate accounting and finance, said, “By 2030, AI will stand for Augmented Intelligence and will play an ever-increasing role in working side-by-side with humans in all sectors to add its advanced and massive cognitive and learning capabilities to critical human domains like medicine, law, accounting, engineering and technology. Imagine a personal bot powered by artificial intelligence working by your side (in your laptop or smartphone) making recommendations on key topics by providing up-to-the-minute research or key pattern recognition and analysis of your organization’s data? One example is a CPA in tax given a complex global tax situation amid constantly changing tax laws in all jurisdictions who would be able to research and provide guidance on the most complex global issues in seconds. It is my hope for the future of artificial intelligence in 2030 that we will be augmenting our intelligence with these ‘machines.’”
A professor of computer science expert in systems who works at a major U.S. technological university wrote, “By 2030, we should expect advances in AI, networking and other technologies enabled by AI and networks, e.g., the growing areas of persuasive and motivational technologies, to improve the workplace in many ways beyond replacing humans with robots.”
The following one-liners from anonymous respondents express a bright future for human jobs:

“History of technology shows that the number of new roles and jobs created will likely exceed the number of roles and jobs that are destroyed.”
“AI will not be competing with humanity but augmenting it for the better.”
“We make a mistake when we look for direct impact without considering the larger picture – we worry about a worker displaced by a machine rather than focus on broader opportunities for a better-trained and healthier workforce where geography or income no longer determine access not just to information but to relevant and appropriate information paths.”
“AI can significantly improve usability and thus access to the benefits of technology. Many powerful technical tools today require detailed expertise, and AI can bring more of those to a larger swath of the population.”

Respondents who have fears about AI’s impact on work
A section earlier in this report shared a number of key experts’ concerns about the potential negative impact of AI on the socioeconomic future if steps are not taken soon to begin to adjust to a future with far fewer jobs for humans. Many additional respondents to this canvassing shared fears about this.
Wout de Natris, an internet cybercrime and security consultant based in Rotterdam, Netherlands, wrote, “Hope: Advancement in health care, education, decision-making, availability of information, higher standards in ICT-security, global cooperation on these issues, etc. Fear: Huge segments of society, especially the middle classes who carry society in most ways, e.g., through taxes, savings and purchases, will be rendered jobless through endless economic cuts by industry, followed by governments due to lower tax income. Hence all of society suffers. Can governments and industry refrain from an overkill of surveillance? Otherwise privacy values keep declining, leading to a lower quality of life.”
Jonathan Taplin, director emeritus at the University of Southern California’s Annenberg Innovation Lab, wrote, “My fear is that the current political class is completely unprepared for the disruptions that AI and robotics applied at scale will bring to our economy. While techno-utopians point to universal basic income as a possible solution to wide-scale unemployment, there is no indication that anyone in politics has an appetite for such a solution. And because I believe that meaningful work is essential to human dignity, I’m not sure that universal basic income would be helpful in the first place.”
Alex Halavais, an associate professor of social technologies at Arizona State University, wrote, “AI is likely to rapidly displace many workers over the next 10 years, and so there will be some potentially significant negative effects at the social and economic level in the short run.”
Uta Russmann, professor in the department of communication at FHWien der WKW University of Applied Sciences for Management & Communication, said, “Many people will not be benefitting from this development, as robots will do their jobs. Blue-collar workers, people working in supermarkets stacking shelves, etc., will not be needed less, but the job market will not offer them any other possibilities. The gap between rich and poor will increase as the need for highly skilled and very well-paid people increases and the need for less skilled workers will decrease tremendously.”
Ross Stapleton-Gray, principal at Stapleton-Gray and Associates, an information technology and policy consulting firm, commented, “Human-machine interaction could be for good or for ill. It will be hugely influenced by decisions on social priorities. We may be at a tipping point in recognizing that social inequities need to be addressed, so, say, a decreased need for human labor due to AI will result in more time for leisure, education, etc., instead of increasing wealth inequity.”
Aneesh Aneesh, author of “Global Labor: Algocratic Modes of Organization” and professor at the University of Wisconsin, Milwaukee, responded, “Just as automation left large groups of working people behind even as the United States got wealthier as a country, it is quite likely that AI systems will automate the service sector in a similar way. Unless the welfare state returns with a vengeance, it is difficult to see the increased aggregate wealth resulting in any meaningful gains for the bottom half of society.”
Alper Dincel of T.C. Istanbul Kultur University in Turkey, wrote, “Unqualified people won’t find jobs, as machines and programs take over easy work in the near future. Machines will also solve performance problems. There is no bright future for most people if we don’t start to try finding solutions.”
Jason Abbott, professor and director at the Center for Asian Democracy at University of Louisville, said, “AI is likely to create significant challenges to the labor force as previously skilled (semi-skilled) jobs are replaced by AI – everything from AI in trucks and distribution to airlines, logistics and even medical records and diagnoses.”
Kenneth R. Fleischmann, an associate professor at the University of Texas at Austin’s School of Information, responded, “In corporate settings, I worry that AI will be used to replace human workers to a disproportionate extent, such that the net economic benefit of AI is positive, but that economic benefit is not distributed equally among individuals, with a smaller number of wealthy individuals worldwide prospering, and a larger number of less wealthy individuals worldwide suffering from fewer opportunities for gainful employment.”
Gerry Ellis, founder and digital usability and accessibility consultant at Feel The BenefIT, responded, “Technology has always been far more quickly developed and adopted in the richer parts of the world than in the poorer regions where new technology is generally not affordable. AI cannot be taken as a stand-alone technology but in conjunction with other converging technologies like augmented reality, robotics, virtual reality, the Internet of Things, big data analysis, etc. It is estimated that around 80% of jobs that will be done in 2030 do not exist yet. One of the reasons why unskilled and particularly repetitive jobs migrate to poor countries is because of cheap labour costs, but AI combined with robotics will begin to do many of these jobs. For all of these reasons combined, the large proportion of the earth’s population that lives in the under-developed and developing world is likely to be left behind by technological developments. Unless the needs of people with disabilities are taken into account when designing AI related technologies, the same is true for them (or I should say ‘us,’ as I am blind).”
Karen Oates, director of workforce development and financial stability for La Casa de Esperanza, commented, “Ongoing increases in the use of AI will not benefit the working poor and low-to-middle-income people. Having worked with these populations for 10 years I’ve already observed many of these people losing employment when robots and self-operating forklifts are implemented. Although there are opportunities to program and maintain these machines, realistically people who have the requisite knowledge and education will fill those roles. The majority of employers will be unwilling to invest the resources to train employees unless there is an economic incentive from the government to do so. Many lower-wage workers won’t have the confidence to return to school to develop new knowledge/skills when they were unsuccessful in the past. As the use of AI increases, low-wage workers will lose the small niche they hold in our economy.”
Peggy Lahammer, director of health/life sciences at Robins Kaplan LLP and legal market analyst, commented, “Jobs will continue to change and as many disappear new ones will be created. These changes will have an impact on society as many people are left without the necessary skills.”
A European computer science professor expert in machine learning commented, “The social sorting systems introduced by AI will most likely define and further entrench the existing world order of the haves and the have-nots, making social mobility more difficult and precarious given the unpredictability of AI-driven judgements of fit. The interesting problem to solve will be the fact that initial designs of AI will come with built-in imaginaries of what ‘good’ or ‘correct’ constitutes. The level of flexibility designed in to allow for changes in normative perceptions and judgements will be key to ensuring that AI driven-systems support rather than obstruct productive social change.”
Stephen McDowell, a professor of communication at Florida State University and expert in new media and internet governance, commented, “Much of our daily lives is made up of routines and habits that we repeat, and AI could assist in these practices. However, just because some things we do are repetitive does not mean they are insignificant. We draw a lot of meaning from things we do on a daily, weekly or annual basis, whether by ourselves or with others. Cultural practices such as cooking, shopping, cleaning, coordinating and telling stories are crucial parts of building our families and larger communities. Similarly, at work, some of the routines are predictable, but are also how we gain a sense of mastery and expertise in a specific domain. In both these examples, we will have to think about how we define knowledge, expertise, collaboration, and growth and development.”
David Sarokin, author of “Missed Information: Better Information for Building a Wealthier, More Sustainable Future,” commented, “My biggest concern is that our educational system will not keep up with the demands of our modern times. It is doing a poor job of providing the foundations to our students. As more and more jobs are usurped by AI-endowed machines – everything from assembling cars to flipping burgers – those entering the workplace will need a level of technical sophistication that few graduates possess these days.”
Justin Amyx, a technician with Comcast, said, “My worry is automation. Automation occurs usually with mundane tasks that fill low-paying, blue-collar-and-under jobs. Those jobs will disappear – lawn maintenance, truck drivers and fast food, to name a few. Those un-skilled or low-skilled workers will be jobless. Unless we have training programs to take care of worker displacement there will be issues.”
The future of health care:
Great expectations for many lives saved, extended and improved, mixed with worries about data abuses and a divide between ‘the haves and have-nots’
Many of these experts have high hopes for continued incremental advances across all aspects of health care and life extension. They predict a rise in access to various tools, including digital agents that can perform rudimentary exams with no need to visit a clinic, a reduction in medical errors and better, faster recognition of risks and solutions. They also worry over the potential for a widening health care divide between those who can afford cutting-edge tools and treatments and those less privileged. They express concerns about the potential for data abuses such as the denial of insurance or coverage or benefits for select people or procedures.
Leonard Kleinrock, Internet Hall of Fame member and co-director of the first host-to-host online connection and professor of computer science at the University of California, Los Angeles, predicted, “As AI and machine learning improve, we will see highly customized interactions between humans and their health care needs. This mass customization will enable each human to have her medical history, DNA profile, drug allergies, genetic makeup, etc., always available to any caregiver/medical professional that they engage with, and this will be readily accessible to the individual as well. Their care will be tailored to their specific needs and the very latest advances will be able to be provided rapidly after the advances are established. The rapid provision of the best medical treatment will provide great benefits. In hospital settings, such customized information will dramatically reduce the occurrence of medical injuries and deaths due to medical errors. My hope and expectation is that intelligent agents will be able to assess the likely risks and the benefits that ensue from proposed treatments and procedures, far better than is done now by human evaluators, such humans, even experts, typically being poor decision makers in the face of uncertainty. But to bring this about, there will need to be carefully conducted tests and experimentation to assess the quality of the outcomes of AI-based decision making in this field. However, as with any ‘optimized’ system, one must continually be aware of the fragility of optimized systems when they are applied beyond the confines of their range of applicability.”
Kenneth Grady, futurist, founding author of the Algorithmic Society blog and adjunct and advisor at the Michigan State University College of Law, responded, “In the next dozen years, AI will still be moving through a phase where it will augment what humans can do. It will help us sift through, organize and even evaluate the mountains of data we create each day. For example, doctors today still work with siloed data. Each patient’s vital signs, medicines, dosage rates, test results and side effects remain trapped in isolated systems. Doctors must evaluate this data without the benefit of knowing how it compares to the thousands of other patients around the country (or world) with similar problems. They struggle to turn the data into effective treatments by reading research articles and mentally comparing them to each patient’s data. As it evolves, AI will improve the process. Instead of episodic studies, doctors will have near-real-time access to information showing the effects of treatment regimes. Benefits and risks of drug interactions will be identified faster. Novel treatments will become evident more quickly.  Doctors will still manage the last mile, interpreting the analysis generated through AI. This human in the loop approach will remain critical during this phase. As powerful as AI will become, it still will not match humans on understanding how to integrate treatment with values. When will a family sacrifice effectiveness of treatment to prolong quality of life? When two life-threatening illnesses compete, which will the patient want treated first? This will be an important learning phase, as humans understand the limits of AI.”
Charles Zheng, a researcher in machine learning and AI with the National Institute of Mental Health, commented, “In the year 2030, I expect AI will be more powerful than they currently are, but not yet at human level for most tasks. A patient checking into a hospital will be directed to the correct desk by a robot. The receptionist will be aided by software that listens to their conversation with the patient and automatically populates the information fields without needing the receptionist to type the information. Another program cross-references the database in the cloud to check for errors. The patient’s medical images would first be automatically labeled by a computer program before being sent to a radiologist.”
A professor of computer science expert in systems who works at a major U.S. technological university wrote, “By 2030 … physiological monitoring devices (e.g., lower heartbeats and decreasing blood sugar levels) could indicate lower levels of physical alertness. Smart apps could detect those decaying physical conditions (at an individual level) and suggest improvements to the user (e.g., taking a coffee break with a snack). Granted, there may be large-scale problems caused by AI and robots, e.g., massive unemployment, but the recent trends seem to indicate small improvements such as health monitor apps outlined above, would be more easily developed and deployed successfully.”
Kenneth Cukier, author and senior editor at The Economist, commented, “AI will be making more decisions in life, and some people will be uneasy with that. But these are decisions that are more effectively done by machines, such as assessing insurance risk, the propensity to repay a loan or to survive a disease. A good example is health care: Algorithms, not doctors, will be diagnosing many diseases, even if human doctors are still ‘in the loop.’ The benefit is that healthcare can reach down to populations that are today underserved: the poor and rural worldwide.”
Gabor Melli, senior director of engineering for AI and machine learning for Sony PlayStation, responded, “My hope is that by 2030 most of humanity will have ready access to health care and education through digital agents.”
Kate Eddens, research scientist at the Indiana University Network Science Institute, responded, “There is an opportunity for AI to enhance human ability to gain critical information in decision-making, particularly in the world of health care. There are so many moving parts and components to understanding health care needs and deciding how to proceed in treatment and prevention. With AI, we can program algorithms to help refine those decision-making processes, but only when we train the AI tools on human thinking, a tremendous amount of real data and actual circumstances and experiences. There are some contexts in which human bias and emotion can be detrimental to decision-making. For example, breast cancer is over-diagnosed and over-treated. While mammography guidelines have changed to try to reflect this reality, strong human emotion powered by anecdotal experience leaves some practitioners unwilling to change their recommendations based on evidence and advocacy groups reluctant to change their stance based on public outcry. Perhaps there is an opportunity for AI to calculate a more specific risk for each individual person, allowing for a tailored experience amid the broader guidelines. If screening guidelines change to ‘recommended based on individual risk,’ it lessens the burden on both the care provider and the individual. People still have to make their own decisions, but they may be able to do so with more information and a greater understanding of their own risk and reward. This is such a low-tech and simple example of AI, but one in which AI can – importantly – supplement human decision-making without replacing it.”
Angelique Hedberg, senior corporate strategy analyst at RTI International, said, “The greatest advancements and achievements will be in health – physical, mental and environmental. The improvements will have positive trickle-down impacts on education, work, gender equality and reduced inequality. AI will redefine our understanding of health care, optimizing existing processes while simultaneously redefining how we answer questions about what it means to be healthy, bringing care earlier in the cycle due to advances in diagnostics and assessment, i.e. in the future preventative care identifies and initiates treatment for illness before symptoms present. The advances will not be constrained to humans; they will include animals and the built environment. This will happen across the disease spectrum. Advanced ‘omics’ will empower better decisions. There will be a push and a pull by the market and individuals. This is a global story, with fragmented and discontinuous moves being played out over the next decade as we witness wildly different experiments in health across the globe. This future is full of hope for individuals and communities. My greatest hope is for disabled individuals and those currently living with disabilities. I’m excited for communities and interpersonal connections as the work in this future will allow for and increase the value of the human-to-human experiences. Progress is often only seen in retrospect; I hope the speed of exponential change allows everyone to enjoy the benefits of these collaborations.”
An anonymous respondent wrote, “In health care, I hope AI will improve the diagnostics and reduce the number of errors. Doctors cannot recall all the possibilities; they have problems correlating all the symptoms and recognizing the patterns. I hope that in the future patients will be interviewed by computers, which will correlate the described symptoms with results of tests. I hope that with the further development of AI and cognitive computing there will be fewer errors in reports of medical imaging and diagnosis.”
Eduardo Vendrell, a computer science professor at the Polytechnic University of Valencia in Spain, responded, “In the field of health, many solutions will appear that will allow us to anticipate current problems and discover other risk situations more efficiently. The use of personal gadgets and other domestic devices will allow interacting directly with professionals and institutions in any situation of danger or deterioration of our health.”
Monica Murero, director of the E-Life International Institute and associate professor in sociology of new technology at the University of Naples Federico II in Italy, commented, “In health care, I foresee positive outcomes in terms of reducing human mistakes, that are currently still creating several failures. Also, I foresee an increased development of mobile (remote) 24/7 health care services and personalized medicine thanks to AI and human-machine collaboration applied to the field.”
Uta Russmann, professor in the department of communication at FHWien der WKW University of Applied Sciences for Management & Communication, said, “Life expectancy is increasing (globally) and human-machine/AI collaboration will help older people to manage their life on their own by taking care of them, helping them in the household (taking down the garbage, cleaning up, etc.) as well as keeping them company – just like cats and dogs do, but it will be a much more ‘advanced’ interaction.”
Lindsey Andersen, an activist at the intersection of human rights and technology for Freedom House and Internews, now doing graduate research at Princeton University, commented, “AI will augment human intelligence. In health care, for example, it will help doctors more accurately diagnose and treat disease and continually monitor high-risk patients through internet-connected medical devices. It will bring health care to places with a shortage of doctors, allowing health care workers to diagnose and treat disease anywhere in the world and to prevent disease outbreaks before they start.”
An anonymous respondent said, “The most important place where AI will make a difference is in health care of the elderly. Personal assistants are already capable of many important tasks to help make sure older adults stay in their home. But adding to that emotion detection, more in-depth health monitoring and AI-based diagnostics will surely enhance the power of these tools.”
Denis Parra, assistant professor of computer science in the school of engineering at the Pontifical Catholic University of Chile, commented, “I live in a developing country. Whilst there are potential negative aspects of AI (loss of jobs), for people with disabilities AI technology could improve their lives. I imagine people entering a government office or health facility where people with eye- or ear-related disabilities could effortlessly interact to state their necessities and resolve their information needs.”
Timothy Leffel, research scientist, National Opinion Research Center (NORC) at the University of Chicago, said, “Formulaic transactions and interactions are particularly ripe for automation. This can be good in cases where human error can cause problems, e.g., for well-understood diagnostic medical testing.”
Jean-Daniel Fekete, researcher in human-computer interaction at INRIA in France, said, “Humans and machines will integrate more, improving health through monitoring and easing via machine control. Personal data will then become even more revealing and intrusive and should be kept under personal control.”
Joe Whittaker, a former professor of sciences and associate director of the NASA GESTAR program, now associate provost at Jackson State University, responded, “My hope is that AI/human-machine interface will become commonplace especially in the academic research and health care arena. I envision significant advances in brain-machine interface to facilitate mitigation of physical and mental challenges. Similar uses in robotics should also be used to assist the elderly.”
James Gannon, global head of eCompliance for emerging technology, cloud and cybersecurity at Novartis, responded, “AI will increase the speed and availability to develop drugs and therapies for orphan indications. AI will assist in general lifestyle and health care management for the average person.”
Jay Sanders, president and CEO of the Global Telemedicine Group, responded, “AI will bring collective expertise to the decision point, and in health care, bringing collective expertise to the bedside will save many lives now lost by individual medical errors.”
Geoff Arnold, CTO for the Verizon Smart Communities organization, said, “One of the most important trends over the next 12 years is the aging population and the high costs of providing them with care and mobility. AI will provide better data-driven diagnoses of medical and cognitive issues and it will facilitate affordable AV-based paratransit for the less mobile. It will support, not replace, human care-givers.”
John Lazzaro, retired professor of electrical engineering and computer science, University of California, Berkeley, commented, “When I visit my primary care physician today, she spends a fair amount time typing into an EMS application as she’s talking to me. In this sense, the computer has already arrived in the clinic. An AI system that frees her from this clerical task – that can listen and watch and distill the doctor-patient interaction into actionable data – would be an improvement. A more-advanced AI system would be able to form a ‘second opinion’ based on this data as the appointment unfolds, discreetly advising the doctor via a wearable. The end goal is a reduction in the number of ‘false starts’ in-patient diagnosis. If you’ve read Lisa Sander’s columns in the New York Times, where she traces the arc of difficult diagnoses, you understand the real clinical problem that this system addresses.”
Steve Farnsworth, chief marketing officer at Demand Marketing, commented, “Machine learning and AI offer tools to turn that into actionable data. One project using machine learning and big data already was able to predict SIDS correctly 94% of the time. Imagine AI looking at diagnostics, tests and successful treatments of millions of medical cases. We would instantly have a deluge of new cures and know the most effective treatment options using only the data, medicines and therapies we have now. The jump in quality health care alone for humans is staggering. This is only one application for AI.”
Daniel Siewiorek, a professor with the Human-Computer Interaction Institute at Carnegie Mellon University, predicted, “AI will enable systems to perform labor-intensive activities where there are labor shortages. For example, consider recovery from an injury. There is a shortage of physical therapists to monitor and correct exercises. AI would enable a virtual coach to monitor, correct and encourage a patient. Virtual coaches could take on the persona of a human companion or a pet, allowing the aging population to live independently.”
Joly MacFie, president of the Internet Society, New York chapter, commented, “AI will have many benefits for people with disabilities and health issues. Much of the aging baby boomer generation will be in this category.”
The overall hopes for the future of health care are tempered by concerns that there will continue to be inequities in access to the best care and worries that private health data may be used to limit people’s options.
Craig Burdett, a respondent who provided no identifying details, wrote, “While most AI will probably be a positive benefit, the possible darker side of AI could lead to a loss of agency for some. For example, in a health care setting an increasing use of AI could allow wealthier patients access to significantly-more-advanced diagnosis agents. When coupled with a supportive care team, these patients could receive better treatment and a greater range of treatment options. Conversely, less-affluent patients may be relegated to automated diagnoses and treatment plants with little opportunity for interaction to explore alternative treatments. AI could, effectively, manage long-term health care costs by offering lesser treatment (and sub-optimal recovery rates) to individuals perceived to have a lower status. Consider two patients with diabetes. One patient, upon diagnosis, modifies their eating and exercise patterns (borne out by embedded diagnostic tools) and would benefit from more advanced treatment. The second patient fails to modify their behaviour resulting in substantial ongoing treatment that could be avoided by simple lifestyle choices. An AI could subjectively evaluate that the patient has little interest in their own health and withhold more expensive treatment options leading to a shorter lifespan and an overall cost saving.”
Sumandra Majee, an architect at F5 Networks Inc., said, “AI, deep learning, etc., will become more a part of daily life in advanced countries. This will potentially widen the gap between technology-savvy people and economically well-to-do folks and the folks with limited access to technology. However, I am hopeful that in the field of healthcare, especially when it comes to diagnosis, AI will significantly augment the field, allowing doctors to do a far better job. Many of the routines aspects of checkups can be done via technology. There is no reason an expert human has to be involved in basic A/B testing to reach a conclusion. Machines can be implemented for those tasks and human doctors should only do the critical parts. I do see AI playing a negative role in education, where students may not often actually do the hard work of learning through experience. It might actually make the overall population dumber.”
Timothy Graham, a postdoctoral research fellow in sociology and computer science at Australian National University, commented, “In health care, we see current systems already under heavy criticism (e.g., the My Health Record system in Australia, or the NHS Digital program), because they are nudging citizens into using the system through an ‘opt-out’ mechanism and there are concerns that those who do not opt out may be profiled, targeted and/or denied access to services based on their own data.”
Valarie Bell, a computational social scientist at the University of North Texas, commented, “Let’s say medical diagnosis is taken over by machines, computers and robotics – how will stressful prognoses be communicated? Will a hologram or a computer deliver ‘the bad news’ instead of a physician? Given the health care industry’s inherent profit motives it would be easy for them to justify how much cheaper it would be to simply have devices diagnose, prescribe treatment and do patient care, without concern for the importance of human touch and interactions. Thus, we may devolve into a health care system where the rich actually get a human doctor while everyone else, or at least the poor and uninsured, get the robot.”
The following one-liners from anonymous respondents also tie into the future of health care:

“People could use a virtual doctor for information and first-level response; so much time could be saved!”
“The merging of data science and AI could benefit strategic planning of the future research and development efforts that should be undertaken by humanity.”
“I see economic efficiencies and advances in preventive medicine and treatment of disease, however, I do think there will be plenty of adverse consequences.”
“Data can reduce errors – for instance, in clearly taking into account the side effects of a medicine or use of multiple medications.”
“Human-machine/AI collaboration will reduce barriers to proper medical treatment through better recordkeeping and preventative measures.”
“AI can take over many of the administrative tasks current doctors must do, allowing them more time with patients.”

The future of education:
High hopes for advances in adaptive and individualized learning, but some doubt that there will be any significant progress and worry over digital divide
Over the past few decades, experts and amateurs alike have predicted the internet would have large-scale impacts on education. Many of these hopes have not lived up to the hype. Some respondents to this canvassing said the advent of AI could foster those changes. They expect to see more options for affordable adaptive and individualized learning solutions, including digital agents or “AI assistants” that work to enhance student-teacher interactions and effectiveness.
Barry Chudakov, founder and principal of Sertain Research and author of “Metalifestream,” commented, “In the learning environment, AI has the potential to finally demolish the retain-to-know learning (and regurgitate) model. Knowing is no longer retaining – machine intelligence does that; it is making significant connections. Connect and assimilate becomes the new learning model.”
Lou Gross, professor of mathematical ecology and expert in grid computing, spatial optimization and modeling of ecological systems at the University of Tennessee, Knoxville, said, “I see AI as assisting in individualized instruction and training in ways that are currently unavailable or too expensive. There are hosts of school systems around the world that have some technology but are using it in very constrained ways. AI use will provide better adaptive learning and help achieve a teacher’s goal of personalizing education based on each student’s progress.”
Guy Levi, chief innovation officer for the Center for Educational Technology, based in Israel, wrote, “In the field of education AI will promote personalization, which almost by definition promotes motivation. The ability to move learning forward all the time by a personal AI assistant, which opens the learning to new paths, is a game changer. The AI assistants will also communicate with one another and will orchestrate teamwork and collaboration. The AI assistants will also be able to manage diverse methods of learning, such as productive failure, teach-back and other innovating pedagogies.”
Micah Altman, a senior fellow at the Brookings Institution and head scientist in the program on information science at MIT Libraries, wrote, “These technologies will help to adapt learning (and other environments) to the needs of each individual by translating language, aiding memory and providing us feedback on our own emotional and cognitive state and on the environment. We all need adaptation; each of us, practically every day, is at times tired, distracted, fuzzy-headed or nervous, which limits how we learn, how we understand and how we interact with others. AI has the potential to assist us to engage with the world better – even when conditions are not ideal – and to better understand ourselves.”
Shigeki Goto, Asia-Pacific internet pioneer, Internet Hall of Fame member and a professor of computer science at Waseda University, commented, “AI is already applied to personalized medicine for an individual patient. Similarly, it will be applied to learning or education to realize ‘personalized learning’ or tailored education. We need to collect data which covers both of successful learning and failure experiences, because machine learning requires positive and negative data.”
Andreas Kirsch, fellow at Newspeak House, formerly with Google and DeepMind in Zurich and London, wrote, “Higher education outside of normal academia will benefit further from AI progress and empower more people with access to knowledge and information. For example, question-and-answer systems will improve. Tech similar to Google Translate and WaveNet will lower the barrier of knowledge acquisition for non-English speakers. At the same time, child labor will be reduced because robots will be able to perform the tasks far cheaper and faster, forcing governments in Asia to find real solutions.”
Kristin Jenkins, executive director of BioQUEST Curriculum Consortium, said, “One of the benefits of this technology is the potential to have really effective, responsive education resources. We know that students benefit from immediate feedback and the opportunity to practice applying new information repeatedly to enhance mastery. AI systems are perfect for analyzing students’ progress, providing more practice where needed and moving on to new material when students are ready. This allows time with instructors to focus on more-complex learning, including 21st-century skills.”
Mike Meyer, chief information officer at Honolulu Community College, commented, “Adult education availability and relevance will undergo a major transformation. Community colleges will become more directly community centers for both occupational training and greatly expanded optional liberal arts, art, crafts and hobbies. Classes will, by 2030, be predominantly augmented-reality-based, with a full mix of physical and virtual students in classes presented in virtual classrooms by national and international universities and organizations. The driving need will be expansion of knowledge for personal interest and enjoyment as universal basic income or equity will replace the automated tasks that had provided subsistence jobs in the old system.”
Jennifer Groff, co-founder of the Center for Curriculum Redesign, an international non-governmental organization dedicated to redesigning education for the 21st century, wrote, “The impact on learning and learning environments has the potential to be one of the most positive future outcomes. Learning is largely intangible and invisible, making it a ‘black box’ – and our tools to capture and support learning to this point have been archaic. Think large-scale assessment. Learners need tools that help them understand where they are in a learning pathway, how they learn best, what they need next and so on. We’re only just beginning to use technology to better answer these questions. AI has the potential to help us better understand learning, gain insights into learners at scale and, ultimately, build better learning tools and systems for them. But as a large social system, it is also prey to the complications of poor public policy that ultimately warps and diminishes AI’s potential positive impact.”
Norton Gusky, an education-technology consultant, wrote, “By 2030 most learners will have personal profiles that will tap into AI/machine learning. Learning will happen everywhere and at any time. There will be appropriate filters that will limit the influence of AI, but ethical considerations will also be an issue.”
Cliff Zukin, professor of public policy and political science at Rutgers University’s School of Planning and Public Policy and the Eagleton Institute of Politics, said, “It takes ‘information’ out of the category of a commodity, and more information makes for better decisions and is democratizing. Education, to me, has always been the status leveler, correcting, to some extent, for birth luck and social mobility. This will be like Asimov’s ‘Foundation,’ where everyone is plugged into the data-sphere. There is a dark side (later) but overall a positive.”
However, some expect that there will be a continuing digital divide in education, with the privileged having more access to advanced tools and more capacity for using them well, while the less-privileged lag behind.
Henning Schulzrinne, co-chair of the Internet Technical Committee of the IEEE Communications Society, professor at Columbia University and Internet Hall of Fame member, said, “Human-mediated education will become a luxury good. Some high school- and college-level teaching will be conducted partially by video and AI-graded assignments, using similar platforms to the MOOC [massive open online courses] models today, with no human involvement, to deal with increasing costs for education (‘robo-TA’).”
Joe Whittaker, a former professor of sciences and associate director of the NASA GESTAR program, now associate provost at Jackson State University, responded, “Huge segments of society will be left behind or excluded completely from the benefits of digital advances – many persons in underserved communities as well as others who are socio-economically challenged. This is due to the fact that these persons will be under-prepared generally, with little or no digital training or knowledge base. They rarely have access to the relatively ubiquitous internet, except when at school or in the workplace. Clearly, the children of these persons will be greatly disadvantaged.”
Some witnesses of technology’s evolution over the past few decades feel that its most-positive potential has been disappointingly delayed. After witnessing the slower-than-expected progress of tech’s impact on public education since the 1990s, they are less hopeful than others.
Ed Lyell, longtime educational technologies expert and professor at Adams State University, said education has been held back to this point by the tyranny of the status quo. He wrote, “By 2030, lifelong learning will become more widespread for all ages. The tools already exist, including Khan Academy and YouTube. We don’t have to know as much, just how to find information when we want it. We will have on-demand, 24/7 ‘schooling.’ This will make going to sit-down classroom schools more and more a hindrance to our learning. The biggest negative will be from those protecting current, status-quo education including teachers/faculty, school boards and college administrators. They are protecting their paycheck- or ego-based role. They will need training, counseling and help to embrace the existing and forthcoming change as good for all learners. Part of the problem now is that they do not want to acknowledge the reality of how current schools are today. Some do a good job, yet these are mostly serving already smarter, higher-income communities. Parents fight to have their children have a school like they experienced, forgetting how inefficient and often useless it was. AI can help customize curricula to each learner and guide/monitor their journey through multiple learning activities, including some existing schools, on-the-job learning, competency-based learning, internships and such. You can already learn much more, and more efficiently, using online resources than almost all of the classes I took in my public schooling and college, all the way through getting a Ph.D.”
A consultant and analyst also said that advances in education have been held back by entrenched interests in legacy education systems, writing, “The use of technology in education is minimal today due to the existence and persistence of the classroom-in-a-school model. As we have seen over the last 30 years, the application of artificial intelligence in the field of man/machine interface has grown in many unexpected directions. Who would have thought back in the late 1970s that the breadth of today’s online (i.e., internet) capabilities could emerged? I believe we are just seeing the beginning of the benefits of the man/machine interface for mankind. The institutionalized education model must be eliminated to allow education of each and every individual to grow. The human brain can be ‘educated’ 24 hours a day by intelligent ‘educators’ who may not even be human in the future. Access to information is no longer a barrier as it was 50 years ago. The next step now is to remove the barrier of structured human delivery of learning in the classroom.”
Brock Hinzmann, a partner in the Business Futures Network who worked for 40 years as a futures researcher at SRI International, was hopeful in his comments but also issued a serious warning. He wrote: “Most of the improvements in the technologies we call AI will involve machine learning from big data to improve the efficiency of systems, which will improve the economy and wealth. It will improve emotion and intention recognition, augment human senses and improve overall satisfaction in human-computer interfaces. There will also be abuses in monitoring personal data and emotions and in controlling human behavior, which we need to recognize early and thwart. Intelligent machines will recognize patterns that lead to equipment failures or flaws in final products and be able to correct a condition or shut down and pinpoint the problem. Autonomous vehicles will be able to analyze data from other vehicles and sensors in the roads or on the people nearby to recognize changing conditions and avoid accidents. In education and training, AI learning systems will recognize learning preferences, styles and progress of individuals and help direct them toward a personally satisfying outcome. However, governments or religious organizations may monitor emotions and activities using AI to direct them to ‘feel’ a certain way, to monitor them and to punish them if their emotional responses at work, in education or in public do not conform to some norm. Education could become indoctrination; democracy could become autocracy or theocracy.”
About this canvassing of experts
The expert predictions reported here about the impact of the internet between 2018 and 2030 came in response to questions asked by Pew Research Center and Elon University’s Imagining the Internet Center in an online canvassing conducted between July 4, 2018, and Aug. 6, 2018. This is the 10th Future of the Internet study the two organizations have conducted together. For this project, we invited more than 10,000 experts and members of the interested public to share their opinions on the likely future of the internet, and 985 responded to at least one of the questions we asked. This report covers only the answers to our questions about AI and the future of humans. We also asked respondents to answer a series of questions tied to the 50th anniversary of the ARPANET/internet; additional reports tied to those responses will be released in 2019, the anniversary year.
Specifically related to artificial intelligence, the participants in the nonscientific canvassing were asked:
“Please think forward to the year 2030. Analysts expect that people will become even more dependent on networked artificial intelligence (AI) in complex digital systems. Some say we will continue on the historic arc of augmenting our lives with mostly positive results as we widely implement these networked tools. Some say our increasing dependence on these AI and related systems is likely to lead to widespread difficulties.
“Our question: By 2030, do you think it is most likely that advancing AI and related technology systems will enhance human capacities and empower them? That is, most of the time, will most people be better off than they are today? Or is it most likely that advancing AI and related technology systems will lessen human autonomy and agency to such an extent that most people will not be better off than the way things are today?”
The answers of the 979 respondents include:

63% who said most people will be better off
37% who said most people will not be better off
25 respondents who chose not to select either option

Additionally, they were also asked:
“Please explain why you chose the answer you did and sketch out a vision of how the human-machine/AI collaboration will function in 2030. Please consider giving an example of how a typical human-machine interaction will look and feel in a specific area, for instance, in the workplace, in family life, in a health care setting or in a learning environment. Why? What is your hope or fear? What actions might be taken to assure the best future?”
The web-based instrument was first sent directly to a list of targeted experts identified and accumulated by Pew Research Center and Elon University during previous “Future of the Internet” studies, as well as those identified in an earlier study of people who made predictions about the likely future of the internet between 1990 to 1995. Additional experts with proven interest in this particular research topic were also added to the list. Among those invited were artificial intelligence researchers, developers and business leaders from leading global organizations, including, to name a few, Oxford, Cambridge, MIT, Stanford and Carnegie Mellon universities, Google, Microsoft, Facebook, Amazon, Kernel, Kyndi, BT and Cloudflare; leaders active in global internet governance and internet research activities, such as the Internet Engineering Task Force (IETF), Internet Corporation for Assigned Names and Numbers (ICANN), Internet Society (ISOC), International Telecommunications Union (ITU), Association of Internet Researchers (AoIR), and the Organization for Economic Cooperation and Development (OECD). We also invited a large number of professionals and policy people working in government, including the National Science Foundation, Federal Communications Commission, U.S. military and European Union; think tanks and interest networks (for instance, those that include professionals and academics in anthropology, sociology, psychology, law, political science and communications); engineering/computer science and business/entrepreneurship faculty, graduate students and postgraduate researchers who have published work tied to these topics; plus many who are active in civil society organizations such as Association for Progressive Communications (APC), Electronic Privacy Information Center (EPIC), Electronic Frontier Foundation (EFF) and Access Now; and those affiliated with newly emerging nonprofits and other research units. Invitees were encouraged to share the survey link with others they believed would have an interest in participating, thus there was a small “snowball” effect as a small percentage of these invitees invited others to weigh in.
Since the data are based on a nonrandom sample, the results are not projectable to any population other than the individuals expressing their points of view in this sample.
The respondents’ remarks reflect their personal positions and are not the positions of their employers; the descriptions of their leadership roles help identify their background and the locus of their expertise. About half of the expert respondents elected to remain anonymous. Because people’s level of expertise is an important element of their participation in the conversation, anonymous respondents were given the opportunity to share a description of their internet expertise or background and this was noted where relevant in this report.
Some 519 respondents answered the demographic questions on the canvassing. About 70% identified themselves as being based in North America, while 30% hail from other corners of the world. When asked about their “primary area of internet interest,” 33% identified themselves as professor/teacher; 17% as research scientists; 13% as futurists or consultants; 8% as technology developers or administrators; 5% as entrepreneurs or business leaders; 5% as advocates or activist users; 4% as pioneers or originators; 1% as legislators, politicians or lawyers; and an additional 13% specified their primary area of interest as “other.”
Following is a list of some of the key respondents in this canvassing:
Walid Al-Saqaf, senior lecturer at Sodertorn University, Sweden, and member of the board of trustees of the Internet Society (ISOC); Aneesh Aneesh, author of “Global Labor: Algocratic Modes of Organization”; Kostas Alexandridis, author of “Exploring Complex Dynamics in Multi-agent-based Intelligent Systems”; Micah Altman, director of research and head scientist for the program on information science at MIT; Geoff Arnold, CTO for the Verizon Smart Communities organization; Rob Atkinson, president of the Information Technology and Innovation Foundation; Collin Baker, senior AI researcher at the International Computer Science Institute at the University of California, Berkeley; Brian Behlendorf, executive director of the Hyperledger project at The Linux Foundation; Nathaniel Borenstein, chief scientist at Mimecast; danah boyd, founder and president of the Data & Society Research Institute, and principal researcher at Microsoft; Stowe Boyd, founder and managing director at Work Futures; Henry E. Brady, dean, Goldman School of Public Policy, University of California, Berkeley; Erik Brynjolfsson, director of the MIT Initiative on the Digital Economy and author of “Machine, Platform, Crowd: Harnessing Our Digital Future”; Jamais Cascio, distinguished fellow at the Institute for the Future; Vint Cerf, Internet Hall of Fame member and vice president and chief internet evangelist at Google; Barry Chudakov, founder and principal at Sertain Research and StreamFuzion Corp.; Joël Colloc, professor at Université du Havre Normandy University and author of “Ethics of Autonomous Information Systems”; Steve Crocker, CEO and co-founder of Shinkuro Inc. and Internet Hall of Fame member; Kenneth Cukier, author and senior editor at The Economist; Wout de Natris, internet cybercrime and security consultant; Eileen Donahoe, executive director of the Global Digital Policy Incubator at Stanford University, Judith Donath, Harvard University’s Berkman Klein Center for Internet & Society; William Dutton, Oxford Martin Fellow at the Global Cyber Security Capacity Centre; Robert Epstein, a senior research psychologist and founding director of the Loebner Prize Competition in Artificial Intelligence, Susan Etlinger, an industry analyst for Altimeter Group; Jean-Daniel Fekete, researcher in information visualization, visual analytics and human-computer interaction at INRIA, France; Seth Finkelstein, consulting programmer and EFF Pioneer Award winner; Charlie Firestone, executive director of the Aspen Institute’s communications and society program; Bob Frankston, internet pioneer and software innovator; Divina Frau-Meigs, UNESCO chair for sustainable digital development; Richard Forno, of the Center for Cybersecurity at the University of Maryland-Baltimore County; Oscar Gandy, professor emeritus of communication at the University of Pennsylvania; Charles Geiger, head of the executive secretariat for the UN’s World Summit on the Information Society; Ashok Goel, director of the Human-Centered Computing Ph.D. Program at Georgia Tech; Ken Goldberg, distinguished chair in engineering, and founding member, Berkeley AI Research Lab; Marina Gorbis, executive director of the Institute for the Future; Shigeki Goto, Asia-Pacific internet pioneer and Internet Hall of Fame member; Theodore Gordon, futurist and co-founder of the Millennium Project; Kenneth Grady, futurist and founding author of The Algorithmic Society blog; Sam Gregory, director of WITNESS and digital human rights activist; Wendy Hall, executive director of the Web Science Institute; John C. Havens, executive director of the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems and the Council on Extended Intelligence; Marek Havrda, director at NEOPAS and strategic adviser for the GoodAI project; Jim Hendler, director of the Rensselaer Polytechnic Institute for Data Exploration and Application; Perry Hewitt, a marketing, content and technology executive; Brock Hinzmann, a partner in the Business Futures Network who worked for 40 years as a futures researcher at SRI International; Bernie Hogan, senior research fellow, Oxford Internet Institute; Barry Hughes, senior scientist at the Center for International Futures, University of Denver; Jeff Jarvis, director of the Tow-Knight Center at City University of New York’s Craig Newmark School of Journalism; Bryan Johnson, founder and CEO of Kernel (developer of advanced neural interfaces) and OS Fund; Anthony Judge, editor of tbe Encyclopedia of World Problems and Human Potential; James Kadtke, expert on converging technologies at the Institute for National Strategic Studies, U.S. National Defense University; Sonia Katyal, co-director of the Berkeley Center for Law and Technology and a member of the inaugural U.S. Commerce Department Digital Economy Board of Advisors; Frank Kaufmann, founder and director of the Values in Knowledge Foundation; Fiona Kerr, professor of neural systems and complexity at the University of Adelaide; Annalie Killian, futurist and vice president at Sparks & Honey; Andreas Kirsch, fellow at Newspeak House, formerly with Google and DeepMind in Zurich and London; Michael Kleeman, a senior fellow at the University of California, San Diego and board member at the Institute for the Future; Leonard Kleinrock, Internet Hall of Fame member and professor of computer science at the University of California, Los Angeles; Bart Knijnenburg, researcher on decision-making and recommender systems at Clemson University; Gary L. Kreps, distinguished professor and director of the Center for Health and Risk Communication at George Mason University; Larry Lannom, internet pioneer and vice president at the Corporation for National Research Initiatives (CNRI); Peter Levine, professor and associate dean for research at Tufts University’s Tisch College of Civic Life; John Markoff, fellow at the Center for Advanced Study in the Behavioral Sciences at Stanford University; Matt Mason, roboticist and former director of the Robotics Institute at Carnegie Mellon University; Craig J. Mathias, principal for the Farpoint Group; Giacomo Mazzone, head of institutional relations at the European Broadcasting Union; Andrew McLaughlin, executive director of the Center for Innovative Thinking at Yale, previously deputy CTO of the U.S. and global public policy lead for Google; Panagiotis T. Metaxas, author of “Technology, Propaganda and the Limits of Human Intellect” and professor of computer science, Wellesley College; Robert Metcalfe, co-inventor of Ethernet, founder of 3Com and Internet Hall of Fame member; Jerry Michalski, founder of the Relationship Economy eXpedition (REX); Steven Miller, vice provost and professor of information systems at Singapore Management University; Mario Morino, chair of the Morino Institute and co-founder of Venture Philanthropy Partners; Monica Murero, director of the E-Life International Institute, Italy; Grace Mutung’u, co-leader of the Kenya ICT Action Network; Martijn van Otterlo, author of “Gatekeeping Algorithms with Human Ethical Bias,” Tilburg University, Netherlands; Ian Peter, internet pioneer and advocate and co-founder of the Association for Progressive Communications (APC); Justin Reich, executive director of the MIT Teaching Systems Lab; Peter Reiner, professor and co-founder of the National Core for Neuroethics at the University of British Columbia; Lawrence Roberts, designer and manager of ARPANET (the precursor to the global internet) and Internet Hall of Fame member; Michael Roberts, Internet Hall of Fame member and first president and CEO of ICANN; Marc Rotenberg, executive director of EPIC; Douglas Rushkoff, writer, documentarian, and lecturer who focuses on human autonomy in a digital age; David Sarokin, author of “Missed Information: Better Information for Building a Wealthier, More Sustainable Future”; Thomas Schneider, vice-director at the Federal Office of Communications (OFCOM) in Switzerland; L. Schomaker, professor at the University of Groningen and scientific director of the Artificial Intelligence and Cognitive Engineering (ALICE) research institute; Ben Shneiderman, distinguished professor and founder of the Human Computer Interaction Lab at the University of Maryland; Dan Schultz, senior creative technologist at Internet Archive; Henning Schulzrinne, Internet Hall of Fame member and professor at Columbia University; Evan Selinger, professor of philosophy at Rochester Institute of Technology; Wendy Seltzer, strategy lead and counsel at the World Wide Web Consortium; Greg Shannon, chief scientist for the CERT Division at Carnegie Mellon University’s Software Engineering Institute; Daniel Siewiorek, professor with the Human-Computer Interaction Institute at Carnegie Mellon University; Mark Surman, executive director of the Mozilla Foundation; Brad Templeton, chair emeritus for the Electronic Frontier Foundation; Baratunde Thurston, futurist and former director of digital at The Onion; Sherry Turkle, MIT professor and author of “Alone Together”; Joseph Turow, professor of communication at the University of Pennsylvania; Stuart A. Umpleby, professor emeritus at George Washington University; Karl M. van Meter, author of “Computational Social Science in the Era of Big Data”; Michael Veale, co-author of “Fairness and Accountability Designs Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making”; Amy Webb, futurist, professor and founder of the Future Today Institute; David Wells, chief financial officer at Netflix; David Weinberger, senior researcher at Harvard University’s Berkman Klein Center for Internet & Society; Paul Werbos, former program director at the U.S. National Science Foundation; Betsy Williams, Center for Digital Society and Data Studies at the University of Arizona; John Willinsky, professor and director of the Public Knowledge Project at Stanford Graduate School of Education; Yvette Wohn, director of the Social Interaction Lab at the New Jersey Institute of Technology and expert on human-computer interaction; Andrew Wycoff, the director of OECD’s directorate for science, technology and innovation; Cliff Zukin, professor of public policy and political science at the School for Planning and Public Policy, Rutgers University.
A selection of institutions at which some of the respondents work or have affiliations:
Abt Associates; Access Now; Aeon; Allen Institute for Artificial Intelligence; Alpine Technology Group; Altimeter Group; American Institute for Behavioral Research and Technology; American Library Association; Antelope Consulting; Anticipatory Futures Group; Arizona State University; Artificial Intelligence Research Institute, Universitat Autònoma de Barcelona; Aspen Institute; AT&T; Australian National University; Bad Idea Factory; Bar-Ilan University; Bloomberg Businessweek; Bogazici University; Brookings Institution; BT Group; Business Futures Network; California Institute of Technology; Carnegie Mellon University; Center for Advanced Study in the Behavioral Sciences, Stanford University; Centre for Policy Modelling, Manchester Metropolitan University; Centre National de la Recherche Scientifique; Cisco Systems; Clemson University; Cloudflare; Columbia University; Comcast; Constellation Research; Cornell University; Corporation for National Research Initiatives; Council of Europe; Agency for Electronic Government and Information Society in Uruguay; Electronic Frontiers Australia; Electronic Frontier Foundation; Emergent Research; ENIAC Programmers Project; Eurac Research, Italy; FSA Technologies; Farpoint Group; Foresight Alliance; Future of Privacy Forum; Future Today Institute; Futurism.com; Gartner; General Electric; Georgia Tech; Ginkgo Bioworks; Global Forum for Media Development; Google; Harvard University; Hokkaido University; IBM; Internet Corporation for Assigned Names and Numbers (ICANN); Ignite Social Media; Information Technology and Innovation Foundation; Institute for Defense Analyses; Institute for the Future; Instituto Superior Técnico, Portugal; Institute for Ethics and Emerging Technologies; Internet Engineering Task Force (IETF); International Academy for Systems and Cybernetic Sciences; Internet Society; Institute for Communication & Leadership, Lucerne; Jet Propulsion Lab; Johns Hopkins University; Kansai University; Institute for Systems and Robotics, University of Lisbon; Institute of Electrical and Electronics Engineers (IEEE); Keio University; Kernel; Kyndi; Knowledge and Digital Culture Foundation, Mexico; KPMG; Leading Futurists; LeTourneau University; Linux Foundation; Los Alamos National Laboratory; Machine Intelligence Research Institute; Massachusetts Institute of Technology; Maverick Technologies; McKinsey & Company; Media Psychology Research Center; Microsoft; Millennium Project; Monster Worldwide; Mozilla; Nanyang Technological University; National Chengchi University; National Institute of Mental Health; NetLab; The New School; New York University; Netflix; NLnet Foundation; NORC at the University of Chicago; Novartis, Switzerland; Organization for Economic Cooperation and Development (OECD); Ontario College of Art and Design Strategic Foresight and Innovation; Open the Future; Open University of Israel; Oracle; O’Reilly Media; Global Cyber Security Capacity Center, Oxford University;  Packet Clearing House; People-Centered Internet; Perimeter Institute for Theoretical Physics; Politecnico di Milano; Princeton University; Privacy International; Purdue University; Queen Mary University of London; Quinnovation; RAND; Research ICT Africa; Rochester Institute of Technology; Rose-Hulman Institute of Technology; Russell Sage Foundation; Salesforce; SRI International; Sciteb, London; Shinkuro; Significance Systems; Singapore Management University; Sir Syed University of Engineering and Technology, Pakistan; SLAC National Accelerator Laboratory; Södertörn University, Sweden; Social Science Research Council; University of Paris III: Sorbonne Nouvelle; South China University of Technology; Stanford University; Straits Knowledge; Team Human; The Logic; Technische Universität Kaiserslautern, Germany; Tecnológico de Monterrey, Mexico; The Crucible; United Nations; University of California, Berkeley; University of California, Los Angeles; University of California, San Diego; University College London; University of Denver; Universitat Oberta de Catalunya; Universidade NOVA de Lisboa, Portugal; the Universities of Alabama, Arizona, Delaware, Florida, Maryland, Michigan, Minnesota, Pennsylvania, Southern California, Utah and Vermont; the Universities of Calcutta, Cambridge, Cologne, Cyprus, Edinburgh, Granada, Groningen, Liverpool, Otago, Pavia, Salford and Waterloo; UNESCO; USENIX Association; U.S. Department of Energy; U.S. Naval Postgraduate School; U.S. Special Operations Command SOFWERX; Telecommunications and Radiocommunications Regulator of Vanuatu; Virginia Tech; Vision & Logic; Vizalytics; World Wide Web Foundation; Wellville; Wikimedia; Witness; Yale Law School Information Society Project.
Links to complete sets of credited and anonymous responses from those respondents who wrote elaborations after selecting their answers to the radio-button choice can be found below.
All credited responses to the question on AI and the Future of Humans
All anonymous responses to the question on AI and the Future of Humans



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMingFodHRwczovL3d3dy5pbmRpYXRvZGF5LmluL2VkdWNhdGlvbi10b2RheS9mZWF0dXJlcGhpbGlhL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNhbi1kZXNpZ24tY3VycmljdWx1bS10by1wcmVwYXJlLWZvci1mdXR1cmUtam9icy1odG1sLTE0MDQ1NDQtMjAxOC0xMi0wN9IBogFodHRwczovL3d3dy5pbmRpYXRvZGF5LmluL2FtcC9lZHVjYXRpb24tdG9kYXkvZmVhdHVyZXBoaWxpYS9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jYW4tZGVzaWduLWN1cnJpY3VsdW0tdG8tcHJlcGFyZS1mb3ItZnV0dXJlLWpvYnMtaHRtbC0xNDA0NTQ0LTIwMTgtMTItMDc?oc=5,How Artificial Intelligence is helping universities design a curriculum for future jobs that don't exist now - India Today,2018-12-07,India Today,https://www.indiatoday.in,"According to the report, 9% of India’s 600 million estimated workforces would be deployed in future jobs that do not exist today. Here&#039;s how Artificial Intelligence and Big Data can help us design the right curriculum.","Curriculum, future jobs, artificial intelligence, skill, ai, big data, students","Artificial Intelligence is changing the dynamics of the education industry. We are studying for future jobs that don't exist now. So, how can we design a curriculum to prepare students for those?","Artificial Intelligence is changing the dynamics of the education industry. We are studying for future jobs that don't exist now. So, how can we design a curriculum to prepare students for those?",https://schema.org,,ProfilePage,,https://www.indiatoday.in/author/india-today-web-desk,,,https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png,,,,"{'@type': 'Organization', 'name': 'India Today', 'url': 'https://www.indiatoday.in/', 'logo': {'@type': 'ImageObject', 'url': 'https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png', 'width': 600, 'height': 60}}",,,,,,,"[{'@type': 'ListItem', 'name': 'News', 'position': 1, 'item': {'@id': 'https://www.indiatoday.in/', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': 'Education Today', 'position': 2, 'item': {'@id': 'https://www.indiatoday.in/education-today', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': 'Featurephilia', 'position': 3, 'item': {'@id': 'https://www.indiatoday.in/education-today/featurephilia', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': ""How Artificial Intelligence is helping universities design a curriculum for future jobs that don't exist now"", 'position': 4}]","{'@type': 'SpeakableSpecification', 'cssSelector': ['h1', '.story-kicker']}",India Today Web Desk,"{'@type': 'SearchAction', 'target': 'https://www.indiatoday.in/search/{search_term_string}', 'query-input': 'required name=search_term_string'}","{'@type': 'ImageObject', 'url': 'https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png', 'width': 600, 'height': 60}","['https://www.facebook.com/IndiaToday', 'https://twitter.com/indiatoday', 'https://www.youtube.com/Indiatoday', 'https://www.instagram.com/indiatoday/']","{'@type': 'PostalAddress', 'streetAddress': 'FC-8, Ecity Bioscope Rd, Film City', 'addressLocality': 'Sector 16A, Noida', 'addressRegion': 'India', 'postalCode': '201301', 'telephone': '0120 480 7100'}",1200.0,675.0,"{'@type': 'Organization', 'name': 'India Today', 'url': 'https://www.indiatoday.in/'}","{'@id': 'https://www.indiatoday.in/author/india-today-web-desk', '@type': 'Person', 'name': 'India Today Web Desk'}","[{'@type': 'Article', 'headline': ""How Artificial Intelligence is helping universities design a curriculum for future jobs that don't exist now - India Today"", 'url': 'https://www.indiatoday.in/education-today/featurephilia/story/artificial-intelligence-can-design-curriculum-to-prepare-for-future-jobs-html-1404544-2018-12-07', 'datePublished': '2018-12-07 16:00:00+5:30', 'author': {'@id': 'https://www.indiatoday.in/author/india-today-web-desk'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vd3d3LnRoZWhyZGlnZXN0LmNvbS81LW9mZmljZS1pbnZlbnRpb25zLXRoYXQtd2lsbC1tYWtlLXdvcmstZnVuLWFnYWluL9IBAA?oc=5,5 Office Inventions That Will Make Work Fun Again! - The HR Digest,2018-12-07,The HR Digest,https://www.thehrdigest.com,The modern office must continually evolve using newer office inventions to stay relevant. What could the workplace possibly look like in another 50 years to come and what office inventions might play a key role?,,The modern office must continually evolve using newer office inventions to stay relevant. What could the workplace possibly look like in another 50 years to come and what office inventions might play a key role?,,https://schema.org/,"[{'@type': 'Article', '@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/#article', 'isPartOf': {'@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/'}, 'author': {'name': 'Diana Coker', '@id': 'https://www.thehrdigest.com/#/schema/person/82855b797a6ec180689e0685ccc911bd'}, 'headline': '5 Office Inventions That Will Make Work Fun Again!', 'datePublished': '2018-12-07T10:37:00+00:00', 'dateModified': '2021-07-22T07:43:58+00:00', 'mainEntityOfPage': {'@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/'}, 'wordCount': 802, 'commentCount': 0, 'publisher': {'@id': 'https://www.thehrdigest.com/#organization'}, 'image': {'@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/#primaryimage'}, 'thumbnailUrl': 'https://www.thehrdigest.com/wp-content/uploads/2020/04/Inventions-Office.jpg', 'keywords': ['artificial intelligence', 'Internet of Things', 'office Inventions', 'Office Inventions To Make Work Fun Again', 'Real time collaboration', 'remote workforce'], 'articleSection': ['Featured', 'Workplace Culture'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/', 'url': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/', 'name': '5 Office Inventions That Will Make Work Fun Again!', 'isPartOf': {'@id': 'https://www.thehrdigest.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/#primaryimage'}, 'image': {'@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/#primaryimage'}, 'thumbnailUrl': 'https://www.thehrdigest.com/wp-content/uploads/2020/04/Inventions-Office.jpg', 'datePublished': '2018-12-07T10:37:00+00:00', 'dateModified': '2021-07-22T07:43:58+00:00', 'description': 'The modern office must continually evolve using newer office inventions to stay relevant. What could the workplace possibly look like in another 50 years to come and what office inventions might play a key role?', 'breadcrumb': {'@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/#primaryimage', 'url': 'https://www.thehrdigest.com/wp-content/uploads/2020/04/Inventions-Office.jpg', 'contentUrl': 'https://www.thehrdigest.com/wp-content/uploads/2020/04/Inventions-Office.jpg', 'width': 1000, 'height': 744, 'caption': 'Inventions Office'}, {'@type': 'BreadcrumbList', '@id': 'https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.thehrdigest.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Trends', 'item': 'https://www.thehrdigest.com/trends/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Workplace Culture', 'item': 'https://www.thehrdigest.com/trends/workplace-culture/'}, {'@type': 'ListItem', 'position': 4, 'name': '5 Office Inventions That Will Make Work Fun Again!'}]}, {'@type': 'WebSite', '@id': 'https://www.thehrdigest.com/#website', 'url': 'https://www.thehrdigest.com/', 'name': 'The HR Digest', 'description': '', 'publisher': {'@id': 'https://www.thehrdigest.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.thehrdigest.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.thehrdigest.com/#organization', 'name': 'The HR Digest', 'url': 'https://www.thehrdigest.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.thehrdigest.com/#/schema/logo/image/', 'url': 'https://www.thehrdigest.com/wp-content/uploads/2020/03/logo.png', 'contentUrl': 'https://www.thehrdigest.com/wp-content/uploads/2020/03/logo.png', 'width': 210, 'height': 176, 'caption': 'The HR Digest'}, 'image': {'@id': 'https://www.thehrdigest.com/#/schema/logo/image/'}, 'sameAs': ['https://x.com/TheHRDigest', 'https://www.linkedin.com/company/thehrdigest/']}, {'@type': 'Person', '@id': 'https://www.thehrdigest.com/#/schema/person/82855b797a6ec180689e0685ccc911bd', 'name': 'Diana Coker', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.thehrdigest.com/#/schema/person/image/', 'url': 'https://www.thehrdigest.com/wp-content/uploads/2020/07/Diana-Coker-150x150.jpg', 'contentUrl': 'https://www.thehrdigest.com/wp-content/uploads/2020/07/Diana-Coker-150x150.jpg', 'caption': 'Diana Coker'}, 'description': 'Diana Coker is a staff writer at The HR Digest, based in New York. She also reports for brands like Technowize. Diana covers HR news, corporate culture, employee benefits, compensation, and leadership. She loves writing HR success stories of individuals who inspire the world. She’s keen on political science and entertains her readers by covering usual workplace tactics.', 'sameAs': ['https://www.facebook.com/thehrdigest', 'https://www.instagram.com/thehrdigest/', 'https://www.youtube.com/channel/UCpDq0o7oNtkiKA4w2eSPDcQ'], 'url': 'https://www.thehrdigest.com/author/dianacoker/'}]",WebPage,5 Office Inventions That Will Make Work Fun Again!,https://www.thehrdigest.com/5-office-inventions-that-will-make-work-fun-again/,,,['https://www.thehrdigest.com/wp-content/uploads/2020/04/Inventions-Office-768x571.jpg'],,"[{'@type': 'Person', 'name': 'Diana Coker', 'url': 'https://www.thehrdigest.com/author/dianacoker/'}]",,,,"Dec 07, 2018","Dec 07, 2018",,,"




5 Office Inventions That Will Make Work Fun Again!

Diana Coker
December 07, 2018
Featured Workplace Culture


Walk into almost any workplace, big or small, and you’ll quickly see how technology has transformed the way we work. Whether you’re a freelancer, a delivery driver, or a CHRO, one thing is clear: The modern office has adapted to new technology and tools in a number of ways to cater for changes in evolving workplace needs and working styles.
How, for example, did we live without Skype or Slack? Think about the Otis Elevator. Otis’ invention lifted cities and freed us from the tyranny of stairs as tall workplaces started to pop up in cities. But, Skype or the elevator, of course, is not the only inventions that solved humankind’s pesky everyday work problems. More importantly, remote workers and entrepreneurs enjoyed better careers as laptops and smart devices grew more popular.
The modern office must continually evolve to stay relevant. It has to provide smart technology to the interconnected workforce to encourage collaborative brainstorming so the focus remains on efficiency, interconnected-ness, sustainability, and productivity. What could the workplace possibly look like in another 50 years to come?
Real-Time Collaboration

Real-time collaboration has been the essence of the modern office. Think of the time that’s wasted due to technical issues encountered while trying to set up an inter-departmental online meeting. The current generation of real-time collaboration office tools like Slack and Microsoft Teams promise improved productivity and enhanced workflow between different teams. For instance, screen sharing on Google Docs allows different people to design a car or edit a video simultaneously.
VR and AR
With Virtual Reality and Augmented Reality, real-time collaboration will no longer be a source of distraction and frustration. Imagine two interior designers in different cities looking at the same 3D hologram of a workspace using their AR glasses. They can scrutinize the design, make tweaks in real time and walk through the project together.

VR and AR will expand the modern office to something that’s more than four walls and people in cubicles. It will provide collaboration regardless of location and proximity of individuals to each other.
Internet of Things
As we increase the number of gadgets in an ever interconnected smart office, there is more need to connect them to one another. IoT will empower office workers to become more efficient and increase productivity while saving time. For example, your calendar says there is a meeting at 9 am in the conference room. When you get there, the smart coffee machine has already brewed coffee without anyone pressing a button, and the audiovisual equipment has set itself up.

During the meeting, you are tasked with a meeting with a prospective client that afternoon. Your smartphone automatically adds the meeting to the calendar. At noon, your smart car is ready to take you to the destination it knows from the calendar without you having to enter it.
IoT devices will communicate and anticipate all your workplace needs. At the end of the day, you’ll save time and focus on what really matters.
Artificial Intelligence
A recent Zoom survey found that 73% of respondents expect artificial intelligence to have a positive impact on meeting. There are invaluable ways in which AI can increase ease of work, productivity and overall workplace efficiency. For example, ROSS, an artificial intelligence program based on IBM”s Watson AI system that is designed to step into the role of a lawyer. It can skim through data to get you facts from a decade ago and how it relates to a current case. With the help of machine learning, ROSS can become an integral part of a law firm, helping them with various cases.

AI can help eliminate the time wasted doing repetitive, non-core tasks. At the end of the day, it will help employees focus on what matters the most. For example, Textio, a Seattle-based company, provides AI-based software that can help companies write effective job postings and recruiting emails. Perhaps using AI we can enhance various human resources functions.
The Remote Workforce
A recent survey notes that 34% of employers expect more than half of their workforce to work remotely by the end of the decade. More importantly, 25% of business leaders believe that 75% of their workforce would be working remotely by 2020.

The survey has provided a lot to ponder upon. There’s no doubt that remote workers are the happiest, thanks to increased flexibility and level of autonomy enjoyed. Working remotely increases productivity as workplace distractions are eliminated. More so, it reduces employee turnover which is one of the costliest expenditures for organizations.
With the right tools, businesses can reduce management costs, boosts motivation and enhance teamwork within the remote workforce. Things like real-time collaboration, VR and AR, and cloud computing will allow companies to allow greater autonomy and flexibility within the workforce.


artificial intelligenceInternet of Thingsoffice InventionsOffice Inventions To Make Work Fun AgainReal time collaborationremote workforce







FAQs






Diana Coker



Diana Coker is a staff writer at The HR Digest, based in New York. She also reports for brands like Technowize. Diana covers HR news, corporate culture, employee benefits, compensation, and leadership. She loves writing HR success stories of individuals who inspire the world. She’s keen on political science and entertains her readers by covering usual workplace tactics.





PREVIOUS ARTICLE
« How to Be More Efficient At Your Payroll Job


NEXT ARTICLE
What Managers Need To Know About Anger in the Workplace »




Stay tuned!
We don’t want you to miss anything. Subscribe to our newsletter and stay updated on the latest HR news and trends.




First name

Last name
Email





 



Similar Articles









Safety First—OSHA-Dollar General $12 Million Settlement Reached
Featured
 Ava Martinez - July 16, 2024

Last year, OSHA added Dollar General to the “Severe Violator Enforcement Program” for its poor workplace safety, and all the accumulated...











Far From Over—NSEU Announces Indefinite Strike at Samsung
Featured
 Ava Martinez - July 15, 2024

Union workers at Samsung have turned a three-day strike into an indefinite one, demanding that Samsung agree with their terms and change the...











The Ins and Outs of Responding to a Resignation Letter
Featured
 Ava Martinez - July 14, 2024

Formulating a reply to a resignation letter requires you to take on a sensitive approach and carefully word your acceptance of their decisio...











Should you be Friends with Coworkers? Mapping the Pros and Cons
Workplace Culture
 Ava Martinez - July 13, 2024

Socializing with coworkers is essential to maintain a healthy work environment but it is also good to establish some boundaries when you do....












Leave a Reply Cancel replyYour email address will not be published. Required fields are marked *Comment * Name * 
Email * 
Website 
 Save my name, email, and website in this browser for the next time I comment.
 

 






































",,"{'@type': 'SpeakableSpecification', 'xPath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}",5 Office Inventions That Will Make Work Fun Again!,,https://www.thehrdigest.com/wp-content/uploads/2020/03/logo.png,"['https://www.linkedin.com/company/thehrdigest', 'https://www.facebook.com/thehrdigest', 'https://twitter.com/TheHRDigest', 'https://in.pinterest.com/thehrdigest', 'https://www.instagram.com/thehrdigest', 'https://www.youtube.com/channel/UCpDq0o7oNtkiKA4w2eSPDcQ']","{'@type': 'PostalAddress', 'streetAddress': '3651 Lindell Road #300D', 'addressLocality': 'Las Vegas', 'addressRegion': 'Nevada', 'postalCode': '89103', 'addressCountry': 'United States'}",,,,,,The HR Digest,"{'@type': 'ContactPoint', 'contactType': 'office', 'telephone': '1-888-409-1588'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd3d3LnBld3Jlc2VhcmNoLm9yZy9pbnRlcm5ldC8yMDE4LzEyLzEwL3NvbHV0aW9ucy10by1hZGRyZXNzLWFpcy1hbnRpY2lwYXRlZC1uZWdhdGl2ZS1pbXBhY3RzL9IBAA?oc=5,2. Solutions to address AI's anticipated negative impacts - Pew Research Center,2018-12-10,Pew Research Center,https://www.pewresearch.org,A number of participants in this canvassing offered solutions to the worrisome potential future spawned by AI. Among them: 1) improving collaboration,[],A number of participants in this canvassing offered solutions to the worrisome potential future spawned by AI. Among them: 1) improving collaboration,,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/#article', 'isPartOf': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/'}, 'author': {'name': 'Sara Atske', '@id': 'https://www.pewresearch.org/#/schema/person/81ad7bd61667c7d73ab64351212a033c'}, 'headline': '2. Solutions to address AI’s anticipated negative impacts', 'datePublished': '2018-12-10T16:55:56+00:00', 'dateModified': '2024-04-14T09:12:46+00:00', 'mainEntityOfPage': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/'}, 'wordCount': 10729, 'commentCount': 0, 'publisher': {'@id': 'https://www.pewresearch.org/#organization'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://platform.pewresearch.org/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/', 'url': 'https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/', 'name': '2. Solutions to address AI’s anticipated negative impacts | Pew Research Center', 'isPartOf': {'@id': 'https://www.pewresearch.org/#website'}, 'datePublished': '2018-12-10T16:55:56+00:00', 'dateModified': '2024-04-14T09:12:46+00:00', 'description': 'A number of participants in this canvassing offered solutions to the worrisome potential future spawned by AI. Among them: 1) improving collaboration', 'breadcrumb': {'@id': 'https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/']}]}, {'@type': 'BreadcrumbList', '@id': 'https://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.pewresearch.org'}, {'@type': 'ListItem', 'position': 2, 'name': 'Research Topics', 'item': 'https://www.pewresearch.org/topics-categorized/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Internet &amp; Technology', 'item': 'https://www.pewresearch.org/topic/internet-technology/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Emerging Technology', 'item': 'https://www.pewresearch.org/topic/internet-technology/emerging-technology/'}, {'@type': 'ListItem', 'position': 5, 'name': 'Artificial Intelligence'}]}, {'@type': 'WebSite', '@id': 'https://www.pewresearch.org/#website', 'url': 'https://www.pewresearch.org/', 'name': 'Pew Research Center', 'description': 'Numbers, Facts and Trends Shaping Your World', 'publisher': {'@id': 'https://www.pewresearch.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.pewresearch.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.pewresearch.org/#organization', 'name': 'Pew Research Center', 'url': 'https://www.pewresearch.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/#/schema/logo/image/', 'url': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2024/04/logo-fallback.png', 'contentUrl': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2024/04/logo-fallback.png', 'width': 1265, 'height': 192, 'caption': 'Pew Research Center'}, 'image': {'@id': 'https://www.pewresearch.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/pewresearch', 'https://twitter.com/pewresearch', 'https://www.linkedin.com/company/pew-research-center/', 'https://www.youtube.com/user/PewResearchCenter']}, {'@type': 'Person', '@id': 'https://www.pewresearch.org/#/schema/person/81ad7bd61667c7d73ab64351212a033c', 'name': 'Sara Atske', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/5788245e97afeb895fedf7ded23300bd?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/5788245e97afeb895fedf7ded23300bd?s=96&d=mm&r=g', 'caption': 'Sara Atske'}, 'url': 'https://www.pewresearch.org/author/satske/'}]",NewsArticle,2. Solutions to address AI’s anticipated negative impacts,http://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/,"{'@type': 'WebPage', '@id': 'http://www.pewresearch.org/internet/2018/12/10/solutions-to-address-ais-anticipated-negative-impacts/'}",,"{'@type': 'ImageObject', 'url': ''}",,"[{'@type': 'Person', 'name': 'Sara Atske'}]",['Sara Atske'],"{'@type': 'Organization', 'name': 'Pew Research Center', 'logo': 'https://www.pewresearch.org/wp-content/themes/prc-block-theme/assets/img/square.png'}",2018-12-10T16:55:56Z,2018-12-10T16:55:56Z,2024-04-14T09:12:46Z,,,"short readsMay 15, 2024 

   

A quarter of U.S. teachers say AI tools do more harm than good in K-12 education ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvam9lbWNrZW5kcmljay8yMDE4LzEyLzE5L2hvdy1mYXN0LWlzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWdyb3dpbmctbG9vay1hdC10aGUta2V5LWJlbGx3ZXRoZXJzL9IBAA?oc=5,How Fast Is Artificial Intelligence Growing? Look At The Key Bellwethers - Forbes,2018-12-19,Forbes,https://www.forbes.com,"Stanford researchers document AI growth across many indicators, including startups, venture capital, job openings and academic programs.",,"Stanford researchers document AI growth across many indicators, including startups, venture capital, job openings and academic programs.","Stanford researchers document AI growth across many indicators, including startups, venture capital, job openings and academic programs.",http://schema.org,,BreadcrumbList,How Fast Is Artificial Intelligence Growing? Look At The Key Bellwethers,https://www.forbes.com/sites/joemckendrick/2018/12/19/how-fast-is-artificial-intelligence-growing-look-at-the-key-bellwethers/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/joemckendrick/files/2016/11/National-Gallery-of-Art-cropped-Washington-DC-July-2016-photo-by-Joe-McKendrick-300x275.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",AI & Big Data,"{'@type': 'Person', 'name': 'Joe McKendrick', 'url': 'https://www.forbes.com/sites/joemckendrick/', 'description': 'I am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the 2023 AI Summit in New York, as well as the 2021 and 2022 Summits. I regularly contribute to Harvard Business Review on AI topics. My column on service orientation appears on CNET, covering topics shaping business and technology careers. I am also a co-author of the SOA Manifesto, which outlines the values and guiding principles of service orientation in business and IT. Much of my research work is in conjunction with Forbes Insights and Unisphere Research/ Information Today, Inc., covering topics such as artificial intelligence, cloud computing, digital transformation, and big data analytics. In a previous life, I served as communications and research manager of the Administrative Management Society (AMS), an international professional association dedicated to advancing knowledge within the IT and business management fields. I am a graduate of Temple University.', 'sameAs': ['https://www.twitter.com/joemckendrick', 'Joe McKendrick']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2018-12-19T00:26:00-05:00,2018-12-19T11:03:01-05:00,AI & Big Data,,"Edit StoryInnovationEnterprise TechHow Fast Is Artificial Intelligence Growing? Look At The Key BellwethersJoe McKendrickSenior ContributorOpinions expressed by Forbes Contributors are their own.I track how technology innovations move markets and careersFollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 19, 2018,12:26am ESTUpdated Dec 19, 2018, 11:03am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinOne can intuitively surmise artificial intelligence (AI) is today's hot commodity, gaining traction in businesses, academia and government in recent years. Now, there is data -- all in one place -- that documents growth across many indicators, including startups, venture capital, job openings and academic programs. These bellwethers were captured in the AI Index, produced under the auspices of was conceived within Stanford University's Human-Centered AI Institute and the One Hundred Year Study on AI (AI100).








AI in the mainstream
Photo: Joe McKendrick






One key measure of AI development is startups and venture capital funding. From January 2015 to January 2018, active AI startups increased 2.1x, while all  active startups increased 1.3x, the report states. ""For the most part, growth in all active startups has remained relatively steady, while the number of AI startups has seen exponential growth,"" the report's authors add. The trickle of venture capital into AI startups, another bellwether, also turned into a torrent. VC funding for AI startups in the US increased 4.5x from 2013 to 2017. Meanwhile, VC funding for all active startups increased 2.08x.
Another key measure, job openings, accelerated in AI. While machine learning is the largest skill cited as a requirement, deep learning is growing at the fastest rate — from 2015 to 2017 the number of job openings requiring deep learning increased 35x, the report's authors state.
PROMOTED
The AI Index also cited McKinsey data that demonstrated the types of AI solutions being deployed in organizations. In North American organizations, the main forms of AI include the following:

Robotic process automation 23%
Machine learning 23%
Conversational interfaces 20%
Computer vision 20%









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Natural language text understanding 17%
Natural language speech understanding 16%
Natural language generation 11%

Another interesting bellwether, downloads from AI-oriented open source solutions, is way up. The number of robot operating system (ROS) binary packages downloaded from ROS.org, an open source software stack for robotics.  Since 2014, total downloads and unique downloads have increased by 352% and 567%, respectively. ""This represents an increased interest in both robotics and the use of robot systems,"" the report's authors conclude. ""Because the number of unique downloads is growing at a faster rate than the total number of downloads, we can infer that there are more ROS users, not just that ROS is more frequently used.""
Finally, another telling AI bellwether is AI course enrollment. The percentage of undergraduate students enrolled in introductory AI and machine learning courses has grown. While introductory AI courses tend to have a slightly larger proportion of undergraduate students than introductory machine learning courses (an average of 5.2% in AI versus 4.4% in ML), the number of undergraduate students in introductory machine learning courses are growing at a faster rate.  Introductory AI enrollment was 3.4x larger in 2017 than it was in 2012, while introductory machine learning course enrollment was 5x larger than it was in 2012.  ""This depicts the growing importance of machine learning as a subfield of AI,"" the report states.Joe McKendrickFollowingFollowI am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the... Read MoreEditorial StandardsPrintReprints & Permissions","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",,How Fast Is Artificial Intelligence Growing? Look At The Key Bellwethers,,,,,,,,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vd3d3LnB1YmxpY3NlY3RvcmV4ZWN1dGl2ZS5jb20vSW50ZXJ2aWV3cy90aGUtZGV2aWwtaXMtaW4tdGhlLWRhdGHSAQA?oc=5,Artificial intelligence: the devil is in the data - Public Sector Executive,2018-12-17,Public Sector Executive,https://www.publicsectorexecutive.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vd3d3LmluZy5jb20vTmV3c3Jvb20vTmV3cy9Vc2luZy1BSS10by1hc3Nlc3MtY3JlZGl0LXJpc2suaHRt0gEA?oc=5,Using AI to assess credit risk | ING - ING.com,2018-12-17,ING.com,https://www.ing.com,17 December 2018,"Financial Services, ING",ING teams up with Google and PWC in the area of artificial intelligence.,ING teams up with Google and PWC in the area of artificial intelligence.,https://schema.org,,Organization,,https://www.ing.com,,,,,,,,,,,,,"


Using AI to assess credit risk



17 December 2018
 1 min read



 17 December 2018 
Next to blockchain, artificial intelligence (AI) is the cool kid on the technology block. The financial services industry especially is reaping the benefits of AI with ING no stranger to the game.
 Fresh from bringing in chatbots to process customer requests faster than ever, using predictive analytics in bond trading, and working with Google on digital voice assistants, ING is putting artificial intelligence to work in Risk Management. We’ve teamed up with Google and PwC to develop an early warning system (EWS) that helps credit risk analysts make quicker and more informed decisions. 


Anand Autar, ING’s early warning system project leader.

 The EWS is an AI-powered application that collects and analyses large amounts of data to identify whether clients are exposed to potential risks, a task currently performed manually by risk analysts. “Speed is of the essence in credit risk management. The earlier we detect any risk, the quicker and better we can serve clients to prevent losses,” said Anand Autar, project leader at ING.  “Through machine learning, the EWS scans financial and non-financial information, such as news items from all over the world.”Credit risk analysts set their own warning criteria. For example, a client’s share price falls by more than a pre-set percentage, or a client’s media coverage is negative based on sentiment analysis. Processing up to 80,000 articles every day, the EWS is ‘fed’ real-time market data from Refinitiv  (former Thomson Reuters) and news from public sources. It uses Google’s natural language processing and translation services for articles published in local media outlets.“The system learns from experience, so in time it will become better at identifying the sentiment of news and developments in the market,” said Görkem Köseoğlu, head of AI and Robotics at ING.ING aims to add predictive capabilities to the application in the near future. “This ambition requires further refinement of algorithms, and we’ll get there,” said Görkem. “Customers expect more predictive capabilities in their products and services, so for us meeting that customer demand is important.”Read what PwC says about the collaboration.





Share


Twitter
LinkedIn
E-mail
Whatsapp








",,,ING,,,"['https://www.facebook.com/ing', 'https://www.twitter.com/ING_news', 'https://www.youtube.com/ING', 'https://www.linkedin.com/company/ing', 'https://www.slideshare.net/ING/', 'https://www.flickr.com/photos/inggroup/']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vbmV3cy5taWNyb3NvZnQuY29tL2FwYWMvZmVhdHVyZXMvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLXJlbmV3YWJsZXMtYS1wZWVrLWludG8tdGhlLWZ1dHVyZS1vZi1lbmVyZ3kv0gEA?oc=5,Artificial intelligence and renewables: A peek into the future of energy - Microsoft Stories Asia - Microsoft,2018-12-20,Microsoft,https://news.microsoft.com,,,,,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://news.microsoft.com/apac/features/artificial-intelligence-and-renewables-a-peek-into-the-future-of-energy/', 'url': 'https://news.microsoft.com/apac/features/artificial-intelligence-and-renewables-a-peek-into-the-future-of-energy/', 'name': 'Artificial intelligence and renewables: A peek into the future of energy - Microsoft Stories Asia', 'isPartOf': {'@id': 'https://news.microsoft.com/apac/#website'}, 'primaryImageOfPage': {'@id': 'https://news.microsoft.com/apac/features/artificial-intelligence-and-renewables-a-peek-into-the-future-of-energy/#primaryimage'}, 'image': {'@id': 'https://news.microsoft.com/apac/features/artificial-intelligence-and-renewables-a-peek-into-the-future-of-energy/#primaryimage'}, 'thumbnailUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/43/2018/12/envision-header.jpg', 'datePublished': '2018-12-20T10:25:02+00:00', 'dateModified': '2022-11-30T22:26:28+00:00', 'breadcrumb': {'@id': 'https://news.microsoft.com/apac/features/artificial-intelligence-and-renewables-a-peek-into-the-future-of-energy/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.microsoft.com/apac/features/artificial-intelligence-and-renewables-a-peek-into-the-future-of-energy/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.microsoft.com/apac/features/artificial-intelligence-and-renewables-a-peek-into-the-future-of-energy/#primaryimage', 'url': 'https://news.microsoft.com/wp-content/uploads/prod/sites/43/2018/12/envision-header.jpg', 'contentUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/43/2018/12/envision-header.jpg', 'width': 2557, 'height': 1354}, {'@type': 'BreadcrumbList', '@id': 'https://news.microsoft.com/apac/features/artificial-intelligence-and-renewables-a-peek-into-the-future-of-energy/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.microsoft.com/apac/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Features', 'item': 'https://news.microsoft.com/apac/features/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial intelligence and renewables: A peek into the future of energy'}]}, {'@type': 'WebSite', '@id': 'https://news.microsoft.com/apac/#website', 'url': 'https://news.microsoft.com/apac/', 'name': 'Asia News Center', 'description': 'Microsoft Stories Asia', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.microsoft.com/apac/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vaGJyLm9yZy8yMDE4LzEyLzUtcXVlc3Rpb25zLXdlLXNob3VsZC1iZS1hc2tpbmctYWJvdXQtYXV0b21hdGlvbi1hbmQtam9ic9IBAA?oc=5,5 Questions We Should Be Asking About Automation and Jobs - Harvard Business Review,2018-12-19,Harvard Business Review,https://hbr.org,"We simply don’t know for sure whether automation, algorithms, and AI will ultimately create more jobs than they destroy. But this uncertainty should not blind or distract us from other pressing questions about automation that we’re sure to face regardless of whether automation adds to or subtracts from the total number of jobs. Here are five important, overlooked questions about automation and jobs: Will workers whose jobs are automated be able to transition to new jobs? Who will bear the burden of automation? How will automation affect the supply of labor? How will automation affect wages, and how will wages affect automation? And, how will automation change job searching?",,"We simply don’t know for sure whether automation, algorithms, and AI will ultimately create more jobs than they destroy. But this uncertainty should not blind or distract us from other pressing questions about automation that we’re sure to face regardless of whether automation adds to or subtracts from the total number of jobs. Here are five important, overlooked questions about automation and jobs: Will workers whose jobs are automated be able to transition to new jobs? Who will bear the burden of automation? How will automation affect the supply of labor? How will automation affect wages, and how will wages affect automation? And, how will automation change job searching?",,https://schema.org,,WebSite,,https://hbr.org/,,,,,,,,,,,Economics,,,,,,"{'@type': 'SearchAction', 'target': 'https://hbr.org/search?term={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd3d3LnRoZWFydG5ld3NwYXBlci5jb20vMjAxOC8xMi8xNy93ZS1tdXN0LW5vdC1sZXQtdGhlLWFydC1tYXJrZXQtaG9vZHdpbmstdXMtaW4tdGhlLWFpLWRlYmF0ZdIBAA?oc=5,We must not let the art market hoodwink us in the AI debate - Art Newspaper,2018-12-17,Art Newspaper,https://www.theartnewspaper.com,"The AI work that was sold at Christie's is profound in its conservatism, but others reflect how the technology can impact on art in fascinating ways","['Auction houses', ""Christie's"", 'Technology', 'Artificial intelligence']","The AI work that was sold at Christie's is profound in its conservatism, but others reflect how the technology can impact on art in fascinating ways","The AI work that was sold at Christie's is profound in its conservatism, but others reflect how the technology can impact on art in fascinating ways",http://schema.org,,NewsArticle,We must not let the art market hoodwink us in the AI debate,https://www.theartnewspaper.com/2018/12/17/we-must-not-let-the-art-market-hoodwink-us-in-the-ai-debate,,"https://cdn.sanity.io/images/cxgd3urn/production/18b6ad6743c082ec359cbb05f914dc819ec32fde-910x476.jpg?rect=59,0,793,476&w=1200&h=720&q=85&fit=crop&auto=format","https://cdn.sanity.io/images/cxgd3urn/production/18b6ad6743c082ec359cbb05f914dc819ec32fde-910x476.jpg?rect=59,0,793,476&w=1200&h=720&q=85&fit=crop&auto=format",comment,"[{'@type': 'Person', 'name': 'Ben Luke', 'url': 'https://www.theartnewspaper.com/authors/ben-luke'}]","[{'@type': 'Person', 'name': 'Ben Luke', 'url': 'https://www.theartnewspaper.com/authors/ben-luke'}]","{'@type': 'Organization', 'name': 'The Art Newspaper - International art news and events', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.sanity.io/images/cxgd3urn/production/3241e32fac3321c3bdffacdbe1fabc51852fe343-828x315.jpg?rect=152,0,525,315&w=1200&h=720&q=85&fit=crop&auto=format'}}",,2018-12-17T10:10:14.937Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LnByaW5jZXRvbi5lZHUvbmV3cy8yMDE4LzEyLzE4L2dvb2dsZS1vcGVuLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWxhYi1wcmluY2V0b24tYW5kLWNvbGxhYm9yYXRlLXVuaXZlcnNpdHnSAQA?oc=5,Google to open artificial intelligence lab in Princeton and collaborate with University researchers - Princeton University,2018-12-18,Princeton University,https://www.princeton.edu,Princeton University computer science professors Elad Hazan and Yoram Singer will lead a new Google artificial intelligence lab opening in January in the town of Princeton. The lab is expected to expand New Jersey’s burgeoning innovation ecosystem by building a collaborative effort to advance research in artificial intelligence.,,Princeton University computer science professors Elad Hazan and Yoram Singer will lead a new Google artificial intelligence lab opening in January in the town of Princeton. The lab is expected to expand New Jersey’s burgeoning innovation ecosystem by building a collaborative effort to advance research in artificial intelligence.,Princeton University computer science professors Elad Hazan and Yoram Singer will lead a new Google artificial intelligence lab opening in January in the town of Princeton. The lab is expected to expand New Jersey’s burgeoning innovation ecosystem by building a collaborative effort to advance research in artificial intelligence.,,,,,,,,,,,,,,,,,,"






Google to open artificial intelligence lab in Princeton and collaborate with University researchers





Share on Facebook
Share on Twitter
Share on LinkedIn
Email
Print


By 

Steven Schultz, Office of Engineering Communications

    on 
            Dec. 18, 2018, 3:04 p.m.
       

Google will open an artificial intelligence laboratory in January at 1 Palmer Square in the town of Princeton. This is a view of the main entrance to the lab, which will be led by Princeton computer science professors Elad Hazan and Yoram Singer.Photo byDenise Applewhite, Office of Communications



Two Princeton University computer science(link is external) professors will lead a new Google AI lab opening in January in the town of Princeton. The lab is expected to expand New Jersey’s burgeoning innovation ecosystem by building a collaborative effort to advance research in artificial intelligence.
The lab, at 1 Palmer Square, will start with a small number of faculty members, graduate and undergraduate student researchers, recent graduates and software engineers. The lab builds on several years of close collaboration between Google and professors Elad Hazan and Yoram Singer, who will split their time working for Google and Princeton.
The work in the lab will focus on a discipline within artificial intelligence known as machine learning(link is external), in which computers learn from existing information and develop the ability to draw conclusions and make decisions in new situations that were not in the original data. Examples include speech recognition systems that transcribe a wide spectrum of voices, and self-driving cars that process complex visual cues. In particular, the work will build on recent advances by Hazan, Singer and colleagues in optimization methods for machine learning to improve their speed and accuracy while reducing the required computing power.
“We feel it’s a great opportunity, both for machine learning theorists at Princeton to benefit from exposure to real-world computing problems, and for Google to benefit from long-term, unconstrained academic research that Google may incorporate into future products,” said Singer. 
Hazan said Princeton has longstanding strength in the mathematics and theory behind machine learning, optimization and computing in general. “As academics we try to think about theory for solving problems that are, many times, in the abstract, and it’s very helpful for us to be in touch with real-world problems,” he said.
Inside the Google lab, illustrations showing iconic Princeton campus structures Blair Arch and Whig Hall adorn an interior wall.Photo byDenise Applewhite, Office of Communications
“A primary focus of the group is developing efficient methods for faster training of learning machines,” said Hazan. One of the most popular methods to train deep neural networks, a powerful current approach to machine learning, is an algorithm called AdaGrad, co-developed by Hazan and Singer with their colleague Stanford University professor John Duchi. “The study of efficient mathematical optimization has deep roots in Princeton” said Hazan, “starting from the work of John von Neumann,” who was a visiting faculty member at the University before moving to the neighboring Institute for Advanced Study. 
Von Neumann was also the founder of game theory, which is of great relevance to creating optimization algorithms that cope effectively with various types of noise, or spurious information in data, said Hazan. In the field of mathematical optimization, such robust algorithms are said to attain “no regret guarantees.” 
“Computing started at Princeton more than 80 years ago when alumnus Alan Turing first introduced a theory for how machines could calculate,” said Emily Carter, dean of the School of Engineering and Applied Science. “This collaboration is another excellent example of how fundamental insights in mathematics and theoretical computer science drive new technologies with benefits far beyond the original domain of the work.”
Jennifer Rexford, chair of the Department of Computer Science, said the new venture comes at a time of significant growth in computer science and related areas of data science at Princeton. “The work with Google will complement all three pillars of excellence that make data science at Princeton strong today: a foundation in the theory and math behind computing; collaborations that are accelerating discovery across fields such as genomics, neuroscience, chemistry, psychology and sociology; and leadership, through our Center for Information Technology Policy(link is external), in the broader societal implications of computing such as bias and ethics in AI, privacy and security,” Rexford said.
“It’s an exciting opportunity to work with a leading company while also maintaining the strong academic independence and freedom that is essential to Princeton,” Rexford said. 
The decision to open a lab in Princeton reflects Google’s longstanding openness to collaborating with academic researchers, supporting the open-source community and publishing results in peer-reviewed conferences and journals, said Andrew Pierson, a Google program manager. On a practical level, Google’s enormous computing resources give researchers the ability to run experiments that would otherwise be difficult as they optimize algorithms that deal with millions of variables and perform trillions of calculations, Pierson said.
But a bottom-line motivation for collaborating with Princeton, said Amy McDonald Sandjideh, a technical program manager at Google, is talent. Because the community of artificial intelligence researchers is small, she said, continued progress requires new sources of inspiration and collaboration. 
“We specifically chose a location very close to the University to promote such collaborations,” McDonald Sandjideh said. “Particularly having access to graduate students and even undergrads can provide a lot of inspiration. Sometimes you learn the most from teaching and helping younger people understand what you’ve been working on and that can really push you in new directions. That is a great benefit for Google in working more closely with universities like Princeton that have really excellent minds.”


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LmVmaW5hbmNpYWxjYXJlZXJzLmNvbS9uZXdzLzIwMTgvMTIvYnJldmFuLWhvd2FyZC1haS1rYXJpbS1wYXRyaWNrLWtoaWFy0gEA?oc=5,Brevan Howard takes bigger leap into AI with key appointment - eFinancialCareers,2018-12-17,eFinancialCareers,https://www.efinancialcareers.com,Brevan Howard just promoted one of its own as it seeks to tap into the power of AI.,,Brevan Howard just promoted one of its own as it seeks to tap into the power of AI.,,http://schema.org,,NewsArticle,Brevan Howard takes bigger leap into AI with key appointment,,,,https://cdn.filestackcontent.com/jbmbWG2TRzaaoQM66rur,News,"{'@type': 'Person', 'name': 'Beecher Tuttle'}",,"{'@type': 'Organization', 'name': 'eFinancialCareers', 'logo': 'https://cdn.filestackcontent.com/output=format:png/STeC4XocSHe1udufYKjO'}",,2018-12-17T17:03:37.000Z,2018-12-17T17:03:37.000Z,dhiefc:analytics,,,,,Brevan Howard takes bigger leap into AI with key appointment,,,,,,,,,,,,,https://www.efinancialcareers.com/news/2018/12/brevan-howard-ai-karim-patrick-khiar,english,"Over the last two years in particular, quantitative hedge funds have begun integrating artificial intelligence and machine learning as part of their strategies. Two Sigma, Citadel, AQR and Man Group come to mind as some of the more notable early adopters. Now Brevan Howard appears to be making a bigger push.

 The hedge fund giant has promoted Karim-Patrick Khiar to the head of artificial intelligence in New York, where he’ll work on driven systematic investments. Khiar started with Brevan Howard in 2017 as its head data strategist but moved into his new role last month.

 The move doesn’t mean that Brevan Howard is only now incorporating AI and machine learning technologies. Founder Alan Howard https://www.fnlondon.com/articles/alan-howard-backs-artificial-intelligence-data-venture-20180705 back in July. He said at the time that Brevan Howard was a current user of Quant Insight’s service, which “helps [the fund] untangle complex markets and identify what is driving asset prices.” However, the hedge fund has even deeper ties to Quant Insight, /2017/02/quant-insights, a former partner and macro portfolio manager at Brevan Howard. The startup /2017/03/amit-khanna-quant-insight in 2017, but clearly there is no bad blood between the two firms. Even so, with Khiar now in his new role, Brevan Howard appears to be making more of a direct investment in AI itself.

 Khiar has one of the most eclectic backgrounds you’ll find. He spent roughly eight years as an aerospace engineer in Paris before moving into finance, according to LinkedIn. He later ended up at BlackRock as the global head of structuring for fixed income and, eventually, a director of risk and quantitative analysis and research. He began delving into AI as a managing director at Morgan Stanley in 2015. He has both an MBA and a master’s in financial engineering from the University of California, Berkeley Haas School of Management. He has also done master’s-level work in artificial engineering and aerospace engineering.

 Have a confidential story, tip, or comment you’d like to share? Contact: mailto:btuttle@efinancialcareers.com

 Bear with us if you leave a comment at the bottom of this article: all our comments are moderated by actual human beings. Sometimes these humans might be asleep, or away from their desks, so it may take a while for your comment to appear. Eventually it will – unless it’s offensive or libelous (in which case it won’t). ",,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDE4LzEyLzE3LzE4MTQ0MzU2L2FpLWltYWdlLWdlbmVyYXRpb24tZmFrZS1mYWNlcy1wZW9wbGUtbnZpZGlhLWdlbmVyYXRpdmUtYWR2ZXJzYXJpYWwtbmV0d29ya3MtZ2Fuc9IBAA?oc=5,These faces show how far AI image generation has advanced in just four years - The Verge,2018-12-17,The Verge,https://www.theverge.com,Artificial intelligence has become incredibly good at creating fake AI faces. Just look at this latest research from Nvidia as proof. But what problems will these AI fakes cause in the future? Will society be able to trust its eyes?,,Can you spot the fake AI faces? ,,http://schema.org/,,NewsArticle,These faces show how far AI image generation has advanced in just four years,https://www.theverge.com/2018/12/17/18144356/ai-image-generation-fake-faces-people-nvidia-generative-adversarial-networks-gans,,https://cdn.vox-cdn.com/thumbor/3N5ntVSJcBFJqMe4lv-mMjl2UXw=/0x0:920x613/1400x788/filters:focal(460x307:461x308)/cdn.vox-cdn.com/uploads/chorus_asset/file/13631853/ai_face_generation.jpg,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/3N5ntVSJcBFJqMe4lv-mMjl2UXw=/0x0:920x613/1400x788/filters:focal(460x307:461x308)/cdn.vox-cdn.com/uploads/chorus_asset/file/13631853/ai_face_generation.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/0yXQNjSoawaWwHN-MUcbsW0vYmw=/0x0:920x613/1400x1050/filters:focal(460x307:461x308)/cdn.vox-cdn.com/uploads/chorus_asset/file/13631853/ai_face_generation.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/cIhhsTmqT0X17R9qpDovc1q9sfI=/0x0:920x613/1400x1400/filters:focal(460x307:461x308)/cdn.vox-cdn.com/uploads/chorus_asset/file/13631853/ai_face_generation.jpg', 'width': 1400, 'height': 1400}]",,"[{'@type': 'Person', 'name': 'James Vincent', 'url': 'https://www.theverge.com/authors/james-vincent'}]",,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",,2018-12-17T16:49:06.000Z,2018-12-17T16:49:06.000Z,,,"Tech/Artificial IntelligenceThese faces show how far AI image generation has advanced in just four yearsThese faces show how far AI image generation has advanced in just four years / Those people on the right aren’t real; they’re the product of machine learningBy  James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge. Dec 17, 2018, 11:49 AM ESTShare this story0 Comments / 0 NewThe faces on the left were created by AI in 2014; on the right are ones made by AI in 2018.  Image: Goodfellow et al; Karras, Laine, Aila / NvidiaDevelopments in artificial intelligence move at a startling pace — so much so that it’s often difficult to keep track. But one area where progress is as plain as the nose on your AI-generated face is the use of neural networks to create fake images. In brief: we’re getting scarily good at it. In the image above you can see what four years of progress in AI image generation looks like. The crude black-and-white faces on the left are from 2014, published as part of a landmark paper that introduced the AI tool known as the generative adversarial network (GAN). The color faces on the right come from a paper published earlier this month, which uses the same basic method but is clearly a world apart in terms of image quality. These realistic faces are the work of researchers from Nvidia. In their paper, shared publicly last week, they describe modifying the basic GAN architecture to create these images. Take a look at the pictures below. If you didn’t know they were fake, could you tell the difference? Some of Nvidia’s AI-generated faces. Image: Karras, Laine, AilaWhat’s particularly interesting is that these fake faces can also be easily customized. Nvidia’s engineers incorporated a method known as style transfer into their work, in which the characteristics of one image are blended with another. You might recognize the term from various image filters that are popular on apps like Prisma and Facebook in recent years, which can make your selfies look like an impressionist painting or a cubist work of art.Applying style transfer to face generation allowed Nvidia’s researchers to customize faces to an impressive degree. In the grid below, you can see this in action. A source image of a real person (the top row) has the facial characteristics of another person (right-hand column) imposed onto it. Traits like skin and hair color are blended together, creating what looks like to be an entirely new person in the process.Style transfer allows you to blend facial characteristics from different people.  Image: Karras, Laine, AilaOf course, the ability to create realistic AI faces raises troubling questions. (Not least of all, how long until stock photo models go out of work?) Experts have been raising the alarm for the past couple of years about how AI fakery might impact society. These tools could be used for misinformation and propaganda and might erode public trust in pictorial evidence, a trend that could damage the justice system as well as politics. (Sadly, these issues aren’t discussed in Nvidia’s paper, and when we reached out to the company, it said it couldn’t talk about the work until it had been properly peer-reviewed.) These warnings shouldn’t be ignored. As we’ve seen with the use of deepfakes to create non-consensual pornography, there are always people who are willing to use these tools in questionable ways. But at the same time, despite what the doomsayers say, the information apocalypse is not quite nigh. For one, the ability to generate faces has received special attention in the AI community; you can’t doctor any image in any way you like with the same fidelity. There are also serious constraints when it comes to expertise and time. It took Nvidia’s researchers a week training their model on eight Tesla GPUs to create these faces.There are also clues we can look for to spot fakes. In a recent blog post, artist and coder Kyle McDonald listed a number of tells. Hair, for example, is very difficult to fake. It often looks too regular, like it’s been painted on with a brush, or too blurry, blending into someone’s face. Similarly, AI generators don’t quite understand human facial symmetry. They often place ears at different levels or make eyes different colors. They’re also not very good at generating text or numbers, which just come out as illegible blobs. Some examples of AI-generated faces with obvious asymmetrical features.  Image by Kyle McDonaldIf you read the beginning of this post, though, these hints probably aren’t a huge consolation. After all, Nvidia’s work shows just how fast AI in this domain is progressing, and it won’t be long until researchers create algorithms that can avoid these tells. Thankfully, experts are already thinking about new ways to authenticate digital pictures. Some solutions have already been launched, like camera apps that stamp pictures with geocodes to verify when and where they were taken, for example. Clearly, there is going to be a running battle between AI fakery and image authentication for decades to come. And at the moment, AI is charging decisively into the lead. Comments0 Comments / 0 NewFeatured Videos From The VergeSamsung Galaxy Watch Ultra: ring any bells?
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe $649.99 Samsung Galaxy Watch Ultra doesn’t hide where it got its inspiration from, but it is the first to have FDA-cleared sleep apnea detection.Most PopularMost PopularIt’s never been easier for the cops to break into your phoneThe FBI says it has ‘gained access’ to the Trump rally shooter’s phoneGoogle is reportedly planning its biggest startup acquisition everThe Google Pixel 9 just leaked againAmazon’s press-to-order Dash buttons are officially discontinuedVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",,,,,,,,,,,,,,,,,,,"Developments in artificial intelligence move at a startling pace — so much so that it’s often difficult to keep track. But one area where progress is as plain as the nose on your AI-generated face is the use of neural networks to create fake images. In brief: we’re getting scarily good at it. 

In the image above you can see what four years of progress in AI image generation looks like. The crude black-and-white faces on the left are from 2014, published as part of a landmark paper that introduced the AI tool known as the generative adversarial network (GAN). The color faces on the right come from a paper published earlier this month, which uses the same basic method but is clearly a world apart in terms of image quality. 

These realistic faces are the work of researchers from Nvidia. In their paper, shared publicly last week, they describe modifying the basic GAN architecture to create these images. Take a look at the pictures below. If you didn’t know they were fake, could you tell the difference? 

[Image: Some of Nvidia’s AI-generated faces. https://cdn.vox-cdn.com/thumbor/ZoxdDK4Es5JoiZ4aItSeGOB6F6Q=/0x0:1114x556/1114x556/filters:focal(557x278:558x279)/cdn.vox-cdn.com/uploads/chorus_asset/file/13631823/Screen_Shot_2018_12_17_at_3.25.35_PM.png]

What’s particularly interesting is that these fake faces can also be easily customized. Nvidia’s engineers incorporated a method known as style transfer into their work, in which the characteristics of one image are blended with another. You might recognize the term from various image filters that are popular on apps like Prisma and Facebook in recent years, which can make your selfies look like an impressionist painting or a cubist work of art.

Applying style transfer to face generation allowed Nvidia’s researchers to customize faces to an impressive degree. In the grid below, you can see this in action. A source image of a real person (the top row) has the facial characteristics of another person (right-hand column) imposed onto it. Traits like skin and hair color are blended together, creating what looks like to be an entirely new person in the process.

[Image: Style transfer allows you to blend facial characteristics from different people. https://cdn.vox-cdn.com/thumbor/NsvqcRRUgul0nycoQ_zOeUaC7NA=/0x0:1011x650/1011x650/filters:focal(506x325:507x326)/cdn.vox-cdn.com/uploads/chorus_asset/file/13631832/Screen_Shot_2018_12_17_at_3.32.40_PM.png]

Of course, the ability to create realistic AI faces raises troubling questions. (Not least of all, how long until stock photo models go out of work?) Experts have been raising the alarm for the past couple of years about how AI fakery might impact society. These tools could be used for misinformation and propaganda and might erode public trust in pictorial evidence, a trend that could damage the justice system as well as politics. (Sadly, these issues aren’t discussed in Nvidia’s paper, and when we reached out to the company, it said it couldn’t talk about the work until it had been properly peer-reviewed.) 

These warnings shouldn’t be ignored. As we’ve seen with the use of deepfakes to create non-consensual pornography, there are always people who are willing to use these tools in questionable ways. But at the same time, despite what the doomsayers say, the information apocalypse is not quite nigh. For one, the ability to generate faces has received special attention in the AI community; you can’t doctor any image in any way you like with the same fidelity. There are also serious constraints when it comes to expertise and time. It took Nvidia’s researchers a week training their model on eight Tesla GPUs to create these faces.

There are also clues we can look for to spot fakes. In a recent blog post, artist and coder Kyle McDonald listed a number of tells. Hair, for example, is very difficult to fake. It often looks too regular, like it’s been painted on with a brush, or too blurry, blending into someone’s face. Similarly, AI generators don’t quite understand human facial symmetry. They often place ears at different levels or make eyes different colors. They’re also not very good at generating text or numbers, which just come out as illegible blobs. 

[Image: Some examples of AI-generated faces with obvious asymmetrical features. https://cdn.vox-cdn.com/thumbor/u3o27PLhma47CewKZp8NoFt1Q50=/0x0:800x266/800x266/filters:focal(400x133:401x134)/cdn.vox-cdn.com/uploads/chorus_asset/file/13631847/1_fQEPjVkihxmK4iRm8dyVcA.png]

If you read the beginning of this post, though, these hints probably aren’t a huge consolation. After all, Nvidia’s work shows just how fast AI in this domain is progressing, and it won’t be long until researchers create algorithms that can avoid these tells. 

Thankfully, experts are already thinking about new ways to authenticate digital pictures. Some solutions have already been launched, like camera apps that stamp pictures with geocodes to verify when and where they were taken, for example. Clearly, there is going to be a running battle between AI fakery and image authentication for decades to come. And at the moment, AI is charging decisively into the lead. 
",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vdGhlZ2xvYmVwb3N0LmNvbS8yMDE4LzEyLzE4L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWh1bWFuLWxhYm9yL9IBTGh0dHBzOi8vdGhlZ2xvYmVwb3N0LmNvbS8yMDE4LzEyLzE4L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWh1bWFuLWxhYm9yL2FtcC8?oc=5,Germany’s Artificial Intelligence Initiative: Last Hurrah or New Hope? - The Globe Post,2018-12-18,The Globe Post,https://theglobepost.com,Germany’s investment in artificial intelligence is step in the right direction but redistributing resources is needed as AI could eliminate human labor.,,Germany’s investment in artificial intelligence is step in the right direction but redistributing resources is needed as AI could eliminate human labor.,,http://schema.org,"[{'@type': 'Article', '@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/#article', 'isPartOf': {'@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/'}, 'author': {'name': 'Arend Hintze', '@id': 'https://theglobepost.com/#/schema/person/dd1a433d9f2bcab8926b43586304fd14'}, 'headline': 'Germany&#8217;s Artificial Intelligence Initiative: Last Hurrah or New Hope?', 'datePublished': '2018-12-18T10:05:18+00:00', 'dateModified': '2018-12-18T23:51:35+00:00', 'mainEntityOfPage': {'@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/'}, 'wordCount': 1151, 'publisher': {'@id': 'https://theglobepost.com/#organization'}, 'image': {'@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/#primaryimage'}, 'thumbnailUrl': 'https://theglobepost.com/wp-content/uploads/2018/12/Merkel-AI.jpg', 'keywords': ['Angela Merkel', 'artificial intelligence', 'Germany'], 'articleSection': ['Opinion'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/', 'url': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/', 'name': ""Germany's Artificial Intelligence Initiative: Last Hurrah or New Hope?"", 'isPartOf': {'@id': 'https://theglobepost.com/#website'}, 'primaryImageOfPage': {'@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/#primaryimage'}, 'image': {'@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/#primaryimage'}, 'thumbnailUrl': 'https://theglobepost.com/wp-content/uploads/2018/12/Merkel-AI.jpg', 'datePublished': '2018-12-18T10:05:18+00:00', 'dateModified': '2018-12-18T23:51:35+00:00', 'description': 'Germany’s investment in artificial intelligence is step in the right direction but redistributing resources is needed as AI could eliminate human labor.', 'breadcrumb': {'@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/#primaryimage', 'url': 'https://theglobepost.com/wp-content/uploads/2018/12/Merkel-AI.jpg', 'contentUrl': 'https://theglobepost.com/wp-content/uploads/2018/12/Merkel-AI.jpg', 'width': 940, 'height': 529, 'caption': 'German Chancellor Angela Merkel looking at a robot during a trade fair for industrial technology. Photo: Tobias Schwarz, AFP'}, {'@type': 'BreadcrumbList', '@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://theglobepost.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Germany&#8217;s Artificial Intelligence Initiative: Last Hurrah or New Hope?'}]}, {'@type': 'WebSite', '@id': 'https://theglobepost.com/#website', 'url': 'https://theglobepost.com/', 'name': 'The Globe Post', 'description': 'Daily and breaking news, analysis, opinion, and features from around the world.', 'publisher': {'@id': 'https://theglobepost.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://theglobepost.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://theglobepost.com/#organization', 'name': 'The Globe Post', 'url': 'https://theglobepost.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://theglobepost.com/#/schema/logo/image/', 'url': 'https://theglobepost.com/wp-content/uploads/2017/07/logo-the-globe-post-mobile.png', 'contentUrl': 'https://theglobepost.com/wp-content/uploads/2017/07/logo-the-globe-post-mobile.png', 'width': 140, 'height': 48, 'caption': 'The Globe Post'}, 'image': {'@id': 'https://theglobepost.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/tglobepost/', 'https://twitter.com/tglobepost', 'https://www.instagram.com/tglobepost/', 'https://www.youtube.com/channel/UC6fmebWgQEQ_0B6INdyKoMA']}, {'@type': 'Person', '@id': 'https://theglobepost.com/#/schema/person/dd1a433d9f2bcab8926b43586304fd14', 'name': 'Arend Hintze', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://theglobepost.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/63ebde423e83d823aa3724d31419bcbc?s=96&d=blank&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/63ebde423e83d823aa3724d31419bcbc?s=96&d=blank&r=g', 'caption': 'Arend Hintze'}, 'description': 'Assistant Professor for Integrative Biology &amp; Computer science and Engineering, Michigan State University', 'url': 'https://theglobepost.com/author/arendhintze/'}]",BreadcrumbList,Germany&#8217;s Artificial Intelligence Initiative: Last Hurrah or New Hope?,https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/,"{'@type': 'WebPage', '@id': 'https://theglobepost.com/2018/12/18/artificial-intelligence-human-labor/'}",,"{'@type': 'ImageObject', 'url': 'https://theglobepost.com/wp-content/uploads/2018/12/Merkel-AI.jpg', 'width': 940, 'height': 529}",['Opinion'],"{'@type': 'Person', 'name': 'Arend Hintze', 'url': 'https://theglobepost.com/author/arendhintze/'}",,"{'@type': 'Organization', 'name': 'The Globe Post', 'url': 'https://theglobepost.com', 'logo': {'@type': 'ImageObject', 'url': 'https://theglobepost.com/wp-content/uploads/2018/12/globe-post-logo-1.png'}, 'sameAs': ['https://www.facebook.com/tglobepost/', 'https://twitter.com/tglobepost']}",2018-12-18 05:05:18,2018-12-18 05:05:18,2018-12-18 23:51:35,,,"







World



AI Images of White Faces Are Now ‘Hyper-Real’: Study

by Staff Writer November 13, 2023


","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://theglobepost.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://theglobepost.com/category/opinion/', 'name': 'Opinion'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://theglobepost.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://theglobepost.com/category/opinion/', 'name': 'Opinion'}}]",,Germany&#8217;s Artificial Intelligence Initiative: Last Hurrah or New Hope?,"{'@type': 'SearchAction', 'target': 'https://theglobepost.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}","{'@type': 'ImageObject', 'url': 'https://theglobepost.com/wp-content/uploads/2018/12/globe-post-logo-1.png'}","['https://www.facebook.com/tglobepost/', 'https://twitter.com/tglobepost']",,,,,,,,"{'@type': 'ContactPoint', 'telephone': '2027538899', 'contactType': 'customer service', 'areaServed': ['World']}",,,,,"<p style=""font-weight: 400;"">Germany's government is in trouble. The nationalist AfD party united <a href=""https://www.theguardian.com/world/ng-interactive/2017/sep/24/german-elections-2017-latest-results-live-merkel-bundestag-afd"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://www.theguardian.com/world/ng-interactive/2017/sep/24/german-elections-2017-latest-results-live-merkel-bundestag-afd&amp;source=gmail&amp;ust=1545091781622000&amp;usg=AFQjCNGnVoTLT_Lk8s8wmA5z6e4ZHxxqKg"">12.6 percent</a> of the public voters behind them during the <a href=""https://theglobepost.com/2017/09/27/germany-election-merkel-afd/"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://theglobepost.com/2017/09/27/germany-election-merkel-afd/&amp;source=gmail&amp;ust=1545091781622000&amp;usg=AFQjCNHP8xsjc06_TrbQVQe9AkVXwEDPjA"">2017 elections</a>, for a simple reason: Chancellor <strong>Angela Merkel</strong> took the immigration crisis head-on, allowing <a href=""https://www.vox.com/world/2018/6/18/17474908/germany-immigration-migration-angela-merkel-donald-trump"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://www.vox.com/world/2018/6/18/17474908/germany-immigration-migration-angela-merkel-donald-trump&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNF5Inatc9GzoWG8PRI97OkeNCzpLA"">about 1.4 million refugees</a> to migrate to Germany. This made many people afraid of losing their jobs. The <a href=""https://theglobepost.com/2017/12/02/german-far-right-new-leaders/"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://theglobepost.com/2017/12/02/german-far-right-new-leaders/&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNGXcUJOAkqyGDYk_gvWNxrM75T8QA"">right-wing demagogues</a> jumped on that opportunity and aggravated the discontent of those who have little income, little education, and low support of the government by pointing out that every German euro that goes towards immigrants could have gone to them instead.</p>
<p style=""font-weight: 400;"">People see their financial existence and jobs at peril because of others who have less. But it is not those who have less that get the jobs. It is automation and <a href=""https://theglobepost.com/2018/10/05/ai-racial-bias/"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://theglobepost.com/2018/10/05/ai-racial-bias/&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNGPd1xRFtnOQtAi9Zv-MXlvYCNVVg"">artificial intelligence</a> (AI) that remove the necessity of human labor.</p>
During the <a href=""https://www.history.com/topics/industrial-revolution"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://www.history.com/topics/industrial-revolution&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNHnEA0eKqTEt8GvTIVLA_62m0N_gQ"">industrial revolution</a>, many people who did physical labor lost their jobs to machines, and the job market pushed workers to more cognitive jobs and offices. Instead of muscles and skills, the one thing that machines couldn't do - thinking - became in demand. But with the advent of AI, this last niche for employment will be in jeopardy soon.
<h2><strong>Human Labor and Artificial Intelligence</strong></h2>
Until now, production costs depended on resources, energy, cost of human labor, and the cost of development. We cannot remove energy and resources from this equation, but with AI and <a href=""https://www.zdnet.com/article/what-is-artificial-general-intelligence/"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://www.zdnet.com/article/what-is-artificial-general-intelligence/&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNH6GSPrapoNz2wxiMZ9BEsfeM2qCw"">artificial general intelligence</a> – machines that have the same cognitive abilities as human beings – human labor can be eliminated.

https://www.youtube.com/watch?v=zjeBGkS4LAA

There is, however, one big problem with this approach: the consumers of the products that are created by these new machines will no longer have jobs or an income that allows them to purchase these products. So, how do we prevent this perfect storm of first making everyone unemployed and then consequently crashing the economy altogether?
<p style=""font-weight: 400;"">Avoiding this future by banning AI technology, for example, would only work if everyone is going along. We know how easy it is for politicians to agree on something as obvious as <a href=""https://theglobepost.com/2018/06/27/climate-change-global-warming-pollution/"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://theglobepost.com/2018/06/27/climate-change-global-warming-pollution/&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNGaq6aHf6NSQ4RN1JzLC8r54Y3jHw"">climate change</a>, right? So, the answer is that instead of preventing that future, we should embrace it.</p>


[caption id=""attachment_16176"" align=""alignright"" width=""350""]<a href=""https://theglobepost.com/wp-content/uploads/2018/10/AfD-protest-Germany.jpg""><img class=""wp-image-16176"" src=""https://theglobepost.com/wp-content/uploads/2018/10/AfD-protest-Germany.jpg"" alt=""Supporters of Germany's AfD show German flags and display posters saying 'Merkel must go'"" width=""350"" height=""197"" /></a> AfD-supporters in Berlin. Photo: AFP[/caption]
<p style=""font-weight: 400;"">Ironically, it is the socialist idea of an <a href=""https://basicincome.org/basic-income/"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://basicincome.org/basic-income/&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNEs910GInyXlafVRnW3HkuvzfTZvA"">unconditional basic income</a> that might solve this self-inflicted capitalist nightmare. Distribute resources equally and let the fully automatized free market deal with the question about what needs to be produced. This is exactly what those <a href=""https://theglobepost.com/2018/02/19/germany-far-right/"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://theglobepost.com/2018/02/19/germany-far-right/&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNHgyglypsVG-bVXb0lq9qhS-v3rkg"">German nationalist voters</a> demanded in the first place: “We want to make a living, and we fear for competition.”</p>
Let me address another elephant in the room. We keep hearing that competition and a monetary incentive drive innovation, and therefore, we cannot get rid of money or capitalism. I work on artificial general intelligence not because I get a stellar salary, but because I am an idealist. Redistributing wealth will not get rid of idealists, but allows more people to become one. Outsourcing thinking to the machines also involved outsourcing creativity and innovation. You see, I don't need money to incentivize AI to innovate, I just need AI.
<h2><strong>Germany’s AI Strategy</strong></h2>
I think the German government fears that the country will be outcompeted by others who have an advantage in AI research, but I don't think they are aware of the other socio-economic implications that I made above.

Regardless, the government pledged a <a href=""https://theglobepost.com/2018/12/11/germany-artificial-intelligence/"" target=""_blank"" rel=""noopener"" data-saferedirecturl=""https://www.google.com/url?q=https://theglobepost.com/2018/12/11/germany-artificial-intelligence/&amp;source=gmail&amp;ust=1545091781623000&amp;usg=AFQjCNHV8w3iGSt0N171wp1XWN0U8f1Aug"">€3 billion ($3.4 billion) investment in artificial intelligence</a> to employ more professors and professionals in the domain of AI research.

[caption id=""attachment_17260"" align=""aligncenter"" width=""768""]<a href=""https://theglobepost.com/wp-content/uploads/2018/12/Merkel-Digital-Gipfel.jpg""><img class=""size-full wp-image-17260"" src=""https://theglobepost.com/wp-content/uploads/2018/12/Merkel-Digital-Gipfel.jpg"" alt=""German Chancellor Angela Merkel speaking about artificial intelligence at the Digital Summit in Nuremberg"" width=""768"" height=""481"" /></a> German Chancellor Angela Merkel speaking at the Digital Summit in Nuremberg. Photo: Chrisof Stache, AFP[/caption]
<p style=""font-weight: 400;"">Current job offers seek people who know how to do machine learning (systems that can improve from experience without being explicitly programmed) and AI in general, and because of their competitive salaries attract everyone who knows how to apply these technologies and who doesn’t think that writing grants, publications, and teaching are the most rewarding ways of spending time. As a result, it becomes harder and harder to find professors and postdocs, our academic youth.</p>
University job offers, on the other hand, are often overly focused on finding researchers in deep learning specifically instead of artificial intelligence in general. Current AI technology is dominated by deep learning: a technology that trains complex <a href=""https://www.digitaltrends.com/cool-tech/what-is-an-artificial-neural-network/"" target=""_blank"" rel=""noopener"">artificial neural networks (ANNs)</a> to recognize situations and act accordingly. For example, you keep showing the ANN images of cats and dogs and positively or negatively reinforce the network, until it can tell the difference.

[caption id=""attachment_17509"" align=""alignleft"" width=""250""]<a href=""https://theglobepost.com/wp-content/uploads/2018/12/Siri-e1545015382815.jpg""><img class=""wp-image-17509"" src=""https://theglobepost.com/wp-content/uploads/2018/12/Siri-e1545015382815.jpg"" alt=""Mobile phone showing Siri"" width=""250"" height=""282"" /></a> Photo: AFP[/caption]
<p style=""font-weight: 400;"">ANNs were invented in 1958, but with the extreme computing power we now have and new mathematical and computational tricks, training these ANNs becomes tractable. Remember, the hype we experience from products like Cortana, Google Assistant, and Siri is not coming from great academic advancements in the field, but from the <a href=""http://fortune.com/ai-artificial-intelligence-deep-machine-learning/"" target=""_blank"" rel=""noopener"">ability to translate it into products due to better computational power</a>. The next breakthrough or paradigm shift will not come from deep learning, but another field within the domain of artificial intelligence research.</p>
<p style=""font-weight: 400;"">I am obviously biased and think that neuro-evolution is the ticket to general purpose AI. Regardless, the best hiring strategy in this situation, given that <a href=""https://www.ft.com/content/fe1f9194-e8e3-11e8-a34c-663b3f553b35"" target=""_blank"" rel=""noopener"">Germany is now providing sufficient resources</a>, is bet hedging. My advice would be to advance research in as many directions as possible, by hiring in the general field of AI and not just in deep learning. It is like buying lottery tickets: the more different numbers you have, the bigger your chances to win.</p>
<p style=""font-weight: 400;"">At the same time, the industry is translating academic advancements into products and desperately seeks people with deep learning expertise. While these technologies become much more accessible and easier to use, it is also implied that the new professors to be hired need to be able to teach deep learning and data science.</p>
<p style=""font-weight: 400;"">Right now, job ads for academic positions focus too narrowly on deep learning, and it is exactly that category of people who are also sought in the industry - a competition that makes hiring professors almost impossible. Academia should lead the innovation, and thus an investment in academia should be for future technology, as long as these academics can teach the skills needed in the industry.</p>
<p style=""font-weight: 400;""><a href=""https://www.dw.com/en/germany-launches-digital-strategy-to-become-artificial-intelligence-leader/a-46298494"" target=""_blank"" rel=""noopener"">Germany’s €3 billion investment</a> is a step in the right direction, and 0.1 percent of total GDP is an excellent starting point. Germany, pump as much money into this as possible and hire as diverse as possible! This is not the race to the moon, it is the race for the artificial mind, and this endeavor has an immediate impact on the economy and will change our way of living in the most profound way imaginable. It will make the need to work for money obsolete and requires us to find a sustainable way to redistribute resources.</p>",https://theglobepost.com/#website,Germany&#8217;s Artificial Intelligence Initiative: Last Hurrah or New Hope?,2018-12-18 05:05:18,2018-12-18 23:51:35,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vcHJlc3NyZWxlYXNlcy5yZXNwb25zZXNvdXJjZS5jb20vbmV3cy85NjgyNy9ncmVlbnZhbi1vZmZlcnMtZWFzaWVyLWdyZWVuZXItcmVtb3ZhbHMtd2l0aC1hdXRvbWF0ZWQtaG91ci1ib29raW5nLXVzaW5nL9IBAA?oc=5,"GreenVan offers easier, greener removals with automated 24 hour booking using Artificial Intelligence - ResponseSource",2018-12-17,ResponseSource,https://pressreleases.responsesource.com,"Customers looking to move home - or just a few items - can now book in minutes instead of hours using a very simple chat booking service from GreenVan. Customers get the lowest price promise, free ins...","Health,Home & Garden,Women's Interest & Beauty,Environment & Nature,Consumer Technology,Business & Finance,Public Sector, Third Sector & Legal,Computing & Telecoms,Transport & Logistics,Construction & Property","Customers looking to move home - or just a few items - can now book in minutes instead of hours using a very simple chat booking service from GreenVan. Customers get the lowest price promise, free ins...","Customers looking to move home - or just a few items - can now book in minutes instead of hours using a very simple chat booking service from GreenVan. Customers get the lowest price promise, free ins...",http://schema.org,,Article,"GreenVan offers easier, greener removals with automated 24 hour booking using Artificial Intelligence ",,"{'@type': 'WebPage', '@id': 'https://pressreleases.responsesource.com/news/96827/greenvan-offers-easier-greener-removals-with-automated-hour-booking-using/'}",,"{'@type': 'ImageObject', 'url': 'https://mediaserver.responsesource.com/press-release/115546/GreenVan+Image+17+Dec+18.png', 'thumbnail': {'@type': 'ImageObject', 'url': 'https://mediaserver.responsesource.com/press-release/tb_lrg/115546/GreenVan+Image+17+Dec+18.png'}}",,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'url': 'https://mediaserver.responsesource.com/newsroom-logo/tb_lrg/115462/greenvan.png'}, 'name': 'GreenVan'}",,"{'@type': 'Organization', 'name': 'ResponseSource', 'logo': {'@type': 'ImageObject', 'url': 'https://pressreleases.responsesource.com/img/logo/RS-LOGO-600.jpg'}}",,2018-12-17T10:40:00+00:00,,,,"



GreenVan offers easier, greener removals with automated 24 hour booking using Artificial Intelligence
Monday 17 December 2018 PDF Print




















Customers looking to move home - or just a few items - can now book in minutes instead of hours using a very simple chat booking service from GreenVan. Customers get the lowest price promise, free insurance, a 24 hour manager to help them, as well as being able to specify their own pick up times, free changes and cancellations.

The service – with over a thousand satisfied customers already - uses a mixture of AI, algorithms and automation to provide a revolutionary service for the removals industry, saving money and increasing sustainability for both consumers and drivers.

Anuj Gupta founder of Greenvan says: “Our bot and and human team members are available 24 hours to make it easy for our customers – it takes a couple of minutes on www.GreenVan.eu  to book a job and receive an instant confirmation.”

GreenVan’s Driver Partners who provide the removals services also benefit - they can double their disposable income, get a ready made job sheet, and reduce the need for an office, marketing or their own customer support because GreenVan takes care of all this. Drivers have the opportunity to become their own boss by working on days they want and get more family time. 

This magic equation of customers experiencing lower prices on one hand and the mover drivers doubling their disposable income on the other due to increased volumes makes it an exciting self feeding loop. This greater demand for movers creates more jobs in the economy.

The algorithms optimise the routes and keep the vehicles as regionalised as possible reducing the fuel consumption and carbon emission, making the environment much healthier.The company has moved a thousand customers who seem delighted with the service as many have given a 10 on 10 rating.

GreenVan is supported by the Department of International Trade (DIT) UK and is yet another high growth startup tech company which will play a vital role in reshaping the logistics sector and also feed into the government’s goals of a Greener London. 

The founders have received a number of awards including BEST TECHNOLOGY IN THE WORLD BY MICROSOFT and ERNST & YOUNG ENTREPRENEUR OF THE YEAR NEW YORK for previous successful ventures.

The company’s high profitability at scale makes it a unique value proposition for investors. In the future the company also intends to move into other services including electricians and plumbers where the founders have identified a lot of both customer and vendor pain.

www.Greenvan.eu 
Media or investor enquiries can be sent to:
sara@greenvan.eu
 0207 193 5403


Summary of the business
A PLATFORM WHERE THE USER CAN FIND VENDORS OFFERING VARIOUS HOME SERVICES
THE FIRST SERVICE ADDRESSED IS HOME REMOVALS
THE PLATFORM IS A UNIQUE COMBINATION OF AI, AUTOMATION, BLOCKCHAIN & ALGORITHM
THE PLATFORM MAKES IT AFFORDABLE, EASY, RELIABLE FOR CUSTOMERS TO MOVE
DRIVERS DOUBLE THEIR DISPOSABLE INCOME, WITH NO NEED FOR AN OFFICE, MARKETING ETC
THOUSANDS OF NEW JOBS DUE TO GREATER DEMAND
REDUCTION IN FUEL CONSUMPTION MAKES THE ENVIRONMENT MUCH HEALTHIER https://greenvan.eu/green-mission
THE INDUSTRY TODAY HAS EITHER SMALL PLAYERS WHO CANNOT SCALE BECAUSE OF THE LACK OF SUCH A TECHNOLOGY PLATFORM OR VERY LARGE PLAYERS WHO ARE TOO EXPENSIVE FOR THE GENERAL CONSUMER
THE TEAM IS OF EXPERIENCED ENTREPRENEURS - WINNERS OF BEST TECHNOLOGY IN THE WORLD BY MICROSOFT, HOLDERS OF PATENTS, E & Y AWARD, NEW YORK.
TECHNOLOGY ENABLES THE BUSINESS TO SCALE GLOBALLY WITHOUT MORE MAN POWER
THE BUSINESS HOLDS STRONG POTENTIAL TO BE A UNICORN IN THE NEXT COUPLE OF YEARS




This press release was distributed by ResponseSource Press Release Wire on behalf of GreenVan in the following categories:
			                Health, 			                Home & Garden, 			                Women's Interest & Beauty, 			                Environment & Nature, 			                Consumer Technology, 			                Business & Finance, 			                Public Sector, Third Sector & Legal, 			                Computing & Telecoms, 			                Transport & Logistics, 			                Construction & Property, 			 for more information visit https://pressreleasewire.responsesource.com/about.
",,,,,,,,,,,,,,,,,en,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9pbnNpZGUtdGhlLXBlbnRhZ29ucy1wbGFuLXRvLXdpbi1vdmVyLXNpbGljb24tdmFsbGV5cy1haS1leHBlcnRzL9IBAA?oc=5,"In Project Maven's Wake, the Pentagon Seeks AI Tech Talent - WIRED",2018-12-21,WIRED,https://www.wired.com,"The Defense Department wants to use AI in warfare. In the aftermath of Project Maven, it still needs Big Tech’s help.","['the big story', 'security', 'ai', 'project maven', 'web']","The Defense Department wants to use AI in warfare. In the aftermath of Project Maven, it still needs Big Tech’s help.","The Defense Department wants to use AI in warfare. In the aftermath of Project Maven, it still needs Big Tech’s help.",https://schema.org/,,BreadcrumbList,"In Project Maven's Wake, the Pentagon Seeks AI Tech Talent",https://www.wired.com/story/inside-the-pentagons-plan-to-win-over-silicon-valleys-ai-experts/,"{'@type': 'WebPage', '@id': 'https://www.wired.com/story/inside-the-pentagons-plan-to-win-over-silicon-valleys-ai-experts/'}","https://media.wired.com/photos/5c1c383529ff200b2600066b/1:1/w_750,h_750,c_limit/ai-pentagon-elena-lacey-wired.gif","['https://media.wired.com/photos/5c1c383529ff200b2600066b/16:9/w_992,h_558,c_limit/ai-pentagon-elena-lacey-wired.gif', 'https://media.wired.com/photos/5c1c383529ff200b2600066b/4:3/w_1000,h_750,c_limit/ai-pentagon-elena-lacey-wired.gif', 'https://media.wired.com/photos/5c1c383529ff200b2600066b/1:1/w_750,h_750,c_limit/ai-pentagon-elena-lacey-wired.gif']",the big story,"[{'@type': 'Person', 'name': 'Zachary Fryer-Biggs', 'sameAs': 'https://www.wired.com/author/zachary-fryer-biggs/'}]",,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",,2018-12-21T07:26:14.934-05:00,2018-12-21T07:26:14.934-05:00,tags,,"Zachary Fryer-BiggsThe Big StoryDec 21, 2018 7:26 AMInside the Pentagon’s Plan to Win Over Silicon Valley's AI ExpertsThe Defense Department wants to use AI in warfare. In the aftermath of Project Maven, it still needs Big Tech’s help.Play/Pause ButtonPauseElena Lacey; Getty ImagesSave this storySaveSave this storySaveThe American military is desperately trying to get a leg up in the field of artificial intelligence, which top officials are convinced will deliver victory in future warfare. But internal Pentagon documents and interviews with senior officials make clear that the Defense Department is reeling from being spurned by a tech giant and struggling to develop a plan that might work in a new sort of battle—for hearts and minds in Silicon Valley.The battle began with an unexpected loss. In June, Google announced it was pulling out of a Pentagon program—the much-discussed Project Maven—that used the tech giant’s artificial intelligence software. Thousands of the company’s employees had signed a petition two months earlier calling for an end to its work on the project, an effort to create algorithms that could help intelligence analysts pick out military targets from video footage.Inside the Pentagon, Google’s withdrawal brought a combination of frustration and distress—even anger—that has percolated ever since, according to five sources familiar with internal discussions on Maven, the military’s first big effort to utilize AI in warfare.About This StoryThis article was produced in partnership with the Center for Public Integrity, a nonprofit, nonpartisan news organization.“We have stumbled unprepared into a contest over the strategic narrative,” said an internal Pentagon memo circulated to roughly 50 defense officials on June 28. The memo depicted a department caught flat-footed and newly at risk of alienating experts critical to the military’s artificial intelligence development plans.Trending NowHow a Son Made a Chatbot of His Dying Dad“We will not compete effectively against our adversaries if we do not win the ‘hearts and minds’ of the key supporters,” it warned.Maven was actually far from complete and cost only about $70 million in 2017, a molecule of water in the Pentagon’s oceanic $600 billion budget that year. But Google’s announcement exemplified a larger public relations and scientific challenge the department is still wrestling with. It has responded so far by trying to create a new public image for its AI work and by seeking a review of the department’s AI policy by an advisory board of top executives from tech companies.The reason for the Pentagon’s anxiety is clear: It wants a smooth path to use artificial intelligence in weaponry of the future, a desire already backed by the promise of several billion dollars to try to ensure such systems are trusted and accepted by military commanders, plus billions more in expenditures on the technologies themselves.AdvertisementThe exact role that AI will wind up playing in warfare remains unclear. Many weapons with AI will not involve decision-making by machine algorithms, but the potential for them to do so will exist. As a Pentagon strategy document said in August: “Technologies underpinning unmanned systems would make it possible to develop and deploy autonomous systems that could independently select and attack targets with lethal force.”Developing artificial intelligence, officials say, is unlike creating other military technologies. While the military can easily turn to big defense contractors for cutting-edge work on fighter jets and bombs, the heart of innovation in AI and machine learning resides among the non-defense tech giants of Silicon Valley. Without their help, officials worry, they could lose an escalating global arms race in which AI will play an increasingly important role, something top officials say they are unwilling to accept.“If you decide not to work on Maven, you’re not actually having a discussion on if artificial intelligence or machine learning are going to be used for military operations,” Chris Lynch, a former tech entrepreneur who now runs the Pentagon’s Defense Digital Service, said in an interview. AI is coming to warfare, he says, so the question is, which American technologists are going to engineer it?Most PopularCultureThe Real Reason Will Smith Broke Twitch’s Biggest Streaming RecordBy Adam BumasGearThe Top New Features Coming to Apple’s iOS 18 and iPadOS 18By Julian ChokkattuPoliticsJ.D. Vance Is Trump’s Pick for Vice PresidentBy Vittoria ElliottSecurityUS Senators Secretly Work to Block Safeguards Against Surveillance AbuseBy Dell CameronLynch, who recruits technical experts to spend several years working on Pentagon problems before returning to the private sector, said that AI technology is too important, and that the agency will proceed even if it has to rely on lesser experts. But without the help of the industry’s best minds, Lynch added, “we’re going to pay somebody who is far less capable to go build a far less capable product that may put young men and women in dangerous positions, and there may be mistakes because of it.”Google isn’t likely to shift gears soon. Less than a week after announcing that the company would not seek to renew the Maven contract in June, Google released a set of AI principles which specified that the company would not use AI for “weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.”Some defense officials have complained since then that Google was being unpatriotic, noting that the company was still pursuing work with the Chinese government, the top US competitor in artificial intelligence technology.“I have a hard time with companies that are working very hard to engage in the market inside of China, and engaging in projects where intellectual property is shared with the Chinese, which is synonymous with sharing it with the Chinese military, and then don't want to work for the US military,” General Joe Dunford, chairman of the Joint Chiefs of Staff, commented while speaking at a conference in November.In December testimony before congress, Google CEO Sundar Pichai acknowledged that Google had experimented with a program involving China, Project Dragonfly, aimed at developing a model of what government-censored search results would look like in China. However, Pichai testified that Google currently “has no plans to launch in China.”Project Maven’s aim was to simplify work for intelligence analysts by tagging object types in video footage from drones and other platforms, helping analysts gather information and narrow their focus on potential targets, according to sources familiar with the partly classified program. But the algorithms did not select the targets or order strikes, a longtime fear of those worried about the intersection of advanced computing and new forms of lethal violence.Many at Google nonetheless saw the program in alarming terms.“They immediately heard drones and then they thought machine learning and automatic target recognition, and I think it escalated for them pretty quickly about enabling targeted killing, enabling targeted warfare,” said a former Google employee familiar with the internal discussions.Google is just one of the tech giants that the Pentagon has sought to enlist in its effort to inject AI into modern warfare technology. Among the others: Microsoft and Amazon. After Google’s announcement in June more than a dozen large defense firms approached defense officials, offering to take over the work, according to current and former Pentagon officials.But Silicon Valley activists also say the industry cannot easily ignore the ethical qualms of tech workers. “There’s a division between those who answer to shareholders, who want to get access to Defense Department contracts worth multimillions of dollars, and the rank and file who have to build the things and who feel morally complicit for things they don’t agree with,” the former Google employee said.Most PopularCultureThe Real Reason Will Smith Broke Twitch’s Biggest Streaming RecordBy Adam BumasGearThe Top New Features Coming to Apple’s iOS 18 and iPadOS 18By Julian ChokkattuPoliticsJ.D. Vance Is Trump’s Pick for Vice PresidentBy Vittoria ElliottSecurityUS Senators Secretly Work to Block Safeguards Against Surveillance AbuseBy Dell CameronIn an effort to bridge this gulf and dampen hard-edged opposition from AI engineers, the Defense Department has so far undertaken two initiatives.The first, formally begun in late June, was to create a Joint Artificial Intelligence Center meant to oversee and manage all of the military’s AI efforts, with an initial focus on PR-friendly humanitarian missions. It’s set to be run by Lieutenant General Jack Shanahan, whose last major assignment was running Project Maven. In a politically shrewd decision, its first major initiative is to figure out a way to use AI to help organize the military’s search and rescue response to natural disasters.“Our goal is to save lives,” Brendan McCord, one of the chief architects of the Pentagon’s AI strategy, said while speaking at a technical conference in October. “Our military’s fundamental role, its mission, is to keep the peace. It is to deter war and protect our country. It is to improve global stability, and it’s to ultimately protect the set of values that came out of the Enlightenment.”The second initiative is to order a new review of AI ethics by an advisory panel of tech experts, the Defense Innovation Board, which includes former Google CEO Eric Schmidt and LinkedIn cofounder Reid Hoffman.That review, designed to develop principles for the use of AI by the military, is being managed by Joshua Marcuse, a former adviser to the secretary of defense on innovation issues who is now executive director of the board. Set to take about nine months, the advisory panel will hold public meetings with AI experts, while an internal Pentagon group also considers questions. Then it will forward recommendations to secretary of defense James Mattis about the ways that AI should or should not be injected into weapons programs.“This has got to be about actually looking in the mirror and being willing to impose some constraints on what we will do, on what we won’t do, knowing what the boundaries are,” Marcuse said in an interview.To make sure the debate is robust, Marcuse said that the board is seeking out critics of the military’s role in AI.“They have a set of concerns, I think really valid and legitimate concerns, about how the Department of Defense is going to apply these technologies, because we have legal authority to invade people’s privacy in certain circumstances, we have legal authority to commit violence, we have legal authority to wage war,” he said.Resolving those concerns is critical, officials say, because of the difference in how Washington and Beijing manage AI talent. China can conscript experts to work on military problems, whereas the United States has to find a way to interest and attract outside experts.“They have to choose to work with us, so we need to offer them a meaningful, verifiable commitment that there are real opportunities to work with us where they can feel confident that they’re the good guys,” Marcuse said.Despite his willingness to discuss potential future constraints on AI usage, Marcuse said he didn’t think the board would try to change the Pentagon’s existing policy on autonomous weapons that depend on AI, which was put in place by the Obama administration in 2012.Most PopularCultureThe Real Reason Will Smith Broke Twitch’s Biggest Streaming RecordBy Adam BumasGearThe Top New Features Coming to Apple’s iOS 18 and iPadOS 18By Julian ChokkattuPoliticsJ.D. Vance Is Trump’s Pick for Vice PresidentBy Vittoria ElliottSecurityUS Senators Secretly Work to Block Safeguards Against Surveillance AbuseBy Dell CameronThat policy, which underwent a minor technical revision by the Trump administration in May 2017, doesn’t prevent the military from using artificial intelligence in any of its weapons systems. It mandates that commanders have “appropriate levels of human judgment” over any AI-infused weapons systems, although the phrase isn’t further defined and remains a source of confusion within the Pentagon, according to multiple officials there.It does, however, require that before a computer could be programmed to initiate deadly action, the weapons system that contains it must undergo special review by three senior Pentagon officials—in advance of its purchase. To date that special review hasn’t been undertaken.In late 2016, during the waning days of the Obama administration, the Pentagon took a new look at the 2012 policy and decided in a classified report that no major change was needed, according to a former defense official familiar with the details. “There was nothing that was held up, there was no one who thought, ‘Oh we have to update the directives,’” the former official said.The Trump administration nonetheless has internally discussed making it clearer to weapons engineers within the military—who it fears have been reluctant to inject AI into their designs—that the policy doesn’t ban the use of autonomy in weapons systems. The contretemps in Silicon Valley over Project Maven at least temporarily halted that discussion, prompting the department’s leaders to try first to win the support of the Defense Innovation Board.But one way or another, the Pentagon intends to integrate more AI into its weaponry. “We’re not going to sit on the sidelines as a new technology revolutionizes the battlefield,” Marcuse said. “It’s not fair to the American people, it’s not fair to our service members who we send into harm’s way, and it’s not fair to our allies who depend on us.”The Center for Public Integrity is a nonprofit, nonpartisan, investigative newsroom in Washington, DC. More of its national security reporting can be found here.Enter your email to get the Wired newsletterclose dialogRecommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialogMore Great WIRED StoriesAlexa grew up this year, mostly because we talked to it8 sci-fi writers imagine the bold and new future of workThe mad scramble for the world's most coveted meteoriteGalileo, krypton, and how the true meter came to beEverything you want to know about the promise of 5G👀 Looking for the latest gadgets? Check out our picks, gift guides, and best deals all year round📩 Get even more of our inside scoops with our weekly Backchannel newsletter","[{'@type': 'ListItem', 'position': 1, 'name': 'The Big Story', 'item': 'https://www.wired.com/big-story/'}, {'@type': 'ListItem', 'position': 2, 'name': ""Inside the Pentagon’s Plan to Win Over Silicon Valley's AI Experts""}]",,,,,,,,,,,,,,True,,,,"The battle began with an unexpected loss. In June, Google announced it was pulling out of a Pentagon program—the much-discussed Project Maven—that used the tech giant’s artificial intelligence software. Thousands of the company’s employees had signed a petition two months earlier calling for an end to its work on the project, an effort to create algorithms that could help intelligence analysts pick out military targets from video footage.
Inside the Pentagon, Google’s withdrawal brought a combination of frustration and distress—even anger—that has percolated ever since, according to five sources familiar with internal discussions on Maven, the military’s first big effort to utilize AI in warfare.
“We have stumbled unprepared into a contest over the strategic narrative,” said an internal Pentagon memo circulated to roughly 50 defense officials on June 28. The memo depicted a department caught flat-footed and newly at risk of alienating experts critical to the military’s artificial intelligence development plans.
“We will not compete effectively against our adversaries if we do not win the ‘hearts and minds’ of the key supporters,” it warned.
Maven was actually far from complete and cost only about $70 million in 2017, a molecule of water in the Pentagon’s oceanic $600 billion budget that year. But Google’s announcement exemplified a larger public relations and scientific challenge the department is still wrestling with. It has responded so far by trying to create a new public image for its AI work and by seeking a review of the department’s AI policy by an advisory board of top executives from tech companies.
The reason for the Pentagon’s anxiety is clear: It wants a smooth path to use artificial intelligence in weaponry of the future, a desire already backed by the promise of several billion dollars to try to ensure such systems are trusted and accepted by military commanders, plus billions more in expenditures on the technologies themselves.
Developing artificial intelligence, officials say, is unlike creating other military technologies. While the military can easily turn to big defense contractors for cutting-edge work on fighter jets and bombs, the heart of innovation in AI and machine learning resides among the non-defense tech giants of Silicon Valley. Without their help, officials worry, they could lose an escalating global arms race in which AI will play an increasingly important role, something top officials say they are unwilling to accept.
“If you decide not to work on Maven, you’re not actually having a discussion on if artificial intelligence or machine learning are going to be used for military operations,” Chris Lynch, a former tech entrepreneur who now runs the Pentagon’s Defense Digital Service, said in an interview. AI is coming to warfare, he says, so the question is, which American technologists are going to engineer it?
Lynch, who recruits technical experts to spend several years working on Pentagon problems before returning to the private sector, said that AI technology is too important, and that the agency will proceed even if it has to rely on lesser experts. But without the help of the industry’s best minds, Lynch added, “we’re going to pay somebody who is far less capable to go build a far less capable product that may put young men and women in dangerous positions, and there may be mistakes because of it.”
Google isn’t likely to shift gears soon. Less than a week after announcing that the company would not seek to renew the Maven contract in June, Google released a set of AI principles which specified that the company would not use AI for “weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.”
Some defense officials have complained since then that Google was being unpatriotic, noting that the company was still pursuing work with the Chinese government, the top US competitor in artificial intelligence technology.
“I have a hard time with companies that are working very hard to engage in the market inside of China, and engaging in projects where intellectual property is shared with the Chinese, which is synonymous with sharing it with the Chinese military, and then don't want to work for the US military,” General Joe Dunford, chairman of the Joint Chiefs of Staff, commented while speaking at a conference in November.
In December testimony before congress, Google CEO Sundar Pichai acknowledged that Google had experimented with a program involving China, Project Dragonfly, aimed at developing a model of what government-censored search results would look like in China. However, Pichai testified that Google currently “has no plans to launch in China.”
Project Maven’s aim was to simplify work for intelligence analysts by tagging object types in video footage from drones and other platforms, helping analysts gather information and narrow their focus on potential targets, according to sources familiar with the partly classified program. But the algorithms did not select the targets or order strikes, a longtime fear of those worried about the intersection of advanced computing and new forms of lethal violence.
Many at Google nonetheless saw the program in alarming terms.
“They immediately heard drones and then they thought machine learning and automatic target recognition, and I think it escalated for them pretty quickly about enabling targeted killing, enabling targeted warfare,” said a former Google employee familiar with the internal discussions.
Google is just one of the tech giants that the Pentagon has sought to enlist in its effort to inject AI into modern warfare technology. Among the others: Microsoft and Amazon. After Google’s announcement in June more than a dozen large defense firms approached defense officials, offering to take over the work, according to current and former Pentagon officials.
But Silicon Valley activists also say the industry cannot easily ignore the ethical qualms of tech workers. “There’s a division between those who answer to shareholders, who want to get access to Defense Department contracts worth multimillions of dollars, and the rank and file who have to build the things and who feel morally complicit for things they don’t agree with,” the former Google employee said.
The first, formally begun in late June, was to create a Joint Artificial Intelligence Center meant to oversee and manage all of the military’s AI efforts, with an initial focus on PR-friendly humanitarian missions. It’s set to be run by Lieutenant General Jack Shanahan, whose last major assignment was running Project Maven. In a politically shrewd decision, its first major initiative is to figure out a way to use AI to help organize the military’s search and rescue response to natural disasters.
“Our goal is to save lives,” Brendan McCord, one of the chief architects of the Pentagon’s AI strategy, said while speaking at a technical conference in October. “Our military’s fundamental role, its mission, is to keep the peace. It is to deter war and protect our country. It is to improve global stability, and it’s to ultimately protect the set of values that came out of the Enlightenment.”
The second initiative is to order a new review of AI ethics by an advisory panel of tech experts, the Defense Innovation Board, which includes former Google CEO Eric Schmidt and LinkedIn cofounder Reid Hoffman.
That review, designed to develop principles for the use of AI by the military, is being managed by Joshua Marcuse, a former adviser to the secretary of defense on innovation issues who is now executive director of the board. Set to take about nine months, the advisory panel will hold public meetings with AI experts, while an internal Pentagon group also considers questions. Then it will forward recommendations to secretary of defense James Mattis about the ways that AI should or should not be injected into weapons programs.
“This has got to be about actually looking in the mirror and being willing to impose some constraints on what we will do, on what we won’t do, knowing what the boundaries are,” Marcuse said in an interview.
To make sure the debate is robust, Marcuse said that the board is seeking out critics of the military’s role in AI.
“They have a set of concerns, I think really valid and legitimate concerns, about how the Department of Defense is going to apply these technologies, because we have legal authority to invade people’s privacy in certain circumstances, we have legal authority to commit violence, we have legal authority to wage war,” he said.
Resolving those concerns is critical, officials say, because of the difference in how Washington and Beijing manage AI talent. China can conscript experts to work on military problems, whereas the United States has to find a way to interest and attract outside experts.
“They have to choose to work with us, so we need to offer them a meaningful, verifiable commitment that there are real opportunities to work with us where they can feel confident that they’re the good guys,” Marcuse said.
Despite his willingness to discuss potential future constraints on AI usage, Marcuse said he didn’t think the board would try to change the Pentagon’s existing policy on autonomous weapons that depend on AI, which was put in place by the Obama administration in 2012.
That policy, which underwent a minor technical revision by the Trump administration in May 2017, doesn’t prevent the military from using artificial intelligence in any of its weapons systems. It mandates that commanders have “appropriate levels of human judgment” over any AI-infused weapons systems, although the phrase isn’t further defined and remains a source of confusion within the Pentagon, according to multiple officials there.
It does, however, require that before a computer could be programmed to initiate deadly action, the weapons system that contains it must undergo special review by three senior Pentagon officials—in advance of its purchase. To date that special review hasn’t been undertaken.
In late 2016, during the waning days of the Obama administration, the Pentagon took a new look at the 2012 policy and decided in a classified report that no major change was needed, according to a former defense official familiar with the details. “There was nothing that was held up, there was no one who thought, ‘Oh we have to update the directives,’” the former official said.
The Trump administration nonetheless has internally discussed making it clearer to weapons engineers within the military—who it fears have been reluctant to inject AI into their designs—that the policy doesn’t ban the use of autonomy in weapons systems. The contretemps in Silicon Valley over Project Maven at least temporarily halted that discussion, prompting the department’s leaders to try first to win the support of the Defense Innovation Board.
But one way or another, the Pentagon intends to integrate more AI into its weaponry. “We’re not going to sit on the sidelines as a new technology revolutionizes the battlefield,” Marcuse said. “It’s not fair to the American people, it’s not fair to our service members who we send into harm’s way, and it’s not fair to our allies who depend on us.”

The Center for Public Integrity is a nonprofit, nonpartisan, investigative newsroom in Washington, DC. More of its national security reporting can be found here.

More Great WIRED Stories

Alexa grew up this year, mostly because we talked to it
8 sci-fi writers imagine the bold and new future of work
The mad scramble for the world's most coveted meteorite
Galileo, krypton, and how the true meter came to be
Everything you want to know about the promise of 5G
👀 Looking for the latest gadgets? Check out our picks, gift guides, and best deals all year round
📩 Get even more of our inside scoops with our weekly Backchannel newsletter",,,,,,"{'@type': 'CreativeWork', 'name': 'WIRED'}","The Defense Department wants to use AI in warfare. In the aftermath of Project Maven, it still needs Big Tech’s help.",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LmtkbnVnZ2V0cy5jb20vMjAxOC8xMi9tYWNoaW5lLWxlYXJuaW5nLWV4cGxhaW5hYmlsaXR5LWludGVycHJldGFiaWxpdHktYWkuaHRtbNIBAA?oc=5,Machine Learning Explainability vs Interpretability: Two concepts that could help restore trust in AI - KDnuggets - KDnuggets,2018-12-20,KDnuggets,https://www.kdnuggets.com,"We explain the key differences between explainability and interpretability and why they're so important for machine learning and AI, before taking a look at several techniques and methods for improving machine learning interpretability.",,"We explain the key differences between explainability and interpretability and why they're so important for machine learning and AI, before taking a look at several techniques and methods for improving machine learning interpretability.","We explain the key differences between explainability and interpretability and why they're so important for machine learning and AI, before taking a look at several techniques and methods for improving machine learning interpretability.",,,,,,,,,,,,,,,,2018 Dec Opinions,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vd3d3LnZpY2UuY29tL2VuL2FydGljbGUvN3h5YWJiL2NoaW5hLWFpLWRvbWluYW5jZS1yZWxpZXMtb24teW91bmctZGF0YS1sYWJlbGVyc9IBAA?oc=5,China Is Achieving AI Dominance by Relying on Young Blue-Collar Workers - VICE,2018-12-21,VICE,https://www.vice.com,"To remain the world leader in artificial intelligence, China relies on young “data labelers” who work eight hours a day processing massive amounts of data to make computers smart.",,"To remain the world leader in artificial intelligence, China relies on young “data labelers” who work eight hours a day processing massive amounts of data to make computers smart.","To remain the world leader in artificial intelligence, China relies on young “data labelers” who work eight hours a day processing massive amounts of data to make computers smart.",https://schema.org,"[{'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.vice.com/en'}, {'@type': 'ListItem', 'position': 2, 'name': 'Tech', 'item': 'https://www.vice.com/en/section/tech'}]}, {'@context': 'https://schema.org', '@type': 'NewsArticle', 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.vice.com/en/article/7xyabb/china-ai-dominance-relies-on-young-data-labelers'}, 'headline': 'China Is Achieving AI Dominance by Relying on Young Blue-Collar Workers', 'image': ['https://video-images.vice.com/articles/5c1be0f6edf7c400064f1b1c/lede/1545332276147-ai_11.jpeg?crop=1xw:0.8433382137628112xh;center,center&resize=1200:*'], 'datePublished': '2018-12-21T14:00:00.000Z', 'dateModified': '2018-12-21T14:00:00.000Z', 'author': {'@type': 'Person', 'name': 'Huizhong Wu'}, 'publisher': {'@type': 'Organization', 'name': 'VICE', 'logo': {'@type': 'ImageObject', 'url': 'https://vice-web-statics-cdn.vice.com/images/vice-og.png'}}}, {'@context': 'https://schema.org', '@type': 'ItemList', 'name': 'China Is Achieving AI Dominance by Relying on Young Blue-Collar Workers', 'itemListElement': []}, []]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vY3Jvc3NjdXQuY29tLzIwMTgvMTIvY291bGQtd2FzaGluZ3Rvbi1zdGF0ZS1iZS1uZXh0LWFpLWZyb250aWVy0gEA?oc=5,Could Washington state be the next AI frontier? - Crosscut,2018-12-21,Crosscut,https://crosscut.com,"As the state Legislature contemplates how it can help the emergent industry, the University of Washington lays the groundwork for a future workforce.",,"As the state Legislature contemplates how it can help the emergent industry, the University of Washington lays the groundwork for a future workforce.","As the state Legislature contemplates how it can help the emergent industry, the University of Washington lays the groundwork for a future workforce.",https://schema.org,"[{'@type': 'NewsArticle', 'headline': 'Could Washington state be the next AI frontier?', 'name': 'Could Washington state be the next AI frontier?', 'description': 'As the state Legislature contemplates how\xa0it can help the emergent industry, the University of Washington lays the groundwork for a future workforce.', 'image': {'@type': 'ImageObject', 'representativeOfPage': 'True', 'url': 'https://crosscut.com/sites/default/files/styles/max_2000x2000/public/images/articles/mcknight_amazon_0263_0.jpg?itok=vuG0BXxN', 'width': '2000', 'height': '1333'}, 'datePublished': '2018-12-21T13:00:00Z', 'dateModified': '2018-12-21T05:00:00-0800', 'author': {'@type': 'Person', 'name': 'John Stang'}, 'publisher': {'@type': 'Organization', '@id': 'https://crosscut.com/', 'name': 'Cascade PBS News', 'url': 'https://crosscut.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://crosscut.com/themes/custom/crosscut/assets/images/logos/cpbs_logo.png', 'width': '95', 'height': '51'}}, 'articleSection': 'Politics', 'keywords': ['Education', 'Innovation', 'Labor', 'Washington State'], 'url': 'https://crosscut.com/2018/12/could-washington-state-be-next-ai-frontier', 'thumbnailUrl': 'https://crosscut.com/sites/default/files/styles/thumbnail/public/images/articles/mcknight_amazon_0263_0.jpg?itok=Gdk5lV5h', 'creator': {'@type': 'Person', 'name': 'John Stang'}, 'mainEntityOfPage': 'https://crosscut.com/2018/12/could-washington-state-be-next-ai-frontier'}]",,,,,,,,,,,,,,,,"






Share




Share on Facebook


Share on Twitter


Share via E-mail


Print






Politics

Could Washington state be the next AI frontier?


As the state Legislature contemplates how it can help the emerging industry, the University of Washington lays the groundwork for a future workforce.


by 
      
John Stang


 / 
December 21, 2018









 


Advances in artificial intelligence are at the heart of the Amazon Go stores, where checkers have been replaced by sensors. (Photo by Matt M. McKnight/Crosscut)






Advertisement











An Israeli company claims it can figure out someone’s personality just by having its machine-learning programs study that person’s face. Meanwhile, in China, a machine-learning program picks criminals from noncriminal just from looking at their photos. The program relies on data based on conclusions made by Chinese judges. The criminals looked more masculine, the judges had concluded, had smaller eyes and were more likely to frown than the noncriminals.









But is this a fair way to label someone a criminal?
This is the kind of question that students grapple with in the University of Washington’s new course in artificial intelligence ethics, which wrapped up earlier this month. Developed by professors Adrienne Fairhall and Blaise Aguera y Arcas, the course asks thorny questions about bias, privacy and surveillance in technology that has infiltrated our modern lives, from the checkout counter to self-driving cars.
Another lesson in artificial intelligence has been happening about 60 miles down I-5, where lawmakers have been contemplating the role that government should play in regulating how artificial intelligence  — of which “machine learning” is a subset — is developed and deployed, as well as what to do about its potential impact on labor.



Next:
Four candidates are vying to fill the open WA Supreme Court seat



In recent weeks, the Washington House Technology & Economic Development Committee has received two briefings in Olympia concerning Washington state’s place as a center for artificial intelligence — an attempt to “get our mind around the subject,” said Rep, Jeff Morris, D-Mount Vernon and outgoing chairman of the technology committee. At issue is how the industry can be improved and, if necessary, regulated. 
“What should we be looking for?  What should we be doing?” said Rep. Terry Nealey, R-Dayton. 
The Legislature is acting now because the world of artificial intelligence is booming. 
This month, a report by experts from several universities and corporations — dubbed the “AI Index 2018” — noted that while there were no artificial intelligence startup ventures in 1995, almost 5,000 such companies existed by 2015 and slightly more than 10,000 exist today. Another indication of this boom is that 2017 produced nine times the academic papers on artificial intelligence than were written in 2000. 



Next:
Seattle City Council sends $1.55B transportation tax to the ballot



Washington is a player in this emerging market. The state is currently home to almost 200 ventures dealing with artificial intelligence — from Microsoft and Amazon to the Allen Institute for Artificial Intelligence and dozens of tiny startups. Meanwhile, regional companies, including Expedia, Starbucks, Boeing and T-Mobile, are all working with artificial intelligence.
“We are Ground Zero of an amazing AI cluster,” said Joseph Williams, director of tech industry economic development at the Washington Department of Commerce.
Yet, despite its position in the AI market, Washington has had trouble attracting venture capital — the private investment money needed for startup firms to survive their initial years. Washington has about 100 venture capital deals involving AI in play, said Williams. By comparisons, three venture capital firms in the San Francisco area each have about 100 such deals in play. New York — because it is a banking center — has about 235 in motion.
Other investments are on the rise. The University of Washington, for instance, is increasing its AI footprint.
The number of students at the University of Washington studying some form of artificial intelligence has jumped from about 200 in 2008 to almost 1,000 today. The number of artificial intelligence and machine-learning instructors at the university’s Paul Allen School of Computer Science & Engineering has increased to 20 from eight in the same period.
Naturally, the number of courses at the school for both major and nonmajors has grown as well, to 10 today from four in 2008, and include natural language processing, robotics and deep learning. These do not include artificial intelligence-related classes taught elsewhere at the university, including the new ethics course.
“I think it would be great if we can expand more rapidly,” said Dan Weld, who teaches artificial Intelligence courses at the University of Washington. “I’m not sure we’re meeting the demand.”
“It’s always hard to predict whether we’re at the beginning of huge growth or if we’re at a point where the bubble will pop,” he added, noting that he personally believes the field is facing a huge growth spurt.
Williams said the Seattle area now accounts for 5.9 percent of the job posting for artificial intelligence jobs in the nation — sixth best in the United States, behind New York City at 11.6 percent, San Francisco at 9.6 percent, San Jose at 9.2 percent, Washington, D.C., at 7.9 percent and Boston at 6.1 percent.
“We have way better talent than New York on AI,” Williams said. “(Washington state) is just not on the radar screen.”
Washington state has roughly 6,400 people working in the artificial intelligence industry, although not all are actual AI researchers or scientists, whose jobs come with salaries of $300,000 to $500,000 a year. The competition for these workers is fierce. “We get our data scientists poached all the time,” Sacha Fontaine, energy solutions director for Siemens.
One way the government could help the industry is to increase the flow of homegrown talent, said Weld, the UW instructor. He believes the Legislature should focus on efforts by the state’s school districts to prepare students for the field. “It’s important to make sure computer science is taught at the (elementary) and the high school levels,” he said  
Roughly a third of Washington’s high schools teach advanced computer science, and the state does not have a plan to provide computer science in the rest of the schools, especially for those that currently do not have the money to do so, said Ed Lazowska, who holds the Bill & Melinda Gates Chair at the UW's computer science and engineering school.
“Computer science needs to be available in every school in our state,” he added. 
As far as regulation goes, Dan Grossman, deputy director of UW’s computer science and engineering school, said he believes the Legislature should pick its path carefully in tackling artificial intelligence. “The best regulation is not about a particular technology, but about a particular problem,” he said. “Where autonomous vehicles are allowed and not allowed to drive — that is the role of government.”






      Please support independent local news for all.
    
We rely on donations from readers like you to sustain Crosscut's in-depth reporting on issues critical to the PNW.
Donate









Advertisement




Advertisement












Recent









Politics



The Cascade PBS 2024 Washington Statewide Voter Guide is here





 We partnered with newsrooms around WA to bring you profiles on every candidate, from the governor's race to your local legislative district.




by 
      
Cascade PBS Newsroom Staff


 / 
July 11













News



Dancers struggle to find work as Eastern WA’s last strip club closes





 “Clubs shutting down may not immediately lead to trafficking,” says one advocate. “But it immediately leads to all sorts of other vulnerable situations.”




by 
      
Erin Sellers


 / 
June 28












Advertisement




Advertisement











Topics:

Education,
Innovation,
Labor,
Washington State




Share




Share on Facebook


Share on Twitter


Share via E-mail


Print







",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPGh0dHBzOi8vd3d3LnNub3Blcy5jb20vZmFjdC1jaGVjay9haS1yb2JvdHMta2lsbC1zY2llbnRpc3RzL9IBAA?oc=5,Did Four AI Robots Kill 29 Scientists in Japan? - Snopes.com,2018-12-19,Snopes.com,https://www.snopes.com,Four AI-controlled robots killed 29 scientists in Japan in August 2017. ,"robots, Artificial Intelligence","The claim came from a UFOlogist -- and, yes, it does sound like something from a movie.",,https://schema.org,,BreadcrumbList,Did Four AI Robots Kill 29 Scientists in Japan?,https://www.snopes.com,"{'@type': 'WebPage', '@id': 'https://www.snopes.com//fact-check/ai-robots-kill-scientists/'}",https://mediaproxy.snopes.com/width/1200/height/675/https://media.snopes.com/2018/12/shutterstock_638342005.jpg,"{'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.snopes.com/design/images/logo-s-crop-on.svg', 'url': 'https://www.snopes.com/design/images/logo-s-crop-on.svg', 'caption': 'Snopes.com'}",Junk News,"{'@context': 'http://schema.org/', '@type': 'Organization', 'url': 'https://www.snopes.com', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.snopes.com/design/images/logo-s-crop-on.svg', 'url': 'https://www.snopes.com/design/images/logo-s-crop-on.svg', 'caption': 'Snopes.com'}, 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.snopes.com/design/images/logo-s-crop-on.svg', 'url': 'https://www.snopes.com/design/images/logo-s-crop-on.svg', 'caption': 'Snopes.com'}, 'sameAs': ['https://www.facebook.com/snopes', 'https://twitter.com/snopes', 'https://www.instagram.com/snopesdotcom/', 'https://www.linkedin.com/company/snopes.com', 'https://www.youtube.com/channel/UCHQAmn49BObyOsPHCnKRC4w', 'https://www.pinterest.com/snopesdotcom/', 'https://en.wikipedia.org/wiki/Snopes']}",,"{'@type': 'Organization', 'name': 'Snopes.com', 'logo': {'@type': 'ImageObject', 'url': 'https://media.snopes.com/2017/09/snopes-logo-black.png'}}",2018-12-19T03:52:58Z,2018-12-19T03:52:58Z,2018-12-19T03:52:58Z,,,"



Claim:

											Four AI-controlled robots killed 29 scientists in Japan in August 2017. 										


Rating:





													False
													
About this rating 










In December 2018, social media users began circulating a short and blurry video clip showing a woman relaying a story about 29 scientists who were reportedly killed by artificial intelligence-controlled robots in Japan (""4 robots kill 29 scientists""). One iteration of this footage, which asserted that the AI robot massacre had occurred in South Korea, not Japan, can be glimpsed below:

Advertisement:This clip was taken from an hour-long presentation delivered by conspiracy theorist and UFOlogist Linda Moulton Howe at the Conscious of Life Expo in Los Angeles in February 2018. Howe's presentation was largely about the dangers of artificial intelligence, but it was also entwined with stories about alien encounters, abductions, and alternate dimensions.

Howe kicked off her speech with a story about four AI robots killing 29 scientists in Japan that she reportedly heard about from a former Marine who had been doing contract work for government agencies such as the CIA, the NSA, and the DIA (Defense Intelligence Agency):
Advertisement:
On Saturday August 26 2017, not very long ago, I received a phone call from a whistle blower in the Intel world I've known for about a year and a half. He is an honorably discharged marine, but he continues to work on contracts with the CIA, NSA, DIA agencies. I always keep notebooks all over my house, my office, my car, everywhere so that I can write down a phone call that I can't record or that I'm not in my studio to record.
So I wrote this down almost word for word.
At a top robotics company in Japan this week four robots being developed for military applications killed 29 humans in the lab. And they did it by shooting what he called metal bullets. I didn't know there was any other kind.
The scariest part is that lab workers deactivated two of the robots, took apart the third, but the fourth began restoring itself and somehow connected to an orbiting satellite to download information about how it could rebuild itself even more strongly than before.
And this next sentence, this is a quote, I'm writing this down. I've been doing this for years.
This is serious shit Linda. but you're never going to hear about this in the news. The robotics company has too much to lose, and the government wants AI robot soldiers. Close quote.
Howe's story was suspiciously void of specifics. She didn't identify the source of her information, the name of the factory where the alleged massacre occurred, or the names of any of the scientists who were reportedly killed. And while Howe claimed that reports of this robot uprising were suppressed by the government, one would expect some coverage about the deaths or disappearances of dozens of Japan's top scientists to have hit the news, even if the robot aspect of the story was obscured. Yet we found no such reports.
Advertisement:It was also odd that this tale served as little more than a footnote in Howe's overall presentation. In fact, this outlandish story seemed to function more as an attention-grabbing anecdote and less as a retelling of a genuine incident. After opening with this alleged robot massacre report, Howe transitioned to the dangers of artificial intelligence, spent most of her time focused on alien encounters, and then concluded by saying that humans may actually be the artificially intelligent creations of an alien race: ""Is it fair to ponder that those first humans were artificial intelligence for those who made us from manipulating genetics like robotic lab scientists are now doing on earth today? ... Are we humans actually someone else's androids?""
Linda Moulton Howe's full presentation can be viewed below:

Advertisement:Howe has told this story at least one other time, as part of an interview with the ""Mysterious Outpost Radio"" at the ""Ozark Mountain UFO Conference."" During that telling, Howe added that her Marine source would only communicate with her in short texts or 30-second phone calls because his phone had been tapped, and that she made no claims of having handwritten notes of those conversations. Howe also maintained that her source didn't actually witness any such robot massacre, but that he was relaying information he had reportedly come across during his contract work:

At best, the claim that 29 scientists were killed by AI robots in Japan is based on third-hand information unsupported by any actual evidence. At worst, this rumor was made up out of whole cloth as an attention-grabbing anecdote for a speech about how human beings are merely the artificially intelligent creations of an alien race.
Advertisement:","[{'@type': 'ListItem', 'name': 'Homepage', 'item': 'https://www.snopes.com', 'position': 1}, {'@type': 'ListItem', 'name': 'Fact Check', 'item': 'https://www.snopes.com/fact-check/', 'position': 2}]",,,,"{'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.snopes.com/design/images/logo-s-crop-on.svg', 'url': 'https://www.snopes.com/design/images/logo-s-crop-on.svg', 'caption': 'Snopes.com'}","['https://www.facebook.com/snopes', 'https://twitter.com/snopes', 'https://www.instagram.com/snopesdotcom/', 'https://www.linkedin.com/company/snopes.com', 'https://www.youtube.com/channel/UCHQAmn49BObyOsPHCnKRC4w', 'https://www.pinterest.com/snopesdotcom/', 'https://en.wikipedia.org/wiki/Snopes']",,,,,,,,,,,,,,,,,,,,"The claim came from a UFOlogist -- and, yes, it does sound like something from a movie.",Four AI-controlled robots killed 29 scientists in Japan in August 2017. ,"{'@type': 'Rating', 'alternateName': 'False'}",{'@type': 'CreativeWork'},,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvc2NpZW5jZS9ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3BvdHRlZC1ldmVyeS1zb2xhci1wYW5lbC1pbi10aGUtdS1z0gFpaHR0cHM6Ly93d3cucGJzLm9yZy9uZXdzaG91ci9hbXAvc2NpZW5jZS9ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3BvdHRlZC1ldmVyeS1zb2xhci1wYW5lbC1pbi10aGUtdS1z?oc=5,How artificial intelligence spotted every solar panel in the U.S. - PBS NewsHour,2018-12-19,PBS NewsHour,https://www.pbs.org,Curious onlookers can check out the open-access maps. Publicly available information on this scale could help revolutionize the future of energy.,,Curious onlookers can check out the open-access maps. Publicly available information on this scale could help revolutionize the future of energy.,Curious onlookers can check out the open-access maps. Publicly available information on this scale could help revolutionize the future of energy.,,,,,,,,,,,,,,,,Science,,"






Full Episode










Monday, Jul 15


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vcG9saWN5b3B0aW9ucy5pcnBwLm9yZy9tYWdhemluZXMvZGVjZW1iZXItMjAxOC9mdXR1cmUtd29ya2Vycy1yaWdodHMtYWktYWdlL9IBAA?oc=5,The future of workers' rights in the AI age - Policy Options,2018-12-17,Policy Options,https://policyoptions.irpp.org,"When thinking about protecting basic rights for citizens in the AI age, we should ask how technology contributes to general welfare and good society.",,"When thinking about protecting basic rights for citizens in the AI age, we should ask how technology contributes to general welfare and good society.",,https://schema.org,"[{'@type': 'WebSite', '@id': 'https://policyoptions.irpp.org/#website', 'url': 'https://policyoptions.irpp.org/', 'name': 'Policy Options', 'description': 'Institute for Research on Public Policy', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://policyoptions.irpp.org/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://policyoptions.irpp.org/magazines/december-2018/future-workers-rights-ai-age/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://policyoptions.irpp.org/wp-content/uploads/sites/2/2018/12/Wp-kai.jpg', 'width': 2000, 'height': 700}, {'@type': 'WebPage', '@id': 'https://policyoptions.irpp.org/magazines/december-2018/future-workers-rights-ai-age/#webpage', 'url': 'https://policyoptions.irpp.org/magazines/december-2018/future-workers-rights-ai-age/', 'name': 'The future of workers’ rights in the AI age', 'isPartOf': {'@id': 'https://policyoptions.irpp.org/#website'}, 'primaryImageOfPage': {'@id': 'https://policyoptions.irpp.org/magazines/december-2018/future-workers-rights-ai-age/#primaryimage'}, 'datePublished': '2018-12-17T11:31:14+00:00', 'dateModified': '2021-04-02T12:36:26+00:00', 'description': 'When thinking about protecting basic rights for citizens in the AI age, we should ask how technology contributes to general welfare and good society.', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://policyoptions.irpp.org/magazines/december-2018/future-workers-rights-ai-age/']}]}, {'@type': 'Person', '@id': ''}]",,,,,,,,,,,,,,,,"







EconomySocial Policy 


				How to help older Canadians continue to work 
			

by  Rosanna Tamburri
July 2, 2024 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiigFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2NvZ25pdGl2ZXdvcmxkLzIwMTgvMTIvMjAvZ2VvZmYtaGludG9uLWRpc21pc3NlZC10aGUtbmVlZC1mb3ItZXhwbGFpbmFibGUtYWktOC1leHBlcnRzLWV4cGxhaW4td2h5LWhlcy13cm9uZy_SAQA?oc=5,Geoff Hinton Dismissed The Need For Explainable AI: 8 Experts Explain Why He's Wrong - Forbes,2018-12-20,Forbes,https://www.forbes.com,"Geoffrey Hinton, Godfather of AI and Head of Google Brain dismissed the need for Explainable AI. His justification has set off a discourse among AI/ML practitioners in industry, academia and government, who were eager to refute his arguments.",,"Geoffrey Hinton, Godfather of AI and Head of Google Brain dismissed the need for Explainable AI. His justification has set off a discourse among AI/ML practitioners in industry, academia and government, who were eager to refute his arguments.","Geoffrey Hinton, Godfather of AI and Head of Google Brain dismissed the need for Explainable AI. His justification has set off a discourse among AI/ML practitioners in industry, academia and government, who were eager to refute his arguments.",http://schema.org,,BreadcrumbList,Geoff Hinton Dismissed The Need For Explainable AI: 8 Experts Explain Why He's Wrong,https://www.forbes.com/sites/cognitiveworld/2018/12/20/geoff-hinton-dismissed-the-need-for-explainable-ai-8-experts-explain-why-hes-wrong/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/cognitiveworld/files/2018/12/QuestionMarksStack-1200x800.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",AI & Big Data,"{'@type': 'Person', 'name': 'Hessie Jones', 'url': 'https://www.forbes.com/sites/hessiejones/', 'description': 'Hessie Jones is an Author, Strategist, Investor and Data Privacy Practitioner, advocating for human-centred AI, education and the ethical distribution of AI in this era of transformation. She is a member of the cofounding team of the Personally identifiable Information Standards Architecture (PIISA), developing an open model to detect and remediate PII in AI models; is also a cofounding member of MyData Canada, is on the Board of Women in AI Ethics and is the Innovation Manager with Altitude Accelerator. In her work, she aims to advance the quality of human-computer experiences through values-based innovation prioritizing human-centred design. As a seasoned digital strategist, author, tech geek and data junkie, she has spent the last 18 years on the internet at Yahoo!, Aegis Media, CIBC, and Citi, as well as tech startups including Cerebri and OverlayTV. Hessie saw things change rapidly when search and social started to change the game for advertising and decided to figure out the way new market dynamics would change corporate environments forever: in process, in culture and in mindset. She launched ArCompany in social intelligence, AI readiness and research. Through the weekly think tank discussions her team curated, she surfaced the generational divide in this changing technology landscape across a multitude of topics. She was highlighted in 2019 in the 100 Brilliant Women in AI Ethics. She is also a board member with Technology for Good Canada and a contributor/editor to GritDaily, and Forbes, as well as a former editor for Towards Data Science.', 'sameAs': ['https://www.linkedin.com/in/hessiejones1/', 'https://www.twitter.com/hessiejones', 'https://muckrack.com/hessie-jones', 'hessie.jones']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2018-12-20T22:47:00-05:00,2018-12-20T22:47:01-05:00,AI & Big Data,,"More From ForbesJun 17, 2024,04:42am EDTProtecting Human Rights In The Age Of Intelligent MachinesApr 24, 2024,05:00am EDTWhat AI Can Tell Us About OzempicFeb 22, 2024,03:42am ESTUnlocking The Power Of Social Data For Clinical Trial DesignJan 25, 2024,04:55am ESTCPG Product Innovation Should Be A Science, Not An ArtAug 7, 2023,08:57am EDTListening Before We Talk: Why Social Data Is Key To Successful NPD In 2023Mar 28, 2023,10:07am EDTHow Technology Is Empowering CPGs To Do More With LessFeb 21, 2023,05:24am ESTAre Humans And Collaboration Still At The Heart Of Innovation?Edit StoryForbesInnovationAIGeoff Hinton Dismissed The Need For Explainable AI: 8 Experts Explain Why He's WrongHessie JonesContributorCOGNITIVE WORLDContributor GroupOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 20, 2018,10:47pm ESTUpdated Dec 20, 2018, 10:47pm ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







A heap of questions..
Depositphotos enhanced by CogWorld





If the expectation is that automation will be ubiquitous in the next decade, reliance on human judgement will diminish. The promises of Artificial Intelligence are met with cautious optimism as the technology evolves and the environment around it attempts to keep pace. In this nascent period, industry, academia and lawmakers are grappling with the outcomes of these technologies and their impact on our social norms. The domino effect here created by AI will alter all facets of policy, technology and society.

In a recent interview with Wired Geoff Hinton, distinguished computer scientist, Head of Google Brain, and renowned for his work with Artificial Neural Networks, stated this when prompted about AI's eventual role in decision-making:

I’m an expert on trying to get the technology to work, not an expert on social policy. One place where I do have technical expertise that’s relevant is [whether] regulators should insist that you can explain how your AI system works. I think that would be a complete disaster.
PROMOTED
People can’t explain how they work, for most of the things they do. When you hire somebody, the decision is based on all sorts of things you can quantify, and then all sorts of gut feelings. People have no idea how they do that. If you ask them to explain their decision, you are forcing them to make up a story. 
Neural nets have a similar problem. When you train a neural net, it will learn a billion numbers that represent the knowledge it has extracted from the training data. If you put in an image, out comes the right decision, say, whether this was a pedestrian or not. But if you ask “Why did it think that?” well if there were any simple rules for deciding whether an image contains a pedestrian or not, it would have been a solved problem ages ago.
... [In response to how do we trust systems?] You should regulate them based on how they perform. You run the experiments to see if the thing’s biased, or if it is likely to kill fewer people than a person. With self-driving cars, I think people kind of accept that now. That even if you don’t quite know how a self-driving car does it all, if it has a lot fewer accidents than a person-driven car then it’s a good thing. I think we’re going to have to do it like you would for people: You just see how they perform, and if they repeatedly run into difficulties then you say they’re not so good.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            




I reached out to notable practitioners in AI/ML industry, government and academia to weigh in on his arguments:  Ann Cavoukian, Rumman Chowdhury, Joy Buolamwini, Karen Bennet, Tim Miller, Heather Roff, Alejandro Saucedo and David Gunning. This article curates this discourse:
Let's break this down:
Hinton: ""I’m an expert on trying to get the technology to work, not an expert on social policy. One place where I do have technical expertise that’s relevant is [whether] regulators should insist that you can explain how your AI system works. I think that would be a complete disaster.""
For sometime, debate's ensued to determine who is liable for societal or individual harms resulting from algorithmic flaws: The data scientist, the machine or the company? For Dr. Heather Roff, Associate Fellow from the Leverhulme Centre for the Future of Intelligence, University of Cambridge, the responsibility needs to be broadened. She asserts,

This is a dangerous position to take. An expert on technology who feels themselves divorced from social or policy implications does not understand that technology is not value neutral, and that their decisions—even seemingly basic ones on how many gradient descents to take in a system — have socio-political implications. If one thinks they are only Scientists doing Science, but then simultaneously think that regulators should take an interest has fundamentally misunderstood their role as scientists engaging in socially and morally important questions. If your work requires legislation then you should think about that at the design stage… period.

Dr. Rumman Chowdhury, Managing Director and Global Lead for Responsible AI at Accenture agrees with Roff and addresses the very harms that today's AI experimentation exhibit. The fallout is societal. The solution needs to be a holistic collaboration between technology and policy.


We cannot divorce 'making things work' and 'impact on society' when it comes to applied artificial intelligence. Frankly, your AI does not ""work"" if it is biased, perpetuates social inequality and discrimination, or reinforces unequal power structures. Setting up that delineation is not only dangerous, it sets up a false dichotomy of ""tech innovators"" versus ""regulators."" Regulation, whether in the form of social norms, guidelines, or enforceable law, is intended to enable trust and ease adoption of technology in a way that is beneficial to society. Safe innovation is enabled with well designed regulation. 


Hinton: ""People can’t explain how they work, for most of the things they do... People have no idea how they do that. If you ask them to explain their decision, you are forcing them to make up a story.""
 

Timothy Miller, Associate Professor in computer science at the University of Melbourne, Australia, whose specializes in explainable AI and human-agent collaboration, disputes Hinton's claim on the limitations of human explanation: 

His quoted paragraph is itself an explanation: an explanation of why he has reached the decision that explainability for AI would be a disaster. Is he making up a story about this? I imagine he would claim that he is not and that it is based on careful reasoning. But in reality, it is based on neurons in his brain firing in a particular way that nobody understands. The ability to communicate his reasons to others is a strength of the human brain. Philosopher Daniel Dennett claims that consciousness itself is simply our brain creating an `edited digest’ of our brains inner workers for precisely the purpose of communicating our thoughts and intentions (including explanations) to others. 

Hinton: ""Neural nets have a similar problem. When you train a neural net, it will learn a billion numbers that represent the knowledge it has extracted from the training data. If you put in an image, out comes the right decision, say, whether this was a pedestrian or not. But if you ask “Why did it think that?” well if there were any simple rules for deciding whether an image contains a pedestrian or not, it would have been a solved problem ages ago.""
So if humans are to slowly cede control to autonomous algorithms, it will increasingly become difficult to understand what led to those decisions. Deep Learning requires minimal supervision and with enough training data can identify patterns from the data it accesses. As Hinton notes, eventually it becomes more difficult, even for the architects of this algorithm to understand the specific reasons for those outcomes. Dr. Ann Cavoukian, Distinguished Expert-in-Residence, leading the Privacy by Design Centre of Excellence at Ryerson University and former three-term Privacy Commissioner of Ontario, agrees with this.... somewhat:

...humans can externalize features that define a dog... however with current deep learning algorithms, although they may initially decompose an image into relevant features, and then recompose those features back into an image for categorization, these features are implicit to the algorithm, buried in the myriad numbers of parameter values. Current algorithms cannot externalize these features and use them to explain a decision. What is needed are algorithms that construct “wholes” from previously learned “parts/features” such that the features are also external to the algorithm that is making the decision.
...there is a second process taking place: there is a meta-algorithm in the brain that is able to view the process of decision-making and collect the sequence of features that were involved in the decision, and based on those, output the explanation. Again, this cannot be done with existing deep learning because the features are implicit– in the parameter values. Moreover, any one parameter value may affect features associated with categories other than “dog,” in the above example.

For Heather Roff, comparing humans to neural nets is not a ""true equivalence"":

...it is false equivalence. We can interrogate and probe human beings as to why they did X or Y. We even claim that we have AI based “lie detectors” to use micro facial expressions to show when someone is being untruthful. So why should we think that AI can save us from our worst selves but also accept that we cannot as humans figure these same things out? Designers must figure out what to measure, what data is important or relevant and the like, and AIs right now are not able to do that themselves. So to claim that humans are inherently opaque and non-transparent and that justifies us using other intelligence that are actually more opaque and inherently nonhuman-like in their reasoning as a justified argument is a false equivalence. Humans have a theory of mind. AIs right now do not. I don’t have a sense of what another being like me may think, if I’m an AI. I DO have that as a human being. And this excuse — as a an attempted justification at using tech that we don’t understand fully — is a red herring.

For the DOD, where precision in aspects of  war require investigation and justification, David Gunning introduces the work being done on explainable ML that will allow future warfighters to ""understand, appropriately trust and manage an emerging generation of AI Machine partners"" :

There are techniques to explain deep nets: DARPA’s Explainable AI (XAI) program, and a growing community of researchers, are developing techniques that can be used to explain, at least partially, deep nets: (1) there are techniques that can select the training examples that were most influential in a decision; (2) there are techniques to identify the most salient input features used in a decision; (3) there are network dissection techniques that can identify meaning features inside the layers of a deep net that can be used for explanation; and: (4) there are deep learning researchers who are developing deep learning techniques to generate explanations. 

Alejandro Saucedo, Chief Scientist, The Institute for Ethical AI & Machine Learning, partially agrees with Hinton in that it's not possible to open complex systems or models and provide a thorough explanation, however only focusing on the algorithm itself and trying to understand the value of each weight and its interaction with the outcomes is short-sighted.


AI explainability cannot be addressed by solely looking at it as a technological challenge. It requires consideration of the processes, infrastructure and even humans (yes, humans) operating the algorithms themselves.
It is possible to reach a reasonable level of explainability and accountability by ensuring the right touchpoints with domain experts are in place throughout the development and operation of AI systems. Sometimes this may involve a trade-off between explainability and accuracy, but it may be required depending on the critical nature of the project. A reasonable level of explainability can only be achieved through cross-functional collaboration across technology experts, industry practitioners and policy-makers.
At the Institute for Ethical AI, we are empowering industry practitioners to find this reasonable level of explainability with the AI Procurement Framework we released this year. It provides professionals with the tools to evaluate the maturity of their machine learning systems through a checklist which highlights red flags around processes and infrastructure.


Hinton: ""You should regulate them based on how they perform. You run the experiments to see if the thing’s biased, or if it is likely to kill fewer people than a person. With self-driving cars, I think people kind of accept that now. That even if you don’t quite know how a self-driving car does it all, if it has a lot fewer accidents than a person-driven car then it’s a good thing. I think we’re going to have to do it like you would for people: You just see how they perform, and if they repeatedly run into difficulties then you say they’re not so good.""
Reactive legislation cannot and should not be the panacea for technology going forward. Today, rampant harms as a result of existing bias in systems, unproven technology raise ethical concerns about their deployment. Recidivism, self-driving cars, social bots and facial recognition technologies released into the ether have created a growing movement to determine thresholds for accuracy with a check on legal and societal acceptances before they are commercialized. Joy Buolamwini, MIT Media Lab, Graduate Researcher and Founder, Algorithmic Justice League, who has extensive experience in facial recognition technology has been a strong proponent for government action:


Not only do we need to look at biased outcomes we need to look at bias from design, development, deployment, and governance of AI. Even systems that show decreased of harmful technical bias can be deployed in ways that breach civil liberties and human rights. Take the example of facial analysis systems which my research has shown to have substantial racial and gender bias. Companies have been working to reduce this technical bias, but there still needs to be accountability about how the technology is used and who it is sold to. Given everything we know about facial analysis technology failures it should not be used for lethal applications. Yet companies like Microsoft and Amazon appear poised to apply the technology for fatal military use if left unchecked. Even though the social impact of facial recognition technology is ill understood, companies are equipping law enforcement departments with this technology with no legal oversight or meaningful accountability. We need explanations for irresponsible use of facial analysis technology and a moratorium on life or liberty threatening applications. This is why we launched the Safe Face Pledge to prevent the lethal use and mitigate abuse of facial analysis technology. 



In business, justification behind decisions is a standard practice. In the fallout of Enron, the genesis of laws like Sarbanes Oxley were formed for the purpose of protecting the public and the business from fraud or errors. Explainability has been the business norm. It's our system of checks and balances. Ann Cavoukian, who served in policy for three consecutive terms as Privacy Commissioner disagrees with regulation as a result of performance:

I don’t share Geoff’s view of after-the-fact regulation. Technology is simply moving far too fast, and regulations, in this day and age, are a lagging remedy. We must be pre-emptive and proactively build-in explainability. However, to implement useful explainability will require different artificial architectures from the existing ones.



 Rumman Chowdhury goes a step further beyond explainability and towards understandable AI for law, business and society:



In talking about ""explainability"" as a false fix, Hinton is raising a discussion those of us in the ethics and AI space have addressed already. We agree, that explaining the activation functions of nodes, or a technical explanation of decisions, is not useful. What we seek is actionable understanding. Depending on the implementation (whether human or algorithmic), there are decisions that need an explanation, and we work to create understandable and actionable explanations to AI outcomes. This means, not only creating systems of explanations that are useful to humans, but creating systems of addressing and redressing potential issues and harms.


Karen Bennet, Principle at ArCompany (disclosure) and former senior engineering executive at Yahoo!, Redhat and IBM provides a pragmatic perspective that supports Chowdhury's understandable AI, and builds more accountability within data science and engineering:

In all the organizations that I have been working with, there is a disconnect between the people who are building predictive models and those who know how to best serve the organization's objectives. There are laws, standards or regulations that an organization must adhere to, so we do need to solve the problem of making an intelligence system accountable, so it can be audited and trusted to do the right thing. In the financial industry, e.g., before software is deployed live, there is an exhaust checklist that must be adhered to get approval; and one of them is explaining to a non-techie what the software does. It is not enough to just say look at the results. As incidents happen, the judicial system will also require these explanations. I suggest we look at Intelligent systems in (4) categories: Research/Human in Loop; Applied/Human in Loop; Research/Autonomous and Applied/Autonomous, as each has different requirements.

AI adoption comes with trust in our systems, with the belief that humanity's interests are given full consideration in AI's decisions. We're not there yet. In retrospect, this discourse is necessary to bring the issues of technology and all its impacts to the forefront. The division that exists between research and regulation will quickly dissipate as AI slowly wields itself into all facets of our lives.Hessie JonesFollowingFollowHessie Jones is an Author, Strategist, Investor and Data Privacy Practitioner, advocating for human-centred AI, education and the ethical... Read MoreEditorial StandardsPrintReprints & Permissions","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",,Geoff Hinton Dismissed The Need For Explainable AI: 8 Experts Explain Why He's Wrong,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiiwFodHRwczovL3d3dy5uZXh0Z292LmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS8yMDE4LzEyL2FpLXlvdXItbmV4dC1qb2ItY291bGQtYmUtZmx5aW5nLWNhci1kZXZlbG9wZXItb3ItY3liZXItY2FsYW1pdHktZm9yZWNhc3Rlci8xNTM2NDAv0gEA?oc=5,"With AI, Your Next Job Could Be 'Flying Car Developer' Or 'Cyber Calamity Forecaster' - Nextgov/FCW",2018-12-18,Nextgov/FCW,https://www.nextgov.com,Can man and machine can co-exist at work?,,Can man and machine can co-exist at work?,Can man and machine can co-exist at work?,http://schema.org,,Article,"With AI, Your Next Job Could Be 'Flying Car Developer' Or 'Cyber Calamity Forecaster'",https://www.nextgov.com,https://qz.com/india/1499168/the-new-tech-jobs-ai-big-data-will-create-as-per-cognizant/,,"{'url': 'https://cdn.nextgov.com/media/img/cd/2018/12/18/121818aiNG/route-fifty-lead-image.jpg?1627467788', 'width': 1200, '@type': 'ImageObject', 'height': 550}",,"{'url': '/voices/nupur-anand/14322/', '@type': 'Person', 'name': 'Nupur Anand'}",,"{'@type': 'Organization', 'name': 'Quartz'}",,2018-12-18T15:00:00,2023-07-10T17:33:02,,,"

With AI, Your Next Job Could Be 'Flying Car Developer' Or 'Cyber Calamity Forecaster'
                    CNStock/Shutterstock.com
                  
Sponsor Message

Sponsor Message


      
  Get the latest federal technology news delivered to your inbox.

    emailStay Connected
Sponsor Message

Sponsor Message

Featured eBooks
  Cyber Workforce
            Read Now
              Law Enforcement TechRead NowAI in the WorkplaceRead Now





            
              
                
                  




  


By

Nupur Anand,Quartz







































            
              
                
  



  By



        Nupur Anand
      ,Quartz

|

             December 18, 2018
            

Can man and machine can co-exist at work?






                  Artificial Intelligence
                









                  Career Advice
                









                  Workforce
                












































Have you wondered what new job roles the rise of artificial intelligence and data analytics will throw up in the near future?Cognizant, IT services major, tried to figure it out and here’s what it has found. In a study it published Monday, the IT major listed 21 roles that will emerge in the next 10 years and that will be central to the future of work. Some of these are:“…even as work is changing with the emergence of AI, humans have never been more integral to the future of work,” the study said. “These jobs are both plausible and futuristic—and represent important work that humans will continue to need to do.”Cognizant believes man and machine can co-exist in these roles. These futuristic jobs fall under the same theme. However, it is extremely important for techies to upgrade their skills to remain relevant in the job market.“With the future of work evolving quickly, skills too must evolve to keep pace. Frequent skill upgrades are needed to ensure that people have the relevant skills to be–and stay–employable,” added Cognizant.This should serve as a wake-up call for graduates in India who are anyway in dire need for re-skilling. As per some estimates, currently, not even 60 percent of the graduates from management, technical, and engineering institutions get placed, Satya Pal Singh, the union minister of state for human resources development, told parliament Monday.“To encourage 100% placements to the graduates, All India Council for Technical Education (AICTE) has launched outcome-based model curriculum for UG (undergraduation) and PG (postgraduation) level courses in engineering and management programmes to make it industry oriented. Institutions have now been made responsible for arranging internships of their students so as to enhance their employability,” he added.However, clearly, a lot more needs to be done.








Share This:



NEXT STORY:

              Homeland Security Delegation Visits Asia for Emerging Tech Ideas
            













Human operators must be held accountable for AI’s use in conflicts, Air Force secretary says







Why NIST is prioritizing creating a dictionary of AI development







SSA restructures tech shop to center on the CIO







How a push to the cloud helped a Ukrainian bank keep faith with customers amid war







The people problem behind the government’s AI ambitions






sponsor content

Optimize Field Service Operations with Trusted Solutions for Government








Human operators must be held accountable for AI’s use in conflicts, Air Force secretary says






Why NIST is prioritizing creating a dictionary of AI development






SSA restructures tech shop to center on the CIO






How a push to the cloud helped a Ukrainian bank keep faith with customers amid war






The people problem behind the government’s AI ambitions





sponsor content

Optimize Field Service Operations with Trusted Solutions for Government






",,,Nextgov/FCW,,,"['https://www.facebook.com/NextgovFCW/', 'https://twitter.com/NextgovFCW', 'https://www.linkedin.com/company/nextgovfcw/']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LnRoZWF0bGFudGljLmNvbS90ZWNobm9sb2d5L2FyY2hpdmUvMjAxOC8xMi83LWFyZ3VtZW50cy1hZ2FpbnN0LXRoZS1hdXRvbm9tb3VzLXZlaGljbGUtdXRvcGlhLzU3ODYzOC_SAQA?oc=5,Seven Arguments Against the Autonomous-Vehicle Utopia - The Atlantic,2018-12-20,The Atlantic,https://www.theatlantic.com,All the ways the self-driving future &lt;em&gt;won’t&lt;/em&gt; come to pass,"Self-driving cars, self-driving-car service, old-school car manufacturers, self-driving works, driverless cars, autonomous future, Google’s sister company Waymo, human intelligence, different disciplines, Such algorithms, materialize.Bear Case, lifetimes of many people, Proponents of autonomous cars, self-driving-car security specialist, various levels of artificial intelligence, electric cars, likely outcome, banality of the Equifax breachThe transportation reporter, whole lot of other things, University of Washington, Carnegie Mellon University, early days, Human driving, Public transportation, lot of perceptual challenges, duo of essays, big-data hacks, different bear case, individual choice, Consumer vehicles, identity theft, Bear Case, Electric Vehicles, unusual circumstances, safe operation, fleet of robo-cars, affordable housing, physical danger, self-driving-car safety, individual tasks, sheer number, different things, current transportation-service companies, physical reality, question of calibrating, artificial-intelligence researcher, seminal event, MIT Computer Science, vehicles, self-driving systems",All the ways the self-driving future won’t come to pass,,https://schema.org,,NewsArticle,Seven Arguments Against the Autonomous-Vehicle Utopia,https://www.theatlantic.com/technology/archive/2018/12/7-arguments-against-the-autonomous-vehicle-utopia/578638/,"{'@type': 'WebPage', '@id': 'https://www.theatlantic.com/technology/archive/2018/12/7-arguments-against-the-autonomous-vehicle-utopia/578638/'}",,"[{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 720}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 405}, 'url': 'https://cdn.theatlantic.com/thumbor/9brOwkirzkUT593ffcUU1_-V6rY=/0x388:5383x3416/720x405/media/img/mt/2018/12/RTX6G49X/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'url': 'https://cdn.theatlantic.com/thumbor/ifbMIkSBanvsazkE9EdUY6c6CA0=/1012x0:4601x3589/1080x1080/media/img/mt/2018/12/RTX6G49X/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1200}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/Yk5SCqPRjl5YZ7gFeEVCuVDua8U=/297x0:5082x3589/1200x900/media/img/mt/2018/12/RTX6G49X/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1600}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/_KkQYWCSUwfKW6S_47uyz_vjaJM=/0x388:5383x3416/1600x900/media/img/mt/2018/12/RTX6G49X/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 960}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/GoWV0SR7-FujzmYO_SnPiCTKStc=/0x388:5383x3416/960x540/media/img/mt/2018/12/RTX6G49X/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/jDPgJeFagh4TjlCRR5R9WNpwrXs=/1012x0:4601x3589/540x540/media/img/mt/2018/12/RTX6G49X/original.jpg'}]",Technology,"[{'@type': 'Person', 'name': 'Alexis C. Madrigal', 'sameAs': 'https://www.theatlantic.com/author/alexis-madrigal/'}]",,{'@id': 'https://www.theatlantic.com/#publisher'},,2018-12-20T17:14:56Z,2023-08-08T22:57:16Z,Technology,,"TechnologySeven Arguments Against the Autonomous-Vehicle UtopiaAll the ways the self-driving future won’t come to passBy Alexis C. MadrigalA Neolix self-driving vehicle, seen at the IEEV New Energy Vehicles Exhibition in Beijing (Thomas Peter / Reuters)December 20, 2018ShareSave Self-driving cars are coming. Tech giants such as Uber and Alphabet have bet on it, as have old-school car manufacturers such as Ford and General Motors. But even as Google’s sister company Waymo prepares to launch its self-driving-car service and automakers prototype vehicles with various levels of artificial intelligence, there are some who believe that the autonomous future has been oversold—that even if driverless cars are coming, it won’t be as fast, or as smooth, as we’ve been led to think. The skeptics come from different disciplines inside and out of the technology and automotive industries, and each has a different bear case against self-driving cars. Add them up and you have a guide to all the ways our autonomous future might not materialize.Bear Case 1: They Won’t Work Until Cars Are as Smart as HumansComputers have nowhere near human intelligence. On individual tasks, such as playing Go or identifying some objects in a picture, they can outperform humans, but that skill does not generalize. Proponents of autonomous cars tend to see driving as more like Go: a task that can be accomplished with a far-lower-than-human understanding of the world. But in a duo of essays in 2017, Rodney Brooks, a legendary roboticist and artificial-intelligence researcher who directed the MIT Computer Science and Artificial Intelligence Laboratory for a decade, argued against the short-term viability of self-driving cars based on the sheer number of “edge cases,” i.e., unusual circumstances, they’d have to handle.To read this story, Sign in or start a subscription.CloseNever miss a story. Start your subscription.Uncompromising quality. Enduring impact. Your support ensures a bright future for independent journalism.Get StartedAlready have an account? Sign inAlexis Madrigal is a contributing writer at The Atlantic and the host of KQED’s Forum.",,,The Atlantic,"{'@type': 'SearchAction', 'target': 'https://www.theatlantic.com/search/?q={q}', 'query-input': 'required name=q'}","{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'url': 'https://cdn.theatlantic.com/assets/media/files/atlantic-logo--224x224.png'}","['https://www.facebook.com/TheAtlantic', 'https://twitter.com/theatlantic']",,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article-content-body'}",,,False,,en-US,,,https://www.theatlantic.com/#publisher,,,,,,Seven Arguments Against the Autonomous-Vehicle Utopia,,,,1072-7825,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LmFybXkubWlsL2FydGljbGUvMjE1MjkxL2JsYWNrX2hhd2tfaGVsaWNvcHRlcl9waWxvdF9pbnRlcm5zX3dpdGhfYXJteV9yZXNlYXJjaGVyc9IBYWh0dHBzOi8vd3d3LmFybXkubWlsL2FydGljbGUtYW1wLzIxNTI5MS9ibGFja19oYXdrX2hlbGljb3B0ZXJfcGlsb3RfaW50ZXJuc193aXRoX2FybXlfcmVzZWFyY2hlcnM?oc=5,Black Hawk helicopter pilot interns with Army researchers - United States Army,2018-12-19,United States Army,https://www.army.mil,"Researchers from the U.S. Army Research, Development, and Engineering Command Research Laboratory, the Army's corporate research laboratory, recently partnered with Texas A&M University to work on artificial intelligence and machine learning as appli...",,"Researchers from the U.S. Army Research, Development, and Engineering Command Research Laboratory, the Army's corporate research laboratory, recently partnered with Texas A&M University to work on artificial intelligence and machine learning as appli...","Researchers from the U.S. Army Research, Development, and Engineering Command Research Laboratory, the Army's corporate research laboratory, recently partnered with Texas A&M University to work on artificial intelligence and machine learning as appli...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAxOC8xMi8zMS90aGUtbW9zdC1hbWF6aW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW1pbGVzdG9uZXMtc28tZmFyL9IBAA?oc=5,The Most Amazing Artificial Intelligence Milestones So Far - Forbes,2018-12-31,Forbes,https://www.forbes.com,"Artificial Intelligence is everywhere, and sometimes it feels like something that has just emerged out of nothing. Here we look at the key milestones in the journey towards AI.",,"Artificial Intelligence is everywhere, and sometimes it feels like something that has just emerged out of nothing. Here we look at the key milestones in the journey towards AI.","Artificial Intelligence is everywhere, and sometimes it feels like something that has just emerged out of nothing. Here we look at the key milestones in the journey towards AI.",http://schema.org,,BreadcrumbList,The Most Amazing Artificial Intelligence Milestones So Far,https://www.forbes.com/sites/bernardmarr/2018/12/31/the-most-amazing-artificial-intelligence-milestones-so-far/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2018/12/AdobeStock_220811776-1200x686.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",Enterprise & Cloud,"{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2018-12-31T00:22:00-05:00,2021-12-10T08:30:38-05:00,Enterprise & Cloud,,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise TechThe Most Amazing Artificial Intelligence Milestones So FarBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 31, 2018,12:22am ESTUpdated Dec 10, 2021, 08:30am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinArtificial Intelligence (AI) is the hot topic of the moment in technology, and the driving force behind most of the big technological breakthroughs of recent years.
In fact, with all of the breathless hype we hear about it today, it's easy to forget that AI isn't anything all that new. Throughout the last century, it has moved out of the domain of science fiction and into the real world. The theory and the fundamental computer science which makes it possible has been around for decades.









The Most Amazing Artificial Intelligence Milestones So Far
Adobe Stock





Since the dawn of computing in the early 20th century, scientists and engineers have understood that the eventual aim is to build machines capable of thinking and learning in the way that the human brain – the most sophisticated decision-making system in the known universe – does.
PROMOTED
Today’s cutting-edge deep learning using artificial neural networks are the current state-of-the-art, but there have been many milestones along the road which have made it possible. Here's my rundown of those that are generally considered to be the most significant.

1637 – Descartes breaks down the difference
Long before robots were even a feature of science fiction, scientist and philosopher Rene Descartes pondered the possibility that machines would one day think and make decisions. While he erroneously decided that they would never be able to talk like humans, he did identify a division between machines which might one day learn about performing one specific task, and those which might be able to adapt to any job. Today, these two fields are known as specialized and general AI. In many ways, he set the stage for the challenge of creating AI.
1956 – The Dartmouth Conference
With the emergence of ideas such as neural networks and machine learning, Dartmouth College professor John McCarthy coined the term ""artificial intelligence"" and organized an intensive summer workshop bringing together leading experts in the field.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



During the brainstorming session, attempts were made to lay down a framework to allow academic exploration and development of “thinking” machines to begin. Many fields which are fundamental to today’s cutting-edge AI, including natural language processing, computer vision, and neural networks, were part of the agenda.
1966 – ELIZA gives computers a voice
ELIZA, developed at MIT by Joseph Weizenbaum, was perhaps the world’s first chatbot – and a direct ancestor of the likes of Alexa and Siri. ELIZA represented an early implementation of natural language processing, which aims to teach computers to communicate with us in human language, rather than to require us to program them in computer code, or interact through a user interface. ELIZA couldn’t talk like Alexa – she communicated through text – and she wasn’t capable of learning from her conversations with humans. Nevertheless, she paved the way for later efforts to break down the communication barrier between people and machines.
1980 – XCON and the rise of useful AI
Digital Equipment Corporation’s XCON expert learning system was deployed in 1980 and by 1986 was credited with generating annual savings for the company of $40 million. This is significant because until this point AI systems were generally regarded as impressive technological feats with limited real-world usefulness. Now it was clear that the rollout of smart machines into business had begun – by 1985 corporations were spending $1 billion per year on AI systems.
1988 – A statistical approach
IBM researchers publish A Statistical Approach to Language Translation, introducing principles of probability into the until-then rule-driven field of machine learning. It tackled the challenge of automated translation between human languages – French and English.
This marked a switch in emphasis to designing programs to determine the probability of various outcomes based on information (data) they are trained on, rather than training them to determine rules. This is often considered to be a huge leap in terms of mimicking the cognitive processes of the human brain and forms the basis of machine learning as it is used today.
1991 – The birth of the Internet
The importance of this one can't be overstated. In 1991 CERN researcher Tim Berners-Lee put the world's first website online and published the workings of the hypertext transfer protocol (HTTP). Computers had been connecting to share data for decades, mainly at educational institutions and large businesses. But the arrival of the worldwide web was the catalyst for society at large to plug itself into the online world. Within a few short years, millions of people from every part of the world would be connected, generating and sharing data – the fuel of AI - at a previously inconceivable rate.
1997 – Deep Blue defeats world chess champion Garry Kasparov
IBM’s chess supercomputer didn’t use techniques that would be considered true AI by today’s standards. Essentially it relied on “brute force” methods of calculating every possible option at high speed, rather than analyzing gameplay and learning about the game. However, it was important from a publicity point of view – drawing attention to the fact that computers were evolving very quickly and becoming increasingly competent at activities at which humans previously reigned unchallenged.
2005 – The DARPA Grand Challenge
2005 marked the second year that DARPA held its Grand Challenge – a race for autonomous vehicles across over 100 kilometers of off-road terrain in the Mojave desert. In 2004, none of the entrants managed to complete the course. The following year, however, five vehicles made their way around, with the team from Stanford University taking the prize for the fastest time.
The race was designed to spur the development of autonomous driving technology, and it certainly did that. By 2007, a simulated urban environment had been constructed for vehicles to navigate, meaning they had to be able to deal with traffic regulations and other moving vehicles.
2011 – IBM Watson’s Jeopardy! Victory
Cognitive computing engine Watson faced off against champion players of the TV game show Jeopardy!, defeating them and claiming a $1 million prize. This was significant because while Deep Blue had proven over a decade previously that a game where moves could be described mathematically, like chess could be conquered through brute force, the concept of a computer beating humans at a language based, the creative-thinking game was unheard of.
2012 – The true power of deep learning is unveiled to the world – computers learn to identify cats
Researchers at Stanford and Google including Jeff Dean and Andrew Ng publish their paper Building High-Level Features Using Large Scale Unsupervised Learning, building on previous research into multilayer neural nets known as deep neural networks.
Their research explored unsupervised learning, which does away with the expensive and time-consuming task of manually labeling data before it can be used to train machine learning algorithms. It would accelerate the pace of AI development and open up a new world of possibilities when it came to building machines to do work which until then could only be done by humans.
Specifically, they singled out the fact that their system had become highly competent at recognizing pictures of cats.
The paper described a model which would enable an artificial network to be built containing around one billion connections. It also conceded that while this was a significant step towards building an ""artificial brain,"" there was still some way to go – with neurons in a human brain thought to be joined by a network of around 10 trillion connectors.
2015 – Machines “see” better than humans
Researchers studying the annual ImageNet challenge – where algorithms compete to show their proficiency in recognizing and describing a library of 1,000 images – declare that machines are now outperforming humans.
Since the contest was launched in 2010, the accuracy rate of the winning algorithm increased from 71.8% to 97.3% - promoting researchers to declare that computers could identify objects in visual data more accurately than humans.
2016 – AlphaGo goes where no machine has gone before
Gameplay has long been a chosen method for demonstrating the abilities of thinking machines, and the trend continued to make headlines in 2016 when AlphaGo, created by Deep Mind (now a Google subsidiary) defeated world Go champion Lee Sedol over five matches. Although Go moves can be described mathematically, the sheer number of the variations of the game that can be played – there are over 100,000 possible opening moves in Go, compared to 400 in Chess) make the brute force approach impractical. AlphaGo used neural networks to study the game and learn as it played.
2018 – Self-driving cars hit the roads
The development of self-driving cars is a headline use case for today’s VR – the application which has captured the public imagination more than any other. Like the AI that powers them, they aren’t something which has emerged overnight, despite how it may appear to someone who hasn’t been following technology trends. General Motors predicted the eventual arrival of driverless vehicles at the 1939 World’s Fair. The Stanford Cart – originally built to explore how lunar vehicles might function, then repurposed as an autonomous road vehicle – was debuted in 1961.
But there can be no doubt that 2018 marked a significant milestone, with the launch of Google spin-off Waymo’s self-driving taxi service in Phoenix, Arizona. The first commercial autonomous vehicle hire service, Waymo One is currently in use by 400 members of the public who pay to be driven to their schools and workplaces within a 100 square mile area.
While human operators currently ride with every vehicle, to monitor their performance and take the controls in case of emergency, this undoubtedly marks a significant step towards a future where self-driving cars will be a reality for all of us.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing... Read MoreEditorial StandardsPrintReprints & Permissions","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",,The Most Amazing Artificial Intelligence Milestones So Far,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vd3d3LmluZm9ybWF0aW9uLWFnZS5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtMjAxOC0yMDE5LTkzMTIv0gEA?oc=5,Artificial intelligence: What changed in 2018 and what to expect in 2019 - Information Age,2018-12-27,Information Age,https://www.information-age.com,"In the artificial intelligence and machine learning space, 2019 will see the rise of the intelligent application",,"In the artificial intelligence and machine learning space, 2019 will see the rise of the intelligent application",,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#article', 'isPartOf': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/'}, 'author': {'name': 'Nick Ismail', '@id': 'https://www.information-age.com/#/schema/person/4aadc26dcee71ce0fc2931dd5acf3f6e'}, 'headline': 'Artificial intelligence: What changed in 2018 and what to expect in 2019', 'datePublished': '2018-12-27T08:20:45+00:00', 'dateModified': '2022-12-01T12:30:41+00:00', 'mainEntityOfPage': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/'}, 'wordCount': 1113, 'publisher': {'@id': 'https://www.information-age.com/#organization'}, 'image': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#primaryimage'}, 'thumbnailUrl': 'https://informationage-production.s3.amazonaws.com/uploads/2022/10/AdobeStock_122106614-scaled.jpeg', 'keywords': ['Artificial Intelligence', 'Chatbots', 'Machine Learning', 'Smartphone'], 'articleSection': ['AI &amp; Machine Learning', 'Consumer Electronics &amp; Mobile'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/', 'url': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/', 'name': 'Artificial intelligence: What changed in 2018 and what to expect in 2019', 'isPartOf': {'@id': 'https://www.information-age.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#primaryimage'}, 'image': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#primaryimage'}, 'thumbnailUrl': 'https://informationage-production.s3.amazonaws.com/uploads/2022/10/AdobeStock_122106614-scaled.jpeg', 'datePublished': '2018-12-27T08:20:45+00:00', 'dateModified': '2022-12-01T12:30:41+00:00', 'description': 'In the artificial intelligence and machine learning space, 2019 will see the rise of the intelligent application', 'breadcrumb': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.information-age.com/artificial-intelligence-2018-2019-9312/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#primaryimage', 'url': 'https://informationage-production.s3.amazonaws.com/uploads/2022/10/AdobeStock_122106614-scaled.jpeg', 'contentUrl': 'https://informationage-production.s3.amazonaws.com/uploads/2022/10/AdobeStock_122106614-scaled.jpeg', 'width': 2560, 'height': 1707}, {'@type': 'BreadcrumbList', '@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.information-age.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Topics', 'item': 'https://www.information-age.com/topics/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI &amp; Machine Learning', 'item': 'https://www.information-age.com/topics/ai-machine-learning/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Artificial intelligence: What changed in 2018 and what to expect in 2019'}]}, {'@type': 'WebSite', '@id': 'https://www.information-age.com/#website', 'url': 'https://www.information-age.com/', 'name': 'Information Age', 'description': 'Insight and Analysis for the CTO', 'publisher': {'@id': 'https://www.information-age.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.information-age.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.information-age.com/#organization', 'name': 'Information Age', 'url': 'https://www.information-age.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.information-age.com/#/schema/logo/image/', 'url': 'https://s42137.p1364.sites.pressdns.com/wp-content/uploads/2022/09/IA_NEW_LOGO_2018_RGB.png', 'contentUrl': 'https://s42137.p1364.sites.pressdns.com/wp-content/uploads/2022/09/IA_NEW_LOGO_2018_RGB.png', 'width': 400, 'height': 50, 'caption': 'Information Age'}, 'image': {'@id': 'https://www.information-age.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/informationage/', 'https://x.com/InformationAge', 'https://www.linkedin.com/company/information-age/', 'https://www.youtube.com/informationage']}, {'@type': 'Person', '@id': 'https://www.information-age.com/#/schema/person/4aadc26dcee71ce0fc2931dd5acf3f6e', 'name': 'Nick Ismail', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.information-age.com/#/schema/person/image/', 'url': 'https://informationage-staging.s3.eu-west-2.amazonaws.com/uploads/2022/11/Nick_Ismail-96x96.jpeg', 'contentUrl': 'https://informationage-staging.s3.eu-west-2.amazonaws.com/uploads/2022/11/Nick_Ismail-96x96.jpeg', 'caption': 'Nick Ismail'}, 'description': 'Nick Ismail is a former editor for Information Age (from 2018 to 2022) before moving on to become Global Head of Brand Journalism at HCLTech. He has a particular interest in smart technologies, AI and cyber security.', 'sameAs': ['https://uk.linkedin.com/in/nicholas-ismail-480a069b'], 'url': 'https://www.information-age.com/author/nickismail/'}]",,,,,,,,,,,,,,,,"

Artificial intelligence (AI) is one of those technologies that excites the public and business imagination alike. Long since a favourite theme in science-fiction, it is now gaining traction in everyday practical scenarios.





In 2018, we saw a considerable rise in the adoption of AI around the world and across industries, with businesses using it to improve operations, generate new innovations and boost customer experience.

Investing in artificial intelligence: What businesses need to know
To make artificial intelligence work for a business, leaders need to ensure that employee skills are honed in line with technological investments. Read here
With financial services, telecoms and high tech leading the way in bringing AI into the mainstream, and other areas such as automotive, healthcare, energy and retail also embracing it, we expect the rapid growth of AI to continue in 2019 as companies strive to get the most value and competitive advantage from the data they capture. Let’s take a look at what’s been powering the rise of AI recently and what might be around the corner.
Data skills
Data is the fuel for AI. As data collection, analysis and storage abilities dramatically improved over recent years, most companies found themselves with a huge potential resource and yet under-equipped to wrestle with such high volumes of information.
In 2018, that started to change, as the people skills made headway in catching up with the technology. There remains a lot of complexity around how data is handled and used, but businesses are starting to see a deeper understanding of the specific skills needed to help companies bear fruit from data, and how these can be mapped onto ‘personas’ they can train up, or recruit.
Businesses are steadily learning how data scientists and AI developers work differently from traditional app developers, the tools they need, and how to bring them into app dev teams cohesively.
>See also: A deep look into artificial intelligence, machine learning and data science
For vendors in this space, the challenge is to make AI more easily accessible for all developers. Some are building machine learning frameworks to help organisations apply AI across use cases.
In 2019, vendors and enterprises alike need to continue to broaden their skill set, training existing developers and bringing new data scientists on board. To target the shortage of data scientists (and other data worker personas) at its roots, as a society we need to engage and inspire young people to boost demand in the education system, as well as supply that education. With a continued push expected this year and beyond, AI can fulfil its potential ‘superpower’ status for developers, helping them tap rich new sources of innovation.
Chatbots
One use case that has become more prevalent in the last twelve months is chatbots. Chatbots’ increase in popularity stems from businesses’ desire to give users the same experience online as they would get in-store – be they retail banking customers, healthcare patients, retail shoppers, or whoever else.
>See also: AI: from hype to reality in healthcare
Chatbots are great because they can respond very quickly to customers and deliver personalised care by taking advantage of data analysis and algorithms to determine the category a user falls into.
Machine learning (ML) frameworks
One of the biggest surprises in this area of 2018 was to see the consolidation of machine learning frameworks continue. There have been AI and ML libraries and projects for decades, but in the past 5-7 years we’ve seen a lot more investment in building deep learning libraries and artificial neural networks. Some of the big players in this area have poured tremendous amounts of resource and efforts into this, pulling in scarce talent.
With these corporations having access to much greater amounts of infrastructure for storage and compute power than universities could supply, they have transitioned many researchers from the academic space to the corporate space. With such heavy investment, it was easy to expect these key players to want to keep their assets closed for a few more years in order to monetise the value they have amassed.
>See also: AI in the workplace – what executives need to consider
There is obvious benefit to be gained collectively from building together, such as faster innovation and more freedom of choice for developers, and there is also a large-scale push more generally in the direction of open source in the tech industry today. It could also be said that in the context of today’s huge wave of cloud computing, even these high value frameworks can simply be drivers of workloads on top of the cloud infrastructures these big players have.
The intelligent application
With almost 8.5 billion mobile connections globally and counting, (see GSMA data), many of us use a smartphone, if not multiple smartphones, daily. Probably half or more of your mobile applications will have AI functionality, either directly embedded into the app or supporting it in the back-end. For example, your keyboard learns how you – and everyone else – interacts with it to improve how it works.
If you want to buy something through an online retailer, it will make recommendations based on your purchase history as well as typical buying habits using an AI engine. Ride-sharing apps and navigation apps use AI to calculate how to connect various users on a route. Intelligent applications are likely to continue to gather steam in 2019.
Avoiding bias
Any new technology may bring pitfalls that have not been fully anticipated. We’re finding with AI that the algorithms are only as good as the training data they are using, which can have negative consequences. The issue of how humans can pass on their own biases and prejudices to algorithms with damaging results, in anything from crime prediction to language translation, became better known in 2018.
>See also: How to harness AI to improve workplace efficiency
This should be given a lot more attention, and hope to see real action to address this challenge in 2019. Vendors need to think about how they can offer tools and tutorials to help less experienced data scientists, developers and businesses at large gain a better understanding of data and the human impact of AI. Together, we can develop a more structural approach to the problem.
To be continued…
The application of artificial intelligence and machine learning will solve business problems and bring new ideas to life to continue into 2019 as companies strive to get the most business value and competitive advantage from their existing data. Watch this space.
Sourced by Kim Palko, principal product manager, Data and Analytics, Red Hat JBoss, and Matthew Farrellee, Emerging Technology & Strategy, CTO Office, Red Hat


Tagged: Artificial Intelligence, Chatbots, Machine Learning, Smartphone 






					Nick Ismail					




				Nick Ismail is a former editor for Information Age (from 2018 to 2022) before moving on to become Global Head of Brand Journalism at HCLTech. He has a particular interest in smart technologies, AI and...				
				More by Nick Ismail				



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vYmR0ZWNodGFsa3MuY29tLzIwMTgvMTIvMjgvdG9wLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXN0b3JpZXMtMjAxOC_SAVBodHRwczovL2JkdGVjaHRhbGtzLmNvbS8yMDE4LzEyLzI4L3RvcC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1zdG9yaWVzLTIwMTgvYW1wLw?oc=5,The biggest artificial intelligence developments of 2018 - TechTalks,2018-12-28,TechTalks,https://bdtechtalks.com,"2018 was a year of reckoning for the AI industry. In parallel to technological developments, there was ample focus on the ethical concerns of artificial intelligence technology.",,"2018 was a year of reckoning for the AI industry. In parallel to technological developments, there was ample focus on the ethical concerns of artificial intelligence technology.","2018 was a year of reckoning for the AI industry. In parallel to technological developments, there was ample focus on the ethical concerns of artificial intelligence technology.",http://schema.org,"[{'@type': 'BlogPosting', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#blogposting', 'name': 'The biggest artificial intelligence developments of 2018 - TechTalks', 'headline': 'The biggest artificial intelligence developments of 2018', 'author': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'publisher': {'@id': 'https://bdtechtalks.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2018/12/Google-IO-2018-sundar-pichai-keynote-Duplex.png?fit=3350%2C1866&ssl=1', 'width': 3350, 'height': 1866, 'caption': 'Google CEO Sundar Pichai introduces Duplex AI at I/O 2018 developer conference (Source: YouTube)'}, 'datePublished': '2018-12-28T14:00:00+00:00', 'dateModified': '2018-12-27T20:30:41+00:00', 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#webpage'}, 'isPartOf': {'@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#webpage'}, 'articleSection': 'Blog, AI ethics, Artificial intelligence (AI), bendee983'}, {'@type': 'BreadcrumbList', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://bdtechtalks.com/#listItem', 'position': 1, 'name': 'Home', 'item': 'https://bdtechtalks.com/', 'nextItem': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem', 'position': 2, 'name': '2018', 'item': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/', 'nextItem': 'https://bdtechtalks.com/2018/12/#listItem', 'previousItem': 'https://bdtechtalks.com/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2018/12/#listItem', 'position': 3, 'name': 'December', 'item': 'https://bdtechtalks.com/2018/12/', 'nextItem': 'https://bdtechtalks.com/2018/12/28/#listItem', 'previousItem': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2018/12/28/#listItem', 'position': 4, 'name': '28', 'item': 'https://bdtechtalks.com/2018/12/28/', 'nextItem': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem', 'previousItem': 'https://bdtechtalks.com/2018/12/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem', 'position': 5, 'name': 'The biggest artificial intelligence developments of 2018', 'previousItem': 'https://bdtechtalks.com/2018/12/28/#listItem'}]}, {'@type': 'Organization', '@id': 'https://bdtechtalks.com/#organization', 'name': 'TechTalks', 'description': 'Technology solving problems... and creating new ones', 'url': 'https://bdtechtalks.com/'}, {'@type': 'Person', '@id': 'https://bdtechtalks.com/author/bendee983/#author', 'url': 'https://bdtechtalks.com/author/bendee983/', 'name': 'Ben Dickson', 'image': {'@type': 'ImageObject', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#authorImage', 'url': 'https://secure.gravatar.com/avatar/5184782561a26df20cb56c8eb87eef27?s=96&d=identicon&r=g', 'width': 96, 'height': 96, 'caption': 'Ben Dickson'}}, {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#webpage', 'url': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/', 'name': 'The biggest artificial intelligence developments of 2018 - TechTalks', 'description': '2018 was a year of reckoning for the AI industry. In parallel to technological developments, there was ample focus on the ethical concerns of artificial intelligence technology.', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://bdtechtalks.com/#website'}, 'breadcrumb': {'@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#breadcrumblist'}, 'author': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'creator': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2018/12/Google-IO-2018-sundar-pichai-keynote-Duplex.png?fit=3350%2C1866&ssl=1', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#mainImage', 'width': 3350, 'height': 1866, 'caption': 'Google CEO Sundar Pichai introduces Duplex AI at I/O 2018 developer conference (Source: YouTube)'}, 'primaryImageOfPage': {'@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#mainImage'}, 'datePublished': '2018-12-28T14:00:00+00:00', 'dateModified': '2018-12-27T20:30:41+00:00'}, {'@type': 'WebSite', '@id': 'https://bdtechtalks.com/#website', 'url': 'https://bdtechtalks.com/', 'name': 'TechTalks', 'description': 'Technology solving problems... and creating new ones', 'inLanguage': 'en-US', 'publisher': {'@id': 'https://bdtechtalks.com/#organization'}}]",BreadcrumbList,,,,,,,,,,,,,,,"

Blog

The biggest artificial intelligence developments of 2018

By Ben Dickson -   December 28, 2018 




Facebook


Twitter


ReddIt


Linkedin




Google CEO Sundar Pichai introduces Duplex AI at I/O 2018 developer conference (Source: YouTube)
Last year, when I was rounding up the biggest artificial intelligence developments of 2017, I had a very hard time choosing which stories were most worth covering. In that regard, 2018 didn’t see much change. This year, we saw even more AI papers published and more innovation in the space than 2017.
But beyond innovation and technological advances, 2018 was perhaps a year of reckoning for the ethical implications of advances in AI technologies. Unlike previous cycles of AI’s rise and fall, in which the industry receded into its periodic winter without making any notable impact on everyday lives, today’s AI technologies have become pivotal to many of the things we do. And we need to think about what their negative impacts can be.
Without further ado, here are some of the most noteworthy AI stories of 2018. Looking forward to more exciting AI stories in 2019.
Google’s fascinating—and creepy—AI

In May, in Google’s yearly I/O developer conference, CEO Sundar Pichai revealed Duplex, an addition to the Google Assistant that could make calls on behalf of a user and perform tasks such as booking restaurant tables and hair salon appointments.
Duplex immediately inspired awe and cheers among the crowd that attended the conference because it sounded like a real human, and as the demos showed, the service workers who spoke to it didn’t know they were talking to an AI agent.

But immediately after the conference, tech outlets became filled with stories and commentary about the ethical implications of AI technologies that were hard to differentiate from humans. There were fears that such tools could serve questionable purposes, such as impersonating people or automating spam calls and phishing scams. Many people also rightly criticized Google for not disclosing to Duplex’s interlocutors that they were speaking with a bot (Google remedied that later).
As we discussed in these pages, it takes more than an automated, human-sounding voice to be able to engage in conversations at the level of human intelligence. So many of the concerns that surround the evil capabilities of Duplex AI are bloated, proven by its very limited and conservative release.
Controversy surrounding the use of facial recognition
Source: Depositphotos
Facial recognition technology is one of the areas that has benefited immensely from advances in deep learning and neural networks. More and more companies, organizations and government agencies are able to leverage AI-powered facial recognition technologies for different tasks. For obvious reasons, advocates of privacy and digital rights are worried about the implications of unfettered use of facial recognition by law enforcement.
One of the companies that came under much scrutiny was Amazon, which sells a commercial facial detection service named Rekognition. In May, the American Civil Liberties Union disclosed documents that showed Amazon was marketing Rekognition for government surveillance, including for tasks such as “person tracking” and identifying “persons of interest,” which ACLU interpreted as “undocumented immigrants” and “black activists.” ACLU further revealed that law enforcement in at least three cities were using Rekognition to surveil on citizens.
“People should be free to walk down the street without being watched by the government. By automating mass surveillance, facial recognition systems like Rekognition threaten this freedom, posing a particular threat to communities already unjustly targeted in the current political climate. Once powerful surveillance systems like these are built and deployed, the harm will be extremely difficult to undo,” ACLU warned.
In July, ACLU again raised concern about the failures of Rekognition. In another report, the organization showed that Rekognition misidentified the pictures of 28 members of Congress as documented criminals. “The false matches were disproportionately of people of color,” ACLU observed.
A spokesperson for Amazon told different outlets that the reason for the mistake was a misconfiguration by the researchers.
The use of Rekognition by police also caused tumult in Amazon’s own ranks. In a letter, 450 employees called on Amazon to stop selling the technology to law enforcement.
Amazon was not the only company having troubles over the use of facial recognition. In February, researchers at MIT Media Lab released findings that showed facial recognition systems developed by IBM and Microsoft suffered from algorithmic bias and were less accurate when detecting female and non-white faces. Both companies later reported that they had corrected the deficiencies in their algorithms
Microsoft president Brad Smith eventually addressed the controversies surrounding the use of AI-powered facial recognition in a famous blog post in which he stressed the need to support government and military institutions with cutting edge technology, but also called for further regulation of facial recognition technology.
Project Maven, Google’s ill-fated dabbling in military AI projects

In March, it became known that Google was partnering with the Department of Defense to develop AI for drones. The effort was part of a project codenamed Maven, whose stated mission is to “accelerate the DoD’s integration of big data and machine learning.” Google was reportedly helping in the use of artificial intelligence to detect objects in drone footage.
The U.S. military is already using drones to conduct air strikes against targets in foreign countries. The disclosure raised concerns that such efforts might help develop autonomous lethal weapons that enable an AI algorithms to designate and open fire on targets without the intervention of a human operator.
A spokesperson for Google disclosed that the company was only providing DoD with access to its TensorFlow application programming interface (API) to help automate the detection of objects in footages of surveillance drones, a task that places a heavy burden on analysts when done manually. The spokesperson also said that Google was working on policies and safeguards to make sure its technology would not be put to ill use.
Google’s explanations were not enough to assuage the concerns of industry experts and its own employees. Shortly after news of Google’s involvement in Project Maven became public, more than 3,000 Google employees signed an open letter to Pichai and called for the termination of the development of a possibly lethal AI technology. “We cannot outsource the moral responsibility of our technologies to third parties,” the employees wrote in their letter.
The Google employees’ letter was followed by a similar petition by 90 academics in artificial intelligence, ethics, and computer science that called on Google to end its work on military AI. “While the reports on Project Maven currently emphasize the role of human analysts, these technologies are poised to become a basis for automated target recognition and autonomous weapon systems,” the academics wrote in their letter.
The signatories also warned that as AI-based object detection becomes reliable and trustworthy, its implementers will be wont to trust it in more sensitive tasks. “We are then just a short step away from authorizing autonomous drones to kill automatically, without human supervision or meaningful human control,” the academics warned.
Months later, several Google employees resigned in protest to the company’s continued involvement in developing AI products that could serve lethal purposes. “I tried to remind myself right that Google’s decisions are not my decisions. I’m not personally responsible for everything they do. But I do feel responsibility when I see something that I should escalate it,” one of the resigning employees said.
Under pressure from its employees and the AI community, Google announced in June that it would not be renewing its contract to work on Project Maven after it expires in 2019. Subsequently, Pichai published a set of ethical principles that Google will follow from now on when working on AI projects. Pichai explicitly stated that his company will not be pursuing the development of AI technologies related to weapons, surveillance or anything that can cause harm.
Amazon abandons AI recruiting technology due to bias

In October, Reuters reported that Amazon had scrapped an AI recruiting tool because it was discriminating against women. Amazon’s hiring team had been experimenting with the tool to review resumes and shortlist candidates for job positions.
Amazon employs more than 500 thousand people across the world. A reliable AI-driven hiring software could help slash the costs and efforts required to manage the tens of thousands of job applications that the company has to process every year.
But as the episode shows, automating tasks that require human intuition and commonsense are very hard, and as we’ve examined in these pages, contrary to mythical beliefs, AI algorithms will inherit—and amplify—our individual and societal biases. Like most other tech companies, Amazon is dominated by white men, which means whatever data was used to train its machine learning algorithms already contained these same biases. As a result, the AI algorithms had found a tendency to favor male candidates.
OpenAI matched up against professional Dota 2 players—and lost

Moving on from ethical issues, there were some interesting developments in AI projects that made the headlines this year. Playing and mastering games has always been one of the main areas of focus of artificial intelligence researchers. After beating chess and Go champions, AI experts have set their eyes on computer games such as StarCraft and Dota 2.
These games are much more complicated than board games because first, users must make decisions in real time, and second, they don’t have full information about the state of the game.
In June, OpenAI, the non-profit AI research lab that launched in 2015 with funding from Y Combinator president Sam Altman and Tesla CEO Elon Musk, introduced OpenAI Five, a team of five neural networks that had trained on 80 years’ worth of Dota 2 gameplay and had proven their worth against amateur human players.
In August, OpenAI Five participated in an international Dota 2 tournament and competed against professional players in a best-of-three series. It lost. But in spite of the defeat, the mere fact that deep learning algorithms were able to compete at such a high level was an achievement for the AI industry.
AI in 2019
2018 saw the maturation of the artificial intelligence industry. 2019 will surely see more interesting developments emerge. What do you think will be the biggest highlight of the AI industry in 2019? Share with us in the comments section.
Like this:Like Loading... 


TAGSAI ethicsArtificial intelligence (AI) 


Facebook


Twitter


ReddIt


Linkedin


 Previous articleThe security threats of neural networks and deep learning algorithmsNext articleMajor cybersecurity breaches and data leaks in 2018; business as usual Ben DicksonBen is a software engineer and the founder of TechTalks. He writes about technology, business and politics.




  
","[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://bdtechtalks.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/category/blog/', 'name': 'Blog'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/', 'name': 'The biggest artificial intelligence developments of 2018'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMTIvMzEvdGVjaG5vbG9neS9odW1hbi1yZXNvdXJjZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaHVtdS5odG1s0gEA?oc=5,Firm Led by Google Veterans Uses A.I. to 'Nudge' Workers Toward Happiness (Published 2018) - The New York Times,2018-12-31,The New York Times,https://www.nytimes.com,"Humu, a Silicon Valley start-up, applies data-driven lessons in human resources to the goal of improving employee satisfaction.",,"Humu, a Silicon Valley start-up, applies data-driven lessons in human resources to the goal of improving employee satisfaction.","Humu, a Silicon Valley start-up, applies data-driven lessons in human resources to the goal of improving employee satisfaction.",https://schema.org,,NewsMediaOrganization,Firm Led by Google Veterans Uses A.I. to ‘Nudge’ Workers Toward Happiness,https://www.nytimes.com/,https://www.nytimes.com/2018/12/31/technology/human-resources-artificial-intelligence-humu.html,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/12/31/business/31HUMU05/31HUMU05-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2018/12/31/business/31HUMU05/31HUMU05-videoSixteenByNineJumbo1600.jpg', 'caption': 'Lizbeydi Dimas, an employee of the salad chain Sweetgreen, at a store in Mountain View, Calif. Sweetgreen turned to Humu, a start-up, for ideas on how to improve its workers’ satisfaction.', 'creditText': 'Cayce Clifford for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/12/31/business/31HUMU05/merlin_144427707_44a0132d-7e8c-4437-ae0a-e8bca7fb859d-superJumbo.jpg', 'height': 2048, 'width': 1639, 'contentUrl': 'https://static01.nyt.com/images/2018/12/31/business/31HUMU05/merlin_144427707_44a0132d-7e8c-4437-ae0a-e8bca7fb859d-superJumbo.jpg', 'caption': 'Lizbeydi Dimas, an employee of the salad chain Sweetgreen, at a store in Mountain View, Calif. Sweetgreen turned to Humu, a start-up, for ideas on how to improve its workers’ satisfaction.', 'creditText': 'Cayce Clifford for The New York Times'}]",,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/daisuke-wakabayashi', 'name': 'Daisuke Wakabayashi'}]",,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,2018-12-31T21:28:44.000Z,2018-12-31T22:27:17.000Z,Technology,,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTFirm Led by Google Veterans Uses A.I. to ‘Nudge’ Workers Toward HappinessShare full articleRead in appLizbeydi Dimas, an employee of the salad chain Sweetgreen, at a store in Mountain View, Calif. Sweetgreen turned to Humu, a start-up, for ideas on how to improve its workers’ satisfaction.Credit...Cayce Clifford for The New York TimesBy Daisuke WakabayashiDec. 31, 2018MOUNTAIN VIEW, Calif. — Technology companies like to promote artificial intelligence’s potential for solving some of the world’s toughest problems, like reducing automobile deaths and helping doctors diagnose diseases. A company started by three former Google employees is pitching A.I. as the answer to a more common problem: being happier at work.The start-up, Humu, is based in Google’s hometown, and it builds on some of the so-called people-analytics programs pioneered by the internet giant, which has studied things like the traits that define great managers and how to foster better teamwork.Humu wants to bring similar data-driven insights to other companies. It digs through employee surveys using artificial intelligence to identify one or two behavioral changes that are likely to make the biggest impact on elevating a work force’s happiness. Then it uses emails and text messages to “nudge” individual employees into small actions that advance the larger goal.At a company where workers feel that the way decisions are made is opaque, Humu might nudge a manager before a meeting to ask the members of her team for input and to be prepared to change her mind. Humu might ask a different employee to come up with questions involving her team that she would like to have answered.AdvertisementSKIP ADVERTISEMENTAt the heart of Humu’s efforts is the company’s “nudge engine” (yes, it’s trademarked). It is based on the economist Richard Thaler’s Nobel Prize-winning research into how people often make decisions because of what is easier rather than what is in their best interest, and how a well-timed nudge can prompt them to make better choices.ImageLaszlo Bock, Humu’s chief executive, led people operations, or human resources, at Google. “We want to be the person we hope we can be,” he said, referring to an idea at the heart of Humu’s business. “But we need to be reminded.”Credit...HumuGoogle has used this approach to coax employees into the corporate equivalent of eating their vegetables, prodding them to save more for retirement, waste less food at the cafeteria and opt for healthier snacks.Using machine learning, Humu will tailor the timing, content and techniques of the messages it delivers based on how employees respond.“Often we want to be better people,” said Laszlo Bock, Humu’s chief executive and Google’s former leader of what the company calls people operations, or human resources. “We want to be the person we hope we can be. But we need to be reminded. A nudge can have a powerful impact if correctly deployed on how people behave and on human performance.”AdvertisementSKIP ADVERTISEMENTIn Mr. Bock’s decade-plus tenure at Google, the company’s work force grew more than eightfold. Google struggled at times with how to manage its rapid expansion, and some employees accused the company of creating a workplace that was hostile to women.In November, 20,000 employees — prompted by an article in The New York Times that detailed how Google had paid millions of dollars in exit packages to male executives accused of misconduct — walked off the job to protest the company’s handling of sexual harassment.The episode underscored Google’s unique and seemingly incongruous internal culture. Employees feel empowered to agitate for change, and the company takes innovative approaches to managing its work force. But deep-rooted problems fester as they would anywhere else.ImageMr. Bock in 2011 with a fellow Google employee, Jason Grishkoff. “A nudge can have a powerful impact if correctly deployed on how people behave and on human performance,” Mr. Bock said.Credit...Peter DaSilva for The New York TimesWhile Mr. Bock was at Google, he led many of its human-resources analytics efforts and became well known in the field, writing a 2015 book that laid out the company’s data-driven approach to personnel management.AdvertisementSKIP ADVERTISEMENTHe started Humu in 2017 shortly after leaving Google with two former colleagues: Jessie Wisdom, who has a doctorate in behavioral decision research and worked with Mr. Bock in people analytics, and Wayne Crosby, a former director of engineering at Google. Humu has raised $40 million and has 15 customers, companies that range in size from 150 to 65,000 employees.One major challenge for the company is handling data and artificial intelligence in the sensitive area of human resources. Humu said its software was built with employee privacy in mind, allowing workers to delete personal data, including anonymous comments made in company surveys. Humu said it complied with Europe’s stringent data privacy rules.But will workers consider the nudges useful or manipulative?Todd Haugh, an assistant professor of business law and ethics at Indiana University’s Kelley School of Business, said nudges could push workers into behaving in ways that benefited their employers’ interests over their own.“The companies are the only ones who know what the purpose of the nudge is,” Professor Haugh said. “The individual who is designing the nudge is the one whose interests are going to be put in the forefront.”AdvertisementSKIP ADVERTISEMENTDr. Wisdom, who ran much of Google’s nudge research, said it was hard to argue with most of the messages the company delivered because they encouraged behavior most people would welcome.ImageSweetgreen employees at the Mountain View store holding a short meeting to discuss topics like career development.Credit...Cayce Clifford for The New York Times“Anybody can do whatever they want,” she said. “It’s just about designing the context in which people are making the decision in ways that is going to help the most people. We’re never trying to get people to do things that they don’t actually want to do.”Sanjiv Razdan, the chief operating officer at Sweetgreen, a salad chain and one of Humu’s customers, said that if nudges did not have a track record at Google, he would probably consider the concept a bunch of “hocus-pocus happiness nonsense.”But after receiving nudges for a few months himself in emails from Mr. Crosby, whose email address is used to send the messages, Mr. Razdan said the bite-size reminders made it easy to take action right away. In one instance, he said, he was prompted to ask members of his team for their opinions on decisions he was facing.“The team doesn’t know I was nudged,” he said. “But I’m not ashamed to tell everyone that I heard from Wayne today.”AdvertisementSKIP ADVERTISEMENTJonathan Neman, Sweetgreen’s chief executive, said Humu had pinpointed the issue Sweetgreen cares about most: employee retention.Like most restaurant chains, Sweetgreen, which has 90 stores in the United States, depends on hourly employees. Retaining workers and keeping them happy is critical. Recruiting and training employees is costly, and experienced workers are more productive. Happier employees tend to treat customers better. And customers like seeing familiar faces.ImageJuana Padron, a Sweetgreen employee in Mountain View. The chain’s managers get “nudged” with messages like “Consider what skills each team member needs to be successful, both in their current role and longer term in their career.”Credit...Cayce Clifford for The New York TimesIn August, when Humu analyzed a survey of sentiment among 1,800 store employees that Sweetgreen had conducted the previous month, it found that 43 percent of the respondents had occasionally considered applying for jobs outside Sweetgreen.If Sweetgreen wanted to improve its retention rate, Humu’s algorithms determined, there was one statement from the survey that the chain needed more employees to agree with: “I believe there are good development opportunities for me at Sweetgreen.”AdvertisementSKIP ADVERTISEMENTOf the survey’s respondents, 81 percent had reacted positively to the statement. That was a strong score for the fast-food industry, but it was still below the overall 88 percent happiness index Humu had given Sweetgreen overall. The suggestion was that although the company’s employees were generally happy, some felt they lacked opportunities to advance their careers.Humu recommended that store managers — known as head coaches at Sweetgreen — hold one-on-one meetings with staff members to discuss development goals.About a month later, in early September, Elena Jimenez, the head coach at Sweetgreen’s Mountain View store, got a nudge. So far, Sweetgreen is nudging only managers.“Consider what skills each team member needs to be successful, both in their current role and longer term in their career,” the email read. “Take notes. Preparing this list of skills will help you spot opportunities for your team as they arise — so it’s worth putting the work in now!”Ms. Jimenez discussed career development at her next “sweet talk,” a short meeting before her store opened one day. Then she spoke to her employees individually and learned that many of them wanted to learn different skills, whether handling online orders or chopping and dicing the vegetables that go into Sweetgreen salads.“It was a good reminder to keep everyone happy and motivated,” she said. “I hope it helps me retain my staff. It’s not easy around here.”Follow Daisuke Wakabayashi on Twitter: @daiwaka. A version of this article appears in print on Jan. 1, 2019, Section B, Page 1 of the New York edition with the headline: Toward a Happier Office With Data-Driven Nudges. Order Reprints | Today’s Paper | SubscribeSee more on: Alphabet Inc.Share full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",,,The New York Times,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",,,False,,,,,https://www.nytimes.com/#publisher,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",Toward a Happier Office With Data-Driven Nudges,,,,,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3Lm5ld3lvcmtlci5jb20vc2NpZW5jZS9lbGVtZW50cy9ob3ctdGhlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXByb2dyYW0tYWxwaGF6ZXJvLW1hc3RlcmVkLWl0cy1nYW1lc9IBAA?oc=5,How the Artificial Intelligence Program AlphaZero Mastered Its Games - The New Yorker,2018-12-28,The New Yorker,https://www.newyorker.com,"James Somers on AlphaZero, an artificial-intelligence program animated by an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been.","['tech', 'artificial intelligence (a.i.)', 'chess', 'computer games', 'web']","At its core was an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been.","At its core was an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been.",https://schema.org/,,BreadcrumbList,How the Artificial Intelligence Program AlphaZero Mastered Its Games,https://www.newyorker.com/science/elements/how-the-artificial-intelligence-program-alphazero-mastered-its-games,"{'@type': 'WebPage', '@id': 'https://www.newyorker.com/science/elements/how-the-artificial-intelligence-program-alphazero-mastered-its-games'}","https://media.newyorker.com/photos/5c24f4778822322ea4b3befe/1:1/w_1711,h_1711,c_limit/Somers-AlphaZero.jpg","['https://media.newyorker.com/photos/5c24f4778822322ea4b3befe/16:9/w_2560,h_1440,c_limit/Somers-AlphaZero.jpg', 'https://media.newyorker.com/photos/5c24f4778822322ea4b3befe/4:3/w_2279,h_1709,c_limit/Somers-AlphaZero.jpg', 'https://media.newyorker.com/photos/5c24f4778822322ea4b3befe/1:1/w_1711,h_1711,c_limit/Somers-AlphaZero.jpg']",,"[{'@type': 'Person', 'name': 'James Somers', 'sameAs': 'https://www.newyorker.com/contributors/james-somers'}]",,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'The New Yorker', 'logo': {'@type': 'ImageObject', 'url': 'https://www.newyorker.com/verso/static/the-new-yorker/assets/social-image-hub.jpg', 'width': '500px', 'height': '117px'}, 'url': 'https://www.newyorker.com'}",,2018-12-28T05:00:00.000-05:00,2018-12-28T05:00:00.000-05:00,tags,,"TechHow the Artificial-Intelligence Program AlphaZero Mastered Its GamesBy James SomersDecember 28, 2018In 2016, a Google program soundly defeated Lee Sedol, the world’s best Go player, in a match viewed by more than a hundred million people.Photograph by Ahn Young-joon / APSave this storySave this storySave this storySave this storyA few weeks ago, a group of researchers from Google’s artificial-intelligence subsidiary, DeepMind, published a paper in the journal Science that described an A.I. for playing games. While their system is general-purpose enough to work for many two-person games, the researchers had adapted it specifically for Go, chess, and shogi (“Japanese chess”); it was given no knowledge beyond the rules of each game. At first it made random moves. Then it started learning through self-play. Over the course of nine hours, the chess version of the program played forty-four million games against itself on a massive cluster of specialized Google hardware. After two hours, it began performing better than human players; after four, it was beating the best chess engine in the world.The best of The New Yorker, in your in-boxReporting, commentary, culture, and humor. Sign up for our newsletters now.The program, called AlphaZero, descends from AlphaGo, an A.I. that became known for defeating Lee Sedol, the world’s best Go player, in March of 2016. Sedol’s defeat was a stunning upset. In “AlphaGo,” a documentary released earlier this year on Netflix, the  filmmakers follow both the team that developed the A.I. and its human opponents, who have devoted their lives to the game. We watch as these humans experience the stages of a new kind of grief. At first, they don’t see how they can lose to a machine: “I believe that human intuition is still too advanced for A.I. to have caught up,” Sedol says, the day before his five-game match with AlphaGo. Then, when the machine starts winning, a kind of panic sets in. In one particularly poignant moment, Sedol, under pressure after having lost his first game, gets up from the table and, leaving his clock running, walks outside for a cigarette. He looks out over the rooftops of Seoul. (On the Internet, more than fifty million people were watching the match.) Meanwhile, the A.I., unaware that its opponent has gone anywhere, plays a move that commentators called creative, surprising, and beautiful. In the end, Sedol lost, 1-4. Before there could be acceptance, there was depression. “I want to apologize for being so powerless,” he said in a press conference. Eventually, Sedol, along with the rest of the Go community, came to appreciate the machine. “I think this will bring a new paradigm to Go,” he said. Fan Hui, the European champion, agreed. “Maybe it can show humans something we’ve never discovered. Maybe it’s beautiful.”AlphaGo was a triumph for its creators, but still unsatisfying, because it depended so much on human Go expertise. The A.I. learned which moves it should make, in part, by trying to mimic world-class players. It also used a set of hand-coded heuristics to avoid the worst blunders when looking ahead in games. To the researchers building AlphaGo, this knowledge felt like a crutch. They set out to build a new version of the A.I. that learned on its own, as a “tabula rasa.”The result, AlphaGo Zero, detailed in a paper published in October, 2017, was so called because it had zero knowledge of Go beyond the rules. This new program was much less well-known; perhaps you can ask for the world’s attention only so many times. But in a way it was the more remarkable achievement, one that no longer had much to do with Go at all. In fact, less than two months later, DeepMind published a preprint of a third paper, showing that the algorithm behind AlphaGo Zero could be generalized to any two-person, zero-sum game of perfect information (that is, a game in which there are no hidden elements, such as face-down cards in poker). DeepMind dropped the “Go” from the name and christened its new system AlphaZero. At its core was an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been. Perhaps more surprising, this iteration of the system was also by far the simplest.A typical chess engine is a hodgepodge of tweaks and shims made over decades of trial and error. The best engine in the world, Stockfish, is open source, and it gets better by a kind of Darwinian selection: someone suggests an idea; tens of thousands of games are played between the version with the idea and the version without it; the best version wins. As a result, it is not a particularly elegant program, and it can be hard for coders to understand. Many of the changes programmers make to Stockfish are best formulated in terms of chess, not computer science, and concern how to evaluate a given situation on the board: Should a knight be worth 2.1 points or 2.2? What if it’s on the third rank, and the opponent has an opposite-colored bishop? To illustrate this point, David Silver, the head of research at DeepMind, once listed the moving parts in Stockfish. There are more than fifty of them, each requiring a significant amount of code, each a bit of hard-won chess arcana: the Counter Move Heuristic; databases of known endgames; evaluation modules for Doubled Pawns, Trapped Pieces, Rooks on (Semi) Open Files, and so on; strategies for searching the tree of possible moves, like “aspiration windows” and “iterative deepening.”AlphaZero, by contrast, has only two parts: a neural network and an algorithm called Monte Carlo Tree Search. (In a nod to the gaming mecca, mathematicians refer to approaches that involve some randomness as “Monte Carlo methods.”) The idea behind M.C.T.S., as it’s often known, is that a game like chess is really a tree of possibilities. If I move my rook to d8, you could capture it or let it be, at which point I could push a pawn or move my bishop or protect my queen. . . . The trouble is that this tree gets incredibly large incredibly quickly. No amount of computing power would be enough to search it exhaustively. An expert human player is an expert precisely because her mind automatically identifies the essential parts of the tree and focusses its attention there. Computers, if they are to compete, must somehow do the same.Chess commentators have praised AlphaZero, declaring that the engine “plays like a human on fire.”Photograph Courtesy DeepMind TechnologiesThis is where the neural network comes in. AlphaZero’s neural network receives, as input, the layout of the board for the last few moves of the game. As output, it estimates how likely the current player is to win and predicts which of the currently available moves are likely to work best. The M.C.T.S. algorithm uses these predictions to decide where to focus in the tree. If the network guesses that ‘knight-takes-bishop’ is likely to be a good move, for example, then the M.C.T.S. will devote more of its time to exploring the consequences of that move. But it balances this “exploitation” of promising moves with a little “exploration”: it sometimes picks moves it thinks are unlikely to bear fruit, just in case they do.At first, the neural network guiding this search is fairly stupid: it makes its predictions more or less at random. As a result, the Monte Carlo Tree Search starts out doing a pretty bad job of focussing on the important parts of the tree. But the genius of AlphaZero is in how it learns. It takes these two half-working parts and has them hone each other. Even when a dumb neural network does a bad job of predicting which moves will work, it’s still useful to look ahead in the game tree: toward the end of the game, for instance, the M.C.T.S. can still learn which positions actually lead to victory, at least some of the time. This knowledge can then be used to improve the neural network. When a game is done, and you know the outcome, you look at what the neural network predicted for each position (say, that there’s an 80.2 per cent chance that castling is the best move) and compare that to what actually happened (say, that the percentage is more like 60.5); you can then “correct” your neural network by tuning its synaptic connections until it prefers winning moves. In essence, all of the M.C.T.S.’s searching is distilled into new weights for the neural network.With a slightly better network, of course, the search gets slightly less misguided—and this allows it to search better, thereby extracting better information for training the network. On and on it goes, in a feedback loop that ratchets up, very quickly, toward the plateau of known ability.When the AlphaGo Zero and AlphaZero papers were published, a small army of enthusiasts began describing the systems in blog posts and YouTube videos and building their own copycat versions. Most of this work was explanatory—it flowed from the amateur urge to learn and share that gave rise to the Web in the first place. But a couple of efforts also sprung up to replicate the work at a large scale. The DeepMind papers, after all, had merely described the greatest Go- and chess-playing programs in the world—they hadn’t contained the source code, and the company hadn’t made the programs themselves available to players. Having declared victory, its  engineers had departed the field.Video From The New YorkerChess Grandmaster Garry Kasparov Replays His Four Most Memorable GamesGian-Carlo Pascutto, a computer programmer who works at the Mozilla Corporation, had a track record of building competitive game engines, first in chess, then in Go. He followed the latest research. As the combination of Monte Carlo Tree Search and a neural network became the state of the art in Go A.I.s, Pascutto built the world’s most successful open-source Go engines—first Leela, then LeelaZero—which mirrored the advances made by DeepMind. The trouble was that DeepMind had access to Google’s vast cloud and Pascutto didn’t. To train its Go engine, DeepMind used five thousand of Google’s “Tensor Processing Units”—chips specifically designed for neural-network calculations—for thirteen days. To do the same work on his desktop system, Pascutto would have to run it for seventeen hundred years.To compensate for his lack of computing power, Pascutto distributed the effort. LeelaZero is a federated system: anyone who wants to participate can download the latest version, donate whatever computing power he has to it, and upload the data he generates so that the system can be slightly improved. The distributed LeelaZero community has had their system play more than ten million games against itself—a little more than AlphaGo Zero. It is now one of the strongest existing Go engines.It wasn’t long before the idea was extended to chess. In December of last year, when the AlphaZero preprint was published, “it was like a bomb hit the community,” Gary Linscott said. Linscott, a computer scientist who had worked on Stockfish, used the existing LeelaZero code base, and the new ideas in the AlphaZero paper, to create Leela Chess Zero. (For Stockfish, he had developed a testing framework so that new ideas for the engine could be distributed to a fleet of volunteers, and thus vetted more quickly; distributing the training for a neural network was a natural next step.) There were kinks to sort out, and educated guesses to make about details that the DeepMind team had left out of their papers, but within a few months the neural network began improving. The chess world was already obsessed with AlphaZero:  posts on chess.com celebrated the engine; commentators and grandmasters pored over the handful of AlphaZero games that DeepMind had released with their paper, declaring that this was “how chess ought to be played,” that the engine “plays like a human on fire.”  Quickly, Lc0, as Leela Chess Zero became known, attracted hundreds of volunteers. As they contributed their computer power and improvements to the source code, the engine got even better. Today, one core contributor suspects that it is just a few months away from overtaking Stockfish. Not long after, it may become better than AlphaZero itself.When we spoke over the phone, Linscott marvelled that a project like his, which would once have taken a talented doctoral student several years, could now be done by an interested amateur in a couple of months. Software libraries for neural networks allow for the replication of a world-beating design using only a few dozen lines of code; the tools already exist for distributing computation among a set of volunteers, and chipmakers such as Nvidia have put cheap and powerful G.P.U.s—graphics-processing chips, which are perfect for training neural networks—into the hands of millions of ordinary computer users. An algorithm like M.C.T.S. is simple enough to be implemented in an afternoon or two. You don’t even need to be an expert in the game for which you’re building an engine. When he built LeelaZero, Pascutto hadn’t played Go for about twenty years.David Silver, the head of research at DeepMind, has pointed out a seeming paradox at the heart of his company’s recent work with games: the simpler its programs got—from AlphaGo to AlphaGo Zero to AlphaZero—the better they performed. “Maybe one of the principles that we’re after,” he said, in a talk in December of 2017, “is this idea that by doing less, by removing complexity from the algorithm, it enables us to become more general.” By removing the Go knowledge from their Go engine, they made a better Go engine—and, at the same time, an engine that could play shogi and chess.It was never obvious that things would turn out this way. In 1953, Alan Turing, who helped create modern computing, wrote a short paper titled, “Digital Computers Applied to Games.” In it, he developed a chess program “based on an introspective analysis of my thought processes while playing.” The program was simple, but in its case simplicity was no virtue: like Turing, who wasn’t a gifted chess player, it missed much of the depth of the game and didn't play very well. Even so, Turing conjectured that the idea that “one cannot programme a machine to play a better game than one plays oneself” was a “rather glib view.” Although it sounds right to say that “no animal can swallow an animal heavier than itself,” plenty of animals can. Similarly, Turing suggested, there might be no contradiction in a bad chess player making a chess program that plays brilliantly. One tantalizing way to do it would be to have the program learn for itself.The success of AlphaZero seems to bear this out. It has a simple structure, but it’s capable of learning surprisingly deep features of the games it plays. In one section of the AlphaGo Zero paper, the DeepMind team illustrates how their A.I., after a certain number of training cycles, discovers strategies well-known to master players, only to discard them just a few cycles later. It is odd and a little unsettling to see humanity’s best ideas trundled over on the way to something better; it hits close to home in a way that seeing a physical machine exceed us—a bulldozer shifting a load of earth, say—doesn’t. In a recent editorial in Science, Garry Kasparov, the former chess champion who lost to I.B.M.’s Deep Blue in 1997, argues that AlphaZero doesn’t play chess in a way that reflects the presumably systematic “priorities and prejudices of programmers”; instead—even though it searches far fewer positions per move than a traditional engine—it plays in an open, aggressive style and seems to think in terms of strategy rather than tactics, like a human with uncanny vision. “Because AlphaZero programs itself,” Kasparov writes, “I would say that its style reflects the truth.”Playing chess like a human, of course, isn't the same thing as thinking about chess like a human, or learning like one. There is an old saying that game-playing is the Drosophila of A.I.: as the fruit fly is to biologists, so games like Go and chess are to computer scientists studying the mechanisms of intelligence. It’s an evocative analogy. And yet it could be that the task of playing chess, once it’s converted into the task of searching tens of thousands of nodes per second in a game tree, exercises a different kind of intelligence than the one we care about most. Played in this way, chess might be more like earth-moving than we thought: an activity that, in the end, isn’t our forté, and so shouldn’t be all that dear to our souls. To learn, AlphaZero needs to play millions more games than a human does— but, when it’s done, it plays like a genius. It relies on churning faster than a person ever could through a deep search tree, then uses a neural network to process what it finds into something that resembles intuition. Surely the program teaches us something new about intelligence. But its success also underscores just how much the world’s best human players can see by means of a very different process—one based on reading, talking, and feeling, in addition to playing. What may be most surprising is that we humans have done as well as we have in games that seem, now, to have been made for machines.","[{'@type': 'ListItem', 'position': 1, 'name': 'Tech', 'item': 'https://www.newyorker.com/tech'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence (A.I.)', 'item': 'https://www.newyorker.com/tag/artificial-intelligence-ai'}, {'@type': 'ListItem', 'position': 3, 'name': 'How the Artificial-Intelligence Program AlphaZero Mastered Its Games'}]",,,,,,,,,,,,,,True,,,,"The program, called AlphaZero, descends from AlphaGo, an A.I. that became known for defeating Lee Sedol, the world’s best Go player, in March of 2016. Sedol’s defeat was a stunning upset. In “AlphaGo,” a documentary released earlier this year on Netflix, the  filmmakers follow both the team that developed the A.I. and its human opponents, who have devoted their lives to the game. We watch as these humans experience the stages of a new kind of grief. At first, they don’t see how they can lose to a machine: “I believe that human intuition is still too advanced for A.I. to have caught up,” Sedol says, the day before his five-game match with AlphaGo. Then, when the machine starts winning, a kind of panic sets in. In one particularly poignant moment, Sedol, under pressure after having lost his first game, gets up from the table and, leaving his clock running, walks outside for a cigarette. He looks out over the rooftops of Seoul. (On the Internet, more than fifty million people were watching the match.) Meanwhile, the A.I., unaware that its opponent has gone anywhere, plays a move that commentators called creative, surprising, and beautiful. In the end, Sedol lost, 1-4. Before there could be acceptance, there was depression. “I want to apologize for being so powerless,” he said in a press conference. Eventually, Sedol, along with the rest of the Go community, came to appreciate the machine. “I think this will bring a new paradigm to Go,” he said. Fan Hui, the European champion, agreed. “Maybe it can show humans something we’ve never discovered. Maybe it’s beautiful.”
AlphaGo was a triumph for its creators, but still unsatisfying, because it depended so much on human Go expertise. The A.I. learned which moves it should make, in part, by trying to mimic world-class players. It also used a set of hand-coded heuristics to avoid the worst blunders when looking ahead in games. To the researchers building AlphaGo, this knowledge felt like a crutch. They set out to build a new version of the A.I. that learned on its own, as a “tabula rasa.”
The result, AlphaGo Zero, detailed in a paper published in October, 2017, was so called because it had zero knowledge of Go beyond the rules. This new program was much less well-known; perhaps you can ask for the world’s attention only so many times. But in a way it was the more remarkable achievement, one that no longer had much to do with Go at all. In fact, less than two months later, DeepMind published a preprint of a third paper, showing that the algorithm behind AlphaGo Zero could be generalized to any two-person, zero-sum game of perfect information (that is, a game in which there are no hidden elements, such as face-down cards in poker). DeepMind dropped the “Go” from the name and christened its new system AlphaZero. At its core was an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been. Perhaps more surprising, this iteration of the system was also by far the simplest.
AlphaZero, by contrast, has only two parts: a neural network and an algorithm called Monte Carlo Tree Search. (In a nod to the gaming mecca, mathematicians refer to approaches that involve some randomness as “Monte Carlo methods.”) The idea behind M.C.T.S., as it’s often known, is that a game like chess is really a tree of possibilities. If I move my rook to d8, you could capture it or let it be, at which point I could push a pawn or move my bishop or protect my queen. . . . The trouble is that this tree gets incredibly large incredibly quickly. No amount of computing power would be enough to search it exhaustively. An expert human player is an expert precisely because her mind automatically identifies the essential parts of the tree and focusses its attention there. Computers, if they are to compete, must somehow do the same.
This is where the neural network comes in. AlphaZero’s neural network receives, as input, the layout of the board for the last few moves of the game. As output, it estimates how likely the current player is to win and predicts which of the currently available moves are likely to work best. The M.C.T.S. algorithm uses these predictions to decide where to focus in the tree. If the network guesses that ‘knight-takes-bishop’ is likely to be a good move, for example, then the M.C.T.S. will devote more of its time to exploring the consequences of that move. But it balances this “exploitation” of promising moves with a little “exploration”: it sometimes picks moves it thinks are unlikely to bear fruit, just in case they do.
At first, the neural network guiding this search is fairly stupid: it makes its predictions more or less at random. As a result, the Monte Carlo Tree Search starts out doing a pretty bad job of focussing on the important parts of the tree. But the genius of AlphaZero is in how it learns. It takes these two half-working parts and has them hone each other. Even when a dumb neural network does a bad job of predicting which moves will work, it’s still useful to look ahead in the game tree: toward the end of the game, for instance, the M.C.T.S. can still learn which positions actually lead to victory, at least some of the time. This knowledge can then be used to improve the neural network. When a game is done, and you know the outcome, you look at what the neural network predicted for each position (say, that there’s an 80.2 per cent chance that castling is the best move) and compare that to what actually happened (say, that the percentage is more like 60.5); you can then “correct” your neural network by tuning its synaptic connections until it prefers winning moves. In essence, all of the M.C.T.S.’s searching is distilled into new weights for the neural network.
With a slightly better network, of course, the search gets slightly less misguided—and this allows it to search better, thereby extracting better information for training the network. On and on it goes, in a feedback loop that ratchets up, very quickly, toward the plateau of known ability.
Gian-Carlo Pascutto, a computer programmer who works at the Mozilla Corporation, had a track record of building competitive game engines, first in chess, then in Go. He followed the latest research. As the combination of Monte Carlo Tree Search and a neural network became the state of the art in Go A.I.s, Pascutto built the world’s most successful open-source Go engines—first Leela, then LeelaZero—which mirrored the advances made by DeepMind. The trouble was that DeepMind had access to Google’s vast cloud and Pascutto didn’t. To train its Go engine, DeepMind used five thousand of Google’s “Tensor Processing Units”—chips specifically designed for neural-network calculations—for thirteen days. To do the same work on his desktop system, Pascutto would have to run it for seventeen hundred years.
To compensate for his lack of computing power, Pascutto distributed the effort. LeelaZero is a federated system: anyone who wants to participate can download the latest version, donate whatever computing power he has to it, and upload the data he generates so that the system can be slightly improved. The distributed LeelaZero community has had their system play more than ten million games against itself—a little more than AlphaGo Zero. It is now one of the strongest existing Go engines.
It wasn’t long before the idea was extended to chess. In December of last year, when the AlphaZero preprint was published, “it was like a bomb hit the community,” Gary Linscott said. Linscott, a computer scientist who had worked on Stockfish, used the existing LeelaZero code base, and the new ideas in the AlphaZero paper, to create Leela Chess Zero. (For Stockfish, he had developed a testing framework so that new ideas for the engine could be distributed to a fleet of volunteers, and thus vetted more quickly; distributing the training for a neural network was a natural next step.) There were kinks to sort out, and educated guesses to make about details that the DeepMind team had left out of their papers, but within a few months the neural network began improving. The chess world was already obsessed with AlphaZero:  posts on chess.com celebrated the engine; commentators and grandmasters pored over the handful of AlphaZero games that DeepMind had released with their paper, declaring that this was “how chess ought to be played,” that the engine “plays like a human on fire.”  Quickly, Lc0, as Leela Chess Zero became known, attracted hundreds of volunteers. As they contributed their computer power and improvements to the source code, the engine got even better. Today, one core contributor suspects that it is just a few months away from overtaking Stockfish. Not long after, it may become better than AlphaZero itself.
When we spoke over the phone, Linscott marvelled that a project like his, which would once have taken a talented doctoral student several years, could now be done by an interested amateur in a couple of months. Software libraries for neural networks allow for the replication of a world-beating design using only a few dozen lines of code; the tools already exist for distributing computation among a set of volunteers, and chipmakers such as Nvidia have put cheap and powerful G.P.U.s—graphics-processing chips, which are perfect for training neural networks—into the hands of millions of ordinary computer users. An algorithm like M.C.T.S. is simple enough to be implemented in an afternoon or two. You don’t even need to be an expert in the game for which you’re building an engine. When he built LeelaZero, Pascutto hadn’t played Go for about twenty years.
It was never obvious that things would turn out this way. In 1953, Alan Turing, who helped create modern computing, wrote a short paper titled, “Digital Computers Applied to Games.” In it, he developed a chess program “based on an introspective analysis of my thought processes while playing.” The program was simple, but in its case simplicity was no virtue: like Turing, who wasn’t a gifted chess player, it missed much of the depth of the game and didn't play very well. Even so, Turing conjectured that the idea that “one cannot programme a machine to play a better game than one plays oneself” was a “rather glib view.” Although it sounds right to say that “no animal can swallow an animal heavier than itself,” plenty of animals can. Similarly, Turing suggested, there might be no contradiction in a bad chess player making a chess program that plays brilliantly. One tantalizing way to do it would be to have the program learn for itself.
The success of AlphaZero seems to bear this out. It has a simple structure, but it’s capable of learning surprisingly deep features of the games it plays. In one section of the AlphaGo Zero paper, the DeepMind team illustrates how their A.I., after a certain number of training cycles, discovers strategies well-known to master players, only to discard them just a few cycles later. It is odd and a little unsettling to see humanity’s best ideas trundled over on the way to something better; it hits close to home in a way that seeing a physical machine exceed us—a bulldozer shifting a load of earth, say—doesn’t. In a recent editorial in Science, Garry Kasparov, the former chess champion who lost to I.B.M.’s Deep Blue in 1997, argues that AlphaZero doesn’t play chess in a way that reflects the presumably systematic “priorities and prejudices of programmers”; instead—even though it searches far fewer positions per move than a traditional engine—it plays in an open, aggressive style and seems to think in terms of strategy rather than tactics, like a human with uncanny vision. “Because AlphaZero programs itself,” Kasparov writes, “I would say that its style reflects the truth.”
Playing chess like a human, of course, isn't the same thing as thinking about chess like a human, or learning like one. There is an old saying that game-playing is the Drosophila of A.I.: as the fruit fly is to biologists, so games like Go and chess are to computer scientists studying the mechanisms of intelligence. It’s an evocative analogy. And yet it could be that the task of playing chess, once it’s converted into the task of searching tens of thousands of nodes per second in a game tree, exercises a different kind of intelligence than the one we care about most. Played in this way, chess might be more like earth-moving than we thought: an activity that, in the end, isn’t our forté, and so shouldn’t be all that dear to our souls. To learn, AlphaZero needs to play millions more games than a human does— but, when it’s done, it plays like a genius. It relies on churning faster than a person ever could through a deep search tree, then uses a neural network to process what it finds into something that resembles intuition. Surely the program teaches us something new about intelligence. But its success also underscores just how much the world’s best human players can see by means of a very different process—one based on reading, talking, and feeling, in addition to playing. What may be most surprising is that we humans have done as well as we have in games that seem, now, to have been made for machines.",,,,,,"{'@type': 'CreativeWork', 'name': 'The New Yorker'}","James Somers on AlphaZero, an artificial-intelligence program animated by an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been.",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vaW50ZXJlc3RpbmdlbmdpbmVlcmluZy5jb20vaW5ub3ZhdGlvbi9haS12cy1sYXd5ZXJzLXRoZS1mdXR1cmUtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLWxhd9IBAA?oc=5,AI vs. lawyers: The future of Artificial Intelligence and law - Interesting Engineering,2018-12-29,Interesting Engineering,https://interestingengineering.com,"There must be human-made objects that are able to do most of the things humans do; especially the things that require ""intelligence"". How will this impact lawyers?",AI,"There must be human-made objects that are able to do most of the things humans do; especially the things that require ""intelligence"". How will this impact lawyers?","There must be human-made objects that are able to do most of the things humans do; especially the things that require ""intelligence"". How will this impact lawyers?",https://schema.org,"[{'@type': 'NewsArticle', '@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#article', 'isPartOf': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law'}, 'author': {'name': 'Interesting Engineering', '@id': 'https://interestingengineering.com/#/schema/person/81843ebb6463000002a8611c599f48cd'}, 'headline': 'AI vs. lawyers: The future of Artificial Intelligence and law', 'datePublished': '2018-12-29T10:25:00+00:00', 'dateModified': '2018-12-29T10:25:00+00:00', 'mainEntityOfPage': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law'}, 'wordCount': 1720, 'commentCount': 0, 'publisher': {'@id': 'https://interestingengineering.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': False, 'caption': False}, 'thumbnailUrl': 'https://images.interestingengineering.com/images/ai_lawyers_son-1_-_Kopya_1208x608.jpg', 'keywords': ['AI'], 'articleSection': ['Innovation'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://interestingengineering.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law', 'url': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law', 'name': 'AI vs. lawyers: The future of Artificial Intelligence and law', 'isPartOf': {'@id': 'https://interestingengineering.com/#website'}, 'primaryImageOfPage': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#primaryimage'}, 'image': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#primaryimage'}, 'thumbnailUrl': 'https://images.interestingengineering.com/images/ai_lawyers_son-1_-_Kopya_1208x608.jpg', 'datePublished': '2018-12-29T10:25:00+00:00', 'dateModified': '2018-12-29T10:25:00+00:00', 'description': 'There must be human-made objects that are able to do most of the things humans do; especially the things that require ""intelligence"". How will this impact lawyers?', 'breadcrumb': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#primaryimage', 'url': 'https://images.interestingengineering.com/images/ai_lawyers_son-1_-_Kopya_1208x608.jpg', 'contentUrl': 'https://images.interestingengineering.com/images/ai_lawyers_son-1_-_Kopya_1208x608.jpg'}, {'@type': 'BreadcrumbList', '@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://interestingengineering.com/news'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://interestingengineering.com/innovation'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI vs. lawyers: The future of Artificial Intelligence and law'}]}, {'@type': 'WebSite', '@id': 'https://interestingengineering.com/#website', 'url': 'https://interestingengineering.com/', 'name': 'Interesting Engineering', 'description': '', 'publisher': {'@id': 'https://interestingengineering.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://interestingengineering.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://interestingengineering.com/#organization', 'name': 'Interesting Engineering', 'url': 'https://interestingengineering.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://interestingengineering.com/#/schema/logo/image/', 'url': 'https://cms.interestingengineering.com/wp-content/uploads/2024/02/Interesting_Engineering-1.jpg', 'contentUrl': 'https://cms.interestingengineering.com/wp-content/uploads/2024/02/Interesting_Engineering-1.jpg', 'width': 590, 'height': 198, 'caption': 'Interesting Engineering'}, 'image': {'@id': 'https://interestingengineering.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/interestingengineering/', 'https://x.com/IntEngineering', 'https://www.linkedin.com/company/interestingengineering/'], 'email': 'info@interestingengineering.com', 'numberOfEmployees': {'@type': 'QuantitativeValue', 'minValue': '201', 'maxValue': '500'}, 'publishingPrinciples': 'https://interestingengineering.com/home-page'}]",,,,,,,,,,,,,,,,"ShareInnovationAI vs. lawyers: The future of Artificial Intelligence and lawThere must be human-made objects that are able to do most of the things humans do; especially the things that require “intelligence”. How will this impact lawyers?
Published: Dec 29, 2018 05:25 AM ESTInteresting Engineering6 years ago0ShareDepositphoto“Can machines think?” 
Let’s expand this question asked by Alan Turing in the 50s. The countless disaster scenarios, in which artificial intelligence (AI) takes over the world and destroys humanity, are already made-up and still being told in Hollywood.
AI has not yet taken control of humanity, but it has indeed taken control of many aspects of our lives even if we do not perceive it as such. We accept AI as a part of our lives. The simplest example is our smartphones. Bionic hands and laser rust removal, the best of IE this week
1/100:29Bionic hands and laser rust removal, the best of IE this week





Skip in 5s
 
Continue watchingBionic hands and laser rust removal, the best of IE this weekafter the adVisit Advertiser websiteGO TO PAGE
The use of AI applications in this domain is so widespread that it is now possible to produce solutions for almost all professional groups. Medicine, education, automotive, defense, agriculture, automation, energy, natural sciences, finance, art, and even law.
But can AI replace human lawyers?
The Role of Deep Learning 
Over the past 7 years, the main sub-area of AI has been deep learning. Deep learning is more successful than humans especially in processing visual data and analyzing images from the images, what objects or living things exist, relationships with each other, event estimation, object/person tracking, etc.
Deep learning includes AI models that generate the most successful results in the application areas of recent years, based on artificial neural networks and requiring a lot of processing power.
How do AI Systems Learn Language?
Models used for natural language processing are also within the scope of deep learning.
Using natural language processing models, we can parse millions of data files loaded into the computer by class. In this process, the system learns the relationship between words from all the documents and is able to predict that the word ‘carrot’ comes after the word ‘rabbit’ with higher probability than the word ‘sun’.
AI can estimate this due to the fact that the words perform meaning analysis based on their statistical status in sentences. It is possible to summarize or classify a long paragraph, including time-space information from single sentences.
AI to Form Meaning Networks
More and more data is accumulating on the Internet every day. Thanks to the enormous data, we can realize artificial intelligence applications that are self-generating ‘meaning networks’.
It not only informs us about the sociological, psychological, ethnic, sociocultural, and economic levels of communities or people living in a region but also helps us predict where the developing hot agenda can be, just like in the U.S. presidential election.
Using the voice doctor application on our phone, we can try to determine what our discomfort is and to perform pre-interventions with very high accuracy. Babylon, which has more than 40,000 users in the UK, is an exemplary AI assistant physician practice.
What if AI tries to practice as a lawyer?
Imagine that a ‘human lawyer’ can handle all the cases in the world after AI’s preliminary research.
For a human lawyer, it takes weeks to do research, but AI can do it in just a few seconds. Moreover, AI does not get tired, sleep, eat, or drink coffee. In fact, AI can produce more successful results than an average experienced lawyer.
What would you say to that? Will AI and machine learning eradicate the need for lawyers?

Source: Dilara Kizrak Design Studio/Instagram

Dilara Kizrak Design Studio/Instagram


Leibniz: the first lawyer to predict the use of machines in law
Leibniz, who is one of the grandfathers of AI, was a lawyer and said: ‘It is unworthy of excellent men to lose hours like slaves in the labor of calculation which could safely be relegated to anyone else if machines were used.’
In 1673, he presented the machine for four arithmetic operations in the UK. Leibniz says: ‘The only way to correct our reasoning is to make them as tangible as the mathematicians’ so that we can find our error at a glance, and when there are disagreements between people, let’s calculate and see who is right!’
So, let’s think, why shouldn’t it be possible for machines to complete all steps of the event chain which occurs in a lawyer’s mind while they are deciding?
Why couldn’t the machine do it? Why can it not calculate who is right in the dispute between people or how to find the middle way? Isn’t that a ‘robot mediator’? These questions belong to the 17th century! I would like to point out, and we are at the end of 2018!
AINOW’s Contribution to create the future of legal AI
‘Since men near monopoly of all higher forms of intelligence have been one of the most basic facts of human existence throughout the past history of this planet, such developments would clearly create a new economics, a new sociology, and a new history!’ says J. Schwartz.
In June 2018, AINOW—a research institute examining the social implications of AI—convened a workshop with the goal of bringing together legal, scientific, and technical advocates who focus on litigating algorithmic decision-making across various areas of the law (e.g., employment, public benefits, criminal justice).
They structured the day with the practical aim of discussing strategy and best practices while also exchanging ideas and experiences in litigation and other advocacy in this space.
The gathering included several of the lawyers who brought the cases alongside advocates, researchers, technical experts, social scientists, and other leading thinkers in the area of algorithmic accountability.
What are the accuracy rates of the AI Programs? 
In 2017, in an experiment involving more than 100 lawyers in London, hundreds of actual applications to the Finance Ombudsman for a specific credit card irregularity were examined.
While the accuracy of human prediction was 66.3%, an AI program trained to predict whether or not to accept files achieved 86.6% accuracy.

Source: LawGeex

LawGeex


Evisort to reduce the time cost of the Judicial System
Also, in late 2017, four Harvard Law School students argued that using AI to formulate and manage drafts of law contracts was a very accurate move.
With their powerful new search engine called Evisort that harnesses cloud storage and AI, they hope to revolutionize the costly and labor-intensive way that lawyers currently handle contracts and other transactional work, liberating them for more creative and interesting tasks.
When they say, “In six seconds they can review a 30-page contract and pull out information for you”, lawyers say, “Why did I spend 10 years of my life doing that?” That reaction is what gets them excited to keep going.
The way to reduce costs without sacrificing performance and accuracy is through the use of deep learning and machine learning models in natural language processing for law correspondence.
Performance comparison of the AI lawyers and the human lawyers
Another current study was from LawGeex, which was founded in 2014. They compared the performance of 20 experienced United Nations lawyers to their AI systems and published a 40-page report.
Obtained results: In the daily legal risk assessment task, the highest performance among human lawyers was 94%, the lowest performance was 64%, and the average performance was 85%, while the average of AI was 94% success.
In addition, the average time required for ‘human lawyers’ for this process is 92 minutes, while the time needed by AI is 26 seconds. AI can continue this process for a long time without rest!
Historical Records are Helping the AI Systems 
The most important part of the success of these studies is that the data is regularly found in digital media. Harvard Law School recently shared the 360-year-old case law of the United States of America according to each of the states with AI developers on the online platform.
This is an important resource for speeding up the work. But the biggest obstacles to natural language processing are language-specific rules and the need for such resources in all languages. The developments in English are quite bright because most of the data is regularly available in this language.

Source:Depositphotos


Human-AI lawyer cooperation
As I mentioned at the beginning, these AI applications which are developed by using data make similar inferences by looking at the millions of cases in the past while giving a higher performance compared to the success of a group of human lawyers.
In all these AI examples, human lawyers regained their lost time. Artificial intelligence enables human lawyers to work with speed and more data. These AI systems show us cooperation between humans and AI, which is important. That defined human-in-loop. It aims at providing lawyers with more consultancy and getting rid of fatigue duty.
For many applications of AI, the human-centered approach supports the idea of human-AI collaboration instead of AI competing against a human.
But what about the subjective observations and prejudices that are stored in the data used by these machines? If the motives for data transfer are not healthy, would it not make the decisions wrong? Is it possible for AI to collect parser, connective, formative, regenerator, and operator which are included by ‘human lawyer’?
Systems could adopt the prejudices of the case documents so far, such as those that were decided according to racist approaches in the past. So AI systems in their current status are not prone to the social conflicts that their context of creation contains within.
How do we provide serious judgment, attention, insightful behavior, assessment, and judicial data to create a healthy judgment? Perhaps the machine actually needs to be exposed to past data or to be manipulated by human collaborators to overcome these issues.
Questions on AI ethics
Is manipulation meant to interfere with the evolution of the machine and is it wrong? We’re coming to a point where AI ethics is on the agenda!
Will the attorney receive support from the AI machine while taking care of his job? Will AI software have its own rights? Can AI machines participate in civil law or criminal law transactions?
When we give the same case to the machines where the same programs are installed and when we want each machine to solve the same problem more than once, will there be nuanced differences between these solutions? Should it be? According to time and space, how should we differentiate each case?
Well, is ‘human’ considered to be ‘robotized’ in professional execution today? Maybe we cannot remove prejudices from human beings, but we need to keep people away from AI to prevent prejudice. These are the issues that need to be discussed for a while.        RECOMMENDED ARTICLES

0COMMENTNEWSLETTERThe Blueprint DailyStay up-to-date on engineering, tech, space, and science news with The Blueprint.Sign Up  By clicking sign up, you confirm that you accept this site's Terms of Use and Privacy PolicyABOUT THE EDITORInteresting Engineering Interesting Engineering is a diverse group of journalists, videographers, and creators that aims to help the world better understand the art and science of engineering. With a combination of innovative storytelling and bespoke content formats, we cover the latest developments and breakthroughs in engineering, science, and technology.NewsinnovationPOPULAR ARTICLES1militaryGerman Navy ditches epic floppy disks from its warships after 30 yearsJijo Malayila day ago02energyCO2 to stone: Startup plans to inject 100 tons of carbon 1 km inside EarthChris Younga day ago03innovationStartup’s tricks drop methane emissions from rice cultivation by 35%Ameya Palejaa day ago04cultureSting operation: Kenya uses hidden bee hives to fight timber smugglersMaria Mocerinoa day ago0RELATED ARTICLESspaceFirst direct evidence of underground lava tube on Moon’s surface foundmilitaryUkraine’s trainer jet dogfights, downs Russian spy drones in WWI-stylecultureUN: 100 lorries may need 15 years to clear 40 million tons of Gaza debrisinnovationElectric abra: World’s 1st 3D-printed traditional wooden boat sets sail in DubaiJOBSSee All

Find Your Place In The World BY Amply







GTT, LLC

Staff Engineer
Chevy Chase
$90 an hour
See Job







Envision, LLC

Cloud Engineer
St. Louis
See Job







Navy Federal Credit Union

ETS Engineer IV (ServiceNow Engineer)
Vienna
$124,700 - $183,800 a year
See Job







SAIC

Network Engineer
Richmond
See Job



Search More Roles


FEATURED STORIES



 
 








",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvcXVvcmEvMjAxOC8xMi8yNy93aGF0LWluZHVzdHJpZXMtd2lsbC1yZW1haW4tdW50b3VjaGVkLWJ5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,What Industries Will Remain Untouched By Artificial Intelligence? - Forbes,2018-12-27,Forbes,https://www.forbes.com,What jobs will AI probably not destroy? This question was originally answered on Quora by Martin Ford.,,What jobs will AI probably not destroy? This question was originally answered on Quora by Martin Ford.,What jobs will AI probably not destroy? This question was originally answered on Quora by Martin Ford.,http://schema.org,,BreadcrumbList,What Industries Will Remain Untouched By Artificial Intelligence?,https://www.forbes.com/sites/quora/2018/12/27/what-industries-will-remain-untouched-by-artificial-intelligence/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/dam/imageserve/41583431/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",Consumer Tech,"{'@type': 'Person', 'name': 'Quora', 'url': 'https://www.forbes.com/sites/quora/', 'description': 'Quora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.', 'sameAs': ['https://www.twitter.com/Quora', 'http://www.quora.com/']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2018-12-27T20:02:00-05:00,2018-12-27T20:02:52-05:00,Consumer Tech,,"More From ForbesJul 16, 2024,06:30am EDTZoc Flips The Script On Education With AIJul 16, 2024,06:00am EDTMeet NuPhy’s New And Improved Halo96 V2 Mechanical KeyboardJul 15, 2024,07:29pm EDTNew Software Hints At Samsung’s  Galaxy Z Fold6 UpgradeJul 15, 2024,04:20pm EDTThe Most Interesting Facts About Human BehaviorJul 15, 2024,04:19pm EDTThe Relationship Between Introversion And IntelligenceJul 15, 2024,04:17pm EDTThe Importance Of Research In Securing A Spot In BS/MD ProgramsJul 15, 2024,04:17pm EDTUnique Ways To Market A Product Or ServiceEdit StoryForbesInnovationConsumer TechWhat Industries Will Remain Untouched By Artificial Intelligence?QuoraContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 27, 2018,08:02pm ESTUpdated Dec 27, 2018, 08:02pm ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







David Paul Morris/Bloomberg
© 2017 Bloomberg Finance LP





What jobs will AI probably not destroy? originally appeared on Quora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.

Answer by Martin Ford, Futurist, Author of Architects of Intelligence, AI Expert, on Quora:
The jobs that are most susceptible to automation in the near term are those that are fundamentally routine or predictable in nature. If you have a boring job—where you come to work and do the same kinds of things again and again, you should probably worry. The tasks within jobs like this are likely to be encapsulated in the data that is collected by organizations. So it may only be a matter of time before a powerful machine learning algorithm comes along that can automate much of this work.
PROMOTED
So the answer to this question is that the jobs that will be safest are those which are NOT routine or predictable.
I think this especially includes 3 kinds of work:


Creative work — where you are building something new, thinking outside the box in non-predictable ways, etc.
Human-centered work—where you build sophisticated relationships with people. This would include caring roles, as with a nurse or social worker, but also business roles where you need a need understanding of your clients.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Skilled trade work—this includes jobs that require lots of mobility, dexterity and flexibility in unpredictable environments. Examples would be electricians or plumbers. Building a robot that can do these jobs is probably far in the future.

Of course, the important caveat here is that this applies only to the foreseeable future. In the long run, major advances in AI—and especially the advent of human-level AI (or AGI)—could be a game changer even for these relatively safe jobs.
This question originally appeared on Quora - the place to gain and share knowledge, empowering people to learn from others and better understand the world. You can follow Quora on Twitter, Facebook, and Google+. More questions:

Artificial Intelligence: Which major AI breakthroughs are we closest to right now (late 2018)?
The Future: How will AI technology grow and improve in the coming decades?
Economics: Will AI, robotics and automation replacing human jobs require that we change how our economy functions?
QuoraFollowingFollowQuora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.Editorial StandardsPrintReprints & PermissionsThe video player is currently playing an ad. You can skip the ad in 5 sec with a mouse or keyboard
1/100:10Mona Kattan On Building In Entrepreneurship And Founding Kayali | Forbes 30/50 Summit 2024





Skip Ad
 
Continue watchingMona Kattan On Building In Entrepreneurship And Founding Kayali | Forbes 30/50 Summit 2024after the adVisit Advertiser websiteGO TO PAGE","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Consumer Tech', 'item': 'https://www.forbes.com/consumer-tech/'}]",,What Industries Will Remain Untouched By Artificial Intelligence?,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMijAFodHRwczovL3d3dy5wYWxtYmVhY2hwb3N0LmNvbS9zdG9yeS9uZXdzL2NyaW1lLzIwMTgvMTIvMzEvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3BlZWRzLXdvcmstYXQtcGFsbS1iZWFjaC1jb3VudHktY2xlcmtzLW9mZmljZS82NDA4NjM3MDA3L9IBAA?oc=5,Artificial intelligence speeds work at PBC clerk's office - Palm Beach Post,2018-12-31,Palm Beach Post,https://www.palmbeachpost.com,"WEST PALM BEACH — Back in the not-so-long-ago old days, human beings looked at newly-filed court documents , assigned them numbers and placed them in file folders so judges, lawyers and those whose l…",,"WEST PALM BEACH — Back in the not-so-long-ago old days, human beings looked at newly-filed court documents , assigned them numbers and placed them in file folders so judges, lawyers and those whose l…","WEST PALM BEACH — Back in the not-so-long-ago old days, human beings looked at newly-filed court documents , assigned them numbers and placed them in file folders so judges, lawyers and those whose l…",,,,,,,,,,,,,,,,,,"CRIMEArtificial intelligence speeds work at PBC clerk's officeJane Musgravejmusgrave@pbpost.comPlayPauseSound OnSound Off0:000:34AD0:11SKIPClosedCaptionOpen ShareEnter Full ScreenExit Full ScreenWEST PALM BEACH — Back in the not-so-long-ago old days, human beings looked at newly-filed court documents, assigned them numbers and placed them in file folders so judges, lawyers and those whose lives or livelihoods depended on them could retrieve them later.Not anymore. Humans, it seems, are becoming obsolete.County Clerk & Comptroller Sharon Bock has a passion for public serviceInstead, Palm Beach County Clerk Sharon Bock is using artificial intelligence to file thousands of documents that stream into her office each week. By July, she said she expects the majority of court records that are filed electronically will be docketed by computer software.“As the world’s technology becomes more advanced, customers expect faster service,” she said of why she has embraced artificial intelligence. Computer technology has allowed her to quickly process court documents and make them available to the public.Her use of artificial intelligence has attracted the attention of the tech community. In December, her office was among 50 businesses, governments and nonprofit agencies throughout the country to be recognized by IDG, a Boston-based technology media, data and marketing services company. The company's online magazine, CIO, and its CIO (Chief Information Officer) Executive Council sponsored the awards. Winners were selected by executive informational technology leaders who evaluated projects on complexity, scale, outcomes and innovation, IDG said.“The Digital Edge 50 awards recognize the very best projects driving IT innovation,” said Anne McCrory, a group vice president of the executive council.While 89 percent of businesses plan to adopt a digital-first model, only 44 percent have followed through, McCrory said. The awards that will be handed to Bock and leaders at Bank of America, Cornell University, Humana and others at a conference in March in Ponte Vedra Beach, recognize those who put their plans into action.Bock launched the artificial intelligence in March, using software developed by Florida-based Computing Systems Innovation. The software has been trained to read and process different types of documents. Working around the clock, it allows documents to be processed almost immediately after they are filed electronically, she said.In addition to the honor from IDG, she said other court officials in Florida have taken notice. In July, clerks from other counties in Florida, along with representatives from the Administrative Office of the U.S. Courts and from the National Center for State Courts visited her office to find out how they can use technology to become more efficient.“I’m honored that our artificial intelligence program has been recognized as a leader in digital innovation, and that it will serve as a model for other organizations around the world,” Bock said.jmusgrave@pbpost.com@pbpcourtsCompareCredit2 Cards Charging 0% Interest Until Nearly 2026With no annual fee and no interest until nearly 2026, this card is helping Americans pay off debt in record time.CompareCredit|AdAdUndoGeorgetown University250+ Courses That Will Help You Make the Most of Your SummerGeorgetown is offering courses taught by its world-renowned faculty, so you can explore new subjects and get ahead.Georgetown University|AdAdUndoinvesting.comThe Top 25 Most Beautiful Women In The Worldinvesting.com|AdAdUndoPenny PincherVirginia: Big Changes Near Chantilly Leaves Drivers FumingDo not pay your auto insurance bill until you read this.Penny Pincher|AdAdUndoMiami M.D.Surgeon Reveals: Don't Laser Your Dark Spots! (Use This Household Item Instead)Miami M.D.|AdAdUndo plaque psoriasis | search adsPlaque psoriasis is silent but deadly: 10 Symptoms you should knowWhat does plaque psoriasis look like? Look at the symptoms plaque psoriasis | search ads|AdAdUndoGeorgetown UniversityEarn Credit and Get Ahead This Summer at GeorgetownBrowse Georgetown's more than 250 summer courses, all taught by world-renowned faculty.Georgetown University|AdAdLearn MoreUndoUltraCutUse This and Never Have to Change Your Whipper Snipper Line AgainUltraCut|AdAdUndoFisher Investments7 Wealth Tips Once Your Portfolio Reaches $1 MillionHow do retirees take steps to preserve their wealth in retirement? Download The Seven Secrets of High Net Worth Investors now.Fisher Investments|AdAdLearn MoreUndoCoupon Code FinderAmazon's Worst Nightmare: Thousands Canceling Prime for This Clever HackThis simple trick can save tons of money on Amazon, but most Prime members are ignoring it.Coupon Code Finder|AdAdUndoDeal of the DayREVIEWEDJLab Headphones Are Under $20 For Amazon Prime DayREVIEWEDView Deal Recommendations are independently chosen by our editors. Purchases you make through our links may earn us a commission.UndoRecommendedWade Wilson crimes: Convicted killer attempted escape from FL jailnewsUndo






























",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMikAFodHRwczovL21lZGl1bS5kYXRhZHJpdmVuaW52ZXN0b3IuY29tL25ldy10cmF1bWEtdGhlcmFweS11c2luZy1zdG9yeXRlbGxpbmctbXVzaWMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWktYW5kLXZpcnR1YWwtcmVhbGl0eS12ci0zOTcwYmYzNjE5MzfSAQA?oc=5,"New Trauma Therapy using storytelling, music, artificial intelligence (AI) and virtual reality (VR) - DataDrivenInvestor",2018-12-29,DataDrivenInvestor,https://medium.datadriveninvestor.com,"One very sad but true thing is — there is a lot of suffering in this world. Take a look around, there are different horrible things happening everywhere. From seemingly endless civil wars in the…",,"One very sad but true thing is — there is a lot of suffering in this world. Take a look around, there are different horrible things…","One very sad but true thing is — there is a lot of suffering in this world. Take a look around, there are different horrible things…",http://schema.org,,NewsArticle,"New Trauma Therapy using storytelling, music, artificial intelligence (AI) and virtual reality (VR)",https://medium.datadriveninvestor.com/new-trauma-therapy-using-storytelling-music-artificial-intelligence-ai-and-virtual-reality-vr-3970bf361937,https://medium.datadriveninvestor.com/new-trauma-therapy-using-storytelling-music-artificial-intelligence-ai-and-virtual-reality-vr-3970bf361937,,['https://miro.medium.com/v2/da:true/resize:fit:1200/0*4_9RIUaTNPCxSWZF'],,"{'@type': 'Person', 'name': 'Akira Olsen, PsyD', 'url': 'https://medium.datadriveninvestor.com/@akiraolsen'}","['Akira Olsen, PsyD']","{'@type': 'Organization', 'name': 'DataDrivenInvestor', 'url': 'medium.datadriveninvestor.com', 'logo': {'@type': 'ImageObject', 'width': 308, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:616/1*OMF3fSqH8t4xBJ9-6oZDZw.png'}}",2018-12-30T06:40:02.520Z,2018-12-30T06:40:02.520Z,2021-12-07T04:14:50.528Z,,,"New Trauma Therapy using storytelling, music, artificial intelligence (AI) and virtual reality (VR)Akira Olsen, PsyD·FollowPublished inDataDrivenInvestor·9 min read·Dec 30, 20189.2K7ListenSharePhoto by Nick Herasimenka on UnsplashOne very sad but true thing is — there is a lot of suffering in this world. Take a look around, there are different horrible things happening everywhere. From seemingly endless civil wars in the middle east to the economic crisis in some European and African countries. There is not a single person in this world who has never had any sad or embarrassing experience (except you are a 1-year-old). At times these terrible experiences can leave serious scars on us. According to the American Psychological Association, trauma is an emotional response to a terrible event such as rape, accident, or natural disaster. Here are some stats about traumatic experiences — about 30% of military men who have seen war will have PTSD. 15–25% of women have been sexually abused as children or teenagers. About 11% of children are being abused emotionally. One-third of women and one-fourth of men in America are experiencing physical violence from their spouses. In fact, if you are a survivor of the recent wildfire in California or the hurricane in some parts of America, and it still affects you deeply, then by definition, you may have been traumatized by the event. If you are still trying to know how trauma feels like, you can try to remember the worst thing that ever happened to you. A breakup, divorce, or the death of a loved one? That’s how trauma looks like. Now, try to double the way you feel anytime you think about that. That is how serious trauma looks like. The fact is many more people than you probably think have been traumatized in one way or another. There is a saying that goes like this — “a problem shared is half-solved”. We are going to talk about how storytelling otherwise known as narrative exposure therapy can help traumatized people heal. We are going to talk about narrative therapy, how it works, and its different types. Then we will talk about how artificial intelligence and virtual intelligence can help you incorporate music and other elements to your narrative therapy.What is narrative exposure therapy and how does it work?Actually, a better question would be — “how does your memory work?” The reason you should know this is that in order to understand narrative exposure therapy better, you would have to learn a bit about how memories work. Memories are not a fixed thing. Have you noticed that for you to remember something permanently, you have to think about it over and over again? The brain stores up the past memories in a type of archive folder in the brain. It also tries to associate the memory it wants to archive with other memory folders. This is an attempt to make it easily accessible. It’s just like archiving a folder you think may be useful later on but is not needed at the moment. If you want to archive a file, you can either:a) Toss it somewhere you usually toss all the stuff you don’t need orb) Try to arrange it alphabetically or with an orderly reference system that will make it easier for you to retrieve later.If you chose option a — well, good luck retrieving your file when you need it if you have about a hundred thousand different files in your basket. However, option b makes it easier to retrieve your files. Luckily for us, our brain not only tries to archive our memories like option b but does even better — our brain also tries to associate our memories with each other. Anytime you remember something, your brain makes stronger connection neurons in order to strengthen the memories. In other words, the more you think about an experience the stronger your memory of it and the stronger the emotions and physical reactions you experience anytime you think about it. Now, before we begin to talk about narrative exposure therapy, we need to understand one more thing — how does trauma work?Remember, the definition of trauma by the American Psychological Association as an emotional response to disturbing events like rape, accidents, or natural disaster? The question is, how does your brain create the disturbing emotional response we see in trauma? It has something to do with your memories. There are three aspects of memory. The first is the cognitive aspect which has to do with your ability to think and reason — your ability to frame what happened to you in a logical and analytical manner. In traumatized people, memories can be a jumbled mess of scary pictures scenes, and images. Second is the emotional aspect which has to do with the way you feel when you think about your experience (fear, anguish, pain, etc..). Traumatized people cannot completely detach themselves from their traumatic memories so may still have fresh emotions when they remember them. The third is the somatic aspect which is the way your body reacts to your feelings like trembling, sweating, agitation, and so on. When you experience a traumatic event, you keep on reliving the moment because the trauma affects parts of your brain like the forebrain (controls cognitive), limbic system (controls emotional), and hindbrain (controls somatic) which help archive your memories. What this means is that either all or part of the memory is not properly archived into the long-term memory storage. Trauma disrupts the cognitive, somatic, and emotional aspects of your memory. This means that anytime you remember such an event, it is as if it is literally happening to you. You can feel the trauma physically, emotionally and you even react to it. You may be trembling, having rapid palpitations, sweating, and so on when you think about the event that left you traumatized — like a sexual assault for example. Trauma is a way of your body trying to adapt to the terrible situation so it can protect you from future experiences. However, the problem is, a traumatized person adapts in a way that does more harm than good. That is why it is called “maladaptation”. Narrative exposure therapy tries to connect the dots of the cognitive, emotional, and somatic aspects of your memory so that your brain can archive it. Once, your brain archives it, it will only remain a memory and nothing more. In other words, you become separated from your problem.A straight-to-the-point discussion on narrative exposure therapy and how it works:Now that we have an understanding of what memory and trauma are, let us talk about what narrative exposure therapy is. It was invented by Michael White and David Epston in 1990. It is meant to separate traumatized people from their problems. It involves telling your own story. Getting a traumatized person to tell their story may bring back or even worsen the trauma. This is why it’s best if experts handle this. Narrative exposure therapy is not just about telling your story but trying to make sense of your emotional, reasoning (cognitive), and body reactions (somatic) to your traumatic experience. It’s important to practice mindfulness when you are telling your story as mindfulness helps you dissociate from your problems. You can read more on mindfulness in our article about it. Narrative therapy aims to change the effect your traumatic experience has on you. It aims to help you detach yourself from the traumatic experience. Trauma is sustained when the cognitive, emotional and somatic aspects of your memory are incongruent. As a therapist using narrative therapy, your job is to help your clients find their voice. They should be able to tell a story in their own words to help them find healing, meaning and re-establish their own identity. In narrative exposure therapy, you are not just telling a story which deals only with the cognitive part of the memory, but you are also trying to make sense of how you feel (your emotions) when you remember the event and why you act a certain way when you feel that way (your somatic responses). Making sense of these using mindfulness techniques can help you get over your trauma and understand yourself much better. Narrative therapy starts with a more superficial general story of yourself, then you gradually begin to go deeper into your traumatic experience exploring all the aspects of your memory till you can make sense of what happened to you and you can detach yourself from your problems. You can then tell your story in an alternative but a more positive, helpful and self-compassionate way that helps reinforce positive feelings and reactions. This technique is also called “re-storying” or “re-authoring”. Hence, it doesn’t hurt you as much when you think about it. So, let’s talk about where virtual reality and artificial intelligence come in.How artificial intelligence (AI) and virtual reality (VR) can make narrative therapy more effective:AI and VR are making huge waves in many industries today. They have great potentials in different areas like gaming, healthcare, education, defense, and even the adult industry. VR and AI are incredible tools to enhance your storytelling. The better your ability to tell your story, from the cognitive, emotional, and somatic aspects, the greater your chances of treating trauma. What’s more is that adolescents find using AI and VR fun. VR can bring your story to life. Life-like animations of your stories can be projected. What’s more is that it does not feel as threatening as a real-life exposure therapy because you know it is not real although it is realistic. The immersive form of VR can feel real because it is almost as if you are there. It can help make your thinking more logical, and with the guidance of the therapist, you can have more control over your somatic and emotional responses to your memories. AI can take your experience to the next level. Currently, AI exists that can simplify the animation of characters in VR. This means you can act out your story without the headaches of animation. All you have to do is to wear some sensors that allow the AI to detect your movements and animate the character of your choice. This is something like controlling a game character with your body. Also, there are AIs like AIVA which can compose music of your choice. It has scored about 30,000 compositions and mastered them much like a music student. It can take from these compositions and make new music tracks. It also understands several music genres and can compose soundtracks in different genres. That’s much like the same way humans learn and compose music, just a million times faster. With AI combined with VR, you can make a complete film of your own story with soundtracks and maybe songs if you wish.Music plays a vital role in emotions and reactions. More so, it is fun for millennials and Gen Z as they enjoy having their own type of music and watching videos. AI and VR make storytelling more immersive for teenagers as they get to watch a video of their own story, framed in their own words. Narrative therapy with AI and VR strengthens the cognitive, emotional, and somatic aspects of memory. When the brain can make sense of all these aspects of the memory of an event and bring them together logically, then it becomes easy for the brain to archive the memory. Hence, it is easier to drop the traumatic experience and move on.ReferencesAmerican Psychological Organisation. (n.d.). Retrieved from https://www.apa.org/ptsd-guideline/treatments/narrative-exposure-therapy.aspxClaudia M. Fletcher, G. B. (2018). More to the Story: Synthesizing Narrative Therapy with the Adaptive Information Processing Model. Journal of Counselor Practice, 9(2), 53–76. doi:DOI: 10.22229/ cmf902110Good therapy. (n.d.). Retrieved from https://www.goodtherapy.org/learn-about-therapy/types/narrative-therapyMark B. Powers, P. M. (2008). Virtual reality exposure therapy for anxiety disorders: A meta-analysis. Journal of Anxiety Disorders, 561–569. doi:doi:10.1016/j.janxdis.2007.04.006Shilling, A. (2017). Clinical Virtual Reality tools to advance the prevention, assessment, and treatment of PTSD. Eur J Psychotraumatol. doi: doi: 10.1080/20008198.2017.1414560White, M. & Epston, D. (1990). Narrative Means to Therapeutic Ends. W. W. Norton & Company; 1 edition.youtube. (n.d.). artificial intelligence and music. Retrieved from https://www.youtube.com/watch?v=wYb3Wimn01syoutube. (n.d.). storytelling through songs. Retrieved from https://www.youtube.com/watch?v=U0mPOkyKPJQ",,,"New Trauma Therapy using storytelling, music, artificial intelligence (AI) and virtual reality (VR)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3970bf361937,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vd3d3LmphbWFpY2FvYnNlcnZlci5jb20vMjAxOC8xMi8zMC8yMDE5LWFuZC1iZXlvbmQtd2hhdC10by1leHBlY3QtZnJvbS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,2019 and beyond...what to expect from artificial intelligence - Jamaica Observer,2018-12-30,Jamaica Observer,https://www.jamaicaobserver.com,"“We stand on the brink of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. In its scale, scope, and complexity, the transformation will b...",,"“We stand on the brink of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. In its scale, scope, and...","“We stand on the brink of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. In its scale, scope, and...",http://schema.org,,BreadcrumbList,2019 and beyond&#8230;what to expect from artificial intelligence,https://www.jamaicaobserver.com/,"{'@type': 'WebPage', '@id': 'https://www.jamaicaobserver.com/2018/12/30/2019-and-beyond-what-to-expect-from-artificial-intelligence/'}",,https://www.jamaicaobserver.com/jamaicaobserver/news/wp-content/uploads/sites/4/2018/12/3da76d85ff4d897557196596ae68539d.jpg,['News'],"[{'@type': 'Person', 'name': 'BY SHARLENE HENDRICKS Staff reporter hendrickss@jamaicaobserver.com', 'url': 'https://www.jamaicaobserver.com/author/by-sharlene-hendricks-staff-reporter-hendrickssjamaicaobserver-com/'}]",,,,2018-12-30T00:00:00-05:00,2018-12-30T00:00:00-05:00,,,"NewsCourt rules school breached constitutional rights of dreadlocks student, PNP applauds ruling","[{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://www.jamaicaobserver.com/category/news/'}]",,Jamaica Observer,,"{'@type': 'ImageObject', 'url': 'https://www.jamaicaobserver.com/jamaicaobserver/news/wp-content/uploads/sites/4/2023/09/jol_color_logo.png', 'width': '1000', 'height': '320'}","['https://www.facebook.com/jamaicaobserver', 'https://twitter.com/jamaicaobserver', 'https://www.instagram.com/jamaicaobserver/']","{'@type': 'PostalAddress', 'streetAddress': 'Kingston 40-42 1/2 Beechwood Avenue', 'addressLocality': 'Kingston', 'postalCode': '5', 'addressCountry': 'JM'}",,,,,,,"[{'@type': 'ContactPoint', 'contactType': 'Public Engagement', 'url': 'https://www.jamaicaobserver.com/contact-us/'}]",True,,,,,,,,,,,,,,,,,,,,https://www.jamaicaobserver.com/privacy-policy/,,,,876-926-7655,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LmlyaXNodGltZXMuY29tL2J1c2luZXNzL3RlY2hub2xvZ3kvY29uY2VybnMtb3Zlci1odWdlLWdlbmRlci1nYXAtaW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utd29ya2ZvcmNlLTEuMzc0MDkwMNIBAA?oc=5,Concerns over huge gender gap in artificial intelligence workforce - The Irish Times,2018-12-24,The Irish Times,https://www.irishtimes.com,New World Economic Forum study shows women account for just 22% of AI workforce,"linkedin,saadia-zahidi",New World Economic Forum study shows women account for just 22% of AI workforce,New World Economic Forum study shows women account for just 22% of AI workforce,https://schema.org,,NewsArticle,Concerns over huge gender gap in artificial intelligence workforce,https://www.irishtimes.com/business/technology/concerns-over-huge-gender-gap-in-artificial-intelligence-workforce-1.3740900,"{'@type': 'WebPage', '@id': 'https://schema.org/WebPage', 'url': 'https://www.irishtimes.com/business/technology/concerns-over-huge-gender-gap-in-artificial-intelligence-workforce-1.3740900'}",,"['https://www.irishtimes.com/resizer/v2/IOQFHUPOPYI2KTOAXYLD72VETQ.jpg?auth=988238e5e9641c687f6d4097d0258faa0ddc601b9e213eec4fd74388c2376021&smart=true&width=1600&height=900', 'https://www.irishtimes.com/resizer/v2/IOQFHUPOPYI2KTOAXYLD72VETQ.jpg?auth=988238e5e9641c687f6d4097d0258faa0ddc601b9e213eec4fd74388c2376021&smart=true&width=1600&height=1200', 'https://www.irishtimes.com/resizer/v2/IOQFHUPOPYI2KTOAXYLD72VETQ.jpg?auth=988238e5e9641c687f6d4097d0258faa0ddc601b9e213eec4fd74388c2376021&smart=true&width=1600&height=1600']",Technology,"[{'@type': 'Person', 'name': 'Charlie Taylor', 'url': 'https://www.irishtimes.com/author/charlie-taylor', 'sameAs': 'https://www.irishtimes.com/author/charlie-taylor'}]",,"{'@type': 'Organization', 'name': 'The Irish Times', 'url': 'https://www.irishtimes.com', 'logo': {'@type': 'ImageObject', 'url': '', 'width': 600, 'height': 60}}",,2018-12-24T02:15:00Z,2018-12-24T02:15:00Z,,,"Men are much more likely to work in the area of artificial intelligence (AI) than women, according to a new report which finds the gender talent gap in the sector is three times larger than in other industries.Research carried out by the World Economic Forum in collaboration with LinkedIn shows women account for just 22 per cent of the AI workforce. This, the forum warned, has huge implications for society as a whole as automation increases.“In an era when human skills are increasingly important and complementary to technology, the world cannot afford to deprive itself of women’s talent in sectors in which talent is already scarce,” it said.OutnumberedIn addition to being outnumbered three to one, the research found that women working in AI are less likely to be positioned in senior roles. The data indicates that women with AI skills tend to be employed in areas such as data analytics, research, information management and teaching, whereas men tend to work in more lucrative and senior positions including as software engineers, heads of engineering or IT, or as chief executives.READ MOREThe Christmas Tech quiz: Test your knowledgeSounds yummy: Heston Blumenthal serves up aural treats in ‘Pod & Chips’Keyword Studios predicts full-year pretax profits of about €37mNo-deal Brexit: New legal structures needed for data transfers across BorderThe forum said given the depth of the problem there is a clear need for proactive measures to prevent a deepening of the gender gap in other industries where AI skills are becoming in demand. These include traditionally male-dominated industries such as manufacturing, hardware and networking as well as software and IT services, as well as traditionally female sectors such as non-profits, healthcare and education.The forum said its findings indicate the need for urgent action with concerns that gender bias could enter the coding process, leading to real-world implications.Reskilling""Industries must proactively hardwire gender parity in the future of work through effective training, reskilling and upskilling interventions and tangible job transition pathways, which will be key to narrowing these emerging gender gaps and reversing the trends we are seeing today. It's in their long-term interest because diverse businesses perform better,"" said Saadia Zahidi, head of the centre for the new economy and society and Member of the Managing Board, World Economic Forum.",,,The Irish Times,,"{'@type': 'ImageObject', 'url': '', 'width': 1024, 'height': 547}","['https://www.facebook.com/irishtimes/', 'http://www.linkedin.com/company/the-irish-times', 'https://www.youtube.com/user/IrishTimes', 'https://twitter.com/IrishTimes']","{'@type': 'PostalAddress', 'postOfficeBoxNumber': 'PO Box 74', 'streetAddress': '24-28 Tara Street', 'addressLocality': 'Dublin 2', 'addressRegion': 'County Dublin', 'addressCountry': 'Ireland', 'postalCode': 'D02 CX89'}",,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.paywall'}",,"[{'@type': 'ContactPoint', 'contactType': 'Customer Support', 'email': 'services@irishtimes.com', 'telephone': '+353 1 9203901'}, {'@type': 'ContactPoint', 'contactType': 'Sales', 'email': 'mediasolutions@irishtimes.com', 'telephone': '+353 1 5320978'}, {'@type': 'ContactPoint', 'contactType': 'News Desk', 'email': 'newsdesk@irishtimes.com', 'telephone': ''}]",False,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vY2Vwci5vcmcvdm94ZXUvY29sdW1ucy9ob3ctZnV0dXJlLXdvcmstbWF5LXVuZm9sZC1jb3Jwb3JhdGUtZGVtYW5kLXNpZGUtcGVyc3BlY3RpdmXSAQA?oc=5,How the future of work may unfold: A corporate demand-side perspective - CEPR,2018-12-23,CEPR,https://cepr.org,"Advances in artificial intelligence have led to fears of job losses. This column uses a global survey covering more than 3,000 executives across 14 sectors and ten countries to examine the impact of AI on the demand side of the labour market. Ultimately, the effect on employment will depend on whether companies choose to use current forms of AI for innovation or pure automation, and whether they foresee a return from it.",,"Advances in artificial intelligence have led to fears of job losses. This column uses a global survey covering more than 3,000 executives across 14 sectors and ten countries to examine the impact of AI on the demand side of the labour market. Ultimately, the effect on employment will depend on whether companies choose to use current forms of AI for innovation or pure automation, and whether they foresee a return from it.","Advances in artificial intelligence have led to fears of job losses. This column uses a global survey covering more than 3,000 executives across 14 sectors and ten countries to examine the impact of AI on the demand side of the labour market. Ultimately, the effect on employment will depend on whether companies choose to use current forms of AI for innovation or pure automation, and whether they foresee a return from it.",,,,,,,,,,,,,,,,,,"




















VoxEU Column

        Labour Markets
          

        Productivity and Innovation
          

How the future of work may unfold: A corporate demand-side perspective



Jacques R.J. Bughin


/ 


23 Dec 2018

  Advances in artificial intelligence have led to fears of job losses. This column uses a global survey covering more than 3,000 executives across 14 sectors and ten countries to examine the impact of AI on the demand side of the labour market. Ultimately, the effect on employment will depend on whether companies choose to use current forms of AI for innovation or pure automation, and whether they foresee a return from it.






Share






Twitter







Facebook







LinkedIn





Authors




















 Jacques R.J. Bughin


Senior partner, Director, McKinsey Global Institute
McKinsey & Company 





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMif2h0dHBzOi8vd3d3Lm9wZW5jdWx0dXJlLmNvbS8yMDE4LzEyL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNyZWF0ZXMtcmVhbGlzdGljLXBob3Rvcy1vZi1wZW9wbGUtbm9uZS1vZi13aG9tLWFjdHVhbGx5LWV4aXN0Lmh0bWzSAQA?oc=5,"Artificial Intelligence Creates Realistic Photos of People, None of Whom Actually Exist - Open Culture",2018-12-24,Open Culture,https://www.openculture.com,"Each day in the 2010s, it seems, brings another startling development in the field of artificial intelligence — a field widely written off not all that long ago as a dead end. Open Culture, openculture.com",,"Each day in the 2010s, it seems, brings another startling development in the field of artificial intelligence — a field widely written off not all that long ago as a dead end.",,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html#article', 'isPartOf': {'@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html'}, 'author': {'name': 'Colin Marshall', '@id': 'https://www.openculture.com/#/schema/person/6876a344072c1e9dd894f4044f353ccf'}, 'headline': 'Artificial Intelligence Creates Realistic Photos of People, None of Whom Actually Exist', 'datePublished': '2018-12-24T18:00:28+00:00', 'dateModified': '2018-12-24T19:55:22+00:00', 'mainEntityOfPage': {'@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html'}, 'wordCount': 636, 'commentCount': 5, 'publisher': {'@id': 'https://www.openculture.com/#organization'}, 'image': {'@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html#primaryimage'}, 'thumbnailUrl': 'https://www.openculture.com/wp-content/uploads/2018/12/AI-Face-1-e15456263742702.png', 'articleSection': ['Photography', 'Technology'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html', 'url': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html', 'name': 'Artificial Intelligence Creates Realistic Photos of People, None of Whom Actually Exist', 'isPartOf': {'@id': 'https://www.openculture.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html#primaryimage'}, 'image': {'@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html#primaryimage'}, 'thumbnailUrl': 'https://www.openculture.com/wp-content/uploads/2018/12/AI-Face-1-e15456263742702.png', 'datePublished': '2018-12-24T18:00:28+00:00', 'dateModified': '2018-12-24T19:55:22+00:00', 'breadcrumb': {'@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html#primaryimage', 'url': 'https://cdn8.openculture.com/2018/12/23205526/AI-Face-1-e15456263742702.png', 'contentUrl': 'https://cdn8.openculture.com/2018/12/23205526/AI-Face-1-e15456263742702.png', 'width': 900, 'height': 451}, {'@type': 'BreadcrumbList', '@id': 'https://www.openculture.com/2018/12/artificial-intelligence-creates-realistic-photos-of-people-none-of-whom-actually-exist.html#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.openculture.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence Creates Realistic Photos of People, None of Whom Actually Exist'}]}, {'@type': 'WebSite', '@id': 'https://www.openculture.com/#website', 'url': 'https://www.openculture.com/', 'name': 'Open Culture', 'description': 'The best free cultural &amp; educational media on the web', 'publisher': {'@id': 'https://www.openculture.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.openculture.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.openculture.com/#organization', 'name': 'Openculture.com', 'url': 'https://www.openculture.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.openculture.com/#/schema/logo/image/', 'url': 'https://cdn8.openculture.com/2021/04/24113050/OC-favicon.png', 'contentUrl': 'https://cdn8.openculture.com/2021/04/24113050/OC-favicon.png', 'width': 400, 'height': 400, 'caption': 'Openculture.com'}, 'image': {'@id': 'https://www.openculture.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.openculture.com/#/schema/person/6876a344072c1e9dd894f4044f353ccf', 'name': 'Colin Marshall', 'sameAs': ['http://blog.colinmarshall.org/?page_id=2', 'https://x.com/colinmarshall'], 'url': 'https://www.openculture.com/author/cjmarshall'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMTIvMjYvc2NpZW5jZS9jaGVzcy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS5odG1s0gEA?oc=5,One Giant Step for a Chess-Playing Machine (Published 2018) - The New York Times,2018-12-26,The New York Times,https://www.nytimes.com,"The stunning success of AlphaZero, a deep-learning algorithm, heralds a new age of insight — one that, for humans, may not last long.",,"The stunning success of AlphaZero, a deep-learning algorithm, heralds a new age of insight — one that, for humans, may not last long.","The stunning success of AlphaZero, a deep-learning algorithm, heralds a new age of insight — one that, for humans, may not last long.",https://schema.org,,NewsMediaOrganization,One Giant Step for a Chess-Playing Machine,https://www.nytimes.com/,https://www.nytimes.com/2018/12/26/science/chess-artificial-intelligence.html,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/01/08/science/00DEEPCHESS1/00DEEPCHESS1-videoSixteenByNineJumbo1600-v2.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2019/01/08/science/00DEEPCHESS1/00DEEPCHESS1-videoSixteenByNineJumbo1600-v2.jpg', 'caption': 'Televisions broadcasting the Google DeepMind Challenge Match between Google&rsquo;s artificial intelligence program, AlphaGo, a predecessor of AlphaZero, and South Korean professional Go player, Lee Sedol, in an electronics store in Seoul in 2016. The computer won the match.', 'creditText': 'Ahn Young-joon/Associated Press'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/01/08/science/00DEEPCHESS1/00DEEPCHESS1-superJumbo-v2.jpg', 'height': 1227, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2019/01/08/science/00DEEPCHESS1/00DEEPCHESS1-superJumbo-v2.jpg', 'caption': 'Televisions broadcasting the Google DeepMind Challenge Match between Google&rsquo;s artificial intelligence program, AlphaGo, a predecessor of AlphaZero, and South Korean professional Go player, Lee Sedol, in an electronics store in Seoul in 2016. The computer won the match.', 'creditText': 'Ahn Young-joon/Associated Press'}]",,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': '', 'name': 'Steven Strogatz'}]",,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,2018-12-26T15:40:17.000Z,2019-01-02T17:08:32.000Z,Science,,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTEssayOne Giant Step for a Chess-Playing MachineThe stunning success of AlphaZero, a deep-learning algorithm, heralds a new age of insight — one that, for humans, may not last long.Share full article356Read in appTelevisions broadcasting the Google DeepMind Challenge Match between Google’s artificial intelligence program, AlphaGo, a predecessor of AlphaZero, and South Korean professional Go player, Lee Sedol, in an electronics store in Seoul in 2016. The computer won the match.Credit...Ahn Young-joon/Associated PressBy Steven StrogatzDec. 26, 2018In early December, researchers at DeepMind, the artificial-intelligence company owned by Google’s parent corporation, Alphabet Inc., filed a dispatch from the frontiers of chess.A year earlier, on Dec. 5, 2017, the team had stunned the chess world with its announcement of AlphaZero, a machine-learning algorithm that had mastered not only chess but shogi, or Japanese chess, and Go. The algorithm started with no knowledge of the games beyond their basic rules. It then played against itself millions of times and learned from its mistakes. In a matter of hours, the algorithm became the best player, human or computer, the world has ever seen.The details of AlphaZero’s achievements and inner workings have now been formally peer-reviewed and published in the journal Science this month. The new paper addresses several serious criticisms of the original claim. (Among other things, it was hard to tell whether AlphaZero was playing its chosen opponent, a computational beast named Stockfish, with total fairness.) Consider those concerns dispelled. AlphaZero has not grown stronger in the past twelve months, but the evidence of its superiority has. It clearly displays a breed of intellect that humans have not seen before, and that we will be mulling over for a long time to come.Subscribe to The Times to read as many articles as you like.A version of this article appears in print on Jan. 8, 2019, Section D, Page 1 of the New York edition with the headline: One Giant Step for a Chess-Playing Machine. Order Reprints | Today’s Paper | SubscribeSee more on: Garry KasparovRead 356 CommentsShare full article356Read in appAdvertisementSKIP ADVERTISEMENTComments 356One Giant Step for a Chess-Playing MachineSkip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.",,,The New York Times,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",,,False,,,,,https://www.nytimes.com/#publisher,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",One Giant Step for a Chess-Playing Machine,,,,,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,,,{'@id': '#commentsContainer'},356.0,,
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vd3d3LndlYnByb25ld3MuY29tL3JhbmQtaGluZGktaHVtYW4tbGlrZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,Rand Hindi: Human-Like Artificial Intelligence is Never Going to Exist - WebProNews,2018-12-26,WebProNews,https://www.webpronews.com,Keywords,,"Dr. Rand Hindi says that without emotional intelligence machines will never be able to obtain human-like artificial intelligence. Reminiscent of Star Trek Next Generation, Hindi says that most decisions humans make are actually emotionally driven and machines don’t have an emotional IQ.",,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/#article', 'isPartOf': {'@id': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/'}, 'author': {'name': 'Rich Ord', '@id': 'https://www.webpronews.com/#/schema/person/5ecd76a178ca453e4cd59d815751cf9a'}, 'headline': 'Rand Hindi: Human-Like Artificial Intelligence is Never Going to Exist', 'datePublished': '2018-12-26T05:01:36+00:00', 'dateModified': '2020-10-16T13:19:38+00:00', 'mainEntityOfPage': {'@id': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/'}, 'wordCount': 1413, 'publisher': {'@id': 'https://www.webpronews.com/#organization'}, 'image': {'@id': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://i0.wp.com/www.webpronews.com/wp-content/uploads/2018/12/Screen-Shot-2018-12-20-at-2.09.37-AM.png?fit=864%2C493&ssl=1', 'keywords': ['AI', 'Artificial Intelligence', 'Deep Learning', 'Dr. Rand Hindi', 'LinkedIn', 'Machine Learning', 'Snips'], 'articleSection': ['AITrends', 'EmergechTechUpdate', 'HealthRevolution', 'MarketingAI', 'RobotRevolutionPro'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/', 'url': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/', 'name': 'Rand Hindi: Human-Like Artificial Intelligence is Never Going to Exist', 'isPartOf': {'@id': 'https://www.webpronews.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://i0.wp.com/www.webpronews.com/wp-content/uploads/2018/12/Screen-Shot-2018-12-20-at-2.09.37-AM.png?fit=864%2C493&ssl=1', 'datePublished': '2018-12-26T05:01:36+00:00', 'dateModified': '2020-10-16T13:19:38+00:00', 'description': 'Dr. Rand Hindi says that without emotional intelligence machines will never be able to obtain human-like artificial intelligence. Reminiscent of Star Trek Next Generation, Hindi says that most decisions humans make are actually emotionally driven and machines don’t have an emotional IQ.', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.webpronews.com/rand-hindi-human-like-artificial-intelligence/#primaryimage', 'url': 'https://i0.wp.com/www.webpronews.com/wp-content/uploads/2018/12/Screen-Shot-2018-12-20-at-2.09.37-AM.png?fit=864%2C493&ssl=1', 'contentUrl': 'https://i0.wp.com/www.webpronews.com/wp-content/uploads/2018/12/Screen-Shot-2018-12-20-at-2.09.37-AM.png?fit=864%2C493&ssl=1', 'width': 864, 'height': 493}, {'@type': 'WebSite', '@id': 'https://www.webpronews.com/#website', 'url': 'https://www.webpronews.com/', 'name': 'WebProNews', 'description': 'Breaking News in Tech, Search, Social, &amp; Business', 'publisher': {'@id': 'https://www.webpronews.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.webpronews.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.webpronews.com/#organization', 'name': 'WebProNews', 'url': 'https://www.webpronews.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.webpronews.com/#/schema/logo/image/', 'url': 'https://i0.wp.com/www.webpronews.com/wp-content/uploads/2023/07/newlogotest.png?fit=129%2C45&ssl=1', 'contentUrl': 'https://i0.wp.com/www.webpronews.com/wp-content/uploads/2023/07/newlogotest.png?fit=129%2C45&ssl=1', 'width': 129, 'height': 45, 'caption': 'WebProNews'}, 'image': {'@id': 'https://www.webpronews.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/WebProNews/', 'https://x.com/webpronews', 'https://www.linkedin.com/company/webpronews']}, {'@type': 'Person', '@id': 'https://www.webpronews.com/#/schema/person/5ecd76a178ca453e4cd59d815751cf9a', 'name': 'Rich Ord', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.webpronews.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/51854dd50ecdaf41376c741a5f198e92?s=96&d=mm&r=pg', 'contentUrl': 'https://secure.gravatar.com/avatar/51854dd50ecdaf41376c741a5f198e92?s=96&d=mm&r=pg', 'caption': 'Rich Ord'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiS2h0dHBzOi8vd3d3LmRhdGFzY2llbmNlY2VudHJhbC5jb20vdGhlLXRydXRoLWFib3V0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,The Truth about Artificial Intelligence - DataScienceCentral.com - Data Science Central,2018-12-26,Data Science Central,https://www.datasciencecentral.com,,,"How will AI evolve and what major innovations are on the horizon? What will its impact be on the job market, economy, and society? What is the path toward human-level machine intelligence? What should we be concerned about as artificial intelligence advances? The Architects of Intelligence contains a series of in-depth, one-to-one interviews where New… Read More »The Truth about Artificial Intelligence",,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/#article', 'isPartOf': {'@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/'}, 'author': {'name': 'PacktPublishing', '@id': 'https://www.datasciencecentral.com/#/schema/person/31d09d10898964ff709b46b867b87ad4'}, 'headline': 'The Truth about Artificial Intelligence', 'datePublished': '2018-12-26T20:43:00+00:00', 'dateModified': '2018-12-26T20:43:00+00:00', 'mainEntityOfPage': {'@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/'}, 'wordCount': 266, 'commentCount': 0, 'publisher': {'@id': 'https://www.datasciencecentral.com/#organization'}, 'image': {'@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.datasciencecentral.com/wp-content/uploads/2021/10/524959158.png', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/', 'url': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/', 'name': 'The Truth about Artificial Intelligence - DataScienceCentral.com', 'isPartOf': {'@id': 'https://www.datasciencecentral.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.datasciencecentral.com/wp-content/uploads/2021/10/524959158.png', 'datePublished': '2018-12-26T20:43:00+00:00', 'dateModified': '2018-12-26T20:43:00+00:00', 'breadcrumb': {'@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/#primaryimage', 'url': 'https://www.datasciencecentral.com/wp-content/uploads/2021/10/524959158.png', 'contentUrl': 'https://www.datasciencecentral.com/wp-content/uploads/2021/10/524959158.png', 'width': 302, 'height': 373}, {'@type': 'BreadcrumbList', '@id': 'https://www.datasciencecentral.com/the-truth-about-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.datasciencecentral.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Uncategorized'}]}, {'@type': 'WebSite', '@id': 'https://www.datasciencecentral.com/#website', 'url': 'https://www.datasciencecentral.com/', 'name': 'Data Science Central', 'description': 'A COMMUNITY FOR AI PRACTITIONERS', 'publisher': {'@id': 'https://www.datasciencecentral.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.datasciencecentral.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.datasciencecentral.com/#organization', 'name': 'TechTarget', 'url': 'https://www.datasciencecentral.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datasciencecentral.com/#/schema/logo/image/', 'url': 'https://www.datasciencecentral.com/wp-content/uploads/2021/10/cropped-cropped-TT-Data-Science-Center-logo-2.png', 'contentUrl': 'https://www.datasciencecentral.com/wp-content/uploads/2021/10/cropped-cropped-TT-Data-Science-Center-logo-2.png', 'width': 500, 'height': 64, 'caption': 'TechTarget'}, 'image': {'@id': 'https://www.datasciencecentral.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.datasciencecentral.com/#/schema/person/31d09d10898964ff709b46b867b87ad4', 'name': 'PacktPublishing', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datasciencecentral.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/033ae6b675bc2c3b89df37b2bc439a65?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/033ae6b675bc2c3b89df37b2bc439a65?s=96&d=mm&r=g', 'caption': 'PacktPublishing'}, 'url': 'https://www.datasciencecentral.com/author/packtpublishing/'}]",,,,,,,,,,,,,,,,"
Home » UncategorizedThe Truth about Artificial Intelligence PacktPublishingDecember 26, 2018 at 4:43 pm
How will AI evolve and what major innovations are on the horizon? What will its impact be on the job market, economy, and society? What is the path toward human-level machine intelligence? What should we be concerned about as artificial intelligence advances?

The Architects of Intelligence contains a series of in-depth, one-to-one interviews where New York Times bestselling author, Martin Ford, looks for the truth about AI and what we need to know and prepare for with the coming impact of AI on our lives.
Martin explores our future by meeting with twenty-three of the most important people in artificial intelligence today, including ‘the Godfather of AI’, Geoffrey Hinton, and Andrew Ng, founder of Google Brain, to find out the truth from the hype, and how we need to prepare for AI.
What You Will Learn:

The state of modern AI
How AI will evolve and the breakthroughs we can expect
Insights into the minds of AI founders and leaders
How and when we will achieve human-level AI
The impact and risks associated with AI and its impact on society and the economy

About the Author
Martin Ford is a futurist and the author of two books: The New York Times Bestselling Rise of the Robots: Technology and the Threat of a Jobless Future (winner of the 2015 Financial Times/McKinsey Business Book of the Year Award and translated into more than 20 languages) and The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future, as well as the founder of a Silicon Valley-based software development firm. 
Book Preview

Tags:Uncategorized  previousWhy You Should be a Data Science Generalist – and How to Become Onenext30 Things I learned Organizing South East Asia's Largest Datathon


Leave a Reply Cancel replyYour email address will not be published. Required fields are marked *Name * 
Email * 
Website 
Comment *  Save my name, email, and website in this browser for the next time I comment.
 

Δ 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vbXl0ZWNoZGVjaXNpb25zLmNvbS9pdC1pbmZyYXN0cnVjdHVyZS9nb29nbGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utb2JqZWN0LXBsYWNpbmcv0gEA?oc=5,Google Artificial Intelligence Power Demonstrated in Object-Placing - TechDecisions,2018-12-24,TechDecisions,https://mytechdecisions.com,,"['artificial intelligence', 'augmented reality', 'virtual reality']","Due to advancements in object-placing technology, artificial intelligence designers might find the design process flowing easier and more efficiently.",,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/', 'url': 'https://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/', 'name': 'Google Artificial Intelligence Power Demonstrated in Object-Placing - My TechDecisions', 'isPartOf': {'@id': 'https://mytechdecisions.com/#website'}, 'primaryImageOfPage': {'@id': 'https://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/#primaryimage'}, 'image': {'@id': 'https://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/#primaryimage'}, 'thumbnailUrl': 'https://mytechdecisions.com/wp-content/uploads/2018/10/artificial_intelligence_robot_thinking.jpg', 'datePublished': '2018-12-24T15:00:39+00:00', 'dateModified': '2018-12-17T18:56:02+00:00', 'author': {'@id': 'https://mytechdecisions.com/#/schema/person/16158f6e98761e8d572a0feb0e36b233'}, 'breadcrumb': {'@id': 'https://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/#primaryimage', 'url': 'https://mytechdecisions.com/wp-content/uploads/2018/10/artificial_intelligence_robot_thinking.jpg', 'contentUrl': 'https://mytechdecisions.com/wp-content/uploads/2018/10/artificial_intelligence_robot_thinking.jpg', 'width': 1000, 'height': 500, 'caption': 'Artificial Intelligence Lux, ai bald head'}, {'@type': 'BreadcrumbList', '@id': 'https://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://mytechdecisions.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Google Artificial Intelligence Power Demonstrated in Object-Placing'}]}, {'@type': 'WebSite', '@id': 'https://mytechdecisions.com/#website', 'url': 'https://mytechdecisions.com/', 'name': 'My TechDecisions', 'description': 'The end user’s first and last stop for making technology decisions', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://mytechdecisions.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://mytechdecisions.com/#/schema/person/16158f6e98761e8d572a0feb0e36b233', 'name': 'TechDecisions Staff', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://mytechdecisions.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/ee26cb3657bc1e1314233506c8d246f7?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/ee26cb3657bc1e1314233506c8d246f7?s=96&d=mm&r=g', 'caption': 'TechDecisions Staff'}, 'url': 'https://mytechdecisions.com/author/techdecisions-staff/'}]",NewsArticle,Google Artificial Intelligence Power Demonstrated in Object-Placing,http://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/,"{'@type': 'WebPage', '@id': 'http://mytechdecisions.com/it-infrastructure/google-artificial-intelligence-object-placing/'}",https://mytechdecisions.com/wp-content/uploads/2018/10/artificial_intelligence_robot_thinking-150x150.jpg,"{'@type': 'ImageObject', 'url': 'https://mytechdecisions.com/wp-content/uploads/2018/10/artificial_intelligence_robot_thinking.jpg'}",IT Infrastructure,"[{'@type': 'Person', 'name': 'TechDecisions Staff'}]",['TechDecisions Staff'],"{'@type': 'Organization', 'name': 'My TechDecisions', 'logo': 'https://mytechdecisions.com/wp-content/uploads/2017/03/cropped-TD-icon1-1.png'}",2018-12-24T15:00:39Z,2018-12-24T15:00:39Z,2018-12-24T15:00:39Z,,,"



IT InfrastructureGoogle Artificial Intelligence Power Demonstrated in Object-Placing
Due to advancements in object-placing technology, artificial intelligence designers might find the design process flowing easier and more efficiently. December 24, 2018 Jessica Messier Leave a Comment  


In the world of AR, VR and video game design, designers may run into the challenge of inserting certain objects into an image and having it conform to a scene. However, due to new research by Seoul National University, the University of California at Merced, and Google AI, there’s a new system that can make designers’ jobs easier, says Venture Beat.
The new system can learn how to insert an object into an image in a “semantically coherent,” or “convincing” manner; in other words, in a scene depicting a city, pedestrians appear on the sidewalk, and cars appear on the street. The technology, Venture Beat says, can potentially serve as a powerful tool for image editing and scene parsing applications.
Here’s how it works:
The editing technology contains two modules – one determines where certain objects should be in a scene, and the other distinguishes what the objects should look like. These modules leverage two-part neural networks made of generators that produce samples and discriminators that work to determine the created images from real-world images, Venture Beat says.
“Because the system simultaneously models the distribution with respect to an inserted image, it enables both modules to communicate with and optimize each other.” Over time, the system learns different distributions for different categories put in a scene.
Related:How Deep Learning is Improving Artificial Intelligence
Based on Venture Beat’s report, it looks like this solution has been able to outperform the baseline by inserting realistic-looking objects. “When an image recognizer…was applied to images produced by the AI, it was able to detect the synthesized objects with .79 recall. More tellingly, in a survey performed with workers from Amazon’s Mechanical Turk, 43 percent thought that the AI-generated objects were real.”
As a result, decision makers in the AR, VR and video game-creation space might consider keeping an eye on this technology, as it might one day make their jobs easier and tighten their work up.
“This shows that our approach is capable of performing the object synthesis and insertion task,” the researchers from Seoul National University, the University of California at Merced and Google AI wrote in their report about the system. “As our method jointly models where and what, it could be used for solving other computer vision problems. One of the interesting future works would be handling occlusions between objects.”

If you enjoyed this article and want to receive more valuable industry content like this, click here to sign up for our digital newsletters!






Tagged With: Artificial Intelligence, Augmented Reality, Virtual RealityRelated Content: Top Three Network Concerns for Technology Decision Makers Four Questions to Guide High-Impact Enterprise AI Integrations Top AV/IT Integration Trends Shaping Enterprise Operations in…  5 Things You Need to Know About the… Free downloadable guide you may like:Practical Design Guide for Office SpacesRecent Gartner research shows that workers prefer to return to the office for in-person meetings for relevant milestones, as well as for face-to-face time with co-workers. When designing the office spaces — and meeting spaces in particular — enabling that connection between co-workers is crucial. But introducing the right collaboration technology in meeting spaces can […]Reader Interactions 
Leave a Reply Cancel replyYour email address will not be published. Required fields are marked *Comment * Name * 
Email * 
Website 
 Save my name, email, and website in this browser for the next time I comment.
 

Δ 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vaW50ZXJlc3RpbmdlbmdpbmVlcmluZy5jb20vaW5ub3ZhdGlvbi9wZXJzb25hbGl6ZWQtbGVhcm5pbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLWVkdWNhdGlvbi1pbi10aGUtZnV0dXJl0gEA?oc=5,Personalized Learning: Artificial Intelligence and Education in the Future - Interesting Engineering,2018-12-24,Interesting Engineering,https://interestingengineering.com,Artificial intelligence is transforming how we’ll learn in the future,,Artificial intelligence is transforming how we’ll learn in the future,Artificial intelligence is transforming how we’ll learn in the future,https://schema.org,"[{'@type': 'NewsArticle', '@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future#article', 'isPartOf': {'@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future'}, 'author': {'name': 'John Loeffler', '@id': 'https://interestingengineering.com/#/schema/person/7d6b26bab17bf952ad1968947d58eea0'}, 'headline': 'Personalized Learning: Artificial Intelligence and Education in the Future', 'datePublished': '2018-12-24T15:36:00+00:00', 'dateModified': '2018-12-24T15:36:00+00:00', 'mainEntityOfPage': {'@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future'}, 'wordCount': 1102, 'commentCount': 0, 'publisher': {'@id': 'https://interestingengineering.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': False, 'caption': False}, 'thumbnailUrl': 'https://images.interestingengineering.com/images/DECEMBER/Computer-Classroom.jpg', 'articleSection': ['Innovation'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://interestingengineering.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future', 'url': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future', 'name': 'Personalized Learning: Artificial Intelligence and Education in the Future', 'isPartOf': {'@id': 'https://interestingengineering.com/#website'}, 'primaryImageOfPage': {'@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future#primaryimage'}, 'image': {'@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future#primaryimage'}, 'thumbnailUrl': 'https://images.interestingengineering.com/images/DECEMBER/Computer-Classroom.jpg', 'datePublished': '2018-12-24T15:36:00+00:00', 'dateModified': '2018-12-24T15:36:00+00:00', 'description': 'Artificial intelligence is transforming how we’ll learn in the future', 'breadcrumb': {'@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future#primaryimage', 'url': 'https://images.interestingengineering.com/images/DECEMBER/Computer-Classroom.jpg', 'contentUrl': 'https://images.interestingengineering.com/images/DECEMBER/Computer-Classroom.jpg'}, {'@type': 'BreadcrumbList', '@id': 'https://interestingengineering.com/innovation/personalized-learning-artificial-intelligence-and-education-in-the-future#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://interestingengineering.com/news'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://interestingengineering.com/innovation'}, {'@type': 'ListItem', 'position': 3, 'name': 'Personalized Learning: Artificial Intelligence and Education in the Future'}]}, {'@type': 'WebSite', '@id': 'https://interestingengineering.com/#website', 'url': 'https://interestingengineering.com/', 'name': 'Interesting Engineering', 'description': '', 'publisher': {'@id': 'https://interestingengineering.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://interestingengineering.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://interestingengineering.com/#organization', 'name': 'Interesting Engineering', 'url': 'https://interestingengineering.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://interestingengineering.com/#/schema/logo/image/', 'url': 'https://cms.interestingengineering.com/wp-content/uploads/2024/02/Interesting_Engineering-1.jpg', 'contentUrl': 'https://cms.interestingengineering.com/wp-content/uploads/2024/02/Interesting_Engineering-1.jpg', 'width': 590, 'height': 198, 'caption': 'Interesting Engineering'}, 'image': {'@id': 'https://interestingengineering.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/interestingengineering/', 'https://x.com/IntEngineering', 'https://www.linkedin.com/company/interestingengineering/'], 'email': 'info@interestingengineering.com', 'numberOfEmployees': {'@type': 'QuantitativeValue', 'minValue': '201', 'maxValue': '500'}, 'publishingPrinciples': 'https://interestingengineering.com/home-page'}]",,,,,,,,,,,,,,,,"ShareInnovationPersonalized Learning: Artificial Intelligence and Education in the FutureArtificial intelligence is transforming how we’ll learn in the future
Published: Dec 24, 2018 10:36 AM ESTJohn Loeffler6 years ago0ShareMike MacKenzie/Flickr/vpnrusIt goes without saying that artificial intelligence is changing the nature of industries from transportation to finance, and education is no different with the prospect of personalized learning quickly becoming a reality. 
As more and more of a student’s education is experienced through a computer, data on their educational progress can be collected, leading to more personalized learning plans while assisting the teacher in identifying problem areas for students.  Bionic hands and laser rust removal, the best of IE this week
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
While artificial intelligence in education might appear unnerving for some, the benefits are too great to ignore.
The growth of Artificial Intelligence and Big Data in Education
Source: Pixabay
There are few spaces in life that haven’t been touched in some form by computer software. Whether it’s shopping, dating, or just keeping up with old friends, everything we do seems to be mediated in some form by computers. 
It shouldn’t surprise us then that how we educate ourselves isn’t immune. 
D2L, a leader in educational software, is the maker of Brightspace Insights, a suite of analytical tools for educators. 
Brightspace is able to capture, aggregate, and analyze data streamed from several different sources, including learning apps, online resources, publishers, and other learning management systems to build a complete model of individual student learning behaviors. 
By pulling this student data into one place, Brightspace can produce reports, predictive data analytics, and visualizations in real time that are fed into an instructor’s workflow. Over time, this can teach the teacher exactly what a student needs to succeed. 
Source: Pixabay
“With the previous version of our analytics product, instructors received information on learner success even before they took their first test. But it was only using data based on Brightspace tools,” says Nick Oddson, Senior Vice President of Product development for D2L.
“With the new Brightspace Insights, we can now deliver that same insight, but based on the entire ecosystem of learning tools.”
Until recently, the only way to measure student learning was through tests and assignments, but that only captures a small slice of a student’s education.
Over the course of a student’s educational career, they output an enormous amount of data in the form of papers, exams, and classroom participation that rarely carries over to the next term.
With these new tools, however, student data can be stored an analyzed over time to see what material they engage with more successfully and what educational deficits they may have hidden in their past work that might be inhibiting their future potential.
Personalized Learning: Teaching the Teachers
What all of this data represents is a roadmap for how a student learns. 
By having a fuller understanding of the student on day one, educators are better positioned to utilize their training and skills to address these students’ individual needs from the start, rather than spending weeks or months identifying problems that they’d then have little time to actually address.
According to D2L President John Baker, with software like Brightspace Insights, “we’ve made it easier for instructors to predict and forecast learners at risk, to help them while they’re learning, not just by flagging issues at the end of a term.”
Meanwhile, by having all of a students’ data pulled together and aggregated in advance, these learning management systems help assist the teacher in crafting personalized learning plans for students.
This system works to a student’s strengths rather than approach a classroom full of students and use one approach that works better for some while leaving others behind.
Source: Pixabay
[see-also]
This is one of the most powerful aspects of artificial intelligence in education.
 AIs and machine learning are especially good at identifying patterns that may be opaque to human eyes, so by looking at a student’s educational data, an AI can assist the teacher in identifying the ways individual students comprehend the material. 
Some students thrive by reading assigned materials, while others are inhibited by a wall of text that is more readily understood when presented in a lecture form. 
By identifying these trends in a student’s data, students can be presented material in a more accessible way that won’t leave them behind with a one size fits all approach, creating a personalized learning experience that can improve educational outcomes. 
AI, the Ultimate Teacher Assistant
Source: Pixabay
It might be tempting to think that machine learning and AI can replace classroom instructors, but that misses the essential role that artificial intelligence should play in education, and not just in developing personalized learning plans. 
Machines are dreadful when it comes to tasks requiring emotional intelligence, a skill that is essential for educating a diverse student body. 
Simply putting an AI in front of a classroom is a recipe for disaster as students eager to slough off work learn to game the AI, thereby ruining whatever advantage the AI brings to the wealth of educational data available to it.
Instead, the AI is meant to free the educator from the most time-consuming and monotonous tasks, such as grading exams and checking papers for plagiarism. 
Any teacher will tell you how this work takes up a majority of their time, time that could be better spent using their specialized training to improve the quality of their student’s educations.
By having an AI assisting the teacher, rather than replace them, AI-enhanced education can unleash the educator to fully utilize their training in ways that simply were not possible to earlier generations of educators. 
The Changing Role of the Educator
Source: Pixabay
Naturally, there is some hesitancy when it comes to bringing artificial intelligence into the classroom. 
Teachers over the past couple of decades have been on the receiving end of budget cuts and abuse, leading them to understandably become rather twitchy when someone comes into their classroom with the next big idea that looks an awful lot like a replacement.
But an AI isn’t anywhere close to being capable of doing a skilled educators job, much less outperforming them. Like other industries where artificial intelligence is making inroads and generating anxiety, this is largely a product of a misunderstanding of the underlying technology. 
Proper introduction and teaching the teachers how to harness these new tools in the classroom can go a long way to assuaging the anxieties such technology can create. 
It is vital that we begin to do so. AIs cannot and should not replace teachers, but through personalized learning programs and having AI assist the teacher by eliminating time-consuming paperwork, AIs can be a transformational and liberating innovation in education. RECOMMENDED ARTICLES




 








AI sexbots with advanced sensors could give human interaction feel








Sponsored


7 Wealth Tips Once Your Portfolio Reaches $1 Million
How do retirees take steps to preserve their wealth in retirement? Download The Seven Secrets of High Net Worth Investors now.
Fisher Investments










Scientists create world’s first ‘Vagina-on-a-Chip’ to combat bacterial diseases








Sponsored


Doctor: Sleep Apnea Treatment Without CPAP (It's Genius)
Try it tonight!
Sleep Apnea News



 







0COMMENTNEWSLETTERThe Blueprint DailyStay up-to-date on engineering, tech, space, and science news with The Blueprint.Sign Up  By clicking sign up, you confirm that you accept this site's Terms of Use and Privacy PolicyABOUT THE EDITORJohn Loeffler John is a writer and programmer living in New York City. He writes about computers, gadgetry, gaming, VR/AR, and related consumer technologies. You can find him on Twitter @thisdotjohnNewsinnovationPOPULAR ARTICLES1militaryGerman Navy ditches epic floppy disks from its warships after 30 yearsJijo Malayila day ago02energyCO2 to stone: Startup plans to inject 100 tons of carbon 1 km inside EarthChris Younga day ago03innovationStartup’s tricks drop methane emissions from rice cultivation by 35%Ameya Palejaa day ago04cultureSting operation: Kenya uses hidden bee hives to fight timber smugglersMaria Mocerinoa day ago0RELATED ARTICLESspaceFirst direct evidence of underground lava tube on Moon’s surface foundmilitaryUkraine’s trainer jet dogfights, downs Russian spy drones in WWI-stylecultureUN: 100 lorries may need 15 years to clear 40 million tons of Gaza debrisinnovationElectric abra: World’s 1st 3D-printed traditional wooden boat sets sail in DubaiJOBSSee All

Find Your Place In The World BY Amply







Merge IT

IT Support Engineer
Waipahu
$23 - $26 an hour
See Job







SAIC

Systems Engineer
Denver
$80,001 - $120,000 a year
See Job







The Travelers Companies, Inc.

Cybersecurity Software Engineer
Hartford
$115,700 - $190,900 a year
See Job







Booz Allen

Software Engineer
Melbourne
$67,700 - $154,000 a year
See Job



Search More Roles


FEATURED STORIES



 
 








",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd2h5eS5vcmcvYXJ0aWNsZXMvZ29vZ2xlLXRvLW9wZW4tbGFiLWF0LXByaW5jZXRvbi1hcy10ZWNoLWNvbXBhbmllcy1leHBhbmQtYWNyb3NzLXUtcy_SAQA?oc=5,"Google to open artificial intelligence lab in Princeton, N.J. — WHYY - WHYY",2018-12-22,WHYY,https://whyy.org,"This January, the tech company Google will open a new artificial intelligence lab just across the street from Princeton University.","['artificial intelligence', 'princeton']","This January, the tech company Google will open a new artificial intelligence lab just across the street from Princeton University.","This January, the tech company Google will open a new artificial intelligence lab just across the street from Princeton University.",http://schema.org,,NewsArticle,"Google to open artificial intelligence lab in Princeton, N.J.",http://whyy.org/articles/google-to-open-lab-at-princeton-as-tech-companies-expand-across-u-s/,"{'@type': 'WebPage', '@id': 'http://whyy.org/articles/google-to-open-lab-at-princeton-as-tech-companies-expand-across-u-s/'}",https://whyy.org/wp-content/uploads/2018/12/20181212_GoogleAI_space_DJA_007-150x150.jpg,"{'@type': 'ImageObject', 'url': 'https://whyy.org/wp-content/uploads/2018/12/20181212_GoogleAI_space_DJA_007-150x150.jpg'}",Science,"[{'@type': 'Person', 'name': 'Alan Yu'}]",[],"{'@type': 'Organization', 'name': 'WHYY', 'logo': {'@type': 'ImageObject', 'url': ''}}",2018-12-22T16:00:25Z,2018-12-22T16:00:25Z,2018-12-22T16:00:25Z,,,"





Morning Edition
Listen Live
Listen Live


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMipwFodHRwczovL3d3dy5jb2xvcmFkb3BvbGl0aWNzLmNvbS9uZXdzL3BlbnRhZ29uLXNheXMtdS1zLW1pbGl0YXJ5LWlzLWxvc2luZy1pdHMtYWR2YW50YWdlLXdpdGgtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYXJ0aWNsZV9iNTk1YTQ4OC0wNTZhLTExZTktODQyNy1iN2Q1YThlNTc0ZWEuaHRtbNIBAA?oc=5,Pentagon says U.S. military is losing its advantage with artificial intelligence - coloradopolitics.com,2018-12-26,coloradopolitics.com,https://www.coloradopolitics.com,"WASHINGTON — The U.S. military is starting to lose a high-tech advantage as China and Russia develop sophisticated artificial intelligence, Pentagon officials are warning Congress.",news,"WASHINGTON — The U.S. military is starting to lose a high-tech advantage as China and Russia develop sophisticated artificial intelligence, Pentagon officials are warning Congress.",,https://schema.org,,Organization,,http://www.coloradopolitics.com,,,,,,,,,,,,,"


















Prev










Previous


Previous



Colorado Republicans praise Trump's pick of 'young, dynamic'…
Leading Colorado Republicans and delegates to the party's na…









Next










Next Up


Next Up



Trial begins in lawsuit alleging voter intimidation in Color…
Three civic rights organizations began to make their case in…














Pentagon says U.S. military is losing its advantage with artificial intelligence




Tom Ramstack, special to Colorado Politics


Dec 26, 2018

Dec 26, 2018
Updated 
Nov 18, 2019

 0












Facebook






Twitter






WhatsApp






SMS






Email



















PhonlamaiPhoto / iStock














Facebook






Twitter






WhatsApp






SMS






Email






Print






Copy article link






Save















WASHINGTON — The U.S. military is starting to lose a high-tech advantage as China and Russia develop sophisticated artificial intelligence, Pentagon officials are warning Congress.A recent subcommittee hearing on the issue held special significance for Colorado Springs defense subcontractor Polaris Alpha, which last May won a $2.3 million Defense Department contract to develop artificial intelligence systems.If Congress approves more spending on artificial intelligence, Polaris Alpha is likely to be among the winners.The House Armed Services subcommittee on emerging threats and capabilities listened earlier this month as Pentagon officials describe China’s strategic plan for increasing spending on artificial intelligence, or “AI.”Artificial intelligence is a branch of computer science that develops intelligent machines that work and react like humans, ideally with faster responses and smaller margins for error. Facial recognition technology and self-driving cars are examples.It is used by the Defense Department to identify and respond to military threats and aggression.China spent $12 billion in 2017 on artificial intelligence but plans to increase its budget to at least $70 billion by 2020, according to Defense Department reports. Meanwhile, the U.S. military spent about $7.4 billion for new technology development in fiscal 2017, which included artificial intelligence.“Other nations, particularly China and Russia, are making significant investments in AI for military purposes,” Dana Deasy, the Pentagon’s chief information officer, told the panel.“These investments threaten to erode our technological and operational advantages and destabilize the free and open international order.”The subcommittee called the hearing partly as a response to the John S. McCain National Defense Authorization Act for fiscal year 2019, which directed the Defense Department to review how artificial intelligence is serving military needs.The measure requires the Pentagon to develop a plan for artificial intelligence. The Polaris Alpha contract is supposed to be one part of the plan.Amber Thompson-Nadler, spokeswoman for Polaris Alpha parent company Parsons, told Colorado Politics that its technology is “enhancing warfighter situational awareness, predicting threats and supporting mission planning.”She added, “AI is an increasingly vital tool in the U.S. military’s arsenal for the simple reason that it provides the warfighter with an asymmetric advantage across the entire spectrum of the modern battlefield.”Colorado Republican U.S. Rep. Doug Lamborn is a member of the subcommittee on emerging threats and capabilities. Although he did not speak during the hearing, other members of the Colorado delegation offered strong opinions on military artificial intelligence and Colorado’s role in supporting it.“It’s extremely important we make sure U.S. military technology and capabilities remain ahead of other countries like China and Russia, and Colorado companies can play a major role in this space,” Colorado U.S. Sen. Cory Gardner, a Republican, said in a statement.Colorado U.S. Rep. Ken Buck, a Republican, said, “The United States should aim to lead the world in artificial intelligence research and overall military readiness. It is frightening that the U.S. may have ceded our AI advantage to China, given China’s human rights abuses and aggressive behavior in the South China Sea.”A key component of the Pentagon’s plan is establishment of the Washington-based Joint Artificial Intelligence Center. Announced last summer, it will oversee nearly efforts to develop the technology.Pentagon officials say their first initiative among new artificial intelligence programs is Project Maven.The project uses advanced computer algorithms for “computer vision,” which is a form of machine learning. Analysts can feed data into the system where objects of interest can be automatically extracted, similar to keywords that search and identify information from among billions of data items on Google and other search engines.However, Project Maven more often searches for military threats from among moving or still imagery, such a film footage from airborne drones.








Facebook






Twitter






WhatsApp






SMS






Email






Print






Copy article link






Save
















Around the WebAds by RevcontentThis Is The Highest Rated Hearing Aid In The Ushear.comClint Eastwood, 93, Now Lives Alone in District of ColumbiaDaily Sports ReporterHere's How Much You Should Pay For Affordable Gutter GuardsLeafFilter PartnerA Pair of Reading Glasses That Can See Both Far and Near！OutfanyA 70-year-old Engineer Designed This Nail Clipper for Seniors All Over the WorldSherumThe Conjoined Twins Are No Longer Togetherswift VerdictThis New Portable AC is Sweeping the District of ColumbiaOutfanyKeurig Owners Beware: the Shocking Reason Many Nearly Gave Up Their Machines!Coffee MagazineGrandma Shocks Doctors With Simple Trick to Treat Allergy Symptoms (Watch)HikariBlast




×
Post a comment as Guest








Post As


Emoticons 


  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  



Comment Text



CAPTCHA





Cancel


Post comment











×
Report








Cancel


Report Abuse












×

Watch this discussion.
Stop watching this discussion.




Watch this discussion




Get an email notification whenever someone contributes to the discussion


Notifications from this discussion will be disabled.




Cancel



Start watching
Stop watching











 (0) comments






Welcome to the discussion.


Log In


Post a comment as Guest



Keep it Clean. Please avoid obscene, vulgar, lewd,
racist or sexually-oriented language.
PLEASE TURN OFF YOUR CAPS LOCK.
Don't Threaten. Threats of harming another
person will not be tolerated.
Be Truthful. Don't knowingly lie about anyone
or anything.
Be Nice. No racism, sexism or any sort of -ism
that is degrading to another person.
Be Proactive. Use the 'Report' link on
each comment to let us know of abusive posts.
Share with Us. We'd love to hear eyewitness
accounts, the history behind an article.



Post a comment



Watch this discussion.
Stop watching this discussion.


























",,,,,,"['https://www.facebook.com/coloradopolitics/', 'https://twitter.com/colo_politics/', 'https://www.instagram.com/coloradopolitics/', 'editor@coloradopolitics.com']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMilwFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Jlcm5hcmRtYXJyLzIwMTgvMTIvMTQvdGhlLWFtYXppbmctd2F5cy1ob3ctdW5pbGV2ZXItdXNlcy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS10by1yZWNydWl0LXRyYWluLXRob3VzYW5kcy1vZi1lbXBsb3llZXMv0gEA?oc=5,The Amazing Ways How Unilever Uses Artificial Intelligence To Recruit & Train Thousands Of Employees - Forbes,2018-12-14,Forbes,https://www.forbes.com,"Unilever, the multinational consumer goods manufacturer, uses artificial intelligence and machine learning to help with recruiting and onboarding of new employees. The algorithms help to sift through CVs and even conduct and analyze video interviews.",,"Unilever, the multinational consumer goods manufacturer, uses artificial intelligence and machine learning to help with recruiting and onboarding of new employees. The algorithms help to sift through CVs and even conduct and analyze video interviews.","Unilever, the multinational consumer goods manufacturer, uses artificial intelligence and machine learning to help with recruiting and onboarding of new employees. The algorithms help to sift through CVs and even conduct and analyze video interviews.",http://schema.org,,BreadcrumbList,The Amazing Ways How Unilever Uses Artificial Intelligence To Recruit & Train Thousands Of Employees,https://www.forbes.com/sites/bernardmarr/2018/12/14/the-amazing-ways-how-unilever-uses-artificial-intelligence-to-recruit-train-thousands-of-employees/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2018/12/AdobeStock_206783935-1200x800.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",Enterprise & Cloud,"{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2018-12-14T00:07:00-05:00,2019-03-07T09:28:17-05:00,Enterprise & Cloud,,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise TechThe Amazing Ways How Unilever Uses Artificial Intelligence To Recruit & Train Thousands Of EmployeesBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 14, 2018,12:07am ESTUpdated Mar 7, 2019, 09:28am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinIt’s hard to live a day in the developed world without using a Unilever product. The multinational manufactures and distributes over 400 consumer goods brands covering food and beverages, domestic cleaning products and personal hygiene.








Adobe Stock
Adobe Stock






With so many processes to coordinate and manage, artificial intelligence is quickly becoming essential for organizations of its scale. This applies to both research and development as well as the huge support infrastructure needed for a business with 170,000 employees.
Recently it announced that it had developed machine learning algorithms capable of sniffing your armpit and telling you whether you are suffering from body odors. While this may seem like ""using a sledgehammer to crack a walnut,"" the technology which has been developed could well go on to be used to monitor food for freshness, helping to solve the problem of food overproduction and waste endemic in society.
PROMOTED
As well as these smart, public-facing initiatives, though, artificial intelligence is being put to use behind the scenes to help screen and assess the more than one million people per year who apply for jobs with Unilever. If they make the grade and become one of the thousands who are offered a job, they have AI-powered tools to help them adjust to their new role and hit the ground running.

AI-enhanced recruiting
Unilever recruits more than 30,000 people a year and processes around 1.8 million job applications.
This takes a tremendous amount of time and resources. As a multinational brand operating in 190 countries, applicants are based all around the world. Finding the right people is an essential ingredient for success, and Unilever can't afford to overlook talent just because it is buried at the bottom of a pile of CVs.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



To tackle this problem, Unilever partnered with Pymetrics, a specialist in AI recruitment, to create an online platform, which means candidates can be initially assessed from their own homes, in front of a computer or mobile phone screen.
First, they are asked to play a selection of games that test their aptitude, logic, and reasoning, and appetite for risk. Machine learning algorithms are then used to assess their suitability for whatever role they have applied for, by matching their profiles against those of previously successful employees.





The second stage of the process involves submitting a video interview. Again, the assessor is not a human being but a machine learning algorithm. The algorithm examines the videos of candidates who answering questions for around 30 minutes, and through a mixture of natural language processing and body language analysis, determines who is likely to be a good fit.
Unilever's chief of HR, Leena Nair, told me that around 70,000 person-hours of interviewing and assessing candidates had been cut, thanks to the automated screening system.
She said, ""We look for people with a sense of purpose – systemic thinking, resilience, business acumen. Based on that profile, the games and the video interview are all programmed to look for cues in their behavior that will help us understand who will fit in at Unilever.""
Referring to the video interview analytics for their future leaders program, she tells me: “Every screenshot gives us many data points about the person, so we work with a number of partners and use a lot of proprietary technology with those partners, and then we select 3,500 or so people to go through to our discovery center.” After spending a day with real leaders and recruiters, Unilever selects about 800 people who will be offered a job.
The system is also designed to give feedback to all applicants, even those who aren’t successful.
“What I like about the process is that each and every person who applies to us gets some feedback,” Nair says.
“Normally when people send an application to a large company it can go into a ‘black hole’ – thank you very much for your CV, we’ll get back to you – and you never hear from them again.
“All of our applicants get a couple of pages of feedback, how they did in the game, how they did in the video interviews, what characteristics they have that fit, and if they don’t fit, the reason why they didn’t, and what we think they should do to be successful in a future application.
“It’s an example of artificial intelligence allowing us to be more human.”
So while Unilever isn’t quite ready to hand the entire recruitment process over to machines just yet, it has shown that it can assist with the initial “sift” when it comes to preliminary screening of applicants.
Robots to help you settle into the job
After making the grade, another machine-learning-driven initiative is helping new employees get started in their new roles – adapting to the day-to-day routines as well as the corporate culture at the business.
Unabot is a natural language processing (NLP) bot built on Microsoft’s Bot framework, designed to understand what employees need to know and fetch information for them when it is asked.
“We joke about the fact we don’t know whether it’s a man or a woman – it’s Unabot,” Nair tells me.
“Unabot doesn’t only answer HR questions, questions about anything that affects employees should be answered by Unabot, and it is now the front face for any employee question – they might ask it about IT systems, or about their allowances – so we are learning about what matters to employees in real time.”
Through interacting with employees, Unabot has learned to answer questions such as where parking is available, the timing of shuttle buses, and when annual salary reviews are due to take place.
Unlike, for example, Alexa or consumer-facing, customer-service corporate chatbots, Unabot must also be able to filter and apply information based on who it is speaking to. It is capable of differentiating the information it passes on based on both the user's geographical location and their level of seniority within the company.
Unabot was first rolled out for employees based in the Philippines and is now operating in 36 countries. It has been selected as the next AI initiative that will be rolled out globally in all of Unilever’s 190 markets.
“It’s a new way of working,” Nair tells me, “We never go in and say it's perfect so let’s roll it out in all countries,’ we learn what we can in one country and roll it out in the next one.”
Currently, all of its data comes from internal sources, such as company guidelines, schedules, policy documents and questions asked by the employees themselves. In the future, this could be expanded to include external data such as learning materials.
And although it’s early days, the initial analysis seems to show that the initiative is popular with staff – with 36% of those in areas where it is deployed having used it at least once, and around 80% going on to use it again.
One lesson learned early on was that the importance of providing a frictionless experience.
“So we’ve learned that you have to make anything that interacts with employees or consumers effortless,” Nair says.
“People interact in different ways – a policy document is written in a particular way, its three or four pages of what an employee shouldn’t do. But an employee tends to ask questions in very simplistic ways – how does this impact my life, where will I find this, what can I do?”
Machine learning – particularly NLP – can overcome this due to its ability to detect which questions are repeatedly asked, even if they are asked in different ways, and present the right information.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",,The Amazing Ways How Unilever Uses Artificial Intelligence To Recruit & Train Thousands Of Employees,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3Lm5lc3RhLm9yZy51ay9ibG9nL2NvbXBsZXgtZWNvbm9taWNzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,The complex economics of artificial intelligence - nesta,2018-12-13,nesta,https://www.nesta.org.uk,"Artificial Intelligence is making our economies more complex, and this creates new risks. I overview what they are, and how to manage them.",,"What if Artificial Intelligence fails, but we adopt it anyway? We explore the economic complexities of AI, and how to manage them.","What if Artificial Intelligence fails, but we adopt it anyway? We explore the economic complexities of AI, and how to manage them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vc2xvYW5yZXZpZXcubWl0LmVkdS92aWRlby9wdXR0aW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvLXdvcmsv0gEA?oc=5,Webinar: Putting Artificial Intelligence to Work - MIT Sloan Management Review,2018-12-14,MIT Sloan Management Review,https://sloanreview.mit.edu,"Getting started with AI means understanding its capabilities, its limitations, and the ethics of its use.",,"Getting started with AI means understanding its capabilities, its limitations, and the ethics of its use.","Getting started with AI means understanding its capabilities, its limitations, and the ethics of its use.",,,,,,,,,,,,,,,,,,"





Webinar
Putting Artificial Intelligence to Work
Thomas H. Davenport and Paul Michelman

December 14, 2018

Runtime 1:01:06

subscribe-icon
Subscribe










 Share



 Twitter



Facebook







Linkedin











Putting Artificial Intelligence to Work







Topics


Managing Technology


Ethics


Technology Implementation





What to Read Next

 How to Create Slides That Suit Your Superiors: 11 Tips | Nancy Duarte
 Three Questions to Ask About Your Digital Strategy
 Will AI Help or Hurt Sustainability? Yes | Andrew Winston
 Make a Stronger Business Case for Sustainability



To get started with AI, a company needs to understand what it’s capable of — and what it isn’t.











For more on how organizations can implement artificial intelligence, read Thomas H. Davenport’s new book.

Most of us are by now convinced of the tremendous potential of artificial intelligence. We’ve followed the hype, we’ve read the articles, and we’ve formed some understanding. Now, we want to put it to work. How does a company get started? How do you build a strategy, put a team in place, and increase the chances of having real success with AI?
Please join distinguished speaker Thomas H. Davenport, author of the recent book, The AI Advantage: How to Put the Artificial Intelligence Revolution to Work, as he brings us his practical advice and examples on how to achieve the business value that AI offers.
In this webinar, you’ll learn:

The appropriate level of ambition when setting an AI strategy.
What technologies are available and how companies are using them.
How companies should think about ethics and ethics policies when implementing AI.
How your organization can become “a more cognitive company.”



Event Notifications

Get periodic email updates on upcoming webinars, panel discussions, and other special events.


















                sign up            




Please enter a valid email address
Thank you for signing up
Privacy Policy





Topics


Managing Technology


Ethics


Technology Implementation





About the Authors
Thomas H. Davenport (@tdav) is President’s Distinguished Professor of Information Technology and Management at Babson College, a research fellow at the MIT Initiative on the Digital Economy, a senior adviser to Deloitte Analytics, and author of the recent book, The AI Advantage: How to Put the Artificial Intelligence Revolution to Work. Paul Michelman is editor in chief of MIT Sloan Management Review.



Tags: 

Artificial Intelligence
Business Value
Video
Webinar
Webinars & Videos





More Like This
           Driving Manufacturing Efficiency With AI: Pirelli’s Daniele Petecchi                Fashioning the Perfect Fit With AI: Stitch Fix’s Jeff Cooper                AI Hype and Skepticism: Economist Paul Romer                Marketing With Generative AI: Harvard Business School’s Ayelet Israeli     




Add a comment Cancel replyYou must sign in to post a comment.First time here? Sign up for a free account: Comment on articles and get access to many more articles. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy50aGV2ZXJnZS5jb20vMjAxOC8xMi8xMi8xODEzNjkyOS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1haS1pbmRleC1yZXBvcnQtMjAxOC1tYWNoaW5lLWxlYXJuaW5nLWdsb2JhbC1wcm9ncmVzcy1yZXNlYXJjaNIBAA?oc=5,"The AI boom is happening all over the world, and it's accelerating quickly - The Verge",2018-12-12,The Verge,https://www.theverge.com,"The second annual AI Index report pulls together data and expert findings on the field’s progress and acceleration. The experts include members of Harvard, MIT, Stanford, the nonprofit OpenAI, and the Partnership on AI industry consortium. The goal is to measure the field’s progress using hard data and to try and make sense of that progress as it relates to thorny subjects like workplace automation and the quest for artificial general intelligence",,The second annual AI Index report pulls together data and expert findings on the field’s progress and acceleration.,,http://schema.org/,,NewsArticle,"The AI boom is happening all over the world, and it’s accelerating quickly",https://www.theverge.com/2018/12/12/18136929/artificial-intelligence-ai-index-report-2018-machine-learning-global-progress-research,,https://cdn.vox-cdn.com/thumbor/FqJKU0SvAgBBlOqXbRCL9AhHowQ=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292779/acastro_181017_1777_brain_ai_0002.jpg,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/FqJKU0SvAgBBlOqXbRCL9AhHowQ=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292779/acastro_181017_1777_brain_ai_0002.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/p2l9KdLuVe_tnOFn3Gle73Mm2Jg=/0x0:2040x1360/1400x1050/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292779/acastro_181017_1777_brain_ai_0002.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/KxmLFxvDEBE2woExeahlYKD2-PQ=/0x0:2040x1360/1400x1400/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292779/acastro_181017_1777_brain_ai_0002.jpg', 'width': 1400, 'height': 1400}]",,"[{'@type': 'Person', 'name': 'Nick Statt', 'url': 'https://www.theverge.com/authors/nick-statt'}]",,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",,2018-12-12T16:00:03.000Z,2018-12-12T16:00:03.000Z,,,"Tech/Artificial Intelligence/US & WorldThe AI boom is happening all over the world, and it’s accelerating quicklyThe AI boom is happening all over the world, and it’s accelerating quickly / The second annual AI Index report pulls together data and expert findings on the field’s progress and accelerationBy  Nick Statt, is a Senior Producer on Decoder. Previously, he wrote about technology and gaming for Naavik, Protocol, and The Verge. Dec 12, 2018, 11:00 AM ESTShare this story0 Comments / 0 New Illustration by Alex Castro / The VergeThe rate of progress in the field of artificial intelligence is one of the most hotly contested aspects of the ongoing boom in teaching computers and robots how to see the world, make sense of it, and eventually perform complex tasks both in the physical realm and the virtual one. And just how fast the industry is moving, and to what end, is typically measured not just by actual product advancements and research milestones, but also by the prognostications and voiced concerns of AI leaders, futurists, academics, economists, and policymakers. AI is going to change the world — but how and when are still open questions. Today, findings from a group of experts were published in an ongoing effort to help answer those questions. The experts include members of Harvard, MIT, Stanford, the nonprofit OpenAI, and the Partnership on AI industry consortium, among others, and they were put together as part of the second annual AI Index. The goal is to measure the field’s progress using hard data and to try and make sense of that progress as it relates to thorny subjects like workplace automation and the overarching quest for artificial general intelligence, or the type of intelligence that could let a machine perform any task a human could. AI will change the world, but researchers are still trying to figure out how and whenThe first report, published last December, found that investment and work in AI was accelerated at an unprecedented rate and that, while progress in certain fields like limited game-playing and vision has been extraordinary, AI remains far behind in general intelligence tasks that would result in, say, total automation of more than a limited variety of jobs. Still, the report was lacking in what the authors call a “global perspective,” and this second edition set out to answer many of the same questions with new, more granular data and a more international scope. “There is no AI story without global perspective. The 2017 report was heavily skewed towards North American activities. This reflected a limited number of global partnerships, not an intrinsic bias,” reads the 2018 report’s introduction. “This year, we begin to close the global gap. We recognize that there is a long journey ahead — one that involves collaboration and outside participation — to make this report truly comprehensive.” In that spirit of global analysis, the second AI Index report finds that commercial and research work in AI, as well as funding, is exploding pretty much everywhere on the planet. There’s an especially high concentration in Europe and Asia, with China, Japan, and South Korea leading Eastern countries in AI research paper publication, university enrollment, and patent applications. In fact, Europe is the largest publisher of AI papers, with 28 percent of all AI-related publications last year. China is close behind with 25 percent, while North America is responsible for 17 percent.  Image: AI Index Report 2018When it comes to the type of AI activity, the report finds that machine learning and so-called probabilistic reasoning — or the type of cognition-related performance that lets a game-playing AI outsmart a human opponent — is far and away the leading research category by a number of published papers. Not far behind, however, is work on computer vision, which is the foundational sub-discipline of AI that’s helping to develop self-driving cars and power augmented reality and object recognition, and neural networks, which, like machine learning, are instrumental in training those algorithms to improve over time. Less important, at least in the current moment, are areas like natural language processing, which is what lets your smart speaker understand what you’re saying and respond in kind, and general planning and decision making, which is what will be required of robots when automated machines are inevitably more integral facets of daily life.  Image: AI Index Report 2018A fascinating element of the report is how research in those categories breaks down by global region. China is heavily focused on agricultural science, engineering, and technology, while Europe and North America are focused more on the humanities and medical and health sciences, though Europe is generally more well-rounded in its approach to research. Some other interesting tidbits from the report include US AI research papers, which, despite being lower in volume, outpace China and Europe in citations. Government-related organizations and research outfits also account for far more papers in China and Europe than corporations or the medical field, while the US’s AI research efforts are largely dominated by corporate efforts, which makes sense given the immense investment in the field from Apple, Amazon, Google, Facebook, and Microsoft.  Image: AI Index Report 2018As far as performance goes, AI continues to skyrocket, especially in fields like computer vision. By measuring benchmark performance for the widely used image training database ImageNet, the report finds that the time it takes to spin up a model that can classify pictures at state-of-the-art accuracy fell “from around on hour to around 4 minutes” in just 18 months. That equates to a roughly 16x jump in training speed. Other areas like object segmentation, which is what lets software differentiate between an image’s background and its subject, has increased in precision by 72 percent in just three years.  Image: AI Index Report 2018For areas like machine translation and parsing, which is what lets software understand syntactic structures and more easily answer questions, accuracy and proficiency is getting more and more refined, but with diminishing returns as algorithms get ever closer human-level understanding of language. In a separate “human-level milestones” section, the report breaks down some big 2018 milestones in fields like game-playing and medical diagnostics where progress is accelerating at surprising rates. Those include progress from Google-owned DeepMind in playing the classic first-person shooter Quake in objective-oriented game modes like capture the flag, as well as landmark performances against amateur and then former professional players of the online battle arena game Dota 2.  Illustration by Alex Castro / The VergeAll of this hard data is fantastic in understanding where the AI field stands right now and how it’s been growing over the years and is projected to grow in the future. Yet, we’re still stuck in murky territory when it comes to harder questions around automation and the ways that AI could be implemented in areas like criminal justice, border patrol screenings, warfare, and other areas where performance is less important than the underlying governmental policy at play. AI will only continue to get more sophisticated, but there are a number of hurdles, both technological and with regard to bias and safety, before such software could be reliably used without error in hospitals, education systems, airports, and police departments. Unfortunately, that hasn't stopped corporations and governments from continuing to plow forward in deploying AI in the real world. This year, we discovered that Amazon was selling its Recognition facial recognition software to law enforcement, while Google found itself embroiled in controversy after it was discovered it was contributing computer vision expertise to a Department of Defense drone program known as Project Maven. AI is increasingly being put to work by governments in situations that are ripe for abuseGoogle said it would pull out of the project once its contract expired, and it also published a wide-ranging set of AI ethics principles that included a pledge never to develop AI weaponry surveillance systems or to contribute to any project that violated “widely accepted principles of international law and human rights.” But it’s clear that the leaders of Silicon Valley see AI as a prime business opportunity and such projects and contracts as the financial reward for participating in the AI research arms race. Elsewhere in the world, AI is helping governments pioneer systems of surveillance and law enforcement that constantly track citizens as they move about society. According to The New York Times, China is using millions of cameras and AI-assisted technologies like facial recognition to create the world’s most comprehensive surveillance system for its nearly 1.4 billion-person populace. Such a system is expected to link with the country’s new social credit system for scoring citizens and stratifying society into layers of access and privilege based on education, financial background, and other metrics, all of which will be informed by a day-to-day data collection and analysis of people’s real-world and online behaviors.  Illustration by Alex Castro / The VergeWith automation, we’ve come to an understanding that mass unemployment isn’t coming anytime soon, and the bigger concern is whether we as a society are prepared for the nature of work to transition toward less stable, lower-paid jobs without safety nets like health insurance. Not everyone is going to lose their job right away. Rather, certain jobs will be eliminated over time, while others will become semi-automated. And some jobs will always require a human being. The fate of workers will depend on certain employer constraints, labor laws and regulations, and whether there’s a good enough system in place to transition people into new roles or industries. For instance, a McKinsey Global Institute report from November of last year found that 800 million jobs could be lost to worldwide automation by 2030, but only about 6 percent of all jobs are at risk of complete automation. How that process of moving from a human-only job to an AI- or robot-assisted one is developed could mean the difference between a full-blown crisis and a historical paradigm shift. Automation won’t eliminate every job, but it will complicate the nature of workA paper from US think tank, the Center for Global Development, that was published back in July centered on the potential effects of AI and robotic automation on global labor markets. Researchers found that there is not nearly enough work being done to prepare for the overall automation fallout, and we’re spending too much time debating the general ethics and viability of complete automation in a narrow set of markets. “Questions like profitability, labor regulations, unionization, and corporate-social expectations will be at least as important as technical constraints in determining which jobs get automated,” the paper concluded. Not everything is all doom and gloom. Part of the philosophy behind the AI Index report is about asking the right questions and making sure that the people making policy, the public, and the leaders of the AI industry have data to make informed decisions. It may be too early to reliably measure the impact of AI on society — the industry is only just getting started — but preparing ourselves for what it all means and how it will affect daily life, work, and public institutions like health care, education, and law enforcement is perhaps just as important as the research and product development itself. Only by investing in both can we avoid the risk of creating technologies that change the world for the worse. Comments0 Comments / 0 NewFeatured Videos From The VergeNew chips, new screens, new gadgets | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge’s David Pierce takes a look at the Boox Palma, a phone-shaped e-reader that runs Android. He also compares notes with Clockwise’s Matt Martin and writer Craig Mod. Later, The Verge’s Nathan Edwards and Tom Warren join the show to discuss their experience using Microsoft’s new Surface Copilot PCs.Most PopularMost PopularIt’s never been easier for the cops to break into your phoneThe FBI says it has ‘gained access’ to the Trump rally shooter’s phoneGoogle is reportedly planning its biggest startup acquisition everThe Google Pixel 9 just leaked againAmazon’s press-to-order Dash buttons are officially discontinuedVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",,,,,,,,,,,,,,,,,,,"The rate of progress in the field of artificial intelligence is one of the most hotly contested aspects of the ongoing boom in teaching computers and robots how to see the world, make sense of it, and eventually perform complex tasks both in the physical realm and the virtual one. And just how fast the industry is moving, and to what end, is typically measured not just by actual product advancements and research milestones, but also by the prognostications and voiced concerns of AI leaders, futurists, academics, economists, and policymakers. AI is going to change the world — but how and when are still open questions. 

Today, findings from a group of experts were published in an ongoing effort to help answer those questions. The experts include members of Harvard, MIT, Stanford, the nonprofit OpenAI, and the Partnership on AI industry consortium, among others, and they were put together as part of the second annual AI Index. The goal is to measure the field’s progress using hard data and to try and make sense of that progress as it relates to thorny subjects like workplace automation and the overarching quest for artificial general intelligence, or the type of intelligence that could let a machine perform any task a human could. 

""AI will change the world, but researchers are still trying to figure out how and when""

The first report, published last December, found that investment and work in AI was accelerated at an unprecedented rate and that, while progress in certain fields like limited game-playing and vision has been extraordinary, AI remains far behind in general intelligence tasks that would result in, say, total automation of more than a limited variety of jobs. Still, the report was lacking in what the authors call a “global perspective,” and this second edition set out to answer many of the same questions with new, more granular data and a more international scope. 

“There is no AI story without global perspective. The 2017 report was heavily skewed towards North American activities. This reflected a limited number of global partnerships, not an intrinsic bias,” reads the 2018 report’s introduction. “This year, we begin to close the global gap. We recognize that there is a long journey ahead — one that involves collaboration and outside participation — to make this report truly comprehensive.” 

In that spirit of global analysis, the second AI Index report finds that commercial and research work in AI, as well as funding, is exploding pretty much everywhere on the planet. There’s an especially high concentration in Europe and Asia, with China, Japan, and South Korea leading Eastern countries in AI research paper publication, university enrollment, and patent applications. In fact, Europe is the largest publisher of AI papers, with 28 percent of all AI-related publications last year. China is close behind with 25 percent, while North America is responsible for 17 percent. 

[Image: https://cdn.vox-cdn.com/thumbor/RPBDtuyKxpdcCm1NqfwSL2zbeGU=/0x0:1500x938/1500x938/filters:focal(750x469:751x470)/cdn.vox-cdn.com/uploads/chorus_asset/file/13620067/Screen_Shot_2018_12_11_at_4.40.33_PM.png]

When it comes to the type of AI activity, the report finds that machine learning and so-called probabilistic reasoning — or the type of cognition-related performance that lets a game-playing AI outsmart a human opponent — is far and away the leading research category by a number of published papers. 

Not far behind, however, is work on computer vision, which is the foundational sub-discipline of AI that’s helping to develop self-driving cars and power augmented reality and object recognition, and neural networks, which, like machine learning, are instrumental in training those algorithms to improve over time. Less important, at least in the current moment, are areas like natural language processing, which is what lets your smart speaker understand what you’re saying and respond in kind, and general planning and decision making, which is what will be required of robots when automated machines are inevitably more integral facets of daily life. 

[Image: https://cdn.vox-cdn.com/thumbor/hvIS03tjRgc1KhOYpyuiwBesePc=/0x0:1512x784/1512x784/filters:focal(756x392:757x393)/cdn.vox-cdn.com/uploads/chorus_asset/file/13620113/Screen_Shot_2018_12_11_at_4.52.09_PM.png]

A fascinating element of the report is how research in those categories breaks down by global region. China is heavily focused on agricultural science, engineering, and technology, while Europe and North America are focused more on the humanities and medical and health sciences, though Europe is generally more well-rounded in its approach to research. 

Some other interesting tidbits from the report include US AI research papers, which, despite being lower in volume, outpace China and Europe in citations. Government-related organizations and research outfits also account for far more papers in China and Europe than corporations or the medical field, while the US’s AI research efforts are largely dominated by corporate efforts, which makes sense given the immense investment in the field from Apple, Amazon, Google, Facebook, and Microsoft. 

[Image: https://cdn.vox-cdn.com/thumbor/RRKcv7-zY82LA8od7QHX0Dtrfi8=/0x0:1472x1210/1472x1210/filters:focal(736x605:737x606)/cdn.vox-cdn.com/uploads/chorus_asset/file/13620123/Screen_Shot_2018_12_11_at_4.54.22_PM.png]

As far as performance goes, AI continues to skyrocket, especially in fields like computer vision. By measuring benchmark performance for the widely used image training database ImageNet, the report finds that the time it takes to spin up a model that can classify pictures at state-of-the-art accuracy fell “from around on hour to around 4 minutes” in just 18 months. That equates to a roughly 16x jump in training speed. Other areas like object segmentation, which is what lets software differentiate between an image’s background and its subject, has increased in precision by 72 percent in just three years. 

[Image: https://cdn.vox-cdn.com/thumbor/r54qlL4NurxhZjGRBl8VXOR6WBA=/0x0:1500x784/1500x784/filters:focal(750x392:751x393)/cdn.vox-cdn.com/uploads/chorus_asset/file/13620159/Screen_Shot_2018_12_11_at_5.10.20_PM.png]

For areas like machine translation and parsing, which is what lets software understand syntactic structures and more easily answer questions, accuracy and proficiency is getting more and more refined, but with diminishing returns as algorithms get ever closer human-level understanding of language. 

In a separate “human-level milestones” section, the report breaks down some big 2018 milestones in fields like game-playing and medical diagnostics where progress is accelerating at surprising rates. Those include progress from Google-owned DeepMind in playing the classic first-person shooter Quake in objective-oriented game modes like capture the flag, as well as landmark performances against amateur and then former professional players of the online battle arena game Dota 2. 

[Image: https://cdn.vox-cdn.com/thumbor/K9LLPvhFykJUoh4dZ8exNTQNAhA=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/12322323/acastro_180730_1777_facial_recognition_0001.jpg]

All of this hard data is fantastic in understanding where the AI field stands right now and how it’s been growing over the years and is projected to grow in the future. Yet, we’re still stuck in murky territory when it comes to harder questions around automation and the ways that AI could be implemented in areas like criminal justice, border patrol screenings, warfare, and other areas where performance is less important than the underlying governmental policy at play. AI will only continue to get more sophisticated, but there are a number of hurdles, both technological and with regard to bias and safety, before such software could be reliably used without error in hospitals, education systems, airports, and police departments. 

Unfortunately, that hasn't stopped corporations and governments from continuing to plow forward in deploying AI in the real world. This year, we discovered that Amazon was selling its Recognition facial recognition software to law enforcement, while Google found itself embroiled in controversy after it was discovered it was contributing computer vision expertise to a Department of Defense drone program known as Project Maven. 

""AI is increasingly being put to work by governments in situations that are ripe for abuse""

Google said it would pull out of the project once its contract expired, and it also published a wide-ranging set of AI ethics principles that included a pledge never to develop AI weaponry surveillance systems or to contribute to any project that violated “widely accepted principles of international law and human rights.” But it’s clear that the leaders of Silicon Valley see AI as a prime business opportunity and such projects and contracts as the financial reward for participating in the AI research arms race. 

Elsewhere in the world, AI is helping governments pioneer systems of surveillance and law enforcement that constantly track citizens as they move about society. According to The New York Times, China is using millions of cameras and AI-assisted technologies like facial recognition to create the world’s most comprehensive surveillance system for its nearly 1.4 billion-person populace. Such a system is expected to link with the country’s new social credit system for scoring citizens and stratifying society into layers of access and privilege based on education, financial background, and other metrics, all of which will be informed by a day-to-day data collection and analysis of people’s real-world and online behaviors. 

[Image: https://cdn.vox-cdn.com/thumbor/N7T4mkiAUafT8j2aMDhsQKwRsg8=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292777/acastro_181017_1777_brain_ai_0001.jpg]

With automation, we’ve come to an understanding that mass unemployment isn’t coming anytime soon, and the bigger concern is whether we as a society are prepared for the nature of work to transition toward less stable, lower-paid jobs without safety nets like health insurance. 

Not everyone is going to lose their job right away. Rather, certain jobs will be eliminated over time, while others will become semi-automated. And some jobs will always require a human being. The fate of workers will depend on certain employer constraints, labor laws and regulations, and whether there’s a good enough system in place to transition people into new roles or industries. For instance, a McKinsey Global Institute report from November of last year found that 800 million jobs could be lost to worldwide automation by 2030, but only about 6 percent of all jobs are at risk of complete automation. How that process of moving from a human-only job to an AI- or robot-assisted one is developed could mean the difference between a full-blown crisis and a historical paradigm shift. 

""Automation won’t eliminate every job, but it will complicate the nature of work""

A paper from US think tank, the Center for Global Development, that was published back in July centered on the potential effects of AI and robotic automation on global labor markets. Researchers found that there is not nearly enough work being done to prepare for the overall automation fallout, and we’re spending too much time debating the general ethics and viability of complete automation in a narrow set of markets. “Questions like profitability, labor regulations, unionization, and corporate-social expectations will be at least as important as technical constraints in determining which jobs get automated,” the paper concluded. 

Not everything is all doom and gloom. Part of the philosophy behind the AI Index report is about asking the right questions and making sure that the people making policy, the public, and the leaders of the AI industry have data to make informed decisions. It may be too early to reliably measure the impact of AI on society — the industry is only just getting started — but preparing ourselves for what it all means and how it will affect daily life, work, and public institutions like health care, education, and law enforcement is perhaps just as important as the research and product development itself. Only by investing in both can we avoid the risk of creating technologies that change the world for the worse. 
",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvdGhlLWltcGFjdC1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1vbi1pbnRlcm5hdGlvbmFsLXRyYWRlL9IBAA?oc=5,The impact of artificial intelligence on international trade | Brookings - Brookings Institution,2018-12-13,Brookings Institution,https://www.brookings.edu,"AI is already starting to fundamentally change global trade, writes Joshua P. Meltzer.",,"AI is already starting to fundamentally change global trade, writes Joshua P. Meltzer.",,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/the-impact-of-artificial-intelligence-on-international-trade/', 'url': 'https://www.brookings.edu/articles/the-impact-of-artificial-intelligence-on-international-trade/', 'name': 'The impact of artificial intelligence on international trade | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/the-impact-of-artificial-intelligence-on-international-trade/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/the-impact-of-artificial-intelligence-on-international-trade/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2016/11/shipping_containers010.jpg?quality=75', 'datePublished': '2018-12-13T05:01:16+00:00', 'dateModified': '2022-03-09T04:07:04+00:00', 'description': 'AI is already starting to fundamentally change global trade, writes Joshua P. Meltzer.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/the-impact-of-artificial-intelligence-on-international-trade/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/the-impact-of-artificial-intelligence-on-international-trade/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/the-impact-of-artificial-intelligence-on-international-trade/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2016/11/shipping_containers010.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2016/11/shipping_containers010.jpg?quality=75', 'width': 3600, 'height': 2400, 'caption': 'Container boxes are seen at the Yangshan Deep Water Port, part of the Shanghai Free Trade Zone, in Shanghai, China September 24, 2016. Picture taken September 24, 2016. REUTERS/Aly Song/File Photo - RTSS0CU'}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/the-impact-of-artificial-intelligence-on-international-trade/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'The impact of artificial intelligence on international trade'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,"

 Back to Janesville 









                        Back to Janesville 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vd3d3LmJiYy5jb20vZnV0dXJlL2FydGljbGUvMjAxODEyMTItY2FuLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWVuZC10cmFmZmljLWphbXPSAQA?oc=5,The technology that could end traffic jams - BBC.com,2018-12-12,BBC.com,https://www.bbc.com,"With the number of cars clogging roads around the world expected to double in the coming decades, new approaches are needed to keep traffic moving.",,"With the number of cars clogging roads around the world expected to double in the coming decades, new approaches are needed to keep traffic moving.","With the number of cars clogging roads around the world expected to double in the coming decades, new approaches are needed to keep traffic moving.",https://schema.org,,NewsArticle,The technology that could end traffic jams,,,,['https://ychef.files.bbci.co.uk/1280x720/p06vd8mk.jpg'],,"{'@type': 'Person', 'name': 'Francesca Baker', 'url': ''}",,"{'@type': 'Organization', 'name': 'BBC'}",,2018-12-12T16:27:09.000Z,2022-02-24T18:18:33.067Z,,,"The technology that could end traffic jams12 December 2018By Francesca Baker, Features correspondentShareGetty ImagesSoaring numbers of cars and lorries on roads around the world is creating a headache for motorists as they find themselves stuck in traffic jams (Credit: Getty Images)With the number of cars clogging roads around the world expected to double in the coming decades, new ways of responding to crashes, controlling traffic lights and creating diversions will be needed to keep traffic moving.We’ve all been there. Stuck at traffic lights that never seem to change to green. Sitting in queues of cars that stretch on for miles or delayed by a glut of slow traffic that suddenly disappears. Traffic jams are a blight on our modern, fast moving lives. And we have been dealing with them in a very unmodern way.We don’t move about and travel in the same way that we used to, yet our traffic management systems have struggled to keep pace with the relentless onslaught of vehicles they have to deal with now. Jam-busting measures are often slow to react to changes in road or weather conditions and many traffic lights still work on timers that are often out of synchronisation, preventing vehicles from flowing freely.You might also like: • The chef making 120 burgers every hour • The aircraft designer who’s never flown • What single word defines who you are?In 2015 there were an estimated 1.3 billion motor vehicles on the world’s roads and with growing affluence in developing economies that number is expected to soar to over 2 billion by 2040. Even with new roads and bypasses, this ever increasing level of traffic could quickly outstrip the ability of our road networks to cope in many busy areas, such as cities.But by combining new communications technology with the power of artificial intelligence (AI) to crunch vast amounts of data in real time it may be possible to ease our clogged roads so they can cope with the growing number of cars.While many see self-driving vehicles as the panacea for traffic jams, it will be at least two decades before they start to make a meaningful impact on our roadsWhile many see self-driving vehicles as the panacea for traffic jams – provided these robotic vehicles can be taught to drive less erratically and react faster than human motorists – it will be at least two decades before they start to make a meaningful impact on our roads. In the meantime, highways agencies and city planners will have to cope with an ever-more complicated mix of human, semi-autonomous and autonomous drivers on the roads. Keeping them all moving will require traffic management systems to be instantly reactive and adaptable.Getty ImagesThere are hopes that new technology can ease traffic jams in already congested cities like Bengaluru, India, where vehicles often move at a walking pace (Credit: Getty Images)In Bengaluru, India, which regularly faces long traffic jams and the average speed on some roads at peak hours is just 4km/h (2.5mph),  Siemens Mobility has built a prototype monitoring system that that uses AI through traffic cameras. Traffic cameras automatically detect vehicles and this information is sent back to a central control centre where algorithms estimate the density of traffic on the road. The system then alters the traffic lights based on real-time road congestions.To respond in this way, however, requires data. A lot of data. Fortunately, this is not something in short supply. There’s lots of information from traffic monitoring systems, road infrastructure, cars and drivers themselves via their mobile phones. Millions of cameras line our roads while the passing vehicles induces tiny electrical currents in loops of metal hidden beneath the tarmac, providing further information about the traffic conditions. Motorists can send instant updates about hold ups thanks to the navigation software they use on their mobile phones and in their cars.Some of this monitoring technology – like the induction loops – have been around since the 1960s while others like cameras capable of tracking traffic and reading number plates are more recent. The challenge is doing something useful with all this information.“Since Isaac Newton we have been trying to influence the world by building mathematical models,” says Gabor Orosz, an associate professor in engineering  at the University of Michigan. “If we have data we can figure things out. The same applies to traffic.”There are now attempts to harness AI’s ability to make sense of large amounts of information and change the way that we move around our cities.Researchers at The Alan Turing Institute in London and the Toyota Mobility Foundation recently launched a new project together that is exploring how traffic management systems can become more dynamic and responsive through the use of AI. They are currently using simulations that scale up in complexity and evolve, helping their algorithms to learn how to predict changes in the traffic. Although they are still testing the system, they hope to soon apply their systems in the real world.Getty ImagesModern traffic management systems often use a combination of cameras and sensors in the road itself to assess the density of vehicles (Credit: Getty Images)“With deep machine learning we can improve predictability,” says William Chernicoff, head of research and innovation at the Toyota Mobility Foundation. “Metropolitan mobility managers can then make faster and more informed decisions on signal timing, suggested routing to system users, and capacity allocation.”Journey times in the city have fallen by 25% while vehicle emissions have dropped by up to 20%In Pittsburgh researchers are already working with city managers on a similar approach that has been operating in the city since 2012. An adaptive traffic control system developed by researchers at the Robotics Institute, Carnegie Mellon University, has been rolled out around the city by a company called Rapid Flow Tech. Their Surtrac technology is being used at 50 intersections in Pittsburgh and since launching, it has reduced wait times at intersections by up to 40%, according to the company. It also claims that journey times in the city have fallen by 25% while vehicle emissions have dropped by up to 20%.The system uses video feeds to automatically detect the number of road users, including pedestrians, and types of vehicles that are at an intersection. The AI software then processes this information second by second to come up with the best way to move traffic through the intersection, changing traffic lights depending on the most optimal way of keeping traffic moving. Decisions can be made autonomously, and shared with neighbouring intersections to help them understand what is coming their way.As vehicles become more connected with the help of mobile phone and other wireless technology, they too will help to feed even more information into systems like this. In the future, according to Griffin Schultz of Rapid Flow, connected vehicles will be able to communicate information about their speed, driver behaviour and even potential faults to the surrounding infrastructure.“At the moment we are just learning, but in the future this will be all pervasive,” he says. “It’s not just about cars, but will help all types of road users in a multimodal transportation society.”Getty ImagesBeing stuck in frustrating queues on busy roads can eat up many hours of motorists' day, reducing the time they have to do something more productive (Credit: Getty Images)Elsewhere, intelligent infrastructure is helping transport networks to become more connected. Siemens Mobility are working with cities and municipalities around the world to identify patterns of movement in an attempt to identify ways of improving experience for everyone on the road.“There are real world projects around the globe and the applications are continuously expanding,” says Markus Schlitt, head of intelligent traffic systems at the company.“In future cities, traffic will be so complex that without artificial Intelligence (AI) it will be virtual gridlock,” says Schlitt. “By utilising the data, we’re able identify patterns that would not have been seen without AI. Through continuous learning, we’re able to constantly update the traffic patterns and thus traffic flow. This results in less waiting time and fewer emissions.”In Hagen, Germany, they are using artificial intelligence to optimise traffic light control and reduce the waiting time at an intersection. Simulations suggest it can decrease waiting times at lights by up to 47% compared to a traditional pre-timed signal plan.But it’s not just motorists that are benefiting from the use of AI. Siemens Mobility are operating a fleet of 1,400 electric bikes in Lisbon, Portugal,, using machine learning to analyse various data sources like the weather to predict the future demand at each of the 140 bike-sharing stations. This allows them to ensure the availability of bikes and spaces in charging docks for those returning bikes. The predictions are used along with recent traffic information to help bike collection teams restock docking stations and provide optimal routing for service technicians who maintain the bikes.“This not only reduces operational running costs, it also increases the end-customers’ user experience,” says Schlitt. “So when you need to get around in Lisbon, you can be sure that there is always an e-bike available for you at the stations.”Siemens MobilityKeeping track of electric bikes as people move them around a city is a mind boggling task for a human but relatively easy for a computer (Credit: Siemens Mobility)As brilliant as the technology is, we can’t rely on it solely. Mischa Dohler, from the department of informatics at King’s College London and co-founder of traffic monitoring technology company Worldsensing, has been trialling AI and machine learning in Bogota, Colombia. He says the technology has already produced great results, by using road signals and signs to reroute traffic when there is an accident, reduce traffic jams, and lessen the time motorists spend seeking parking spaces.But he says that while AI is helping to make this sort adaptive transport network possible, the human element is important too. He calls this “explainable AI planning”. It is “so important because it takes intelligent decisions autonomously but is also understandable”, allowing humans to take decisions alongside the AI or adapt if something goes wrong. As well as being intellectually and technically capable, motorists themselves will have to be open to the idea of their traffic systems being controlled by computers.“When cities rely on algorithms to enact policy, that policy becomes obfuscated by computation,” says Jed Carter, editor of online technology magazine Moving World. “It becomes even harder for citizens to understand why they’ve been re-routed, photographed or detained when the reasons for those actions are buried in computer code.”But deploying smart technologies onto the roads will do more than simply prevent traffic jams. Mark Nicholson, from Vivacity Labs, who ran a UK Government backed project deploying intelligent traffic light signals in Milton Keynes, England, says that newer technologies have a lot of other benefits. Cost is one – as technology takes over more of the heavy lifting of traffic management, it will require less human intervention on mundane tasks like watching traffic cameras.Automated systems are also getting better at differentiating between large numbers of road users, so can prioritise cyclists, buses or emergency vehicles for example, which can improve safetyAutomated systems are also getting better at differentiating between large numbers of road users, so can prioritise cyclists, buses or emergency vehicles for example, which can improve safety. Keeping traffic flowing can also reduce energy consumption caused by idling vehicles when stationary and improves air quality. It can help to cut engine emissions and so help to reduce impacts on the environment. It can make parking easier and frees up time for motorists to be more productive.   Vivacity LabsSmart cameras at junctions can automatically identify different road users, allowing the traffic management system to adapt according to their needs (Credit: Vivacity Labs)“We want to automate and let the humans focus on what is important or more long term,” says Nicholson. “(Things) like choosing whether air quality is poor enough to prioritise HGVs to make sure they don’t need to stop next to a school, planning where to put a new bypass, as well as immediate issues such as choosing how to reroute traffic around a crash.”Nicholson says that the real benefit of technology is the way that it frees up humans to do important higher level work. By automating the tedious, time consuming day-to-day running of the transport networks means humans working alongside the machines can focus on what they are best at – adapting to situations that require adaptive thinking and creative solutions.The results from the Milton Keynes project are promising. City-wide intelligent cameras capable of identifying and classifying all vehicles and road users allowed for accurate, highly localised data around the city, giving planners and authorities insight into where and when roads get busy, the expected routes that motorists might take, and where parking spaces are likely to be available. Vivacity installed 411 of its smart traffic cameras at the major junctions in Milton Keynes, totalling 104 junctions and 812 carriageways. As well as counting and classifying road users, the sensors can measure time it takes for vehicles to travel between junctions and provide live photos to help with the development of future planning.Vivacity feed the data into a machine learning model that learns typical daily patterns and combines this with how the traffic responds to transient changes in the road network. It evolves and adapts over time, improving its predictive power and minimising the amount of human intervention required. It provides historical and live data, and predicts traffic flows for the day.The system is already predicting traffic conditions 15 minutes in advance with 89% accuracy compared to what happens in realityThe system is already predicting traffic conditions 15 minutes in advance with 89% accuracy compared to what happens in reality.""It is not only helping citizens see parking space availability in real time today, but also lays the foundations for future connected & autonomous transport technologies in Milton Keynes,” says Nicholson.What seems to be clear is that giving AI the green light on our roads could keep us all moving forward. “This is just the beginning – we haven’t even fully harnessed the capabilities and benefits of AI,” adds Markus Schlitt, from Seimens Mobility.Join 900,000+ Future fans by liking us on Facebook, or follow us on Twitter or Instagram. If you liked this story, sign up for the weekly bbc.com features newsletter, called “If You Only Read 6 Things This Week”. A handpicked selection of stories from BBC Future, Culture, Capital, and Travel, delivered to your inbox every Friday.Artificial intelligenceTransport",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LmJlbmVmaXRuZXdzLmNvbS9vcGluaW9uLzctcmVhc29ucy13aHktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbmVlZHMtcGVvcGxl0gEA?oc=5,7 reasons why artificial intelligence needs people - Employee Benefit News,2018-12-12,Employee Benefit News,https://www.benefitnews.com,"Despite the inherently negative narrative around the impact on jobs, most of the impact of automation of work through AI will result in a ""displacement,"" not a ""replacement,"" of work.","['Artificial intelligence', 'Machine learning', 'Data management', 'HR Technology', 'Wellness, Innovation, and Technology Resource Center', 'Free']","Despite the inherently negative narrative around the impact on jobs, most of the impact of automation of work through AI will result in a ""displacement,"" not a ""replacement,"" of work.","Despite the inherently negative narrative around the impact on jobs, most of the impact of automation of work through AI will result in a ""displacement,"" not a ""replacement,"" of work.",http://schema.org,,NewsArticle,7 reasons why artificial intelligence needs people,https://www.benefitnews.com/opinion/7-reasons-why-artificial-intelligence-needs-people,"{'@type': 'WebPage', '@id': 'https://www.benefitnews.com/opinion/7-reasons-why-artificial-intelligence-needs-people'}",https://arizent.brightspotcdn.com/19/db/57f87389462287fb35a075e76383/artificial-intelligence-19.jpg,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://arizent.brightspotcdn.com/19/db/57f87389462287fb35a075e76383/artificial-intelligence-19.jpg'}",OpinionArticle,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Genpact', 'articleSection': 'Author', 'description': 'Sanjay Srivastava is chief digital officer at Genpact, a global professional services firm focused on delivering digital transformation.', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject'}, 'jobTitle': 'Chief digital officer', 'name': 'Sanjay Srivastava', 'url': 'https://www.benefitnews.com/author/sanjay-srivastava-im1035002'}]","[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Genpact', 'articleSection': 'Author', 'description': 'Sanjay Srivastava is chief digital officer at Genpact, a global professional services firm focused on delivering digital transformation.', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject'}, 'jobTitle': 'Chief digital officer', 'name': 'Sanjay Srivastava', 'url': 'https://www.benefitnews.com/author/sanjay-srivastava-im1035002'}]","{'logo': {'@type': 'ImageObject', 'height': '40px', 'url': 'https://arizent.brightspotcdn.com/c2/04/7dcda7264a978d15e051f6c829c1/employeebenefitnews-brand-logo-color-no-padding.svg', '@context': 'http://schema.org'}, 'sameAs': [], 'name': 'Employee Benefit News', 'foundingDate': '', '@type': 'NewsMediaOrganization'}",2018-12-12T15:59:57.896Z,2018-12-12T15:59:57.896Z,2018-12-15T14:06:17.166Z,,,"   Artificial intelligence   Benefits Think  7 reasons why artificial intelligence needs people      By     Sanjay Srivastava     December 12, 2018, 10:59 a.m. EST  6 Min Read    Sponsored by           Facebook   Twitter   LinkedIn   Email       As we reflect on the definition of work in the business world, it’s clear that most work today is the exception processing of tasks that we couldn’t fully automate yet. And, with artificial intelligence changing the way we program software, we can solve for this last mile of enterprise automation we hadn’t been able to figure out over the past 30 years. As AI projects roll out over the next few years, we will need to rethink the definition of the work that people will do. And in the post-AI era the future of work will become one of the largest agenda items for policy makers, corporate executives and social economists.  Despite the strong and inherently negative narrative around the impact on jobs, the bulk of the impact from the automation of work through AI will result in a “displacement” of work not a “replacement” of work – it’s easy to see how the abacus-to-calculator-to-Excel phenomenon created completely new work around financial planning and reporting, and enterprise performance management. Similarly, AI will end up accelerating the future of work and resulting displacement of jobs will be a transition already in place, not an entirely new discussion. As some work gets automated other jobs will get created, in particular ones that require creativity, compassion and generalized thinking.      A NAO humanoid robot, developed by Softbank Corp. Photographer: Krisztian Bocsi/BloombergKrisztian Bocsi/Bloomberg   Shifting away from the larger impact of AI on jobs, and zooming in a little closer to getting AI operationalized, it’s clear people will be needed in many different ways to make AI work. From my observations across dozens of AI rollouts, here are seven areas where human knowledge and expertise will be a critical requirement in AI projects.1. Being an ethical compassFirst and foremost, selecting the right AI applications is one the most important decisions that people can make. Are we using AI for the right reasons – to help people with special needs by enhancing eyesight, to provide translation in hearing aids for better communications across cultures, to increase diversity in the hiring process? Or, are we using it for the wrong applications – from influencing elections to guiding the criminal justice system? People provide the ethical compass needed to determine AI’s use cases.2. Bringing contextWe need people in the loop to orient AI towards the right goals. This happens already with supervised learning, where people label the datasets in advance before running AI algorithms. But even in unsupervised or reinforced learning, people need to ensure the algorithm is leading to results that matter for the business, for instance, in pharmacovigilance, when prioritizing between life-threatening and benign secondary effects of taking medicine. In addition, we need people to contextualize AI’s results. For example, an AI algorithm predicting failure from sensors on aircraft engine parts will not know to interpret the data differently if the aircraft is flying over the Sahara versus the North Pole. People must feed this context into the algorithm; otherwise predictions can be off. It is more powerful to combine a moderately strong AI algorithm with human domain expertise than to use the most powerful deep learning model without any such context.3. Providing governance In a digital workforce, planning should take into account the inputs, outputs, and various exchanges involved with every process. We cannot just toss a robot into the mix and let it do its own thing. For instance, a minor change to a webform can throw off robot process automation working elsewhere. Mapping out how machines and other systems will work together can prevent potential hiccups and obstacles. When managers only have to oversee people, they can easily see when an employee clocks in, clocks out, or physically does not show up for work at all. Since AI is virtual, it becomes harder to tell whether or not a robot is working. For instance, if there is a random password change that blocks a bot from logging in, then not only does the work stop, but we may not notice it until hours or even weeks later. In a hybrid workforce, we should be able to easily see if and how AI is working, just as much as human employees. People drive governance.4. Handling complexityThe new man-meets-machine dynamic will make current jobs easier to do, but the focus of people will shift to higher value and more complex jobs. With AI taking over some tasks, employees are then free to look at bigger issues and concerns. Take banking for example. Chatbots in the world of finance can now handle more routine issues such as payment status, allowing human agents to dedicate their time to more complicated, customer cases, such as identifying the root cause of payment delays. This evolution towards more complex work is not new; when spreadsheets were invented, the financial analyst’s role went from reporting to planning. 5. Preventing bias As mentioned in another column, the two big reasons for AI bias are the lack of diversity in data samples and rushed or incomplete training algorithms. In both cases, people with domain knowledge are key. Industry or process experts can help think through potential biases, train the models accordingly, and govern over the machines to see that they don’t fall out of line. Diversity in the teams working with AI can also address training bias. When we only have a select few working on a system, it becomes skewed to the thinking of a small group of individuals. By bringing in a team with different skills and approaches, we can have a more holistic, ethical design and come up with new angles.6. Managing change Managing this next-gen, hybrid workforce is very different from just managing people. We have to think about how we deal with the change, make sure robots are holding up their end, and see that employees have the right skills to work with their new AI coworkers. Putting seasoned employees alongside machines is a dramatic change – which is putting it lightly. AI design is moving from “humans in the loop” to “computers in the group.” Sometimes we forget to consider change management because we are eager to get AI going and start seeing some results. This actually does more harm than good, creating problems later down the line, due to rushed projects and negative thinking from employees. Any project has to start with a clear change management plan to prevent problems from both people and technology.7. Connecting creativity and compassionWhen Apple introduced the iPhone, we had no idea what new jobs it would create. Following the introduction of the iPhone, we came up with an entirely new creative industry of applications, ecommerce, ride sharing, wearables, online communities, video gaming, all invented by people who saw the potential of this new technology and applied their creativity to it. Just like creativity boomed after the iPhone’s launch, new creative applications will emerge from AI. We don’t know what they are yet, though people will drive that future. Much has been written about AI’s ability to create: art, poetry, and music are some recent and prominent examples.AI can help enhance creativity, though humans bring the compassion that goes hand in hand here. Kai Fu Lee, in his latest Ted Talk, explains how humans can thrive in the age of AI by harnessing compassion and creativity.Get ready for the hybrid workforcePeople who can translate their knowledge to these seven areas will be more important than ever. There is a great opportunity now to reskill employees on how to apply their experience in meaningful ways, and create greater talent. At the same time, recruiting programs should look for “bilingual” people, meaning those who already have both domain and digital knowledge, and can walk in, make those connections, and do the job.In the future workforce, people and machines will be equally important, combining industry knowledge with AI and automation. We have to start thinking more about how to manage this combination and make sure there are well-thought plans, structures, and education in place. Then, we can really consider ourselves ready to work alongside AI.       Sanjay Srivastava   Chief digital officer, Genpact     This article originally appeared in Digital Insurance.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mcmFtZXdvcmstYS12aXN1YWwtaW50cm9kdWN0aW9uLXRvLW1hY2hpbmUtbGVhcm5pbmctYW5kLWFpLWQ3ZTM2YjMwNGY4N9IBAA?oc=5,Artificial Intelligence Framework: A Visual Introduction to Machine Learning and AI - Towards Data Science,2018-12-12,Towards Data Science,https://towardsdatascience.com,An AI introduction to beginners providing a comprehensive overview of various AI and machine learning approaches like supervised or unsupervised learning.,,"The transformative nature of Artificial Intelligence in business and our society is evident. Like the internet and the smart phone, AI is…","The transformative nature of Artificial Intelligence in business and our society is evident. Like the internet and the smart phone, AI is…",http://schema.org,,NewsArticle,Artificial Intelligence Framework: A Visual Introduction to Machine Learning and AI,https://towardsdatascience.com/artificial-intelligence-framework-a-visual-introduction-to-machine-learning-and-ai-d7e36b304f87,https://towardsdatascience.com/artificial-intelligence-framework-a-visual-introduction-to-machine-learning-and-ai-d7e36b304f87,,['https://miro.medium.com/v2/resize:fit:1200/1*MaaHUyoKjbTwH9A02F6X7w.png'],,"{'@type': 'Person', 'name': 'Nils', 'url': 'https://nils-ackermann.medium.com'}",['Nils'],"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",2018-12-13T05:24:23.352Z,2018-12-13T05:24:23.352Z,2021-12-07T00:43:50.051Z,,,"Member-only storyArtificial Intelligence Framework: A Visual Introduction to Machine Learning and AIAll you need to know for your next AI or Machine Learning elevator pitchNils·FollowPublished inTowards Data Science·12 min read·Dec 13, 20181855ListenSharePhoto: a-image/ShutterstockThe transformative nature of Artificial Intelligence in business and our society is evident. Like the internet and the smartphone, AI is an enabler technology that will have a far-reaching impact on all areas of our life.In order to better understand the underlying concepts, I would like to share a picture with you that I typically use when explaining the broader context of machine learning / deep learning and how it relates to Artificial Intelligence.You will find many great articles here on medium or elsewhere which give a very good introduction to AI (I have linked some at the end of this article). Nevertheless, what I have not seen so far is an AI overview which is easy to digest visually. If you know something I could use instead, go ahead and let me know in the comments section below. But until then, let me share the visualisation that I am using right now. I will also briefly walk through the key components of the figure in this article.",,,Artificial Intelligence Framework: A Visual Introduction to Machine Learning and AI,,,,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,False,,,,,,,,,,,,,,,,,,,,,,,d7e36b304f87,,,,,
https://news.google.com/rss/articles/CBMiRWh0dHBzOi8vaGJyLm9yZy8yMDE4LzEyL3VzaW5nLWFpLXRvLWltcHJvdmUtZWxlY3Ryb25pYy1oZWFsdGgtcmVjb3Jkc9IBAA?oc=5,Using AI to Improve Electronic Health Records - Harvard Business Review,2018-12-13,Harvard Business Review,https://hbr.org,"Electronic health record systems for large, integrated healthcare delivery networks today are often viewed as monolithic, inflexible, difficult to use and costly to configure. As delivery networks grow and deploy broad enterprise EHR platforms, the challenge of making them help rather than hinder clinicians is increasing. A promising approach is to use AI to make existing EHR systems more flexible and intelligent. Some delivery networks are making strides in this direction, using AI to assist with data extraction from free text, clinical documentation and data entry, and clinical decision support. Ultimately, AI should help doctors tailor EHRs to their specific needs and work styles making them easier to use and more valuable in the care process. That could help reduce clinician burnout and improve patient outcomes.",,"Electronic health record systems for large, integrated healthcare delivery networks today are often viewed as monolithic, inflexible, difficult to use and costly to configure. As delivery networks grow and deploy broad enterprise EHR platforms, the challenge of making them help rather than hinder clinicians is increasing. A promising approach is to use AI to make existing EHR systems more flexible and intelligent. Some delivery networks are making strides in this direction, using AI to assist with data extraction from free text, clinical documentation and data entry, and clinical decision support. Ultimately, AI should help doctors tailor EHRs to their specific needs and work styles making them easier to use and more valuable in the care process. That could help reduce clinician burnout and improve patient outcomes.",,https://schema.org,,WebSite,,https://hbr.org/,,,,,,,,,,,Innovation,,,,,,"{'@type': 'SearchAction', 'target': 'https://hbr.org/search?term={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMinQFodHRwczovL3d3dy53YXNoaW5ndG9ucG9zdC5jb20vdGVjaG5vbG9neS8yMDE4LzEyLzEyL2dvb2dsZS1jZW8tc3VuZGFyLXBpY2hhaS1mZWFycy1hYm91dC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hcmUtdmVyeS1sZWdpdGltYXRlLWhlLXNheXMtcG9zdC1pbnRlcnZpZXcv0gEA?oc=5,"Google CEO Sundar Pichai: Fears about artificial intelligence are 'very legitimate,' he says in Post interview - The Washington Post",2018-12-12,The Washington Post,https://www.washingtonpost.com,"Speaking with The Washington Post after his first testimony to Congress, Pichai said that new AI tools — the backbone of such innovations as driverless cars and disease-detecting algorithms — require companies to set ethical guardrails and think through how the technology can be abused.","google, alphabet, sundar pichai, house judiciary committee, congress, artificial intelligence, ai, privacy, security, dragonfly, china, maven, pentagon, defense department, drones, microsoft, ibm, bias, ethics, weapons","Speaking with The Washington Post after his first testimony to Congress, Pichai said that new AI tools — the backbone of such innovations as driverless cars and disease-detecting algorithms — require companies to set ethical guardrails and think through how the technology can be abused.","Speaking with The Washington Post after his first testimony to Congress, Pichai said that new AI tools — the backbone of such innovations as driverless cars and disease-detecting algorithms — require companies to set ethical guardrails and think through how the technology can be abused.",https://schema.org,,BreadcrumbList,"Google CEO Sundar Pichai: Fears about artificial intelligence are ‘very legitimate,’ he says in Post interview",,https://www.washingtonpost.com/technology/2018/12/12/google-ceo-sundar-pichai-fears-about-artificial-intelligence-are-very-legitimate-he-says-post-interview/,,,,"[{'@type': 'Person', 'name': 'Tony Romm', 'url': 'https://www.washingtonpost.com/people/tony-romm/'}, {'@type': 'Person', 'name': 'Drew Harwell', 'url': 'https://www.washingtonpost.com/people/drew-harwell/'}, {'@type': 'Person', 'name': 'Craig Timberg', 'url': 'https://www.washingtonpost.com/people/craig-timberg/'}]",,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}",,2018-12-12T23:06:29.839Z,2018-12-13T03:01:08.435Z,The Switch - OLD,,"ShareComment on this storyComment24Add to your saved storiesSaveGoogle chief executive Sundar Pichai, head of one of the world’s leading artificial intelligence companies, said in an interview this week that concerns about harmful applications of the technology are “very legitimate” — but the tech industry should be trusted to responsibly regulate its use.Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeSpeaking with The Washington Post on Tuesday afternoon, Pichai said that new AI tools — the backbone of such innovations as driverless cars and disease-detecting algorithms — require companies to set ethical guardrails and think through how the technology can be abused.“I think tech has to realize it just can’t build it and then fix it,” Pichai said. “I think that doesn’t work.” Story continues below advertisementTech giants have to ensure artificial intelligence with “agency of its own” doesn't harm humankind, Pichai said. He said he is optimistic about the technology's long-term benefits, but his assessment of the potential risks of AI parallels some tech critics, who contend the technology could be used to empower invasive surveillance, deadly weaponry and the spread of misinformation. Other tech executives, like SpaceX and Tesla founder Elon Musk, have offered more dire predictions that AI could prove to be “far more dangerous than nukes.” AdvertisementGoogle’s AI technology underpins everything from the company’s controversial China project to the surfacing of hateful, conspiratorial videos on its YouTube subsidiary — a problem Pichai promised to address in the coming year. How Google decides to deploy its AI has also sparked recent employee unrest.💻Follow TechnologyFollowPichai’s call for self-regulation followed his testimony in Congress, where lawmakers threatened to impose limits on technology in response to its misuse, including as a conduit for spreading misinformation and hate speech. His acknowledgment about the potential threats posed by AI was a critical assertion because the Indian-born engineer often has touted the world-shaping implications of automated systems that could learn and make decisions without human control.Two years after #Pizzagate showed the dangers of hateful conspiracies, they’re still rampant on YouTubePichai said in the interview that lawmakers around the world are still trying to grasp AI’s effects and the potential need for government regulation. “Sometimes I worry people underestimate the scale of change that’s possible in the mid- to long term, and I think the questions are actually pretty complex,” he said. Other tech giants, including Microsoft, recently have embraced regulation of AI — both by the companies that create the technology and the governments that oversee its use.AdvertisementStory continues below advertisementBut AI, if handled properly, could have “tremendous benefits,” Pichai explained, including helping doctors detect eye disease and other ailments through automated scans of health data. “Regulating a technology in its early days is hard, but I do think companies should self-regulate,” he said. “This is why we've tried hard to articulate a set of AI principles. We may not have gotten everything right, but we thought it was important to start a conversation.” Pichai, who joined Google in 2004 and became chief executive 11 years later, in January called AI “one of the most important things that humanity is working on” and said it could prove to be “more profound” for human society than “electricity or fire.” But the race to perfect machines that can operate on their own has rekindled familiar fears that Silicon Valley’s corporate ethos — “move fast and break things,” as Facebook once put it — could result in powerful, imperfect technology eliminating jobs and harming people.Within Google, its AI efforts also have created controversy: The company faced heavy criticism earlier this year because of its work on a Defense Department contract involving AI that could automatically tag cars, buildings and other objects for use in military drones. Some employees resigned because of what they called Google’s profiting off the “business of war."" AdvertisementStory continues below advertisementAsked about the employee backlash, Pichai told The Post that its workers were “an important part of our culture.” “They definitely have an input, and it’s an important input, it’s something I cherish,” he said.In June, after announcing Google wouldn’t renew the contract next year, Pichai unveiled a set of AI-ethics principles that included general bans on developing systems that could be used to cause harm, damage human rights or aid in “surveillance violating internationally accepted norms."" The company faced criticism for releasing AI tools that could be misused in the wrong hands. Google’s release in 2015 of its internal machine-learning software, TensorFlow, has helped accelerate the wide-scale development of AI, but it has also been used to automate the creation of lifelike fake videos that have been used for harassment and disinformation.AdvertisementStory continues below advertisementGoogle and Pichai have defended the release by saying that keeping the technology restricted could lead to less public oversight and prevent developers and researchers from improving its capabilities in beneficial ways.“Over time, as you make progress, I think it’s important to have conversations around ethics [and] bias and make simultaneous progress,” Pichai said during his interview with The Post.“In some sense, you do want to develop ethical frameworks, engage non-computer scientists in the field early on,” he said. “You have to involve humanity in a more representative way because the technology is going to affect humanity.” Pichai likened the early work to set parameters around AI to the academic community’s efforts in the early days of genetics research. “Many biologists started drawing lines on where the technology should go,” he said. “There's been a lot of self-regulation by the academic community, which I think has been extraordinarily important.” Google CEO Sundar Pichai emerges ‘unscathed’ from the circus in WashingtonThe Google executive said it would be most essential in the development of autonomous weapons, an issue that’s rankled tech executives and employees. In July, thousands of tech workers representing companies including Google signed a pledge against developing AI tools that could be programmed to kill.AdvertisementStory continues below advertisementPichai also said he found some hateful, conspiratorial YouTube videos described in a Post story Tuesday “abhorrent” and indicated that the company would work to improve its systems for detecting problematic content. The videos, which together had been watched millions of times on YouTube since appearing in April, discussed baseless allegations that Democrat Hillary Clinton and her longtime aide Huma Abedin had attacked, killed and drank the blood of a girl.Pichai said he had not seen the videos, which he was questioned about during the congressional hearing, and declined to say whether YouTube’s shortcomings in this area were a result of limits in the detection systems or in policies for evaluating whether a particular video should be removed. But he added, “You’ll see us in 2019 continue to do more here.” Pichai also portrayed Google’s efforts to develop a new product for the government-controlled Chinese Internet market as preliminary, declining to say what the product might be or when it would come to market — if ever.AdvertisementStory continues below advertisementDubbed Project Dragonfly, the effort has caused backlash among employees and human rights activists who warn about the possibility of Google assisting government surveillance in a country that tolerates little political dissent. When asked whether it’s possible that Google might make a product that allows Chinese officials to know who searches for sensitive terms, such as the Tiananmen Square massacre, Pichai said it was too soon to make any such judgments.“It’s a hypothetical,” Pichai said. “We are so far away from being in that position.” Share24 CommentsNewsletterAs news breaksTech News AlertsBreaking news email alerts on technology and the tech industry.Sign upSubscribe to comment and get the full experience. Choose your plan →","[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}, {'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'The Switch - OLD', 'position': 2, 'item': 'https://www.washingtonpost.com/technology/the-switch/'}]",,,,,,,,,,,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,False,,,,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvdG9tdmFuZGVyYXJrLzIwMTgvMTIvMTIvd2hhdC1rLTEyLXN0dWRlbnRzLXNob3VsZC1rbm93LWFib3V0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,What K-12 Students Should Know About Artificial Intelligence - Forbes,2018-12-12,Forbes,https://www.forbes.com,"Artificial intelligence (AI) is the most important change force in modern society, but it remains common for high school graduate to know nothing about how it works, the opportunities it creates and what we need guard against.",,"Artificial intelligence (AI) is the most important change force in modern society, but it remains common for high school graduate to know nothing about how it works, the opportunities it creates and what we need guard against.","Artificial intelligence (AI) is the most important change force in modern society, but it remains common for high school graduate to know nothing about how it works, the opportunities it creates and what we need guard against.",http://schema.org,,BreadcrumbList,What K-12 Students Should Know About Artificial Intelligence,https://www.forbes.com/sites/tomvanderark/2018/12/12/what-k-12-students-should-know-about-artificial-intelligence/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/tomvanderark/files/2018/12/Forbes-1.png?format=png&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",Education,"{'@type': 'Person', 'name': 'Tom Vander Ark', 'url': 'https://www.forbes.com/sites/tomvanderark/', 'description': ""I am an advocate for better learning for everyone. As CEO of Getting Smart, I advise schools, districts, networks, foundations and learning organizations on the path forward. I've written or co-authored more than 50 books and papers including Getting Smart, Smart Cities, Smart Parents, Better Together, and The Power of Place. I served as a public school superintendent and the first Executive Director of Education for the Bill & Melinda Gates Foundation. I serve on the boards of nonprofits including Education Board Partners, 4.0 Schools, Digital Learning Institute, eduInnovation and advise One Stone, Teton Science Schools, Whittle School & Studios, and Mastery Transcript Consortium."", 'sameAs': ['https://www.twitter.com/@tvanderark']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2018-12-12T05:00:00-05:00,2018-12-15T00:05:09-05:00,Education,,"More From ForbesJul 13, 2024,07:35pm EDTWhat Does Project 2025 Actually Plan For Education?Jul 12, 2024,05:40pm EDTEducation Freedom Not In The Presidential Debate But In The StatesJul 12, 2024,08:34am EDTCal Poly Humboldt President To Resign Months After Protests, No Confidence VoteJul 12, 2024,06:00am EDTThe Supreme Court Puts An End To Higher Education Regulatory WhiplashJul 11, 2024,01:23pm EDTNSF Making Huge Investment In New Computing Center Led By University Of TexasJul 11, 2024,06:59am EDTNew Jersey  Considers Bill That Would Cap College TuitionJul 10, 2024,10:48am EDTTrust In News And Government Has Plummeted, And That’s Good For TrumpEdit StoryForbesLeadershipEducationWhat K-12 Students Should Know About Artificial IntelligenceTom Vander ArkContributorOpinions expressed by Forbes Contributors are their own.I write about the future of learning, work and human development.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 12, 2018,05:00am ESTUpdated Dec 15, 2018, 12:05am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







Amon Millner, Olin College
Tom Vander Ark





Machines that learn are reshaping lives and livelihoods. Artificial intelligence (AI) is the most important change force in modern society, but it remains common for high school graduates to know nothing about how it works, the opportunities it creates and what we need guard against. 

In May, the Association for the Advancement of Artificial Intelligence (AAAI) and the Computer Science Teachers Association (CSTA) launched the AI for K-12 Working Group (AI4K12) to define for artificial intelligence what students should know and be able to do.  The AI4K12 steering committee includes David Touretzky, Carnegie Mellon; Christina Gardner-McCune, University of Florida; Fred Martin, University of Massachusetts; and Deborah Seehorn, CSTA Curriculum Committee. 
With lots of input, the steering committee drafted five big ideas that every student should know. A summary of the report (available here) they will present at the AAAI conference in January follows. 
PROMOTED
Big Idea #1: Computers perceive the world using sensors. The ability of computers to “see” and “hear” well enough to be practically useful is one of the most significant achievements of AI. Students should understand that machine perception of spoken language or visual imagery requires extensive domain knowledge. Graduates should be able to identify and demonstrate the limitations of machine perception systems and use open machine learning tools to train perceptual classifiers.

Big Idea #2: Agents maintain models/representations of the world and use them for reasoning. Representation is one of the fundamental problems of intelligence, both natural and artificial. Students should understand the concept of a representation--the way a map represents a territory, or a diagram represents a board game. Students should further understand that computers construct representations using data, and these representations can be manipulated by applying reasoning algorithms that derive new information from what is already known. High school students should be able to make use of elementary data structures to program simple inference algorithms.
Big Idea #3: Computers can learn from data. Machine learning algorithms allow computers to create their own representations using training data that is either supplied by people or acquired by the machine itself. High school students should be able to train a network and code simple applications using open tools.









CxO
US


CEO: C-suite news, analysis, and advice for top decision makers right to your inbox.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the CEO newsletter!


                More Newsletters
            


You’re all set! Enjoy the CEO newsletter!

                More Newsletters
            



Big Idea #4: Making agents interact naturally with humans is a substantial challenge for AI developers. Understanding people is one of the hardest problems faced by intelligent agents. Inferring a person’s future intentions by observing their actions is challenging even for humans. Robots will need to acquire some of this skill if they are to be welcome in our lives. High school students should be able to construct context-free grammars to parse simple languages and use open tools to construct a chatbot. They should also be able to use sentiment analysis tools to extract emotional tone from text.
Big Idea #5: AI applications can impact society in both positive and negative ways. Students should be able to identify ways that AI is contributing to their lives. The societal impacts of AI involve two kinds of questions: what applications should AI be used for and what ethical criteria should AI systems be required to meet?
Students should understand that the ethical construction of AI systems that make decisions affecting people’s lives requires attention to the issues of transparency and fairness.  High school students should be able to evaluate new AI technologies and describe the ethical or societal impact questions raised by them. AI4K12 will be developing guidelines but not curriculum. They plan to curate online resources for educators.Tom Vander ArkFollowingFollowI am an advocate for better learning for everyone. As CEO of Getting Smart, I advise schools, districts, networks, foundations and learning organizations on... Read MoreEditorial StandardsPrintReprints & Permissions","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Leadership', 'item': 'https://www.forbes.com/leadership/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Education', 'item': 'https://www.forbes.com/education/'}]",,What K-12 Students Should Know About Artificial Intelligence,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvYXJ0cy93aHktYXV0b21hdGlvbi13b250LXB1dC1hcnRpc3RzLW91dC1vZi13b3JrLWp1c3QteWV00gFaaHR0cHM6Ly93d3cucGJzLm9yZy9uZXdzaG91ci9hbXAvYXJ0cy93aHktYXV0b21hdGlvbi13b250LXB1dC1hcnRpc3RzLW91dC1vZi13b3JrLWp1c3QteWV0?oc=5,Why automation won’t put artists out of work just yet - PBS NewsHour,2018-12-14,PBS NewsHour,https://www.pbs.org,"Creative fields are often held up as careers that are least threatened by the advancement of artificial intelligence. But computers and robots have already proven they can contribute to and change the arts, especially in commercial ways.",,"Creative fields are often held up as careers that are least threatened by the advancement of artificial intelligence. But computers and robots have already proven they can contribute to and change the arts, especially in commercial ways.","Creative fields are often held up as careers that are least threatened by the advancement of artificial intelligence. But computers and robots have already proven they can contribute to and change the arts, especially in commercial ways.",,,,,,,,,,,,,,,,Arts,,"






Full Episode










Monday, Jul 15


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmM0aXNybmV0LmNvbS9pdC1uZXR3b3Jrcy8yMDE4LzEyLzEzL3Jpc2Utb2YtdGhlLW1hY2hpbmVzLXRoZS1wZW50YWdvbnMtYWktd29ya2ZvcmNlLXBsYW4v0gEA?oc=5,Rise of the machines: The Pentagon's AI workforce plan - C4ISRNET,2018-12-13,C4ISRNET,https://www.c4isrnet.com,The Department of Defense is trying to build artificial intelligence proficiency in its future workforce to maintain an edge on competitor nations.,"['artificial-intelligence', 'dod-ai', 'joint-artificial-intelligence-center', 'cio', 'artificial-intelligence', 'DoD-AI', 'Joint-Artificial-Intelligence-Center', 'CIO', 'circulated-c4isrnet']",The Department of Defense is trying to build artificial intelligence proficiency in its future workforce to maintain an edge on competitor nations.,,http://schema.org,,NewsArticle,Rise of the machines: The Pentagon’s AI workforce plan,https://www.c4isrnet.com/it-networks/2018/12/13/rise-of-the-machines-the-pentagons-ai-workforce-plan/,"{'type': 'WebPage', '@id': 'https://www.c4isrnet.com/it-networks/2018/12/13/rise-of-the-machines-the-pentagons-ai-workforce-plan/'}",,"{'url': 'https://www.c4isrnet.com/resizer/exXwFLXKE9C7KFYFyPgjLi77itM=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/L2HNRYXSSRBQDCLG2A7HQPLCH4.jpg', '@type': 'ImageObject'}",IT and Networks,"[{'@type': 'Person', 'name': 'Mark Pomerleau'}]",,"{'@type': 'Organization', 'name': 'C4ISRNet', 'url': 'https://www.c4isrnet.com/', 'logo': {'@type': 'ImageObject', 'url': '/resources/img/c4isrnet-logo-white.png?d=124'}}",,2018-12-13T20:31:01.639Z,2022-08-18T04:21:24.879Z,IT and Networks,,"The Department of Defense is looking to build a 21st century military staffed with a cadre of resident data scientists, engineers and artificial intelligence professionals.Dana Deasy, the DoD’s chief information officer, told a House Armed Services Committee panel Dec. 11 that the department’s philosophy is they’re going to need to build an internal capability inside the military.RELATEDThe Pentagon wants to enlist AI to protect AIIn testimony before a House subcommittee, leaders from the Pentagon's research wing discussed what it will take to maintain an edge in artificial intelligence.By Kelsey D. AthertonThis takes the form of the recently established Joint Artificial Intelligence Center (JAIC), which currently has approximately 30 people assigned to it — a combination of uniformed and civilian personnel, Deasy said.He added that the plan to help build resident expertise is to bring 10 highly talented individuals from the services into the JAIC and team them with data scientists DoD is recruiting, so when they leave JAIC they can bring knowledge in new areas back to their respective services.RELATEDNow the Air Force has an artificial intelligence teamThe service recently stood up a cross functional team for AI.By Mark PomerleauDeasy also discussed a parallel track in which DoD is looking to recruit people through a combination of commercial, academia and think tank contacts, noting that they have “quite a list” of people they’re identifying.Ultimately, however, he said the department might need something similar to the Cyber Excepted Service — a specialized personnel system designed with certain flexibilities for hiring much-needed cyber professionals — but for data science and AI.This model will allow DoD to recruit in a way that has additional speed, but comes with hurdles such as handling compensation for employees differently, as well as how to onboard new recruits under such a model.Is the U.S. behind?One of the top contentions of many experts in the field is that the United States is either at the cusp of, if not already behind top nations, such as China, in the AI arms race.One top DoD official explained the United States is still ahead, but the race is getting closer.“I would say we are not behind. Right now we are actually ahead; however, we are in danger of losing that leadership position,” Lisa Porter, deputy undersecretary of defense for research and engineering, told the House panel.Porter said the U.S. government has invested in this space for decades, with recent large scale investment coming from the private sector.Now, China has recognized the importance of this multi-tiered approach, she said, accounting for the tremendous increases in their investments, particularly in academia and the startup community.About  Mark PomerleauMark Pomerleau is a reporter for C4ISRNET, covering information warfare and cyberspace.Share:More In IT and NetworksSouth Korea to deploy laser weapons to intercept North Korean dronesThe Defense Acquisition Program Administration said it will deploy at least one anti-air laser weapons system — called “Block-I” — this year.US to send Tomahawks, hypersonics, other long-range fires to GermanyThe move is in-line with the Army's plan to provide such capability to its Multidomain Task Force there.Beavers takes reins from Sherman as acting DOD information officerAs the most senior IT advisor to the secretary of defense, Beavers is taking over from former CIO John Sherman.Quieting Discord: A new frontier in military leaks and extremismFrom secret Pentagon leaks to radicalization in the military community, Discord is continuing to grapple with keeping bad actors off the popular platform.Astronauts say Boeing space capsule can safely return them to EarthNASA test pilots Butch Wilmore and Suni Williams launched aboard Starliner capsule early last month.",,,C4ISRNet,,/resources/img/c4isrnet-logo-white.png,"['https://www.facebook.com/https://www.facebook.com/C4ISRNet', 'https://twitter.com/c4isrnet']",,,,,,,,,,,,,,https://www.c4isrnet.com/#publisher,,,,https://www.c4isrnet.com/it-networks/2018/12/13/rise-of-the-machines-the-pentagons-ai-workforce-plan/,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LnRla2VkaWEuY29tL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFuZC10aGUtZnV0dXJlLW9mLWxhdy1wcmFjdGljZS1pbi1hZnJpY2ExL9IBAA?oc=5,Artificial Intelligence and the Future of Law Practice in Africa - Tekedia,2018-12-16,Tekedia,https://www.tekedia.com,,,"Artificial Intelligence and the Future of Law Practice in Africa[1] by Ademola Adeyoju [You can download this work here [PDF] Introduction A revolution is coming. And none of us can stop or resist it. Like a nuclear Armageddon, it will sweep the length and breadth of entire industries; it will change the way we live and […]",,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/', 'url': 'https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/', 'name': 'Artificial Intelligence and the Future of Law Practice in Africa - Tekedia', 'isPartOf': {'@id': 'https://www.tekedia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/#primaryimage'}, 'image': {'@id': 'https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/#primaryimage'}, 'thumbnailUrl': 'https://tkcdn.tekedia.com/wp-content/uploads/2018/12/06171715/AL-Legal.jpg', 'datePublished': '2018-12-16T12:19:50+00:00', 'dateModified': '2023-06-12T19:27:28+00:00', 'author': {'@id': 'https://www.tekedia.com/#/schema/person/d22ad5a5db9b7e570be9bd0abe4373d2'}, 'breadcrumb': {'@id': 'https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/#primaryimage', 'url': 'https://tkcdn.tekedia.com/wp-content/uploads/2018/12/06171715/AL-Legal.jpg', 'contentUrl': 'https://tkcdn.tekedia.com/wp-content/uploads/2018/12/06171715/AL-Legal.jpg', 'width': 1200, 'height': 500}, {'@type': 'BreadcrumbList', '@id': 'https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.tekedia.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence and the Future of Law Practice in Africa'}]}, {'@type': 'WebSite', '@id': 'https://www.tekedia.com/#website', 'url': 'https://www.tekedia.com/', 'name': 'Tekedia', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.tekedia.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.tekedia.com/#/schema/person/d22ad5a5db9b7e570be9bd0abe4373d2', 'name': 'Guest Author', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.tekedia.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/edc86adbf931b80093503f0b831b2a8d?s=96&d=identicon&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/edc86adbf931b80093503f0b831b2a8d?s=96&d=identicon&r=g', 'caption': 'Guest Author'}, 'url': 'https://www.tekedia.com/author/guestauthor/'}]",BreadcrumbList,,,,,,,,,,,,,,,"


Latest Insights | News





                        Artificial Intelligence and the Future of Law Practice in Africa                    




December 16, 2018

|
                    by			
                    Guest Author
|
6 













Artificial Intelligence and the Future of Law Practice in Africa[1]
by Ademola Adeyoju
[You can download this work here [PDF]
Tekedia Mini-MBA edition 15 (Sept 9 – Dec 7, 2024) has started registrations; register today for early bird discounts.
Tekedia AI in Business Masterclass opens registrations here.
Join Tekedia Capital Syndicate and invest in Africa’s finest startups here.


Introduction
A revolution is coming.
And none of us can stop or resist it. Like a nuclear Armageddon, it will sweep the length and breadth of entire industries; it will change the way we live and work, alter the current course of our existence, and usher in a new era—the fourth industrial revolution.
After steam, electricity, and computing, the age of deep digital transformation—fuelled by incredible advances in technology—is now upon us; we stand on the threshold of vast changes. These changes will be, in scope and scale, unlike anything humankind has experienced before.[2] And of the technologies that will materially impact our lives, artificial intelligence (AI) is a prime candidate.[3]
Currently, about 6.4bn sensors are connected to the internet; and there are about 4.6bn mobile users, 3.4bn internet users, and 2.3bn social medial users.[4] It is this exploding volume of data and the ability to harness them that is primarily driving AI research and development.
By themselves, the four major cloud-service provider (CSP): Amazon, Microsoft, IBM and Google have more than $1 billion in investments and has over 200,000 servers in over a million square feet of space. And it is estimated that global spending on AI will grow 50 percent compounded annually and will reach $57.6 billion by 2021.
What really is “artificial intelligence”?
First, let me tell you what artificial intelligence (AI) is not.
It is not all about robots. Machine control (robotics and autonomous machines) is just one aspect of AI research. Other areas include machine learning (deep, supervised, unsupervised, reinforcement and large scale machine learning) and machine perception (computer vision, speech recognition, natural language processing, Internet of Things)[5]
Also, it is not our final invention—Terminator is a good, futuristic movie but smart robots won’t kill us all. Well, not probably.
Put simply, artificial intelligence is intelligence displayed by machines, in contrast to the natural intelligence displayed by humans and other animals.[6] In the words of John McCarthy—the man who coined the term ‘artificial intelligence’—AI is the “science and engineering of making intelligent machines”. The term is also used to denote machines that could use cognitive computing capabilities to mine data, decipher trends and pattern, and machines with the “ability to reason, discover meaning, generalize, or learn from past experiences”[7]
In what was a giant step for computerkind and a depressing day for mankind, Deep Blue—a chess-playing AI that could scan 200 million positions per second and analyse 74 moves ahead—shocked the world when it made history by outmaneuvering Gary Kasparov, a chess world champion who, at 22, was eating other grandmasters for breakfast and who had never lost to a human opponent.
Fast forward two decades later and Alpha Zero—a machine that rediscovered thousands of years of human knowledge and highly strategic moves and then invented better moves of its own—was unveiled. By playing itself a million times over, the machine achieved a superhuman level in just hours. And what’s really shocking was the fact that the machine did all of this without human expertise, data, or knowledge!
In another ‘Man vs Machine battle’, the Case Cruncher Alpha beat its human counterparts in a competition where the legal AI was pitted against 100 commercial lawyers given factual scenarios of hundreds of cases and asked to predict the success of the claim. Case Cruncher achieved 86 percent accuracy and won by over 20 percent.
Right. There’s such thing as legal AI.
The world’s first AI lawyer, ROSS, reads through thousands of cases and delivers a ranked list of the most relevant ones, helps lawyers to analyze legal issues and make connections that would otherwise be invisible. It even writes legal memo like actual humans!
Clever software tools like Ravel Law and Lex Machina predict the attitude and workings of a judge, the usual moves of opposing counsel, and the possible outcomes of cases by using large volume of litigation information, court decisions, filing data, and legal processes.
Also, AI-powered platforms such as Kira Systems, helps analyze documents and uncover trends and patterns. A legal analytics firm, Premonition AI, provides information on the effectiveness of litigators before particular judges by mining what it claims is the biggest litigation database in the world. Seal Software can crawl through a network to discover, and then classify, all of a company’s existing contracts and KM Standards can “identify common clauses, agreement structure, standard clause language, and common clause alternatives” in a set of contracts. Indeed, there are now AI-powered programs that help judges review criminal records, help evaluate the gravity and frequency of offences, and assist in sentencing.
AI would anchor many areas of legal practice (souce: law)
For many reasons, interests in artificial intelligence have spiked, conversations are growing, and the impact of AI is being widely recognized, even in a heel-dragging, precedent-based profession like law.
Artificial Intelligence and Law: David and Goliath
Law is the only self-regulated profession on earth. It has not changed much since the industrial revolution.
It enjoys substantial immunity from outside challengers, particularly in comparison to other professions.[8] This immunity is safeguarded by the enactment of protectionist professional rules and guidelines which govern civility, ethics, and protect lawyers from overthrow.[9] But it appears very likely that law—though shielded by regulations and imbued in tradition—might not be able to withstand the sweeping influence of the digital revolution for long. “Carefully erected protections sheltering the legal profession from disruption is now being eroded”,[10] and the foundation of the monopoly over legal work and the ‘practice of law’ is beginning to crumble.
Traditionally and historically, only lawyers can legally engage in the practice of law. But things are beginning to change. In the landmark case of Lola v Skadden[11], the Court held that “tasks that could otherwise be performed entirely by a machine cannot be said to engage in the practice of law,” meaning that once some task can be entirely performed by a machine, that task can no longer be considered to be ‘the practice of law’. According to the Yale Journal of Law and Technology, “[t]he broader implications of this decision are threefold:

As machines evolve, they will encroach on and limit the tasks considered to be the “practice of law”;
Mechanistic tasks removed from the ‘practice of law’ may no longer be regulated by professional rules governing the legal field; and
To survive the rise of technology in the legal field, lawyers will need to adapt to a new ‘practice of law’ in which they will act as innovators, purveyors of judgment and wisdom, and guardians of fairness, impartiality, and accountability within the law.”[12]

Just as Salomon v Salomon[13] revolutionized corporate law, the decision in Lola v Skadden may soon spark a global trend. Predictions already abound. According to Deloitte, over 100,000 thousand jobs will be automated in the legal sector in the UK alone by 2025, and companies that fail to adopt AI are fated to be left behind. Law is no longer safe from AI. And a single rock from the agile and fluid AI’s sling may knock down the highly regulated, heavily armored, and greatly encumbered legal profession.
Analogically speaking, David may take out Goliath again.
The good news is: Some firms are already keeping up with the machines.
And why not? Machines work smarter, more efficiently, and more accurately than any human; they do ordinarily grueling and time-consuming tasks such as contract creation, management, and review in seconds; and they never get tired, never need caffeine to stay awake, and never ask for vacations!
Smart firms like Dentons are not simply trying to keep up, they are actually doing something. Apart from investing in legal technology startups, Dentons has also established an innovation and venture arm known as NextLaw Labs. According to the firm’s Chief Innovation Officer, “[our] industry is being disrupted, and we should do some of that [disruption] ourselves, not just be a victim of it.”[14] Also, law firms like Ashurst in Australia, Baker McKenzie in the United Kingdom are already incorporating AI into their services.[15]
The Future of Law Practice in Africa
While ‘AI’ remains a relatively unknown, and possibly even scary, term to many lawyers and professionals in Africa, it is comforting to know that some African firms like Bowmans, Webber Wentzel, and KTA Advocates have adopted AI to improve their legal services delivery.
Bowmans lead the way by some miles. In one of our correspondence, Celia Pienaar, the Legal Services Improvement Manager at Bowmans and Cathy Truter, Of Counsel and Project Head of AI implementation revealed to me that “Bowmans was one of the first firms to have adopted and rolled out an AI product in Africa, across six offices and four jurisdictions (Kenya, South Africa, Tanzania, and Uganda).” Sidestepping the hype around future use cases of AI, Bowmans focuses on real cases that would create immediate and tangible benefits. Commenting further, Celia said, “By streamlining the mundane, time-consuming tasks through the use of AI systems, [Bowmans] is able to free up [their] lawyers’ time to focus on high level tasks.” This is some serious pacesetting.
We now have, also, companies dedicated to advancing legal technologies. In 2016, Nigeria’s foremost legal technologies company, LawPavilion, launched LawPavilionPrime. The first of its kind in Africa, the AI “gives in-depth analysis of the strengths and weaknesses of legal positions and authorities by generating a never-before-seen statistical analysis, historical data, precedential value ratings, conflicting judgments, locus classicus, statutory or literary authorities and opinions.”[16] And now, the company has unveiled TIMI, Nigeria’s first artificial intelligence legal assistant. Apart from assisting lawyers with legal research, litigation, and opinion drafting, TIMI also provides notes with legal authorities and gives a step-by-step guide on drafting and filing court processes.
“In the past, the legal field has had time to carefully consider its adoption of technological innovations. This is no longer the case.”[17] “The time is rapidly approaching when many lawyers, professors, judges, managing partners, and other legal professionals will regret that they did not act before technology caught up, and surpassed, the legal profession”[18]
Are there limits to what these machines can do?             
The world is getting more curious by the second. White- and blue-collar jobs are under threat. And perhaps the most prevailing question now is: are there any limits to what machines can do?
Well, the truth is no one knows for sure. Not even the experts can say.
As Niel Bohrs once said: “Prediction is difficult, especially about the future”, and making efforts to see into the future is a fool’s errand. However, it suffices to say that, for now, there are certain limits. The AI technology that currently exists are ‘narrow’ or ‘weak’, in that they are designed to perform narrow or specific tasks, such as legal outcome prediction, contract review, and language translation. We still haven’t developed a general-purpose machine—or General AI—which is a notional future AI system, expected to outperform humans at nearly every cognitive task.[19]
“But it is impossible to deny that progress is being made, and rapidly too. First, it was said that the subtleties of chess would make it impossible for the then (human) champion to be beaten. Wrong. Then it was argued that the Chinese game of Go, far more complex than chess, would resist the rise of robots. Wrong again. And now artificial intelligence is creating debaters to take on modern-day Ciceros and give them a run for their money.”[20]
Should I be scared? Will AI Take Lawyers’ Jobs?
On a recent episode of The Daily Show, a young lawyer played by comedian (and law school graduate) Ronny Chieng, half-jokingly threatens in a satirical skit to sue the robots that stole his job. In the skit, Chieng’s case against legal robots goes to trial, but the jurors are robots and the judge is Amazon’s Alexa. Chieng’s opening statement reflects the struggles that attorneys may soon meet:
Your honor, members of the jury, this is about the essence of humanity itself, because unlike that thing [pointing to the legal robot] I went to law school—taught by humans. I spent countless, sleepless, nights, reading, writing, pondering [things]…, all things artificial intelligence can’t do, and quite frankly I’m sensing a lot of bias in this court room.[21]
Right. With the rise of AI comes the fear of job loss.
Indeed, concerns about computers taking over lawyers’ jobs go back to the 1950s when AI technology began to rise. But predictions of structural change in the legal industry date back at least to the invention of the typewriter. Yet the introduction of new technologies: word processing, e-mail, photocopying electronic filing system, automated document processing—once seen as threats to the legal profession—have actually helped lawyers prosper.
Emerging technologies like AI would have transformational impacts on Legal Practice (source: law)
But of course, AI is a different beast.
AI development is expected to continue its inspired, relentless match, leaving radical changes in its wake. The $600 billion global legal services market is not immune, and lawyers and law firms are not spared from this revolution. But it is not all gloom and doom, for, “many of these technologies are only able to complete a discrete task or a discrete portion of a legal project.  Attorneys still will be required to deliver the final product.”[22] More so, while routine tasks like documents review and management are prime candidates for automation, complex situations involving uncertain laws, conflicting rights, and unique fact patterns will remain difficult to be automated for an extended period of time.[23]
So even though intelligent software tools cut down the amount of time and money spent on certain tasks, and generally improves efficiency and accuracy, it is hard to imagine that machines will one day take over lawyers’ jobs. Au contraire, because legal services will become faster, cheaper and more consistent, demand for legal services might actually increase since more people will be able to afford legal representation.
Lawyers need not be afraid. “Despite advances in technology toward providing technical answers in some of these areas, clients still need lawyers to predict human reactions in ways that no computer can handle.”[24] And clients still need to engage with humans. As Celia succinctly puts it: the point is not to “create robot lawyers, but to take the robots out of the lawyer.” Even as data explodes and becomes easier to harness, and even as the rise of AI continues, lawyers need not tremble. After all, “data isn’t everything when it comes to decision-making [and lawyering]. Experience, intuition, hunches, imagination, and judgment all matter too.”[25] As Margaret Heffernan once observed, “artificial intelligence is unlikely to be the answer to genuine stupidity”.
What Can Lawyers Do To Survive The Rise of The Machines?
First off, lawyers need to stop seeing the rise of AI as a threat: instead, they should start to adapt. Adaptation in this case does not mean competing with AI—which would be a futile effort—but rather embracing its possibilities.[26] As I said at the beginning of this piece, although we cannot stop the revolution that is coming, we can adjust timely and reposition ourselves. Right. Lawyers and law firms should not wait for machines to take their jobs or their competitive edge. They should instead learn about how they can leverage AI, and see how they can turn a potential foe into a friend.
Again, lawyers must jettison their innate tendencies to resist change: they must innovate. In the face of imminent disruptions, lawyers and law firms should be willing to incorporate technological skills. It’s good to know that many African firms are already deploying cutting-edge technology in providing legal services. Apart from the likes of Bowmans and Webber Wentzel in South Africa, Nigerian firms like Aelex, Olaniwun Ajayi, and Infusion Lawyers—the country’s first fully virtual IP&IT law firm—have embraced the endless possibilities that technology has to offer.
“If other industries can successfully adopt AI, why not lawyers?”[27]
Lawyers must adjust their perspectives. As AI allows tasks to become automated, lawyers must appreciate the encroachment and impact of AI on the legal profession and must strategically reposition themselves. Those who fail to do this may suffer. Brick-and-mortar lawyers who earn their fees from protracting cases and from low-level document review and drafting of common legal documents like Deeds and Wills—tasks that AI can complete in seconds—will watch their practice slowly die.
The American Bar Association has already extended the lawyers’ ‘duty of competence’ beyond the knowledge of substantive law to a duty of technological competence. If America has done it, Africa will catch up soon.
Conclusion
The pace of technological advancement is unpredictable. Advances in artificial intelligence are overturning many assumptions—things once considered the stuff of science fiction are fast becoming a part of our reality.
Yet while jobs like legal research, case prediction, compliance, contract reviewing and drafting, precedent management and other routine and repetitive tasks, billing, secretarial and paralegal duties, etc., are under threat, “AI and legal tech cannot yet replicate the experience and creativity of a battle-hardened legal practitioner [and] legal jobs that require [the] ability to connect and work with other people are currently insulated from the onslaught of AI.”[28]
But one is almost immediately prompted to ask: for how long can this last?
In the long term, “some see computers continuing to double in power every two years, reaching levels of computing power by the 2020s that rival the human brain and that by the 2050s rival, in a single desktop machine, the power of all human brains combined. Given such vast increases in computational power, they see computers as besting humans at what lawyers do, which is to provide reliable, expert answers to difficult questions.”[29]
Steady increase in computing power, availability of large volume of data, the evolution of more effective algorithms, and access to capital, which has exploded in the last couple of years, with 200 AI startups raising $1.5 billion in equity funding[30] is driving the resurgence. And as the legal industry becomes more and more aware, “[c]ompetition in legal AI will be fierce over the next few years. Traditional law firms will compete for startups, non-traditional legal service providers like Thomson Reuters, and legal outsiders such as Bloomberg and PwC [will compete] for tech- and law-qualified staff and market share.”[31]
Businesses—including law firms and lawyers—must develop clear long-term strategy that envision new ways to use AI; they must find ways to deal with changing client demands. Or they risk being left behind. The future is uncertain and in many ways, unpredictable. Coming to terms with that and developing strategies to take advantage is key to success.”[32]
In many ways, AI “represents both the biggest opportunity and potentially the greatest threat to the legal profession since its formation.”[33]
 
[1] I wish to specially appreciate Professor Tanel Kerikmae, LL.M, LL.Lic, Ph.D, Professor of European Law, TalTech University, Celia Pienaar, the Legal Services Improvement Manager at Bowmans (the Firm),  and Cathy Truter, Of Counsel and Project Head of AI Implementation, Bowmans, for their brilliant contributions to this article. Thank you for your invaluable insights!
[2] Klaus Schwab, “The Fourth Industrial Revolution, Available at https://www.weforum.org/about/the/fourth-industrial-revolution-by-klaus-schwab/  Accessed 30 October 2018
[3] Richard Kemp, “Legal Aspects of Artificial Intelligence” KEMP IT LAW, November 2016
[4] see http://www.datacenterknowledge.com/special-report-the-worlds-largest-data-centers/(data centres)
[5] See Richard Kemp, supra, note 3
[6] https://en.m.wikipedia.org/wiki/Artificial_intelligence Accessed 1 November 2018
[7] “Artificial Intelligence”, Encyclopedia Britannica”, https://www.britannica.com/technology/artificial-intelligence. Accessed 1 November 2018
[8] Laurel A. Rigertas, The Legal Profession’s Monopoly: Failing to Protect Consumers, 82 FORDHAM L. REV. 2683, 2697 (2014).
[9] See Michael Simon, Alvin F. Lindsay, Loly Sosa & Paige Comparato, supra, note 3 at 257
[10] Michael Simon, Alvin F. Lindsay, Loly Sosa & Paige Comparato, “Lola v. Skadden and the Automation of the Legal Profession”, The Yale Journal of Law & Technology, Vol. 20
[11] Lola v. Skadden, Arps, Slate, Meagher & Flom, No. 14-3845 (2d Cir. 2015)
[12] ibid. pg, 234
[13] Salomon v A Salomon Co Ltd [1897] AC22, UKHL
[14] http://www.nytimes.com/2017/03/19/technology/lawyers-artificial-intelligence.html Accessed 28 November 2018
[15] Kenneth Muhangi, “Artificial Intelligence and the future of lawyering”, https://www.newvision.co.ug/new_vision/news/1480226/artificial-intelligence-future-lawyering Accessed 5 November 2018
[16] LawPavilion, ‘LawPavilion Launches the First Legal Analytics Software in Africa at the 56th Annual General Conference of the NBA In Port-Harcourt’, (2016). Available from: < http://lawpavilion.com/blog/lawpavilion-launches-the-first-legal-analytics-software-in-africa-at-the-56th-annual-general-conference-of-the-nba-in-port-harcourt/> Accessed 9 December 2018
[17] ibid. pg, 309
[18] Supra, note 11
[19] “Benefits and Risks of Artificial Intelligence” https://futureoflife.org/background/benefits-risks-of-artificial-intelligence
[20] “Don’t panic—the debating robots aren’t coming for our jobs yet”, <https:www.theguardian.com/commentisfree/2018/jun/20/debating-robots-jobs-ibm-project-debater-artificial-intelligence> Accessed 9 November 2018
[21] Ronny Chieng, Disrupting the Legal System with Robots, DAILY SHOW (Mar. 7, 2018), http://www.cc.com/video-clips/b27lei/the-daily-show-with-trevor-noah- disrupting-the-legal-system-with-robots [http://perma.cc/2L9S-NAM7].
[22] Brett M. Anders, Ana C. Shields, and Adi Elliot, “The Future of Work:  How Emerging Technologies, including Artificial Intelligence, are Transforming the Legal Profession” Jackson Lewis PC.
[23] Frank Pasquale & Glyn Cashwell, “Four Futures of Legal Automation”, UCLA Law Review Discourse, University of California School of Law.
[24] See Michael Simon, Alvin F. Lindsay, Loly Sosa & Paige Comparato, supra, note 3 at 307
[25] ibid.
[26] See Kenneth Muhangi, supra, note 9
[27] See Michael Simon, Alvin F. Lindsay, Loly Sosa & Paige Comparato, supra, note 3 at 291
[28] “Rage Against the Machines: Artificial Intelligence and the Future of Legal Practice”, Alexander Ross Davis, “http://insight.thomsonreuters.com.au/posts/artificial-intelligence-future-legal-practice Accessed 2 December 2018
[29] Ray Worthy Campbell, The Digital Future of the Oldest Information Profession 3 (Jan. 17, 2016), https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2716972 [https://perma.cc/VUV8 -UTWH].
[30] “Transforming the Legal Profession: The Impact and Challenges of Artificial Intelligence”, Siddharth Peter de Souza, http://www.digitalpolicy.org/transforming-legal-profession-impact-challenges-artificial-intelligence Accessed 9 November 2018
[31] ibid.
[32] Simon Harper “The Mindset of the Legal Profession” Top of the Bots: the LexisNexis perspective.
[33] Joanna Goodman, “Robots in Law: How Artificial Intelligence Is Transforming Legal Services” 3 (2016).
Share this:FacebookTwitterWhatsAppLinkedInEmailPrintLike this:Like Loading...

 



TAGS
featured





Previous article
The Bitcoin Age: Liberating Minds, and Accommodating Opposing Perspectives





Next article
My Song Today



Filed in:
Latest Insights | News




 


Guest Author







Share this post

Twitter
Facebook
Google+
LinkedIn
Pinterest
Email




","[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.tekedia.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.tekedia.com/category/insights/', 'name': 'Latest Insights | News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.tekedia.com/artificial-intelligence-and-the-future-of-law-practice-in-africa1/', 'name': 'Artificial Intelligence and the Future of Law Practice in Africa'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUGh0dHBzOi8vd3d3LmRpZ2l0YWxpbmZvcm1hdGlvbndvcmxkLmNvbS8yMDE4LzEyL2V2aWwtdnMtZ29vZC1haS1pbmZvZ3JhcGhpYy5odG1s0gEA?oc=5,Artificial Intelligence: Good Versus Evil (infographic) - Digital Information World,2018-12-14,Digital Information World,https://www.digitalinformationworld.com,"Artificial intelligence is only as great as we make it, and it has the potential to turn out good or to turn out evil. This infographic makes a strong case for AI ultimately being used for good.",,"Artificial intelligence is only as great as we make it, and it has the potential to turn out good or to turn out evil. This infographic makes a strong case for AI ultimately being used for good.",,https://schema.org,"[{'@type': 'NewsArticle', 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.digitalinformationworld.com/2018/12/evil-vs-good-ai-infographic.html'}, 'headline': 'Artificial Intelligence: Good Versus Evil (infographic)', 'description': ' Artificial intelligence  is the stuff of scary movies for some people. In 2001: A Space Odyssey, the AI system known as Hal frightened us a...', 'datePublished': '2018-12-14T19:48:00+05:00', 'dateModified': '2019-03-11T15:14:06+05:00', 'image': {'@type': 'ImageObject', 'url': 'https://lh3.googleusercontent.com/blogger_img_proxy/AEn0k_utcyRlm8EvH94-bDni7Q2-ZB9Xb7KyRRssFWwaXeyqsqOicyh1MPwpKYXUgqFtAJCoB9wPkamGx4IoATh_jyFiIA=w1200-h675-p-k-no-nu', 'height': 675, 'width': 1200}, 'author': {'@type': 'Person', 'name': 'Irfan Ahmad', 'url': 'https://www.blogger.com/profile/01699983436594895218'}, 'publisher': {'@type': 'Organization', 'name': 'Digital Information World', 'logo': {'@type': 'ImageObject', 'url': 'https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_2G7rZnwmyZTDMLFoY-riJL0i1M8mrCeMuoh49crmbIg85m29MrYPmPukirz-B7Cr9oHirJvr-Sq7FcQW5vpQxtGdoZDCFxeHphbeU0uSuBl5kKuG-JF5QilaaloAH-QVs0zNBib5ub7VFixG30fqmfQbQr5z9MGrcJ_V5GfVVevCiRTeOpnvy7Ii/s200/digital-information-world-logo.png', 'width': 206, 'height': 60}}}, {'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.digitalinformationworld.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'AI', 'item': 'https://www.digitalinformationworld.com/search/label/AI'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial Intelligence: Good Versus Evil (infographic)', 'item': 'https://www.digitalinformationworld.com/2018/12/evil-vs-good-ai-infographic.html'}]}]",,,,,,,,,,,,,,,,"



Artificial Intelligence: Good Versus Evil (infographic)







Irfan Ahmad


12/14/2018 07:48:00 PM










Artificial intelligence is the stuff of scary movies for some people. In 2001: A Space Odyssey, the AI system known as Hal frightened us all by calmly saying, “I’m sorry, Dave, I can’t let you do that,” which made us question whether giving a computer that much power over our lives was a worthwhile endeavour.  Despite the reasonable caution we feel toward AI, in many ways it is already changing our lives for the better. Artificial intelligence is what you make of it, and if we as a society can agree to use it as a force for good there’s no limit to the positive impact it can make on humanity.

AI Breaks Bad
As the old saying goes, garbage in, garbage out. We’ve seen several attempts at training AI go awry in recent years that can all be traced back to our own imperfections as the human programmers of this technology. AI-driven Twitter bots have been turned into racists within days of being released onto the internet, while AI-driven predictive algorithms used to predict crime have been shown to adopt racial profiling. Rather than being the neutral and dispassionate fair-minded equalizers we want them to be, they instead take on our own flaws when we program them.

There’s also a great deal of fear about what will happen to humans when artificial intelligence takes over our careers. Currently it is predicted that AI will take over 38% of jobs by the mid-2030s, and 86% of executives say that workers will need to shift their skills sets in the future. These fears are similar to when automation took over things like farming and assembly lines at the turn of the century and people were unprepared to deal with the changing demands of the economic landscape.

AI Can Be A Great Force For Good
Those fears about losing your job to artificial intelligence may be unfounded, however. There are certain jobs that AI just cannot do, and keeping that in mind as you choose or retool your career path can help you stay ahead of the game. What’s more, as AI takes over certain jobs - the repetitive ones are going to be the first to go - it will free us up to gain even higher ground in terms of innovation. When the menial tasks are taken care of by machines, more human power can be freed up to achieve greater technological advances. 

Already AI has changed the face of healthcare through customized pharmaceutical treatments and highly accurate infectious disease model analysis. It has helped to improve road safety through predictive braking, lane monitoring, and more. There are even advancements being made in learning with the help of functional MRI studies that are being applied to how humans actually learn.

In the near future, artificial intelligence can be leveraged to solve some of our most pressing problems. Scientists are already looking to AI to help with predictive farming models that will enable us to use fewer resources to grow food in a more efficient manner. They are looking to AI to help make trucking more efficient in order to reduce greenhouse gas emissions. It can also help people with certain types of disabilities live more full and robust lives. AI can help blind people interact with their environments more deeply and it can help deaf people do the same.

Whether AI is used for good or for evil is truly up to us. What can this technology do in the right hands? And what if it falls into the wrong ones? Learn more about the good versus evil sides of AI from this infographic.






Tags:
AI
artificial-intelligence
news
Technology




Facebook
Twitter






",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS90aGUtaW52aXNpYmxlLXdvcmtlcnMtb2YtdGhlLWFpLWVyYS1jODM3MzU0ODFiYdIBAA?oc=5,The invisible workers of the AI era | by Maximilian GAHNTZ - Towards Data Science,2018-12-12,Towards Data Science,https://towardsdatascience.com,"Labeling data has emerged as new type of blue-collar job which powers AI — and with it, an entire industry has sprung up. We need to make sure that these workers are not overlooked.",,A new type of blue-collar industry has emerged around labeling the data that powers Artificial Intelligence.,A new type of blue-collar industry has emerged around labeling the data that powers Artificial Intelligence.,http://schema.org,,NewsArticle,The invisible workers of the AI era - Towards Data Science,https://towardsdatascience.com/the-invisible-workers-of-the-ai-era-c83735481ba,https://towardsdatascience.com/the-invisible-workers-of-the-ai-era-c83735481ba,,['https://miro.medium.com/v2/resize:fit:1200/1*9srAU7ky-z4D0l5gMj0wIQ.png'],,"{'@type': 'Person', 'name': 'Maximilian GAHNTZ', 'url': 'https://towardsdatascience.com/@oskarmaximilian.gahntz'}",['Maximilian GAHNTZ'],"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",2018-12-12T09:37:08.757Z,2018-12-12T09:37:08.757Z,2021-12-07T00:43:27.747Z,,,"Top highlightThe invisible workers of the AI eraA new type of blue-collar industry has emerged around curating the data that powers AIMaximilian GAHNTZ·FollowPublished inTowards Data Science·8 min read·Dec 12, 20183304ListenShareIn the early days of research on Artificial Intelligence, Frank Rosenblatt, a scientist at Cornell University in the United States, invented what he called the “perceptron”. The perceptron was an algorithm designed to classify objects it was shown and an ancestor of modern Artificial Intelligence. When Rosenblatt became a little boastful at a press conference in 1958, the New York Times picked up on it and went a little overboard with excitement. “NEW NAVY DEVICE LEARNS BY DOING; Psychologist Shows Embryo of Computer Designed to Read and Grow Wiser”, read the title of an article. And the author went on:The Navy said the perceptron would be the first non-living mechanism “capable of receiving, recognizing and identifying its surroundings without any human training or control”Does this tone sound familiar?Not a week goes by without news of new breakthroughs in Artificial Intelligence and of algorithms being able to complete tasks which were previously reserved to humans. There is plenty of talk these days about the automation of jobs and our new algorithmic overlords which get complicated tasks done with seemingly very little human involvement. This, however, is a fallacy — that we cannot see the humans behind AI does not mean that there are none. And this does not only apply to the engineers developing these algorithms. In fact, there is a new class of blue-collar jobs curating the data which is so critical to the functioning of the algorithms which are said to power our digitalized economy.It would not be the first time that we overlook the masses of people working hard to make technology work. Not much time has passed since “computers” were actually people, a substantial share of whom (underpaid) women, working on computations which have since been automated. Women were also among the first computer programmers, operating complex machines such as the one built to run Rosenblatt’s perceptron algorithm, yet overshadowed by the engineers of these first computers. Little attention was paid to these backroom workers of big technology firms, government agencies, and research labs at the time. Only recently, there has been an uptick in recognition of these workers, in academia but also, for example, in Hollywood. We should learn from history and not repeat these mistakes. To do so, we need to take a look at who the new hidden figures of technology are, what their job is, and why they are needed.A computing group at NASA’s Jet Propulsion Laboratory, circa 1955 (source: JPL/Caltech)Like a car without wheelsWhen people talk about AI these days, what they really mean is usually Machine Learning (ML). Most ML algorithms, in turn, are essentially statistical models which “learn” how to perform a particular task by analyzing large samples of data — “training data” — they were previously fed. Developers rely on these models because of what is referred to as “Polanyi’s paradox”: We know more than we can tell, that is. Much of our knowledge is tacit, which is why we can’t simply program it into software in the form of hard rules; no matter how trivial the task, to teach computer programs we need to show, or “train”, them. Thus, a very sophisticated, but untrained ML algorithm is like a sports car without wheels: it may still look nice, but it won’t get you anywhere — it’s essentially useless. Similarly, if you feed your ML model garbage training data, it will spit out garbage results.But what exactly is “training data”? Let’s say you run a blueberry muffin factory, but every once in a while a runaway dog from a nearby animal shelter accidentally jumps onto the conveyer built and your AI-powered packaging robot needs to differentiate between the muffins and the dogs so that no dog ends up on a grocery store shelf. For the robot to pull this off, it needs to be fed with a lot of pictures of muffins and dogs, and they need to be labeled accordingly so it can deduce their identifying characteristics. The same principle applies, for example, to self-driving cars (which need to be able to identify a stop sign, amongst other things) and most other AI applications.Chihuahua or muffin? Not that easy to tell for a machine without human supervision (source: Mariya Yao)This poses a problem for companies: How do they obtain labeled or annotated data? Even if they get their hands on large troves of data — such as photos (for image recognition algorithms), voice recordings (for speech recognition), or written text (for sentiment analysis) — labeling all this data is a tedious task, and one which needs to be completed by humans. It is work.50 ways to label dataThere are different ways to get your data labeled. Some firms label their data themselves — although this can be costly, as hiring people simply for these tasks costs firms both money and flexibility. Other companies even find ways to get people to label their data for free. Ever wonder why Google’s reCAPTCHA keeps asking you to identify traffic signs on blurry photos? (A small hint: Google’s holding company Alphabet also owns Waymo, which is at the forefront of autonomous driving) In most cases, however, it is paid workers who label and curate data and an entire outsourcing industry has sprung up around it. Be it in factory-like workplaces around the world or through remote work at home or on a smartphone: These are the invisible workers who power Artificial Intelligence.reCAPTCHA — everybody’s favorite pastime on the internetMuch like Western firms started offshoring manufacturing jobs to developing countries starting in the 1960s and 1970s, tech companies are outsourcing data labeling to foreign companies running what can be described as data labeling factories. And much like in the past, these jobs are moved to places — from China to Central Africa — where wages are low and working conditions more favorable for them. There, masses of workers in former warehouses and large open space offices sit in front of computers and spend their workdays labeling data. As Li Yuan quotes the co-founder of a Chinese data labeling company in a recent piece for the New York Times:We’re the construction workers in the digital world. Our job is to lay one brick after another […] But we play an important role in A.I. Without us, they can’t build the skyscrapers.Another way to outsource data labeling is through online crowdworking platforms, relying on their users completing tasks broken down into small components all around the world. This includes large platforms such as Amazon’s Mechanical Turk with its hundreds of thousands of registered crowdworkers, but also specialized platforms. Some large technology companies even have their own crowdworking platforms to curate data, others can rely on smaller platform services that focus exclusively on data labeling. Workers’ motivations for these jobs vary: some people want to make an extra buck in their spare time and value the flexibility such platforms offer. As one user of Spare5, a specialized data labeling app, explains in a promotional video:It’s just, you know, something I can easily do, just pull my phone out, do a few tasks, make a few dockets on the way home and to work. […] For me it’s a little bit rewarding knowing that I spent this time really digging deep, trying to find the information […] I feel like I am solving a mystery, solving this puzzle.Others, however, rely on these platform jobs for their livelihood and are oftentimes faced with substantial risks: low pay, no (or few) employment protections and employee rights, and along with that enormous uncertainty.The blue-collar job of the age of AITaking a step back, it becomes evident that a new type of low-skill, blue-collar job has emerged to satisfy technology’s appetite for labeled data. As opposed to doing physical assembly line work in the industrial economy, this new AI working class has become part of a digitalized “data supply chain”. Of course, not all of these jobs are low-skill — an algorithm detecting cancer on images from CT scans needs to be trained by experienced radiologists. But, in accordance with Polanyi’s paradox, most tasks researchers are trying to get ML applications to complete are still fairly simple for humans and training these algorithms requires little more than common sense.It is thus important to make sure that this new class of jobs becomes a driver of economic security for workers, not a source of exploitation. As for supply chains in more “traditional” global industries, such as mining or the clothing industry, it is on all of us — governments, consumers, and firms — to ensure that those who label data work under decent conditions.It will be difficult for governments to regulate work in this global, borderless market for data labeling services. Yet, they must strive to adapt existing institutions aimed at improving working conditions and to push companies to create fair data supply chains. Both crowdwork and work in data labeling factories pose different challenges in this respect, but none of these obstacles are insurmountable. Overcoming them does, however, require regulatory efforts as well as international and cross-sectoral cooperation. Firms, in turn, must offer some transparency regarding their data supply chains. And although first-world consumers still remain largely oblivious of the conditions under which their clothes and gadgets are manufactured in far-away places, we, too, should seek to hold tech companies accountable for the way they power their artificially intelligent applications. After all, consumers do have leverage and responsible consumption can have an impact on firms’ behavior.No matter how excited we get about the pace of technological progress, it is as important now as it was in the past to keep reminding ourselves that there are people behind most of the advances in AI we hear about day in and day out in the media — many of them, actually. And as ML researchers are looking for an ever-growing number of new tasks to be automated, these jobs are not going to go away soon. Let’s make sure they are decent jobs then.This article was written in the context of the course “History of the Technology Revolution” at Sciences Po Paris, taught by Laurène Tran, Besiana Balla, and Nicolas Colin.Further ReadingIf the above piqued your interest, here are some more articles exploring the same topic:Sarah Dai, AI promises jobs revolution but first it needs old-fashioned manual labour — from China, South China Morning Post, October 2018Mark Graham, The rise of the planetary labour market — and what it means for the future of work, The New Statesman, January 2018Hope Reese, Is ‘data labeling’ the new blue-collar job of the AI era?, TechRepublic, March 2016Hope Reese and Nick Heath, Inside Amazon’s clickworker platform: How half a million people are being paid pennies to train AI, TechRepublic, Dember 2016Tom Simonite, To Make AI Smarter, Humans Perform Oddball Low-Paid Tasks, Wired, September 2018Li Yuan, How Cheap Labor Drives China’s A.I. Ambitions, The New York Times, November 2018",,,The invisible workers of the AI era - Towards Data Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,c83735481ba,,,,,
https://news.google.com/rss/articles/CBMiggFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Jlcm5hcmRtYXJyLzIwMTgvMTIvMDMvNS1pbXBvcnRhbnQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcHJlZGljdGlvbnMtZm9yLTIwMTktZXZlcnlvbmUtc2hvdWxkLXJlYWQv0gEA?oc=5,5 Important Artificial Intelligence Predictions (For 2019) Everyone Should Read - Forbes,2018-12-03,Forbes,https://www.forbes.com,"Artificial intelligence (AI), machine learning and deep learning have made huge strides in 2018.  In this post we look at some of the key AI predictions for 2019, where is will be used, how it will make the biggest impact, as well as the key challenges we have to address.",,"Artificial intelligence (AI), machine learning and deep learning have made huge strides in 2018.  In this post we look at some of the key AI predictions for 2019, where is will be used, how it will make the biggest impact, as well as the key challenges we have to address.","Artificial intelligence (AI), machine learning and deep learning have made huge strides in 2018.  In this post we look at some of the key AI predictions for 2019, where is will be used, how it will make the biggest impact, as well as the key challenges we have to address.",http://schema.org,,BreadcrumbList,5 Important Artificial Intelligence Predictions (For 2019) Everyone Should Read,https://www.forbes.com/sites/bernardmarr/2018/12/03/5-important-artificial-intelligence-predictions-for-2019-everyone-should-read/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2018/12/AdobeStock_230414896-1200x676.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",Enterprise & Cloud,"{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2018-12-03T00:20:00-05:00,2018-12-14T11:29:30-05:00,Enterprise & Cloud,,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise Tech5 Important Artificial Intelligence Predictions (For 2019) Everyone Should ReadBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 3, 2018,12:20am ESTUpdated Dec 14, 2018, 11:29am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinArtificial Intelligence – specifically machine learning and deep learning – was everywhere in 2018 and don’t expect the hype to die down over the next 12 months.
The hype will die eventually of course, and AI will become another consistent thread in the tapestry of our lives, just like the internet, electricity, and combustion did in days of yore.

But for at least the next year, and probably longer, expect astonishing breakthroughs as well as continued excitement and hyperbole from commentators.








5 Important Artificial Intelligence Predictions (For 2019) Everyone Should Read
Adobe Stock





This is because expectations of the changes to business and society which AI promises (or in some cases threatens) to bring about go beyond anything dreamed up during previous technological revolutions.
PROMOTED
AI points towards a future where machines not only do all of the physical work, as they have done since the industrial revolution but also the “thinking” work – planning, strategizing and making decisions.

The jury’s still out on whether this will lead to a glorious utopia, with humans free to spend their lives following more meaningful pursuits, rather than on those which economic necessity dictates they dedicate their time, or to widespread unemployment and social unrest.
We probably won’t arrive at either of those outcomes in 2019, but it’s a topic which will continue to be hotly debated. In the meantime, here are five things that we can expect to happen:









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            




 AI increasingly becomes a matter of international politics

2018 has seen major world powers increasingly putting up fences to protect their national interests when it comes to trade and defense. Nowhere has this been more apparent than in the relationship between the world's two AI superpowers, the US and China.
In the face of tariffs and export restrictions on goods and services used to create AI imposed by the US Government, China has stepped up its efforts to become self-reliant when it comes to research and development.
Chinese tech manufacturer Huawei announced plans to develop its own AI processing chips, reducing the need for the country’s booming AI industry to rely on US manufacturers like Intel and Nvidia.
At the same time, Google has faced public criticism for its apparent willingness to do business with Chinese tech companies (many with links to the Chinese government) while withdrawing (after pressure from its employees) from arrangements to work with US government agencies due to concerns its tech may be militarised.
With nationalist politics enjoying a resurgence, there are two apparent dangers here.
Firstly, that artificial intelligence technology could be increasingly adopted by authoritarian regimes to restrict freedoms, such as the rights to privacy or free speech.
Secondly, that these tensions could compromise the spirit of cooperation between academic and industrial organizations across the world. This framework of open collaboration has been instrumental to the rapid development and deployment of AI technology we see taking place today and putting up borders around a nation’s AI development is likely to slow that progress. In particular, it is expected to slow the development of common standards around AI and data, which could greatly increase the usefulness of AI.

 A Move Towards “Transparent AI”

The adoption of AI across wider society – particularly when it involves dealing with human data – is hindered by the ""black box problem."" Mostly, its workings seem arcane and unfathomable without a thorough understanding of what it's actually doing.
To achieve its full potential AI needs to be trusted – we need to know what it is doing with our data, why, and how it makes its decisions when it comes to issues that affect our lives. This is often difficult to convey – particularly as what makes AI particularly useful is its ability to draw connections and make inferences which may not be obvious or may even seem counter-intuitive to us.
But building trust in AI systems isn’t just about reassuring the public. Research and business will also benefit from openness which exposes bias in data or algorithms. Reports have even found that companies are sometimes holding back from deploying AI due to fears they may face liabilities in the future if current technology is later judged to be unfair or unethical.
In 2019 we're likely to see an increased emphasis on measures designed to increase the transparency of AI. This year IBM unveiled technology developed to improve the traceability of decisions into its AI OpenScale technology. This concept gives real-time insights into not only what decisions are being made, but how they are being made, drawing connections between data that is used, decision weighting and potential for bias in information.
The General Data Protection Regulation, put into action across Europe this year, gives citizens some protection against decisions which have “legal or other significant” impact on their lives made solely by machines. While it isn’t yet a blisteringly hot political potato, its prominence in public discourse is likely to grow during 2019, further encouraging businesses to work towards transparency.

 AI and automation drilling deeper into every business 

In 2018, companies began to get a firmer grip on the realities of what AI can and can’t do. After spending the previous few years getting their data in order and identifying areas where AI could bring quick rewards, or fail fast, big business is as a whole ready to move ahead with proven initiatives, moving from piloting and soft-launching to global deployment.
In financial services, vast real-time logs of thousands of transactions per second are routinely parsed by machine learning algorithms. Retailers are proficient at grabbing data through till receipts and loyalty programmes and feeding it into AI engines to work out how to get better at selling us things. Manufacturers use predictive technology to know precisely what stresses machinery can be put under and when it is likely to break down or fail.
In 2019 we’ll see growing confidence that this smart, predictive technology, bolstered by learnings it has picked up in its initial deployments, can be rolled out wholesale across all of a business’s operations.
AI will branch out into support functions such as HR or optimizing supply chains, where decisions around logistics, as well as hiring and firing, will become increasingly informed by automation. AI solutions for managing compliance and legal issues are also likely to be increasingly adopted. As these tools will often be fit-for-purpose across a number of organizations, they will increasingly be offered as-a-service, offering smaller businesses a bite of the AI cherry, too.
We’re also likely to see an increase in businesses using their data to generate new revenue streams. Building up big databases of transactions and customer activity within its industry essentially lets any sufficiently data-savvy business begin to “Googlify” itself. Becoming a source of data-as-a-service has been transformational for businesses such as John Deere, which offers analytics based on agricultural data to help farmers grow crops more efficiently. In 2019 more companies will adopt this strategy as they come to understand the value of the information they own.

 More jobs will be created by AI than will be lost to it. 

As I mentioned in my introduction to this post, in the long-term its uncertain if the rise of the machines will lead to human unemployment and social strife, a utopian workless future, or (probably more realistically) something in between.
For the next year, at least, though, it seems it isn’t going to be immediately problematic in this regard. Gartner predicts that by the end of 2019, AI will be creating more jobs than it is taking.
While 1.8 million jobs will be lost to automation – with manufacturing in particular singled out as likely to take a hit – 2.3 million will be created. In particular, Gartner's report finds, these could be focused on education, healthcare, and the public sector.
A likely driver for this disparity is the emphasis placed on rolling out AI in an ""augmenting"" capacity when it comes to deploying it in non-manual jobs. Warehouse workers and retail cashiers have often been replaced wholesale by automated technology. But when it comes to doctors and lawyers, AI service providers have made concerted effort to present their technology as something which can work alongside human professionals, assisting them with repetitive tasks while leaving the ""final say"" to them.
This means those industries benefit from the growth in human jobs on the technical side – those needed to deploy the technology and train the workforce on using it – while retaining the professionals who carry out the actual work.
For the financial services, the outlook is perhaps slightly grimmer. Some estimates, such as those made by former Citigroup CEO Vikram Pandit in 2017, predict that the sector's human workforce could be 30% smaller within five years. With back-office functions increasingly being managed by machines, we could be well on our way to seeing that come true by the end of next year.

 AI assistants will become truly useful 

AI is genuinely interwoven into our lives now, to the point that most people don't give a second thought to the fact that when they search Google, shop at Amazon or watch Netflix, highly precise, AI-driven predictions are at work to make the experience flow.
A slightly more apparent sense of engagement with robotic intelligence comes about when we interact with AI assistants – Siri, Alexa, or Google Assistant, for example – to help us make sense of the myriad of data sources available to us in the modern world.
In 2019, more of us than ever will use an AI assistant to arrange our calendars, plan our journeys and order a pizza. These services will become increasingly useful as they learn to anticipate our behaviors better and understand our habits.
Data gathered from users allows application designers to understand exactly which features are providing value, and which are underused, perhaps consuming valuable resources (through bandwidth or reporting) which could be better used elsewhere.
As a result, functions which we do want to use AI for – such as ordering taxis and food deliveries, and choosing restaurants to visit – are becoming increasingly streamlined and accessible.
On top of this, AI assistants are designed to become increasingly efficient at understanding their human users, as the natural language algorithms used to encode speech into computer-readable data, and vice versa is exposed to more and more information about how we communicate.
It's evident that conversations between  Alexa or Google Assistant and us can seem very stilted today. However, the rapid acceleration of understanding in this field means that, by the end of 2019, we will be getting used to far more natural and flowing discourse with the machines we share our lives with.
Check out these links for more information on artificial intelligence and many practical AI case examples.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",,5 Important Artificial Intelligence Predictions (For 2019) Everyone Should Read,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LnN0cmF0ZWd5LWJ1c2luZXNzLmNvbS9hcnRpY2xlL1VuZGVyc3RhbmRpbmctdGhlLVBvdGVudGlhbC1vZi1BcnRpZmljaWFsLUludGVsbGlnZW5jZdIBAA?oc=5,Understanding the potential of artificial intelligence - strategy+business Today,2018-12-05,strategy+business Today,https://www.strategy-business.com,"Daniel Hulme, CEO of the AI solutions startup Satalia, offers other chief executives a primer on the technology that will shape the future of work and business.","['GMO', 'thought leaders', 'artificial intelligence', 'tech companies', 'sentient computers', 'digital strategy', 'big data', 'algorithms and strategy', 'Inside the Mind of the CEO']","Daniel Hulme, CEO of the AI solutions startup Satalia, offers other chief executives a primer on the technology that will shape the future of work and business.","Daniel Hulme, CEO of the AI solutions startup Satalia, offers other chief executives a primer on the technology that will shape the future of work and business.",http://schema.org,,Article,Understanding the potential of artificial intelligence,https://www.strategy-business.com/article/Understanding-the-Potential-of-Artificial-Intelligence?gko=412e8,,https://www.strategy-business.com/media/image/41283042_thumb5_690x400.jpg,,Thought leaders,,"['Euan Cameron', 'Deborah Unger']",,2018-12-05T06:00:00Z,,,,,"

Thought leaders
Understanding the potential of artificial intelligenceDaniel Hulme, CEO of the AI solutions startup Satalia, offers other chief executives a primer on the technology that will shape the future of work and business.
by Euan Cameron and Deborah UngerDecember 5, 2018
Share to: 

Share on X 
Share on LinkedIn 
Share on Facebook 
Email this article 







Photograph courtesy of Satalia

A version of this article appeared in the Spring 2019 issue of strategy+business.
This interview is part of the Inside the Mind of the CEO series, which explores a wide range of critical decisions faced by chief executives around the world.

In 2008, Daniel Hulme started Satalia, a company that uses data science, machine learning, and optimization (making the best use of resources) to build customized platforms that solve tough logistics problems involving products, services, and people. Lately, Hulme has spent a good portion of his time explaining the ins and outs of artificial intelligence to other CEOs. He sees a big information gap at the top of most companies — yet this is where technology investment decisions are made. Misunderstanding AI, Hulme believes, can lead people to both overestimate its value and underestimate its impact.
Satalia’s work is a leading example of what AI is currently good at. Not coincidentally, it is also the commercialization of Hulme’s research at University College London (UCL), where he is the director of the business analytics master’s degree program. Satalia’s clients are household names in the U.K.; they include Tesco, DFS, and the British Broadcasting Corporation. (Disclosure: PwC, which publishes strategy+business, uses Satalia’s technology and is working with the company to develop an offering to take to mutual clients.)

PwC Insights


PwC's Global CEO Survey





Quiz: Are you an AI optimist?




The increasingly competitive market for AI expertise is both a blessing and a curse for Satalia. The company, with a staff of 30 that is expected to grow quickly in 2019, can’t attract talent through salaries alone, so it also relies on an innovative management concept. This organizational structure reflects what Hulme believes will become the prevailing model of successful corporations in the future. Satalia, a loose-knit operational hub, based in a trendy North London shared workspace, taps into a “gig economy”–style global talent network and offers flexibility and fun, with few if any layers of management.
The setting is a long way from Morecambe, a sleepy coastal resort town on the chilly northwestern coast of the United Kingdom, where Hulme, 38, grew up. Morecambe is famous not for computer science but for potted shrimp, a late British comedian (Eric Morecambe, who took the town’s name as his own), and a very British playwright, Alan Bennett. A girl Hulme met at age 16 came from London, and inspired him to move 250 miles south after finishing secondary school. There, he entered UCL and the world of artificial intelligence. In September 2018, Hulme sat down with strategy+business in the cafeteria of Satalia’s shared offices to explain the artificial intelligence revolution and why there are no truly intelligent machines — yet.
S+B: What drew you to artificial intelligence?
HULME: I’ve always been interested in what it means to be human, and in the nature of the universe. I did my undergraduate [degree] in AI and my master’s in AI, and my Ph.D. in AI, so I guess I’ve been doing 19 years’ worth of activity in AI.
S+B: What is your definition of AI?
HULME: There are two definitions of AI, and the more popular one is the weakest. This first definition [concerns] machines that can do tasks that were traditionally in the realm of human beings. Over the past decade, due to advances in technologies like deep learning, we have started to build machines that can do things like recognize objects in images, and understand and respond to natural language. Humans are the most intelligent things we know in the universe, so when we start to see machines do tasks once constrained to the human domain, then we assume that is intelligence.


 
Get the strategy+business newsletter delivered to your inbox
(sample)

EmailEmail address:
 




But I would argue that humans are not that intelligent. Humans are good at finding patterns in, at most, four dimensions, and we’re terrible at solving problems that involve more than seven things. Machines can find patterns in thousands of dimensions and can solve problems that involve millions of things. Even these technologies aren’t AI — they’re just algorithms. They do the same thing over and over again. In fact, my definition of stupidity is doing the same thing over again and expecting a different result.
S+B: And the second definition of AI?
HULME: The best definition of intelligence — artificial or human — that I’ve found is goal-directed adaptive behavior. I use goal-directed in the sense of trying to achieve an objective, which in business might be to roster your staff more effectively, or to allocate marketing spend to sell as [much] ice cream as possible. It might be whatever goal you’re seeking.
Behavior is how quickly or frictionlessly I can move resources to achieve the objective. For example, if my goal is to sell lots of ice cream, how can I allocate my resources to make sure that I’m achieving the objective?

Related Stories


The future of artificial intelligence depends on trust
by Anand Rao and Euan Cameron

s+b Blogs

Why Robots Need Adult Supervision
by Daniel Gross



Why is it so hard to trust a blockchain?
by Steve Davies and Grainne McNamara


But the key word for me in the definition of goal-directed adaptive behavior is adaptive. If your computer system is not making a decision and then learning whether that decision was good or bad and adapting its own internal model of the world, I would argue that it’s not true AI. And it’s OK for companies at the moment to be calling machine learning AI. So for me, the true [definition of] AI [involves] systems that can learn and adapt themselves without the aid of a human. Adaptability is synonymous with intelligence.
In fact, most companies don’t have machine learning problems — they have optimization problems. Optimization is the process of allocating resources to achieve an objective, subject to some constraints. Optimization problems are exceptionally hard to solve. For example, how should I route my vehicles to minimize travel time, or how do I allocate staff to maximize utilization, or how do I spend marketing money to maximize impact, or how do I allocate sales staff to opportunities to maximize yield? There are only a handful of people across the world who are good at solving problems like this with AI.
S+B: How do you think CEOs see AI today?
HULME: Many CEOs feel they need to bring AI into their organization. There’s this fear factor that if you’re not on the AI bandwagon, then you’re going to lose out to competitors that are going to be eating your market, because they’re using technologies to make decisions faster and better than you.
They may ask the chief information officer, “What are we doing in AI?” And the CIO will then hire or try to hire data scientists, whose work represents a kind of proxy for AI. But data scientists only have a certain type of skill. They understand how to use statistics and machine learning to find patterns in data. They’re not necessarily good at building production-grade systems that can make decisions or that can adapt themselves.
S+B: So you don’t believe that machine learning, in itself, can evolve into the kinds of adaptive systems that companies need.
HULME: A lot of people are saying, “Well, [with] these deep learning models, these data scientists will solve all our problems,” and actually, they won’t. As I said, machine learning, data science, and statistics are great at finding patterns in data. But the most important thing is making decisions that leverage the patterns found in data. This requires a completely different set of skills: discrete mathematics, operations research, and optimization. These skills are massively underrepresented in industry.
S+B: What kinds of questions, then, should CEOs be asking about AI?
HULME: One is, what technologies and solutions should they be bringing into their organization to remove the biggest frictions? So first they need to identify the big frictions that are aligned to their core competencies and assess what technologies they need to innovate the core competencies. The biggest frictions might come from having lots of costs associated with employing people. Or the company might have frictions associated with customer experience. Or, if I have a lot of analysts reading lots of reports and then trying to synthesize those reports into information, we can get machine learning to do that better.

CEOs also need to have a very clear understanding about the competitive landscape. Most companies don’t just have direct competition; they also have indirect competition from the Googles and the Facebooks and the Alibabas. Lots of those big companies can enter almost any market and shake it up. So companies need to be looking tangentially at indirect competitors and assessing what these competitors could do, given all the data that they’re currently sitting on — because once they figure out how to mobilize that data, they can cannibalize those markets.
And then the third question CEOs should ask is how do they bring the right talent capability into their organization to help execute a strategy to remain competitive? It’s hard for most companies to do this, so you have to learn to work with startups and third-party vendors to deliver innovations and help you quickly adapt to a changing world.
S+B: On the question of talent and skills: You say data science is only part of it. What other categories should companies be looking at?
HULME: There are four categories of AI skills. The first category is the data. Companies should ask: Are we getting our data into the shape where people can consume it? There are lots of companies out there that are throwing money at building data lakes — that’s all the raw data that a company holds from code generation to sales information — because they think at some point in the future data lakes will be useful. That’s not a bad investment, but I would also suggest that you need to be building applications straight away on top of that data lake that drive value into your business. Companies…should be thinking about building digital twins of their organizations, i.e., a perfect digital representation of their physical assets, like their infrastructure and employees.
S+B: What’s the second AI category?
HULME: Next is recruiting data scientists who have the machine learning and statistics skills to find insights from the data. Then, the third is [finding] what I call the decision scientists: people who can understand how to make decisions or solve optimization problems that leverage those insights.
And fourth, crucially, for true AI, you need to have an AI architect who understands how to glue these three components together: the data, the machine learning, and the optimization to build adaptive systems. And at the moment, it’s the CIO who is trying to step into that role of overseeing this. But I don’t know of many companies out there that have true AI architects. For now, companies are managing maybe part of this, but not all four categories.
S+B: Can you say more about the digital twin concept? What can digital twins be used for?
HULME: Digital twins are the next evolution of digital transformation. To be able to adapt more quickly to a changing world, companies need to create a digital replica of all of their physical assets, their infrastructure and people. Once you have a twin, you can start to run experiments and simulate scenarios to operate your business more effectively. Further down the line we may even have AI setting those experiments, and running experiments without the aid of the human. The role of the strategist and of leadership is to develop a strong vision and purpose, i.e., [determining] what key objective the organization needs to aspire to. I hope that organizations will realize that this objective needs to be much more sophisticated than a financial return to be able to attract, empower, and motivate talent. Exceptional talent wants to align with a strong purpose and inspirational leaders.

S+B: Are we going to have a wave of wasted AI spending?
HULME: There is a bit of a bubble in AI. I don’t think that it’s going to go to waste. I think that all this investment will be additive, but there’s an over-expectation of what machine learning can bring right now, because of a lack of appreciation of the fact that machine learning is only part of the journey. And the next part of the journey for most big companies is optimization and decision making.
S+B: You’re saying that AI is simultaneously overhyped and underexploited.
HULME: As [futurist] Roy Amara noted, the impact of technology tends to be overestimated in the short run and underestimated in the long run. For now, you can probably ignore the idea of having adaptive systems in your business. That will come later. In the short run, you can use AI to remove the friction of mundane and repetitive tasks across the organization. If used correctly, this can absolutely change your business. But there’s a lot of hype out there, and a lot of people investing in these technologies don’t know what they’re doing.
S+B: How well equipped is AI to help business leaders forecast the future?
HULME: The world is changing so quickly, it’s very difficult to actually have all the necessary data points to be able to help you forecast accurately. At the moment, that’s still in the realm of human beings.

“If used correctly, AI can absolutely change your business. But there’s a lot of hype out there, and a lot of people investing in these technologies don’t know what they’re doing.”


Share to:
Twitter
Facebook
LinkedIn


I’ll give you an example. Someone I know who worked at a loan company told me this story. They were trying to predict who might default on their loans, and they decided to collect social data from LinkedIn and Facebook to see whether they could find indicators there. Actually, all that data was useless. But there are two really good predictors of defaulters: One is the Internet caches [browsing histories] that contain websites with a particular font that is often found on gambling sites. The other is the number of mistakes people make when they are filling out the loan application, which [can be] an indication of whether they are intoxicated.
So you don’t need all the data in the world. You just need the right data, and the right amount of data. It all stems from: What is the problem we’re trying to solve, and how are we solving that problem at the moment? What data are people consuming, and what algorithms are they using? Because it’s most likely that data will solve the problem. We just need to start by replicating what’s in experts’ heads.
S+B: As the CEO of an AI company, what do you think are the greatest threats your company faces?
HULME: I used to think that technology was a threat, in the sense that my competitors had access to advanced technologies and data. But now I think [the worry] is not getting the talent to use that technology. How do you attract and retain that talent? And that comes back to culture and purpose.
One of the things I’m worried about is my team going to work for other companies that can pay twice as much. Bigger companies now have access to very cheap capital, and they understand how to get users, even by losing money. They know that users are going to be valuable in the future. They know how to attract the right talent; they can pay high salaries; they know how to keep them happy by giving them beanbags and free food and all of this kind of stuff. And it’s going to be very, very difficult, I think, for traditional startups to compete with those organizations without them being hoovered up very quickly. Even in academia now we’re seeing the really good professors just being hoovered up by these large organizations. So the biggest threat for me is large companies that have access to infinite amounts of cheap capital that will be able to out-innovate me because of their access to [people].
S+B: Do you expect AI experts to be in high demand in general?
HULME: I do. Lots of companies will be telling their investors, “OK, we need to get money to build our own AI teams or data science teams.” And in reality, it’s going to be very difficult for most companies out there to attract and retain that talent. In some respects, that’s a problem we are trying to solve at Satalia. We try to help companies understand what kind of people they need and be honest with themselves.
S+B: Which countries do you think will move fastest with the next stages of AI?
HULME: It comes back to the ethical questions around GDPR [the European Union’s recently enacted General Data Protection Regulation] and building “explainable algorithms.” So if you’re building algorithms now that are making decisions in people’s lives, in Europe you need to be able to explain how those algorithms are making those decisions.

Unfortunately, countries that don’t have constraints — maybe the Chinas and Russias of this world —may be able to out-innovate countries that do have those restrictions, because it’s very, very, very hard to build explainable algorithms. And if there is no legislation for this, you may find unscrupulous organizations trying out systems that could have horrible outcomes, but there will be unclear jurisdictional repercussions. In a hospital, for example, is it you or the algorithm that just made the mistake? That’s why it’s important to understand and to explain how a computer is making its decisions. And we are not there yet.
S+B: Overall, what effect do you think AI will have on jobs? Will it create more?
HULME: In the short term, over the coming decade, I believe that AI will create jobs. In the long term, it will remove more jobs than it creates. I spend a lot of time thinking about the concept of economic singularity. This is the point at which AI will free people from their jobs and those people won’t be able to retrain fast enough to get another job, because AI will have taken it, too. Some experts believe that this could happen in the next 10 to 20 years, and that governments and our economy aren’t prepared for it. Satalia’s purpose is to try to address these future problems. We need to somehow create a global infrastructure that supports those people who are going to be out of work.
There’s another concept called the technological singularity, in which we build AI smarter than us in every possible way. It will be the last invention humanity needs to create, because it will be able to think infinitely faster and better than humans. Many scholars predict we will birth a superintelligence around the middle of our century. It will either be the most glorious thing to happen to humanity or perhaps our biggest existential threat. My concern is that if we are not cooperating as a global species by the time we create it, then it will see us as a threat and remove us from the equation. My purpose is to steer the world toward cooperation, and that means reinventing our political and economic models, and agreeing on a new objective function for humanity. The impulse for countries to increase GDP and companies to make profits means that more and more investment will be made to drive efficiencies and profits, which is leading us to a global economic and environmental crisis. We need a sustainable objective function, and we need to get everyone on the planet contributing to it; otherwise, we may destroy ourselves. I don’t believe that governments are prepared or can act quickly enough, so I hope the change will come from business leaders who have a huge influence and responsibility to steer us toward a positive future.
S+B: This implies that we need to put in safeguards now to ensure the ethical development of AI.
HULME: For millennia, philosophers have been debating how society should be structured and what it means to live a “good life.” As our environments start to intelligently interact with us, we’re giving them the power to create and destroy. We have to embed ethical behaviors into these system, which makes it an extremely exciting time for humanity, because we now have to agree on what those ethical behaviors should be.
S+B: Are there other technologies — perhaps blockchain — that will deliver this AI-enhanced world?
HULME: Blockchain technology is giving the world a trusted data platform, and AI is providing the means to collaborate and connect without friction. Over the coming decade we might see the emergence of a DAO [decentralized autonomous organization]  that will allow for truly decentralized and distributed decisions and actions. I can imagine a world in which anyone could boot up a project by launching a DAO that enables contributions from anywhere in the world. The DAO is similar to the open source movement, but in this new paradigm, anyone  —  software engineers, designers, marketers, accountants, and even strategists  —  will be able to rally around an idea and contribute to its development. Work won’t be provided for free or for kudos, as in the open source model. Instead, fiscal remuneration will be determined by the quantity and quality of the contribution. This means that anyone will be able to contribute to a project, even for just a few hours, and they will be rewarded fairly for their work. As people work on these open projects, the DAO captures their contribution on a public blockchain. These contributions accumulate to form a reputation that determines the rate of remuneration on future projects. People develop different rates for different skills, and the rate evolves dynamically over time. You would be paid a different rate for marketing work than for software development, depending on your relative skill in each.
S+B: This upends the financing models we have today, similar to the ICOs (initial coin offerings) that have been developed out of bitcoin. Will this continue, and what is your vision of this autonomous world?
HULME: Many of these open projects will use digital tokens as their economic model. A Cambrian explosion [a rapid diversification among animals found in the fossil record] of funding models will appear, such as ICOs and other types of token sales. Selling tokens will give DAO projects the capital to get started. By reducing the waste and friction, we may reach a point at which new innovations help ensure that everyone’s basic needs are met. Giving everyone seamless access to healthcare, nutrition, and education will mean that people have the freedom to create and contribute to DAO projects without the need for initial funding. Since digital tokens have no jurisdiction, contributors from anywhere in the world can be remunerated with the same currency. Someone in Europe who contributed the same value to a DAO project as someone in India would receive the same remuneration. And because everyone has a fair opportunity to contribute to DAO projects, there may be a rapid redistribution of wealth.

One of the founding principles of the DAO is that all products are open source. The creation of a completely frictionless free market, where the cheapest and best-placed people could contribute, means that toxic companies are starved of labor and customers. Efficient markets coupled with conscientious consumption could spawn tens of thousands of new organizations whose products and services are developed to meet real needs and provide real benefits.
People will be able to work anywhere they want, which could cause mass migration. Digital nomads could force governments to reassess and innovate their policies to attract and retain corporations and talent by reducing taxes and slackening employment laws. The freedom to work anywhere will cause substantial population shifts and reenergized communities, with people growing their own food, harnessing natural energy sources, and turning away from mass-produced or packaged solutions. This reemergence of community after years of isolated self-interest could have a huge impact on the happiness levels of all age groups.
S+B: Back to the here and now. How far away are we from solving technology problems so that being a small company today in this world of AI won’t be a disadvantage?
HULME: The tools themselves are not too far away. One of Satalia’s aspirations is to build a platform that allows somebody to boot up a company or an organization, and then attract people from anywhere in the world to contribute to a particular product or service. I have a personal mission to try to get the world cooperating as a global community because I don’t believe that our current economic and political systems are sustainable for the planet.
In some respects, the biggest threat to a company like Satalia is the limitation of its own internal structure. In the future, the success of Satalia will be to remove the concept of a centralized organization, and that means completely decentralizing Satalia itself. That’s OK. And that’s why I’m trying to operate Satalia as a self-organizing company. I want to build a platform to create a decentralized world and be an exemplar for what amazing innovations you can build if you harness and empower amazing talent. In a decentralized world, people could learn to cooperate and contribute more positively to society, and potentially help address some of the threats I’ve mentioned above. If I could create a world where anybody could boot up an idea and get people to surround it and drive it forward, then that’s a world that I want to live in.

Read more: PwC's 2019 AI Predictions and the six priorities businesses must consider in the coming year.

Author profiles:
Euan Cameron is a partner with PwC UK based in London. He is the U.K. artificial intelligence leader, focusing on designing and deploying applied machine learning and AI solutions for both clients and PwC itself. Prior to his current role, he worked for two decades in corporate strategy development and M&A.
Deborah Unger is a senior editor of strategy+business.

Share to: 

Share on X 
Share on LinkedIn 
Share on Facebook 
Email this article 


Topics: algorithms and strategy, artificial intelligence, big data, digital strategy, Inside the Mind of the CEO, sentient computers, tech companies, thought leaders

Recommended stories

How Artificial Intelligence Can Make Us Better at Being HumanThe surprising ways machine learning can pick up when we fail.by Linda Rodriguez McRobbie


The future of artificial intelligence depends on trustIf it is to drive business success, AI cannot hide in a black box. For more insight, see “3 Steps to Building Trust in AI.”by Anand Rao and Euan Cameron


Artificial Intelligence: What to Expect in 2018Eight ways that AI is likely to reshape business in the next 12 months. For further insights, see PwC’s study.




Digital issue



From sludge to success

The June issue of s+b explores how the road to business renewal starts when CEOs step in to reduce organizational friction.






",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMikgFodHRwczovL3d3dy5jb2UuaW50L2VuL3dlYi9jZXBlai9jZXBlai1ldXJvcGVhbi1ldGhpY2FsLWNoYXJ0ZXItb24tdGhlLXVzZS1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1haS1pbi1qdWRpY2lhbC1zeXN0ZW1zLWFuZC10aGVpci1lbnZpcm9ubWVudNIBAA?oc=5,CEPEJ European Ethical Charter on the use of artificial intelligence (AI) in judicial systems and their environment ... - Council of Europe,2018-12-04,Council of Europe,https://www.coe.int,,,,,https://schema.org,,WebPage,,,,,,,,,,2018-11-19,,2023-09-29,,," 

The European Commission for the Efficiency of Justice (CEPEJ) of the Council of Europe adopted in December 2018 the first European text setting out ethical principles relating to the use of artificial intelligence (AI) in judicial systems.
The Charter provides a framework of principles that can guide policy makers, legislators and justice professionals when they grapple with the rapid development of AI in national judicial processes.
The CEPEJ’s view as set out in the Charter is that the application of AI in the field of justice can contribute to improve the efficiency and quality and must be implemented in a responsible manner which complies with the fundamental rights guaranteed in particular in the European Convention on Human Rights (ECHR) and the Council of Europe Convention on the Protection of Personal Data. For the CEPEJ, it is essential to ensure that AI remains a tool in the service of the general interest and that its use respects individual rights.
The CEPEJ has identified the following core principles to be respected in the field of AI and justice:
 Principle of respect of fundamental rights: ensuring that the design and implementation of artificial intelligence tools and services are compatible with fundamental rights;
 Principle of non-discrimination: specifically preventing the development or intensification of any discrimination between individuals or groups of individuals;
 Principle of quality and security: with regard to the processing of judicial decisions and data, using certified sources and intangible data with models conceived in a multi-disciplinary manner, in a secure technological environment;
 Principle of transparency, impartiality and fairness: making data processing methods accessible and understandable, authorising external audits;
 Principle “under user control”: precluding a prescriptive approach and ensuring that users are informed actors and in control of their choices.
For the CEPEJ, compliance with these principles must be ensured in the processing of judicial decisions and data by algorithms and in the use made of them.
The CEPEJ Charter is accompanied by an in-depth study on the use of AI in judicial systems, notably AI applications processing judicial decisions and data.
 Link to the European Ethical Charter on the use of artificial intelligence in judicial systems
  Link to the presentation note of the European Ethical Charter on the use of artificial intelligence in judicial systems",,,CEPEJ European Ethical Charter on the use of artificial intelligence (AI) in judicial systems and their environment,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LnNvY2lhbGlzdHBhcnR5Lm9yZy51ay9hcnRpY2xlcy8yODM4NC8wNS0xMi0yMDE4L3RoZS1ncm93dGgtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdGVjaG5vbG9neS_SAQA?oc=5,The growth of artificial intelligence technology - Socialist Party,2018-12-05,Socialist Party,https://www.socialistparty.org.uk,,,AI technologies cannot be harmoniously rolled out due to the contradictions of capitalism,,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/#article', 'isPartOf': {'@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/'}, 'author': {'name': 'Archivist', '@id': 'https://www.socialistparty.org.uk/#/schema/person/0b9f768e8d8f64cb9168a63ac1c5b30c'}, 'headline': 'The growth of artificial intelligence technology', 'datePublished': '2018-12-05T15:19:47+00:00', 'dateModified': '2022-01-09T16:19:40+00:00', 'mainEntityOfPage': {'@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/'}, 'wordCount': 1922, 'publisher': {'@id': 'https://www.socialistparty.org.uk/#organization'}, 'image': {'@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/#primaryimage'}, 'thumbnailUrl': 'https://www.socialistparty.org.uk/wp-content/uploads/pics/25/25093.jpg', 'keywords': ['Issue 1021', 'Jobs', 'Socialism', 'Technology'], 'articleSection': ['Economy and finance', 'Science and technology'], 'inLanguage': 'en-GB'}, {'@type': 'WebPage', '@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/', 'url': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/', 'name': 'The growth of artificial intelligence technology - Socialist Party', 'isPartOf': {'@id': 'https://www.socialistparty.org.uk/#website'}, 'primaryImageOfPage': {'@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/#primaryimage'}, 'image': {'@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/#primaryimage'}, 'thumbnailUrl': 'https://www.socialistparty.org.uk/wp-content/uploads/pics/25/25093.jpg', 'datePublished': '2018-12-05T15:19:47+00:00', 'dateModified': '2022-01-09T16:19:40+00:00', 'breadcrumb': {'@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/#primaryimage', 'url': 'https://www.socialistparty.org.uk/wp-content/uploads/pics/25/25093.jpg', 'contentUrl': 'https://www.socialistparty.org.uk/wp-content/uploads/pics/25/25093.jpg', 'width': 2000, 'height': 1600, 'caption': 'In Marxist terms, the fight for our future is not dystopia or utopia, but one of capitalism or socialism, photo www.vpnsrus.com, credit: Www.vpnsrus.com (uploaded 05/12/2018)'}, {'@type': 'BreadcrumbList', '@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.socialistparty.org.uk/'}, {'@type': 'ListItem', 'position': 2, 'name': 'The growth of artificial intelligence technology'}]}, {'@type': 'WebSite', '@id': 'https://www.socialistparty.org.uk/#website', 'url': 'https://www.socialistparty.org.uk/', 'name': 'Socialist Party', 'description': 'Socialism is a democratic society run for the needs of all and not the profits of a few', 'publisher': {'@id': 'https://www.socialistparty.org.uk/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.socialistparty.org.uk/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://www.socialistparty.org.uk/#organization', 'name': 'Socialist Party', 'url': 'https://www.socialistparty.org.uk/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.socialistparty.org.uk/#/schema/logo/image/', 'url': 'https://www.socialistparty.org.uk/wp-content/uploads/2022/03/SP-Logo-Colour-A3-with-formerly-Militant-1200px.jpg', 'contentUrl': 'https://www.socialistparty.org.uk/wp-content/uploads/2022/03/SP-Logo-Colour-A3-with-formerly-Militant-1200px.jpg', 'width': 1201, 'height': 510, 'caption': 'Socialist Party'}, 'image': {'@id': 'https://www.socialistparty.org.uk/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/CWISocialistParty/', 'https://x.com/Socialist_party', 'https://instagram.com/socialistpartycwi', 'https://www.youtube.com/UCsSSEOdny3fFStVEnLDUeWg']}, {'@type': 'Person', '@id': 'https://www.socialistparty.org.uk/#/schema/person/0b9f768e8d8f64cb9168a63ac1c5b30c', 'name': 'Archivist', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.socialistparty.org.uk/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/d5b70e8cf351f6ba45b527a65750e530?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/d5b70e8cf351f6ba45b527a65750e530?s=96&d=mm&r=g', 'caption': 'Archivist'}, 'url': 'https://www.socialistparty.org.uk/articles/author/archivist/'}]",BreadcrumbList,,,,,,,,,,,,,,,"






Home  Economy and finance  The growth of artificial intelligence technology

Economy and financeScience and technology The growth of artificial intelligence technology

05/12/2018 










FacebookTwitterWhatsAppEmailPrint




Its negative impact under capitalism, and its revolutionary potential under socialism
Robin Clapp, Socialist Party national committee




 In Marxist terms, the fight for our future is not dystopia or utopia, but one of capitalism or socialism, photo www.vpnsrus.com   (Click to enlarge: opens in new window)



In a warning laced with ironies, former warmongering US Secretary of State Henry Kissinger – who presided over many of the atrocities of the Vietnam war in the 1960s and 1970s – warned in an article in Russia Today in July that: “We are in the midst of a sweeping technical revolution whose consequences we have failed to fully reckon and whose culmination may be a world relying on machines powered by data and algorithms and ungoverned by ethical or philosophical norms”.
The development of Artificial Intelligence (AI), machines that do not just carry out pre-programmed instructions but learn more new programmes and instruction by experience and by new situations, does pose fundamental questions for capitalists and the workers’ movement, with some AI advocates arguing that algorithms will soon surpass the intelligence of humans. They call this the ‘singularity’ moment.
Yet for socialists, there is nothing intrinsically revolutionary about these new technologies while they remain restrained by the capitalist mode of production that needs human labour power to generate profit. 
Indeed, in every previous historical epoch there have been new technologies, but their ownership has lain just as firmly in the economic grip of the ruling class of the day.
Robots and more highly developed forms of AI do not change the exploitation of humans by other humans and cannot solve the fundamental contradictions of capitalism.
The productive forces long ago burst asunder the boundaries of the nation state, but this process cannot be completed by capitalism.
Many AIs exist principally as digital entities, but in other applications the intelligence is embodied in a robot that augments human work.
In manufacturing, robots are evolving from potentially dangerous and ‘dumb’ industrial machines into context-aware ‘cobots’.
The technology is already used widely, to provide speech and face recognition, language translation, and personal recommendations on music, film and shopping sites.
Calculating and predicting more quickly and accurately than has ever been possible what the likelihood is of a particular outcome, is the fundamental advance which AI brings.
In the future, it is claimed that AI could deliver driverless cars, smart personal assistants, and intelligent energy grids.
Yet in austerity-ridden capitalist society, even the filling of potholes is a task beyond this system.
Jobs risk
As long as capitalism is in the driving seat, a planned and coordinated rolling out of AI is impossible in a manner that creates well-paid jobs and new opportunities for workers displaced by machines.
The economist Robert Gordon predicts 47% of jobs in the US, most of them semi-skilled, will disappear in the next few years, while an in-depth study by Citi and Oxford University predicts that 77% of all jobs in China are at risk of automation and 57% of all jobs across the OECD (a grouping of advanced capitalist countries).
The responsibility for combatting this dystopian view of the future lies with the workers’ organisations and left parties.
But the leaderships have not put forward clear ideas for the organised working class to see its role in changing society.
Instead of simply bowing to the ‘inevitable’, the trade unions must formulate a programme for jobs that includes the demand for an immediate struggle for a shorter working week without loss of pay, sharing out the work without loss of pay and a real living minimum wage. 
These demands must be linked to public ownership of major industries under workers’ control and management, in order to facilitate democratic socialist planning.
The capitalists themselves at their annual hideaways in Davos, Switzerland, have begun to ponder this question of how to deal with displaced workers and the social risks that will be triggered by large-scale surges in unemployment.
Traditional ‘middle class’ jobs will be threatened too and as Karl Marx warned 170 years ago, the continuation of capitalism leads inevitably to the growing pauperisation of the mass of the population.
Therefore it is incumbent on socialists not to settle for the idea of a ‘universal basic income’ as advanced by many on the utopian liberal left, but instead to fight for the full socialist transformation of society, which alone can take full advantage of the dazzling potential latent in AI.
On the basis of a socialist revolution and common ownership, the distribution of the output produced by the robots can be controlled and distributed to each, according to their needs.
If society operates through maintaining the private ownership of the robots, then the class struggle for the control of the surplus must continue.
The use of robots has grown exponentially since the 1950s. An industrial robot costs about £4 an hour to operate, compared to average total EU labour costs of about £40 an hour or £9 an hour in China.
Pepper Robots which engage in basic interactions and monitoring with elderly people are used in thousands of care homes in Japan.
They communicate through speech and with gestures, moving independently and picking up signs that someone is unwell.
With 25% of Japan’s population now aged 65 or over, on present trends, there will be a shortfall of 380,000 care workers by 2025.
The UK will need up to 700,000 more care-working roles by 2030. Pepper robots are being trialled here too and recently one performed before a parliamentary select committee. What impact will this have on the quality of social care?
Robotics
China is now the world’s biggest operator of industrial robots, according to the International Federation of Robotics.
One company, which exports 1,500 kitchen sinks a day, has spent over $3 million on nine robots that do jobs formerly done by 140 workers.
The boss comments: “These machines are cheaper, more precise and more reliable than people. I’ve never had a whole batch ruined by robots. I look forward to replacing more humans in future.”
Robots are employed in abattoirs and butchery and can cut fat off meat much more efficiently than humans, because of the use of cheaper and more responsive sensors. 
Another boss boasts: “It’s becoming economically feasible to use machines to do this because you save another 3 or 4% of the meat – and that’s worth a lot on a production line, where you can move quickly.”
The payback period for a welding robot in the Chinese automotive industry dropped from 5.3 years to 1.3 years between 2010 and 2017, according to analysts at Citi.
China’s rising labour costs may be an indirect silver lining because they are driving technological advancement, but simultaneously, immense social problems are being stored up, where massive and constant displacements of workers is leading to a rash of bitter industrial strikes, a questioning of the regime and tomorrow, even revolutionary movements.
Technology is never a neutral factor in production in a class society. The internet is a valuable means of communication for the workers’ movement, but can also be used to undermine democratic debate and spread misinformation. In extremis, right-wing governments have shut it down!
Prior to the financial crash of 2007 which triggered the ‘great recession’, the gurus of high finance boasted that their wizardry with algorithms had assured them there was almost no risk to the ‘skyscraper on chicken’s legs’ that was the volatile, speculative and largely fictitious derivatives market.
They were soon to learn that financial algorithms are not infallible. Others continue to be hypnotised by the get-rich-quick crypto-currency market, powered by algorithms and destined once again to end in tears for the parasitic ‘coupon clippers’ (wealthy holders of interest-bearing bonds).
At best the applications of AI can be rolled out only unevenly by the private sector. Historically the much-derided state has taken the risk in advancing science and AI, with the algorithm that led to Google’s success coming from a grant from the US National Science Foundation.
The iPhone would not exist if not for previously developed public technologies – the internet, GPS, lithium-ion batteries, microprocessors, multi-touch screen, SIRI, click-wheel, liquid crystal display, and so on.
Planning
A major technological innovation is unfolding around nanotechnology – the manipulation of matter on an atomic, molecular and supra-molecular scale. 
This requires cooperation and coordination among a variety of disciplines, including physics, chemistry, materials science, engineering and computer simulation. So far, it has been governments that have been primarily financing this research.
Today has parallels with the 1930s rather than with the post-war boom years, meaning AI is curtailed by capitalism, just as new technologies were stymied in the inter-war years.
The capitalist economist JM Keynes argued that the application of these technologies in the 1930s could even then reduce the working week to 19 hours. Yet investment and production seized up as economic depression spread like virus.
Marx and Engels explained through the law of historical materialism that the motor force of progress is the development of the means of production – industry, science, technology and technique.
The development of the productive forces is a process of humankind’s mastery over nature, of harnessing the forces bequeathed to us by our surroundings.
Those forms of AI that are presently conceived as most important include transformative developments like gene-sequencing technology, broad reach forms like the internet, economically lucrative breakthroughs like advanced robotics and potential game-changers such as energy storage technologies. 3D computers, once just a Star Trek fantasy, have opened up limitless possibilities.
In healthcare, AI can multi-scan cancer patients, allowing for adaptive radiotherapy where scanning, image mark-up and beam planning are done before every treatment session.
That way, the radiotherapy beams are sculpted to the tumour’s size and shape on the day, not when it was first imaged.
AI enthusiasts dream that the economic impact of these technologies – from falls in price and diffusion and improved efficiency, could be between $14 and $33 trillion a year in 2025.
AI technologies cannot, however, be harmoniously rolled out, due to the contradictions of capitalism. Capitalism can never give finished expression to the economic trends within it.
In Marxist terms, the fight for our future is not dystopia or utopia, but one of capitalism or socialism.
The real ‘third revolution’ will be the socialist one which, linked to the internet of things can connect everything with everyone in an integrated planned global network.
People, machines, natural resources, production lines, logistic networks, consumption habits, recycling flows, and virtually every other aspect of economic and social life will be linked via sensors and software.
Realm of freedom
This is the outline for a socialist world, in which humankind will be transformed. Engels once said “the invading revolution” is before us.
All capitalist institutions proceed from the belief that the capitalist system is permanent, yet the epidemic of chaos and crisis that is their system, creates social explosions out of which we can build the forces to change society completely.
The very future of the planet, from the struggle to eradicate disease and poverty to the protection of Earth from the horrors of climate change is a question that will be settled by the living struggle between class forces.
In the memorable words of revolutionary socialist Leon Trotsky: “For the first time mankind will regard itself as raw material, or at best as a physical and psychic semi-finished product.
“Socialism will mean a leap from the realm of necessity into the realm of freedom in this sense also, that the human of today, with all their contradictions and lack of harmony, will open the road for a new and happier race” (In Defence of the October Revolution, 1932).



TAGSIssue 1021JobsSocialismTechnology 
FacebookTwitterWhatsAppEmailPrint

 Previous articleSocialist Students conference date setNext articlePCS AGS election: Where now after the Left Unity conference? Archivist  




SearchSearch
> Do a Google search




Join 
Subscribe
Donate







 



","[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.socialistparty.org.uk/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.socialistparty.org.uk/articles/category/economy-and-finance/', 'name': 'Economy and finance'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.socialistparty.org.uk/articles/28384/05-12-2018/the-growth-of-artificial-intelligence-technology/', 'name': 'The growth of artificial intelligence technology'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LnJpdC5lZHUvbmV3cy9yaXQtcmVzZWFyY2hlci1wcmVzZW50cy13b3JsZHMtdG9wLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWV4cGVydHPSAQA?oc=5,RIT researcher presents with world's top artificial intelligence experts | RIT - Rochester Institute of Technology,2018-12-06,Rochester Institute of Technology,https://www.rit.edu,"Researchers at RIT are sharing their work amongst the world’s top artificial intelligence experts this week at NeurIPS 2018, the premier AI conference. The RIT team designed and implemented an algorithm that allows AI to analyze high-dimensional data sets more efficiently.",,,,,,,,,,,,,,,,,,,,,"



								December 6, 2018
							

																			by Scott Bureau



RIT researcher presents with world’s top artificial intelligence experts
RIT paper on new machine learning algorithm accepted for premier AI conference




Share on Facebook


Share on Twitter


Share on LinkedIn


Share on Reddit


Share via Email






‌



 RIT assistant professor and alumnus Rui Li joined the world’s best artificial intelligence experts to present a new machine learning algorithm at NeurIPS 2018, the largest AI conference, Dec. 5 in Montreal.   





Researchers at Rochester Institute of Technology are sharing their work amongst the world’s top artificial intelligence experts this week at NeurIPS 2018, the premier AI conference. The RIT team designed and implemented an algorithm that allows AI to analyze high-dimensional data sets more efficiently.
A paper on the RIT work, called “Sparse Covariance Modeling in High Dimensions with Gaussian Processes,” was accepted for the Conference on Neural Information Processing Systems (NeurIPS), where academics and industry share work that pushes the boundaries of what is possible in AI. Rui Li, an assistant professor of computing and information sciences at RIT, was invited to give a spotlight presentation at the conference Dec. 5 in Montreal.
NeurIPS is the longest-running and largest artificial intelligence gathering for scientists and industry, with nearly 9,000 attendees this year. In fact, the first batch of 2,000 tickets for the conference sold out in less than 12 minutes.
The RIT research, led by Li, seeks to maintain a balance between speed and accuracy when a computer is working to analyze high-dimensional data sets. The new algorithm essentially helps to condense the number of dimensions while keeping the information statistically accurate.
For artificial intelligence to work, a computer must quickly analyze data with thousands of variables. This is what allows AI to find statistical relationships in data that a human never could. However, even for high-powered computers, these immense calculations can be time and energy consuming.
“This research is motivated by the increasing prevalence of high-dimensional data sets and the computational capacity to analyze and model their volatility and co-volatility varying over some covariates,” said Li, who is also a 2013 graduate of RIT’s Ph.D. program in computing and information sciences. “The study proposed a methodology to scale to high dimensional observations by reducing the dimensions while preserving the latent information; it allows sharing information in the latent basis across covariates.”
For the study, the team designed and implemented an efficient inference algorithm for tractable computation.
“I model the observation elements’ changing covariances as sparse multivariate stochastic processes,” Li said. “To characterize the changing correlations, we jointly model the latent factors and the factor loadings as collections of basis functions that vary with the covariates as Gaussian processes.”
The work has applications in computational biology, where it can help find statistical relationships in thousands of genes over different experimental conditions. Another example of its use is crime occurrence correlations between spatially disjoint regions that evolve over time.
“By capturing the spatio-temporal variations, we can provide key information to predict crime occurrence over time and among regions,” said Li.
Li presented the work along with other top AI researchers in academia and industry. The conference also includes talks and demonstrations from tech giants, including Amazon, Apple and Google.
“NeurIPS is the top-tier venue in AI and machine learning,” Li said. “All the important major players from academia and industry leaders are getting together to present their cutting-edge research. I’m looking forward to meeting some legendary heroes in the fields.”
Other members of the RIT research team include Kishan KC, a computing and information sciences Ph.D. student; Feng Cui, graduate director of RIT’s bioinformatics program and an associate professor; and Anne Haake, dean of RIT’s Golisano College of Computing and Information Sciences. The work was supported by the National Science Foundation (NSF) and National Institutes of Health (NIH).
To learn more about the research, read the paper.


Topics
creativity and innovation
research









Recommended News








			July 15, 2024
		






						RCSD students showcase microchip projects at RIT's summer camp   


WHAM-TV features students from the Rochester City School District as they gain hands-on experience at Microchip Experience Camp.







			July 15, 2024
		






						High school students discover the big impact of tiny microchips during Chip Experience 
					


The immersion, which allowed students to create their own microchip projects, provided full tuition for the week, a $500 stipend per student, housing, meals, and transportation. 







			July 12, 2024
		






						Exploding Kittens game created by RIT alumnus debuts on Netflix
					


Exploding Kittens, the animated series based on the game, premiered on Netflix July 12. The nine-episode first season brings characters from the game to life and introduces new ones. It also coincides with updates to the Netflix Exploding Kittens mobile game and new show-adapted merchandise.







			July 11, 2024
		






						My Phone Was Cloned   


AARP interviews Jonathan Weissman, principal lecturer in the Department of Cybersecurity, about how to prevent criminals from taking over your phone and draining bank accounts. (This content may require a subscription to view.)











More News  



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vaGJyLm9yZy8yMDE4LzEyL3doeS1jb21wYW5pZXMtdGhhdC13YWl0LXRvLWFkb3B0LWFpLW1heS1uZXZlci1jYXRjaC11cNIBAA?oc=5,Why Companies That Wait to Adopt AI May Never Catch Up - Harvard Business Review,2018-12-06,Harvard Business Review,https://hbr.org,"While some companies—most large banks, Ford and GM, Pfizer, and virtually all tech firms—are aggressively adopting artificial intelligence, many are not. Instead they are waiting for the technology to mature and for expertise in AI to become more widely available. They are planning to be “fast followers”—a strategy that has worked with most information technologies. That likely won’t work. It can take a long time to develop and fully implement AI systems, and there are few if any shortcuts to the necessary steps. Once they have been successfully undertaken, scaling—particularly if the company has a plentiful supply of data and the knowledge engineering mastered —can be very rapid. By the time a late adopter has done all the necessary preparation, earlier adopters will have taken considerable market share—they’ll be able to operate at substantially lower costs with better performance. In short, the winners may take all and late adopters may never catch up.",,"While some companies—most large banks, Ford and GM, Pfizer, and virtually all tech firms—are aggressively adopting artificial intelligence, many are not. Instead they are waiting for the technology to mature and for expertise in AI to become more widely available. They are planning to be “fast followers”—a strategy that has worked with most information technologies. That likely won’t work. It can take a long time to develop and fully implement AI systems, and there are few if any shortcuts to the necessary steps. Once they have been successfully undertaken, scaling—particularly if the company has a plentiful supply of data and the knowledge engineering mastered —can be very rapid. By the time a late adopter has done all the necessary preparation, earlier adopters will have taken considerable market share—they’ll be able to operate at substantially lower costs with better performance. In short, the winners may take all and late adopters may never catch up.",,https://schema.org,,WebSite,,https://hbr.org/,,,,,,,,,,,Competitive strategy,,,,,,"{'@type': 'SearchAction', 'target': 'https://hbr.org/search?term={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vbmV3cy5taWNyb3NvZnQuY29tL3RyYW5zZm9ybS9mcm9tLXNlZWQtdG8tc2lwLWhvdy1hbmhldXNlci1idXNjaC1pbmJldi11c2VzLWFpLXRvLWRyaXZlLWdyb3d0aC_SAQA?oc=5,From seed to sip: How Anheuser-Busch InBev uses AI to drive growth | Transform - Microsoft,2018-12-05,Microsoft,https://news.microsoft.com,Anheuser-Busch InBev (AB InBev) is using artificial intelligence to drive growth and innovation across all dimensions of its global brewing business.,,Anheuser-Busch InBev (AB InBev) is using artificial intelligence to drive growth and innovation across all dimensions of its global brewing business.,,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://news.microsoft.com/transform/from-seed-to-sip-how-anheuser-busch-inbev-uses-ai-to-drive-growth/', 'url': 'https://news.microsoft.com/transform/from-seed-to-sip-how-anheuser-busch-inbev-uses-ai-to-drive-growth/', 'name': 'From seed to sip: How Anheuser-Busch InBev uses AI to drive growth | Transform', 'isPartOf': {'@id': 'https://news.microsoft.com/transform/#website'}, 'primaryImageOfPage': {'@id': 'https://news.microsoft.com/transform/from-seed-to-sip-how-anheuser-busch-inbev-uses-ai-to-drive-growth/#primaryimage'}, 'image': {'@id': 'https://news.microsoft.com/transform/from-seed-to-sip-how-anheuser-busch-inbev-uses-ai-to-drive-growth/#primaryimage'}, 'thumbnailUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/382/2018/11/Tassilo-on-Customer-Panel-v1_Resized.jpg', 'datePublished': '2018-12-05T16:56:22+00:00', 'dateModified': '2018-12-11T19:18:30+00:00', 'author': {'@id': ''}, 'description': 'Anheuser-Busch InBev (AB InBev) is using artificial intelligence to drive growth and innovation across all dimensions of its global brewing business.', 'breadcrumb': {'@id': 'https://news.microsoft.com/transform/from-seed-to-sip-how-anheuser-busch-inbev-uses-ai-to-drive-growth/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.microsoft.com/transform/from-seed-to-sip-how-anheuser-busch-inbev-uses-ai-to-drive-growth/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.microsoft.com/transform/from-seed-to-sip-how-anheuser-busch-inbev-uses-ai-to-drive-growth/#primaryimage', 'url': 'https://news.microsoft.com/wp-content/uploads/prod/sites/382/2018/11/Tassilo-on-Customer-Panel-v1_Resized.jpg', 'contentUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/382/2018/11/Tassilo-on-Customer-Panel-v1_Resized.jpg', 'width': 3000, 'height': 2000, 'caption': 'At the Conversations in AI event, Microsoft CVP of Azure Julia White leads a panel discussion with (left to right) Tassilo Festetics, vice president, global solutions, Anheuser-Busch InBev; Abhishek Pani, senior director of AI product and data science, Adobe; Jack Brown, SVP of product and software, Arccos Golf; and Fiona Tan, SVP of customer technology, Walmart Labs.'}, {'@type': 'BreadcrumbList', '@id': 'https://news.microsoft.com/transform/from-seed-to-sip-how-anheuser-busch-inbev-uses-ai-to-drive-growth/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.microsoft.com/transform/'}, {'@type': 'ListItem', 'position': 2, 'name': 'From seed to sip: How Anheuser-Busch InBev uses AI to drive growth'}]}, {'@type': 'WebSite', '@id': 'https://news.microsoft.com/transform/#website', 'url': 'https://news.microsoft.com/transform/', 'name': 'Transform', 'description': 'Digital transformations and the new face of business', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.microsoft.com/transform/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': '', 'url': 'https://news.microsoft.com/transform/author/'}]",,,,,,,,,,,,,,,,"


 
Feature
Taste of success: FoodCloud uses technology to get surplus food to nonprofits more efficiently
By Microsoft Stories Europe

Nov 21, 2022


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vZW5naW5lZXJpbmcuZmIuY29tLzIwMTgvMTIvMDUvYWktcmVzZWFyY2gvZmFpci1maWZ0aC1hbm5pdmVyc2FyeS_SAQA?oc=5,FAIR at 5: Facebook Artificial Intelligence Research accomplishments - Facebook Engineering,2018-12-05,Facebook Engineering,https://engineering.fb.com,Accomplishments from the first five years of Facebook AI Research (FAIR),,"Five years ago, we created the Facebook AI Research (FAIR) group to advance the state of the art of AI through open research for the benefit of all — it’s an effort to understand the nature o…",,https://schema.org,"[{'@type': 'Article', '@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/#article', 'isPartOf': {'@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/'}, 'author': [{'@id': 'https://engineering.fb.com/#/schema/person/image/c6b31f14678d3e2a78f037236cb1a13a'}, {'@id': 'https://engineering.fb.com/#/schema/person/image/2e7d0c6ab40bd076c3cf6f98088f0c34'}, {'@id': 'https://engineering.fb.com/#/schema/person/image/7bd9bb1d565cd3dae3c401281f6ac0db'}], 'headline': 'FAIR turns five: What we&#8217;ve accomplished and where we&#8217;re headed', 'datePublished': '2018-12-05T16:55:30+00:00', 'dateModified': '2020-03-24T04:38:57+00:00', 'mainEntityOfPage': {'@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/'}, 'wordCount': 3102, 'publisher': {'@id': 'https://engineering.fb.com/#organization'}, 'image': {'@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/#primaryimage'}, 'thumbnailUrl': 'https://engineering.fb.com/wp-content/uploads/2018/12/FAIR_homepage.jpg', 'articleSection': ['AI Research', 'Open Source'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/', 'url': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/', 'name': 'FAIR at 5: Facebook Artificial Intelligence Research accomplishments', 'isPartOf': {'@id': 'https://engineering.fb.com/#website'}, 'primaryImageOfPage': {'@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/#primaryimage'}, 'image': {'@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/#primaryimage'}, 'thumbnailUrl': 'https://engineering.fb.com/wp-content/uploads/2018/12/FAIR_homepage.jpg', 'datePublished': '2018-12-05T16:55:30+00:00', 'dateModified': '2020-03-24T04:38:57+00:00', 'description': 'Accomplishments from the first five years of Facebook AI Research (FAIR)', 'breadcrumb': {'@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/#primaryimage', 'url': 'https://engineering.fb.com/wp-content/uploads/2018/12/FAIR_homepage.jpg', 'contentUrl': 'https://engineering.fb.com/wp-content/uploads/2018/12/FAIR_homepage.jpg', 'width': 1600, 'height': 900}, {'@type': 'BreadcrumbList', '@id': 'https://engineering.fb.com/2018/12/05/ai-research/fair-fifth-anniversary/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://engineering.fb.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'FAIR turns five: What we&#8217;ve accomplished and where we&#8217;re headed'}]}, {'@type': 'WebSite', '@id': 'https://engineering.fb.com/#website', 'url': 'https://engineering.fb.com/', 'name': 'Engineering at Meta', 'description': 'Engineering at Meta Blog', 'publisher': {'@id': 'https://engineering.fb.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://engineering.fb.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://engineering.fb.com/#organization', 'name': 'Meta', 'url': 'https://engineering.fb.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://engineering.fb.com/#/schema/logo/image/', 'url': 'https://engineering.fb.com/wp-content/uploads/2023/08/Meta_lockup_positive-primary_RGB.jpg', 'contentUrl': 'https://engineering.fb.com/wp-content/uploads/2023/08/Meta_lockup_positive-primary_RGB.jpg', 'width': 29011, 'height': 12501, 'caption': 'Meta'}, 'image': {'@id': 'https://engineering.fb.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/Engineering/', 'https://twitter.com/fb_engineering']}, [], {'@type': 'Person', '@id': 'https://engineering.fb.com/#/schema/person/image/c6b31f14678d3e2a78f037236cb1a13a', 'name': 'Yann LeCun', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://engineering.fb.com/#/schema/person/image/23494c9101089ad44ae88ce9d2f56aac', 'url': 'https://secure.gravatar.com/avatar/?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/?s=96&d=mm&r=g', 'caption': 'Yann LeCun'}, 'url': 'https://engineering.fb.com/author/yann-lecun/'}, {'@type': 'Person', '@id': 'https://engineering.fb.com/#/schema/person/image/2e7d0c6ab40bd076c3cf6f98088f0c34', 'name': 'Jerome Pesenti', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://engineering.fb.com/#/schema/person/image/23494c9101089ad44ae88ce9d2f56aac', 'url': 'https://secure.gravatar.com/avatar/?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/?s=96&d=mm&r=g', 'caption': 'Jerome Pesenti'}, 'url': 'https://engineering.fb.com/author/jerome-pesenti/'}, {'@type': 'Person', '@id': 'https://engineering.fb.com/#/schema/person/image/7bd9bb1d565cd3dae3c401281f6ac0db', 'name': 'Mike Schroepfer', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://engineering.fb.com/#/schema/person/image/93d47a50482c698bc37188c1772434bb', 'url': 'https://engineering.fb.com/wp-content/uploads/2021/10/schrepauthorpic.jpeg?w=192&h=181&crop=1', 'contentUrl': 'https://engineering.fb.com/wp-content/uploads/2021/10/schrepauthorpic.jpeg?w=192&h=181&crop=1', 'width': 192, 'height': 181, 'caption': 'Mike Schroepfer'}, 'description': ""Mike Schroepfer is the Chief Technology Officer at Facebook. He leads the development of the technology and teams that enable Facebook to connect billions of people around the world and make breakthroughs in fields like artificial intelligence and virtual reality. Before Facebook, Mike was Vice President of Engineering at Mozilla Corporation. He led the global and open product development process behind Firefox. Prior to that he was a distinguished engineer at Sun Microsystems, which acquired his company, CenterRun. He began his career working at startups including a digital effects company where he developed software used in major motion pictures. Mike holds a bachelor's and master's degree in computer science from Stanford University."", 'url': 'https://engineering.fb.com/author/mike-schroepfer/'}]",,,,,,,,,,,,,,,,"


			POSTED ON DECEMBER 5, 2018 TO AI Research, Open Source
FAIR turns five: What we’ve accomplished and where we’re headed 


 


				By Yann LeCun, Jerome Pesenti, Mike Schroepfer 



















Five years ago, we created the Facebook AI Research (FAIR) group to advance the state of the art of AI through open research for the benefit of all — it’s an effort to understand the nature of intelligence so that we might create intelligent machines. Since then, FAIR has learned a lot and grown into an international research organization with labs in Menlo Park, New York, Paris, Montreal, Tel Aviv, Seattle, Pittsburgh, and London. AI has become so central to Facebook that FAIR is now part of a larger Facebook AI organization that works on all aspects of AI R&D, from fundamental research to applied research and technology development.
FAIR has applied an open model to all aspects of our work, collaborating broadly with the community. Our teams publish cutting-edge research early and often, and open-source our research code, data sets, and tools like PyTorch, fastText, FAISS, and Detectron where possible. The approach has been successful for advancing the state of AI research. This year, FAIR’s researchers have won recognition, including Best Paper awards, at ACL, EMNLP, CVPR, and ECCV, and Test of Time awards at ECCV, ICML, and NeurIPS. We know working in the open allows everyone to make faster progress on AI.
Making machines truly intelligent is a scientific challenge as well as a technological and product engineering challenge. A significant part of FAIR’s research focuses on fundamental questions about the keys to reasoning, prediction, planning, and unsupervised learning. And in turn, these areas of investigation require better theoretical understanding in fields such as generative models, causality, high-dimensional stochastic optimization, and game theory. These long-term research explorations are required to unlock the full future potential of artificial intelligence. Of all the projects we’ve tackled over the past five years, we’ve picked a handful that show how FAIR has approached its mission, contributed to our field, and made an impact on the world.

This timeline highlights many of FAIR’s projects over the past five years.

Memory networks
In 2014, researchers at FAIR identified an intrinsic limitation in neural networks — long-term memory. Though neural nets could learn during the process of training on data sets, once these systems were in operation they were typically unable to store new information to help solve a particular task later on. So we developed a new class of learning-model-enabled machines that remembered enough of their interactions to answer general knowledge questions and refer to previous statements in a conversation. In our initial 2014 paper on this approach, we tested this by having a memory-enabled network answer questions about the plot of the Lord of the Rings series, based on a short summary provided to it. The system was able to learn simple linguistic patterns and generalize the meanings of unknown words, correctly answering, for example, that at the end of the story Frodo was in the shire and the ring was in Mount Doom.

FAIR continued to develop this approach over the next two years, extending the research and exploring related areas. With StackRNN, the team augmented an RNN with push-pop stacks that could be trained from sequences in an unsupervised manner. With bAbl, the team built data sets of question-answering tasks to help benchmark performance in text understanding. bAbI is now part of the open source project ParlAI that includes thousands of dialogue examples, ranging from responses to restaurant-reservation requests to answers about movie casts. We also iterated on memory network architectures, making them increasingly useful for real-world applications. These updates included end-to-end memory networks, which allowed them to work with less supervision, and then key-value memory networks, which could be trained by generalizing from completely unsupervised sources, such as Wikipedia entries.
Self-supervised learning and generative models
It has long been one of FAIR’s priorities to scale up AI by exploiting large amounts of unlabeled data through self-supervised learning (SSL). With SSL, a machine can learn abstract representations of the world by being fed unlabeled images, video, or audio. An example of SSL is showing video clips to a machine and training it to predict future frames. By learning to predict, the machine captures knowledge about how the world works and learns good abstract representations of it. Using SSL, machines learn by observation, a bit like human and animal babies do, and accumulate large quantities of background knowledge about the world. The hope is that a form of common sense could emerge. Acquiring predictive world models is also key to building AI systems that can reason, predict the consequences of their actions, and act in the real world.
In 2014, our friends from MILA at Université de Montréal proposed a new unsupervised learning method called generative adversarial networks (GANs). We were immediately fascinated by the potential applications of self-supervised learning. But as promising as GANs looked, they had been demonstrated only on “toy” problems. Starting in 2015, we published a series of papers that were instrumental in convincing the research community that GANs really worked. GANs are used to train machines to make predictions under uncertainty by pitting two neural networks against each other. In a typical GAN architecture, the generator network produces data — such as an image or a video frame — from a bunch of random numbers (and perhaps past video frames). Meanwhile, the discriminator network has to differentiate between real data — real images and video frames — and the generator’s “false” outputs. This ongoing contest optimizes both networks and leads to increasingly better predictions.
Each of our papers focused on different variants of GANs, including image generation in Deep Convolutional Generative Adversarial Networks (DCGANs) and Laplacian Adversarial Networks (LAPGANs), and video prediction in Adversarial Gradient Difference Loss Predictors (AGDLs). But our collective contribution was to show that GANs could “invent” realistic-looking images of, for example, nonexistent bedrooms, faces, or dogs.

This example shows a series of fashion designs created by generative networks.

Other researchers have since picked up on our work in GANs, using them to produce stunning high-resolution images. But GANs are notorious for being very difficult to tune and for often failing to converge. So FAIR has explored ways to make GANs more reliable by focusing on understanding adversarial training at the theoretical level. In 2017, we introduced the Wasserstein GAN (WGAN) method, which proposed a way to make the discriminator “smooth” and more efficient, in order to tell the generator how to improve its predictions. The WGAN was essentially the first GAN whose convergence was robust on a wide range of applications. This avoided the need to balance the output of discriminators and generators as the system is optimized, which results in significantly more learning stability, particularly for high-resolution image generation tasks.
Since then, FAIR researchers and Facebook engineers have used adversarial training methods for a range of applications, including long-term video prediction and the creation of fashion pieces. But the really interesting part of GANs is what they mean for the future. As a brand-new technique that wasn’t available to us even a few years ago, it opens up new opportunities to generate data in areas where we have little data. It will likely be a key tool on our quest to build machines that can learn on their own.
Text classification that scales
Text understanding isn’t a single task but a sprawling matrix of subtasks that organize words, phrases, and entire data sets of language into a format that machines can process. But before much of that work can take place, the text itself has to be classified. Years ago, NLP models such as word2vec classified text through extensive, word-based training, with the model assigning a distinct vector to each word in its training data set. For Facebook, the status quo was simply too slow and too dependent on fully supervised data. We needed text classification that could eventually work with hundreds or even thousands of languages, many of which don’t lend themselves to extensive data sets. And the system needed to scale across the entire range of text-based features and services, as well as our NLP research.
So in 2016 FAIR built fastText, a framework for rapid text classification and learning word representations that takes into account the larger morphology of the words it classifies. In a paper published in 2017, FAIR proposed a model that assigns vectors to “subword units” (e.g., sequences of 3 or 4 characters) rather than to whole words, allowing the system to create representations for words that didn’t appear in training data. The end result was a model whose classifications can scale to billions of words, learning from novel, untrained words while also training significantly faster than typical deep learning classifiers. In some cases, training that had taken several days with previous models was finished in a few seconds with fastText.
FastText has proved to be a vital contribution to the study and application of AI-based language understanding, and it’s now available in 157 languages. The original paper has been cited more than a thousand times in other publications, and fastText remains one of the most commonly used baselines for word embedding systems. Outside of Facebook, fastText has been used for a diverse array of applications, ranging from the familiar, such as suggesting message replies, to the exotic — an “algorithmic theater” production called The Great Outdoors, which used fastText to help select and order public internet comments that would become the script for each performance. The framework is deployed at Facebook to classify text across 19 languages, and it’s used in tandem with DeepText for translation and natural language understanding.
Cutting-edge translation research
Fast, accurate, and flexible translation is a key component of helping people around the world to communicate. So, in the early days of FAIR, we set out to find a new approach that would outperform statistical machine translation, which was then the state-of-the-art method. It took three years of work to build a CNN-based neural machine translation (NMT) architecture with the right combination of speed, accuracy, and learning. (FAIR published a paper in 2017 detailing its work.) In our experiments, this approach resulted in a 9x increase in speed over RNNs while maintaining state-of-the-art accuracy rates.

Not only are our multi-hop CNNs easier to train on more limited data sets, but they’re also better able to understand misspelled or abbreviated words, such translating “tmrw” as “mañana.” Overall, the NMT transition has improved accuracy by an average of 11 percent and sped delivery of translations by 2.5x. And in addition to improving our own systems, we open-sourced the code and models for fairseq, the sequence-to-sequence modeling toolkit that we used for our CNN-based system.
To sidestep the need for vast training data sets for translations (often called corpora), we’re also pursuing other methods, such as multilingual embeddings, which can enable training across multiple languages. Last year, we released MUSE, an open source Python library that provides two different methods for learning multilingual embeddings: a supervised approach, using the 110 bilingual dictionaries included in the release, and a newer, unsupervised method that allows new bilingual dictionaries to be built between two languages without parallel corpora. We followed this with an EMNLP award-winning paper demonstrating a dramatic improvement in unsupervised training for translation of full sentences.

Two-dimensional word embeddings in two languages (left) can be aligned via a simple rotation (right). After the rotation, word translation is performed via nearest neighbor search.
By sharing research and resources like fairseq and MUSE, we’re encouraging others to take advantage of faster, more accurate, and more versatile translation techniques, whether for research purposes or production applications.
AI tools that level everybody up
Progress in AI depends not only on breakthrough ideas but also on having powerful platforms and tools for testing and then implementing them. FAIR has prioritized building these systems and sharing them with the world. In 2015, we open-sourced the Torch deep learning modules created by FAIR to speed up training of larger neural nets. We released Torchnet in 2016 to make it easier for the community to rapidly build effective and reusable learning systems. Soon after, we introduced Caffe2, our modular deep learning framework for mobile computing that is now running neural nets on more than 1 billion phones around the world. And then we collaborated with Microsoft and Amazon to release ONNX, a common representation for neural networks that makes it simple to move between frameworks as needed.
In particular, our work on PyTorch demonstrates FAIR’s commitment to rapid iteration, meaningful impact, open systems, and collaboration with the AI community. PyTorch began as a small effort with just a handful of FAIR researchers. Rather than build a completely new deep learning framework, we chose to build on top of the Torch open source library, and we integrated with acceleration libraries from Intel and NVIDIA to maximize speed. We announced PyTorch at the beginning of 2017 — less than two years ago! It’s now the second-fastest-growing open source project on GitHub and the framework of choice for AI developers around the globe. In October, hundreds of members of the AI community attended the first PyTorch Developers Conference to hear presentations from Caltech, FAIR, fast.ai, Google, Microsoft, NVIDIA, Tesla, and many others. And now the release of PyTorch 1.0 integrates the modular, production-oriented capabilities of Caffe2 and ONNX to provide a seamless path from research prototyping to production deployment, with deep integration with cloud services and technology providers.

PyTorch is integrated in Facebook products that are used by billions of people, as well as in FAIR research projects such as fairseq(-py), which accelerates translations by 80 percent over the previous version. PyTorch is also used by ELF OpenGo, our reinforcement learning bot; our EmbodiedQA work; and our successful effort to train image recognition networks on billions of public images with hashtags. And beyond Facebook, PyTorch powers projects from AllenNLP to NYU professor Dr. Narges Razavian’s work to use AI to improve early detection of disease. And now Udacity and fast.ai are helping even more people get going with PyTorch.
Whereas PyTorch made it faster and easier to take models from research to production, our work on Facebook AI Similarity Search (FAISS) has accelerated large-scale search. FAISS began as an internal research project to better utilize GPUs for identifying similarities related to user preferences, and it is now the fastest available library of its kind and able to leverage billion-scale data sets. FAISS has already opened up possibilities for recommendation engines and AI-based assistant systems. We released it as an open source library last year, and FAISS has been widely adopted by the developer community, with more than 5,000 GitHub stars and integration into NVIDIA’s GPU-accelerated scikit-learn library, cuML.
A new benchmark for computer vision
Seeking to understand the nature of intelligence is a study in multisensory modalities, but the story of FAIR’s past five years is really bookended by advancements in computer vision. Before FAIR was born, there was a small team of AI specialists at Facebook seeking to better understand how pixels represent people in images, so that the right photos might be surfaced for people at the right times. Fast-forward to 2017, and FAIR researchers had won the International Conference on Computer Vision Best Paper for Mask R-CNN, combining the best of computer vision worlds: object detection with semantic segmentation.

As the paper stated, “Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners.” The work rapidly became the basis for computer vision research in the broader AI community. The technology was then integrated into our open source Detectron system, bringing the meta algorithm’s intuitive ease of use, speed, and accuracy to researchers everywhere.
This foundational work now underpins a myriad of Facebook’s current systems, such as automatic alt text to help the visually impaired and tools that detect objectionable content. It’s also groundwork for future applications: AR features across our platforms and Smart Camera in Portal have roots in this work. This research continues, with the focus moving to video, where our DensePose project will help our systems understand video content as well as they understand photos.

Demonstration of DensePose creating a 3D surface on top of people as they move.
Image understanding: Faster training and bigger data sets
Computer vision isn’t the only area where FAIR has looked to address scale challenges. FAIR partnered with Facebook’s Applied Machine Learning (AML) team to tackle the limitations of training speed and training set sizes, as well as the lack of supervised data sets. In a paper published earlier this year, the team at AML discussed how they trained image recognition networks on large sets of public images with hashtags, the biggest of which included 3.5 billion images and 17,000 hashtags. It was an order of magnitude more than any previous published work and the results were the best published results for the industry to-date: 85.4% accuracy.
This breakthrough was made possible by FAIR’s research on training speed — FAIR was able to train ImageNet an order of a magnitude faster that previous state of the art. They got the training time down to under one hour, showing how to perform SGD training with minibatch sizes an order of magnitude larger than were previously considered practical. In their words: “To achieve this result, we adopt a linear scaling rule for adjusting learning rates as a function of minibatch size and develop a new warmup scheme that overcomes optimization challenges early in training.”
With this improvement in training speed, we were able to perform directed research on weakly supervised learning on bigger data sets than was previously possible. Both results show the clear value of a partnership between FAIR and AML. When the science of solving AI is buttressed by practical research and application in production, we see rapid, state-of-the-art results.
The future of FAIR
When we created FAIR, our ultimate goal was to understand intelligence, to discover its fundamental principles, and to make machines significantly more intelligent. Our goal has not changed. We’re continuing to expand our research efforts into areas such as developing machines able to acquire models of the world through self-supervised learning, training machines to reason, and training them to plan and conceive complex sequences of actions. That is one reason we are working on robotics, visual reasoning, and dialogue systems. We’ve described some of the more concrete projects that show how far we’ve come, but we still have far to go in scientific and technological advances to make machines sufficiently intelligent to help people in their daily lives.
Share this:FacebookThreadsXLinkedInHacker NewsEmail

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vd3d3LmZhc3Rjb21wYW55LmNvbS85MDI3NjM1Ni9zdG9wLWZyZWFraW5nLW91dC1hYm91dC1yb2JvdHMv0gEA?oc=5,Stop freaking out about robots - Fast Company,2018-12-05,Fast Company,https://www.fastcompany.com,Automation need not be stirred into a doom-laden soup along with Trump and climate change. Here are three reasons why we should welcome the march of the robots.,,"Counterintuitive as it may seem, automation can play a key role in creating more and better jobs.",Automation need not be stirred into a doom-laden soup along with Trump and climate change. Here are three reasons why we should welcome the march of the robots.,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/#article', 'isPartOf': {'@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/'}, 'author': [{'@type': 'Person', '@id': 'https://www.fastcompany.com/user/kevin-mccullagh#/schema/person/bf2fb7d1825a1df3ca308ad0bf48591e', 'name': 'Kevin McCullagh', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/kevin-mccullagh#/schema/person/image/f75cbf93ba65c2cbb98edff0a5b5c32a', 'url': 'https://secure.gravatar.com/avatar/7a760f2652641accf04427193a16fae6?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/7a760f2652641accf04427193a16fae6?s=96&d=mm&r=g', 'caption': 'Kevin McCullagh'}, 'url': 'https://www.fastcompany.com/user/kevin-mccullagh', 'description': '<p>Kevin McCullagh is the founder of Plan, a product strategy consultancy in London. He also writes, speaks, and curates conferences on design, business, and society. <a href=""https://www.plan.bz"">www.plan.bz</a><br />\n<a href=""https://twitter.com/kevinmccull"" target=""_blank"">@kevinmccull</a></p>'}], 'headline': 'Stop freaking out about robots', 'datePublished': '2018-12-05T12:00:28+00:00', 'dateModified': '2018-12-05T16:35:10+00:00', 'mainEntityOfPage': {'@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/'}, 'wordCount': 1583, 'publisher': {'@id': 'https://www.fastcompany.com/#organization'}, 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots#primaryimage', 'url': 'https://images.fastcompany.com/image/upload/wp-cms/uploads/2018/12/p-1-90276356-rage-against-the-machine.jpg', 'contentUrl': 'https://images.fastcompany.com/image/upload/wp-cms/uploads/2018/12/p-1-90276356-rage-against-the-machine.jpg', 'caption': 'Stop freaking out about robots'}, 'thumbnailUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2018/12/p-1-90276356-rage-against-the-machine.jpg', 'keywords': ['Amazon', 'automation', 'byline', 'byline_Kevin McCullagh', 'elon musk', 'Fiat', 'google', 'Paul Krugman', 'perspective', 'robots', 'strada', 'Toyota'], 'articleSection': ['Design'], 'inLanguage': 'en-US', 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://cms.mansueto.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/', 'url': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/', 'name': 'Stop freaking out about robots - Fast Company', 'isPartOf': {'@id': 'https://www.fastcompany.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/#primaryimage'}, 'image': {'@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/#primaryimage'}, 'thumbnailUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2018/12/p-1-90276356-rage-against-the-machine.jpg', 'datePublished': '2018-12-05T12:00:28+00:00', 'dateModified': '2018-12-05T16:35:10+00:00', 'description': 'Automation need not be stirred into a doom-laden soup along with Trump and climate change. Here are three reasons why we should welcome the march of the robots.', 'breadcrumb': {'@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/']}], 'author': [{'@type': 'Person', '@id': 'https://www.fastcompany.com/user/kevin-mccullagh#/schema/person/bf2fb7d1825a1df3ca308ad0bf48591e', 'name': 'Kevin McCullagh', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/kevin-mccullagh#/schema/person/image/f75cbf93ba65c2cbb98edff0a5b5c32a', 'url': 'https://secure.gravatar.com/avatar/7a760f2652641accf04427193a16fae6?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/7a760f2652641accf04427193a16fae6?s=96&d=mm&r=g', 'caption': 'Kevin McCullagh'}, 'url': 'https://www.fastcompany.com/user/kevin-mccullagh', 'description': '<p>Kevin McCullagh is the founder of Plan, a product strategy consultancy in London. He also writes, speaks, and curates conferences on design, business, and society. <a href=""https://www.plan.bz"">www.plan.bz</a><br />\n<a href=""https://twitter.com/kevinmccull"" target=""_blank"">@kevinmccull</a></p>'}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/#primaryimage', 'url': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2018/12/p-1-90276356-rage-against-the-machine.jpg', 'contentUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2018/12/p-1-90276356-rage-against-the-machine.jpg', 'width': 1920, 'height': 1080, 'caption': '[Source Image: PhonlamaiPhoto/iStock]'}, {'@type': 'BreadcrumbList', '@id': 'https://www.fastcompany.com/90276356/stop-freaking-out-about-robots/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.fastcompany.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'Stop freaking out about robots'}]}, {'@type': 'WebSite', '@id': 'https://www.fastcompany.com/#website', 'url': 'https://www.fastcompany.com/', 'name': 'Fast Company', 'description': '', 'publisher': {'@id': 'https://www.fastcompany.com/#organization'}, 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.fastcompany.com/#organization', 'name': 'Fast Company', 'url': 'https://www.fastcompany.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/#/schema/logo/image/', 'url': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms-2/2024/03/fc_logo.png', 'contentUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms-2/2024/03/fc_logo.png', 'width': 696, 'height': 696, 'caption': 'Fast Company'}, 'image': {'@id': 'https://www.fastcompany.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/FastCompany/', 'https://x.com/FastCompany', 'https://fastcompany.social/@fastcompany', 'https://www.linkedin.com/company/fast-company/']}, {'@type': 'Person', '@id': 'https://www.fastcompany.com/user/kevin-mccullagh#/schema/person/bf2fb7d1825a1df3ca308ad0bf48591e', 'name': 'Kevin McCullagh', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/kevin-mccullagh#/schema/person/image/f75cbf93ba65c2cbb98edff0a5b5c32a', 'url': 'https://secure.gravatar.com/avatar/7a760f2652641accf04427193a16fae6?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/7a760f2652641accf04427193a16fae6?s=96&d=mm&r=g', 'caption': 'Kevin McCullagh'}, 'url': 'https://www.fastcompany.com/user/kevin-mccullagh', 'description': '<p>Kevin McCullagh is the founder of Plan, a product strategy consultancy in London. He also writes, speaks, and curates conferences on design, business, and society. <a href=""https://www.plan.bz"">www.plan.bz</a><br />\n<a href=""https://twitter.com/kevinmccull"" target=""_blank"">@kevinmccull</a></p>'}]",,,,,,,,,,,,,,,,"A 2017 New Yorker cover by R Kikuo Johnson painted a dystopian scene. Robots pace and trundle past a homeless human kneeling at their feet, while one deigns to lower its gaze to flip a few coins in his cup. The image expressed perfectly the pervading, and misplaced, pessimism around the impacts of automation not just among East Coast sophisticates, but across the U.S. and the developed world. In fact, it is a view that has even infiltrated one of the last pockets of optimism about the future: the wide-eyed utopianism of Silicon Valley.Tech Support by R. Kikuo Johnson. [Image: R. Kikuo Johnson (illustration)/The New Yorker]When even the technorati are starting to agonize over the future of artificial intelligence and the perils of automation, you have to wonder. Elon Musk–often a champion of the human ability to improve its condition through material progress–is becomingfearmonger-in-chief of the artificial intelligence apocalypse: “There certainly will be job disruption. Because what’s going to happen is robots will be able to do everything better than us . . . I mean all of us.”The most widely held fear, and one that taps into our earliest fears about industrialization, is of mass unemployment as robots take most of the jobs. Other critiques of the proliferation of artificial intelligence and increased automation are more nuanced. Some say that it will drive even greater inequality between the “cognitive elite” and the deskilled masses. The Guardian reflected a widespread concern over the potential concentration of power by the robot-owning corporations: “If you think inequality is a problem now, imagine a world where the rich can get richer all by themselves.”These concerns lie behind growing calls for Universal Basic Income, robot taxes, and the break-up of Big Tech giants like Google and Amazon. But the situation isn’t as grim as we might think. Automation need not be stirred into a doom-laden soup along with Trump and climate change. In fact, if we step back from the narrow focus on technology and take a wider historical, economic, and humanist view, the picture is far from bleak. Counterintuitive as it may seem, automation can play a key role in creating more and better jobs, and rising prosperity. There are broadly three reasons to be cheerful about the march of the robots.[Image: Hulton Archive/Getty Images]Automation drives growthSince the Industrial Revolution, the automation of human labor has run hand-in-hand with productivity gains, economic growth, and an increase in the number of jobs and prosperity. It is productivity growth that largely accounts for why most of us are six times better off than our great-grandparents. As Paul Krugman put it, in economics, “Productivity isn’t everything–but in the long run, it’s almost everything.” How can automating work create more jobs?A classic example of how this process can work is that, during the Industrial Revolution, 98% of the manual labor involved in weaving cloth was mechanized. But, despite the concerns of the Luddites, the number of textile workers in the U.K. exploded. As costs plummeted, demand grew, and so did the size of the industry–and therefore job numbers. The cake got bigger. The jobs also changed from hand weaving to operating the weaving machines. A more recent example is the impact of Electronic Discovery Software (EDS) on junior lawyers and paralegals, who traditionally spent the bulk of their time sifting through piles of documents. EDS was first applied in the 1990s, and did the job more quickly and more accurately than humans. Yet paralegal and junior lawyer jobs have grown quicker than the rest of the workforce since 2000.How so? As searching became cheaper and quicker, law firms searched more documents, and judges allowed more expansive discovery requests. Economists have a name for the intuitive, but mistaken, idea that there is a certain amount of work to do in an economy, and if productivity increases there will be fewer jobs to go around–the Lump of labor fallacy. There are, of course, occupations that fared less well in the face of technology, such as typesetters, once graphic designers adopted desktop-publishing software in the 1990s. But the general pattern is that machines take over mundane tasks, and humans move on to do more sophisticated–and often meaningful–work that machines can’t do yet.And the net effect in a buoyant economy is job growth. A long view reveals that each round of automation brings similar fears–when the first printed books with illustrations began to appear in the 1470s, wood engravers in the German city of Augsburg protested and stopped the presses. In fact, their skills turned out to be in higher demand than before, as more books needed illustrating.Automation makes work more rewardingThe general assumption is that if the robot doesn’t replace you, it will deskill you. Yet a study by the Boston University School of Law into the impact of automation on 270 occupations in the U.S. since 1950 found that only one was eliminated: lift operators.The other jobs were partially automated and in many cases, this automation led to more jobs, often more skilled positions. The impact of ATMs on bank clerks is a case in point. The number of branch employees has grown since cash machines were first installed: ATMs allowed banks to operate branches at lower cost, enabling them to open many more. At the same time, banks morphed into financial-service providers, giving clerks more opportunity for upward job mobility. Machines generally take on the simple tasks, as humans move to more complex–and often more meaningful–work.[Photo: Franck V./Unsplash]Overestimation of machines, underrating humansIn 1979, Fiat ran a television ad in the U.K. for the Strada with the tagline, “Handbuilt by robots.” In the 1980s, the march of the robots was seen as inevitable and, as with the assembly line, car production would lead the way. Forty years later, Toyota, the guru of manufacturing innovation, has robots doing less than 8% of the work on the factory floor–a ratio that hasn’t changed in 15 years. When asked why, the president of Toyota Motor Manufacturing, Kentucky, replied that “machines are good for repetitive things, but they can’t improve their own efficiency or the quality of their work. Only people can.”Even in manufacturing, automation isn’t as easy as many assume. Pessimists tend to overestimate the extent to which humans can be replaced and how fast it will happen. They share a faulty assumption with artificial-intelligence optimists, who look forward to “singularity,” when computer intelligence will supposedly surpass our own. They see impressive breakthroughs in narrow and bounded machine-learning problems, like beating humans at board games, and extrapolate that this singularity is inevitable and around the corner.advertisementThis assumption runs far ahead of current knowledge. Neuroscientists are only scratching the surface of understanding how our brains perceive, learn, and understand, while human consciousness is still a highly contested topic in both philosophy and psychology. We’re a long way from understanding human intelligence, never mind surpassing it. Gloom merchants tend to imbue technology with superpowers while running down human ingenuity. Surely our perception, curiosity, creativity, critical thinking, judgment, and adaptability will drive the world forward–aided by more automation.We shape technology and, of course, it shapes us, but it does not define our future. Social and political forces are pivotal. The fatalism around robot-driven inequality suffers from peering at the future through technology blinkers. If robots drive inequality, how is it that Sweden has three times as many robots as the U.K. as a proportion of manufacturing workers–and much lower levels of inequality? Many other factors feed into the U.K.’s relatively high levels of inequality, such as low investment in education and in research and development, an overreliance on cheap labor, and an erosion of union power.It is no coincidence that inequality in the U.K. soared between 1979 and 1990, during Margaret Thatcher’s assault on the unions. Fretting about robot-induced impoverishment tomorrow obscures the real policy-related causes of wage suppression today. With living standards stagnating across the developed world, boosting productivity growth should be a pressing priority. Far from running scared of it, we should be ramping up our investment in automation.Of course, the road to semi-automated economic renewal will not be pain-free–many jobs will be lost in parts of the economy, while others will be created elsewhere.But even more will be lost if the economy continues to ossify. This is where the state has a key role to play in devising and implementing an industrial renaissance strategy to navigate the disruption caused by the next wave of automation. This should include investing in R&D in job-creating sectors such as autonomous transportation, virtual and augmented reality, and data security, as well as introducing automation to the backward construction industry as part of a desperately needed expansion in housebuilding. There is, after all, no shortage of problems to solve and work to be done, including in human-intensive sectors that desperately need revitalization, such as healthcare and infrastructure.An ambitious program to support and retrain workers for the parts of the economy that will grow as a result of automation is also needed. In short, timidity, not technology, is the problem. We have nothing to fear, but the fear of robots itself.Kevin McCullagh is founder of the London-based consultancy Plan. Recognize your technological breakthrough by applying to this year’s Next Big Things in Tech Awards! Extended Deadline to Apply: Friday, July 19.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvc2hvdy90aGUtcm9ib3RzLWFyZS1jb21pbmctd2lsbC10aGV5LXdvcmstd2l0aC11c9IBUmh0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvYW1wL3Nob3cvdGhlLXJvYm90cy1hcmUtY29taW5nLXdpbGwtdGhleS13b3JrLXdpdGgtdXM?oc=5,The robots are coming. Will they work with us? - PBS NewsHour,2018-12-05,PBS NewsHour,https://www.pbs.org,"In the latest installment of our Future of Work series, Miles O’Brien visits MIT’s Interactive Robotics Laboratory to understand the “new species” of robots scientists are designing to work alongside humans safely. Though the devices often excel at repetitive tasks, will they be able to function just as well in dynamic environments, such as the faced-paced world of health care?",,"In the latest installment of our Future of Work series, Miles O’Brien visits MIT’s Interactive Robotics Laboratory to understand the “new species” of robots scientists are designing to work alongside humans safely. Though the devices often excel at repetitive tasks, will they be able to function just as well in dynamic environments, such as the faced-paced world of health care?","In the latest installment of our Future of Work series, Miles O’Brien visits MIT’s Interactive Robotics Laboratory to understand the “new species” of robots scientists are designing to work alongside humans safely. Though the devices often excel at repetitive tasks, will they be able to function just as well in dynamic environments, such as the faced-paced world of health care?",,,,,,,,,,,,,,,,Nation,,"






Full Episode










Sunday, Jul 14


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmVudHJlcHJlbmV1ci5jb20vc2NpZW5jZS10ZWNobm9sb2d5L2hvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jYW4taGVscC15b3UtYmV0dGVyLW1hbmFnZS15b3VyLzMyMzU1NtIBAA?oc=5,How Artificial Intelligence Can Help You Better Manage Your Time - Entrepreneur,2018-12-03,Entrepreneur,https://www.entrepreneur.com,"Make time management easy, and see productivity increase.","['Science & Technology', 'Thought Leaders', 'Productivity', 'Time Management', 'Entrepreneurs', 'Technology', 'Artificial Intelligence']","Make time management easy, and see productivity increase.","Make time management easy, and see productivity increase.",https://schema.org,,BreadcrumbList,How Artificial Intelligence Can Help You Better Manage Your Time,https://www.entrepreneur.com,"{'@type': 'WebPage', '@id': 'https://www.entrepreneur.com/science-technology/how-artificial-intelligence-can-help-you-better-manage-your/323556'}",https://assets.entrepreneur.com/content/3x2/2000/20181203222512-GettyImages-953313446.jpeg?format=pjeg&auto=webp&width=300&crop=1:1,"['https://assets.entrepreneur.com/content/3x2/2000/20181203222512-GettyImages-953313446.jpeg?format=pjeg&auto=webp&crop=1:1', 'https://assets.entrepreneur.com/content/3x2/2000/20181203222512-GettyImages-953313446.jpeg?format=pjeg&auto=webp&crop=4:3', 'https://assets.entrepreneur.com/content/3x2/2000/20181203222512-GettyImages-953313446.jpeg?format=pjeg&auto=webp&crop=16:9']",Science & Technology,"{'@type': 'Person', 'name': 'Raj Narayanaswamy', 'image': 'https://assets.entrepreneur.com/content/1x1/300/20160722134255-Raj-300dpi.jpeg', 'sameAs': ['https://x.com/rajn65', 'https://www.linkedin.com/in/narayanaswamyraj', 'http://www.replicon.com/company/blog', 'http://www.replicon.com/'], 'description': 'As CEO, Raj Narayanaswamy is responsible for executing Replicon’s strategic goals and leading corporate initiatives. With more than 25 years of software development and senior management experience, he is widely recognized for his visionary approach in developing innovative software applications.', 'worksFor': 'Replicon', 'jobTitle': 'Co-founder and co-CEO', 'url': 'https://www.entrepreneur.com/author/raj-narayanaswamy'}",,"{'@type': 'Organization', 'name': 'Entrepreneur', 'logo': {'@type': 'ImageObject', 'url': 'https://assets.entrepreneur.com/static/20240220061344-entrepreneur-logo-black.svg'}, 'sameAs': ['https://www.facebook.com/entrepreneur', 'https://x.com/entrepreneur', 'https://www.linkedin.com/company/entrepreneur-media', 'https://www.youtube.com/user/EntrepreneurOnline', 'https://www.instagram.com/entrepreneur/', 'https://www.tiktok.com/@entrepreneur', 'https://story.snapchat.com/p/79f50f16-1715-45da-9dd4-842c96d79d05/2407079582115840', 'https://www.entrepreneur.com/latest.rss']}",,2018-12-03T13:00:00+00:00,2018-12-03T13:00:00+00:00,How Artificial Intelligence Can Help You Better Manage Your Time | Entrepreneur,,"


  How Artificial Intelligence Can Help You Better Manage Your Time
  
    Make time management easy, and see productivity increase.
  





                  By          
            Raj Narayanaswamy
          

            Edited by 
                          Heather Wilkerson
                      

            Dec 3, 2018
          




          Share        


Copy


 






Subscribe to the Entrepreneur Daily newsletter to get business news, tips and inspiration sent to your inboxSubscribeI understand that the data I am submitting will be used to provide me with the above-described products and/or services and communications in connection therewith.Read our privacy policy for more information.



    Opinions expressed by Entrepreneur contributors are their own.  








Photographer is my life | Getty Images


Evolving trends in the workforce are encouraging companies to reexamine their legacy ecosystems, and many are discovering that they lack the capacity most businesses today require to manage the modernization and digitalization of their workforce. As a result, these organizations require ongoing disruptive and expensive fixes in an attempt to bridge the gaps left behind from these outdated systems.Related: 10 Key Pitfalls To Avoid During the Digital Transformation ProcessBusinesses are also slowly realizing that, in order to manage today's modern workforce, they must use a system of record for time. Between companies' legacy technology, resulting disparate data, and inflexible and unintuitive interfaces, the picture is clear -- time management needs to enter the 21st century. The best time management processes collect the most data while asking the least amount of supervisors and employees, and many organizations are finding that artificial intelligence provides the tools to get there. With features like facial recognition, AI-powered chatbots and intelligent business process management, modern time management solutions can be frictionless, automated and unobtrusive. Artificial intelligence has found a home in today's diverse, mobile and modern business needs -- and leveraging it, organizations can support their workforce modernization and standardization initiatives.



AI can be applied to do the heavy lifting in the process of gathering time data, adding context and connecting it to metrics, which directly results in a more streamlined, centralized system altogether.New tools of the tradeAdvanced intelligent tech allows for automated data harvesting and seamless integration with an existing business structure. Mobile and non-intrusive data capture minimize the need for manual time inputs from employees, and instead automatically harvest time data from a business's ecosystem to tie back to specific deliverables and metrics. With facial identification, employees simply walk up to their time clock and automatically log in through facial recognition. This is fast, simple, and provides the benefits of biometrics without the additional hardware costs. If employees prefer a conversation, they can strike up a dialogue with a chatbot about their time, increasing adoption and accurate data collection.


Related: Simple Tools You Can Use to Manage Your Time and Increase ProductivityWorkflows for the wiseFancy new features like those described above aren't the only thing going for AI. Many managers today sift through the drudgery of time sheets, scouring for exceptions, errors and inconsistencies. Aside from adding administrative overhead, the real danger is in the error and delays that inevitably result from this never-ending manual process. Intelligent workflows simplify business processes by validating data in real-time with built-in exceptions, so supervisors of any department can get visibility where and when it counts. Whether it's approvals, payroll or compliance, companies can increase collaboration and reduce errors dramatically.Managing in the nowWith a wealth of real-time data now readily accessible, businesses are empowered to make important decisions almost instantly. Managers, supervisors and leaders can receive advance alerts and notifications that enable them to make proactive informed decisions with accurate data. With up-to-the-minute information on hours worked, compliance, exceptions and resource availability, errors and wasted time are all but eliminated.Related: 3 Forward-Looking Mindsets Entrepreneurs Need to Have About AITo prepare for the next wave of workforce modernization, businesses should be honing in on productivity. To start, measuring it accurately -- and in order to do that, businesses must account for 100 percent of resource time, and tie it back to all outcomes. With the digitization and modernization of time management, businesses are using these AI technologies to empower their employees to directly affect the outcomes. This promotes a system of record for time and work, enabled by artificial intelligence. By leveraging advanced technologies like AI and machine learning into the fundamental time tracking framework, and staying ahead of the curve on cutting-edge tech, businesses can achieve real profitability.
  
","[{'@type': 'ListItem', 'position': 0, 'name': 'Science & Technology', 'item': 'https://www.entrepreneur.com/science-technology'}]",,,,https://assets.entrepreneur.com/static/20240220061344-entrepreneur-logo-black.svg,,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': True, 'cssSelector': '.gate-check'}",,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,"{'@type': 'Person', 'name': 'Heather Wilkerson', 'jobTitle': 'Entrepreneur Staff Editor', 'worksFor': 'Entrepreneur', 'description': '', 'url': 'https://www.entrepreneur.com'}",
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3LnNlYXR0bGV0aW1lcy5jb20vZXhwbG9yZS9jYXJlZXJzL25ldy1ibHVlLWNvbGxhci1qb2JzLXRoYXQtd2lsbC1zdXJ2aXZlLXRoZS1yaXNlLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,New blue-collar jobs that will survive the rise of artificial intelligence | Produced by Seattle Times Marketing - The Seattle Times,2018-12-05,The Seattle Times,https://www.seattletimes.com,"Call it the automation paradox: The infusion of AI, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve...",,"Call it the automation paradox: The infusion of AI, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency.","Call it the automation paradox: The infusion of AI, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency.",https://schema.org,,BreadcrumbList,,,,,,,,,,,,,,,"


CareersExplore 
Produced by Seattle Times Marketing 
      New blue-collar jobs that will survive the rise of artificial intelligence      







Originally published December 5, 2018 at 6:00 am



(Thinkstock) 




Call it the automation paradox: The infusion of AI, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency.

Share story






By 

Craig Torres

Bloomberg News 


It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Virginia. Twelve candidates are divided into three teams and given the task of assembling a box. Twelve Rolls Royce employees stand around them, one assigned to each candidate, taking notes. 
The box is a prop, and the test has nothing to do with programming or repairing the robots that make engine parts here. It’s about collaborative problem solving.
“We are looking at what they say, we are looking at what they do, we are looking at the body language of how they are interacting,” says Lorin Sodell, the plant manager.

For all the technical marvels inside this fully automated, 8-year-old facility, Sodell talks a lot about soft skills such as trouble shooting and intuition.


Related Stories


Looking for a second career? 'Take it a step at a time'


How to alienate a colleague, one coffee at a time


Bye-bye cubicles and corner offices: Reserving a desk for the day is new work trend


Work friends can be hard to find. How to combat loneliness in the workplace


Firms lure workers back to office with promise of their own desk


It’s a miserable time to try and land an internship




“There are virtually no manual operations here anymore,” he says. People “aren’t as tied to the equipment as they were in the past, and they are really freed up to work on more higher-order activities.”
Call it the automation paradox: The infusion of artificial intelligence, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency.
The new blue-collar labor force will need four “distinctively more human” core competencies for advanced production: complex reasoning, social and emotional intelligence, creativity and certain forms of sensory perception, according to Jim Wilson, a managing director at Accenture Plc.
“Work in a certain sense, and globally in manufacturing, is becoming more human and less robotic,” says Wilson, who helped lead an Accenture study on emerging technologies and employment needs covering 14,000 companies in 14 large, industrialized nations.
Few narratives in economics and social policy are as alarmist as the penetration of automation and artificial intelligence into the workplace, especially in manufacturing.
Economists talk about the hollowing-out of middle-income employment. American political discourse is full of nostalgia for high-paying blue-collar jobs. The Trump Administration is imposing tariffs and rewriting trade agreements to entice companies to keep plants in the U.S. or even bring them back.
The stark reality is that automation will continue to erode away repetitive work no matter where people do it. But there is also a myth in this narrative that suggests America has permanently lost its edge. The vacant mills in the southeast and Midwest, and the struggling cities around them, are evidence of how technology and low-cost labor can rapidly kill off less-agile industries. This isn’t necessarily a prologue to what’s next, however.
Cutting-edge manufacturing not only involves the extreme precision of a Rolls Royce turbo-fan disc. It’s also moving toward mass customization and what Erica Fuchs calls “parts consolidation” — making more-complex blocks of components so a car, for example, has far fewer parts. This new frontier often involves experimentation, with engineers learning through frequent contact with production staff, requiring workers to make new kinds of contributions.
“This is a chance for the U.S. to lead. We have the knowledge and skills,” says Fuchs, an engineering and public-policy professor at Carnegie Mellon University. “When you move manufacturing overseas, it can become unprofitable to produce with the most advanced technologies.”
The new alliance between labor and smart machines is apparent on Rolls Royce’s shop floor. The 33 machinists aren’t repeating one single operation but are responsible for the flow of fan-disc and turbine-blade production. They are in charge of their day, monitoring operations, consulting with engineers and maintaining equipment.

This demonstrates what automation really does: It changes the way people use their time. A visit to the plant also reveals why factory workers in automated operations need more than some knowledge of machine-tool maintenance and programming: They are part of a process run by a team.
Sodell opens what looks like a giant suitcase. Inside is a titanium disc about the size of a truck tire. Unfinished, it costs $35,000, and it’s worth more than twice that much once it’s machined as closely as possible to the engineers’ perfect mathematical description of the part. The end product is so finely cut and grooved it resembles a piece of industrial jewelry.

“I am not at all bothered by the fact that there isn’t a person here looking after this,” he says, standing next to a cutting station about half the size of a subway car. Inside, a robot arm is measuring by itself, picking out its own tools and recording data along the way.
Variations in the material, temperatures and vibration can cause the robot to deviate from the engineers’ model. So human instinct and know-how are required to devise new techniques that reduce the variance. Just by looking at the way titanium is flecking off a disc in the cutting cell, for example, a machinist can tell something is off, Sodell says. With expensive raw materials, such technical acumen is crucial.
It’s also important because current artificial-intelligence systems don’t have full comprehension of non-standard events, the way a GPS in a car can’t comprehend a sudden detour. And they don’t always have the ability to come up with innovations that improve the process.
Sodell says workers are constantly looking for ways to refine automation and tells the story of a new hire who figured out a way to get one of the machines to clean itself. He developed a tool and wrote a program that is now part of the production system.

Technicians start off making $48,000 a year and can earn as much as $70,000, depending on achievement and skill level. Most need at least two years of experience or precision-machining certification from a community college. Rolls Royce is collaborating with these schools and relying on instructors like Tim Robertson, among the first 50 people it hired in Virginia. He now teaches advanced manufacturing at Danville Community College and says it’s hard to explain what work is like at an automated facility. Jobs require a lot more mental engagement, he explains, because machinists are looking at data as much as materials and equipment.
The Danville program includes a class on talking through conflict, along with live production where students are required to meet a schedule for different components in a simulated plant. The group stops twice a day and discusses how to optimize work flow.

“You can ship a machine tool to any country in the world,” Robertson says. “But the key is going to be the high-level technician that can interact with the data at high-level activity and be flexible.”
 

Craig Torres 





","[{'@type': 'ListItem', 'position': 1, 'name': 'Explore', 'item': 'https://www.seattletimes.com/explore/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Careers', 'item': 'https://www.seattletimes.com/explore/careers/'}, {'@type': 'ListItem', 'position': 3, 'name': 'New blue-collar jobs that will survive the rise of artificial intelligence'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMif2h0dHBzOi8vd3d3LmJ1c2luZXNzcm91bmR0YWJsZS5vcmcvYnJ0LWlubm92YXRpb24tc3VtbWl0LXRoZS1mdXR1cmUtb2Ytd29yay1pbi1hbi1lcmEtb2YtYXV0b21hdGlvbi1hbmQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2XSAQA?oc=5,BRT Innovation Summit: The Future of Work in an Era of Automation and Artificial Intelligence - Business Roundtable,2018-12-06,Business Roundtable,https://www.businessroundtable.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMTIvMDYvYnVzaW5lc3MvZWNvbm9teS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1oaXJpbmcuaHRtbNIBAA?oc=5,"A.I. as Talent Scout: Unorthodox Hires, and Maybe Lower Pay (Published 2018) - The New York Times",2018-12-06,The New York Times,https://www.nytimes.com,"A form of artificial intelligence is being used to surface job candidates with the attributes of a perfect fit, even without conventional credentials.",,"A form of artificial intelligence is being used to surface job candidates with the attributes of a perfect fit, even without conventional credentials.","A form of artificial intelligence is being used to surface job candidates with the attributes of a perfect fit, even without conventional credentials.",https://schema.org,,BreadcrumbList,"A.I. as Talent Scout: Unorthodox Hires, and Maybe Lower Pay",https://www.nytimes.com/,https://www.nytimes.com/2018/12/06/business/economy/artificial-intelligence-hiring.html,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/12/07/business/07hiring/07hiring-videoSixteenByNineJumbo1600-v2.jpg', 'height': 899, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2018/12/07/business/07hiring/07hiring-videoSixteenByNineJumbo1600-v2.jpg', 'creditText': 'Mengxin Li'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/12/07/business/07hiring/07hiring-superJumbo-v2.gif', 'height': 1024, 'width': 819, 'contentUrl': 'https://static01.nyt.com/images/2018/12/07/business/07hiring/07hiring-superJumbo-v2.gif', 'creditText': 'Mengxin Li'}]",,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/noam-scheiber', 'name': 'Noam Scheiber'}]",,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,2018-12-07T00:47:53.000Z,2018-12-07T00:47:53.000Z,Business,,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTA.I. as Talent Scout: Unorthodox Hires, and Maybe Lower PayShare full article50Read in appCredit...Mengxin LiBy Noam ScheiberDec. 6, 2018One day this fall, Ashutosh Garg, the chief executive of a recruiting service called Eightfold.ai, turned up a résumé that piqued his interest.It belonged to a prospective data scientist, someone who unearths patterns in data to help businesses make decisions, like how to target ads. But curiously, the résumé featured the term “data science” nowhere.Instead, the résumé belonged to an analyst at Barclays who had done graduate work in physics at the University of California, Los Angeles. Though his profile on the social network LinkedIn indicated that he had never worked as a data scientist, Eightfold’s software flagged him as a good fit. He was similar in certain key ways, like his math and computer chops, to four actual data scientists whom Mr. Garg had instructed the software to consider as a model.The idea is not to focus on job titles, but “what skills they have,” Mr. Garg said. “You’re really looking for people who have not done it, but can do it.”AdvertisementSKIP ADVERTISEMENTThe power of such technology will be immediately apparent to any employer scrambling to fill jobs in a tight labor market — not least positions for data scientists, whom companies like Google, Facebook and Amazon are competing to attract.Thanks to services like Eightfold, which rely on sophisticated algorithms to match workers and jobs, many employers may soon have access to a universe of prospective workers — even for hard-to-fill roles — whom they might not otherwise have come across.And while that could also help some candidates, there’s a potential downside for job seekers: Such algorithms may also lower wages in these fields, said Bo Cowgill, an economist at Columbia University who has studied the use of artificial intelligence in hiring.“You get the more nontraditional, equally qualified, equally high-performing people,” Mr. Cowgill said. But the employer “doesn’t seem to have to compete for them as much.”For years, employers and online intermediaries have used algorithms to help fill job openings, but their methods were often crude. A computer would identify key words on résumés, then determine whether those words corresponded to text in job descriptions.AdvertisementSKIP ADVERTISEMENTWhile this approach can be more efficient than manually searching a site like LinkedIn, it has drawbacks. Applicants can game the process by larding their résumés with terms the machines are likely to be looking for. Conversely, poorly worded job listings could cause computers to overlook qualified candidates.But recent advances in a form of artificial intelligence known as deep learning have made the machines used by some companies, like Eightfold and the online job hub ZipRecruiter, far more powerful. Instead of simply scanning words on a page and matching them to words in a job description, a machine can now identify skills and aptitudes that don’t explicitly appear on a candidate’s résumé.To illustrate, Mr. Garg points out that about 90 percent of software engineers at the financial software company Intuit in Mountain View, Calif., know the programming language Java, according to data Eightfold has analyzed. That means the machine is on safe ground inferring that an Intuit software engineer knows Java, even if he or she doesn’t list the skill on a résumé.By performing a similar exercise across an entire résumé, the company’s software can build a detailed profile of a job applicant. It can extract more than the usual amount of information from categories like education (certain disciplines at less prominent universities, like natural-language processing at the University of Massachusetts, Amherst, produce high-achieving workers) and even hobbies (chess players tend to be good at coding, basketball players at sales).Eightfold, which is based in Silicon Valley, also makes a clever trade with clients: to improve its results, Eightfold asks clients to use its human-resources software, which imports employee data in anonymous form. This includes information on how workers with different backgrounds perform in different jobs, and how much they earn.AdvertisementSKIP ADVERTISEMENTEightfold can then use this data to better predict performance — say, how well an Intuit software engineer who plays chess and graduated from the University of Massachusetts might do at Amazon or Microsoft.Intuit did not respond to a request for comment.The software tool can be especially powerful to an employer intent on expanding a search beyond candidates with conventional experience and qualifications. In that case, a recruiter can specify criteria (like industry and location, and even how likely the candidate is to accept an offer) that would turn up less traditional résumés.Claudia Villanueva, a recruiting and diversity official at AdRoll Group, which helps clients with digital ads and marketing, said she recently used Eightfold when trying to fill a financial-planning position. The top candidate had experience in industries the tech world often shuns, like manufacturing. But the Eightfold algorithm flagged her as a winner.“The tech industry sometimes has a hard time moving past tech experience,” Ms. Villanueva said. “We keep hiring the same people in the industry. To me this is a really interesting example of how we broke that cycle a bit.”ImageAshutosh Garg, left, is a co-founder and chief executive of the hiring service Eightfold.ai, which has applied artificial intelligence to job recruitment. Kamal Ahluwalia, center, is president, and Varun Kacholia, another co-founder, is chief technical officer.Credit...Anastasiia Sapon for The New York TimesIn the case of the Barclays analyst, Eightfold’s software pegged him as a budding data scientist partly because he had a master’s degree in statistics and knew computer programming languages like C++ and Matlab, even though he had no apparent background in data science.AdvertisementSKIP ADVERTISEMENT“We have gone ahead and analyzed tens of millions to hundreds of millions of profiles of people to see how people have moved in their career,” Mr. Garg said. “You can predict what they’re likely to do next very easily.” He conceded that the approach worked less well in new or obscure fields with limited data.Steve Goodman, the chief executive of Restless Bandit, another firm that applies artificial intelligence to recruiting, compared the exercise of finding nontraditional candidates to filling a professional sports roster.Sports franchises tend to pay far more for free agents who leave their previous team than for players they draft out of college or high school, because the free agents have a record. But if computers were able to predict the performance of draft picks with relative precision, this could change their calculus. The price of free agents might drop, and the price of signing a draft pick would rise. This is, in effect, what software can accomplish using artificial intelligence.“We surface people we think would be good draft picks,” rather than people doing the same jobs, Mr. Goodman said. “This person is a little more junior, but based on their career track, people who look like them are cheaper and better for you.”AdvertisementSKIP ADVERTISEMENTMr. Cowgill, the Columbia economist, said this logic was largely correct, but with one key wrinkle: According to his research, the gains to the less obviously qualified candidates unearthed by machines can be so large that they offset smaller losses to conventional candidates.In a technical field like software engineering, for example, a dropout from a no-name university could end up making a very comfortable living after becoming known to employers. But established coders are sufficiently in demand that wages are likely to remain high even as it becomes easier to find alternatives.In fields requiring fewer technical skills, on the other hand, wages could fall significantly.Consider, say, senior marketing jobs, for which large companies often require a master’s degree in business administration. If machines can reliably identify less experienced, less credentialed candidates who are likely to excel, it could depress wages.“You can think of cases in the product market where people thought they needed something special and you really didn’t — the commodity, low-cost person took over,” said John Horton, a labor economist at N.Y.U. Think of hand-held video cameras after the proliferation of smartphones.“That could happen in labor markets with the realization that you don’t need anything special here,” Mr. Horton said.AdvertisementSKIP ADVERTISEMENTAll of this presumes, however, that deep-learning technology is viable for use in recruiting and human resources and could eventually become commonplace. Surveys suggest that only a small minority of companies have adopted these tools, and that even fewer feel prepared to exploit them.A recent paper summarizing the findings of a conference at the University of Pennsylvania, involving roughly 20 employers, cited a variety of problems. Among them were the difficulty of measuring employees’ performance and the sense of unfairness that workers might feel if a computer were to make hiring, firing and promotion decisions.Perhaps the greatest concern is a basic methodological point — call it the N.B.A. problem. If you were studying National Basketball Association players to figure out what makes one great, you would find almost no correlation between performance and height. Almost everyone in this rarefied world is taller than average. And those who aren’t compensate with other gifts, like unusual speed and athleticism.If, on the other hand, you selected people at random from the general population and gauged their basketball potential, you would find that it was highly correlated with height.The concern is that machines are, in effect, only studying N.B.A. players — the people who already have jobs at a company, or even the people who sought jobs — not the general population.AdvertisementSKIP ADVERTISEMENTMr. Cowgill believes there are solutions. He wrote a paper showing that seemingly unqualified applicants whom a company accidentally interviews allow a machine to simulate a crude randomized experiment, helping the company learn more about what makes a good employee.But perhaps more telling is that sophisticated technology companies are already using artificial intelligence to help fill jobs. Mr. Garg, who worked as a research scientist at Google for four years, says the company uses such techniques in its recruiting.Google says it uses machines to take a second look at résumés in its database that human recruiters may have missed for a limited set of roles.The advantage that a vendor like Eightfold has, Mr. Garg asserted, is access to internal data at dozens of other companies, something even Google can’t claim. “We now can build much deeper models than these companies can build by themselves,” he said.Cade Metz contributed reporting. A version of this article appears in print on Dec. 7, 2018, Section B, Page 1 of the New York edition with the headline: Unorthodox Hires, And Maybe Lower Pay. Order Reprints | Today’s Paper | SubscribeRead 50 CommentsShare full article50Read in appAdvertisementSKIP ADVERTISEMENTComments 50A.I. as Talent Scout: Unorthodox Hires, and Maybe Lower PaySkip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Enjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more","[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Business', 'position': 1, 'item': 'https://www.nytimes.com/section/business'}, {'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Economy', 'position': 2, 'item': 'https://www.nytimes.com/section/business/economy'}]",,The New York Times,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",,,False,,,,,https://www.nytimes.com/#publisher,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","Unorthodox Hires, And Maybe Lower Pay",,,,,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,,,{'@id': '#commentsContainer'},50.0,,
https://news.google.com/rss/articles/CBMikgFodHRwczovL3d3dy5zcGljZXdvcmtzLmNvbS90ZWNoL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2ludGVydmlld3MvcGVyZmVjdGluZy1wcmVzZW50YXRpb25zLXdpdGgtYWktYW4taW50ZXJ2aWV3LXdpdGgtbWl0Y2gtZ3Jhc3NvLW9mLWJlYXV0aWZ1bGFpL9IBAA?oc=5,Perfecting Presentations with AI: An Interview with Mitch Grasso of Beautiful.ai - Spiceworks News and Insights,2018-12-04,Spiceworks News and Insights,https://www.spiceworks.com,"“We’re moving closer to “Productivity 3.0,” where the product becomes the expert, so you don’t have to be.”This fascinat...",,An Interview with Mitch Grasso of Beautiful.ai on making prefect presentations with AI. Get a glimpse into the beautiful new world of AI-powered presentations.,,,,,,,,,,,,,,,,,,,"



























 



Radhika Mukherjee



					IT Editor				




December 4, 2018




 






“We’re moving closer to “Productivity 3.0,” where the product becomes the expert, so you don’t have to be.”
This fascinating Interview with Mitch Grasso, CEO and Founder, Beautiful.ai, focuses on how anyone, no matter how design-challenged, can now make beautiful presentations, with the help of AI-powered solutions like Beautiful.ai. 
1. Despite all the advancements in interactive technology and media, PowerPoint presentations have stood the test of time. What does that say about PPTs or about the professionals who use them?
I don’t think this says something about PPT. It says something about the value of presentations in general, as a way to communicate well. Clearly, using a visual medium to back up verbal communications is a better method to engage and motivate, as opposed to words on a page or a person simply speaking to a room full of people. Professionals that regularly use the presentation format have experienced the obvious value they offer. We see a huge opportunity with adopting this format as a way to “present” your work every day – not just for a formal presentation. 
2. What is the value proposition of Beautiful.ai? How is it different from say a Prezi or similar?
While presentations are ubiquitous, they still aren’t easy to create. We think people should be able to focus on their content and story, not worry about the details of design. The reality is most people aren’t designers, and most presentation tools offer this completely blank canvas. Just organizing and presenting ideas is difficult enough for most people, but when you add the challenge of having to visualize these concepts using an authoring tool like PPT or Prezi – it becomes a nightmare effort. We have built-in design “best practices” that let people communicate their intent without the distractions of bad design. 
3. Collaborative work places, remote work forces, mobile work – these are the new realities. It’s led to the rise of products like Slack and its ilk. How does your vision build on/support these new workplace realities? 
To me, collaboration has become table stakes – it’s “Productivity 2.0.” We’re moving closer to “Productivity 3.0,” where the product becomes the expert, so you don’t have to be. Our tool is smarter, intuitive and supportive, so we are excited about collaboration in the cloud, mainly because it allows for an improvement in product intelligence. 
4. What is the model of Beautiful.AI? What is your vision of how it can transform work?
At Beautiful, our mission is to make your work life simpler, more effective and more inspiring for everyone. We believe in “making work beautiful,” which is a tall mountain to climb but one we’re passionate about summiting. Imagine a future where visualizing everyday ideas at work is done with a few clicks of a button, so teams and clients are educated and motivated faster and more effectively. We’re excited about that future.
5. Who in the organization should be making a decision on investing in a product like yours for the organization (once you start pricing)? 
We have a “bottom up” approach to engaging with the enterprise. Right now, we’re focused on making individuals within organizations happy. We’re already appealing to anyone who wants to elevate how they communicate with colleagues and clients, which is entry-level employees all the way to the C-Suite. We’re less worried about marketing to specific hierarchies right now, and more focused on solving the problems of presentation design. Once we perfect the “presentation experience” for individuals, we will work on adopting the product for the enterprise.
6. What integrations are you planning in the near term? 
Currently, we’re allocating our internal resources for additional product functionalities that relate to presentation design. Our primary goal is to solve the problems with presentations first and we want to make that experience as close to perfect as possible — through automation, intelligence and good design. But we’ll definitely integrate with document management tools, workflow and cloud storage like Google Drive and Dropbox in the near future. 
7. What are your users telling you? What are the challenges with getting management buy-in to investing in productivity tools that feel, perform and look better?
First of all, our users are telling us that they love that we’re solving all the problems of past presentation tools. We get love letters all the time, and really appreciate hearing their feedback. The obvious, inherent challenges with enterprise are three-fold: supporting their existing brand standards (design), addressing specific feature requests (customer service) and onboarding new products (integration). In the meantime, we are getting a ton of inbound interest from corporations on how they can roll this out to their teams – they react very positively to the restraints of the tool, and the fact that it can maintain their design standards for them.
8. The data visualization space is becoming increasingly important for companies inundated with data, dashboards, reports and analytics. What trends are you excited about in this space as we head into 2020 and beyond?
In terms of trends, we are really passionate about the idea of telling a story by visualizing data. And that’s what we’re doing already: building tools that help you tease out that story and give it life through design and animation, instead of just showing boring tables and graphs. 
Radhika: Thank you for that super-interesting glimpse into the beautiful new world of AI-powered presentations and design, Mitch. We hope to speak with you again, soon!
About Mitch Grasso: Mitch GrassoOpens a new window  is a serial entrepreneur with strong technology, design and product skills. He is currently the founder and CEO of a new startup, Beautiful.ai, which will revolutionize how people build beautiful visual documents. In 2007, he founded SlideRocket — the first cloud-based presentation tool focused on team collaboration, analytics and multimedia content authoring. 
About Beautiful.ai: Beautiful.ai is an online presentation design tool that lets you present your work easily, effectively and beautifully. Beautiful.ai also offers valuable presentation resources like stock photography, branding customizations, iconography, data visualization, and animation. Learn more at https://www.beautiful.ai/.








								                  Digital Transformation										



Share This Article:
 





Radhika Mukherjee

				                  IT Editor	                          


 opens a new window
 opens a new window 



 opens a new window  opens a new window
  	
					Radhika Mukherjee has 11+ years of experience as an IT writer, editor, trainer and manager. She's a creative writer at heart and has two books of short stories to her credit. An avid reader, she has a keen interest in environmental and social justice issues.			








								Do you still have questions? Head over to the Spiceworks Community to find answers.
							

Take me to Community





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vbS5lY29ub21pY3RpbWVzLmNvbS9qb2JzL3Jpc2Utb2YtdGhlLW1hY2hpbmVzLXdoZW4tYm90cy10YWtlLW92ZXItdGhlLXdvcmtwbGFjZS9hcnRpY2xlc2hvdy82NjkzMDA2OC5jbXPSAXRodHRwczovL20uZWNvbm9taWN0aW1lcy5jb20vam9icy9yaXNlLW9mLXRoZS1tYWNoaW5lcy13aGVuLWJvdHMtdGFrZS1vdmVyLXRoZS13b3JrcGxhY2UvYW1wX2FydGljbGVzaG93LzY2OTMwMDY4LmNtcw?oc=5,Rise of the machines: When bots take over the workplace - The Economic Times,2018-12-04,The Economic Times,https://m.economictimes.com,"Its the Year of the Bots. They are efficient, can handle scale and work tirelessly without a lunch break.","['bots', 'Cognizant', 'facebook', 'Gartner', 'Oracle Corporation', 'hdfc bank', 'artificial intelligence']","Its the Year of the Bots. They are efficient, can handle scale and work tirelessly without a lunch break.","Its the Year of the Bots. They are efficient, can handle scale and work tirelessly without a lunch break.",https://schema.org/,,WebPage,Rise of the machines: When bots take over the workplace,https://economictimes.indiatimes.com/jobs/rise-of-the-machines-when-bots-take-over-the-workplace/articleshow/66930068.cms,https://economictimes.indiatimes.com/jobs/rise-of-the-machines-when-bots-take-over-the-workplace/articleshow/66930068.cms,,"{'@type': 'ImageObject', 'url': 'https://img.etimg.com/thumb/msid-66930068,resizemode-4,width-1200,height-900,imgsize-439193,overlay-etcareers/photo.jpg', 'width': 1200, 'height': 900}",Careers,"{'@type': 'Person', 'name': 'Shelley Singh'}",,"{'@type': 'NewsMediaOrganization', 'name': 'Economic Times', 'logo': {'@type': 'ImageObject', 'url': 'https://img.etimg.com/thumb/msid-76939477,width-600,height-60,quality-100/economictimes.jpg', 'width': 600, 'height': 60}}",,2018-12-04T08:04:00+05:30,2018-12-04T18:59:00+05:30,,,"AgenciesIn a billion-plus country where only 10-12% of the 480 million workers are in the organised sector, intelligent automation — though inevitable — is bound to face backlash.At makemytrip.com, Myra and Gia were godsend.If tourists start booking Shimla holidays to enjoy the snow and traffic outstrips the number of rooms, the duo sends alerts to hotel chains in the region to increase online inventory. They forecast demand, answer customer queries and can even update on flight delays.Explore courses from Top Institutes inSelect a Course CategoryProduct Management Supply Chain  MBA Healthcare Management Data Science Public Policy  Leadership  PGDM  MCA Digital Marketing  Healthcare Data Analytics  Degree HR Management Project Management  CXO Strategic Management   Skills you’ll gain:  Customer Insights & Market AnalysisProduct Strategy & RoadmappingAgile Product DevelopmentBusiness Acumen & Financial Analysis Duration: 36 Weeks    Northwestern University Kellogg Post Graduate Certificate in Product Management   Starts on Jun 20, 2024 Get Details    Skills you’ll gain:  Product Strategy & RoadmappingUser-Centric Product DesignAgile Product DevelopmentMarket Analysis & Product Launch Duration: 24 Weeks    Indian School of Business Professional Certificate in Product Management   Starts on Jun 26, 2024 Get Details    Skills you’ll gain:  Creating Effective Product RoadmapUser Research & Translating it to Product DesignKey Metrics via Product AnalyticsHand-On Projects Using Cutting Edge Tools Duration: 12 Weeks    Indian School of Business ISB Product Management   Starts on May 14, 2024 Get Details    Skills you’ll gain:  Product Strategy & Competitive Advantage TacticsProduct Development Processes & Market OrientationsProduct Analytics & Data-Driven Decision MakingAgile Development, Design Thinking, & Product Leadership Duration: 40 Weeks    IIM Kozhikode Professional Certificate in Product Management   Starts on Jun 26, 2024 Get Details  The duo has been at the travel portal’s headquarters in Cyber City, Gurgaon, for just a year but has already moved on to solving more difficult tasks such as managing loyalty programmes.    by Taboolaby TaboolaSponsored LinksSponsored LinksPromoted LinksPromoted LinksYou May LikeNew and Permanent Teeth in 24 Hours - Life Changing!G4 By GolpaLearn MoreUndoWhether cancellations or refunds from 12,000-15,000 customer interactions every day, about 60% are resolved by the duo and some of their other techsavvy mates. And after all that, they take time out to share the workload of senior colleagues.Superhuman, you would say. We wholeheartedly agree. For Myra and Gia are not flesh and blood white-collar executives. They are bots.You Might Also Like:Cyborg: Manufacturing the man-machine Play VideoPlaySkip BackwardSkip ForwardUnmuteCurrent Time 0:00/Duration 50:00Loaded: 0.51%00:00Stream Type LIVESeek to live, currently behind liveLIVERemaining Time -50:00 1xPlayback RateChaptersChaptersDescriptionsdescriptions off, selectedCaptionscaptions settings, opens captions settings dialogcaptions off, selectedAudio Trackdefault, selectedPicture-in-PictureFullscreenThis is a modal window.Beginning of dialog window. Escape will cancel and close the window.TextColorWhiteBlackRedGreenBlueYellowMagentaCyanOpacityOpaqueSemi-TransparentText BackgroundColorBlackWhiteRedGreenBlueYellowMagentaCyanOpacityOpaqueSemi-TransparentTransparentCaption Area BackgroundColorBlackWhiteRedGreenBlueYellowMagentaCyanOpacityTransparentSemi-TransparentOpaqueFont Size50%75%100%125%150%175%200%300%400%Text Edge StyleNoneRaisedDepressedUniformDrop shadowFont FamilyProportional Sans-SerifMonospace Sans-SerifProportional SerifMonospace SerifCasualScriptSmall CapsReset restore all settings to the default valuesDoneClose Modal DialogEnd of dialog window.AdvertisementIt’s the Year of the Bots. They are efficient, can handle scale, accuracy and, most importantly, work tirelessly without a lunch break.Inspired by SoftBank-backed Ping An Good Doctor of China, insurance aggregator PolicyBazaar.com started a healthcare venture, docprime.com, with an investment of around $50 million in April. It would help users book doctor and lab appointments. Chief executive Ashish Gupta says it couldn’t have started without bots!At Ping An Good Doctor, bots enable 700,000 consultancies, with 1,000 bots working alongside human agents. “Such scale is possible only with bots.” adds Gupta, who is also the chief technology officer of PolicyBazaar. Without them, the 10-year old insurance aggregator would have needed three to five times more people to do tasks such as selling motor or health insurance. About half the motor covers are sold by bots, a number Gupta expects will increase to 75% in the next couple of years.Thousands of bots will work alongside humans to book appointments with doctors, schedule meetings, deliver customer support, help access records, assist in work and so on. EY predicts a five-fold increase in their numbers at the workplace in the next year.You Might Also Like:View: How India's services sector is a perfect springboard for automationThe largest temp staffing company in India, TeamLease Services, has calculated that 0.1% of industrial jobs have been lost to robots, while 37% of the jobs that currently exist will change in some way. That change is coming about faster now, driven by bots or software applications that perform automated tasks such as searching online, paying bills, answering queries, fixing an appointment with a doctor or a plumber, helping in research, driving marketing campaigns, filing tax returns or checking for errors in documents without human intervention.Bots and robots both do the same thing. But bots are software and robots are mechanical. Yet both excel at repetitive tasks – ones we call the daily grind, or tedious chores.Robots have mechanised manufacturing somewhat in the last few years but in their new avatar, bots are altering services companies. A car manufacturer such as Ford could be using robots on the factory floors to make cars just like they do at their Gujarat export plant, but in the corporate offices, bots can be devising multi-platform campaigns to sell those sedans or SUVs.The scope is wider. That is why L&T is using them for payable and contract management; Airtel for billing and customer services; TataSky for finance and supply chain functions. Bajaj Electricals has Paddy taking employee complaints and booking technician visits and EY has deployed 1,500 bots for clients across functions — finance, HR, IT or any activity that has a set procedure (rule-based processing). At HDFC Bank, job applications from humans are screened by bots and the first videoconferenced interview is also with one.You Might Also Like:The factor that will be key to getting a job in the age of robotsWherever there is a highly templatised, predictable, non-cognitive assignment, bots are taking over. At the same time, they are constantly upgrading. Like HDFC Bank’s Eva is helping users decide between recurring or fixed deposits. In some financial services firms, bots are advisors, cherry-picking bespoke investment and savings products for clients after mapping their age, risk profile, time horizon and several other parameters.Depending on the complexity, a single bot can cost from Rs 40 lakh to Rs 1.5 crore to develop.“Earlier there were no alternatives but to throw bodies at mundane jobs. Now, bots are taking over while humans move to better quality, higherthinking jobs,” says Rituparna Chakraborty, co-founder, TeamLease.Bengaluru-based tech services provider Mindtree has gone a step further to make it official. It reported the addition of 426 bots to its workforce as of June 30 and 484 in its second quarter results. The mid-tier firm started declaring quarterly bot numbers along with human employees added from early this year. “We wanted to signal to the world that our industry is changing,” says Rostow Ravanan, chief executive, Mindtree. “Bots are a rising trend.”Transformers: The Next GenBots or software programs for specific tasks have been around for many years, with 40% of customer queries being the FAQ type — ideal for bot-level intelligence. Some like Vaibhav Gawde, head, solutions consulting, Oracle India, have seen at least three generations at play.The first gen are single skill, single task bots. The second generation, in use at present, can handle multiple tasks such as employee self-service, IT help desk or customer queries. The third gen will be powered by artificial intelligence (AI) and use self-learning to improve their own knowledge to help human users.Similarly, activity bots that Mindtree has built can decide who the best person (human) is to do a job. As machines do more tasks, humans can perhaps utilise free time to upskill themselves, argues Ravanan. “Bots will save human workers four hours in an eight-hour shift. By 2022, one-third of all customer services will be done by bots,” feels Arup Roy, vice-president, research at Gartner, a tech advisory firm. Early evolvers are finding ways to blend human and intelligent bot workers that complement each other’s strengths and weaknesses. “We are elevating these ‘systems that do’ bots with ‘think and learn’ bots to drive intelligent automation,” says Sumithra Gomatam, president, digital operations, Cognizant.At lingerie brand Clovia, customer interactions are handled by bots. Pankaj Vermani, founder and chief executive, says, “The next phase of bots will see customers being guided on product selection and size discovery assistance.”A large ecommerce company is using bots to pay suppliers. “If you are doing 10 million transactions daily, accuracy is important and so is time and compliance. This is where bots score,” says Milan Sheth, lead, intelligent automation, EY India. “We are trying to create bots to pick out anomalies in non-disclosure agreements and memoranda of understanding. The progression is: use bots to assist, then assign them tasks and eventually leave it all for bots to do,” predicts Nitin Chugh, country head, digital banking, HDFC Bank.I Robot: Where’s My Paycheque?There can be much fiery debate over bots snatching away humans’ jobs. But while each bot is as good as, or better, than 2.5 human workers, it needs at least 5-7 people to develop, deploy and maintain it. Ergo, at least coders can rest easy.But in a billion-plus country where only 10-12% of the 480 million workers are in the organised sector, intelligent automation — though inevitable — is bound to face backlash. In election season, farm distress and youth unemployment is already political ammunition.Yogendra Yadav, national president, Swaraj India, feels it’s a “fundamental error in believing there’s something called advanced technology.” The US and Europe have deficient labour and excess capital, he argues, making bots relevant there. “In India, the situation is the opposite. Advanced, cutting edge technology should create jobs with least amount of capital.”Chakraborty of TeamLease has a counterargument. “Any innovation comes with side effects. That’s no argument against innovation. Use of bots is mankind’s statement to move to higher order jobs,” she says.For technology apologists, bots crumble if there are multiple intents and can only be designed, created, developed and even maintained by humans. “Historically, market expansion and job creation are because of use of technology. I can empathise with people’s fears,” says Ravanan. However, “getting humans and intelligent bots to collaborate and feed off each other’s insights will be key to evolution,” feels Gomatam.As per EY estimates, 40% of any job component is digital and increasing. “If the economy doesn’t grow, even bots will be unemployed. If the economy expands, as is expected, there will be jobs for both humans and bots,” argues Sheth. Of the 15 names mentioned in this story, three are of bots. It’s possible that a story written five years from now will be based mostly on conversations with chatbots. In some global newsrooms, baby steps have already been carried out.There is, however, a dark side. Bots are being employed to spread misinformation or propaganda in political and corporate warfare. Canny algorithms invade our space with targeted messaging. In today’s Orwellian world, everything — from personal photographs to financial records — are vulnerable to the prying eyes of bots.   Facing unprecedented global backlash, Facebook and Twitter have purged millions of bots who have been spamming humans while promoting hate, misogyny, terror, sexual abuse and pornography or just plain falsehoods.“We now stop more than one million accounts per day at the time of upload,” points out Monika Bickert, vice-president, product policy and counter-terrorism, Facebook. About 1.3 billion fake accounts have been brought down in May-October.Of course, it is unlikely that the need for humans —to write a story, run factories or companies and work at the bank — will disappear. Still, dystopian though it may seem, the post of a bot manager who has been trained by bot teachers and hired by bots may be a coveted job sooner than you think.You Might Also Like:To hire US graduates, Indian IT firms go straight to source    by Taboolaby TaboolaSponsored LinksSponsored LinksPromoted LinksPromoted LinksYou May LikeHorror Stories Of Entitled PeopleA family of 5 gets on my flight. I was in the bathroom at the time, as I returned to my seat, my stuff was gone and the mother was sitting in my spot. “Wait at the back of the plane” she says. Nope. She messed with the wrong man.MoneyMadeRead MoreUndoTop Doctors 'Anti-Lazy' Drops Are Going Viral This July(Now Legally Sold Online)Health HeadlinesBuy NowUndoAmazon's Worst Nightmare: Thousands Canceling Prime for This Clever HackThis simple trick can save tons of money on Amazon, but most Prime members are ignoring it.Coupon Code FinderUndo2 Cards Charging 0% Interest Until Nearly 2026With no annual fee and no interest until nearly 2026, this card is helping Americans pay off debt in record time.CompareCreditUndoThis New AC Cooler Cools the Room In SecondsSherumLearn MoreUndoSeniors are Paying Next to Nothing for Viking River Cruises (See How)River CruiseLearn MoreUndoUnbelievable: Calculator Shows The Value Of Your House Instantly (Take a Look)search by your address to see your home's value instantlyHome Value Calculator | Search Ads Search NowUndoDon't Pay For New Gutters. Get This 3-In-1 System InsteadLeaf Filter USALearn MoreUndoThe Secret Legal Source of 87¢ Generic Viagra CVS Doesn't Want You to DiscoverPublic Health Forum by Friday PlansUndoRead More News onbotsCognizantfacebookGartnerOracle Corporationhdfc bankartificial intelligence",,"{'@type': 'SpeakableSpecification', 'cssSelector': ['.article_wrap h1', '.artSyn h2']}",Rise of the machines: When bots take over the workplace,,"{'@type': 'ImageObject', 'url': 'https://img.etimg.com/thumb/msid-76939477,width-600,height-60,quality-100/economictimes.jpg', 'width': 600, 'height': 60}",,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'https://schema.org/False', 'cssSelector': '.paywall'}",,,https://schema.org/False,,en,,"At makemytrip.com, Myra and Gia were godsend.If tourists start booking Shimla holidays to enjoy the snow and traffic outstrips the number of rooms, the duo sends alerts to hotel chains in the region to increase online inventory. They forecast demand, answer customer queries and can even update on flight delays.The duo has been at the travel portal’s headquarters in Cyber City, Gurgaon, for just a year but has already moved on to solving more difficult tasks such as managing loyalty programmes.Whether cancellations or refunds from 12,000-15,000 customer interactions every day, about 60% are resolved by the duo and some of their other techsavvy mates. And after all that, they take time out to share the workload of senior colleagues.Superhuman, you would say. We wholeheartedly agree. For Myra and Gia are not flesh and blood white-collar executives. They are bots.       66930787 66930388 66933549 66926731   It’s the Year of the Bots. They are efficient, can handle scale, accuracy and, most importantly, work tirelessly without a lunch break.Inspired by SoftBank-backed Ping An Good Doctor of China, insurance aggregator PolicyBazaar.com started a healthcare venture, docprime.com, with an investment of around $50 million in April. It would help users book doctor and lab appointments. Chief executive Ashish Gupta says it couldn’t have started without bots!At Ping An Good Doctor, bots enable 700,000 consultancies, with 1,000 bots working alongside human agents. “Such scale is possible only with bots.” adds Gupta, who is also the chief technology officer of PolicyBazaar. Without them, the 10-year old insurance aggregator would have needed three to five times more people to do tasks such as selling motor or health insurance. About half the motor covers are sold by bots, a number Gupta expects will increase to 75% in the next couple of years.Thousands of bots will work alongside humans to book appointments with doctors, schedule meetings, deliver customer support, help access records, assist in work and so on. EY predicts a five-fold increase in their numbers at the workplace in the next year.The largest temp staffing company in India, TeamLease Services, has calculated that 0.1% of industrial jobs have been lost to robots, while 37% of the jobs that currently exist will change in some way. That change is coming about faster now, driven by bots or software applications that perform automated tasks such as searching online, paying bills, answering queries, fixing an appointment with a doctor or a plumber, helping in research, driving marketing campaigns, filing tax returns or checking for errors in documents without human intervention.Bots and robots both do the same thing. But bots are software and robots are mechanical. Yet both excel at repetitive tasks – ones we call the daily grind, or tedious chores.Robots have mechanised manufacturing somewhat in the last few years but in their new avatar, bots are altering services companies. A car manufacturer such as Ford could be using robots on the factory floors to make cars just like they do at their Gujarat export plant, but in the corporate offices, bots can be devising multi-platform campaigns to sell those sedans or SUVs.The scope is wider. That is why L&T is using them for payable and contract management; Airtel for billing and customer services; TataSky for finance and supply chain functions. Bajaj Electricals has Paddy taking employee complaints and booking technician visits and EY has deployed 1,500 bots for clients across functions — finance, HR, IT or any activity that has a set procedure (rule-based processing). At HDFC Bank, job applications from humans are screened by bots and the first videoconferenced interview is also with one.Wherever there is a highly templatised, predictable, non-cognitive assignment, bots are taking over. At the same time, they are constantly upgrading. Like HDFC Bank’s Eva is helping users decide between recurring or fixed deposits. In some financial services firms, bots are advisors, cherry-picking bespoke investment and savings products for clients after mapping their age, risk profile, time horizon and several other parameters.Depending on the complexity, a single bot can cost from Rs 40 lakh to Rs 1.5 crore to develop.“Earlier there were no alternatives but to throw bodies at mundane jobs. Now, bots are taking over while humans move to better quality, higherthinking jobs,” says Rituparna Chakraborty, co-founder, TeamLease.Bengaluru-based tech services provider Mindtree has gone a step further to make it official. It reported the addition of 426 bots to its workforce as of June 30 and 484 in its second quarter results. The mid-tier firm started declaring quarterly bot numbers along with human employees added from early this year. “We wanted to signal to the world that our industry is changing,” says Rostow Ravanan, chief executive, Mindtree. “Bots are a rising trend.”Transformers: The Next GenBots or software programs for specific tasks have been around for many years, with 40% of customer queries being the FAQ type — ideal for bot-level intelligence. Some like Vaibhav Gawde, head, solutions consulting, Oracle India, have seen at least three generations at play.The first gen are single skill, single task bots. The second generation, in use at present, can handle multiple tasks such as employee self-service, IT help desk or customer queries. The third gen will be powered by artificial intelligence (AI) and use self-learning to improve their own knowledge to help human users.Similarly, activity bots that Mindtree has built can decide who the best person (human) is to do a job. As machines do more tasks, humans can perhaps utilise free time to upskill themselves, argues Ravanan.                  “Bots will save human workers four hours in an eight-hour shift. By 2022, one-third of all customer services will be done by bots,” feels Arup Roy, vice-president, research at Gartner, a tech advisory firm. Early evolvers are finding ways to blend human and intelligent bot workers that complement each other’s strengths and weaknesses. “We are elevating these ‘systems that do’ bots with ‘think and learn’ bots to drive intelligent automation,” says Sumithra Gomatam, president, digital operations, Cognizant.At lingerie brand Clovia, customer interactions are handled by bots. Pankaj Vermani, founder and chief executive, says, “The next phase of bots will see customers being guided on product selection and size discovery assistance.”A large ecommerce company is using bots to pay suppliers. “If you are doing 10 million transactions daily, accuracy is important and so is time and compliance. This is where bots score,” says Milan Sheth, lead, intelligent automation, EY India. “We are trying to create bots to pick out anomalies in non-disclosure agreements and memoranda of understanding. The progression is: use bots to assist, then assign them tasks and eventually leave it all for bots to do,” predicts Nitin Chugh, country head, digital banking, HDFC Bank.I Robot: Where’s My Paycheque?There can be much fiery debate over bots snatching away humans’ jobs. But while each bot is as good as, or better, than 2.5 human workers, it needs at least 5-7 people to develop, deploy and maintain it. Ergo, at least coders can rest easy.But in a billion-plus country where only 10-12% of the 480 million workers are in the organised sector, intelligent automation — though inevitable — is bound to face backlash. In election season, farm distress and youth unemployment is already political ammunition.Yogendra Yadav, national president, Swaraj India, feels it’s a “fundamental error in believing there’s something called advanced technology.” The US and Europe have deficient labour and excess capital, he argues, making bots relevant there. “In India, the situation is the opposite. Advanced, cutting edge technology should create jobs with least amount of capital.”Chakraborty of TeamLease has a counterargument. “Any innovation comes with side effects. That’s no argument against innovation. Use of bots is mankind’s statement to move to higher order jobs,” she says.For technology apologists, bots crumble if there are multiple intents and can only be designed, created, developed and even maintained by humans. “Historically, market expansion and job creation are because of use of technology. I can empathise with people’s fears,” says Ravanan. However, “getting humans and intelligent bots to collaborate and feed off each other’s insights will be key to evolution,” feels Gomatam.As per EY estimates, 40% of any job component is digital and increasing. “If the economy doesn’t grow, even bots will be unemployed. If the economy expands, as is expected, there will be jobs for both humans and bots,” argues Sheth. Of the 15 names mentioned in this story, three are of bots. It’s possible that a story written five years from now will be based mostly on conversations with chatbots. In some global newsrooms, baby steps have already been carried out.There is, however, a dark side. Bots are being employed to spread misinformation or propaganda in political and corporate warfare. Canny algorithms invade our space with targeted messaging. In today’s Orwellian world, everything — from personal photographs to financial records — are vulnerable to the prying eyes of bots.  66937209  Facing unprecedented global backlash, Facebook and Twitter have purged millions of bots who have been spamming humans while promoting hate, misogyny, terror, sexual abuse and pornography or just plain falsehoods.“We now stop more than one million accounts per day at the time of upload,” points out Monika Bickert, vice-president, product policy and counter-terrorism, Facebook. About 1.3 billion fake accounts have been brought down in May-October.Of course, it is unlikely that the need for humans —to write a story, run factories or companies and work at the bank — will disappear. Still, dystopian though it may seem, the post of a bot manager who has been trained by bot teachers and hired by bots may be a coveted job sooner than you think.",,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Economic Times', 'productID': 'prime.economictimes.indiatimes.com:prime'}",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiS2h0dHBzOi8vd3d3LmVuZ2luZWVyaW5nLmNvbS90aGUtdXNlLW9mLWFpLWFuZC12ci1pbi1tYWludGVuYW5jZS1tYW5hZ2VtZW50L9IBAA?oc=5,The Use of AI and VR In Maintenance Management - ENGINEERING.com,2018-12-03,ENGINEERING.com,https://www.engineering.com,A look at how artificial intelligence and virtual reality are changing manufacturing.,,A look at how artificial intelligence and virtual reality are changing manufacturing.,,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://www.engineering.com/the-use-of-ai-and-vr-in-maintenance-management/', 'url': 'https://www.engineering.com/the-use-of-ai-and-vr-in-maintenance-management/', 'name': 'The Use of AI and VR In Maintenance Management - Engineering.com', 'isPartOf': {'@id': 'https://www.engineering.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.engineering.com/the-use-of-ai-and-vr-in-maintenance-management/#primaryimage'}, 'image': {'@id': 'https://www.engineering.com/the-use-of-ai-and-vr-in-maintenance-management/#primaryimage'}, 'thumbnailUrl': 'https://www.engineering.com/wp-content/uploads/2024/05/bigstock-Industrial-Factory-Woman-With-198968515.jpg', 'datePublished': '2018-12-03T10:42:00+00:00', 'dateModified': '2018-12-03T10:42:00+00:00', 'author': {'@id': 'https://www.engineering.com/#/schema/person/c143dad0ddd21ddc74292570a4c22a39'}, 'description': 'A look at how artificial intelligence and virtual reality are changing manufacturing.', 'breadcrumb': {'@id': 'https://www.engineering.com/the-use-of-ai-and-vr-in-maintenance-management/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.engineering.com/the-use-of-ai-and-vr-in-maintenance-management/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.engineering.com/the-use-of-ai-and-vr-in-maintenance-management/#primaryimage', 'url': 'https://www.engineering.com/wp-content/uploads/2024/05/bigstock-Industrial-Factory-Woman-With-198968515.jpg', 'contentUrl': 'https://www.engineering.com/wp-content/uploads/2024/05/bigstock-Industrial-Factory-Woman-With-198968515.jpg', 'width': 640, 'height': 427}, {'@type': 'BreadcrumbList', '@id': 'https://www.engineering.com/the-use-of-ai-and-vr-in-maintenance-management/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.engineering.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'The Use of AI and VR In Maintenance Management'}]}, {'@type': 'WebSite', '@id': 'https://www.engineering.com/#website', 'url': 'https://www.engineering.com/', 'name': 'Engineering.com', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.engineering.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.engineering.com/#/schema/person/c143dad0ddd21ddc74292570a4c22a39', 'name': 'Bryan Christiansen', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.engineering.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/74904329232a46c523d1508a48cb031b?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/74904329232a46c523d1508a48cb031b?s=96&d=mm&r=g', 'caption': 'Bryan Christiansen'}, 'url': 'https://www.engineering.com/author/bryan-christiansen/'}]",,,,,,,,,,,,,,,,"


 


3D Printing


																	3D-Printed Swag Ideas for Your Next Trade Show																


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiNWh0dHBzOi8vaHJtYXNpYS5jb20vY2hpbmEtbGVhZHMtaW4taGlyaW5nLWFpLXRhbGVudHMv0gEA?oc=5,China leads the world in hiring AI talents | HRM Asia - HRM Asia,2018-12-06,HRM Asia,https://hrmasia.com,,,"China and the US are leading the way in AI employment globally, with China topping the list with just over 12,000 job listings.",,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://hrmasia.com/china-leads-in-hiring-ai-talents/', 'url': 'https://hrmasia.com/china-leads-in-hiring-ai-talents/', 'name': 'China leads the world in hiring AI talents | HRM Asia', 'isPartOf': {'@id': 'https://hrmasia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://hrmasia.com/china-leads-in-hiring-ai-talents/#primaryimage'}, 'image': {'@id': 'https://hrmasia.com/china-leads-in-hiring-ai-talents/#primaryimage'}, 'thumbnailUrl': 'https://hrmasia.com/wp-content/uploads/2018/12/pic-1.jpg', 'datePublished': '2018-12-06T00:05:40+00:00', 'dateModified': '2018-12-10T02:14:14+00:00', 'author': {'@id': 'https://hrmasia.com/#/schema/person/b29372701a854890161e0ea362a6b0c6'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://hrmasia.com/china-leads-in-hiring-ai-talents/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrmasia.com/china-leads-in-hiring-ai-talents/#primaryimage', 'url': 'https://hrmasia.com/wp-content/uploads/2018/12/pic-1.jpg', 'contentUrl': 'https://hrmasia.com/wp-content/uploads/2018/12/pic-1.jpg', 'width': 1536, 'height': 1536}, {'@type': 'WebSite', '@id': 'https://hrmasia.com/#website', 'url': 'https://hrmasia.com/', 'name': 'HRM Asia', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://hrmasia.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://hrmasia.com/#/schema/person/b29372701a854890161e0ea362a6b0c6', 'name': 'HRM Asia Newsroom', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrmasia.com/#/schema/person/image/', 'url': 'https://hrmasia.com/wp-content/uploads/2018/09/HRM_Avatar2-120x120.jpg', 'contentUrl': 'https://hrmasia.com/wp-content/uploads/2018/09/HRM_Avatar2-120x120.jpg', 'caption': 'HRM Asia Newsroom'}, 'url': 'https://hrmasia.com/author/hrmasia/'}]",,,,,,,,,,,,,,,,"

China leads the world in hiring AI talents

        China and the US are leading the way in AI employment globally, with China topping the list with just over 12,000 job listings.    


        By: HRM Asia Newsroom | December 6, 2018
            

Topics: Asia-Pacific | China | Europe | News | Recruitment | US   


 
 
China has topped the list of 15 industry-leading countries with the most artificial intelligence (AI) job offerings, according to software company UiPath.
China has over 12,000 job listings covering roles including software engineer, intelligence researcher, sales engineer and product engineer. This is followed by the United States at 7,000. Other leading countries include Japan, the United Kingdom, India, Germany, France, Canada, Australia, and Poland.
The company looked at AI job offerings worldwide, scanning through 30,000 job listings from 15 countries.
UiPath reported that China’s Suzhou and Shanghai are the top two cities in the number of AI jobs, with 3,300 and 1,600 jobs respectively.
According to PwC, AI could add up to US$15.7 trillion (SGD$21 trillion) to the global economy by 2030.
ShareTweetShare

 




 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vd3d3LmNuYmMuY29tLzIwMTgvMTIvMDUvd2FsbWFydC13aWxsLXVzZS1odW5kcmVkcy1vZi1haS1yb2JvdC1qYW5pdG9ycy10by1zY3J1Yi1zdG9yZS1mbG9vcnMuaHRtbNIBbWh0dHBzOi8vd3d3LmNuYmMuY29tL2FtcC8yMDE4LzEyLzA1L3dhbG1hcnQtd2lsbC11c2UtaHVuZHJlZHMtb2YtYWktcm9ib3QtamFuaXRvcnMtdG8tc2NydWItc3RvcmUtZmxvb3JzLmh0bWw?oc=5,Walmart will soon use hundreds of A.I. robot janitors to scrub the floors of US stores - CNBC,2018-12-05,CNBC,https://www.cnbc.com,"Walmart, America's largest private employer, is deploying 360 floor scrubbing robots armed with artificial intelligence technology in stores across the US after partnering with AI company Brain Corporation.","['makeit', 'Articles', 'Robotics', 'Walmart Inc', 'Entrepreneurship', 'Make It - Power Players', 'Make It', 'Make It - Life', 'Make It - Food, Travel and Tech', 'source:tagname:CNBC US Source']","Walmart, America's largest private employer, is deploying 360 floor scrubbing robots armed with artificial intelligence technology in stores across the US after partnering with AI company Brain Corporation.","Walmart, America's largest private employer, is deploying 360 floor scrubbing robots armed with artificial intelligence technology in stores across the US after partnering with AI company Brain Corporation.",https://schema.org,,NewsArticle,Walmart will soon use hundreds of A.I. robot janitors to scrub the floors of US stores ,https://www.cnbc.com/2018/12/05/walmart-will-use-hundreds-of-ai-robot-janitors-to-scrub-store-floors.html,https://www.cnbc.com/2018/12/05/walmart-will-use-hundreds-of-ai-robot-janitors-to-scrub-store-floors.html,https://image.cnbcfm.com/api/v1/image/105609537-1544038192286walmartbraincorprobot.jpg?v=1684512026&w=720&h=405,"{'@type': 'ImageObject', 'url': 'https://image.cnbcfm.com/api/v1/image/105609537-1544038192286walmartbraincorprobot.jpg?v=1684512026', 'width': 2000, 'height': 1125}",Make It,"[{'@type': 'Person', 'name': 'Tom Huddleston Jr.', 'url': 'https://www.cnbc.com/tom-huddleston-jr/'}]",,"{'@type': 'NewsMediaOrganization', 'name': 'CNBC', 'url': 'https://www.cnbc.com/', 'foundingDate': '1989-04-17', 'logo': {'@type': 'ImageObject', 'url': 'https://sc.cnbcfm.com/applications/cnbc.com/staticcontent/img/cnbc-hdr-logo2.png', 'width': 378, 'height': 98}, 'sameAs': ['https://www.facebook.com/CNBCMakeIt', 'https://www.twitter.com/CNBCMakeit', 'https://www.linkedin.com/showcase/cnbc-make-it']}",2018-12-05T19:37:06+0000,2018-12-05T19:37:06+0000,2018-12-05T22:16:07+0000,"Make It - Food, Travel and Tech",,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', '/html/head/meta[@name=""description""]/@content'], 'cssSelector': ['.group p']}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{'@type': 'VideoObject', 'contentUrl': 'http://pdl.iphone.cnbc.com/VCPS/Y2016/M11D18/3000569336/makeit_robots_take_jobs_clifford_L.mp4', 'description': 'Some experts say as many lose their jobs, due in part to automation, one solution might be for the government to institute a universal basic income.', 'duration': 'PT1M15S', 'name': 'If robots take your job, the government might have to pay you to live', 'thumbnailUrl': 'https://image.cnbcfm.com/api/v1/image/104117471-makeit_robots_take_jobs_clifford_mezz.jpg?v=1529473338', 'uploadDate': '2016-11-18T15:20:03+0000'}"
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3doYXQtam9icy13aWxsLWJlLXJlcGxhY2VkLWJ5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW9yLXRlY2hub2xvZ3nSAYYBaHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3doYXQtam9icy13aWxsLWJlLXJlcGxhY2VkLWJ5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW9yLXRlY2hub2xvZ3k?oc=5,What Jobs will be Replaced by Artificial intelligence or Technology? - Analytics Insight,2018-12-02,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,Artificial Intelligence Jobs,Jobs replaced by Artificial Intelligence,AI to replace jobs,Jobs will be Replaced by Artificial intelligence","Simply, it can be assumed that most jobs will ultimately get replaced by technology. And no one is safe. Artificial Intelligence will very soon capture the role","Simply, it can be assumed that most jobs will ultimately get replaced by technology. And no one is safe. Artificial Intelligence will very soon capture the role",http://schema.org,,NewsArticle,What Jobs will be Replaced by Artificial intelligence or Technology?,https://www.analyticsinsight.net/artificial-intelligence/what-jobs-will-be-replaced-by-artificial-intelligence-or-technology,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/what-jobs-will-be-replaced-by-artificial-intelligence-or-technology'}",https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2018/12/AI-Jobs.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2018/12/AI-Jobs.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",Artificial Intelligence,"[{'@type': 'Person', 'givenName': 'Pragna Mohapatra', 'name': 'Pragna Mohapatra', 'url': 'https://www.analyticsinsight.net/author/pragna-mohapatra'}]",,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.linkedin.com/company/analytics-insight/', 'https://www.facebook.com/analyticsinsight.net', 'https://twitter.com/analyticsinme', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/'], 'id': 'https://www.analyticsinsight.net'}",2018-12-02T13:41:05Z,2018-12-02T13:41:05Z,2018-12-02T13:41:05Z,,,"How Macroeconomic Factors Influence Crypto Market Volatility
","[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'What Jobs will be Replaced by Artificial intelligence or Technology?', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/what-jobs-will-be-replaced-by-artificial-intelligence-or-technology'}]",,What Jobs will be Replaced by Artificial intelligence or Technology?,,,,,,,,,,,,,,,,"Simply, it can be assumed that most jobs will ultimately get replaced by technology. And no one is safe. Artificial Intelligence will very soon capture the role of many white-collar jobs too, just like machines have taken away many blue-collar jobs and the tractors reduced many farming jobs..We have made a list of jobs which may soon be replaced by Artificial Intelligence. These jobs have a standard sequence of recurring activities or they are cheaper when computerized than carried out by a human. Such estimated patterns are easy to reproduce through highly developed machine learning algorithms..Call Center Customer Care.Why: At most of the call centers, humans are employed to answer and counter the customer queries. But, in the Google I/O 2018 event, Google displayed a demo version of Google Duplex. It was so wonderful that you wouldn't think it's a demo version. The assistant making calls and interacting with a real person at the other end of the line is not only amazing but also well, job taking. Google Duplex is so good and its completed version can easily replace the human workers at the call center..Tele-Marketers.Why: Today, chances are high you've received one of those robocalls from telecom companies and different service providers. In Uganda, most people remember these robo-calls at the time of the presidential elections when a robocall in President Museveni's voice called a number of people showing gratitude to them for voting..Many people hate this type of promotion and its return on investment is little. Therefore, businesses aim to mechanize it with cheaper and mostly more competent AI..Clerks.Why: Most bookkeeping is replaced by automated programs like QuickBooks, FreshBooks, and Microsoft Office. These are more inexpensive than hiring people. One program is enough to perform all the company's book-keeping..Couriers.Why: The job of delivery guys have been reducing in some developed countries. They are getting replaced by drones and robots. As a result, this area may soon get dominated by automation and AI drones..In many parts of Africa, there are no delivery drones. In the technology world, what occurs in Rome does not end there. Soon AI will make its way to these markets too and the delivery boy will have some unemployment to deal with..Retail shopkeepers.Why: Currently, people are getting more dependent on online platforms than the physical store. Companies are trying to make the shopping experience as tremendous with features like self-checkout. Buyers are getting more tech-savvy and companies may take the help of AI to fix this. Physical shopkeepers are probably to be replaced by Artificial Intelligence and other technologies.Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/what-jobs-will-be-replaced-by-artificial-intelligence-or-technology', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2018/12/AI-Jobs.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,,,,,,,,

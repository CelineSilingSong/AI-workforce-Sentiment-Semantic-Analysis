URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,mainEntityOfPage,dateCreated,jobTitle,mainEntity,identifier,creator,breadcrumb,articleBody,isPartOf,mentions,hasPart,address,diversityPolicy,email,legalName,leiCode,telephone,logo,brand,thumbnailUrl,alternativeHeadline,speakable,specialty,mainContentOFPage,inLanguage,lastReviewed,target,foundingDate,slogan,contactPoint,sameAs,founder,numberOfEmployees,potentialAction,copyrightYear,contentLocation,associatedMedia,@graph,isBasedOn,comment,commentCount,copyrightHolder,sourceOrganization,@id,ethicsPolicy,masthead,uploadDate,embedUrl,contentUrl,duration,tags,about,sponsor,editor
https://news.google.com/rss/articles/CBMimwFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Jlcm5hcmRtYXJyLzIwMjEvMDEvMjkvdGhlLWFtYXppbmctd2F5cy13aWxkLW1lLXVzZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLWNpdGl6ZW4tc2NpZW50aXN0cy10by1oZWxwLXdpdGgtY29uc2VydmF0aW9uL9IBAA?oc=5,The Amazing Ways Wild Me Uses Artificial Intelligence And Citizen Scientists To Help With Conservation - Forbes,2021-01-29,Forbes,https://www.forbes.com,"Wildlife conservation is an enormous challenge. Wild Me, a non-profit organization, is leveraging the photos and videos of citizen scientists and the cloud, artificial intelligence, and computer vision to help track individual animals and to inform wildlife conservation efforts.","ai,artificial intelligence,wildlife,conservation,data sets,big data","Wildlife conservation is an enormous challenge. Wild Me, a non-profit organization, is leveraging the photos and videos of citizen scientists and the cloud, artificial intelligence, and computer vision to help track individual animals and to inform wildlife conservation efforts.","Wildlife conservation is an enormous challenge. Wild Me, a non-profit organization, is leveraging the photos and videos of citizen scientists and the cloud, artificial intelligence, and computer vision to help track individual animals and to inform wildlife conservation efforts.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2021/01/29/the-amazing-ways-wild-me-uses-artificial-intelligence-and-citizen-scientists-to-help-with-conservation/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/60139ca26580dd95edd4bbc2/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",The Amazing Ways Wild Me Uses Artificial Intelligence And Citizen Scientists To Help With Conservation,2021-01-29T00:28:40-05:00,2021-01-29T10:37:45-05:00,Enterprise Tech,The Amazing Ways Wild Me Uses Artificial Intelligence And Citizen Scientists To Help With Conservation,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise Tech,,"More From ForbesJul 15, 2024,09:02am EDTWhen Will Quantum Computers Affect Your Competitive Landscape?Jul 15, 2024,09:00am EDTAristotle’s Timeless Guide To Mastering AIOpsJul 15, 2024,03:25am EDTIEEE Travels In July (Japan, China And Greece)Jul 14, 2024,03:19am EDTMaking A More Accurate And Sustainable AI ModelJul 12, 2024,09:00am EDT‘Knowledge Is Power’: The Antipattern That Is Holding Your Team BackJul 12, 2024,07:00am EDTHow Generative AI Rattles the WorkplaceJul 11, 2024,12:49pm EDTReality Check: Generative AI’s Impact May Be Overstated, For NowEdit StoryForbesInnovationEnterprise TechThe Amazing Ways Wild Me Uses Artificial Intelligence And Citizen Scientists To Help With ConservationBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itJan 29, 2021,12:28am ESTUpdated Jan 29, 2021, 10:37am ESTThis article is more than 3 years old.Share to FacebookShare to TwitterShare to LinkedinDid you know that scientists have identified only 1.5 million species out of the 10 million estimated on Earth? And many of those species are vulnerable to extinction. Thanks to the efforts of the non-profit organization Wild Me, the gargantuan task of wildlife preservation is getting a much-needed assist from citizen scientists who photograph and video wildlife when traveling the world, plus high-tech solutions such as cloud computing, artificial intelligence, and machine vision.
The Amazing Ways Wild Me Uses Artificial Intelligence And Citizen Scientists To Help With ... [+] ConservationAdobe Stock

Creating Collaborative Data Sets

To make the progress on wildlife conservation that’s necessary, it’s going to take pulling data out of proprietary data sets and joining them into collaborative data sets. This is precisely what Wild Me and its Wildbook platform can do for the effort. The human effort it would take to sort through and classify images and videos of each animal is prohibitively time-consuming. With cloud computing and artificial intelligence, not only does the accuracy improve, but it reduces the time of identifying individual animals from hours when humans do it down to seconds when machines are on the job.

Once the specific animal is identified by the machine analyzing its unique markings, including stripes, spots, and other defining physical features such as scars, the location, time, and date of the image is recorded. Over time, the records for each animal continue to grow as more citizen scientists and researchers add to the image catalog. The data that's collected about each animal can be used by wildlife experts to track the health, migration, and other important facts about a species. Scientists can use this species info along with climate, geographic, behavioral, and environmental data to better understand the ecological and conservation issues they are facing.

PROMOTED
Wild Me started off by tracking whale sharks, a project that launched in 2003 after Jason Holmberg, director of engineering for Wild Me and chief information architect of Wildbook, went scuba diving and saw his first whale shark. After that first encounter, he joined a research expedition and learned how whale sharks were being tracked at the time by using plastic tags. Unfortunately, these plastic tags were rarely re-sighted, therefore making the ability to collect sufficient data on each individual animal nearly impossible.
Holmberg believed there was a more effective way to track animals by using computer vision. He set out to develop the algorithm and the platform to do just that. Wild Me and Wildbook are the result. 
MORE FROMFORBES ADVISORBest High-Yield Savings Accounts Of September 2023ByKevin PayneContributorBest 5% Interest Savings Accounts of September 2023ByCassidy HortonContributor
Today, Wild Me uses computer vision algorithms to identify whale sharks based on their unique markings from the photos taken around the world by tour operators, tourists, and researchers. They have tagged more than 8,100 whale sharks since the project began, thanks to the contributions of citizen scientists. The success of this database has prompted many other researchers to realize the potential of the citizen-scientist model for their conservation efforts, including projects focused on zebras, humpback whales, ragged-tooth sharks, polar bears, and more. Wild Me made its Wildbook platform open source to allow others to use this non-invasive tracking of species. 









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



To make the Wildbook platform better equipped to scale and handle many more endangered species, Wild Me is working with Microsoft and its AI for Earth program. Now that Wild Me and Microsoft are collaborating, they have grand ambitions that could include expanding the artificial intelligence tools to many more species as well as launching a tweet bot. Already an intelligent agent tags ""whale shark"" on YouTube videos nightly by using machine learning and natural language processing to read the video description to determine if the video's description includes info about the animal.


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
By 2100, 38 percent of all species will be extinct without action and intervention. Insights from data and the processing power that comes with the cloud and artificial intelligence can be instrumental in understanding the issue and how extinction could be prevented. These efforts are most certainly time-sensitive, so any technology that can speed the efforts are necessary. The beauty of Wild Me and its efforts is the combination of citizen scientists participating to submit the data, images, and videos required for the machines to yield insights about wildlife conservation. The public also has the ability to follow their favorite animals and to contribute to the global conservation effort. 
There’s no doubt Wild Me’s innovations have revolutionized animal identification. It’s a spectacular example of what can result when humans and machines combine efforts for the greater good.
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihgFodHRwczovL3d3dy5jb2UuaW50L2VuL3dlYi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS8tL2ZhY2lhbC1yZWNvZ25pdGlvbi1zdHJpY3QtcmVndWxhdGlvbi1pcy1uZWVkZWQtdG8tcHJldmVudC1odW1hbi1yaWdodHMtdmlvbGF0aW9uc9IBAA?oc=5,Facial recognition: strict regulation is needed to prevent human rights violations - Council of Europe,2021-01-29,Council of Europe,https://www.coe.int,Latest news of the Council of Europe's work related to AI,"newsroom,ai,dg1 human rights and rule of law,central division dg1,public,compulsory,general, news, ai, council of europe",Latest news of the Council of Europe's work related to AI, Strasbourg 28 January 2021,https://schema.org,WebPage,,"{'@type': 'ImageObject', 'url': 'https://www.coe.int/documents/40452431/43026603/facial+recognition+DP.jpg/75af6869-31a9-b632-bf87-ebe2eff0e263', 'height': 489, 'width': 870}","{'@type': 'Organization', 'name': 'Council of Europe'}","{'@type': 'Organization', 'name': 'Council of Europe', 'logo': {'@type': 'ImageObject', 'url': 'https://static.coe.int/pics/logos/desktop/logo-coe-google-news.png', 'width': 78, 'height': 60}}",Facial recognition: strict regulation is needed to prevent human rights violations,2021-01-29T15:08:00+00:00,2024-05-17,,News,,,,,"

Strasbourg
28 January 2021


                Diminuer la taille du texte
            

                Augmenter la taille du texte
            

                Imprimer la page
            




©Shutterstock

The Council of Europe has called for strict rules to avoid the significant risks to privacy and data protection posed by the increasing use of facial recognition technologies. Furthermore, certain applications of facial recognition should be banned altogether to avoid discrimination.
In a new set of guidelines addressed to governments, legislators and businesses, the 47-state human rights organisation proposes that the use of facial recognition for the sole purpose of determining a person’s skin colour, religious or other belief, sex, racial or ethnic origin, age, health or social status should be prohibited.
This ban should also be applied to “affect recognition” technologies – which can identify emotions and be used to detect personality traits, inner feelings, mental health condition or workers´ level of engagement – since they pose important risks in fields such as employment, access to insurance and education.
“At is best, facial recognition can be convenient, helping us to navigate obstacles in our everyday lives. At its worst, it threatens our essential human rights, including privacy, equal treatment and non-discrimination, empowering state authorities and others to monitor and control important aspects of our lives – often without our knowledge or consent,” said Council of Europe Secretary General Marija Pejčinović Burić.
“But this can be stopped. These guidelines ensure the protection of people’s personal dignity, human rights and fundamental freedoms, including the security of their personal data.”
The guidelines state that a democratic debate is needed on the use of live facial recognition in public places and schools, in light of their intrusiveness, and possibly also on the need for a moratorium pending further analysis.
The use of covert live facial recognition technologies by law enforcement would only be acceptable if strictly necessary and proportionate to prevent imminent and substantial risks to public security that are documented in advance.
Private companies should not be allowed to use facial recognition in uncontrolled environments, such as shopping centres, for marketing or private security purposes.
The guidelines were developed by the Consultative Committee of the Council of Europe Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data, which brings together experts representing the 55 states parties to the Convention as well as 20 observer countries.
The Convention, the first ever binding international treaty addressing the need to protect personal data, was opened for signature in Strasbourg forty years ago today, on 28 January 1981.
 
More information:

Data Protection
Artificial Intelligence

","{'@type': 'WebPage', '@id': 'https://www.coe.int/en/web/artificial-intelligence/-/facial-recognition-strict-regulation-is-needed-to-prevent-human-rights-violations'}",2018-11-28,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOWh0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9vdXItcGVvcGxlL2FsZXhhbmRlci1zdWtoYXJldnNredIBAA?oc=5,Alexander Sukharevsky - McKinsey,2021-01-30,McKinsey,https://www.mckinsey.com,"Global leader of QuantumBlack, AI by McKinsey, working across industries to redefine business models and improve performance through the responsible use of artificial intelligence and technology",,"Global leader of QuantumBlack, AI by McKinsey, working across industries to redefine business models and improve performance through the responsible use of artificial intelligence and technology",,https://schema.org,Person,,,,,,,,,Alexander Sukharevsky,,,,,,,,"Senior Partner, London",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMmh0dHBzOi8vd3d3Lm5hdHVyZS5jb20vYXJ0aWNsZXMvczQxNTk4LTAyMS04MjA5OC0z0gEA?oc=5,A multilayer multimodal detection and prediction model based on explainable artificial intelligence for Alzheimer's ... - Nature.com,2021-01-29,Nature.com,https://www.nature.com,"Alzheimer’s disease (AD) is the most common type of dementia. Its diagnosis and progression detection have been intensively studied. Nevertheless, research studies often have little effect on clinical practice mainly due to the following reasons: (1) Most studies depend mainly on a single modality, especially neuroimaging; (2) diagnosis and progression detection are usually studied separately as two independent problems; and (3) current studies concentrate mainly on optimizing the performance of complex machine learning models, while disregarding their explainability. As a result, physicians struggle to interpret these models, and feel it is hard to trust them. In this paper, we carefully develop an accurate and interpretable AD diagnosis and progression detection model. This model provides physicians with accurate decisions along with a set of explanations for every decision. Specifically, the model integrates 11 modalities of 1048 subjects from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) real-world dataset: 294 cognitively normal, 254 stable mild cognitive impairment (MCI), 232 progressive MCI, and 268 AD. It is actually a two-layer model with random forest (RF) as classifier algorithm. In the first layer, the model carries out a multi-class classification for the early diagnosis of AD patients. In the second layer, the model applies binary classification to detect possible MCI-to-AD progression within three years from a baseline diagnosis. The performance of the model is optimized with key markers selected from a large set of biological and clinical measures. Regarding explainability, we provide, for each layer, global and instance-based explanations of the RF classifier by using the SHapley Additive exPlanations (SHAP) feature attribution framework. In addition, we implement 22 explainers based on decision trees and fuzzy rule-based systems to provide complementary justifications for every RF decision in each layer. Furthermore, these explanations are represented in natural language form to help physicians understand the predictions. The designed model achieves a cross-validation accuracy of 93.95% and an F1-score of 93.94% in the first layer, while it achieves a cross-validation accuracy of 87.08% and an F1-Score of 87.09% in the second layer. The resulting system is not only accurate, but also trustworthy, accountable, and medically applicable, thanks to the provided explanations which are broadly consistent with each other and with the AD medical literature. The proposed system can help to enhance the clinical understanding of AD diagnosis and progression processes by providing detailed insights into the effect of different modalities on the disease risk.",,,Scientific Reports - A multilayer multimodal detection and prediction model based on explainable artificial intelligence for Alzheimer’s disease,https://schema.org,WebPage,,,,,,,,,,,,,,"




Download PDF








Article

Open access

Published: 29 January 2021

A multilayer multimodal detection and prediction model based on explainable artificial intelligence for Alzheimer’s disease
Shaker El-Sappagh1,2, Jose M. Alonso3, S. M. Riazul Islam4, Ahmad M. Sultan5 & …Kyung Sup Kwak6 Show authors

Scientific Reports
volume 11, Article number: 2660 (2021)
            Cite this article




22k Accesses


136 Citations


17 Altmetric


Metrics details






AbstractAlzheimer’s disease (AD) is the most common type of dementia. Its diagnosis and progression detection have been intensively studied. Nevertheless, research studies often have little effect on clinical practice mainly due to the following reasons: (1) Most studies depend mainly on a single modality, especially neuroimaging; (2) diagnosis and progression detection are usually studied separately as two independent problems; and (3) current studies concentrate mainly on optimizing the performance of complex machine learning models, while disregarding their explainability. As a result, physicians struggle to interpret these models, and feel it is hard to trust them. In this paper, we carefully develop an accurate and interpretable AD diagnosis and progression detection model. This model provides physicians with accurate decisions along with a set of explanations for every decision. Specifically, the model integrates 11 modalities of 1048 subjects from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) real-world dataset: 294 cognitively normal, 254 stable mild cognitive impairment (MCI), 232 progressive MCI, and 268 AD. It is actually a two-layer model with random forest (RF) as classifier algorithm. In the first layer, the model carries out a multi-class classification for the early diagnosis of AD patients. In the second layer, the model applies binary classification to detect possible MCI-to-AD progression within three years from a baseline diagnosis. The performance of the model is optimized with key markers selected from a large set of biological and clinical measures. Regarding explainability, we provide, for each layer, global and instance-based explanations of the RF classifier by using the SHapley Additive exPlanations (SHAP) feature attribution framework. In addition, we implement 22 explainers based on decision trees and fuzzy rule-based systems to provide complementary justifications for every RF decision in each layer. Furthermore, these explanations are represented in natural language form to help physicians understand the predictions. The designed model achieves a cross-validation accuracy of 93.95% and an F1-score of 93.94% in the first layer, while it achieves a cross-validation accuracy of 87.08% and an F1-Score of 87.09% in the second layer. The resulting system is not only accurate, but also trustworthy, accountable, and medically applicable, thanks to the provided explanations which are broadly consistent with each other and with the AD medical literature. The proposed system can help to enhance the clinical understanding of AD diagnosis and progression processes by providing detailed insights into the effect of different modalities on the disease risk.



Similar content being viewed by others






An explainable machine learning approach for Alzheimer’s disease classification
                                        


Article
Open access
01 February 2024









In-depth insights into Alzheimer’s disease by using explainable machine learning approach
                                        


Article
Open access
20 April 2022









Machine learning prediction of incidence of Alzheimer’s disease using large-scale administrative health data
                                        


Article
Open access
26 March 2020








IntroductionAlzheimer’s disease (AD) is a chronic neurodegenerative disease. This irreversible disorder is characterized by abnormal accumulation of amyloid plaques and neurofibrillary tangles in the brain, resulting in progressive decline in memory, thinking and language skills, along with behavioral changes. With increased human life expectancy, 11 million to 16 million elderly people are likely to suffer from AD by 20501. As far as we know, there is no effective recovery for this disease. However, early detection is of fundamental importance for timely treatment and progression delay2,3,4. Furthermore, prediction of the probable progression of the disease from mild cognitive impairment (MCI) to AD is of critical importance5,6. MCI is considered an intermediate stage between age-associated cognitive impairment and AD. For effective treatment, it is therefore essential to detect patients with MCI at high risk of progression to AD7. As a result, AD diagnosis and progression detection are multistage in nature. First, physicians determine the category of the patient (MCI or AD). Second, they deeply investigate patient biomarkers to determine progression status to AD from MCI. Most studies in the literature focus either on AD diagnosis1,8,9,10,11,12 or MCI progression, i.e., progressive MCI (pMCI) versus stable MCI (sMCI)13,14,15. Even if it is highly desirable to deal simultaneously with AD diagnosis and MCI progression, this task is extremely hard mainly due to the multimodality nature that also jeopardizes explainability.AD symptomatology is multimodal in nature4,16 correlated with cognitive scores, neuropathology vital signs, symptoms, demographics, medical history, neuropsychological battery, lab tests, etc. Complementary information exists among the modalities, which can be exploited to build powerful classifiers17. Therefore, medically intuitive AD detection methods should not rely only on measurements of a unique domain, such as physiological or behavioral symptoms. Alberdi et al.1 surveyed the AD diagnosis studies based on multimodal data. The combination of multimodalities facilitates the detection of subtle changes in all modalities from the very beginning, which results in reliable diagnoses. Once in the hands of an expert, it is still a challenge to correctly diagnose AD. Usually, medical experts are not able to manually analyze all of these vast and diverse biomarkers, and recognize the so-small behavioral shifts in AD patients until it is too late18. AD could be diagnosed after two years of memory problems19. There is an emerging need for advanced AD detection and prediction models that can serve as a helping hand for medical practitioners to diagnose or detect the disease earlier and more accurately5,19,20. These models can be used to build the inference engines of an AD clinical decision support system (CDSS). However, as far as we know there is no CDSS for AD diagnosis and progression detection ready to use at primary care. In this context, two lines of research have been conducted to address the previous challenges: (1) deep learning (DL) techniques which are able to automatically learn complex, non-linear data transformations that optimize performance metrics21,22,23; and (2) regular machine learning (ML) techniques, especially support vector machine (SVM) and random forest (RF)7,24,25,26,27,28.Unfortunately, all these previous studies focused mainly on improving the system performance while neglecting interpretability issues. Accordingly, although these studies achieved tremendous advances in prediction, they are not expected to be acceptable in the medical environment. There exists a significant gap between academic research outcomes and their effective utilization in medical practice due to several reasons20. The entire patient medical history must be considered to achieve intuitive, stable, and robust decisions20. Most DL-based methods only concentrate on analysis of neuroimaging, i.e., Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET). Nevertheless, Oxtoby and Alexander29 asserted that neuroimaging is not sufficient for AD diagnosis and studying its progression. Furthermore, it is frequently the case that physicians do not rely on the latest technical approaches and methodologies (e.g., DL and RF), despite their high accuracy18, because complex model performance and explainability are in apparent conflict- i.e., the search for a good performance-explainability trade-off is required. Most of these approaches and schemes are inherently opaque, not understandable, and unable to easily answer the following straightforward questions. Why/how has it reached a specific decision, and why/how is it medically relevant30? The patterns learned from datasets by using complex ML algorithms do not necessarily carry correct and comprehensible knowledge. Thus, medical experts do not trust decisions provided by black-box models without comprehensive and easy-to-understand explanations31. For these reasons, the ML techniques employed in the clinical domain normally do not consider sophisticated models, resorting instead to simpler and interpretable (e.g., linear) models at the expense of accuracy32. Many studies have tried to open the black box of complex models and provide an explanation of their decisions, either by understanding how the models work or by explaining their decisions33. This new trend is called accountable, transparent, actionable, or explainable Artificial Intelligence (AI), or just XAI for short. Explainability is the ability of ML algorithms to (mathematically) explain or justify their results using terms which are understandable to humans.A CDSS should be based only on ML models that provide a balance between accuracy and explainability. These models are expected to provide sufficient information about the relationship between input features and predictions, and to allow users to answer questions like the following. Which features are the key players in the prediction of interest? Why am I deemed as normal/MCI/AD in the medical diagnosis? For these reasons, the second line of research introduced above (i.e., a CDSS based on regular ML techniques) seems more intuitive and medically acceptable. Regular ML techniques involving linear models and rule-induction algorithms (e.g., a decision tree [DT]34 or a fuzzy rule-based system [FRBS]35,36) are usually preferred when the priority is to generate explainable models18,37,38,39. Unfortunately, these models are not always accurate enough40. One solution is to use an accurate algorithm as an oracle for the classification purpose, and a collection of carefully designed interpretable models (which behave as digital twins of the oracle, i.e., they imitate the classification behavior of the oracle) as candidates to generate explanations of the output provided by the oracle41. The other solution is to open the black box and collect the explanations from the opaque model itself. For example, some studies have extracted interpretable rules from black-box models such as neural networks and SVMs42,43. In the case of RF, Brieman44 asserted that it is an A + predictor for performance, but rates an F on interpretability. More recently, some authors have shown how the behavior of RF can be interpreted to some degree31,45. There exists no study in the literature, which use the RF algorithm in the core of an explainable CDSS system for AD diagnoses and progression detection.Despite the current research effort, AD detection and progression prediction are still openly challenging problems, due to the limited accuracy and limited explainability of existing solutions. The medical domain requires both accurate and explainable AI models. In this paper, we therefore develop a new RF-based explainable AD detection and progression prediction model. Our contributions are as follows:

1.
We demonstrate how to retain interpretability, even when a complex ensemble model like RF is used. The objective of this approach is two-fold: (1) To illustrate the development and validation process of a two-layer computational framework for diagnosing AD patients and predicting pMCI within three years from baseline diagnosis; and (2) to describe how to provide detailed and multiple explanations for the ML decisions. The resulting model provides physicians with a good balance between accuracy and explainability.


2.
We build accurate ML ensemble classifiers based on RF for the two layers; utilizing multimodal AD datasets collected from the Alzheimer’s Disease Neuroimaging Initiative (ADNI). We employ a comprehensive list of modalities to diagnose AD and predict its progression, in agreement with a physician who was taken as domain expert.


3.
We build 22 explainers, based on a set of interpretable ML techniques (i.e. DT and FRBS), ready to explain to physicians the outcome of the two-layer framework. This reverse engineering method is called a black-box outcome explanation33. All explainers’ decisions compatible with RF decisions are used to provide physicians with a pool of plausible explanations. In analogy with a panel of experts who may have different experience and background, each explanation comes from a different explainer which pays attention to the most relevant features for different modalities, and comes along with information about the reliability of the explainer in terms of its accuracy. The consistency and coherence of such explanations are validated by domain experts and ranked according to their explainability-accuracy trade-off. Moreover, they are mapped to a human-friendly language for easy understanding.


4.
We provide physicians with some insights into driving factors of our prediction model from multiple points of view including natural language, visualization, and feature importance based on SHapley Additive exPlanations (SHAP).

The rest of this paper is organized as follows. Section 2 presents and discusses the main reported results. Section 3 introduces the datasets used and goes in depth with technical details of the proposed method. Section 4 concludes the paper.Results and discussionIdentification of informative AD featuresTo reduce computational complexity that comes with the high dimensionality nature of the ADNI, we selected the most relevant feature set using automatic feature selection strategy. For each layer, the full dataset is stratified and randomly divided into a model development set [\(S1\)] and a testing set [\(S2\)]. \(S1\) and \(S2\) are filtered to create the best feature sets \(MS1\) and \(MS2\), respectively (see the Feature Selection and Modeling Approach Section; in Material and Methods). The new sets are used to tune, train, and tests the utilized ML models. Training and tuning of ML models is done with cross-validation over MS1 while MS2 is reserved to provide readers with final test evaluation, mainly regarding some illustrative examples of the explainability of the proposed framework.Figure 1A shows the performance of different subset sizes assessed with RF-RFE (A.1), SVM-RFE (A.2), and GB-RFE (A.3) for the first layer. For different combinations of features, the accuracy from RF, SVM, and GB was measured, and the subset of features with the best performance was detained. As summarized in Table 1, for RF-RFE, we obtained a combination of 28 features [cognitive scores (8), genetics (5), lab tests (1), demographics (3), MRI (2), neuropsychological battery (6), and PET (3)] to attain the highest predictive accuracy of 94.4% (see Supplementary File [part 2], Table T1). Because the optimal subset of features derived using the RFE-RF approach yields the maximum accuracy, we utilized it for training the classification model. These features form about 15% of the whole feature set. Inspired by20, the features selected with RF-RFE are clustered into six modality kinds: (1) cognitive scores (CS) [eight features]; (2) neuropsychological battery (NB) [six features]; (3) MRI [two features], (4) PET [three features], (5) genetics [five features], and (6) medical history (MH) (lab test and demographics) [four features]. It is worth noting that the selected features based on RF-RFE are the most discriminant and informative features for the current classification problem (P < 0.05, Kruskal–Wallis test). The list of non-selected features does not add discriminative values with RFE; however, as asserted by our domain experts, many of these neglected features could provide additional knowledge to understand the made decisions (i.e., they include critical values for model’s explainability in accordance with physicians’ intuition and background). The different modalities were screened to investigate whether a cost-effective and non-invasive subset of features have a higher discriminative power than the whole dataset.Figure 1Selected features for both layers based on three different techniques of SVM, RF, and GB. The first row is for the first layer, and the second row is for the second layer.Full size imageTable 1 Performance of the RFE for the two layers.Full size tableFigure 1B shows the performance of different subset sizes assessed with RF-RFE (B.1), SVM-RFE (B.2), and GB-RFE (B.3) for the second layer. The accuracy of RF, SVM, and GB was calculated for different combinations of features, and the subset of features with the best performance was taken. Similar to the First Layer, the RFE algorithm attained a higher performance when combined with RF than GB and SVM. With RF-RFE (see Table 1), the combination of 36 features [cognitive scores (7), genetics (5), lab tests (6), demographics (1), MRI (5), neuropsychological battery (7), PET (3), and vital signs (2)] achieves the highest predictive accuracy at 86.8%. Accordingly, we used the RF-RFE feature set for training the classification model. These features formed about 19% of the total feature set, (see Supplementary File [part 2], Table T1). Furthermore, we grouped this list of features into five modality types: (1) cognitive and functional assessments (CFA) (CS and NB), (2) MRI, (3) PET, (4) genetics, and (5) MH (lab tests, age, and vital signs). As with the First Layer, we analyzed the performance of different RF classifiers constructed using each modality (as well as their combinations).First layer: early AD detection performanceThe First Layer in the framework is responsible for detecting AD patients from CN and MCI patients. To determine the smallest number of features that produces the most accurate results, we performed a set of experiments using different combination of modalities. Table 2 shows the performance obtained for the multiclass classification problem (i.e., CN, MCI, and AD) by using the whole training dataset and different combinations of six selected modalities (CS, NB, MRI, PET, MH, and genetics) and RF classifier (see the Random Forest for Classification Section). The models’ performance has been evaluated using the area under the receiver operating characteristic curve (AUC), precision, recall, accuracy (AC), and F1-score (F1) metrics (see the Model Performance Evaluation Metrics; in Material and methods). When the whole feature set is used, the model has a multiclass classification accuracy (MCA) of 93.42 ± 2.73% based on tenfold CV. We can see that the CS modality has the highest accuracy (MCA = 92.00 ± 2.26%), compared to other single modalities. As a result, the CS modality was combined with other modalities to test the improvement in the model performance. Please note that, although adding more features could increase the model’s confidence, it also adds additional noises. The two-modality combination CS + NB improved the CS accuracy by about 1%, i.e., MCA = 93.00 ± 2.61%. We notice that the standard deviation of the combined CS + NB data slightly increased compared to the CS dataset alone, but still it is less than the standard deviation of the models based on the whole dataset. After integration of the CS + NB modality with the other types of data, the genetics data improved the accuracy of the system to 93.95 ± 2.30%. We discover that the RF shows more confidence based on the CS + NB + Genetics dataset than CS + NB dataset. This is because its performance has lower standard deviation. The resulting modality of CS + NB + Genetics was tested by combining it with MRI, PET, and MH. However, the performance was not enhanced, and the models become noisier. As a result, the combination of CS, NB, and Genetics was selected as the one producing the best performance.Table 2 Random Forest performance validation for detecting AD patients based on tenfold cross-validation.Full size tableThe next step is to show the generalization capability of the proposed model. As shown in Table 3, we observe the same trend already shown in Table 2. Once again, the combination of NB, CS, and Genetics again achieved the best performance.Table 3 Random Forest performance testing for detecting AD patients (\(MS2\) test dataset;10% of the original data).Full size tableSecond layer: AD progression prediction performanceThe Second Layer in our framework optimizes a binary classification problem to predict the progression to AD within three years from baseline (i.e., sMCI versus pMCI). This classifier is first validated using tenfold CV on the \(MS1\) dataset. As shown in Table 4 with bold typeface, the best performance of this model was observed for the combined CFA, PET, Genetics, and MRI data, i.e. Precision = 88.07 ± 0.70%, Recall = 86.08 ± 1.30%, Accuracy = 87.09 ± 0.80%, F1-score = 87.08 ± 0.90%, and AUC = 87.08 ± 0.80%. In addition, this model achieved the lowest variance in performance compared to all models based on other combinations and the whole feature space. Regarding single modalities, CFA achieves the best performance (see Table 4). In addition, cognitive scores and neuropsychological battery are usually considered in clinical practice. Models built using either MH or PET alone achieved the worst performance and were noisy. Based on the results from single modalities, we combined the best CFA model with each of the other modalities to see if the performance may be improved or not.Table 4 Random Forest performance validation for predicting whether MCI subjects will progress to AD or not (tenfold cross-validation; Second Layer).Full size tableThe addition of PET data improves the predictive performance of our model because PET data provide complementary information about disease progression. The combination of CFA and PET modalities achieves the best performance compared to combinations of other pairs of modalities. However, the resulting model is less confident compared to the model based on CFA alone. This is probably because the PET modality added noise to the combined set. In addition, the CFA + PET modality achieved the smallest variance compared to other two modalities combinations. To check for possible improvement in model performance, the CFA + PET feature set was combined with each of the MRI, Genetics, and MH modalities. The multimodality of CFA, PET, and Genetics enhances the performance of progression prediction by about 2%, compared to the combined CFA and PET modality. In addition, the resulting model is more stable compared to the CFA + PET-based model. This is in accordance with the fact that medically, Amyloid β, PTAU, and TAU are critical biomarkers to monitor the progression of AD46,47,48,49,50,51. Finally, we check the effect of combining MRI and MH with the rest of the modalities (CFA, PET, and Genetics). Again, integrating MRI brain volume features (including the hippocampus, ICV, and others) improves the model accuracy by about 1%. MRI volume features provide vital information for effective prediction of AD progression. According to our domain experts, we believe this is medically promising because it is critical to integrate MRI features in order to measure possible AD progression. With the unseen data in \(MS2\) we verify the good generalization of the generated models that we already observed with tenfold CV (see Table 5).Table 5 Random Forest performance measures for AD progression prediction of MCI subjects based on CFA, MRI, PET, genetics, and MH modalities (\(MS2\) test dataset; Second Layer).Full size tableComparison with other classifiersRecently, Travers et al.21 provided a comprehensive survey of DL techniques in biology and medicine. In this context, Choi and Jin22 utilized a convolutional neural network (CNN) to detect pMCI cases based on positron emission tomography (PET) images. Spasov et al.23 proposed a multimodal DL classification model for AD progression detection based on the late fusion of magnetic resonance imaging (MRI), demographic, neuropsychological, and apolipoprotein E (APOE) e4 genetic data.In addition, many AD studies have considered a single modality, especially MRI, to make a binary classification of sMCI versus pMCI52,53. Li et al.54 used five cognitive scores with a Cox linear regression model to build two prognostic models of AD. Moradi et al.27 achieved an area under the curve (AUC) of 0.77 in discriminating pMCI from sMCI based on RF and MRI data only; after fusing MRI features with baseline cognitive scores and age, they achieved an AUC of 0.90 for the same problem. Jin et al.55 used a Bayesian network to analyze multimodal data from ADNI data including demographics, MRI, PET, neuropsychometrics tests, and genotypes. It is worth noting that RF56,57 is an ensemble classifier that can provide more accurate predictions than other ML techniques. Fernandez-Delgado et al.40 evaluated 179 classifiers using different UCI datasets, and concluded that RF outperforms other classifiers, including SVMs and neural networks. RF works well with a mixture of quantitative and categorical features, and unlike SVM, it handles multiclass problems natively. RF is able to learn wide datasets with a very large number of features, compared to the number of cases. RF has been used intensively in the AD domain26,57,58. For example, Ramírez et al.58 proposed an ML model to predict MCI from normal patients. This model is based on feature standardization, analysis of variance feature selection, partial least squares feature dimension reduction, and an ensemble of one vs. rest RF classifiers. The model achieved accuracy of 56.25% based on MRI data.To verify the goodness and robustness of our approach in each layer, we compared the performance of the RF models with other predictive models, namely the SVM, KNN, Naïve Bayes (NB), and DT models. For each layer, we use the selected features of RFE. For each selected algorithm, we tuned its hyperparameters the same way we tuned the RF algorithm. The results of the best performing parameters are shown in Tables 6 and 7. Our proposal outperforms the rest of classifiers. It is worth noting that we did not compare our model with the artificial neural network approach because they achieved really bad performance in preliminary experiments, mainly due to the small size of the used datasets. In other words, our data is not big enough for training and testing the state-of-the-art DL architectures.Table 6 Comparison of different classifiers (\(MS2\) test dataset; First Layer).Full size tableTable 7 Comparison of different classifiers (\(MS2\) test dataset; Second Layer).Full size tableModels explainabilityExplainability based on random forest internal logicBased on SHAP explainers, we calculate feature contributions of RF models (see the Explainability Capabilities Section; in Material and methods). Figure S1 in Supplementary File (part 2) shows this rank for each class in each layer. The most influential feature for the First Layer is CDRSB followed by MMSE, and the lowest feature is TRABSCOR_PartBTimeToComplete from the neuropsychological battery group (see Supplementary File [part 2], Table T2). For the Second Layer, FAQ plays the main role followed by ADNI_MEM, and Trail4Total has the lowest impact (see Supplementary File [part 2], Table T2). According to our domain experts, it is medically intuitive for cognitive scores to play the main role in detecting AD patients. However, for progression detection, we can see that Hippocampus and MidTerp volumes from MRI images also play significant role, in addition to FDG and SROI from PET images. Table 8 summarizes the sensitivity of the explainer to the different feature values for both layers. For further details about these features and terminologies, readers are invited to see the Supplementary File (part 2) and ADNI at http://adni.loni.usc.edu.Table 8 Examples of the relationship between features and class prediction.Full size tableExplainability of the behavior of individual featuresThe global feature importance gives an abstract view about the role of each feature, but we cannot know the direction of these effects. For example, we cannot know if a high value for CDRSB will increase the probability of selecting the AD, MCI, or CN class. Using SHAP summary plots, we are able to analyze the behavior of our XAI framework with respect to different values of features. Figure 2 shows the summary plots for every class in the first layer. Each dot represents the impact on a particular class of a particular feature for a given instance, and it is colored according to what magnitude of the value contributes to the model impact. The color represents the feature value (red = high, blue = low). We notice a different order for each class.Figure 2SHAP summary plots for the first layer. The upper left figure represents the CN class, the upper right figure represents the MCI class, and the second row represents the AD class.Full size imageIn the First Layer, we find that MMSE is more significant than CDRSB for the AD class, but CDRSB has the highest impact on the CN and MCI classes, see Table 8. The model shows a high degree of non-linearity because the impacts of many features are spread across relatively wide ranges. We notice that the high values of CDRSB have great positive impact on the model for predicting the AD class, meaning CDRSB is a factor that increases AD risk. For the CN class, low values of CDRSB have extreme positive impact on the model. In contrast, high values of ADNI_MEM, DigitalTotalScore, and MOCA have a positive impact on predicting the CN class. For the MCI class, low values of CDRSB have an extreme negative impact on the model. The CDGLOBAL feature is less critical than MOCA for the MCI class. However, in some cases, high values of this feature have a more negative impact on MCI cases than MOCA. The same happens for FAQ, where low values have a more positive impact on a system decision for the MCI class than MOCA and CDGLOBAL. We noticed that AD and MCI classes are related to negative values of ADNI_MEM, but CN is related to positive values. In addition, by plotting the impact of a feature on every sample, we can detect the impact of outliers. For example, in the case of the picture related to AD, although CDGLOBAL is not the most important feature globally, it is critical for a subset of patients. This is indicated by the long-tailed distribution to the right. Again, the same situation applies to the DigitalTotalScore feature for the AD class.In the Second Layer, although HCI is globally less significant than ADNI_MEM for both sMCI and pMCI, in a subset of patients, this feature has more impact than ADNI_MEM, see Table 8 and Fig. 3. The same is true for CDRSB in relation to MOCA for the pMCI class, and ADAS 11 in relation to CDRSB for the sMCI class. A feature with a longer tail to the right means it has a greater positive influence, and vice versa. As a result, understanding the detailed role of each feature alone and in combination with other features is of critical importance. For example, large values of RAVLT_immediate positively impact the model toward selecting the sMCI class, but negatively impact towards the pMCI class. FAQ is the most important feature for both classes, followed by ADNI_MEM, HCI, and ADAS 13. The two classes show symmetric behaviors for all features. It is clear that low values of FAQ negatively affect the prediction of pMCI class, but they have the largest positive impact for the sMCI class. Large values of ADAS 13 have a higher positive impact on the model for predicting the pMCI than ADNI_MEM. Small values of FDG have a greater positive impact for predicting pMCI than MOCA and ADAS 11. As a result, some features are not critical globally, but extreme values for specific cases have a greater impact in the model than the globally important features. Based on the knowledge of our domain experts, this is also medically intuitive, and increases the confidence of medical experts in the behavior of our system.Figure 3SHAP summary plots for the second layer. The left figure shows the pMCI class, and the right figure shows the sMCI class.Full size imageExplainability of individual casesFigure 4 shows examples of prediction for each class in the First Layer, and Figure S2 in Supplementary file (part 2) shows another example from the Second Layer. In addition, the figure illustrates supervised clustering of all cases according to their similarities.Figure 4First layer example predictions for AD (A), CN (B), and MCI (C) and SHAP supervised clustering in model behavior for all cases in each class. Red indicates attributions that push the score higher, while blue indicates contributions that push the score lower. A few of the noticeable subgroups are annotated with the features that define them.Full size imageEach example is a vertical line, and SHAP values for all cases are ordered by similarity. We identify some critical values for each cluster. Figure 4 (A) (part 1) shows a case with a probability of 75% for being AD. It also shows the most significant feature values that have a positive impact for that class, such as MMSE = 24, CDRSB = 3.0, MOCA = 19.3, etc. This is consistent with ADNI data, where the average values of all AD subjects are MMSE = 23.235 ± 2.015, CDRSB = 4.3 ± 1.591, and MOCA = 17.553 ± 3.377. In addition, it shows the features that push the classification away from the AD class including DigitalTotalScore = 33, CDGLOBAL = 0, etc. The features with less impact such as TAU = 347.9, PTAU = 31.64, RAVLT immediate = 27, FAQ = 5, and Trial5Total = 7 are represented with short arrows. Figure 4 (A) (part 2) shows the behavior of the model on all the instances, and the role of each feature to support (red) or not support (blue) classification as AD. Different clusters are defined according to the values of critical features. We find that when MMSE is in the interval [27, 30] and MOCA is in [23.62, 29], this combination has the greatest role in preventing the model from selecting the AD class (blue cluster). On the other hand, when CDRSB is in the range [3.5, 6.0], FAQ is in [6–17], and ADAS 13 is in [20–36], the model will mostly classify cases as AD (red cluster).Figure 4 (B) (part 1) does the same thing for the CN class. The model is 99% confident that the case is CN. Clearly defined clusters explain the model behavior in selecting the CN class. The most critical factors that push the decision towards CN class are CDRSB = 0 and DigitalTotalScore = 50. Figure 4 (B) (part 2) shows the overall logic in detecting CN subjects. We observe some critical values of some clusters from this figure. For example, if CDRSB = 0, FAQ = 0, DigitalTotalScore is in [31, 50], MMSE is in [27, 30], and ADAS 13 is in [1, 15], the patient is mostly classified as CN (red cluster). This means that if MMSE is combined with both CDRSB and FAQ at 0, it loses a lot of its impact on AD class prediction. According to the ADNI data and our experts’ knowledge, these decisions are medically intuitive because the average values of critical factors for CN subjects are CDRSB = 0.039 ± 0.141, FAQ = 0.194 ± 0.720, and DigitalTotalScore = 48.173 ± 7.481. Figure 4 (C) (part 1) shows the prediction of our model for an MCI case. In general, the characteristics of MCI cases are between those of CN and AD classifications. According to the model prediction, the low value of CDRSB (1 in this current case) has a high positive impact on predicting MCI cases. This subject has a negative ADNI_MEM value, which may have a significant impact on the system’s decision. By comparing the feature values of the three cases, we can say that a little change in CDRSB has a great impact on performance, and this is compatible with Fig. 2. Please note that the combination of different values of features could change the role of the related feature, as well as the final decision.Explainability of the interaction between featuresAs shown in the middle of Figs. 3 and 4, many features (such as PTAU for AD class and ABETA for the CN and MCI classes), show a high degree of uncertainty. In addition, some features (such as Entorhinal and PTAU) seem to have less impact, because they are at the bottom of the list. However, these features may have a critical impact if they were combined with specific values of other features. To study the role of these types of features, we need to zoom in and study their behavior in combination with other features. Note that interaction analysis can be studied for other globally important features, as well, like CDRSB and FAQ.Due to space restrictions, in Figure S3 of Supplementary File (part 2), we give a detailed example of the interaction impacts from one of these noisy features (e.g. PTAU) in the First Layer, and we study the impact of less globally critical feature (e.g., Entorhinal) in the Second Layer to highlight its role (see Fig. 2). As can be seen, the domain expert is able to interpret the internal behavior of the ML model and know exactly why it makes specific decisions. We notice that some features may be globally unimportant, but in some cases, they have extreme SHAP values, and that shows the real impact of these features. In addition, the real impact of a feature can be discovered by studying its interactions with other related features. Supplementary File (part 2) (Figure S4 to Figure S8) shows the SHAP interaction summaries for the most important features in both layers and for each class.Explainability based on single explainersIn this section, we provide explanations of the RF model decisions from other explainers and based on other data types. Domain experts often consider these biomarkers to make accountable decisions. For example, the First Layer’s model does not consider MRI and PET data. Furthermore, the Second Layer’s model does not consider medical history. In addition, both models do not consider lab tests, vital signs, and physical examinations. However, all these features are considered by our explainers. It is worth noting that we are not interested in explaining the internal behavior of the RF model but providing physicians with post-hoc explanations of every decision. In the same way, how different physicians may figure out different explanations (in terms of different features) for a given output, our explainers yield complementary, consistent and reliable explanations.Tables 9 and 10 summarize the quality (i.e. the performance-explainability trade-off) of the 22 explainers (11 DT and 11 FURIA) for each layer. Even if some of these explainers exhibit poor performance, they all exhibit complementary explainability because they depend on different features. In practice, these explainers provide physicians with plausible explanations in natural language. It is worth noting that given a specific data instance, only those explainers that point out at the same output class as the RF model are taken into account when generating explanations. Moreover, physicians are provided with explanations along with information about the reliability of each single explainer in terms of its balance between accuracy and explainability. At the end, the physician makes the final decision on which explainers to trust or to discard likewise she may ask for alternative opinions of different colleagues who are likely to have different experience and background. As expected, DT is clever for some modalities, while FURIA is better for others.Table 9 The performance of the explainers on different modalities (First Layer).Full size tableTable 10 The performance of the explainers on different modalities (Second Layer).Full size tableWe analyzed each instance in the test dataset of both layers and recorded how many explainers could predict the same class as their corresponding oracle (i.e. the RF model). The test set in the First Layer was made up of 105 instances. On average, 58.1% of the instances were managed by each single explainer. Regarding the number of explainers that act for each single instance, we found there were 13 (the median value) explainers considered; being 3 the worst case and 22 the best case. Being DT (vital signs-based) the least used explainer (34.4%) and FURIA (cognitive scores based) the most used explainer (92.4%). The test set in the Second Layer was made up of 49 instances. On average, 63% of the instances were managed by each single explainer. Being DT (neurological exams-based) the least used explainer (47%) and both DT and FURIA (cognitive scores-based) the most used explainers (78%). Regarding the number of explainers which act for each single instance, we observed that 14 (the median value) explainers are considered; being 7 the worst case and 20 the best case. All in all, we can conclude that even in the worst cases, we are ready to supply physicians with more than one single explanation. Moreover, explanations are normally rich, thanks to the fact that they involve several modalities. This fact was especially well appreciated by the physicians who collaborated in our study.Case studies for FURIA and DT explainersThe supplementary file (part 3) lists a group of AD cases to tests the system explainability. The supplementary file (part 2) shows the expressiveness of the generated explanations for three illustrative case studies (see Supplementary File [part 2], Table T3 to T7). We tested the following: (1) the ability of explainers to generate supplementary explanations, (2) their consistency with the generated explanations from SHAP, and (3) the quality of the generated natural language explanations. In case study 1, we can see that generated explanations add many values to the interpretability and confidence of the decisions made. First, the explainers reinforce the explanations from SHAP. Second, they increase the confidence physicians have about the decision made. In case study 2, physicians can investigate all the information to understand why the system makes a specific decision. We note perfect matches among SHAP and explainers’ outputs. In case study 3, we observe how explanations related to sMCI and pMCI are somehow in contrast (and in accordance with) physicians’ intuition and background.Model strengths and limitationsThe proposed model is designed to comprehensively integrate high-fidelity Alzheimer’s data to predict AD and detect its possible progression within three years from baseline. We demonstrated the high predictive powers of the proposed models. The First Layer model achieves the best results by combining the NB, CS, and Genetics modalities. These modalities achieved the best cross-validations results. On the other hand, the Second Layer model shows the highest results based on CS, NB, PET, MRI, and Genetics. Both CS and NB have important roles in improving the performance of our model. Similar observations have been reported in the literature20. Note that not all biomarkers of these modalities are used in the training process, but only the features selected by the RFE technique. Using black-box models in the medical domain is very dangerous and not acceptable. Our model achieves superior performance, compared to other ML models; in addition, it combines high-accuracy, complex models (i.e. ensemble RF) with interpretable explanations. This combination allows physicians to receive the best possible predictions, and at the same time, gain insight into why those predictions were made. These actionable decisions increase the confidence and trust in the model’s behavior, help to debug the model, and can work as an educational tool for inexperienced physicians. Note that we used the word “confidence” to indicate that the model provided its results with small variances. In contrast, we used the word “trust” to indicate that our model provided interpretable and explainable results which improved the domain expert’s trust in the model’s decision. Moreover, when the model provided a result with high confidence, it then enhanced the domain expert’s level of trust. Consequently, in our study, more confidence resulted in more trust, in addition to the trust gained from explainability. The quantification of trust for deep learning models has been discussed recently59. Taking this quantification process into account would be an insightful investigation.Training general practitioners, based on educational interventions, to recognize and manage AD has no significant impact on clinical practice60. A CDSS can provide another solution, but current systems are mostly based on a single modality52,53, make use of binary models (e.g., CADi2)61, or are not explainable8,9,10,11,12,13,14,15. As a result, current systems are rarely used routinely in AD management. We believe that a CDSS based on our comprehensive, accurate, and explainable model could make a difference in practice. We provide explanations from different perspectives including CS, NB, MRI, PET, Genetics, medical history, etc. In addition, we provide detailed explanations based on feature contributions. We believe that these explanations provide supplementary knowledge for physicians to fully understand the rationale behind the decisions taken. To the best of our knowledge, this is the first study that provides such a comprehensive model and with such explainability features.Our model has a couple of limitations worth noting. First, we only considered the baseline data for making decisions. Because AD is a chronic disease, a time-series data analysis would be of critical value62,63. A future attempt will study the role of longitudinal data to enhance the model’s accuracy and explainability. We could consider some DL techniques, which are clever at handling time-series data, such as long short-term memory, in such a future study. Second, the ADNI collects data about the roles of a patient’s medication history and comorbidities on AD progression. No such research has been done previously to study these data. Another future enhancement could be the integration into the prediction ML model of semantic intelligence from ontologies. We will consider semantics from the standard ontologies (e.g. RxNorm, Systematized Nomenclature of Medicine-Clinical Terms [SNOMED CT], etc.) to encode these data and to infer hidden knowledge about the relationships between drugs, diseases, and Alzheimer’s. Third, the network science approaches have been used to characterizing the brain activities for AD patients to extract interconnectivity patterns of brain regions based on neuroimaging techniques64,65,66,67. Although these studies provided additional insights into AD pathophysiology, they come with several limitations. For example, Chen et al.,64 used a small cohort of 55 subjects for classifying subjects as AD vs. MCI vs. AD using the large-scale network analysis approach. These data have been collected at baseline visit only, and no longitudinal study has been performed. However, cross-sectional studies cannot dynamically observe changes in network patterns with disease progression. Furthermore, postmortem studies are required as the reference standard when validating the large-scale network methods. In addition, the study used simple linear regression to measure the relationship between changes in network connectivity strengths and behavioral scores. Wang et al.65 utilized a small dataset of 89 subjects to evaluate the impaired network functional connectivity with AD progression. Even though the whole brain network is complex, varied, and interrelated, this study was based on only five networks which put limitations placed on its results. Thus, the entire brain network analysis with finely defined regions is important. Also, this study is based on baseline data only. Besides, longitudinal data of multiple modalities such as functional and structural MRI, PET, genetic genotype, etc. should be fused to follow individuals to differentiate all the severity levels. In future studies, one might explore these network science approaches and integrate them with advanced XAI and deep learning techniques. In this context, we can study the roles of time series data to improve the current literature. Moreover, the role of data fusion of different modalities might be explored using different ML and DL algorithms. Finally, a web based CDSS system based on a user-friendly interface can provide medically intuitive aids for both medical experts and general practitioners. Work is currently in progress to develop such a system, which will be extended to work as a pluggable component of the electronic health record ecosystem. This design facilitates data entry by the physician, online training of the models, and automatic updates on patient status.Material and methodsADNI studyData used in this work was collected from the ADNI database (adni.loni.usc.edu). Subjects have been enrolled from over 57 sites across the U.S. and Canada. The study was conducted according to the Good Clinical Practice guidelines, the Declaration of Helsinki, US 21 CFR part 50 —Protection of Human Subjects—and part 56—Institutional Review Boards. Subjects were willing and able to undergo test procedures, including neuroimaging and follow-up, and written informed consent was obtained from participants. All data are publicly available, at http://adni.loni.usc.edu/.In all, 1048 subjects (54.5% male) participated in the study and were categorized into four groups based on the individual clinical diagnosis at baseline and future visits, as follows: (a) cognitively normal (CN): 294 subjects (28.1%) diagnosed as CN at baseline who remained CN at the time this manuscript is prepared. (b) sMCI: 254 subjects (24.2%) diagnosed as MCI at all-time points. (c) pMCI: 232 subjects (22.1%) evaluated as MCI at baseline visit who had progressed to AD within three years. (d) AD: 268 subjects (25.6%) who had a clinical diagnosis of AD for all visits. Subjects showing improvement in their clinical diagnosis during follow up (i.e., those clinically diagnosed as MCI but reverting to CN, or those clinically diagnosed as AD but reverting to MCI or CN) were excluded from the study because of the potential uncertainty of clinical misdiagnosis, considering that AD is considered irreversible form of dementia. In addition, cases that had a direct conversion from CN to AD were also removed. Patients taking part in this study are anonymized and the actual list of patient IDs in our study can be found in Supplementary File (part 1). The data used in this research are from the baseline visits only, no longitudinal data were considered.Study cohortsEligible participant patients were from 55 to 91 years old, fluent in English or Spanish, and had at least six years of education. Participants were categorized into three groups: CN, MCI (sMCI + pMCI), or AD. CN individuals were free of memory complaints, had a mini-mental state examination (MMSE) score of 24 to 30, and an average clinical dementia rating sum of boxes score (CDR-SB) of 0.04. MCI individuals had MMSE scores of 23 to 30, and an average CDR-SB of 1.582. MMSE and CDR-SB scores for MCI subjects were considerably different from CN subjects (P < 0.0001). The ages of MCI subjects were significantly different from AD and CN subjects (P < 0.005). The years of education for MCI subjects were significantly different from CN subjects (P < 0.01). AD patients fulfill diagnostic criteria for probable AD as set by the National Institute of Neurological and Communicative Disorders and Stroke of the United States and the Alzheimer’s Disease and Related Disorders Association68, with MMSE scores of 19 to 27 and an average CDR-SB of 4.347. MMSE and CDR-SB scores of AD subjects were significantly different from CN and MCI subjects (p < 0.0001). The ages of AD subjects were significantly different from CN subjects (P < 0.05), and the education years of AD subjects were significantly different from CN subjects (P < 0.0001) and MCI subjects (P < 0.01). Available ADNI subjects (n = 1048) with both a T1-weighted MRI scan and a PET–fluorodeoxyglucose (PET-FDG) image upon preparation of this manuscript were used in this study. For the PET data, we collected only three PET-FDG features from Banner Alzheimer’s Institute (BAI)-PET Naval Medical Research Center (NMRC) summaries and University of California, Berkeley, FDG analysis69. The MRI features used in our experiments are based on the imaging data from the ADNI database processed by a team from UCSF, who performed cortical reconstruction and volumetric segmentations with the FreeSurfer version 6.0 image analysis suite (https://surfer.nmr.mgh.harvard.edu/) according to the atlas generated by Desikan et al.70.The FreeSurfer software version 6.0 (https://surfer.nmr.mgh.harvard.edu/) was employed to automatically label cortical and subcortical tissue classes for the structural MRI scan of each subject, and to extract thickness measures of cortical regions of interest and cortical and subcortical volume measures. Based on the 312 features collected from each MRI image, we calculated seven features including ventricles, middle temporal gyrus [midTemp], fusiform, entorhinal, hippocampus, and whole brain volume. The equations used to calculate these features can be found in Supplementary File (part 2). Details of the analysis procedure are available at ADNI (http://adni.loni.usc.edu/methods/mri-tool/mri-analysis/). Detailed descriptions of the ADNI subjects, image acquisition protocol procedures, and post-acquisition preprocessing procedures can be found at ADNI (http://www.adni-info.org/). Demographic and clinical information of the subjects is shown in Table 11. In this study, we utilized multiple modalities that include the followings: (i) Cognitive scores, e.g. 12 features of the Alzheimer’s diseases assessment scale–cognitive subscale (ADAS-Cog) 11, ADAS-Cog 13, global CDR (CDGLOBAL), CDRSB, functional assessment questionnaire (FAQ), geriatric depression scale (GDT), MMSE, Montreal cognitive assessment (MoCA), and the neuropsychiatric inventory questionnaire score (NPISCORE). (ii) PET features, i.e. FDG, hypometabolic convergence index (HCI), and statistical region of interest [SROI]). (iii) Neuropsychological battery, i.e. 35 features of the Rey auditory verbal learning test (RAVLT), CLOCK, COPY, and AVTOT total scores and sub-scores. (iv) Neuropathology vital signs, i.e. seven features including body mass index (BMI), weight, blood pressure, etc. (v) Cerebrospinal fluid (CSF) biomarkers, i.e. TAU, phosphorylated TAU—PTAU, and amyloid-β peptide of 42 amino acids- Aβ1–42. (vi) Demographics, i.e. gender, age, number of years of education, marital status, and ethnic and racial categories. (vii) Medical history, i.e. 22 binary features to check the patient and parents histories, including smoking, allergies, malignancy, gastrointestinal problems, etc. (viii) Symptoms, i.e. 27 binary features asking about diarrhea, dizziness, falls, etc. (ix) Lab tests, i.e. 41 blood lab tests, including vitamin B12, monocytes, platelets, etc. (x) Physical examinations, i.e. 10 feature asking about problems in the head, neck, skin, chest, etc. (xi) Neurological exams, i.e. 12 binary features from the cerebellar exam, gait, motor strength, sensory capabilities, etc. (xii) MRI volumetric features, i.e. volumes of ventricles, MidTemp, fusiform, entorhinal cortex, hippocampus, total intracranial volume (ICV), and whole brain. (xiii) Genetics, i.e. APOE4. To the best of our knowledge, there are no studies in the literature, which study the role of all of these biomarkers. More details about these features can be found in Supplementary File (part 2).Table 11 Descriptive statistics from the dataset used.Full size tableFeature selection and modeling approachThe proposed model has two main layers. Each layer has an oracle classifier based on RF and a set of 22 explainers. The oracle is trained to be as accurate as possible based on the fused dataset. The First Layer’s oracle classifies the patient as CN, MCI, or AD based on the whole dataset. The Second Layer’s oracle concentrates further on the MCI cases, filtered from the previous layer, to predict their probable progression to AD within three years from baseline. As such, the Second Layer classifies the MCI cases into sMCI and pMCI cases. The development process of the proposed oracles has several major steps, as presented in Fig. 5. These steps are applied in the same order for both layers separately. First, after fusing the raw data modalities, for each layer, the full dataset is stratified and randomly divided into a model development set [\(S1\)] (90%) and a testing set [\(S2\)] (10%) that is utilized to evaluate and compare the generality and explainability of models. This split prevents the mixing of model-selection and performance estimation, which supports the estimations of unbiased generalization performance from the models. Second, a feature standardization step is assimilated on numerical features to normalize them in the same way, which is done by standardizing the random variables with zero mean and unitary standard deviation. Note that categorical features are excluded from the normalization process.Figure 5Development process for the oracle model in each layer.Full size imageThird, for enhanced generalization performance of the models, the \(S1\) set is used to implement a feature selection process to identify the most relevant features. Fourth, most ML approaches tend to generate biased models when handling imbalanced datasets. Our Second Layer’s dataset is balanced (52.3% sMCI and 47.7% pMCI). However, the First Layer’s dataset is imbalanced (28.05% CN, 46.37% MCI, and 25.58% AD). Therefore, the synthetic minority oversampling technique (SMOTE) is used to handle the class imbalance in the \(S1\) set of the First Layer by resampling the original data and creating synthetic instances71. Fifth, to guarantee unbiased tuning of model hyperparameters, and because our datasets are relatively small, the model selection and validation process (i.e. hyperparameter optimization) is carried out based on the grid search and nested k-fold stratified cross-validation (CV) where k = 1072. The entire process has two loops: an inner loop for hyperparameter tuning, and an outer loop for evaluation of the model with selected parameters on unseen data73. Model selection without nested CV uses the same data from parameter tuning and model evaluation, where information may leak into the model and overfit the data. The leave-one-out cross-validation (LOOCV), i.e. k-fold CV where k = n72, assures small bias but large variance74. The tenfold CV provides the best trade-off between bias and variance75. Keeping the \(S2\) set untouched helps us to verify that the generalization performance of the selected model thanks to tenfold CV is preserved even with unseen data. In each layer, we develop an RF classification model based on the selected features.RF classifiers are used because they are accurate, and it is possible to get the feature contributions for the whole model (a global explanation) and calculate feature contributions for each specific instance (a local explanation). Although SVM and DL have a huge capability to fit complex nonlinear models to the data and achieve high performance, the resultant models are opaque what makes hard to explain their decisions18. We therefore selected RF as the oracle to classify patients in our two-layer model.After building the RF oracle classifiers, we implement two interpretable classifiers (DT and FRBS) for each of the 11 modalities in each layer. The resulting 22 classifiers play the role of explainers to interpret the oracle decisions at each layer. Thus, we have 11 classifiers as a DT, and 11 classifiers as an FRBS. The FRBS deals naturally with imprecision and uncertainty36. Moreover, an FRBS plays an important role in the quest for XAI76. More precisely, we selected the Fuzzy Unordered Rule Induction Algorithm (FURIA) [51] from among all algorithms available for building an FRBS. FURIA is recognized as one of the most accurate fuzzy classifiers. In addition, FURIA usually yields a compact set of fuzzy IF–THEN rules. FURIA is based on the Repeated Incremental Pruning to Produce Error Reduction (RIPPER) algorithm77. FURIA translates RIPPER rule antecedents into trapezoidal fuzzy sets. These antecedents are related by FURIA weighed rules, which do not necessarily include an antecedent for all the input attributes and can have more than one antecedent for the same attribute. Each FURIA rule is associated with a certainty factor, i.e. a rule weight that FURIA computes regarding the relevance of the rule in accordance with the training data. Given a specific data instance, the min–max fuzzy inference mechanism is applied, and the winning rule, i.e. the one with maximum firing degree, determines the output class. If no rules are fired for a given data instance, then FURIA applies the so-called rule-stretching mechanism, which looks for slight modifications in the rule base with the aim of finding a new rule on-the-fly that is able to manage the given instance. Unfortunately, FURIA rules lack linguistic meaning because they have local semantics, i.e. the most suitable fuzzy sets are defined independently for each rule. This fact may jeopardize the interpretability of FURIA rules.With the aim of paving the way from interpretable to explainable classifiers, we use ExpliClas78. This is a web service ready to provide users with multimodal (textual + graphical) explanations related to the DT and FURIA. As a matter of fact, ExpliClas creates a linguistic layer on top of the DT and FURIA. First, global semantics (whether we consider the DT or FURIA) is set up beforehand. By default, three linguistic terms (e.g., low, medium, high) are defined for each attribute. Next, domain experts (if available) can add/remove/refine the given linguistic terms to assure they are meaningful. Then, given a specific data instance, the actual classification carried out by the DT or FURIA is automatically interpreted by ExpliClas with regard to the linguistic terms previously defined. In practice, both the activated branch of the DT and the winner rule of FURIA are translated into sequences of meaningful words (i.e., each numerical interval in the DT or fuzzy set in FURIA is verbalized by the closest linguistic term in ExpliClas). As a result, users are provided with an explanation in natural language of the output class in terms of the involved attributes. It is worth noting that we substituted the default linguistic terms in ExpliClas by meaningful linguistic terms in agreement with a physician in this study.Figure 6 shows a detailed description of our proposed XAI framework. The first step is preprocessing, which is used to prepare and improve the quality of the datasets. This step has the following four sub-processes.

Preparing biological modalities: For the biological MRI modality, we used ready-made extracted and pre-processed features (http://adni.loni.usc.edu/), done by ADNI. We then used these detailed features to create a list of seven volumetric summary features for the most critical brain regions of interest, including the hippocampus, ventricles, entorhinal, fusiform gyrus, MidTemp, whole brain, and ICV. For biological PET modality, we collected only three FDG-PET features from BAI-PET NMRC summaries and UC Berkeley-FDG analysis69. For instance, to measure FDG, mean levels of glucose metabolisms are first recorded at different regions of interest. The five most common regions are left and right angular gyri, posterior cingulate cortex, and left and right inferior temporal gyri. Then, the summation of the mean glucose metabolisms is considered FDG79. Other PET measures include the HCI to characterize in a single summary metric the extent to which both the magnitude and spatial extent of cerebral glucose hypometabolism in a person’s FDG-PET image corresponds to that in patients with probable AD dementia80. Our prepared PET and MRI features are based on their popularity in studies from the literature, their availability, and their level of accuracy in our current medical problem (see Supplementary File [part 2] for further details).


Multimodal fusion: The AD environment is multimodal in nature, where multiple feature sets are combined. This is called multimodal fusion, where each modality has supplementary information to support the final decision. In this context, two simple strategies are followed: late fusion and early fusion. In late fusion (i.e., decision-level fusion), a different model is trained independently for each modality, and the individual outcomes are merged into a final common decision, as seen in Fig. 7a. In the early fusion strategy (i.e., feature-level fusion), raw features from the individual modalities are integrated to create a common feature vector. The common feature vector is then used to train a classifier as the final prediction model, as seen in Fig. 7b. Each strategy has its own advantages and disadvantages. However, late fusion is based mainly on computing weights associated to which classifiers, which is not an easy process to learn and to explain. Therefore, in this study, we apply the early fusion strategy.


Data standardization: After data splitting, each type of participating data may have a different order of magnitude. These raw data cannot be used directly to train the RF model. To ensure that every feature has the same level of importance, data were standardized using the z-score method (see Eq. 1). The standardized data is therefore normally distributed with mean and standard deviation of 0 and 1, respectively.$$z_{j} = \frac{{x_{j} - \mu_{j} }}{{\sigma_{j} }}$$
                    (1)
                
where \({x}_{j}\) is the old value of feature \(j\), \({z}_{j}\) is the normalized value, \({\mu }_{j}\) is the feature’s mean, and \({\sigma }_{j}\) is the feature’s standard deviation. As a side effect, this method removes outliers.


Handling missing values: For handling missing values, we first removed any feature with more than 30% of the values missing. Then, we use the k-nearest neighbors (KNN) algorithm to impute missing values, where missing values are replaced using information from neighbor subjects that have the same class. After finding \(k\) neighbors, the imputation value is computed by averaging the values of those neighbors. In our study, the mixed Euclidean distance (MED) was used, and k was set to 10 empirically via experiments (for numerical values, the Euclidean distance was used; for categorical values, a distance of 0 was taken if both values were the same, otherwise the distance was set to 1). Please note that the data standardization process has been done before the missing values handling.$$MED\left( {x,y} \right) = \sqrt {\mathop \sum \limits_{i = 1}^{N} d_{i} \left( {x_{i} ,y_{i} } \right)^{2} }$$
                    (2)
                
where \(d_{i} \left( {x_{i} ,y_{i} } \right) = \left\{ {\begin{array}{*{20}l} {overlab\left( {x_{i} ,y_{i} } \right)} \hfill & {if\;i\;is\;categorical} \hfill \\ {diff\left( {x_{i} ,y_{i} } \right)} \hfill & {if\;i\;is\;numerical} \hfill \\ \end{array} } \right.\), \(overlab\left( {x_{i} ,y_{i} } \right) = \left\{ {\begin{array}{*{20}l} 0 \hfill & {if\;x_{i} = y_{i} } \hfill \\ 1 \hfill & {if\;x_{i} \ne y_{i} } \hfill \\ \end{array} } \right.\), and \(diff\left({x}_{i},{y}_{i}\right)=\frac{{x}_{i}-{y}_{i}}{{max}_{i}-{min}_{i}}\)

Figure 6The proposed XAI framework. A variety of data modalities are used to build the predictive model. In addition, a variety of explanations are built for the entire RF behavior and for each prediction. The FreeSurfer version 6.0 is used (https://surfer.nmr.mgh.harvard.edu/).Full size imageFigure 7Multimodal fusion strategies: (a) late fusion, (b) early fusion.Full size imageFor the automatic feature selection, we used wrapper methods, which obtain subsets of features, and offer better performance than filter methods20. The commonly used classifiers in wrapper are naïve Bayes81, SVM82, RF83, and AdaBoost84. Along with greedy search algorithms, these methods find the optimal set of features. It is worth noting that the well-known principal component analysis (PCA) technique cannot be used in our experiments because we need to preserve meaningful medical features, and PCA produces synthetic features that are hard to interpret as a combination of the principal components.Recursive feature elimination (RFE) is famous in the medical domain owing to its efficiency in reducing computational burden85. It maximizes its predictor performance through backward feature elimination as well as its ranking criterion. The literature asserts that RF-RFE outperforms SVM-RFE in finding the best subsets of features, and does not need any parameter regulation to offer reasonable outcomes86. We applied RFE with the stratified tenfold CV related to the \(S1\) dataset. To prevent the bias introduced by randomly partitioning a dataset in CV, the tenfold CV procedure was repeated five times with different data partitions. To evaluate the robustness of the RF-RFE process in selecting the optimal set of features, we utilized the RFE method with RF, SVM, and gradient boosting (GB) classifiers. The initial fused feature set had 188 features combined from 11 different modalities, including MRI, genetics, and symptoms.The two RF models are used as the oracle to make the final decisions. Of course, final decisions are made by physicians in light of the provided information (i.e., both oracle decisions, along with related explanations). The 11 modalities are used separately to build classifiers by using two interpretable ML models, i.e. DT and FURIA. In each layer, the resulting 22 interpretable models are used to support the oracle model by providing interpretations of its decisions. The supplementary explanations extracted from different modalities with different classification algorithms are expected to enhance the medical expert’s confidence in the oracle decisions. As a result, it supports the applicability of the resulting system in real medical environments. It is worth noting that we are not interested in explaining the internal behavior of the oracle but providing physicians with post-hoc explanations of the decision output. Our approach is inspired in the way how different experts who look at the same patient may figure out different explanations for a given output in terms of different features (i.e., in accordance with their own knowledge and background). Similarly, our explainers provide physicians with complementary explanations, all of them consistent and reliable.Random forest for classificationRF is an ensemble classifier formed by a family of \(T\) decision trees,\(h\left({n}_{1}|{\theta }_{1}\right),\dots , h\left({n}_{T}|{\theta }_{T}\right)\), where \({\theta }_{i}=({\theta }_{i1},{\theta }_{i2}{,\dots ,\theta }_{ip})\) is a list of \(p\) features for DT \(i\), and \({n}_{i}\) represents the training instances. Each DT leads to a classifier. Specifically, given data \(D={\{{(\theta }_{i},{y}_{i})\}}_{i=1}^{N}\), we train a family of classifiers,\({h}_{T}\). The predictions of all individual trees are combined by using the majority-voting mechanism. A node is partitioned using the best possible binary split. In our case, information gain is used to define the split point at each node, where \(G\left(S,A\right)=E\left(S\right)-\sum_{v\in values\left(A\right)}\frac{\left|{S}_{v}\right|}{\left|S\right|}E\left({S}_{V}\right)\), and \(E(X)=-\sum_{i=1}^{c}{p}_{i} {log}_{2}({p}_{i})\) is the entropy of set \(X\), in which \({p}_{i}\) is the probability of class \(i\); \(\left|{S}_{v}\right|\) is the number of cases with \(A={S}_{v}\), and \(|S|\) is the number of cases in \(A\). Outliers are likely to be ignored by most trees, which makes RF more stable.Another important feature of RF is its ability to measure the importance of each feature based on the Gini impurity index. Gini impurity is the likelihood of an incorrect classification of a randomly selected case if it was randomly labeled according to the class distribution of the data. From intuitive perspective, Gini impurity helps the algorithm to decide the optimal split from a root node, and subsequent splits. It is calculated as \(G(D)=\sum_{i=1}^{c}p\left(i\right)*(1-p(i))\), where \(c\) is the number of classes and \(p(i)\) is the relative frequency of class \(i\) in \(D\). For an attribute \({\theta }_{m}\), if it splits \(D\) in to \({D}_{1}\) and \({D}_{2}\), then the Gini index for \({\theta }_{m}\) is \({G}_{{\theta }_{m}}\left(D\right)=\frac{\left|{D}_{1}\right|}{\left|D\right|}G\left({D}_{1}\right)+\frac{\left|{D}_{2}\right|}{\left|D\right|}G\left({D}_{2}\right),\) and the reduction in impurity is \(\Delta G\left({\theta }_{m}\right)=G\left(D\right)-{G}_{{\theta }_{m}}\left(D\right)\). A binary DT,\({h}_{T}\), is built from a learning sample of size \({n}_{t}\) drawn from \(D\) using a recursive procedure, which identifies at each node \(t\) the split condition \({s}_{t}={\theta }_{m}<c\) that splits \({n}_{t}\) node samples into \({t}_{L}\), and \({t}_{R}\) maximizes the decrease \(\Delta i\left(s,t\right)=i\left(t\right)-pL*i\left({t}_{L}\right)-pR*i({t}_{R})\); \(\Delta i\) is the importance of node \(t\) based on Gini importance; \(pL={n}_{{t}_{L}}\), and \(pR={n}_{{t}_{R}}\). For each node split, the Gini impurity index values for the two child nodes are less than the value for the parent node. For each variable, the summation of Gini impurity decreases in a dataset over all trees in the RF model and is the corresponding Gini importance measure for that variable. The global importance of a feature, \({\theta }_{m}\), for predicting \(y\) is calculated by adding up the weighted impurity decreases, \(p\left(t\right)\Delta i\left({s}_{t},t\right)\), for all nodes \(t\) where \({\theta }_{m}\) is used, averaged over all \(T\) trees in the forest (see Eq. 3).$$imp\left( {\theta_{m} } \right) = \frac{1}{T}\mathop \sum \limits_{T} \mathop \sum \limits_{{t \in T:v\left( {s_{t} } \right) = \theta_{m} }} p\left( t \right)\Delta i\left( {s_{t} ,t} \right)$$
                    (3)
                Interested readers are referred to56 for further details about the RF algorithm. More details on the Gini variable importance approach in RF can be found in87.Explainability capabilitiesAs RF is an ensemble classifier, it is difficult to get understandable explanation from this complex model. Therefore, we use a collection of simpler models, see Fig. 8, to endow RF with explainability. Each of these models is called “an explainer.” These models provide complementary views and explanations associated to the original RF model. Because AD is a complex disease and RF is a complex model, in order to have a global comprehensive, consistent, and accurate picture about AD progression, several explanatory techniques are required88. Our explainer framework includes SHAP explainer, DT explainer, and fuzzy explainer. Each of these explainers has been carefully designed to exhibit a good balance between accuracy and explainability. All explainers have been tested to verify they provide physicians with consistent and reliable explanations. As a result, medical expert will be more confident regarding the RF decisions.Figure 8Roles of explainers to enhance RF interpretability.Full size imageFor each layer in the proposed model, we provide two types of explanation. The first type gets explanations from the RF black-box model itself. For an RF model \(b\) and a dataset \(D=\left\{\theta ,Y\right\}\), function \(f:\left(\theta \to Y\right)\times \left({\theta }^{n}\times {Y}^{n}\right)\to V\) takes \(b\) and \(D\) as input and returns either global or local approximations \(V\) of the behavior of \(b\),\(f(b,D)=v\in V\), where \(V\) is the set of all possible explanations from RF. List \(V\) includes explanations regarding both global and local issues. We use Eli5 to calculate global feature importance based on the Gini index89,90, i.e. we compute the level of importance for all features based on the entire set of training data and the RF structure. Because model \(b\) is complex, global explanations can sometimes be too approximate to be trustworthy. In addition, medical experts prefer individualized explanations for each specific patient according to his/her own features. Then, we need to take care of local feature contributions too. These explanations, with the contribution directions, are provided for every single patient according to his/her feature vector. We use SHAP tree explainer, which is called the additive feature attribution method42,91. SHAP is based on the Shapely value concept from game theory91,92. Shapely values are used to estimate the magnitude as sign of feature contributions or importance. It is a theoretically justified and model-agnostic approach that builds a local explanation model,\(g\) for the original model \(f\). This model is a linear combination of binary variables \(g\left({x}^{^{\prime}}\right)={\varnothing }_{0}+\sum_{j=1}^{M}{\varnothing }_{j}{x}_{j}^{^{\prime}}\), where \({x}_{j}^{^{\prime}}\) is a simplified input that map to the original input \(x\) using the mapping function \({x=h}_{x}\left({x}^{^{\prime}}\right)\), \({x}^{^{\prime}}\in {\left\{0, 1\right\}}^{M}\) is the coalition vector and the 1 means the features in the new data are the same as those of the original data (the instance \(x\)), and 0 means the features in the new data are different from those of the original data, \(M\) is the total number of features, and \({\varnothing }_{j}\in {\mathbb{R}}\) is the Shapely value that measures the average feature attribution value for feature \(j\) for instance \(x\). SHAP try to ensure that \(g\left({z}^{^{\prime}}\right)\approx f({h}_{x}\left({z}^{^{\prime}}\right))\) when \({z}^{^{\prime}}\approx {x}^{^{\prime}}\). SHAP calculates \({\varnothing }_{j}\) based on the Shapley value from game theory (see Eq. 4)93:$$\emptyset_{j} = \mathop \sum \limits_{{S \in \left\{ {x_{1} , \ldots ,x_{M} } \right\}\backslash \left\{ {x_{j} } \right\}}} \frac{{\left| S \right|!\left( {M - \left| S \right| - 1} \right)!}}{M!}\left( {f\left( {S \cup \left\{ {x_{j} } \right\}} \right) - f\left( S \right)} \right)$$
                    (4)
                
where \(S\) is the subset of set of the features used in the model which have non-zero indexes in \({x}^{^{\prime}}\), \({x}^{^{\prime}}\) is the vector of feature values for the instance to be explained, \((\left|S\right|!\left(M-\left|S\right|-1\right)!)/M!\) is a weighting factor, and \(f\left(S\right)=E[f(x)|{x}_{S}]\) is the expected value of \(f\) for features in subset \(S\) that are marginalized over features not included in subset \(S\). SHAP values are consistent and accurate because they are calculated by averaging the differences in predictions over every possible feature ordering. In addition, the mean magnitude of the SHAP values can be used to estimate the global feature importance. We will compare the Gini index and SHAP-based methods using our datasets and trained RF classifiers.Because an individual decision explanation is critical in the medical domain, and because confidence is very important in order to create a trustworthy model, we add another type of explainability. The second type collects explanations from auxiliary or post-hoc models that try to explain RF decisions. The explainer is a function \(f:\left({\theta }^{m}\to Y\right)\times \left({\theta }^{n\times m}\times {Y}^{n}\right)\to \left({\theta }^{m}\to Y\right)\), which takes \(b\), \(D\) as input and returns local predictor \({p}_{i}\), i.e.\({p}_{i}=f(b,D)\), where \({p}_{i}\) is able to mimic the behavior of \(b\); a local explanatory function \({\varepsilon }_{i}:\left(\left({\theta }^{m}\to Y\right)\times \left({\theta }^{m}\times Y\right)\times {\theta }^{m}\right)\to \varepsilon\) exists, for \(b\),\({p}_{i}\), and \({\theta }^{m}\) instances are inputs; and \({\varepsilon }_{i}\) returns a human interpretable explanation for the patient record \({\theta }^{m}\), i.e.\({ \varepsilon }_{i}=f\left(b, {p}_{i},{\theta }^{m}\right)=e\). We implement interpretable classifiers (i.e. DT and FURIA) for each individual modality. These explainers create simple and easy-to-understand explanations from different dimensions (e.g. MRI, cognitive scores, symptoms, etc.), which help to inform domain experts about the oracle’s decision. By using these 22 explainers, we are confident that each oracle’s decision will have a sufficient number of related explanations. The most important thing regarding these 22 explainers is that they are not affected by the feature selection process, which means more features will participate in the explanation. In addition, the extracted formal knowledge from RF and post-hoc models is represented in natural language form by using ExpliClas78. Accordingly, we resolve the accuracy-explainability trade-off by providing a variety of explanations, while retaining the accuracy of a complex ensemble model (i.e. RF).Model performance evaluation metricsTo evaluate the proposed method, we used the following performance metrics: The area under the receiver operating characteristic curve (AUC), precision, recall, accuracy (AC), and F1-score (F1). In addition to the performance evaluation, the system maximizes the interpretability of the underlying models, and pays special attention to explainability, which can serve as an indispensable tool in the era of precision medicine. To validate the performance of the models, we report both cross-validation as well as test results. In each layer, we compared the performance of the best RF model with other ML models, including SVM, KNN, and decision tree models. The hyperparameters of these algorithms were tuned in the same way as RF.We used several libraries in the Python data science ecosystem to execute the experiments. The scikit-learn 0.21.2 package was used to perform feature selection and to train and evaluate all classifiers. Eli5 0.8.2 and SHAP 0.26.0 were used for explainability, and ExpliClas was used to provide natural language explanations from the 22 explainers. The naturalness and acceptability of generated explanations was validated by the physicians who collaborated in our study.Concluding remarksIn this paper, we proposed a highly accurate and explainable ML model based on a RF classifier. We have shown that multimodal RF classifiers can be successfully applied to AD detection and progression prediction. We proved that predictions based on combined multimodalities are significantly better than any single modality for both binary and multi-class classification tasks. Based on precise selection of the most informative features from 11 multimodalities, the system achieved the highest accuracies. Explainability was achieved using a variety of techniques. First, we provided a set of explanation capabilities for the RF models based on SHAP. For each layer’s model, global feature importance for the whole RF model and feature contributions for each specific patient were provided. For the first layer, we found that MMSE was the most important feature for the AD class, and CDRSB was the most important predictor for CN and MCI classes. For the second layer, FAQ was the most important feature for both sMCI and pMCI classes. Second, we implemented 22 explainers for each layer based on a decision tree classifier and a fuzzy rule-based system. Each explainer is based on a single modality. As a result, in each layer, each output decision comes up along with several complementary, consistent and reliable explanations. To validate the effectiveness of our model, we conducted experiments using the ADNI dataset. The model achieved high performance in each layer. The first layer had cross-validation accuracy of 93.95% and an F1-score of 93.94%, and second layer had cross-validation accuracy of 87.08% and an F1-Score of 87.09%. Moreover, our model exhibits a good accuracy-interpretability tradeoff because it achieved very accurate results as well as high level of interpretability. The resulting two-layer model provided justifiable, medically accurate, and hence, actionable decisions that can enhance physician confidence.The proposed ML model is accurate and explainable. However, it is worth noting that even if we achieved promising results from an academic point of view, we are still far from applying the model in a real-world clinical scenario; what we plan to do in the future. This is a long-term ongoing project. Currently, we are reporting results of the first stage. We have already validated our model with the ADNI dataset; what is a crucial contribution to pave the way towards the application of the model to real clinical data in primary care or general medical practice. Although it is the biggest and most popular real dataset for Alzheimer’s disease, the relevance of our work to direct primary care is limited by the ADNI cohort. Therefore, to translate the outcomes of this study into full-scale clinical practice, further investigations are required to determine its performance characteristics by applying the model to other relevant datasets. We plan to enhance our model with the aim of achieving even higher performance by means of deep learning applied to longitudinal data while preserving explainability issues as we already did in the present manuscript.Ethics statementData used in this study were obtained from the ADNI (http://adni.loni.usc.edu/). The Alzheimer’s Disease Neuroimaging Initiative Data and Publications Committee (ADNI DPC) coordinates patient enrollment and ensures standard practice on the uses and distribution of the data as follows: The ADNI data were previously collected across 50 research sites. To participate in the study, each study subject gave written informed consent at the time of enrollment for imaging and genetic sample collection and completed questionnaires approved by each participating sites’ Institutional Review Board (IRB). All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards. A complete description of ADNI and up-to-date information is available at http://adni.loni.usc.edu/ and data access requests are to be sent to http://adni.loni.usc.edu/data-samples/access-data/. Detailed inclusion criteria for the diagnostic categories can be found at the ADNI website (http://adni.loni.usc.edu/methods). The ethics committees/institutional review board that approved the ADNI study are listed within Supplementary file (part 4).


Data availability
The data that support the findings of this study are openly available at the ADNI web site (http://adni.loni.usc.edu/). In addition, the specific patient RIDs used in our study and the full description of used features can be found in the Supplementary Files.
AbbreviationsAD:
Alzheimer’s disease
ADAS-Cog:
Features of the Alzheimer’s diseases assessment scale-cognitive
ADNI:
Alzheimer’s Disease Neuroimaging Initiative
APOE:
Apolipoprotein E
AUC:
Area under the ROC curve
AV45:
Average AV45 SUVR of frontal
CDSS:
Clinical decision support system
CNN:
Convolutional neural network
CFA:
Cognitive and functional assessments
CS:
Cognitive scores
CDRSB:
Clinical dementia rating sum of boxes
CDGLOBAL:
Global CDR
DL:
Deep learning
DT:
Decision tree
DARPA:
Defense Advanced Research Projects Agency
FRBS:
Fuzzy rule-based system
FAQ:
Functional assessment questionnaire
GB:
Gradient boosting
GDT:
Geriatric depression scale
GDPR:
General data protection regulation
HCI:
Hypometabolic convergence index
ICV:
Intracranial volume
KNN:
K nearest neighbor
MRI:
Magnetic resonance imaging
ML:
Machine learning
MCI:
Mild cognitive impairment
MCA:
Multiclass classification accuracy
MMSE:
Mini-Mental State Examination
MoCA:
Montreal cognitive assessment
MH:
Medical history
NPISCORE:
Neuropsychiatric inventory questionnaire score
NB:
Neuropsychological battery
NB:
Naïve Bayes
pMCI:
Progressive MCI
PTAU:
Phosphorylated TAU
PET:
Positron emission tomography
PCA:
Principal component analysis
RF:
Random forest
RFE:
Recursive feature elimination
RAVLT:
Rey Auditory Verbal Learning Test
SHAP:
SHapley Additive exPlanations
sMCI:
Stable MCI
SVM:
Support vector machine
SNOMED CT:
Systematized Nomenclature of Medicine-Clinical Terms
XAI:
Explainable artificial intelligence
ReferencesAlberdi, A., Aztiria, A. & Basarab, A. On the early diagnosis of Alzheimer’s disease from multimodal signals: a survey. Artif. Intell. Med. 71, 1–29 (2016).Article 
    PubMed 
    
                    Google Scholar 
                Masters, C. L. & Beyreuther, K. Alzheimer’s centennial legacy: prospects for rational therapeutic intervention targeting the Aβ amyloid pathway. Brain 129, 2823–2839 (2006).Article 
    PubMed 
    
                    Google Scholar 
                Zamrini, E., De Santi, S. & Tolar, M. Imaging is superior to cognitive testing for early diagnosis of Alzheimer’s disease. Neurobiol. Aging 25, 685–691 (2004).Article 
    PubMed 
    
                    Google Scholar 
                Liu, M., Zhang, J., Adeli, E. & Shen, D. Joint classification and regression via deep multi-task multi-channel learning for Alzheimer’s disease diagnosis. IEEE Trans. Biomed. Eng. 1 (2018).Lee, G. et al. Predicting Alzheimer’s disease progression using multi-modal deep learning approach. Sci. Rep. 9, 1–12 (2019).ADS 
    CAS 
    
                    Google Scholar 
                Nie, L. et al. Modeling disease progression via multisource multitask learners: a case study with Alzheimer’s disease. IEEE Trans. Neural Netw. Learn. Syst. 28, 1508–1519 (2017).Article 
    MathSciNet 
    PubMed 
    
                    Google Scholar 
                Wee, C. Y., Yap, P. T. & Shen, D. Prediction of Alzheimer’s disease and mild cognitive impairment using cortical morphological patterns. Hum. Brain Mapp. 34, 3411–3425 (2013).Article 
    PubMed 
    
                    Google Scholar 
                Liao, Q. et al. Multi-task deep convolutional neural network for cancer diagnosis. Neurocomputing https://doi.org/10.1016/j.neucom.2018.06.084 (2018).Article 
    
                    Google Scholar 
                Lu, D., Popuri, K., Ding, W., Balachandar, R. & Beg, M. F. Multimodal and multiscale deep neural networks for the early diagnosis of Alzheimer’s disease using structural MR and FDG-PET images. Sci. Rep. 8, 5697 (2018).Article 
    ADS 
    PubMed 
    PubMed Central 
    CAS 
    
                    Google Scholar 
                Liu, M., Cheng, D., Wang, K. & Wang, Y. Multi-modality cascaded convolutional neural networks for Alzheimer’s disease diagnosis. Neuroinformatics 16, 295–308 (2018).Article 
    PubMed 
    
                    Google Scholar 
                Qiu, S. et al. Fusion of deep learning models of MRI scans, mini-mental state examination, and logical memory test enhances diagnosis of mild cognitive impairment. Alzheimer’s Dement. Diagnosis Assess. Dis. Monit. 10, 737–749 (2018).
                    Google Scholar 
                Kim-Han, T., Pew-Thian, Y. & Dinggang, S. Multi-stage diagnosis of Alzheimer’s Disease with incomplete multimodal data via multi-task deep learning. In Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support 160–168 (Springer, Cham, 2017).Hinrichs, C., Singh, V., Xu, G. & Johnson, S. C. Predictive markers for AD in a multi-modality framework: an analysis of MCI progression in the ADNI population. Neuroimage 55, 574–589 (2011).Article 
    PubMed 
    
                    Google Scholar 
                Zhou, J., Liu, J., Narayan, V. A. & Ye, J. Modeling disease progression via multi-task learning. Neuroimage 78, 233–248 (2013).Article 
    PubMed 
    
                    Google Scholar 
                Wang, T., Qiu, R. G. & Yu, M. Predictive modeling of the progression of Alzheimer’ s disease with recurrent neural networks. Sci. Rep. https://doi.org/10.1038/s41598-018-27337-w (2018).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Ding, X. et al. A hybrid computational approach for efficient Alzheimer’s disease classification based on heterogeneous data. Sci. Rep. 8, 1–10 (2018).Article 
    CAS 
    
                    Google Scholar 
                Gray, K. R., Aljabar, P., Heckemann, R. A. & Hammers, A. Random forest-based similarity measures for multi-modal classification of Alzheimer’ s disease. Neuroimage 65, 167–175 (2013).Article 
    PubMed 
    
                    Google Scholar 
                Das, D., Ito, J., Kadowaki, T. & Tsuda, K. An interpretable machine learning model for diagnosis of Alzheimer’s disease. PeerJ 7, e6543 (2019).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Mattila, J. et al. A disease state fingerprint for evaluation of Alzheimer’s disease. J. Alzheimer’s Dis. 27, 163–176 (2011).Article 
    
                    Google Scholar 
                Bucholc, M. et al. A practical computerized decision support system for predicting the severity of Alzheimer’s disease of an individual. Expert Syst. Appl. 130, 157–171 (2019).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Travers, C. et al. Opportunities and obstacles for deep learning in biology and medicine. bioRxiv https://doi.org/10.1101/142760 (2017).Article 
    
                    Google Scholar 
                Choi, H. & Jin, K. H. Predicting cognitive decline with deep learning of brain metabolism and amyloid imaging. Behav. Brain Res. 344, 103–109 (2018).Article 
    CAS 
    PubMed 
    
                    Google Scholar 
                Spasov, S., Passamonti, L., Duggento, A., Lio, P. & Toschi, N. A parameter-efficient deep learning approach to predict conversion from mild cognitive impairment to Alzheimer’s disease. Neuroimage 189, 276–287 (2019).Article 
    PubMed 
    
                    Google Scholar 
                Zhang, D. & Shen, D. Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer’s disease. Neuroimage 59, 895–907 (2012).Article 
    PubMed 
    
                    Google Scholar 
                Cheng, B., Liu, M., Zhang, D., Munsell, B. C. & Shen, D. Domain transfer learning for MCI conversion prediction. IEEE Trans. Biomed. Eng. 62, 1805–1817 (2015).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Moore, P. J., Lyons, T. J. & Gallacher, J. Random forest prediction of Alzheimer’s disease using pairwise selection from time series data. PLoS ONE 14, 1–14 (2019).Article 
    
                    Google Scholar 
                Moradi, E., Pepe, A., Gaser, C., Huttunen, H. & Tohka, J. Machine learning framework for early MRI-based Alzheimer’s conversion prediction in MCI subjects. Neuroimage 104, 398–412 (2015).Article 
    PubMed 
    
                    Google Scholar 
                Fisher, C. K., Smith, A. M. & Walsh, J. R. Machine learning for comprehensive forecasting of Alzheimer’s disease progression. Sci. Rep. 9, 1–14 (2019).Article 
    CAS 
    
                    Google Scholar 
                Oxtoby, N. P. & Alexander, D. C. Imaging plus X: Multimodal models of neurodegenerative disease. Curr. Opin. Neurol. 30, 371–379 (2017).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Burrell, J. How the machine ‘Thinks:’ understanding opacity in machine learning algorithms. Ssrn https://doi.org/10.2139/ssrn.2660674 (2015).Article 
    
                    Google Scholar 
                Adadi, A. & Berrada, M. Peeking Inside the black-box: a survey on explainable artificial intelligence (XAI). IEEE Access 6, 52138–52160 (2018).Article 
    
                    Google Scholar 
                Lundberg, S. M. et al. Explainable machine-learning predictions for the prevention of hypoxaemia during surgery. Nat. Biomed. Eng. 2, 749–760 (2018).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Guidotti, R. et al. A survey of methods for explaining black box models. ACM Comput. Surv. 51, 93:1-93:42 (2018).
                    Google Scholar 
                Quinlan, J. R. C4.5: Programs for Machine Learning (Morgan Kaufmann Publishers, San Mateo, 1993).
                    Google Scholar 
                El-Sappagh, S. et al. An ontology-based interpretable fuzzy decision support system for diabetes diagnosis. IEEE Access 6, 37371–37394 (2018).Article 
    
                    Google Scholar 
                Trillas, E. & Eciolaza, L. Fuzzy Logic: An Introductory Course for Engineering Students (Springer, New York, 2015).Book 
    
                    Google Scholar 
                Huysmans, J., Dejaeger, K., Mues, C., Vanthienen, J. & Baesens, B. An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models. Decis. Support Syst. 51, 141–154 (2011).Article 
    
                    Google Scholar 
                Alonso, J. M., Castiello, C., Lucarelli, M. & Mencar, C. Modeling interpretable fuzzy rule-based classifiers for medical decision support. In Medical Applications of Intelligent Data Analysis: Research Advancements. 1064–1081 (Hershey, PA, USA: IGI Global, 2013).Alonso, J. M., Castiello, C. & Mencar, C. Interpretability of fuzzy systems: current research trends and prospects. In Springer Handbook of Computational Intelligence 219–237 (Springer, Berlin, 2015).Fernandez-Delgado, M., Cernadas, E., Barro, S. & Amorim, D. Do we need hundreds of classifiers to solve real world classification problems. J. Mach. Learn. Res. 15, 3133–3181 (2014).MathSciNet 
    MATH 
    
                    Google Scholar 
                Alonso, J. M., Ramos-Soto, A., Castiello, C. & Mencar, C. Hybrid data-expert explainable beer style classifier. In IJCAI/ECAI Workshop on Explainable Artificial Intelligence 1–5 (2018).Ribeiro, M. T., Singh, S. & Guestrin, C. ‘Why Should I Trust You?’: Explaining the Predictions of Any Classifier (2016).Zhou, Z.-H., Jiang, Y. & Chen, S.-F. Extracting symbolic rules from trained neural network ensembles. AI Commun. 16, 3–15 (2003).MATH 
    
                    Google Scholar 
                Breiman, L. Statistical modeling: the two cultures. Stat. Sci. 16, 199–231 (2001).Article 
    MathSciNet 
    MATH 
    
                    Google Scholar 
                Zhao, X., Wu, Y., Lee, D. L. & Cui, W. IForest: interpreting random forests via visual analytics. IEEE Trans. Vis. Comput. Graph. 25, 407–416 (2019).Article 
    
                    Google Scholar 
                Matthews, K. Tau protein abnormalities correlate with the severity of dementia in Alzheimer’s disease. Nat. Clin. Pract. Neurol. 2, 178 (2006).Article 
    
                    Google Scholar 
                Murphy, M. P. & Levine, H. Alzheimer’s disease and the amyloid-β peptide. J. Alzheimer’s Dis. 19, 311–323 (2010).Article 
    CAS 
    
                    Google Scholar 
                Sadigh-Eteghad, S. et al. Amyloid-beta: a crucial factor in Alzheimer’s disease. Med. Princ. Pract. 24, 1–10 (2015).Article 
    PubMed 
    
                    Google Scholar 
                Verdile, G. et al. The role of beta amyloid in Alzheimer’ s disease: still a cause of everything or the only one who got caught?. Pharmacol. Res. 50, 397–409 (2004).Article 
    CAS 
    PubMed 
    
                    Google Scholar 
                Thaweepoksomboon, J. et al. Assessment of cerebrospinal fluid (CSF) beta-amyloid (1–42), phosphorylated tau (ptau-181) and total Tau protein in patients with Alzheimer’s disease (AD) and other dementia at Siriraj Hospital Thailand. J. Med. Assoc. Thai. 94(Suppl 1), S77-83 (2011).PubMed 
    
                    Google Scholar 
                Zetterberg, H. Biomarkers for Alzheimer’ s disease: current status and prospects for the future. J. Intern. Med. 6, 643–663 (2018).
                    Google Scholar 
                Weiner, M. W. et al. Recent publications from the Alzheimer’s disease neuroimaging initiative: reviewing progress toward improved AD clinical trials. Alzheimer’s Dement. 13, e1–e85 (2017).ADS 
    
                    Google Scholar 
                Tong, T. et al. A novel grading biomarker for the prediction of conversion from mild cognitive impairment to Alzheimer’s disease. IEEE Trans. Biomed. Eng. 64, 155–165 (2017).Article 
    PubMed 
    
                    Google Scholar 
                Li, K., O’Brien, R., Lutz, M. & Luo, S. A prognostic model of Alzheimer’s disease relying on multiple longitudinal measures and time-to-event data. Alzheimer’s Dement. 14, 644–651 (2018).Article 
    
                    Google Scholar 
                Jin, Y., Su, Y., Zhou, X. H. & Huang, S. Heterogeneous multimodal biomarkers analysis for Alzheimer’s disease via Bayesian network. Eurasip J. Bioinform. Syst. Biol. 2016, 4–11 (2016).Article 
    CAS 
    
                    Google Scholar 
                Breiman, L. E. O. Random forests. Mach. Learn. 45, 5–32 (2001).Article 
    MATH 
    
                    Google Scholar 
                Lebedev, A. V. et al. Random forest ensembles for detection and prediction of Alzheimer’s disease with a good between-cohort robustness. NeuroImage Clin. 6, 115–125 (2014).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Ramírez, J. et al. Ensemble of random forests one vs. rest classifiers for MCI and AD prediction using ANOVA cortical and subcortical feature selection and partial least squares. J. Neurosci. Methods 302, 47–57 (2018).Article 
    PubMed 
    
                    Google Scholar 
                Cheng, M., Nazarian, S. & Bogdan, P. There is hope after all: quantifying opinion and trustworthiness in neural networks. Front. Artif. Intell. 3 (2020).Dodd, E., Cheston, R. & Ivanecka, A. The assessment of dementia in primary care. J. Psychiatr. Ment. Health Nurs. 22, 731–737 (2015).Article 
    CAS 
    PubMed 
    
                    Google Scholar 
                Onoda, K. & Yamaguchi, S. Revision of the cognitive assessment for dementia, iPad version (CADi2). PLoS One 9 (2014).El-Sappagh, S., Abuhmed, T., Riazul Islam, S. M. & Kwak, K. S. Multimodal multitask deep learning model for Alzheimer’s disease progression detection based on time series data. Neurocomputing 412, 197–215 (2020).Article 
    
                    Google Scholar 
                El-Sappagh, S. et al. Alzheimer’s disease progression detection model based on an early fusion of cost-effective multimodal data. Futur. Gener. Comput. Syst. 115 (2021).Chen, G. et al. Classification of Alzheimer disease, mild cognitive impairment, and normal cognitive status with large-scale network analysis based on resting-state functional MR imaging. Radiology 259, 213–221 (2011).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Wang, P. et al. Aberrant intra-and inter-network connectivity architectures in Alzheimer’s disease and mild cognitive impairment. Sci. Rep. 5, 1–12 (2015).
                    Google Scholar 
                Yang, R. & Bogdan, P. Controlling the multifractal generating measures of complex networks. Sci. Rep. 10, 1–13 (2020).CAS 
    
                    Google Scholar 
                Zhang, Y., Zhang, H., Chen, X., Lee, S. W. & Shen, D. Hybrid high-order functional connectivity networks using resting-state functional MRI for mild cognitive impairment diagnosis. Sci. Rep. 7, 1–15 (2017).ADS 
    CAS 
    
                    Google Scholar 
                McKhann, G. et al. Clinical diagnosis of Alzheimer’s disease: report of the NINCDS-ADRDA Work Group under the auspices of Department of Health and Human Services Task Force on Alzheimer’s Disease. Neurology 34, 939–939 (2012).Article 
    
                    Google Scholar 
                Jagust, W. J. et al. The Alzheimer’s disease neuroimaging initiative 2 PET core: 2015. Alzheimer’s Dement. 11, 757–771 (2015).Article 
    
                    Google Scholar 
                Desikan, R. S. et al. An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest. Neuroimage 31, 968–980 (2006).Article 
    PubMed 
    
                    Google Scholar 
                Chawla, N. V., Bowyer, K. W., Hall, L. O. & Kegelmeyer, W. P. SMOTE: Synthetic minority over-sampling technique. J. Artif. Intell. Res. 16, 321–357 (2002).Article 
    MATH 
    
                    Google Scholar 
                Elisseeff, A. & Pontil, M. Leave-one-out error and stability of learning algorithms with applications. In NATO science series sub series iii computer and systems sciences 111–130 (ISO Press, 2003).Krstajic, D., Buturovic, L. J., Leahy, D. E. & Thomas, S. Cross-validation pitfalls when selecting and assessing regression and classification models. J. Cheminform. 6, 1–15 (2014).Article 
    
                    Google Scholar 
                Raschka, S. Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning. (2018).Kohavi, R. A study of cross-validation and bootstrap for accuracy estimation and model selection. Ijcai 14, 1137–1145 (1995).
                    Google Scholar 
                Alonso, J. M., Castiello, C. & Mencar, C. A bibliometric analysis of the explainable artificial intelligence research field. In Information Processing and Management of Uncertainty in Knowledge-Based Systems-Theory and Foundations, CCIS853, 1–13 (Springer, 2018).Cohen, W. Fast effective rule induction. In International Conference on Machine Learning (ICML) 115–123 (1995).Alonso, J. M. & Bugar, A. ExpliClas: automatic generation of explanations in natural language for weka classifiers. In IEEE International Conference on Fuzzy Systems 1–6 (2019).Landau, S. M. et al. Associations between cognitive, functional, and FDG-PET measures of decline in AD and MCI. Neurobiol. Aging 32, 1207–1218 (2011).Article 
    PubMed 
    
                    Google Scholar 
                Chen, K. et al. Characterizing Alzheimer’s disease using a hypometabolic convergence index. Neuroimage 56, 52–60 (2011).Article 
    CAS 
    PubMed 
    
                    Google Scholar 
                Cortizo, J. C. & Giraldez, I. Multi criteria wrapper improvements to Naive Bayes learning. In International Conference on Intelligent Data Engineering and Automated Learning 419–427 (Springer, Berlin, Heidelberg, 2006). https://doi.org/10.1007/11875581_51.Maldonado, S., Weber, R. & Famili, F. Feature selection for high-dimensional class-imbalanced data sets using support vector machines. Inf. Sci. (Ny) 286, 228–246 (2014).Article 
    
                    Google Scholar 
                Rodin, A. S. et al. Use of wrapper algorithms coupled with a random forests classifier for variable selection in large-scale genomic association studies. J. Comput. Biol. 16, 1705–1718 (2010).Article 
    CAS 
    
                    Google Scholar 
                Panthong, R. & Srivihok, A. Wrapper feature subset selection for dimension reduction based on ensemble learning algorithm. Procedia Comput. Sci. 72, 162–169 (2015).Article 
    
                    Google Scholar 
                Li, Z., Xie, W. & Liu, T. Efficient feature selection and classification for microarray data. PLoS ONE 13, 1–21 (2018).
                    Google Scholar 
                Granitto, P. M., Furlanello, C., Biasioli, F. & Gasperi, F. Recursive feature elimination with random forest for PTR-MS analysis of agroindustrial products. Chemom. Intell. Lab. Syst. 83, 83–90 (2006).Article 
    CAS 
    
                    Google Scholar 
                Menze, B. H. et al. A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data. BMC Bioinformatics 10, 1–16 (2009).Article 
    CAS 
    
                    Google Scholar 
                Hall, P. On the Art and Science of Machine Learning Explanations. arXiv Prepr. arXiv 1810.02909 (2018).Ando Saabas. Interpreting Random Forests, treeinterpreter. (2019).Korobov, M. & Lopuhin, K. ELI5 Documentation. (2019).Lundberg, S. & Lee, S.-I. A Unified approach to interpreting model predictions. In Advances in Neural Information Processing Systems 4765–4774 (2017).Molnar, C. Interpretable Machine Learning A Guide for Making Black Box Models Explainable. (2020).Štrumbelj, E. & Kononenko, I. Explaining prediction models and individual predictions with feature contributions. Knowl. Inf. Syst. 41, 647–665 (2014).Article 
    
                    Google Scholar 
                Download referencesAcknowledgementsThe authors would like to thank Farid Badria, a professor of pharmacognosy and head of the Liver Research Lab, Mansoura University, Egypt, and Hosam Zaghloul, a professor in the Clinical Pathology Department, Faculty of Medicine, Mansoura University, Egypt, for their efforts to assist this work. for their assistance as medical experts to finish the experimental part of this study. This work was supported by National Research Foundation of Korea-Grant funded by the Korean Government (Ministry of Science and ICT)-NRF-2020R1A2B5B02002478). In addition, Dr. Jose M. Alonso is Ramon y Cajal Researcher (RYC-2016-19802), and its research is supported by the Spanish Ministry of Science, Innovation and Universities (grants RTI2018-099646-B-I00, TIN2017-84796-C2-1-R, TIN2017-90773-REDT, and RED2018-102641-T) and the Galician Ministry of Education, University and Professional Training (grants ED431F 2018/02, ED431C 2018/29, ED431G/08, and ED431G2019/04), with all grants co-funded by the European Regional Development Fund (ERDF/FEDER program). Data collection and sharing for this project was funded by the Alzheimer’s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). The ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie; Alzheimer’s Association; Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research & Development, LLC.; Johnson & Johnson Pharmaceutical Research & Development LLC.; Lumosity; Lundbeck; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer’s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.Author informationAuthors and AffiliationsCentro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, 15782, Santiago de Compostela, SpainShaker El-SappaghInformation Systems Department, Faculty of Computers and Artificial Intelligence, Benha University, Banha, 13518, EgyptShaker El-SappaghCentro Singular de Investigación en Tecnoloxías Intelixentes, Universidade de Santiago de Compostela, 15703, Santiago, SpainJose M. AlonsoDepartment of Computer Science and Engineering, Sejong University, 209 Neungdong-ro, Gwangjin-gu, Seoul, 05006, KoreaS. M. Riazul IslamGastrointestinal Surgical Center, Faculty of Medicine, Mansoura University, Mansura, 35516, EgyptAhmad M. SultanDepartment of Information and Communication Engineering, Inha University, Incheon, 22212, South KoreaKyung Sup KwakAuthorsShaker El-SappaghView author publicationsYou can also search for this author in
                        PubMed Google ScholarJose M. AlonsoView author publicationsYou can also search for this author in
                        PubMed Google ScholarS. M. Riazul IslamView author publicationsYou can also search for this author in
                        PubMed Google ScholarAhmad M. SultanView author publicationsYou can also search for this author in
                        PubMed Google ScholarKyung Sup KwakView author publicationsYou can also search for this author in
                        PubMed Google ScholarContributionsMethodology, S.E.S., and S.M.R.I.; conceptualization, J.M.A. and K.S.K.; formal analysis, S.E.S., A.M.S., J.M.A, S.M.R.I., and K.S.K.; validation, S.E.S., A.M.S., and S.M.R.I.; visualization, J.M.A., and A.M.S.; investigation, S.E.S., and J.M.A.; data curation, K.S.K.; writing—original draft preparation, S.E.S. and J.M.A; writing—review and editing, K.S.K.; supervision, K.S.K. and S.E.S.Corresponding authorsCorrespondence to
                Shaker El-Sappagh or Kyung Sup Kwak.Ethics declarations
Competing interests
The authors declare no competing interests.
Additional informationPublisher's noteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Supplementary InformationSupplementary Information.Rights and permissions
Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Reprints and permissionsAbout this articleCite this articleEl-Sappagh, S., Alonso, J.M., Islam, S.M.R. et al. A multilayer multimodal detection and prediction model based on explainable artificial intelligence for Alzheimer’s disease.
                    Sci Rep 11, 2660 (2021). https://doi.org/10.1038/s41598-021-82098-3Download citationReceived: 21 October 2019Accepted: 29 December 2020Published: 29 January 2021DOI: https://doi.org/10.1038/s41598-021-82098-3Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        
Subjects

Classification and taxonomyComputational neuroscienceData miningData processingMachine learning





This article is cited by





                                        Interpreting artificial intelligence models: a systematic review on the application of LIME and SHAP in Alzheimer’s disease detection
                                    


Viswan VimbiNoushath ShaffiMufti Mahmud

Brain Informatics (2024)




                                        A multimodal deep learning approach for the prediction of cognitive decline and its effectiveness in clinical trials for Alzheimer’s disease
                                    


Caihua WangHisateru TachimoriYuichi Yamashita

Translational Psychiatry (2024)




                                        Multimodal classification of Alzheimer's disease and mild cognitive impairment using custom MKSCDDL kernel over CNN with transparent decision-making for explainable diagnosis
                                    


V. AdarshG. R. GangadharanPaolo Zanetti

Scientific Reports (2024)




                                        An explainable machine learning approach for Alzheimer’s disease classification
                                    


Abbas Saad AlatranyWasiq KhanDhiya Al-Jumeily

Scientific Reports (2024)




                                        Advanced ensemble machine-learning and explainable ai with hybridized clustering for solar irradiation prediction in Bangladesh
                                    


Muhammad Samee SevasNusrat SharminSaidur Rahaman Sagor

Theoretical and Applied Climatology (2024)





CommentsBy submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.





",,,,"{'headline': 'A multilayer multimodal detection and prediction model based on explainable artificial intelligence for Alzheimer’s disease', 'description': 'Alzheimer’s disease (AD) is the most common type of dementia. Its diagnosis and progression detection have been intensively studied. Nevertheless, research studies often have little effect on clinical practice mainly due to the following reasons: (1) Most studies depend mainly on a single modality, especially neuroimaging; (2) diagnosis and progression detection are usually studied separately as two independent problems; and (3) current studies concentrate mainly on optimizing the performance of complex machine learning models, while disregarding their explainability. As a result, physicians struggle to interpret these models, and feel it is hard to trust them. In this paper, we carefully develop an accurate and interpretable AD diagnosis and progression detection model. This model provides physicians with accurate decisions along with a set of explanations for every decision. Specifically, the model integrates 11 modalities of 1048 subjects from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) real-world dataset: 294 cognitively normal, 254 stable mild cognitive impairment (MCI), 232 progressive MCI, and 268 AD. It is actually a two-layer model with random forest (RF) as classifier algorithm. In the first layer, the model carries out a multi-class classification for the early diagnosis of AD patients. In the second layer, the model applies binary classification to detect possible MCI-to-AD progression within three years from a baseline diagnosis. The performance of the model is optimized with key markers selected from a large set of biological and clinical measures. Regarding explainability, we provide, for each layer, global and instance-based explanations of the RF classifier by using the SHapley Additive exPlanations (SHAP) feature attribution framework. In addition, we implement 22 explainers based on decision trees and fuzzy rule-based systems to provide complementary justifications for every RF decision in each layer. Furthermore, these explanations are represented in natural language form to help physicians understand the predictions. The designed model achieves a cross-validation accuracy of 93.95% and an F1-score of 93.94% in the first layer, while it achieves a cross-validation accuracy of 87.08% and an F1-Score of 87.09% in the second layer. The resulting system is not only accurate, but also trustworthy, accountable, and medically applicable, thanks to the provided explanations which are broadly consistent with each other and with the AD medical literature. The proposed system can help to enhance the clinical understanding of AD diagnosis and progression processes by providing detailed insights into the effect of different modalities on the disease risk.', 'datePublished': '2021-01-29T00:00:00Z', 'dateModified': '2021-01-29T00:00:00Z', 'pageStart': '1', 'pageEnd': '26', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'sameAs': 'https://doi.org/10.1038/s41598-021-82098-3', 'keywords': ['Classification and taxonomy', 'Computational neuroscience', 'Data mining', 'Data processing', 'Machine learning', 'Science', 'Humanities and Social Sciences', 'multidisciplinary'], 'image': ['https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41598-021-82098-3/MediaObjects/41598_2021_82098_Fig1_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41598-021-82098-3/MediaObjects/41598_2021_82098_Fig2_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41598-021-82098-3/MediaObjects/41598_2021_82098_Fig3_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41598-021-82098-3/MediaObjects/41598_2021_82098_Fig4_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41598-021-82098-3/MediaObjects/41598_2021_82098_Fig5_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41598-021-82098-3/MediaObjects/41598_2021_82098_Fig6_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41598-021-82098-3/MediaObjects/41598_2021_82098_Fig7_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41598-021-82098-3/MediaObjects/41598_2021_82098_Fig8_HTML.png'], 'isPartOf': {'name': 'Scientific Reports', 'issn': ['2045-2322'], 'volumeNumber': '11', '@type': ['Periodical', 'PublicationVolume']}, 'publisher': {'name': 'Nature Publishing Group UK', 'logo': {'url': 'https://www.springernature.com/app-sn/public/images/logo-springernature.png', '@type': 'ImageObject'}, '@type': 'Organization'}, 'author': [{'name': 'Shaker El-Sappagh', 'affiliation': [{'name': 'Universidade de Santiago de Compostela', 'address': {'name': 'Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain', '@type': 'PostalAddress'}, '@type': 'Organization'}, {'name': 'Benha University', 'address': {'name': 'Information Systems Department, Faculty of Computers and Artificial Intelligence, Benha University, Banha, Egypt', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'shaker.elsappagh@usc.es', '@type': 'Person'}, {'name': 'Jose M. Alonso', 'affiliation': [{'name': 'Universidade de Santiago de Compostela', 'address': {'name': 'Centro Singular de Investigación en Tecnoloxías Intelixentes, Universidade de Santiago de Compostela, Santiago, Spain', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'S. M. Riazul Islam', 'affiliation': [{'name': 'Sejong University', 'address': {'name': 'Department of Computer Science and Engineering, Sejong University, Seoul, Korea', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Ahmad M. Sultan', 'affiliation': [{'name': 'Mansoura University', 'address': {'name': 'Gastrointestinal Surgical Center, Faculty of Medicine, Mansoura University, Mansura, Egypt', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Kyung Sup Kwak', 'affiliation': [{'name': 'Inha University', 'address': {'name': 'Department of Information and Communication Engineering, Inha University, Incheon, South Korea', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'kskwak@inha.ac.kr', '@type': 'Person'}], 'isAccessibleForFree': True, '@type': 'ScholarlyArticle'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiuQFodHRwczovL25ld3Nyb29tLmFjY2VudHVyZS5jb20vbmV3cy8yMDIxL2Z1dHVyZS1yZWFkeS1vcmdhbml6YXRpb25zLWxldmVyYWdpbmctZGlnaXRhbC10by1vcGVyYXRlLWZhc3Rlci1hbmQtc21hcnRlci1jb3VsZC1oZWxwLXVubG9jay01LXRyaWxsaW9uLWluLWVjb25vbWljLWdyb3d0aC1zYXlzLWFjY2VudHVyZS1zdHVkedIBAA?oc=5,“Future-Ready” Organizations Leveraging Digital to Operate Faster and Smarter Could Help Unlock $5 Trillion in ... - Newsroom | Accenture,2021-01-27,Newsroom | Accenture,https://newsroom.accenture.com,"NEW YORK; Jan. 27, 2021 - The pandemic-driven acceleration of digital adoption and the resulting new agile ways of operating could unlock $5.4 trillion in profitable growth i","future-ready, fast track","NEW YORK; Jan. 27, 2021 - The pandemic-driven acceleration of digital adoption and the resulting new agile ways of operating could unlock $5.4 trillion in profitable growth i","NEW YORK; Jan. 27, 2021 - The pandemic-driven acceleration of digital adoption and the resulting new agile ways of operating could unlock $5.4 trillion in profitable growth i",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vYmVjb21pbmdodW1hbi5haS9hLWNyYXNoLWNvdXJzZS1vbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mNTQyM2EzNmUwOGXSAQA?oc=5,A crash course on Artificial Intelligence | by Veronica Sant | Becoming Human - Becoming Human: Artificial Intelligence Magazine,2021-01-29,Becoming Human: Artificial Intelligence Magazine,https://becominghuman.ai,Artificial intelligence refers to the development of computer-based solutions that can perform tasks that mimic human intelligence. AI collects different technologies that can be brought together…,,"Artificial intelligence is everywhere. We use them into our homes, cars and air traffic controllers.","Artificial intelligence is everywhere. We use them into our homes, cars and air traffic controllers.",http://schema.org,NewsArticle,https://becominghuman.ai/a-crash-course-on-artificial-intelligence-f5423a36e08e,['https://miro.medium.com/v2/resize:fit:1200/1*wB18Ws0IrMZKrmGSr207Rg.jpeg'],"{'@type': 'Person', 'name': 'Veronica Sant', 'url': 'https://versant.medium.com'}","{'@type': 'Organization', 'name': 'Becoming Human: Artificial Intelligence Magazine', 'url': 'becominghuman.ai', 'logo': {'@type': 'ImageObject', 'width': 146, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:292/1*1fYpRTTpKQNa0zuEPe3itg.png'}}",A crash course on Artificial Intelligence - Becoming Human: Artificial Intelligence Magazine,2021-01-29T18:25:09.027Z,2021-12-29T00:31:02.551Z,,A crash course on Artificial Intelligence - Becoming Human: Artificial Intelligence Magazine,,,,,"Top highlightA crash course on Artificial IntelligenceVeronica Sant·FollowPublished inBecoming Human: Artificial Intelligence Magazine·7 min read·Jan 29, 202160ListenShareArtificial intelligence refers to the development of computer-based solutions that can perform tasks that mimic human intelligence.AI collects different technologies that can be brought together, where a machine acts at human-like intelligence levels. This includes learning rules that require simple decisions and reasonings to arrive at certain conclusions, learn from past mistakes, and experience self-correction.There are many steps along the way where the computer can learn like a human. AI systems can be put into complexity buckets. At the moment, simple, weak and narrow systems are everywhere. We use them into our homes, cars and air traffic controllers.The idea is that an AI system is trained for specific tasks. These tasks could include virtual personal assistants such as Apple’s Siri, classifying images, and translation speech. For example, by merely asking Amazon’s Alexa, it can help you answer, set alarms and purchases, and so much more. So you may already be using artificial intelligence every day in your home.There is a race to build robust AI when presented with unfamiliar tasks. A strong AI system would be able to find a solution without human intervention. Its intelligence would not just be able to touch but also to surpass that of humans. Strong AI currently exists with limits but is expected to advance over the next few decades. There are a host of other benefits that AI Brings.Big Data JobsThe origins of Artificial Intelligence TechnologyArtificial Intelligence is not new. It was formally founded in 1956 by a group of scientists in the United States. Artificial Intelligence has gone through many cycles since then, going through significant scientific breakthroughs, followed by ‘AI winters’ — times of disappointment after AI failed to deliver its hype. In recent years, with the more widespread AI application, AI’s responsible use, including ethics and bias, has become a significant factor in its development.The technologies behind Artificial IntelligenceSense lets a machine perceive the world around it by gathering and processing images, sounds, speech and text, facial recognition, image categorisation, sound pattern recognition, and translating speech to text.Computer vision allows machines such as computers or mobile phones to see their surroundings. Computer vision has already made its way to our mobile phones via different e-commerce or camera apps.Trending AI Articles:1. Write Your First AI Project in 15 Minutes2. Generating neural speech synthesis voice acting using xVASynth3. Top 5 Artificial Intelligence (AI) Trends for 20214. Why You’re Using Spotify WrongAudio Processing has to do with detecting and translating audio signals, like Google Cloud vision. It classifies images into thousands of categories such as cats and detects objects and faces within images. The second is Amazon Echo, which acts as a personal DJ to control through your voice.Now a Fourth Industrial Revolution is building on digital technologies. It is thought to be a fusion of technologies that blur the lines between the physical, digital, and biological spheres. (Nkusi, 2020)AI enables a machine to understand the information it collects through pattern recognition, such as finding patterns in social media posts on fraudulent behaviours for insurance claims. This is very similar to how humans interpret information by understanding the patterns presented and their contexts.Some of the technologies that are behind it are Natural language processing or NLP. This technology allows computer programmes to understand spoken language. NLP currently works through a process called deep learning. In essence, language is broken down into shorter elemental pieces to teach the machine to understand their relationships and work together.Knowledge representation is about representing information about the world in a form. A computer system can solve complex tasks such as diagnosing a medical condition or having a natural language dialogue. Speech recognition, this is the translation of speech into text or format that machines can read. For instance, think about automated phone systems that recognise your voice, process your request and put you through the correct department when you call a company.Facebook also uses natural language processing to look for patterns and user posts to understand how people feel about a particular brand or product. Chatbots like IPSoft Amelia or IBM Watson perform service desk roles such as handling customer complaints or solving customer complaints or customer help desk issues.AI can continuously learn, improve the outcomes, and become better at doing the task. It can continually optimise the performance by learning from successes or failures of these actions.Some examples of where AI is acting and learning are Netflix, suggesting movies, TV Shows, and documentaries, based on the viewer’s prior activity, patterns, and behaviours. The more you watch, the more it learns and better suggests relevant content for you to watch. Deep learning is one of the things that makes self-driving cars possible.Artificial Intelligence is also used to assist humans in non-repetitive tasks to find patterns. Learns from experiences and then using machine learning, choose the correct responses. Unlike automation, it does not follow orders or rules.It is used to provide insights. For example, imagine someone has a head injury and needs to determine the level of damage. An AI machine could help diagnose the degree of damage by being ‘trained’ on multiple X-rays of previous head injuries. It would then understand the severity of the current head injury and provide an informed result. This could help doctors provide their overall diagnosis for the patient a lot quicker as they would already have gained insight into the severity of the AI machine’s injury and would therefore have a better understanding of the patient’s condition before doing their checks.The benefits and things to consider relating to Artificial IntelligenceAI brings a new level of efficiency to the use of resources. Machine learning can extract meaning from large and complex data sets. Can, therefore, see patterns and anomalies in data that humans cannot.Secondly, AI has been able to analyse weather patterns and climate data, resulting in more accurate forecasts. Thirdly, a better customer experience, using AI, can improve how it interacts with its customers. This could involve things like customer experience through chatbots and digital assistants, who are available 24/7 to converse with customers. It could also mean that in hospitals, AI can focus on the manual and repetitive tasks such as understanding a patient’s medical history by reading through all the historical records. In contrast, nurses focus on the more human side of their jobs, like forming close interpersonal relationships with patients. AI has also led to other enjoyable and innovative solutions. In certain hotels, hotel guests can now check-in to their hotel using an app by merely using their fingerprints or taking a selfie.Artificial Intelligence is not here to replace us. It is here to help us.The best results are achieved when human experts work hand in hand with AI, each bringing the best of their unique capabilities to a problem.Artificial Intelligence, including machine learning and deep learning systems, are changing each and every industry and could create incredible opportunities for businesses. (Nkusi, 2020)BibliographyAccenture. (n.d.). What is AI exactly? Retrieved November 21, 2020, from https://www.accenture.com/us-en/insights/artificial-intelligence/what-ai-exactlyArtificial Intelligence (AI) Services & Solutions | Accenture. (n.d.). Accenture. Retrieved November 19, 2020, from https://www.accenture.com/us-en/services/ai-artificial-intelligence-indexGlobal, B. (n.d.). The history of artificial intelligence. Bosch Global. Retrieved November 21, 2020, from https://www.bosch.com/stories/history-of-artificial-intelligence/Nkusi, B. F. (2020, December 23). Let’s adapt our skills to work with Artificial Intelligence. The New Times | Rwanda. https://www.newtimes.co.rw/opinions/lets-adapt-our-skills-work-artificial-intelligenceWhat is Machine Learning? (2017, January 11). [Video]. YouTube. https://www.youtube.com/watch?v=f_uwKZIAeM0This blog is a project for Study Unit MCS5460, University of Malta.Don’t forget to give us your 👏 !",https://becominghuman.ai/a-crash-course-on-artificial-intelligence-f5423a36e08e,2021-01-29T18:25:09.027Z,,,f5423a36e08e,['Veronica Sant'],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMjEvcm9idXN0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvb2xzLXByZWRpY3QtZnV0dXJlLWNhbmNlci0wMTI40gEA?oc=5,Robust artificial intelligence tools to predict future cancer - MIT News,2021-01-28,MIT News,https://news.mit.edu,"MIT researchers have improved their machine learning system, Mirai, developed to predict cancer risk from mammogram images, and validated their effectiveness with studies across several hospitals.","Institute for Medical Engineering and Science (IMES), J-Clinic, artificial intelligence, machine learning, breast cancer, mammograms, Regina Barzilay, Mirai, Algorithms, Massachusetts General Hospital (MGH), Karolinska Institute, Chang Gung Memorial Hospital, Tyrer-Cuzick model, Adam Yala, Peter G. Mikhael","MIT researchers have improved their machine learning system, Mirai, developed to predict cancer risk from mammogram images, and validated their effectiveness with studies across several hospitals.",,,,,,,,,,,,,,,,,"


Researchers created a risk-assessment algorithm that shows consistent performance across datasets from US, Europe, and Asia.










Watch Video



Rachel Gordon
|
MIT CSAIL


 Publication Date:
 January 28, 2021





Press Inquiries

  Press Contact:



      
            Rachel        

            Gordon        

  

      Email:
     rachelg@csail.mit.edu


      Phone:
              617-258-0675      
  

      
            MIT Computer Science and Artificial Intelligence Laboratory        

  








 Close














 Caption:
          MIT researchers have improved their machine learning system developed to predict cancer risk from mammogram images, and validated their effectiveness with studies across several hospitals.      
          

 Credits:
          Images courtesy of the researchers.      
          

















Previous image
Next image






















To catch cancer earlier, we need to predict who is going to get it in the future. The complex nature of forecasting risk has been bolstered by artificial intelligence (AI) tools, but the adoption of AI in medicine has been limited by poor performance on new patient populations and neglect to racial minorities. 
Two years ago, a team of scientists from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Jameel Clinic demonstrated a deep learning system to predict cancer risk using just a patient’s mammogram. The model showed significant promise and even improved inclusivity: It was equally accurate for both white and Black women, which is especially important given that Black women are 43 percent more likely to die from breast cancer. 
But to integrate image-based risk models into clinical care and make them widely available, the researchers say the models needed both algorithmic improvements and large-scale validation across several hospitals to prove their robustness. 
To that end, they tailored their new “Mirai” algorithm to capture the unique requirements of risk modeling. Mirai jointly models a patient’s risk across multiple future time points, and can optionally benefit from clinical risk factors such as age or family history, if they are available. The algorithm is also designed to produce predictions that are consistent across minor variances in clinical environments, like the choice of mammography machine.  








      

            Robust artificial intelligence tools may be used to predict future breast cancer.        

    



The team trained Mirai on the same dataset of over 200,000 exams from Massachusetts General Hospital (MGH) from their prior work, and validated it on test sets from MGH, the Karolinska Institute in Sweden, and Chang Gung Memorial Hospital in Taiwan. Mirai is now installed at MGH, and the team’s collaborators are actively working on integrating the model into care. 
Mirai was significantly more accurate than prior methods in predicting cancer risk and identifying high-risk groups across all three datasets. When comparing high-risk cohorts on the MGH test set, the team found that their model identified nearly two times more future cancer diagnoses compared the current clinical standard, the Tyrer-Cuzick model. Mirai was similarly accurate across patients of different races, age groups, and breast density categories in the MGH test set, and across different cancer subtypes in the Karolinska test set. 
“Improved breast cancer risk models enable targeted screening strategies that achieve earlier detection, and less screening harm than existing guidelines,” says Adam Yala, CSAIL PhD student and lead author on a paper about Mirai that was published this week in Science Translational Medicine. “Our goal is to make these advances part of the standard of care. We are partnering with clinicians from Novant Health in North Carolina, Emory in Georgia, Maccabi in Israel, TecSalud in Mexico, Apollo in India, and Barretos in Brazil to further validate the model on diverse populations and study how to best clinically implement it.” 
How it works 
Despite the wide adoption of breast cancer screening, the researchers say the practice is riddled with controversy: More-aggressive screening strategies aim to maximize the benefits of early detection, whereas less-frequent screenings aim to reduce false positives, anxiety, and costs for those who will never even develop breast cancer.  
Current clinical guidelines use risk models to determine which patients should be recommended for supplemental imaging and MRI. Some guidelines use risk models with just age to determine if, and how often, a woman should get screened; others combine multiple factors related to age, hormones, genetics, and breast density to determine further testing. Despite decades of effort, the accuracy of risk models used in clinical practice remains modest.  
Recently, deep learning mammography-based risk models have shown promising performance. To bring this technology to the clinic, the team identified three innovations they believe are critical for risk modeling: jointly modeling time, the optional use of non-image risk factors, and methods to ensure consistent performance across clinical settings. 
1. Time 
Inherent to risk modeling is learning from patients with different amounts of follow-up, and assessing risk at different time points: this can determine how often they get screened, whether they should have supplemental imaging, or even consider preventive treatments. 
Although it’s possible to train separate models to assess risk for each time point, this approach can result in risk assessments that don’t make sense — like predicting that a patient has a higher risk of developing cancer within two years than they do within five years. To address this, the team designed their model to predict risk at all time points simultaneously, by using a tool called an “additive-hazard layer.” 
The additive-hazard layer works as follows: Their network predicts a patient’s risk at a time point, such as five years, as an extension of their risk at the previous time point, such as four years. In doing so, their model can learn from data with variable amounts of follow-up, and then produce self-consistent risk assessments. 
2. Non-image risk factors 
While this method primarily focuses on mammograms, the team wanted to also use non-image risk factors such as age and hormonal factors if they were available — but not require them at the time of the test. One approach would be to add these factors as an input to the model with the image, but this design would prevent the majority of hospitals (such as Karolinska and CGMH), which don’t have this infrastructure, from using the model. 
For Mirai to benefit from risk factors without requiring them, the network predicts that information at training time, and if it's not there, it can use its own predictive version. Mammograms are rich sources of health information, and so many traditional risk factors such as age and menopausal status can be easily predicted from their imaging. As a result of this design, the same model could be used by any clinic globally, and if they have that additional information, they can use it. 
3. Consistent performance across clinical environments 
To incorporate deep-learning risk models into clinical guidelines, the models must perform consistently across diverse clinical environments, and its predictions cannot be affected by minor variations like which machine the mammogram was taken on. Even across a single hospital, the scientists found that standard training did not produce consistent predictions before and after a change in mammography machines, as the algorithm could learn to rely on different cues specific to the environment. To de-bias the model, the team used an adversarial scheme where the model specifically learns mammogram representations that are invariant to the source clinical environment, to produce consistent predictions. 
To further test these updates across diverse clinical settings, the scientists evaluated Mirai on new test sets from Karolinska in Sweden and Chang Gung Memorial Hospital in Taiwan, and found it obtained consistent performance. The team also analyzed the model’s performance across races, ages, and breast density categories in the MGH test set, and across cancer subtypes on the Karolinska dataset, and found it performed similarly across all subgroups. 
“African-American women continue to present with breast cancer at younger ages, and often at later stages,” says Salewai Oseni, a breast surgeon at Massachusetts General Hospital who was not involved with the work. “This, coupled with the higher instance of triple-negative breast cancer in this group, has resulted in increased breast cancer mortality. This study demonstrates the development of a risk model whose prediction has notable accuracy across race. The opportunity for its use clinically is high.” 
Here's how Mirai works: 
1. The mammogram image is put through something called an ""image encoder.""
2. Each image representation, as well as which view it came from, is aggregated with other images from other views to obtain a representation of the entire mammogram.
3. With the mammogram, a patient's traditional risk factors are predicted using a Tyrer-Cuzick model (age, weight, hormonal factors). If unavailable, predicted values are used. 
4. With this information, the additive-hazard layer predicts a patient’s risk for each year over the next five years. 
Improving Mirai 
Although the current model doesn’t look at any of the patient’s previous imaging results, changes in imaging over time contain a wealth of information. In the future the team aims to create methods that can effectively utilize a patient's full imaging history.
In a similar fashion, the team notes that the model could be further improved by utilizing “tomosynthesis,” an X-ray technique for screening asymptomatic cancer patients. Beyond improving accuracy, additional research is required to determine how to adapt image-based risk models to different mammography devices with limited data. 
“We know MRI can catch cancers earlier than mammography, and that earlier detection improves patient outcomes,” says Yala. “But for patients at low risk of cancer, the risk of false-positives can outweigh the benefits. With improved risk models, we can design more nuanced risk-screening guidelines that offer more sensitive screening, like MRI, to patients who will develop cancer, to get better outcomes while reducing unnecessary screening and over-treatment for the rest.” 
“We’re both excited and humbled to ask the question if this AI system will work for African-American populations,” says Judy Gichoya, MD, MS and assistant professor of interventional radiology and informatics at Emory University, who was not involved with the work. “We’re extensively studying this question, and how to detect failure.” 
Yala wrote the paper on Mirai alongside MIT research specialist Peter G. Mikhael, radiologist Fredrik Strand of Karolinska University Hospital, Gigin Lin of Chang Gung Memorial Hospital, Associate Professor Kevin Smith of KTH Royal Institute of Technology, Professor Yung-Liang Wan of Chang Gung University, Leslie Lamb of MGH, Kevin Hughes of MGH, senior author and Harvard Medical School Professor Constance Lehman of MGH, and senior author and MIT Professor Regina Barzilay. 
The work was supported by grants from Susan G Komen, Breast Cancer Research Foundation, Quanta Computing, and the MIT Jameel Clinic. It was also supported by Chang Gung Medical Foundation Grant, and by Stockholm Läns Landsting HMT Grant. 
 








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print









Paper






Paper: ""Toward robust mammography-based models for breast cancer risk""








Press Mentions


WCVBProf. Regina Barzilay speaks with Nicole Estephan of WCVB-TV’s Chronicle about her work developing new AI systems that could be used to help diagnose breast and lung cancer before the cancers are detectable to the human eye.







 Full story via WCVB →
CNNResearchers at MIT developed a system that uses artificial intelligence to help predict future risk of developing breast cancer, reports Poppy Harlow for CNN. What this work does “is identifies risk. It can tell a woman that you’re at high risk for developing breast cancer before you develop breast cancer,” says Larry Norton, medical director of the Lauder Breast Center at the Memorial Sloan Kettering Cancer Center.







 Full story via CNN →
STATSTAT reporters Katie Palmer and Casey Ross spotlight how Prof. Regina Barzilay has developed an AI tool called Mirai that can identify early signs of breast cancer from mammograms. “Mirai’s predictions were rolled into a screening tool called Tempo, which resulted in earlier detection compared to a standard annual screening,” writes Palmer and Ross.











Full story via STAT →
Good Morning AmericaProf. Regina Barzilay speaks with Good Morning America about her work developing a new AI tool that could “revolutionize early breast cancer detection” by identifying patients at high risk of developing the disease. “If this technology is used in a uniform way,” says Barzilay, “we can identify early who are high-risk patients and intervene.”







 Full story via Good Morning America →
The Washington PostWashington Post reporter Steve Zeitchik spotlights Prof. Regina Barzilay and graduate student Adam Yala’s work developing a new AI system, called Mirai, that could transform how breast cancer is diagnosed, “an innovation that could seriously disrupt how we think about the disease.” Zeitchik writes: “Mirai could transform how mammograms are used, open up a whole new world of testing and prevention, allow patients to avoid aggressive treatments and even save the lives of countless people who get breast cancer.”











Full story via The Washington Post →
WiredWired reporter Will Knight spotlights how MIT researchers built a machine learning system that can help predict which patients are most likely to develop breast cancer. “What the AI tools are doing is they're extracting information that my eye and my brain can't,” says Constance Lehman, a professor of radiology at Harvard Medical School and division chief of breast imaging at MGH.











Full story via Wired →















Previous item
Next item



















Related Links

Adam YalaRegina Barzilay""Learning to Cure"" research group at CSAILJameel ClinicComputer Science and Artificial Intelligence LaboratoryMIT Schwarzman College of Computing






Related Topics

School of Engineering
MIT Schwarzman College of Computing
Biological engineering
Electrical Engineering & Computer Science (eecs)
Computer Science and Artificial Intelligence Laboratory (CSAIL)
Institute for Medical Engineering and Science (IMES)
Health care
Medicine
Research
Women
Cancer
Policy
Disease
Artificial intelligence
Machine learning
Health sciences and technology
Collaboration
Algorithms
Technology and society



Related Articles











Can mammogram screening be more effective?













A new approach to targeting tumors and tracking their spread













Using AI to predict breast cancer and personalize care 













Automated system identifies dense tissue, a risk factor for breast cancer, in mammograms

















Previous item
Next item
















",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vY3VsdHVyZS5wbC9lbi9hcnRpY2xlL2NpY2VyLWN1bS1jYXVsZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1tZWV0cy1wb2xpc2gtcGllcm9nadIBAA?oc=5,‘Cicer cum Caule’: Artificial Intelligence Meets Polish Pierogi | Article - Culture.pl,2021-01-29,Culture.pl,https://culture.pl,Interdisciplinary curator Anna Desponds and cultural technologist Philo van Kemenade discuss their project ‘Cicer cum Caule’ – a workshop aimed at explaining some fundamental notions of artificial intelligence through the process of making traditional Polish dumplings.,"digital art, digital culture, art & technology, technology, women, women in contemporary art, ami, Digital Cultures",,Interdisciplinary curator Anna Desponds and cultural technologist Philo van Kemenade discuss their project ‘Cicer cum Caule’ – a workshop aimed at explaining some fundamental notions of artificial intelligence through the process of making traditional Polish dumplings.,,,,,,,,,,,,,,,,EnglishpolskiEnglishукраїнськарусскийSearchContrastOpen MenuClose MenuLanguagesEnglishMain Topics#architecture#cuisine#design#film#heritage#literatureMore Topics#music#performing arts#travel in Poland#visual artsPodcastBookAll Our ProjectsArtists & Works IndexMultimedia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vd3d3LmNhbGNhbGlzdGVjaC5jb20vY3RlY2gvYXJ0aWNsZXMvMCw3MzQwLEwtMzg4OTk3OSwwMC5odG1s0gEA?oc=5,Pinecone raises $10 million to develop AI database - CTech,2021-01-27,CTech,https://www.calcalistech.com,"Company is run by former creators of Amazon’s artificial intelligence platform AWS, and plans to use funds for doubling its workforce in coming year","['Pinecone', 'AI', 'Machine Learning', 'Snowflake']","Company is run by former creators of Amazon’s artificial intelligence platform AWS, and plans to use funds for doubling its workforce in coming year","Company is run by former creators of Amazon’s artificial intelligence platform AWS, and plans to use funds for doubling its workforce in coming year",http://schema.org/,NewsArticle,https://www.calcalistech.com/ctechnews/category/5596,"{'@type': 'ImageObject', 'url': 'https://pic1.calcalist.co.il/PicServer3/2021/01/27/1055257/1NL.jpg', 'height': '147', 'width': '270'}","{'@type': 'Person', 'name': 'Meir Orbach'}","{'@type': 'Organization', 'name': 'Ctech', 'logo': {'@type': 'ImageObject', 'url': 'https://www.calcalistech.com/images/1280/header/Desktop%20Logo.png', 'height': '60', 'width': '195'}}",Pinecone raises $10 million to develop AI database ,2021-01-27T20:13:34,2021-05-25T12:30:04,,VC,,,,,,"{'@type': 'WebPage', '@id': 'https://www.calcalistech.com/ctech/articles/0,7340,L-3889979,00.html'}",,,,,,"{'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': '1', 'item': {'@type': 'WebSite', '@id': 'https://www.calcalistech.com/ctechnews', 'name': 'CTech'}}, {'@type': 'ListItem', 'position': '2', 'item': {'@type': 'WebSite', '@id': 'https://www.calcalistech.com/ctechnews/category/5596', 'name': 'VC'}}]}","Israeli artificial intelligence company Pinecone, the developer of machine learning infrastructure for the cloud, announced on Wednesday that it raised $10 million in seed funding. The round was led by the Wing Venture Capital. Peter Wagner, the Founding Partner of Wing, who was one of the first investors in Snowflake, has joined Pinecone’s board. Pinecone’s system was built by the same team that created Amazon SageMaker, the corporation’s solution for machine learning and artificial intelligence, and was founded by Dr. Edo Liberty, formerly a scientist and director at Amazon AWS. The company employs 10 people, is based out of Tel Aviv, and plans to use the funds to double its workforce over the coming year. 
 
Artificial intelligence companies use embedders to present information - from documents, images and videos, to user characterization. Existing databases and search engines have developed a way to process tabular information or documents, but aren’t yet adapted to process vectors in real-time on a broad scale. As a result, in recent years companies who use AI are forced to build their own solutions.
 
 
 
Pinecone’s database allows infrastructure and ML engineers to process and index billions of high-dimensional vectors in real-time without development efforts. In that way, companies can retrieve information to answer queries, by finding similar vectors, with sharp accuracy and within milliseconds. For example, one of the largest retailers in the world reported that using Pinecon’s system for offering buyer recommendations to customers on its website via its deep learning models, grew its revenues by 18.5% in comparison to existing solutions. “Leading techies are starting to rely on machine learning. Pinecone provides them with the necessary technology which was supposed to only be in the hands of only a few large tech corporations,” said Liberty, founder and CEO of Pinecone. 
 
“Modern organizations and businesses are based on data, and they are transitioning to the future with the help of AI. Similar to the way that companies like Snowflake have set in motion a data revolution, Pinecone is expected to strengthen its data teams and enable companies to adopt AI technologies,” Wagner said. 
 
Pinecone’s founding team has previously built systems for machine learning on a global scale. Liberty has managed Yahoo’s ML platform, after managing Amazon’s AI labs, including the one where his team created Amazon SageMaker. Amir Sadoughi heads the company’s engineering team, and is a former senior engineer at Amazon Cloud Services, and led SageMaker’s engineering development. 
 
Pinecone, which was founded in 2019, includes a team of engineers who have built AI platforms for Amazon AWS AI, Google, Facebook, and Yahoo, and whose scientists have published over 100 academic articles and patents in the field of ML, data, distributed systems, and algorithms. The company has offices in Silicon Valley, New York, and Tel Aviv. One of the company’s investors leads the Wing fund, which invests in company business technologies such as Cohesity, Snowflake, and Gong.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LmJsb29tYmVyZy5jb20vbmV3cy9hcnRpY2xlcy8yMDIxLTAxLTI4L2dvb2dsZS1jZW8tc2F5cy1pbnRlcm5hbC1yYW5jb3Itb3Zlci1haS1kdWUtdG8tdHJhbnNwYXJlbmN50gEA?oc=5,Google CEO Says Internal Rancor Over AI Due to Transparency - Bloomberg,2021-01-28,Bloomberg,https://www.bloomberg.com,Alphabet Inc. Chief Executive Officer Sundar Pichai said employee dissent about Google’s artificial intelligence work seems intense because the company is so transparent.,"ALPHABET INC-CL A,Artificial Intelligence,Sundar Pichai,World Economic Forum,Regulation,Culture,Inclusion,Europe,Australia,Quantum Computing,politics,markets,technology",Alphabet Inc. Chief Executive Officer Sundar Pichai said employee dissent about Google’s artificial intelligence work seems intense because the company is so transparent.,Alphabet Inc. Chief Executive Officer Sundar Pichai said employee dissent about Google’s artificial intelligence work seems intense because the company is so transparent.,http://schema.org,NewsMediaOrganization,https://www.bloomberg.com,"['https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iBcIY0yz5WTA/v0/1200x800.jpg', 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iBcIY0yz5WTA/v0/-1x-1.jpg', 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/social-default.cc6ae30e.jpg']","[{'@type': 'Person', 'name': 'Nico Grant'}]","{'@type': 'Organization', 'name': 'Bloomberg', 'url': 'https://www.bloomberg.com', 'logo': {'@type': 'ImageObject', 'url': 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/bloomberg-logo-amp.bae0aa0a.png', 'width': 262, 'height': 60}}",Google CEO Says Internal Rancor Over AI Due to Transparency,2021-01-28T20:01:14.162Z,2021-01-28T20:01:14.162Z,,Bloomberg,False,,,,"TechnologyGoogle CEO Says Internal Rancor Over AI Due to TransparencyFacebookTwitterLinkedInEmailLinkGiftExpandSundar PichaiPhotographer: Geert Vanden Wijngaert/BloombergFacebookTwitterLinkedInEmailLinkGiftGift this articleHave a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MOREFacebookTwitterLinkedInEmailLinkGiftBy Nico GrantJanuary 28, 2021 at 3:01 PM ESTBookmarkSaveLock This article is for subscribers only.Alphabet Inc. Chief Executive Officer Sundar Pichai said employee dissent about Google’s artificial intelligence work seems intense because the company is so transparent.“Part of the reason you see a lot of debate, I mean, we engage as a company,” Pichai said Thursday during a World Economic Forum discussion. “We are a lot more transparent than most other companies, and so you do see us in the middle of these issues. I take it as a sign that we allow for debate to happen around this area and we need to get better as a company. We are committed to doing so.”Have a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MORE",https://www.bloomberg.com/news/articles/2021-01-28/google-ceo-says-internal-rancor-over-ai-due-to-transparency,2021-01-28T20:01:14.162Z,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Bloomberg', 'productID': 'bloomberg.com:basic'}","[{'@type': 'CollectionPage', 'name': 'Technology', 'url': 'https://www.bloomberg.com/technology'}]","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}","{'@type': 'PostalAddress', 'addressCountry': 'USA', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10022', 'streetAddress': '731 Lexington Avenue'}",https://www.bloomberg.com/diversity-inclusion,inquiry1@bloomberg.net,Bloomberg Finance L.P.,5493001KJTIIGC8Y1R12,(212) 318-2000,https://www.bloomberg.com/logo-bloomberg.svg,"[{'@type': 'Brand', 'name': 'Bloomberg markets', 'url': 'https://www.bloomberg.com/markets'}, {'@type': 'Brand', 'name': 'Bloomberg technology', 'url': 'https://www.bloomberg.com/technology'}, {'@type': 'Brand', 'name': 'Bloomberg pursuits', 'url': 'https://www.bloomberg.com/pursuits'}, {'@type': 'Brand', 'name': 'Bloomberg politics', 'url': 'https://www.bloomberg.com/politics'}, {'@type': 'Brand', 'name': 'Bloomberg opinion', 'url': 'https://www.bloomberg.com/opinion', 'logo': 'https://www.bloomberg.com/logo-bloomberg_opinion.svg'}, {'@type': 'Brand', 'name': 'Bloomberg businessweek', 'url': 'https://www.bloomberg.com/businessweek', 'logo': 'https://www.bloomberg.com/logo-bloomberg_businessweek.svg'}, {'@type': 'Brand', 'name': 'Bloomberg green', 'url': 'https://www.bloomberg.com/green'}, {'@type': 'Brand', 'name': 'Bloomberg equality', 'url': 'https://www.bloomberg.com/equality'}, {'@type': 'Brand', 'name': 'Bloomberg citylab', 'url': 'https://www.bloomberg.com/citylab'}, {'@type': 'Brand', 'name': 'Bloomberg crypto', 'url': 'https://www.bloomberg.com/crypto'}, {'@type': 'Brand', 'name': 'Bloomberg industries', 'url': 'https://www.bloomberg.com/industries'}, {'@type': 'Brand', 'name': 'Bloomberg economics', 'url': 'https://www.bloomberg.com/economics'}, {'@type': 'Brand', 'name': 'Bloomberg ai', 'url': 'https://www.bloomberg.com/ai'}, {'@type': 'Brand', 'name': 'Bloomberg wealth', 'url': 'https://www.bloomberg.com/wealth'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiiwFodHRwczovL25ld3Nyb29tLmlibS5jb20vMjAyMS0wMS0yOC1OZXctSUJNLVRSSVJJR0EtQ2FwYWJpbGl0aWVzLXRvLUhlbHAtU3VwcG9ydC1Pcmdhbml6YXRpb25zLVJldHVybi10by1Xb3JrLXdpdGgtQUktRHJpdmVuLVNwYWNlLVBsYW5uaW5n0gEA?oc=5,New IBM TRIRIGA Capabilities to Help Support Organizations' Return to Work with AI-Driven Space Planning - IBM Newsroom,2021-01-28,IBM Newsroom,https://newsroom.ibm.com,"IBM today introduced capabilities in its IBM TRIRIGA integrated workplace management system that is designed to use artificial intelligence and near real-time insights to help organizations create a safe, productive and efficient workplace. These new capabilities include dynamic space planning, indoor wayfinding and a virtual assistant and are designed to help support organizations' return to work and support employee well-being and productivity.",,"IBM, (NYSE: IBM) today introduced capabilities in its IBM TRIRIGA integrated workplace management system that is designed to use artificial intelligence and near real-time insights to help...","IBM, (NYSE: IBM) today introduced capabilities in its IBM TRIRIGA integrated workplace management system that is designed to use artificial intelligence and near real-time insights to help...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vd3d3LndpY2hpdGEuZWR1L2Fib3V0L3dzdW5ld3MvbmV3cy8yMDIxLzAxLWphbi9xdWFudHVtXzMucGhw0gEA?oc=5,Team explores link between artificial intelligence and quantum computing - Wichita State University,2021-01-27,Wichita State University,https://www.wichita.edu,,,"Jan. 27, 2021 — For three decades, an interdisciplinary team at Wichita State has been exploring how machine learning – also known as artificial intelligence – can maximize the potential of quantum computing.","Jan. 27, 2021 — For three decades, an interdisciplinary team at Wichita State has been exploring how machine learning – also known as artificial intelligence – can maximize the potential of quantum computing.",,,,,,,,,,,,,,,,"
For three decades, an interdisciplinary team at Wichita State has been exploring how
                        machine learning – also known as artificial intelligence – can maximize the potential
                        of quantum computing.
Quantum computing applies the understanding of quantum physics – the behavior of energy
                        and matter at its most basic level – so that computations may be performed at unprecedented
                        speed, solving problems of exceptional complexity that cannot be solved by conventional
                        computers.
Led by Dr. Elizabeth Behrman, a professor of physics, and Dr. James Steck, professor
                        of aerospace engineering, the group currently has seven faculty actively involved.
Behrman, a pioneer in the field of quantum computing, said the two first met in 1990
                        when they were both new faculty at Wichita State.
“Twenty-five years ago, I was doing a lot of research on artificial neural network,
                        which are used in adaptive flight controls,” said Steck, whose area of expertise is
                        flight control systems. Artificial neural networks are structured like the brain,
                        made out of artificial neurons connected together by data pathways modeling synapses
                        in the brain.
“The brain has 10 billion neurons. An ant has 100,000 neurons,” Steck said. “Even
                        today it is hard to build an artificial neural network as big as an ant’s brain, so
                        I was looking at quantum devices, which are very small as a way to build a really
                        big artificial brain.”
Steck and Behrman began looking at the overlap of her research into quantum computing
                        and his interest in artificial neural networks. “If you believe in reincarnation,
                        I suppose you could say I must have been extra virtuous in my previous life I had
                        the good fortune to find such an excellent collaborator as Jim Steck,” she said.

We had incredible difficulty getting published at first. Neural network journals said,
                              ‘What is this quantum stuff?’ and physics journals said, ‘What is this artificial
                              neural network stuff?’Dr. Elizabeth Behrmanprofessor of physics
“Machine learning is used to train artificial neural networks, so we started applying
                        machine learning to train quantum computers to do calculations at a time when everyone
                        else was approaching quantum computers using the same logic gate methods used with
                        traditional PC microprocessors,” Steck said.
 Sometimes, you can be too far ahead of your time. While quantum computing and neural
                        networks have recently become a popular topic of research, in the 1990s the two found
                        it hard to get recognition for their work because it just didn’t “fit” traditional
                        fields of research.
“We had incredible difficulty getting published at first,” Behrman said. “Neural network
                        journals said, ‘What is this quantum stuff?’ and physics journals said, ‘What is this
                        artificial neural network stuff?’”
“We were doing really cool groundbreaking work on using machine learning for quantum
                        computing long before it was cool,” Steck said.
They begin presenting papers and publishing journal articles on topics related to
                        neural networks and quantum computing in the early 1990s. Their landmark work came
                        in 2008 when they published their break-through concepts for machine learning in quantum
                        computers. That paper, “Quantum algorithm design using dynamic learning” in Quantum Information and Computation, has been cited by other researchers dozens of times since.
Generally though, their work is not widely known, Berhman said, but occasionally thanks
                        to the internet, new collaborators seek out the pair. One of these is Dr. Cindy Miller,
                        Joint Staff liaison to NATO Allied Command Transformation. Miller’s job is to seek
                        out areas of promising technological advances from which the United States and our
                        allies would benefit, she said.
""Dr. Behrman and Dr. Steck are advancing a type of research that has the potential
                        to achieve earlier some of the anticipated advantages of quantum computing.  Those
                        advantages include military capabilities for the United States and our allies to ensure
                        our soldiers, sailors, airmen, marines, and guardians have what they need to keep
                        them safe and make them successful,” Miller said.
“Anticipated advantages include the ability to train faster and more precise artificial
                        intelligence in operations; optimizing military logistics; and the development of
                        new materials for weapon systems,” she said. “They have been kind enough to let me
                        learn more about this important field through interaction with their research group.""
In addition to Steck and Behrman, their research group now includes faculty from McPherson
                        College and University of Kansas, in addition to five at Wichita State: Behrman, Steck,
                        and Saideep Nannapaneni, Nathan Thompson and Bill Ingle.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LnBvcHVsYXJtZWNoYW5pY3MuY29tL3RlY2hub2xvZ3kvcm9ib3RzL2EzNTI2NzUwOC9odW1hbnMtY2FudC1jb250YWluLXN1cGVyaW50ZWxsaWdlbnQtbWFjaGluZXMv0gEA?oc=5,Humans Can't Contain Superintelligent Machines | Super AI - Popular Mechanics,2021-01-28,Popular Mechanics,https://www.popularmechanics.com,"New calculations show we won't be able to control superintelligent machines. Well, humans had a pretty good run.",,"Well, we had a pretty good run.",,,,,,,,,,,,,,,Robots,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vaW5kaWFhaS5nb3YuaW4vYXJ0aWNsZS95ZXMtbm9uLXRlY2hpZXMtdG9vLWNhbi13b3JrLWluLWFpLWhlcmUtcy1ob3fSAQA?oc=5,"Yes, non-techies too can work in AI. Here's how! - INDIAai",2021-01-27,INDIAai,https://indiaai.gov.in,"True, Artificial Intelligence is a subfield of Computer Science. It is also true that if you’re a techie trained in the computer sciences, AI is a very lucrative area to work in. But the reverse may not be true.",undefined,"True, Artificial Intelligence is a subfield of Computer Science. It is also true that if you’re a techie trained in the computer sciences, AI is a very lucrative area to work in. But the reverse may not be true.","True, Artificial Intelligence is a subfield of Computer Science. It is also true that if you’re a techie trained in the computer sciences, AI is a very lucrative area to work in. But the reverse may not be true.",,,,,,,,,,,,,,,,"
                            Proforma for submission of nominations for IndiaAI Fellowship under the IndiaAI Mission
                         
                                    Article
                                 
                                4 Min
                            ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RoZS1yb2xlLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFuZC1tbC1pbi1pbnRlbGxpZ2VudC1hbmFseXRpY3PSAYYBaHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RoZS1yb2xlLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFuZC1tbC1pbi1pbnRlbGxpZ2VudC1hbmFseXRpY3M?oc=5,The Role of Artificial Intelligence and ML in Intelligent Analytics - Analytics Insight,2021-01-27,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,AI and ML in intelligent analytics,role of AI and ML,analytics data,Machine Learning",AI and ML in intelligent analytics can drive the efficiency in business Analytics has been changing the way organizations operate for a long while. Since more o,AI and ML in intelligent analytics can drive the efficiency in business Analytics has been changing the way organizations operate for a long while. Since more o,http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/the-role-of-artificial-intelligence-and-ml-in-intelligent-analytics,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Intelligent-Analysis.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Priya Dialani', 'name': 'Priya Dialani', 'url': 'https://www.analyticsinsight.net/author/priya-dialani'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",The Role of Artificial Intelligence and ML in Intelligent Analytics,2021-01-27T00:59:52Z,2021-01-27T00:59:52Z,Artificial Intelligence,The Role of Artificial Intelligence and ML in Intelligent Analytics,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Role of Artificial Intelligence and ML in Intelligent Analytics', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/the-role-of-artificial-intelligence-and-ml-in-intelligent-analytics'}]",,,What is AI and Data Science Engineering? ,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/the-role-of-artificial-intelligence-and-ml-in-intelligent-analytics'}",2021-01-27T00:59:52Z,,,,,,"AI and ML in intelligent analytics can drive the efficiency in business.Analytics has been changing the way organizations operate for a long while. Since more organizations are dominating their utilization of analytics, they are diving further into their data to build proficiency, acquire a more prominent upper hand, and lift their bottom lines significantly more..Analytics powers your business, however, what amount of value would you say you are truly harnessing from your data?.Artificial intelligence and machine learning can help. Artificial intelligence is a collection of technologies that extract patterns and valuable insights from huge datasets, then making forecasts dependent on that data. Truth be told, AI exists today that can assist you with getting more value out of the data you as of now have, bind together that data, and make forecasts about customer behaviors based on it..The adoption of AI has been driven not just by increased computational power and new algorithms yet additionally the growth of data now accessible. For intelligence analysts, that multiplication of data implies surefire data over-burden. Human analysts essentially can't adapt to that much information. They need assistance..Intelligence leaders realize that AI can assist to adapt to this data downpour yet they may likewise consider what sway AI will have on their work and staff. For example, Twitter utilizes machine learning and AI to assess tweets in real-time and score them utilizing different measurements to show tweets that can possibly drive the most engagement..Google is researching virtually every part of machine learning and is making advancements in old-style algorithms and different applications like speech translation, prediction systems, natural language processing, and search ranking..Artificial intelligence plays a significant part in assisting organizations with handling data without forfeiting accuracy or speed..With digital transformation widely being embraced, the volume and size of data have expanded significantly. Also, dealing with such gigantic data isn't simple. Artificial intelligence- fueled data-driven innovation can help organizations manage such data to guarantee importance, worth, security, and transparency. They can depend on AI data integration platforms to ingest, change, and use information easily and with accuracy. Such platforms give an end-to-end encrypted environment that protects information from undesirable infringing and breaches, and make them hard to work with..Artificial intelligence and ML frameworks exist that utilize analytics data to assist you with foreseeing results and effective blueprints. Artificial intelligence- empowered frameworks can analyze information from many sources and deliver forecasts about what works and what doesn't. It can likewise deeply jump into information about your customers and offer predictions about buyer inclinations, marketing and sales channels, and product development strategies..Artificial intelligence/ML advances empower companies across various industries to harness value from customer information with no trouble. For instance, AI data integration solutions empower all business users to map information between various fields to make it simpler to incorporate the data into a unified database. Since these arrangements can be effortlessly utilized by non-technical users, IT people need not assume full responsibility. This leaves IT to zero in on other vital tasks..These solutions use ML algorithms to provide predictions of data, which can additionally quicken the data transformation process. Since the decisions are taken utilizing algorithms, the chance of mistakes like missing qualities, deceptions, errors, and so on, reduce. Hence, companies can use AI/ML tools to change the manner in which they deliver customer value. They can plan and integrate data and keep up data integrity, improving decision-making and boosting growth..The advantages of AI and ML, notwithstanding, can go a long way beyond time savings. All things considered, intelligence work is a never-ending process; there is consistently another difficulty that demands attention. So saving time with AI won't decrease the staff or trim intelligence budgets. Or maybe, the more noteworthy value of AI comes from what may be named an &quot;automation dividend&quot;: the better ways experts can utilize their time after these advances reduce their workload..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.","{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/the-role-of-artificial-intelligence-and-ml-in-intelligent-analytics', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Intelligent-Analysis.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Intelligent-Analysis.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3Lm5oaC5uby9lbi9uaGgtYnVsbGV0aW4vYXJ0aWNsZS1hcmNoaXZlLzIwMjEvamFudWFyL3NlY3VyZWQtaGVyLWRyZWFtLWpvYi1lYXJseS_SAQA?oc=5,Secured her dream job early - nhh.no,2021-01-27,nhh.no,https://www.nhh.no,NHH student Inger Mirjam Madland (26) secured a job at her dream workplace before she started work on her master’s thesis.,,NHH student Inger Mirjam Madland (26) secured a job at her dream workplace before she started work on her master’s thesis. ,NHH student Inger Mirjam Madland (26) secured a job at her dream workplace before she started work on her master’s thesis.,,,,,,,,,,,,,,,,"
Protects companies against cyber attacks

Andreas Orset combined economics and technology studies at NHH to adapt to the future job market. This secured him a permanent job a year and a half before graduating.         
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiswFodHRwczovL3d3dy51YWxiZXJ0YS5jYS9jb21wdXRpbmctc2NpZW5jZS9uZXdzLWFuZC1ldmVudHMvbmV3cy8yMDIxL2phbnVhcnkvbWlrZS1ib3dsaW5nLWVsZWN0ZWQtYXMtYS1mZWxsb3ctb2YtdGhlLWFzc29jaWF0aW9uLWZvci10aGUtYWR2YW5jZW1lbnQtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UuaHRtbNIBAA?oc=5,Mike Bowling elected as a Fellow of the Association for the Advancement of Artificial Intelligence - University of Alberta,2021-01-29,University of Alberta,https://www.ualberta.ca,,,,,https://schema.org,Article,,['media-library/news/mike_bowling_amii.jpg'],"{'@type': 'Person', 'name': 'unknown'}","{'@type': 'Organization', 'name': 'University of Alberta', 'logo': {'@type': 'ImageObject', 'url': 'https://content.presspage.com/clients/o_1979.png'}}",Mike Bowling elected as a Fellow of the Association for the Advancement of Artificial Intelligence,2021-01-29T00:00Z,2022-08-15T10:31Z,,,,,,,,"{'@type': 'WebPage', '@id': '//www.ualberta.ca/'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vaW5kaWFuZXhwcmVzcy5jb20vYXJ0aWNsZS90ZWNobm9sb2d5L3RlY2gtbmV3cy10ZWNobm9sb2d5L2dvb2dsZS1jZW8tc2F5cy1pbnRlcm5hbC1yYW5jb3Itb3Zlci1haS1kdWUtdG8tdHJhbnNwYXJlbmN5L9IBgwFodHRwczovL2luZGlhbmV4cHJlc3MuY29tL2FydGljbGUvdGVjaG5vbG9neS90ZWNoLW5ld3MtdGVjaG5vbG9neS9nb29nbGUtY2VvLXNheXMtaW50ZXJuYWwtcmFuY29yLW92ZXItYWktZHVlLXRvLXRyYW5zcGFyZW5jeS9saXRlLw?oc=5,Google CEO says internal rancor over AI due to transparency - The Indian Express,2021-01-29,The Indian Express,https://indianexpress.com,Alphabet Inc Chief Executive Officer Sundar Pichai said employee dissent about Google’s artificial intelligence work seems intense because the company is so transparent.,"['Google’s artificial intelligence ', ' Google AI', ' Google AI dissent', ' Google controversies', ' Google AI news', ' Sundar Pichai news', ' Google artificial intelligence news', '']",Alphabet Inc Chief Executive Officer Sundar Pichai said employee dissent about Google’s artificial intelligence work seems intense because the company is so transparent.,Alphabet Inc Chief Executive Officer Sundar Pichai said employee dissent about Google’s artificial intelligence work seems intense because the company is so transparent.,https://schema.org,NewsArticle,https://indianexpress.com/article/technology/tech-news-technology/google-ceo-says-internal-rancor-over-ai-due-to-transparency/,https://images.indianexpress.com/2021/01/4b17bb2a-8d51-43cf-bc18-500a2408414e-1.jpg,"[{'@type': 'Thing', 'name': 'IE Online', 'url': 'https://indianexpress.com/'}]","{'@type': 'NewsMediaOrganization', 'name': 'The Indian Express', 'url': 'https://indianexpress.com/', 'foundingDate': '1932', 'ethicsPolicy': 'https://indianexpress.com/privacy-policy/', 'SameAs': ['https://www.facebook.com/indianexpress', 'https://twitter.com/IndianExpress', 'https://www.youtube.com/@indianexpress', 'https://www.instagram.com/indianexpress/', 'https://www.linkedin.com/company/indian-express/'], 'logo': {'@type': 'ImageObject', 'url': 'https://images.indianexpress.com/2019/11/ienewlogo3_new.png', 'width': '600', 'height': '60'}}",Google CEO says internal rancor over AI due to transparency,2021-01-29T12:53:28+05:30,2021-01-29T12:53:28+05:30,technology,"['Home', 'Subscribe', 'India News', 'Cities', 'Videos', 'Audio', 'Explained', 'Education', 'Political Pulse', 'Opinion', 'Entertainment', 'Investigations', 'Lifestyle', 'Technology', 'Sports', 'Express Premium', 'Latest News', 'World News', 'Trending', 'Photos', 'Elections 2023', 'Web Stories', 'Bollywood', 'Cricket', 'Science', 'Business', 'Horoscope', 'Delhi News', 'Mumbai News', 'Hyderabad News', 'Bengaluru News', 'What Is', 'When Is', 'Who Is', 'How To', ""Today's Paper"", 'Brand Solutions']",False,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://indianexpress.com/', 'name': 'News'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://indianexpress.com/section/technology/', 'name': 'Technology'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://indianexpress.com/section/technology/tech-news-technology/', 'name': 'Tech'}}]",,,,"{'@type': 'WebPage', '@id': 'https://indianexpress.com/article/technology/tech-news-technology/google-ceo-says-internal-rancor-over-ai-due-to-transparency/'}",,,,,,,"Alphabet Inc Chief Executive Officer Sundar Pichai said employee dissent about Google’s artificial intelligence work seems intense because the company is so transparent. “Part of the reason you see a lot of debate, I mean, we engage as a company,” Pichai said Thursday during a World Economic Forum discussion. “We are a lot more transparent than most other companies, and so you do see us in the middle of these issues. I take it as a sign that we allow for debate to happen around this area and we need to get better as a company. We are committed to doing so.” In December, Timnit Gebru, a researcher best known for showing how facial recognition algorithms are better at identifying White people than Black people, left Google in a storm of controversy. She has said she was fired after the company demanded she retract a research paper she co-authored that questioned an AI technology at the heart of Google’s search engine. The company has said she resigned. Close to 2,700 Googlers and more than 4,300 academics and civil society supporters signed a petition in favor of Gebru. Pichai emailed an apology to employees and said he is investigating the incident. The CEO said Thursday that listening to staff is an important part of Google’s culture and he wants to work with employee groups on sustainability and diversity and inclusion efforts. Google is being targeted by regulators from the European Union to Australia to the US on issues such as antitrust and whether the company should pay publishers for news. While the company is fighting many of these efforts, Pichai said he hopes to see more regulation in some areas, including an international accord on AI safety and quantum computing and guidance from governments on content moderation and free speech online. Digital misinformation “is bigger than any single company,” he said. “It is here to stay. As a society, we need to develop the next set of frameworks for us to function through that. That’s the debate we’re in the middle of.”","{'@type': ['CreativeWork', 'Product'], 'name': 'IE Premium', 'productID': 'indianexpress.com:showcase'}",,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.ie-premium-content-block', 'video': [], 'audio': []}","{'@type': 'PostalAddress', 'streetAddress': 'Express Building, B-1/B, Sector-10', 'addressLocality': 'Noida', 'addressRegion': 'India', 'postalCode': '201301'}",,,The Indian Express,,,"{'@type': 'ImageObject', 'url': 'https://indianexpress.com/wp-content/themes/indianexpress/images/indian-express-logo-n.svg', 'inLanguage': 'en-US', 'width': 600, 'height': 60, 'caption': 'The Indian Express'}",,,,"{'@type': 'SpeakableSpecification', 'xpath': ['//title', ""//meta[@name='description']/@content""]}",https://schema.org/NewsMediaOrganization,News,en,2024-07-17,"{'type': 'EntryPoint', 'urlTemplate': 'https://indexpress.page.link/shareDL'}",1932.0,JOURNALISM OF COURAGE,"{'@type': 'ContactPoint', 'telephone': '+91-120-6651500', 'areaServed': 'IN', 'availableLanguage': 'English', 'hoursAvailable': {'opens': '09:30', 'closes': '18:30'}}","['https://www.facebook.com/indianexpress', 'https://twitter.com/IndianExpress', 'https://www.linkedin.com/company/indian-express', 'https://www.instagram.com/indianexpress/', 'https://www.youtube.com/channel/UCJEDFSxHHOW1PpBccdSxOTA']","{'@type': 'Person', 'name': 'Ramnath Goenka', 'url': 'https://indianexpress.com/ramnath-goenka/', 'sameAs': 'https://indianexpress.com/ramnath-goenka/'}","{'@type': 'QuantitativeValue', 'value': 153}","{'@type': 'SearchAction', 'target': 'https://indianexpress.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}",2024.0,"{'@type': 'AdministrativeArea', 'name': 'Noida, India'}","{'@type': 'ImageObject', 'url': 'https://images.indianexpress.com/2021/01/4b17bb2a-8d51-43cf-bc18-500a2408414e-1.jpg', 'caption': 'Sundar Pichai, chief executive officer of Alphabet Inc said that listening to staff is an important part of Google’s culture ( image source : Bloomberg)', 'description': 'Google’s artificial intelligence , Google AI, Google AI dissent, Google controversies, Google AI news, Sundar Pichai news, Google artificial intelligence news,', 'width': 1200, 'height': 675}",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9pbXBsZW1lbnRpbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdGFsZW50LXRvLWZpbGwtaW4tY29tcGFuaWVzLXNraWxsLWdhcNIBjQFodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hbXAvc3RvcnkvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvaW1wbGVtZW50aW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRhbGVudC10by1maWxsLWluLWNvbXBhbmllcy1za2lsbC1nYXA?oc=5,Implementing Artificial Intelligence Talent to Fill in Companies Skill Gap - Analytics Insight,2021-01-27,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence Talent,AI strategy,AI talent,artificial intelligence,use of AI technologies",How the Implementation of AI Talent feeds Organisations Skill Gap There is an international shortage of artificial intelligence talent and labour markets across,How the Implementation of AI Talent feeds Organisations Skill Gap There is an international shortage of artificial intelligence talent and labour markets across,http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/implementing-artificial-intelligence-talent-to-fill-in-companies-skill-gap,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-16.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Puja Das', 'name': 'Puja Das', 'url': 'https://www.analyticsinsight.net/author/puja-das'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",Implementing Artificial Intelligence Talent to Fill in Companies Skill Gap,2021-01-27T02:28:59Z,2021-01-27T02:28:59Z,Artificial Intelligence,Implementing Artificial Intelligence Talent to Fill in Companies Skill Gap,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Implementing Artificial Intelligence Talent to Fill in Companies Skill Gap', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/implementing-artificial-intelligence-talent-to-fill-in-companies-skill-gap'}]",,,What is AI and Data Science Engineering? ,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/implementing-artificial-intelligence-talent-to-fill-in-companies-skill-gap'}",2021-01-27T02:28:59Z,,,,,,"How the Implementation of AI Talent feeds Organisations Skill Gap.There is an international shortage of artificial intelligence talent and labour markets across the world cannot keep up with the demand for developers. There is also a shortage of mathematicians and scientists who can develop new and innovative artificial intelligence (AI) technology..A study by Microsoft and IDC reveals that the shortage of workers with artificial intelligence skills has prevented companies that want to embrace AI from being capable of doing so. Enterprises must discover creative ways to supplement the talent they require to initiate AI projects across industries until highly skilled AI developers enter the workforce. Those projects could involve voice, image, or pattern recognition allowing autonomous movement or simulating realistic conversations. Such innovations can strengthen a new generation of healthcare tools and smart home devices..Companies across all industries have been struggling to secure top AI talent from a pool that is not expanding fast enough. Even during the economic disruption and layoffs due to the COVID-19 pandemic, the demand for AI talent has been robust. Leaders are looking to minimise costs through automation and efficiency. In such a scenario, companies need not solely be looking for fresh graduates. Instead, they need to actively start investing in training current employees and recruiting people with AI-adjacent skills..To get deep insights into it, let's look at how companies can implement AI talent to feed the skill gap effectively:.Build a team of In-house Expertise.Companies in niche areas and smaller organisations should not be too stubborn about recruiting preferences. Part of this requires not looking for people who already have AI experience. Instead, hire employees who show the hard and soft skills which could eventually make them a valuable asset of an artificial intelligence team. They add flexibility and enthusiasm for learning, complex problem-solving skills, data visualisation and analytics, understanding in mathematics, and security..Invest in Learning.Company leadership often talk about a nice game for continuous growth and learning, but they don't tangibly invest time and resources for people to do so. To save time and invest in resources effectively, companies need to focus on robust skills development in the field of AI. However, this might not provide the expected results..Companies can start small, but the leadership team requires creating the time and resources people need to commit to learning artificial intelligence skills and technologies. Ad-hoc opportunities don't likely deliver results a company wants. Besides, someone who is worried about if the manager is looking over the individual's shoulder and wondering the reason why the person is not doing a real job cannot concentrate on meaningful learning..Although skill development reaches its potential when the teachings are grounded in real projects, businesses often are not equipped to train their employees in emerging technologies like AI. Managers should encourage employees to opt for related courses from Coursera, Udacity, Datacamp, etc. They also should support these endeavours by offering employees time to learn the skills they need..Structure Team According to the Problem.The composition of an AI team depends on the problem being solved, the team's approach, and the level of incorporation required with the development team to support production. However, there are a few things to keep in mind. First, hiring solo AI talent is not advisable. Second, AI professionals rely on partnership for ideas and can feel isolated if they are the only member of a larger team. Third, companies may begin with a small team to validate data and the team's ideas, regardless of the domain. Finally, companies need to ensure that they have a robust AI strategy before expanding the team..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.","{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/implementing-artificial-intelligence-talent-to-fill-in-companies-skill-gap', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-16.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-16.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LnN2Z2V1cm9wZS5vcmcvYmxvZy9oZWFkbGluZXMvY2FuLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWRvLXRoZS1qb2Itb2YtYW4tYXVkaW8tZW5naW5lZXIv0gEA?oc=5,Can artificial intelligence do the job of an audio engineer? - SVG Europe,2021-01-11,SVG Europe,https://www.svgeurope.org,"By Michel Bais, managing director, Mobile Viewpoint Artificial intelligence (AI) is beginning to be adopted across the broadcast arena as a new ...",,"By Michel Bais, managing director, Mobile Viewpoint Artificial intelligence (AI) is beginning to be adopted across the broadcast arena as a new ...",,,,,,,,,,,,,,,,,"
Can artificial intelligence do the job of an audio engineer?

By SVG Contributor Monday, January 11, 2021 - 06:35
                                    Print This Story

By Michel Bais, managing director, Mobile Viewpoint
Artificial intelligence (AI) is beginning to be adopted across the broadcast arena as a new initiative to enable productions and operational processes that were previously cost prohibitive or expensive. It is not positioned to replace jobs, but to enable productions that were previously just not possible. But can AI be applied to the audio?
As a video technology company, we often get wrongly accused of not prioritising the audio element as much as the video quality. We have been implementing AI for video as an alternative to camera people so it may be interesting to some that as a video technology company, we are developing what we believe is a world first: a method to also capture audio as part of the production, but without the need of an audio engineer.
But what is this exactly?  One example is in sports production where a panoramic camera is utilised above the field of play and captures the whole pitch in super high resolution. Then, using the power of AI, a virtual cutout of the action in full HD is created which live streams only the ball and the action of the players around the ball. There isn’t a cameraperson or director in sight and it enables live sports production at a fraction of the traditional cost. This could be ideal for those games that previously could not be live streamed, such as youth sports, training games and grassroots games, and it allows sports clubs and media right holders effective ways to monetise or promote their content that were previously not possible.
AI audio
But what about the audio element? A major part of any sports production is capturing the mood of the game, of which all the sounds and noise are a fundamental part of the experience. Traditionally there would be a bank of microphones on the pitch-side, capturing different parts of the pitch and the reaction of the spectators. So, if a goal is scored by the home supporters than the reaction of the home supporters can be ingested into the production. Any swearing or bad language can be taken out. It is the job of the audio engineer to do this.
As part of an AI production where AI creates a virtual camera to track the ball, we believe it would be interesting to also allow the AI to follow the audio in the same way, taking the place of the audio engineer and giving a much more varied and compelling audio experience. This we feel is a world first. In reality this means developing a panoramic audio capturing device which replaces the bank of costly microphones. The AI will only reveal the audio that is relevant to the video shot and embed that with the live stream.
Wide appeal
It is something under serious development at IQ Video Solutions.  The future of this technology could be applied to many situations. At some point for budget productions, we see the panoramic camera being used as a replacement for a multicamera production, whether that be in a panel show, a council meeting or a studio set up. If the audio capture device can filter out other noises and only pick up the relevant audio to that specific shot, then we can create much more relevant productions and reduce costs accordingly.
Are we trying to replace jobs with AI? First, we remove the need for the camera person and director, and now the audio engineer? This is not our intention – the AI platform is designed to enable productions that previously were not feasible by not having the budget or resource to create a professional production. The AI Audio Engineer is an extension of that philosophy and adding to the overall AI proposition. There will continue to be a place for manned productions for those who have the budget.
 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vd3d3LndpcmVkLWdvdi5uZXQvd2cvbmV3cy5uc2YvYXJ0aWNsZXMvRlNDUytlbWJyYWNlcythcnRpZmljaWFsK2ludGVsbGlnZW5jZSt0bytoZWxwK2N1c3RvbWVycyswNzAxMjAyMTE0MTAwMD9vcGVu0gEA?oc=5,FSCS embraces artificial intelligence to help customers | FSCS | Official Press Release - WiredGov,2021-01-07,WiredGov,https://www.wired-gov.net,FSCS is pioneering the use of artificial intelligence (AI) to help process claims – it's the latest innovation we've brought in to improve the experience for our customers.,"AI,LCF,FSCS,Barber,CMC,CMCs,Capgemini,Capita,Capital,Chief,Emails,Finance,Gathering,However,January,Jimmy,June,London,Microsoft,Officer",FSCS is pioneering the use of artificial intelligence (AI) to help process claims – it's the latest innovation we've brought in to improve the experience for our customers.,FSCS is pioneering the use of artificial intelligence (AI) to help process claims – it's the latest innovation we've brought in to improve the experience for our customers.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmVkZ2VtaWRkbGVlYXN0LmNvbS9zZWN1cml0eS85NTA1OS1ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY2FuLXN1cHBvcnQtZm9vZC1zZWN1cml0edIBAA?oc=5,How artificial intelligence can support food security - Edge Middle East,2021-01-10,Edge Middle East,https://www.edgemiddleeast.com,"Artificial intelligence is a powerful technology that's driving transformation across every industry and it also has the potential to solve some of humanity's greatest challenges.. How artificial intelligence can support food security. Artificial Intelligence, data centre, food security, Gitex, Microsoft, Security, UAE. Security.",,"Artificial intelligence is a powerful technology that's driving transformation across every industry and it also has the potential to solve some of humanity's greatest challenges.. How artificial intelligence can support food security. Artificial Intelligence, data centre, food security, Gitex, Microsoft, Security, UAE. Security.","Artificial intelligence is a powerful technology that's driving transformation across every industry and it also has the potential to solve some of humanity's greatest challenges.. How artificial intelligence can support food security. Artificial Intelligence, data centre, food security, Gitex, Microsoft, Security, UAE. Security.",https://schema.org,,,,,,,,,,,,,Security,,"

Always at the forefront of innovation, the UAE is fast adopting Artificial Intelligence (AI) as a key technology aiding digital transformation and a move towards a high-tech economy. Key strategies, such as the adoption of the ‘UAE Strategy for Artificial Intelligence (AI)’, applied to future services, sectors and infrastructure projects are driving this AI vision as much as the appointment of the first ever Minister of State for Artificial Intelligence, Digital Economy and Remote Work Applications, His Excellency Omar Bin Sultan Al Olama.
Crucially, the application of this fast-moving technology is not just confined to advanced industries such as manufacturing or aeronautics as many might imagine: AI has the potential to impact every area of our lives and empower those working to solve humanitarian issues and create a more sustainable and accessible world.
Using AI for Good


Microsoft is focused on helping businesses and organisations across industries re-imagine the way they do business going forward, building resilience for the future. To do this, we are continuously investing in technology infrastructure – into data centres but more importantly into skilling and technical capabilities of the UAE population.
Ultimately, we believe that AI innovation has huge potential to transform not only businesses but our entire society for the better, as we champion applications that empower those working to solve humanitarian issues and create a more sustainable and accessible world.
To further harness this potential, under its ‘AI for Good Programme’ Microsoft is investing $115 million over five years, providing funding, technology and expertise to individuals and organisations so they can tackle some of society’s big issues.


UAE Food Security
One of the areas under the spotlight in Microsoft’s AI for Good programme is food supply: how do we make sure that we can grow food locally and sustainably and that supply chains are protected? By 2050, it is estimated that there will be a need to feed 9-10 billion people with a finite amount of additional arable land and water. Cloud technology may prove critical to mitigate this agricultural challenge.
Particularly for the UAE, which is a net importer of food, this is mission critical and entails considerations from increasing local food production to exploring ways to diversify food import sources. Recognising the challenge, the UAE government quickly created a comprehensive food security approach that would stand the country in good stead throughout the pandemic and create a strong food infrastructure for the future – an area which is crucial for the UAE for its long-term planning.


Also read: Microsoft highlights AI innovation at GITEX 2020
His Highness Sheikh Mohammed bin Rashid Al Maktoum, Vice-President and Prime Minister of the UAE and Ruler of Dubai, has indicated the priority given to technologies, saying “We want to invest in new agricultural fields and mechanisms by harnessing advanced technologies and make proactive changes in agricultural and food systems.”
A first step in this direction has been the launch of the Food Security Dashboard of Dubai in June 2020, which is capable of using artificial intelligence and data analytics to rapidly measure the five important indicators of food security including, the supply index; stock availability; local production; consumption levels; and the cost of vital commodities in the Emirate.
Azure FarmBeats – bringing technology to the farm
With this priority given to technologies in delivering food security, Microsoft’s goal is to enable data-driven farming. We believe that data, coupled with the farmer’s knowledge and intuition about his or her farm, can help increase farm productivity, and help reduce costs. However, getting data from the farm is extremely difficult, since there is often no power in the field, or Internet on the farms.
We are building several unique solutions to solve these problems using low-cost sensors, drones, and vision and machine learning algorithms. Our solution, Azure FarmBeats, provides farmers with access to the Microsoft cloud and AI technologies, enabling data driven decisions that growers can act on. Capabilities include aggregating agricultural data from different sources; fusing different agricultural datasets from sensors, drones & satellites; rapidly building AI/ML models using the fused datasets and building customised digital agriculture solutions.
Microsoft has successfully rolled out FarmBeats around the world, including a partnership with the U.S. Department of Agriculture (USDA) on an initiative outfitting a network of high-tech sensors, putting data in the hands of farmers and scientists in ways unimaginable a few years ago. The sensors at the 7,000-acre farm at the USDA’s Beltsville Agricultural Research Center in Maryland harness data and artificial intelligence to help farmers cut costs, increase yields and sustainably grow crops that are more resilient to climate change.
FarmBeats is also offering tech and business resources to Series C startups in India, which can boost their business with Azure benefits, technical support, market strategies, unlimited technical support, and new sale opportunities. Companies that have plans to build digital agriculture solutions now have the opportunity to co-build customised solutions Azure FarmBeats without the need to invest in deep data engineering. By using Azure FarmBeats, startups can acquire, aggregate and process agricultural data and rapidly develop their own AI/ML model.
Microsoft will be showcasing its new solution Azure FarmBeats at GITEX as one of the examples of how technology can help farming communities to be more sustainable and productive.
AI for a better world
The world has gone through a series of challenges through the course of the year when digital transformation has been compressed from leaps that would usually take years to a matter of months. As we have all been forced to rethink the ways we go about our lives, governments and organisations are now looking with fresh eyes to positive applications.
Human ingenuity and technology have dovetailed together to firstly provide a response to the pandemic and then support a recovery, providing a rapid learning curve and a newfound appreciation of and openness to technology. These shared experiences have opened people’s eyes in recognition of how technology can provide solutions to all manner of challenges, beyond the theoretical to the practical at a grand scale. Now this same digital transformation journey paves the way for a reimagining and rebuilding of essential foundations of our lives including food security, creating a more resilient and sustainable world.



Tagged: Artificial Intelligence, data centre, food security, Gitex, Microsoft, Security, UAE 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': ['NewsMediaOrganization', 'Organization'], '@id': 'https://www.edgemiddleeast.com/#organization', 'name': 'ITP.net', 'url': 'https://www.edgemiddleeast.com', 'sameAs': ['https://www.facebook.com/ITPnet-463859577013646', 'https://twitter.com/ITP_English'], 'logo': {'@type': 'ImageObject', '@id': 'https://www.edgemiddleeast.com/#logo', 'url': 'https://www.edgemiddleeast.com/cloud/2024/07/15/Edge_New_Logo_White-01-1.png', 'contentUrl': 'https://www.edgemiddleeast.com/cloud/2024/07/15/Edge_New_Logo_White-01-1.png', 'caption': 'ITP.net', 'inLanguage': 'en-US'}}, {'@type': 'WebSite', '@id': 'https://www.edgemiddleeast.com/#website', 'url': 'https://www.edgemiddleeast.com', 'name': 'ITP.net', 'publisher': {'@id': 'https://www.edgemiddleeast.com/#organization'}, 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://www.edgemiddleeast.com/cloud/2021/08/19/shutterstock_1083770003-1.jpg', 'url': 'https://www.edgemiddleeast.com/cloud/2021/08/19/shutterstock_1083770003-1.jpg', 'width': '800', 'height': '600', 'caption': 'How artificial intelligence can support food security', 'inLanguage': 'en-US'}, {'@type': 'BreadcrumbList', '@id': 'https://www.edgemiddleeast.com/security/95059-how-artificial-intelligence-can-support-food-security#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': '1', 'item': {'@id': 'https://www.edgemiddleeast.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': '2', 'item': {'@id': 'https://www.edgemiddleeast.com/security', 'name': 'Security'}}, {'@type': 'ListItem', 'position': '3', 'item': {'@id': 'https://www.edgemiddleeast.com/security/95059-how-artificial-intelligence-can-support-food-security', 'name': 'How artificial intelligence can support food security'}}]}, {'@type': 'WebPage', '@id': 'https://www.edgemiddleeast.com/security/95059-how-artificial-intelligence-can-support-food-security#webpage', 'url': 'https://www.edgemiddleeast.com/security/95059-how-artificial-intelligence-can-support-food-security', 'name': 'How artificial intelligence can support food security - Edge Middle East', 'datePublished': '2021-01-10T09:15:00+04:00', 'dateModified': '2021-08-20T12:44:03+04:00', 'isPartOf': {'@id': 'https://www.edgemiddleeast.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.edgemiddleeast.com/cloud/2021/08/19/shutterstock_1083770003-1.jpg'}, 'inLanguage': 'en-US', 'breadcrumb': {'@id': 'https://www.edgemiddleeast.com/security/95059-how-artificial-intelligence-can-support-food-security#breadcrumb'}}, {'@type': 'Person', '@id': 'https://www.edgemiddleeast.com/author/bond', 'name': 'ITP Staff', 'description': 'ITP Staff - Author at Edge Middle East . Find the Latest News Stories, Views, Reviews, Comments, Analysis &amp; Updates across Dubai, UAE, Saudi Arabia, Gulf, GCC and Middle East by ITP Staff .', 'url': 'https://www.edgemiddleeast.com/author/bond', 'image': {'@type': 'ImageObject', '@id': 'https://secure.gravatar.com/avatar/7b95d7d5ad8d1541a640eb4264aa91ab?s=96&amp;d=mm&amp;r=g', 'url': 'https://secure.gravatar.com/avatar/7b95d7d5ad8d1541a640eb4264aa91ab?s=96&amp;d=mm&amp;r=g', 'caption': 'ITP Staff', 'inLanguage': 'en-US'}, 'sameAs': ['http://itpnet.itpshare.com'], 'worksFor': {'@id': 'https://www.edgemiddleeast.com/#organization'}}, {'@type': 'NewsArticle', 'headline': 'How artificial intelligence can support food security - Edge Middle East', 'datePublished': '2021-01-10T09:15:00+04:00', 'dateModified': '2021-08-20T12:44:03+04:00', 'articleSection': 'Security', 'author': {'@id': 'https://www.edgemiddleeast.com/author/bond', 'name': 'ITP Staff'}, 'publisher': {'@id': 'https://www.edgemiddleeast.com/#organization'}, 'description': 'Artificial intelligence is a powerful technology that&#039;s driving transformation across every industry and it also has the potential to solve some of humanity&#039;s greatest challenges.. How artificial intelligence can support food security. Artificial Intelligence, data centre, food security, Gitex, Microsoft, Security, UAE. Security.', 'copyrightYear': '2021', 'copyrightHolder': {'@id': 'https://www.edgemiddleeast.com/#organization'}, 'name': 'How artificial intelligence can support food security - Edge Middle East', '@id': 'https://www.edgemiddleeast.com/security/95059-how-artificial-intelligence-can-support-food-security#richSnippet', 'isPartOf': {'@id': 'https://www.edgemiddleeast.com/security/95059-how-artificial-intelligence-can-support-food-security#webpage'}, 'image': {'@id': 'https://www.edgemiddleeast.com/cloud/2021/08/19/shutterstock_1083770003-1.jpg'}, 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://www.edgemiddleeast.com/security/95059-how-artificial-intelligence-can-support-food-security#webpage'}}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmRpY2UuY29tL2NhcmVlci1hZHZpY2Uvd2hpY2gtdGVjaG5vbG9neS1qb2JzLXdpbGwtcmVxdWlyZS1hLWktYW5kLW1hY2hpbmUtbGVhcm5pbmctc2tpbGxz0gEA?oc=5,Which Technology Jobs Will Require A.I. and Machine Learning Skills? - Dice Insights,2021-01-08,Dice Insights,https://www.dice.com,Artificial intelligence (A.I.) and machine learning seem poised to dominate the future of technology jobs. But which jobs will see big impact?,,Artificial intelligence (A.I.) and machine learning seem poised to dominate the future of technology jobs. But which jobs will see big impact?,,https://schema.org/,Article,,"{'@type': 'ImageObject', 'url': 'https://www.dice.com/binaries/large/content/gallery/dice/insights/2020/06/shutterstock_731158624.jpg', 'width': 1200, 'height': 776}","{'@type': 'Person', 'name': 'Nick Kolakowski', 'url': 'https://www.dice.com/about/authors/nick-kolakowski'}","{'@type': 'Organization', 'name': 'Dice', 'url': 'https://www.dice.com', 'logo': 'https://www.dice.com/binaries/content/gallery/dice/icons/dice-logo.svg', 'sameAs': ['https://www.linkedin.com/company/dice', 'https://www.facebook.com/dice', 'https://twitter.com/Dicedotcom', 'https://www.instagram.com/dicedotcom', 'https://www.youtube.com/Dice', 'https://www.facebook.com/DiceforEmployers', 'https://twitter.com/Dice4Employers']}",Which Technology Jobs Will Require A.I. and Machine Learning Skills?,2021-01-08T18:08:00Z,,,,,,Insights,,"
Which Technology Jobs Will Require A.I. and Machine Learning Skills?

                by
                    
                    Nick Kolakowski
                    
Jan 8, 2021
                4 min read
            


Artificial intelligence (A.I.) and machine learning seem poised to dominate the future. Companies everywhere are pouring resources into making their apps and services “smarter.” But which technology jobs will actually require A.I. skills?  
For an answer to that question, we turn to Burning Glass, which collects and analyzes millions of job postings from across the country. Specifically, we wanted to see which professions had the highest percentage of job postings requesting A.I. skills. Here’s that breakdown; as the cliché goes, some of these results may surprise you:   
  
What can we conclude from this breakdown? Although you might think that artificial intelligence skills are very much in demand among software developers and engineers (after all, someone needs to build a smarter chatbot), data science is clearly the profession where A.I. is most in vogue.   
Indeed, there’s a lot of overlap between A.I. and data science. Both disciplines involve collecting, wrangling, cleaning, and analyzing massive amounts of data. But whereas a data scientist will analyze data for insights that they present to the broader organization, artificial intelligence and machine learning experts will use those datasets to train A.I. platforms to become “smarter.” Once sufficiently trained, those platforms can then make their own (hopefully correct) inferences about data.   
Given that intersection of artificial intelligence and data science, many machine-learning and A.I. experts become data scientists, and vice versa. That relationship will likely only deepen in the years ahead. Burning Glass suggests that machine learning is a “defining skill” among data scientists, necessary for day-to-day tasks; if you’re aiming for a job as a data scientist, having extensive knowledge of artificial intelligence and machine-learning tools and platforms can give you a crucial advantage in a crowded market.   
Many other technologist roles will see the need for artificial intelligence skills increase in the years ahead. If you’re involved in software development, for instance, learning A.I. skills now will prepare you for a future in which A.I. tools and platforms are a prevalent element in many companies’ tech stacks. And make no mistake about it: Managers and executives will also need to become familiar with A.I. concepts and skills. “A.I. is not going to replace managers but managers that use A.I. will replace those that do not,” Rob Thomas, senior vice president of IBM’s cloud and data platform, recently told CNBC.  
Overall, jobs utilizing artificial intelligence skills are projected to grow 43.4 percent over the next decade; the current median salary for jobs that heavily utilize A.I. skills is $105,000, higher than for many other professions. It must be noted, though, that A.I. and machine learning are areas where you really need to know your stuff, and hiring managers will surely test you on both your knowledge of fundamental concepts as well as your ability to execute. When applying for A.I.-related jobs, a portfolio of previous projects can only help your prospects.     
Granted, it’s still early days for A.I.: Despite all the hype, relatively few companies have integrated A.I. into either their front-end products or back-end infrastructure. Nonetheless, it’s clear that employers are already interested in technologists who are familiar with the A.I. and machine learning platforms that will help determine the future.   



   Sign Up Today
  
Want more great insights? Create a Dice profile today to receive the weekly Dice Advisor newsletter, packed with everything you need to boost your career in tech. Register now

  
","{'@type': 'WebPage', '@id': 'https://www.dice.com/career-advice/which-technology-jobs-will-require-a-i-and-machine-learning-skills'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vd3d3LmlibS5jb20vYmxvZy9nbS1maW5hbmNpYWwtaW50ZWdyYXRlcy1haS1mb3Itc3VwZXJpb3ItY3VzdG9tZXItc2VydmljZS_SAQA?oc=5,GM Financial integrates AI for superior customer service - IBM,2021-01-08,IBM,https://www.ibm.com,,,"At GM Financial, it’s my job to drive remarkable customer experiences. Answering customers’ questions quickly and accurately is a big part of that. These days, much of our customer care comes in the form of live messages on our customer service app. People text us about things like the status of their remaining loan balances, […]",,https://schema.org,,,,,,,,,,,,,,,"


 







                              Artificial intelligence  
                        


                        July 15, 2024                  


Are bigger language models always better?

  4 min read - As enterprises look to separate the hype from where AI can add true value, it’s unclear if increasingly larger language models will always lead to better business solutions.                        


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.ibm.com/blog/gm-financial-integrates-ai-for-superior-customer-service/', 'url': 'https://www.ibm.com/blogs/watson/2020/08/gm-financial-uses-ibm-watson-assistant-to-develop-a-secure-and-powerful-ai-assistant/', 'name': 'GM Financial integrates AI for superior customer service - IBM Blog', 'isPartOf': {'@id': 'https://www.ibm.com/blog/#website'}, 'primaryImageOfPage': {'@id': 'https://www.ibm.com/blogs/watson/2020/08/gm-financial-uses-ibm-watson-assistant-to-develop-a-secure-and-powerful-ai-assistant/#primaryimage'}, 'image': {'@id': 'https://www.ibm.com/blogs/watson/2020/08/gm-financial-uses-ibm-watson-assistant-to-develop-a-secure-and-powerful-ai-assistant/#primaryimage'}, 'thumbnailUrl': 'https://www.ibm.com/blog/wp-content/uploads/2021/01/WR1346717AS_12.02.20_990x498px.jpg', 'datePublished': '2021-01-08T22:33:33+00:00', 'dateModified': '2021-01-21T17:08:25+00:00', 'author': {'@id': 'https://www.ibm.com/blog/#/schema/person/27a6c8c9cf573927c84922b15b7adaa5'}, 'breadcrumb': {'@id': 'https://www.ibm.com/blogs/watson/2020/08/gm-financial-uses-ibm-watson-assistant-to-develop-a-secure-and-powerful-ai-assistant/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.ibm.com/blogs/watson/2020/08/gm-financial-uses-ibm-watson-assistant-to-develop-a-secure-and-powerful-ai-assistant/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.ibm.com/blogs/watson/2020/08/gm-financial-uses-ibm-watson-assistant-to-develop-a-secure-and-powerful-ai-assistant/#primaryimage', 'url': 'https://www.ibm.com/blog/wp-content/uploads/2021/01/WR1346717AS_12.02.20_990x498px.jpg', 'contentUrl': 'https://www.ibm.com/blog/wp-content/uploads/2021/01/WR1346717AS_12.02.20_990x498px.jpg', 'width': 990, 'height': 498, 'caption': 'WR1346717AS_12.02.20_990x498px'}, {'@type': 'BreadcrumbList', '@id': 'https://www.ibm.com/blogs/watson/2020/08/gm-financial-uses-ibm-watson-assistant-to-develop-a-secure-and-powerful-ai-assistant/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://ibm.com/blog/'}, {'@type': 'ListItem', 'position': 2, 'name': 'GM Financial integrates AI for superior customer service', 'item': ''}]}, {'@type': 'WebSite', '@id': 'https://www.ibm.com/blog/#website', 'url': 'https://www.ibm.com/blog/', 'name': 'IBM Blog', 'description': 'IBM Blog', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.ibm.com/blog/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.ibm.com/blog/#/schema/person/27a6c8c9cf573927c84922b15b7adaa5', 'name': 'J2AI Blog Editor', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.ibm.com/blog/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/45b18e41a00e4bc56f268e32209e1434?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/45b18e41a00e4bc56f268e32209e1434?s=96&d=mm&r=g', 'caption': 'J2AI Blog Editor'}, 'url': 'https://www.ibm.com/blog/author/j2ai-editor/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOmh0dHBzOi8vd3d3LnNraW1hZy5jb20vZ2Vhci9jYXJ2LWFpLXRlY2hub2xvZ3ktZm9yLXNraWVycy_SAQA?oc=5,Review of Carv's Artificial Intelligence Technology for Skiers - Ski Magazine,2021-01-11,Ski Magazine,https://www.skimag.com,"Want to improve your skiing? Carv, an AI app that analyzes your skiing via 48 pressure sensors, can tell you what you're doing well and what needs work when it comes to skiing technique.","['artificial intellegence', 'carv', 'ski app', 'skullcandy']","Want to improve your skiing? Carv, an AI app that analyzes your skiing via 48 pressure sensors, can tell you what you're doing well and what needs work when it comes to skiing technique.",,https://schema.org,NewsArticle,https://www.skimag.com/gear/carv-ai-technology-for-skiers/,"{'@type': 'ImageObject', 'url': 'https://cdn.skimag.com/wp-content/uploads/2019/10/ski1019-news-carve.jpg'}","[{'@type': 'Person', 'name': 'Jenny Wiegand'}]","{'@type': 'Organization', 'name': 'SKI', 'logo': 'https://www.skimag.com/wp-content/uploads/2021/01/cropped-ski.png'}",Skiing in the Digital Age,2019-10-03T04:40:37Z,2021-01-12T00:44:47Z,Gadgets and Tech,,,,,,"




Skiing in the Digital Age

Want to improve your skiing? There's an AI app for that.





    Updated
    Jan 11, 2021

Jenny Wiegand







Facebook Icon





Email Icon































Photo courtesy of Carv 
              















      Heading out the door? Read this article on the new Outside+ app available now on iOS devices for members!
      Download the app.
    

Like many who have skied their entire lives but have rarely seen themselves ski on video, I fancy myself an above-average skier. Carv, however, thought there was room for improvement. According to Carv, an AI ski coach analyzing my skiing via 48 pressure sensors in my ski boots, I do have some carving chops (Carv picked up high edge angles)—but my turns weren’t symmetrical. Through headphones connected to the Bluetooth trackers mounted on the back of my ski boots, Carv let me know mid-run that I was applying uneven and inconsistent pressure in my turns to the right. I course-corrected by pressuring my downhill ski more consistently throughout my next right turn. I was rewarded with a “ding” and “That’s it, nice work!” from Carv.
Launched as a prototype on Kickstarter in 2016 with a 3.0 version set to debut in December 2019, Carv is the brainchild of Jamie Grant, a recreational skier with a background in physics and machine learning who was hungry for concrete ski data to help him improve on the slopes. “I wanted a way to measure technique and understand what I needed to do to improve,” says Grant. “To date, there has been virtually no digital innovation in skiing. As an industry it has been vastly outperformed by other sports such as cycling and golf.”
So Grant and Carv co-developer Pruthvikar Reddy designed a system of smart inserts that fit beneath the liner of any ski boot; a hardware piece that attaches to the cuff of the ski boot and tracks over 35 metrics on every turn; and the Carv app that analyzes your skiing ability, provides real-time audio feedback, and incentivizes you to learn and progress through skill-specific drills and challenges.
“Carv allows anybody to be able to track their skiing, diagnose issues, and improve their technique on their own terms and in their own time,” says Grant. While the idea of an AI ski coach may meet skepticism, it has piqued the interest of ski instructors. “Carv shows the truth about how I stand and move versus how I think I stand and move on skis,” says Michael Rogan, head coach of the Professional Ski Instructors of America alpine demo team. After testing Carv 2.0, Rogan believes Carv could be an effective tool to enhance coaching and learning between instructors and students on the slopes. That said, Carv isn’t a substitute for ski instructors. “Carv gives you a lot of information, almost too much. Trying to make sense of it all can be overwhelming,” says Rogan.

How to Bash Bumps

In other words, Carv gives you a comprehensive diagnosis of your skiing problems, but not a treatment plan as actionable or astute as one you would receive from an instructor IRL. However, if you’re a data nerd, Carv has the potential to get you hooked on the coolest aspect of skiing—technique. At that point, you might as well embrace the nerd.
Digital Slope Tech
Give your ski days a boost with these smart gadgets.
Snowcookie Smart Ski Tracker
 Photo courtesy of Snowcookie
An AI ski monitoring system that tracks and analyzes your skiing via three wireless sensors (one for each ski and one for your body) and spits out all that data via a smartphone app. [$360; snowcookiesports.com]
Phoozy XP3 Thermal Capsule
 Photo credit: Keri Bascetta
This phone case made with NASA-inspired materials prevents the cold from sucking the life out of your phone battery. Bonuses: a stash pocket for cards and cash plus military-grade impact protection. [$50; phoozy.com]

Also available on Amazon: Phoozy XP3 Thermal Capsule

Skullcandy Vert
 Photo courtesy of Skullcandy
These headphones feature a Bluetooth dial that easily clips to your goggle strap for easy, on-the-go phone and music control, even while wearing gloves. [$79; skullcandy.com]

Also available on Amazon: Skullcandy Vert Headphones






















Jenny Wiegand




              Jenny Wiegand is Outside's associate gear director, a job that mandates she test and write about the latest and greatest in gear for a living. While she's a passionate mountain biker, an enthusiastic climber, and a reluctant trail runner, her true love is skiing. Before joining the Outside gear team, she served as the managing editor at SKI.
            








Similar Reads







Let’s Explore the Joys and Pitfalls of Dating a Skier Dude







Everything I Wish I Knew Before Skiing Park City For The First Time







Five Smartwatches that Will Improve Your Skiing Experience







11 Things About Skiing in Europe That Shock Americans











Tags




Artificial Intellegence


Carv


Ski App


Skullcandy










","{'@type': 'WebPage', '@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/'}",2019-10-03T04:40:37Z,,,,,,,,,,,,,,,,,,https://cdn.skimag.com/wp-content/uploads/2019/10/ski1019-news-carve.jpg,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/#article', 'isPartOf': {'@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/'}, 'author': {'name': 'Jenny Wiegand', '@id': 'https://www.skimag.com/#/schema/person/218', '@type': 'Person', 'url': 'https://www.skimag.com/byline/jenny-wiegand/'}, 'headline': 'Skiing in the Digital Age', 'datePublished': '2019-10-03T04:40:37+00:00', 'dateModified': '2021-01-12T00:44:47+00:00', 'mainEntityOfPage': {'@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/'}, 'wordCount': 638, 'publisher': {'@id': 'https://www.skimag.com/#organization'}, 'image': {'@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/#primaryimage'}, 'thumbnailUrl': 'https://cdn.skimag.com/wp-content/uploads/2019/10/ski1019-news-carve.jpg', 'keywords': ['Artificial Intellegence', 'Carv', 'Ski App', 'Skullcandy'], 'articleSection': ['Gadgets and Tech', 'Gear'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/', 'url': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/', 'name': ""Review of Carv's Artificial Intelligence Technology for Skiers"", 'isPartOf': {'@id': 'https://www.skimag.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/#primaryimage'}, 'image': {'@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/#primaryimage'}, 'thumbnailUrl': 'https://cdn.skimag.com/wp-content/uploads/2019/10/ski1019-news-carve.jpg', 'datePublished': '2019-10-03T04:40:37+00:00', 'dateModified': '2021-01-12T00:44:47+00:00', 'description': ""Want to improve your skiing? Carv, an AI app that analyzes your skiing via 48 pressure sensors, can tell you what you're doing well and what needs work when it comes to skiing technique."", 'breadcrumb': {'@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.skimag.com/gear/carv-ai-technology-for-skiers/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/#primaryimage', 'url': 'https://cdn.skimag.com/wp-content/uploads/2019/10/ski1019-news-carve.jpg', 'contentUrl': 'https://cdn.skimag.com/wp-content/uploads/2019/10/ski1019-news-carve.jpg', 'width': 2100, 'height': 1530, 'caption': 'Photo courtesy of Carv'}, {'@type': 'BreadcrumbList', '@id': 'https://www.skimag.com/gear/carv-ai-technology-for-skiers/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Gadgets and Tech', 'item': 'https://www.skimag.com/gadgets-and-tech/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Skiing in the Digital Age'}]}, {'@type': 'WebSite', '@id': 'https://www.skimag.com/#website', 'url': 'https://www.skimag.com/', 'name': 'SKI', 'description': 'Ski Resorts, Skiing Equipment, Ski How-To&#039;s', 'publisher': {'@id': 'https://www.skimag.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.skimag.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.skimag.com/#organization', 'name': 'Ski Magazine', 'url': 'https://www.skimag.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.skimag.com/#/schema/logo/image/', 'url': 'https://cdn.skimag.com/wp-content/uploads/2021/01/ski-logo.png', 'contentUrl': 'https://cdn.skimag.com/wp-content/uploads/2021/01/ski-logo.png', 'width': 1200, 'height': 632, 'caption': 'Ski Magazine'}, 'image': {'@id': 'https://www.skimag.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.skimag.com/#/schema/person/218', 'name': 'Jenny Wiegand', 'url': 'https://www.skimag.com/byline/jenny-wiegand/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihAFodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9ob3ctY29sbGVjdGl2ZS1pbnRlbGxpZ2VuY2UtYW5kLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNhbi1iZW5lZml0LXNvY2lldHnSAY4BaHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2hvdy1jb2xsZWN0aXZlLWludGVsbGlnZW5jZS1hbmQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY2FuLWJlbmVmaXQtc29jaWV0eQ?oc=5,How Collective Intelligence and Artificial Intelligence can Benefit Society - Analytics Insight,2021-01-11,Analytics Insight,https://www.analyticsinsight.net,,"Collective Intelligence and Artificial Intelligence,Collective Intelligence,Artificial Intelligence,Cloud Platform,collective intelligence and AI to benefit society",Combination of collective intelligence and AI impacts Society as a Disruptive Product The great majority of debate about artificial intelligence (AI) starts wit,Combination of collective intelligence and AI impacts Society as a Disruptive Product The great majority of debate about artificial intelligence (AI) starts wit,http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/how-collective-intelligence-and-artificial-intelligence-can-benefit-society,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-7.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Puja Das', 'name': 'Puja Das', 'url': 'https://www.analyticsinsight.net/author/puja-das'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",How Collective Intelligence and Artificial Intelligence can Benefit Society,2021-01-11T03:38:49Z,2021-01-11T03:38:49Z,Artificial Intelligence,How Collective Intelligence and Artificial Intelligence can Benefit Society,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'How Collective Intelligence and Artificial Intelligence can Benefit Society', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/how-collective-intelligence-and-artificial-intelligence-can-benefit-society'}]",,,What is AI and Data Science Engineering? ,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/how-collective-intelligence-and-artificial-intelligence-can-benefit-society'}",2021-01-11T03:38:49Z,,,,,,"Combination of collective intelligence and AI impacts Society as a Disruptive Product.The great majority of debate about artificial intelligence (AI) starts with the capabilities of existing or emergent technologies like machine learning (ML), deep learning, computer vision, and natural language processing (NLP) and asks where these might be used. But an alternative approach turns the question on its head and asks how institutions or systems could be more intelligent. The spread of intelligent machines often coincides with less intelligence at a systems level. How should 'thought' happen at a large scale, involving many people and frequently many machines, to better solve social problems? In particular, let's discuss collective intelligence and AI to benefit society..There's a great potential in AI if handled well, but many of the biggest gains will come from better approaches to combining human and machine intelligence, especially harnessing the intelligence of groups for social purposes..A solar-infused autonomous drone scans for forest fires. A surgeon first operates on a digital heart before the individual picks up a scalpel. Global community bands together are going to print personal protection equipment to fight a pandemic..And this is possible with cloud computing, AI and a virtual 3D design shop or the 3DEXPERIENCE innovation lab. This open innovation laboratory adopts the concept of the social enterprise and merges collective intelligence with a cross-collaborative approach by building communities of people who are passionate and willing to accomplish a common objective..3DEXPERIENCE innovation lab is neither only a software nor only cloud, but it's also a community of people's skills and services available for the marketplace. As technologies are now more accessible, newcomers can also disrupt. And for software companies like Dassault Systèmes, there are unlimited real-world opportunities with the power of collective intelligence, especially when one is bringing together industry experts, healthcare professionals, makers, and scientists to tackle COVID-19 pandemic. This approach could be an interesting way to accelerate, to transfer the know-how, and avoid any mistakes..3DEXPERIENCE Lab program provides those start-ups that impact society as a disruptive product or project aiming to make real impact access to this software and professional solutions that the industry is using in their everyday activities. Because of the cloud platform with its communities, start-ups get access to mentors. And these mentors help them boost their development, providing know-how and knowledge..As 3DExperience Lab creates a way for an enterprise to develop an entire product as a 3D vision, integrating feedback from the research lab, the factory floor, and the customer, all the stakeholders can work in a single environment in the cloud using some apps like CATIA or SolidWorks. They can get done the engineering part of the job on the same data model they would use to perform their own simulations. Any kind of digital simulation helps those people to accelerate the engineering and the design of their product. By following that, they can optimise the design and then go to the manufacturing aspect, delivering all the processes required for programming the machines. It is a standard way to operate..This platform also offers accessibility to services for the marketplace. As early-stage start-ups struggle to find the right partner or the right supplier to manufacture something, they can source components from millions of components that are available through qualified suppliers online at one click of a button..They can access thousands of factories globally, wherein they can produce their parts through those factories, managing all the business online between the two suppliers. They may also have access to engineering services where one wishes to do something, but one doesn't have the skills to do it. Hence the individual then contracts the job to a service bureau or qualified partners that could deliver the job. So it is not only software or cloud but also a community of people's skills and services available for the marketplace..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.","{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/how-collective-intelligence-and-artificial-intelligence-can-benefit-society', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-7.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-7.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPWh0dHBzOi8vZGlzY292ZXIubGFubC5nb3YvbmV3cy8wMTExLXJvc2VuLXNjaG9sYXItZmVsbG93c2hpcC_SAQA?oc=5,"Experimental, theoretical physicists can now apply for Rosen Scholar Fellowship to work at Los Alamos Neutron ... - Discover LANL",2021-01-11,Discover LANL,https://discover.lanl.gov,"Fellowship supports research on neutron scattering, dynamic materials, isotope production, and both applied and basic research in nuclear physics for up to one year","Rosen Scholar Fellowship, Los Alamos Neutron Science Center","Fellowship supports research on neutron scattering, dynamic materials, isotope production, and both applied and basic research in nuclear physics for up to one year","Fellowship supports research on neutron scattering, dynamic materials, isotope production, and both applied and basic research in nuclear physics for up to one year",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vd3d3LnBhc2FkZW5hbm93LmNvbS9tYWluL2NhbHRlY2gtcHJvZmVzc29yLXRvLXNoYXJlLWluc2lnaHRzLW9uLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Caltech Professor to Share Insights on Artificial Intelligence – Pasadena Now - Pasadena Now,2021-01-11,Pasadena Now,https://www.pasadenanow.com,"Daily Newsmagazine and City Guide to Pasadena, California featuring local news, breaking news, events, weather, sports news, schools news, shopping, restaurants and more from Pasadena Now","Pasadena, local news, Los Angeles County news, latest news, Pasadena events, things to do in Pasadena, Pasadena city guide, Pasadena restaurants, breaking news, calendar, lifestyles, community news, nonprofit news, Pasadena shopping news, Pasadena arts and culture, food and drink, popular things to do in Pasadena, Pasadena living, official events calendar, old town Pasadena news",,,,,,,,,,,,,,,,,,"





[print-me target=""#content""]


18 recommended








0 comments




ShareShareTweetSharePin it 




 

Yisong Yue, Caltech professor of computing and mathematical sciences, pictured in an undated photo provided by Caltech.
With the necessary technological precursors now in place, the burgeoning field of artificial intelligence promises to reshape countless aspects of the world as we know it, according to Caltech Professor of Computing and Mathematical Sciences Yisong Yue.
Yue’s inviting the community to join in an online lecture Wednesday to share a bit about what he’s learned in recent years, and where the technology may be headed.
The free lecture is part of Caltech’s Earnest C. Watson Lecture Series and will be held at 5 p.m. via Zoom.
“I have been studying various aspects of machine learning and artificial intelligence, in particular, now that the technology has been maturing,” Yue said. “How do we identify, expose, characterize and then address all the challenges related to getting machine learning deployed and working in various real-world settings that arise in the sciences and the engineering?”
At the Watson lecture, Yue said he was looking forward to chatting with the public “about some of the lessons that I’ve learned. Some of those are success stories and some are the challenges that remain in this quest.”
Both computing power and data collection have advanced to levels capable of supporting meaningful A.I., he said.
And the third one is, of course, better algorithm and better and better approaches,” according to Yue. “That’s really my bread and butter. That’s the part that I help out with the most: new software designs and algorithms to address these new modalities that people want to apply machine learning, artificial intelligence to.”
Yue said he expected to see some major developments in the field in the near future.
“It’s a long path from basic science to what ends up being a sustainable commercial enterprise. That long path is part of what makes it hard to predict,” he said. “But I’m very optimistic that in the next 10 to 20 years, we’ll see some things that are very unexpected.”
At its core, A.I. focuses on teaching machines to think for themselves in order to solve problems for humans, Yue explained.
“Rather than having a human figure out every little detail by hand, the A.I. would just do it automatically from collecting lots of data,” he said.
At Caltech’s Center for Autonomous Systems and Technology lab, or CAST, for example, scientists have applied A.I. to design new types of robotics controllers, Yue said.
Robots in the past are, for lack of a better term, robotic,” he said. “They’re rigid and not flexible. And one of the reasons why they’re rigid and not flexible is because the way you write down the governing models are just so approximate that you can’t do anything flexible. And so A.I. gives an opportunity to be able to very cost-effectively build these flexible models for robotics that were not possible before.”
Potential applications are limited only by the imagination, from swarms of drones working as teams to deliver packages or extinguish fires, to new ways to develop materials, to self-driving cars and other autonomous vehicles, he said. “I think that in the foreseeable future, every field will be impacted by A.I.”
But like with any new and powerful technology, there are ethical considerations that will need to be addressed, in addition to scientific ones.
“I think it’s important to recognize that whenever we have a transformative technology, it can both be used for good and be misused for harm,” Yue said. “If you make it really cheap to design new materials, you can make it really cheap to design new bioweapons, potentially.”
“These technologies are very transformative and I’m very excited about their potential, but I think it’s important to recognize that as we think about the transformative potential of these technologies and we understand how they may be used for harm and we try to figure out a solution as a society,” he said. “Understanding how an A.I. system can be misused or can make mistakes, and just having a better understanding of how A.I. works, is going to be beneficial for everyone.”
Those interested in participating in Wednesday’s online lecture are asked to register online at caltech.zoom.us/webinar/register/WN_rnALVguDQxyKTvh9X9xdUQ.






 Get our daily Pasadena newspaper in your email box. Free.
Get all the latest Pasadena news, more than 10 fresh stories daily, 7 days a week at 7 a.m.


Subscribe






 










Make a comment

Your email address will not be published. Required fields are marked *

Name (required) 
Mail (required) (not be published) 
Website 




 

	   





 
 
 
 
 
 









More Cool Stuff
Washington Woman Reveals Her Secret To Earning $1k/Day From HomeBirch GoldLook For Any High School Yearbook, It's FreeClassmatesVet Warns: ""If Your Dog Licks Its Paws, Watch This Immediately""Nutra CompleteAverage Nurse Salary In 2024 Is Just Mind Blowing (See List)Search AdsRam 1500 For Seniors May Take You By Surprise. (See Prices)Search AdsSeniors Free Car Insurance Based On Their Age (Take A Look)Search AdsDistrict of Columbia Introduces New Rules for Senior DriversAuto InsuranceDrone Captures Something Nobody Was Supposed To See In District of ColumbiaHappyinshapeBarron And His Girlfriend, Who You Will Easily RecognizeBuzz DayWashington: Unsold Repossessed Cars Sell For Almost NothingSearch AdsThe All-New, Mind Blowing Hyundai Palisade Is Finally Here!Search AdsWarning Signs Of Psoriatic Arthritis (Don't Ignore The Symptoms)Search AdsHidden Signals You Have Dementia. Take The Quiz NowSearch AdsWe Can't Believe Melania Trump Actually Did This!Buzz DayNew Retirement Village In Washington (Take A Look At The Prices)Search Ads




Top of the News  



Government


STAFF REPORT
Pasadena City Council Moves to Revise Controversial Noise Ordinance






Government


BY EDDIE RIVERA
Councilmember-elect Cole Leads Public Safety Panel Discussion






Government


STAFF REPORT
Pasadena’s Zoning Code Gets a Facelift






faithfernandez More »
ShareTweetShare on Google+Pin on PinterestSend with WhatsApp





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiJ2h0dHBzOi8vd3d3LmlibS5jb20vdG9waWNzL2luZHVzdHJ5LTQtMNIBAA?oc=5,What is Industry 4.0? - IBM,2021-01-07,IBM,https://www.ibm.com,"Industry 4.0 is the realization of digital transformation in the field, delivering real-time decision making, enhanced productivity, flexibility and agility.",Industry 4 0,"Synonymous with smart manufacturing, Industry 4.0 is the realization of the digital transformation of the field, delivering real-time decision making, enhanced productivity, flexibility and agility.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRWh0dHBzOi8vYnVpbHRpbi5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvbGFuZC1tb3JlLWludGVydmlld3Mtam9ic9IBAA?oc=5,What to Know About an ATS to Land More Interviews - Built In,2021-01-08,Built In,https://builtin.com,"If you’ve ever applied for a job that seems like a great fit and heard nothing back, you may be a victim of applicant tracking systems (ATS). Here’s what you need to know to navigate them and increase your chances of getting the job.",,"If you’ve ever applied for a job that seems like a great fit and heard nothing back, you may be a victim of applicant tracking systems (ATS). Here’s what you need to know to navigate them and increase your chances of getting the job.","If you’ve ever applied for a job that seems like a great fit and heard nothing back, you may be a victim of applicant tracking systems (ATS). Here’s what you need to know to navigate them and increase your chances of getting the job.",https://schema.org,,,,,,,,,,,,,,,"

























Companies have been using applicant tracking systems (ATS) since the 1990s, but most job seekers still don’t understand what happens between the time they upload a resume and the time when it’s finally viewed by a recruiter or hiring manager.
When I found myself on the job hunt back in 2013, I spent hours each day submitting my resume online but wasn’t hearing back. Job seekers refer to this as the “resume black hole.” So, I started investigating and discovered that the online portals used for hiring — ATS — were simply parsing resumes, and recruiters were searching resumes based on keywords and skills.
In order to get more interviews, I knew I would have to carefully tailor each and every resume to the job description with ATS in mind. I built the first version of Jobscan to help myself automate the process of seeing which skills and keywords were featured in the job description but weren’t on my resume.
It turns out, millions of job seekers needed the same help.
 
Why Applicant Tracking Systems Exist
Virtually all Fortune 500 companies use ATS as part of their hiring process. Top employers have several open positions across multiple departments at any given time. And because applying for jobs online is now easier than ever, each of these job openings gets flooded with hundreds if not thousands of applicants, many of whom are not qualified.
ATS helps to organize and sort the applicants for a company’s team of recruiters and hiring managers. And it’s not just Fortune 500. At Jobscan, we often receive over 500 applicants per open position, which our small recruiting team couldn’t handle without the help of a powerful ATS.
With ATS, recruiters and hiring managers can efficiently narrow down the applicant pool. Unfortunately, the systems aren’t perfect, which means well-qualified candidates can slip through the cracks.
 
How Applicant Tracking Systems Work
ATS collect and store resumes in a database accessible by the company’s hiring professionals. There are dozens of popular ATS in the marketplace, and they all behave a little bit differently, but here are a few ways recruiters use ATS to interact with your resume:
Viewing Applications
Most recruiters still manually skim as many incoming resumes as possible. Experienced recruiters can rule out applicants in a matter of seconds. They scan your resume for hard skills, job titles, accomplishments and notable companies. If they don’t see what they need at a glance, they’ll move on to the next applicant. Because of this, it’s important for job seekers to make sure their most relevant skills and qualifications can be easily identified.
Keyword Searches
Recruiters can filter through the applicants by searching for job titles and key skills. For example, if a recruiter is overwhelmed by 700 applications for a product manager position, they might start by searching for “Product Manager” to eliminate anyone who hasn’t held the exact job title in the past. Then, they can take the filtering a step further by searching for hard skills and softwares critical to the role, like InVision for prototyping or Asana for prioritization.
Automatic Rankings
Some ATS can even automatically compare your resume to the job description. For example, Taleo, one of the most popular ATS among Fortune 500 companies, has a feature called “Req Rank” that stack ranks each applicant based on how well their resume scores against the job description. That way, instead of reviewing every single application, a recruiter could choose to focus on candidates the ATS identified as a great match.
 
How to ‘Beat’ Applicant Tracking Systems
What’s the common thread between a recruiter manually skimming an application, searching their ATS or utilizing an automated ranking algorithm?
Job titles, skills and keywords.
And what’s the easiest way to figure out which keywords the recruiter and/or ATS algorithms are targeting?
The job description.
Identify the specific skills and qualifications mentioned in the job description and add them to your resume when appropriate. (This should go without saying, but don’t lie about your qualifications!) If a skill or keyword is mentioned multiple times in the job description, it’s probably important. Mention the same skill multiple times in your resume.
Career coaches used to tell job seekers to print out the job description and use a highlighter to identify skills and keywords. Now, this process has been automated by Jobscan through the use of AI and machine learning algorithms.
The other aspect of creating an ATS-friendly resume is to pay close attention to formatting. Here are three common formatting traps to avoid:
Don’t use a resume template that has tables or columns. Most ATS scan your resume from top-to-bottom, left-to-right, no matter what. This causes unreadable parsing errors when the ATS attempts to import your resume information into a digital applicant profile.
	 
Use common section headings like “Work Experience” and “Education” rather than trying to be cute or creative. ATS are programmed to parse out experience based on expected section headings, so anything out of the ordinary could cause a parsing error.
	 
For skills and qualifications that have a common acronym, spell it out and include the acronym to maximize searchability. For example, “generally accepted accounting principles (GAAP)” or “customer experience (CX).”
You don’t have to get lost in the applicant tracking system’s black hole. Make ATS work for you by tailoring your resume with targeted keywords from the job description. That’s how you get to the top of the list and one step closer to your dream job.
Stick Around and Read Some MoreWhat Your Workplace May Be Missing — Humanity



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@context': 'https://schema.org', '@type': 'Article', 'headline': 'What You Should Know About an Applicant Tracking System (ATS) to Land More Interviews — and Jobs', 'name': 'What You Should Know About an Applicant Tracking System (ATS) to Land More Interviews — and Jobs', 'description': 'Companies have been using applicant tracking systems (ATS) since the 1990s, but most job seekers still don’t understand what happens between the time they upload a resume and the time when it’s finally viewed by a recruiter or hiring manager.', 'image': {'@type': 'ImageObject', 'url': 'https://builtin.com/sites/www.builtin.com/files/duotone%2520%252853%2529_0.png', 'representativeOfPage': True}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://builtin.com/artificial-intelligence/land-more-interviews-jobs', 'name': 'What You Should Know About an Applicant Tracking System (ATS) to Land More Interviews — and Jobs'}, 'url': 'https://builtin.com/artificial-intelligence/land-more-interviews-jobs', 'about': [{'@type': 'Thing', 'name': 'Expert Contributors'}, {'@type': 'Thing', 'name': 'Artificial Intelligence'}, {'@type': 'Thing', 'name': ""Editors' Picks""}, {'@type': 'Thing', 'name': 'Machine Learning'}, {'@type': 'Thing', 'name': 'Job Descriptions'}], 'author': {'@type': 'Person', '@id': 'https://builtin.com/authors/james-hu', 'name': 'James Hu', 'description': 'Founder and CEO, Jobscan;&nbsp;formerly&nbsp;co-founder of&nbsp;a carpooling startup in Asia and&nbsp;product manager at Kabam Games, Groupon&nbsp;and Microsoft.\r\n', 'jobTitle': 'Founder and CEO, Jobscan', 'url': 'https://builtin.com/authors/james-hu'}, 'datePublished': '2021-01-08T04:45:00+00:00', 'publisher': {'@type': 'Organization', '@id': 'https://builtin.com', 'name': 'Built In', 'url': 'https://builtin.com', 'sameAs': ['https://www.facebook.com/BuiltInHQ/', 'https://twitter.com/builtin', 'https://www.instagram.com/builtin/', 'https://www.linkedin.com/company/built-in'], 'brand': {'@type': 'Brand', 'name': 'Built In'}, 'logo': {'@type': 'ImageObject', 'url': 'https://static.builtin.com/dist/images/built-logo.png', 'representativeOfPage': True}}}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RoZS1lbmRsZXNzLW9wcG9ydHVuaXRpZXMtYW5kLWZldy1jaGFsbGVuZ2VzLW9mLW11bHRpbW9kYWwtYWnSAYABaHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RoZS1lbmRsZXNzLW9wcG9ydHVuaXRpZXMtYW5kLWZldy1jaGFsbGVuZ2VzLW9mLW11bHRpbW9kYWwtYWk?oc=5,The Endless Opportunities and Few Challenges of Multimodal AI - Analytics Insight,2021-01-09,Analytics Insight,https://www.analyticsinsight.net,,"Multimodal Learning,AI information sources,Artificial Intelligence,Multimodal AI,Multimodal learning and AI","When Artificial Intelligence is changing the way people live, utilizing the multimodal approach can see and perceive outer situations. Billions of petabytes of ","When Artificial Intelligence is changing the way people live, utilizing the multimodal approach can see and perceive outer situations. Billions of petabytes of ",http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/the-endless-opportunities-and-few-challenges-of-multimodal-ai,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-6.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Priya Dialani', 'name': 'Priya Dialani', 'url': 'https://www.analyticsinsight.net/author/priya-dialani'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",The Endless Opportunities and Few Challenges of Multimodal AI,2021-01-09T03:00:24Z,2021-01-09T03:00:24Z,Artificial Intelligence,The Endless Opportunities and Few Challenges of Multimodal AI,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Endless Opportunities and Few Challenges of Multimodal AI', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/the-endless-opportunities-and-few-challenges-of-multimodal-ai'}]",,,What is AI and Data Science Engineering? ,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/the-endless-opportunities-and-few-challenges-of-multimodal-ai'}",2021-01-09T03:00:24Z,,,,,,"When Artificial Intelligence is changing the way people live, utilizing the multimodal approach can see and perceive outer situations..Billions of petabytes of data move through AI devices consistently. Nonetheless, at this moment, the vast majority of these AI devices are working independently of one another. However, as the volume of data moving through these gadgets increments in the coming years, technology organizations and implementers should sort out a path for every one of them to learn, think, and work together to genuinely harness the potential that AI can deliver..An interesting report by ABI Research envisions that while the total installed base of AI devices will increase from 2.69 billion in 2019 to 4.47 billion out of 2024, nearly not many will be interoperable temporarily. Instead of consolidating the gigabytes to petabytes of data coursing through them into a single AI model or framework, they'll work independently and heterogeneously to sort out the data they're fed..Derived from the Latin words 'multus' which means numerous and 'modalis' which means mode, multimodality, with regards to human perception, is basically that the capacity to use various multiple sensory modalities to encode and decode external surroundings. At the point when joined, they make a united, singular perspective on the world..Multimodal perception rises above the universe of innovation. When applied to Artificial Intelligence explicitly, joining different AI information sources into one model is known as Multimodal Learning..In contrast to conventional unimodal learning frameworks, multimodal systems can convey correlative data about one another, which will possibly become evident when they are both included in the learning cycle. In this manner, learning-based techniques that consolidate signals from various modalities are fit for creating more robust inference, or even new insights, which would be inconceivable in a unimodal framework..Multimodal learning presents two essential advantages:.Firstly, numerous sensors observing the same data can make more strong forecasts, since recognizing changes in it may be possible when the two modalities are available. Secondly, the combination of numerous sensors can encourage the capture of complementary information or trends that may not be caught by individual modalities..With its visual dialogue framework, Facebook would have all the earmarks to be pursuing a digital assistant that copies human partners by reacting to pictures, messages, and messages about pictures as normally as an individual may. For instance, given the brief &quot;I need to get a few seats — show me earthy colored ones and enlighten me regarding the materials,&quot; the assistant may reply with a picture of earthy colored seats and the content &quot;How would you like these? They have a strong earthy colored tone with a foam fitting.&quot;.In the automotive space, multimodal learning is being presented with Advanced Driver Assistance Systems (ADAS), In-Vehicle Human Machine Interface (HMI) associates, and Driver Monitoring Systems (DMS) for real-time inferencing and forecast..Robotics vendors are fusing multimodal systems into robotics HMIs and movement automation to widen customer appeal and give more noteworthy collaboration among laborers and robots in the industrial space..Similarly, as we have set up that human perception is emotional, the equivalent can be said for machines. In a time when AI is changing the way people live and work-AI, utilizing the multimodal approach, can see and perceive outer situations. Simultaneously, this methodology imitates the human way to deal with perception, including imperfections as well..All the more explicitly, the advantage is that machines can replicate this human way to deal with the perception of external scenarios. However, certain AI technology can see data up to 150x faster than a human (in corresponding with a human guard)..With this new turn of events, we are drawing nearer to mirroring human insight, and well, the possibilities are endless..There's only one issue. Multimodal systems get on inclinations in datasets. The variety of questions and ideas engaged with assignments like VQA, as well as the absence of great data, regularly keep models from figuring out how to &quot;reason,&quot; driving them to make educated guesses by depending on dataset statistics..The solution will probably include bigger, more comprehensive training datasets. A paper published by engineers at École Normale Supérieure in Paris, Inria Paris, and the Czech Institute of Informatics, Robotics, and Cybernetics proposes a VQA dataset made from millions of narrated videos. Comprising naturally produced sets of questions and answers from transcribed recordings, the dataset dispenses with the requirement for manual annotation while empowering strong performance on well-known benchmarks, as per the analysts..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.","{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/the-endless-opportunities-and-few-challenges-of-multimodal-ai', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-6.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-6.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2xhdGVzdC1uZXdzL2lzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRoZS1mdXR1cmUtb2YtcGVyZnVtZdIBZ2h0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9sYXRlc3QtbmV3cy9pcy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS10aGUtZnV0dXJlLW9mLXBlcmZ1bWU?oc=5,Is Artificial Intelligence the Future of Perfume? - Analytics Insight,2021-01-11,Analytics Insight,https://www.analyticsinsight.net,,"Artificial intelligence in fragrance,Using machine learning in Fragrance ,Benefit of AI for fragrance manufacturing,AI in Fragrance,Machine Learning in Fragrance Industry","One of the most significant benefits of AI for fragrance manufacturing is the ability to easily recommend alternative formulations. For the fragrance industry, ","One of the most significant benefits of AI for fragrance manufacturing is the ability to easily recommend alternative formulations. For the fragrance industry, ",http://schema.org,NewsArticle,https://www.analyticsinsight.net/latest-news/is-artificial-intelligence-the-future-of-perfume,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/sillages-paris_aude-lemoine-scaled.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Monomita Chakraborty', 'name': 'Monomita Chakraborty', 'url': 'https://www.analyticsinsight.net/author/monomita-chakraborty'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",Is Artificial Intelligence the Future of Perfume?,2021-01-11T11:31:24Z,2021-01-11T11:31:24Z,Latest News,Is Artificial Intelligence the Future of Perfume?,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Latest News', 'item': 'https://www.analyticsinsight.net/latest-news'}, {'@type': 'ListItem', 'position': 3, 'name': 'Is Artificial Intelligence the Future of Perfume?', 'item': 'https://www.analyticsinsight.net/latest-news/is-artificial-intelligence-the-future-of-perfume'}]",,,What is AI and Data Science Engineering? ,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/latest-news/is-artificial-intelligence-the-future-of-perfume'}",2021-01-11T11:31:24Z,,,,,,"One of the most significant benefits of AI for fragrance manufacturing is the ability to easily recommend alternative formulations..For the fragrance industry, artificial intelligence and data-driven algorithms represent a new age that is being developed by machine learning..For use by both customers and industry professionals, a range of top fragrance developers have built and introduced their own in-house AI platforms as well as digital reference directories. According to Perfumer Flavorist, &quot;Givaudan created Carto, an AI scent creation tool which allows perfumers to develop their formulas with the help of Givaudan's Odor Value Map; Eve, an AI inspired tool used to create products based on the requests and capabilities of the customer; and, also, opened a digital factory in Paris.&quot; .One of the most significant benefits of AI for fragrance manufacturing is the ability to easily recommend alternative ingredients or formulations. The fragrance industry is currently addressing many cultural forces, such as the development of natural or 'clean' fragrances that reduce the use of synthetic ingredients, as well as the effects of raw ingredients from natural calamities or deforestation/desertification..There is also a first-ever AI-made fragrance, called Philyra, which was developed as a collaboration between IBM and Symrise, a major supplier of flavors and fragrances, available in Brazil..Philyra is capable of learning about formulas, raw materials, historical performance data, market trends and is being produced by perfumer David Apel to create new fragrances for one of the world's top beauty companies, the Brazilian cosmetics business called O Boticário..Philyra uses a number of modern and sophisticated machine learning algorithms to recognize various trends and perfume combinations quickly by going through hundreds of different perfume formulas and raw materials. This then also allows it to design completely new fragrance formulas..As AI can beat nothing in terms of data work, IBM researchers have used data-based methods to use the information on the formats, fragrance families, raw materials, and background data on fragrances and formulations that were previously designed. The algorithm for machine learning creates new variations of these equations that were customized to the demographic and character of the consumer..The entire framework is focused on machine learning, and IBM &amp; Symrise researchers aim to introduce AI perfume technology to the world. In addition, the device can also be used for other forms of applications, including the creation of flavors, cosmetics, and household goods, such as washing products and detergents..In the production of new fragrances, it seems probable that solutions like Philyra will become standard instruments. Since Symrise will eventually have the competitive advantage of analyzing data and learning machinery, the business must increasingly employ knowledge and data capital. The company is unique in terms of creating proprietary software, with its large database of fragrances, which help it gain a competitive edge. The collaborative effort of data scientists and perfumers appears to be just a continuity of art and science which have produced fragrances since prehistoric times. While IBM's collaboration has been used to draw publicity, AI technology will be used behind the curtain for generations to come to maintain the enchantment that embraces our preferred fragrances..NINU, the world's 1st SMART perfume (patent-pending), with an AI-driven app, is another recent example. It was inspired by Peter Florjančič, the greatest innovator in the history of perfume. NINU has also been named as a tribute to the first two recorded perfumers in the world..In the traditional perfume industry, NINU is a fresh breeze. It respects the tradition and builds on a centuries-old legacy by leveraging the latest technological advances. It enables you to find your scent and play with it by integrating three distinct high-quality fragrances in a single high-tech interface. This is a simple and patent-pending invention that helps you to adapt your perfume to match all moods and occasions. Their goal is to give vibrance (and new dimensions) each day..What makes NINU intelligent is an AI-guided application that delivers every drop of your precious perfume and an electronic micro precision extracting device. It embarks on a journey of perfume fusion led by Pierre, the AI perfume master. With only a few quick taps on your phone, he will take care of your every request. You've got total power over your fragrance. And he will tell you to restore it exactly when you start running out. You can still find something for yourself with over a million different fragrances to choose from. They believe that something special is created when beauty and technology fuse together..Every year, the global cosmetics industry produces 120 billion packaging units, which means 12 billion tonnes of plastic by 2050, if the trend continues. It is also earth-friendly since it uses natural ink in packaging cartons, has a cartridge refill mechanism, and less packaging to minimize the use of plastic. Perfume bottles are made of recycled glass as well. NINU is on a quest to make the perfume industry more user-friendly and greener..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.","{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/latest-news/is-artificial-intelligence-the-future-of-perfume', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/sillages-paris_aude-lemoine-scaled.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/sillages-paris_aude-lemoine-scaled.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRWh0dHBzOi8vd3d3Lm1hcGZyZS5jb20vZW4vaW5zaWdodHMvaW5ub3ZhdGlvbi9haS1wZW9wbGUtZGlzYWJpbGl0aWVzL9IBAA?oc=5,Can Artificial Intelligence make life easier for people with disabilities? - Web corporativa | MAPFRE,2021-01-18,Web corporativa | MAPFRE,https://www.mapfre.com,,,,,https://schema.org,,,,,,,,,,,,,,,"INNOVATION| 18.01.2021Can Artificial Intelligence make life easier for people with disabilities? Redacción MAPFRE   @mapfre “Technology has changed the world, bringing knowledge within reach and expanding a range of opportunities. Persons with disabilities can benefit enormously from such advances, yet too many lack access to these essential tools.” These words were spoken by former UN Secretary-General Ban Ki-moon in 2014, and remain as relevant today as they did then. Ban Ki-moon also pointed out that technology could help people with disabilities to harness their full potential within their communities and workplaces, and make the most of their capabilities. Six years later, advances have been made, and technologies such as Artificial Intelligence have made major steps forward, so much so that it is shaping up to be a key tool for including people with disabilities in a society that tends to segregate them. Inclusion versus exclusionThis is precisely the most important issue when it comes to technology and disability. There is no doubt that advances greatly help people who suffer from physical, sensory or mental disabilities (the many examples of which will be covered later), however, it is also true that this same technology can oftentimes end up excluding these people even more if they are not taken into account.According to the article, ‘Inteligencia Artificial y Personas con Discapacidad desde una visión exigente de derechos humanos’ (Artificial Intelligence and People with Disabilities from a Demanding View of Human Rights) by the Comité Español de Representantes de Personas con Discapacidad (CERMI — Spanish Committee of Representatives of Persons with Disabilities), there are risks involved when using Artificial Intelligence, as they detected “discrimination against social groups whose rights such as gender, race or immigration situation are more exposed to being violated,” to which they also added that “recent studies show that people with disabilities, both women and men, are not alien to this phenomenon, very often through multiple and cross-sectional discrimination.”“Discriminatory” Artificial IntelligenceCERMI points out both the main dangers of exclusive use of AI and the great benefits of inclusive use, i.e. encouraging separation or evolving toward ever-increasing inclusion.The risks include:Using AI systems to justify genetic selection of people without disabilities.Identifying or discriminating against people with disabilities.Creating systems based on standardization models that exclude or do not take into account the needs, opinions and diversity of people with disabilities.Designing AI systems based on data that includes stereotypes, biases and prejudices relating to disability.Using systems that do not allow people with disabilities to make decisions by themselves or through their representative organizations.Joan Pahisa, who has a PhD in Computer Science and is an expert in Accessible Technology and R&D at Fundación ONCE, also spoke about this potential reality, stating that both technology in general and AI in particular tend to succumb to society’s usual prejudices. The fact is, if programmers are barely even aware of the reality of people with disabilities, the resulting Artificial Intelligence will suffer from that capacity to learn, so it will end up excluding people with disabilities.Inclusive Artificial IntelligenceDespite these logical fears, new technologies undoubtedly provide a fantastic opportunity to improve the lives of people with disabilities.CERMI points out numerous benefits, of which the following are most notable:Facilitating access to information and communication itself in all media and formats.Facilitating decision-making.Improving accessibility in the environment.Programming robots that facilitate personal assistance.Automotive AI systems.Improved health care and habilitation and rehabilitation services.In addition to highlighting some risks, the aforementioned Joan Pahisa also mentioned the great potential that AI has through examples such as “algorithms that read texts and recognize images, devices that transcribe conversations for people with hearing difficulties, home automation that allows you to control the lights, remote window blinds and thermostats, assistive robots and countless other solutions that already facilitate independence for many people.”In-depth analysisIn fact, many projects are currently underway around the world, as Artificial Intelligence applications have enormous potential for people with all kinds of disabilities (visual, auditory, cognitive, mobility, learning, etc.).There are many examples in this regard. One such example is in Poland, where a project named INSENSION has been developed that aims to better understand the needs of people with multiple and severe intellectual disabilities. An Artificial Intelligence system analyzes each person through audio and video and deciphers what each movement, gesture or sound means. This helps their caregivers, who can then better care for their patients.AccessibilityAnother example is the initiative launched by Microsoft in 2018, AI for Accessibility, which identifies projects aimed at improving accessibility for people with disabilities.AI for Accessibility focuses on three key areas:Employment, given that “the unemployment rate is more than twice as high for people with disabilities.”Daily life, where they see “great opportunities in building modern solutions for people with disabilities by making software and devices smarter and more contextually relevant.”Communication, which “is fundamental to providing equal access to information and opportunities.” Working environmentAs for progress in the working environment, the Adecco Foundation and Keysight created the Fourth Technology and Disability Report, according to which new technologies have improved the overall quality of life of six out of ten people with disabilities.What’s more, the report also claims that “new generations are facing a professional future in which they can work, breaking the outdated tradition that associates people with disabilities with inactivity and dependence.”Technology has helped people with disabilities to be able to hold job positions that they previously never used to, with everything that this entails in terms of social exclusion and the loss of assets with great capabilities.As Mike Hess, a US-based entrepreneur and founder of The Blind Institute of Technology, put it in an interview where he showed no hesitation in describing losing his sight as an inconvenience, nothing more: “I’m married, I’m a father to three children, I’ve competed in martial arts, I ski, climb mountains and I’ve had a successful 20-year career in the tech industry.”An untapped resourceIn fact, Mike Hess is certain that “people with disabilities are the greatest untapped resource on the planet: we are the perfect candidates for what I call ‘desk jockey’ type jobs. Today’s technology is so accessible, and people with disabilities are extremely productive and loyal employees. In some ways, they are more productive than sighted people.”After all, pointed out in each product made at the Centro Don Orione de Posada de Llanes (in Spain), it is the result of a “job done by a person with a disability and many other abilities.” And now, through new technologies, these many other abilities can be developed more easily.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/#article', 'isPartOf': {'@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/'}, 'author': {'name': 'Redacción MAPFRE', '@id': 'https://www.mapfre.com/en/#/schema/person/9413341f1ee1d43f65c7b8105adbb364'}, 'headline': 'Can Artificial Intelligence make life easier for people with disabilities?', 'datePublished': '2021-01-18T09:29:09+00:00', 'dateModified': '2021-02-05T11:50:37+00:00', 'mainEntityOfPage': {'@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/'}, 'wordCount': 3095, 'commentCount': 0, 'publisher': {'@id': 'https://www.mapfre.com/en/#organization'}, 'image': {'@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/#primaryimage'}, 'thumbnailUrl': 'https://www.mapfre.com/media/personas-discapacidad.jpg', 'articleSection': ['Innovation', 'Sustainability'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/', 'url': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/', 'name': 'Can Artificial Intelligence make life easier for people with disabilities?', 'isPartOf': {'@id': 'https://www.mapfre.com/en/#website'}, 'primaryImageOfPage': {'@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/#primaryimage'}, 'image': {'@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/#primaryimage'}, 'thumbnailUrl': 'https://www.mapfre.com/media/personas-discapacidad.jpg', 'datePublished': '2021-01-18T09:29:09+00:00', 'dateModified': '2021-02-05T11:50:37+00:00', 'breadcrumb': {'@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/#primaryimage', 'url': 'https://www.mapfre.com/media/personas-discapacidad.jpg', 'contentUrl': 'https://www.mapfre.com/media/personas-discapacidad.jpg', 'width': 736, 'height': 676}, {'@type': 'BreadcrumbList', '@id': 'https://www.mapfre.com/en/insights/innovation/ai-people-disabilities/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.mapfre.com/en/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Can Artificial Intelligence make life easier for people with disabilities?'}]}, {'@type': 'WebSite', '@id': 'https://www.mapfre.com/en/#website', 'url': 'https://www.mapfre.com/en/', 'name': 'MAPFRE', 'description': '', 'publisher': {'@id': 'https://www.mapfre.com/en/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.mapfre.com/en/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.mapfre.com/en/#organization', 'name': 'MAPFRE', 'url': 'https://www.mapfre.com/en/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.mapfre.com/en/#/schema/logo/image/', 'url': 'https://www.mapfre.com/media/logo-mapfre.png', 'contentUrl': 'https://www.mapfre.com/media/logo-mapfre.png', 'width': 160, 'height': 19, 'caption': 'MAPFRE'}, 'image': {'@id': 'https://www.mapfre.com/en/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/MAPFRE.ES/', 'https://x.com/MAPFRE', 'https://www.instagram.com/mapfre/']}, {'@type': 'Person', '@id': 'https://www.mapfre.com/en/#/schema/person/9413341f1ee1d43f65c7b8105adbb364', 'name': 'Redacción MAPFRE', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.mapfre.com/en/#/schema/person/image/', 'url': 'https://www.mapfre.com/media/redaccion-mapfre-150x150.jpg', 'contentUrl': 'https://www.mapfre.com/media/redaccion-mapfre-150x150.jpg', 'caption': 'Redacción MAPFRE'}, 'sameAs': ['https://x.com/mapfre']}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMjEvMy1xdWVzdGlvbnMtdGhvbWFzLW1hbG9uZS1kYW5pZWxhLXJ1cy1ob3ctd29yay13aWxsLWNoYW5nZS1haS0wMTIx0gEA?oc=5,3 Questions: Thomas Malone and Daniela Rus on how AI will change work - MIT News,2021-01-21,MIT News,https://news.mit.edu,MIT professors Thomas Malone and Daniela Rus answer three questions about their brief &quot;Artificial Intelligence and the Future of Work.” ,"MIT Task Force on the Work of the Future, Massachusetts Institute of Technology, MIT, MIT News, Thomas Malone, Daniela Rus, Robert Laubacher, 3 questions, artificial intelligence, workforce, MIT Center for Collective Intelligence, Superminds, human-computer groups, reskilling",MIT professors Thomas Malone and Daniela Rus answer three questions about their brief &quot;Artificial Intelligence and the Future of Work.” ,,,,,,,,,,,,,,,,,"


MIT Task Force on the Work of the Future releases research brief ""Artificial Intelligence and the Future of Work.""




MIT Task Force on the Work of the Future


 Publication Date:
 January 21, 2021












 Caption:
          Thomas Malone (left) is director of the MIT Center for Collective Intelligence and the Patrick J. McGovern Professor of Management. Daniela Rus is director of the Computer Science and Artificial Intelligence Laboratory, the Andrew and Erna Viterbi Professor of Electrical Engineering and Computer Science, and a member of the MIT Task Force on the Work of the Future. Not pictured: Robert Laubacher, associate director of the MIT Center for Collective Intelligence.      
          



















Previous image
Next image






















As part of the MIT Task Force on the Work of the Future’s series of research briefs, Professor Thomas Malone, Professor Daniela Rus, and Robert Laubacher collaborated on ""Artificial Intelligence and the Future of Work,"" a brief that provides a comprehensive overview of AI today and what lies at the AI frontier. 

The authors delve into the question of how work will change with AI and provide policy prescriptions that speak to different parts of society. Thomas Malone is director of the MIT Center for Collective Intelligence and the Patrick J. McGovern Professor of Management in the MIT Sloan School of Management. Daniela Rus is director of the Computer Science and Artificial Intelligence Laboratory, the Andrew and Erna Viterbi Professor of Electrical Engineering and Computer Science, and a member of the MIT Task Force on the Work of the Future. Robert Laubacher is associate director of the MIT Center for Collective Intelligence.

Here, Malone and Rus provide an overview of their research.

Q: You argue in your brief that despite major recent advances, artificial intelligence is nowhere close to matching the breadth and depth of perception, reasoning, communication, and creativity of people. Could you explain some of the limitations of AI?

Rus: Despite recent and significant strides in the AI field, and great promise for the future, today’s AI systems are still quite limited in their ability to reason, make decisions, interact reliably with people and the physical world. Some of today’s greatest successes are due to a machine learning method called deep learning. These systems are trained using vast amounts of data that needs to be manually labeled. Their performance is dependent on the quantity and quality of data used to train them. The larger the training set for the network, the better its performance, and, in turn, the better the product that relies on the machine learning engine. But training large models has high computation cost. Also, bad training data leads to bad performance: when the data has bias, the system response propagates the same bias.

Another limitation of current AI systems is robustness. Current state-of-the-art classifiers achieve impressive performance on benchmarks, but their predictions tend to be brittle. Specifically, inputs that were initially classified correctly can become misclassified once a carefully constructed but indiscernible perturbation is added to them. An important consequence of the lack of robustness is the lack of trust. One of the worrisome factors about the use of AI is the lack of guarantee that an input will be processed and classified correctly. The complex nature of training and using neural networks leads to systems that are difficult for people to understand. The systems are not able to provide explanations for how they reached decisions.

Q: What are the ways AI is complementing, or could complement, human work?

Malone: Today’s AI programs have only specialized intelligence; they’re only capable of doing certain specialized tasks. But humans have a kind of general intelligence that lets them do a much broader range of things.

That means some of the best ways for AI systems to complement human work is to do specialized tasks that computers can do better, faster, or more cheaply than people can. For example, AI systems can be helpful by doing tasks such as interpreting medical X-rays, evaluating the risk of fraud in a credit card charge, or generating unusual new product designs.

And humans can use their social skills, common sense, and other kinds of general intelligence to do things computers can’t do well. For instance, people can provide emotional support to patients diagnosed with cancer. They can decide when to believe customer explanations for unusual credit card transactions, and they can reject new product designs that customers would probably never want.

In other words, many of the most important uses of computers in the future won’t be replacing people; they’ll be working with people in human-computer groups — “superminds” — that can do things better than either people or computers alone could do.

The possibilities here go far beyond what people usually think of when they hear a phrase like “humans in the loop,” Instead of AI technologies just being tools to augment individual humans, we believe that many of their most important uses will occur in the context of groups of humans — often connected by the internet. So we should move from thinking about humans in the loop to computers in the group.

Q: What are some of your recommendations for education, business, and government regarding policies to help smooth the transition of AI technology adoption? 

Rus: In our report, we highlight four types of actions that can reduce the pain associated with job transitions: education and training, matching jobs to job seekers, creating new jobs, and providing counseling and financial support to people as they transition from old to new jobs. Importantly, we will need partnership among a broad range of institutions to get this work done.

Malone: We expect that — as with all previous labor-saving technologies — AI will eventually lead to the creation of more new jobs than it eliminates. But we see many opportunities for different parts of society to help smooth this transition, especially for the individuals whose old jobs are disrupted and who cannot easily find new ones.

For example, we believe that businesses should focus on applying AI in ways that don’t just replace people but that create new jobs by providing novel kinds of products and services. We recommend that all schools include computer literacy and computational thinking in their curricula, and we believe that community colleges should offer more reskilling and online micro-degree programs, often including apprenticeships at local employers.

We think that current worker organizations (such as labor unions and professional associations) or new ones (perhaps called “guilds”) should expand their roles to provide benefits previously tied to formal employment (such as insurance and pensions, career development, social connections, a sense of identity, and income security).

And we believe that governments should increase their investments in education and reskilling programs to make the American workforce once again the best-educated in the world. And they should reshape the legal and regulatory framework that governs work to encourage creating more new jobs.








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print









Paper






Research brief: ""Artificial Intelligence and the Future of Work""






Related Links

MIT Task Force on the Work of the FutureComputer Science and Artificial Intelligence LaboratoryDepartment of Electrical Engineering and Computer ScienceMIT Sloan School of ManagementMIT Schwarzman College of Computing






Related Topics

Labor and jobs
Interview
Faculty
Artificial intelligence
School of Engineering
MIT Sloan School of Management
MIT Schwarzman College of Computing
Electrical Engineering & Computer Science (eecs)
Center for Collective Intelligence
Computer Science and Artificial Intelligence Laboratory (CSAIL)



Related Articles











Why we shouldn’t fear the future of work













Report outlines route toward better jobs, wider prosperity













3 Questions: Sanjay Sarma and Bill Bonvillian on new technologies in workforce education













3Q: Evaluating skills, education, and workforce training in the US

















Previous item
Next item
















",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vd3d3LmRlbnRvbnMuY29tL2VuL2luc2lnaHRzL2FydGljbGVzLzIwMjEvamFudWFyeS8yMS9hZ3RlY2gtYW5kLWFp0gEA?oc=5,AgTech and AI – influential agribusiness trends in Alberta - Dentons,2021-01-21,Dentons,https://www.dentons.com,The agribusiness industry is made up of all farming and farming-related commercial activities from source to sale.,AgTech and AI – influential agribusiness trends in Alberta ,The agribusiness industry is made up of all farming and farming-related commercial activities from source to sale.,,,,,,,,,,,,,,,,,AgTech and AI – influential agribusiness trends in Alberta,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vd3d3LmNuYmMuY29tLzIwMjEvMDEvMjEvZGVlcG1pbmQtb3BlbmFpLWZhaXItYWktcmVzZWFyY2hlcnMtcmFuay10aGUtdG9wLWFpLWxhYnMtd29ybGR3aWRlLmh0bWzSAWtodHRwczovL3d3dy5jbmJjLmNvbS9hbXAvMjAyMS8wMS8yMS9kZWVwbWluZC1vcGVuYWktZmFpci1haS1yZXNlYXJjaGVycy1yYW5rLXRoZS10b3AtYWktbGFicy13b3JsZHdpZGUuaHRtbA?oc=5,Artificial intelligence researchers rank the top A.I. labs worldwide - CNBC,2021-01-21,CNBC,https://www.cnbc.com,"DeepMind, OpenAI, and Facebook AI Research are fighting it out to be the top AI research lab in the world. ","['cnbc', 'Articles', 'Investment strategy', 'Technology', 'Meta Platforms Inc', 'Alphabet Inc', 'Amazon.com Inc', 'Apple Hospitality REIT Inc', 'Apple Inc', 'Microsoft Corp', 'International Business Machines Corp', 'Baidu Inc', 'Tencent Holdings Ltd', 'Salesforce Inc', 'Application Software', 'Investing', 'Technology: Companies', 'Science', 'Tech Trends', 'Tech Edge ', 'Colleges & Universities', 'source:tagname:CNBC Europe Source']","DeepMind, OpenAI, and Facebook AI Research are fighting it out to be the top AI research lab in the world. ","DeepMind, OpenAI, and Facebook AI Research are fighting it out to be the top AI research lab in the world. ",https://schema.org,NewsArticle,https://www.cnbc.com/2021/01/21/deepmind-openai-fair-ai-researchers-rank-the-top-ai-labs-worldwide.html,"{'@type': 'ImageObject', 'url': 'https://image.cnbcfm.com/api/v1/image/103928104-GettyImages-514242504.jpg?v=1532564035', 'width': 1017, 'height': 559}","[{'@type': 'Person', 'name': 'Sam Shead', 'url': 'https://www.cnbc.com/sam-shead/'}]","{'@type': 'NewsMediaOrganization', 'name': 'CNBC', 'url': 'https://www.cnbc.com/', 'foundingDate': '1989-04-17', 'logo': {'@type': 'ImageObject', 'url': 'https://sc.cnbcfm.com/applications/cnbc.com/staticcontent/img/cnbc-hdr-logo2.png', 'width': 378, 'height': 98}, 'sameAs': ['https://www.facebook.com/cnbc', 'https://www.instagram.com/cnbc', 'https://www.linkedin.com/company/cnbc', 'https://twitter.com/cnbc', 'https://en.wikipedia.org/wiki/CNBC', 'https://www.youtube.com/cnbc']}",Artificial intelligence researchers rank the top A.I. labs worldwide,2021-01-21T10:49:28+0000,2021-01-21T22:38:36+0000,Technology,,,,Technology,,,https://www.cnbc.com/2021/01/21/deepmind-openai-fair-ai-researchers-rank-the-top-ai-labs-worldwide.html,2021-01-21T10:49:28+0000,,,,,,,,,,,,,,,,,,https://image.cnbcfm.com/api/v1/image/103928104-GettyImages-514242504.jpg?v=1532564035&w=720&h=405,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', '/html/head/meta[@name=""description""]/@content'], 'cssSelector': ['.group p']}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS80LWJ1c2luZXNzLXN0cmF0ZWdpZXMtZm9yLWltcGxlbWVudGluZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS0yNGRlZmYzOTE1OGPSAQA?oc=5,4 Business Strategies for Implementing Artificial Intelligence | by Jacob Bergdahl - Towards Data Science,2021-01-20,Towards Data Science,https://towardsdatascience.com,"Artificial intelligence (AI) is reinventing industry after industry. In China, AI is tutoring children in more than 1700 schools across 200 cities. In Australia, an AI created a flu vaccine that far…",,Artificial intelligence can improve any activity.,Artificial intelligence can improve any activity.,http://schema.org,NewsArticle,https://towardsdatascience.com/4-business-strategies-for-implementing-artificial-intelligence-24deff39158c,['https://miro.medium.com/v2/resize:fit:1200/1*fs0US-Ylk0hZyMTnuc3rbQ.jpeg'],"{'@type': 'Person', 'name': 'Jacob Bergdahl', 'url': 'https://bergdahl.medium.com'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",4 Business Strategies for Implementing Artificial Intelligence,2021-01-20T13:53:22.385Z,2021-12-27T23:34:46.132Z,,4 Business Strategies for Implementing Artificial Intelligence,False,,,,"Member-only story4 Business Strategies for Implementing Artificial IntelligenceArtificial intelligence can improve any activityJacob Bergdahl·FollowPublished inTowards Data Science·9 min read·Jan 20, 2021165ListenShareYour journey into AI is a lot easier if you have a strategy. Photo by Annie Spratt.Artificial intelligence (AI) is reinventing industry after industry. In China, AI is tutoring children in more than 1700 schools across 200 cities. In Australia, an AI created a flu vaccine that far outperformed all other existing flu vaccines. In the US, a machine-learning robot is autonomously cooking burgers. There are many incredible real world-implementations of AI. And now, with OpenAI’s recent ground-breaking language-generating algorithm called GPT-3, remarkably powerful AI solutions are pouring down like rain. Crafty developers have already deployed GPT-3 to autonomously write viral blog posts, generate web designs, and create role-playing adventures.Machine learning technologies are more accessible than ever, but finding the business case for AI isn’t always straightforward. In this piece of writing, I would like to make AI business strategies more concrete by walking you through four AI strategies that you can use to improve any activity you could imagine. After walking through the four strategies, I’ll help you figure out which strategy to use for any given activity.The PremiseBut first, there is one central point to artificial intelligence that it is important…",https://towardsdatascience.com/4-business-strategies-for-implementing-artificial-intelligence-24deff39158c,2021-01-20T13:53:22.385Z,,,24deff39158c,['Jacob Bergdahl'],,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9jaGluZXNlLWxhYi1haW1pbmctYmlnLWFpLWJyZWFrdGhyb3VnaHMv0gEA?oc=5,This Chinese Lab Is Aiming for Big AI Breakthroughs - WIRED,2021-01-21,WIRED,https://www.wired.com,"China produces as many artificial intelligence researchers as the US, but it lags in key fields like machine learning. The government hopes to make up ground.","['business', 'artificial intelligence', 'ai hub', 'text generation', 'ethics', 'content moderation', 'personal services', 'regulation', 'safety', 'text analysis', 'face recognition', 'big company', 'government', 'research', 'small company', 'startup', 'it', 'public safety', 'images', 'speech', 'text', 'geolocation', 'chips', 'machine learning', 'machine vision', 'natural language processing', 'semiconductors', 'china', 'web']","China produces as many artificial intelligence researchers as the US, but it lags in key fields like machine learning. The government hopes to make up ground.","China produces as many artificial intelligence researchers as the US, but it lags in key fields like machine learning. The government hopes to make up ground.",https://schema.org/,BreadcrumbList,https://www.wired.com/story/chinese-lab-aiming-big-ai-breakthroughs/,"['https://media.wired.com/photos/60089079a9a24f451b08fc1e/16:9/w_2400,h_1350,c_limit/Business-BAAI-Building.jpg', 'https://media.wired.com/photos/60089079a9a24f451b08fc1e/4:3/w_1799,h_1349,c_limit/Business-BAAI-Building.jpg', 'https://media.wired.com/photos/60089079a9a24f451b08fc1e/1:1/w_1312,h_1312,c_limit/Business-BAAI-Building.jpg']","[{'@type': 'Person', 'name': 'Will Knight', 'sameAs': 'https://www.wired.com/author/will-knight/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",This Chinese Lab Is Aiming for Big AI Breakthroughs,2021-01-21T07:00:00.000-05:00,2021-01-21T07:00:00.000-05:00,business,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.wired.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'artificial intelligence', 'item': 'https://www.wired.com/tag/artificial-intelligence/'}, {'@type': 'ListItem', 'position': 3, 'name': 'This Chinese Lab Is Aiming for Big AI Breakthroughs'}]",tags,,"Will KnightBusinessJan 21, 2021 7:00 AMThis Chinese Lab Is Aiming for Big AI BreakthroughsChina produces as many artificial intelligence researchers as the US, but it lags in key fields like machine learning. The government hopes to make up ground.Rendering of the planned headquarters of the Beijing Academy of Artificial Intelligence, scheduled to open later this year.Courtesy of The BAAISave this storySaveSave this storySaveThe AI Database →ApplicationText generationEthicsContent moderationPersonal servicesRegulationSafetyText analysisFace recognitionEnd UserBig companyGovernmentResearchSmall companyStartupSectorITResearchPublic safetySemiconductorsSource DataImagesSpeechTextGeolocationTechnologyChipsMachine learningMachine visionNatural language processingIn a low-rise building overlooking a busy intersection in Beijing, Ji Rong Wen, a middle-aged scientist with thin-rimmed glasses and a mop of black hair, excitedly describes a project that could advance one of the hottest areas of artificial intelligence.Wen leads a team at the Beijing Academy of Artificial Intelligence (BAAI), a government-sponsored research lab that’s testing a powerful new language algorithm—something similar to GPT-3, a program revealed in June by researchers at OpenAI that digests large amounts of text and can generate remarkably coherent, free-flowing language. “This is a big project,” Wen says with a big grin. “It takes a lot of computing infrastructure and money.”Wen, a professor at Renmin University in Beijing recruited to work part-time at BAAI, hopes to create an algorithm that is even cleverer than GPT-3. He plans to combine machine learning with databases of facts, and to feed the algorithm images and video as well as text, in hope of creating a richer understanding of the physical world—that the words cat and fur don’t just often appear in the same sentence, but are associated with one another visually. Other top AI labs, including OpenAI, are doing similar work.Trending NowMachine Learning: Living in the Age of AIOne thing that drew Wen to BAAI is its impressive computational resources. “The BAAI has received stellar support from the government and has strong data and computing power,” he says.His language model is one of many BAAI projects aimed at fundamental advances in AI, reflecting a new era for Chinese technology. Despite considerable hype and hand-wringing over China’s technological ascent, the country has so far primarily excelled at taking innovations from elsewhere and deploying them in new ways. This is particularly evident in AI, an area Chinese leaders consider crucial to their aspirations of becoming a true superpower.Some breakthroughs at BAAI could benefit the government directly. Wen says his language system could serve as an intelligent assistant to help citizens perform civic tasks online like obtaining a visa, a driver’s license, or a business permit. Instead of spending days filling out paperwork and waiting in line, as is the norm, a clever helper could guide citizens through the red tape. Zhanliang Liu, project lead for the effort and previously an engineer at Baidu, China’s top web search company, says his team has built a prototype for Beijing’s Department of Motor Vehicles. “It is a really tough challenge,” he says.AdvertisementThe government might, of course, benefit in other ways. More sophisticated AI language systems could prove useful for scanning social media for questionable comments or for scouring phone call transcripts. The Chinese state has embraced AI as a tool of governance, including for censorship and surveillance, particularly of Muslims in western Xinjiang province. There’s no evidence of BAAI’s work feeding into policing or intelligence, but it is being released openly for anyone to commercialize or apply.At the same time, officials are wary about the potential for AI to erode the power of the state. Several projects at the institute aim to set guardrails for commercial use of AI, to head off ethical challenges and curb the power of big tech companies.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIRED“The Chinese government's trying to get on top of this, to make sure that they're properly in control, and I think that's actually not proving altogether straightforward,” says Nigel Inkster, author of The Great Decoupling, a recent book about the fracturing relationship between China and America.An Ambitious Plan for AIThe government made its AI ambitions clear in a sweeping plan released in 2017. It set AI researchers the goal of making “fundamental breakthroughs by 2025” and called for the country to be “the world’s primary innovation center by 2030.”BAAI opened a year later, in Zhongguancun, a neighborhood of Beijing designed to replicate US innovation hubs such as Boston and Silicon Valley. It is home to a few big tech companies modeled on Western successes, like the PC maker Lenovo and the search engine Sogou, as well as countless cheap electronics stores.In recent years, the electronics stores have begun disappearing, and dozens of startups have sprung up, many focused on finding lucrative uses for AI—in manufacturing, robotics, logistics, education, finance, and other fields.BAAI will move into a new building not far from the current offices later this year. The location is both symbolic and practical, within walking distance of China’s two most prestigious universities, Tsinghua and Peking, as well as the Zhongguancun Integrated Circuit Park, opened by the government last year to attract home-grown microchip businesses.The pandemic has interrupted visits to China. I’ve met some academics working at BAAI before, and talked to others there over Zoom. An administrative assistant gave me a guided tour over WeChat video. Through the tiny screen, I saw engineers and support staff seated in an open-plan office between lush-looking potted plants. Plaques on the wall of the reception area identify the academy’s departments, including Intelligent Information Processing and Face Structured Analysis. A large sign lays out the principles that guide the center: Academic thinking. Basic theory. Top talents. Enterprise innovation. Development policy.One group at BAAI is exploring the mathematical principles underpinning machine-learning algorithms, an endeavor that may help improve upon them. Another group is focused on drawing insights from neuroscience to build better AI programs. The most celebrated machine-learning approach today—deep learning—is loosely inspired by the way neurons and synapses in the human brain learn from input. A better understanding of the biological processes behind animal and human cognition could lead to a new generation of smarter machines. A third group at the academy is focused on designing and developing microchips to run AI applications more efficiently.“Innovation by its very nature is sort of uncertain, and perhaps nowhere more so than in AI.” Noam Yuchtman, London School of EconomicsMany BAAI-affiliated researchers are doing cutting-edge work. One works on ways to make deep learning algorithms more efficient and compact. Another studies “neuromorphic” computer chips that could fundamentally change the way computers work by mirroring biological processes.China boasts some top academic AI talent, but it still has fewer leading experts than the US, Canada, or some European countries. A study of AI research papers by the Paulson Institute released in June found that China and the US produce about the same number of AI researchers each year, but the vast majority of them end up working in the US.The issue has become more urgent of late, after the Trump administration imposed sanctions that capitalize on China’s inability to manufacture the most advanced microchips. The US has most prominently targeted Huawei, which it accuses of funneling data to the government, including for espionage, cutting off its supplies of the chips needed to make high-end smartphones. In 2019, the US broadened Chinese sanctions to ban US firms from doing business with several AI firms, accusing them of supplying technology for state surveillance. President Biden may take a different approach than Trump, but he is unlikely to ignore China’s technological threat.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDTiejun Huang, director of BAAI, speaks carefully, after a long pause to collect and translate his thoughts. He says the center is modeled on Western institutions that bring together different disciplines to advance AI. Despite difficult US-China relations, he says, it is crucial for the academy to build ties with such institutions. It has sent researchers to visit MILA in Canada and the Turing Institute in the UK, two of the world’s top centers of AI expertise. AI scientists from US institutions including Princeton and UC Berkeley serve on the academy’s advisory committee.The Chinese government is not alone in investing in AI. The US Defense Advanced Research Projects Agency backs research with potential military uses. Yet many in the West are wary of how the Chinese state could use technology to further its interests and values—for example, tying digital technologies to the Belt and Road Initiative, which builds economic and infrastructure links to neighboring countries. With clear ties to the Chinese government, it isn’t hard to see a broader agenda in BAAI’s work.Research at BAAI could perhaps serve as tools of soft power, through technical standards, for example. Some Western students of China see the government’s efforts to define standards as a way to favor domestic companies and to shape perceptions and norms of a technology. Chinese firms have been active in setting technical standards for advanced 5G mobile networks. A research group at BAAI is focused on technical standards for AI, releasing proposed notation for machine-learning articles in July.The WIRED Guide to Artificial IntelligenceSupersmart algorithms won't take all the jobs, But they are learning faster than ever, doing everything from medical diagnostics to serving up ads.By Tom SimoniteSome Western researchers say some of what China is doing is not exceptional. Danit Gal, a researcher at Cambridge University’s Leverhulme Center for the Future of Intelligence who specializes in AI ethics and was previously a technology adviser to the UN, was studying at Peking University when the academy opened and has attended several meetings there. She says it is unfair to focus on the controversies when the academy is doing earnest research. “What China is doing, you know the surveillance part, is not unique to China,” she says. “I'm from Israel, and Israeli surveillance and borders are powered by Microsoft.” (Microsoft invested in AnyVision, an Israeli company providing facial-recognition software used at West Bank checkpoints, but it said in March 2020 that it would divest its stake.)Huang and others at BAAI say international researchers should engage with the institute as a way to indirectly influence the Chinese government. “The BAAI is a platform to put together people with different answers, different backgrounds, different views, and from different countries so they can talk to each other and know each other,” Huang says.Glenn Tiffert, who focuses on China at the Hoover Institution, says engagement makes sense, but it is important to appreciate the broader context. “I am absolutely not in favor of decoupling,” he says. “They may be honorable people, people of good faith,” he says of the staff and researchers at the academy. “But it’s important to remember there is a commissar behind the curtain.”Curbing the Private SectorIn the summer of 2019, before the pandemic, I visited a researcher at the Institute of Automation in Beijing who is now a key member of BAAI. The Institute of Automation is also located in Zhongguancun. Its entrance bears testament to the Chinese Communist Party’s longstanding interest in technological innovation: Black-and-white photographs show Mao Zedong meeting with scientists there, alongside color ones showing Xi Jinping, China’s current leader, doing the same.Yi Zeng, a fresh-faced researcher at the Automation Institute, is also director of BAAI’s Research Center for AI Ethics and Safety. His group produced a code of ethics covering uses of AI on behalf of the Beijing city government. The code, which is voluntary for now, says AI should not discriminate; should not be used in ways that pose safety risks; and that end users can choose to opt out if AI systems misbehave.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDZeng showed me a chart of 47 AI ethics codes drawn up by companies and governments in different countries. He said that his group wants to talk to researchers from around the world about issues such as AI bias and privacy protection, but he sidestepped questions about government surveillance.Sign Up TodayDon't miss out on the latest installment of 2034, our new series chronicling a fictional future that feels all too real.Some students of China believe the Chinese Communist Party is in fact wrestling with the ethical implications of AI algorithms—at least those used by private industry—just as much as Western governments are.In November, government regulators blocked Ant Group, a financial tech spin-off of Alibaba, from completing its planned IPO in Hong Kong and Shanghai. The government also said it would investigate Alibaba for possible antitrust abuses. Inkster, the author of The Great Decoupling, says the government is “making strenuous efforts to remind the private sector in China they exist at the government's pleasure.”The Chinese government is preparing a major new privacy law that will limit what data companies can collect and use—but also reinforces the state’s access to data for law enforcement and surveillance. Some work underway at BAAI reflects this new era. In response to the pandemic, a team at the BAAI developed a Bluetooth Covid contact-tracing app that can alert people of possible exposure without collecting identifying information. The BAAI spokeswoman says this has been tested at several offices around Zhongguancun.Noam Yuchtman, a professor at the London School of Economics, has published work that uses evidence from China to suggest that AI benefits uniquely from state intervention, because algorithms are so hungry for data and computer power that governments have access to. But he adds that such a fast-moving and unpredictable technology may also pose problems for governments. “Innovation by its very nature is sort of uncertain, and perhaps nowhere more so than in AI,” he says.Updated 1-22-21, 9:48 pm EST: This story has been updated to correct Tiejun Huang's title. He is director of BAAI, not codirector as previously stated. Enter your email to get the Wired newsletterclose dialogRecommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialogMore Great WIRED Stories📩 Want the latest on tech, science, and more? Sign up for our newsletters!Your body, your self, your surgeon, his InstagramMy quest to survive quarantine—in heated clothesHow law enforcement gets around your phone's encryptionAI-powered text from this program could fool the governmentThe ongoing collapse of the world's aquifers🎮 WIRED Games: Get the latest tips, reviews, and more🏃🏽‍♀️ Want the best tools to get healthy? Check out our Gear team’s picks for the best fitness trackers, running gear (including shoes and socks), and best headphones","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/chinese-lab-aiming-big-ai-breakthroughs/'}",,,,,,,"Wen leads a team at the Beijing Academy of Artificial Intelligence (BAAI), a government-sponsored research lab that’s testing a powerful new language algorithm—something similar to GPT-3, a program revealed in June by researchers at OpenAI that digests large amounts of text and can generate remarkably coherent, free-flowing language. “This is a big project,” Wen says with a big grin. “It takes a lot of computing infrastructure and money.”
Wen, a professor at Renmin University in Beijing recruited to work part-time at BAAI, hopes to create an algorithm that is even cleverer than GPT-3. He plans to combine machine learning with databases of facts, and to feed the algorithm images and video as well as text, in hope of creating a richer understanding of the physical world—that the words cat and fur don’t just often appear in the same sentence, but are associated with one another visually. Other top AI labs, including OpenAI, are doing similar work.
One thing that drew Wen to BAAI is its impressive computational resources. “The BAAI has received stellar support from the government and has strong data and computing power,” he says.
His language model is one of many BAAI projects aimed at fundamental advances in AI, reflecting a new era for Chinese technology. Despite considerable hype and hand-wringing over China’s technological ascent, the country has so far primarily excelled at taking innovations from elsewhere and deploying them in new ways. This is particularly evident in AI, an area Chinese leaders consider crucial to their aspirations of becoming a true superpower.
Some breakthroughs at BAAI could benefit the government directly. Wen says his language system could serve as an intelligent assistant to help citizens perform civic tasks online like obtaining a visa, a driver’s license, or a business permit. Instead of spending days filling out paperwork and waiting in line, as is the norm, a clever helper could guide citizens through the red tape. Zhanliang Liu, project lead for the effort and previously an engineer at Baidu, China’s top web search company, says his team has built a prototype for Beijing’s Department of Motor Vehicles. “It is a really tough challenge,” he says.
The government might, of course, benefit in other ways. More sophisticated AI language systems could prove useful for scanning social media for questionable comments or for scouring phone call transcripts. The Chinese state has embraced AI as a tool of governance, including for censorship and surveillance, particularly of Muslims in western Xinjiang province. There’s no evidence of BAAI’s work feeding into policing or intelligence, but it is being released openly for anyone to commercialize or apply.
At the same time, officials are wary about the potential for AI to erode the power of the state. Several projects at the institute aim to set guardrails for commercial use of AI, to head off ethical challenges and curb the power of big tech companies.
“The Chinese government's trying to get on top of this, to make sure that they're properly in control, and I think that's actually not proving altogether straightforward,” says Nigel Inkster, author of The Great Decoupling, a recent book about the fracturing relationship between China and America.
An Ambitious Plan for AI
The government made its AI ambitions clear in a sweeping plan released in 2017. It set AI researchers the goal of making “fundamental breakthroughs by 2025” and called for the country to be “the world’s primary innovation center by 2030.”
BAAI opened a year later, in Zhongguancun, a neighborhood of Beijing designed to replicate US innovation hubs such as Boston and Silicon Valley. It is home to a few big tech companies modeled on Western successes, like the PC maker Lenovo and the search engine Sogou, as well as countless cheap electronics stores.
In recent years, the electronics stores have begun disappearing, and dozens of startups have sprung up, many focused on finding lucrative uses for AI—in manufacturing, robotics, logistics, education, finance, and other fields.
BAAI will move into a new building not far from the current offices later this year. The location is both symbolic and practical, within walking distance of China’s two most prestigious universities, Tsinghua and Peking, as well as the Zhongguancun Integrated Circuit Park, opened by the government last year to attract home-grown microchip businesses.
The pandemic has interrupted visits to China. I’ve met some academics working at BAAI before, and talked to others there over Zoom. An administrative assistant gave me a guided tour over WeChat video. Through the tiny screen, I saw engineers and support staff seated in an open-plan office between lush-looking potted plants. Plaques on the wall of the reception area identify the academy’s departments, including Intelligent Information Processing and Face Structured Analysis. A large sign lays out the principles that guide the center: Academic thinking. Basic theory. Top talents. Enterprise innovation. Development policy.
One group at BAAI is exploring the mathematical principles underpinning machine-learning algorithms, an endeavor that may help improve upon them. Another group is focused on drawing insights from neuroscience to build better AI programs. The most celebrated machine-learning approach today—deep learning—is loosely inspired by the way neurons and synapses in the human brain learn from input. A better understanding of the biological processes behind animal and human cognition could lead to a new generation of smarter machines. A third group at the academy is focused on designing and developing microchips to run AI applications more efficiently.
Many BAAI-affiliated researchers are doing cutting-edge work. One works on ways to make deep learning algorithms more efficient and compact. Another studies “neuromorphic” computer chips that could fundamentally change the way computers work by mirroring biological processes.
China boasts some top academic AI talent, but it still has fewer leading experts than the US, Canada, or some European countries. A study of AI research papers by the Paulson Institute released in June found that China and the US produce about the same number of AI researchers each year, but the vast majority of them end up working in the US.
The issue has become more urgent of late, after the Trump administration imposed sanctions that capitalize on China’s inability to manufacture the most advanced microchips. The US has most prominently targeted Huawei, which it accuses of funneling data to the government, including for espionage, cutting off its supplies of the chips needed to make high-end smartphones. In 2019, the US broadened Chinese sanctions to ban US firms from doing business with several AI firms, accusing them of supplying technology for state surveillance. President Biden may take a different approach than Trump, but he is unlikely to ignore China’s technological threat.
Tiejun Huang, director of BAAI, speaks carefully, after a long pause to collect and translate his thoughts. He says the center is modeled on Western institutions that bring together different disciplines to advance AI. Despite difficult US-China relations, he says, it is crucial for the academy to build ties with such institutions. It has sent researchers to visit MILA in Canada and the Turing Institute in the UK, two of the world’s top centers of AI expertise. AI scientists from US institutions including Princeton and UC Berkeley serve on the academy’s advisory committee.
The Chinese government is not alone in investing in AI. The US Defense Advanced Research Projects Agency backs research with potential military uses. Yet many in the West are wary of how the Chinese state could use technology to further its interests and values—for example, tying digital technologies to the Belt and Road Initiative, which builds economic and infrastructure links to neighboring countries. With clear ties to the Chinese government, it isn’t hard to see a broader agenda in BAAI’s work.
Research at BAAI could perhaps serve as tools of soft power, through technical standards, for example. Some Western students of China see the government’s efforts to define standards as a way to favor domestic companies and to shape perceptions and norms of a technology. Chinese firms have been active in setting technical standards for advanced 5G mobile networks. A research group at BAAI is focused on technical standards for AI, releasing proposed notation for machine-learning articles in July.
Some Western researchers say some of what China is doing is not exceptional. Danit Gal, a researcher at Cambridge University’s Leverhulme Center for the Future of Intelligence who specializes in AI ethics and was previously a technology adviser to the UN, was studying at Peking University when the academy opened and has attended several meetings there. She says it is unfair to focus on the controversies when the academy is doing earnest research. “What China is doing, you know the surveillance part, is not unique to China,” she says. “I'm from Israel, and Israeli surveillance and borders are powered by Microsoft.” (Microsoft invested in AnyVision, an Israeli company providing facial-recognition software used at West Bank checkpoints, but it said in March 2020 that it would divest its stake.)
Huang and others at BAAI say international researchers should engage with the institute as a way to indirectly influence the Chinese government. “The BAAI is a platform to put together people with different answers, different backgrounds, different views, and from different countries so they can talk to each other and know each other,” Huang says.
Glenn Tiffert, who focuses on China at the Hoover Institution, says engagement makes sense, but it is important to appreciate the broader context. “I am absolutely not in favor of decoupling,” he says. “They may be honorable people, people of good faith,” he says of the staff and researchers at the academy. “But it’s important to remember there is a commissar behind the curtain.”
Curbing the Private Sector
In the summer of 2019, before the pandemic, I visited a researcher at the Institute of Automation in Beijing who is now a key member of BAAI. The Institute of Automation is also located in Zhongguancun. Its entrance bears testament to the Chinese Communist Party’s longstanding interest in technological innovation: Black-and-white photographs show Mao Zedong meeting with scientists there, alongside color ones showing Xi Jinping, China’s current leader, doing the same.
Yi Zeng, a fresh-faced researcher at the Automation Institute, is also director of BAAI’s Research Center for AI Ethics and Safety. His group produced a code of ethics covering uses of AI on behalf of the Beijing city government. The code, which is voluntary for now, says AI should not discriminate; should not be used in ways that pose safety risks; and that end users can choose to opt out if AI systems misbehave.
Zeng showed me a chart of 47 AI ethics codes drawn up by companies and governments in different countries. He said that his group wants to talk to researchers from around the world about issues such as AI bias and privacy protection, but he sidestepped questions about government surveillance.
Some students of China believe the Chinese Communist Party is in fact wrestling with the ethical implications of AI algorithms—at least those used by private industry—just as much as Western governments are.
In November, government regulators blocked Ant Group, a financial tech spin-off of Alibaba, from completing its planned IPO in Hong Kong and Shanghai. The government also said it would investigate Alibaba for possible antitrust abuses. Inkster, the author of The Great Decoupling, says the government is “making strenuous efforts to remind the private sector in China they exist at the government's pleasure.”
The Chinese government is preparing a major new privacy law that will limit what data companies can collect and use—but also reinforces the state’s access to data for law enforcement and surveillance. Some work underway at BAAI reflects this new era. In response to the pandemic, a team at the BAAI developed a Bluetooth Covid contact-tracing app that can alert people of possible exposure without collecting identifying information. The BAAI spokeswoman says this has been tested at several offices around Zhongguancun.
Noam Yuchtman, a professor at the London School of Economics, has published work that uses evidence from China to suggest that AI benefits uniquely from state intervention, because algorithms are so hungry for data and computer power that governments have access to. But he adds that such a fast-moving and unpredictable technology may also pose problems for governments. “Innovation by its very nature is sort of uncertain, and perhaps nowhere more so than in AI,” he says.
Updated 1-22-21, 9:48 pm EST: This story has been updated to correct Tiejun Huang's title. He is director of BAAI, not codirector as previously stated.

More Great WIRED Stories

📩 Want the latest on tech, science, and more? Sign up for our newsletters!
Your body, your self, your surgeon, his Instagram
My quest to survive quarantine—in heated clothes
How law enforcement gets around your phone's encryption
AI-powered text from this program could fool the government
The ongoing collapse of the world's aquifers
🎮 WIRED Games: Get the latest tips, reviews, and more
🏃🏽‍♀️ Want the best tools to get healthy? Check out our Gear team’s picks for the best fitness trackers, running gear (including shoes and socks), and best headphones","{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,,,,,,,,"https://media.wired.com/photos/60089079a9a24f451b08fc1e/1:1/w_1312,h_1312,c_limit/Business-BAAI-Building.jpg","China produces as many artificial intelligence researchers as the US, but it lags in key fields like machine learning. The government hopes to make up ground.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vd3d3LnNjcmliZW5kaS5jb20vYWNhZGVteS9hcnRpY2xlcy9hcnRpZmljaWFsX2ludGVsbGlnZW5jZS5lbi5odG1s0gEA?oc=5,How Scribendi Uses AI to Improve Your Writing - Scribendi.com,2021-01-17,Scribendi.com,https://www.scribendi.com,"Scribendi combines professional editors with best-in-class artificial intelligence to deliver peerless editing and proofreading. Learn more about our propriety editing tools, which use natural language processing and machine learning to deliver high-quality results.",,"Scribendi combines professional editors with best-in-class artificial intelligence to deliver peerless editing and proofreading. Learn more about our propriety editing tools, which use natural language processing and machine learning to deliver high-quality results.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihQFodHRwczovL3d3dy5kZWZlbnNlLmdvdi9OZXdzL05ld3MtU3Rvcmllcy9BcnRpY2xlL0FydGljbGUvMjQ3ODkwMC9kb2QtaW5jb3Jwb3JhdGluZy1haS1ldGhpY3MtaW50by1zeXN0ZW1zLWVuZ2luZWVyaW5nLW9mZmljaWFsLXNheXMv0gEA?oc=5,"DOD Incorporating AI Ethics Into Systems Engineering, Official Says - Department of Defense",2021-01-21,Department of Defense,https://www.defense.gov,,,"Alka Patel, head of artificial intelligence ethics policy at the Joint Artificial Intelligence Center, said that because AI enables autonomy, decision making and system execution at incredibly fast","Alka Patel, head of artificial intelligence ethics policy at the Joint Artificial Intelligence Center, said that because AI enables autonomy, decision making and system execution at incredibly fast",http://schema.org,Organization,https://www.defense.gov/,,,,,,,,U.S. Department of Defense,,,,,"
        You have accessed part of a historical collection on defense.gov. Some of the information contained within may be outdated and links may not function. Please contact the DOD Webmaster with any questions.
    ",,,,,,,,,,,,,,,,,,https://www.defense.gov/Portals/1/Images/DOD-Icon-Header.png?ver=5sAfFl2--9znca0j3SrX_g%3d%3d,,,,,,,,,,,,,[],,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMirAFodHRwczovL3d3dy5wcm5ld3N3aXJlLmNvbS9uZXdzLXJlbGVhc2VzL3JjcC1jb25zdHJ1Y3Rpb24taW5jLWFuZC1ldmVyZ3VhcmRhaS1zaWduLWFncmVlbWVudC10by11dGlsaXplLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFpLXRvLWltcHJvdmUtam9iLXNpdGUtc2FmZXR5LTMwMTIxMDk1MC5odG1s0gEA?oc=5,"RCP Construction, Inc., and Everguard.ai Sign Agreement to Utilize Artificial Intelligence (AI) to Improve Job Site Safety - PR Newswire",2021-01-19,PR Newswire,https://www.prnewswire.com,"/PRNewswire/ -- RCP Construction, Inc. and Everguard.ai today announced a collaboration to bring artificial intelligence (AI) and sensor fusion to commercial...",Everguard.ai,"/PRNewswire/ -- RCP Construction, Inc. and Everguard.ai today announced a collaboration to bring artificial intelligence (AI) and sensor fusion to commercial...","/PRNewswire/ -- RCP Construction, Inc. and Everguard.ai today announced a collaboration to bring artificial intelligence (AI) and sensor fusion to commercial...",https://schema.org,NewsArticle,,['https://mma.prnewswire.com/media/1317320/Everguard_ai_Logo.jpg?p=facebook'],,,"RCP Construction, Inc., and Everguard.ai Sign Agreement to Utilize Artificial Intelligence (AI) to Improve Job Site Safety",2021-01-19T10:24:00-05:00,2021-01-19T10:25:34-05:00,,,,,,,"






RCP Construction, Inc., and Everguard.ai Sign Agreement to Utilize Artificial Intelligence (AI) to Improve Job Site Safety

Companies announce partnership with a focus on safety in commercial construction

















News provided by

Everguard.ai



Jan 19, 2021, 10:24 ET



Share this article









 














 









Share toX





 








Share this article


















Share toX


















IRVINE, Calif., Jan. 19, 2021 /PRNewswire/ -- RCP Construction, Inc. and Everguard.ai today announced a collaboration to bring artificial intelligence (AI) and sensor fusion to commercial construction job sites in an effort to improve safety measures. The agreement will bring Everguard's Sentri360™ platform to RCP Construction's White Rock Center Project located in Rancho Cordova, CA. Sentri360™ creates a paradigm shift from a reactive to a proactive approach to preventing workplace injuries and accidents.  
Initial efforts will focus on using the power of AI and computer vision (CV) to enhance the safety protocols already in place for proper use of personal protective equipment (PPE) and geofencing deep excavation areas on the construction site. The use of heavy machinery, working at height, and the interaction of workers, drivers and machines on a construction site creates significant safety concerns. For example, Everguard's Sentri360™ platform will ensure PPE is worn properly and provide proactive alerts to workers via wearables when PPE is not in use. The platform will monitor for proper use of hard hats, safety glasses and reflective vests as well as face mask use to help reduce the occurrence and spread of COVID-19. Another critical safety use case involves geofencing capabilities where the platform alerts an employee who ventures into a virtual safety zone.   
In addition, this partnership will allow Everguard and RCP Construction to define additional use cases for ongoing development of Everguard's Sentri360™ platform, including teaching the system via new CV algorithms to proactively address other specific hazards found on commercial construction job sites. 
""Making sure our employees return home safely at the end of every day is our number one priority,"" said Phil Fasolo, general superintendent at RCP Construction. ""We are excited to collaborate with Everguard.ai and deploy their platform on our construction worksites to help us optimize safety and efficiency.""  
Everguard.ai is moving environmental health and safety (EHS) from a reactive approach to one of proactive accident avoidance by utilizing AI powered by sensor fusion. Sensor fusion collects inputs from many different technologies, including computer vision (CV), real-time location systems (RTLS) and wearables. Sensor data is fed into edge computer for AI analysis and processing in much the same way that humans process information gathered by their senses. The platform provides near-real-time alerts and analytics to managers and workers, notifying them of safety threats before accidents occur and identifying opportunities for additional employee training. 
""We are thrilled to collaborate with the RCP Construction team to reach the ultimate goal: an accident-free construction industry,"" said Sanjay Pandya, vice president and general manager of construction at Everguard. ""RCP Construction's dedication to ensuring every team member makes it home safely each day is unmatched, and we are excited to provide the technology to help them make strides towards that goal.""
About Everguard.ai
Everguard's mission is to protect companies' most important assets — their people — with the first truly proactive solution dedicated to industrial safety. Their Industrial Health and Safety platform utilizes artificial intelligence (AI) and sensor fusion driven by technologies that include edge computing, computer vision (CV), real-time location system (RTLS), wearables and others. Everguard's Sentri360™ solution provides proactive interventions to help prevent and avoid industrial accidents and the billions of dollars in fees and lost-time incidents they cause.
About RCP Construction
RCP Construction's mission is to create trusted partnerships with clients and team members to deliver a quality product while maintaining the highest levels of innovation, professionalism, integrity, safety and client satisfaction. For 35 years, they have made the experience of building a better experience through high-quality customer service, teamwork, attention to detail, and follow through. 
SOURCE Everguard.ai

 Related Links
 https://everguard.ai/







×
Modal title




",{'@id': 'https://www.prnewswire.com/news-releases/rcp-construction-inc-and-everguardai-sign-agreement-to-utilize-artificial-intelligence-ai-to-improve-job-site-safety-301210950.html'},,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vZm9ydHVuZS5jb20vMjAyMS8wMS8xOS9oaXJldnVlLWRyb3BzLWZhY2lhbC1tb25pdG9yaW5nLWFtaWQtYS1pLWFsZ29yaXRobS1hdWRpdC_SAQA?oc=5,HireVue stops using facial expressions to assess job candidates amid audit of its A.I. algorithms - Fortune,2021-01-19,Fortune,https://fortune.com,Critics claim the company's software is opaque and potentially biased. The company says the independent audit is an effort to improve transparency.,"artificial intelligence, Ai, eye on a.i., machine learning, HireVue, HR technology, hiring technology, hire tech, HR tech, hiring A.I., job interviews, videotaped job interviews, video, facial expressions, facial expression, face tracking, analysis, visual analysis, verbal analysis, nonverbal analysis, natural language processing, NLP, audit, algorithmic audit, algorithmic bias, bias, A.I. bias, racial bias, gender bias, age bias, racial discrimination, gender discrimination, age discrimination, Cathy O&#039;Neil, Weapons of Math destruction, ORCAA, O&#039;Neil Risk Consulting and Algorithmic Auditing, AI ethics, Kevin Parker, Lindsey Zuloaga",Critics claim the company's software is opaque and potentially biased. The company says an independent audit of its A.I. algorithms is a step towards greater transparency—one other businesses should consider.,Critics claim the company's software is opaque and potentially biased. The company says an independent audit of its A.I. algorithms is a step towards greater transparency—one other businesses should consider.,,,,,,,,,,,,,,,,"Newsletters - BroadsheetAs fellow VCs pledge support for Trump, Fearless Fund’s Arian Simone keeps fighting for diversityBYEmma Hinchliffe and Joseph AbramsJuly 17, 2024",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vbmV3cy50ZW1wbGUuZWR1LzIwMjEtMDEtMTkvdGVtcGxlLXJlc2VhcmNoZXJzLWhlbHAtcGVvcGxlLW5ldXJvZGV2ZWxvcG1lbnRhbC1kaXNhYmlsaXRpZXMtc3VjY2VlZC1pdC1qb2Jz0gEA?oc=5,Temple researchers help people with neurodevelopmental disabilities succeed in IT jobs - Temple University News,2021-01-19,Temple University News,https://news.temple.edu,"Temple University researchers are using artificial intelligence to create job support technology for those with neurodevelopmental disabilities, such as autism.",,"Temple University researchers are using artificial intelligence to create job support technology for those with neurodevelopmental disabilities, such as autism.",A $2.3 million award from the National Science Foundation supports the use of artificial intelligence in the development of virtual job assistance ,,,,,,,,,,,,,,,,"

Navigation 
 - Go To - News by topic - Arts & Culture - Athletics - Campus News - Community Engagement - Global Temple - Research - Staff & Faculty - Student Success - Sustainability - Faculty Experts - Public Safety - Return to Campus - Nutshell - Visualize TempleAnnouncementsNewsletters - Temple Now subscriptionPublicationsTemple in the newsSocial MediaSpecial SeriesTemple MagazineAboutAccolades

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3LnZlcnl3ZWxsaGVhbHRoLmNvbS9yZXNlYXJjaGVycy11c2UtYWktcmVwdXJwb3NpbmctbWVkaWNhdGlvbnMtNTA5NjA4N9IBAA?oc=5,Researchers Use AI To Find New Uses for Existing Medications - Verywell Health,2021-01-21,Verywell Health,https://www.verywellhealth.com,Researchers at the Ohio State University have discovered the benefits of using artificial intelligence for drug repurposing.,,Researchers at the Ohio State University have discovered the benefits of using artificial intelligence for drug repurposing.,Researchers at the Ohio State University have discovered the benefits of using artificial intelligence for drug repurposing.,,,,,,,,,,,,,,Verywell,,"


NEWS


 
Health News


 Researchers Use AI To Find New Uses for Existing Medications


By
Caroline Shannon Karasik

Updated on January 21, 2021



 Fact checked by

James Lacy


 














 
Print


 



 





 
 CMB / Getty Images


Key Takeaways
New research shows scientists have developed artificial intelligence to find new uses for existing medications, a process also known as drug repurposing.Drug repurposing can reduce the time frame it typically takes to gain approval for new drugs, as well lower the risk associated with safety testing of new medications.This process has already been used to expedite the development of drugs related to COVID-19.
 New research published early this month by the Ohio State University (OSU) shows scientists have achieved success using a machine learning method to determine whether or not certain drugs can be repurposed for new uses. This researcher-developed process is important progress, given that it can more quickly identify drug candidates that may be repurposed to treat a number of diseases, according to the report published in Nature Machine Intelligence on January 4.1


 “This work shows how artificial intelligence (AI) can be used to ‘test’ a drug on a patient, and speed up hypothesis generation and potentially speed up a clinical trial,” senior study author Ping Zhang, PhD, an assistant professor of computer science and engineering and biomedical informatics at OSU, said in a news release.2 “But we will never replace the physician—drug decisions will always be made by clinicians.”




FDA Approves Remdesivir as First Treatment For COVID-19

 Drug repurposing, of course, is not new. One example? Botox injections, which were first approved to treat crossed eyes, went on to be used as a migraine treatment as well as cosmetically to reduce the appearance of wrinkles. The OSU study focused on repurposing drugs that prevent heart failure and stroke in patients with coronary artery disease but proved the framework could be applied to most diseases.


 The study’s use of artificial intelligence speeds up a process that was already designed to reduce the time frame it takes to gain the approval of new drugs, according to the National Center for Advancing Translational Sciences (NCATS).3 


 “Many agents approved for other uses have already been tested in humans, so detailed information is available on their pharmacology, formulation and potential toxicity,” notes the NCATS website. “Because repurposing builds upon previous research and development efforts, new candidate therapies could be ready for clinical trials quickly, speeding their review by the Food and Drug Administration and, if approved, their integration into health care.”


 Drug repurposing can also lower the risk associated with the safety testing of new medications, according to the news release.2


What This Means For You
In the future, with the help of AI, drug repurposing may be a speedier and more streamlined process. Approving drugs like remdesivir for COVID-19 might be a quicker process.



  How Are Drugs Identified for Repurposing?  
 Before diving into the benefits of drug repurposing, Zhang and his co-researchers on the OSU study asserted that the “gold standard” in drug testing is still randomized clinical trials to determine a drug’s effectiveness against a disease.


 “[But] machine learning can account for hundreds—or thousands—of human differences within a large population that could influence how medicine works in the body,” notes the news release. “These factors, or confounders, ranging from age, sex and race to disease severity and the presence of other illnesses, function as parameters in the deep learning computer algorithm on which the framework is based.”



 The procedure for identifying drugs for repurposing involves a lab first developing an “assay,” a process that will allow it to monitor the compound’s effectiveness, Pek Lum, PhD, co-founder and CEO of Auransa, an AI-driven pharmaceutical company, tells Verywell.


 “A library of already launched compounds (could be in the tens of thousands) that can be repurposed will be screened (tested) for effectiveness using the assay,” Lum explains. “Once a repurposed drug is identified through a screen, it will be further tested in the lab for efficacy in the proposed use. In some cases, if the compound has already been tested previously in clinical trials with an acceptable safety profile for a similar indication or in the case of emergencies like the pandemic, it could go straight into clinical trials without the need to show pre-clinical animal safety again.”


New AI Tool May Help Patients and Nurses Get Extra Rest at Night

 While the repurposed drugs will still need to through clinical trials to show effectiveness in the new use, Lum says drug repurposing is a very useful way to start a drug program “as it can cut short through many steps that are needed or at the very least, one should be able to learn about the repurposed drug through previously generated data.""


  Repurposing for COVID-19  
 If you’re wondering whether or not drug repurposing can be used to speed the process of preventing and treating COVID-19, the answer is yes—and it already has. 


 “The effort to identify already launched drugs that can be repurposed for COVID-19 started early on in the pandemic,” Lum says. “Labs started to test already known antiviral drugs against COVID-19 [using the screening process] mentioned above. For example, remdesivir was tested and shown to be efficacious in COVID-19 relevant assays and trials to test it were very quickly set into motion.”


 Stephen T.C. Wong, PhD, professor of computer science, systems medicine, and bioengineering in oncology at Houston Methodist Research Institute, agrees, adding that Remdesivir is a drug that was originally designed to fight Ebola.


Regeneron Earns First-Ever FDA Approval For Ebola Treatment

 “This example does not involve some sophisticated AI analysis due to the emergency of the COVID-19 situations required fast, immediate actions, but it still follows the four steps in drug repositioning,"" Wong tells Verywell.


  How Does AI Help?  
 Wong points out that AI covers much larger drug candidate searching spaces than individual researchers or clinicians.


 “At the macro-level, AI can help identify the right timing and dosage for administering a repurposed drug efficiently,” he says. “For example, through mining of electronic medical records, AI can identify the ‘signature’ for bad outcomes along the timeline of hospitalization and guide the distributions of resources (e.g. ventilators) and timing of applying different therapeutics.”


AI Can Help Reduce Opioid Prescriptions After Surgery, Research Finds

 At the micro-level, ""AI can help understand the biomolecules involved in disease causation and treatment, generating better match between repositioned drugs and target proteins, and identifying potential adverse side effects,"" Wong says.


 Overall, the gist of AI, Wong says, is that it can sweep a search space of drug candidates beyond human capability, as well as “analyze and quantify” data that can lead to better decision making and drug repositioning to improve human health. 

3 Sources






Verywell Health uses only high-quality sources, including peer-reviewed studies, to support the facts within our articles. Read our editorial process to learn more about how we fact-check and keep our content accurate, reliable, and trustworthy.
 
Liu R, Wei L, Zhang P. A deep learning framework for drug repurposing via emulating clinical trials on real-world patient data. Nature Machine Intelligence. 2021;3(1):68-75. doi: 10.5281/zenodo.4079391
Ohio State News. Using artificial intelligence to find new uses for existing medications.
National Center for Advancing Translational Sciences. Repurposing drugs.










By Caroline Shannon Karasik

Caroline Shannon Karasik is a writer based in Pittsburgh, PA. In addition to Verywell, her work has appeared in several publications, including Good Housekeeping, Women's Health and Well+Good.


 



See Our Editorial Process



Meet Our Medical Expert Board



Share Feedback
 
 
Was this page helpful?


Thanks for your feedback!


What is your feedback?
 Other

 Helpful

 Report an Error



 

 Submit
 




























",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiM2h0dHBzOi8vZmVkc2Nvb3AuY29tL2dzYS1haS1tb25pdG9yaW5nLWV2b2x2ZS13YWxsL9IBAA?oc=5,General Services Administration will use AI to monitor AI - FedScoop,2021-01-21,FedScoop,https://fedscoop.com,A command center-like Evolve Wall will soon display the life cycle of the agency's ongoing emerging technology deployments.,"['artificial intelligence (ai)', 'cybersecurity', 'david shive', 'general services administration (gsa)', 'machine learning', 'nci', 'robotic process automation (rpa)']",A command center-like Evolve Wall will soon display the life cycle of the agency's ongoing emerging technology deployments.,,https://schema.org,NewsArticle,http://fedscoop.com/gsa-ai-monitoring-evolve-wall/,"{'@type': 'ImageObject', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/07/GettyImages-1159603124.jpg'}","[{'@type': 'Person', 'name': 'Dave Nyczepir'}]","{'@type': 'Organization', 'name': 'FedScoop', 'logo': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/cropped-fs_favicon-3.png'}",General Services Administration will use AI to monitor AI,2021-01-21T20:07:16Z,2023-11-08T16:04:15Z,AI,,,,,,"






AI




								General Services Administration will use AI to monitor AI							

								A command center-like Evolve Wall will soon display the life cycle of the agency's ongoing emerging technology deployments.							


By
Dave Nyczepir



January 21, 2021






 
											(Getty Images)										





The General Services Administration will use artificial intelligence to monitor the deployment of AI applications as part of an $807 million contract awarded to NCI Information Systems.
GSA awarded the Digital Innovation for GSA Infrastructure Technologies (DIGIT) task order to NCI, in part, because of a proposed Evolve Wall command-center screen displaying the lifecycle of AI deployments.
The wall will provide Chief Information Officer David Shive and his leadership team with valuable, real-time information, also accessible on their desktops, as GSA aggressively integrates emerging technologies to become an end-to-end digital entity.
“It’s a pretty comprehensive and transparent view of the technologies that are being introduced, those that are being implemented and adopted,” Paul Dillahay, president and CEO of NCI, told FedScoop. “And that was certainly something that I think was discriminating for our proposal and something that I believe will become more commonplace over a longer period of time.”


Advertisement



The commercial technology identifies an organization’s new emerging technology use cases, showing their impact and the speed at which they can become proofs of concept and ultimately deployed.
GSA could use the wall to look at an AI module rolled out two months ago and see how much it’s learning and thereby improving its efficiency.
“They’re really looking to disrupt their own infrastructure and environment so that they can offer better business outcomes and a better customer experience by adopting and accelerating the use of things like AI,” said Bridget Medeiros, chief growth officer at NCI.
The DIGIT task order covers other aspects of intelligent automation, such as automating mundane service desk tasks with robotic process automation and machine learning (ML). The goal is to only have humans interacting with customers dealing with software or hardware problems when absolutely necessary. And when they do, sentiment analysis will inform them of the person’s tone and needs.
NCI is further bringing animated personas to test new service desk concepts without interrupting the day-to-day work of users. Large companies already use personas to test new products before they go to market, and NCI has adapted them for GSA.


Advertisement




A persona can be used to test how changing an aspect about how technicians, administrators or contract specialists work will impact them, as well as what the benefits might be, using ML.
NCI partners’ code is all U.S. based, making it easier for the company to get an authority to operate and work with GSA in other areas like improving the agency’s cybersecurity tools in the wake of the massive SolarWinds hack compromising eight agencies. To date, GSA has not acknowledged any compromise, but its Federal Acquisition Service has used the Orion software in question.
The DIGIT task order has a one-year base and a maximum performance period of seven years and was awarded under the Alliant 2 governmentwide acquisition contract. The award was made by the Federal Systems Integration and Management Center on behalf of the Office of Digital Infrastructure Technologies. It’s also the largest award in NCI’s 31-year history.








Written by Dave Nyczepir
Dave Nyczepir is a technology reporter for FedScoop. He was previously the news editor for Route Fifty and, before that, the education reporter for The Desert Sun newspaper in Palm Springs, California. He covered the 2012 campaign cycle as the staff writer for Campaigns & Elections magazine and Maryland’s 2012 legislative session as the politics reporter for Capital News Service at the University of Maryland, College Park, where he earned his master’s of journalism. 


In This Story



														Cybersecurity													



														NCI													



														Artificial Intelligence (AI)													



														machine learning													



														David Shive													



														General Services Administration (GSA)													



														robotic process automation (RPA)													








Share




Facebook





LinkedIn





Twitter





Copy Link











Advertisement






Advertisement





More Like This






								Energy highlights roadmap for FASST AI program			



By 

						Rebecca Heilweil					










								GSA calls for nominations to emerging tech-focused acquisition advisory committee			



By 

						Caroline Nihill					










								VA plans to award AI tech sprint winners contracts for ambient medical transcription services			



By 

						Caroline Nihill					









Advertisement





Top Stories






								After 2023 outage that paused flights nationwide, FAA now has backup system			



By 

						Rebecca Heilweil					










								FedRAMP ‘undeniably’ in state of limbo without final OMB modernization guidance, Rep. Connolly says			



By 

						Caroline Nihill					










								How the IRS’s ‘cautious’ approach with Direct File prevented its ‘failure’			



By 

						Matt Bracken					










								Social Security Administration transitioning long-time users to Login.gov			



By 

						Rebecca Heilweil					










								Energy Department’s national labs get AI boost in bipartisan Senate bill			



By 

						Matt Bracken					










Advertisement






","{'@type': 'WebPage', '@id': 'http://fedscoop.com/gsa-ai-monitoring-evolve-wall/'}",2021-01-21T20:07:16Z,,,,['Dave Nyczepir'],,,,,,,,,,,,,,https://fedscoop.com/wp-content/uploads/sites/5/2019/07/GettyImages-1159603124.jpg?w=150&h=150&crop=1,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://fedscoop.com/gsa-ai-monitoring-evolve-wall/', 'url': 'https://fedscoop.com/gsa-ai-monitoring-evolve-wall/', 'name': 'General Services Administration will use AI to monitor AI | FedScoop', 'isPartOf': {'@id': 'https://fedscoop.com/#website'}, 'primaryImageOfPage': {'@id': 'https://fedscoop.com/gsa-ai-monitoring-evolve-wall/#primaryimage'}, 'image': {'@id': 'https://fedscoop.com/gsa-ai-monitoring-evolve-wall/#primaryimage'}, 'thumbnailUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/07/GettyImages-1159603124.jpg', 'datePublished': '2021-01-21T20:07:16+00:00', 'dateModified': '2023-11-08T16:04:15+00:00', 'description': ""A command center-like Evolve Wall will soon display the life cycle of the agency's ongoing emerging technology deployments."", 'breadcrumb': {'@id': 'https://fedscoop.com/gsa-ai-monitoring-evolve-wall/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://fedscoop.com/gsa-ai-monitoring-evolve-wall/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/gsa-ai-monitoring-evolve-wall/#primaryimage', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/07/GettyImages-1159603124.jpg', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/07/GettyImages-1159603124.jpg', 'width': 1920, 'height': 1280, 'caption': '(Getty Images)'}, {'@type': 'BreadcrumbList', '@id': 'https://fedscoop.com/gsa-ai-monitoring-evolve-wall/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://fedscoop.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'General Services Administration will use AI to monitor AI'}]}, {'@type': 'WebSite', '@id': 'https://fedscoop.com/#website', 'url': 'https://fedscoop.com/', 'name': 'FedScoop', 'description': 'FedScoop delivers up-to-the-minute breaking government tech news and is the government IT community&#039;s platform for education and collaboration through news, events, radio and TV. FedScoop engages top leaders from the White House, federal agencies, academia and the tech industry both online and in person to discuss ways technology can improve government, and to exchange best practices and identify how to achieve common goals.', 'publisher': {'@id': 'https://fedscoop.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://fedscoop.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://fedscoop.com/#organization', 'name': 'FedScoop', 'url': 'https://fedscoop.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/#/schema/logo/image/', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'width': 1231, 'height': 182, 'caption': 'FedScoop'}, 'image': {'@id': 'https://fedscoop.com/#/schema/logo/image/'}}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3Lmdvdi5zaS9lbi9uZXdzLzIwMjEtMDEtMTktZHItbWloYS1tbGFrYXItYS1zY2llbnRpc3QtY29ubmVjdGluZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS13aXRoLXNwb3J0L9IBAA?oc=5,Dr Miha Mlakar: a scientist connecting artificial intelligence with sport | GOV.SI - Gov.si,2021-01-19,Gov.si,https://www.gov.si,,,"Miha Mlakar is a former captain of the Slovenian Davis Cup team, and a Doctor of Science specialising in algorithms and artificial intelligence, a researcher linking artificial intelligence, data and sport. ","Miha Mlakar is a former captain of the Slovenian Davis Cup team, and a Doctor of Science specialising in algorithms and artificial intelligence, a researcher linking artificial intelligence, data and sport. ",https://schema.org,BreadcrumbList,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://www.gov.si/en/news/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Dr Miha Mlakar: a scientist connecting artificial intelligence with sport', 'item': 'https://www.gov.si/en/news/2021-01-19-dr-miha-mlakar-a-scientist-connecting-artificial-intelligence-with-sport/'}]",,,"






Home




News








Dr Miha Mlakar: a scientist connecting artificial intelligence with sport






19. 1. 2021



								Government Communication Office
								




Miha Mlakar is a former captain of the Slovenian Davis Cup team, and a Doctor of Science specialising in algorithms and artificial intelligence, a researcher linking artificial intelligence, data and sport. 












												Dr Miha Mlakar. | Author Miha Mlakar, osebni arhiv










He is head of the Agents Group in the Department of Intelligent Systems at the Jožef Stefan Institute, and explains his work as follows: »Our main focus is on applied research, or how to apply artificial intelligence methods to practical problems of businesses. We, for example, cooperate with companies Gorenje and Unior in the automated analysis of (semi-finished) products on the production line.« The group’s objective is to develop new methods of working and living. »We are now developing a conversational agent to help people deal with stress, anxiety and depression. However, we would also like to expand our cooperation to as many companies as possible in order to connect their problems with our expertise, thus helping them increase their added value.«Data processing and sportMlakar has always been fascinated by numbers, and with his experience of being a professional tennis player and coach, he is now as a scientist focused on establishing links between data science and sport.  As this is a really novel approach, he is interested in learning how it works in practice.»I apply my knowledge of artificial intelligence and data processing to sport, where many of these approaches are still unique. As a former professional player I have the advantage of knowing both aspects really well, i.e. the technical and the domain side. I can thus solve problems and focus on issues that are later used by players or coaches to improve their performance. In practice, we deal with large quantities of data on individual players. I search for hidden data patterns on whose basis I am able to advise players how to improve their game or, if the data refer to the opponent, which tactic to employ against them,« added Mlakar.He works with a number of professional tennis players but, for the reasons of confidentiality, cannot disclose all their names. »I can, however, tell you that we work with Alexander Zverev, Naomi Osaka, and Simona Halep, and that we are currently in talks with Stefanos Tsitsipas for the next season.«Mlakar previously worked with the world’s top players, Serena Williams and Novak Djoković. His task and that of the data processing team is to assist coaches by providing objective advice on what needs improvement. »This enables coaches to prepare their players in the best possible way. For every match we also analyse the opponent’s data to establish what our player must pay special attention to, what the opponent’s weak spots are and how to turn those weak spots to our advantage.«Analytics and sportAs an excellent tennis player and coach, and former captain of the Slovenian Davis Cup team, Mlakar specialises in connecting tennis with artificial intelligence, but his interests go beyond this. »I am also interested in analysing other sports, and I read a lot about analytical achievements in other sports, so that I closely follow the developments in my research area. In the future I will definitely analyse data for other sports, since the fundamental concepts are similar, you only need to ask the right questions to identify the factors important for your answers. You then translate them into numbers using the right method. I think that analysis is becoming increasingly more recognised and significant in all sports, which means that we will see even more analytical work in the future. There are only minor differences between teams, so even the slightest improvement matters.«Miha Mlakar is thus active in many areas. »Yes, that’s true, I have many interests and sometimes not enough time for proper sleep. But if your work makes you happy, then it isn’t ‘work’. My biggest problem is that the day only has 24 hours,« he stresses, and goes on to say that some things overlap, and, while he develops his knowledge of artificial intelligence at the Jožef Stefan Institute, at the same time he applies this knowledge to other areas. »Of course, credit for my work also goes to my family, who has always supported me and made all this possible.«Author: Polona Prešeren






Similar articles


 RSS





5. 3. 2021


Alpina’s I feel Slovenia hiking boot




18. 2. 2021


Elan showcased the first fully functional folding all-mountain carving skis in the world




10. 2. 2021


The COVID-19 pandemic has created a new reality




19. 1. 2021


Dr Miha Mlakar: a scientist connecting artificial intelligence with sport




20. 12. 2020


International Research Centre on Artificial Intelligence in Ljubljana




20. 12. 2020


The innovative spirit of Slovenian youth - My company project




10. 12. 2020


Slovenia – the only country with a zero waste capital city, zero waste hotel and zero waste events







							
							All news
							
						























































",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3LnRvZGF5b25saW5lLmNvbS9zaW5nYXBvcmUvYWktY2xvdWQtdGVjaG5vbG9neS10aGVzZS1taWxsZW5uaWFscy1yZXNraWxsLXJpZGUtc2luZ2Fwb3Jlcy1kaWdpdGFsaXNhdGlvbi13YXZl0gEA?oc=5,"From AI to cloud technology, these millennials reskilled to ride Singapore's digitalisation wave - TODAY",2021-01-20,TODAY,https://www.todayonline.com,"SINGAPORE — While working as an engineer at electronics manufacturing company Infineon Technologies, Dr Pamela Lin realised that artificial intelligence (AI) could help optimise production processes.","digitilisation,skills,Jobs,millennials,EDB","SINGAPORE — While working as an engineer at electronics manufacturing company Infineon Technologies, Dr Pamela Lin realised that artificial intelligence (AI) could help optimise production processes.","SINGAPORE — While working as an engineer at electronics manufacturing company Infineon Technologies, Dr Pamela Lin realised that artificial intelligence (AI) could help optimise production processes.",https://schema.org,,,,,,,,,,,,,,,"




Advertisement




































      From AI to cloud technology, these millennials reskilled to ride Singapore’s digitalisation wave
  

SINGAPORE — While working as an engineer at electronics manufacturing company Infineon Technologies, Dr Pamela Lin realised that artificial intelligence (AI) could help optimise production processes.














          Ooi Boon Keong/TODAY
                
        


Dr Pamela Lin, 31, a senior engineer at Infineon who already had a PhD but decided to pursue a lower course in a master's programme in technology to learn AI, something she has never done.
























By 


      TAN YIN LIN
  




















By 

      TAN YIN LIN
  



Published January 20, 2021
Updated January 21, 2021









    Bookmark
  






    Bookmark
  






    Share
  




 

        WhatsApp
      


 

        Telegram
      


 

        Facebook
      


 

        Twitter
      


 

        Email
      


 

        LinkedIn
      

























Even though she already had a PhD in mechanical engineering, Dr Pamela Lin, 31, took up a master’s degree in artificial intelligence
After getting retrenched from his corporate sales job last year, Mr Muhammad Khairunnizam Lukman, 34, decided to take up a cloud technology training course
They are among millennials highlighted by the EDB in its year-in-review report, released on Wednesday (Jan 20), for their reskilling efforts
 Advertisement 











SINGAPORE — While working as an engineer at electronics manufacturing company Infineon Technologies, Dr Pamela Lin realised that artificial intelligence (AI) could help optimise production processes.For example, when equipment breaks down, technicians would usually troubleshoot to determine the cause of the malfunction before repairing the equipment.However, with AI, data can be used to predict and diagnose the failure, removing the need to troubleshoot so that technicians can focus on repair work.

      Read also
  






      13,000 more govt-subsidised training places for employees in aerospace sector
  







The potential of AI spurred Dr Lin, now 31, to take up a master’s degree, despite already having spent five years pursuing her higher level PhD in mechanical engineering from the Nanyang Technological University.“People asked me: If I have a PhD, why do you go back to do a master’s?” she said. “It’s not really (about) the qualification, but the knowledge itself.”Advertisement 











She joined Infineon in November 2017, after completing her PhD, and is now a senior engineer leading the backend industrial engineering team’s advanced data analytics team at the German firm.She first got insight into how AI can help the manufacturing industry after taking short courses in areas like big data analytics and statistics shortly after joining Infineon.When her colleagues told her about the National University of Singapore-Institute of System Science’s Master of Technology in Intelligent Systems, she decided to sign up for the programme since the knowledge she gained would help with her job.From January 2019, she spent her Saturdays on the part-time master’s programme, and recently completed the degree this month.

      Read also
  






      Plans to create 1,000 new jobs for landscape sector as NParks moves to adopt high-tech systems
  







“I feel like going into this two-year master’s programme actually accelerated my capability development in this AI domain,” she said.Advertisement 











Dr Lin is among a rising number of millennials who are riding the local digitalisation push, as Singapore presses ahead with its ambitions to become a more advanced technology hub.The Economic Development Board (EDB) highlighted the stories of such millennials to reskill for the tech sector in its year-in-review report released on Wednesday (Jan 20).RETRENCHED DUE TO COVID-19, BUT RESKILLING TO ENTER TECHAnother of these millennials is Mr Muhammad Khairunnizam Lukman, 34. After working in his corporate sales job for more than a year, he was retrenched in March 2020 due to the impact of Covid-19.He then chanced upon an advertisement for Skills Ignition SG, a programme by Google, the Infocomm Media Development Authority, SkillsFuture SG and EDB that equips trainees with skills in digital marketing or cloud technology.Advertisement 

























      Read also
  






      Government has bridged digital divide but has ‘humility’ to try to do more: Iswaran
  







Mr Muhammad Khairunnizam Lukman, 34, at his home on Jan 20, 2021. Photo: Ooi Boon Keong/TODAYCurrently, 1,650 participants are enrolled in the six-month vocational training course, with 60 per cent of participants aged 40 and above.Mr Lukman was initially hesitant about signing up, as he had not worked in the information technology (IT) sector despite graduating with a diploma in business IT.However, after his brother told him that cloud technology was a high-demand area, Mr Lukman became motivated to leverage his previous experience with IT and sign up for the programme’s vocational training course in cloud technology.“And when I saw that this is something our Government also supported, it gave me a sense of confidence that this should be the direction I need to move forward in,” he said.He is now in the fourth month of the six-month programme and receives a monthly training allowance of S$1,500.For Mr Lukman, one of the biggest challenges was readjusting to the IT sector after leaving it for so long. For example, he used programming language Java when studying for his diploma, but now has to learn Python, an entirely new language, for the cloud technology course.After he completes the programme, he hopes to work as a cloud architect.“I do believe that with the certification that I have and the right positive attitude, I should be able to get a job,” he said.






      Related topics
  

      digitilisation
  

      skills
  

      Jobs
  

      millennials
  

      EDB
  




Read more of the latest in


      Singapore
  

      Explore now
  









Advertisement










YOU MIGHT LIKE
TRENDING


      Trending
  









Jackson Wang suppers at Lau Pa Sat after Cartier party, praised for clearing tray after meal












Jamus Lim appointed Workers' Party youth wing president in new CEC appointments












Indonesian man, 75, marries 15-year-old girl who is the same age as his grandkid












A grave problem: Demand for funeral services rising, but retaining workers a problem as young shun low pay, long hours







      Popular
  









 Man threatened to kill pregnant wife when she wanted to travel without him, gets jail for criminal intimidation












Teen pleads guilty to assaulting classmate, rioting, selling unregistered pills in Geylang












Auditor-General flags potential irregularities, lapses in several govt entities; multiple police reports filed












Disbarred lawyer M Ravi pleads guilty to choking colleague, pushing priest at temple, other offences 










 

Recommended by

 







Advertisement





















      Stay in the know. Anytime. Anywhere.
  







      Subscribe to our newsletter for the top features, insights and must reads delivered straight to your inbox.
  














      By clicking subscribe, I agree for my personal data to be used to send me TODAY newsletters, promotional offers and for research and analysis.
  
























      READ THE FULL STORY
  


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', 'headline': 'From AI to cloud technology, these millennials reskilled to ride Singapore’s digitalisation wave', 'name': 'From AI to cloud technology, these millennials reskilled to ride Singapore’s digitalisation wave', 'description': 'SINGAPORE — While working as an engineer at electronics manufacturing company Infineon Technologies, Dr Pamela Lin realised that artificial intelligence (AI) could help optimise production processes.', 'image': {'@type': 'ImageObject', 'url': 'https://onecms-res.cloudinary.com/image/upload/s--0BJDkXc9--/c_fill,g_auto,h_338,w_600/f_auto,q_auto/v1/tdy-migration/pamelalin.jpg?itok=KD7sY-H_', 'width': '100', 'height': '100'}, 'datePublished': '2021-01-20T19:56:02+08:00', 'dateModified': '2021-01-21T09:43:34+08:00', 'author': {'@type': 'Person', '@id': 'https://www.todayonline.com/authors/tan-yin-lin', 'name': 'TAN YIN LIN', 'url': 'https://www.todayonline.com/authors/tan-yin-lin'}, 'publisher': {'@type': 'Organization', '@id': 'https://www.todayonline.com/', 'name': 'TODAY', 'url': 'https://www.todayonline.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://www.todayonline.com/themes/custom/mc_todayonline_theme/images/logo.svg', 'width': '600', 'height': '60'}}, 'mainEntityOfPage': 'https://www.todayonline.com/singapore/ai-cloud-technology-these-millennials-reskill-ride-singapores-digitalisation-wave'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS84LXJldm9sdXRpb25hcnktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdGVjaG5vbG9naWVzLW9mLXRoZS1tb2Rlcm4tZXJhLWY4ZjIyYTQxMjdkMNIBAA?oc=5,8 Revolutionary Artificial Intelligence Technologies Of The Modern Era! - Towards Data Science,2021-01-20,Towards Data Science,https://towardsdatascience.com,"The modern generation of the world is technologically advanced, and the pace of advancements and improvements is continuously increasing with no signs of slowing down. The current era we all live in…",,Exploring and analyzing the 8 AI Technologies that will or already have influenced the world drastically!,Exploring and analyzing the 8 AI Technologies that will or already have influenced the world drastically!,http://schema.org,NewsArticle,https://towardsdatascience.com/8-revolutionary-artificial-intelligence-technologies-of-the-modern-era-f8f22a4127d0,['https://miro.medium.com/v2/da:true/resize:fit:1200/0*wOiYP1mi5MmFZWsA'],"{'@type': 'Person', 'name': 'Bharath K', 'url': 'https://bharath-k1297.medium.com'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",8 Revolutionary Artificial Intelligence Technologies Of The Modern Era,2021-01-20T14:31:44.383Z,2021-12-27T23:35:43.719Z,,8 Revolutionary Artificial Intelligence Technologies Of The Modern Era,False,,,,"Member-only story8 Revolutionary Artificial Intelligence Technologies Of The Modern EraExploring and analyzing the 8 AI Technologies that will or already have influenced the world drasticallyBharath K·FollowPublished inTowards Data Science·17 min read·Jan 20, 2021293ListenSharePhoto by ben o'bro on UnsplashThe Rise of Artificial Intelligence has resulted in the creation of rapid world-changing technologies that can impact the future of all entities, preferably for the better of humanity.The modern generation of the world is technologically advanced, and the pace of advancements and improvements is continuously increasing with no signs of slowing down. The current era we all live in will prove to be the most influential period of all time.The Curve of improvements in humanity has always tended to be an exponential curve. With the discovery of the fire way dating back to thousands of years ago, to the discovery of the wheel, to the inventions of high-quality developments in the 17th and 18th Century, and finally, to the modern era of technological advancements where the majority of the inventions have been made.The inventions and discoveries in the past two to three decades have almost been double that of the overall products in all the previous years combined. With the human intellect improving each day, and with the rise of Artificial Intelligence and Data Science of the…",https://towardsdatascience.com/8-revolutionary-artificial-intelligence-technologies-of-the-modern-era-f8f22a4127d0,2021-01-20T14:31:44.383Z,,,f8f22a4127d0,['Bharath K'],,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPWh0dHBzOi8vd3d3LmNpby5jb20vYXJ0aWNsZS8xOTExNzkvMTItZGFyay1zZWNyZXRzLW9mLWFpLmh0bWzSAT1odHRwczovL3d3dy5jaW8uY29tL2FydGljbGUvMTkxMTc5LzEyLWRhcmstc2VjcmV0cy1vZi1haS5odG1s?oc=5,12 dark secrets of AI - CIO,2021-01-06,CIO,https://www.cio.com,"With the drumbeat for AI across all industries only getting louder, IT leaders must come to grips with the dark secrets of working with artificial intelligence to glean business insights.",,"With the drumbeat for AI across all industries only getting louder, IT leaders must come to grips with the dark secrets of working with artificial intelligence to glean business insights.","With the drumbeat for AI across all industries only getting louder, IT leaders must come to grips with the dark secrets of working with artificial intelligence to glean business insights.",,,,,,,,,,,,,,,,"










		With the drumbeat for AI across all industries only getting louder, IT leaders must come to grips with the dark secrets of working with artificial intelligence to glean business insights.	




 
Credit: Thinkstock






 
Humanity have always dreamed of some omniscient, omnipotent genie that can shoulder its workloads. Now, thanks to the hard work of computer scientists in the labs, we have our answer in artificial intelligence, which if you buy into the hype can do just about anything your company needs done — at least some of it, some of the time.
Yes, the AI innovations are amazing. Virtual helpers like Siri, Alexa, or Google Assistant would seem magical to a time traveler from as recently as 10 to 15 years ago. Your word is their command, and unlike voice recognition tools from the 1990s, they often come up with the right answer — if you avoid curveball questions like asking how many angels can dance on the head of a pin.

[ Cut through the hype with our practical guide to machine learning in business and find out the10 signs you’re ready for AI — but might not succeed. | | Get the latest insights with our CIO Daily newsletter. ]

But for all of their magic, AIs are still reliant on computer programming and that means they suffer from all of the limitations that hold back the more pedestrian code such as spreadsheets or word processors. They do a better job juggling the statistical vagaries of the world, but ultimately, they’re still just computers that make decisions by computing a function and determining whether some number is bigger or smaller than a threshold. Underneath all of the clever mystery and sophisticated algorithms is a set of transistors implementing an IF-THEN decision.











 
 
 
Can we live with this? Do we have any choice? With the drumbeat for AI across all industries only getting louder, we must begin to learn to live with the following dark secrets of artificial intelligence.
More Videos0 seconds of 14 minutes, 53 secondsVolume 0%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledShortcuts Open/Close/ or ?Play/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


Next UpCIO Leadership Live Kathy Kay56:23SettingsOffAutomated Captions - en-USFont ColorWhiteFont Opacity100%Font Size100%Font FamilyArialCharacter EdgeNoneBackground ColorBlackBackground Opacity50%Window ColorBlackWindow Opacity0%ResetWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%200%175%150%125%100%75%50%ArialCourierGeorgiaImpactLucida ConsoleTahomaTimes New RomanTrebuchet MSVerdanaNoneRaisedDepressedUniformDrop ShadowWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%WhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%







Live00:0014:5314:53 

Much of what you find with AI is obvious
The toughest job for an AI scientist is telling the boss that the AI has discovered what everyone already knew. Perhaps it examined 10 billion photographs and discovered the sky is blue. But if you forgot to put night-time photos in the training set, it won’t realize that it gets dark at night. 
But how can an AI avoid the obvious conclusions? The strongest signals in the data will be obvious to anyone working in the trenches and they’ll also be obvious to the computer algorithms digging through the numbers. They’ll be the first answer that the retriever will bring back and drop at your feet. At least the algorithms won’t expect a treat.











 
 
 
Exploiting nuanced AI insights may not be worth it
Of course, good AIs also lock on to small differences when the data is precise. But using these small insights can require deep strategic shifts to the company’s workflow. Some of the subtle distinctions will be too subtle to be worth chasing. And computers will still obsess over them. The problem is that big signals are obvious and small signals may yield small or even nonexistent gains.
Mysterious computers are more threatening
While early researchers hoped that the mathematical approach of a computer algorithm would lend an air of respectability to the final decision, many people in the world aren’t willing to surrender to the god of logic. If anything, the complexity and mystery of AI make it easier for anyone unhappy with the answer to attack the process. Was the algorithm biased? The more mystery and complexity under the hood, the more reasons for the world to be suspicious and angry.
AI is mainly curve fitting
Scientists have been plotting some noisy data and drawing lines through the points for hundreds of years. Many of the AI algorithms at the core of machine learning algorithms do just that. They take some data and draw a line through them. Much of the advancement has come from finding ways to break the problem into thousands, millions, or maybe even billions of little problems and then drawing lines through all of them. It’s not magic; it’s just an assembly line for how we’ve been doing science for centuries. People who don’t like AI and find it easy to poke holes in its decisions focus on the fact that there’s often no deep theory or philosophical scaffolding to lend credibility to the answer. It’s just a guesstimate for the slope of some line.











 
 
 
Gathering data is the real job
Everyone who’s started studying data science begins to realize that there’s not much time for science because finding the data is the real job. AI is a close cousin to data science and it has the same challenges. It’s 0.01% inspiration and 99.99% perspiring over file formats, missing data fields, and character codes.
You need massive data to reach deeper conclusions
Some answers are easy to find, but deeper, more complex answers often require more and more data. Sometimes the amount of data will rise exponentially. AI can leave you with an insatiable appetite for more and more bits.
You’re stuck with the biases of your data
Just like the inhabitants of Plato’s Cave, we’re all limited by what we can see and perceive. AIs are no different. They’re explicitly limited by their training set. If there are biases in the data — and there will be some — the AI will inherit them. If there are holes in the data, there will be holes in the AI’s understanding of the world.  











 
 
 
AI is a black hole for electricity
Most good games have a final level or an ultimate goal. AIs, though, can keep getting more and more complex. As long as you’re willing to pay the electricity bill, they’ll keep churning out more complex models with more nodes, more levels, and more internal state. Maybe this extra complexity will be enough to make the model truly useful. Maybe some emergent sentient behavior will come out of the next run. But maybe we’ll need an even larger collection of GPUs running through the night to really capture the effect.
Explainable AI is just another turtle
AI researchers have been devoting more time of late trying to explain just what the AI is doing.  We can dig into the data and discover that the trained model relies heavily on these parameters that come from a particular corner of the data set. Often, though, the explanations are like those offered by magicians who explain one trick by performing another. Answering the question why is surprisingly hard. You can look at the simplest linear models and stare at the parameters, but often you’ll be left scratching your head. If the model says to multiply the number of miles driven each year by a factor of 0.043255, you might wonder why not 0.043256 or 0.7, or maybe something outrageously different like 411 or 10 billion. Once you’re using a continuum, all of the numbers along the axis might be right. 
It’s like the old model where the Earth was just sitting on a giant Turtle. And where did this turtle stand? On the back of another Turtle. And where does the next stand? It’s turtles all the way down.











 
 
 
Trying to be fair is a challenge
You could leave height out of the training set, but the odds are pretty good that your AI program will find some other proxy to flag the taller people and choose them for your basketball squad. Maybe it will be shoe size. Or perhaps reach. People have dreamed that asking a neutral AI to make an unbiased decision would make the world a fairer place, but sometimes the issues are deeply embedded in reality and the algorithms can’t do any better.
Sometimes the fixes are even worse
Is forcing an AI to be fair any real solution? Some try to insist that AIs generate results with certain preordained percentages. They put their thumb on the scale and rewrite the algorithms to change the output. But then people start to wonder why we bother with any training or data analysis if you’ve already decided the answer you want.
Humans are the real problem
We’re generally happy with AIs when the stakes are low. If you’ve got 10 million pictures to sort, you’re going to be happy if some AI will generate reasonably accurate results most of the time. Sure, there may be issues and mistakes. Some of the glitches might even reflect deep problems with the AI’s biases, issues that might be worthy of a 200-page hairsplitting thesis.











 
 
 
But the AIs aren’t the problem. They will do what they’re told. If they get fussy and start generating error messages, we can hide those messages. If the training set doesn’t generate perfect results, we can put aside the whining result asking for more data. If the accuracy isn’t as high as possible, we can just file that result away. The AIs will go back to work and do the best they can.
Humans, though, are a completely different animal. The AIs are their tools and the humans will be the ones who want to use them to find an advantage and profit from it. Some of these plans will be relatively innocent, but some will be driven by secret malice aforethought. Many times, when we run into a bad AI, it’s because it’s the puppet on the string for some human that’s profiting from the bad behavior.

















 
Related content





Sponsored Content
by Adobe

Pfeiffer Report: AI supercharges enterprise knowledge work

By Adobe


18 Jun 2024

  


events promotion

Unlocking the Secrets to IT Success: Why Attend the CIO100 Symposium & Awards Even if You Haven’t Won an Award
 

				By Elizabeth Cutler				


Jul 17, 2024

2 mins 


Events
Innovation
IT Leadership






news

Fujitsu partners with Cohere to build LLMs for Japanese enterprises
Once developed, the new LLMs will be integrated into Fujitsu’s Kozuchi AI services, specifically designed for private cloud environments. 

				By Gyana Swain				


Jul 17, 2024

5 mins 


Technology Industry
Artificial Intelligence






feature

CIOs are stretched more than ever before — and that’s a good thing
Modern digital leaders have to climb an ever steepening responsibility curve. Successful CIOs embrace this challenge and collaborate with their executive peers to transform the business. 

				By Mark Samuels				


Jul 17, 2024

6 mins 


CIO
Roles
Digital Transformation






case study

Unpacking Leroy Merlin’s marketplace strategy
By the end of the year, B2C marketplaces are expected to reach $3.5 trillion in sales. So offering a better UX and connecting businesses with a wider customer base are vital ways to outsmart the competition. It’s a business model that’s p 

				By Joanne Carew				


Jul 17, 2024

5 mins 


CIO
E-commerce Services
Retail Industry






PODCASTS


VIDEOS


RESOURCES


EVENTS













 
SUBSCRIBE TO OUR NEWSLETTER			

				From our editors straight to your inbox			

			Get started by entering your email address below.		


 



Please enter a valid email address




Subscribe









",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vbmV3cy5vc3UuZWR1L3VzaW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvLWZpbmQtbmV3LXVzZXMtZm9yLWV4aXN0aW5nLW1lZGljYXRpb25zL9IBAA?oc=5,Using artificial intelligence to find new uses for existing medications - The Ohio State University News,2021-01-04,The Ohio State University News,https://news.osu.edu,"Scientists have developed a machine-learning method that crunches massive amounts of data to help determine which existing medications could improve outcomes in diseases for which they are not prescribed.The intent of this work is to speed up drug repurposing, which is not a new concept &ndash; think Botox injections, first approved to treat crossed e...","Research science,News,Research News,medical,Science,Press release,college-medicine,college-engineering,SM-homepage,The Ohio State University","Scientists have developed a machine-learning method that crunches massive amounts of data to help determine which existing medications could improve outcomes in diseases for which they are not prescribed.The intent of this work is to speed up drug repurposing, which is not a new concept – think Botox injections, first approved to treat crossed e...","Scientists have developed a machine-learning method that crunches massive amounts of data to help determine which existing medications could improve outcomes in diseases for which they are not prescribed.The intent of this work is to speed up drug repurposing, which is not a new concept – think Botox injections, first approved to treat crossed e...",https://schema.org,Article,,['https://content.presspage.com/uploads/2170/1920_addiction-71575.jpg?10000'],"{'@type': 'Organization', 'name': 'The Ohio State University'}","{'@type': 'Organization', 'name': 'The Ohio State University', 'logo': {'@type': 'ImageObject', 'url': 'https://content.presspage.com/clients/o_2170.png'}}",Using artificial intelligence to find new uses for existing medications,2021-01-04T17:10:42+01:00,2021-01-08T14:39:18+01:00,,,,,,," 







Share
























Using artificial intelligence could help speed up the process of finding new uses for existing drugs.
Photo: Pixabay




Jan04,
2021

 | 
11:10 AM
America/New_York

Using artificial intelligence to find new uses for existing medications
Scientists crunch data to “screen” candidates for drug repurposing

 









Follow me on X (opens in new window)



Add me on LinkedIn (opens in new window)



Emily CaldwellOhio State News caldwell.151@osu.edu









Scientists have developed a machine-learning method that crunches massive amounts of data to help determine which existing medications could improve outcomes in diseases for which they are not prescribed.The intent of this work is to speed up drug repurposing, which is not a new concept – think Botox injections, first approved to treat crossed eyes and now a migraine treatment and top cosmetic strategy to reduce the appearance of wrinkles.Ping ZhangBut getting to those new uses typically involves a mix of serendipity and time-consuming and expensive randomized clinical trials to ensure that a drug deemed effective for one disorder will be useful as a treatment for something else.The Ohio State University researchers created a framework that combines enormous patient care-related datasets with high-powered computation to arrive at repurposed drug candidates and the estimated effects of those existing medications on a defined set of outcomes.Though this study focused on proposed repurposing of drugs to prevent heart failure and stroke in patients with coronary artery disease, the framework is flexible – and could be applied to most diseases.“This work shows how artificial intelligence can be used to ‘test’ a drug on a patient, and speed up hypothesis generation and potentially speed up a clinical trial,” said senior author Ping Zhang, assistant professor of computer science and engineering and biomedical informatics at Ohio State. “But we will never replace the physician – drug decisions will always be made by clinicians.”The research is published today (Jan. 4, 2021) in Nature Machine Intelligence.Drug repurposing is an attractive pursuit because it could lower the risk associated with safety testing of new medications and dramatically reduce the time it takes to get a drug into the marketplace for clinical use.Randomized clinical trials are the gold standard for determining a drug’s effectiveness against a disease, but Zhang noted that machine learning can account for hundreds – or thousands – of human differences within a large population that could influence how medicine works in the body. These factors, or confounders, ranging from age, sex and race to disease severity and the presence of other illnesses, function as parameters in the deep learning computer algorithm on which the framework is based.That information comes from “real-world evidence,” which is longitudinal observational data about millions of patients captured by electronic medical records or insurance claims and prescription data.“Real-world data has so many confounders. This is the reason we have to introduce the deep learning algorithm, which can handle multiple parameters,” said Zhang, who leads the Artificial Intelligence in Medicine Lab and is a core faculty member in the Translational Data Analytics Institute at Ohio State. “If we have hundreds or thousands of confounders, no human being can work with that. So we have to use artificial intelligence to solve the problem.“We are the first team to introduce use of the deep learning algorithm to handle the real-world data, control for multiple confounders, and emulate clinical trials.”The research team used insurance claims data on nearly 1.2 million heart-disease patients, which provided information on their assigned treatment, disease outcomes and various values for potential confounders. The deep learning algorithm also has the power to take into account the passage of time in each patient’s experience – for every visit, prescription and diagnostic test. The model input for drugs is based on their active ingredients.Applying what is called causal inference theory, the researchers categorized, for the purposes of this analysis, the active drug and placebo patient groups that would be found in a clinical trial. The model tracked patients for two years – and compared their disease status at that end point to whether or not they took medications, which drugs they took and when they started the regimen.“With causal inference, we can address the problem of having multiple treatments. We don’t answer whether drug A or drug B works for this disease or not, but figure out which treatment will have the better performance,” Zhang said.Their hypothesis: that the model would identify drugs that could lower the risk for heart failure and stroke in coronary artery disease patients.The model yielded nine drugs considered likely to provide those therapeutic benefits, three of which are currently in use – meaning the analysis identified six candidates for drug repurposing. Among other findings, the analysis suggested that a diabetes medication, metformin, and escitalopram, used to treat depression and anxiety, could lower risk for heart failure and stroke in the model patient population. As it turns out, both of those drugs are currently being tested for their effectiveness against heart disease.Zhang stressed that what the team found in this case study is less important than how they got there.“My motivation is applying this, along with other experts, to find drugs for diseases without any current treatment. This is very flexible, and we can adjust case-by-case,” he said. “The general model could be applied to any disease if you can define the disease outcome.”The research was supported by the National Center for Advancing Translational Sciences, which funds the Center for Clinical and Translational Science at Ohio State.Graduate student Ruoqi Liu and research assistant professor Lai Wei, both at Ohio State, also worked on the study.
 



Share this




                        Using artificial intelligence to find new uses for existing medications                    






Share on: Twitter






Share on: Facebook






Share on: LinkedIn








 

More Ohio State News




RSS feed - More Ohio State News (opens in new window)


View all headlines - More Ohio State News










Jul
17,
2024

 | 
08:06 AM
America/New_York


What fat cats on a diet may tell us about obesity in humans

Pet cats may be excellent animal models for the study of obesity origins and treatment in humans, a new study of feline gut microbes suggests – and both species would likely get healthier in the research process, scientists say. 

Read more
                                        







Jul
16,
2024

 | 
10:55 AM
America/New_York


A new material for small electronics that gives batteries longer life

Scientists have achieved a series of milestones in growing a high-quality thin film conductor, suggesting in a new study that the material is a promising candidate platform for future wearable electronics and other miniature applications. 

Read more
                                        







Jul
12,
2024

 | 
14:30 PM
America/New_York


Gulbenkian Prize for Humanity awarded to renowned soil scientist Rattan Lal

A globally renowned soil scientist at The Ohio State University, Rattan Lal, has been awarded the 2024 Gulbenkian Prize for Humanity for his significant contributions to global food security, climate resilience and ecosystem protection.

Read more
                                        








Show previous items



Show next items





","{'@type': 'WebPage', '@id': 'https://news.osu.edu/'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy50ZWNodGFyZ2V0LmNvbS9oZWFsdGh0ZWNoYW5hbHl0aWNzL25ld3MvMzY2NTkxMzc1L0FydGlmaWNpYWwtSW50ZWxsaWdlbmNlLUZhbGxzLVNob3J0LWluLURldGVjdGluZy1EaWFiZXRpYy1FeWUtRGlzZWFzZdIBAA?oc=5,Artificial Intelligence Falls Short in Detecting Diabetic Eye Disease - TechTarget,2021-01-06,TechTarget,https://www.techtarget.com,"Of seven artificial intelligence algorithms tested, only one performed better than human clinicians in detecting diabetic eye diseases.",,"Of seven artificial intelligence methods tested, only one performed better than human clinicians in detecting diabetic eye disease.","Of seven artificial intelligence methods tested, only one performed better than human clinicians in detecting diabetic eye disease.",https://schema.org,NewsArticle,,https://cdn.ttgtmedia.com/rms/onlineimages/health analytics_a408295425.jpeg,"[{'name': 'Jessica Kent', '@type': 'Person'}]","{'name': 'TechTarget', 'logo': {'url': 'https://cdn.ttgtmedia.com/rms/amp/amp_teal_logo_115_60.png', 'height': 60, 'width': 115, '@type': 'ImageObject'}, '@type': 'Organization'}",Artificial Intelligence Falls Short in Detecting Diabetic Eye Disease,2021-01-06T04:30Z,,,Artificial Intelligence Falls Short in Detecting Diabetic Eye Disease,False,,,,"


Chinnapong - stock.adobe.com
Chinnapong - stock.adobe.com





News


Artificial Intelligence Falls Short in Detecting Diabetic Eye Disease


Of seven artificial intelligence algorithms tested, only one performed better than human clinicians in detecting diabetic eye diseases.





Share this item with your network:














































By


Jessica Kent


Published: 06 Jan 2021


 
Artificial intelligence algorithms designed to detect diabetic eye disease may not perform as well as developers claim, according to a study published in Diabetes Care.







Diabetes is the leading cause of new cases of blindness among adults in the US, researchers stated. The current shortage of eye-care providers would make it impossible to keep up with demand to provide the requisite annual screenings for this population. And because current approaches of treating retinopathy are most effective when the condition is caught early, eye doctors need an accurate way to quickly identify patients who need treatment. 
To overcome this issue, researchers and vendors have developed artificial intelligence algorithms to help accurately detect diabetic retinopathy. Researchers set out to test the effectiveness of seven AI-based screening algorithms to diagnose diabetic retinopathy against the diagnostic expertise of retina specialists.
Five companies produced the algorithms tested in the study – two in the US, one in China, one in Portugal, and one in France. While many of these companies report excellent results in clinical trials, their performance in real-world settings was unknown.
Researchers used the algorithm-based technologies on retinal images from nearly 24,000 veterans who sought diabetic retinopathy screening at the Veterans Affairs Puget Sound Healthcare System and the Atlanta VA Healthcare System from 2006 to 2018.
The team conducted a test in which the performance of each algorithm and the performance of the human screeners who work in the VA teleretinal screening system were all compared to the diagnoses that expert ophthalmologists gave when looking at the same images.
The results showed that the algorithms don’t perform as well as human clinicians. Three of the algorithms performed reasonably well when compared to the physicians’ diagnoses and one did worse, with a sensitivity of 74.42 percent.
Just one algorithm performed as well as human screeners in the test, achieving a comparable sensitivity of 80.47 percent and specificity of 81.28 percent.
Researchers also found that the algorithms’ performance varied when analyzing images from patient populations in Seattle and Atlanta care settings – indicating that algorithms may need to be trained with a wider range of images.
“It’s alarming that some of these algorithms are not performing consistently since they are being used somewhere in the world,"" said lead researcher Aaron Lee, assistant professor of ophthalmology at the University of Washington School of Medicine.
The team noted that differences in camera equipment and technique could be one explanation, and that their study demonstrates how critical it is for practices to test AI screeners and follow the guidelines about how to properly obtain images of patients’ eyes, because the algorithms are designed to work with a minimum quality of images.
While many studies highlight the potential for AI and machine learning to enhance the work of healthcare professionals, the findings of this research show that the technology is still very much in its infancy. Additionally, the results suggest that while these algorithms may have a high degree of accuracy and sensitivity on their own in the research realm, they may benefit from human input when being used in real-world clinical settings.
Separate studies have found that advanced analytics tools are most effective when combined with the expertise of human providers. In October 2019, a team from NYU School of Medicine and the NYU Center for Data Science showed that combining AI with analysis from human radiologists significantly improved breast cancer detection.
“Our study found that AI identified cancer-related patterns in the data that radiologists could not, and vice versa,” said senior study author Krzysztof J. Geras, PhD, assistant professor in the Department of Radiology at NYU Langone.
“AI detected pixel-level changes in tissue invisible to the human eye, while humans used forms of reasoning not available to AI. The ultimate goal of our work is to augment, not replace, human radiologists,” added Geras, who is also an affiliated faculty member at the NYU Center for Data Science.
In order to ensure humans aren’t left out of the equation, some researchers are working to develop algorithms that have the option to defer clinical decisions to human experts. A machine learning tool recently designed by MIT’s Computer Science and Artificial Intelligence Lab (CSAIL) is able to adapt when and how often it defers to human experts based on factors such as the expert’s availability and level of experience.
“Our algorithms allow you to optimize for whatever choice you want, whether that’s the specific prediction accuracy or the cost of the expert’s time and effort,” said David Sontag, the Von Helmholtz Associate Professor of Medical Engineering in the Department of Electrical Engineering and Computer Science.
“Moreover, by interpreting the learned rejector, the system provides insights into how experts make decisions, and in which settings AI may be more appropriate, or vice-versa.”

Next Steps
Healthcare Artificial Intelligence Requires Data Access, StandardsTop Challenges of Applying Artificial Intelligence to Medical ImagingArtificial Intelligence Method Builds in Error for Better Models





Dig Deeper on Artificial intelligence in healthcare



retina scan




By: Andrew Zola




Generative AI may bolster digital healthcare software development




By: Shania Kennedy




GPT-4 Matches Ophthalmologists in Glaucoma, Retina Management




By: Shania Kennedy




AI-Driven Eye Exams May Increase Screening Rates Among Diabetic Youth




By: Shania Kennedy







Sponsored News


Unlock the Value Of Your Data To Harness Intelligence and Innovation
–HPE


A Generative AI Use Case Brought to Life with Solutions from Dell Technologies
–Dell Technologies and Intel


Power Your Generative AI Initiatives With High-Performance, Reliable, ...
–Dell Technologies and Intel

See More





Related Content


Deep Learning Can Identify Newborns at High Risk of ...
– Healthtech Analytics


ADA Sessions Showcase Diabetic Retinopathy AI, ...
– Healthtech Analytics


Artificial Intelligence May Predict Osteoarthritis ...
– Healthtech Analytics








","{'@type': 'WebPage', '@id': 'https://www.techtarget.com/healthtechanalytics/news/366591375/Artificial-Intelligence-Falls-Short-in-Detecting-Diabetic-Eye-Disease'}",,,,,,,,,,"{'cssSelector': '.paywall', '@type': 'WebPageElement', 'isAccessibleForFree': False}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vZWR1Y2F0aW9uLndpc2MuZWR1L25ld3MvcHVudGFtYmVrYXItY29udHJpYnV0aW5nLXRvLTIwLW1pbGxpb24tbnNmLWZ1bmRlZC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbml0aWF0aXZlL9IBAA?oc=5,"Innovation: Puntambekar contributing to $20 million, NSF-funded artificial intelligence initiative - School of Education - University of Wisconsin–Madison",2021-01-02,University of Wisconsin–Madison,https://education.wisc.edu,,,,,https://schema.org,,,,,,,,,,,,,Learning Connections,,"

Innovation: Puntambekar contributing to $20 million, NSF-funded artificial intelligence initiative 

January 2, 2021 




















By Lynn Armitage, WCER Communications
UW–Madison’s Sadhana Puntambekar will collaborate with national researchers on establishing one of five artificial intelligence (AI) institutes and education hubs. A $100 million initiative of the National Science Foundation, the centers are the single most significant federal investment to date in exploring how AI can benefit the United States’ quality of life, economy, and international competitiveness.
Puntambekar
With an investment of $20 million over five years in each AI institute, the NSF has formed collaborations among researchers from some 30 universities across the country. Puntambekar, the sole representative from UW–Madison, will collaborate with peers from nine universities on the project known as the NSF AI Institute for Student-AI Teaming, spearheaded by the University of Colorado, Boulder. This institute will examine how AI can contribute to the future of education and workforce development.
“What is most exciting about this project is that it takes my previous work on distributed scaffolding to new levels in which we will develop paradigms for students, teachers, and AI agents, each bringing different strengths to work together and complement each other,” says Puntambekar, a Sears-Bascom professor with the School of Education’s Department of Educational Psychology and director of the Interactive Design and Learning Lab within the Wisconsin Center for Education Research. She adds that the institute’s vision is to create a classroom in which teachers, students, and AI work synergistically for effective teaching and learning.
According to Puntambekar, “AI models will help identify learning and collaboration patterns that would be nearly impossible for teachers to identify on their own, let alone in real time. For instance, using content and semantic analysis, AI could recognize two groups that are developing complementary arguments and suggest they share their work to develop more complete reasoning.” She says that AI can also help alert teachers about when, where, and why it may be productive for them to engage with students.
In addition to collaborating with the University of Colorado, Boulder, Puntambekar will work closely on this AI initiative with education partners from seven other universities: Colorado State University; the University of California, Santa Cruz; the University of California, Berkeley; Brandeis University; Worcester Polytechnic University; Georgia Institute of Technology; and the University of Illinois at Urbana-Champaign.
This last month has been exceptionally rewarding for the WCER researcher. Puntambekar has received two other NSF grants exceeding a million dollars each to help advance STEM learning in middle school.
“It’s quite unbelievable to land three grants, one after the other,” shares Puntambekar. “All the projects that were funded proposed innovative uses of technology to support and understand students’ learning. And they all build on my prior work on federally funded projects.”






















 


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebSite', '@id': 'https://education.wisc.edu/#website', 'url': 'https://education.wisc.edu/', 'name': 'School of Education', 'potentialAction': {'@type': 'SearchAction', 'target': 'https://education.wisc.edu/?s={search_term_string}', 'query-input': 'required name=search_term_string'}}, {'@type': 'WebPage', '@id': 'https://education.wisc.edu/news/puntambekar-contributing-to-20-million-nsf-funded-artificial-intelligence-initiative/#webpage', 'url': 'https://education.wisc.edu/news/puntambekar-contributing-to-20-million-nsf-funded-artificial-intelligence-initiative/', 'inLanguage': 'en-US', 'name': 'Innovation: Puntambekar contributing to $20 million, NSF-funded artificial intelligence initiative - School of Education', 'isPartOf': {'@id': 'https://education.wisc.edu/#website'}, 'datePublished': '2021-01-02T19:15:46+00:00', 'dateModified': '2021-01-04T16:48:41+00:00'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPmh0dHBzOi8vZGFpbHl0cnVzdC5jb20vbXVjaC1hZG8tYWJvdXQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,Much ado about Artificial Intelligence - Daily Trust,2021-01-04,Daily Trust,https://dailytrust.com,"In 2017, I visited one of the world’s first and most innovative Artificial Intelligence  companies, DeepMind Technologies on Pancras Square in London. This was an eye-opening experience for me as it heightened my understanding of what the best people in the game worked on and just how far exactly the…",,"In 2017, I visited one of the world’s first and most innovative Artificial Intelligence  companies, DeepMind Technologies on Pancras Square in London. This was an eye-opening experience for me as it heightened my understanding of what the best people in the game worked on and just how far exactly the…","In 2017, I visited one of the world’s first and most innovative Artificial Intelligence  companies, DeepMind Technologies on Pancras Square in London. This was an eye-opening experience for me as it heightened my understanding of what the best people in the game worked on and just how far exactly the…",,,,,,,,,,,,,,Opinion,,"
In 2017, I visited one of the world’s first and most innovative Artificial Intelligence  companies, DeepMind Technologies on Pancras Square in London. This was an eye-opening experience for me as it heightened my understanding of what the best people in the game worked on and just how far exactly the technology has reached beyond the hype. I came face to face with applications that not only demonstrated the immense possibilities of Artificial Intelligence like the Alpha, which famously beat the human world champion of the complex board game, ‘Go’ but also some great examples of how machine learning is helping revolutionise areas like Healthcare with DeepMind’s work with some hospitals and even the United Kingdom’s NHS.  However, my earlier observation was that Artificial Intelligence was at best aspirational at the time, with a lot of future potentials but not quite there yet as the best examples where games, or toys or social media influence.
Since my visit to DeepMind, they have gone from AlphaZero to AlphaGo and now to AlphaFold, which is far from a chess winning machine learning algorithm. AlphaFold accurately predicts the shape of proteins. Not the protein in the context of nutrition but the self-assembling nanomachines that do almost everything in the body. Our cellular processes — everything, which can be said to make us alive — are tasks carried out by proteins. Protein folding (one of the toughest problems in science) could thus help scientists understand the biological processes of every living thing. This is because a protein’s shape is closely linked with its function, and the ability to predict this structure unlocks a greater understanding of what it does and how it works. This means drugs could be discovered more rapidly, diseases treated faster and the unlocking of many great mysteries. Thanks to Machine Learning and Artificial Intelligence. But just what are these terms that people throw around a lot and how do these techniques work?
ad                           Next   Stay       Traveling across Quang Binh to stunning cinematic locations            40         42                                                                                                              00:00                                                       00:00  /  00:00           10 Sec             

Why Lake Rice deal collapsed
With prayer, Nigeria will overcome insecurity – NCPC Boss

Artificial Intelligence
In global terms, 2021 heralds us into a new decade of exciting advancements in technology. One of the most talked-about aspects of technology is Artificial Intelligence or AI. Because it is constantly evolving and transforming, the definition of AI is complicated, depending on who you ask. Hollywood movies have for long used sentient humanoid robots to define it, while another popular culture has popularised self-driving cars and chess-playing bots. In simple terms, AI refers to machines that can reason and act on their own. Like humans and animals, artificially intelligent machines can make decisions for themselves when faced with new situations.


Machine Learning
The quest for artificial intelligence and its builders is the creation of machines that can reason, learn, and act intelligently. Most of the advancements in AI you hear about today are machine learning-based. Machine Learning is, therefore, a type of artificial intelligence that utilises statistics to find patterns in huge sets of data. Data here refers to anything in the digital form fed into the machine learning algorithm ranging from numbers, words, pictures, likes, clicks, etc. Popular examples of machine learning applications are recommendation systems on YouTube and Netflix, search engines like google, social network feeds like Facebook and voice assistants like Siri. Within all these examples is the deep observation of your behavior whether it’s what you watch, click, listen to, like or what you ignore, dislike or say in the case of voice assistance. A pattern is then established by machine learning and an educated guess is made about what you may like or do on the platforms.
Deep Learning
This brings me to a type of machine learning called Deep Learning. Imagine a tremendously better machine learning that can identify and amplify even the smallest pattern. It is also referred to as a deep neural network due to its multi-layered computational nodes that work cohesively to predict, with relative accuracy, based on the data it is fed.  So, in essence, deep learning is basically neural networks; which get their name inspired by the inner workings of the human brain with the nodes acting like neurons and the network acting like a brain. 




You now get the idea of Artificial Intelligence and you know that Machine Learning is by far its most prevalent application. You understand how machine and deep learning work. To complete this gamut, you should know that machine learning (and deep learning) has three varieties. Supervised, unsupervised and reinforced learning.  Supervised learning is the most prevalent variety whereby the computer or machine is told what to look for by labelling the data in order to signal to the machine to look for similar patterns. Every time you watch a show on Netflix, the algorithm will remember it and try to find similar shows based on that reference.
On the contrary, unsupervised learning allows the machine to look for whatever patterns it can find. Here the data has no labels and the algorithm just combs through everything and sorts or arranges based on a wide-ranging parameter identified in the patterns. This is way less popular than supervised learning but has strong applications and is gaining a lot of ground in cybersecurity.
Lastly, there is Reinforcement Learning, which involves the algorithm learning from trial and error to achieve a clear objective. Many consider this to be the latest frontier of machine learning. The algorithm tries out various things towards achieving the set objective and gets either rewarded or penalised depending on how much the particular behaviour helps or hinders it from achieving the set objective.


These are the basic concepts around artificial intelligence and are pretty much the areas to get the most attention from this decade onwards, as we set into a different type of world where artificial intelligence will take on new definitions and become much more practical rather than aspirational as it has been in the past decades.




Join Daily Trust WhatsApp Community For Quick Access To News and Happenings Around You.






",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPGh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjEvMDEvMDQvb3Bpbmlvbi9nb29nbGUtdW5pb24uaHRtbNIBAA?oc=5,Opinion | We're Google Workers. And We're Forming a Union. - The New York Times,2021-01-04,The New York Times,https://www.nytimes.com,Our company’s motto used to be “Don’t be evil.” An organized work force will help us live up to it.,,Our company’s motto used to be “Don’t be evil.” An organized work force will help us live up to it.,Our company’s motto used to be “Don’t be evil.” An organized work force will help us live up to it.,https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/01/05/opinion/04google-02/04google-02-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2021/01/05/opinion/04google-02/04google-02-videoSixteenByNineJumbo1600.jpg', 'caption': 'Protests in Mountain View, Calif., during the November 2018 walkout.', 'creditText': 'Stephen Lam/Reuters'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/01/05/opinion/04google-02/04google-02-superJumbo.jpg', 'height': 1366, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2021/01/05/opinion/04google-02/04google-02-superJumbo.jpg', 'caption': 'Protests in Mountain View, Calif., during the November 2018 walkout.', 'creditText': 'Stephen Lam/Reuters'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/01/05/opinion/04google-02/04google-02-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2021/01/05/opinion/04google-02/04google-02-mediumSquareAt3X.jpg', 'caption': 'Protests in Mountain View, Calif., during the November 2018 walkout.', 'creditText': 'Stephen Lam/Reuters'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': '', 'name': 'Parul Koul'}, {'@context': 'https://schema.org', '@type': 'Person', 'url': '', 'name': 'Chewy Shaw'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",Opinion | We're Google Workers. And We're Forming a Union. ,2021-01-04T11:05:56.000Z,2021-01-04T21:17:49.000Z,,The New York Times,False,,Opinion,,"AdvertisementSKIP ADVERTISEMENTOpinionSupported bySKIP ADVERTISEMENTWe Built Google. This Is Not the Company We Want to Work For.Our company’s motto used to be “Don’t be evil.” An organized work force will help us live up to it.Jan. 4, 2021Protests in Mountain View, Calif., during the November 2018 walkout.Credit...Stephen Lam/ReutersShare full article847Read in appBy Parul Koul and Chewy ShawMs. Koul and Mr. Shaw are, respectively, the executive chair and the vice chair of the Alphabet Workers Union.On Nov. 1, 2018, at 11:10 a.m., some 20,000 Google employees, along with employees of Waymo, Verily and other Alphabet companies, stopped working and walked off the job in cities around the world. A week earlier, The New York Times reported that the company had paid tens of millions of dollars to two executives who had been accused of sexual misconduct toward our co-workers, staying silent about the alleged abuse and letting them walk away with no consequences.People speaking at the protests that morning recounted their own experiences of harassment and discrimination at the company. In San Francisco, one woman held up a sign reading, “I reported and he got promoted.” Others read, “Happy to quit for $90 million, no sexual harassment required” and “Unfair workplaces create unfair platforms.”We’d had enough.The two of us are software engineers, and we were recently elected executive chair and vice chair of the Alphabet Workers Union, a group of more than 200 workers in the United States who believe our company’s structure needs to change.For far too long, thousands of us at Google — and other subsidiaries of Alphabet, Google’s parent company — have had our workplace concerns dismissed by executives. Our bosses have collaborated with repressive governments around the world. They have developed artificial intelligence technology for use by the Department of Defense and profited from ads by a hate group. They have failed to make the changes necessary to meaningfully address our retention issues with people of color.AdvertisementSKIP ADVERTISEMENTMost recently, Timnit Gebru, a leading artificial intelligence researcher and one of the few Black women in her field, said she was fired over her work to fight bias. Her offense? Conducting research that was critical of large-scale A.I. models and being critical of existing diversity and inclusion efforts. In response, thousands of our colleagues organized, demanding an explanation. Both of us have heard from colleagues — some new, some with over a decade at the company — who have decided that working at Alphabet is no longer a choice they can make in good conscience.Sign up for the Opinion Today newsletter  Get expert analysis of the news and a guide to the big ideas shaping the world every weekday morning.  Get it sent to your inbox.Workers have mobilized against these abuses before. Organized workers at the company forced executives to drop Project Maven, the company’s artificial-intelligence program with the Pentagon, and Project Dragonfly, its plan to launch a censored search engine in China. Some of Alphabet’s subcontractors won a $15 minimum hourly wage, parental leave, and health insurance after an employee outcry. And the practice of forced arbitration for claims of sexual harassment was ended after the November 2018 walkout — albeit only for full-time employees, not contractors. A few months later, Google announced that it would end forced arbitration for employees for all claims.To those who are skeptical of unions or believe that tech companies are more innovative without unions, we want to point out that these and other larger problems persist. Discrimination and harassment continue. Alphabet continues to crack down on those who dare to speak out, and keep workers from speaking on sensitive and publicly important topics, like antitrust and monopoly power. For a handful of wealthy executives, this discrimination and unethical working environment are working as intended, at the cost of workers with less institutional power, especially Black, brown, queer, trans, disabled, and female workers. Each time workers organize to demand change, Alphabet’s executives make token promises, doing the bare minimum in the hopes of placating workers.It’s not enough. Today, we’re building on years of organizing efforts at Google to create a formal structure for workers. So far, 226 of us have signed union cards with the Communications Workers of America — the first step in winning a recognized bargaining unit under U.S. law. In other words, we are forming a union.We are the workers who built Alphabet. We write code, clean offices, serve food, drive buses, test self-driving cars and do everything needed to keep this behemoth running. We joined Alphabet because we wanted to build technology that improves the world. Yet time and again, company leaders have put profits ahead of our concerns. We are joining together — temps, vendors, contractors, and full-time employees — to create a unified worker voice. We want Alphabet to be a company where workers have a meaningful say in decisions that affect us and the societies we live in.AdvertisementSKIP ADVERTISEMENTAs union members, we have created an elected leadership and representative structure with dues-paying members. Our union will be open to all Alphabet workers, regardless of classification. About half of the workers at Google are temps, vendors or contractors. They are paid lower salaries, receive fewer benefits, and have little job stability compared with full-time employees, even though they often do the exact same work. They are also more likely to be Black or brown — a segregated employment system that keeps half of the company’s work force in second-class roles. Our union will seek to undo this grave inequity.Everyone at Alphabet — from bus drivers to programmers, from salespeople to janitors — plays a critical part in developing our technology. But right now, a few wealthy executives define what the company produces and how its workers are treated. This isn’t the company we want to work for. We care deeply about what we build and what it’s used for. We are responsible for the technology we bring into the world. And we recognize that its implications reach far beyond the walls of Alphabet.Our union will work to ensure that workers know what they’re working on, and can do their work at a fair wage, without fear of abuse, retaliation or discrimination. When Google went public in 2004, it said it would be a company that “does good things for the world even if we forgo some short-term gains.” Its motto used to be “Don’t be evil.”We will live by that motto. Alphabet is a powerful company, responsible for vast swaths of the internet. It is used by billions of people across the world. It has a responsibility to prioritize the public good. It has a responsibility to its thousands of workers and billions of users to make the world a better place. As Alphabet workers, we can help build that world.Parul Koul is the executive chair of the Alphabet Workers Union. She is a software engineer who joined Google in 2019. Chewy Shaw is the vice chair of the Alphabet Workers Union. He is a site reliability engineer who has been at Google since 2011.The Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this or any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.Follow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.A version of this article appears in print on Jan. 5, 2021, Section A, Page 19 of the New York edition with the headline: A Union Will Make Google Better. Order Reprints | Today’s Paper | SubscribeRead 847 CommentsShare full article847Read in appAdvertisementSKIP ADVERTISEMENTComments 847We Built Google. This Is Not the Company We Want to Work For.Skip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Tell us about yourself. Take the survey.",https://www.nytimes.com/2021/01/04/opinion/google-union.html,,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",,https://www.nytco.com/company/diversity-and-inclusion/,,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",,,Opinion | We Built Google. This Is Not the Company We Want to Work For.,,,,en,,,1851-09-18,,,https://en.wikipedia.org/wiki/The_New_York_Times,,,,2024.0,,,,,{'@id': '#commentsContainer'},847.0,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3Lm1vbml0b3IuY28udWcvdWdhbmRhL2J1c2luZXNzL3Byb3NwZXIvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY291bGQtcm9ib3RzLXRha2Utb3Zlci15b3VyLWpvYi0tMTc5NjA3NtIBAA?oc=5,Artificial Intelligence: Could robots take over your job? - Monitor,2021-01-03,Monitor,https://www.monitor.co.ug,"<p>With the rapid evolution of AI and the enthusiasm demonstrated by both governments and large corporations, it is nearly impossible to give a precise vision of what the AI space will look like in the coming years</p>",,"
With the rapid evolution of AI and the enthusiasm demonstrated by both governments and large corporations, it is nearly impossible to give a precise vision of what the AI space will look like in...",,https://schema.org,BreadcrumbList,,"['https://www.monitor.co.ug/resource/image/1796078/landscape_ratio16x9/1600/900/84b8f623f6540c52060241022b7d6dae/VA/pro7-pic.jpg', 'https://www.monitor.co.ug/resource/image/1796078/landscape_ratio3x2/1620/1080/d9cb7fc0b03a12a3ac878c3d49854fcb/kk/pro7-pic.jpg', 'https://www.monitor.co.ug/resource/image/1796078/portrait_ratio1x1/1600/1600/8ad612a35b8b1df4ae6f3dab5b07b860/ql/pro7-pic.jpg']",,"{'@type': 'Organization', 'name': 'Monitor', 'logo': {'@type': 'ImageObject', 'url': 'https://www.monitor.co.ug/resource/crblob/4637192/61e515b0ca6d190e96961691d558011e/dm-structured-data-logo-png-data.png', 'width': 242, 'height': 60}}",Artificial Intelligence: Could robots take over your job?,2018-12-17T10:11:15Z,2021-01-03T09:14:04Z,,Artificial Intelligence: Could robots take over your job?,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.monitor.co.ug/uganda'}, {'@type': 'ListItem', 'position': 2, 'name': 'Business', 'item': 'https://www.monitor.co.ug/uganda/business'}, {'@type': 'ListItem', 'position': 3, 'name': 'Prosper', 'item': 'https://www.monitor.co.ug/uganda/business/prosper'}]",,,"






PRIME


 Finance releases Shs6 trillion for quarter one 


Finance


7 hours ago








","{'@type': 'WebPage', '@id': 'https://www.monitor.co.ug/uganda/business/prosper/artificial-intelligence-could-robots-take-over-your-job--1796076'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPWh0dHBzOi8vd3d3LnNpbXBsaWxlYXJuLmNvbS9vcGVuLXNvdXJjZS1haS1mcmFtZXdvcmtzLWFydGljbGXSAQA?oc=5,The Top Five Open-Source AI Frameworks - Simplilearn,2021-01-05,Simplilearn,https://www.simplilearn.com,"The results of an AI application are determined by the model architecture. Learn about ✅the best open-source AI frameworks, from Theano to Pytorch. Read on!","ai frameworks, open source ai frameworks, top ai frameworks, best ai frameworks, artificial intelligence framework","The results of an AI application are determined by the model architecture. Learn about ✅the best open-source AI frameworks, from Theano to Pytorch. Read on!","The results of an AI application are determined by the model architecture. Learn about ✅the best open-source AI frameworks, from Theano to Pytorch. Read on!",https://schema.org,BreadcrumbList,https://www.simplilearn.com/open-source-ai-frameworks-article,"{'@type': 'ImageObject', 'url': 'https://www.simplilearn.com/ice9/free_resources_article_thumb/The_Top_Five_Open_Source_AI_Frameworks.jpg', 'height': '506', 'width': '900'}","{'@type': 'Person', 'name': 'Matthew David', 'url': 'https://www.simplilearn.com/authors/matthew-david'}","{'@type': 'Organization', 'name': 'Simplilearn', 'logo': {'@type': 'ImageObject', 'url': 'https://www.simplilearn.com/logo.png', 'width': '200', 'height': '200'}}",The Top Five Open-Source AI Frameworks,2020-12-31T09:48:35+05:30,2023-11-07T13:01:22+05:30,,The Top Five Open-Source AI Frameworks,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.simplilearn.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.simplilearn.com/resources', 'name': 'Resources'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.simplilearn.com/resources/artificial-intelligence-machine-learning', 'name': 'AI & Machine Learning'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://www.simplilearn.com/open-source-ai-frameworks-article', 'name': 'The Top Five Open-Source AI Frameworks'}}]",,,"
A popular misconception is that programming languages are crucial for an AI framework based on neural networks. The results of an AI application are determined by the model architecture rather than the particular language.
Unsurprisingly, Natural Language Processing (NLP), computer vision, and image processing are massive driving forces in AI.
Most popular neural processing frameworks are available as cloud services, such as Google's Tensorflow. According to my data analysis from Stack Overflow, Google's Tensorflow was the most popular machine learning framework, both by installations and downloads, in 2018.
Let us now look at the top open-source AI frameworks.
Become a AI & Machine Learning Professional$267 billionExpected Global AI Market Value By 202737.3%Projected CAGR Of The Global AI Market From 2023-2030$15.7 trillionExpected Total Contribution Of AI To The Global Economy By 2030Artificial Intelligence EngineerIndustry-recognized AI Engineer Master’s certificate from SimplilearnDedicated live sessions by faculty of industry experts11 Months monthsView ProgramPost Graduate Program in AI and Machine LearningProgram completion certificate from Purdue University and SimplilearnGain exposure to ChatGPT, OpenAI, Dall-E, Midjourney & other prominent tools11 Months monthsView ProgramprevNextHere's what learners are saying regarding our programs:Indrakala Nigam BeniwalTechnical Consultant, Land Transport Authority (LTA) SingaporeI completed a Master's Program in Artificial Intelligence Engineer with flying colors from Simplilearn. Thanks to the course teachers and others associated with designing such a wonderful learning experience. Akili YangPersonal Financial Consultant, OCBC BankThe live sessions were quite good; you could ask questions and clear doubts. Also, the self-paced videos can be played conveniently, and any course part can be revisited. The hands-on projects were also perfect for practice; we could use the knowledge we acquired while doing the projects and apply it in real life. prevNextNot sure what you’re looking for?View all Related Programs
1) Tensorflow
Google Tensorflow, an open-source software framework for building and using machine learning neural networks, is very easy to set up and extend. It's the most popular deep learning framework, with the largest number of GitHub stars and the second-highest percentage of open source repositories. 
Tensorflow is probably the most comfortable framework for beginners to work with. However, some neural processing experts may feel a little overwhelmed by the sheer amount of tools and features, making it almost impenetrable to experienced developers.
We will now learn about the next AI framework, RNN.
2) RNN
RNN is an emerging framework for supervised learning and has an extremely flexible and intuitive interface. It's also suitable for designing algorithms for ""deep learning,"" which can be used to distinguish between ""like"" and ""dislike"" in data sets. 
RNN is the second most popular deep learning framework for neural processing and natural language processing. The user community has been extraordinarily active and very helpful, and the project is under active development. According to neural processing experts, it's not the right choice for general ML coding because of the extra layers of abstraction. Neural processing expert Joe Callaghan compared RNN to WATM and said, ""RNN is too hard to learn, but a lot of fun to experiment with."" (Source: Stack Overflow)
The next AI framework is theano.
3) Theano
Theano, an open-source python library for deep learning, is also popular in the neural processing and data science communities. It's widely known for making it easy to implement complex neural networks by abstracting away the neural network components (such as the layers and hidden layers). It's often used to build and train AI models on graphics processing units (GPUs) and has been adopted by Facebook for both training and deploying AI applications.
Theano comes with a library of algorithms that perform neural network operations on data frames. It works with Python, C++, Java, Julia, Scala, and Tensorflow and is currently the most popular AI framework used by developers who use either Tensorflow or Theano. Theoretically, Theano can be used on any platform, but most Theano developers use Tensorflow and Tensorboard.
Theano is a deep learning framework with a comprehensive library of complex algorithms. It is used for training models to perform image classification, object detection, language translation, and speech recognition. Theano has the most extensive library of popular machine learning algorithms, easily combined with Tensorflow.
Tensorflow and Theano are used for most deep learning applications. However, they are not the best choice for NLP.
4) PyTorch
PyTorch is an optimized Python framework for building machine learning algorithms. Researchers often use it for research purposes, but it's also popular among developers who use Tensorflow. 
Medium is a free, open-source Python framework for creating systems, large or small. According to the developers, it's the most ""intuitive"" framework for building systems because it has the most comprehensive interface to hardware accelerators and a friendly API. However, it has a reputation for slow response times when dealing with GPUs.
Torch's versatility is impressive, and developers can use it to train, test, and deploy systems for deep learning and NLP. However, it can also be challenging to set up and maintain, and it doesn't seem to be used as much as other, more established frameworks. 
Parsey McParseface is a Python library for building machine learning models. Its interface is similar to Theano, but it supports a broader set of APIs and supports a more comprehensive range of training data types. 
We will now look at the next AI framework.
5) Caffe2
It is essential to understand that Caffe2 is not a traditional framework for AI training. Instead, it is a trained inference engine based on Neural Networks. The end goal of Caffe2 is to provide the best results in a highly efficient manner compared to Caffe. 
Caffe2 is a powerful open-source library that makes it easy to create deep learning models using the PyTorch framework. We can quickly develop scalable models and get rid of the typical computations involved in traditional models. That is why with Caffe2, we can make the most of our machines and get maximum efficiency out of them.
It is a Python library, and there is no need to worry about any other libraries or third party applications as you can rely on it to furnish the whole framework you will use in the project.
The Best Neural Processing Frameworks for Beginners
Some advanced deep learning frameworks allow neural processing, but many developers are unaware of the many prebuilt plugins and libraries that can enhance RNN and Tensorflow. These frameworks have been incorporated into products such as Microsoft Azure ML and Google Cloud Machine Learning.

Mylica is a Python framework for running neural processing, reinforcement learning, and reinforcement learning, easily customized for specific projects' needs. 
Karos is an open-source reinforcement learning framework that includes a library of reinforcement learning algorithms. It's famous for training reinforcement learning systems on GPUs, and it is compatible with Tensorflow. 
Trainedata is a Python library for creating large-scale reinforcement learning systems. The library's algorithms can run on Python 2.7, 3.4, and 4.x.
Vowpal Wabbit is an open-source deep learning framework that supports reinforcement learning. The idea behind Vowpal Wabbit is to accelerate the training of neural networks in reinforcement learning systems. 

Python has emerged as the most popular language for NLP development. Although useful for other applications, most of these frameworks and libraries are optimized for running on the Python Virtual Machine, which provides highly efficient performance for processing tensor data. It is a very convenient framework for the development of neural network applications.
Deep learning and neural networks are becoming more popular in some fields, including computer vision, health care, and cybersecurity. Machine learning in this emerging field has led to many new applications. As data sources increase, data scientists' demand is likely to increase significantly, leading to more demand for neural processing skills. To take advantage of this trend for your career, consider a comprehensive skilling programs like the Caltech Post Graduate Program in AI and Machine Learning, a collaboration between Simplilearn and Caltech CTME and The Masters in Artificial Intelligence, a dual degree program in collaboration with the International University of Applied Sciences (IU) Germany in collaboration with the London South Bank University (LSBU).
If you have any quesions, feel free to post them in the comments section below. Our team will get back to you at the earliest.

","{'@type': 'WebPage', '@id': 'https://www.simplilearn.com/open-source-ai-frameworks-article'}",,,,,,,,,,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9iZXN0LWNpdGllcy10by13b3JrLWFzLWEtZGF0YS1zY2llbnRpc3QtYTI5NWZmNjBjNmVm0gEA?oc=5,Best Cities to Work as a Data Scientist - Towards Data Science,2021-01-05,Towards Data Science,https://towardsdatascience.com,"The job landscape for Data Scientists is promising. According to the US Bureau of Labour Statistics, by 2026, there will be roughly 11.5 million job openings [1]. These numbers suggest that companies…",,Silicon Valley isn’t your only option. Data Scientists are in demand worldwide and speaking English and French might become a valuable…,Silicon Valley isn’t your only option. Data Scientists are in demand worldwide and speaking English and French might become a valuable…,http://schema.org,NewsArticle,https://towardsdatascience.com/best-cities-to-work-as-a-data-scientist-a295ff60c6ef,['https://miro.medium.com/v2/resize:fit:1200/1*fQbnzjYzRGOPctGG8qNUOA.jpeg'],"{'@type': 'Person', 'name': 'Renato Boemer', 'url': 'https://boemer.medium.com'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",Best Cities to Work as a Data Scientist - Towards Data Science,2021-01-04T16:51:25.546Z,2021-12-26T04:13:25.995Z,,Best Cities to Work as a Data Scientist - Towards Data Science,False,,,,"Member-only storyBest Cities to Work as a Data ScientistSilicon Valley isn’t your only option. Data Scientists are in demand worldwide and speaking both English and French might become a valuable skill.Renato Boemer·FollowPublished inTowards Data Science·6 min read·Jan 4, 20211084ListenSharePhoto by Stephen Leonardi on UnsplashThe job landscape for Data Scientists is promising. According to the US Bureau of Labour Statistics, by 2026, there will be roughly 11.5 million job openings [1]. These numbers suggest that companies outside Silicon Valley recognise the importance of data professionals to their business. As a result, both experienced professionals and those in a career change to Data Science can expand their horizons. Although, Silicon Valley is still the number one area for data professionals — and with the highest average salaries — it’s not the only option.Based on the growing demand in different industries, the list of cities below are on a positive trend for Data Scientists. Some of the factors influencing the list below include the number of hiring companies, government investment, collaboration between academia and industry as well as salary. Interestingly, leading cities are no longer exclusively English-speaking. Investments in Data Professionals and Artificial Intelligence are also directed to French-speaking areas. The French-speaking trend might gain thrust now that the UK has left the European Union.",https://towardsdatascience.com/best-cities-to-work-as-a-data-scientist-a295ff60c6ef,2021-01-04T16:51:25.546Z,,,a295ff60c6ef,['Renato Boemer'],,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOGh0dHBzOi8vd3d3Lm1ha2V1c2VvZi5jb20vaG93LWRvZXMtcmVwbGlrYS1jaGF0Ym90LXdvcmsv0gEA?oc=5,A Deep Dive Into Replika: My AI Friend - MUO - MakeUseOf,2021-01-01,MUO - MakeUseOf,https://www.makeuseof.com,The Replika chat bot can provide realistic responses and even copy your style of communication. How does it do this?,,The Replika chat bot can provide realistic responses and even copy your style of communication. How does it do this?, The Replika chat bot can provide realistic responses and even copy your style of communication. How does it do this? ,http://schema.org,Article,,"{'@type': 'ImageObject', 'contentUrl': 'https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2020/12/Replika-AI-Featured-2.jpg', 'height': '840', 'width': '1680'}","[{'@type': 'Person', '@id': 'https://www.makeuseof.com/author/yash-chellani/#author', 'name': 'Yash Chellani', 'url': 'https://www.makeuseof.com/author/yash-chellani/', 'description': 'Yash is an aspiring computer science student who loves to build things and write about all things tech. In his free time, he likes to play Squash, read a copy of the latest Murakami, and hunt dragons in Skyrim.', 'image': 'https://static1.makeuseofimages.com/wordpress%2Fwp-content%2Fauthors%2F5fd793a21d94e-face%20pic.png', 'sameAs': []}]","{'@type': 'Organization', '@id': 'https://https://www.makeuseof.com/#organization', 'name': 'MakeUseOf', 'url': 'https://https://www.makeuseof.com', 'description': 'MUO is your guide to modern tech. Learn how to make use of the tech and gadgets around you, and discover cool stuff on the internet.', 'publishingPrinciples': 'https://www.valnetinc.com/en/terms-of-use', 'foundingDate': '2007', 'alternateName': 'MUO', 'sameAs': [], 'logo': {'@type': 'ImageObject', 'url': 'https://www.makeuseof.com/public/build/images/muo-amp-logo.png', 'height': '101', 'width': '202'}}",A Deep Dive Into Replika: My AI Friend,2021-01-01T15:00:00Z,2021-01-01T15:00:00Z,"['Technology Explained', 'Artificial Intelligence', 'Chatbot']",,True,"[{'@type': 'ListItem', 'position': '1', 'name': 'Home', 'item': 'https://www.makeuseof.com/'}, {'@type': 'ListItem', 'position': '2', 'name': 'Technology Explained', 'item': 'https://www.makeuseof.com/category/technology-explained/'}, {'@type': 'ListItem', 'position': '3', 'name': 'A Deep Dive Into Replika: My AI Friend', 'item': 'https://www.makeuseof.com/how-does-replika-chatbot-work/'}]",Technology Explained,,"


A Deep Dive Into Replika: My AI Friend
Artificial Intelligence









By 
Yash Chellani


Published Jan 1, 2021




Your changes have been saved

Email Is sent




close
Please verify your email address.


Send confirmation email






close
You’ve reached your account maximum for followed topics.
Manage Your List





 Follow 



Followed




Follow with Notifications



Follow



Unfollow







Share



Facebook



X



LinkedIn



Reddit



Flipboard



Copy link



Email




Link copied to clipboard




Artificial Intelligence


Related




















			What Is AI Slop and What Can You Do About It?
		




























			Try This ""AI or Human?"" Test to Challenge Your AI Detection Skills
		




























			This New Browser Is a Productivity Miracle
		













Sign in to your MUO account



















 Replika: My AI Friend is an app unlike any other. While most apps out there with chatbots use them as virtual assistants, Replika markets its chatbot as—you guessed it—a friend. 








 With its promised ability to ""perceive"" and evaluate abstract quantities such as emotion, Replika’s chatbot might just do justice to its aspirationally human description. 

 From a heart-wrenching origin story to an awe-inspiring backend, Replika is one of those fascinating things that never stop being interesting. Read on to find out about what it is that makes Replika’s AI so remarkable and what promises it holds for the future. 


 The Origins of Replika 
 Replika’s earliest version—a simple AI chatbot—was created by Eugenia Kuyda to replace the void left by the untimely loss of her closest friend, Roman Mazurenko. Built by feeding Roman’s text messages into a neural network to construct a bot that texted just like him, it was meant to serve as a ""digital monument"" of sorts to keep his memory alive. 






 Eventually, with the addition of more complex language models into the equation, the project soon morphed into what it is today—a personal AI that offers a space where you can safely discuss your thoughts, feelings, beliefs, experiences, memories, dreams—your “private perceptual world”. 

 But besides the immense technical and social prospects of this artificially sentient therapist of sorts, what really makes Replika impressive is the technology at its core. 



 Under the Hood 
 At Replika’s heart lies a complex autoregressive language model called GPT-3 that utilizes deep learning to produce human-like text. In this context, the term ""autoregressive"" suggests that the system learns from values (text in this case) that it has previously interacted with. 

 In layman's terms, the more you use it, the better it becomes. 

    





 Replika’s entire UX is built around the user’s interactions with a bot programmed using GPT-3. But what exactly is GPT-3 and how is it powerful enough to emulate human speech? 



 GPT-3: An Overview 
 GPT-3, or Generative Pre-trained Transformer 3, is a more advanced adaptation of Google’s Transformer. Broadly speaking, it’s a neural network architecture that helps machine learning algorithms perform tasks such as language modeling and machine translation. 

 The nodes of such a neural network represent parameters and processes which modify inputs accordingly (somewhat similar to logic and/or conditional statements in programming), while the edges or connections of the network act as signaling channels from one node to another. 

    





 Every connection in this neural network has a weight, or an importance level, which determines the flow of signals from one node to the other. In an autoregressive learning model such as GPT-3, the system receives real-time feedback and continually adjusts the weights of its connections in order to provide more accurate and relevant output. It's these weights that help a neural network ‘learn’ artificially. 

  Related: What Is Machine Learning? Google's Free Course Breaks It Down for You 

 GPT-3 uses a whopping 175 billion connection weight levels or parameters. A parameter is a calculation in a neural network that adjusts the weight of some aspect of the data, to give that aspect greater or lesser prominence in the overall calculation of the data. 

 Hailed as the ultimate autocomplete, GPT-3’s language model, which is purposed to provide predictive text, has been trained on such a vast dataset that all of Wikipedia constitutes merely 0.6 percent of its training data. 





 It includes not only things like news articles, recipes, and poetry, but also coding manuals, fanfiction, religious prophecy, guides to the mountains of Nepal, and whatever else you can imagine. 

    

 As a deep learning system, GPT-3 scours for patterns in data. To put it simply, the program has been trained on a massive collection of text which it mines for statistical regularities. These regularities, such as language conventions or general grammatical structure are often taken for granted by humans, but they’re stored as billions of weighted connections between the different nodes in GPT-3’s neural network. 






 For example, If you input the word “ear” into GPT-3, the program knows, based on the weights in its networks, that the words “ache” and “phone” are much more likely to follow than “American” or “angry”. 



 GPT-3 and Replika: A Meaningful Confluence 
 Replika is what you get when you take something like GPT-3 and distill it to address specific types of conversation. In this case, this includes the empathetic, emotional, and therapeutic aspects of a conversation. 

 While the technology behind Replika is still under development, it offers a plausible gateway to easily accessible interpersonal conversation. 

 Commenting on its usability, the creators claim that they have created a bot that not only talks but also listens. What this means for its users is that their talks with the AI are not a mere exchange of facts and information, but rather a dialogue equipped with linguistic nuances. 






 But talks with Replika aren’t just a matter of sensible dialogue. They also happen to be surprisingly meaningful and emotive in many cases. While interacting with a user, Replika’s AI ""understands"" what the user says, and finds a human response by using its predictive learning model. 

    

 As an autoregressive system, Replika learns and adapts its conversational patterns based on the user’s own way of talking to it. 

 This means that the more you use Replika, the more it trains on your own texts, and the more it becomes like you. A good proportion of users have also mentioned that they have a significant level of emotional attachment to their Replika—something that is not achieved by merely knowing ""how to talk."" 






 Replika of course goes above and beyond that. It adds depth to its conversations in the form of semantic generalization, inflective speech, and conversation tracking. Its algorithm tries to understand who you are—both in terms of your personality and emotions—and then molds the dialogue based on this information. 



 A Closer Look at the Efficacy of GPT-3 
 However, Replika’s humanness is still largely theoretical due to the operational limitations of GPT-3. As such, there is much work to be done for the AI to competently replicate and participate in human conversation. 

 Close inspections of GPT-3 still reveal clearly distinguishable errors as well as nonsensical and plain sloppy writing in some cases. Industry experts suggest that a language processing model would need to have upwards of 1 trillion weighted connections before it can be used to produce bots that are able to effectively replicate human lingo. 








 The Best is Yet to Come 
 Given that GPT-3 is already considered to be an exponential leap in years when compared to predecessors such as Microsoft’s Turing NLG, it is safe to assume that it might be a while before we come up with something better. 

 That said, with future improvements in computing, the processing power afforded by newer systems will surely narrow the gap between human and machine even further. 

 In the meantime, Replika remains a formidable product that combines the best of psychology and artificial intelligence. Its successful integration of a human-friendly UX with a state-of-the-art NLP model is indeed a testament to the immense potential of human-computer interaction technologies. 



















Technology Explained




Artificial Intelligence




Chatbot





Close









Your changes have been saved

Email Is sent




close
Please verify your email address.


Send confirmation email






close
You’ve reached your account maximum for followed topics.
Manage Your List





 Follow 



Followed




Follow with Notifications



Follow



Unfollow












































Readers like you help support MakeUseOf. When you make a purchase using links on our site, we may earn an affiliate commission. Read More.






Recommended




















			6 Helpful Machine Learning Tutorials and Courses to Grasp the Essentials
		


Online Courses

There has never been a better time to dive into machine learning. Here are six useful resources to help you learn about machine learning.






Jul 6, 2018























			5 Must-Have Free Chrome Extensions I Rely on as a Student
		


Browser Extensions

Try these recommended tools to streamline your studies.


1




5 days ago























			Websites Don't Collect Data to Scam You: Here's What They Really Do With It
		


Online Privacy

It's mostly valid and legitimate, though you may want to take steps to protect your data.


1




1 day ago























			Before You Buy a Sony Game on PC, Always Check This
		


PC Gaming

PC freedom meets PlayStation restrictions.






1 hour ago























			How to Start Using Gemini 1.5 Pro for Free
		


Artificial Intelligence

You don't have to fork out for yet another AI model subscription; try Gemini 1.5 Pro for free instead.






5 days ago























			What Is the AppData Folder in Windows, and When Should You Use It?
		


Windows Tips

Learn the purpose of the hidden AppData folder in Windows, so you know when and how to use it.


1




1 day ago

























Trending Now





















			I Love Proton's Private, Distraction-Free Alternative to Google Docs
		




























			How to Restore Your Lost Homepage on Any Browser
		




























			Enjoy Pure Water While Saving Water With Waterdrop: Up to 35% Off This Prime Day
		













","{'@type': 'WebPage', '@id': 'https://www.makeuseof.com/how-does-replika-chatbot-work/'}",,,,,,,,,,"[{'@type': 'WebPageElement', 'isAccessibleForFree': 'True', 'cssSelector': '.article-body'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHA6Ly93d3cud2FzaGluZ3RvbnBvc3QuY29tL2JyYW5kLXN0dWRpby9kZWxvaXR0ZS9haS1hbmQtdGhlLXdvcmtmb3JjZS1vZi10b21vcnJvdy_SAQA?oc=5,AI and the workforce of tomorrow - The Washington Post,2021-01-01,The Washington Post,http://www.washingtonpost.com,The right strategy for digital transformation balances new technologies with the right talent.,,The right strategy for digital transformation balances new technologies with the right talent.,The right strategy for digital transformation balances new technologies with the right talent.,https://schema.org,AdvertiserContentArticle,,['./media/WPBS_Deloitte_Release5_NativePromo_A-1.jpg'],"{'@type': 'Organization', 'name': 'The Washington Post BrandStudio'}","{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'name': 'The Washington Post', 'logo': {'@type': 'ImageObject', 'url': './media/wp_logo_black.png', 'height': 30, 'width': 200}}",AI and the workforce of tomorrow,2020-05-11T15:59:03+00:00,2020-05-11T15:59:15+00:00,,,True,,,,"
AI and the workforce of tomorrow The right strategy for digital transformation balances new technologies with the right talent.scroll
Artificial intelligence is embodied in a range of applications that can offer businesses in many industries a competitive advantage. Investment in such technologies is soaring, and analysts forecast AI spending worldwide will more than double over the next three years, exceeding US$79 billion by 2022.The effect of AI on jobs is still uncertain, but early signs suggest human workers and AI adoption will augment each other, changing the nature of work for the better.Learn more about the talent and workforce effects of AI.Read more











































To achieve the most positive AI outcomes, companies will need the right mix of talent to translate business requirements into the most efficient solutions. This will mean building and deploying AI systems, integrating them into processes and correctly interpreting the results. But early AI adopters will need to bridge a skills gap if they are to maximize the technology’s capabilities.What do leaders regard as the “most needed” roles to fill their company’s AI skills gap? What do leaders regard as the “most needed” roles to fill their company’s AI skills gap? The top four most-needed roles are “AI builders,” who are instrumental in creating AI solutions:
                    Researchers to invent new kinds of AI algorithms and systemsSoftware developers to architect and code AI systemsData scientists to analyze and extract meaningful insights from dataProject managers to ensure that AI projects are executed according to planAlso required will be “translators” who can bridge the business/tech staff divide at both the front and back ends of building AI solutions.















































































































































































































Companies in the AI game have a sense of urgency. At a time when competition for AI skills is fierce, a competitive advantage will depend on the right strategy for dealing with AI talent shortages and the changing nature of work.Early adopters should consider the following to strengthen their AI foothold.
Decide what skills are needed.AI adopters should examine their requirements closely, then consider whether they really need AI research superstars to break new ground, or if goals can be achieved with a skilled engineering team retrained to use available AI tools.Adopters should also involve the organization’s leadership early on and throughout the life cycle of AI initiatives. This will connect the company’s business models and strategy with AI system requirements and help establish metrics for project success. AI adopters also should consider using change management experts to address the challenge of integrating AI into the company’s roles and functions. These professionals, who help ensure organizations actually use new systems or processes after developing them, can be key to overcoming a significant AI integration hurdle.

















































































































































Find the right balance between hiring and reskilling.Leaders also should consider identifying and reskilling current developers, IT staff and other current employees to build the company’s AI expertise. Programs to train developers to create AI solutions and IT staff to deploy those solutions can be tailored to the organization’s specific needs. These can include training employees how to use AI systems in the course of their jobs, as well as to develop structured ways of integrating AI into their roles and functions. For their part, employees should embrace an attitude of lifelong learning and a perspective of how AI assistance may supercharge their future work.





















































































































































































































































Redesign work for the age of AI.Automation’s role extends beyond reducing headcount or optimizing processes. Organizations can use AI to free workers from repetitive or error-prone tasks, bringing their human skills of judgment, interpretation, and empathy to bear on more complex decisions. Leaders should advance a vision of what their “augmented workforce” looks like—and evolve it as their AI capabilities change. They should have a strategy for “redefining work” that lets workers with freed-up capacity create new sources of business value.











































s
                











































Learn more about the talent and workforce effects of AI.Read more
","{'@type': 'WebPage', '@id': 'https://google.com/article'}",,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'sponsor': {'@type': 'Organization', 'name': 'Deloitte'}, 'description': 'The right strategy for digital transformation balances new technologies with the right talent.', 'image': './media/WPBS_Deloitte_Release5_NativePromo_A-1.jpg', 'name': 'AI and the workforce of tomorrow', 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}, 'productID': 'washingtonpost.com:basic', 'sku': 'https://subscribe.washingtonpost.com'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjEvMDEvMDQvdGVjaG5vbG9neS9nb29nbGUtZW1wbG95ZWVzLXVuaW9uLmh0bWzSAQA?oc=5,"Hundreds of Google Employees Unionize, Culminating Years of Activism (Published 2021) - The New York Times",2021-01-04,The New York Times,https://www.nytimes.com,"The creation of the union, a rarity in Silicon Valley, follows years of increasing outspokenness by Google workers. Executives have struggled to handle the change.",,"The creation of the union, a rarity in Silicon Valley, follows years of increasing outspokenness by Google workers. Executives have struggled to handle the change.","The creation of the union, a rarity in Silicon Valley, follows years of increasing outspokenness by Google workers. Executives have struggled to handle the change.",https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/01/04/business/04googleunion1/merlin_181893858_e7c90826-db94-4aee-a812-297f9d231f1d-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2021/01/04/business/04googleunion1/merlin_181893858_e7c90826-db94-4aee-a812-297f9d231f1d-videoSixteenByNineJumbo1600.jpg', 'caption': 'Chewy Shaw, an engineer at Google, at a video meeting with other workers. He said a union would keep pressure on management.', 'creditText': 'Damien Maloney for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/01/04/business/04googleunion1/merlin_181893858_e7c90826-db94-4aee-a812-297f9d231f1d-superJumbo.jpg', 'height': 1536, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2021/01/04/business/04googleunion1/merlin_181893858_e7c90826-db94-4aee-a812-297f9d231f1d-superJumbo.jpg', 'caption': 'Chewy Shaw, an engineer at Google, at a video meeting with other workers. He said a union would keep pressure on management.', 'creditText': 'Damien Maloney for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/01/04/business/04googleunion1/merlin_181893858_e7c90826-db94-4aee-a812-297f9d231f1d-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2021/01/04/business/04googleunion1/merlin_181893858_e7c90826-db94-4aee-a812-297f9d231f1d-mediumSquareAt3X.jpg', 'caption': 'Chewy Shaw, an engineer at Google, at a video meeting with other workers. He said a union would keep pressure on management.', 'creditText': 'Damien Maloney for The New York Times'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/kate-conger', 'name': 'Kate Conger'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","Hundreds of Google Employees Unionize, Culminating Years of Activism",2021-01-04T11:00:08.000Z,2021-01-05T00:27:07.000Z,,The New York Times,False,,Technology,,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTHundreds of Google Employees Unionize, Culminating Years of ActivismThe creation of the union, a rarity in Silicon Valley, follows years of increasing outspokenness by Google workers. Executives have struggled to handle the change.Share full article360Read in appChewy Shaw, an engineer at Google, at a video meeting with other workers. He said a union would keep pressure on management.Credit...Damien Maloney for The New York TimesBy Kate CongerJan. 4, 2021OAKLAND, Calif. — More than 400 Google engineers and other workers have formed a union, the group revealed on Monday, capping years of growing activism at one of the world’s largest companies and presenting a rare beachhead for labor organizers in staunchly anti-union Silicon Valley.The union’s creation is highly unusual for the tech industry, which has long resisted efforts to organize its largely white-collar work force. It follows increasing demands by employees at Google for policy overhauls on pay, harassment and ethics, and is likely to escalate tensions with top leadership.The new union, called the Alphabet Workers Union after Google’s parent company, Alphabet, was organized in secret for the better part of a year and elected its leadership last month. The group is affiliated with the Communications Workers of America, a union that represents workers in telecommunications and media in the United States and Canada.But unlike a traditional union, which demands that an employer come to the bargaining table to agree on a contract, the Alphabet Workers Union is a so-called minority union that represents a fraction of the company’s more than 260,000 full-time employees and contractors. Workers said it was primarily an effort to give structure and longevity to activism at Google, rather than to negotiate for a contract.AdvertisementSKIP ADVERTISEMENTChewy Shaw, an engineer at Google in the San Francisco Bay Area and the vice chair of the union’s leadership council, said the union was a necessary tool to sustain pressure on management so that workers could force changes on workplace issues.“Our goals go beyond the workplace questions of ‘Are people getting paid enough?’ Our issues are going much broader,” he said. “It is a time where a union is an answer to these problems.”In response, Kara Silverstein, Google’s director of people operations, said: “We’ve always worked hard to create a supportive and rewarding workplace for our work force. Of course, our employees have protected labor rights that we support. But as we’ve always done, we’ll continue engaging directly with all our employees.”The new union is the clearest sign of how thoroughly employee activism has swept through Silicon Valley over the past few years. While software engineers and other tech workers largely kept quiet in the past on societal and political issues, employees at Amazon, Salesforce, Pinterest and others have become more vocal on matters like diversity, pay discrimination and sexual harassment.Image“Our goals go beyond the workplace questions of ‘Are people getting paid enough?’” Mr. Shaw said.Credit...Damien Maloney for The New York TimesImageTimnit Gebru, an artificial intelligence researcher, said Google had fired her after she criticized biases in A.I. systems.Credit...Cody O'Loughlin for The New York TimesAdvertisementSKIP ADVERTISEMENTNowhere have those voices been louder than at Google. In 2018, more than 20,000 employees staged a walkout to protest how the company handled sexual harassment. Others have opposed business decisions that they deemed unethical, such as developing artificial intelligence for the Defense Department and providing technology to Customs and Border Protection.Even so, unions have not gained traction in Silicon Valley. Many tech workers shunned them, arguing that labor groups were focused on issues like wages — not a top concern in the high-earning industry — and were not equipped to address their concerns about ethics and the role of technology in society. Labor organizers also found it difficult to corral the tech companies’ huge work forces, which are scattered around the globe.Only a few small union drives have succeeded in tech in the past. Workers at the crowdfunding site Kickstarter and at the app development platform Glitch won union campaigns last year, and a small group of contractors at a Google office in Pittsburgh unionized in 2019. Thousands of employees at an Amazon warehouse in Alabama are also set to vote on a union in the coming months.“There are those who would want you to believe that organizing in the tech industry is completely impossible,” Sara Steffens, C.W.A.’s secretary-treasurer, said of the new Google union. “If you don’t have unions in the tech industry, what does that mean for our country? That’s one reason, from C.W.A.’s point of view, that we see this as a priority.”AdvertisementSKIP ADVERTISEMENTVeena Dubal, a law professor at the University of California, Hastings College of the Law, said the Google union was a “powerful experiment” because it brought unionization into a major tech company and skirted barriers that had prevented such organizing.“If it grows — which Google will do everything they can to prevent — it could have huge impacts not just for the workers but for the broader issues that we are all thinking about in terms of tech power in society,” she said.The union is likely to ratchet up tensions between Google engineers, who work on autonomous cars, artificial intelligence and internet search, and the company’s management. Sundar Pichai, Google’s chief executive, and other executives have tried to come to grips with an increasingly activist work force — but have made missteps.Last month, federal officials said Google had most likely wrongly fired two employees who protested its work with immigration authorities in 2019. Timnit Gebru, a Black woman who is a respected artificial intelligence researcher, also said last month that Google had fired her after she criticized the company’s approach to minority hiring and the biases built into A.I. systems. Her departure set off a storm of criticism about Google’s treatment of minority employees.“These companies find it a bone in their throat to even have a small group of people who say, ‘We work at Google and have another point of view,’” said Nelson Lichtenstein, the director of the Center for the Study of Work, Labor and Democracy at the University of California, Santa Barbara. “Google might well succeed in decimating any organization that comes to the floor.”AdvertisementSKIP ADVERTISEMENTThe Alphabet Workers Union, which represents employees in Silicon Valley and cities like Cambridge, Mass., and Seattle, gives protection and resources to workers who join. Those who opt to become members will contribute 1 percent of their total compensation to the union to fund its efforts.Over the past year, the C.W.A. has pushed to unionize white-collar tech workers. (The NewsGuild, a union that represents New York Times employees, is part of the C.W.A.) The drive focused initially on employees at video game companies, who often work grueling hours and face layoffs.In late 2019, C.W.A. organizers began meeting with Google employees to discuss a union drive, workers who attended the meetings said. Some employees were receptive and signed cards to officially join the union last summer. In December, the Alphabet Workers Union held elections to select a seven-person executive council.But several Google employees who had previously organized petitions and protests at the company objected to the C.W.A.’s overtures. They said they had declined to join because they worried that the effort had sidelined experienced organizers and played down the risks of organizing as it recruited members.ImageGoogle employees staged a walkout in 2018 to protest how the company handled sexual harassment.Credit...Bebeto Matthews/Associated PressAmr Gaber, a Google software engineer who helped organize the 2018 walkout, said C.W.A. officials were dismissive of other labor groups that had supported Google workers during a December 2019 phone call with him and others.AdvertisementSKIP ADVERTISEMENT“They are more concerned about claiming turf than the needs of the workers who were on the phone call,” Mr. Gaber said. “As a long-term labor organizer and brown man, that’s not the type of union I want to build.”The C.W.A. said it had been selected by Google workers to help organize the union and had not elbowed its way in. “It’s really the workers who chose,” Ms. Steffens of C.W.A. said.Traditional unions typically enroll a majority of a work force and petition a state or federal labor board like the National Labor Relations Board to hold an election. If they win the vote, they can bargain with their employer on a contract. A minority union allows employees to organize without first winning a formal vote before the N.L.R.B.The C.W.A. has used this model to organize groups in states where it said labor laws were unfavorable, like the Texas State Employees Union and the United Campus Workers in Tennessee.AdvertisementSKIP ADVERTISEMENTThe structure also gives the union the latitude to include Google contractors, who outnumber full-time workers and who would be excluded from a traditional union. Some Google employees have considered establishing a minority or solidarity union for several years, and ride-hailing drivers have formed similar groups.Although they will not be able to negotiate a contract, the Alphabet Workers Union can use other tactics to pressure Google into changing its policies, labor experts said. Minority unions often turn to public pressure campaigns and lobby legislative or regulatory bodies to influence employers.“We’re going to use every tool that we can to use our collective action to protect people who we think are being discriminated against or retaliated against,” Mr. Shaw said.Members cited the recent N.L.R.B. finding on the firing of two employees and the exit of Dr. Gebru, the prominent researcher, as reasons to broaden its membership and publicly step up its efforts.“Google is making it all the more clear why we need this now,” said Auni Ahsan, a software engineer at Google and an at-large member of the union’s executive council. “Sometimes the boss is the best organizer.”Kate Conger is a technology reporter in San Francisco, covering privacy, policy and labor. Previously, she wrote about cybersecurity for Gizmodo and TechCrunch. More about Kate CongerA version of this article appears in print on Jan. 5, 2021, Section B, Page 1 of the New York edition with the headline: In Silicon Valley Rarity, Hundreds of Google Employees Unionize. Order Reprints | Today’s Paper | SubscribeSee more on: Communications Workers of America, Alphabet Inc.Read 360 CommentsShare full article360Read in appAdvertisementSKIP ADVERTISEMENTComments 360Hundreds of Google Employees Unionize, Culminating Years of ActivismSkip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Enjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",https://www.nytimes.com/2021/01/04/technology/google-employees-union.html,,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",,https://www.nytco.com/company/diversity-and-inclusion/,,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",,,"In Silicon Valley Rarity, Hundreds of Google Employees Unionize",,,,en,,,1851-09-18,,,https://en.wikipedia.org/wiki/The_New_York_Times,,,,2024.0,,,,,{'@id': '#commentsContainer'},360.0,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,,,,,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3LmRldmRpc2NvdXJzZS5jb20vYXJ0aWNsZS90ZWNobm9sb2d5LzEzOTA5NjItZnV0dXJlLW9mLXVyYmFuLXBsYW5uaW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWd1aWRpbmctdGhlLXdhedIBfGh0dHBzOi8vd3d3LmRldmRpc2NvdXJzZS5jb20vYXJ0aWNsZS90ZWNobm9sb2d5LzEzOTA5NjItZnV0dXJlLW9mLXVyYmFuLXBsYW5uaW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWd1aWRpbmctdGhlLXdheT9hbXA?oc=5,Future of Urban Planning: Artificial Intelligence guiding the way - Devdiscourse,2021-01-02,Devdiscourse,https://www.devdiscourse.com,Traditionally policymakers and urban planners havenrsquot had access to city data that can reveal complex patterns and relationships between factors that influence urban development In some cases data is too laborious or costly to measure at frequent time intervals and in others unexpected or unforeseen circumstances such as a pandemic like COVID-19 are responsible for invalidating earlier forecasts,"Urban Planning, Urban Design, Artificial Intelligence, Machine Learning, road infrastructure, population forecasts, Urban development",Advances in emerging technologies like Artificial Intelligence and Machine Learning can help us understand our cities better and derive useful insights from real-time data collected through automated models.,,http://schema.org,NewsArticle,,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'width': '100px', 'height': '100px', 'url': 'https://www.devdiscourse.com/remote.axd?https://devdiscourse.blob.core.windows.net/devnews/02_01_2021_14_49_25_4724643.jpg?width=920'}","{'@type': 'Person', 'name': 'COE-EDP'}","{'@type': 'Organization', 'name': 'Devdiscourse', 'logo': {'@type': 'ImageObject', 'url': 'https://www.devdiscourse.com/AdminFiles/Logo/devdiscourse_news.png'}}",Future of Urban Planning: Artificial Intelligence guiding the way | Technology,2021-01-02T20:29:11+05:30,2021-01-02T20:29:11+05:30,,,,,,,"
Future of Urban Planning: Artificial Intelligence guiding the way Advances in emerging technologies like Artificial Intelligence and Machine Learning can help us understand our cities better and derive useful insights from real-time data collected through automated models. 

COE-EDP
                          | Updated: 02-01-2021 20:29 IST | Created: 02-01-2021 20:29 IST
        

SHARE
    
    
    
    

  
Traditionally, policymakers and urban planners haven’t had access to city data that can reveal complex patterns and relationships between factors that influence urban development. In some cases, data is too laborious or costly to measure at frequent time intervals, and in others, unexpected or unforeseen circumstances such as a pandemic like COVID-19 are responsible for invalidating earlier forecasts.
But this is changing rapidly, with emerging technologies unlocking new possibilities for urban planning. Advances in emerging technologies like Artificial Intelligence and Machine Learning can help us understand our cities better and derive useful insights from real-time data collected through automated models that provide a much closer view of the situation on-ground compared to traditional approaches.Play VideoPlaySkip BackwardSkip ForwardUnmuteCurrent Time 0:00/Duration 50:00Loaded: 1.03%00:00Stream Type LIVESeek to live, currently behind liveLIVERemaining Time -50:00 1xPlayback RateChaptersChaptersDescriptionsdescriptions off, selectedCaptionscaptions settings, opens captions settings dialogcaptions off, selectedAudio Trackdefault, selectedPicture-in-PictureFullscreenThis is a modal window.Beginning of dialog window. Escape will cancel and close the window.TextColorWhiteBlackRedGreenBlueYellowMagentaCyanOpacityOpaqueSemi-TransparentText BackgroundColorBlackWhiteRedGreenBlueYellowMagentaCyanOpacityOpaqueSemi-TransparentTransparentCaption Area BackgroundColorBlackWhiteRedGreenBlueYellowMagentaCyanOpacityTransparentSemi-TransparentOpaqueFont Size50%75%100%125%150%175%200%300%400%Text Edge StyleNoneRaisedDepressedUniformDrop shadowFont FamilyProportional Sans-SerifMonospace Sans-SerifProportional SerifMonospace SerifCasualScriptSmall CapsReset restore all settings to the default valuesDoneClose Modal DialogEnd of dialog window.AdvertisementSkip Ad 
These insights can properly assess public interests and help policymakers in making decisions that are more sustainable.
In this article, we will explore some sophisticated ways in which Artificial Intelligence can enhance Urban Planning.

Improve road infrastructure with AI-based traffic systems

Narrow roads in cities can be a tremendous inconvenience. The combination of small country roads and heavy trucks, sometimes driven by workers unfamiliar with the region, has resulted in countless instances of large vehicles running off the road, rolling over on narrow turns, or being involved in accidents. Problems like traffic and congestion are also common, especially in urban centers.
The obvious solution to solve this is to upgrade the existing road infrastructure or build new highways but accurately predicting their need and maintenance schedule can be difficult. This can be fixed with the help of AI-based traffic and mobility systems. These systems collect and analyze traffic data, generate solutions, and apply them to traffic infrastructure. AI-based traffic systems work by collecting data from connected traffic systems, which provides input about live traffic or years of historical traffic behavior.
These systems can also take into account data about a host of other potential problems that can impact roads and traffic in the future. In order to understand this data, such systems use machine learning models to process, analyze, and learn about traffic infrastructure. The AI then uses those insights to suggest solutions that can enable authorities to build better and safer infrastructure.
A deep learning algorithm can also help in successfully predicting maintenance requirements of road infrastructure and thus prevent expensive and unplanned failures.
Cambridge-based AI company, Intellegens, announced details of a proof of concept project with global construction and infrastructure group Skanska, which could save Hampshire County Council in excess of £100,000 per annum on road drainage and gully maintenance work. In a trial, drainage data of Hampshire County was passed through a deep learning solution which turned it into a series of models that could enable stakeholders to predict where drainage issues were most likely to occur.
Another example is the automatic recognition of road damage by ARCADIS in which images are taken with a camera of a certain road section using annual images from CycloMedia or with a GoPro. These images are then read into a custom-developed software module, which is can determine the exact location of the defect, the type of defect, the extent of the defect, and even recommended a maintenance measure. Using historical data, this model can also calculate the deterioration of roads, allowing road authorities to draw up a predictive maintenance plan.

Forecasting population

Having accurate population forecasts helps the government with long-term infrastructure planning, particularly where land resources are scarce and the infrastructure is expensive and may take many years to build.
Forecasts try to estimate the rate of population growth, but anticipating the numbers and characteristics of the future population is very difficult as it can be influenced by unforeseen circumstances like a pandemic, war, and other mass catastrophes. Death rates can even decrease with advances in medicine and healthcare. Even the United Nations has issued multiple projections of the future world population and revises it every two years. The revisions from the projections released just two years earlier look small but become significant when accumulated over several decades.
Mathematical models can be inadequate in including all the datasets that can influence population growth and making accurate predictions. On the other hand, the cost of collecting the data required for the task is huge. To tackle these problems, machine learning algorithms can be brought to the rescue.
Artificial Intelligence and Machine Learning have gained considerable prominence over the last decade fuelled by a number of high-profile applications. It is used for forecasting too and can be very much efficient in forecasting population with automated collection and analysis of a broad and diverse set of data. These algorithms are used to quickly analyze huge and diverse datasets that can influence the growth of the population and increase the accuracy of forecasts by reducing human errors. 

Water resource management

The vast networks of buried water, wastewater, and stormwater infrastructure are the veins and arteries feeding our people, our cities, and protecting our environment. Without sustainable and viable water, waste, and stormwater solutions, our quality of life is in peril. Society’s water, wastewater, and stormwater systems have always played significant roles in eliminating disease, safeguarding the environment, and protecting communities.
There is a significant strain on water utilities’ ability to continue delivering critical services to customers while operating with limited resources. But using AI in water resource management can make way for need-based water supply and water-saving systems.
Utilities can deploy smart meters, sensors, and other IoT hardware that will inevitably result in the collection of huge amounts of data about water consumption of a region and can also detect leakages to recommend quick action. Automated analysis of this data using Machine Learning and AI will enable building an efficient water system, optimizing current water resources, infrastructure planning for water structures, and give necessary flexibility to handle unforeseen circumstances.

Problems with sewage systems

Sewers are the most important part of sewerage systems. They are laid below the ground and are difficult to repair, often taking up significant time and resources. Smart hardware like small, rugged, low power sensors that are able to communicate with specially-designed machine learning and AI solutions can help authorities to minimize expensive repairs by automatically detecting abnormalities in real-time and recommending timely actions.
Such smart systems getting data from smart sensors installed underground can also significantly reduce the total costs to inspect and assess underground infrastructure. With the help of these systems, utilities can monitor real-time performance and AI models can predict when and where problems may arise.
External data such as weather and tides or migration trends can also be incorporated in the solutions to increases accuracy over the long-term and to actively operate and maintain these sewage systems. These smart systems can also aid in future planning for sewage systems when the data sets become large enough to apply advanced artificial intelligence tools.
AI can also be used to help residents and organizations track their waste in real-time and send notifications to users to correctly sort their waste whenever irregularities are detected.

Smarter and safer driving

The safety of passengers, pedestrians, and drivers has always been the top concern for the transportation industry and AI can bring us closer to ensuring that. Taking advantage of AI models not only decreases accidents or mishaps caused by human errors but can also monitor safety regulation compliance and help drivers in vehicle maintenance by sending them timely alerts.
Using data analytics in logistics, on the other hand, provides a data-driven view on routes and driving behavior, which upgrades the transportation planning process, increase efficiency, and makes the process safer.
Traffic prediction models can allow users to do smarter route planning using historical as well as real-time traffic data, road and weather conditions, and even information about sporting events or construction in the area.
What lies ahead?
Artificial Intelligence is quickly revolutionizing every field from food to aviation. Several of the applications of AI in Urban Planning suggested above are even being utilized in the real-world albeit at a small scale. Some applications can be scaled up quickly to be utilized in many parts of the world.
But the barriers, especially for developing countries, to applying these technologies can still seem daunting. Investments needed to facilitate the collection of data to train AI models can be huge and the upgradation of existing infrastructure can be discouraging.
Under these circumstances, several successful examples of smart cities leading the way could be the boom AI needs to transform urban planning and our lives along with it.
VisionRI's Centre of Excellence on Emerging Development Perspectives (COE-EDP) aims to keep track of the transition trajectory of global development and works towards conceptualization, development, and mainstreaming of innovative developmental approaches, frameworks, and practices.


READ MORE ON:  Urban Planning 
 Urban Design 
 Artificial Intelligence 
 Machine Learning 
 road infrastructure 
 population forecasts 
 Urban development 

  FIRST PUBLISHED IN: Devdiscourse  
Advertisement

   ALSO READ    Machine Learning in Action: DivPSM Enhances Analysis of Diversity Communication on Social Media  
  POST / READ COMMENTS     
","{'@type': 'WebPage', '@id': 'https://www.devdiscourse.com/article/technology/1390962-future-of-urban-planning-artificial-intelligence-guiding-the-way'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vZWRyaS5vcmcvb3VyLXdvcmsvY2l2aWwtc29jaWV0eS1jYWxsLWZvci1haS1yZWQtbGluZXMtaW4tdGhlLWV1cm9wZWFuLXVuaW9ucy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1wcm9wb3NhbC_SAQA?oc=5,Civil society calls for AI red lines in the European Union's Artificial Intelligence proposal - European Digital Rights (EDRi),2021-01-12,European Digital Rights (EDRi),https://edri.org,European Digital Rights together with 61 civil society organisations have sent an open letter to the European Commission demanding redlines for the applications of AI that threaten fundamental rights.,,European Digital Rights together with 61 civil society organisations have sent an open letter to the European Commission demanding redlines for the applications of AI that threaten fundamental rights.,,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/', 'url': 'https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/', 'name': 'Civil society calls for AI red lines in the European Union’s Artificial Intelligence proposal - European Digital Rights (EDRi)', 'isPartOf': {'@id': 'https://edri.org/#website'}, 'primaryImageOfPage': {'@id': 'https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/#primaryimage'}, 'image': {'@id': 'https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/#primaryimage'}, 'thumbnailUrl': 'https://edri.org/wp-content/uploads/2021/01/AI-Open-Letter-2.png', 'datePublished': '2021-01-12T10:15:31+00:00', 'dateModified': '2021-11-19T12:30:13+00:00', 'description': 'European Digital Rights together with 61 civil society organisations have sent an open letter to the European Commission demanding redlines for the applications of AI that threaten fundamental rights.', 'breadcrumb': {'@id': 'https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/#primaryimage', 'url': 'https://edri.org/wp-content/uploads/2021/01/AI-Open-Letter-2.png', 'contentUrl': 'https://edri.org/wp-content/uploads/2021/01/AI-Open-Letter-2.png', 'width': 1200, 'height': 675, 'caption': 'People protesting'}, {'@type': 'BreadcrumbList', '@id': 'https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://edri.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Resources', 'item': 'https://edri.org/our-work/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Civil society calls for AI red lines in the European Union’s Artificial Intelligence proposal'}]}, {'@type': 'WebSite', '@id': 'https://edri.org/#website', 'url': 'https://edri.org/', 'name': 'European Digital Rights (EDRi)', 'description': 'Protecting digital rights in Europe.', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://edri.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vd3d3LmdlcGx1cy5jby51ay9mZWF0dXJlcy9wcmVkaWN0aW5nLWxhbmRzbGlkZXMtMTQtMDEtMjAyMS_SAQA?oc=5,Warning signs: Predicting landslides with artificial intelligence - Ground Engineering,2021-01-14,Ground Engineering,https://www.geplus.co.uk,"Worldwide, landslides cause thousands of deaths and injuries and cost billions of pounds of damage every year. The most common ones are induced by",,"Worldwide, landslides cause thousands of deaths and injuries and cost billions of pounds of damage every year. The most common ones are induced by",,https://schema.org,,,,,,,,,,,,,,,"A project in the US is using Google Earth and artificial intelligence to forecast landslides and build a large-scale, global database. Michaila Hancock reports.Worldwide, landslides cause thousands of deaths and injuries and cost billions of pounds of damage every year. The most common ones are induced by rainfall, often transforming into fast-moving debris flows, causing devastation for those who live in mountainous areas.In its 2019 AI Impact Challenge, Google asked non-profit organisations, social enterprises and research institutions across the globe how they would use artificial intelligence (AI) for social good.It was this call that urged Pennsylvania State University associate professor of civil and environmental engineering Chaopeng Shen to build on his initial idea.“We had a good idea that was looking for such an opportunity,” says Shen, who is also the principal investigator of deepLDB, one of 20 projects awarded funding by Google.“Rainfall-induced landslides are a huge risk for people who live in mountainous areas, and we thought there was a possibility to use AI to better forecast them.”  Shen says that many of these events go unreported, complicating efforts to study and eventually predict them.“Most of the information comes from news reports, and there are a lot of missing events,” Shen says. “In order for us to better forecast landslides, we need to start with a good landslide database.”An example of how Google Earth images are used to identify landslide zonesTraining AIWith the availability of satellite images from Google Earth, past landslides could be identified from space. However, to populate a database would require a lot of work, and this is where the AI comes in.“The first goal of our work was to produce an artificial intelligence method to identify these events from the satellite images,” Shen says. “Once the AI is trained – when it can determine what’s a landslide and what’s not – we can apply it to a very large area, and it will automatically find the places with a suspected event.”At the start of the project, Shen and his Pennsylvania State University co-investigators, associate professor of civil and environmental engineering Tong Qiu and associate professor of computer science Daniel Kifer, were provided with an initial data set of known rainfall-induced landslides by the United States Geological Survey (USGS).  After finding the landslide events in Google Earth, they used the satellite images as training examples in a process called “supervised learning”.“It’s basically object identification,” Shen says. “By looking at the satellite images over time, you get a sense that there might have been an event because the scene changed dramatically. Most of the visual cues come from the vegetation.”Over time, the AI began recognising the cues it could use to identify a landslide, but it also needed to spot the differences from other occurrences, too. The shape of a disturbance might have indicated a landslide, but it could also have been from a wildfire, an excavated mine or a demolished building.“It has to be able to differentiate the real signals from the noise,” Shen says. “What’s a rainfall-induced landslide, and what’s not?”After a year of training, Shen says the model is now correctly identifying a landslide 97% of the time, but he emphasises more training examples are still needed especially in different landscapes.Data verificationThe researchers have set up a portal (www.deepldb.org) where people can help to verify potential landslides identified by the AI, or even upload and label their own Google Earth images.“If an aerial image of a landslide is not from an area we’ve been focused on, they can help us correct it,” Shen says. “The more data we have, the more accurate the model will be.”According to Shen, the level of precision in the database is what sets deepLDB apart, and it allows them to start moving on to the second goal of the project - prediction.“I think we're 90% way through the first phase, in that the models that we've trained are working,” says Shen.  “We're gradually opening it up to the public, so they can help provide us with more information and then we're utilising that information for prediction.”He adds that work has recently begun on the prediction model. The team has worked with Google AI experts to find the best way to build the AI as it looks for patterns in the growing database.Chaopeng Shen, Pennsylvania State University associate professor of civil and environmental engineering“We have some models being put together, and they are giving us some interesting results, but still a lot of work is needed,” Shen says.“We hope people will join, help label events and help add more data onto our platform. It allows them to upload images and label them and then run our model to automatically pick out the possible cases where there's a landslide. It greatly reduces the effort level.“Previously, if you were to identify these from space, it's very painful, because these are very small features, and you have to look very closely.“Landslides are not there most of the time for most places, and it's a very small portion of places where you have landslides you can see. It becomes quite a straining effort to try to identify these from satellite images.“Our model can do a bulk of the effort for the users; it reduces 90% of the effort and makes it much, much more sustainable.”Affected communitiesThe third phase of the project is to make use of the model, says Shen. This involves getting in touch with the stakeholders, including those who live within the communities affected by landslides.“Basically, making the model useful by actually connecting with the communities that are influenced by landslides, and let them chip in. Let them know about it,” adds Shen.He explains that they are already in touch with a community from Darjeeling in north India.“They live on the southern slope of the Himalayas. They have had big landslides that destroyed the road, which means a few months without communication with the outside world,” says Shen.“We hope to bring their data into our system and try to learn from it. And to see if we can help them, to the best of our capacity.”PredictionShen says that he will be publishing a paper on the project and its results later this year.“The next step is to use AI to associate the events in the database with rainfall and other local conditions to try to predict what’s going to happen next,” Shen says.“The novel aspect of the project is we have a very high spatial accuracy, meaning we know exactly where these events are.“With this kind of precision, we can overlay the events with other data sets like soil texture and elevation and find out some of the fundamental reasons why it happens in one area and not the other. Or why yesterday and not the day before.”Shen adds: “Prediction is a big problem worldwide in both developing and developed countries. It is a very difficult problem, and we know that people are far from nailing it.“The folks that I’ve worked with at Google and their philanthropic organisation, Google.org, really want to create some positive impacts in the world. When we work with them, we truly feel that they are really good people trying to make an impact on the world.”ContactChaopeng Shen can be reached at cshen@engr.psu.edu or via his Twitter account @ChaopengShenWant to read more? Subscribe to GE’s enewsletters and follow us on Twitter and LinkedIn artificial intelligence landslides 2021-01-14Michaila Hancock Share Facebook Twitter LinkedIn Email  Add to Bookmarks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://www.geplus.co.uk/#organization', 'name': 'Ground Engineering', 'url': 'https://www.geplus.co.uk/', 'sameAs': ['https://www.linkedin.com/company/ground-engineering-magazine/', 'https://twitter.com/GE_magazine'], 'logo': {'@type': 'ImageObject', '@id': 'https://www.geplus.co.uk/#logo', 'inLanguage': 'en-GB', 'url': 'https://cdn.ca.emap.com/wp-content/uploads/sites/13/2021/10/Ground-Engineering-Logo.jpg', 'contentUrl': 'https://cdn.ca.emap.com/wp-content/uploads/sites/13/2021/10/Ground-Engineering-Logo.jpg', 'width': 1280, 'height': 1248, 'caption': 'Ground Engineering'}, 'image': {'@id': 'https://www.geplus.co.uk/#logo'}}, {'@type': 'WebSite', '@id': 'https://www.geplus.co.uk/#website', 'url': 'https://www.geplus.co.uk/', 'name': 'Ground Engineering', 'description': 'News and features on all aspects of geotechnics, engineering geology and geo-environmental engineering', 'publisher': {'@id': 'https://www.geplus.co.uk/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.geplus.co.uk/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'ImageObject', '@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#primaryimage', 'inLanguage': 'en-GB', 'url': 'https://emap-romulus-prod.s3.eu-west-1.amazonaws.com/wp-content/uploads/sites/13/2021/01/Landslide.jpg', 'contentUrl': 'https://emap-romulus-prod.s3.eu-west-1.amazonaws.com/wp-content/uploads/sites/13/2021/01/Landslide.jpg', 'width': 1059, 'height': 706, 'caption': 'Landslide'}, {'@type': 'WebPage', '@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#webpage', 'url': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/', 'name': 'Warning signs: Predicting landslides with artificial intelligence | Ground Engineering', 'isPartOf': {'@id': 'https://www.geplus.co.uk/#website'}, 'primaryImageOfPage': {'@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#primaryimage'}, 'datePublished': '2021-01-14T11:44:24+00:00', 'dateModified': '2021-02-15T12:53:22+00:00', 'description': 'Worldwide, landslides cause thousands of deaths and injuries and cost billions of pounds of damage every year. The most common ones are induced by', 'breadcrumb': {'@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/']}], 'isAccessibleForFree': 'True'}, {'@type': 'BreadcrumbList', '@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.geplus.co.uk/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Warning signs: Predicting landslides with artificial intelligence'}]}, {'@type': 'Article', '@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#article', 'isPartOf': {'@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#webpage'}, 'author': {'@id': 'https://www.geplus.co.uk/#/schema/person/7d417038becc0a1972dd11007878aa7d'}, 'headline': 'Warning signs: Predicting landslides with artificial intelligence', 'datePublished': '2021-01-14T11:44:24+00:00', 'dateModified': '2021-02-15T12:53:22+00:00', 'mainEntityOfPage': {'@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#webpage'}, 'wordCount': 1256, 'commentCount': 0, 'publisher': {'@id': 'https://www.geplus.co.uk/#organization'}, 'image': {'@id': 'https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#primaryimage'}, 'thumbnailUrl': 'https://emap-romulus-prod.s3.eu-west-1.amazonaws.com/wp-content/uploads/sites/13/2021/01/Landslide.jpg', 'keywords': ['artificial intelligence', 'landslides'], 'articleSection': ['In depth'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.geplus.co.uk/features/predicting-landslides-14-01-2021/#respond']}]}, {'@type': 'Person', '@id': 'https://www.geplus.co.uk/#/schema/person/7d417038becc0a1972dd11007878aa7d', 'name': 'Michaila Hancock', 'image': {'@type': 'ImageObject', '@id': 'https://www.geplus.co.uk/#personlogo', 'inLanguage': 'en-GB', 'url': 'https://secure.gravatar.com/avatar/cfaaf696239cedc5c6949298fbf3fe8a?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/cfaaf696239cedc5c6949298fbf3fe8a?s=96&d=mm&r=g', 'caption': 'Michaila Hancock'}, 'url': 'https://www.geplus.co.uk/author/michaila-hancock/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vdGhlY29udmVyc2F0aW9uLmNvbS9ob3ctZXhwbGFpbmFibGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY2FuLWhlbHAtaHVtYW5zLWlubm92YXRlLTE1MTczN9IBAA?oc=5,How explainable artificial intelligence can help humans innovate - The Conversation,2021-01-13,The Conversation,https://theconversation.com,"AI algorithms can solve hard problems and learn incredible tasks, but they can’t explain how they do these things. If researchers can build explainable AI, it could lead to a flood of new knowledge.",,"AI algorithms can solve hard problems and learn incredible tasks, but they can’t explain how they do these things. If researchers can build explainable AI, it could lead to a flood of new knowledge.",,,,,,,,,,,,,,,,,"






        Understanding how artificial intelligence algorithms solve problems like the Rubik’s Cube makes AI more useful.
        Roland Frisch via Wikimedia Commons, CC BY-SA









            How explainable artificial intelligence can help humans innovate
          




Published: January 13, 2021 8:18am EST












Forest Agostinelli, University of South Carolina



Author





        Forest Agostinelli
      


      Assistant Professor of Computer Science, University of South Carolina
    





Disclosure statement
Forest Agostinelli does not work for, consult, own shares in or receive funding from any company or organization that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment.


Partners

University of South Carolina provides funding as a member of The Conversation US.
View all partners

We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)333


 Facebook389


 LinkedIn


 WhatsApp


 Messenger

 Print


The field of artificial intelligence (AI) has created computers that can drive cars, synthesize chemical compounds, fold proteins and detect high-energy particles at a superhuman level.
However, these AI algorithms cannot explain the thought processes behind their decisions. A computer that masters protein folding and also tells researchers more about the rules of biology is much more useful than a computer that folds proteins without explanation.
Therefore, AI researchers like me are now turning our efforts toward developing AI algorithms that can explain themselves in a manner that humans can understand. If we can do this, I believe that AI will be able to uncover and teach people new facts about the world that have not yet been discovered, leading to new innovations.



When machines are left to learn and solve problems through their own experience, this is called reinforcement learning.
Gremlin/E+ via Getty Images


Learning from experience
One field of AI, called reinforcement learning, studies how computers can learn from their own experiences. In reinforcement learning, an AI explores the world, receiving positive or negative feedback based on its actions.
This approach has led to algorithms that have independently learned to play chess at a superhuman level and prove mathematical theorems without any human guidance. In my work as an AI researcher, I use reinforcement learning to create AI algorithms that learn how to solve puzzles such as the Rubik’s Cube. 
Through reinforcement learning, AIs are independently learning to solve problems that even humans struggle to figure out. This has got me and many other researchers thinking less about what AI can learn and more about what humans can learn from AI. A computer that can solve the Rubik’s Cube should be able to teach people how to solve it, too.
Peering into the black box
Unfortunately, the minds of superhuman AIs are currently out of reach to us humans. AIs make terrible teachers and are what we in the computer science world call “black boxes.”



Researchers have been trying for decades to understand how AIs solve problems.
rockz/iStock via Getty Images Plus


A black-box AI simply spits out solutions without giving reasons for its solutions. Computer scientists have been trying for decades to open this black box, and recent research has shown that many AI algorithms actually do think in ways that are similar to humans. For example, a computer trained to recognize animals will learn about different types of eyes and ears and will put this information together to correctly identify the animal. 
The effort to open up the black box is called explainable AI. My research group at the AI Institute at the University of South Carolina is interested in developing explainable AI. To accomplish this, we work heavily with the Rubik’s Cube. 
The Rubik’s Cube is basically a pathfinding problem: Find a path from point A – a scrambled Rubik’s Cube – to point B – a solved Rubik’s Cube. Other pathfinding problems include navigation, theorem proving and chemical synthesis. 
My lab has set up a website where anyone can see how our AI algorithm solves the Rubik’s Cube; however, a person would be hard-pressed to learn how to solve the cube from this website. This is because the computer cannot tell you the logic behind its solutions.
Solutions to the Rubik’s Cube can be broken down into a few generalized steps – the first step, for example, could be to form a cross while the second step could be to put the corner pieces in place. While the Rubik’s Cube itself has over 10 to the 19th power possible combinations, a generalized step-by-step guide is very easy to remember and is applicable in many different scenarios. 
Approaching a problem by breaking it down into steps is often the default manner in which people explain things to one another. The Rubik’s Cube naturally fits into this step-by-step framework, which gives us the opportunity to open the black box of our algorithm more easily. Creating AI algorithms that have this ability could allow people to collaborate with AI and break down a wide variety of complex problems into easy-to-understand steps.



A step-by-step refinement approach can make it easier for humans to understand why AIs do the things they do.
Forest Agostinelli, CC BY-ND


Collaboration leads to innovation
Our process starts with using one’s own intuition to define a step-by-step plan thought to potentially solve a complex problem. The algorithm then looks at each individual step and gives feedback about which steps are possible, which are impossible and ways the plan could be improved. The human then refines the initial plan using the advice from the AI, and the process repeats until the problem is solved. The hope is that the person and the AI will eventually converge to a kind of mutual understanding.
[Deep knowledge, daily. Sign up for The Conversation’s newsletter.]
Currently, our algorithm is able to consider a human plan for solving the Rubik’s Cube, suggest improvements to the plan, recognize plans that do not work and find alternatives that do. In doing so, it gives feedback that leads to a step-by-step plan for solving the Rubik’s Cube that a person can understand. Our team’s next step is to build an intuitive interface that will allow our algorithm to teach people how to solve the Rubik’s Cube. Our hope is to generalize this approach to a wide range of pathfinding problems. 
People are intuitive in a way unmatched by any AI, but machines are far better in their computational power and algorithmic rigor. This back and forth between man and machine utilizes the strengths from both. I believe this type of collaboration will shed light on previously unsolved problems in everything from chemistry to mathematics, leading to new solutions, intuitions and innovations that may have, otherwise, been out of reach.





Artificial intelligence (AI)


Innovation


Computer science


Machine learning


Black box


Reinforcement learning


Innovation and Invention


Process of Innovation


Explainable AI









",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vYWNjZWxlcmF0aW9uZWNvbm9teS5jb20vYWkvaGlzdG9yeS1hbmQtZnV0dXJlLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFpL9IBAA?oc=5,History and Future of Artificial Intelligence (AI) - Acceleration Economy,2021-01-12,Acceleration Economy,https://accelerationeconomy.com,Artificial Intelligence has come a long since it's early inception. Many advances have been since then that have defined how AI is used and understood. AI is still in it's infancy but will continue to grow in use and democratization.,,Artificial Intelligence has come a long since it's early inception. Many advances have been since then that have defined how AI is used and understood. AI is still in it's infancy but will continue to grow in use and democratization.,,http://schema.org,Article,https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/,"{'@type': 'ImageObject', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2021/05/48zx1609795118733.png', 'width': 1280, 'height': 720}","{'@type': 'Person', 'name': 'Aaron Back'}","{'@type': 'Organization', 'name': 'Acceleration Economy', 'sameAs': 'https://accelerationeconomy.com', 'logo': {'@type': 'ImageObject', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2024/03/AE-cloud-wars-logo.png'}}",History and Future of Artificial Intelligence (AI),2021-01-12T05:00:00-05:00,2021-01-12T05:00:00-05:00,,,,,,,"



Share



Facebook



Twitter



LinkedIn



Email





Artificial intelligence (AI) continues to rapidly expand and make a big impact on the workplace. Yann LeCun is one of the original creators of AI technology, as he is now a highly respected professor at New York University and is also the Chief AI Scientist at Facebook. LeCun also won the Association for Computing Machinery A.M. Turing Award, which is often considered the “Nobel Prize of Computing.” Recently, LeCun was interviewed about the history of artificial intelligence, as he played a critical role in working with others to develop this innovative technology.
Yann is most well-known for his work in computer vision at Bell Labs by using convolutional neural networks to perform a wide range of activities. For example, this technology allows banks to automatically read checks, provides facial recognition to unlock phones, uses speech recognition to perform searches, and it can even detect tumors through medical imagery. Yann believes that artificial intelligence is specialized to perform a variety of actions to make the world a better place. 






 
The Origin of AI
Understanding what is artificial intelligence is important for anyone interested in the history of this technology. Initially, the concept of AI technology began in the 1940s, as Alan Turing set the foundation for traditional computer science with his innovative research. The first artificial neuron was also proposed by Water Pitts and Warren McCulloch, as they believed that the actions of neurons could be viewed as a computation, which allowed the circuits of neurons to perform logical reasoning.
During this time, researchers also worked on cybernetics, which is essentially the science of how each part of a system communicates with each other. This idea created the term “autopoiesis,” which is a system capable of maintaining and reproducing itself while also learning, regulating, and adapting to its environment. All of this research created a significant amount of interest in this field.
Marvin Minsky (co-founder of the Massachusetts Institute of Technology’s AI laboratory) and John McCarthy (co-founder of the Stanford AI Laboratory) organized a conference at Dartmouth College with the help of a couple of scientists at IBM in 1956. This conference gave an opportunity for Allen Newell and Herbert A. Simon to debut Logic Theorist, which was a computer program engineered to perform automated reasoning. Ultimately, the term “artificial intelligence” was born, as this conference played a pivotal role in artificial intelligence history and future.
 
1960s-1980s: Understanding the Limitations of AI
The academic community was eventually split into two categories for the next twenty years, as one focused on biology and the human brain while others drew more inspiration from mathematics. Initially, no one was working on what we consider machine learning in the early 1980s, which was when Yann began his career. However, the field gained new interest in 1986 with a paper titled “Learning Representations by Back-Propagating Errors,” which was published in the Nature Journal. This paper highlighted the potential success of neural network applications and the learning algorithm for backpropagation. However, this excitement was eventually lessened as research found that only a few applications could be solved due to the extensive amount of data that needed to be trained properly. Data was much more expensive during that time, as it couldn’t be easily obtained from open-source data sets or internet archives like today.
 
1990s-2010s: Lack of Development
The history of artificial intelligence during the 1990s through 2010s was known as the “black period” due to the lack of development. Neural nets were ignored and often mocked by other professionals. Yann eventually stopped working on neural nets in 1996 and didn’t return until after 2002. Anyone that clung to neural nets was often viewed as marginal crazy people due to the lack of understanding in the field. 
However, Yann believed that neural networks would eventually be vindicated over time. The limitation of traditional methods for computational was often due to the reliance on front-end hand engineering, while deep learning on convolutional neural nets was much more efficient. In other words, hand-engineered features are designed by very smart people, while a backpropagation algorithm uses data to create the “feature extractors” to fit each task as efficiently as possible. 
This realization of the benefits of artificial intelligence took researchers in the community over twenty years to understand, as Yann believes that the adoption of this technology took longer due to satisfaction of pitting your wits against a problem without the assistance of a machine. However, relegating yourself to a “machine coach” is often a humbling yet very sold decision.
Another way to consider the long-term trends of AI technology is that it initially began with intelligent people focusing on specific tasks that proved successful within the abstract world of which they were created. However, AI technology uses intelligence shaped by empirical evidence that’s fully formed with a specific set of axioms. One of the most interesting challenges of AI is the ability to match “common sense” and the learning ability of a toddler instead of creating synthetic versions of a chess grandmaster.
 
2012: AI Becomes Mainstream
Geoffrey Hinton and Li Deng introduced the use of deep feedforward, non-recurrent networks to recognize speech in late 2009. Neural networks eventually came back in the academic spotlight in October 2012 due to the impressive benchmarks from AlexNet and other submissions to the ImageNet Large Scale Visual Recognition Challenge at the European Conference on Computer Vision and the PASCAL Visual Object Classes Challenge. Jeff Dean and Andrew Ng also programmed a computer cluster in 2012 to train itself to recognize images. Later in the fall of 2012, the New York Times cited Dr. Richard F. Rashid’s presentation with Microsoft that highlighted the potential of deep learning with the translation of Mandarin.
Yann also notes that the build-up of neural networks being embraced goes several years back due to the innovative work of several pioneers in the field. Artificial intelligence examples include Yoshua Bengio’s text prediction in the early 2000s and Pascal Vicent’s work with using denoising autoencoders. Jason Weston and Ronan Collobert also played a key role in their work at the NEC Research Institute in Princeton with their 2011 paper that focused on the “Natural Language Processing (Almost) from Scratch.”
 
2013-2017: Significant Advancements in AI Technology
The year 2012 was pivotal in the development of AI technology. All of these recent advancements began to snowball and made a significant impact on artificial intelligence and machine learning. For example, Tomas Mikolov, with the help of his colleagues at Google, developed Word2vec, which is an innovative method for learning a representation of words that do not require labeled data while also allowing NLP systems to overlook spelling and focus more on semantics. This AI technology also made it much easier to train multilingual systems, which is especially helpful for speakers of “low-resource” languages to access volumes of information that others take for granted.
Ilya Sutskever published the “Sequence to Sequence Learning with Neural Networks” in 2014, as it described a method of creating multilayered Long Short-Term Memory (LSTM) system that’s suited for tasks such as summarization and automated translation. Dzmitry Bahdanau also published the “Neural Machine Translation by Jointly Learning to Align and Translate” in 2015. A few months later, Google, Microsoft, Facebook all had translation systems that were based on recurrent neural networks. Researchers at Google also proposed a more simple network architecture in 2017 that was solely based on attention mechanisms with their paper “Attention is All You Need.” The use of funny titles is always popular in AI research, as many recent papers include names for Sesame Street characters.
While it took decades for gifted researchers to explore very different approaches, which were often focused on narrow application areas or even on abstract problems, we have finally reached a point that uses a data-driven approach to highlight the value in all types of practical domains. The use of AI theorists will still be needed, but using real-world data has been a critical ingredient in getting all of the answers to apply to real problems.
 
Latest Developments in Artificial Intelligence
Neural networks will continue to be refined and used in a variety of new and exciting ways. Yann believes that the work of Francois Charton and Guillaume Lample in a recent paper shows how each system is surprisingly adept at mathematics, as these problems used to be a particular area of weakness for neural networks. One of the most important advancements in using AI technology isn’t in the research by itself, but it’s how the research is conducted. Now it is perfectly normal for industrial research labs to publish papers that include the code and data to produce the results, instead of being listed internally as a trade secret. This openness in the AI field makes it much easier for other artificial intelligence companies to work together.
Ultimately, Yann believes that this openness with other AI companies will accelerate the development of this technology. For example, Google may publish a new technique, and within a few months, Facebook will make an improvement on it. Similarly, Google may make another improvement, as all of these advancements add up and create a culture of providing “reproducible research” to help spread advancement. This new cultural norm is also spreading in other sciences, as this will benefit everyone in helping to develop new technology.
Self-supervised learning is another exciting development for AI companies. Yann believes that AI technology can transform the health care industry and improve the entire world by making it easier to meet the needs of patients. Artificial intelligence and machine learning will continue to play a key role in the development of new technology while also improving upon existing structures. The world of artificial intelligence will only continue to expand as more companies work with each other in the development of this tech.
 
Closing Thoughts
Understanding artificial intelligence history and the latest developments are essential for anyone interested in how this technology will continue to shape the world. The use of AI technology has rapidly evolved compared to only a few years ago. AI companies will continue to research and find new ways to take advantage of this technology. The rise of AI technology will impact all types of industries, whether it’s in the healthcare field, manufacturing, education, transportation, media, banking, and much more.
The one constant in the world of AI technology is change, as the biggest tech companies look at new ways to utilize this technology and improve their business operations. Today’s work environment is extremely competitive, as utilizing AI technology is essential in gaining an edge over other businesses while also better meeting the needs of customers. 
AI technology will continue to become even more widespread, whether it’s autonomous cars transporting people from place to place or AI-powered robots working alongside humans to manufacture products. The use of AI technology can also assist nurses in monitoring patients while also identifying any potential signs of disease. The world of education will also continue to be impacted by AI, as more textbooks become digitized with the use of AI technology, and virtual tutors can help assist human instructors.
All of these exciting changes will make a big impact on day-to-day life now and in the near future in a wide range of sectors. Learning about the impact of AI technology is a great way to stay up to date with these evolving trends. AI companies will continue to find ways to improve upon this existing technology, as the future looks bright with the ever-increasing advancement of AI technology.










","{'@type': 'WebPage', '@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/#article', 'isPartOf': {'@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/'}, 'author': {'name': 'Aaron Back', '@id': 'https://accelerationeconomy.com/#/schema/person/d7da8e3dc3bd3d7b92ab2427dc339b4f'}, 'headline': 'History and Future of Artificial Intelligence (AI)', 'datePublished': '2021-01-12T05:00:00+00:00', 'dateModified': '2021-01-12T05:00:00+00:00', 'mainEntityOfPage': {'@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/'}, 'wordCount': 1932, 'publisher': {'@id': 'https://accelerationeconomy.com/#organization'}, 'image': {'@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/#primaryimage'}, 'thumbnailUrl': 'https://accelerationeconomy.com/wp-content/uploads/2021/05/48zx1609795118733.png', 'articleSection': ['AI Ecosystem', 'News'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/', 'url': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/', 'name': 'History and Future of Artificial Intelligence (AI) - Acceleration Economy', 'isPartOf': {'@id': 'https://accelerationeconomy.com/#website'}, 'primaryImageOfPage': {'@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/#primaryimage'}, 'image': {'@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/#primaryimage'}, 'thumbnailUrl': 'https://accelerationeconomy.com/wp-content/uploads/2021/05/48zx1609795118733.png', 'datePublished': '2021-01-12T05:00:00+00:00', 'dateModified': '2021-01-12T05:00:00+00:00', 'description': ""Artificial Intelligence has come a long since it's early inception. Many advances have been since then that have defined how AI is used and understood. AI is still in it's infancy but will continue to grow in use and democratization."", 'breadcrumb': {'@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/#primaryimage', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2021/05/48zx1609795118733.png', 'contentUrl': 'https://accelerationeconomy.com/wp-content/uploads/2021/05/48zx1609795118733.png', 'width': 1280, 'height': 720}, {'@type': 'BreadcrumbList', '@id': 'https://accelerationeconomy.com/ai/history-and-future-of-artificial-intelligence-ai/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://accelerationeconomy.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'History and Future of Artificial Intelligence (AI)'}]}, {'@type': 'WebSite', '@id': 'https://accelerationeconomy.com/#website', 'url': 'https://accelerationeconomy.com/', 'name': 'Acceleration Economy', 'description': 'Acceleration Economy', 'publisher': {'@id': 'https://accelerationeconomy.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://accelerationeconomy.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://accelerationeconomy.com/#organization', 'name': 'Acceleration Economy', 'url': 'https://accelerationeconomy.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://accelerationeconomy.com/#/schema/logo/image/', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2023/03/AE-Practitioner-Analysts-Retina.png', 'contentUrl': 'https://accelerationeconomy.com/wp-content/uploads/2023/03/AE-Practitioner-Analysts-Retina.png', 'width': 350, 'height': 112, 'caption': 'Acceleration Economy'}, 'image': {'@id': 'https://accelerationeconomy.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://accelerationeconomy.com/#/schema/person/d7da8e3dc3bd3d7b92ab2427dc339b4f', 'name': 'Aaron Back', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://accelerationeconomy.com/#/schema/person/image/', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2023/11/Aaron-Back-new-150x150.jpg', 'contentUrl': 'https://accelerationeconomy.com/wp-content/uploads/2023/11/Aaron-Back-new-150x150.jpg', 'caption': 'Aaron Back'}, 'description': 'Aaron Back (Bearded Analyst), Chief Content Officer for Acceleration Economy, focuses on empowering individuals and organizations with the information they need to make crucial decisions. He surfaces practical insights through podcasts, news desk interviews, analysis reports, and more to equip you with what you need to #competefast in the acceleration economy. | 🎧 Love listening to podcasts wherever you go? Then check out my ""Back @ IT"" podcast and listen wherever you get your podcasts delivered: https://back-at-it.simplecast.com #wdfa', 'sameAs': ['https://back-at-it.simplecast.com/', 'https://www.linkedin.com/in/aaronmback/'], 'url': 'https://accelerationeconomy.com/author/aaron-back/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RoZS1mZWFyLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLWpvYi1sb3Nz0gFyaHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RoZS1mZWFyLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLWpvYi1sb3Nz?oc=5,The Fear of Artificial Intelligence in Job Loss - Analytics Insight,2021-01-16,Analytics Insight,https://www.analyticsinsight.net,,"Artificial intelligence,fear of job loss,Artificial intelligence in job loss,automation,robotics","There is a lot of disturbing buzz about the negative results of AI With all the hype over Artificial Intelligence, there is additionally a lot of disturbing buz","There is a lot of disturbing buzz about the negative results of AI With all the hype over Artificial Intelligence, there is additionally a lot of disturbing buz",http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/the-fear-of-artificial-intelligence-in-job-loss,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-10.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Priya Dialani', 'name': 'Priya Dialani', 'url': 'https://www.analyticsinsight.net/author/priya-dialani'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",The Fear of Artificial Intelligence in Job Loss,2021-01-16T06:00:10Z,2021-01-16T06:00:10Z,Artificial Intelligence,The Fear of Artificial Intelligence in Job Loss,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Fear of Artificial Intelligence in Job Loss', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/the-fear-of-artificial-intelligence-in-job-loss'}]",,,What is AI and Data Science Engineering? ,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/the-fear-of-artificial-intelligence-in-job-loss'}",2021-01-16T06:00:10Z,,,,,,"There is a lot of disturbing buzz about the negative results of AI.With all the hype over Artificial Intelligence, there is additionally a lot of disturbing buzz about the negative results of AI. These fall comprehensively into three categories: job loss, ethical issues, and criminal use..More than one-quarter (27%) of all employees state they are stressed that the work they have now will be disposed of within the next five years because of new innovation, robots or artificial intelligence, as indicated by the quarterly CNBC/SurveyMonkey Workplace Happiness review..In certain industries where technology already has played a profoundly disruptive role, employees fear of automation likewise run higher than the normal: Workers in automotives, business logistics and support, marketing and advertising, and retail are proportionately more stressed over new technology replacing their jobs than those in different industries..42% of workers in the logistics industry have better than expected worries about new technology replacing their jobs. The dread stems from the fact that the business is already witnessing it. Self-driving trucks already are compromising the jobs of truck drivers, and it is causing a huge frenzy in this job line..In a new paper published in the Findings of Empirical Methods in Natural Language Processing (EMNLP), Assistant Professor Xiang Ren and PhD understudy Yuchen Lin at the University of Southern California found that notwithstanding critical advances AI actually doesn't have the common sense required to create conceivable sentences. As Lin disclosed to Science Daily, &quot;Current machine text-generation models can compose an article that might be persuasive to numerous people, yet they're essentially mirroring what they have found in the training stage&quot;..Where these models fizzled was in depicting regular situations. Given the words dogs, frisbee, toss, and catch, one model concocted the sentence &quot;Two dogs are tossing frisbees at one another.&quot; Nothing incorrect in that aside from that it misses what we know through common sense, viz that a canine can't toss frisbees..Another study of Blumberg Capital of 1,000 American adults found that about half are prepared to accept new tech, while the other half are frightened it will remove their jobs. One surprising finding: Most individuals (72%) comprehend that A.I. is proposed to remove the exhausting, dull parts of what they do, freeing them to concentrate on more perplexing and intriguing tasks. All things considered, 81% are so fearful of being supplanted that they're reluctant to surrender their drudge work to an algorithm..When AI dispenses with jobs (all the more precisely, the requirement for them), there is the undeniable loss of pay. This implies less disposable income and a decrease in spending on nice-to-have goods and luxuries. Less demand compels costs to drop. If costs dip under a level where commodity margins are threatened, the organization and at last the business, will crease..Costs of fundamental products will keep on dropping, however contracting margins are somewhat offset by diminishing operational costs (on account of AI-driven automation). Food costs, for instance, could go down..Society overall should then wrestle with the more profound social, financial, and mental consequences of permanent net job losses caused by AI. In reassurance, the deficiency of jobs without (hopefully) loss of lifestyle should give us the time and opportunity to consider these issues..Sociologists will be compelled to rethink and re-plan their models of human association and organization. Financial specialists will be compelled to reevaluate incentives and agency relationships. Politicians will be compelled to create a new manner of speaking for their platforms when the customary political posturings will get moot. Schools will be compelled to battle with a deschooled society..In any case, the day isn't far, caution the analysts, when AI agents will create more commonsensical responses. Already media startups for example, Knowhere and Patch have incorporated AI into their working and even legacy newspapers are fusing a few components of it into their day-to-day working. However, an opinion piece is still some way off..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.","{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/the-fear-of-artificial-intelligence-in-job-loss', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-10.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/01/Artificial-Intelligence-10.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9qb2Itc2NyZWVuaW5nLXNlcnZpY2UtaGFsdHMtZmFjaWFsLWFuYWx5c2lzLWFwcGxpY2FudHMv0gEA?oc=5,Job Screening Service Halts Facial Analysis of Applicants - WIRED,2021-01-12,WIRED,https://www.wired.com,But it’s still using intonation and behavior to assist with hiring decisions.,"['business', 'artificial intelligence', 'ai hub', 'ethics', 'face recognition', 'human-computer interaction', 'personal services', 'recommendation algorithm', 'prediction', 'big company', 'small company', 'consumer services', 'video', 'speech', 'machine learning', 'natural language processing', 'machine vision', 'startup', 'algorithms', 'web']",But it’s still using intonation and behavior to assist with hiring decisions.,But it’s still using intonation and behavior to assist with hiring decisions.,https://schema.org/,BreadcrumbList,https://www.wired.com/story/job-screening-service-halts-facial-analysis-applicants/,"['https://media.wired.com/photos/5ffcea25072d3ec215c55753/16:9/w_2400,h_1350,c_limit/hirevue-1210924894.jpg', 'https://media.wired.com/photos/5ffcea25072d3ec215c55753/4:3/w_1800,h_1350,c_limit/hirevue-1210924894.jpg', 'https://media.wired.com/photos/5ffcea25072d3ec215c55753/1:1/w_1350,h_1350,c_limit/hirevue-1210924894.jpg']","[{'@type': 'Person', 'name': 'Will Knight', 'sameAs': 'https://www.wired.com/author/will-knight/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",Job Screening Service Halts Facial Analysis of Applicants,2021-01-12T08:00:00.000-05:00,2021-01-12T08:00:00.000-05:00,business,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.wired.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'algorithms', 'item': 'https://www.wired.com/tag/algorithms/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Job Screening Service Halts Facial Analysis of Applicants'}]",tags,,"Will KnightBusinessJan 12, 2021 8:00 AMJob Screening Service Halts Facial Analysis of ApplicantsBut it’s still using intonation and behavior to assist with hiring decisions.Illustration: Elena Lacey; Getty ImagesSave this storySaveSave this storySaveThe AI Database →ApplicationEthicsFace recognitionHuman-computer interactionPersonal servicesRecommendation algorithmPredictionEnd UserBig companySmall companyStartupSectorConsumer servicesSource DataVideoSpeechTechnologyMachine learningNatural language processingMachine visionJob hunters may now need to impress not just prospective bosses but artificial intelligence algorithms too—as employers screen candidates by having them answer interview questions on a video that is then assessed by a machine.HireVue, a leading provider of software for vetting job candidates based on an algorithmic assessment, said Tuesday it is killing off a controversial feature of its software: analyzing a person’s facial expressions in a video to discern certain characteristics.AdChoicesADVERTISEMENTJob seekers screened by HireVue sit in front of a webcam and answer questions. Their behavior, intonation, and speech is fed to an algorithm that assigns certain traits and qualities.Trending NowMachine Learning: Living in the Age of AIHireVue says that an “algorithmic audit” of its software conducted last year shows it does not harbor bias. But the nonprofit Electronic Privacy Information Center had filed a complaint against the company with the Federal Trade Commission in 2019.HireVue CEO Kevin Parker acknowledges that public outcry over the use of software to analyze facial expressions in video was part of the calculation. “It was adding some value for customers, but it wasn’t worth the concern,” he says.AdvertisementThe algorithmic audit was performed by an outside firm, O’Neil Risk Consulting and Algorithmic Auditing. The company did not respond to requests for comment.Alex Engler, a fellow at the Brookings Institution who has studied AI hiring, says the idea of using AI to determine someone’s ability, whether it is based on video, audio, or text, is far-fetched. He says it is also problematic that the public cannot vet such claims.“There are parts that machine learning can probably help with, but fully automated interviews, where you’re making inferences about job performance—that’s terrible,” he says. “Modern artificial intelligence can’t make those inferences.”“Fully automated interviews, where you’re making inferences about job performance—that’s terrible.”Alex Engler, fellow, Brookings InstitutionHireVue says that about 700 companies, including GE, Unilever, Delta, and Hilton, use its technology. The software requires job applicants to respond to a series of questions in a recorded video. The company’s software then analyzes various characteristics including the language they use, their speech, and, until now, their facial expressions. It then provides an assessment of the applicant’s suitability for a job, as well as a measure of traits including “dependability,” “emotional intelligence,” and “cognitive ability.”Parker says the company helped screen more than 6 million videos last year, although sometimes this involved simply transcribing answers for an interviewer rather than performing an automated assessment of candidates. He adds that some clients let candidates opt out of automated screening. And he says HireVue has developed ways to avoid penalizing candidates with spotty internet connections, automatically referring those candidates to a human.AI experts warn that algorithms trained on data from previous job applicants may perpetuate existing biases in hiring. Lindsey Zuloaga, HireVue’s chief data scientist, says the company screens for bias on gender, race, and age by collecting that information in training data and looking for signs of bias.But she acknowledges that it may be more difficult to know if the system is biased on factors such as income or education level, or if it could be affected by something like a stutter.“I am surprised they are dropping this, as it was a keystone feature of the product they were marketing,” says John Davisson, senior counsel at EPIC. “That is the source of a lot of concerns around  biometric data collection, as well as these bold claims about being able to measure psychological traits, emotional intelligence, social attitudes, and things like that.”The WIRED Guide to Artificial IntelligenceSupersmart algorithms won't take all the jobs, But they are learning faster than ever, doing everything from medical diagnostics to serving up ads.By Tom SimoniteThe use of facial analysis to determine emotion or personality traits is controversial; some experts warn that the underlying science is flawed.Lisa Feldman Barrett, a professor at Northeastern University who studies analysis of emotion, says a person’s face does not on its own reveal emotion or character. “Just by looking at someone smiling, you can’t really tell anything about them except maybe that they have nice teeth,” she says. “It is a bad idea to make psychological inferences, and therefore determine people's outcomes, based on facial data alone.”Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDEPIC’s FTC complaint accused HireView of failing to guarantee fairness and of using algorithms that cannot be vetted. It also accused the company of misrepresenting its technology by claiming not to use facial recognition. Davisson says the agency has not yet acted on the complaint.But Davisson says he worries that automated analysis of speech could still have problems, and he says it is important that companies release the results of algorithmic audits. He says HireVue’s technology still needs to be vetted thoroughly.“I’m certainly concerned that the same potential issues around data collection and bias and opacity would just carry over to an audio-based screening systemAI hiring has caught the attention of some regulators. A bill before the New York City Council proposes regulating the use of hiring software by requiring employers to inform candidates when they are being assessed by AI, and requiring them to audit their algorithms every year.An Illinois law requires consent from candidates for analysis of video footage. Maryland has banned the use of facial analysis. In 2018, Amazon reportedly abandoned the use of its own technology for automating the assessment of candidate résumés due to biased results.Updated, 1-13-21, 4:50pm ET: An earlier version of this story incorrectly said HireVue had about 100 customers.Enter your email to get the Wired newsletterclose dialogRecommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialogMore Great WIRED Stories📩 Want the latest on tech, science, and more? Sign up for our newsletters!The secret history of the microprocessor, the F-14, and meWhat AlphaGo can teach us about how people learnUnlock your cycling fitness goals by fixing up your bike6 privacy-focused alternatives to apps you use every dayVaccines are here. We have to talk about side effects🎮 WIRED Games: Get the latest tips, reviews, and more🏃🏽‍♀️ Want the best tools to get healthy? Check out our Gear team’s picks for the best fitness trackers, running gear (including shoes and socks), and best headphones","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/job-screening-service-halts-facial-analysis-applicants/'}",,,,,,,"HireVue, a leading provider of software for vetting job candidates based on an algorithmic assessment, said Tuesday it is killing off a controversial feature of its software: analyzing a person’s facial expressions in a video to discern certain characteristics.
Job seekers screened by HireVue sit in front of a webcam and answer questions. Their behavior, intonation, and speech is fed to an algorithm that assigns certain traits and qualities.
HireVue says that an “algorithmic audit” of its software conducted last year shows it does not harbor bias. But the nonprofit Electronic Privacy Information Center had filed a complaint against the company with the Federal Trade Commission in 2019.
HireVue CEO Kevin Parker acknowledges that public outcry over the use of software to analyze facial expressions in video was part of the calculation. “It was adding some value for customers, but it wasn’t worth the concern,” he says.
The algorithmic audit was performed by an outside firm, O’Neil Risk Consulting and Algorithmic Auditing. The company did not respond to requests for comment.
Alex Engler, a fellow at the Brookings Institution who has studied AI hiring, says the idea of using AI to determine someone’s ability, whether it is based on video, audio, or text, is far-fetched. He says it is also problematic that the public cannot vet such claims.
“There are parts that machine learning can probably help with, but fully automated interviews, where you’re making inferences about job performance—that’s terrible,” he says. “Modern artificial intelligence can’t make those inferences.”
HireVue says that about 700 companies, including GE, Unilever, Delta, and Hilton, use its technology. The software requires job applicants to respond to a series of questions in a recorded video. The company’s software then analyzes various characteristics including the language they use, their speech, and, until now, their facial expressions. It then provides an assessment of the applicant’s suitability for a job, as well as a measure of traits including “dependability,” “emotional intelligence,” and “cognitive ability.”
Parker says the company helped screen more than 6 million videos last year, although sometimes this involved simply transcribing answers for an interviewer rather than performing an automated assessment of candidates. He adds that some clients let candidates opt out of automated screening. And he says HireVue has developed ways to avoid penalizing candidates with spotty internet connections, automatically referring those candidates to a human.
AI experts warn that algorithms trained on data from previous job applicants may perpetuate existing biases in hiring. Lindsey Zuloaga, HireVue’s chief data scientist, says the company screens for bias on gender, race, and age by collecting that information in training data and looking for signs of bias.
But she acknowledges that it may be more difficult to know if the system is biased on factors such as income or education level, or if it could be affected by something like a stutter.
“I am surprised they are dropping this, as it was a keystone feature of the product they were marketing,” says John Davisson, senior counsel at EPIC. “That is the source of a lot of concerns around  biometric data collection, as well as these bold claims about being able to measure psychological traits, emotional intelligence, social attitudes, and things like that.”
The use of facial analysis to determine emotion or personality traits is controversial; some experts warn that the underlying science is flawed.
Lisa Feldman Barrett, a professor at Northeastern University who studies analysis of emotion, says a person’s face does not on its own reveal emotion or character. “Just by looking at someone smiling, you can’t really tell anything about them except maybe that they have nice teeth,” she says. “It is a bad idea to make psychological inferences, and therefore determine people's outcomes, based on facial data alone.”
EPIC’s FTC complaint accused HireView of failing to guarantee fairness and of using algorithms that cannot be vetted. It also accused the company of misrepresenting its technology by claiming not to use facial recognition. Davisson says the agency has not yet acted on the complaint.
But Davisson says he worries that automated analysis of speech could still have problems, and he says it is important that companies release the results of algorithmic audits. He says HireVue’s technology still needs to be vetted thoroughly.
“I’m certainly concerned that the same potential issues around data collection and bias and opacity would just carry over to an audio-based screening system
AI hiring has caught the attention of some regulators. A bill before the New York City Council proposes regulating the use of hiring software by requiring employers to inform candidates when they are being assessed by AI, and requiring them to audit their algorithms every year.
An Illinois law requires consent from candidates for analysis of video footage. Maryland has banned the use of facial analysis. In 2018, Amazon reportedly abandoned the use of its own technology for automating the assessment of candidate résumés due to biased results.
Updated, 1-13-21, 4:50pm ET: An earlier version of this story incorrectly said HireVue had about 100 customers.

More Great WIRED Stories

📩 Want the latest on tech, science, and more? Sign up for our newsletters!
The secret history of the microprocessor, the F-14, and me
What AlphaGo can teach us about how people learn
Unlock your cycling fitness goals by fixing up your bike
6 privacy-focused alternatives to apps you use every day
Vaccines are here. We have to talk about side effects
🎮 WIRED Games: Get the latest tips, reviews, and more
🏃🏽‍♀️ Want the best tools to get healthy? Check out our Gear team’s picks for the best fitness trackers, running gear (including shoes and socks), and best headphones","{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,,,,,,,,"https://media.wired.com/photos/5ffcea25072d3ec215c55753/1:1/w_1350,h_1350,c_limit/hirevue-1210924894.jpg",But it’s still using intonation and behavior to assist with hiring decisions.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vd3d3LmVudGVycHJpc2VhaS5uZXdzLzIwMjEvMDEvMTMvaG9uaW5nLWluLW9uLWFpLXUtcy1sYXVuY2hlcy1uYXRpb25hbC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbml0aWF0aXZlLW9mZmljZS_SAQA?oc=5,"Honing In on AI, U.S. Launches National Artificial Intelligence Initiative Office - EnterpriseAI",2021-01-13,EnterpriseAI,https://www.enterpriseai.news,"To drive American leadership in the field of AI into the future, the National Artificial Intelligence Initiative Office has been launched by the White",,"To drive American leadership in the field of AI into the future, the National Artificial Intelligence Initiative Office has been launched by the White",,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/#article', 'isPartOf': {'@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/'}, 'author': {'name': 'Todd R. Weiss', '@id': 'https://www.enterpriseai.news/#/schema/person/fb78f94748db3ae901c8df838a371c96'}, 'headline': 'Honing In on AI, U.S. Launches National Artificial Intelligence Initiative Office', 'datePublished': '2021-01-13T18:43:40+00:00', 'dateModified': '2021-01-13T18:43:40+00:00', 'mainEntityOfPage': {'@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/'}, 'wordCount': 669, 'publisher': {'@id': 'https://www.enterpriseai.news/#organization'}, 'image': {'@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/#primaryimage'}, 'thumbnailUrl': 'https://www.enterpriseai.news/wp-content/uploads/2021/01/National-AI-Office-Seal_300x.png', 'keywords': ['AI', 'AI policy', 'artificial intelliegence', 'federal government', 'technology investment', 'U.S. AI initiatives', 'U.S. government'], 'articleSection': ['Academia', 'AI/ML/DL', 'Energy', 'Financial Services', 'Government', 'Healthcare', 'Life Sciences', 'Manufacturing', 'Media', 'Retail', 'Sectors', 'Slider: Front Page'], 'inLanguage': 'en-US', 'copyrightYear': '2021', 'copyrightHolder': {'@id': 'https://www.enterpriseai.news/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/', 'url': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/', 'name': 'Honing In on AI, U.S. Launches National Artificial Intelligence Initiative Office', 'isPartOf': {'@id': 'https://www.enterpriseai.news/#website'}, 'primaryImageOfPage': {'@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/#primaryimage'}, 'image': {'@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/#primaryimage'}, 'thumbnailUrl': 'https://www.enterpriseai.news/wp-content/uploads/2021/01/National-AI-Office-Seal_300x.png', 'datePublished': '2021-01-13T18:43:40+00:00', 'dateModified': '2021-01-13T18:43:40+00:00', 'description': 'To drive American leadership in the field of AI into the future, the National Artificial Intelligence Initiative Office has been launched by the White', 'breadcrumb': {'@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/#primaryimage', 'url': 'https://www.enterpriseai.news/wp-content/uploads/2021/01/National-AI-Office-Seal_300x.png', 'contentUrl': 'https://www.enterpriseai.news/wp-content/uploads/2021/01/National-AI-Office-Seal_300x.png', 'width': 300, 'height': 300}, {'@type': 'BreadcrumbList', '@id': 'https://www.enterpriseai.news/2021/01/13/honing-in-on-ai-u-s-launches-national-artificial-intelligence-initiative-office/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.enterpriseai.news/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Honing In on AI, U.S. Launches National Artificial Intelligence Initiative Office'}]}, {'@type': 'WebSite', '@id': 'https://www.enterpriseai.news/#website', 'url': 'https://www.enterpriseai.news/', 'name': 'EnterpriseAI', 'description': 'Advanced Computing in the Age of AI', 'publisher': {'@id': 'https://www.enterpriseai.news/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.enterpriseai.news/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.enterpriseai.news/#organization', 'name': 'EnterpriseAI', 'url': 'https://www.enterpriseai.news/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.enterpriseai.news/#/schema/logo/image/', 'url': 'https://www.enterpriseai.news/wp-content/uploads/2013/09/EAI2-01.png', 'contentUrl': 'https://www.enterpriseai.news/wp-content/uploads/2013/09/EAI2-01.png', 'width': 1598, 'height': 533, 'caption': 'EnterpriseAI'}, 'image': {'@id': 'https://www.enterpriseai.news/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/EnterpriseAINews/', 'https://twitter.com/enterpriseai_', 'https://www.linkedin.com/company/enterprisetech/about/']}, {'@type': 'Person', '@id': 'https://www.enterpriseai.news/#/schema/person/fb78f94748db3ae901c8df838a371c96', 'name': 'Todd R. Weiss', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.enterpriseai.news/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/d22225c56fbb97edfe9b0c851b54103b?s=96&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/d22225c56fbb97edfe9b0c851b54103b?s=96&r=g', 'caption': 'Todd R. Weiss'}, 'url': 'https://www.enterpriseai.news/author/todd/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vc2xvYW5yZXZpZXcubWl0LmVkdS9hcnRpY2xlL3RoZS1rZXktdG8tc3VjY2Vzcy13aXRoLWFpLWlzLWh1bWFuLW1hY2hpbmUtY29sbGFib3JhdGlvbi_SAQA?oc=5,The Key to Success With AI Is Human-Machine Collaboration - MIT Sloan Management Review,2021-01-13,MIT Sloan Management Review,https://sloanreview.mit.edu,Companies that emphasize collaboration between AI and human workers are best positioned for success.,,Companies that emphasize collaboration between AI and human workers are best positioned for success.,Companies that emphasize collaboration between AI and human workers are best positioned for success.,,,,,,,,,,,,,,,,"


Big Idea: Artificial Intelligence and Business Strategy The Key to Success With AI Is Human-Machine Collaboration
Companies that emphasize collaboration between AI and human workers are best positioned for success.


Allison Ryder

January 13, 2021

Reading Time: <1 minute





Topics


Data, AI, & Machine Learning


Managing Technology


AI & Machine Learning


Automation


Data & Data Culture


Technology Innovation Strategy




Artificial Intelligence and Business Strategy

            The Artificial Intelligence and Business Strategy initiative explores the growing use of artificial intelligence in the business landscape. The exploration looks specifically at how AI is affecting the development and execution of strategy in organizations.        

In collaboration with

                    BCG                


              
           More in this series
                      




 subscribe-icon

Subscribe
 










Share



 Twitter



Facebook







Linkedin










What to Read Next

 Banish the Harmful Creatures of COVID-Era Work | Melissa Swift
 Don’t Sacrifice Employee Upskilling for Productivity
 Three Questions to Ask About Your Digital Strategy
 Will AI Help or Hurt Sustainability? Yes | Andrew Winston











MIT Sloan Management Review and Boston Consulting Group’s 2020 global executive survey and research report on artificial intelligence and business strategy finds that companies that leverage human-machine collaboration are best positioned for success. To share more specifics about this finding, study coauthors David Kiron and François Candelon recently spoke about the research on a Web Summit panel.
Kiron and Candelon led the audience through the key findings from this fourth annual AI study. First, of over 3,000 organizations surveyed, only about 10% achieve significant financial benefits (defined as 5% to 10% of their overall revenue) with artificial intelligence. The research shows those 10% work with AI differently than other organizations by learning with AI:

They design AI systems that work for themselves.
They engineer systems where AI learns from humans.
They engineer systems where humans learn from AI.

Kiron and Candelon were joined by Mark Maybury, chief technology officer at Stanley Black & Decker, and Gail Evans, global chief digital officer at Mercer, who shared specific examples of how their organizations work toward learning with AI.
For more, watch the video of the Web Summit session, which aired on Dec. 4, 2020.



Get Updates on Leading With AI and Data

Get monthly insights on how artificial intelligence impacts your organization and what it means for your company and customers.


















                sign up            




Please enter a valid email address
Thank you for signing up
Privacy Policy














Topics


Data, AI, & Machine Learning


Managing Technology


AI & Machine Learning


Automation


Data & Data Culture


Technology Innovation Strategy




Artificial Intelligence and Business Strategy

            The Artificial Intelligence and Business Strategy initiative explores the growing use of artificial intelligence in the business landscape. The exploration looks specifically at how AI is affecting the development and execution of strategy in organizations.        

In collaboration with

                    BCG                


              
           More in this series
                      



About the Author
Allison Ryder (@allisonryder) is the senior project editor of MIT Sloan Management Review.



Tags: 

Artificial Intelligence
Chief Digital Officer
Chief Information Officer
Data Strategy
Webinars & Videos





More Like This
           Organizations Face Challenges in Timely Compliance With the EU AI Act                Fashioning the Perfect Fit With AI: Stitch Fix’s Jeff Cooper                AI Hype and Skepticism: Economist Paul Romer                Solving Real User Problems With Generative AI: Slack’s Jackie Rocca     
 


Add a comment Cancel replyYou must sign in to post a comment.First time here? Sign up for a free account: Comment on articles and get access to many more articles. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS93YXNoaW5ndG9uLXBvc3QtbGl2ZS8yMDIxLzAxLzEzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWhlYWx0aC1jYXJlL9IBAA?oc=5,Artificial Intelligence in Health Care - The Washington Post - The Washington Post,2021-01-13,The Washington Post,https://www.washingtonpost.com,"Andrew Hopkins, Ziad Obermeyer, Kimberly Powell & Eric Topol discuss AI in the health-care industry",,"Artificial intelligence is transforming the health-care industry. From machine learning to robotics to wearable sensors used to detect disease, AI is reducing drug dosage errors, streamlining diagnosis, detecting fraud, and providing efficient solutions for some of health care’s greatest challenges. Washington Post Live will convene some of the nation’s top thinkers and innovators in the space who are overseeing the explosion of medical data analytics and machines that are transforming medical care as we know it, including in the fight against COVID-19. Join the conversation on Wednesday, Jan. 13.","Artificial intelligence is transforming the health-care industry. From machine learning to robotics to wearable sensors used to detect disease, AI is reducing drug dosage errors, streamlining diagnosis, detecting fraud, and providing efficient solutions for some of health care’s greatest challenges. Washington Post Live will convene some of the nation’s top thinkers and innovators in the space who are overseeing the explosion of medical data analytics and machines that are transforming medical care as we know it, including in the fight against COVID-19. Join the conversation on Wednesday, Jan. 13.",https://schema.org,VideoObject,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://d1i4t8bqe7zgj6.cloudfront.net/01-13-2021/t_f866bb05f4a94a7c988c51a5804bfb0b_name_t_ae440d041f8f403eb6711e8e1f975fbd_name_file_1920x1080_5400_v4_cropped_.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://d1i4t8bqe7zgj6.cloudfront.net/01-13-2021/t_f866bb05f4a94a7c988c51a5804bfb0b_name_t_ae440d041f8f403eb6711e8e1f975fbd_name_file_1920x1080_5400_v4_cropped_.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://d1i4t8bqe7zgj6.cloudfront.net/01-13-2021/t_f866bb05f4a94a7c988c51a5804bfb0b_name_t_ae440d041f8f403eb6711e8e1f975fbd_name_file_1920x1080_5400_v4_cropped_.jpg&w=800&h=600', 'height': 800, 'width': 600}]","{'@type': 'Person', 'name': 'Washington Post Live'}","{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}",Artificial Intelligence in Health Care,2021-01-05T17:01:19.446Z,2021-01-14T14:24:58.082Z,,Artificial Intelligence in Health Care,False,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Washington Post Live', 'position': 1, 'item': 'https://www.washingtonpost.com/washington-post-live/'}]",Washington Post Live,,"Artificial Intelligence in Health Care52:45sharefull-screenplaymute0:00 / 52:45Andrew Hopkins, Ziad Obermeyer, Kimberly Powell & Eric Topol discuss AI in the health-care industry (Video: The Washington Post)By  Washington Post LiveJanuary 13, 2021 at 2:00 p.m. ESTThis article is free to access.Why?The Washington Post is providing this news free to all readers as a public service.Follow this story and more by signing up for national breaking news email alerts.Artificial intelligence is transforming the health-care industry.From machine learning to robotics to wearable sensors used to detect disease, AI is reducing drug dosage errors, streamlining diagnosis, detecting fraud, and providing efficient solutions for some of health care’s greatest challenges.Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeWashington Post Live will convene some of the nation’s top thinkers and innovators in the space who are overseeing the explosion of medical data analytics and machines that are transforming medical care as we know it, including in the fight against COVID-19.HighlightsAndrew Hopkins, CEO of Exscientia, said the quick development of the coronavirus vaccine is “going to be a watershed in how we think about efficiency and productivity,” adding that the challenge drug developers will now face is ""how do we do this, not just for the urgency of vaccines, but how do we do this for the development of all drugs."" (Video: Washington Post Live)Ziad Obermeyer, professor of health policy and management at the UC Berkeley School of Public Health, said government regulation of artificial intelligence can have a positive impact, but it can't get ahead of the ""many creative and potentially dangerous uses that people are going to put algorithms toward.” “In a lot of our work what we've found is there is a substantial amount of racial bias in algorithms that are fairly widespread...that's the kind of thing that certainly suggests a role for regulation."" (Video: Washington Post Live)Eric Topol, founder and director of the Scripps Research Translational Institute, said we need to move faster in the next six to eight weeks to vaccinate before new variants are widely spread, adding that we’ve already “broken the healthcare system capabilities.” ""The virus is opportunistic and exponential, we have to be the same."" (Video: Washington Post Live)Eric Topol, founder and director of the Scripps Research Translational Institute, said we're going to see more spread of covid-19 strains if we don't get tighter with procedures like wearing masks, social distancing and better surveillance, explaining that the variants “double each week, at least.” (Video: Washington Post Live)Kimberly Powell, VP of health care at NVIDIA, said President-elect Joe Biden’s plan to release nearly all available vaccine doses “makes perfect sense.” “We have so many that need to be protected we’ve got to logistically figure this out…If you think about how Amazon can logistically get packages to my door in a couple of hours, it seems to me that we could target and get shots in arms to the people who need it most. You know that Amazon and their platform is largely driven by artificial intelligence and technology. We’ve got to understand that this technology exists and we’ve got to use everything in our power to put it in place.” (Video: Washington Post Live)GuestsAndrew Hopkins, CEO, ExscientiaAndrew Hopkins is founder and CEO of the global pharmatech company, Exscientia, which uses artificial intelligence (AI) to efficiently discover innovative medicines. For over 20 years, Dr Hopkins’ work and research methods have been driven by a mission to accelerate the time between the start of an idea to a viable new drug candidate for patients. At Exscientia, Dr Hopkins oversaw the discovery of the world’s first precision engineered drug generated by AI to enter phase 1 human clinical trials.AdvertisementStory continues below advertisementPrior to founding Exscientia, Dr Hopkins was the SULSA Research Professor of Translational Biology and the Chair of Medicinal Informatics at the University of Dundee. Before becoming an academic, he held various research leadership positions at Pfizer for 10 years. Hopkins holds a DPhil from the University of Oxford in Molecular Biophysics. He has been awarded Fellowships from several national academies in the UK.Exscientia has offices in Oxford, Miami, and Osaka. Dr Hopkins lives in Oxford with his wife and daughter.Ziad Obermeyer, Professor of Health Policy and Management, UC Berkeley School of Public HealthZiad Obermeyer is the Blue Cross of California Distinguished Professor of Health Policy and Management in the School of Public Health at UC Berkeley, where he does research at the intersection of machine learning, medicine, and health policy. He was named an Emerging Leader in Health and Medicine by the National Academy of Medicine, and received numerous awards including the Early Independence Award -- the National Institutes of Health’s most prestigious award for exceptional junior scientists -- and the Young Investigator Award from the Society for Academic Emergency Medicine. Previously, he was an Assistant Professor at Harvard Medical School. He continues to practice emergency medicine in underserved communities. His work has been published in Science, The New England Journal of Medicine, JAMA, The BMJ, and Health Affairs, and his research has been supported by the National Institutes of Health, Schmidt Futures, the Gordon and Betty Moore Foundation, the Robert Wood Johnson Foundation, and the Laura and John Arnold Foundation. Prior to his career in medicine, he worked as a consultant to pharmaceutical and global health clients at McKinsey & Co. in New Jersey, Geneva, and Tokyo. He is a graduate of Harvard College (magna cum laude) and Harvard Medical School (magna cum laude), and earned an M.Phil. from Cambridge.Kimberly Powell, VP of Health Care, NVIDIAKimberly Powell is vice president of healthcare at NVIDIA. She is responsible for the company’s worldwide healthcare business, including hardware and software platforms for accelerated computing, AI and visualization that power the ecosystem of medical imaging, life sciences, drug discovery and healthcare analytics.AdvertisementStory continues below advertisementPreviously, Powell led the company’s higher education and research business, along with strategic evangelism programs, NVIDIA AI Labs and the NVIDIA Inception program with over 4,000 AI startup members.Share this articleSharePowell joined NVIDIA in 2008 with responsibility for establishing NVIDIA GPUs as the accelerator platform for medical imaging instruments. She spent her early career in engineering and product management of diagnostic display systems at Planar Systems.Powell received a B.S. in electrical engineering with a concentration in computer engineering from Northeastern University.Eric Topol, Founder and Director, Scripps Research Translational InstituteEric Topol is the Founder and Director of the Scripps Research Translational Institute, Professor, Molecular Medicine, and Executive Vice-President of Scripps Research. As a researcher, he has published over 1,200 peer-reviewed articles, with more than 280,000 citations, elected to the National Academy of Medicine, and is one of the top 10 most cited researchers in medicine. His principal scientific focus has been on the genomic and digital tools to individualize medicine.AdvertisementStory continues below advertisementIn 2016, Topol was awarded a $207 million grant from the NIH to lead a significant part of the Precision Medicine (All of Us) Initiative, a prospective research program enrolling 1 million participants in the US. This is in addition to his role as principal investigator for a flagship $35M NIH grant to promote innovation in medicine. He was the founder of a new medical school at Cleveland Clinic, Lerner College of Medicine, with Case Western University. He has over 280,000 followers on Twitter (@EricTopol) where recently he has been reporting insights and research findings for COVID-19. Besides editing several textbooks, he has published 3 bestseller books on the future of medicine: The Creative Destruction of Medicine, The Patient Will See You Now, and Deep Medicine: How Artificial Intelligence Can Make Healthcare Human Again. Lastly, Topol was commissioned by the UK 2018-2019 to lead planning for the National Health Service’s integration of AI and new technologies.Content from GEThis content was produced and paid for by a Washington Post Live event sponsor. The Washington Post newsroom was not involved in the production of this content.How AI is Helping Reimagine Hospitals Today and in the FutureArtificial intelligence is helping clinicians fight COVID-19 and playing a critical role in all facets of care today. While many health-care providers were already using AI in their daily work pre-COVID-19 to speed diagnoses and tackle routine paperwork, that trend increased dramatically as they responded to the challenges of COVID-19. Today, hospitals and providers are using AI to maximize efficiency and minimize staff burnout while improving care for a growing number of patients – and they will continue to do so in the future as systems recover, rebuild and reimagine health care going forward. How do we harness this growth as we reimagine a future of health care and what new advances are possible? Join GE Healthcare’s president and CEO of the U.S. and Canada, Everett Cunningham, along with UC Davis School of Medicine/Health System chief research informatics officer (interim), Rachael Callcut, MD, MSPH as they discuss the potential of AI today and in the future.Artificial intelligence is helping clinicians fight COVID-19 and playing a critical role in all facets of care today. While many health-care providers were already using AI in their daily work pre-COVID-19 to speed diagnoses and tackle routine paperwork, that trend increased dramatically as they responded to the challenges of COVID-19. Today, hospitals and providers are using AI to maximize efficiency and minimize staff burnout while improving care for a growing number of patients – and they will continue to do so in the future as systems recover, rebuild and reimagine health care going forward. How do we harness this growth as we reimagine a future of health care and what new advances are possible? Join GE Healthcare’s president and CEO of the U.S. and Canada, Everett Cunningham, along with UC Davis School of Medicine/Health System chief research informatics officer (interim), Rachael Callcut, MD, MSPH as they discuss the potential of AI today and in the future. (Video: Washington Post Live)Everett Cunningham, President and CEO, GE Healthcare, U.S. and CanadaEverett is the President & CEO of GE Healthcare’s $8 billion U.S. & Canada region. Everett and his team of nearly 8,000 industry experts leverage the capabilities across GE Healthcare to partner with providers and governments to help improve healthcare quality, access and affordability. Prior to joining GE Healthcare, Everett served as the Senior Vice President, Commercial for Quest Diagnostics, responsible for global commercial sales, marketing, and commercial operations. At Quest Diagnostics, Everett led over 1,500 employees and successfully managed $7.6 billion dollars in top line revenue. Prior to his role at Quest Diagnostics, Everett spent 21 years with Pfizer, Inc., where he served most recently as Regional President, Established Products for Asia Pacific. Beginning his career as a Sales Representative, Everett served in roles of increasing responsibility including Senior Director of Worldwide Learning and Development, Senior Director of Business Operations and Vice President Sales for U.S. Pharmaceuticals, and Vice President of Global Corporate Human Resources. With 25+ years of progressive responsibility in pharmaceuticals and medical services, Everett is committed to leadership excellence with a diligent focus on methodical results, demonstrated change agility, building organizational capability, and cross functional matrix teams. Everett earned his bachelor’s degree in economics from Northwestern University.Rachael Callcut, MD, MSPH, Chief Research Informatics Officer (Interim), UC Davis School of Medicine/Health SystemRachael A. Callcut, M.D., M.S.P.H. is the Chief Research Informatics Officer (Interim) of the UC Davis School of Medicine/Health System and the Vice Chair of Clinical Sciences in the Department of Surgery. Dr. Callcut also serves through a joint appointment also as the inaugural Director of Data Science for Center for Digital Health Innovation based at UC San Francisco (UCSF). Dr. Callcut is an internationally renowned expert in Artificial Intelligence and Health Services Research. Her leadership has led to the creation of FDA cleared AI algorithms which are now deployed in clinical settings. Dr. Callcut is also an actively practicing surgeon, double board certified in general surgery and surgical critical care. She also directs NIH and DOD funded research focused on improving outcomes after severe injury or illness including from COVID-19 related acute respiratory distress syndrome. Dr. Callcut received her bachelors degree from Case Western Reserve University, her Masters in Public Health from the University of Wisconsin and her Doctor of Medicine from the University of Cincinnati College of Medicine.Moderated by Mikey Kay, Filmmaker and Freelance CorrespondentIn his second career as a correspondent and filmmaker, along with national security and aviation Mikey Kay has also covered in-depth medical, mental health, political, conservation, religious, and energy-based stories broadcast on the BBC, CNN, ABC News, MSNBC, National Geographic, History Channel, Travel Channel, and Vogue. For most of 2020, Mikey has documented and told over 80 stories as GE Healthcare’s correspondent and filmmaker, driving an RV solo across the U.S, using public transport to get across Europe, using a motorbike to tell stories across India, and a bicycle to tell stories from Sweden and Norway. He is an accomplished correspondent, host, camera operator, writer and editor, and can operate as a correspondent or with a camera at high altitudes, being an experienced mountaineer, or sub-surface being a qualified SCUBA diver. In the last few years he has filmed in Iraq, Siberia, South Africa, Peru, Nicaragua, Namibia, Vietnam, Columbia, Japan, Kenya, Ethiopia, China, Pakistan, Saudi Arabia, UAE, Oman, Lebanon, Kyrgyzstan, Europe, and the United States including Alaska. He filmed and directed his latest film for the BBC, My Autistic Big Brother & Me, in the mountains of North Wales and spent four years writing and editing the initial 60 minute version. The 40 minute version aired on the BBC and BBC iPlayer in early 2019. In his first chapter, he spent 20 years flying and operating assault helicopters as well as strategic planning, in Her Majesty’s Royal Air Force, serving on operational flying tours in Kosovo, Macedonia, Bosnia and Iraq, as well as strategy and diplomacy tours in Afghanistan, Sumatra (post tsunami), India and Africa. He quickly rose to Senior Officer status and spent his final years before military retirement as a military advisor within the UK’s Ministry of Defense.Share10 CommentsNewsletterDailyToday’s HeadlinesThe most important news stories of the day, curated by Post editors, delivered every morning.Sign upSubscribe to comment and get the full experience. Choose your plan →",https://www.washingtonpost.com/washington-post-live/2021/01/13/artificial-intelligence-health-care/,,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,,,,,,,https://www.washingtonpost.com/wp-apps/imrs.php?src=https%3A%2F%2Fd1i4t8bqe7zgj6.cloudfront.net%2F01-13-2021%2Ft_f866bb05f4a94a7c988c51a5804bfb0b_name_t_ae440d041f8f403eb6711e8e1f975fbd_name_file_1920x1080_5400_v4_cropped_.jpg&w=960,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-14T00:09:33Z,https://www.washingtonpost.com/video/c/embed/a451172d-e386-4a6e-ae83-b242a701eb46,https://d21rhj7n383afu.cloudfront.net/washpost-production/The_Washington_Post/20210113/5fff6b1952faff00010cfc39/5fff7036c9e77c0007225526/file_640x360-600-v3.mp4,PT52M45S,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmF1Z2FuaXgub3JnL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXNvbHV0aW9ucy1wcm92aWRlci1vY3RvLXRvLXdvcmstb24tdXMtYXJteXMtaXZhcy1jb250cmFjdC_SAQA?oc=5,Artificial Intelligence solutions provider Octo to work on US Army’s IVAS contract - Auganix,2021-01-13,Auganix,https://www.auganix.org,"In Augmented Reality News January 13, 2021 – Octo, a provider of technology and IT solutions for government clients, has announced that it has been awarded a…",,"In Augmented Reality News January 13, 2021 – Octo, a provider of technology and IT solutions for government clients, has announced that it has been awarded a spot on the US Army’s RS3 92 Situational…","In Augmented Reality News January 13, 2021 – Octo, a provider of technology and IT solutions for government clients, has announced that it has been awarded a spot on the US Army’s RS3 92 Situational…",https://schema.org,,,,,,,,,,,,,,,"
Artificial Intelligence solutions provider Octo to work on US Army’s IVAS contract
January 13, 2021
2021, Augmented Reality News, Awards, Collaborations & Partnerships, Contracts, Defence & Security, News, North America, Platform, Software, System Software, USA



In Augmented Reality News 
January 13, 2021 – Octo, a provider of technology and IT solutions for government clients, has announced that it has been awarded a spot on the US Army’s RS3 92 Situational Awareness and Augmented Reality Technologies contract to provide machine learning and deep learning support to the Army’s Integrated Visual Augmentation System program (IVAS). Octo will partner with security and defence contractor QinetiQ to work on the contract.
The IVAS contract, which went to tender back in August 2018, is part of the US Army’s plan to produce innovative solutions that help to accelerate lethal defensive and offensive capabilities of Army warfighters by utilizing innovative components, including the use of augmented reality (AR). 
The IVAS platform is billed as a “fight-rehearse-train” system, meaning its function on the battlefield is priority, but its AR capabilities, such as real-time mapping, will make it useful for training and rehearsing operations anywhere at any time. As a result, IVAS offers a single platform that allows soldiers to fight, rehearse, and train, improving their sensing, decision making, target acquisition, and target engagement through a next generation, 24/7 situational awareness tool. 

“Octo has a longstanding relationship with the Army, and we are excited to offer AI as part of their mission solutions,” said Rob Albritton, Senior Director of Octo’s AI Center of Excellence. “Enhancing soldier lethality and situational awareness is an Army priority, and IVAS serves as the centerpiece. IVAS will operationalize AI in ways the Army could only imagine two years ago. Supporting our close combat force with emerging technology they can use in the field is an honor.”
Octo’s Chief Technology Officer Sujey Edward said, “Octo has a long history of introducing emerging technology into Federal Government agencies, and Rob is helping us lead the way by giving the Army the kind of advanced tools they need to better protect their warfighters and our nation.”
He continued, “Octo is serious about AI. We have the experience and the people to make AI solutions happen for our Federal Government customers. We’re proud to have Rob bringing with him the level of expertise the armed forces depend on, and we look forward to further supporting them by providing tactical edge AI solutions.”
Mehul Sanghani, Octo’s CEO, added: “Winning contracts like IVAS is part of our focus on emerging technologies as a means of helping the government leverage these newly available solutions to maximize mission effectiveness,” added Mehul Sanghani, Octo’s CEO. 
The company stated that the award demonstrates Octo’s artificial intelligence (AI) capabilities and solutions, however did not disclose a monetary amount for the award. For more information on the US Army’s IVAS contract, please click here.
Image / video credit: US Army / YouTube
Share this articleClick to share on X (Opens in new window)Click to share on LinkedIn (Opens in new window)Click to share on Facebook (Opens in new window)Click to share on WhatsApp (Opens in new window)Click to share on Reddit (Opens in new window)Related PostsUS Army accepts delivery of 20 prototypes of IVAS 1.2 variant from MicrosoftAugmented Reality Advertising: 10 Powerful Examples of Branded AR CampaignsHaptX partners with Y-12 National Security Complex to advance nuclear operations trainingThe Future of XR in the AEC Industry


About the authorSam SpriggSam is the Founder and Managing Editor of Auganix. With a background in research and report writing, he has been covering XR industry news for the past seven years. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebSite', '@id': 'https://www.auganix.org/#/schema/WebSite', 'url': 'https://www.auganix.org/', 'name': 'Auganix.org', 'description': 'AR and VR industry news', 'inLanguage': 'en-US', 'potentialAction': {'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.auganix.org/search/{search_term_string}/'}, 'query-input': 'required name=search_term_string'}, 'publisher': {'@type': 'Organization', '@id': 'https://www.auganix.org/#/schema/Organization', 'name': 'Auganix.org', 'url': 'https://www.auganix.org/', 'sameAs': ['https://www.facebook.com/auganix', 'https://twitter.com/auganix_org', 'https://ca.linkedin.com/company/auganix'], 'logo': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/www.auganix.org/wp-content/uploads/2022/06/Auganix-Header-Image-1.png?fit=900%2C165&ssl=1', 'contentUrl': 'https://i0.wp.com/www.auganix.org/wp-content/uploads/2022/06/Auganix-Header-Image-1.png?fit=900%2C165&ssl=1', 'width': 900, 'height': 165, 'contentSize': '11626'}}}, {'@type': 'WebPage', '@id': 'https://www.auganix.org/artificial-intelligence-solutions-provider-octo-to-work-on-us-armys-ivas-contract/', 'url': 'https://www.auganix.org/artificial-intelligence-solutions-provider-octo-to-work-on-us-armys-ivas-contract/', 'name': 'Artificial Intelligence solutions provider Octo to work on US Army&#8217;s IVAS contract | Auganix.org', 'description': 'In Augmented Reality News January 13, 2021 &ndash; Octo, a provider of technology and IT solutions for government clients, has announced that it has been awarded a&#8230;', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://www.auganix.org/#/schema/WebSite'}, 'breadcrumb': {'@type': 'BreadcrumbList', '@id': 'https://www.auganix.org/#/schema/BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': 'https://www.auganix.org/', 'name': 'Auganix.org'}, {'@type': 'ListItem', 'position': 2, 'item': 'https://www.auganix.org/category/news/', 'name': 'AR and VR Industry News'}, {'@type': 'ListItem', 'position': 3, 'item': 'https://www.auganix.org/category/news/contracts/', 'name': 'AR and VR Contract Tenders and Awards'}, {'@type': 'ListItem', 'position': 4, 'item': 'https://www.auganix.org/category/news/contracts/contract-awards/', 'name': 'AR and VR Contract Awards and News'}, {'@type': 'ListItem', 'position': 5, 'name': 'Artificial Intelligence solutions provider Octo to work on US Army&#8217;s IVAS contract'}]}, 'potentialAction': {'@type': 'ReadAction', 'target': 'https://www.auganix.org/artificial-intelligence-solutions-provider-octo-to-work-on-us-armys-ivas-contract/'}, 'datePublished': '2021-01-13', 'dateModified': '2021-01-13', 'author': {'@type': 'Person', '@id': 'https://www.auganix.org/#/schema/Person/7627c724b0c40c567c69694f46fdef31', 'name': 'Sam Sprigg', 'description': 'Sam is the Founder and Managing Editor of Auganix. With a background in research and report writing, he has been covering XR industry news for the past seven years.'}}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vbmV3cy5mdWxsZXJ0b24uZWR1LzIwMjEvMDEvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVzZWFyY2gtdG8taW1wcm92ZS1hY2FkZW1pYy1wZXJmb3JtYW5jZS1pbi1zdGVtL9IBAA?oc=5,Artificial Intelligence Research to Improve Academic Performance in STEM - CSUF News,2021-01-13,CSUF News,https://news.fullerton.edu,"To help students boost their academic performance and stick with STEM majors, Cal State Fullerton’s Yu Bai, assistant professor of computer engineering, is working on a solution using artificial intelligence — machines that think like humans.",,"To help students boost their academic performance and stick with STEM majors, Cal State Fullerton’s Yu Bai, assistant professor of computer engineering, is working on a solution using artificial intelligence — machines that think like humans.",,https://schema.org,,,,,,,,,,,,,,,"

 
Some college students struggle with the rigor of a STEM major and often drop out and change majors. 
To help students boost their academic performance and stick with STEM majors, Cal State Fullerton’s Yu Bai, assistant professor of computer engineering, is working on a solution using artificial intelligence — machines that think like humans.
Bai is developing an assisted-learning system using artificial intelligence (AI) technology to identify barriers and help college students, especially those from underrepresented backgrounds, persist and be successful in STEM (science, technology, engineering and math) coursework. Studies show that underrepresented students either switch or drop their engineering major at an alarming higher rate (40%) than their peers (29%), Bai added.
Bai’s research was selected by the National Academies of Sciences, Engineering and Medicine as one of 50 winning projects in its “ideas competition” that attracted projects from higher institutions around the world. The winning ideas were presented at a November symposium, sponsored by the National Science Foundation, to drive change in STEM education and influence funding priorities for NSF and other organizations. 
Bai’s project, called APLES (AI-Driven Personalized Learning System), offers students an individualized academic plan, as well as interventions, such as peer group learning sessions to master course concepts. One of the most innovative aspects is that the AI learning system integrates students’ academic performance, background, and other personal and cultural data to predict their knowledge difficulties in specific STEM courses, Bai noted.
Compared to human efforts, the AI-driven learning system is being developed to predict students’ knowledge difficulties before taking the STEM course; analyze data from homework, labs, quizzes, exams and class discussions to forecast learning challenges; monitor the student’s study habits and knowledge to offer recommendations for campus support and resources; and suggest career paths.
Yu Bai, assistant professor of computer engineering
“This AI learning system can identify the uniqueness of each student, as well as offer information about students to their instructors to allow them to better understand each other so that undergraduate STEM education and learning become a more proactive, collaborative practice in the future,” Bai said.
Bai, who is seeking public and private funding for the project, has submitted a grant proposal to NSF with collaborators from the University of Missouri-Kansas City and Cal Poly Pomona. CSUF computer engineering and computer science undergraduates and graduate students also are involved in the research project. 
The end-goal of the project is to develop an intelligent learning system that can be used at colleges and universities across the country, specifically institutions that serve underrepresented students, Bai said. 
“CSUF students will benefit from this research since, by using AI to personalize learning, it eliminates the equity gap between underrepresented and general students,” he said.
As part of the project, in the fall semester, Bai developed an AI algorithm for predicting student performance on exams in his computer science and engineering classes. According to the results, 42% of the students had difficulty grasping the concepts. Based on the prediction results, he performed early interventions to help students do better on the exam, in which students achieved an 86% average (out of 100%) — an 11% improvement over the previous semester. The algorithm can be used for other STEM courses in science and mathematics, Bai added.
“With its powerful processing and predicting ability that can transform fast, personalized and targeted curation of content, artificial intelligence will no doubt revolutionize learning and instruction,” Bai said. “To keep the U.S. leading in the fast advancement of technology, we need to prepare students for the demand of a well-trained, diverse STEM workforce.” 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/#article', 'isPartOf': {'@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/'}, 'author': {'name': 'Debra Cano Ramos', '@id': 'https://news.fullerton.edu/#/schema/person/0a76ae90ce61f6820941462b909da938'}, 'headline': 'Artificial Intelligence Research to Improve Academic Performance in STEM', 'datePublished': '2021-01-13T20:32:43+00:00', 'dateModified': '2022-02-07T16:57:50+00:00', 'mainEntityOfPage': {'@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/'}, 'wordCount': 604, 'publisher': {'@id': 'https://news.fullerton.edu/#organization'}, 'image': {'@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/#primaryimage'}, 'thumbnailUrl': 'https://news.fullerton.edu/app/uploads/2021/01/Learning-Artificial-Intelligence.jpg', 'keywords': ['Awards and Honors', 'Research and Creative Activities'], 'articleSection': ['Engineering and Computer Science', 'It Takes a Titan Campaign'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/', 'url': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/', 'name': 'Artificial Intelligence Research to Improve Academic Performance in STEM | CSUF News', 'isPartOf': {'@id': 'https://news.fullerton.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/#primaryimage'}, 'image': {'@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/#primaryimage'}, 'thumbnailUrl': 'https://news.fullerton.edu/app/uploads/2021/01/Learning-Artificial-Intelligence.jpg', 'datePublished': '2021-01-13T20:32:43+00:00', 'dateModified': '2022-02-07T16:57:50+00:00', 'description': 'To help students boost their academic performance and stick with STEM majors, Cal State Fullerton’s Yu Bai, assistant professor of computer engineering, is working on a solution using artificial intelligence — machines that think like humans.', 'breadcrumb': {'@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/#primaryimage', 'url': 'https://news.fullerton.edu/app/uploads/2021/01/Learning-Artificial-Intelligence.jpg', 'contentUrl': 'https://news.fullerton.edu/app/uploads/2021/01/Learning-Artificial-Intelligence.jpg', 'width': 800, 'height': 502, 'caption': 'Illustration showing Artificial Intelligence'}, {'@type': 'BreadcrumbList', '@id': 'https://news.fullerton.edu/2021/01/artificial-intelligence-research-to-improve-academic-performance-in-stem/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.fullerton.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence Research to Improve Academic Performance in STEM'}]}, {'@type': 'WebSite', '@id': 'https://news.fullerton.edu/#website', 'url': 'https://news.fullerton.edu/', 'name': 'CSUF News', 'description': 'California State University, Fullerton', 'publisher': {'@id': 'https://news.fullerton.edu/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.fullerton.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://news.fullerton.edu/#organization', 'name': 'California State University, Fullerton', 'url': 'https://news.fullerton.edu/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.fullerton.edu/#/schema/logo/image/', 'url': 'https://news.fullerton.edu/app/uploads/2020/09/csuf-logo.png', 'contentUrl': 'https://news.fullerton.edu/app/uploads/2020/09/csuf-logo.png', 'width': 1436, 'height': 331, 'caption': 'California State University, Fullerton'}, 'image': {'@id': 'https://news.fullerton.edu/#/schema/logo/image/'}, 'sameAs': ['http://www.facebook.com/csufofficial', 'https://x.com/csuf']}, {'@type': 'Person', '@id': 'https://news.fullerton.edu/#/schema/person/0a76ae90ce61f6820941462b909da938', 'name': 'Debra Cano Ramos'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPGh0dHBzOi8vZmVkc2Nvb3AuY29tL25hdGlvbmFsLWFpLWluaXRpYXRpdmUtb2ZmaWNlLWxhdW5jaGVkL9IBAA?oc=5,National AI Initiative Office launched by White House - FedScoop,2021-01-12,FedScoop,https://fedscoop.com,"The new office is expected to coordinate research and policymaking across government, industry and academia for years to come.","['american ai initiative', 'artificial intelligence (ai)', 'donald trump', 'lynne parker', 'michael kratsios', 'national artificial intelligence initiative office', 'national artificial intelligence research and development strategic plan', 'national defense authorization act', 'office of science and technology policy', 'select committee on artificial intelligence', 'white house']","The new office is expected to coordinate research and policymaking across government, industry and academia for years to come.",,https://schema.org,NewsArticle,http://fedscoop.com/national-ai-initiative-office-launched/,"{'@type': 'ImageObject', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2020/03/lynne-parker-20200311.jpg'}","[{'@type': 'Person', 'name': 'Dave Nyczepir'}]","{'@type': 'Organization', 'name': 'FedScoop', 'logo': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/cropped-fs_favicon-3.png'}",National AI Initiative Office launched by White House,2021-01-12T18:36:41Z,2023-11-08T16:04:16Z,AI,,,,,,"






AI




								National AI Initiative Office launched by White House							

								The new office is expected to coordinate research and policymaking across government, industry and academia for years to come.							


By
Dave Nyczepir



January 12, 2021






 
											Lynne Parker speaks March 11, 2020, at the IT Modernization Summit presented by FedScoop. (Scoop News Group)										





The White House on Tuesday fulfilled its requirement to establish an office responsible for coordinating artificial intelligence research and policymaking across government, industry and academia.
Dubbed the National AI Initiative Office, it will implement a national AI strategy under the leadership of Founding Director Lynne Parker, who also serves as U.S. deputy chief technology officer.
The White House Office of Science and Technology Policy established the office in accordance with the National AI Initiative Act of 2020, which codified a number of policies and initiatives aimed at ensuring U.S. leadership in the technology globally.
“The National Artificial Intelligence Initiative Office will be integral to the federal government’s AI efforts for many years to come, serving as a central hub for national AI research and policy for the entire U.S. innovation ecosystem,” said Michael Kratsios, U.S. CTO, in a statement.


Advertisement



Some have noted the new office’s logo, which features a bald eagle clutching a neural network — the technology central to machine learning and AI.
The National AI Initiative Office seal
The National AI Initiative Act of 2020 was passed as part of the National Defense Authorization Act of 2021 earlier this month.
Additionally the law codified the American AI Initiative to increase research investment, improve access to computing and data resources, set technical standards, build a workforce, and engage with allies.
The White House-based Select Committee on AI was expanded and made permanent to oversee the initiative, and the national AI research institutes and National AI Research and Development Strategic Plan were codified.


Advertisement




A National AI Research Resource for existing compute power and datasets is now required, as is an annual AI budget rollup of all federal investments.
The Industries of the Future Act was also included in the NDAA and requires a plan to double AI R&D investment, as suggested in the Trump administration’s final budget proposal.








Written by Dave Nyczepir
Dave Nyczepir is a technology reporter for FedScoop. He was previously the news editor for Route Fifty and, before that, the education reporter for The Desert Sun newspaper in Palm Springs, California. He covered the 2012 campaign cycle as the staff writer for Campaigns & Elections magazine and Maryland’s 2012 legislative session as the politics reporter for Capital News Service at the University of Maryland, College Park, where he earned his master’s of journalism. 


In This Story



														White House													



														Artificial Intelligence (AI)													



														Donald Trump													



														Office of Science and Technology Policy													



														National Defense Authorization Act													



														Michael Kratsios													



														Select Committee on Artificial Intelligence													



														National Artificial Intelligence Research and Development Strategic Plan													



														American AI Initiative													



														Lynne Parker													



														National Artificial Intelligence Initiative Office													








Share




Facebook





LinkedIn





Twitter





Copy Link











Advertisement






Advertisement





More Like This






								Energy highlights roadmap for FASST AI program			



By 

						Rebecca Heilweil					










								GSA calls for nominations to emerging tech-focused acquisition advisory committee			



By 

						Caroline Nihill					










								VA plans to award AI tech sprint winners contracts for ambient medical transcription services			



By 

						Caroline Nihill					









Advertisement





Top Stories






								After 2023 outage that paused flights nationwide, FAA now has backup system			



By 

						Rebecca Heilweil					










								FedRAMP ‘undeniably’ in state of limbo without final OMB modernization guidance, Rep. Connolly says			



By 

						Caroline Nihill					










								How the IRS’s ‘cautious’ approach with Direct File prevented its ‘failure’			



By 

						Matt Bracken					










								Social Security Administration transitioning long-time users to Login.gov			



By 

						Rebecca Heilweil					










								Energy Department’s national labs get AI boost in bipartisan Senate bill			



By 

						Matt Bracken					










Advertisement






","{'@type': 'WebPage', '@id': 'http://fedscoop.com/national-ai-initiative-office-launched/'}",2021-01-12T18:36:41Z,,,,['Dave Nyczepir'],,,,,,,,,,,,,,https://fedscoop.com/wp-content/uploads/sites/5/2020/03/lynne-parker-20200311.jpg?w=150&h=150&crop=1,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://fedscoop.com/national-ai-initiative-office-launched/', 'url': 'https://fedscoop.com/national-ai-initiative-office-launched/', 'name': 'National AI Initiative Office launched by White House | FedScoop', 'isPartOf': {'@id': 'https://fedscoop.com/#website'}, 'primaryImageOfPage': {'@id': 'https://fedscoop.com/national-ai-initiative-office-launched/#primaryimage'}, 'image': {'@id': 'https://fedscoop.com/national-ai-initiative-office-launched/#primaryimage'}, 'thumbnailUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2020/03/lynne-parker-20200311.jpg', 'datePublished': '2021-01-12T18:36:41+00:00', 'dateModified': '2023-11-08T16:04:16+00:00', 'description': 'The new office is expected to coordinate research and policymaking across government, industry and academia for years to come.', 'breadcrumb': {'@id': 'https://fedscoop.com/national-ai-initiative-office-launched/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://fedscoop.com/national-ai-initiative-office-launched/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/national-ai-initiative-office-launched/#primaryimage', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2020/03/lynne-parker-20200311.jpg', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2020/03/lynne-parker-20200311.jpg', 'width': 1920, 'height': 1024, 'caption': 'Lynne Parker speaks March 11, 2020, at the IT Modernization Summit presented by FedScoop. (Scoop News Group)'}, {'@type': 'BreadcrumbList', '@id': 'https://fedscoop.com/national-ai-initiative-office-launched/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://fedscoop.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'National AI Initiative Office launched by White House'}]}, {'@type': 'WebSite', '@id': 'https://fedscoop.com/#website', 'url': 'https://fedscoop.com/', 'name': 'FedScoop', 'description': 'FedScoop delivers up-to-the-minute breaking government tech news and is the government IT community&#039;s platform for education and collaboration through news, events, radio and TV. FedScoop engages top leaders from the White House, federal agencies, academia and the tech industry both online and in person to discuss ways technology can improve government, and to exchange best practices and identify how to achieve common goals.', 'publisher': {'@id': 'https://fedscoop.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://fedscoop.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://fedscoop.com/#organization', 'name': 'FedScoop', 'url': 'https://fedscoop.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/#/schema/logo/image/', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'width': 1231, 'height': 182, 'caption': 'FedScoop'}, 'image': {'@id': 'https://fedscoop.com/#/schema/logo/image/'}}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vc3R1ZHlmaW5kcy5vcmcvbm8td2F5LXRvLWNvbnRyb2wtc3VwZXItYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWkv0gEA?oc=5,No stopping AI? Scientists conclude there would be no way to control super-intelligent machines - Study Finds,2021-01-15,Study Finds,https://studyfinds.org,"Movies have already started pondering if future robots will one day threaten the human race. Now, scientists say there may be no way to stop the rise of artificial intelligence.",,"Movies have already started pondering if future robots will one day threaten the human race. Now, scientists say there may be no way to stop the rise of artificial intelligence.","Movies have already started pondering if future robots will one day threaten the human race. Now, scientists say there may be no way to stop the rise of machines.",https://schema.org,,,,,,,,,,,,,,,"Image by Gerd Altmann from Pixabay BERLIN, Germany — From self-driving cars to computers that can win game shows, humans have a natural curiosity and interest in artificial intelligence (AI). As scientists continue making machines smarter and smarter however, some are asking “what happens when computers get too smart for their own good?” From “The Matrix” to “The Terminator,” the entertainment industry has already started pondering if future robots will one day threaten the human race. Now, a new study concludes there may be no way to stop the rise of machines. An international team says humans would not be able to prevent super artificial intelligence from doing whatever it wanted to.
Scientists from the Center for Humans and Machines at the Max Planck Institute have started to picture what such a machine would look like. Imagine an AI program with an intelligence far superior to humans. So much so that it could learn on its own without new programming. If it was connected to the internet, researchers say the AI would have access to all of humanity’s data and could even take control of other machines around the globe.
Study authors ask what would such an intelligence do with all that power? Would it work to make all of our lives better? Would it devote its processing power to fixing issues like climate change? Or, would the machine look to take over the lives of its human neighbors?
Controlling the uncontrollable? The dangers of super artificial intelligence
Both computer programmers and philosophers have studied if there’s a way keep a super-intelligent AI from potentially turning on its human makers; ensuring that future computers could not cause harm to their owners. The new study reveals, unfortunately, it appears to be virtually impossible to keep a super-intelligent AI in line.
“A super-intelligent machine that controls the world sounds like science fiction. But there are already machines that perform certain important tasks independently without programmers fully understanding how they learned it. The question therefore arises whether this could at some point become uncontrollable and dangerous for humanity,” says study co-author Manuel Cebrian, leader of the Digital Mobilization Group at the Center for Humans and Machines, in a university release.
The international team looked at two different ways to control artificial intelligence. The first curbed the power of the superintelligence by walling it up and keeping it from connecting to the internet. It also could not connect to other technical devices in the outside world. The problem with this plan is fairly obviously; such a computer would not be able to do much of anything to actually help humans.
Being nice to humans does not compute
The second option focused on creating an algorithm which would give the supercomputer ethical principles. This would hopefully force the AI to consider the best interests of humanity.
The study created a theoretical containment algorithm that would keep AI from harming people under any circumstance. In simulations, AI would stop functioning if researchers considered its actions harmful. Despite keeping the AI from attaining world domination, the study authors say this just wouldn’t work in the real world.
“If you break the problem down to basic rules from theoretical computer science, it turns out that an algorithm that would command an AI not to destroy the world could inadvertently halt its own operations. If this happened, you would not know whether the containment algorithm is still analyzing the threat, or whether it has stopped to contain the harmful AI. In effect, this makes the containment algorithm unusable,” says Iyad Rahwan, Director of the Center for Humans and Machines.
The study concludes that containing artificial intelligence is an incomputable problem. No single computer program can find a foolproof way to keep AI from acting harmful if it wants to. Researchers add that humans may not even realize when super-intelligent machines actually arrive in the tech world. So, are they already here?
The study appears in the Journal of Artificial Intelligence Research.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', '@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/#article', 'isPartOf': {'@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/'}, 'author': {'name': 'Chris Melore', '@id': 'https://studyfinds.org/#/schema/person/2987d2ce62d02e16acce4689baf1e500'}, 'headline': 'No stopping AI? Scientists conclude there would be no way to control super-intelligent machines', 'datePublished': '2021-01-15T22:46:29+00:00', 'dateModified': '2021-01-15T22:46:29+00:00', 'mainEntityOfPage': {'@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/'}, 'wordCount': 673, 'publisher': {'@id': 'https://studyfinds.org/#organization'}, 'image': {'@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/#primaryimage'}, 'thumbnailUrl': 'https://studyfinds.org/wp-content/uploads/2019/01/artificial-intelligence-2167835.jpg', 'keywords': ['artificial intelligence', 'computers', 'humanity', 'robots'], 'articleSection': ['Intelligence', 'Science &amp; Technology News'], 'inLanguage': 'en-US', 'copyrightYear': '2021', 'copyrightHolder': {'@id': 'https://studyfinds.org/#organization'}}, {'@type': 'WebPage', '@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/', 'url': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/', 'name': 'No stopping AI? Scientists conclude there would be no way to control super-intelligent machines', 'isPartOf': {'@id': 'https://studyfinds.org/#website'}, 'primaryImageOfPage': {'@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/#primaryimage'}, 'image': {'@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/#primaryimage'}, 'thumbnailUrl': 'https://studyfinds.org/wp-content/uploads/2019/01/artificial-intelligence-2167835.jpg', 'datePublished': '2021-01-15T22:46:29+00:00', 'dateModified': '2021-01-15T22:46:29+00:00', 'description': 'Movies have already started pondering if future robots will one day threaten the human race. Now, scientists say there may be no way to stop the rise of artificial intelligence.', 'breadcrumb': {'@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/#primaryimage', 'url': 'https://studyfinds.org/wp-content/uploads/2019/01/artificial-intelligence-2167835.jpg', 'contentUrl': 'https://studyfinds.org/wp-content/uploads/2019/01/artificial-intelligence-2167835.jpg', 'width': '2048', 'height': '1371', 'caption': 'Image by Gerd Altmann from Pixabay'}, {'@type': 'BreadcrumbList', '@id': 'https://studyfinds.org/no-way-to-control-super-artificial-intelligence-ai/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://studyfinds.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Science &amp; Technology News', 'item': 'https://studyfinds.org/category/science-technology/'}, {'@type': 'ListItem', 'position': 3, 'name': 'No stopping AI? Scientists conclude there would be no way to control super-intelligent machines'}]}, {'@type': 'WebSite', '@id': 'https://studyfinds.org/#website', 'url': 'https://studyfinds.org/', 'name': 'StudyFinds', 'description': 'Science news and product reviews.', 'publisher': {'@id': 'https://studyfinds.org/#organization'}, 'alternateName': 'Study Finds', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://studyfinds.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://studyfinds.org/#organization', 'name': 'StudyFinds', 'url': 'https://studyfinds.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://studyfinds.org/#/schema/logo/image/', 'url': 'https://studyfinds.org/wp-content/uploads/2024/06/Favicon.png', 'contentUrl': 'https://studyfinds.org/wp-content/uploads/2024/06/Favicon.png', 'width': 512, 'height': 512, 'caption': 'StudyFinds'}, 'image': {'@id': 'https://studyfinds.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/StudyFindsorg/', 'https://x.com/studyfindsorg', 'https://www.youtube.com/channel/UCuo0ikC6qmXrXPvqWUNzY7w', 'https://twitter.com/studyfindsorg', 'https://www.linkedin.com/company/studyfinds/', 'https://www.instagram.com/wowstudyfinds', 'https://www.google.com/ads/publisher/stories/study_finds/'], 'description': 'StudyFinds was created at the end of 2016 when founder Steve Fink realized there was no hub for studies focused on the average reader. A longtime journalist, Murrow Award-winning managing editor, and progressive content development executive across his 20 years with CBS Local Digital Media, CBS Television Stations, and CBS News, Steve found himself always fascinated by the scientific studies frequently featured on newscasts. That’s when the idea for StudyFinds came to his mind.', 'email': 'editor@studyfinds.org', 'legalName': '41 Push Ups', 'foundingDate': '2016-09-01', 'numberOfEmployees': {'@type': 'QuantitativeValue', 'minValue': '11', 'maxValue': '50'}, 'publishingPrinciples': 'https://studyfinds.org/mission/', 'ownershipFundingInfo': 'https://studyfinds.org/our-story/', 'actionableFeedbackPolicy': 'https://studyfinds.org/mission/', 'correctionsPolicy': 'https://studyfinds.org/mission/', 'ethicsPolicy': 'https://studyfinds.org/mission/'}, {'@type': 'Person', '@id': 'https://studyfinds.org/#/schema/person/2987d2ce62d02e16acce4689baf1e500', 'name': 'Chris Melore', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://studyfinds.org/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/86890f9ac6f6d6079ae7028d0e83a156?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/86890f9ac6f6d6079ae7028d0e83a156?s=96&d=mm&r=g', 'caption': 'Chris Melore'}, 'description': 'Chris Melore has been a writer, researcher, editor, and producer in the New York-area since 2006. He won a local Emmy award for his work in sports television in 2011.', 'sameAs': ['https://studyfinds.org/author/cmelore/'], 'url': 'https://studyfinds.org/author/cmelore/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vcmVzb3VyY2UtcmVjeWNsaW5nLmNvbS9wbGFzdGljcy8yMDIxLzAxLzEzL2hvdy10aGUtdXNlLW9mLXJvYm90aWNzLWlzLWV2b2x2aW5nLWF0LXNvcnRpbmctZmFjaWxpdGllcy_SAW1odHRwczovL3Jlc291cmNlLXJlY3ljbGluZy5jb20vcGxhc3RpY3MvMjAyMS8wMS8xMy9ob3ctdGhlLXVzZS1vZi1yb2JvdGljcy1pcy1ldm9sdmluZy1hdC1zb3J0aW5nLWZhY2lsaXRpZXMv?oc=5,How the use of robotics is evolving at sorting facilities - Plastics Recycling Update,2021-01-13,Plastics Recycling Update,https://resource-recycling.com,A leader with AMP Robotics says artificial intelligence has changed how robotics can be incorporated into recycling facilities. | Courtesy of AMP Robotics. A recycling facility operator and a robotics company say artificial intelligence is providing materials recovery firms with much-needed data to analyze changes in the recycling stream.,,A recycling facility operator and a robotics company say artificial intelligence is providing materials recovery firms with much-needed data to analyze changes in the recycling stream. That’s in addition to sortation improvements. Representatives from AMP Robotics and GFL Environmental spoke …Continue Reading→,,https://schema.org/,NewsArticle,https://resource-recycling.com/plastics/2021/01/13/how-the-use-of-robotics-is-evolving-at-sorting-facilities/,"{'@type': 'ImageObject', 'url': 'https://resource-recycling.com/plastics/wp-content/uploads/sites/4/2021/01/AMP-Robotics-Tandem_Gripper-web-1024x683.jpg', 'width': '900', 'height': '600'}","{'@type': 'Person', 'name': 'Colin Staub', 'url': 'https://resource-recycling.com/plastics/author/colinstaub/', 'description': 'Colin Staub is a reporter at Resource Recycling. He can be contacted at colin@resource-recycling.com.', 'image': {'@type': 'ImageObject', 'url': 'https://resource-recycling.com/plastics/wp-content/uploads/sites/4/2021/11/Colin-Staub-web-square-96x96.jpg', 'height': 96, 'width': 96}}","{'@type': 'Organization', '@id': 'https://resource-recycling.com/plastics/#organization', 'name': 'Plastics Recycling Update', 'logo': {'@type': 'ImageObject', 'url': 'https://resource-recycling.com/plastics/wp-content/themes/rrtt132plastics/logo.png', 'width': 600, 'height': 60}}",How the use of robotics is evolving at sorting facilities,2021-01-13T09:20:41-08:00,2021-01-13T09:20:41-08:00,News,,,,,,"


How the use of robotics is evolving at sorting facilities


Published: January 13, 2021  Updated: January 13, 2021January 13, 2021   by  Colin Staub
A leader with AMP Robotics says artificial intelligence has changed how robotics can be incorporated into recycling facilities. | Courtesy of AMP Robotics.
A recycling facility operator and a robotics company say artificial intelligence is providing materials recovery firms with much-needed data to analyze changes in the recycling stream. That’s in addition to sortation improvements.

Representatives from AMP Robotics and GFL Environmental spoke about the benefits of robotics during a recent presentation hosted by Greenbiz, a business sustainability media and events company.
The event was tied to an announcement from AMP and Keurig Dr Pepper (KDP), which recently redesigned its K-Cup coffee pods to produce them in a polypropylene format that is recyclable in many U.S. programs, though not all.
After the product redesign, KDP and AMP Robotics worked together to equip AMP’s robotic sorting systems with the tools to properly identify and sort the cups in a materials recovery facility (MRF). The project partners hailed the collaboration as an example of how producers, equipment/technology companies and other recycling stakeholders can work together to improve sortation.
“It really shows how artificial intelligence can help these facilities adapt quickly and really take advantage of these valuable material streams,” said Matanya Horowitz, founder and CEO of AMP Robotics.
Mitigating workforce and data challenges
The use of robots has grown exponentially in recent years. In 2019, Plastics Recycling Update tallied nearly 100 in use in North America from providers AMP, Bulk Handling Systems (BHS), Machinex and ZenRobotics. Since then, others have entered the market, including Bollegraaf (Van Dyk Recycling Solutions is selling the robot in North America). In November, AMP announced it signed a deal with Waste Connections to deploy two dozen robots to MRFs across the country.
Horowitz of AMP Robotics said artificial intelligence has changed how robotics can be incorporated into MRFs. Machine learning allows robots to, over time, identify more and more items within the recycling stream. That includes materials that are smashed up, moldy, dirty and “generally inconsistent,” he said.
“This is largely what’s kept robots from being used in the recycling industry already,” Horowitz added. His company this month announced it raised $55 million from a number of investment sources.
During the Greenbiz event, Brent Hildebrand, vice president of recycling for GFL, spoke on behalf of the Canadian-headquartered hauler and MRF operator, which is one of the largest in North America. Hildebrand previously worked in positions at AMP, as well as Alpine Waste & Recycling, which was acquired by GFL.
The Denver-area Alpine Waste & Recycling MRF was an early adopter of robotics technology. One factor that led the facility to install robotic sorting systems was the rising cost of running a MRF, Hildebrand said.
“Part of those rising costs is rising labor cost,” Hildebrand said. “And on top of that, it’s just finding labor for these sites.”
The company found robotics to be a promising alternative when the company can’t find enough manual sorting personnel to staff its facilities.
Another driver is the evolving material stream, Hildebrand said. He pointed to PET bottles and aluminum cans as two significant examples of recyclable products that have been made with less and less material over the years.
“That changes the dynamic for what we can produce from a volume standpoint,” Hildebrand said.
Artificial intelligence can help the company respond to these changes in inbound material, he noted. For one, it can help a MRF determine exactly how the material stream is changing, by giving MRF operators the data to perceive changes. Beyond providing efficient material sorting, the artificial intelligence in robots is “really closely tied to a challenge in the industry of extracting information about the process,” Horowitz said.
“Really a core problem for recycling is that there hasn’t been a sensor that would let you tell what’s going on in the material stream, so identify how many bottles, identify whose bottles, identify what bottles are high quality and things like that,” Horowitz said. “And now with artificial intelligence, you sort of have this core capability that you can take advantage of in different ways.”
View of the AMP’s AI material identification at work on a sorting line.
Precision and customization
In addition to collecting data to develop a baseline of information, the artificial intelligence can help MRFs adapt quickly when new materials are introduced into packaging
“What’s powerful about this technology is that it can provide a new level of identification,” Horowitz said. “Pretty much anything you can teach a person to identify, you can teach our systems to identify as well.”
Robots can learn to identify different packaging from specific brands, types of material, shapes of packaging and more.
These expanded identification abilities have significant practical applications for MRF operators, particularly when it comes to producing higher-value commodities. As an example, Horowitz pointed to the common MRF practice of producing bales of mixed plastics Nos. 3-7, which are sold for typically low prices. But greater sorting can change that equation.
“When you start to do things like separate out the No. 5 plastics, the polypropylene, that can actually have significant value,” Horowitz said. “There are similar patterns in paper. If you separate out the office paper and the newspaper, it’s also more valuable.”
Hildebrand added that this sorting ability even allows MRFs to produce customized commodities for specific end users.
“In our business, we have buyers of these materials and they want a certain specification,” Hildebrand said. For example, buyers might want a bit more OCC included in a mixed-paper bale, depending on the application. MRFs that can meet those custom specifications may fetch a premium for their bales.
“You can kind of tailor these recipes to what your buyers want,” Hildebrand said.
A version of this story appeared in Resource Recycling on January 12.
More stories about technology
Platform scales up tools to digitize recycling sectorEntering the digital age of buying and sellingRecyclable, light-blocking shrink sleeve patented
 
















Posted in  News | 
Tagged technology | 



","{'@type': 'WebPage', '@id': 'https://resource-recycling.com/plastics/2021/01/13/how-the-use-of-robotics-is-evolving-at-sorting-facilities/'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vdGhlY29udmVyc2F0aW9uLmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jYW4tZGVlcGVuLXNvY2lhbC1pbmVxdWFsaXR5LWhlcmUtYXJlLTUtd2F5cy10by1oZWxwLXByZXZlbnQtdGhpcy0xNTIyMjbSAQA?oc=5,Artificial intelligence can deepen social inequality. Here are 5 ways to help prevent this - The Conversation,2021-01-12,The Conversation,https://theconversation.com,"If the historical data used to train an AI system disadvantages certain minority groups, the system can be swayed to follow these patterns in its own decision-making process.",,"If the historical data used to train an AI system disadvantages certain minority groups, the system can be swayed to follow these patterns in its own decision-making process.",,,,,,,,,,,,,,,,,"






Shutterstock









            Artificial intelligence can deepen social inequality. Here are 5 ways to help prevent this
          




Published: January 12, 2021 2:10pm EST












Tiberio Caetano, Bill Simpson-Young, University of Sydney



Authors





        Tiberio Caetano
      


      Chief Scientist, Gradient Institute, University of Sydney
    





        Bill Simpson-Young
      


      Chief Executive, Gradient Institute, University of Sydney
    





Disclosure statement
Tiberio Caetano is Chief Scientist of Gradient Institute. Gradient Institute is an independent non-profit and registered charity that researches, designs and develops ethical AI systems, and provides training in how to build accountability and transparency into machine learning systems. Gradient Institute receives funding from IAG and support from University of Sydney and ANU. The work referred to in this article was partly funded by a grant from the Consumer Policy Research Centre administered through the Australian Human Rights Commission.
Bill Simpson-Young is Chief Executive of Gradient Institute. Gradient Institute is an independent non-profit and registered charity that researches, designs and develops ethical AI systems, and provides training in how to build accountability and transparency into machine learning systems. Gradient Institute receives funding from IAG and support from University of Sydney and ANU. The work referred to in this article was partly funded by a grant from the Consumer Policy Research Centre administered through the Australian Human Rights Commission.


Partners

University of  Sydney provides funding as a member of The Conversation AU.
View all partners

We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)79


 Facebook458


 LinkedIn


 WhatsApp


 Messenger

 Print


From Google searches and dating sites to detecting credit card fraud, artificial intelligence (AI) keeps finding new ways to creep into our lives. But can we trust the algorithms that drive it?
As humans, we make errors. We can have attention lapses and misinterpret information. Yet when we reassess, we can pick out our errors and correct them.
But when an AI system makes an error, it will be repeated again and again no matter how many times it looks at the same data under the same circumstances. 
AI systems are trained using data that inevitably reflect the past. If a training data set contains inherent biases from past human decisions, these biases are codified and amplified by the system. 
Or if it contains less data about a particular minority group, predictions for that group will tend to be worse. This is called “algorithmic bias”.
Gradient Institute has co-authored a paper demonstrating how businesses can identify algorithmic bias in AI systems, and how they can mitigate it.
The work was produced in collaboration with the Australian Human Rights Commission, Consumer Policy Research Centre, CSIRO’s Data61 and the CHOICE advocacy group.
How does algorithmic bias arise?
Algorithmic bias may arise through a lack of suitable training data, or as a result of inappropriate system design or configuration.
For example, a system that helps a bank decide whether or not to grant loans would typically be trained using a large data set of the bank’s previous loan decisions (and other relevant data to which the bank has access). 
The system can compare a new loan applicant’s financial history, employment history and demographic information with corresponding information from previous applicants. From this, it tries to predict whether the new applicant will be able to repay the loan.
But this approach can be problematic. One way in which algorithmic bias could arise in this situation is through unconscious biases from loan managers who made past decisions about mortgage applications. 
If customers from minority groups were denied loans unfairly in the past, the AI will consider these groups’ general repayment ability to be lower than it is.
Young people, people of colour, single women, people with disabilities and blue-collar workers are just some examples of groups that may be disadvantaged.




      Read more:
      Artificial Intelligence has a gender bias problem -- just ask Siri




Bias harms both individuals and companies
The biased AI system described above poses two key risks for the bank. 
First, the bank could miss out on potential clients, by sending victims of bias to its competitors. It could also be held liable under anti-discrimination laws. 
If an AI system continually applies inherent bias in its decisions, it becomes easier for government or consumer groups to identify this systematic pattern. This can lead to hefty fines and penalties.



Centrelink’s now-scrapped robodebt system automatically raised welfare debts against people it predicted were overpaid. If the recipient didn’t provide income evidence, an algorithm generated a fortnightly income figure for them by averaging data available to the Australia Tax Office. These estimates had major errors.
James Ross/AAP


Mitigating algorithmic bias
Our paper explores several ways in which algorithmic bias can arise. 
It also provides technical guidance on how this bias can be removed, so AI systems produce ethical outcomes which don’t discriminate based on characteristics such as race, age, sex or disability. 
For our paper, we ran a simulation of a hypothetical electricity retailer using an AI-powered tool to decide how to offer products to customers and on what terms. The simulation was trained on fictional historical data made up of fictional individuals.
Based on our results, we identify five approaches to correcting algorithmic bias. This toolkit can be applied to businesses across a range of sectors to help ensure AI systems are fair and accurate.
1. Get better data
The risk of algorithmic bias can be reduced by obtaining additional data points or new types of information on individuals, especially those who are underrepresented (minorities) or those who may appear inaccurately in existing data.
2. Pre-process the data
This consists of editing a dataset to mask or remove information about attributes associated with protections under anti-discrimination law, such as race or gender.
3. Increase model complexity
A simpler AI model can be easier to test, monitor and interrogate. But it can also be less accurate and lead to generalisations which favour the majority over minorities.
4. Modify the system
The logic and parameters of an AI system can be proactively adjusted to directly counteract algorithmic bias. For example, this can be done by setting a different decision threshold for a disadvantaged group.
5. Change the prediction target
The specific measure chosen to guide an AI system directly influences how it makes decisions across different groups. Finding a fairer measure to use as the prediction target will help reduce algorithmic bias. 



The effectiveness of an AI system is highly dependent on the quality of data used to train it.
Shutterstock


Consider legality and morality
In our recommendations to government and businesses wanting to employ AI decision-making, we foremost stress the importance of considering general principles of fairness and human rights when using such technology. And this must be done before a system is in-use. 
We also recommend systems are rigorously designed and tested to ensure outputs aren’t tainted by algorithmic bias. Once operational, they should be closely monitored.
Finally, we advise that to use AI systems responsibly and ethically extends beyond compliance with the narrow letter of the law. It also requires the system to be aligned with broadly-accepted social norms — and considerate of impact on individuals, communities and the environment.
With AI decision-making tools becoming commonplace, we now have an opportunity to not only increase productivity, but create a more equitable and just society – that is, if we use them carefully.




      Read more:
      YouTube's algorithms might radicalise people – but the real problem is we've no idea how they work









Artificial intelligence (AI)


Artificial intelligence and jobs


Algorithmic bias


Artificial intelligence (AI) bias


Artificial Intelligence ethics









",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQGh0dHBzOi8vYW5hbHl0aWNzaW5kaWFtYWcuY29tL3RvcC1haS10b29scy1mb3ItcmVzdW1lLXNjcmVlbmluZy_SAQA?oc=5,Top AI Tools For Resume Screening - AIM,2021-01-15,AIM,https://analyticsindiamag.com,,,,,,,,,,,,,,,,,,,,"






				When remote working is a business model			



			Sri Krishna		

			23/05/2022		


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vaW5mb3RlY2hsZWFkLmNvbS9uZXR3b3JraW5nL2ludGVsLW5hbWVzLXBhdC1nZWxzaW5nZXItZm9yLWNlby1qb2ItcmVwbGFjaW5nLWJvYi1zd2FuLTY0ODY40gEA?oc=5,Intel names Pat Gelsinger for CEO job replacing Bob Swan - InfotechLead.com,2021-01-13,InfotechLead.com,https://infotechlead.com,,,"Intel announced the appointment of Pat Gelsinger as its chief executive officer, effective Feb. 15, 2021. Pat Gelsinger will succeed Bob Swan, who will remain CEO until Feb. 15. Intel said today’s announcement is unrelated to Intel’s 2020 financial performance. Intel expects its fourth-quarter 2020 revenue and EPS to exceed its prior guidance provided on […]",,https://schema.org,,,,,,,,,,,,,,,"





Intel names Pat Gelsinger for CEO job replacing Bob Swan


Networking

13/01/2021 

Intel announced the appointment of Pat Gelsinger as its chief executive officer, effective Feb. 15, 2021. Pat Gelsinger will succeed Bob Swan, who will remain CEO until Feb. 15.

Intel said today’s announcement is unrelated to Intel’s 2020 financial performance. Intel expects its fourth-quarter 2020 revenue and EPS to exceed its prior guidance provided on Oct. 22, 2020. Intel said the company has made strong progress on its 7nm process technology and plans on providing an update when it reports its full fourth-quarter and full-year 2020 results on Jan. 21, 2021.
Most recently, Pat Gelsinger served as the CEO of VMware since 2012, where he transformed the company into a recognized global leader in cloud infrastructure, enterprise mobility and cyber security, almost tripling the company’s annual revenues.
Prior to joining VMware, Pat Gelsinger was president and chief operating officer of EMC Information Infrastructure Products at EMC, overseeing engineering and operations for information storage, data computing, backup and recovery, RSA security and enterprise solutions.
Before joining EMC, Pat Gelsinger spent 30 years at Intel, becoming the company’s first chief technology officer and driving the creation of key industry technologies such as USB and Wi-Fi. He was the architect of the original 80486 processor, led 14 different microprocessor programs and played key roles in the Core and Xeon families.



TopicsIntel


Related News





Networking
Intel announcements at Computex 2024






Devices
Intel intros Thunderbolt Share software to transform PC-to-PC interactions






Artificial Intelligence
Intel says Aurora supercomputer is the fastest AI system in the world






Artificial Intelligence
Intel Unveils AI Plans for Paris 2024 Olympic and Paralympic Games






Networking
Main Facts about Intel Gaudi 3 AI Accelerator for GenAI Revolution





Latest News





Software
Cognizant wins five-year tech contract from Victory Capital






Security
IBM wins cyber security contract from USAID






Security
How Google’s proposed $23 bn deal of Wiz will enhance security business






Tech
VC funding: SamanTree Medical, SMART Global, HammerTech, Exa, Jacobi Robotics






mobility
Tech contracts: Clearwater, CGI, Iteach








Latest News





 


 

Software
Cognizant wins five-year tech contract from Victory Capital






 


 

Security
IBM wins cyber security contract from USAID






 


 

Security
How Google’s proposed $23 bn deal of Wiz will enhance security business






 


 

Tech
VC funding: SamanTree Medical, SMART Global, HammerTech, Exa, Jacobi Robotics



  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://infotechlead.com/networking/intel-names-pat-gelsinger-for-ceo-job-replacing-bob-swan-64868', 'url': 'https://infotechlead.com/networking/intel-names-pat-gelsinger-for-ceo-job-replacing-bob-swan-64868', 'name': 'Intel names Pat Gelsinger for CEO job replacing Bob Swan - InfotechLead', 'isPartOf': {'@id': 'https://infotechlead.com/#website'}, 'primaryImageOfPage': {'@id': 'https://infotechlead.com/networking/intel-names-pat-gelsinger-for-ceo-job-replacing-bob-swan-64868#primaryimage'}, 'image': {'@id': 'https://infotechlead.com/networking/intel-names-pat-gelsinger-for-ceo-job-replacing-bob-swan-64868#primaryimage'}, 'thumbnailUrl': 'https://infotechlead.com/wp-content/uploads/2013/03/VMware-CEO-Pat-Gelsinger.jpg', 'datePublished': '2021-01-13T14:41:32+00:00', 'dateModified': '2021-01-13T14:41:32+00:00', 'author': {'@id': 'https://infotechlead.com/#/schema/person/63857ec6f520fb9ca4e788a3a0b5f744'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://infotechlead.com/networking/intel-names-pat-gelsinger-for-ceo-job-replacing-bob-swan-64868']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://infotechlead.com/networking/intel-names-pat-gelsinger-for-ceo-job-replacing-bob-swan-64868#primaryimage', 'url': 'https://infotechlead.com/wp-content/uploads/2013/03/VMware-CEO-Pat-Gelsinger.jpg', 'contentUrl': 'https://infotechlead.com/wp-content/uploads/2013/03/VMware-CEO-Pat-Gelsinger.jpg', 'width': 451, 'height': 304, 'caption': 'VMware CEO Pat Gelsinger'}, {'@type': 'WebSite', '@id': 'https://infotechlead.com/#website', 'url': 'https://infotechlead.com/', 'name': 'InfotechLead', 'description': 'IT news, enterprise IT, big data, data center, cloud, software, mobility', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://infotechlead.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://infotechlead.com/#/schema/person/63857ec6f520fb9ca4e788a3a0b5f744', 'name': 'infotech', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://infotechlead.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/fd89cc0d509dc29f38e62ad16b5d3087?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/fd89cc0d509dc29f38e62ad16b5d3087?s=96&d=mm&r=g', 'caption': 'infotech'}, 'url': 'https://infotechlead.com/author/infotech'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvam9lbWNrZW5kcmljay8yMDIxLzAxLzIzL3RoZS1tb3N0LWltcG9ydGFudC12b2ljZS1pbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mcm9udGxpbmUtd29ya2Vycy_SAQA?oc=5,The Most Important Voice In Artificial Intelligence: Frontline Workers - Forbes,2021-01-23,Forbes,https://www.forbes.com,"Success with AI is going to be a bumpy and uneven road, and is going to need more human knowledge and input than we can ever imagine. ","Artificial intelligence,Stanford University,Center for Human-Centered Artificial Intelligence","Success with AI is going to be a bumpy and uneven road, and is going to need more human knowledge and input than we can ever imagine. ","Success with AI is going to be a bumpy and uneven road, and is going to need more human knowledge and input than we can ever imagine. ",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/joemckendrick/2021/01/23/the-most-important-voice-in-artificial-intelligence-frontline-workers/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/600c584297d2fc0b51fa5541/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Joe McKendrick', 'url': 'https://www.forbes.com/sites/joemckendrick/', 'description': 'I am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the 2023 AI Summit in New York, as well as the 2021 and 2022 Summits. I regularly contribute to Harvard Business Review on AI topics. My column on service orientation appears on CNET, covering topics shaping business and technology careers. I am also a co-author of the SOA Manifesto, which outlines the values and guiding principles of service orientation in business and IT. Much of my research work is in conjunction with Forbes Insights and Unisphere Research/ Information Today, Inc., covering topics such as artificial intelligence, cloud computing, digital transformation, and big data analytics. In a previous life, I served as communications and research manager of the Administrative Management Society (AMS), an international professional association dedicated to advancing knowledge within the IT and business management fields. I am a graduate of Temple University.', 'sameAs': ['https://www.twitter.com/joemckendrick', 'Joe McKendrick']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",The Most Important Voice In Artificial Intelligence: Frontline Workers,2021-01-23T12:17:42-05:00,2021-01-23T19:27:40-05:00,Enterprise Tech,The Most Important Voice In Artificial Intelligence: Frontline Workers,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise Tech,,"Edit StoryInnovationEnterprise TechThe Most Important Voice In Artificial Intelligence: Frontline WorkersJoe McKendrickSenior ContributorOpinions expressed by Forbes Contributors are their own.I track how technology innovations move markets and careersFollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itJan 23, 2021,12:17pm ESTUpdated Jan 23, 2021, 07:27pm ESTThis article is more than 3 years old.Share to FacebookShare to TwitterShare to LinkedinLet frontline workers guide AI processesgetty
A recent article and analysis by Nick Reed at Brink News suggests the driverless car revolution isn’t gaining as much traction as originally predicted. “Five years ago, there was a lot of hype, a sense that this was something that was coming very soon and would be a part of the lives of many people,” he says. “But people underestimated the scale of the challenge of operating a fully automated, safety-critical system in an unpredictable and infinitely variable environment.”


The slow uptake of driverless cars may be an allegory for what may be a slower-than-expected uptake of artificial intelligence in general. After all, businesses surely operate in “unpredictable and infinitely variable environments” — and the past year has certainly put an exclamation point on this observation.

Success with AI is going to be a bumpy and uneven road, and is going to need more human knowledge and input than we can ever imagine. At its core, artificial intelligence isn’t really a job-killer — it’s more of a taskmaster. The challenge for people and organizations, then, is to provide the knowledge and training to prepare for this new age. No one is more critical to AI success than the people who will be working with it on the front lines.

PROMOTED
Who really understands the business from the ground up? Who faces customers every day — and are likely the only faces (or voices) customers see or hear? The frontline and service workers make the business happen, and will make AI happen.

That’s the word coming out of a recent panel discussion, hosted by Stanford University’s center for Human-Centered Artificial Intelligence (HAI). More needs to be done to engage the workforce to help steer the changes AI is bringing about in a positive direction. Business leaders and policymakers need to be more proactive in this process.
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineTrump Signs Posted Outside Attempted Assassin’s Home, Neighbors Say: What We Know About Thomas Matthew Crooks
While jobs will be lost, many more will be enhanced, elevated, and created, says James Manyika, chairman of the McKinsey Global Institute. “There will be jobs that'll be lost, partly because technology will be able to do the various activities involved in that job. There will be jobs that will be changed. The jobs change is part of the fact that while the job is still there, technology will complement some of those activities.”









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



The share of jobs and occupations “that can be fully automated in terms of all their constituent activities is actually relatively small, at least for the next several decades,” Manyika adds.
How should we prepare the workforce for the changes ahead — to encourage their involvement in the AI revolution, as well as deliver the skills needed to make it happen? Many jobs, for example, are frontline workers who don’t have access to many technology tools. This is a crucial question, says Mary Kay Henry, international president of the Service Employees International Union (SEIU). “Seventy percent of the U.S. workforce is in the service sector, and one in four jobs are care jobs. Those jobs are poverty jobs that, in most cases, there's two million black, brown, and immigrant women doing home care work in this nation. It's the fastest growing job [category]. I think those workers would love to understand how technology and artificial intelligence could actually elevate the work they do caring for the nation's elderly and people with disabilities.”
There are structural barriers to this kind of work that do not lend it too well to AI and automation retraining, Henry points out. “There's a lack of regular schedule. They have to hustle for hours every week, and one week to the next, they don't know really what their schedule is, which makes it impossible for them to engage in any kind of ongoing education. That also keeps them from being able to have a dialogue with their employers about how artificial intelligence in technology gets introduced into their work.”
Empowering the jobs of frontline workers is “where technology that complements what workers do, what people do, becomes critically important,” Manyika responds, advocating that workers be fully involved in the technology adoption process. “What I always tell people when we have this conversation is don't worry about a jobless future. It is not for many, many decades. What we should think about is how we manage the transitions and adaptations as we help workers cope with this.”
For starters, he continues, “we do have to solve the skills question because as jobs change, we're going to need to make sure that workers can actually adapt, learn skills, be able to work alongside machines, or move into occupations that are actually growing. The second question is how do we help workers transition either form declining occupations to the occupations that are growing? This is where policy and other mechanisms are really, really important to make sure we support the workers, we have the safety nets and the benefit models, and transition supports to actually help workers transition.”
This is critical, as a large segment of the workforce now, and going forward, are occupations such as care workers and teachers, who need to be compensated more fairly. Finally, Manyika says, “we need to solve for is how do we actually redesign work, because what happens is, the workplace actually changes as we bring in technology to the workforce. How do we think about data in the workplace? How do we think about redesigning the work itself? By the way, if we didn't think these questions about redesigning work were urgent, we only have to pay attention to what's happened with Covid.”
There is growing recognition that AI and robotics will only succeed when there is a human component to processes, he adds. “There are certain aspects of training where it actually is very helpful to actually do that with workers alongside the machines. How do you think about robotic manipulation, for example? Some of that training can actually be done by the machines. One of the things that's interesting in this Covid moment is robotic mechanisms have actually been quite important in actually doing things like improving testing. Quite often, when machines are trying to learn how to place and locate things in a space and in an environment, it's often very helpful to learn that from real human beings, so work alongside human beings... There's a co-learning aspect to this. I think that's another way in which workers can be part of the process.”
Healthcare provides an exemplary proving ground for the ways people can work to design AI-driven workplaces and processes that deliver the benefits intended. “In healthcare, we recognize that looping in these workers, from clinicians to caretakers, we start to understand deeply the privacy concerns and ethical concerns,” says Fei-Fei Li, co-director of Stanford HAI. “When we started working with the nurses in Stanford Hospital about hand-hygiene practice, the initial reaction was ‘You'll never be allowed to do this because there is a privacy infringement, or actually concern for the nurses.’ But as we loop in the nurses and understand the concerns, we share the technology that does not infringe on privacy, you realize these people are so incredible. They are creative, they're supportive, they want what's best for the patients, they become our biggest allies and partners in this. There is a lack of culture in tech right now to involve more of our workers, especially service workers, in the early stage of the tech design, all the way to the application stage.”
Follow me on Twitter. Joe McKendrickFollowingFollowI am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3Lm1pY3Jvc29mdC5jb20vZW4tdXMvcmVzZWFyY2gvcHJvamVjdC90aGUtbmV3LWZ1dHVyZS1vZi13b3JrL9IBAA?oc=5,The New Future of Work - Microsoft,2021-01-25,Microsoft,https://www.microsoft.com,Researchers at Microsoft formed a cross-company initiative to coordinate their efforts with the goal of gaining a holistic understanding of the impact of remote work and identifying opportunities to support new work practices.,,Researchers at Microsoft formed a cross-company initiative to coordinate their efforts with the goal of gaining a holistic understanding of the impact of remote work and identifying opportunities to support new work practices.,,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.microsoft.com/en-us/research/project/the-new-future-of-work/', 'url': 'https://www.microsoft.com/en-us/research/project/the-new-future-of-work/', 'name': 'The New Future of Work - Microsoft Research', 'isPartOf': {'@id': 'https://www.microsoft.com/en-us/research/#website'}, 'primaryImageOfPage': {'@id': 'https://www.microsoft.com/en-us/research/project/the-new-future-of-work/#primaryimage'}, 'image': {'@id': 'https://www.microsoft.com/en-us/research/project/the-new-future-of-work/#primaryimage'}, 'thumbnailUrl': 'https://www.microsoft.com/en-us/research/uploads/prod/2021/01/NFW_WorkLab_headerv2_01-2021_1920x720.jpg', 'datePublished': '2021-01-25T15:40:51+00:00', 'dateModified': '2024-06-21T20:44:18+00:00', 'description': 'Researchers at Microsoft formed a cross-company initiative to coordinate their efforts with the goal of gaining a holistic understanding of the impact of remote work and identifying opportunities to support new work practices.', 'breadcrumb': {'@id': 'https://www.microsoft.com/en-us/research/project/the-new-future-of-work/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.microsoft.com/en-us/research/project/the-new-future-of-work/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.microsoft.com/en-us/research/project/the-new-future-of-work/#primaryimage', 'url': 'https://www.microsoft.com/en-us/research/uploads/prod/2021/01/NFW_WorkLab_headerv2_01-2021_1920x720.jpg', 'contentUrl': 'https://www.microsoft.com/en-us/research/uploads/prod/2021/01/NFW_WorkLab_headerv2_01-2021_1920x720.jpg', 'width': 1920, 'height': 720, 'caption': 'New Future of Work header graphic'}, {'@type': 'BreadcrumbList', '@id': 'https://www.microsoft.com/en-us/research/project/the-new-future-of-work/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.microsoft.com/en-us/research/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Projects', 'item': 'https://www.microsoft.com/en-us/research/project'}, {'@type': 'ListItem', 'position': 3, 'name': 'The New Future of Work'}]}, {'@type': 'WebSite', '@id': 'https://www.microsoft.com/en-us/research/#website', 'url': 'https://www.microsoft.com/en-us/research/', 'name': 'Microsoft Research', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.microsoft.com/en-us/research/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmhlYWx0aHloZWFyaW5nLmNvbS9yZXBvcnQvNTMxNjgtSGVhcmluZy1haWRzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWRlZXAtbGVhcm5pbmctb3RpY29u0gEA?oc=5,AI hearing aids: How artificial intelligence can help hearing loss - Healthy Hearing,2021-01-25,Healthy Hearing,https://www.healthyhearing.com,Premium hearing aids may use artificial intelligence like machine learning and deep neural networks to help process sound. Learn why this is a significant improvement for people with hearing loss.,,Premium hearing aids may use artificial intelligence like machine learning and deep neural networks to help process sound. Learn why this is a significant improvement for people with hearing loss.,,https://schema.org,BreadcrumbList,,,,,,,,,,,"[{'@type': 'ListItem', 'position': '1', 'name': 'Home', 'item': 'https://www.healthyhearing.com/'}, {'@type': 'ListItem', 'position': '2', 'name': 'Report', 'item': 'https://www.healthyhearing.com/report'}, {'@type': 'ListItem', 'position': '3', 'name': 'Hearing aids with artificial intelligence', 'item': 'https://www.healthyhearing.com/report/53168-Hearing-aids-artificial-intelligence-deep-learning-oticon'}]",HH Report,,"





www.HealthyHearing.com








Hearing aids with artificial intelligence


Contributed by Madeleine BurryJanuary 25, 20212021-01-25T00:00:00-06:00


Fantastical notions of all-powerful robots, straight out of Hollywood, may come to mind when you think about artificial intelligence (AI). But set aside thoughts of the machines taking over: When it comes to your hearing aids, AI helps the devices function better. 
For instance, AI can help wrangle one of the most challenging situations if you struggle to hear: Engaging in a conversation when you’re in a crowded, loud space (think: a restaurant or cafe). Because as you know if you wear a hearing aid, louder isn’t the solution. 
From month to month, year to year, researchers are finding more ways to harness this technology and use it to improve hearing aids. Here’s what you need to know about how hearing aids use AI—and if a hearing aid with this functionality is right for you or a loved one. 

Key terms: AI, machine learning, deep neural network 
Put simply, artificial intelligence is defined as the ability of a machine to simulate human intelligence, performing a set of tasks that require “intelligent” decisions by following predetermined rules. 
“Artificial intelligence is a very broad definition. Machine learning, neural network, deep learning, and all of those, fall under the AI umbrella,” says Issa M.S. Panahi, PhD, professor of electrical and computer engineering in the Erik Jonsson School of Engineering and Computer Science at the University of Texas at Dallas. 
Through machine learning, a subset of AI, machines use algorithms (aka, a set of rules) to sort through giant amounts of data and make decisions or predictions. 
Go one level deeper, and we get to the deep neural network (DNN): This form of AI is set up to mimic the neural habits of the brain, and aims to respond the same way your brain would, without being explicitly programmed how to react in a given situation. 
You’re familiar with this technology if your inbox sorts emails into categories (important, promotional, etc.), if you take advantage of recommendations of ""what to watch next"" on streaming networks, or if you’ve marveled over self-parking cars. Some more mundane but important examples of deep learning include weather forecasting and credit card fraud protection. These tools have gotten much better in recent years due to deep learning. 
How hearing aids use AI 

Audiologist Scott Young

“The AI that occurs in hearing aids has actually been going on for years, but it’s a slow burn to think about how that’s actually happened,” says Scott Young, Aud, CCC-A, owner of Hearing Solution Centers, Inc. in Tulsa, Okla. 
Hearing aids used to be relatively simple, he notes, but when hearing aids introduced a technology known as wide dynamic range compression (WDRC) the devices actually began to make a few decisions based on what it heard, he says. 
“Over the last several years, AI has come even further—it actually listens to what the environment does,” Scott says. And, it responds accordingly. Essentially, a DNN allows hearing aids to begin to mimic how your brain would hear sound if your hearing wasn’t impaired.  
For hearing aids to work effectively, they need to adapt to a person’s individual hearing needs as well as all sorts of background noise environments, Panahi says. “AI, machine learning, and neural networks, are very good techniques to deal with such a complicated, nonlinear, multi-variable type of problem,” he says. 
What the research shows
Researchers have been able to accomplish a lot with AI to date, when it comes to improving hearing. 
For instance, researchers at the Perception and Neurodynamics Laboratory (PNL) at the Ohio State University trained a DNN to distinguish speech (what people want to hear) from other noise (such as humming and other background conversations), writes DeLiang Wang, professor of computer science and engineering at Ohio State University, in IEEE Spectrum. “People with hearing impairment could decipher only 29 percent of words muddled by babble without the program, but they understood 84 percent after the processing,” Wang writes. 

Photo: UT-Dallas
Dr. Issa Panahi is working on smartphone
-based AI apps to help people with hearing
loss. 

And at University of Texas at Dallas, Panahi, along with co-principal investigator Dr. Linda Thibodeau, used AI to create a smartphone app that can tell the direction where speech is coming from. This app calls on models built using a massive library of sounds to identify and diminish background noise, so people hear better. Place a smartphone with the app on a table, or rest it in the GPS stand in your car, and “clean speech is transmitted to the hearing aid devices or earbuds,” Panahi says. 
“The importance of AI is it overcom[es] a lot of issues that cannot be easily solved by a traditional mathematical approach for signal processing,” Panahi says. 
The app is not yet available to the public, Dr. Thibodeau says (code, demos, and more information are available on the website). 
Neural-network powered hearing aids
In recent years, major hearing aid manufacturers have been adding AI technology to their premium hearing aid models. For example Widex's Moment hearing aid utilizes AI and machine learning to create hearing programs based on a wearer's typical environments.
And this January, Oticon introduced its newest hearing aid device, Oticon More™, the first hearing aid with an on-board deep neural network. Oticon More was trained—using 12 million-plus real-life sounds—so that people wearing it can better understand speech and the sounds around them.

Oticon More hearing aids, which are
rechargeable.

In a complicated ""sound scene""—picture a bustling airport or hospital emergency room—the Oticon More's neural net receives a complicated layer of sounds, known as input. The DNN gets to work, first scanning and extracting simple sound elements and patterns from the input. It builds these elements together to recognize and make sense of what's happening. Lastly, the hearing aids then make a decision on how to balance the sound scene, making sure the output is clean and ideally balanced to the person's unique type of hearing loss. 

""We wanted our system to be able to find speech even when it's embedded in background noise. And that's happening in real-time and in an ongoing basis.""

This improvement is especially key for speech in noise, explained Donald J. Schum, PhD, Vice President of Audiology at Oticon, during the product launch event.
""Speech and other sounds in the environment are complicated acoustic wave forms, but with unique patterns and structures that are exactly the sort of data deep learning is designed to analyze,"" he said. ""We wanted our system to be able to find speech even when it's embedded in background noise. And that's happening in real-time and in an ongoing basis.""
Do I need a hearing aid with AI? 
Think of hearing aids as existing on a spectrum, says Young—hearing aids range widely in price, and some at the lower end have fewer AI-driven bells and whistles, he says. 
He points out that some patients may not need all the features—people who live alone or rarely leave the house, and don’t find themselves in crowded scenarios often, for instance, might not benefit from the functionality found in higher-end models. 
But for anyone who is out and about a lot, especially in situations where there are big soundscapes, AI-powered features allow for an improved hearing experience.
Listening effort is reduced
What ""improvement"" looks like can be measured in a lot of ways, but one key indicator is memory recall, Schum explained. It's not that the hearing aids like Oticon More literally improve a person's memory, he explained, it's that artificial intelligence helps people spend less time trying to make sense of the noise around them, a process known as ""listening effort.""
When the listening effort is more natural, a person can focus more on the conversation and all the nuances conveyed within.
""It's allowing the brain to work in the most natural way possible,"" he said. 
Related: Connect your hearing aids to your phone with apps 
    Madeleine Burry  Madeleine Burry is a Brooklyn-based freelance writer and editor. She's written about health for several online publications, including Women's Health, Prevention, Health, Livestrong and Good Housekeeping. You can follow her on Twitter @lovelanewest.
Read more about Madeleine.    
										Related Help Pages:
    Types and styles Technology Bluetooth 







 Share  Tweet  Share  Pin  Print

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vdGVjaG5vbG9neW1hZ2F6aW5lLmNvbS9haS1hbmQtbWFjaGluZS1sZWFybmluZy9haS1oZWxwaW5nLW9yLWhpbmRlcmluZy1lbXBsb3llZXPSAQA?oc=5,Is AI helping or hindering employees? - Technology Magazine,2021-01-22,Technology Magazine,https://technologymagazine.com,"We could see the emergence of 97 million new roles adapted to the new division of labour between humans, machines and algorithms...",,"We could see the emergence of 97 million new roles adapted to the new division of labour between humans, machines and algorithms...",,https://schema.org,NewsArticle,https://technologymagazine.com/ai-and-machine-learning/ai-helping-or-hindering-employees,"[{'url': 'https://assets.bizclikmedia.net/668/a26967cb206c4fc0703a1ed9af4781d5:111f2c5f5c9be5684675adb0d5571f70/405wf62akk899yf6220120212359-jpeg.webp.jpg', 'width': 668, 'height': 504, 'alt': 'Is AI helping or hindering employees?'}]","[{'@type': 'Person', 'name': 'Balakrishna D R', 'url': ''}]","{'@type': 'Organization', 'name': 'Bizclik Media Ltd'}",Is AI helping or hindering employees?,2021-01-22T12:24:03Z,,,,,,,,,"{'@type': 'WebPage', '@id': 'https://technologymagazine.com/ai-and-machine-learning/ai-helping-or-hindering-employees'}",,,,,,,,,,,,,,,,,/meta/technology/icon-192.png,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"['infosys', 'AI']",[],[],
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LmRlZmVuc2UuZ292L05ld3MvTmV3cy1TdG9yaWVzL0FydGljbGUvQXJ0aWNsZS8yNDgwMjg4L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWlzLWEtd29yay1pbi1wcm9ncmVzcy1vZmZpY2lhbC1zYXlzL9IBAA?oc=5,"Artificial Intelligence Is a Work in Progress, Official Says - Department of Defense",2021-01-22,Department of Defense,https://www.defense.gov,,,"Expectations are high that artificial intelligence will be a game changer for the military — and it is, in fact, one of the Defense Department's top priorities.","Expectations are high that artificial intelligence will be a game changer for the military — and it is, in fact, one of the Defense Department's top priorities.",http://schema.org,Organization,https://www.defense.gov/,,,,,,,,U.S. Department of Defense,,,,,"
        You have accessed part of a historical collection on defense.gov. Some of the information contained within may be outdated and links may not function. Please contact the DOD Webmaster with any questions.
    ",,,,,,,,,,,,,,,,,,https://www.defense.gov/Portals/1/Images/DOD-Icon-Header.png?ver=5sAfFl2--9znca0j3SrX_g%3d%3d,,,,,,,,,,,,,[],,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LmNvZS5pbnQvZW4vd2ViL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLy0vYWktbGF3LXdlYmluYXItOS1mYWNpYWwtcmVjb2duaXRpb24tdnMtY3JpbWluYWwtanVzdGljZdIBAA?oc=5,AI&Law Webinar #9: Facial recognition vs. Criminal Justice - Council of Europe,2021-01-26,Council of Europe,https://www.coe.int,Latest news of the Council of Europe's work related to AI,"newsroom,ai,dg1 human rights and rule of law,central division dg1,public,compulsory,general, news, ai, council of europe",Latest news of the Council of Europe's work related to AI, Strasbourg 2 February 2021,https://schema.org,WebPage,,"{'@type': 'ImageObject', 'url': 'https://www.coe.int/documents/40452431/43026603/AILB+09+-+Flyer+EN_870.png/22bed0d1-7041-0459-79b0-8dac4ace87b2', 'height': 489, 'width': 870}","{'@type': 'Organization', 'name': 'Council of Europe'}","{'@type': 'Organization', 'name': 'Council of Europe', 'logo': {'@type': 'ImageObject', 'url': 'https://static.coe.int/pics/logos/desktop/logo-coe-google-news.png', 'width': 78, 'height': 60}}",AI&Law Webinar #9: Facial recognition vs. Criminal Justice,2021-01-26T15:39:00+00:00,2024-05-17,,News,,,,,"

Strasbourg
2 February 2021


                Diminuer la taille du texte
            

                Augmenter la taille du texte
            

                Imprimer la page
            





The AI and Law webinars, co-organised by the Council of Europe and the University of Strasbourg (UMR DRES), are regular meetings open to a wide public, public decision-makers, officials from international organisations and national administrations and academics, whose aim is to measure the stakes of subjects at the frontiers of digital techniques and the practice of law.
This webinar focusses on the role artificial intelligence techniques such as facial recognition play in the criminal justice system. Deep learning techniques of this type promise to make it considerably easier to identify people from pictures and can be a real boon to police departments, provided the identification is technically reliable and fair – and the person in question was already a suspect before they were identified.
Currently a hot topic, video surveillance coupled with a facial recognition system is gaining traction in Europe while several North American cities have not only stopped using facial recognition, some have prohibited it. Does video surveillance create suspects? Is the fact that someone is present in a specific place – predetermined by the police – constitute reasonable grounds on which to launch a criminal investigation? Is using such combined surveillance and recognition systems a fair and effective way to fight crime?
Clear regulations have been adopted in recent decades to govern the use of investigative measures based on specific techniques such as telecommunications interception, using GPS to track vehicles, and installing surveillance cameras in homes. In Europe, the use of such techniques is reviewed by the European Court of Human Rights. Should similar rules apply when facial recognition is used to identify people?
Turning the mere identification of someone into grounds to investigate or proof of a crime is a legally delicate endeavor. Identification by a witness is governed by rules of criminal procedure. Witnesses must testify and be questioned by defense counsel before a judge, and in some cases their testimony cannot be admitted as evidence. Does AI testify? Does it provide an expert opinion? Can defense counsel question it, or impugn its reliability? Do otherwise benign observations produced by AI, such as that a driverless car was on the road, play a role in criminal proceedings?
Speakers 

Thomas Lampert, Ph.D., Chair of Artificial Intelligence and Data Science, University of Strasbourg
Kate Robertson, Criminal and regulatory litigator, Markson Law, Toronto
Sabine Gless, Ph.D., Professor of Criminal Law and Procedure, University of Basel

Hosted by Juliette Lelieur (University of Strasbourg) and Yannick Meneceur (Council of Europe)

Full recording available 

","{'@type': 'WebPage', '@id': 'https://www.coe.int/en/web/artificial-intelligence/-/ai-law-webinar-9-facial-recognition-vs-criminal-justice'}",2018-11-28,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9pLWxhbmRlZC1hLWpvYi1hdC1hbi1haS1zdGFydHVwLWFmdGVyLXN0dWR5aW5nLWZvci1vbmx5LTQtbW9udGhzLTc2ZDgxNjExN2ExY9IBAA?oc=5,I Landed a Job at an AI Startup after Studying for Only 4 Months - Towards Data Science,2021-01-25,Towards Data Science,https://towardsdatascience.com,I was about to finish my bachelor’s in aerospace engineering and the only thing I had for sure was that I didn’t want to work as an aerospace engineer. Not quite a clear future. My thesis defense was…,,"What, how, when and to what degree I studied","What, how, when and to what degree I studied",http://schema.org,NewsArticle,https://towardsdatascience.com/i-landed-a-job-at-an-ai-startup-after-studying-for-only-4-months-76d816117a1c,['https://miro.medium.com/v2/resize:fit:1200/1*7IatRIAgdnVwbhsHl3dvIQ.jpeg'],"{'@type': 'Person', 'name': 'Alberto Romero', 'url': 'https://albertoromgar.medium.com'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",I Landed a Job at an AI Startup after Studying for Only 4 Months,2021-01-26T00:06:43.580Z,2021-12-28T14:45:16.169Z,,I Landed a Job at an AI Startup after Studying for Only 4 Months,False,,,,"Member-only storyI Landed a Job at an AI Startup after Studying for Only 4 MonthsWhat, how, when, and to what degree I studiedAlberto Romero·FollowPublished inTowards Data Science·11 min read·Jan 25, 20213815ListenSharePhoto by Christina Morillo from PexelsI was about to finish my bachelor’s in aerospace engineering and the only thing I had for sure was that I didn’t want to work as an aerospace engineer. Not quite a clear future.My thesis defense was just a few months ahead when I stumbled across the field of neurotechnology. I had always loved psychology and everything related to the human mind so it caught my attention. The “tech” part made it sound like something I could get into from my background, but I had no idea how I could get there from where I was.I postponed the decision but soon I was out of college and had to choose: “I either follow the path and do what it’s expected from me or defy the odds and go for what is calling me.I chose the latter and defined a path to find a job in the field of Neurotech. However, I lacked half the knowledge and most skills. I needed a bridge to make the process less steep. So I defined one:“Aerospace Engineering -> Artificial Intelligence -> Neuroscience/Neurotechnology”Easy, right? AI was waiting for me in the middle. I had enough mathematical background to study AI by myself. And at…",https://towardsdatascience.com/i-landed-a-job-at-an-ai-startup-after-studying-for-only-4-months-76d816117a1c,2021-01-26T00:06:43.580Z,,,76d816117a1c,['Alberto Romero'],,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LmFhYXMub3JnL25ld3MvYWFhcy1wcm9qZWN0LXByb21vdGUtc29jaWFsbHktcmVzcG9uc2libGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaGVhbHRoY2FyZS1raWNrcy1wdWJsaWPSAQA?oc=5,AAAS Project to Promote Socially Responsible Artificial Intelligence in Healthcare Kicks Off with Public Opinion Work - AAAS,2021-01-25,AAAS,https://www.aaas.org,"AAAS is launching a project to support the responsible development and deployment of artificial intelligence (AI) in healthcare contexts, and specifically in public health crises like the COVID-19 pandemic. Today the project released a landscape assessment of existing public opinion work in this area compiled by a team of researchers from the University of Wisconsin-Madison. This report summarizes what we know about public views of the use of AI in healthcare and in areas affecting the pandemic response, with an emphasis on understanding the concerns of populations most vulnerable to the negative impacts of AI technology.",,"AAAS is launching a project to support the responsible development and deployment of artificial intelligence (AI) in healthcare contexts, and specifically in public health crises like the COVID-19 pandemic. Today the project released a landscape assessment of existing public opinion work in this area compiled by a team of researchers from the University of Wisconsin-Madison. This report summarizes what we know about public views of the use of AI in healthcare and in areas affecting the pandemic response, with an emphasis on understanding the concerns of populations most vulnerable to the negative impacts of AI technology.","AAAS is launching a project to support the responsible development and deployment of artificial intelligence (AI) in healthcare contexts, and specifically in public health crises like the COVID-19 pandemic. Today the project released a landscape assessment of existing public opinion work in this area compiled by a team of researchers from the University of Wisconsin-Madison. This report summarizes what we know about public views of the use of AI in healthcare and in areas affecting the pandemic response, with an emphasis on understanding the concerns of populations most vulnerable to the negative impacts of AI technology.",,,,,,,,,,,,,,,,"

25 January 2021
by: Elana Kimbrell




 










        Contact tracing apps use artificial intelligence to track the spread of disease.
      

Photo credit: Photo by John Cameron on Unsplash.








1




        Contact tracing apps use artificial intelligence to track the spread of disease.
      

Photo credit: Photo by John Cameron on Unsplash.









AAAS is launching a project to support the responsible development and deployment of artificial intelligence (AI) in healthcare contexts, and specifically in public health crises like the COVID-19 pandemic. Today the project released a landscape assessment of existing public opinion work in this area compiled by a team of researchers from the University of Wisconsin-Madison.[1] This report summarizes what we know about public views of the use of AI in healthcare and in areas affecting the pandemic response, with an emphasis on understanding the concerns of populations most vulnerable to the negative impacts of AI technology. 
“By understanding the views of people who might use or be affected by new technologies, and seeking out diverse voices that include marginalized communities, we aim to deepen conversations about the implications of these technologies for civic society,” said Emily Therese Cloyd, director of the AAAS Center for Public Engagement with Science & Technology. “Such conversations can reveal questions and concerns about the ways technologies are designed and applied before they become problems -- or light the way to new approaches that hadn't been considered previously.”
From containment of the virus to drug development, AI-driven healthcare applications have played an important role in the COVID-19 response. AAAS identified three areas where these applications could have an outsize impact on privacy and human rights, or pose a greater risk of potential abuses: surveillance (e.g., contact tracing), medical triage, and allocation of resources. The landscape assessment released today reviews public opinion on the AI landscape more broadly while also seeking to understand the concerns of vulnerable communities in particular, including in the context of the three areas identified.  
The landscape assessment, intended as a baseline to show where additional research may be useful, found very little existing survey work on public opinions of AI in the United States. Surveys that do exist do not provide breakdowns by demographic, although the researchers did some of this analysis as part of their work. The landscape assessment recommends that future work “pay special attention to minority groups and groups that are traditionally digitally marginalized, as these groups are more susceptible to negative outcomes of AI usage and applications (for example, racial bias embodied in AI systems).”
Findings from the assessment also flagged as a gap that polls “tend to focus on specific, sometimes very hypothetical or obscure-seeming potential applications of AI, making it difficult to piece together an overall picture of public opinion regarding AI in general and in healthcare contexts in particular.”
AAAS intends to incorporate the results from this landscape assessment into a responsibility framework for creating and using AI in ways that alleviate, rather than exacerbate, any negative impacts of the technology among vulnerable and marginalized populations. AAAS will develop and disseminate this framework in collaboration with representatives of these groups as well as with AI experts and developers, social scientists, and policymakers.   
To follow up on the landscape assessment, AAAS is working with researchers from Marquette University and the Medical College of Wisconsin[2] to convene focus groups and gather more qualitative information from specific populations. The focus groups will be held with Black, Latino, Southeast Asian, and First Nations communities in the Milwaukee area. 
“Our aim is to engage with these communities to gain a clearer picture of their general understandings of AI and its range of uses within the healthcare context, their reactions to the potential uses of AI technology in response to the COVID-19 pandemic, attitudes about the use of personal health data in the development of AI, and views about whether they feel AI might help (or, perhaps perpetuate) health disparities in their respective communities,” says Michael Zimmer, lead investigator.
In the coming weeks, the project will also release a report summarizing the uses of AI in the COVID response, and focused on the three applications identified (surveillance, triage, and resource allocation.) In later stages, AAAS intends to work with community leaders, AI experts and developers, social scientists, and policymakers to develop and deliver written and digital materials and direct engagement activities to promote conversations between scientific experts and diverse publics. Engagement activities may include online discussion forums, virtual workshops, town halls, webinars, and other appropriate convenings.
The Artificial Intelligence (AI2): Application/Implications Initiative was launched with support from Microsoft. The project is guided by an advisory group of multidisciplinary experts. Those interested in contributing to this work may do so at: https://www.aaas.org/ai2/donate.
 

[1] University of Wisconsin, Madison research team: Todd P. Newman, Emily L. Howell, Luye Bao, Becca Beets, and Shiyu Yang.


[2] Michael Zimmer and Praveen Madiraju (Marquette University) and Zeno Franco (Medical College of Wisconsin)








",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAyMS8wMS8yNS9mYWtlLW5ld3MtaXMtcmFtcGFudC1oZXJlLWlzLWhvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jYW4taGVscC_SAQA?oc=5,"Fake News Is Rampant, Here Is How Artificial Intelligence Can Help - Forbes",2021-01-25,Forbes,https://www.forbes.com,"As with so many of our modern problems, artificial intelligence is now on the job helping to fight false news. Logically is one company that uses artificial intelligence to provide fact-checking services for consumers.","fake news,ai,artificial intelligence,deepfake","As with so many of our modern problems, artificial intelligence is now on the job helping to fight false news. Logically is one company that uses artificial intelligence to provide fact-checking services for consumers.","As with so many of our modern problems, artificial intelligence is now on the job helping to fight false news. Logically is one company that uses artificial intelligence to provide fact-checking services for consumers.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2021/01/25/fake-news-is-rampant-here-is-how-artificial-intelligence-can-help/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/600e55afcd20ae16e22d2456/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","Fake News Is Rampant, Here Is How Artificial Intelligence Can Help",2021-01-25T00:25:47-05:00,2024-01-27T12:20:45-05:00,Enterprise Tech,"Fake News Is Rampant, Here Is How Artificial Intelligence Can Help",False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise Tech,,"More From ForbesJul 16, 2024,01:24am EDTThe Best Generative AI Workplace Productivity ToolsJul 15, 2024,09:02am EDTWhen Will Quantum Computers Affect Your Competitive Landscape?Jul 15, 2024,09:00am EDTAristotle’s Timeless Guide To Mastering AIOpsJul 15, 2024,03:25am EDTIEEE Travels In July (Japan, China And Greece)Jul 14, 2024,03:19am EDTMaking A More Accurate And Sustainable AI ModelJul 12, 2024,09:00am EDT‘Knowledge Is Power’: The Antipattern That Is Holding Your Team BackJul 12, 2024,07:00am EDTHow Generative AI Rattles the WorkplaceEdit StoryForbesInnovationEnterprise TechFake News Is Rampant, Here Is How Artificial Intelligence Can HelpBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itJan 25, 2021,12:25am ESTThis article is more than 3 years old.Share to FacebookShare to TwitterShare to LinkedinOne of the latest collaborations between artificial intelligence and humans is further evidence of how machines and humans can create better results when working together. Artificial intelligence (AI) is now on the job to combat the spread of misinformation on the internet and social platforms thanks to the efforts of start-ups such as Logically. While AI is able to analyze the enormous amounts of info generated daily on a scale that's impossible for humans, ultimately, humans need to be part of the process of fact-checking to ensure credibility. As Lyric Jain, founder and CEO of Logically, said, toxic news travels faster than the truth. Our world desperately needs a way to discern truth from fiction in our news and public, political and economic discussions, and artificial intelligence will help us do that.
Fake News Is Rampant, Here Is How Artificial Intelligence Can Help Adobe Stock

The Fake News “Infodemic”

People are inundated with info every single day. Each minute, there are 98,000 tweets, 160 million emails sent, and 600 videos uploaded to YouTube. Politicians. Marketers. News outlets. Plus, there are countless individuals spewing their opinions since self-publishing is so easy. People crave a way to sort through all the information to find valuable nuggets they can use in their own life. They want facts, and companies are starting to respond often by using machine learning and AI tools. 

Logically Verifies Fact from Fiction

To make critical decisions in life, we require facts. However, since anyone has the ability to publish information on the internet, false news travels fast and can have dire consequences. UK start-up Logically was founded in 2017 by Lyric Jain, an alum of MIT and Cambridge. He set out to develop a solution that combined artificial and human intelligence to verify the veracity of news, social discussion, and images.
PROMOTED
Through a free app that can be downloaded from the Apple Store or Google Play, readers can verify content by sharing an article with Logically. The company also has a Chrome browser extension that works on more than 160,000 social platforms and news sites to fact-check news stories. The company deployed first in the UK and India and then spread to the United States ahead of the 2020 election cycle to fact-check for consumers as well as government agencies.
How Does Logically Work? 
Logically’s AI algorithms use natural language processing to understand and analyze text. The AI models label the credibility of the source of the content with a rating of low, medium, high, and an article as reliable or unreliable based on comparisons of similar content from more than 100,000 sources. The algorithms are checking not only content, but metadata and images too.
MORE FROMFORBES ADVISORBest High-Yield Savings Accounts Of September 2023ByKevin PayneContributorBest 5% Interest Savings Accounts of September 2023ByCassidy HortonContributor
During India’s last election campaign, Logically analyzed more than 1 million articles. They found 50,000 to be fake. The algorithms also check the toxicity of content and can block out profane and obscene content. This is an area where the algorithms are a bit less proficient as they are with fact verification, where they might mistakenly flag tongue-in-cheek communication as toxic.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Machines are adept at quickly analyzing volumes of content. They can flag questionable items for review by a human fact-checker as well as become smarter over time with feedback from results.
On a Fact-Finding Mission


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
When there is a need as great as we have with fighting fake news to safeguard our communities and commerce from the damage lies can inflict, it’s not hard to imagine that several innovators have stepped up to help develop solutions.
Another organization that is working to rid the world of misinformation is Full Fact, a team of independent fact-checkers that is also building automated fact-checking tools. Since 2015, they have been developing tech to increase their fact-checking impact. Full Fact collects and monitors data, identifies and labels claims, and often takes the fact-checking process offline with humans.
AdVerif.ai is an AI company that aims to keep users safe from inappropriate and deceiving content, spam, and fake news. The company's FakeRank algorithms help advertisers, publishers, and ad networks to moderate content and ensure compliance with company policies to ultimately protect users and keep the reputations of brands safe.
As the world’s largest social media networks have come under fire for the part they play in spreading fake news, companies such as Facebook, Twitter, and others will rely on technology and AI tools to help them address the public's demands. Facebook worked with independent fact-checking organizations Snopes, Politifact, ABC News, and FactCheck.org to verify viral stories. They also announced initiatives such as applying machine learning and building new products to identify and limit the spread of false news.
As the pursuit of fighting fake news becomes more sophisticated, technology leaders will continue to work to find even better ways to sort out fact from fiction also well as refine the AI tools that can help fight disinformation. Deep learning can help automate some of the steps in fake news detection, according to a team of researchers at DarwinAI and Canada's University of Waterloo. They are segmenting fact-checking into various sub-tasks, including stance detection where the system is given a claim on a news story plus other stories on the same subject to determine if those other stories support or refute the claim in the original piece.
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vbGl0aHViLmNvbS9mcm9tLXRoZS1nb2xkZW4tYWdlLXRvLXJvb21iYXMtcmVhZGluZy1hYm91dC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,From the Golden Age to… Roombas: 8 Essential Books About Artificial Intelligence - Literary Hub,2021-01-25,Literary Hub,https://lithub.com,,,"The field of Artificial Intelligence (AI) is concerned with building machines that have the same capabilities that human beings have. If the ultimate dream of AI is ever realized, then we will have…",,,,,,,,,,,,,,,,,"

Support Lit Hub.
Join our community of readers.
 
Close

to the Lithub Daily
Thank you for subscribing!



Email













						Submit
					





 Tim Lankester on the promise, failure and legacy of Margaret Thatcher's monetarist experimentAdSkipStay  00:19/00:30Ad ends in 11s LIVE
Popular Posts1.Crooked Parallels: On Alice Munro, Andrea Skinner, and My Mother’s Failure to Protect MeJuly 12, 2024 by Jonny Diamond562.Envy, Obsession, and Instagram: On My Mental Breakdown at an Esteemed Writing ConferenceJuly 12, 2024 by Brittany Ackerman483.They paved Pemberley and put up a parking lot.July 10, 2024 by Brittany Allen114.Lit Hub’s Most Anticipated Books of 2024, Part TwoJuly 10, 2024 by Emily Temple3

The Best Reviewed Books of the WeekJuly 12, 20245 Reviews You Need to Read This WeekJuly 11, 2024 by Book MarksThe Best Reviewed Books of the MonthJune 28, 2024 by Book Marks5 Reviews You Need to Read This WeekJune 27, 2024 by Book MarksThe Best Reviewed Books of the WeekJune 21, 2024 by Book Marks

Sepia Model Murder, 1969: The Slaying of Bani YelvertonJuly 17, 2024 by Michael GonzalesThe Backlist: Margot Douaihy and Polly Stewart Revisit Patricia Highsmith's 'Edith's Diary'July 17, 2024 by Polly StewartThe Trees Did It: Five Novels Where Nature Gets Involved in the CrimeJuly 17, 2024 by Alisa AleringScene-Stealing SidekicksJuly 17, 2024 by Jennie MartsDestination Thrillers: The Lure of the UnknownJuly 16, 2024 by Stephanie DeCarolis
Follow us on Twitter


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vcGh5cy5vcmcvbmV3cy8yMDIxLTAxLXdheXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3BhY2UtZXhwbG9yYXRpb24uaHRtbNIBUGh0dHBzOi8vcGh5cy5vcmcvbmV3cy8yMDIxLTAxLXdheXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3BhY2UtZXhwbG9yYXRpb24uYW1w?oc=5,Five ways artificial intelligence can help space exploration - Phys.org,2021-01-26,Phys.org,https://phys.org,"Artificial intelligence has been making waves in recent years, enabling us to solve problems faster than traditional computing could ever allow. Recently, for example, Google's artificial intelligence subsidiary DeepMind developed AlphaFold2, a program which solved the protein-folding problem. This is a problem which has had baffled scientists for 50 years.","Science, Physics News, Science news, Technology News, Physics, Materials, Nanotech, Technology, Science","Artificial intelligence has been making waves in recent years, enabling us to solve problems faster than traditional computing could ever allow. Recently, for example, Google's artificial intelligence subsidiary DeepMind developed AlphaFold2, a program which solved the protein-folding problem. This is a problem which has had baffled scientists for 50 years.","Artificial intelligence has been making waves in recent years, enabling us to solve problems faster than traditional computing could ever allow. Recently, for example, Google's artificial intelligence ...",https://schema.org,BreadcrumbList,,"{'@type': 'ImageObject', 'url': 'https://scx2.b-cdn.net/gfx/news/2021/fivewaysarti.jpg', 'width': 600, 'height': 900}","[{'@type': 'Person', 'name': 'Deep Bandivadekar'}, {'@type': 'Person', 'name': 'Audrey Berquand'}]","{'@type': 'Organization', 'name': 'Phys.org', 'logo': {'@type': 'ImageObject', 'url': 'https://phys.b-cdn.net/tmpl/v6/img/logo.amp.png', 'width': 204, 'height': 60}}",Five ways artificial intelligence can help space exploration,2021-01-26T09:09:52-05:00,2021-01-26T09:09:52-05:00,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://phys.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Astronomy &amp; Space', 'item': 'https://phys.org/space-news/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Space Exploration', 'item': 'https://phys.org/space-news/space-exploration/'}]",,,"










														January 26, 2021
														
													






Five ways artificial intelligence can help space exploration

										 by Deep Bandivadekar and Audrey Berquand, 										 										 The Conversation







                CIMON will assist astronauts on the International Space Station. Credit: NASA/Kim Shiflett, CC BY
 

Artificial intelligence has been making waves in recent years, enabling us to solve problems faster than traditional computing could ever allow. Recently, for example, Google's artificial intelligence subsidiary DeepMind developed AlphaFold2, a program which solved the protein-folding problem. This is a problem which has had baffled scientists for 50 years.





Advances in AI have allowed us to make progress in all kinds of disciplines—and these are not limited to applications on this planet. From designing missions to clearing Earth's orbit of junk, here are a few ways artificial intelligence can help us venture further in space.
Astronaut assistants
Do you remember Tars and Case, the assistant robots from the film Interstellar? While these robots don't exist yet for real space missions, researchers are working towards something similar, creating intelligent assistants to help astronauts. These AI-based assistants, even though they may not look as fancy as those in the movies, could be incredibly useful to space exploration.
A recently developed virtual assistant can potentially detect any dangers in lengthy space missions such as changes in the spacecraft atmosphere—for example increased carbon dioxide—or a sensor malfunction that could be potentially harmful. It would then alert the crew with suggestions for inspection.
An AI assistant called Cimon was flown to the international space station (ISS) in December 2019, where it is being tested for three years. Eventually, Cimon will be used to reduce astronauts' stress by performing tasks they ask it to do. NASA is also developing a companion for astronauts aboard the ISS, called Robonaut, which will work alongside the astronauts or take on tasks that are too risky for them.





                AI has also been harnessed to address the problem of space junk. Credit: NASA Orbital Debris Program Office, CC BY
 


Mission design and planning
Planning a mission to Mars is not an easy task, but artificial intelligence can make it easier. New space missions traditionally rely on knowledge gathered by previous studies. However, this information can often be limited or not fully accessible.






This means the technical information flow is constrained by who can access and share it among other mission design engineers. But what if all the information from practically all previous space missions were available to anyone with authority in just a few clicks. One day there may be a smarter system—similar to Wikipedia, but with artificial intelligence that can answer complex queries with reliable and relevant information—to help with early design and planning of new space missions.
Researchers are working on the idea of a design engineering assistant to reduce the time required for initial mission design which otherwise takes many human work hours. ""Daphne"" is another example of an intelligent assistant for designing Earth observation satellite systems. Daphne is used by systems engineers in satellite design teams. It makes their job easier by providing access to relevant information including feedback as well as answers to specific queries.
Satellite data processing
Earth observation satellites generate tremendous amounts of data. This is received by ground stations in chunks over a large period of time, and has to be pieced together before it can be analyzed. While there have been some crowdsourcing projects to do basic satellite imagery analysis on a very small scale, artificial intelligence can come to our rescue for detailed satellite data analysis.
For the sheer volume of data received, AI has been very effective in processing it smartly. It's been used to estimate heat storage in urban areas and to combine meteorological data with satellite imagery for wind speed estimation. AI has also helped with solar radiation estimation using geostationary satellite data, among many other applications.
AI for data processing can also be used for the satellites themselves. In recent research, scientists tested various AI techniques for a remote satellite health monitoring system. This is capable of analyzing data received from satellites to detect any problems, predict satellite health performance and present a visualization for informed decision making.










Virtual tour of the moon.
Space debris
One of the biggest space challenges of the 21st century is how to tackle space debris. According to ESA, there are nearly 34,000 objects bigger than 10cm which pose serious threats to existing space infrastructure. There are some innovative approaches to deal with the menace, such as designing satellites to re-enter Earth's atmosphere if they are deployed within the low Earth orbit region making them disintegrate completely in a controlled way.
Another approach is to avoid any possible collisions in space, preventing the creation of any debris. In a recent study, researchers developed a method to design collision avoidance maneuvers using machine-learning (ML) techniques.
Another novel approach is to use the enormous computing power available on Earth to train ML models, transmit those models to the spacecraft already in orbit or on their way, and use them on board for various decisions. One way to ensure safety of space flights has recently been proposed using already trained networks on board the spacecraft. This allows more flexibility in satellite design while keeping the danger of in orbit collision at a minimum.






Navigation systems
On Earth, we are used to tools such as Google Maps which use GPS or other navigation systems. But there is no such a system for other extraterrestrial bodies, for now.
We do not have any navigation satellites around the Moon or Mars but we could use the millions of images we have from observation satellites such as the Lunar Reconnaissance Orbiter (LRO). In 2018, a team of researchers from NASA in collaboration with Intel developed an intelligent navigation system using AI to explore the planets. They trained the model on the millions of photographs available from various missions and created a virtual Moon map.
As we carry on to explore the universe, we will continue to plan ambitious missions to satisfy our inherent curiosity as well as to improve the human lives on Earth. In our endeavors, artificial intelligence will help us both on Earth and in space make this exploration possible.


													Provided by
																											The Conversation








This article is republished from The Conversation under a Creative Commons license. Read the original article.




Citation:
												Five ways artificial intelligence can help space exploration (2021, January 26)
												retrieved 17 July 2024
												from https://phys.org/news/2021-01-ways-artificial-intelligence-space-exploration.html
											 

											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 


","{'@type': 'WebPage', '@id': 'https://phys.org/news/2021-01-ways-artificial-intelligence-space-exploration.html'}",,,,,,,,,,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='Description']/@content""]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vYW1lcmljYW5saWJyYXJpZXNtYWdhemluZS5vcmcvYmxvZ3MvdGhlLXNjb29wL21lZXRpbmctdGhlLWZ1dHVyZS1oZWFkLW9uL9IBAA?oc=5,Meeting the Future Head-on - American Libraries,2021-01-25,American Libraries,https://americanlibrariesmagazine.org,AI technology was highlighted in the session “Artificial Intelligence: The Future is Already Here” on January 24 as part of the 2021 ALA Midwinter Meeting & Exhibits’ LibLearnX Preview and the Symposium on the Future of Libraries.,,AI technology was highlighted in the session “Artificial Intelligence: The Future is Already Here” on January 24 as part of the 2021 ALA Midwinter Meeting & Exhibits’ LibLearnX Preview and the Symposium on the Future of Libraries.,,https://schema.org,,,,,,,,,,,,,,,"

Meeting the Future Head-onHow the Hawaii State Library System is introducing artificial intelligence


			By Carrie Smith | 		
January 25, 2021




FacebookTwitterEmailPrint
If you’re not ready for them, the changes brought on by new technology might “punch you in the mouth,” said Ian Kitajima, director of corporate development at Oceanit Research Foundation.
It’s a timely, if violent, image: The pandemic has accelerated numerous technological changes, including digitization, automation, and remote work. In the midst of this upheaval, the Hawaii State Library system has partnered with Oceanit to help dodge any metaphorical punches by bringing artificial intelligence (AI) technology, along with job training and mentorship for students, to the library.
With Stacey Aldrich, state librarian of Hawaii, Kitajima shared details about their partnership and the future of AI technology in the session “Artificial Intelligence: The Future is Already Here” on Sunday, January 24 as part of the 2021 ALA Midwinter Meeting & Exhibits’ LibLearnX Preview and the Symposium on the Future of Libraries.
Aldrich approached Oceanit because she was looking for a more effective way of tracking library occupancy. At the time, the Hawaii library system—the only statewide public library system in the US—relied on manual people-counting to assess usage and occupancy. Aldrich sought instead a way to use Oceanit technology to implement people-counting while using the data in a way that protects people’s privacy.
The partnership would not only bring AI into the libraries, but also leverage Oceanit’s Aloha AI Student Trailblazers program to offer opportunities for students across the islands to learn about AI and work with the data to help the library envision new ideas for managing resources. “We want to make sure we’re looking at how we use it, what we can do with it, and how we can help educate folks,” Aldrich said.
The partnership centers on the Aloha AI System and Occupancy Sensors. While most people-counters use a motion detector to count entries and exits, these sensors use AI technology that has been trained on massive datasets to identify human beings. However, the system helps maintain library visitors’ privacy by analyzing camera input on the sensors themselves instead of transmitting them to a central database, which means that the only data stored in the cloud is that a person entered the library at a specific time. Advances in AI technology have lowered the cost of these more powerful sensors. “If we were trying to do this three years ago, I would have told Stacey it’s just not feasible,” Kitajima said.
Testing began in October 2020 at the Kaimuki Public Library in Honolulu. An online dashboard provides a real-time occupancy count; soon it will include an audio component to notify library staff when occupancy is too high. Students from Hawaii high schools will begin training in March to use the data and present further questions to the library for analysis under mentorship from Oceanit.
Kitajima identifies AI as one of several “mega-trends” in technology that will affect life and work in the years to come. He predicts that it will be just as influential as the internet when it comes to creating new businesses, and believes that focusing on students now will help develop and diversify the technology in the future. “We have to have a balance within, especially in artificial intelligence,” he says, adding that AI should respect privacy and culture. “Technology sometimes tends to be so efficient that we lose our cultural practices.”
Student participation also helps provide training for careers in AI and other data-related fields. The Oceanit program exposes students to innovation mindsets and design thinking instead of a particular technological device or format, since, Kitajima noted, technology changes while the approaches needed to evolve it stay the same.
By engaging students in a community problem, “we have a unique opportunity to have multiple benefits for everyone,” Kitajima said.
FacebookTwitterEmailPrint 

CARRIE SMITH is editorial and advertising associate for American Libraries.
 
Share
FacebookTwitterEmailPrint 

Tagged Under#alamw21ALA Midwinter Meeting and Exhibitsartificial intelligenceLibLearnXLibrary technologySymposium on the Future of Libraries 




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebSite', '@id': 'https://americanlibrariesmagazine.org/#website', 'url': 'https://americanlibrariesmagazine.org/', 'name': 'American Libraries Magazine', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://americanlibrariesmagazine.org/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://americanlibrariesmagazine.org/blogs/the-scoop/meeting-the-future-head-on/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://americanlibrariesmagazine.org/wp-content/uploads/2021/01/artificial-intelligence.jpg', 'width': 970, 'height': 647, 'caption': 'Stacey Aldrich and Ian Kitajima'}, {'@type': 'WebPage', '@id': 'https://americanlibrariesmagazine.org/blogs/the-scoop/meeting-the-future-head-on/#webpage', 'url': 'https://americanlibrariesmagazine.org/blogs/the-scoop/meeting-the-future-head-on/', 'name': 'Meeting the Future Head-on | American Libraries Magazine', 'isPartOf': {'@id': 'https://americanlibrariesmagazine.org/#website'}, 'primaryImageOfPage': {'@id': 'https://americanlibrariesmagazine.org/blogs/the-scoop/meeting-the-future-head-on/#primaryimage'}, 'datePublished': '2021-01-25T21:57:12+00:00', 'dateModified': '2021-01-29T16:36:36+00:00', 'description': 'AI technology was highlighted in the session “Artificial Intelligence: The Future is Already Here” on January 24 as part of the 2021 ALA Midwinter Meeting & Exhibits’ LibLearnX Preview and the Symposium on the Future of Libraries.', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://americanlibrariesmagazine.org/blogs/the-scoop/meeting-the-future-head-on/']}]}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3LnpkbmV0LmNvbS9hcnRpY2xlL3RoZS1kZXZlbG9wZXJzLWRyZWFtLXRoaXMtY29tcGFueXMtdGVjaC13b3Jrc3BhY2UtYnJpbmdzLWFnaWxlLWRldmVsb3BtZW50LXRvLWxpZmUv0gEA?oc=5,The developer's dream? This company's tech workspace brings Agile development to life - ZDNet,2021-01-25,ZDNet,https://www.zdnet.com,"A new Forrester report shows that to survive the next ten years, businesses will need to switch their strategy from efficiency to agility.",,Jewellery firm Pandora built a new digital hub for its engineering and data-science talent. That space has created a whole new way of working.,Jewellery firm Pandora built a new digital hub for its engineering and data-science talent. That space has created a whole new way of working.,https://schema.org,VideoObject,,,,,,,,,Digital transformation: Businesses must switch their strategy from efficiency to agility,,,,,,,,,,,,,,,,,,,,,,,,,https://www.zdnet.com/a/img/resize/0c4617746ebbc25c6e4671ca4050543d33f05c13/2020/07/30/1b4870f3-ac90-4081-ae5e-966176b65494/digital-transformation-businesses-must-s-5f1eaff2931ab320db2dcfd2-1-jul-30-2020-11-05-32-poster.jpg?auto=webp&fit=crop&height=675&width=1200,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-07-30T12:03:18.000Z,https://www.zdnet.com/video/share/digital-transformation-businesses-must-switch-their-strategy-from-efficiency-to-agility/,https://mt-rv-v5.zdnet.com/vr/2020/07/30/1770103875993/wochit-5f1eaff2931ab320db2dcfd2-digital_transformation_businesses_must_switch_their_strategy_from_efficiency_to_agility_426251_742.mp4,PT0H1M9S,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LmJ1c2luZXNzaW5zaWRlci5jb20vaW52ZXN0aW5nLXN0cmF0ZWd5LXN0b2NrLXBpY2tpbmctYWktcmVuZWUteWFvLWhvdy1pdC13b3Jrcy0yMDIxLTHSAWVodHRwczovL3d3dy5idXNpbmVzc2luc2lkZXIuY29tL2ludmVzdGluZy1zdHJhdGVneS1zdG9jay1waWNraW5nLWFpLXJlbmVlLXlhby1ob3ctaXQtd29ya3MtMjAyMS0xP2FtcA?oc=5,"Investing strategy, stock-picking with AI: Renee Yao on how fund works - Business Insider",2021-01-26,Business Insider,https://www.businessinsider.com,"Renee Yao, whose fund defied a bad year for traditional quant funds in 2020, shared how her AI-driven strategy works.","Investing, Stock Market, AI","Renee Yao, whose fund defied a bad year for traditional quant funds in 2020, shared how her AI-driven strategy works.",,http://schema.org,BreadcrumbList,,"{'@type': 'ImageObject', 'url': 'https://i.insider.com/600db4477e47190011cb8f04?width=1136&format=jpeg', 'width': 1136, 'height': 852, 'caption': 'Renee Yao is the founder and portfolio manager of quant hedge fund Neo Ivy Capital.'}","{'@type': 'Person', 'name': 'Vicky Ge Huang', 'sameAs': 'https://www.businessinsider.com/author/vicky-ge-huang'}","{'@context': 'http://schema.org', '@type': 'Organization', 'name': 'Insider', 'legalName': 'Insider Inc.', 'foundingDate': '2007', 'url': 'www.businessinsider.com', 'sameAs': ['https://www.instagram.com/insiderbusiness', 'https://www.twitter.com/businessinsider', 'https://www.facebook.com/businessinsider', 'https://www.linkedin.com/company/businessinsider', 'https://www.youtube.com/@InsiderBusiness'], 'founder': {'@type': 'Person', 'name': 'Henry Blodget'}, 'logo': {'@type': 'ImageObject', 'url': 'https://www.businessinsider.com/public/assets/logos/structured-data.png', 'width': 305, 'height': 60}}","Investing strategy, stock-picking with AI: Renee Yao on how fund works",2021-01-26T18:01:15Z,2021-01-27T23:31:50Z,Markets,An ex-hedge fund quant researcher whose firm uses AI to pick stocks breaks down how her fast-moving strategy works — and shares why it's superior in chaotic market environments,True,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.businessinsider.com/', 'name': 'Business Insider'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.businessinsider.com/markets', 'name': 'Markets'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.businessinsider.com/investing-strategy-stock-picking-ai-renee-yao-how-it-works-2021-1', 'name': ""An ex-hedge fund quant researcher whose firm uses AI to pick stocks breaks down how her fast-moving strategy works — and shares why it's superior in chaotic market environments""}}]",,,"




                                    Markets
                                  
 
An ex-hedge fund quant researcher whose firm uses AI to pick stocks breaks down how her fast-moving strategy works — and shares why it's superior in chaotic market environments








Vicky Ge Huang 
Jan 26, 2021, 1:01 PM EST 







Share icon
An curved arrow pointing right.

 Share





Facebook Icon
The letter F.


Facebook
 



Email icon
An envelope. It indicates the ability to send an email.


Email
 



Twitter icon
A stylized bird with an open mouth, tweeting.


Twitter
 



LinkedIn icon


LinkedIn
 



Link icon
An image of a chain link. It symobilizes a website link url.


Copy Link
 





lighning bolt icon
An icon in the shape of a lightning bolt.

 
Impact Link

 
 



Save Article Icon
A bookmark

 Save





 
                                      Read in app
                                  












Angle down icon
An icon in the shape of an angle pointing down.

 

Renee Yao is the founder and portfolio manager of quant hedge fund Neo Ivy Capital.
 
                            Neo Ivy Capital
                          










Renee Yao is the founder of Neo Ivy Capital, which applies artificial intelligence to financial markets.
In an interview, Yao explains how her quant strategy is set up to act fast in a chaotic market environment.
Because of her work, Insider named Yao to our annual list of the 10 leaders transforming investing in North America.
Visit Insider's Transforming Business homepage for more stories.











 


                                    Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview








 















Thanks for signing up!


                              Access your favorite topics in a personalized feed while you're on the go.
                              
                                download the app
                               





Email address





                                      Sign up
                                     



                                  By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy. You can opt-out at any time by visiting our Preferences page or by clicking ""unsubscribe"" at the bottom of the email.
                              








 

After a pandemic-stricken year that catapulted some of the most aggressive retail traders to millionaire status, the idea of turning to computer-driven quantitative hedge funds for outsized returns can seem unnecessary. Renee Yao, the founder and portfolio manager of quant hedge fund Neo Ivy Capital, begs to disagree. ""For the past six months, there's been a lot of retail flows into the market and the retail flows love those high-volatility, high-returns penny stocks,"" said Yao, noting that meanwhile, blue-chip stocks attracted little inflows. That discrepancy breeds the danger for a correction — something that Yao's fund is always monitoring so that it can act fast in a chaotic market environment. An example of such drama was the Dow's 13.7% decline in March followed by its 11% gain in April. ""If you use the traditional quant investing methodology, which you basically train your models with historical data, your model is going to get lost, because those are very rare events,"" Yao said.That's why so many traditional big-name quant hedge funds were hit with poor performance in 2020. For example, Jim Simons' Renaissance Institutional Diversified Alpha fund was down 32% while Ray Dalio's Bridgewater Pure Alpha II fund declined 12.57% last year. How does an artificial intelligence strategy work?Yao's fund, which manages about $200 million in client assets, has generated a consistent 10% in annualized return since its inception in June 2016 thanks to its artificial intelligence-driven model.



                                Related stories
                              


""The whole purpose of AI is to train the computer to think and analyze like a human being; it's not entirely reliant on historic data,"" she said. ""So our model was able to quickly pick up the change in market regime and deliver positive returns for both March and April last year.""Instead of training the computers with historical data and hoping history repeats itself, Yao and her researchers write their own artificial intelligence algorithm that automatically generates trading ideas for the fund 24/7, non-stop.It does so by collecting the relevant data, cleaning the data, processing the data-generated forecasts, and then translating the forecasts into tradable targets, according to Yao. ""For example, the AI might say that today Elon Musk sent a tweet about Tesla, it's a good tweet, it's a piece of good news so we think the Tesla stock will go up,"" she said. ""So it's going to give a positive conviction to the Tesla stock.""She continued: ""Then the algo will go ahead and incorporate that conviction into the risk constraint we have, and then translate that conviction into how many shares of Tesla we want to buy, and then sent the order to the market.""With no human discretion in the stock selection process, the fund holds a diversified pool of about 1,000 stocks.  A new generation of quants Yao represents a new generation of quant hedge fund managers who are embracing artificial intelligence to harness the infinite possibilities in financial markets. But she technically grew up in the world of traditional quantitative investing.After finishing her master's in statistics at Columbia University, Yao started her career as a quant researcher at hedge fund giant Citadel before joining Millennium Partners and WorldQuant as a portfolio manager. ""As I continued to work in traditional quantitative investing, I started to observe that the space has become very crowded, and more and more people are trading similar ideas,"" she recalled. ""So we were trying very hard to find a new angle, a new source of alpha that is uncorrelated to the traditional way.""Yao found this new angle while conducting joint research with Google's DeepMind lab, which was also working on its Alpha Go paper that introduced modern AI theory to the public for the first time.""Once you build this AI system, the system will automatically find new ideas for you, which completely frees up the human resources,"" she said. ""We don't need to hire hundreds of thousands of Ph.D.s like some of the second generation traditional quant funds do. Instead, we just build this system that will automatically do all the jobs of the Ph.D.s.""She added: ""In terms of business model, this is a good business model. In terms of the results, obviously, the results are quite good compared to traditional quantitative investing.""As the quant investing landscape evolves, Yao continues to upgrade the system and technology that support her hedge fund. Aside from work, she is also trying to support the industry by helping to groom the next generation of quants. ""Whenever I have time, I would actually go back to Columbia and attend some of the seminars they hold at the business school and statistics department,"" she said. ""Whenever I have the opportunity, I will go there and try to encourage more women to focus on science and mathematics.""

 







                                Read next
                              





Investing
Stock Market
AI


 



 


Close icon
Two crossed lines that form an 'X'. It indicates a way to close an interaction, or dismiss a notification.
                    



","{'@type': 'WebPage', '@id': 'https://www.businessinsider.com/investing-strategy-stock-picking-ai-renee-yao-how-it-works-2021-1'}",,,,,,,"After a pandemic-stricken year that catapulted some of the most aggressive retail traders to millionaire status, the idea of turning to computer-driven quantitative hedge funds for outsized returns can seem unnecessary. Renee Yao, the founder and portfolio manager of quant hedge fund Neo Ivy Capital, begs to disagree. ""For the past six months, there's been a lot of retail flows into the market and the retail flows love those high-volatility, high-returns penny stocks,"" said Yao, noting that meanwhile, blue-chip stocks attracted little inflows. That discrepancy breeds the danger for a correction — something that Yao's fund is always monitoring so that it can act fast in a chaotic market environment. An example of such drama was the Dow's 13.7% decline in March followed by its 11% gain in April. ""If you use the traditional quant investing methodology, which you basically train your models with historical data, your model is going to get lost, because those are very rare events,"" Yao said.That's why so many traditional big-name quant hedge funds were hit with poor performance in 2020. For example, Jim Simons' Renaissance Institutional Diversified Alpha fund was down 32% while Ray Dalio's Bridgewater Pure Alpha II fund declined 12.57% last year. Yao's fund, which manages about $200 million in client assets, has generated a consistent 10% in annualized return since its inception in June 2016 thanks to its artificial intelligence-driven model.""The whole purpose of AI is to train the computer to think and analyze like a human being; it's not entirely reliant on historic data,"" she said. ""So our model was able to quickly pick up the change in market regime and deliver positive returns for both March and April last year.""Instead of training the computers with historical data and hoping history repeats itself, Yao and her researchers write their own artificial intelligence algorithm that automatically generates trading ideas for the fund 24/7, non-stop.It does so by collecting the relevant data, cleaning the data, processing the data-generated forecasts, and then translating the forecasts into tradable targets, according to Yao. ""For example, the AI might say that today Elon Musk sent a tweet about Tesla, it's a good tweet, it's a piece of good news so we think the Tesla stock will go up,"" she said. ""So it's going to give a positive conviction to the Tesla stock.""She continued: ""Then the algo will go ahead and incorporate that conviction into the risk constraint we have, and then translate that conviction into how many shares of Tesla we want to buy, and then sent the order to the market.""With no human discretion in the stock selection process, the fund holds a diversified pool of about 1,000 stocks.  Yao represents a new generation of quant hedge fund managers who are embracing artificial intelligence to harness the infinite possibilities in financial markets. But she technically grew up in the world of traditional quantitative investing.After finishing her master's in statistics at Columbia University, Yao started her career as a quant researcher at hedge fund giant Citadel before joining Millennium Partners and WorldQuant as a portfolio manager. ""As I continued to work in traditional quantitative investing, I started to observe that the space has become very crowded, and more and more people are trading similar ideas,"" she recalled. ""So we were trying very hard to find a new angle, a new source of alpha that is uncorrelated to the traditional way.""Yao found this new angle while conducting joint research with Google's DeepMind lab, which was also working on its Alpha Go paper that introduced modern AI theory to the public for the first time.""Once you build this AI system, the system will automatically find new ideas for you, which completely frees up the human resources,"" she said. ""We don't need to hire hundreds of thousands of Ph.D.s like some of the second generation traditional quant funds do. Instead, we just build this system that will automatically do all the jobs of the Ph.D.s.""She added: ""In terms of business model, this is a good business model. In terms of the results, obviously, the results are quite good compared to traditional quantitative investing.""As the quant investing landscape evolves, Yao continues to upgrade the system and technology that support her hedge fund. Aside from work, she is also trying to support the industry by helping to groom the next generation of quants. ""Whenever I have time, I would actually go back to Columbia and attend some of the seminars they hold at the business school and statistics department,"" she said. ""Whenever I have the opportunity, I will go there and try to encourage more women to focus on science and mathematics.""",,,"[{'@type': 'WebPageElement', 'isAccessibleForFree': True, 'cssSelector': '.content-lock-content'}]",,,,,,,,,,An ex-hedge fund quant researcher whose firm uses AI to pick stocks breaks down how her fast-moving strateg...,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{'@type': 'Person', 'name': 'Akin Oyedele'}"
https://news.google.com/rss/articles/CBMiNmh0dHBzOi8vbS50aGVpbnZlc3Rvci5jby5rci92aWV3LnBocD91ZD0yMDIxMDEyMjAwMDY5MNIBAA?oc=5,Coupang stresses sound work environment - The Investor,2021-01-22,The Investor,https://m.theinvestor.co.kr,"South Korean e-commerce giant Coupang said Friday that it has strived to lower the work intensity of staff at its fulfillment centers through large-scale recruitment and investment in automation technology, amid criticism that its harsh work environment led to death of employees.   According to Coupang’s estimate, Coupang fulfillment centers has hired 28,451 workers as of end-2020, adding 12,484 workers to its ...",,"South Korean e-commerce giant Coupang said Friday that it has strived to lower the work intensity of staff at its fulfillment centers through large-scale recruitment and investment in automation technology, amid criticism that its harsh work environment led to death of employees.   According to Coupang’s estimate, Coupang fulfillment centers has hired 28,451 workers as of end-2020, adding 12,484 workers to its ...","South Korean e-commerce giant Coupang said Friday that it has strived to lower the work intensity of staff at its fulfillment centers through large-scale recruitment and investment in automation technology, amid criticism that its harsh work environment led to death of employees.   According to Coupang’s estimate, Coupang fulfillment centers has hired 28,451 workers as of end-2020, adding 12,484 workers to its ...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,

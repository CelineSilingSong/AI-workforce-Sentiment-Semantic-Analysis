URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,mainEntityOfPage,alternativeHeadline,hasPart,copyrightHolder,sourceOrganization,copyrightYear,isPartOf,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,@graph,speakable,articleBody,thumbnailUrl,dateCreated,alternateName,legalName,address,email,telephone,heading,isBasedOn,identifier,creator,mentions,leiCode,brand,dateline,uploadDate,duration,potentialAction,contentUrl,inLanguage,specialty,mainContentOFPage,associatedMedia,abstract,mainEntity,wordCount,genre,wordcount,comment,commentCount,publishingPrinciples,license
https://news.google.com/rss/articles/CBMif2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAxOC8xMS8xOS9pcy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1kYW5nZXJvdXMtNi1haS1yaXNrcy1ldmVyeW9uZS1zaG91bGQta25vdy1hYm91dC_SAQA?oc=5,Is Artificial Intelligence Dangerous? 6 AI Risks Everyone Should Know About - Forbes,2018-11-19,Forbes,https://www.forbes.com,"Discussions about AI often focus on its positive impacts for society while disregarding the more difficult and less-popular idea that AI could also potentially be dangerous. Just like any powerful tool, AI can be used for good and bad. Here are a few AI risks everyone should know about.",,"Discussions about AI often focus on its positive impacts for society while disregarding the more difficult and less-popular idea that AI could also potentially be dangerous. Just like any powerful tool, AI can be used for good and bad. Here are a few AI risks everyone should know about.","Discussions about AI often focus on its positive impacts for society while disregarding the more difficult and less-popular idea that AI could also potentially be dangerous. Just like any powerful tool, AI can be used for good and bad. Here are a few AI risks everyone should know about.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2018/11/19/is-artificial-intelligence-dangerous-6-ai-risks-everyone-should-know-about/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2018/11/AdobeStock_171462504-1200x675.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Is Artificial Intelligence Dangerous? 6 AI Risks Everyone Should Know About,2018-11-19T00:20:00-05:00,2021-12-10T08:30:39-05:00,Enterprise & Cloud,Is Artificial Intelligence Dangerous? 6 AI Risks Everyone Should Know About,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise TechIs Artificial Intelligence Dangerous? 6 AI Risks Everyone Should Know AboutBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 19, 2018,12:20am ESTUpdated Dec 10, 2021, 08:30am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinShould we be scared of artificial intelligence (AI)?
Some notable individuals such as legendary physicist Stephen Hawking and Tesla and SpaceX leader and innovator Elon Musk suggest AI could potentially be very dangerous; Musk at one point was comparing AI to the dangers of the dictator of North Korea. Microsoft co-founder Bill Gates also believes there’s reason to be cautious, but that the good can outweigh the bad if managed properly. Since recent developments have made super-intelligent machines possible much sooner than initially thought, the time is now to determine what dangers artificial intelligence poses.









Adobe Stock
Adobe Stock





What is applied and general artificial intelligence?
At the core, artificial intelligence is about building machines that can think and act intelligently and includes tools such as Google's search algorithms or the machines that make self-driving cars possible. While most current applications are used to impact humankind positively, any powerful tool can be wielded for harmful purposes when it falls into the wrong hands. Today, we have achieved applied AI—AI that performs a narrow task such as facial recognition, natural language processing or internet searches. Ultimately, experts in the field are working towards artificial general intelligence, where systems can handle any task that intelligent humans could perform, and most likely beat us at each of them.
PROMOTED
In a comment, Elon Musk wrote: ""The pace of progress in artificial intelligence (I'm not referring to narrow AI) is incredibly fast. Unless you have direct exposure to groups like Deepmind, you have no idea how fast—it is growing at a pace close to exponential. The risk of something seriously dangerous happening is in the five-year timeframe. 10 years at most.”






There are indeed plenty of AI applications that make our everyday lives more convenient and efficient. It's the AI applications that play a critical role in ensuring safety that Musk, Hawking, and others were concerned about when they proclaimed their hesitation about the technology. For example, if AI is responsible for ensuring the operation of our power grid and our worst fears are realized, and the system goes rogue or gets hacked by an enemy, it could result in massive harm.
How can artificial intelligence be dangerous?
While we haven’t achieved super-intelligent machines yet, the legal, political, societal, financial and regulatory issues are so complex and wide-reaching that it’s necessary to take a look at them now so we are prepared to safely operate among them when the time comes. Outside of preparing for a future with super-intelligent machines now, artificial intelligence can already pose dangers in its current form. Let’s take a look at some key AI-related risks.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Autonomous weapons
AI programmed to do something dangerous, as is the case with autonomous weapons programmed to kill, is one way AI can pose risks. It might even be plausible to expect that the nuclear arms race will be replaced with a global autonomous weapons race. Russia’s president Vladimir Putin said: “Artificial intelligence is the future, not only for Russia, but for all humankind. It comes with enormous opportunities, but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the ruler of the world.”
Aside from being concerned that autonomous weapons might gain a “mind of their own,” a more imminent concern is the dangers autonomous weapons might have with an individual or government that doesn’t value human life. Once deployed, they will likely be difficult to dismantle or combat.
Social manipulation
Social media through its autonomous-powered algorithms is very effective at target marketing. They know who we are, what we like and are incredibly good at surmising what we think. Investigations are still underway to determine the fault of Cambridge Analytica and others associated with the firm who used the data from 50 million Facebook users to try to sway the outcome of the 2016 U.S. presidential election and the U.K.'s Brexit referendum, but if the accusations are correct, it illustrates AI's power for social manipulation. By spreading propaganda to individuals identified through algorithms and personal data, AI can target them and spread whatever information they like, in whatever format they will find most convincing—fact or fiction.
Invasion of privacy and social grading
It is now possible to track and analyze an individual's every move online as well as when they are going about their daily business. Cameras are nearly everywhere, and facial recognition algorithms know who you are. In fact, this is the type of information that is going to power China's social credit system that is expected to give every one of its 1.4 billion citizens a personal score based on how they behave—things such as do they jaywalk, do they smoke in non-smoking areas and how much time they spend playing video games. When Big Brother is watching you and then making decisions based on that intel, it’s not only an invasion of privacy it can quickly turn to social oppression.
Misalignment between our goals and the machine’s
Part of what humans value in AI-powered machines is their efficiency and effectiveness. But, if we aren’t clear with the goals we set for AI machines, it could be dangerous if a machine isn’t armed with the same goals we have. For example, a command to “Get me to the airport as quickly as possible” might have dire consequences. Without specifying that the rules of the road must be respected because we value human life, a machine could quite effectively accomplish its goal of getting you to the airport as quickly as possible and do literally what you asked, but leave behind a trail of accidents.
Discrimination
Since machines can collect, track and analyze so much about you, it’s very possible for those machines to use that information against you. It’s not hard to imagine an insurance company telling you you’re not insurable based on the number of times you were caught on camera talking on your phone. An employer might withhold a job offer based on your “social credit score.”
Any powerful technology can be misused. Today, artificial intelligence is used for many good causes including to help us make better medical diagnoses, find new ways to cure cancer and make our cars safer. Unfortunately, as our AI capabilities expand we will also see it being used for dangerous or malicious purposes. Since AI technology is advancing so rapidly, it is vital for us to start to debate the best ways for AI to develop positively while minimizing its destructive potential.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vd3d3LmJiYy5jb20vZnV0dXJlL2FydGljbGUvMjAxODExMTUtYS1ndWlkZS10by1ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaXMtY2hhbmdpbmctdGhlLXdvcmxk0gEA?oc=5,The A-Z of how artificial intelligence is changing the world - BBC.com,2018-11-19,BBC.com,https://www.bbc.com,Artificial intelligence can no longer be considered a technology of the future – it is already shaping our everyday lives. Here is our guide to understanding the minds of machines.,,Artificial intelligence can no longer be considered a technology of the future – it is already shaping our everyday lives. Here is our guide to understanding the minds of machines.,Artificial intelligence can no longer be considered a technology of the future – it is already shaping our everyday lives. Here is our guide to understanding the minds of machines.,https://schema.org,NewsArticle,,['https://ychef.files.bbci.co.uk/1280x720/p06rz07p.jpg'],"{'@type': 'Person', 'name': 'Richard Gray', 'url': ''}","{'@type': 'Organization', 'name': 'BBC'}",The A-Z of how artificial intelligence is changing the world,2018-11-19T12:48:06.000Z,2022-02-24T18:16:14.397Z,,,,,,,"The A-Z of how artificial intelligence is changing the world19 November 2018By Richard Gray, @chalkmark, Features correspondentShareAlamyFacial recognition systems have been shown to misidentify black faces and often fail to see women's faces at all (Credit: Alamy)Artificial intelligence can no longer be considered a technology of the future – it is already shaping our everyday lives. Here is our guide to understanding the minds of machines.Getty ImagesFor many, the true test lies in areas where humans excel – such as complex reasoning, creativity and understanding (Credit: Getty Images)Since the early days of computers, scientists have strived to create machines that can rival humans in their ability to think, reason and learn – in other words, artificial intelligence.While today’s AI systems still fall short of that goal, they are starting to perform as well as, and sometimes better than, their creators at certain tasks. Thanks to new techniques that allow machines to learn from enormous sets of data, AI has taken massive leaps forward.AI is starting to move out of research labs and into the real world. It is having an impact on our lives. There can be little doubt that we are entering the age of artificial intelligence.(Image credit: Getty Images)AlamyFacial recognition systems have been shown to misidentify black faces and often fail to see women's faces at all (Credit: Alamy)As AI enters the real world by assessing loan applications, informing courtroom decisions or helping to identify patients who should receive treatment, so too does one of its most fundamental flaws: bias.Algorithms are only as good as the code that governs them and the data used to teach them. Each can carry the watermark of our own preconceptions. Facial recognition software can misclassify black faces or fail to identify women, criminal profiling algorithms have ranked non-whites as higher risk and recruitment tools have scored women lower than men.But with these challenges, there has been mounting pressure on technology giants to fix them.(Image credit: Alamy)Getty ImagesChatbots are one of the most visual forms of AI in our lives (Credit: Getty Images)These talkative machines use the power of two branches of AI, natural language processing and natural language generation, to interact with human users. They appear on social media feeds, customer service pages and websites to provide conversation, advice and companionship – and they are transforming the way we interact with organisations including utilities companies, adult websites, pizza delivery firms, online stores, banks and even governments.(Image credit: Getty Images)0:26d is for… designDesigning new components for cars or aircraft is a slow, painstaking process, but artificial intelligence can generate millions of innovative new shapes and configurations in just a few hours. With a few simple instructions, the algorithm produced new highly efficient designs for a drone in the video above. Companies like General Motors and Airbus are among those using AI to help them design new components. (Video credit: AutoDesk, Inc)Getty ImagesPredicting where and when the next migration crisis is likely to occur will allow aid agencies get help where it is needed faster (Credit: Getty Images)The world is witnessing its worst humanitarian crisis on record: an estimated 68.5 million people are currently displaced from their homes by drought, famine or war.But artificial intelligence could help. Researchers working with the UN have been building algorithms that can use data on energy generation, economic growth, population size and food production to predict where future migration crises may occur.Others, such as the Alan Turing Institute in the UK and the US’s Political Instability Task Force, have been building AI capable of predicting where future conflicts may occur. Using statistical data, military reports and analysing news reports for signs of rising tensions, their machines can estimate the likelihood of violence escalating in trouble spots.(Image credit: Getty Images)Getty ImagesChelsea Football Club is working with researchers to use artificial Intelligence to help players make better decisions on the football pitch (Credit: Getty Images)The result of a football match can hang on a single split-second decision made by a player. If the athlete had chosen to pass the ball rather than shoot at goal, for example, their team’s fortunes may have changed dramatically.Researchers working with one of the Premier League’s biggest clubs, Chelsea FC, are using AI to help analyse these crucial player decisions to predict what might have happened if they had done something different. They hope this will help the team learn how to make better decisions during a match, and perhaps even win more games.(Image credit: Getty Images)NvidiaThese people do not exist, but were dreamed up by a generative adversarial network that can create images entirely from scratch (Credit: Nvidia)None of these people exist. They may appear to have the well-honed features of celebrities, but in fact these faces have been dreamed up by a type of AI computer system known as a generative adversarial network, or Gan.As the name suggests, these are comprised of algorithms that work in opposition to each other. One is trained on a set of data – in this case celebrity photos – which it uses to produce its own versions. A second computer network then judges the work to see if it can spot differences between the computer-generated images and the originals. In response, the first network tweaks how it produces its celebrity photos in an attempt to fool the other network. The result is an ever more realistic set of images.(Image credit: Nvidia)0:27The magic of GansWhile early Gan-generated images were low resolution messes that regularly produced pictures of faces with too many eyes or melted-looking features, as this video illustrates, they can now able to 'grow' realistic photo-quality images over time. (Video credit: Nvidia)MITBy tweaking the surface texture, a turtle can be made to look like a gun to a machine vision system (Credit: MIT)While the capabilities of machines have taken a leap forward in recent years, they still get things wrong in hilarious, and sometimes concerning, ways. Take the AI Tetris-playing bot that decided the best way to avoid losing was to indefinitely pause the game.Others can be fooled in baffling ways. Scientists at the Massachusetts Institute of Technology recently demonstrated that popular machine vision algorithms used to identify objects in images and camera footage can be fooled into thinking a model of a sea turtle is a rifle, or a baseball is an espresso. They did this by subtly changing the texture of the objects so they look like one thing to our eyes – but like something else to the machines.“There is a concern that if real-world systems ­– the machine vision in a self-driving car, for example – were attacked in this way, it could cause real harm,” warns Anish Athalye, the researcher who led the study.(Image credit: MIT)Helena SarinArtists are using artificial intelligence to generate strange and unusual images (Credit Helena Sarin)One thing that has become clear as machine learning is used more frequently is that machines see the world very differently from us. While humans intuitively absorb knowledge about how the world works from birth, machines have to be specifically taught these rules. But freed from these constraints, they also produce some wild visions that are helping to inspire artists, musicians and filmmakers.Machine vision researcher and artist Helena Sarin feeds her own drawings to a Gan (see g is for...) which then produces strangely beautiful images like those shown here.Image credit: (Helena Sarin)Getty ImagesPredicting where traffic jams and accidents will occur with AI should help to keep roads clear of snarl ups (Credit: Getty Images)The ebb and flow of traffic on busy roads and cities is difficult to predict. It varies with human behaviour, road conditions, time of day and year, weather and accidents.But by analysing vast amounts of information quickly, AI is being tested to keep traffic flowing more smoothly by taking control of traffic signals, predicting accidents and forecasting potential snarl ups.(Image credit: Getty Images)Maeve/RavelryKnitting patterns generated by AI are pretty strange looking (Credit: Maeve/Ravelry)Trained on existing patterns, artificial intelligence is being used to create new fashion and textile designs. One imaginatively named experiment, called SkyKnit, has created bizarre tentacle-strewn knitting patterns with unique stitches that have gathered their own cult following.(Image Credit: Maeve/Ravelry)FacebookTwo chatbots created by Facebook communciated with each other in their own shorthand language (Credit: Facebook)Our ability to communicate with the spoken and written word is among the defining features of our species. A branch of machine learning that trains algorithms to understand and reproduce language is threatening that position.Natural language generation algorithms can now turn reams of sports statistics or financial data into succinct news stories. They are being used to produce marketing copy. Some have been trained to write their own fairytales, mimic Shakespeare and even compose poems. In most cases, the text they produce is nonsense, but in others it has become a strange art form in its own right.Perhaps more intriguing still is what happens when AIs talk to each other. In the case of two negotiating chatbots created by Facebook, they began to communicate in their own strange language.(Image credit: Facebook)Getty ImagesNeural networks are modelled on the structures in the human brain (Credit: Getty Images)While other approaches to developing AI exist, machine learning has largely powered much of the recent leaps and bounds in the field. It is designed to loosely mimic the way humans themselves gather knowledge – through learning. But while humans can pick up patterns or a skill from just a few examples, machines require vast amounts of data.Reams of information are fed to webs of code that form connections between different parts of the network as it identifies patterns, giving it the ability to interpret future data.n is for… neural networksTo create machines that can think like humans, computer scientists have understandably turned to nature to solve the problem, creating algorithms that mimic the structure of the brain. To do this, they are creating networks of algorithms designed to act like the neurons in the brain. Connections between these mathematical neurons form to create clusters as the machine learns.(Image credit: Getty Images)Getty ImagesThe signs of alzheimer's disease can be spotted in brain scans by artificial intelligence years before diagnosis (Credit: Getty Images)While spotting patterns that might otherwise elude human eyes is an area where machines excel, some of the most exciting areas of AI lie in their ability to predict the future too.A growing suite of AI-powered applications that can spot cancers or the early signs of eye disease are being used by doctors around the world, but recently researchers showed that AI can also predict whether someone might suffer conditions like Alzheimer’s disease years before they show any symptoms.(Image credit: Getty Images)Getty ImagesPolice are using AI to help them catch criminals (Credit: Getty Images)Police forces around the world are testing AI systems that could help them to catch more criminals faster. In the UK, for example, one force is trialling a facial recognition system that can identify a suspect from just a portion of their face, such as an ear. Another system developed in Spain scours crime scene photographs for signs of evidence that can link crimes.AI systems are also being used to help police and courts make decisions about whether a suspect should be held in custody or released on bail by predicting their risk of committing other offences.(Image credit: Getty Images)Getty ImagesEarthquake aftershocks can be accurately predicted using AI (Credit: Getty Images)Like other natural disasters, earthquakes are notoriously difficult to predict. But computers deploying deep learning – a form of machine learning – can predict the location of devastating aftershocks that often cause further death and destruction.(Image credit: Getty Images)Getty ImagesNatural language generation is allowing machines to produce real-sounding rap lyrics (Credit: Getty Images)A foul-mouthed, slang-slinging silicon lyricist, Deep-flow is a rhyme-busting AI that can spit out rap lyrics so fluently, it can be hard to distinguish from the real deal.(Image credit: Getty Images)Getty ImagesAI is already creeping into our homes in the form of voice-activated assistants and in our phones, but its potential goes far beyond simply answering questions. As more appliances and devices are connected to home networks, AI can be used to manage them. Smart thermostats powered by AI can tune your heating to your lifestyle, while sensors that analyse data from your home electricity metre can identify a distinct ‘fingerprint’ of each appliance that can be identified to help switch off power-hungry devices when not in use.Getty ImagesThe Turing test for machine intelligence was thought up by Alan Turing (Credit: Getty Images)Developed by computing pioneer Alan Turing, the Turing test is considered to be one of the key measures of artificial intelligence. Turing suggested that a way of testing a machine’s ‘intelligence’ would be its ability to fool a human into thinking it was human. In some areas, this has arguably been achieved, with chatbots that can convincingly converse with humans or write realistic looking online reviews. But some critics point out that the Turing Test doesn’t measure true intelligence – only the ability to mimic it.u is for… unsupervised learningEarly forms of machine learning used data such as images that had been painstakingly labelled to help algorithms identify the objects they contained. But more recently researchers have been using another approach. Unsupervised learning allows the algorithms to draw their own inferences by looking for patterns in the data they are given.(Image credit: Getty Images)Efficient Vineyard ProjectBy analysing grape quality and foliage levels on vines with machine vision, AI algorithms can help managers improve wine quality (Credit: Efficient Vineyard Project)Machine vision algorithms allow computers to recognise everything from faces to cats and galaxies in images or video footage. But in the US and Europe, researchers are combining machine vision with other AI systems to help farmers better manage their crops.These projects are using robots to trundle through vineyards to monitor the vines and identify plants that need to be pruned or have their fruit removed to ensure the best quality grapes for producing wine.(Image credit: Efficient Vineyard Project)Getty ImagesMachine vision can spot poachers from drone footage, helping to prevent wildlife crime (Credit: Getty Images)With the vast areas of dense vegetation covering East Africa, poachers frequently melt away undetected after killing their prey. Patrolling the skies overhead with drones, however, has allowed conservationists to use machine vision systems to spot poachers in infrared footage. Other systems use AI to monitor endangered species with the help of mosquitoes or to track illegal wildlife goods, such as ivory and rhino horns, on social media.(Image credit: Getty Images)Getty ImagesAritificial intelligence is being used to help track illegal activity online (Credit: Getty Images)Forget creepy looking sex-robots, intelligent sex toys or seductive chatbots. Artificial intelligence is being put to use against the darker side of the sex industry. Investigators are using it to scour the internet for signs of illegal sex rings or to track down victims of human traffickers who have ended up as sex slaves. (Image credit: Getty Images)Moley RoboticsThe Moley robotic chef can now cook hundreds of different meals from a catalogue of recipes (Credit: Moley Robotics)From creating unusual (and sometimes disgusting) new recipes to physically taking over duties in front of the stove, electronic chefs are already cooking up changes in the kitchen.(Image credit: Moley Robotics)GettyMarwell Zoo near Winchester, England, is using AI to manage the heating system to keep its Nyala antelope warm in the winter (Credit: Getty Images)Nyala antelope are native to the hot, dry savanna of southern Africa. So when winter arrives at Marwell Zoo near Winchester, England, they can find it a little chilly. To compensate, the zoo has installed an experimental heater system that uses infrared sensors and machine learning to keep the animals comfortable inside.(Image credit: Getty Images)Artificial intelligence",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vd3d3Lm1hcmtldGluZ3dlZWsuY29tL2xleHVzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFkdmVydC_SAQA?oc=5,How Lexus programmed a machine to write the world's first AI-scripted ad - Marketing Week,2018-11-16,Marketing Week,https://www.marketingweek.com,"Lexus used data on 15 years of award-winning luxury campaigns, as well as information about the brand and human emotion to create a 60-second film that tells the story of a car that comes to life and will inevitably lead to questions about whether artificial intelligence can do the same creative job as humans.",,"Lexus used data on 15 years of award-winning luxury campaigns, as well as information about the brand and human emotion to create a 60-second film that tells the story of a car that comes to life and will inevitably lead to questions about whether artificial intelligence can do the same creative job as humans.","Lexus used data on 15 years of award-winning luxury campaigns, as well as information about the brand and human emotion to create a 60-second film that tells the story of a car that comes to life and will inevitably lead to questions about whether artificial intelligence can do the same creative job as humans.",https://schema.org,NewsArticle,,"{'@type': 'ImageObject', 'url': 'https://marketingweek.imgix.net/content/uploads/2018/11/16115601/Lexus-AI.jpg', 'width': 1240, 'height': 1040}","{'@type': 'Person', 'name': 'Ellen Hammett', 'url': 'https://www.marketingweek.com/author/ellen-hammett/'}","{'@type': 'Organization', 'name': 'Marketing Week', 'logo': {'@type': 'ImageObject', 'url': 'https://marketingweek.imgix.net/content/uploads/2019/06/24112104/MW_2019_FAVICON_228-2.png?auto=compress,format&#038;q=60&#038;w=60&#038;h=60', 'width': 60, 'height': 60}}",How Lexus programmed a machine to write the world's first AI-scripted ad,2018-11-16T12:48:05+00:00,2018-11-19T12:04:50+00:00,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.marketingweek.com/', 'name': 'Marketing Week | marketing news, opinion, trends and jobs'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.marketingweek.com/category/uncategorized/', 'name': 'Uncategorized'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.marketingweek.com/lexus-artificial-intelligence-advert/', 'name': 'How Lexus programmed a machine to write the world&#8217;s first AI-scripted ad'}}]",,,"
 How Lexus programmed a machine to write the world’s first AI-scripted ad Lexus used data on 15 years of award-winning luxury campaigns, as well as information about the brand and human emotion to create a 60-second film that tells the story of a car that comes to life and will inevitably lead to questions about whether artificial intelligence can do the same creative job as humans.
 



		By Ellen Hammett 


16 Nov 2018
12:48 pm








X





Facebook





LinkedIn






Lexus has created the first ever advert scripted entirely by artificial intelligence – a dramatic 60-second film that tells the story of a car that comes to life to mark the launch of its new ES executive saloon car.
Like Frankenstein’s Monster, the ad begins with a Lexus engineer admiring his creation. He looks on and sheds a tear as the car is taken away and threatened with destruction, taking to the open and stormy roads before being shackled and readied for an imminent crash test that is being broadcast live on TV while its owner watches in suspense.
It is the car’s automatic emergency braking system that saves the day, demonstrating one of the main technological features built into the ES model.
The production process, which Lexus says took no longer than a normal campaign (around six months from brief to output), involved developing the bespoke AI and training it with data including 15 years of award-winning luxury adverts, emotional intelligence about what connects most strongly with viewers and specially commissioned information about human intuition.

To avoid the risk of producing something that felt too familiar or too mass market in tone, additional data on the Lexus brand and the project guideline were inputted into the AI to keep the script original and on-brand.
Directed by Oscar winner Kevin Macdonald, whose work includes The Last King of Scotland and Whitney Houston biopic Whitney, the ad was built by technical partner Visual Voice in collaboration with Lexus’s creative agency The&Partnership, with support from IBM Watson.
Man vs machine
While there are “narrative leaps” that wouldn’t pass in the cinema, the film largely makes sense and Lexus says it didn’t have to change much. And the more Lexus uses AI, the quicker it believes the creative process will become.
Perhaps most disconcertingly, the ad resonates on a very human level, raising the possibility that while a computer might not be able to understand human emotions, it has the capacity to replicate them and create an emotional connection.
But Lexus’s brand general manager, Michael Tripp, says this doesn’t mean creative agencies are going to be made redundant in favour of machines.

Philosophically, could this cut out or change the creative aspect of this process? Yes.
Michael Tripp, Lexus

Speaking to Marketing Week at the ad’s premier yesterday (15 November), Tripp explains: “Our ambition under this umbrella is not to replace the human element but to augment it.  Philosophically, could this cut out or change the creative aspect of this process? Yes. But our strategy at Lexus is we believe in man plus machine.
“I could never ask you to go look at 15 years of award-winning films and give me that data but I can now get that and use it to inform our creative.”
Lexus already has a neurological sensor built into one of its cars that measures the temperature of somebody’s face and adjusts the temperature of the car accordingly. It is this kind of information Tripp believes will allow machines to create human emotions more accurately in future.

“I don’t think it’s an understanding of the emotion,” he says. “If we connected you to neurological sensors, or if we could take that information and put it into some kind of objective information then yes. The real question is moving from objectivity to subjectivity and this is where I’ve yet to see that’s possible.
“It wouldn’t be reading your emotion, it would be the fact your heart beat increased or maybe you perspire. And this becomes objective data which can then be used to learn, adjust and adapt.”
In terms of effectiveness, Tripp says Lexus is most interested in the organic response. “Anything that happens online or on social we typically see a return of 2% to 5%,” he says.
“For me, what we can use is organic and sentiment to see what people think before we start putting paid behind it. So we have a little bit of this luxury and that’s how we’ll measure it, as well as post testing.”
The film will be unveiled on Monday (19 November) across Europe in cinemas and on digital and social channels.






X





Facebook





LinkedIn




News Advertising Automotives Data & Analytics Toyota
","{'@type': 'WebPage', '@id': 'https://www.marketingweek.com/lexus-artificial-intelligence-advert/'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LmhlYWx0aGNhcmVmaW5hbmNlbmV3cy5jb20vbmV3cy93aHktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utd29udC1yZXBsYWNlLWRvY3RvcnPSAQA?oc=5,Why artificial intelligence won't replace doctors - Healthcare Finance News,2018-11-19,Healthcare Finance News,https://www.healthcarefinancenews.com,"While AI has already shown promise in automating certain tasks, it doesn't seem likely that it will replace flesh-and-blood clinicians anytime soon.",,"While AI has already shown promise in automating certain tasks, it doesn't seem likely that it will replace flesh-and-blood clinicians anytime soon.","While AI has already shown promise in automating certain tasks, it doesn't seem likely that it will replace flesh-and-blood clinicians anytime soon.",,,,,,,,,,,,,,,,"


Nov 19, 2018
More on Workforce

Why artificial intelligence won't replace doctors

        While AI has already shown promise in automating certain tasks, it doesn't seem likely that it will replace flesh-and-blood clinicians anytime soon.      







Jeff Lagasse, Editor










 

Artificial intelligence is coming to healthcare. In fact, in areas such as radiology and cancer detection, it's already here in places, and is poised to become ever more prevalent in the industry. Which naturally raises a question for nurses and physicians: Is AI coming for my job?
Well, probably not. At least according to experts we interviewed for our Focus on Artificial Intelligence.
That said, both AI and machine learning are in a prime position to alter clinical workflows and physician training. And with the market growing the way it is, implementation is inevitable. A recent Accenture report estimated that the AI health market will hit $6.6 billion by 2021. That's up from $600 million in 2014.
Artificial intelligence and machine learning algorithms tend to rely on large quantities of data to be effective, and that data needs human hands to collect it and human eyes to analyze it. And since AI in healthcare is currently utilized mainly to aggregate and organize data -- looking for trends and patterns and making recommendations -- a human component is very much needed.
So physicians and nurses don't have to worry. Probably. At least for now.
WHAT THE EXPERTS THINK
PeriGen CEO Matthew Sappern puts no stock in the theory that clinicians' jobs are in jeopardy. Instead, he looks at AI more as an empowerment tool.
""I think it does things that are really imperative that are not necessarily what nurses can do,"" he said. ""These tools are not so great where reasoning and empathy are required. You teach them to do something, and they will do it over and over and over again, period. They're good tools to provide perspective, but it's all about the provider or nurse who's making sense of that information.""
In many ways, said Sappern, AI can help nurses focus more on the actual job of nursing, and focus more on the abstract things that can truly impact patient care. And it has the potential to increase their confidence, as they can report back to the doctor with hard stats instead of vagaries. Used wisely and it can be a boon to fact-based clinical observation.
Jvion Chief Product Officer Dr. John Showalter was equally dismissive of claims that jobs are in jeopardy. The hype is scary, he said. The reality is not.
""There are great benefits that do amazing things for patients,"" said Showalter. ""When you come in and improve the scoring for falls, for example, and you understand what needs to be done to prevent falls, that's ready for prime time today.
""There absolutely places where AI is ready to go today, and then there's a whole bunch of AI hype that's really scary, so sorting out the AI that's ready to help patients and the hype can be really difficult for leadership.
Sappern and Showalter's opinions mirror the conclusions of an article appearing this year in The Conversation analyzing the potential effect of AI, or lack thereof, on high-skilled jobs.
USING AI AS A TOOL
In the analysis the author notes that innovations in various industrial revolutions have always created new jobs even as they've taken old jobs away; what makes the AI revolution different is that it has the potential to affect white-collar jobs.
No need for alarms to go off, though, at least not initially, since AI in healthcare would primarily affect lower-skilled office work, like data processing. Though highly trained professionals could also be affected, the switch so far seems to be happening in a way that shows AI to be a tool more so than a threat, as professionals can now learn how to benefit from its powerful predictive powers.
In some cases, the technology could be used to help fill the physician shortage that is even now gripping many parts of the country, and is expected to get worse.
Eldon Richards, chief technology officer at Recondo Technologies, said AI is now addressing a lot of repetitive tasks that a human might do today.
""If reviewing the ethics of a decision, or complex data or one-off decision, AI is not good at those today,"" said Richards. ""Ai is very far off when it comes to those capabilities. The mundane, routine things we do, like typing in a word processor, AI us simplifying those things for us, so now we're shifting our focus from these simple tasks to things that require a little more training. I certainly do not see unemployment going up.""
That sentiment is echoed by Mary Sun, AI researcher at First Derm and medical student at Mount Sinai Medical Center.
""People see it as a job replacement thing and I think that's a pretty flawed way to look at it,"" she said. ""In many other industries, like when I was in commercial tech, it's viewed much more as an augmentation, and piece of mind, and double checking and making sure that you're involving patterns that one doctor cannot possibly see.
	""As one doctor, you can't possibly see a million patients across your lifetime. But medicine, at least diagnosis, is all in the pattern recognition. So I think it's going to be very exciting when we find ways to augment our diagnoses and make them a lot more robust.""
Carlo Perez, CEO of Swift Medical, feels similarly, viewing AI as augmentative tool. While it may alter the role of a doctor somewhat, it won't replace them entirely.
""What we feel is the doctor will transition into someone who understands how to wield data science, who understands how to use these tools,"" said Perez. ""Hopefully someone will not need to truly understand AI, but will understand their relationship to it. Which is, 'I can utilize these tools, I understand these tools, and I understand how to utilize them in partnership to make better decisions.'""


		Focus on Artificial Intelligence
In November, we take a deep dive into AI and machine learning.


Twitter: @JELagasse
	Email the writer: jeff.lagasse@himssmedia.com
 


 
News



Healthcare organizations ask HHS to delay quality measure reporting for ACOs

The American Hospital Association and American Medical Association are among the 11 organizations signing the letter.



Ending racism in healthcare often begins with medical education - and is the target of a new national project

Inequities can be found in every facet of the industry, but targeting medical students and residents can help stem the tide.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vd3d3LmltZi5vcmcvZW4vQmxvZ3MvQXJ0aWNsZXMvMjAxOC8xMS8xNi9ibG9nLVdvbWVuLVRlY2hub2xvZ3ktdGhlLUZ1dHVyZS1vZi1Xb3Jr0gEA?oc=5,"Women, Technology, and the Future of Work - International Monetary Fund",2018-11-16,International Monetary Fund,https://www.imf.org,,,,,,,,,,,,,,,,,,,,"




November 16, 2018
عربي, 中文, Español, Français, 日本語, Português, Русский

[caption id=""attachment_25011"" align=""alignnone"" width=""1024""] Women are currently underrepresented in fields experiencing job growth, such as engineering and information and communication technology (photo: Vgajic/iStock by Getty Images)[/caption]

The way we work is changing at an unprecedented rate. Digitalization, artificial intelligence, and machine learning are eliminating many jobs involving low and middle-skill routine tasks through automation.
Our new research finds the trend toward greater automation will be especially challenging for women.

More than ever, women will need to break the glass ceiling.

On average, women face an 11 percent risk of losing their jobs due to automation, compared to 9 percent of their male counterparts. So while many men are losing their jobs to automation, we estimate that 26 million women’s jobs in 30 countries are at high risk of being displaced by technology within the next 20 years. We find that women’s jobs have a 70 percent or higher probability of automation. This translates globally to 180 million women’s jobs.
We must understand the impact of these trends on women’s lives if we are to gain gender equity in the work place.
What policies can countries implement now to ensure that women contribute to the economy, while moving toward greater automation?
Women at higher risk 
Hard-won gains from policies to increase the number of women in the paid workforce and to increase women’s pay to equal men’s may be quickly eroded if women work predominantly in sectors and occupations that are at high risk of being automated.

Women who are 40 and older, and those in clerical, service, and sales positions are disproportionately at risk.
Nearly 50 percent of women with a high school education, or less, are at high risk of their jobs being automated, compared to 40 percent of men. The risk for women with a bachelor’s degree or higher is 1 percent.



The chart below shows how the automation of jobs effects people in different countries. Men and women in the United Kingdom and the United States face about the same amount of risk for job automation. In Japan and Israel, women’s jobs are more vulnerable to automation than men’s. Women’s jobs in Finland are less vulnerable to automation than men’s.

Opportunities and challenges 
Women are currently underrepresented in fields experiencing job growth, such as engineering and information and communications technology. In tech, women are 15 percent less likely than men to be managers and professionals, and 19 percent are more likely to be clerks and service workers performing more routine tasks, which leaves women at a high risk of displacement by technology.
More than ever, women will need to break the glass ceiling. Our analysis shows that differences in routineness of job tasks exacerbate gender inequality in returns to labor. Even after taking into account such factors as differences in skill, experience and choice of occupation, nearly 5 percent of the wage gap between women and men is because women perform more routine job tasks. In the US this means women forfeit $26,000 in income over the course of their working life.
There are some bright spots. In advanced and emerging economies, which are experiencing rapid aging, jobs are likely to grow in traditionally female-dominated sectors such as health, and social services―jobs requiring cognitive and interpersonal skills and thus less prone to automation. Coping with aging populations will require both more human workers and greater use of artificial intelligence, robotics, and other advanced technologies to complement and boost productivity of workers in healthcare services.
Policies that work
Governments need to enact policies that foster gender equality and empowerment in the changing landscape of work:

Provide women with the right skills. Early investment in women in STEM fields, like the program Girls Who Code in the US, along with peer mentoring, can help break down gender stereotypes and increase women in scientific fields. Tax deductions for training those already in the workforce, like in the Netherlands, and portable individual learning accounts, like in France, could help remove barriers to lifelong learning.
Close gender gaps in leadership positions. Providing affordable childcare and replacing family taxation with individual taxation, like in Canada and Italy, can play an important role in boosting women’s career progression. Countries can set relevant recruitment and retention targets for organizations, as well as promotion quotas, like in Norway, and establish mentorship and training programs to promote women into managerial positions.
Bridge the digital gender divide. Governments have a role to play through public investment in capital infrastructure and ensuring equal access to finance and connectivity, like in Finland.
Ease transitions for workers. Countries can support workers as they change jobs because of automation with training and benefits that are linked to individuals rather than jobs, like the individual training accounts in France and Singapore. Social protection systems will need to adapt to the new forms of work. To address deteriorating income security associated with rapid technological change, some countries may consider expansion of non-contributory pensions and adoption of basic income guarantees may be warranted.

Automation has made it even more urgent to step up efforts to level the playing field between men and women, so that all have equal opportunities to contribute to, and benefit from, the new more technology-enabled world.

Related Links:
Technology, and the Future of Work 
Economic Gains from Gender Inclusion
Women in Finance: An Economic Case for Gender Equality
Chart of the Week: Equal Pay Remains a Global Issue
Gender and the IMF


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMTEvMTgvdGVjaG5vbG9neS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1sYW5ndWFnZS5odG1s0gEA?oc=5,"Finally, a Machine That Can Finish Your Sentence (Published 2018) - The New York Times",2018-11-18,The New York Times,https://www.nytimes.com,Completing someone else’s thought is not an easy trick for A.I. But new systems are starting to crack the code of natural language.,,Completing someone else’s thought is not an easy trick for A.I. But new systems are starting to crack the code of natural language.,Completing someone else’s thought is not an easy trick for A.I. But new systems are starting to crack the code of natural language.,https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/11/19/business/19LANGUAGE/00LANGUAGE-videoSixteenByNineJumbo1600.jpg', 'height': 591, 'width': 1050, 'contentUrl': 'https://static01.nyt.com/images/2018/11/19/business/19LANGUAGE/00LANGUAGE-videoSixteenByNineJumbo1600.jpg', 'creditText': 'Nicolas Ortega'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/11/19/business/19LANGUAGE/TEST-superJumbo.gif', 'height': 1350, 'width': 1050, 'contentUrl': 'https://static01.nyt.com/images/2018/11/19/business/19LANGUAGE/TEST-superJumbo.gif', 'creditText': 'Nicolas Ortega'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/cade-metz', 'name': 'Cade Metz'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","Finally, a Machine That Can Finish Your Sentence",2018-11-18T21:05:16.000Z,2018-11-18T21:05:16.000Z,,The New York Times,False,,Technology,,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingCredit...Nicolas OrtegaSkip to contentSkip to site indexSearch & Section NavigationSection NavigationFinally, a Machine That Can Finish Your SentenceCompleting someone else’s thought is not an easy trick for A.I. But new systems are starting to crack the code of natural language.Credit...Nicolas OrtegaSupported bySKIP ADVERTISEMENTShare full articleRead in appBy Cade MetzNov. 18, 2018In August, researchers from the Allen Institute for Artificial Intelligence, a lab based in Seattle, unveiled an English test for computers. It examined whether machines could complete sentences like this one:On stage, a woman takes a seat at the piano. Shea) sits on a bench as her sister plays with the doll.b) smiles with someone as the music plays.c) is in the crowd, watching the dancers.d) nervously sets her fingers on the keys.Subscribe to The Times to read as many articles as you like.Follow Cade Metz on Twitter: @CadeMetz. A version of this article appears in print on Nov. 19, 2018, Section B, Page 3 of the New York edition with the headline: Finally, a Machine That Can Finish Your Sentence. Order Reprints | Today’s Paper | SubscribeSee more on: Alphabet Inc., OpenAIShare full articleRead in appAdvertisementSKIP ADVERTISEMENT",https://www.nytimes.com/2018/11/18/technology/artificial-intelligence-language.html,"Finally, a Machine That Can Finish Your Sentence","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPGh0dHBzOi8vd3d3LnJpdC5lZHUvbmV3cy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1odW1hbi10b3VjaNIBAA?oc=5,Artificial Intelligence - with a human touch | RIT - Rochester Institute of Technology,2018-11-20,Rochester Institute of Technology,https://www.rit.edu,"There is a growing group of RIT researchers working in a field broadly known as artificial intelligence, or AI. They are building increasingly complex algorithms—the rules that govern operating systems—so that machines can perform tasks that normally require human intelligence.",,,,,,,,,,,,,,,,,,,"



								November 20, 2018
							

																			by Michelle Cometa



Artificial Intelligence - with a human touch




Share on Facebook


Share on Twitter


Share on LinkedIn


Share on Reddit


Share via Email







‌



A. Sue Weisler
 Dhireesha Kudithipudi, a professor of computer engineering, is part of a growing group of RIT researchers working in artificial intelligence. 


Some of RIT’s professors are teaching very different kinds of students. Their classrooms are labs, and the students are high-tech computers being taught to think.
There is a growing group of RIT researchers working in a field broadly known as artificial intelligence, or AI. They are building increasingly complex algorithms—the rules that govern operating systems—so that machines can perform tasks that normally require human intelligence, including making decisions.
As part of RIT’s Center for Human-Aware Artificial Intelligence, these faculty researchers believe their work, with multi-millions of dollars in funding from the National Science Foundation, National Security Administration, Air Force Research Labs and other prominent organizations, could lead to breakthroughs in everything from health care to energy management to cybersecurity.
“There is an exuberance in this field,” said Dhireesha Kudithipudi, one of the center founders and a professor of computer engineering. “And the work and research we are doing today is to improve human lives tomorrow.”
RIT is uniquely positioned to tackle this area because the university has the right combination of people with expertise in AI, as well as researchers in specialized fields, such as American Sign Language and imaging science.
Work at the center builds on national priorities for AI, where the economic impact is projected to increase global GDP by nearly $16 trillion by 2030, according to a 2017 report by PricewaterhouseCoopers.
“There is a huge opportunity for researchers in this domain, but the tricky part is that these researchers need to be truly interdisciplinary,” said Kudithipudi, director of the center, who is seeing some of those interdisciplinary connections being made.
AI is an umbrella term for multiple fields of computing technologies—deep learning, computer vision, neuromorphic computing, natural language processing, for example—strengths of the faculty researchers involved in the center. These strengths became the center’s four key areas: brain-inspired computing, machine learning and perception, automation and human-centered AI.
Projects will address society’s challenges in the areas of manufacturing, cybersecurity, sustainable systems and energy develop–ment, and improve medical care and technology. They will also address deeper questions such as how do humans and machines interact with each other and how do machines interpret intent.
“The benefits and future successes of AI will come from multiple disciplines and people who come together to develop new application domains,” Kudithipudi said.


Related News

Building astute robots
Teaching computers to learn
Giving computers a better brain
Improving ASL communication

Topics
grants
creativity and innovation
research









Recommended News








			July 15, 2024
		






						RCSD students showcase microchip projects at RIT's summer camp   


WHAM-TV features students from the Rochester City School District as they gain hands-on experience at Microchip Experience Camp.







			July 15, 2024
		






						High school students discover the big impact of tiny microchips during Chip Experience 
					


The immersion, which allowed students to create their own microchip projects, provided full tuition for the week, a $500 stipend per student, housing, meals, and transportation. 







			July 12, 2024
		






						Exploding Kittens game created by RIT alumnus debuts on Netflix
					


Exploding Kittens, the animated series based on the game, premiered on Netflix July 12. The nine-episode first season brings characters from the game to life and introduces new ones. It also coincides with updates to the Netflix Exploding Kittens mobile game and new show-adapted merchandise.







			July 11, 2024
		






						My Phone Was Cloned   


AARP interviews Jonathan Weissman, principal lecturer in the Department of Cybersecurity, about how to prevent criminals from taking over your phone and draining bank accounts. (This content may require a subscription to view.)











More News  



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LmJiYy5jb20vZnV0dXJlL2FydGljbGUvMjAxODExMTYtd2h5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWlzLXNoYXBpbmctb3VyLXdvcmxk0gEA?oc=5,Why artificial intelligence is shaping our world - BBC.com,2018-11-19,BBC.com,https://www.bbc.com,Welcome to Machine Minds: a new season on BBC Future about all the ways that artificial intelligence is changing our lives.,,Welcome to Machine Minds: a new season on BBC Future about all the ways that artificial intelligence is changing our lives.,Welcome to Machine Minds: a new season on BBC Future about all the ways that artificial intelligence is changing our lives.,https://schema.org,NewsArticle,,['https://ychef.files.bbci.co.uk/1280x720/p06s020x.jpg'],"{'@type': 'Person', 'name': 'Richard Gray', 'url': ''}","{'@type': 'Organization', 'name': 'BBC'}",Why artificial intelligence is shaping our world,2018-11-19T08:03:46.000Z,2022-02-28T13:30:03.688Z,,,,,,,"Why artificial intelligence is shaping our world19 November 2018By Richard Gray, @chalkmark, Features correspondentShareGetty ImagesArtificial intelligence is already impacting our everyday lives in some surprising ways (Credit: Getty Images)Welcome to Machine Minds: a new season on BBC Future about all the ways that artificial intelligence is changing our lives.We stand on the edge of a crucial moment in the history of our species – a time when a creation of our own inventiveness has the potential to change everything. For some, it will be humanity’s salvation, while for others, it could be our downfall. We are entering the age of artificial intelligence (AI).While AI is still some way from the sentient machines portrayed in science fiction, the creation of algorithms that can learn, understand language and mimic some aspects of the human mind have led to huge advances. Today AI is being used in hundreds of different industries.The machines we use on a daily basis are getting smarter, meaning that AI is no longer a futuristic technology but is increasingly integrated into every realm of our lives. From suggesting what books we might like to buy online to powering the virtual assistants that inhabit our phones and smart speakers, some of the applications are more visible than others. In truth, AI is touching our lives far more than many of us realise.Banks are using it to detect fraud and predict changes in the stock marketsInsurance companies are employing AI to help them produce policy quotes and assess claimsIt’s helping police forces to identify suspects from grainy CCTV imagesIn courtrooms it’s offering advice to judges about whether to grant bail conditions to criminal suspectsMachines with the capability to identify images are helping doctors spot disease.Algorithms that use machine learning – one of the leading branches of AI – are helping self-driving cars to navigate our complex roadsThey are helping linguists to decifer lost languagesAnd it is helping firms make decisions about who to hire and fireEven on flights, AI is being used by air traffic controllers to help to keep us safe both in the air and on the ground.Yet there are also deep ethical questions about how and when AI should be used. And whether the hype surrounding this technology outstrips what is really achievable.Over the next four months, BBC Future is going to explore the technologies and trends at the cutting-edge of AI, sorting the hype from where it has real-world promise. We will probe the profound implications of letting these silicon brains into our lives and how it will shape our relationships, our work and our societies.One of the early pioneers of computer science Alan Perlis once quipped that “a year spent in artificial intelligence is enough to make one believe in God,” out of frustration at the problems of producing computer networks that could mimic the human brain. Is the prospect of creating machines that could possibly hope to compete with our brains still out of reach? Or are they now able to do the things humans can only dream of?What is AI really capable of? How can it help us solve our problems? And how should we feel about this future?Join us on our journey through the research, applications and future of AI.Join 900,000+ Future fans by liking us on Facebook, or follow us on Twitter or Instagram. If you liked this story, sign up for the weekly bbc.com features newsletter, called “If You Only Read 6 Things This Week”. A handpicked selection of stories from BBC Future, Culture, Capital, and Travel, delivered to your inbox every Friday.Artificial intelligence",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LnRlY2h0YXJnZXQuY29tL3NlYXJjaGhyc29mdHdhcmUvb3Bpbmlvbi9XaWxsLUtyb25vcy1BSS1pbXByb3ZlLWxpZmUtZm9yLWhvdXJseS1lbXBsb3llZXMtRXhwZXJ0cy1hcmUtc3BsaXTSAQA?oc=5,Will Kronos AI improve life for hourly employees? Experts are split - TechTarget,2018-11-20,TechTarget,https://www.techtarget.com,"The idea of AI in HR seems ubiquitous today, but mostly for salaried workers. A new Kronos AI platform takes aim at the hourly workforce, but can it help? Here's what three experts said.",,"Three experts weigh in on whether a new Kronos AI tool aimed at hourly workers can make a difference. More than half of the American workforce is paid by the hour, making engagement and retention challenging.","Three experts weigh in on whether a new Kronos AI tool aimed at hourly workers can make a difference. More than half of the American workforce is paid by the hour, making engagement and retention c...",https://schema.org,Article,,https://cdn.ttgtmedia.com/visuals/searchEnterpriseAI/ai-platforms/searchEnterpriseAI_023.png,"[{'name': 'Valerie Silverthorne', '@type': 'Person'}]","{'name': 'TechTarget', 'logo': {'url': 'https://cdn.ttgtmedia.com/rms/amp/amp_teal_logo_115_60.png', 'height': 60, 'width': 115, '@type': 'ImageObject'}, '@type': 'Organization'}",Will Kronos AI improve life for hourly employees? Experts are split,2018-11-20T16:43Z,,,Will Kronos AI improve life for hourly employees? Experts are split,False,,,,"






Opinion


Will Kronos AI improve life for hourly employees? Experts are split


The idea of AI in HR seems ubiquitous today, but mostly for salaried workers. A new Kronos AI platform takes aim at the hourly workforce, but can it help? Here's what three experts said.





Share this item with your network:

















































By


Valerie Silverthorne



Published: 20 Nov 2018


 
Can AI really improve the lives -- and perhaps the staying power -- of hourly workers, or is the technology not quite there yet?
The question is timely, as HCM platform-maker Kronos Inc. just rolled out an AI-powered tool aimed at the hourly workforce. To put it all in context, workers paid by the hour represented nearly 59% of employed Americans in 2017, according to U.S. Bureau of Labor Statistics, and that number has grown 15% since 1996. And a 2015 study from the Society of Human Resource Management found that hourly workers' turnover rate was 49% annually.







In one sense, the Kronos AI announcement seems to be business as usual. In 2018, a slew of AI and machine learning-based tools arrived in the HR space. But almost universally, those products have been designed to improve the HR workload or are used by salaried employees. If AI had anything to do with the hourly workforce, my cynical thought was that it was more likely to be taking their jobs than actually helping them out.

Kronos AI tries to tackle shift swaps
That's why it was time to look deeper at how AI could make a difference in areas like employee engagement, starting with the Kronos AI tool, Aimee, which is an acronym for Artificial Intelligence for Managers and Employees. Jayson Saba, senior director of product marketing at Kronos, is, not surprisingly, excited about what AI can offer.
""A workplace that uses artificial intelligence is actually a pretty cool place to be,"" he wrote in an email.
But it was practicality and not the coolness factor Kronos was pursuing with Aimee's first big use case in the Kronos Workforce Dimensions suite: shift swapping.
""When an employee needs to swap a shift, Aimee looks back at the last nine or more months of shift swaps and learn from that history,"" Saba explained. ""Who do you usually swap with? Who usually accepts those swaps? What days do you like to swap on? What days do other people not like to work? Aimee then makes a recommendation about which employees are most likely to want to swap.""
Kronos also recognized that not all hourly workers are created equal. A nurse might have a hospital email address and easy access to a computer, while a fast food employee might not. That's why the company teamed up with Workplace by Facebook and IBM's Watson supercomputer to offer chatbot-powered shift swapping on any mobile device, as well as coaching or training options, Saba said.
And, like several other competing products, Aimee offers predictive features that can help managers identify which employees might be most likely to leave.


Hourly scheduling is 'hellishly hard'
Putting Kronos AI to work with scheduling issues is largely a winning combination for HR analyst Katherine Jones, who gives Kronos points for tackling the hourly workforce.
""That's the most difficult part of the market,"" she said. ""What makes Kronos AI and the product suite more interesting to me is they're looking at difficult business problems and trying to use smart technology to figure it out."" Shift scheduling and swapping are ""hellishly hard"" problems to solve, she said, so it makes sense to use a technology like AI ""that doesn't get tired or overwhelmed with too much data.""
That all sounds good -- if you believe AI can really bring it all home. Brian Sommer, founder of analyst firm TechVentive, was not familiar with the new Kronos AI announcement, but he has looked hard at AI in HR and is skeptical -- at least at this point.



It's not like they're going to go on their breaks and get on a mobile phone for a coaching session.


Trevor Whiteanalyst, Nucleus Research




""We're really, really in the early stages of AI and ML [machine learning] in this space,"" he said. Describing AI as a shiny toy most companies lack the expertise or staff to make work, Sommer doesn't buy the idea that AI can predict turnover, which is a particularly tough problem to solve when it comes to hourly workers.
""We're relying on the correlations where we've seen the pattern before,"" he said. ""An employee has used up all vacation time or starts having more erratic time clock activity or has cashed in stock options. The problem is there is no agreement among firms about what are the correct indicators and no two firms use the same indicators to calculate the [flight risk] score.""
Although Jones vehemently disagrees with this perspective -- ""It's the easiest thing ever to create an algorithm to predict flight risk"" -- she does think the debate is meaningless for most hourly workers. ""They'll change jobs right away if they can get [a small raise] somewhere else,"" she said.


Hourly worker priority: Steady schedule and pay
Trevor White, an analyst at Nucleus Research, goes even further. He thinks the Kronos AI platform is looking to solve a problem that simply does not exist.
""I'm not sure how much the stuff around coaching is really going to make a difference,"" he said.
Nucleus has interviewed hourly workers, he said, and found their priorities are a fixed schedule and a steady paycheck. Anything outside of that doesn't matter, he asserted.
""It's not like they're going to go on their breaks and get on a mobile phone for a coaching session.""
Hiring and employee retention are hard in every single segment of the market today, but for companies fuelled by hourly workers, the challenges are greater and the risks of failure are no doubt higher.
AI feels like a no-brainer for shift swaps and scheduling, but like some of the experts, I need more convincing about how coaching on the go can improve an hourly worker's loyalty or job satisfaction. And I'm still wondering how many hourly jobs AI-powered robots might eventually replace.


Next Steps
Kronos and Ultimate Software merge





Dig Deeper on Core HR administration technology



How generative AI is put to work in business applications




By: Peter Allison




The 10 biggest ransomware attacks in history




By: Mary Pratt




Lawsuit claims Kronos breach exposed data for 'millions'




By: Peyton Doyle




Kronos attack fallout continues with data breach disclosures




By: Peyton Doyle







Sponsored News


Dell Technologies GenAI-validated Designs and Dell Reference Designs
–Dell Technologies and Intel


Flexible IT: When Performance and Security Can’t Be Compromised
–Dell Technologies


Confidently extend AI across your organization
–HPE

See More





Related Content


Kronos shift scheduling software a grind for ...
– HR Software


Kronos introduces its latest time clock, Kronos ...
– HR Software


New WorkJam app aims at preventing nurse burnout
– HR Software








","{'@type': 'WebPage', '@id': 'https://www.techtarget.com/searchhrsoftware/opinion/Will-Kronos-AI-improve-life-for-hourly-employees-Experts-are-split'}",,"{'cssSelector': '.paywall', '@type': 'WebPageElement', 'isAccessibleForFree': False}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vd3d3LmF4aW9zLmNvbS8yMDE4LzExLzE3L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWp1ZGdlc9IBAA?oc=5,Can judging be automated? - Axios,2018-11-17,Axios,https://www.axios.com,Scholars are debating if computers can replace human judges.,"Judges,Visuals,Illustrations,Justice,Deep learning",Scholars are debating if computers can replace human judges.,Scholars are debating if computers can replace human judges.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmdyZWVuaG91c2Vncm93ZXIuY29tL3RlY2hub2xvZ3kvaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNhbi1oZWxwLXlvdS1sZWFybi1tb3JlLWFib3V0LXlvdXItZ3JlZW5ob3VzZS_SAXpodHRwczovL3d3dy5ncmVlbmhvdXNlZ3Jvd2VyLmNvbS90ZWNobm9sb2d5L2hvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jYW4taGVscC15b3UtbGVhcm4tbW9yZS1hYm91dC15b3VyLWdyZWVuaG91c2UvP2FtcA?oc=5,How Artificial Intelligence Can Help You Learn More About Your Greenhouse - Greenhouse Grower,2018-11-19,Greenhouse Grower,https://www.greenhousegrower.com,Greenhouse growers are faced with compiling and analyzing more data than ever before. Using artificial intelligence and robotics can streamline this process.,,Greenhouse growers are faced with compiling and analyzing more data than ever before. Using artificial intelligence and robotics can streamline this process.,,https://schema.org,,,,,,,,,,,,,,,"



 
By Saber Miresmailli|November 19, 2018  


As new sensors become available to us, we gain new insight about our crops and can make better decisions. Photo courtesy of Ecoation.
I used to be a grower, and over the years, I have met several master growers who could tell a lot about their crop with a single glance. I know growers who can smell spider mites or powdery mildew on their tomatoes. These incredible individuals have amazing abilities that they mastered over the years. Yet all of them are facing a big problem these days: We can’t be everywhere at once.Advertisement
Greenhouses are getting bigger, and we simply cannot walk the entire crop anymore. Even on bicycles and scooters, one can only visit a small fraction of the greenhouse.
We also invest in multiple sensors. From climate, light level, water pH, and temperature, we constantly measure conditions in our greenhouses. As new sensors become available to us, we gain new insight about our crops and can make better decisions. We use automation and robotics to streamline repetitive tasks that require consistency and speed.
While the influx of data from multiple sources can be empowering, it can also be overwhelming for growers who suddenly get too much information about their operation. In the same way that we can’t walk through several acres of plants every day, we can’t look at several terrabytes of data and make sense of them on a daily basis. We need actionable intelligence, and that is why we need artificial intelligence (AI) in greenhouses.








Top Articles
































Read More






Read More






Read More






Read More






Read More






Read More






Read More
PrevNext
Testing Climate-Ready Landscape Plants Benefits Growers and Consumers


By now, you probably have already formed an opinion about AI. Some might think of AI and robots as evil tools that will lead us to our doomsday, and some might think of them as the silver bullet that can finally fix all our problems. I think both views are extreme and are propagated by a growing number of sensor companies who use AI terminology to describe their technologies. To properly embrace AI in our industry, we need to demystify it first.
Three Principles of Artificial Intelligence
1. Machine learning and robotics will be used to automate repetitive tasks, and this will result in loss of certain types of jobs. But this is not new. Fruit sorting machines took the job of many human sorters, but we still have people in packinghouses who do different jobs. We still need humans in the loop.
2. Machine learning and AI algorithms can be trained to do certain tasks faster and better than humans. Yet the training requires significant investment of time and resources. You need to make sure the signals on which you want to train the algorithms are strong and not mixed with a high level of noise. The choice of sensor and what you measure is important, but more so is the role of the human providing the labels to train the machine. If the quality of the labeled data is low, the predictive model cannot perform well.
3. To build AI, a significantly large amount of data must be collected. The question is, who will own this data? There are companies who provide free sensors, cameras, and services to growers just so they can collect and own the data. I agree that the data can inform high-level decisions and has value, but I also believe the grower should be the owner and should decide if, when, and with whom they want to share their data.
Having said that, I believe we need to share data related to symptoms of pests and diseases. This data should not contain any information about specific farms or locations. It should be like a guide for pests of greenhouses that contains color pictures of infested plants. We should create a digital library of crop stress symptoms and allow everyone to access it and contribute data to it.
When it comes to AI systems, the business intelligence and data related to methods of growing should be kept in the hands of the grower because the industry is competitive, but there is a benefit to sharing data about pests and diseases that affects all of us. The ownership of data and what to keep and what to share needs careful consideration.




0
1
5

How Artificial Intelligence Can Help You Learn More About Your Greenhouse










Subscribe to 
eNewsletter 












Subscribe










Dr. Saber Miresmailli (saber@ecoation.com) is Founder and CEO of Ecoation Innovative Solutions Inc. in North Vancouver, BC, Canada. Miresmailli made a presentation on this topic at the Canadian Greenhouse Conference in October. See all author stories here.









 

Leave a ReplyCancel reply 










How Artificial Intelligence Can Help You Learn More About Your Greenhouse - Wiredfocus says: 

November 19, 2018 at 8:35 pm 
[…] READ SOURCE […]
Reply



How Artificial Intelligence Can Help You Learn More About Your Greenhouse – NewsChest Technology says: 

November 20, 2018 at 6:05 am 
[…] As new sensors become available to us, we gain new insight about our crops and can make better decisions. Photo courtesy of Ecoation. I used to be a grower, and over the years, I have met several master growers who could tell a lot about their crop with a single glance. I know growers who can smell spider mites or powdery mildew on their tomatoes. These incredible individuals have amazing abilities that they mastered over the years. Yet all of them are facing a big problem these days: We […] How Artificial Intelligence Can Help You Learn More About Your Greenhouse […]
Reply

 




Related articles






Putting New Greenhouse Technology Through the Paces







Proven Winners Adds Customizable Communication Hub to the Connect+ Program







Incentives Help Growers Invest in Solar Energy and Agrivoltaics




 












",,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.greenhousegrower.com/technology/how-artificial-intelligence-can-help-you-learn-more-about-your-greenhouse/', 'url': 'https://www.greenhousegrower.com/technology/how-artificial-intelligence-can-help-you-learn-more-about-your-greenhouse/', 'name': 'How Artificial Intelligence Can Help You Learn More About Your Greenhouse - Greenhouse Grower', 'isPartOf': {'@id': 'https://www.greenhousegrower.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.greenhousegrower.com/technology/how-artificial-intelligence-can-help-you-learn-more-about-your-greenhouse/#primaryimage'}, 'image': {'@id': 'https://www.greenhousegrower.com/technology/how-artificial-intelligence-can-help-you-learn-more-about-your-greenhouse/#primaryimage'}, 'thumbnailUrl': 'https://www.greenhousegrower.com/wp-content/uploads/2018/11/Artificial-Intelligence-in-Greenhouse.jpg', 'datePublished': '2018-11-19T18:47:40+00:00', 'dateModified': '2018-11-19T19:46:32+00:00', 'author': {'@id': 'https://www.greenhousegrower.com/#/schema/person/efc5d15df0d7b19739c70818be6a3792'}, 'description': 'Greenhouse growers are faced with compiling and analyzing more data than ever before. Using artificial intelligence and robotics can streamline this process.', 'breadcrumb': {'@id': 'https://www.greenhousegrower.com/technology/how-artificial-intelligence-can-help-you-learn-more-about-your-greenhouse/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.greenhousegrower.com/technology/how-artificial-intelligence-can-help-you-learn-more-about-your-greenhouse/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.greenhousegrower.com/technology/how-artificial-intelligence-can-help-you-learn-more-about-your-greenhouse/#primaryimage', 'url': 'https://www.greenhousegrower.com/wp-content/uploads/2018/11/Artificial-Intelligence-in-Greenhouse.jpg', 'contentUrl': 'https://www.greenhousegrower.com/wp-content/uploads/2018/11/Artificial-Intelligence-in-Greenhouse.jpg', 'width': 896, 'height': 504, 'caption': 'Artificial-Intelligence-in-Greenhouse'}, {'@type': 'BreadcrumbList', '@id': 'https://www.greenhousegrower.com/technology/how-artificial-intelligence-can-help-you-learn-more-about-your-greenhouse/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.greenhousegrower.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How Artificial Intelligence Can Help You Learn More About Your Greenhouse'}]}, {'@type': 'WebSite', '@id': 'https://www.greenhousegrower.com/#website', 'url': 'https://www.greenhousegrower.com/', 'name': 'Greenhouse Grower', 'description': 'The Future of Floriculture', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.greenhousegrower.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.greenhousegrower.com/#/schema/person/efc5d15df0d7b19739c70818be6a3792', 'name': 'Brian Sparks', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.greenhousegrower.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/d346f4481eb30db5e26000a962a7198e?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/d346f4481eb30db5e26000a962a7198e?s=96&d=mm&r=g', 'caption': 'Brian Sparks'}, 'description': 'Brian Sparks is senior editor of Greenhouse Grower and editor of Greenhouse Grower Technology.', 'url': 'https://www.greenhousegrower.com/author/sparks/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8veW91cnN0b3J5LmNvbS9teXN0b3J5L3RoZS1mdXR1cmUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tdGhlLXNlcnZpY2UtLWlha2MyeW82YTLSAQA?oc=5,The Future Artificial Intelligence in the Service Industry - YourStory,2018-11-20,YourStory,https://yourstory.com,"Artificial intelligence has grown into a full-fledged ecosystem. With the automation it brings to almost every aspect of our life, we see it creeping into our mobile phones, our devices connected over IoT and websites, Artificial Intelligence has become a way of living. The major breakthroughs that ","artificial-intelligence, mobile-app-development, hire-mobile-app-developeryzTwo","Artificial intelligence has grown into a full-fledged ecosystem. With the automation it brings to almost every aspect of our life, we see it creeping into our mobile phones, our devices connected over IoT and websites, Artificial Intelligence has become a way of living. The major breakthroughs that ","Artificial intelligence has grown into a full-fledged ecosystem. With the automation it brings to almost every aspect of our life, we see it creeping into our mobile phones, our devices connected over IoT and websites, Artificial Intelligence has become a way of living. The major breakthroughs that ",http://schema.org,Article,https://yourstory.com/mystory/the-future-artificial-intelligence-in-the-service--iakc2yo6a2,['https://images.yourstory.com/cs/1/b3c4ba60-ab5e-11e8-8691-f70342131e20/237-min1542607243343.jpg'],"{'@type': 'Person', 'name': 'Vikash Jangid'}","{'@type': 'Organization', 'name': 'YourStory', 'alternateName': ['Yourstory', 'Yourstory Media Pvt Ltd', 'Yourstory Media'], 'logo': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/cs/static/logos/publisher-logo.png', 'width': 292, 'height': 60, 'caption': 'YourStory Media'}, 'url': 'https://yourstory.com', 'sameAs': ['https://www.facebook.com/yourstorycom', 'https://twitter.com/YourStoryCo', 'https://www.youtube.com/user/yourstorytv', 'https://instagram.com/yourstory_com', 'http://plus.google.com/111272339013288238153', 'https://in.linkedin.com/company/yourstory-com']}",The Future Artificial Intelligence in the Service Industry,2018-11-20T10:27:20.236Z,2018-11-20T10:27:20.236Z,News,The Future Artificial Intelligence in the Service Industry,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://yourstory.com', 'name': 'YourStory', 'image': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/cs/static/logos/publisher-logo.png', 'width': 292, 'height': 60}}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://yourstory.com/mystory/the-future-artificial-intelligence-in-the-service--iakc2yo6a2', 'name': 'The Future Artificial Intelligence in the Service Industry', 'image': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/cs/1/b3c4ba60-ab5e-11e8-8691-f70342131e20/237-min1542607243343.jpg', 'height': 400, 'width': 800}}}]",,,,"{'@type': 'WebPage', '@id': 'https://yourstory.com/mystory/the-future-artificial-intelligence-in-the-service--iakc2yo6a2'}",the-future-artificial-intelligence-in-the-service--iakc2yo6a2,,,,,"{'@type': 'WebPage', '@id': 'https://yourstory.com/mystory/the-future-artificial-intelligence-in-the-service--iakc2yo6a2', 'url': 'https://yourstory.com/mystory/the-future-artificial-intelligence-in-the-service--iakc2yo6a2', 'inLanguage': 'en', 'name': 'The Future Artificial Intelligence in the Service Industry', 'datePublished': '2018-11-20T10:27:20.236Z', 'dateModified': '2018-11-20T10:27:20.236Z', 'description': 'Artificial intelligence has grown into a full-fledged ecosystem. With the automation it brings to almost every aspect of our life, we see it creeping into our mobile phones, our devices connected over IoT and websites, Artificial Intelligence has become a way of living. The major breakthroughs that ', 'isPartOf': {'@type': 'WebSite', '@id': 'https://yourstory.com/#website', 'url': 'https://yourstory.com/', 'name': 'YourStory', 'headline': 'Yourstory', 'description': 'YourStory | Stories from the Startups, Business, SMEs, Research, Entrepreneurs, Social, Women, Automotive and other sectors', 'publisher': {'@type': 'Organization', 'name': 'YourStory', 'alternateName': ['Yourstory', 'Yourstory Media Pvt Ltd', 'Yourstory Media'], 'logo': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/cs/static/logos/publisher-logo.png', 'width': 292, 'height': 60, 'caption': 'YourStory Media'}, 'url': 'https://yourstory.com', 'sameAs': ['https://www.facebook.com/yourstorycom', 'https://twitter.com/YourStoryCo', 'https://www.youtube.com/user/yourstorytv', 'https://instagram.com/yourstory_com', 'http://plus.google.com/111272339013288238153', 'https://in.linkedin.com/company/yourstory-com']}}}",,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}","Artificial IntelligenceArtificial intelligence has grown into a full-fledged ecosystem. With the automation it brings to almost every aspect of our life, we see it creeping into our mobile phones, our devices connected over IoT and websites, Artificial Intelligence has become a way of living.The major breakthroughs that our generation has witnessed are in the service industry where the Chat representatives have been replaced by chatbots. This is just the tip of the iceberg. The customer service industry is very excited to put the advantages of AI powered solutions to use. Not only is it reducing the human effort, but it is also bringing in more accuracy and precision in services fueled by an ecosystem driven by innovative mobile app developers. A lot of customer service representative’s job is repetitive, mundane and has a pattern which makes it easy for the AI scientists to develop algorithms that fit in the space well.Before we go to the actual use cases let us understand what segments of AI are fueling the automation in the service industry:MACHINE LEARNINGMachine learning is an aspect of AI that makes a computer learn, just like a human. A large amount of training data is fed to an algorithm which learns from this data and offers its predictive analysis just like humans. This adds to the capabilities of AI tools to answer the queries of clients as per the training data from where it learned all it knows. > Read more:- How AI will revolutionize the mobile app developmentNATURAL LANGUAGE PROCESSINGBy Natural language processing, we understand that the voice or text input by the customer is understood at a deeper level by the algorithm. Understanding the human language even at an emotional level has also been achieved by the AI using NLP.Let us know to see the practical phases of customer service where we will interact with AI in near future:SOCIAL MEDIA MESSENGER BOTBusiness has moved to social media over the last 2-3 years. This gives customers and business a direct platform to interact. But if as a customer you think it is the actual representative talking to you, you are mistaken. The current state of social media bots is driven by AI. These real-time bots offer such a personalized response to each customer query that the revenues are skyrocketing with the adaption of AI. The cognitive capability is finding its way into all aspects of customer service across multiple business verticals.QUICK AND AUTOMATED RESPONSEAI has disrupted the customer service interface as it is offering 24/7 tireless service to the customers. Business is able to garner international traction due to this capability. As efficient as these programs have become with the support of GPU advancements, the accuracy and speed of replying to queries has massively advanced and is expected to get even better. The bots, today, can identify the customer issues from the chats and have access to the previous buying patterns of the customers. The mobile app developers offer the chatbots a capability to understand the text and voice by using intelligent algorithms. SAVING TRAINING EFFORTCost of business increases when they have to invest in the training of newly hired representatives. Using chatbots tremendously decreases the dollars spent on training and monitoring activities. It also lowers the recruitment costs as building, deploying and training the chatbot is a onetime activity. Although we will witness a steep downfall in the recruitment field of sales representatives who handle calls or replying to emails, we will see these representatives up-skilling and working at better positions. MULTIPLE SUPPORT CHANNELSLots of digital channels are being used for creating a business presence over a widespread digital world. As the number of channels is growing, the business is more in need of AI powered solutions that integrate the data coming in from different channels like social media, websites and offline buying to identify the buying patterns of the customers. It is bringing in the balance between the deployments of so many channels.> Also Read:- On-Demand mobile app development and the benefits it brings to any businessPREDICTIONS AND INSIGHTAmazon’s recommendation engine is a perfect tool that is promoting sales. What it does is that it makes sense out of the buyer data like the viewed products, buying products and more to identify the shopping pattern. It encourages sales by offering suggestions to buyers. The Machine learning algorithms are actually learning as the user buys and this is how it keeps up with the user’s choices and suggests relevant products only.SPEED OF SERVICEWho wants to wait in a queue to connect to a sales representative or a chat representative to get an answer to a single question? This was discouraging the buyers. With the chatbot, the websites especially e-commerce are offering zero wait time and quick resolution of queries. It offers a tremendous potential of enhanced customer services that is directly linked with the reputation of the brand.RELIABILITY AND PERSONALIZATIONAs AI algorithms are becoming more precise, the reliability and personalization are on the rise as the mobile app developer is focusing on the same. The customers have adapted to the way chatbots interact with them and are not bothered that they are talking to the AI powered algorithms. The intelligent bots are surmounting the standards of customer service as it eliminates the bias and any kind of language barriers.CONCLUSIONAI powered chatbots are bringing an element of intelligence to the future of customer service industry. As the technology is advancing, the innovation in the chatbots is also skyrocketing. The organizations are laying more focus on offering better support to its buyers using artificial intelligence algorithms. All this capability if render to an App by a mobile app developer by training the AI engine. A lot of research is going into finding the right balance between technology and human interaction skills. The deeper understanding is customer behavior is being done based on the data generated on social media, websites, Apps and more. This data is being used by the AI engineers to train the algorithms that can function as chatbots to offer intelligent customer support.The personalization AI brings in is not humanly possible. At the minimum costs, AI supported chatbots in every business segment are helping the business grow with speed and efficiency.At its innovative best, the AI developers are working to improvise the customer service industry in an entirely new light.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigAFodHRwczovL3d3dy5uZXdpbmRpYW5leHByZXNzLmNvbS9saWZlc3R5bGUvdGVjaC8yMDE4L05vdi8yMC9uZXctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3lzdGVtLWNhbi1kcmF3LWNhcmljYXR1cmVzLTE5MDA4MTcuaHRtbNIBigFodHRwczovL3d3dy5uZXdpbmRpYW5leHByZXNzLmNvbS9hbXAvc3RvcnkvbGlmZXN0eWxlL3RlY2gvMjAxOC9Ob3YvMjAvbmV3LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXN5c3RlbS1jYW4tZHJhdy1jYXJpY2F0dXJlcy0xOTAwODE3Lmh0bWw?oc=5,New Artificial Intelligence system can draw caricatures - The New Indian Express,2018-11-20,The New Indian Express,https://www.newindianexpress.com,,,WASHINGTON: Scientists have developed an artificial intelligence (AI) system that can sketch caricatures from a given portrait. Caricature portrait drawing is a,WASHINGTON: Scientists have developed an artificial intelligence (AI) system that can sketch caricatures from a given portrait. Caricature portrait drawing is a,http://schema.org,NewsArticle,https://www.newindianexpress.com/lifestyle/tech/2018/Nov/20/new-artificial-intelligence-system-can-draw-caricatures-1900817.html,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/TNIE/import/2018/11/20/original/abraham_lincoln.JPG?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'From our online archive', 'name': 'From our online archive', 'url': 'https://www.newindianexpress.com/author/from-our-online-archive'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'The New Indian Express', 'url': 'https://www.newindianexpress.com', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'newindianexpress', 'contentUrl': 'https://images.assettype.com/newindianexpress/2024-01/513ad66b-9f6c-4c96-a3d5-ea0e785580a6/Long_Light_Mode_500_Height.png', 'url': 'https://images.assettype.com/newindianexpress/2024-01/513ad66b-9f6c-4c96-a3d5-ea0e785580a6/Long_Light_Mode_500_Height.png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.facebook.com/thenewindianxpress', 'https://twitter.com/NewIndianXpress', 'https://instagram.com/newindianexpress/', 'https://www.youtube.com/user/thenewindianxpress', 'https://t.me/thenewindianexpress'], 'id': 'https://www.newindianexpress.com'}",New Artificial Intelligence system can draw caricatures,2018-11-20T16:11:00Z,2018-11-20T16:11:00Z,Tech,New Artificial Intelligence system can draw caricatures,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.newindianexpress.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'Lifestyle', 'item': 'https://www.newindianexpress.com/lifestyle'}, {'@type': 'ListItem', 'position': 3, 'name': 'Tech', 'item': 'https://www.newindianexpress.com/lifestyle/tech'}, {'@type': 'ListItem', 'position': 4, 'name': 'New Artificial Intelligence system can draw caricatures', 'item': 'https://www.newindianexpress.com/lifestyle/tech/2018/Nov/20/new-artificial-intelligence-system-can-draw-caricatures-1900817.html'}]",,,,"{'@type': 'WebPage', '@id': 'https://www.newindianexpress.com/lifestyle/tech/2018/Nov/20/new-artificial-intelligence-system-can-draw-caricatures-1900817.html'}",,,,,,"{'@type': 'WebPage', 'url': 'https://www.newindianexpress.com/lifestyle/tech/2018/Nov/20/new-artificial-intelligence-system-can-draw-caricatures-1900817.html', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/TNIE/import/2018/11/20/original/abraham_lincoln.JPG?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,"WASHINGTON: Scientists have developed an artificial intelligence (AI) system that can sketch caricatures from a given portrait..Caricature portrait drawing is a distinct art form where artists draw a person's face in an exaggerated manner, most times to elicit humour..Automating this technique poses challenges due to the number of intricate details and shapes involved and level of professional skills it takes to transform a person artistically from their real-life selves to a creatively exaggerated one..&quot;Compared to traditional graphics-based methods which define hand-crafted rules, our novel approach leverages big data and machine learning to synthesize caricatures from thousands of examples drawn by professional artists,&quot; said Kaidi Cao, a graduate student at Stanford University in the US..&quot;While existing style transfer methods have focused mainly on appearance style, our technique achieves both geometric exaggeration and appearance stylisation involved in caricature drawing,&quot; said Cao, who conducted the work during his internship at Microsoft..The method enables users to automate caricatures of portraits and can be applied to tasks such as creating caricatured avatars for social media and designing cartoon characters..The technique also has potential applications in marketing, advertising and journalism..The researchers turned to a well-known technique in machine learning, Generative Adversarial Network (GAN), for unpaired photo-to-caricature translation to generate caricatures that preserve the identity of the portrait..Called 'CariGANs', the computational framework precisely models geometric exaggeration in photos (shapes of faces, specific angles) and appearance stylization (look, feel, pencil strokes, shadowing) via two algorithms the researchers have labelled, CariGeoGAN and CariStyGAN..CariGeoGAN only models the geometry-to-geometry mapping from face photos to caricatures and CariStyGAN transfers the style appearance from caricatures to face photos without any deformation to the geometry of the original image..The two networks are separately trained for each task so that the learning procedure is more robust, notes the researchers..The CariGANs framework enables users to control the exaggeration degree in geometric and appearance style by dragging slides or giving an example caricature..Researchers conducted perceptual studies to evaluate their framework's ability to generate caricatures of portraits that are easily recognisable and not overly distorted in shape and appearance style..They demonstrated, through several examples, that existing methods resulted in unrecognisable caricature translation..Their method successfully generated clearer, more accurate caricature depictions of portrait photos, as if they were hand drawn by a professional artist..Currently, the focus of this work has centred on caricatures of people, primarily headshots or portraits..In future work, the researchers intend to explore beyond facial caricature generation into the full body or more complex scenes..They are also interested in designing improved human-computer interaction (HCI) systems that would give users more freedom and user control on the machine learning-generated results..Follow The New Indian Express channel on WhatsApp Download the TNIE app to stay with us and follow the latest",https://media.assettype.com/TNIE/import/2018/11/20/original/abraham_lincoln.JPG?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,2018-11-20T16:11:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiiwFodHRwczovL3d3dy5idXNpbmVzc2luc2lkZXIuaW4vaW5kaWEtMS00LW1pbGxpb24tbmV3LWl0LWpvYnMtYnktMjAyNy1idXQtaW5kaWFuLWVuZ2luZWVyaW5nLXN0dWRlbnRzLW5vdC1qb2ItcmVhZHkvYXJ0aWNsZXNob3cvNjY2NTE5MTYuY21z0gGPAWh0dHBzOi8vd3d3LmJ1c2luZXNzaW5zaWRlci5pbi9pbmRpYS0xLTQtbWlsbGlvbi1uZXctaXQtam9icy1ieS0yMDI3LWJ1dC1pbmRpYW4tZW5naW5lZXJpbmctc3R1ZGVudHMtbm90LWpvYi1yZWFkeS9hbXBfYXJ0aWNsZXNob3cvNjY2NTE5MTYuY21z?oc=5,India may have 1.4 million new IT jobs by 2027 but there’s a shortage of IT professionals to fill those roles - Business Insider India,2018-11-16,Business Insider India,https://www.businessinsider.in,(Photo source: Wikimedia)A joint study conducted by Cisco and the International Data Corporation states that there could more than 1. 4 million new IT jobs available in India by 2027.,it professionals india employment india internet of things jobs cybersecurity jobs it careers india engineering jobs india it professions india IT roles CISCO it jobs india,(Photo source: Wikimedia)A joint study conducted by Cisco and the International Data Corporation states that there could more than 1. 4 million new IT jobs available in India by 2027.,(Photo source: Wikimedia)A joint study conducted by Cisco and the International Data Corporation states that there could more than 1. 4 million new IT jobs available in India by 2027.,http://schema.org,WebPage,https://www.businessinsider.in/india-1-4-million-new-it-jobs-by-2027-but-indian-engineering-students-not-job-ready/articleshow/66651916.cms,"{'@type': 'ImageObject', 'url': 'https://www.businessinsider.in/thumb.cms?msid=66651916&width=1200&height=900', 'width': '1200', 'height': '900'}","{'@type': 'Person', 'name': 'Prabhjote Gill'}","{'@type': 'Organization', 'name': 'Business Insider India', 'logo': {'@type': 'ImageObject', 'width': '600', 'height': '60', 'url': 'https://www.businessinsider.in/photo/69280259/bi_logo.jpg'}}",India may have 1.4 million new IT jobs by 2027 but there’s a shortage of IT professionals to fill those roles | Business Insider India,2018-11-16T15:21:43+05:30,2018-11-16T15:21:43+05:30,,India may have 1.4 million new IT jobs by 2027 but there’s a shortage of IT professionals to fill those roles,,,,,Careers4 min readI'm struggling to date in Silicon Valley in my 30s. I want …A 35-year-old FAANG manager's career in Big Tech has negatively impacted his da…Robin Madell   Jul 10 2024 11:31 IST,https://www.businessinsider.in/india-1-4-million-new-it-jobs-by-2027-but-indian-engineering-students-not-job-ready/articleshow/66651916.cms,,,,,,,"{'@type': 'ImageObject', 'width': '600', 'height': '60', 'url': 'https://staticbiassets.in/thumb/msid-60085318,width-1000,height-750/default-thumb.jpg'}",,,,,,"['https://www.facebook.com/BusinessInsiderIndia', 'https://twitter.com/BiIndia']",,"{'@type': 'SpeakableSpecification', 'cssSelector': ['.bg-white']}","(Photo source: Wikimedia)A joint study conducted by Cisco and the International Data Corporation states that there could more than 1.4 million new IT jobs available in India by 2027.This would mean a 46% growth in employment opportunities derived from the digital sector. But even now 140,000 jobs are vacant in the IT segment due to underskilled graduates who aren’t ‘job ready’ flooding the market.Emerging technology like cybersecurity and the Internet of Things (IoT) has the potential to add 1.4 million new IT jobs in India by 2027 according to ‘The 20 Most Significant IT Roles You Should Consider in India’ report by Cisco and the International Data Corporation. While employment opportunities may be aplenty 140,000 jobs lie vacant in artificial intelligence and big data analytics as of now according to a Nasscom report that came out in July. A 1.4 million increase in jobs would mean a 46% in growth in employment opportunities driven by digital transformation according to IANS. Leading the digital industry will the demand for professionals will skills in cloud solutions, followed by data analysis and big data. Supply-demand mismatchThe Cisco-led report highlights that demand for these roles will be all the more paramount since there’s a shortage of available IT professionals with the required skill sets. Since IT organisations may find these roles hard to fill, it’s possible they may choose to implement in-house programs to train their existing employees.Moreover, the availability of these jobs will determine how and where people work, especially taking into account India’s demographic dividend. Nasscom’s report in July highlighted that while there may be a demand of IT professionals, there’s a link between the low employability rate of India’s engineering graduates and the fact their skills are currently inadequate when it comes to actual application. Basically, IT graduates may have the degree but they’re nowhere near job ready.With the upcoming opportunities, it seems imperative that the $167 billion Indian IT industry needs to invest in re-skilling their employees in order to fully capitalise on new technologies. The list of ‘Most Significant IT Roles’ is the culmination of surveying the most ‘in-demand’ positions and the ones that will play the ‘most important’ roles in the coming future. The global survey examined 2 million IT job postings and came up with a list of 20 specific IT roles that it deems to be the most significant.See also:Potential for India’s workforce lies in digital transformation: ReportIT whirlwind has impacted mid-level employees the most — here’s howTamil Nadu is building a union of Tech professionals",https://www.businessinsider.in/thumb.cms?msid=66651916&width=1200&height=900,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiLmh0dHBzOi8vd3d3LmJiYy5jby51ay9uZXdzL3RlY2hub2xvZ3ktNDYwNTU1OTXSATJodHRwczovL3d3dy5iYmMuY28udWsvbmV3cy90ZWNobm9sb2d5LTQ2MDU1NTk1LmFtcA?oc=5,Why Big Tech pays poor Kenyans to teach self-driving cars - BBC,2018-11-03,BBC,https://www.bbc.co.uk,The data that powers the most cutting edge technology in Silicon Valley begins in Nairobi's slum.,,The data that powers the most cutting edge technology in Silicon Valley begins in Nairobi's slum.,The data that powers the most cutting edge technology in Silicon Valley begins in Nairobi's slum.,http://schema.org,ReportageNewsArticle,https://www.bbc.com/news/technology-46055595,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_news/9259/production/_104156473_whatsubject.jpg'}","[{'@type': 'Person', 'name': 'By Dave Lee'}]","{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'publishingPrinciples': 'http://www.bbc.co.uk/news/help-41670342', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",Why Big Tech pays poor Kenyans to teach self-driving cars,2018-11-03T01:30:13.000Z,2018-11-03T01:30:13.000Z,,,,,,,"Why Big Tech pays poor Kenyans to teach self-driving cars2 November 2018By Dave Lee, North America technology reporterShare6:08WATCH: Why Kenyans are becoming experts in AIWhen Artificial Intelligence works as intended, Silicon Valley types often say it's ""like magic"".But it isn't magic. It's Brenda, a 26-year-old single mother who lives Kibera, Africa's largest slum, and perhaps the toughest neighbourhood on earth, where hundreds of thousands of people live in a space not too much bigger than London's Hyde Park.Each day, Brenda leaves her home here to catch a bus to the east side of Nairobi where she, along with more than 1,000 colleagues in the same building, work hard on a side of artificial intelligence we hear little about - and see even less.In her eight-hour shift, she creates training data. Information - images, most often - prepared in a way that computers can understand. Brenda lives in Kibera, considered Africa's largest slumBrenda loads up an image, and then uses the mouse to trace around just about everything. People, cars, road signs, lane markings - even the sky, specifying whether it's cloudy or bright. Ingesting millions of these images into an artificial intelligence system means a self-driving car, to use one example, can begin to ""recognise"" those objects in the real world. The more data, the supposedly smarter the machine.She and her colleagues sit close - often too close - to their monitors, zooming in on the images to make sure not a single pixel is tagged incorrectly. Their work will be checked by a superior, who will send it back if it's not up to scratch. For the fastest, most accurate trainers, the honour of having your name up on one of the many TV screens around the office. And the most popular perk of all: shopping vouchers.""You get to do something unique,"" Brenda told me when I visited the tiny home she shares with her daughter, brother and mother.""With my work that I'm doing, I believe I'm working for something that is going to help someone in future.""Slum schoolBrenda does this work for Samasource, a San Francisco-based company that counts Google, Microsoft, Salesforce and Yahoo among its clients. Most of these firms don't like to discuss the exact nature of their work with Samasource - as it is often for future projects - but it can be said that the information prepared here forms a crucial part of some of Silicon Valley's biggest and most famous efforts in AI. For eight hours a day, Brenda trains data used for artificial intelligenceIt's the kind of technological progress that will likely never be felt in a place like Kibera. As Africa's largest slum, it has more pressing problems to solve, such as a lack of reliable clean water, and a well-known sanitation crisis.But that's not to say artificial intelligence can't have a positive impact here. We drove to one of Kibera's few permanent buildings, found near a railway line that, on this rainy day, looked thoroughly decommissioned by mud, but has apparently been in regular use since its colonial inception.Almost exactly a year ago, this building was the dividing line between stone-throwing rioters and the military. Today, it's a thriving hub of activity: a media school and studio, something of a cafeteria, and on the first floor, a room full of PCs. Here, Gideon Ngeno teaches around 25 students the basics of using a personal computer.What's curious about this process is that digital literacy is high, even in Kibera, where smartphones are common and every other shop is selling chargers and accessories, which people buy using the mobile money system MPesa.Images have to be painstakingly annotated - cars, roads, signs... even the skyBut much of Africa has leapfrogged the desktop PC era. The keyboard and mouse combination is a foreign, cumbersome experience. One Samasource team member told me how she'd often observe trainees look away from their PCs and pick up their phone when asked to search for information on the internet.The course taught here is designed specifically for those wanting to go on to work at Samasource or another digital economy company. It costs 500 Kenyan shillings - around $5. That's a not insignificant amount for people who often live below the poverty line. The company used to offer the course for free, but without the financial commitment, I was told attendance (and concentration) was sketchy at best. Now the biggest challenge, Ngeno said, was noise - as we spoke, a group of eager children did exactly what you'd expect of them when handed a selection of musical instruments. Outside, a market thronged with activity.A campus fit for CaliforniaIn contrast, the Samasource office is in a part of Nairobi that reassures you this is a city on the up. The company occupies four floors of a business park building, with vast banks of computers being used for the job of training data. SamasourceThe data is used to help automated systems ""recognise"" objects in the real worldIf you didn't look out of the windows, you might think you were at a Silicon Valley tech firm. Walls are covered in corrugated iron in a way that would be considered achingly trendy in California, but here serve as a reminder of the environment many of the workers come from: around 75% are from the slum.Most impressively, Samasource has overcome a problem that most Silicon Valley firms are famously grappling with. Just over half of their workforce is made up of women, a remarkable feat in a country where starting a family more often than not rules out a career for the mother. Here, a lactation room, up to 90 days maternity leave, and flexibility around shift patterns makes the firm a stand-out example of inclusivity not just in Kenya, but globally.""Like a lot of people say, if you have a man in the workplace, he'll support his family,"" said Hellen Savala, who runs human resources. ""[But] if you have a woman in the workplace, she'll support her family, and the extended family. So you'll have a lot more impact.""'It would never work'That balance isn't just among those doing the entry level work, either. In San Francisco's Mission District, in an office far more modest than what the firm has in Kenya, Samasource's chief executive Leila Janah beamed when talking about how the firm's management team is majority female. ""It's extremely unusual in Silicon Valley more broadly, but especially within artificial intelligence.""We just think of it as normal. It's a competitive advantage.""Leila Janah, right, was at first criticised for wanting to outsource jobs away from the USFounded in 2008, Samasource received a frosty reception in its early days. In recession-hit America, outsourcing a large number of jobs to the developing world was not seen as a welcome idea. It arguably still isn't. Those who did like the concept worried there were too few people with the digital skills necessary to do the work to a standard the tech giants would accept.""Very smart people in the tech world, and in the world of big philanthropy said this was a wonderful idea, but that it would never work,"" Janah recalled. Today, Samasource is the largest organisation of its kind in East Africa, and also has facilities in Asia and North America.Cheap labourJanah touts the company's record for accuracy and security as the major reasons why Google et al come to them for this work. But of course, there's an obvious motivation for these companies to use workers in parts of the world where wages are rock bottom, and where locals are desperate for steady work.Samasource targets those currently earning around $2 a day, or less, in the so-called informal economy of odd - or dangerous - jobs. Samasource instead provides a living wage of around $9 a day. That's an improvement, but still a pittance for Silicon Valley.Gideon Ngeno teaches basic digital literacy right in the heart of Kibera's slum""Yes, it's cost effective,"" Janah said. ""But one thing that's critical in our line of work is to not pay wages that would distort local labour markets. If we were to pay people substantially more than that, we would throw everything off. That would have a potentially negative impact on the cost of housing, the cost of food in the communities in which our workers thrive.""Then of course, there's a question of what happens if the work is no longer needed. Samasource's main business is, after all, in providing data for automated systems. What if the process of creating that data becomes automated as well?""That's the billion dollar technology question that everyone is paranoid about,"" Janah said.""I think there's a lot of hype around that. But if you actually talk to data scientists, the minds behind these algorithms, you'll find the machine is much further behind than most people realise. ""We're going to need training data for a long time.""'It has changed my everything'Being a data training expert is boring, repetitive, never-ending work. And when not in front of our cameras, some staff talked about how they faced pressure to work quickly in order to hit company targets, leading to fewer breaks. Some Samasource workers are freelancers who can work anywhere, but with a webcam watching them as they work.Idris lived in the slum, but has since been able to move, and has plans to take a business leadership courseNone of the staff we saw at the office had any kind of acceptable ergonomic support, often crouching over, clicking away furiously, for hours on end - a certain strain to eyes and body. The company has said it would work on that.Complaints about the work - which are certainly not unique in this industry - are quickly followed up with stories of changed lives. Samasource believes it has impacted almost 50,000 people in the developing world; those who either worked at Samasource, or are supported by someone who did. It has surveyed former employees and discovered that around 84% continued on to more formal work or took up higher education.One of those workers moving onto bigger things is Idris Abdi, 25, who was able to move out of the slum.""It has changed my… my everything,"" he said.""It has changed my perspective, it has exposed me to see there is hope beyond living here.""________Follow Dave Lee on Twitter @DaveLeeBBCDo you have more information about this or any other technology story? You can reach Dave directly and securely through encrypted messaging app Signal on: +1 (628) 400-7370What is artificial intelligence?How AI is transforming tennisCould AI replace doctors?",https://www.bbc.com/news/technology-46055595,,,,,,,,,,,,,,,,,https://ichef.bbci.co.uk/news/1024/branded_news/9259/production/_104156473_whatsubject.jpg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3Lm11dHVhbGFydC5jb20vQXJ0aWNsZS9UaGUtUmVhbC1GdXR1cmUtb2YtQXJ0LWFuZC1BcnRpZmljaWFsLUluL0Q3NDFBMEMwQzYwMkY3RTXSAQA?oc=5,An Expert Guide to Art and Artificial Intelligence - MutualArt.com,2018-11-02,MutualArt.com,https://www.mutualart.com,Here's our expert guide to the future of art and AI ,,Mario Klingemann and Anna Ridler give us the expert take on AI and art	,,http://schema.org,Article,https://www.mutualart.com/Article/The-Real-Future-of-Art-and-Artificial-In/D741A0C0C602F7E5,['https://media.mutualart.com/Images//2018_11/01/10/104714346/22c7f88a-174d-4ddf-9212-8788f889d5fc.Jpeg'],"{'@type': 'Person', 'name': 'Adam Heardman'}","{'@type': 'Organization', 'name': 'MutualArt News', 'sameAs': 'https://www.mutualart.com/magazine', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mutualart.com/img/mutualartShareLogo.jpg'}}",An Expert Guide to Art and Artificial Intelligence,11/2/2018 12:00:00 AM,11/2/2018 12:00:00 AM,Features,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vZWRyaS5vcmcvb3VyLXdvcmsvZ3JlZWNlLWNsYXJpZmljYXRpb25zLXNvdWdodC1vbi1odW1hbi1yaWdodHMtaW1wYWN0cy1vZi1pYm9yZGVyY3RybC_SAQA?oc=5,Greece: Clarifications sought on human rights impacts of iBorderCtrl - European Digital Rights (EDRi),2018-11-05,European Digital Rights (EDRi),https://edri.org,,,"On 5 November 2018, EDRi observer Homo Digitalis filed a petition to the Greek Parliament about the pilot implementation of the iBorderCtrl project on the Greek border. The Minister in charge will have 25 days to reply to it.",,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/', 'url': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/', 'name': 'Greece: Clarifications sought on human rights impacts of iBorderCtrl - European Digital Rights (EDRi)', 'isPartOf': {'@id': 'https://edri.org/#website'}, 'primaryImageOfPage': {'@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#primaryimage'}, 'image': {'@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#primaryimage'}, 'thumbnailUrl': 'https://edri.org/wp-content/uploads/2018/11/iBorderCtrl.png', 'datePublished': '2018-11-21T00:00:00+00:00', 'dateModified': '2020-08-26T07:32:19+00:00', 'breadcrumb': {'@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#primaryimage', 'url': 'https://edri.org/wp-content/uploads/2018/11/iBorderCtrl.png', 'contentUrl': 'https://edri.org/wp-content/uploads/2018/11/iBorderCtrl.png', 'width': 600, 'height': 296, 'caption': ''}, {'@type': 'BreadcrumbList', '@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://edri.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Resources', 'item': 'https://edri.org/our-work/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Greece: Clarifications sought on human rights impacts of iBorderCtrl'}]}, {'@type': 'WebSite', '@id': 'https://edri.org/#website', 'url': 'https://edri.org/', 'name': 'European Digital Rights (EDRi)', 'description': 'Protecting digital rights in Europe.', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://edri.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LmFtZXJpY2FtYWdhemluZS5vcmcvcG9saXRpY3Mtc29jaWV0eS8yMDE4LzExLzAyL3doYXQtYXJlLWRhbmdlcnMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utb3VyLWJyYXZlLW5ldy13b3JsZC1zZWxm0gEA?oc=5,"Should we be worried about A.I.? Theologians, philosophers and Catholic thinkers weigh in - America: The Jesuit Review",2018-11-02,America: The Jesuit Review,https://www.americamagazine.org,"As Facebook, Apple and Google pour billions into artificial intelligence, ethicists and moral philosophers are racing to keep up, and Catholic thinkers are looking ahead to the possible harms to humanity.",,"As Facebook, Apple and Google pour billions into artificial intelligence, ethicists and moral philosophers are racing to keep up, and Catholic thinkers are looking ahead to the possible harms to humanity.","As Facebook, Apple and Google pour billions into artificial intelligence, ethicists and moral philosophers are racing to keep up, and Catholic thinkers are looking ahead to the possible harms to humanity.",,,,,,,,,,,,,,,," Politics & SocietyFeaturesNovember 12, 2018 issueShould we be worried about A.I.? Theologians, philosophers and Catholic thinkers weigh inJohn W. MillerNovember 02, 2018FacebookTwitterEmail(iStock)Like paper, print, steel and the wheel, computer-generated artificial intelligence is a revolutionary technology that can bend how we work, play and love. It is already doing so in ways we can and cannot perceive.As Facebook, Apple and Google pour billions into A.I. development, there is a fledgling branch of academic ethical study—influenced by Catholic social teaching and encompassing thinkers like the Jesuit scientist Pierre Teilhard de Chardin—that aims to study its moral consequences, contain the harm it might do and push tech firms to integrate social goods like privacy and fairness into their business plans.Advertisement“There are a lot of people suddenly interested in A.I. ethics because they realize they’re playing with fire,” says Brian Green, an A.I. ethicist at Santa Clara University. “And this is the biggest thing since fire.”“There are a lot of people suddenly interested in A.I. ethics because they realize they’re playing with fire. And this is the biggest thing since fire.”Tweet thisThe field of A.I. ethics includes two broad categories. One is the philosophical and sometimes theological questioning about how artificial intelligence changes our destiny and role as humans in the universe; the other is a set of nuts-and-bolts questions about the impact of powerful A.I. consumer products, like smartphones, drones and social media algorithms.
Recommended for You



The problem with cutting off your family members 
Nathan Beacom





Survey: U.S. Catholics are divided on immigration—even though they know church teaching on it 
Mark M. Gray



AdvertisementThe first is concerned with what is termed artificial general intelligence. A.G.I. describes the kind of powerful artificial intelligence that not only simulates human reasoning but surpasses it by combining computational might with human qualities like learning from mistakes, self-doubt and curiosity about mysteries within and without.A popular word—singularity—has been coined to describe the moment when machines become smarter, and maybe more powerful, than humans. That moment, which would represent a clear break from traditional religious narratives about creation, has philosophical and theological implications that can make your head spin.But before going all the way there—because it is not all that clear that this is ever going to happen—let us talk about the branch of A.I. ethics more concerned with practical problems, like if it is O.K. that your phone knows when to sell you a pizza.Advertisement“For now, the singularity is science fiction,” Shannon Vallor, a philosophy professor who also teaches at Santa Clara, tells me. “There are enough ethical concerns in the short term.”The ‘Black Mirror’ factorWhile we ponder A.G.I., artificial narrow intelligence is already here: Google Maps suggesting the road less traveled, voice-activated programs like Siri answering trivia questions, Cambridge Analytica crunching private data to help swing an election, and military drones choosing how to kill people on the ground. A.N.I. is what animates the androids in the HBO series “Westworld”—that is, until they develop A.G.I. and start making decisions on their own and posing human questions about existence, love and death.Even without the singular, and unlikely, appearance of robot overlords, the possible outcomes of artificial narrow intelligence gone awry include plenty of apocalyptic scenarios, akin to the plots of the TV series “Black Mirror.” A temperature control system, for example, could kill all humans because that would be a rational way to cool down the planet, or a network of energy-efficient computers could take over nuclear plants so it will have enough power to operate on its own.AdvertisementThe more programmers push their machines to make smart decisions that surprise and delight us, the more they risk triggering something unexpected and awful.The invention of the internet took most philosophers by surprise. This time, A.I. ethicists view it as their job to keep up.“There’s a lack of awareness in Silicon Valley of moral questions,” says Tae Wan Kim, an A.I. ethicist at Carnegie Mellon University in Pittsburgh. (John W. Miller)“There’s a lack of awareness in Silicon Valley of moral questions, and churches and government don’t know enough about the technology to contribute much for now,” says Tae Wan Kim, an A.I. ethicist at Carnegie Mellon University in Pittsburgh. “We’re trying to bridge that gap.”A.I. ethicists consult with schools, businesses and governments. They train tech entrepreneurs to think about questions like the following. Should tech companies that collect and analyze DNA data be allowed to sell that data to pharmaceutical firms in order to save lives? Is it possible to write code that offers guidance on whether to approve life insurance or loan applications in an ethical way? Should the government ban realistic sex robots that could tempt vulnerable people into thinking they are in the equivalent of a human relationship? How much should we invest in technology that throws millions of people out of work?Tech companies themselves are steering more resources into ethics, and tech leaders are thinking seriously about the impact of their inventions. A recent survey of Silicon Valley parents found that many had prohibited their own children from using smartphones.The more programmers push their machines to get creative and make smart decisions, the more they risk triggering something unexpected and awful.Tweet thisMr. Kim frames his work as that of a public intellectual, reacting to the latest efforts by corporations to show they are taking A.I. ethics seriously.In June, for example, Google, seeking to reassure the public and regulators, published a list of seven principles for guiding its A.I. applications. It said that A.I. should be socially beneficial, avoid creating or reinforcing unfair bias, be built and tested for safety, be accountable to people, incorporate privacy design principles, uphold high standards of scientific excellence, and be made available to uses that accord with these principles.In response, Mr. Kim published a critical commentary on his blog. The problem with promising social benefits, for example, is that “Google can take advantage of local norms,” he wrote. “If China allows, legally, Google to use AI in a way that violates human rights, Google will go for it.” (At press time, Google had not responded to multiple requests for comment on this criticism.)The biggest headache for A.I. ethicists is that a global internet makes it harder to enforce any universal principle like freedom of speech. The corporations are, for the most part, in charge. That is especially true when it comes to deciding how much work we should let machines do.The invention of the internet took most philosophers by surprise. This time, A.I. ethicists view it as their job to keep up.Tweet thisAn argument familiar to anybody who has ever studied economics is that new technologies create as many jobs as they destroy. Thus the invention of the cotton gin in the 19th century called for industries dedicated to producing the necessary parts of wood and iron. When horses were replaced as a primary form of transportation, stable hands found jobs as auto mechanics. And so on.A.I. ethicists say the current technological revolution is different because it is the first to replicate intellectual tasks. This kind of automation could create a permanently underemployed class of people, says Mr. Kim.A purely economic response to unemployment might be a universal basic income, or distribution of cash to every citizen, but Mr. Kim says A.I. ethicists cannot help returning to the realization that lives without purposeful activity, like a job, are usually miserable. “Catholic social teaching is an important influence for A.I. ethicists, because it addresses how important work is to human dignity and happiness,” he explains.“Money alone doesn’t give your life happiness and meaning,” he says. “You get so many other things out of work, like community, character development, intellectual stimulation and dignity.” When his dad retired from his job running a noodle factory in South Korea, “he got money, but he lost community and self-respect,” says Mr. Kim.That is a strong argument for valuing a job well done by human hands; but as long as we stick with capitalism, the capacity of robots to work fast and cheap is going to make them attractive, say A.I. ethicists.“Maybe religious leaders need to work on redefining what work is,” says Mr. Kim. “Some people have proposed virtual reality work,” he says, referring to simulated jobs within computer games. “That doesn’t sound satisfying, but maybe work is not just gainful employment.”There is also a chance that the impact of automation might not be as bad as feared. A company in Pittsburgh called Legal Sifter offers a service that uses an algorithm to read contracts and detect loopholes, mistakes and omissions. This technology is possible because legal language is more formulaic than most writing. “We’ve increased our productivity seven- or eightfold without having to hire any new people,” says Kevin Miller, the company’s chief executive. “We’re making legal services more affordable to more people.”But he says lawyers will not disappear: “As long as you have human juries, you’re going to have human lawyers and judges…. The future isn’t lawyer versus robot, it’s lawyer plus robot versus lawyer plus robot.”Autonomous cars and the Trolley ProblemThe most common jobs for American men are behind the wheel. Now self-driving vehicles threaten to throw millions of taxi and truck drivers out of work.We are still at least a decade away from the day when self-driving cars occupy major stretches of our highways, but the automobile is so important in modern life that any change in how it works would greatly transform society.Autonomous automobiles raise dozens of issues for A.I. ethicists. The most famous is a variant of the so-called trolley problem, a concept popularized by philosopher Philippa Foot in the 1960s. A current version describes the dilemma a machine might face if a crowded bus is in its fast-moving path. Should it change direction and try to kill fewer people? What if changing direction threatens a child? The baby-or-bus bind one of those instantaneous, tricky and messy decisions that humans accept as part of life, even if we know we do not always make them perfectly. It is the kind of choice for which we know there might never be an algorithm, especially if one starts trying to calculate the relative worth of injuries. Imagine, for example, telling a bicyclist that taking his or her life is worth it to keep a busful of people out of wheelchairs.Technology experts say that the trolley problem is still theoretical because machines presently have a hard time making distinctions between people and things like plastic bags and shopping carts, leading to unpredictable scenarios. This is largely because neuroscientists still have an incomplete grasp of how vision works.Is it morally correct to tell an autonomous car to drive the speed limit when everybody else is driving 20 miles an hour over?”Tweet this“But there are many ethical or moral situations that are likely to happen, and they’re the ones that matter,” says Mike Ramsey, an automotive analyst for Gartner Research.The biggest problem “is programming a robot to break the law on purpose,” he says. “Is it morally correct to tell the computer to drive the speed limit when everybody else is driving 20 miles an hour over?”Humans break rules in reasonable ways all the time. For example, letting somebody out of a car outside of a crosswalk is almost always safe, if not always technically legal. Making that distinction is still almost impossible for a machine.And as programmers try to make this type of reasoning possible for machines, invariably they base their algorithms on data derived from human behavior. In a fallen world, that’s a problem.“There’s a risk of A.I. systems being used in ways that amplify unjust social biases,” says Ms. Vallor, the philosopher at Santa Clara University. “If there’s a pattern, A.I. will amplify that pattern.”Loan, mortgage or insurance applications could be denied at higher rates for marginalized social groups if, for example, the algorithm looks at whether there is a history of homeownership in the family. A.I. ethicists do not necessarily advocate programming to carry out affirmative action, but they say the risk is that A.I. systems will not correct for previous patterns of discrimination.Ethicists are also concerned that relying on A.I. to make life-altering decisions cedes even more influence than they already have to corporations that collect, buy and sell private data, as well as to governments that regulate how the data can be used. In one dystopian scenario, a government could deny health care or other public benefits to people deemed to engage in “bad” behavior, based on the data recorded by social media companies and gadgets like Fitbit.Every artificial intelligence program is based on how a particular human views the world, says Mr. Green, the ethicist at Santa Clara. “You can imitate so many aspects of humanity,” he says, “but what quality of people are you going to copy?”“Copying people” is the aim of a separate branch of A.I. that simulates human connection. A.I. robots and pets can offer the simulation of friendship, family, therapy and even romance.Already, some people say they are in “relationships” with robots, creating strange new ethical questions. Tweet thisOne study found that autistic children trying to learn language and basic social interaction responded more favorably to an A.I. robot than to an actual person. But the philosopher Alexis Elder argues that this constitutes a moral hazard. “The hazard involves these robots’ potential to present the appearance of friendship to a population” who cannot tell the difference between real and fake friends, she writes in the essay collection Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence. “Aristotle cautioned that deceiving others with false appearances is of the same kind as counterfeiting currency.”Another form of counterfeit relationship A.I. technology proposes is, not surprisingly, romance. Makers of new lines of artificial intelligence dolls costing over $10,000 each claim, as one ad says, to “deliver the most enjoyable conversation and interaction you can have with a machine.”Already, some people say they are in “relationships” with robots, creating strange new ethical questions. If somebody destroys your robot, is that murder? Should the government make laws protecting your right to take a robot partner to a ballgame or on an airplane trip, or to take bereavement leave if it breaks?Even Dan Savage, the most famous sex columnist in the United States, sounds a cautionary note. “Sex robots are coming whether we like it or not,” he tells me. “But we will have to take a look at the real impact they’re having on people’s lives.”Pierre Teilhard de Chardin’s wild rideInevitably, ethicists tackling A.N.I. run into the deeper philosophical questions posed by those who study A.G.I. One example of how narrow intelligence can appear to turn into a more general form came when a computer program beat Lee Sedol, a human champion of the strategic game Go, in 2016. Early in the game, the machine, Alpha Go, played a move that did not make sense to its human onlookers until the very end. That mysterious creativity is an intensely human quality, and a harbinger of what A.G.I. might look like.A.G.I. theorists pose their own set of questions. They debate whether tech firms and governments should develop A.G.I. as quickly as possible to work out all the kinks, or block its development in order to forestall machines’ taking over the planet. They wonder what it would be like to implant a chip in our brain that would make us 200 times smarter, or immortal or turn us into God. Might that be a human right? Some even speculate that A.G.I. is itself a new god to be worshipped.But the singularity, if it happens, poses a definite problem for thinkers of almost every religious bent, because it would be such a clear break from traditional narratives.“Christians are facing a real crisis, because our theology is based on how God made us autonomous,” says Mr. Kim, who is a Presbyterian deacon. “But now you have machines that are autonomous, too, so what is it that makes us special as humans?”Pierre Teilhard de Chardin, a French Jesuit and scientist, helped to found a school of thought called transhumanism, which views all technology as an extension of the human self. (AP Image)One Catholic thinker who thought deeply about the impact of artificial intelligence is Pierre Teilhard de Chardin, a French Jesuit and scientist who helped to found a school of thought called transhumanism, which views all technology as an extension of the human self.“His writings anticipated the internet and what the computer could do for us,” says Ilia Delio, O.S.F., a professor at Villanova.Teilhard de Chardin viewed technology with a wide lens. “The New Testament is a type of technology,” says Sister Delio, explaining the point of view. “Jesus was about becoming something new, a transhuman, not in the sense of betterment, but in the sense of more human.”Critics of transhumanism say that it promotes materialistic and hedonistic points of view. In a recent essay in America, John Conley, S.J., of Loyola University Maryland, called the movement “a cause for alarm.” He wrote: “Is there any place for people with disabilities in this utopia? Why would we want to abolish aging and dying, essential constituents of the human drama, the fountainhead of our art and literature? Can there be love and creativity without anguish? Who will flourish and who will be eliminated in this construction of the posthuman? Does nature itself have no intrinsic worth?”Teilhard’s writings have also been tainted by echoes of the racist eugenics popular in the 1920s. He contended, for example, that “not all ethnic groups have the same value.”But his purely philosophical arguments about technology have regained currency among Catholic thinkers this century, and reading Teilhard can be a wild ride. Christian thinkers conventionally say, as St. John Paul II did, that every technological conception should advance the natural development of the human person. Teilhard went farther. He reasoned that technology, including artificial intelligence, could link all of humanity, bringing us to a point of ultimate spiritual unity through knowledge and love. He termed the moment of global spiritual coming-together the Omega Point. And it was not the kind of consumer conformism that tech executives dream about.“Now you have machines that are autonomous, too, so what makes us special as humans?”Tweet this“This state is obtained not by identification (God becoming all) but by the differentiating and communicating action of love (God all in everyone). And that is essentially orthodox and Christian,” Teilhard wrote.RELATED STORIES What would Jesus do about Artificial Intelligence? Become more human.Simcha Fisher How the church can help fight the tyranny of algorithmsJim McDermott Why we need a new theology of workJonathan Malesic  Internet privacy is about the common good, not just competition and consumersThe EditorsThis idealism is similar to that of Tim Berners-Lee, one of the scientists who wrote the software that created the internet. The purpose of the web was to serve humanity, he said in a recent interview with Vanity Fair. But centralized and corporate control, he said, has “ended up producing—with no deliberate action of the people who designed the platform—a large-scale emergent phenomenon which is anti-human.” He and others now say the accumulation and selling of personal data dehumanizes and commodifies people, instead of enhancing their humanity.Interestingly, the A.I. debate provokes theological questioning by people who usually do not talk all that much about God.Juan Ortiz Freuler, a policy fellow at the Washington-based World Wide Web Foundation, which Mr. Berners-Lee started to protect human rights, says he hears people in the tech industry “argue that a system so complex we can’t understand it is like a god.” But it is not a god, says Mr. Freuler. “It’s a company wearing the mask of a god. And we don’t always know what their values are.”You do not have to worship technology as a god to realize that our choices, and lives, are increasingly influenced by decision-making software. But as every A.I. ethicist I talked to told me, we should not be confused about who is responsible for making the important decisions.“We still have our freedom,” says Sister Delio. “We can still make choices.”FacebookTwitterEmailMore: Science / TechnologyJohn W. MillerJohn W. Miller is a Pittsburgh-based writer and former staff reporter and foreign correspondent for The Wall Street Journal.@jwmjournalistShow Comments ( 3)Comments are automatically closed two weeks after an article's initial publication. See our comments policy for more.Stanley Kopacz5 years 8 months agoA human Go player has played perhaps tens of thousands of games. I believe the Go-playing AI played millions of games with itself, losing and winning millions of games in preparation. The level of ""experience"" is higher. In the case of any rule based game, the number of possibilities is defined enough. The question is whether a similar process can be applied to real life situations. In this case, the AI would have to play millions of games in a simulation and its skill level would depend if the simulation is accurate and complex enough to mirror reality. Or so I understand it. I guess I should get a textbook on neural networks. What fascinates me is not so much that we can do the things we do but that we are aware of the doing. Very strange.Charles Erlinger5 years 8 months agoAn article in the September, 2018 issue of the Institute of Electronic and Electrical Engineers publication “Computer” by Plamen P. Angelov and Xiaowei Gu of Lancaster University, entitled “Toward Anthropomorphic Machine Learning” sprinkles a little engineering reality on the capability of some of the more popular approaches to Artificial Intelligence that various commercial and governmental entities attempt to implement. The approach in question is called “Deep Learning Neural Networks” or DLNN. The authors supply end-note superscripts that refer to sources that the authors use to corroborate their case, but the notes are not reproduced here, for brevity.“LIMITS AND CHALLENGES OF DEEP LEARNING“The mainstream DLNNs, despite their success (reported results are comparable to or superior to human ability) and publicity (including the commercial version), as well as increasing media interest, still have a number of unanswered questions and deficiencies, as described below.“The internal architecture of DLNNs is opaque … (there are many ad hoc decisions and parameters, such as number of layers, neurons, and parameter values).“The training process of DLNNs requires a large amount of  data, time, and computational resources, which preclude training and adaptation in real time; therefore, DLNNs cannot cope with the evolving nature of the data (they have a fixed structure and settings, for example, the number of classes), and they also cannot learn ‘from scratch.’“DLNNs are prone to overfitting. DLNNs cannot handle uncertainty. Not only do they perform poorly on inference data that is significantly different from the training data, but they are also UNAWARE of this (meaning that it is practically impossible to analyze the reasons for errors and failures); they can be easily fooled and thus output high-confidence scores even when facing unrecognizable images.“The whole article and, indeed the entire issue is worth reading. It should be noted that technologists often take ethical issues just as seriously as do ethicists.On a slightly different issue related to the use of AI, it seems that we often forget the layers of protection provided by law and regulation on the safety and effectiveness of human and technology-assisted services that affect public safety. There is a reason for the state-federal licensing system for physicians, engineers who do public engineering projects, lawyers, teachers, various clinicians doing counseling-related work, aviation certifications, drug approvals, and many more professional and skilled trade services and providers. The licensing process involves documented years of pre-licensing experience, formal testing using approved protocols, and background checking. Applying similar standards to AI-generated services affecting public safety and welfare will demand that AI systems be fully susceptible to analysis to insure safety and effectiveness, which means that the processes must be understandable to legislative and regulatory staffs.Santosh Kumar5 years 8 months agoGlobal Digital Forum (GDF) is a global technology conference that has been uniquely designed to bring together an unparalleled line-up of business leaders, practitioners and customers from all over the world, engaged in driving change at the intersection of Artificial Intelligence, Security/Blockchain, Cloud Services and Internet-of-Things and key industry verticals.Register here: http://promotions.plantautomation-technology.com/global-digital-forum-event 

More from America






Ageism is making it impossible to fairly judge Joe Biden
Lynn Casteel Harper





After 35 years, a final settlement reached in the Mount Cashel Orphanage sex abuse cases
Kevin Clarke





‘Stop Donald Trump’ isn’t enough. The Democratic Party needs a deeper message to win the election.
Robert David Sullivan





Mass isn’t a ‘show.’ But it has plenty of drama.
Rebecca Moon Ruark





When the suburban American dream conflicts with Catholic social teaching
Dominic Gideon



Your source for jobs, books, retreats, and much more.Come Join UsVolunteer / VocationDirector of Faith FormationJobs“Our Hope is in Christ” USCCA International Conference August 2-4, 2024 @ DePaul University – Registration Open through July 30!Conferences, EventsSpiritual Practices – An online courseSpiritual ResourcesSacred Heart Seminary and School of TheologySeminaries & Theology StudiesSee all Classifieds 
What to Read Next






Pro-life activists react to GOP platform change on abortion at Trump’s direction
Pro-life activists are pushing back against the Republican Party's new, Trump-directed platform, which appears to soften the party's stance on abortion.

Kate Scanlon - OSV News
July 10, 2024






Latin Patriarchate of Jerusalem condemns Israeli army attack on Catholic school
Following an Israeli attack on Holy Family, a Catholic school turned shelter for hundreds of civilians, the Latin Patriarchate of Jerusalem condemned the attack and called for a cease-fire agreement.

OSV News
July 10, 2024






Trump injured but 'fine' after attempted assassination at rally, shooter and one attendee are dead
Trump’s campaign said the presumptive GOP nominee was doing “fine” after the shooting, which he said pierced the upper part of his right ear.

Jill Colvin,Julie Carr Smyth,Eric Tucker and Michelle L. Price — Associated Press
July 13, 2024






Catholic bishops call for prayers for peace, healing in wake of Trump assassination attempt
""Together with my brother bishops, we condemn political violence, and we offer our prayers for President Trump, and those who were killed or injured,"" said Archbishop Broglio, the president of the U.S. Conference of Catholic Bishops.

Kate Scanlon - OSV News
July 14, 2024






‘Brain death’ and organ donation as culture war issues
In response to an article in our June issue, several physicians and ethicists say there are serious questions about the accuracy of determining brain death under the current criteria.

Our readers
June 27, 2024




 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LnNjaWVudGlmaWNhbWVyaWNhbi5jb20vYXJ0aWNsZS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pcy1sZWFybmluZy10by1rZWVwLWxlYXJuaW5nL9IBAA?oc=5,Artificial Intelligence Is Learning to Keep Learning - Scientific American,2018-11-01,Scientific American,https://www.scientificamerican.com,"Scientific American is the essential guide to the most awe-inspiring advances in science and technology, explaining how they change our understanding of the world and shape our lives.",,A new machine-learning technique mimics the brain’s ability to adapt to new circumstances,A new machine-learning technique mimics the brain’s ability to adapt to new circumstances,https://schema.org,NewsMediaOrganization,https://www.scientificamerican.com/,"['https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?w=1200', 'https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?crop=16%3A9%2Csmart&w=1920', 'https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?crop=4%3A3%2Csmart&w=1200', 'https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?crop=1%3A1%2Csmart&w=1000']","[{'@type': 'Person', 'name': 'Matthew Hutson', 'url': 'https://www.scientificamerican.com/author/matthew-hutson/'}]","{'@id': 'https://www.scientificamerican.com/#publisher', 'name': 'Scientific American'}",Artificial Intelligence Is Learning to Keep Learning,2018-11-01T13:00:00+00:00,2024-02-20T12:15:03.161000+00:00,,Scientific American,False,,,,"November 1, 20182 min readArtificial Intelligence Is Learning to Keep LearningA new machine-learning technique mimics the brain’s ability to adapt to new circumstancesBy Matthew Hutson Thomas FuchsNovember 2018 IssueComputingWhat if you stopped learning after graduation? It sounds stultifying, but that is how most machine-learning systems are trained. They master a task once and then are deployed. But some computer scientists are now developing artificial intelligence that learns and adapts continuously, much like the human brain.Machine-learning algorithms often take the form of a neural network, a large set of simple computing elements, or neurons, that communicate via connections between them that vary in strength, or “weight.” Consider an algorithm designed to recognize images. If it mislabels a picture during training, the weights are adjusted. When mistakes are reduced below a certain threshold, the weights are frozen at set values.The new technique splits each weight into two values that combine to influence how much one neuron can activate another. The first value is trained and frozen as in traditional systems. But the second value continually adjusts in response to surrounding activity in the network. Critically, the algorithm also learns how adjustable to make these weights. So the neural network learns patterns of behavior, as well as how much to modify each part of that behavior in response to new circumstances. The researchers presented their technique in July at a conference in Stockholm, Sweden.Applying the technique, the team created a network that learned to reconstruct half-erased photographs after seeing the full images only a few times. In contrast, a traditional neural network would need to see many more images before it could reconstruct the original. The researchers also created a network that learned to identify handwritten alphabet letters—which are nonuniform, unlike typed ones—after seeing one example.In another task, neural networks controlled a character moving in a simple maze to find rewards. After one million trials, a network with the new semiadjustable weights could find each reward three times as often per trial as could a network with only fixed weights. The static parts of the semiadjustable weights apparently learned the structure of the maze, whereas the dynamic parts learned how to adapt to new reward locations. “This is really powerful,” says Nikhil Mishra, a computer scientist at the University of California, Berkeley, who was not involved in the research, “because the algorithms can adapt more quickly to new tasks and new situations, just like humans would.”Thomas Miconi, a computer scientist at the ride-sharing company Uber and the paper's lead author, says his team now plans to tackle more complicated tasks, such as robotic control and speech recognition. In related work, Miconi wants to simulate “neuromodulation,” an instant networkwide adjustment of adaptability that allows humans to sop up information when something novel or important happens.Rights & PermissionsMatthew Hutson is a freelance science writer based in New York City and author of The 7 Laws of Magical Thinking.More by Matthew HutsonThis article was originally published with the title “Lifelong Learning” in Scientific American Magazine Vol. 319 No. 5 (November 2018), p. 14doi:10.1038/scientificamerican1118-14bView This Issue","{'@type': 'WebPage', '@id': 'https://www.scientificamerican.com/article/artificial-intelligence-is-learning-to-keep-learning/', 'breadcrumb': {'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Computing', 'item': 'https://www.scientificamerican.com/computing/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence Is Learning to Keep Learning', 'item': 'https://www.scientificamerican.com/article/artificial-intelligence-is-learning-to-keep-learning/'}]}}",Artificial Intelligence Is Learning to Keep Learning,,"{'@id': 'https://www.scientificamerican.com/#publisher', 'name': 'Scientific American'}",,,,"{'@type': 'ImageObject', 'url': 'https://www.scientificamerican.com/static/sciam.svg'}",https://www.scientificamerican.com/#publisher,,,https://www.scientificamerican.com/masthead/,1845-08-28,"['https://en.wikipedia.org/wiki/Scientific_American', 'https://www.wikidata.org/wiki/Q39379', 'https://www.jstor.org/publisher/sciamerican', 'https://x.com/sciam', 'https://www.youtube.com/user/SciAmerican', 'https://www.tiktok.com/@scientificamerican', 'https://www.threads.net/@scientific_american', 'https://www.facebook.com/ScientificAmerican/']",,,,https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?w=1200,,SciAm,"Scientific American, a Division of Springer Nature America, Inc.","{'@type': 'PostalAddress', 'streetAddress': '1 New York Plaza', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10004', 'addressCountry': 'US'}",,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvdGhlLWltcGxpY2F0aW9ucy1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mb3ItbmF0aW9uYWwtc2VjdXJpdHktc3RyYXRlZ3kv0gEA?oc=5,The implications of artificial intelligence for national security strategy | Brookings - Brookings Institution,2018-11-01,Brookings Institution,https://www.brookings.edu,Mara Karlin examines the potential effects of AI on national security.,,Mara Karlin examines the potential effects of AI on national security.,,https://schema.org,,,,,,,,,,,,,,,"

 Who has to leave the Federal Reserve next? 









                        Who has to leave the Federal Reserve next? 
",,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/', 'url': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/', 'name': 'The implications of artificial intelligence for national security strategy | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2018/07/RTXT2UT.jpg?quality=75', 'datePublished': '2018-11-01T04:01:17+00:00', 'dateModified': '2022-03-09T04:03:16+00:00', 'description': 'Mara Karlin examines the potential effects of AI on national security.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2018/07/RTXT2UT.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2018/07/RTXT2UT.jpg?quality=75', 'width': 3936, 'height': 2656, 'caption': ""Personnel work at the Air Force Space Command Network Operations &amp; Security Center at Peterson Air Force Base in Colorado Springs, Colorado July 20, 2010. U.S. national security planners are proposing that the 21st century's critical infrastructure -- power grids, communications, water utilities, financial networks -- be similarly shielded from cyber marauders and other foes. The ramparts would be virtual, their perimeters policed by the Pentagon and backed by digital weapons capable of circling the globe in milliseconds to knock out targets. To match Special Report USA-CYBERWAR/ REUTERS/Rick Wilking (UNITED STATES - Tags: MILITARY SCI TECH POLITICS) - GM1E6A51SA301""}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'The implications of artificial intelligence for national security strategy'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LnNjcmlwcHNuZXdzLmNvbS9zY2llbmNlLWFuZC10ZWNoL3doby1vd25zLWFydC1jcmVhdGVkLWJ5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Who Owns Art Created by Artificial Intelligence? (VIDEO) - Scripps News,2018-11-02,Scripps News,https://www.scrippsnews.com,A painting created by AI sold for close to half a million dollars — and also raised questions about ownership.,,A painting created by AI sold for close to half a million dollars — and also raised questions about ownership.,A painting created by AI sold for close to half a million dollars — and also raised questions about ownership.,http://schema.org,Article,,"{'@context': 'http://schema.org', '@type': 'ImageObject'}","[{'@context': 'http://schema.org', '@type': 'Person', 'description': 'Cat is a Chicago-based national correspondent where she writes, produces, reports and video edits stories that impact our community.', 'email': 'Cat.Sandoval@scripps.com', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject'}, 'jobTitle': 'National Correspondent', 'name': 'Cat Sandoval', 'url': 'https://www.scrippsnews.com/cat-sandoval'}]","{'@type': 'Organization', 'name': 'Scripps News (SNEWS)', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://ewscripps.brightspotcdn.com/ec/77/0ffb626a43ec98d505a2d353f0b1/main-logo.png'}}","When Artificial Intelligence Creates Art, Who Owns It?",2018-11-02T21:04:26-0400,2018-11-02T21:04:26-0400,,,,,Science and Tech,,"

Science and Tech


Actions



Facebook



Tweet


Email







When Artificial Intelligence Creates Art, Who Owns It?
A painting created by AI sold for close to half a million dollars — and also raised questions about ownership.









  Prev
Next  









  








  











By:
Cat Sandoval



Posted at 9:04 PM, Nov 02, 2018 




When artificial intelligence produces a work of art, who owns the final product? Not the AI machines — not yet. There are still a lot of human components that play a part. I mean, if a judge didn't give this monkey copyright to his own selfie, then a machine can't technically own anything either. Auction House Christie's sold the first AI-created painting for nearly half a million dollars. Paris art collective Obvious oversaw the creation.""It tries to replicate what any artist would do, like trying to create from what it knows. It forces you to try to understand your own creativity and how you'd be able to replicate it,"" Gauthier Vernier of Obvious said.  In the ""Edmond de Belamy"" painting, humans played a role. So it makes sense that humans own the final output. They, after all, wrote the computer codes and fed the machine 15,000 reference paintings that taught the AI machine how to paint. The GANs AI machine works by using two algorithms: one creates art and a discriminator algorithm that distinguishes between human-made and computer-made art. It's when the discriminator can no longer tell the painting was created by a computer that the art is complete.  ""If the discriminator is able to say, 'wait a minute that's created by a computer' the generator runs it again and the cycle finishes when the discriminator says, 'I give up, I can't tell,'"" said Richard Lloyd, Christie's international department head of prints and multiples. Related StoryRobot Farms Are Here. What Can Farmers Expect?In the case of Bellamy's painting, ownership can be complicated as said by a Christie's spokesperson: ""Is it the person that wrote the algorithm? Is it sort of the combination of the artwork that was uploaded or is it the people that tweaked the software? And I think this is why its so inspiring and interesting because we've never really have to ask these questions before.""Obvious acknowledged they relied on other innovations: the GANs AI tool (created by someone else) and a majority of the open source code from Robbie Barrat. On Twitter, Barrat wrote: ""Am I crazy for thinking that they really just used my network and are selling results?""AI created art and ownership doesn't have to be complicated like the Bellamy painting. When AI is used as a tool for creativity, users of the program retain ownership. Take Google's Deep Dream Generator, which transforms user images into dream visions. Two pieces of art sold for $8,000 each — and the users reaped the profits. 


Copyright 2024 Scripps Media, Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.




Most Recent













Republican delegates officially nominate Trump for president


      Scripps News Staff
    

3:23 PM, Jul 15, 2024 













Donald Trump picks Sen. J.D. Vance as VP running mate


      Scripps News Staff
    

3:09 PM, Jul 15, 2024 













Maker of TurboTax says it's laying off 1,800 workers, also hiring 1,800 others


      Justin Boggs
    

2:27 PM, Jul 15, 2024 








Science and Tech













World's first hydrogen-powered commercial ferry to run on San Francisco Bay


      AP via Scripps News 
    

9:35 AM, Jul 13, 2024 













Hundreds of thousands of people in Houston could be without power this weekend


      John Mone
    

9:22 PM, Jul 12, 2024 













Meta cautiously ended Donald Trump's suspension, now further loosens oversight


      Douglas Jones
    

6:52 PM, Jul 12, 2024 

















Watch Scripps News



","{'@type': 'WebPage', '@id': 'https://www.scrippsnews.com/science-and-tech/who-owns-art-created-by-artificial-intelligence'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmhlYWx0aGNhcmVpdG5ld3MuY29tL25ld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtMy1jaGFydHMtcmV2ZWFsLXdoYXQtaG9zcGl0YWxzLW5lZWQtbmVhci1mdXR1cmXSAQA?oc=5,Artificial Intelligence: 3 charts reveal what hospitals need in the near future - Healthcare IT News,2018-11-01,Healthcare IT News,https://www.healthcareitnews.com,"AI is already having a big impact, but strategic planning is not keeping pace and healthcare organizations need to be proactive about developing tools now.",,"AI is already having a big impact, but strategic planning is not keeping pace and healthcare organizations need to be proactive about developing tools now.","AI is already having a big impact, but strategic planning is not keeping pace and healthcare organizations need to be proactive about developing tools now.",,,,,,,,,,,,,,,,"
HIMSS24 EUROPEAN HEALTH CONFERENCE & EXHIBITIONBetter patient outcomes and stronger workforces are a team project. At HIMSS24 Europe, we’ve built a programme to arm you and your peers with the insights you need to transform health systems back at home.May 29-31, 2024 | RomeLearn More ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDE4LzExLzEvMTgwNTExOTYvYWktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY3VyaW9zaXR5LW9wZW5haS1tb250ZXp1bWFzLXJldmVuZ2Utbm9pc3ktdHYtcHJvYmxlbdIBAA?oc=5,How teaching AI to be curious helps machines learn for themselves - The Verge,2018-11-01,The Verge,https://www.theverge.com,"Artificial intelligence can learn for itself if we teach it to be curious. New research from the Elon Musk-founded lab OpenAI shows how this concept can help an AI agent play Montezuma’s Revenge, an Atari game that’s long proved to be a challenge for machine learning.",,Curiouser and curiouser,,http://schema.org/,NewsArticle,https://www.theverge.com/2018/11/1/18051196/ai-artificial-intelligence-curiosity-openai-montezumas-revenge-noisy-tv-problem,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/TJsqCTrfa8Fyevejn3i8aGeLJjI=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292775/acastro_181017_1777_brain_ai_0003.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/hMHUPD6pVNljiVFqgYupuIUJPQk=/0x0:2040x1360/1400x1050/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292775/acastro_181017_1777_brain_ai_0003.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/28jXduznhdHlBZjMTbIUzB7E_UM=/0x0:2040x1360/1400x1400/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292775/acastro_181017_1777_brain_ai_0003.jpg', 'width': 1400, 'height': 1400}]","[{'@type': 'Person', 'name': 'James Vincent', 'url': 'https://www.theverge.com/authors/james-vincent'}]","{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",How teaching AI to be curious helps machines learn for themselves,2018-11-01T15:11:22.000Z,2018-11-01T15:11:22.000Z,,,,,,,"TechHow teaching AI to be curious helps machines learn for themselvesNew research from OpenAI uses curious AI to beat video gamesBy  James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge. Nov 1, 2018, 11:11 AM EDTShare this story1 Comment / 1 New Illustration by Alex Castro / The VergeWhen playing a video game, what motivates you to carry on? This question is perhaps too broad to yield a single answer, but if you had to sum up why you accept that next quest, jump into a new level, or cave and play just one more turn, the simplest explanation might be “curiosity” — just to see what happens next. And as it turns out, curiosity is a very effective motivator when teaching AI to play video games, too. In a game without rewards, teaching AI is difficultResearch published this week by artificial intelligence lab OpenAI explains how an AI agent with a sense of curiosity outperformed its predecessors playing the classic 1984 Atari game Montezuma’s Revenge. Becoming skilled at Montezuma’s Revenge is not a milestone equivalent to beating Go or Dota 2, but it’s still a notable advance. When the Google-owned DeepMind published its seminal 2015 paper explaining how it beat a number of Atari games using deep learning, Montezuma’s Revenge was the only game it scored 0 percent on. The reason for the game’s difficulty is a mismatch between the way it plays and the way AI agents learn, which also reveals a blind spot in machine learning’s view of the world.Usually, AI agents rely on a training method called reinforcement learning to master video games. In this paradigm, agents are dumped into virtual world, and rewarded for some outcomes (like increasing their score) and penalized for others (like losing a life). The agent starts playing the game random, but learns to improve its strategy through trial and error. Reinforcement learning is often thought of as a key method for building smarter robots.The problem with Montezuma’s Revenge is that it doesn’t provide regular rewards for the AI agent. It’s a puzzle-platformer where players have to explore an underground pyramid, dodging traps and enemies while collecting keys that unlock doors and special items. If you were training an AI agent to beat the game, you could reward it for staying alive and collecting keys, but how do you teach it to save certain keys for certain items, and use those items to overcome traps and complete the level? The answer: curiosity. In OpenAI’s research, their agent was rewarded not just for leaping over pits of spikes, but for exploring new parts in the pyramid. This led to better-than-human performance, with the bot earning a mean score of 10,000 over nine runs (compared to an average human score of 4,000). In one run, it even completed the first of the game’s nine levels. “There’s definitely still a lot of work to do,” OpenAI’s Harrison Edwards tells The Verge. “But what we have at the moment is a system that can explore lots of rooms, get lots of rewards, and occasionally get past the first level.” He adds that the game’s other levels are similar to the first, so playing through the whole thing “is just a matter of time.” Beating the “Noisy TV problem”OpenAI is far from the first lab to try this approach, and AI researchers have been leveraging the concept of “curiosity” as motivation for decades. They’ve also applied it to Montezuma’s Revenge before, though never so successfully without teaching AI to learn from human examples. However, while the general theory here is well-established, building specific solutions is still challenging. For example, prediction-based curiosity is only useful when learning to play certain types of games. It works for titles like Mario, for example, where there are big levels to explore, full of never-before-seen bosses and enemies. But for simpler games like Pong, AI agents prefer to play long rallies rather than actually beat their opponents. (Perhaps because winning the game is more predictable than following path of the ball.) AI can become addicted to random rewards, just like humansAnother issue is the “Noisy TV problem,” which is where AI agents that have been programmed to seek out new experiences get addicted to random patterns, such as a TV tuned to static noise. This is because these agents’ sense of what is “interesting” and “new” comes from their ability to predict the future. Before they take a certain action they predict what the game will look like afterwards. If they guess correctly, chances are they’ve seen this part of the game before. This mechanism is known as “prediction error.” But because static noise is unpredictable, the result is that any AI agent confronted with such a TV (or a similarly unpredictable stimulus) becomes mesmerized. OpenAI compares the problem to human gamblers who are addicted to slot machines, unable to tear themselves away because they don’t know what’s going to happen next. This GIF shows an AI agent exploring a maze and getting distracted by random flashing images.  GIF: OpenAIThis new research from OpenAI sidesteps this issue by varying how the AI predicts the future. The exact methodology (named Random Network Distillation) is complex, but Edwards and his colleague Yuri Burda compare it to hiding a secret for the AI to find in every screen of the game. That secret is random and meaningless (something like, “what is the color in the top left of the screen?” suggests Edwards), but it motivates the agent to explore without leaving it vulnerable to the Noisy TV trap. More importantly, this motivator doesn’t require a lot of calculation, which is incredibly important. These reinforcement learning methods rely on huge amounts of data to train AI agents (OpenAI’s bot, for example, had to play Montezuma’s Revenge for the real-time equivalent of three years) so every step of the journey needs to be as quick as possible. “It is actually much simpler than other methods of exploration.”Arthur Juliani, a software engineer at Unity and machine learning expert, says this is what makes OpenAI’s work impressive. “The method they use is really quite simple and therefore surprisingly effective,” Juliani tells The Verge. “It is actually much simpler than other methods of exploration which have been applied to the game in the past (and [which have] not led to nearly as impressive results).” Juliani says that given the similarities between different levels in Montezuma’s Revenge, OpenAI’s work is “essentially equivalent” to solving the game, but he adds that “the fact that they aren’t able to consistently beat the first level means that there is still some of an open challenge left.” He also wonders whether their approach will work in 3D games, where visual features are more subtle and a first-person view occludes much of the world. “In scenarios where exploration is required, but the differences between parts of the environment are more subtle, the method may not perform as well,” says Juliani.Robots in the real world, like Boston Dynamics’ SpotMini, could also benefit from artificial curiosity.  Photo by Matt Winkelmeyer / Getty Images for WIRED25The point of curiosityBut why do we need curious AI in the first place? What good does it do us, apart from providing humorous parallels to our human tendency to get ensnared by random patterns The big reason is that curiosity helps computers learn on their own. Most machine learning approaches deployed today can be split into two camps: in the first, machines learn by looking at piles of data, working out patterns they can apply to similar problems; and in the second, they’re dropped into an environment and rewarded for achieving certain outcomes using reinforcement learning. Both of these approaches are effective at specific tasks, but they also require a lot of human labor, either labeling training data or designing reward functions for virtual environments. By giving AI systems an intrinsic incentive to explore for explorations’ sake, some of this work is eliminated and humans spend less time holding their AI agent’s hands. (Metaphorically speaking.) OpenAI’s Edwards and Burda say that this sort of curiosity-driven learning system is much better for building computer programs that have to operate in the real world. After all, in reality, as in Montezuma’s Revenge, immediate rewards are often scarce, and we need to work, learn, and explore for long periods of time before we get anything in return. Curiosity helps us keep going, and maybe it can help computers, too. Comments1 Comment / 1 NewFeatured Videos From The VergeTesla’s big, epic, confusing future | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge’s David Pierce and Andy Hawkins discuss the latest at Tesla: new products, new initiatives, and a payday for Elon Musk. Vee Song joins the show to discuss updates to the Apple Watch, a new Samsung Galaxy Watch, and more wearable news. David and Liam James answer a question from the Vergecast Hotline about weather apps.Most PopularMost PopularGoogle is reportedly planning its biggest startup acquisition everAT&T reportedly gave $370,000 to a hacker to delete its stolen customer dataHere’s how much Valve pays its staff — and how few people it employsAmazon’s press-to-order Dash buttons are officially discontinuedComplaints about crashing 13th, 14th Gen Intel CPUs now have data to back them up Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",,,,,,,,,,,,,,,,,"When playing a video game, what motivates you to carry on? 

This question is perhaps too broad to yield a single answer, but if you had to sum up why you accept that next quest, jump into a new level, or cave and play just one more turn, the simplest explanation might be “curiosity” — just to see what happens next. And as it turns out, curiosity is a very effective motivator when teaching AI to play video games, too. 

""In a game without rewards, teaching AI is difficult""

Research published this week by artificial intelligence lab OpenAI explains how an AI agent with a sense of curiosity outperformed its predecessors playing the classic 1984 Atari game Montezuma’s Revenge. Becoming skilled at Montezuma’s Revenge is not a milestone equivalent to beating Go or Dota 2, but it’s still a notable advance. When the Google-owned DeepMind published its seminal 2015 paper explaining how it beat a number of Atari games using deep learning, Montezuma’s Revenge was the only game it scored 0 percent on. 

The reason for the game’s difficulty is a mismatch between the way it plays and the way AI agents learn, which also reveals a blind spot in machine learning’s view of the world.

Usually, AI agents rely on a training method called reinforcement learning to master video games. In this paradigm, agents are dumped into virtual world, and rewarded for some outcomes (like increasing their score) and penalized for others (like losing a life). The agent starts playing the game random, but learns to improve its strategy through trial and error. Reinforcement learning is often thought of as a key method for building smarter robots.

[Media: https://www.youtube.com/watch?v=40VZeFppDEM]

The problem with Montezuma’s Revenge is that it doesn’t provide regular rewards for the AI agent. It’s a puzzle-platformer where players have to explore an underground pyramid, dodging traps and enemies while collecting keys that unlock doors and special items. If you were training an AI agent to beat the game, you could reward it for staying alive and collecting keys, but how do you teach it to save certain keys for certain items, and use those items to overcome traps and complete the level? 

The answer: curiosity. 

In OpenAI’s research, their agent was rewarded not just for leaping over pits of spikes, but for exploring new parts in the pyramid. This led to better-than-human performance, with the bot earning a mean score of 10,000 over nine runs (compared to an average human score of 4,000). In one run, it even completed the first of the game’s nine levels. 

“There’s definitely still a lot of work to do,” OpenAI’s Harrison Edwards tells The Verge. “But what we have at the moment is a system that can explore lots of rooms, get lots of rewards, and occasionally get past the first level.” He adds that the game’s other levels are similar to the first, so playing through the whole thing “is just a matter of time.” 

Beating the “Noisy TV problem”

OpenAI is far from the first lab to try this approach, and AI researchers have been leveraging the concept of “curiosity” as motivation for decades. They’ve also applied it to Montezuma’s Revenge before, though never so successfully without teaching AI to learn from human examples. 

However, while the general theory here is well-established, building specific solutions is still challenging. For example, prediction-based curiosity is only useful when learning to play certain types of games. It works for titles like Mario, for example, where there are big levels to explore, full of never-before-seen bosses and enemies. But for simpler games like Pong, AI agents prefer to play long rallies rather than actually beat their opponents. (Perhaps because winning the game is more predictable than following path of the ball.) 

""AI can become addicted to random rewards, just like humans""

Another issue is the “Noisy TV problem,” which is where AI agents that have been programmed to seek out new experiences get addicted to random patterns, such as a TV tuned to static noise. This is because these agents’ sense of what is “interesting” and “new” comes from their ability to predict the future. Before they take a certain action they predict what the game will look like afterwards. If they guess correctly, chances are they’ve seen this part of the game before. This mechanism is known as “prediction error.” 

But because static noise is unpredictable, the result is that any AI agent confronted with such a TV (or a similarly unpredictable stimulus) becomes mesmerized. OpenAI compares the problem to human gamblers who are addicted to slot machines, unable to tear themselves away because they don’t know what’s going to happen next. 

[Image: This GIF shows an AI agent exploring a maze and getting distracted by random flashing images. https://cdn.vox-cdn.com/thumbor/dnJfvqLW010qC6-har7LD5f5b0Q=/0x0:632x476/632x476/filters:focal(316x238:317x239):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/13369609/noisy_tv_problem.gif]

This new research from OpenAI sidesteps this issue by varying how the AI predicts the future. The exact methodology (named Random Network Distillation) is complex, but Edwards and his colleague Yuri Burda compare it to hiding a secret for the AI to find in every screen of the game. That secret is random and meaningless (something like, “what is the color in the top left of the screen?” suggests Edwards), but it motivates the agent to explore without leaving it vulnerable to the Noisy TV trap. 

More importantly, this motivator doesn’t require a lot of calculation, which is incredibly important. These reinforcement learning methods rely on huge amounts of data to train AI agents (OpenAI’s bot, for example, had to play Montezuma’s Revenge for the real-time equivalent of three years) so every step of the journey needs to be as quick as possible. 

""“It is actually much simpler than other methods of exploration.”""

Arthur Juliani, a software engineer at Unity and machine learning expert, says this is what makes OpenAI’s work impressive. “The method they use is really quite simple and therefore surprisingly effective,” Juliani tells The Verge. “It is actually much simpler than other methods of exploration which have been applied to the game in the past (and [which have] not led to nearly as impressive results).” 

Juliani says that given the similarities between different levels in Montezuma’s Revenge, OpenAI’s work is “essentially equivalent” to solving the game, but he adds that “the fact that they aren’t able to consistently beat the first level means that there is still some of an open challenge left.” He also wonders whether their approach will work in 3D games, where visual features are more subtle and a first-person view occludes much of the world. 

“In scenarios where exploration is required, but the differences between parts of the environment are more subtle, the method may not perform as well,” says Juliani.

[Image: Robots in the real world, like Boston Dynamics’ SpotMini, could also benefit from artificial curiosity. https://cdn.vox-cdn.com/thumbor/RurxOpQu7qNOhZmq31Hlp4EQChQ=/0x0:5568x3712/5568x3712/filters:focal(2784x1856:2785x1857)/cdn.vox-cdn.com/uploads/chorus_asset/file/13369543/1052216080.jpg.jpg]

The point of curiosity

But why do we need curious AI in the first place? What good does it do us, apart from providing humorous parallels to our human tendency to get ensnared by random patterns 

The big reason is that curiosity helps computers learn on their own. 

Most machine learning approaches deployed today can be split into two camps: in the first, machines learn by looking at piles of data, working out patterns they can apply to similar problems; and in the second, they’re dropped into an environment and rewarded for achieving certain outcomes using reinforcement learning. 

Both of these approaches are effective at specific tasks, but they also require a lot of human labor, either labeling training data or designing reward functions for virtual environments. By giving AI systems an intrinsic incentive to explore for explorations’ sake, some of this work is eliminated and humans spend less time holding their AI agent’s hands. (Metaphorically speaking.) 

OpenAI’s Edwards and Burda say that this sort of curiosity-driven learning system is much better for building computer programs that have to operate in the real world. After all, in reality, as in Montezuma’s Revenge, immediate rewards are often scarce, and we need to work, learn, and explore for long periods of time before we get anything in return. Curiosity helps us keep going, and maybe it can help computers, too. 
",https://cdn.vox-cdn.com/thumbor/TJsqCTrfa8Fyevejn3i8aGeLJjI=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292775/acastro_181017_1777_brain_ai_0003.jpg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vd3d3Mi5kZWxvaXR0ZS5jb20vY2EvZW4vcGFnZXMvZGVsb2l0dGUtYW5hbHl0aWNzL2FydGljbGVzL29tbmlhLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLmh0bWzSAQA?oc=5,Omnia AI: Machine Learning & AI Solutions - Deloitte,2018-11-01,Deloitte,https://www2.deloitte.com,"Omnia AI is Deloitte’s AI practice. With deep expertise in machine learning, data integration, & analytics, we can help you with your AI transformation journey.",,"Omnia AI is Deloitte’s AI practice. With deep expertise in machine learning, data integration, & analytics, we can help you with your AI transformation journey.","Omnia AI is Deloitte’s AI practice. With deep expertise in machine learning, data integration, & analytics, we can help you with your AI transformation journey.",,,,,,,,,,,,,,,,"







 
 




Deloitte CR Report Reset. Do not delete! This box/component contains code that is needed on this page. This message will not be visible when page is activated.






 
 














Omnia AI
Your business looks different when you see what AI can do.
We’ll show you how. Connect With Omnia AI



The AI opportunity Who we areOur missionThe AI journeyIn market 





















Seizing the AI opportunity
Artificial intelligence (AI) is no longer on the horizon. It’s here now, and it’s already having a profound impact on how we live, work, and do business.Companies, governments, and organizations must embrace the idea of going places they simply cannot get to using current technologies and processes. AI can and will transform organizational decision-making, drive efficiencies, build new capabilities and businesses, and power sustainable, value-driving activities.But like all revolutions in technology, capturing maximum value while simultaneously minimizing risk will require a strategic understanding of both what AI is, and how it aligns with your core business.




  Maximize revenue  Elevate experience  Reduce costs  Mitigate risk














Artificial intelligenceNoun
1. The capacity of computer systems to perform tasks that traditionally required human input or intelligence.2. A game-changer.Abbreviations AI, A.I.







 
 








Who we are
We provide end-to-end AI solutions that solve complex business challenges and help our clients capture optimal value from AI.
We see new opportunities in emerging technologies that others don’t. And because we’re Deloitte, we’re trusted advisors who work to understand your organization’s objectives from all angles.
With over 450 practitioners in Canada, and supported by Deloitte’s vast global network, we are leaders in capitalizing on the full breadth and depth of AI.

What we do 
Meet the team








Heard about AI Factory?
The AI Factory is where strategy meets intelligent design.
We coordinate and synthesize the powers of Omnia AI to
create unique and targeted products that optimize the
way a business works. Combining machine-learning
capabilities with deep business and industry acumen
allows us to solve complex problems and build tangible,
enterprising solutions.
Through the AI Factory, you have access to trailblazing
AI-driven products tailored to your needs that enable
you to excel in the marketplace.

Learn more








 
 





Our mission
We believe AI has the power to improve Canadian
organizations in transformative ways— and we’ll work
with you to make your business better. Omnia AI leads
all others in starting, enabling, accelerating, and
sustaining the AI journey.







It’s time to initiate your AI journey
AI can help maximize revenue, elevate experience, reduce cost, and mitigate risk. What’s holding you back?
The main difference between businesses that are not adopting AI and those that are, is that adopters don’t wait for the conditions to be right – they get started despite the challenges.








 
 












Understand AI better 









Start your AI journey








Scale your AI operations


















 
 







AI capabilities & services
Your AI journey starts and ends with your strategic business goals. We can help businesses identify their intended AI outcomes, then navigate the AI adoption journey from start to scale with confidence.





Strategy


Educating, inspiring and guiding clients on how to adopt cutting-edge business practices to transform their organization.







Data


Modernizing and transforming data management to enable at scale data centric solutions and AI Insights.







Insights


Developing tailored AI and Analytics solutions to meet specific client and organization needs.


 
Learn about Omnia AI’s services and capabilities











 
 




In market






Canada’s AI imperative
Start, scale, succeed
Technologies like artificial intelligence are fundamentally changing the way we live and work. Our latest report explores the AI demand gap in Canada, digs into the challenges businesses face in their AI adoption journey, and outlines actionable steps businesses can take to move their AI adoption from start to scale.Learn more






The AI opportunity in sourcing and procurement
Opportunities in the market today

            There is a wealth of raw information hidden across the whole source-to-settle lifecycle which has the power to help drive critical strategic, customer, and operational insights. But so far, the benefits of AI in sourcing and procurement have been largely untapped.
          
Learn more






The upskilling imperative
Building a future-ready workforce for the AI age
It’s time for companies and individuals to embrace the upskilling imperative. For companies, upskilling enables them to build a future-ready workforce; for individuals, it’s a way to keep their skills relevant and stay future-ready themselves.Learn more










 
 





Talk to us. You'll see the difference
Connect With Omnia AI












 
 










    Site-within-site Navigation. Do not delete! This box/component contains
    JavaScript that is needed on this page. This message will not be visible
    when page is activated.
  







 
 





Deloitte modal styles and script. Do not delete! This box/component contains code that is needed on this page for the modal to work. This message will not be visible when page is activated.















",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd3d3LmxhdGltZXMuY29tL2J1c2luZXNzL2xhLWZpLWZhY3RvcnktYXV0b21hdGlvbi1za2lsbHMtMjAxODExMDUtc3RvcnkuaHRtbNIBAA?oc=5,Blue-collar jobs will survive the rise of artificial intelligence. But the work will change - Los Angeles Times,2018-11-05,Los Angeles Times,https://www.latimes.com,"Call it the automation paradox: The infusion of artificial intelligence, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency."," robots,factory automation, job skills","It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Va. ","It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Va. ",http://schema.org,NewsArticle,https://www.latimes.com/business/la-fi-factory-automation-skills-20181105-story.html,"[{'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 836, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/7f3d790/2147483647/strip/false/crop/2048x1152+0+0/resize/1486x836!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F13%2Fc5%2F9ede9eb020550067ffe4a08444c8%2Fla-1541106303-7ud74g3j6o-snap-image', 'width': 1486}, {'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 675, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/7a709c4/2147483647/strip/false/crop/2048x1152+0+0/resize/1200x675!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F13%2Fc5%2F9ede9eb020550067ffe4a08444c8%2Fla-1541106303-7ud74g3j6o-snap-image', 'width': 1200}]","[{'@context': 'http://schema.org', '@type': 'Person', 'name': 'Craig Torres'}]","{'@type': 'Organization', 'name': 'Los Angeles Times', 'logo': {'@type': 'ImageObject', 'url': 'https://ca-times.brightspotcdn.com/dims4/default/954b438/2147483647/strip/false/crop/382x60+0+0/resize/382x60!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fde%2F5f%2F46c2d05b430cbc6e775301df1062%2Flogo-full-black.png', 'width': 382, 'height': 60}}",Blue-collar jobs will survive the rise of artificial intelligence. But the work will change,2018-11-05T12:00:00.000Z,2018-11-05T12:00:10.000Z,Business,Blue-collar jobs will survive the rise of artificial intelligence. But the work will change - Los Angeles Times,False,,Business,,"       Assembly line robots inside a Chrysler plant in Sterling Heights, Mich. As automation increases, remaining workers will need to demonstrate complex reasoning, experts say. (Paul Sancya / AP)      By Craig Torres  Nov. 5, 2018 4 AM PT      Share       Share via Close extra sharing options    Email     Facebook    X    LinkedIn    Threads    Reddit    WhatsApp    Copy Link URLCopied!   Print        Bloomberg   It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Va. Twelve candidates are divided into three teams and given the task of assembling a box. Twelve Rolls Royce employees stand around them, one assigned to each candidate, taking notes.The box is a prop, and the test has nothing to do with programming or repairing the robots that make engine parts here. It’s about collaborative problem solving.“We are looking at what they say, we are looking at what they do, we are looking at the body language of how they are interacting,” says Lorin Sodell, the plant manager.AdChoicesADVERTISING Advertisement   For all the technical marvels inside this fully automated, 8-year-old facility, Sodell talks a lot about soft skills such as trouble shooting and intuition.“There are virtually no manual operations here anymore,” he says. People “aren’t as tied to the equipment as they were in the past, and they are really freed up to work on more higher-order activities.”Call it the automation paradox: The infusion of artificial intelligence, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency.   The new blue-collar labor force will need four “distinctively more human” core competencies for advanced production: complex reasoning, social and emotional intelligence, creativity and certain forms of sensory perception, according to Jim Wilson, a managing director at Accenture Plc.“Work in a certain sense, and globally in manufacturing, is becoming more human and less robotic,” says Wilson, who helped lead an Accenture study on emerging technologies and employment needs covering 14,000 companies in 14 large, industrialized nations.Few narratives in economics and social policy are as alarmist as the penetration of automation and artificial intelligence into the workplace, especially in manufacturing. Advertisement    Economists talk about the hollowing-out of middle-income employment. American political discourse is full of nostalgia for high-paying blue-collar jobs. The Trump administration is imposing tariffs and rewriting trade agreements to entice companies to keep plants in the U.S. or even bring them back.The stark reality is that automation will continue to erode repetitive work no matter where people do it. But there is also a myth in this narrative that suggests America has permanently lost its edge. The vacant mills in the southeast and Midwest, and the struggling cities around them, are evidence of how technology and low-cost labor can rapidly kill off less-agile industries. This isn’t necessarily a prologue to what’s next, however.Cutting-edge manufacturing not only involves the extreme precision of a Rolls Royce turbofan disc. It’s also moving toward mass customization and what Erica Fuchs calls “parts consolidation” — making more-complex blocks of components so a car, for example, has far fewer parts. This new frontier often involves experimentation, with engineers learning through frequent contact with production staff, requiring workers to make new kinds of contributions.“This is a chance for the U.S. to lead. We have the knowledge and skills,” says Fuchs, an engineering and public-policy professor at Carnegie Mellon University. “When you move manufacturing overseas, it can become unprofitable to produce with the most advanced technologies.”The new alliance between labor and smart machines is apparent on Rolls Royce’s shop floor. The 33 machinists aren’t repeating one single operation but are responsible for the flow of fan-disc and turbine-blade production. They are in charge of their day, monitoring operations, consulting with engineers and maintaining equipment.This demonstrates what automation really does: It changes the way people use their time. A visit to the plant also reveals why factory workers in automated operations need more than some knowledge of machine-tool maintenance and programming: They are part of a process run by a team.Sodell opens what looks like a giant suitcase. Inside is a titanium disc about the size of a truck tire. Unfinished, it costs $35,000, and it’s worth more than twice that much once it’s machined as closely as possible to the engineers’ perfect mathematical description of the part. The end product is so finely cut and grooved it resembles a piece of industrial jewelry.“I am not at all bothered by the fact that there isn’t a person here looking after this,” he says, standing next to a cutting station about half the size of a subway car. Inside, a robot arm is measuring by itself, picking out its own tools and recording data along the way.Variations in the material, temperatures and vibration can cause the robot to deviate from the engineers’ model. So human instinct and know-how are required to devise new techniques that reduce the variance. Just by looking at the way titanium is flecking off a disc in the cutting cell, for example, a machinist can tell something is off, Sodell says. With expensive raw materials, such technical acumen is crucial.It’s also important because current artificial-intelligence systems don’t have full comprehension of non-standard events, the way a GPS in a car can’t comprehend a sudden detour. And they don’t always have the ability to come up with innovations that improve the process.Sodell says workers are constantly looking for ways to refine automation. He tells the story of a new hire who figured out a way to get one of the machines to clean itself. He developed a tool and wrote a program that is now part of the production system.Technicians start off making $48,000 a year and can earn as much as $70,000, depending on achievement and skill level. Most need at least two years of experience or precision-machining certification from a community college.Rolls Royce is collaborating with these schools and relying on instructors like Tim Robertson, among the first 50 people it hired in Virginia. He now teaches advanced manufacturing at Danville Community College and says it’s hard to explain what work is like at an automated facility. Jobs require a lot more mental engagement, he explains, because machinists are looking at data as much as materials and equipment.The Danville program includes a class on talking through conflict, along with live production where students are required to meet a schedule for different components in a simulated plant. The group stops twice a day and discusses how to optimize work flow.“You can ship a machine tool to any country in the world,” Robertson says. “But the key is going to be the high-level technician that can interact with the data at high-level activity and be flexible.”   More to Read               Opinion: What’s behind the AI boom? Exploited humans   July 12, 2024                California lawmakers are trying to regulate AI before it’s too late. Here’s how    June 19, 2024                California advances measures targeting AI discrimination and deepfakes   May 29, 2024         ","{'@type': 'WebPage', '@id': 'https://www.latimes.com/business/la-fi-factory-automation-skills-20181105-story.html'}",,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}",,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Los Angeles Times', 'productID': 'lanews:all-access'}",,,,,,,,,,"It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Va. Twelve candidates are divided into three teams and given the task of assembling a box. Twelve Rolls Royce employees stand around them, one assigned to each candidate, taking notes. The box is a prop, and the test has nothing to do with programming or repairing the robots that make engine parts here. It’s about collaborative problem solving. “We are looking at what they say, we are looking at what they do, we are looking at the body language of how they are interacting,” says Lorin Sodell, the plant manager. For all the technical marvels inside this fully automated, 8-year-old facility, Sodell talks a lot about soft skills such as trouble shooting and intuition. “There are virtually no manual operations here anymore,” he says. People “aren’t as tied to the equipment as they were in the past, and they are really freed up to work on more higher-order activities.” Call it the automation paradox: The infusion of artificial intelligence, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency. The new blue-collar labor force will need four “distinctively more human” core competencies for advanced production: complex reasoning, social and emotional intelligence, creativity and certain forms of sensory perception, according to Jim Wilson, a managing director at Accenture Plc. “Work in a certain sense, and globally in manufacturing, is becoming more human and less robotic,” says Wilson, who helped lead an Accenture study on emerging technologies and employment needs covering 14,000 companies in 14 large, industrialized nations. Few narratives in economics and social policy are as alarmist as the penetration of automation and artificial intelligence into the workplace, especially in manufacturing. Economists talk about the hollowing-out of middle-income employment. American political discourse is full of nostalgia for high-paying blue-collar jobs. The Trump administration is imposing tariffs and rewriting trade agreements to entice companies to keep plants in the U.S. or even bring them back. The stark reality is that automation will continue to erode repetitive work no matter where people do it. But there is also a myth in this narrative that suggests America has permanently lost its edge. The vacant mills in the southeast and Midwest, and the struggling cities around them, are evidence of how technology and low-cost labor can rapidly kill off less-agile industries. This isn’t necessarily a prologue to what’s next, however. Cutting-edge manufacturing not only involves the extreme precision of a Rolls Royce turbofan disc. It’s also moving toward mass customization and what Erica Fuchs calls “parts consolidation” — making more-complex blocks of components so a car, for example, has far fewer parts. This new frontier often involves experimentation, with engineers learning through frequent contact with production staff, requiring workers to make new kinds of contributions. “This is a chance for the U.S. to lead. We have the knowledge and skills,” says Fuchs, an engineering and public-policy professor at Carnegie Mellon University. “When you move manufacturing overseas, it can become unprofitable to produce with the most advanced technologies.” The new alliance between labor and smart machines is apparent on Rolls Royce’s shop floor. The 33 machinists aren’t repeating one single operation but are responsible for the flow of fan-disc and turbine-blade production. They are in charge of their day, monitoring operations, consulting with engineers and maintaining equipment. This demonstrates what automation really does: It changes the way people use their time. A visit to the plant also reveals why factory workers in automated operations need more than some knowledge of machine-tool maintenance and programming: They are part of a process run by a team. Sodell opens what looks like a giant suitcase. Inside is a titanium disc about the size of a truck tire. Unfinished, it costs $35,000, and it’s worth more than twice that much once it’s machined as closely as possible to the engineers’ perfect mathematical description of the part. The end product is so finely cut and grooved it resembles a piece of industrial jewelry. “I am not at all bothered by the fact that there isn’t a person here looking after this,” he says, standing next to a cutting station about half the size of a subway car. Inside, a robot arm is measuring by itself, picking out its own tools and recording data along the way. Variations in the material, temperatures and vibration can cause the robot to deviate from the engineers’ model. So human instinct and know-how are required to devise new techniques that reduce the variance. Just by looking at the way titanium is flecking off a disc in the cutting cell, for example, a machinist can tell something is off, Sodell says. With expensive raw materials, such technical acumen is crucial. It’s also important because current artificial-intelligence systems don’t have full comprehension of non-standard events, the way a GPS in a car can’t comprehend a sudden detour. And they don’t always have the ability to come up with innovations that improve the process. Sodell says workers are constantly looking for ways to refine automation. He tells the story of a new hire who figured out a way to get one of the machines to clean itself. He developed a tool and wrote a program that is now part of the production system. Technicians start off making $48,000 a year and can earn as much as $70,000, depending on achievement and skill level. Most need at least two years of experience or precision-machining certification from a community college. Rolls Royce is collaborating with these schools and relying on instructors like Tim Robertson, among the first 50 people it hired in Virginia. He now teaches advanced manufacturing at Danville Community College and says it’s hard to explain what work is like at an automated facility. Jobs require a lot more mental engagement, he explains, because machinists are looking at data as much as materials and equipment. The Danville program includes a class on talking through conflict, along with live production where students are required to meet a schedule for different components in a simulated plant. The group stops twice a day and discusses how to optimize work flow. “You can ship a machine tool to any country in the world,” Robertson says. “But the key is going to be the high-level technician that can interact with the data at high-level activity and be flexible.”",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vZ2Vla3R5cmFudC5jb20vbmV3cy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pcy1iZWluZy11c2VkLXRvLXByZWRpY3Qtd2hhdC1tb3ZpZXMtYXVkaWVuY2VzLXdpbGwtd2F0Y2jSAQA?oc=5,Artificial Intelligence is Being Used to Predict What Movies Audiences Will Watch — GeekTyrant - GeekTyrant,2018-11-05,GeekTyrant,https://geektyrant.com,<p>Geek Movie and Entertainment News</p>,,20th Century Fox has been working on using Artificial Intelligence to predict what movies audiences will go see. Their goal is to lessen the risk that movie studios take when making films.,20th Century Fox has been working on using Artificial Intelligence to predict what movies audiences will go see. Their goal is to lessen the risk that movie studios take when making films.,http://schema.org,Article,https://geektyrant.com/news/artificial-intelligence-is-being-used-to-predict-what-movies-audiences-will-watch,http://static1.squarespace.com/static/51b3dc8ee4b051b96ceb10de/51ce6099e4b0d911b4489b79/5bddf63e0ebbe857b71fe6c3/1557985561983/ai.jpg?format=1500w,Tommy Williams,"{'name': 'GeekTyrant', 'logo': {'@type': 'ImageObject'}, '@context': 'http://schema.org', '@type': 'Organization'}",Artificial Intelligence is Being Used to Predict What Movies Audiences Will Watch,2018-11-05T12:30:00-0800,2019-05-15T22:46:01-0700,,Artificial Intelligence is Being Used to Predict What Movies Audiences Will Watch — GeekTyrant,,,,,"


      
        Artificial Intelligence is Being Used to Predict What Movies Audiences Will Watch
      
    

Movie
20th Century FoxArtificial IntelligenceA.I.MerlinLogan
6 years agoby Tommy Williams














Artificial Intelligence is continually being used in more and more areas. Now, 20th Century Fox has been using A.I. in attempts to figure out what movies people will go and watch. They even gave the A.I. program a name: Merlin. Merlin is still a bit of a work in progress, but it is proving to be decent at its job.






Merlin’s job is to watch movie trailers and tag different aspects. He’ll then watch other trailers to determine audience interest. The goal is to help movie studios be able to take less of a risk when they make new movies. The testing of Merlin was performed using the trailer for Logan and here are the most popular tags:













The study then analyzed what movies Merlin predicted versus what movies Logan audiences actually went to watch as can be seen in the chart below:



















You can see that Merlin correctly predicted 11 out of 20 movies. That means there’s a lot of work to be done, but it’s only a matter of time before all movie studios are using machine learning in order to determine which films to greenlight.






Source: /Film﻿








The Black and White Version of GODZILLA MINUS ONE Is Coming to Netflix in August
Read Full Post




DEADPOOL & WOLVERINE TV Spot Offers Up Some Funny New Footage
Read Full Post




Silly Clip From TRANSFOMRERS ONE Shows Transformer Characters Trying to Transform for the First Time
Read Full Post




Awesome Teaser Trailer For Brad Pitt and Joseph Kosinski's Racing Film F1
Read Full Post




BATMAN: CAPED CRUSADER Clip Features Batman Racing Through the Streets of Gotham in His Batmobile
Read Full Post




STRANGER THINGS 5 Official Behind-The-Scenes Video Teases First Look Footage
Read Full Post




Tommy Williams
When I'm not writing for GeekTyrant, I enjoy playing games of all kind, rocking with my guitar, and running my YouTube channel Poor Man Pedals for guitarists. For official inquiries, please email me: tommy.williams@geektyrant.com || @tyguitaxe


GeekTyrant Homepage





Watch LEGO's Fun 90-Second Remake of JAWS 
Read Full Post




Awesome Teaser Trailer for Netflix's TERMINATOR ZERO Anime Series
Read Full Post




Cool CREEPSHOW Poster Art Created By Artist Marc Schoenbach
Read Full Post




Retro Trailer For The 1985 AI Film D.A.R.Y.L.
Read Full Post




INSIDIOUS: THE FURTHER is a New Haunted House Experience Coming To Halloween Horror Nights
Read Full Post




David Lynch Directed and Animated Music Video Which You Can Watch Now
Read Full Post




Behind the Scenes Featurette for Prison Drama SING SING Starring Colman Domingo
Read Full Post




DEADPOOL & WOLVERINE TV Spot Offers Up Some Funny New Footage
Read Full Post




Great Trailer for STARZ Limited Series THREE WOMEN Starring Shailene Woodley, Betty Gilpin, DeWanda Wise and Gabrielle Creevy
Read Full Post




Hot Toys Reveals New X-MEN Wolverine (Brown Suit) Limited Edition Action Figure 
Read Full Post




Trailer for Gritty Detective Thriller CRESCENT CITY Starring Terrence Howard, Esai Morales, Alec Baldwin and Nicky Whelan
Read Full Post




Trailer For The Horror Film THE WHEEL OF HEAVEN Centers on a Women Who Disscovers a Mystical Book in a Thrift Store
Read Full Post







Categories
Art
Comic Book
Games
Gear
Humor
Infographic
Movie
Music
Podcast
Tech
Toy
TV


Original
Rant
Review


Media
Interview
Photos
Poster
Trailer
Videos


Events
Comic-Con
 D23 Expo
E3
NYCC
Star Wars Celebration
Sundance
WonderCon


Alerts
Rumor
Spoiler
Updated


",,,,,,,,,,,,,,[],,,,,,,,"Bubank, CA
USA",freereyes@geektyrant.com,(323) 250-6307,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMijQFodHRwczovL3d3dy5idXNpbmVzc3dpcmUuY29tL25ld3MvaG9tZS8yMDE4MTEwNTAwNTI1MC9lbi9Lcm9ub3MtSW50cm9kdWNlcy1BSU1FRS10aGUtTW9zdC1BZHZhbmNlZC1BSS1FbmdpbmUtQnVpbHQtZm9yLU1hbmFnZXJzLWFuZC1FbXBsb3llZXPSAQA?oc=5,"Kronos Introduces AIMEE, the Most Advanced AI Engine Built for Managers and Employees - Business Wire",2018-11-05,Business Wire,https://www.businesswire.com,"Kronos introduces AIMEE, delivering the first artificial intelligence engine for managers and employees.",,"Kronos introduces AIMEE, delivering the first artificial intelligence engine for managers and employees.","Kronos introduces AIMEE, delivering the first artificial intelligence engine for managers and employees.",,,,,,,,,,,,,,,,"




Kronos Introduces AIMEE, the Most Advanced AI Engine Built for 
      Managers and Employees






November 05, 2018 11:00 AM Eastern Standard Time



LAS VEGAS--(BUSINESS WIRE)--Kronos 
      Incorporated continues to revolutionize the future of work with new 
      enhancements to its game-changing Workforce 
      Dimensions suite, including today’s introduction of AIMEE, 
      the most advanced artificial intelligence (AI) engine built specifically 
      to support managers and employees.
    
“Kronos understands the hourly workforce better than almost anyone, and 
      now with the introduction of AIMEE, Kronos is rethinking how 
      organizations use AI to attract, engage, and retain top talent. Kronos 
      fulfilled their promise to deliver HCM for the modern workforce, further 
      transforming frontline employee engagement.”Post this

News Facts



        AIMEE analyzes massive amounts of organizational data in real time to 
        provide in-the-moment, predictive insights to help employees and 
        managers work smarter.
      

        For HR teams, AIMEE predicts flight risk, identifies employee 
        potential, watches for employee fatigue, and supports succession 
        planning to surface trends and observations that enable more 
        productive conversations to improve engagement, retention, and 
        performance.
      

        AIMEE empowers employees to achieve better work-life balance by 
        building personalized schedules that match individual preferences, 
        processing time off requests in real time, and simplifying shift swaps 
        by suggesting colleagues most likely to accept a swap.
      

        Managers spend less time on processes and more time solving problems 
        with AIMEE’s real-time analytics, which show the impact that absences, 
        open shifts, and unplanned schedule changes have on key performance 
        indicators, leading to more informed decisions that affect employee 
        and organizational success.
      

        Advanced business volume forecasting leverages AI and machine learning 
        from AIMEE to improve scheduling accuracy by as much as 20 percent, 
        ensuring the right staff with the right skills are available to meet 
        demand.
      


Supporting Quotes



Bill Bartow, vice president, global product management, Kronos



      “At Kronos, we’re focused on delivering the most engaging technology 
      experience for everyone in the workforce, whether they’re a manager or 
      employee, paid a salary or by the hour, all around the world. The 
      introduction of AIMEE delivers the benefits of artificial intelligence 
      across the entire organization.”
    


Cliff Stevenson, principal analyst, talent management and workforce 
        management, Brandon Hall Group



      “Kronos understands the hourly workforce better than almost anyone, and 
      now with the introduction of AIMEE, Kronos is rethinking how 
      organizations use AI to attract, engage, and retain top talent. Kronos 
      fulfilled their promise to deliver HCM for the modern workforce, further 
      transforming frontline employee engagement.”
    

Supporting Resources



        This announcement was made from KronosWorks, 
        the world’s largest workforce information exchange. KronosWorks is 
        taking place this week in Las Vegas. See live updates and join the 
        conversation by using #KronosWorks across all social media channels.
      

        As part of the Kronos “Get Social. Give Back.” campaign, every 
        attendee who posts a picture on Twitter or Instagram with #KronosWorks 
        will help Kronos build a large mosaic on-site in real time. Once 
        complete, Kronos will donate $20,000 to The American Red Cross to aid 
        disaster relief efforts.
      

        Wondering how to engage your workforce? Putting people first isn’t 
        just good for employees – it’s good for business. Kronos CEO Aron Ain 
        shares how we did it in his book, WorkInspired: 
        How to Build an Organization Where Everyone Loves to Work.


Subscribe 
        to follow The 
        Workforce Institute at Kronos for insight, research, blogs, and 
        podcasts on how organizations can manage today’s modern workforce to 
        drive engagement and performance.
      

        Connect with Kronos via Facebook, 
        Twitter, 
        LinkedIn, 
        Instagram, 
        and YouTube.
      


About Kronos Incorporated


      Kronos is a leading provider of workforce management and human capital 
      management cloud solutions. Kronos industry-centric workforce 
      applications are purpose-built for businesses, healthcare providers, 
      educational institutions, and government agencies of all sizes. Tens of 
      thousands of organizations — including half of the Fortune 1000® 
      — and more than 40 million people in over 100 countries use Kronos every 
      day. Visit www.kronos.com. 
      Kronos: Workforce Innovation That Works.
    

      © 2018 Kronos Incorporated. All rights reserved. Kronos and the Kronos 
      logo are registered trademarks and Workforce Innovation That Works is a 
      trademark of Kronos Incorporated or a related company. See a complete 
      list of Kronos 
      trademarks. All other trademarks, if any, are property of their 
      respective owners.
    




Contacts

      Dan GouthroKronos Incorporated978.947.7310daniel.gouthro@kronos.com




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMijQFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Jlcm5hcmRtYXJyLzIwMTgvMTEvMTIvdGhlLWFtYXppbmctd2F5cy1nb29nbGUtYW5kLWdyYW1tYXJseS11c2UtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdG8taW1wcm92ZS1vdXItd3JpdGluZy_SAQA?oc=5,The Amazing Ways Google And Grammarly Use Artificial Intelligence To Improve Your Writing - Forbes,2018-11-12,Forbes,https://www.forbes.com,Grammarly and grammar suggestions from Google Docs use artificial intelligence technologies and algorithms to improve the way we write. Grammarly and Google have their sights set on developing their tech to provide even more editorial oversight to help humans communicate more effectively.,,Grammarly and grammar suggestions from Google Docs use artificial intelligence technologies and algorithms to improve the way we write. Grammarly and Google have their sights set on developing their tech to provide even more editorial oversight to help humans communicate more effectively.,Grammarly and grammar suggestions from Google Docs use artificial intelligence technologies and algorithms to improve the way we write. Grammarly and Google have their sights set on developing their tech to provide even more editorial oversight to help humans communicate more effectively.,http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2018/11/12/the-amazing-ways-google-and-grammarly-use-artificial-intelligence-to-improve-our-writing/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2018/11/AdobeStock_156936344-1200x900.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",The Amazing Ways Google And Grammarly Use Artificial Intelligence To Improve Your Writing,2018-11-12T00:19:00-05:00,2018-11-15T05:55:10-05:00,Enterprise & Cloud,The Amazing Ways Google And Grammarly Use Artificial Intelligence To Improve Your Writing,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise TechThe Amazing Ways Google And Grammarly Use Artificial Intelligence To Improve Your WritingBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 12, 2018,12:19am ESTUpdated Nov 15, 2018, 05:55am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinWhile online editing tools such as Grammarly and grammar suggestions from Google Docs aren’t foolproof, the artificial intelligence and machine learning algorithms that power them are successfully improving the way many of us write. In the process, it saved millions of embarrassing errors caused by carelessness (there vs. they're) and, of course, caught mistakes that involved more challenging grammar rules. Whether we write an email, a text or something more formal, even professionals use these editing tools to detect errors before they mistakenly get broadcast. To really appreciate the technology that makes these editing tools possible, let's take a look at these services and the impressive ways they improve our writing.








Adobe Stock
Adobe Stock






Grammarly: The Leader of the Pack
Since its 2009 inception, cloud-based Grammarly has grown to more than 15 million daily active users and is often one of the top-ranked grammar checkers. Users can download the Grammarly Keyboard for their mobile devices, add an extension to Chrome, Firefox, Safari, Microsoft Edge, use the Grammarly Desktop App or download a plug-in for Microsoft Office so the algorithm can spell and grammar check on Word, social media and Outlook. Grammarly switched from a subscription-only model to a freemium model in 2015 to provide more access to users.
How does it work? Just like with other machine learning algorithms, Grammarly's artificial intelligence system was originally provided with a lot of high-quality training data to teach the algorithm by showing it examples of what proper grammar looks like. This text corpus—a huge compilation human researchers organized and labeled so the AI could understand it—showed, as an example, not only proper uses of punctuation, grammar and spelling, but incorrect applications so the machine could learn the difference. In addition, Grammarly’s system uses natural language processing to analyze every nuance of language down to the character level and all the way up to words and full paragraphs of text.
PROMOTED
The feedback the system gets through humans when they ignore a proposed suggestion helps the system get smarter and provides the human linguists working with the input of the machine on how to make the system better. The more text it is exposed to, the better it can make appropriate suggestions. That's one of the reasons the company switched in 2010 to a consumer service from targeting enterprise customers so it would have access to a larger data set and a more significant opportunity.

In 2017, investors General Catalyst, IVP and Spark Capital committed $110 million to the already profitable company to help it further enhance its capabilities. Although the company has made great strides in improving grammar, grammatically correct writing doesn't necessarily mean it is compelling or concise.  So, although the company has a history of adding new checks such as to identify vagueness or plagiarism to improve your writing, expect this new infusion of funds to allow the company to add staff in an effort to continue improvements to its algorithm and the editing it can do. It has adequately tackled the basic mechanics of writing from spelling, grammar, and sentence structure as well as being able to help with clarity and readability of text. The next frontier is to provide context-specific suggestions.
Grammar Suggestions: Google Docs’ AI Grammar Checker
Grammarly may have recently introduced an extension of their own to work with Google Docs, but Google wants to get their own skin in the game with its grammar suggestions product. Google is using machine translation, the same tech they use to translate from one language to another (and one it has said approached human levels of accuracy), to power its editing tool. Instead of language to language, it translates poorly written text into grammatically correct text. If the system identifies a grammar issue, it will highlight it similar to how the spell check functionality works, so you have a chance to review possible grammar errors before hitting “send” or “publish.” Currently, details are limited about the new service, and the grammar check feature is only available via an early adopter program.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



These are undoubtedly intriguing developments, but we don't anticipate that they will take the place of a human writer anytime soon.
And according to the Grammarly Blog, “Our goal is to help you express yourself in the best way possible, whether you're applying for a job or texting a joke to your friends."" Ultimately, the company desires to become ""a true communication assistant that improves how people connect with and understand each other.""  It sounds like a brave mission any high school English teacher would support.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9mZWF0dXJlZC1pbnNpZ2h0cy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9haS1hZG9wdGlvbi1hZHZhbmNlcy1idXQtZm91bmRhdGlvbmFsLWJhcnJpZXJzLXJlbWFpbtIBAA?oc=5,"Adoption of AI advances, but foundational barriers remain - McKinsey",2018-11-13,McKinsey,https://www.mckinsey.com,Survey respondents report the rapid adoption of AI and expect only a minimal effect on head count. Yet few companies have in place the foundational building blocks that enable AI to generate value at scale.,,Survey respondents report the rapid adoption of AI and expect only a minimal effect on head count. Yet few companies have in place the foundational building blocks that enable AI to generate value at scale.,Survey respondents report the rapid adoption of AI and expect only a minimal effect on head count. Yet few companies have in place the foundational building blocks that enable AI to generate value at scale.,https://schema.org,Survey,https://www.mckinsey.com,https://www.mckinsey.com/~/media/mckinsey/featured%20insights/artificial%20intelligence/ai%20adoption%20advances%20but%20foundational%20barriers%20remain/ai-adoption-advances-1536x1536-100.jpg,,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,2018-11-13T00:00:00Z,2018-11-13T00:00:00Z,,,,,,,,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/featured-insights/artificial-intelligence/ai-adoption-advances-but-foundational-barriers-remain'}",,,,,,,,,,,,,,,,,,2018-11-12T17:32:09Z,,,,,,"AI adoption advances, but foundational barriers remain",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9ob3ctdG8tdGVhY2gtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY29tbW9uLXNlbnNlL9IBAA?oc=5,How to Teach Artificial Intelligence Some Common Sense - WIRED,2018-11-13,WIRED,https://www.wired.com,"We’ve spent years teaching neural nets to think like human brains. They’re crazy-smart, but what if we’ve been doing it all wrong?","['business', 'the big story', 'ai hub', 'games', 'research', 'neural network', 'big company', 'magazine-26.12', 'cover story', 'longreads', 'artificial intelligence', 'ai', 'neural networks', '_syndication_noshow', 'magazine']","We’ve spent years teaching neural nets to think like human brains. They’re crazy-smart, but what if we’ve been doing it all wrong?","We’ve spent years teaching neural nets to think like human brains. They’re crazy-smart, but what if we’ve been doing it all wrong?",https://schema.org/,BreadcrumbList,https://www.wired.com/story/how-to-teach-artificial-intelligence-common-sense/,"['https://media.wired.com/photos/5beb0c088daf7470d1923b48/16:9/w_1200,h_675,c_limit/AI-GG3A0107-3w.gif', 'https://media.wired.com/photos/5beb0c088daf7470d1923b48/4:3/w_1064,h_798,c_limit/AI-GG3A0107-3w.gif', 'https://media.wired.com/photos/5beb0c088daf7470d1923b48/1:1/w_800,h_800,c_limit/AI-GG3A0107-3w.gif']","[{'@type': 'Person', 'name': 'Clive Thompson', 'sameAs': 'https://www.wired.com/author/clive-thompson/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",How to Teach Artificial Intelligence Some Common Sense,2018-11-13T06:00:00.000-05:00,2018-11-13T06:00:00.000-05:00,business,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.wired.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'magazine-26.12', 'item': 'https://www.wired.com/tag/magazine-2612/'}, {'@type': 'ListItem', 'position': 3, 'name': 'How to Teach Artificial Intelligence Some Common Sense'}]",tags,,"Clive ThompsonBusinessNov 13, 2018 6:00 AMHow to Teach Artificial Intelligence Some Common SenseWe’ve spent years feeding neural nets vast amounts of data, teaching them to think like human brains. They’re crazy-smart, but they have absolutely no common sense. What if we’ve been doing it all wrong?We’ve spent years feeding neural nets vast amounts of data, teaching them to think like human brains. They’re crazy-smart, but they have absolutely no common sense. What if we’ve been doing it all wrong?Beth HolzerSave this storySaveSave this storySaveThe AI Database →ApplicationGamesEnd UserResearchBig companySectorResearchTechnologyNeural NetworkFive years ago, the coders at DeepMind, a London-based artificial intelligence company, watched excitedly as an AI taught itself to play a classic arcade game. They’d used the hot technique of the day, deep learning, on a seemingly whimsical task: mastering Breakout,1 the Atari game in which you bounce a ball at a wall of bricks, trying to make each one vanish.1 Steve Jobs was working at Atari when he was commissioned to create 1976’s Breakout, a job no other engineer wanted. He roped his friend Steve Wozniak, then at Hewlett-­Packard, into helping him.Deep learning is self-education for machines; you feed an AI huge amounts of data, and eventually it begins to discern patterns all by itself. In this case, the data was the activity on the screen—blocky pixels representing the bricks, the ball, and the player’s paddle. The DeepMind AI, a so-called neural network made up of layered algorithms, wasn’t programmed with any knowledge about how Breakout works, its rules, its goals, or even how to play it. The coders just let the neural net examine the results of each action, each bounce of the ball. Where would it lead?To some very impressive skills, it turns out. During the first few games, the AI flailed around. But after playing a few hundred times, it had begun accurately bouncing the ball. By the 600th game, the neural net was using a more expert move employed by human Breakout players, chipping through an entire column of bricks and setting the ball bouncing merrily along the top of the wall.Trending NowNeuroscientist Explains One Concept in 5 Levels of Difficulty“That was a big surprise for us,” Demis Hassabis, CEO of DeepMind, said at the time. “The strategy completely emerged from the underlying system.” The AI had shown itself capable of what seemed to be an unusually subtle piece of humanlike thinking, a grasping of the inherent concepts behind Breakout. Because neural nets loosely mirror the structure of the human brain, the theory was that they should mimic, in some respects, our own style of cognition. This moment seemed to serve as proof that the theory was right.December 2018. Subscribe to WIRED.
Illustration: Axis of StrengthThen, last year, computer scientists at Vicarious, an AI firm in San Francisco, offered an interesting reality check. They took an AI like the one used by DeepMind and trained it on Breakout. It played great. But then they slightly tweaked the layout of the game. They lifted the paddle up higher in one iteration; in another, they added an unbreakable area in the center of the blocks.A human player would be able to quickly adapt to these changes; the neural net couldn’t. The seemingly supersmart AI could play only the exact style of Breakout it had spent hundreds of games mastering. It couldn’t handle something new.“We humans are not just pattern recognizers,” Dileep George, a computer scientist who cofounded Vicarious, tells me. “We’re also building models about the things we see. And these are causal models—we understand about cause and effect.” Humans engage in reasoning, making logi­cal inferences about the world around us; we have a store of common-sense knowledge that helps us figure out new situations. When we see a game of Breakout that’s a little different from the one we just played, we realize it’s likely to have mostly the same rules and goals. The neural net, on the other hand, hadn’t understood anything about Breakout. All it could do was follow the pattern. When the pattern changed, it was helpless.The A.I. IssueThe A.I. IssueThe DIY Tinkerers Harnessing the Power of AITom SimoniteThe A.I. IssueFei-Fei Li's Quest to Make Machines Better for HumanityJessi HempelThe A.I. IssueThe Genius Neuroscientist Who Might Hold the Key to True AIShaun RavivDeep learning is the reigning monarch of AI. In the six years since it exploded into the mainstream, it has become the dominant way to help machines sense and perceive the world around them. It powers Alexa’s speech recognition, Waymo’s self-driving cars, and Google’s on-the-fly translations. Uber is in some respects a giant optimization problem, using machine learning to figure out where riders will need cars. Baidu, the Chinese tech giant, has more than 2,000 engineers cranking away on neural net AI. For years, it seemed as though deep learning would only keep getting better, leading inexorably to a machine with the fluid, supple intelligence of a person.But some heretics argue that deep learning is hitting a wall. They say that, on its own, it’ll never produce generalized intelligence, because truly humanlike intelligence isn’t just pattern recognition. We need to start figuring out how to imbue AI with everyday common sense, the stuff of human smarts. If we don’t, they warn, we’ll keep bumping up against the limits of deep learning, like visual-recognition systems that can be easily fooled by changing a few inputs, making a deep-learning model think a turtle is a gun. But if we succeed, they say, we’ll witness an explosion of safer, more useful devices—health care robots that navigate a cluttered home, fraud detection systems that don’t trip on false positives, medical breakthroughs powered by machines that ponder cause and effect in disease.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDBut what does true reasoning look like in a machine? And if deep learning can’t get us there, what can?Beth HolzerGary Marcus is a pensive, bespectacled 48-year-old professor of psychology and neuroscience at New York University, and he’s probably the most famous apostate of orthodox deep learning.Marcus first got interested in artificial intelligence in the 1980s and ’90s, when neural nets were still in their experimental phase, and he’s been making the same argument ever since. “It’s not like I came to this party late and want to pee on it,” Marcus told me when I met him at his apartment near NYU. (We are also personal friends.) “As soon as deep learning erupted, I said ‘This is the wrong direction, guys!’ ”SIGN UP TODAYGet the Backchannel newsletter for the best features and investigations on WIRED.Back then, the strategy behind deep learning was the same as it is today. Say you wanted a machine to teach itself to recognize daisies. First you’d code some algorithmic “neurons,” connecting them in layers like a sandwich (when you use several layers, the sandwich gets thicker or deep—hence “deep” learning). You’d show an image of a daisy to the first layer, and its neurons would fire or not fire based on whether the image resembled the examples of daisies it had seen before. The signal would move on to the next layer, where the process would be repeated. Eventually, the layers would winnow down to one final verdict.At first, the neural net is just guessing blindly; it starts life a blank slate, more or less. The key is to establish a useful feedback loop. Every time the AI misses a daisy, that set of neural connections weakens the links that led to an incorrect guess; if it’s successful, it strengthens them. Given enough time and enough daisies, the neural net gets more accurate. It learns to intuit some pattern of daisy-­ness that lets it detect the daisy (and not the sunflower or aster) each time. As the years went on, this core idea—start with a naive network and train by repetition—was improved upon and seemed useful nearly anywhere it was applied.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDBut Marcus was never convinced. For him, the problem is the blank slate: It assumes that humans build their intelligence purely by observing the world around them, and that machines can too. But Marcus doesn’t think that’s how humans work. He walks the intellectual path laid down by Noam Chomsky,2 who argued that humans are born wired to learn, programmed to master language and interpret the physical world.2 In 1975 the psycholo­gist Jean Piaget and the linguist Noam Chomsky met in France for what would prove to be a historic debate. Grossly simplified, Piaget argued that human brains are blank-slate self-­learning machines, and Chomsky that they are endowed with some preprogrammed smarts.For all their supposed braininess, he notes, neural nets don’t appear to work the way human brains do. For starters, they’re much too data-hungry. In most cases, each neural net requires thousands or millions of examples to learn from. Worse, each time you want a neural net to recognize a new type of item, you have to start from scratch. A neural net trained to recognize only canaries isn’t of any use in recognizing, say, birdsong or human speech.“We don’t need massive amounts of data to learn,” Marcus says. His kids didn’t need to see a million cars before they could recognize one. Better yet, they can generalize; when they see a tractor for the first time, they understand that it’s sort of like a car. They can also engage in counterfactuals. Google Translate can map the French equivalent of the English sentence “The glass was pushed, so it fell off the table.” But it doesn’t know what the words mean, so it couldn’t tell you what would happen if the glass weren’t pushed. Humans, Marcus notes, grasp not just the patterns of grammar but the logic behind it. You could give a young child a fake verb like pilk, and she’d likely be able to reason that the past tense would be pilked. She hasn’t seen that word before, of course. She hasn’t been “trained” on it. She has just intuited some logic about how language works and can apply it to a new situation.“These deep-learning systems don’t know how to integrate abstract knowledge,” says Marcus, who founded a company that created AI to learn with less data (and sold the company to Uber in 2016).Earlier this year, Marcus published a white paper on arXiv, arguing that, without some new approaches, deep learning might never get past its current limitations. What it needs is a boost—rules that supplement or are built in to help it reason about the world.Beth HolzerMost PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDOren Etzioni is a smiling bear of a guy. A computer scientist who runs the Allen Institute for Artificial Intelligence in Seattle, he greets me in his bright office wearing jeans and a salmon-­colored shirt, ushering me in past a whiteboard scrawled with musings about machine intelligence. (“DEFINE SUCCESS,” “WHAT’S THE TASK?”) Outside, in the sun-drenched main room of the institute, young AI researchers pad around sylphlike, headphones attached, quietly pecking at keyboards.Etzioni and his team are working on the common-sense problem. He defines it in the context of two legendary AI moments—the trouncing of the chess grandmaster Garry Kasparov3 by IBM’s Deep Blue in 1997 and the equally shocking defeat of the world’s top Go player by DeepMind’s AlphaGo last year. (Google bought DeepMind in 2014.)3 In 1996, Kasparov—then the best chess player in the world—beat Deep Blue. During a rematch a year later, Kasparov surrendered after 19 moves. He later told a reporter: “I’m a human being. When I see something that is well beyond my understanding, I’m afraid.”“With Deep Blue we had a program that would make a superhuman chess move—while the room was on fire,” Etzioni jokes. “Right? Completely lacking context. Fast-forward 20 years, we’ve got a computer that can make a superhuman Go move—while the room is on fire.” Humans, of course, do not have this limitation. His team plays weekly games of bughouse chess, and if a fire broke out the humans would pull the alarm and run for the doors.Humans, in other words, possess a base of knowledge about the world (fire burns things) mixed with the ability to reason about it (you should try to move away from an out-of-control fire). For AI to truly think like people, we need to teach it the stuff that everyone knows, like physics (balls tossed in the air will fall) or the relative sizes of things (an elephant can’t fit in a bathtub). Until AI possesses these basic concepts, Etzioni figures, it won’t be able to reason.With an infusion of hundreds of millions of dollars from Paul Allen,4 Etzioni and his team are trying to develop a layer of common-sense reasoning to work with the existing style of neural net. (The Allen Institute is a nonprofit, so everything they discover will be published, for anyone to use.)4 Microsoft cofounder and philanthropist Paul Allen donated billions to science, climate, and health research, as well as to Seattle causes. He died of complications from cancer on October 15 at age 65.The first problem they face is answering the question, What is common sense?Etzioni describes it as all the knowledge about the world that we take for granted but rarely state out loud. He and his colleagues have created a set of benchmark questions that a truly reasoning AI ought to be able to answer: If I put my socks in a drawer, will they be there tomorrow? If I stomp on someone’s toe, will they be mad?One way to get this knowledge is to extract it from people. Etzioni’s lab is paying crowdsourced humans on Amazon Mechanical Turk to help craft common-sense statements. The team then uses various machine-learning techniques—some old-school statistical analyses, some deep-learning neural nets—to draw lessons from those statements. If they do it right, Etzioni believes they can produce reusable Lego bricks of computer reasoning: One set that understands written words, one that grasps physics, and so on.Yejin Choi, one of Etzioni’s leading common-­sense scientists, has led several of these crowdsourced efforts. In one project, she wanted to develop an AI that would understand the intent or emotion implied by a person’s actions or statements. She started by examining thousands of online stories, blogs, and idiom entries in Wiktionary and extracting “phrasal events,” such as the sentence “Jeff punches Roger’s lights out.” Then she’d anonymize each phrase—“Person X punches Person Y’s lights out”—and ask the Turkers to describe the intent of Person X: Why did they do that? When she had gathered 25,000 of these marked-up sentences, she used them to train a machine-learning system to analyze sentences it had never seen before and infer the emotion or intent of the subject.LEARN MOREThe WIRED Guide to Artificial IntelligenceAt best, the new system worked only half the time. But when it did, it evinced some very humanlike perception: Given a sentence like “Oren cooked Thanksgiving dinner,” it predicted that Oren was trying to impress his family. “We can also reason about others’ reactions, even if they’re not mentioned,” Choi notes. “So X’s family probably feel impressed and loved.” Another system her team built used Turkers to mark up the psychological states of people in stories; the resulting system could also draw some sharp inferences when given a new situation. It was told, for instance, about a music instructor getting angry at his band’s lousy performance and that “the instructor was furious and threw his chair.” The AI predicted that the musicians would “feel fear afterwards,” even though the story doesn’t explicitly say so.Choi, Etzioni, and their colleagues aren’t abandoning deep learning. Indeed, they regard it as a very useful tool. But they don’t think there is a shortcut to the laborious task of coaxing people to explicitly state the weird, invisible, implied knowledge we all possess. Deep learning is garbage in, garbage out. Merely feeding a neural net tons of news articles isn’t enough, because it wouldn’t pick up on the unstated knowledge, the obvious stuff that writers didn’t bother to mention. As Choi puts it, “People don’t say ‘My house is bigger than me.’ ” To help tackle this problem, she had the Turkers analyze the physical relationships implied by 1,100 common verbs, such as “X threw Y.” That, in turn, allowed for a simple statistical model that could take the sentence “Oren threw the ball” and infer that the ball must be smaller than Oren.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDAnother challenge is visual reasoning. Aniruddha Kembhavi, another of Etzioni’s AI scientists, shows me a virtual robot wandering around an onscreen house. Other Allen Institute scientists built the Sims-like house, filling it with everyday items and realistic physics—kitchen cupboards full of dishes, couches that can be pushed around. Then they designed the robot, which looks like a dark gray garbage canister with arms, and told it to hunt down certain items. After thousands of tasks, the neural net gains a basic grounding in real-life facts.“What this agent has learned is, when you ask it ‘Do I have tomatoes?’ it doesn’t go and open all the cabinets. It prefers to open the fridge,” Kembhavi says. “Or if you say ‘Find me my keys,’ it doesn’t try to pick up the television. It just looks behind the television. It has learned that TVs aren’t usually picked up.”Etzioni and his colleagues hope that these various components—Choi’s language reasoning, the visual thinking, other work they’re doing on getting an AI to grasp textbook science information—can all eventually be combined. But how long will it take, and what will the final products look like? They don’t know. The common-sense systems they’re building still make mistakes, sometimes more than half the time. Choi estimates she’ll need around a million crowdsourced human statements as she trains her various language-parsing AIs. Building common sense, it would seem, is uncommonly hard.There are other pathways to making machines that reason, and they’re even more labor-intensive. For example, you could simply sit down and write out, by hand, all the rules that tell a machine how the world works. This is how Doug Lenat’s Cyc project works. For 34 years, Lenat has employed a team of engineers and philosophers to code 25 million rules of general common sense, like “water is wet” or “most people know the first names of their friends.” This lets Cyc deduce things: “Your shirt is wet, so you were probably in the rain.” The advantage is that Lenat has exquisite control over what goes into Cyc’s database; that isn’t true of crowdsourced knowledge.Brute-force, handcrafted AI has become unfashionable in the world of deep learning. That’s partly because it can be “brittle”: Without the right rules about the world, the AI can get flummoxed. This is why scripted chatbots are so frustrating; if they haven’t been explicitly told how to answer a question, they have no way to reason it out. Cyc is enormously more capable than a chatbot and has been licensed for use in health care systems, financial services, and military projects. But the work is achingly slow, and it’s expensive. Lenat says it has cost around $200 million to develop Cyc.But a bit of hand coding could be how you replicate some of the built-in knowledge that, according to the Chomskyite view, human brains possess. That’s what Dileep George and the Vicarious researchers did with Breakout. To create an AI that wouldn’t get stumped by changes to the layout of the game, they abandoned deep learning and built a system that included hard-coded basic assumptions. Without too much trouble, George tells me, their AI learned “that there are objects, and there are interactions between objects, and that the motion of one object can be causally explained between the object and something else.”Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDAs it played Breakout, the system developed the ability to weigh different courses of action and their likely outcomes. This worked in reverse too. If the AI wanted to break a block in the far left corner of the screen, it reasoned to put the paddle in the far right corner. Crucially, this meant that when Vicarious changed the layout of the game—adding new bricks or raising the paddle—the system compensated. It appeared to have extracted some general understanding about Breakout itself.Granted, there are trade-offs in this type of AI engineering. It’s arguably more painstaking to craft and takes careful planning to figure out precisely what foreordained logic to feed into the system. It’s also hard to strike the right balance of speed and accuracy when designing a new system. George says he looks for the minimum set of data “to put into the model so it can learn quickly.” The fewer assumptions you need, the more efficiently the machine will make decisions. Once you’ve trained a deep-learning model to recognize cats, you can show it a Russian blue it has never seen and it renders the verdict—it’s a cat!—almost instantaneously. Having processed millions of photos, it knows not only what makes a cat a cat but also the fastest way to identify one. In contrast, Vicarious’ style of AI is slower, because it’s actively making logical inferences as it goes.When the Vicarious AI works well, it can learn from much less data. George’s team created an AI to bust captchas,5 those “I’m not a robot” obstacles online, by recognizing characters in spite of their distorted, warped appearance.5 Captcha stands for “Completely Automated Public Turing test to tell Computers and Humans Apart.” It originated at Carnegie Mellon University in 2000; Yahoo was the first big company to make its use commonplace.Much as with the Breakout system, they endowed their AI with some abilities up front, such as knowledge that helps it discern the likely edges of characters. With that bootstrapping in place, they only needed to train the AI on 260 images before it learned to break captchas with 90.4 percent accuracy. In contrast, a neural net needed to be trained on more than 2.3 million images before it could break a captcha.Others are building common-sense-like structure into neural nets in different ways. Two researchers at DeepMind, for instance, recently created a hybrid system—part deep learning, part more traditional techniques—known as inductive logic programming. The goal was to produce something that could do mathematical reasoning.They trained it on the children’s game fizz-buzz, in which you count upward from 1, saying “fizz” if a number is divisible by 3 and “buzz” if it is divisible by 5. A regular neural net would be able to do this only for numbers it had seen before; train it up to 100 and it would know that 99 is “fizz” and 100 is “buzz.” But it wouldn’t know what to do with 105. In contrast, the hybrid DeepMind system seemed to understand the rule and went past 100 with no problem. Edward Grefenstette, one of the DeepMind coders who built the hybrid, says, “You can train systems that will generalize in a way that deep-learning networks simply couldn’t on their own.”Beth HolzerMost PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDYann LeCun, a deep-learning pioneer and the current head of Facebook’s AI research wing, agrees with many of the new critiques of the field. He acknowledges that it requires too much training data, that it can’t reason, that it doesn’t have common sense. “I’ve been basically saying this over and over again for the past four years,” he reminds me. But he remains steadfast that deep learning, properly crafted, can provide the answer. He disagrees with the Chomskyite vision of human intelligence. He thinks human brains develop the ability to reason solely through interaction, not built-in rules. “If you think about how animals and babies learn, there’s a lot of things that are learned in the first few minutes, hours, days of life that seem to be done so fast that it looks like they are hardwired,” he notes. “But in fact they don’t need to be hardwired, because they can be learned so quickly.” In this view, to figure out the physics of the world, a baby just moves its head around, data-crunches the incoming imagery, and concludes that, hey, depth of field is a thing.Still, LeCun admits it’s not yet clear which routes will help deep learning get past its humps. It might be “adversarial” neural nets, a relatively new technique in which one neural net tries to fool another neural net with fake data—forcing the second one to develop extremely ­subtle internal representations of pictures, sounds, and other inputs. The advantage here is that you don’t have the “data hungriness” problem. You don’t need to collect millions of data points on which to train the neural nets, because they’re learning by studying each other. (Apocalyptic side note: A similar method is being used to create those profoundly troubling “deepfake” videos in which someone appears to be saying or doing something they are not.)I met LeCun at the offices of Facebook’s AI lab in New York. Mark Zuckerberg recruited him in 2013, with the promise that the lab’s goal would be to push the limits of ambitious AI, not just produce minor tweaks for Facebook’s products. Like an academic lab, LeCun and his researchers publish their work for others to access.LeCun, who retains the rich accent of his native France and has a Bride of Frankenstein shock of white in his thick mass of dark hair, stood at a whiteboard energetically sketching out theories of possible deep-learning advances. On the facing wall was a set of gorgeous paintings from Stanley Kubrick’s 2001: A Space Odyssey—the main spaceship floating in deep space, the wheel-like ship orbiting Earth. “Oh, yes,” LeCun said, when I pointed them out; they were reprints of artwork Kubrick commissioned for the movie.It was weirdly unsettling to discuss humanlike AI with those images around, because of course HAL 9000,6 the humanlike AI in 2001, turns out to be a highly efficient murderer.6 HAL was originally supposed to be voiced by Martin Balsam, an actor with a thick Bronx accent. After recording, however, director Stanley Kubrick decided Balsam sounded “too colloquially American.” He was replaced by Canadian actor Douglas Rain.And this pointed to a deeper philosophical question that floats over the whole debate: Is smarter AI even a good idea? Vicarious’ system cracked captcha, but the whole point of captcha is to prevent bots from impersonating humans. Some AI thinkers worry that the ability to talk to humans and understand their psychology could make a rogue AI incredibly dangerous. Nick Bostrom7 at the University of Oxford has sounded the alarm about the dangers of creating a “superintelligence,” an AI that self-improves and rapidly outstrips humanity, able to outthink and outflank us in every way. (One way he suggests it might amass control is by manipulating people—something for which possessing a “theory of mind” would be quite useful.)7 In 2003, Bostrom published the now-famous paper-clip warning about superintelligence: “A well-meaning team of programmers [could] make a big mistake in designing its goal system. This could result … in a super­intelligence whose top goal is the manufacturing of paper clips, with the consequence that it starts transforming first all of Earth and then increasing portions of space into paper-clip manufacturing facilities.”Elon Musk is sufficiently convinced of this danger that he has funded OpenAI, an organization dedicated to the notion of safe AI.This future doesn’t keep Etzioni up at night. He’s not worried about AI becoming maliciously superintelligent. “We’re worried about something taking over the world,” he scoffs, “that can’t even on its own decide to play chess again.” It’s not clear how an AI would develop a desire to do so or what that desire would look like in software. Deep learning can conquer chess, but it has no inborn will to play.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDWhat does concern him is that current AI is woefully inept. So while we might not be creating HAL with a self-preserving intelligence, an “inept AI attached to deadly weapons can easily kill,” he says. This is partly why Etzioni is so determined to give AI some common sense. Ultimately, he argues, it will make AI safer; the idea that humanity shouldn’t be wholesale slaughtered is, of course, arguably a piece of common-­sense knowledge itself. (Part of the Allen Institute’s mandate is to make AI safer by making it more reasonable.)Related Storieswired25Researchers Call for More Humanity in Artificial IntelligenceTom SimoniteArtificial IntelligenceTo Break a Hate-Speech Algorithm, Try 'Love'Louise MatsakisWIRED Q&AEmmanuel Macron Talks to WIRED About France's AI StrategyNicholas ThompsonEtzioni notes that the dystopic sci-fi visions of AI are less risky than near-term economic displacement. The better AI gets at common sense, the more rapidly it’ll take over jobs that currently are too hard for mere pattern-­matching deep learning: drivers, cashiers, managers, analysts of all stripes, and even (alas) journalists. But truly reasoning AI could wreak havoc even beyond the economy. Imagine how good political disinformation bots would be if they could use common-­sense knowledge to appear indistinguishably human on Twitter or Facebook or in mass phone calls.Marcus agrees that reasoning AI will have dangers. But the upsides, he says, would be huge. AI that could reason and perceive like humans yet move at the speed of computers could revolutionize science, teasing out causal connections at a pace impossible for us alone. It could follow if-then chains and ponder counterfactuals, running mental experiments the way humans do, except with massive robotic knowledge. “We might finally be able to cure mental illness, for example,” Marcus adds. “AI might be able to understand these complex biological cascades of proteins that are involved in building brains and having them work correctly or not.”Sitting beneath the images from 2001, LeCun makes a bit of a heretical point himself. Sure, making artificial intelligence more humanlike helps AI to navigate our world. But directly replicating human styles of thought? It’s not clear that’d be useful. We already have humans who can think like humans; maybe the value of smart machines is that they are quite alien from us.“They will tend to be more useful if they have capabilities we don’t have,” he tells me. “Then they’ll become an amplifier for intelligence. So to some extent you want them to have a nonhuman form of intelligence ... You want them to be more rational than humans.” In other words, maybe it’s worth keeping artificial intelligence a little bit artificial.Clive Thompson (@pomeranian99) is a columnist for WIRED.This article appears in the December issue. Subscribe now.Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.More Great WIRED StoriesThis genius neuroscientist might hold the key to true AIHow to safely and securely dispose of your old gadgetsPHOTOS: When your baby is actually made of siliconeOnline conspiracy groups are a lot like cultsPipeline vandals are reinventing climate activismGet even more of our inside scoops with our weekly Backchannel newsletter","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/how-to-teach-artificial-intelligence-common-sense/'}","We’ve spent years teaching neural nets to think like human brains. They’re crazy-smart, but what if we’ve been doing it all wrong?",,,,,"{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,,,,,,,"Deep learning is self-education for machines; you feed an AI huge amounts of data, and eventually it begins to discern patterns all by itself. In this case, the data was the activity on the screen—blocky pixels representing the bricks, the ball, and the player’s paddle. The DeepMind AI, a so-called neural network made up of layered algorithms, wasn’t programmed with any knowledge about how Breakout works, its rules, its goals, or even how to play it. The coders just let the neural net examine the results of each action, each bounce of the ball. Where would it lead?
To some very impressive skills, it turns out. During the first few games, the AI flailed around. But after playing a few hundred times, it had begun accurately bouncing the ball. By the 600th game, the neural net was using a more expert move employed by human Breakout players, chipping through an entire column of bricks and setting the ball bouncing merrily along the top of the wall.
“That was a big surprise for us,” Demis Hassabis, CEO of DeepMind, said at the time. “The strategy completely emerged from the underlying system.” The AI had shown itself capable of what seemed to be an unusually subtle piece of humanlike thinking, a grasping of the inherent concepts behind Breakout. Because neural nets loosely mirror the structure of the human brain, the theory was that they should mimic, in some respects, our own style of cognition. This moment seemed to serve as proof that the theory was right.
Then, last year, computer scientists at Vicarious, an AI firm in San Francisco, offered an interesting reality check. They took an AI like the one used by DeepMind and trained it on Breakout. It played great. But then they slightly tweaked the layout of the game. They lifted the paddle up higher in one iteration; in another, they added an unbreakable area in the center of the blocks.
A human player would be able to quickly adapt to these changes; the neural net couldn’t. The seemingly supersmart AI could play only the exact style of Breakout it had spent hundreds of games mastering. It couldn’t handle something new.
“We humans are not just pattern recognizers,” Dileep George, a computer scientist who cofounded Vicarious, tells me. “We’re also building models about the things we see. And these are causal models—we understand about cause and effect.” Humans engage in reasoning, making logi­cal inferences about the world around us; we have a store of common-sense knowledge that helps us figure out new situations. When we see a game of Breakout that’s a little different from the one we just played, we realize it’s likely to have mostly the same rules and goals. The neural net, on the other hand, hadn’t understood anything about Breakout. All it could do was follow the pattern. When the pattern changed, it was helpless.
Deep learning is the reigning monarch of AI. In the six years since it exploded into the mainstream, it has become the dominant way to help machines sense and perceive the world around them. It powers Alexa’s speech recognition, Waymo’s self-driving cars, and Google’s on-the-fly translations. Uber is in some respects a giant optimization problem, using machine learning to figure out where riders will need cars. Baidu, the Chinese tech giant, has more than 2,000 engineers cranking away on neural net AI. For years, it seemed as though deep learning would only keep getting better, leading inexorably to a machine with the fluid, supple intelligence of a person.
But some heretics argue that deep learning is hitting a wall. They say that, on its own, it’ll never produce generalized intelligence, because truly humanlike intelligence isn’t just pattern recognition. We need to start figuring out how to imbue AI with everyday common sense, the stuff of human smarts. If we don’t, they warn, we’ll keep bumping up against the limits of deep learning, like visual-recognition systems that can be easily fooled by changing a few inputs, making a deep-learning model think a turtle is a gun. But if we succeed, they say, we’ll witness an explosion of safer, more useful devices—health care robots that navigate a cluttered home, fraud detection systems that don’t trip on false positives, medical breakthroughs powered by machines that ponder cause and effect in disease.
But what does true reasoning look like in a machine? And if deep learning can’t get us there, what can?
Marcus first got interested in artificial intelligence in the 1980s and ’90s, when neural nets were still in their experimental phase, and he’s been making the same argument ever since. “It’s not like I came to this party late and want to pee on it,” Marcus told me when I met him at his apartment near NYU. (We are also personal friends.) “As soon as deep learning erupted, I said ‘This is the wrong direction, guys!’ ”
Back then, the strategy behind deep learning was the same as it is today. Say you wanted a machine to teach itself to recognize daisies. First you’d code some algorithmic “neurons,” connecting them in layers like a sandwich (when you use several layers, the sandwich gets thicker or deep—hence “deep” learning). You’d show an image of a daisy to the first layer, and its neurons would fire or not fire based on whether the image resembled the examples of daisies it had seen before. The signal would move on to the next layer, where the process would be repeated. Eventually, the layers would winnow down to one final verdict.
At first, the neural net is just guessing blindly; it starts life a blank slate, more or less. The key is to establish a useful feedback loop. Every time the AI misses a daisy, that set of neural connections weakens the links that led to an incorrect guess; if it’s successful, it strengthens them. Given enough time and enough daisies, the neural net gets more accurate. It learns to intuit some pattern of daisy-­ness that lets it detect the daisy (and not the sunflower or aster) each time. As the years went on, this core idea—start with a naive network and train by repetition—was improved upon and seemed useful nearly anywhere it was applied.
But Marcus was never convinced. For him, the problem is the blank slate: It assumes that humans build their intelligence purely by observing the world around them, and that machines can too. But Marcus doesn’t think that’s how humans work. He walks the intellectual path laid down by Noam Chomsky,2 who argued that humans are born wired to learn, programmed to master language and interpret the physical world.
For all their supposed braininess, he notes, neural nets don’t appear to work the way human brains do. For starters, they’re much too data-hungry. In most cases, each neural net requires thousands or millions of examples to learn from. Worse, each time you want a neural net to recognize a new type of item, you have to start from scratch. A neural net trained to recognize only canaries isn’t of any use in recognizing, say, birdsong or human speech.
“We don’t need massive amounts of data to learn,” Marcus says. His kids didn’t need to see a million cars before they could recognize one. Better yet, they can generalize; when they see a tractor for the first time, they understand that it’s sort of like a car. They can also engage in counterfactuals. Google Translate can map the French equivalent of the English sentence “The glass was pushed, so it fell off the table.” But it doesn’t know what the words mean, so it couldn’t tell you what would happen if the glass weren’t pushed. Humans, Marcus notes, grasp not just the patterns of grammar but the logic behind it. You could give a young child a fake verb like pilk, and she’d likely be able to reason that the past tense would be pilked. She hasn’t seen that word before, of course. She hasn’t been “trained” on it. She has just intuited some logic about how language works and can apply it to a new situation.
“These deep-learning systems don’t know how to integrate abstract knowledge,” says Marcus, who founded a company that created AI to learn with less data (and sold the company to Uber in 2016).
Earlier this year, Marcus published a white paper on arXiv, arguing that, without some new approaches, deep learning might never get past its current limitations. What it needs is a boost—rules that supplement or are built in to help it reason about the world.
Etzioni and his team are working on the common-sense problem. He defines it in the context of two legendary AI moments—the trouncing of the chess grandmaster Garry Kasparov3 by IBM’s Deep Blue in 1997 and the equally shocking defeat of the world’s top Go player by DeepMind’s AlphaGo last year. (Google bought DeepMind in 2014.)
“With Deep Blue we had a program that would make a superhuman chess move—while the room was on fire,” Etzioni jokes. “Right? Completely lacking context. Fast-forward 20 years, we’ve got a computer that can make a superhuman Go move—while the room is on fire.” Humans, of course, do not have this limitation. His team plays weekly games of bughouse chess, and if a fire broke out the humans would pull the alarm and run for the doors.
Humans, in other words, possess a base of knowledge about the world (fire burns things) mixed with the ability to reason about it (you should try to move away from an out-of-control fire). For AI to truly think like people, we need to teach it the stuff that everyone knows, like physics (balls tossed in the air will fall) or the relative sizes of things (an elephant can’t fit in a bathtub). Until AI possesses these basic concepts, Etzioni figures, it won’t be able to reason.
With an infusion of hundreds of millions of dollars from Paul Allen,4 Etzioni and his team are trying to develop a layer of common-sense reasoning to work with the existing style of neural net. (The Allen Institute is a nonprofit, so everything they discover will be published, for anyone to use.)
The first problem they face is answering the question, What is common sense?
Etzioni describes it as all the knowledge about the world that we take for granted but rarely state out loud. He and his colleagues have created a set of benchmark questions that a truly reasoning AI ought to be able to answer: If I put my socks in a drawer, will they be there tomorrow? If I stomp on someone’s toe, will they be mad?
One way to get this knowledge is to extract it from people. Etzioni’s lab is paying crowdsourced humans on Amazon Mechanical Turk to help craft common-sense statements. The team then uses various machine-learning techniques—some old-school statistical analyses, some deep-learning neural nets—to draw lessons from those statements. If they do it right, Etzioni believes they can produce reusable Lego bricks of computer reasoning: One set that understands written words, one that grasps physics, and so on.
Yejin Choi, one of Etzioni’s leading common-­sense scientists, has led several of these crowdsourced efforts. In one project, she wanted to develop an AI that would understand the intent or emotion implied by a person’s actions or statements. She started by examining thousands of online stories, blogs, and idiom entries in Wiktionary and extracting “phrasal events,” such as the sentence “Jeff punches Roger’s lights out.” Then she’d anonymize each phrase—“Person X punches Person Y’s lights out”—and ask the Turkers to describe the intent of Person X: Why did they do that? When she had gathered 25,000 of these marked-up sentences, she used them to train a machine-learning system to analyze sentences it had never seen before and infer the emotion or intent of the subject.
At best, the new system worked only half the time. But when it did, it evinced some very humanlike perception: Given a sentence like “Oren cooked Thanksgiving dinner,” it predicted that Oren was trying to impress his family. “We can also reason about others’ reactions, even if they’re not mentioned,” Choi notes. “So X’s family probably feel impressed and loved.” Another system her team built used Turkers to mark up the psychological states of people in stories; the resulting system could also draw some sharp inferences when given a new situation. It was told, for instance, about a music instructor getting angry at his band’s lousy performance and that “the instructor was furious and threw his chair.” The AI predicted that the musicians would “feel fear afterwards,” even though the story doesn’t explicitly say so.
Choi, Etzioni, and their colleagues aren’t abandoning deep learning. Indeed, they regard it as a very useful tool. But they don’t think there is a shortcut to the laborious task of coaxing people to explicitly state the weird, invisible, implied knowledge we all possess. Deep learning is garbage in, garbage out. Merely feeding a neural net tons of news articles isn’t enough, because it wouldn’t pick up on the unstated knowledge, the obvious stuff that writers didn’t bother to mention. As Choi puts it, “People don’t say ‘My house is bigger than me.’ ” To help tackle this problem, she had the Turkers analyze the physical relationships implied by 1,100 common verbs, such as “X threw Y.” That, in turn, allowed for a simple statistical model that could take the sentence “Oren threw the ball” and infer that the ball must be smaller than Oren.
Another challenge is visual reasoning. Aniruddha Kembhavi, another of Etzioni’s AI scientists, shows me a virtual robot wandering around an onscreen house. Other Allen Institute scientists built the Sims-like house, filling it with everyday items and realistic physics—kitchen cupboards full of dishes, couches that can be pushed around. Then they designed the robot, which looks like a dark gray garbage canister with arms, and told it to hunt down certain items. After thousands of tasks, the neural net gains a basic grounding in real-life facts.
“What this agent has learned is, when you ask it ‘Do I have tomatoes?’ it doesn’t go and open all the cabinets. It prefers to open the fridge,” Kembhavi says. “Or if you say ‘Find me my keys,’ it doesn’t try to pick up the television. It just looks behind the television. It has learned that TVs aren’t usually picked up.”
Etzioni and his colleagues hope that these various components—Choi’s language reasoning, the visual thinking, other work they’re doing on getting an AI to grasp textbook science information—can all eventually be combined. But how long will it take, and what will the final products look like? They don’t know. The common-sense systems they’re building still make mistakes, sometimes more than half the time. Choi estimates she’ll need around a million crowdsourced human statements as she trains her various language-parsing AIs. Building common sense, it would seem, is uncommonly hard.
Brute-force, handcrafted AI has become unfashionable in the world of deep learning. That’s partly because it can be “brittle”: Without the right rules about the world, the AI can get flummoxed. This is why scripted chatbots are so frustrating; if they haven’t been explicitly told how to answer a question, they have no way to reason it out. Cyc is enormously more capable than a chatbot and has been licensed for use in health care systems, financial services, and military projects. But the work is achingly slow, and it’s expensive. Lenat says it has cost around $200 million to develop Cyc.
But a bit of hand coding could be how you replicate some of the built-in knowledge that, according to the Chomskyite view, human brains possess. That’s what Dileep George and the Vicarious researchers did with Breakout. To create an AI that wouldn’t get stumped by changes to the layout of the game, they abandoned deep learning and built a system that included hard-coded basic assumptions. Without too much trouble, George tells me, their AI learned “that there are objects, and there are interactions between objects, and that the motion of one object can be causally explained between the object and something else.”
As it played Breakout, the system developed the ability to weigh different courses of action and their likely outcomes. This worked in reverse too. If the AI wanted to break a block in the far left corner of the screen, it reasoned to put the paddle in the far right corner. Crucially, this meant that when Vicarious changed the layout of the game—adding new bricks or raising the paddle—the system compensated. It appeared to have extracted some general understanding about Breakout itself.
Granted, there are trade-offs in this type of AI engineering. It’s arguably more painstaking to craft and takes careful planning to figure out precisely what foreordained logic to feed into the system. It’s also hard to strike the right balance of speed and accuracy when designing a new system. George says he looks for the minimum set of data “to put into the model so it can learn quickly.” The fewer assumptions you need, the more efficiently the machine will make decisions. Once you’ve trained a deep-learning model to recognize cats, you can show it a Russian blue it has never seen and it renders the verdict—it’s a cat!—almost instantaneously. Having processed millions of photos, it knows not only what makes a cat a cat but also the fastest way to identify one. In contrast, Vicarious’ style of AI is slower, because it’s actively making logical inferences as it goes.
When the Vicarious AI works well, it can learn from much less data. George’s team created an AI to bust captchas,5 those “I’m not a robot” obstacles online, by recognizing characters in spite of their distorted, warped appearance.
Much as with the Breakout system, they endowed their AI with some abilities up front, such as knowledge that helps it discern the likely edges of characters. With that bootstrapping in place, they only needed to train the AI on 260 images before it learned to break captchas with 90.4 percent accuracy. In contrast, a neural net needed to be trained on more than 2.3 million images before it could break a captcha.
Others are building common-sense-like structure into neural nets in different ways. Two researchers at DeepMind, for instance, recently created a hybrid system—part deep learning, part more traditional techniques—known as inductive logic programming. The goal was to produce something that could do mathematical reasoning.
They trained it on the children’s game fizz-buzz, in which you count upward from 1, saying “fizz” if a number is divisible by 3 and “buzz” if it is divisible by 5. A regular neural net would be able to do this only for numbers it had seen before; train it up to 100 and it would know that 99 is “fizz” and 100 is “buzz.” But it wouldn’t know what to do with 105. In contrast, the hybrid DeepMind system seemed to understand the rule and went past 100 with no problem. Edward Grefenstette, one of the DeepMind coders who built the hybrid, says, “You can train systems that will generalize in a way that deep-learning networks simply couldn’t on their own.”
Still, LeCun admits it’s not yet clear which routes will help deep learning get past its humps. It might be “adversarial” neural nets, a relatively new technique in which one neural net tries to fool another neural net with fake data—forcing the second one to develop extremely ­subtle internal representations of pictures, sounds, and other inputs. The advantage here is that you don’t have the “data hungriness” problem. You don’t need to collect millions of data points on which to train the neural nets, because they’re learning by studying each other. (Apocalyptic side note: A similar method is being used to create those profoundly troubling “deepfake” videos in which someone appears to be saying or doing something they are not.)
I met LeCun at the offices of Facebook’s AI lab in New York. Mark Zuckerberg recruited him in 2013, with the promise that the lab’s goal would be to push the limits of ambitious AI, not just produce minor tweaks for Facebook’s products. Like an academic lab, LeCun and his researchers publish their work for others to access.
LeCun, who retains the rich accent of his native France and has a Bride of Frankenstein shock of white in his thick mass of dark hair, stood at a whiteboard energetically sketching out theories of possible deep-learning advances. On the facing wall was a set of gorgeous paintings from Stanley Kubrick’s 2001: A Space Odyssey—the main spaceship floating in deep space, the wheel-like ship orbiting Earth. “Oh, yes,” LeCun said, when I pointed them out; they were reprints of artwork Kubrick commissioned for the movie.
It was weirdly unsettling to discuss humanlike AI with those images around, because of course HAL 9000,6 the humanlike AI in 2001, turns out to be a highly efficient murderer.
And this pointed to a deeper philosophical question that floats over the whole debate: Is smarter AI even a good idea? Vicarious’ system cracked captcha, but the whole point of captcha is to prevent bots from impersonating humans. Some AI thinkers worry that the ability to talk to humans and understand their psychology could make a rogue AI incredibly dangerous. Nick Bostrom7 at the University of Oxford has sounded the alarm about the dangers of creating a “superintelligence,” an AI that self-improves and rapidly outstrips humanity, able to outthink and outflank us in every way. (One way he suggests it might amass control is by manipulating people—something for which possessing a “theory of mind” would be quite useful.)
Elon Musk is sufficiently convinced of this danger that he has funded OpenAI, an organization dedicated to the notion of safe AI.
This future doesn’t keep Etzioni up at night. He’s not worried about AI becoming maliciously superintelligent. “We’re worried about something taking over the world,” he scoffs, “that can’t even on its own decide to play chess again.” It’s not clear how an AI would develop a desire to do so or what that desire would look like in software. Deep learning can conquer chess, but it has no inborn will to play.
What does concern him is that current AI is woefully inept. So while we might not be creating HAL with a self-preserving intelligence, an “inept AI attached to deadly weapons can easily kill,” he says. This is partly why Etzioni is so determined to give AI some common sense. Ultimately, he argues, it will make AI safer; the idea that humanity shouldn’t be wholesale slaughtered is, of course, arguably a piece of common-­sense knowledge itself. (Part of the Allen Institute’s mandate is to make AI safer by making it more reasonable.)
Etzioni notes that the dystopic sci-fi visions of AI are less risky than near-term economic displacement. The better AI gets at common sense, the more rapidly it’ll take over jobs that currently are too hard for mere pattern-­matching deep learning: drivers, cashiers, managers, analysts of all stripes, and even (alas) journalists. But truly reasoning AI could wreak havoc even beyond the economy. Imagine how good political disinformation bots would be if they could use common-­sense knowledge to appear indistinguishably human on Twitter or Facebook or in mass phone calls.
Marcus agrees that reasoning AI will have dangers. But the upsides, he says, would be huge. AI that could reason and perceive like humans yet move at the speed of computers could revolutionize science, teasing out causal connections at a pace impossible for us alone. It could follow if-then chains and ponder counterfactuals, running mental experiments the way humans do, except with massive robotic knowledge. “We might finally be able to cure mental illness, for example,” Marcus adds. “AI might be able to understand these complex biological cascades of proteins that are involved in building brains and having them work correctly or not.”
Sitting beneath the images from 2001, LeCun makes a bit of a heretical point himself. Sure, making artificial intelligence more humanlike helps AI to navigate our world. But directly replicating human styles of thought? It’s not clear that’d be useful. We already have humans who can think like humans; maybe the value of smart machines is that they are quite alien from us.
“They will tend to be more useful if they have capabilities we don’t have,” he tells me. “Then they’ll become an amplifier for intelligence. So to some extent you want them to have a nonhuman form of intelligence ... You want them to be more rational than humans.” In other words, maybe it’s worth keeping artificial intelligence a little bit artificial.

Clive Thompson (@pomeranian99) is a columnist for WIRED.
This article appears in the December issue. Subscribe now.
Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.

More Great WIRED Stories

This genius neuroscientist might hold the key to true AI
How to safely and securely dispose of your old gadgets
PHOTOS: When your baby is actually made of silicone
Online conspiracy groups are a lot like cults
Pipeline vandals are reinventing climate activism
Get even more of our inside scoops with our weekly Backchannel newsletter","https://media.wired.com/photos/5beb0c088daf7470d1923b48/1:1/w_800,h_800,c_limit/AI-GG3A0107-3w.gif",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vd3d3Lm5vdmFydGlzLmNvbS9zdG9yaWVzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWRlY29kZXMtY2FuY2VyLXBhdGhvbG9neS1pbWFnZXPSAQA?oc=5,Artificial intelligence decodes cancer pathology images - Novartis,2018-11-12,Novartis,https://www.novartis.com,Novartis researchers are collaborating with tech startup PathAI to search for hidden information in pathology slides.,"Cancer, Emerging Technology, Innovation, Novartis Institutes for BioMedical Research, novartis, novartis pharmaceuticals, global healthcare companies,sandoz, sandoz pharmaceuticals, oncology drug development, novartis oncology pipeline, innovative healthcare, rare disease treatment, rare disease patients, innovative medicines, cell therapy, gene therapy",Novartis researchers are collaborating with tech startup PathAI to search for hidden information in pathology slides.,Novartis researchers are collaborating with tech startup PathAI to search for hidden information in pathology slides.,https://schema.org,,,,,,,,,,,,,,,"






Discovery



Artificial intelligence decodes cancer pathology images



Novartis researchers are collaborating with tech startup PathAI to search for hidden information in pathology slides.



By

Elizabeth Dougherty

|
Nov 12, 2018


 
For 150 years, pathologists have been looking through microscopes at tissue samples mounted on slides to diagnose cancer. Each assessment is weighty: Does this patient have cancer or not?
The job of a pathologist is daunting. A single slide could contain hundreds of thousands of cells. Only a handful might be cancer. Inaccurate diagnosis rates range from 3-9% of cases, according to a recent review(link is external).
Enter artificial intelligence (AI), an extra set of unbiased, indefatigable artificial eyes that could help catch errors. Many researchers are pursuing this possibility, but Novartis pathologists think AI might have an additional role to play. They hypothesize that pathology slides could contain information that helps explain why some patients respond to therapy when other seemingly similar patients do not.
To explore this idea, pathologists and data scientists from Novartis have joined forces with tech startup PathAI. They are training an AI system developed by PathAI to learn to see the same patterns pathologists see and then building on that to determine if the system can detect hidden but informative patterns too subtle or complex for pathologists to discern. The effort is part of a larger effort at Novartis to leverage data and digital technologies in ways that could help drug developers get the right drugs to the right patients faster.












View
1/2



View
2/2



<>01













A pathologist sees a field of cells on a slide and relies on years of training to find those that might be cancer.





1/2







The PathAI system also finds signs of cancer and overlays the slide with its assessment, showing cancer (red), surrounding cells (green) and dead cells (black).





2/2










Previous



Next











 
In a first phase of testing, the collaborative team has trained the PathAI system to look at slides from untreated patients and distinguish tumor from normal tissue. The system can also identify different cell types on a slide reliably. For a pathologist, these feats are akin to finding a needle in a haystack and then labeling every piece of straw.
The ability to label every cell is becoming increasingly important as cancer therapies evolve to include medicines that target not only cancer cells but also immune cells. If computers can analyze an entire slide at once and quantify cell types and locations, they could potentially reveal patterns that predict how well a patient might fare on a given therapy.
“Hopefully we can figure out which features correlate with survival or response to a drug,” says Meg McLaughlin, a pathologist and Director of the Oncology Pathology and Biomarkers group in the Oncology Translational Research team at the Novartis Institutes for BioMedical Research (NIBR).
With a recent explosion of experimental immuno-oncology options alongside therapies that target cancer-driving mutations, one of the biggest challenges for drug hunters is matching the most appropriate therapy to individual patients. While genomic information helps drive smart decisions, valuable clues in pathology slides could also help. “We want to create a platform that enables the field of pathology to support the accelerating pace of drug development,” says Andrew Beck, a pathologist, computer scientist and CEO of PathAI, located in Boston, Massachusetts, in the US.

We want to create a platform that enables the field of pathology to support the accelerating pace of drug development.
Andrew Beck, CEO of PathAI

Training the AI model
In collaboration with the Institute of Pathology at the University Hospital Basel in Switzerland, the Novartis team gained access to 400 pathology images from breast and lung cancer tissues along with anonymized information about the patients’ diagnoses and survival times.
The challenge for PathAI’s platform? Given an image, identify cancer, identify cell types and predict the patient’s probability of surviving five years.












One way to approach the challenge is to feed a set of untrained AI algorithms a subset of the data and see what it learns. Unlike a trained pathologist, the machine approaches the problem with no knowledge of cells or cancer.
“A human already has a lot of knowledge,” says NIBR data scientist Holger Hoefling, who is working on the project with PathAI and with an internal NIBR group aiming to use AI to assess safety concerns in pathology images. “Think about autonomous cars. To train a car to drive, the amount of time and data required for training is gigantic. In contrast, you put a human behind the wheel for 20 hours and let them drive.”
To give the untrained algorithms more knowledge about the training data, PathAI decided to feed them even more rich data. A team of consulting pathologists marks up the slides, giving the algorithms more information to work with. It’s a bit like annotations in a hefty piece of literature that highlight and explain critical passages.
For example, when training the algorithms to distinguish cell types, PathAI diced the training slides into about 10 000 smaller images and had pathologists label the cell types in each slice. “We had to think really hard about how we annotate the images,” says McLaughlin. “That step determines to a large extent what you get out of the AI model in the end.”
What is a black box?
AI experts refer to the trained algorithms as a “black box” because it’s difficult to know what the system has learned from the training data or how it makes decisions.
Inside the black box is a set of machine learning algorithms. These algorithms are a cascade of formulas that recognize features, such as the presence of a certain shape, and associate them with real-world data, such as how long a patient actually survived.
As the algorithms see more and more images, they adjust their understanding of the patterns they see in the data. Eventually they learn that certain shapes in a slide predict likely health outcomes, such as having a good chance of living one year or a poor chance of surviving six months.
The black box approach has the benefit of taking a fresh view of the data, so it can reveal unexpected biological patterns. But it can also discover patterns that have no biological meaning at all. Data scientists need to scrutinize the AI model’s output, identify the meaningless conclusions, and adjust the training data and algorithms in ways that weed them out.
Seeing through a machine’s eyes
After training, the PathAI platform lets users see pathology images through the machine’s eyes. Regions of the slides determined to be cancer glow bright red in a field of green surrounding tissue. Different cell types stand out in vivid colors like candies in a dish. The existing platform is for research use only, but PathAI aims to build applications that could be used by doctors in the future.












View
1/2



View
2/2



<>01













Pathologists use visual cues such as cell size and shape to differentiate cell types on a pathology slide.





1/2







The PathAI system has also learned to recognize cell types and overlays the slide with indications of five different kinds: lymphocyte (green), tumor cell (red), macrophage (yellow), plasma cell (black) and fibroblast (purple).





2/2










Previous



Next











 
Now that the researchers have shown that the PathAI system has the potential to see what pathologists see, they want to find out if there’s information in those images that isn’t obvious to pathologists.
For example, they wonder if the distribution and abundance of certain cells, such as immune cells, could hold clues about how well a patient might do on immune therapy. To find out using the human eye would require the painstaking scrutiny of tens of thousands of cells per slide, an implausible task. “I could potentially do it,” says McLaughlin. “But it would take forever.”
With AI, however, the task becomes feasible. McLaughlin and her team at Novartis are supplying PathAI with pathology images and data about survival times and response to therapy from a recent Novartis clinical trial for cancer. Gathering this data together and sharing it with PathAI is no small task. In addition to locating slides and verifying the consent of patients, the team must present orderly and consistent data from doctor’s visits, which can be a challenge when multiple doctors working across several clinics collected it.
“The era we’re heading into is more about data than it is about algorithms,” says Lee Cooper, assistant professor of biomedical informatics and biomedical engineering at Emory University in the US. Cooper specializes in using machine learning to understand pathology images and is collaborating with NIBR researchers. “The algorithms will continue to improve, but really the challenge we’re facing is how to produce the datasets we need to build the best algorithms we can.”
Once the data is in hand, PathAI will have the images annotated. After that, it will be up to the machines to find any hidden messages.
“If we can show that this method can take in this data and overlay information we haven’t seen before from pathologists, we’ll be onto something of potential value,” says Beck.
Video by PJ Kaszas.
Learn how Novartis and PathAI are using #artificialintelligence to decode #cancer pathology images.





Reimagine medicine with Novartis


Find career opportunities in research at Novartis.

Learn More







",,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', 'headline': 'Artificial intelligence decodes cancer pathology images', 'name': 'Artificial intelligence decodes cancer pathology images', 'about': ['Discovery'], 'description': 'Novartis researchers are collaborating with tech startup PathAI to search for hidden information in pathology slides.', 'image': {'@type': 'ImageObject', 'url': 'https://www.novartis.com/sites/novartiscom/files/2021-06/pathai-hero-image.jpg'}, 'datePublished': 'Mon, 11/12/2018 - 11:03', 'dateModified': 'Thu, 02/10/2022 - 13:40', 'publisher': {'@type': 'Organization', '@id': 'https://www.novartis.com/', 'name': 'Novartis', 'url': 'https://www.novartis.com/', 'sameAs': ['https://www.twitter.com/novartis', 'https://www.linkedin.com/company/novartis', 'https://www.youtube.com/user/novartis', 'https://www.facebook.com/novartis', 'https://www.instagram.com/novartis'], 'logo': {'@type': 'ImageObject', 'url': 'https://www.novartis.com/sites/novartis_com/files/novartis-logo-open-graph.jpg'}}, 'mainEntityOfPage': 'https://www.novartis.com/stories/artificial-intelligence-decodes-cancer-pathology-images'}, {'@type': 'WebPage', '@id': 'https://www.novartis.com/', 'breadcrumb': {'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.novartis.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Stories', 'item': 'https://www.novartis.com/stories'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial intelligence decodes cancer pathology images', 'item': 'https://www.novartis.com/stories/artificial-intelligence-decodes-cancer-pathology-images'}]}, 'description': 'Novartis researchers are collaborating with tech startup PathAI to search for hidden information in pathology slides.', 'publisher': {'@type': 'Organization', '@id': 'https://www.novartis.com/', 'name': 'Novartis', 'url': 'https://www.novartis.com/', 'sameAs': ['https://www.twitter.com/novartis', 'https://www.linkedin.com/company/novartis', 'https://www.youtube.com/user/novartis', 'https://www.facebook.com/novartis', 'https://www.instagram.com/novartis'], 'logo': {'@type': 'ImageObject', 'url': 'https://www.novartis.com/sites/novartis_com/files/novartis-logo-open-graph.jpg'}}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9pcy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yYWNpc3QtYW5kLW90aGVyLWNvbmNlcm5zLTgxN2ZhNjBkNzVlOdIBAA?oc=5,Is Artificial Intelligence Racist? (And Other Concerns) | by Mauro Comi - Towards Data Science,2018-11-11,Towards Data Science,https://towardsdatascience.com,"When we think of concerns in Artificial intelligence, two main obvious connections are job loss and lethal autonomous weapons. While killer robots might be an actual threat in the future, the…",,"When we think of concerns in Artificial intelligence, the two main obvious connections are job loss and lethal autonomous weapons. While…","When we think of concerns in Artificial intelligence, the two main obvious connections are job loss and lethal autonomous weapons. While…",http://schema.org,NewsArticle,https://towardsdatascience.com/is-artificial-intelligence-racist-and-other-concerns-817fa60d75e9,['https://miro.medium.com/v2/resize:fit:1200/1*BqejDh9f63qSMa40RyZkdw.jpeg'],"{'@type': 'Person', 'name': 'Mauro Comi', 'url': 'https://towardsdatascience.com/@mauro_ai'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",Is Artificial Intelligence Racist? (And Other Concerns),2018-11-12T00:56:53.970Z,2020-05-09T13:49:58.001Z,,Is Artificial Intelligence Racist? (And Other Concerns),,,,,"Is Artificial Intelligence Racist? (And Other Concerns)Mauro Comi·FollowPublished inTowards Data Science·6 min read·Nov 11, 20181742ListenShareWhen we think of concerns in Artificial intelligence, two main obvious connections are job loss and lethal autonomous weapons. While killer robots might be an actual threat in the future, the consequence of automation is a complicated phenomenon that experts are still actively analyzing. Very likely, as for any major Industrial revolution, the market will gradually stabilize. Advances in technology will create new types of jobs, inconceivable at the moment, which will be later disrupted by a new major technology takeover. We have seen this multiple times in modern history and we are probably going to see this again.A third major field of concern is the ethical impact of AI. Here the question falls: is Artificial Intelligence racist?Well, in short.. there is no short answer.What about a long answer? Tales of Google, Seals, and GorillasIn order to answer this question, we first need to define what Racism is.Racism: The belief that all members of each race possess characteristics, abilities, or qualities specific to that race, especially so as to distinguish it as inferior or superior to another race or races. ~ Oxford DictionariesRacism is related to the generalization of specific characteristics to all the members of a race. Generalization is a key concept in Machine learning and this is especially true in classification algorithms. Inductive learning is related to derive general concepts from specific examples. The majority of techniques in supervised learning try to approximate functions to predict the categories of input values with the highest possible accuracy.A function that fits our training set too closely generates overfitting. In practice, it is not able to derive a proper general function given different inputs. On the other hand, a function that doesn’t fit the dataset accurately leads to underfitting. Hence, the model generated is too simple to produce significant and reliable results.Experts in the field know that classification is all about finding the trade-off between overfitting and underfitting. Indeed, the model needs to derive general rules from a specific training set. This clearly leads to a major problem: if the data used to train the model are biased, the model will produce a biased result.A famous case showing the consequence of biased data is the mislabelling of two African-American young guys. Google Photos, which had recently implemented an automatic image labelling, classified the two teenagers as “gorillas” (all the references are reported at the end of the page). Google was heavily criticized, and someone starting to wonder whether a machine could be trained to be racist on purpose.The Google team immediately apologized and a spokesperson tweeted: “ Until recently, [Google Photos] was confusing white faces with dogs and seals. Machine learning is hard”.The actual reason for the misclassification is not due to racism at all, though. The cause of this error lies in the training set.Superman, criminality and racismIn order to understand what we’ve just discussed, let’s see a simple example of misclassification.Suppose we want to predict whether Clark Kent is a criminal or not. Here the dataset we have:Dataset containing 5 elementsOur training set represents 5 people, belonging to three different races: Kryptonian, Human and Robot.We are going to train a Decision Tree classifier to predict if Clark Kent, who’s a 31 Kryptonian Male guy, would be classified as Criminal or not.First, we train the model:clf = tree.DecisionTreeClassifier()X_train = data[['Sex', 'Age', 'Race']]Y_train = data[['Criminal']]clf.fit(X_train, Y_train)Then, we predict the category “Criminal” based on the trained model:# 1 -> Male# 31 -> Age# 1 -> Kryptonianpred = clf.predict([[1, 31, 1]])print('Is Clark Kent a criminal? Prediction: ',pred[0])As we can see, Clark Kent is classified as Criminal. Let’s check the importance of the features, in order to understand how variables influence the final output of the classifier.Here it is. Based on the dataset that we used to train the model, the most important feature is the variable Race.Bias in Computer VisionThis simple example shows the importance of data collection and data organization. When these two actions are performed poorly, ethical and cultural biases can be encoded in the machine learning model. As reported by a great article from Nature (link at the end), 45% of the most used image database in computer vision comes from the United States. China and India, accounting for 36% of the world population, represents just 3% of data in the ImageNet dataset. This unbalance unintentionally creates a bias and explains why computer vision algorithms label a photograph of a North Indian bride as ‘performance art’.Joy Buolamwini, researcher at MIT, addressed the lack of diversity in the data used to train computer vision algorithms a few years ago. She noticed that, while the most famous facial recognition systems at MIT classified correctly the gender of almost every white person, the accuracy dropped drastically as skin shades got darker. The lowest accuracy was related to dark-skinned females, with an error rate of 34%.How Microsoft corrupted a bot in 24 hoursBias and errors do not only happen in Image classification tasks. Natural Language Processing is the field of Artificial Intelligence that focuses on human language processing. A common methodology shared by many NLP algorithms is mapping words to geometric vectors. This technique considers documents as a collection of vectors, allowing computations between words. Bolukbasi and colleagues, in their paper “Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings”, show how a simple algorithm for analogies, trained on Google News articles, exhibits female/male gender stereotypes. As they report, the model states that ‘man’ is to ‘doctor’ as ‘woman’ is to ‘nurse’.This reminds of a similar controversy: in 2016 Microsoft deployed TayTweets, a Twitter bot trained through casual conversations on Twitter. The idea was incredibly promising, due to the large amount of textual data available every second on Twitter. Anyway, needless to say, the agent started to tweet misogynistic and racist remarks in less than 24 hours. Who would have thought?Racist bots and where to find themTL;DRAnd finally, here we are at the end of our analysis. The whole point of this article is to raise an ethical issue related to AI that is often overlooked. While scientists, engineers and data scientists need to address the unbalance in training sets, users and non-experts need to understand that Artificial Intelligence is based on Mathematics. And Math, as we all know, can be extremely complex. Neural networks, used in Image classification, are considered ‘black boxes’. The results they give are based on extremely high dimensional computations and cannot be fully controlled — even if companies are making a huge effort to understand the intermediate outputs, with amazing results (check my article about Neural Transfer Style, based on this concept).Still, we have a last question to answer, which hopefully will be discussed in the comments below. Is AI racist?Thanks for reading. For any comments or suggestions don’t hesitate to leave a comment!You can find more about me and my projects at maurocomi.com. You can also find me on Linkedin, or email me directly. I am always up for a chat, or to collaborate on new amazing projects.References:Google Photos Tags Two African-Americans As Gorillas Through Facial Recognition SoftwareWhen Brooklyn-native Jacky Alcine logged onto Photos on Sunday evening, he was shocked to find an album titled…www.forbes.comAI can be sexist and racist - it's time to make it fairWhen Google Translate converts news articles written in Spanish into English, phrases referring to women often become…www.nature.comRacist, Sexist AI Could Be A Bigger Problem Than Lost JobsJoy Buolamwini was conducting research at MIT on how computers recognized people's faces, when she started experiencing…www.forbes.comhttps://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist",https://towardsdatascience.com/is-artificial-intelligence-racist-and-other-concerns-817fa60d75e9,,,,,,,,,,,,,,,,,,2018-11-12T00:56:53.970Z,,,,,,,,817fa60d75e9,['Mauro Comi'],,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiO2h0dHBzOi8vd3d3LmJsb29tYmVyZy5jb20vcXVpY2t0YWtlL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Artificial Intelligence - Bloomberg - Bloomberg,2018-11-12,Bloomberg,https://www.bloomberg.com,"Artificial intelligence, or AI, is both the stuff of Terminator-esque, end-of-humanity scenarios and an invisible but steadily increasing part of our daily lives, suggesting what news we should read, for instance, or answering our customer-service queries. Software capable of learning a single narrow task with seemingly superhuman ability is becoming commonplace. AI promises a world of more personalized products and services that are cheaper, faster and free from human error. Many companies thin","Artificial Intelligence,Software,ALPHABET INC-CL A,Military,MICROSOFT CORP,Equality,Jobs,China,Unemployment,TESLA INC,business,quicktake","Artificial intelligence, or AI, is both the stuff of Terminator-esque, end-of-humanity scenarios and an invisible but steadily increasing part of our daily lives, suggesting what news we should read, for instance, or answering our customer-service queries. Software capable of learning a single narrow task with seemingly superhuman ability is becoming commonplace. AI promises a world of more personalized products and services that are cheaper, faster and free from human error. Many companies thin","Artificial intelligence, or AI, is both the stuff of Terminator-esque, end-of-humanity scenarios and an invisible but steadily increasing part of our daily lives, suggesting what news we should read, for instance, or answering our customer-service queries. Software capable of learning a single narrow task with seemingly superhuman ability is becoming commonplace. AI promises a world of more personalized products and services that are cheaper, faster and free from human error. Many companies thin",http://schema.org,NewsMediaOrganization,https://www.bloomberg.com,"['https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iXFvVjhbNxGE/v0/1200x799.jpg', 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iXFvVjhbNxGE/v0/-1x-1.jpg', 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/social-default.cc6ae30e.jpg']","[{'@type': 'Person', 'name': 'Jeremy Kahn'}, {'@type': 'Person', 'name': 'Dina Bass'}]","{'@type': 'Organization', 'name': 'Bloomberg', 'url': 'https://www.bloomberg.com', 'logo': {'@type': 'ImageObject', 'url': 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/bloomberg-logo-amp.bae0aa0a.png', 'width': 262, 'height': 60}}",Artificial Intelligence,2015-07-09T13:55:15.581Z,2018-11-13T05:05:38.854Z,,Bloomberg,False,,,,"QuicktakeArtificial IntelligenceFacebookTwitterLinkedInEmailLinkGiftExpandPhotographer: Balint Porneczi/BloombergFacebookTwitterLinkedInEmailLinkGiftGift this articleHave a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MOREFacebookTwitterLinkedInEmailLinkGiftBy Jeremy Kahn and Dina BassJuly 9, 2015 at 9:55 AM EDTUpdated on  November 13, 2018 at 12:05 AM ESTBookmarkSaveArtificial intelligence, or AI, is both the stuff of Terminator-esque, end-of-humanity scenarios and an invisible but steadily increasing part of our daily lives, suggesting what news we should read, for instance, or answering our customer-service queries. Software capable of learning a single narrow task with seemingly superhuman ability is becoming commonplace. AI promises a world of more personalized products and services that are cheaper, faster and free from human error. Many companies think they can cut their costs substantially by deploying AI. The downside of that is the prospect of mass unemployment. And one doesn’t need to feel that AI is “summoning the demon,” in the words of Tesla Inc. Chief Executive Officer  Elon Musk, to worry about it eroding privacy and increasing inequality.AI is being used to suggest music you might want to listen to or movies you might want to watch. It’s used to spot attempts at bank fraud and cybercrime. It helps rail companies predict when trains need maintenance and doctors to read X-rays and other medical images. International Data Corp. forecasts that annual corporate spending on AI will grow to about $52 billion by 2021. Meanwhile, the McKinsey Global Institute estimates AI technologies could unlock from $9.5 trillion to $15.4 trillion in annual business value worldwide. With these kinds of numbers, it’s not surprising that many governments, including those of the U.K., France, Canada and the U.S., have come to see AI as an important economic priority. Some countries, such as ChinaBloomberg Terminal, have also made the technology an important strategic goal, taking into account its potential military and intelligence applications. Employee protests over AI’s military potential led Alphabet Inc.’s Google to  pull back from a U.S. Department of Defense contract to develop programs to analyze drone footage. Microsoft Corp. called for governments to take action  to regulate AI, particularly facial-recognition programs, which have performed particularly poorly with people with darker skin.Have a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MORE",https://www.bloomberg.com/opinion/quicktake/artificial-intelligence,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}",,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Bloomberg', 'productID': 'bloomberg.com:basic'}",https://www.bloomberg.com/logo-bloomberg.svg,,https://www.bloomberg.com/diversity-inclusion,,,,,,,,,2015-07-09T13:55:15.581Z,,Bloomberg Finance L.P.,"{'@type': 'PostalAddress', 'addressCountry': 'USA', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10022', 'streetAddress': '731 Lexington Avenue'}",inquiry1@bloomberg.net,(212) 318-2000,,,,,"[{'@type': 'CollectionPage', 'name': 'Business news', 'url': 'https://www.bloomberg.com/'}]",5493001KJTIIGC8Y1R12,"[{'@type': 'Brand', 'name': 'Bloomberg markets', 'url': 'https://www.bloomberg.com/markets'}, {'@type': 'Brand', 'name': 'Bloomberg technology', 'url': 'https://www.bloomberg.com/technology'}, {'@type': 'Brand', 'name': 'Bloomberg pursuits', 'url': 'https://www.bloomberg.com/pursuits'}, {'@type': 'Brand', 'name': 'Bloomberg politics', 'url': 'https://www.bloomberg.com/politics'}, {'@type': 'Brand', 'name': 'Bloomberg opinion', 'url': 'https://www.bloomberg.com/opinion', 'logo': 'https://www.bloomberg.com/logo-bloomberg_opinion.svg'}, {'@type': 'Brand', 'name': 'Bloomberg businessweek', 'url': 'https://www.bloomberg.com/businessweek', 'logo': 'https://www.bloomberg.com/logo-bloomberg_businessweek.svg'}, {'@type': 'Brand', 'name': 'Bloomberg green', 'url': 'https://www.bloomberg.com/green'}, {'@type': 'Brand', 'name': 'Bloomberg equality', 'url': 'https://www.bloomberg.com/equality'}, {'@type': 'Brand', 'name': 'Bloomberg citylab', 'url': 'https://www.bloomberg.com/citylab'}, {'@type': 'Brand', 'name': 'Bloomberg crypto', 'url': 'https://www.bloomberg.com/crypto'}, {'@type': 'Brand', 'name': 'Bloomberg industries', 'url': 'https://www.bloomberg.com/industries'}, {'@type': 'Brand', 'name': 'Bloomberg economics', 'url': 'https://www.bloomberg.com/economics'}, {'@type': 'Brand', 'name': 'Bloomberg ai', 'url': 'https://www.bloomberg.com/ai'}, {'@type': 'Brand', 'name': 'Bloomberg wealth', 'url': 'https://www.bloomberg.com/wealth'}]",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMTgvbWl0LWFpLXN1bW1pdC1hZGRyZXNzZXMtdGVjaC1pbXBhY3Qtb24tam9icy1nbG9iYWwtZWNvbm9teS0xMTE10gEA?oc=5,Artificial intelligence summit addresses impact of technology on jobs and global economy - MIT News,2018-11-15,MIT News,https://news.mit.edu,Speakers at MIT&#039;s AI and the Future of Work summit discuss the impact of technology on jobs and global economy.,"MIT, MIT Sloan School of Management, MIT Department of Electrical Engineering and Computer Science (eecs), MIT Initiative on the Digital Economy, MIT Computer Science and Artificial Intelligence Laboratory MIT CSAIL, future of work, artificial intelligence, Economics, jobs, global economy",Speakers at MIT&#039;s AI and the Future of Work summit discuss the impact of technology on jobs and global economy.,,,,,,,,,,,,,,,,,"


Speakers at the summit included Massachusetts Secretary of Labor Rosalin Acosta and former Google chairman Eric Schmidt.




Adam Conner-Simons
|
MIT CSAIL


 Publication Date:
 November 15, 2018





Press Inquiries

  Press Contact:



      
            Adam         

            Conner-Simons        

  

      Email:
     aconner@csail.mit.edu


      Phone:
              617-324-9135      
  

      
            MIT Computer Science & Artificial Intelligence Lab        

  








 Close














 Caption:
          The keynote address at the second annual AI and the Future of Work summit was delivered by Rosalin Acosta, Massachusetts Secretary of Labor and Workforce Development.      
          

 Credits:
          Photo: Rachel Gordon/CSAIL      
          









 Caption:
          MIT professor Erik Brynjolfsson (left) talks with former Google chairman Eric Schmidt at the opening fireside chat.      
          

 Credits:
          Photo: Rachel Gordon/CSAIL      
          









 Caption:
          Left to right: CSAIL's Lori Glover moderates a discussion with Walmart's Becky Schmitt and Accenture's Alison Horn.      
          

 Credits:
          Photo: Rachel Gordon/CSAIL      
          

















Previous image
Next image






















This week MIT hosted its second annual summit on “AI and the Future of Work,” bringing together representatives from industry, government and academia to discuss the opportunities and challenges of artificial intelligence (AI) and automation.
Co-hosted by MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and the Initiative on the Digital Economy (IDE), the event featured former Alphabet chairman Eric Schmidt and Massachusetts Secretary of Labor Rosalin Acosta, who delivered the keynote address.
A common theme throughout the event was the importance of doing more than just thinking about technological disruption and actually working to create public policy that encourages the thoughtful deployment of AI systems.
“The technologies themselves are neutral, so the question is how to organize ourselves in society in a way that addresses their potential to change the job market,” said Diana Farrell, CEO of the JPMorgan Chase Institute. “We’re kidding ourselves if we think that the market is going to, on its own, allow these technologies to infiltrate and yield the kind of outcomes from society that we want.”
The focus on public policy also extended to education. Many panelists spoke of the importance of lifelong learning, in the form of a burgeoning industry of free and low-cost online classes to pick up skills in fields like machine learning and data science that have seen major job growth.
Some speakers believed that future focus needs to happen much earlier the educational pipeline. Fred Goff, who serves as CEO of the blue-collar job-search network Jobcase, did a survey of the platform’s 90 million members about their education. Half said that their K-12 background prepared them for their job today, but less than a quarter said that they think their education will prepare them for the jobs of tomorrow.
Beyond the U.S., industry analysts spoke about the importance of considering AI in the context of the developing world, where there is often low digital literacy.
“How do we support people in remote and isolated areas so that they don’t fall further behind?” asked Tina George, an expert in global technologies for the World Bank. “We can't build Star Wars with Flintstone technology.”
There was also a growing recognition that in industry, AI could actually become something of an equalizer, especially in areas like mergers and acquisitions that rely heavily on data analysis.
""It no longer requires a multi-million dollar budget to get AI going in your company,"" said Nichole Jordan, a managing partner at Grant Thornton LLP. “It represents an opportunity to level the playing field for smaller companies.”
On the academic side, CSAIL Director Professor Daniela Rus discussed the many ways that scientists are using AI for everything from diagnosing disease to predicting food shortages. At the same time, she talked about how important it is for researchers to be thoughtful and intentional as they work on these new breakthroughs.
“AI should be able to help us all get lifted to better lives, and I think there is a lot of potential still untapped,” Rus said in video remarks. “But we can't just push technology forward and hope for the best. We have to work to ensure that the best happens.”








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print







Related Links

AI and the Future of WorkInitiative on the Digital EconomyComputer Science and Artificial Intelligence LaboratoryDepartment of Electrical Engineering and Computer ScienceSchool of EngineeringMIT Sloan School of Management






Related Topics

Special events and guest speakers
Artificial intelligence
Computer science and technology
Computer Science and Artificial Intelligence Laboratory (CSAIL)
Technology and society
Autonomous vehicles
School of Engineering
Labor and jobs
Industry
Health care
Data
Innovation and Entrepreneurship (I&E)
MIT Sloan School of Management



Related Articles











MIT reshapes itself to shape the future













IBM and MIT to pursue joint research in artificial intelligence, establish new MIT-IBM Watson AI Lab













Meeting of the minds for machine intelligence













Cambridge Cyber Summit convenes industry, academia, and government

















Previous item
Next item
















",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3Lm5hdGlvbmFsZ2VvZ3JhcGhpYy5jb20vYW5pbWFscy9hcnRpY2xlL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvdW50cy13aWxkLWFuaW1hbHPSAQA?oc=5,Artificial intelligence is counting animals to help save them - National Geographic,2018-11-13,National Geographic,https://www.nationalgeographic.com,The whale sharks of Mafia Island are unusual because they don't migrate—and researchers want to know why.,,"From analyzing animal photos to combing through YouTube, new software is harnessing data never before accessible to scientists.","From analyzing animal photos to combing through YouTube, new software is harnessing data never before accessible to scientists.",https://schema.org,VideoObject,,"{'url': 'https://i.natgeofe.com/n/bec7bd50-0d57-4982-aeb5-82e5f8184f89/02-machine-saving-animals-nationalgeographic_1977490.jpg', '@type': 'ImageObject'}","[{'name': 'Anne Casselman', '@type': 'Person'}]","{'logo': {'@type': 'ImageObject'}, '@type': 'Organization'}",How artificial intelligence is changing wildlife research,2018-11-13T11:00:08.000Z,,,Investigating the Mysterious Whale Sharks of Mafia Island,,,Animals,,,{'@type': 'WebPage'},,,,,,,,,,,,,,,,,https://i.natgeofe.com/n/cc99c3e6-72e7-4acb-8569-8b3e4cf59b72/00000159-b1e9-d46a-afdd-b5ef8d960000.jpg,,,,,,,,,,,,,,,2017-01-18T14:09:59.000Z,PT0H3M50S,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vd3d3LmxhdGltZXMuY29tL2J1c2luZXNzL2xhLWZpLWhpbWktc2llZ2VsLTIwMTgxMTExLXN0b3J5Lmh0bWzSAQA?oc=5,How I Made It: Ian Siegel employs artificial intelligence to disrupt the job recruitment industry - Los Angeles Times,2018-11-11,Los Angeles Times,https://www.latimes.com,"Ian Siegel, ceo of Santa Monica-based ZipRecruiter, has taken a non-traditional route in his career and at his recruiting company.",,"Ian Siegel, 45, is chief executive of Santa Monica-based ZipRecruiter, the company he co-founded in 2010 to disrupt the recruitment and hiring industry. ","Ian Siegel, 45, is chief executive of Santa Monica-based ZipRecruiter, the company he co-founded in 2010 to disrupt the recruitment and hiring industry. ",http://schema.org,NewsArticle,https://www.latimes.com/business/la-fi-himi-siegel-20181111-story.html,"[{'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 836, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/5a1a62f/2147483647/strip/false/crop/2047x1151+0+0/resize/1486x836!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F3b%2F95%2F526ea77747bcbc07f4f672df1f47%2Fla-1541726639-h0wlhi0wk9-snap-image', 'width': 1486}, {'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 675, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/efd8392/2147483647/strip/false/crop/2046x1151+0+0/resize/1200x675!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F3b%2F95%2F526ea77747bcbc07f4f672df1f47%2Fla-1541726639-h0wlhi0wk9-snap-image', 'width': 1200}]","[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Los Angeles Times', 'description': 'Ronald D. White was a reporter for the Los Angeles Times from 1993 to 2024. ', 'name': 'Ronald D. White', 'url': 'https://www.latimes.com/people/ronald-d-white'}]","{'@type': 'Organization', 'name': 'Los Angeles Times', 'logo': {'@type': 'ImageObject', 'url': 'https://ca-times.brightspotcdn.com/dims4/default/954b438/2147483647/strip/false/crop/382x60+0+0/resize/382x60!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fde%2F5f%2F46c2d05b430cbc6e775301df1062%2Flogo-full-black.png', 'width': 382, 'height': 60}}",Ian Siegel employs artificial intelligence to disrupt the job recruitment industry,2018-11-11T13:00:00.000Z,2019-07-19T02:12:58.578Z,Business,Ian Siegel employs artificial intelligence to disrupt the job recruitment industry - Los Angeles Times,False,,Business,,"       Ian Siegel, co-founder and chief executive of ZipRecruiter, at the company’s Santa Monica office. (Christina House / Los Angeles Times)       By Ronald D. WhiteStaff Writer    Nov. 11, 2018 5 AM PT      Share       Share via Close extra sharing options    Email     Facebook    X    LinkedIn    Threads    Reddit    WhatsApp    Copy Link URLCopied!   Print        Ian Siegel, 45, is chief executive of Santa Monica-based ZipRecruiter, the company he co-founded in 2010 to disrupt the recruitment and hiring industry. Since then, more than 1.5 million businesses and more than 430 million job seekers have used the online employment marketplace, according to the company. ZipRecruiter has nearly 1,000 employees, a quarter of whom are engineers.Business acumenStudying sociology, psychology and English at Oberlin College wasn’t the waste of time that Siegel feared it might be once he started a career in business.AdChoicesADVERTISING Advertisement   “If you think of psychology as the individual, sociology as society and social psychology as the study of small group dynamics, I was already identifying the opinion leader, the emotional leader, early on in my career. I was breaking down every group into the categories I studied while I was in college, and it actually was really helpful,” Siegel said.The inspirationThe Los Angeles native held executive-level positions at six different companies over 15 years. In hindsight, he sees the connective tissue that inspired ZipRecruiter.“I had to do my own recruiting,” Siegel said, “posting positions to different job boards, each with a different mechanism. For years I was saying, ‘This is crazy. Why isn’t there a magic button I can push and send the same job to all the different job boards and bring all the candidates onto one list, just make it easy and efficient to hire somebody?’”   The lessonSiegel was suffering massive guilt at one of those early jobs, managing a technology team on an interim basis for a West Hollywood firm called Citysearch from 1996 to 1998. He actually apologized to his team for being so unqualified, having studied only non-tech subjects in college.“They told me I was the best manager they ever had, because I listened,” Siegel said. “People didn’t need me to be an engineer. They needed me to be clear about the problem I wanted solved, and they needed the autonomy and the resources to go do it the way they wanted to do it.”Leadership style“Listen more than you talk,” Siegel said of his approach. “Describe the problem we’re trying to solve, describe what success looks like, and then keep listening, because your job is not to do all the work, your job is not to figure out the optimal solution, your job is to create space for all the smart people that you’ve hired to go work on that problem.” Advertisement    ‘Build the solution’“I pulled together three friends. Two of them were engineers, one a designer,” Siegel said. “The four of us worked at my kitchen table at night and on weekends, and we built the first version of ZipRecruiter, and literally the day we launched it, it was like a rocket ship, like right out of the gate, product market fit.”Comfortable fitSiegel had three co-founders who were essential to the start-up days, he said. Ward Poulos had worked with Siegel “at three different companies. When I was mulling on this idea, he was the first person I talked to.” Will Redd “was an engineer that we had both worked with at companies in the past.” Software wizard Joe Edmonds rounded out the group.“We were really aligned in terms of approach and personality, so it was very easy to work together,” Siegel said. All three are still with the company.Growing painsZipRecruiter found that fast growth creates its own problems, Siegel said. “It’s always difficult to scale fast,” he said. “Things always break. There’s this cliche saying that the person that’s right for a 10-person company isn’t right for a 100-person company, the person that’s right for a 100-person company isn’t right for a 1,000-person company, and it’s absolutely true.”Corporate raiders“As we grew, we literally cherry-picked the top 5% of talent that we had worked with across multiple businesses,” Siegel said, “and then we got all their No. 1 referenced friends as well. We have a development office in Israel staffed with some of the best data scientists in the world doing R&D for us. It’s high-level algorithmic work. We’re just applying it to the job category.”Embracing AI talentMany companies are stumbling as they attempt to embrace artificial intelligence and harness it to their business models. Siegel said AI has given his company a built-in advantage by more quickly extracting data from resumes and more efficiently generating likely matches.“We’re ZipRecruiter. We think we’re literally the easiest way to hire, so when we need to add all these bodies, all this expertise, we can eat our own dog food, because we have hired most of the people who work at ZipRecruiter, through ZipRecruiter, so that was probably our ace in the hole.”PersonalSiegel has been married to his wife, Rochelle, for 18 years. They have a 15-year-old daughter and an 11-year-old son. To clear his mind, Siegel prefers running to meditation, and he loves to read. “I’m fascinated by entrepreneurs telling their true truths, not the gilded PR-ready, ‘we were awesome from the beginning’ stories. I love the stories from the trenches. The ugly way that soup got made. I just find it reassuring, and it reminds me that it’s not easy for anyone.”     More to Read               Opinion: What’s behind the AI boom? Exploited humans   July 12, 2024                Granderson: So what if Gen Z applicants bring their parents to a job interview?   June 8, 2024                California advances measures targeting AI discrimination and deepfakes   May 29, 2024         ","{'@type': 'WebPage', '@id': 'https://www.latimes.com/business/la-fi-himi-siegel-20181111-story.html'}",,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}",,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Los Angeles Times', 'productID': 'lanews:all-access'}",,,,,,,,,,"Ian Siegel, 45, is chief executive of Santa Monica-based ZipRecruiter, the company he co-founded in 2010 to disrupt the recruitment and hiring industry. Since then, more than 1.5 million businesses and more than 430 million job seekers have used the online employment marketplace, according to the company. ZipRecruiter has nearly 1,000 employees, a quarter of whom are engineers. Business acumenStudying sociology, psychology and English at Oberlin College wasn’t the waste of time that Siegel feared it might be once he started a career in business. “If you think of psychology as the individual, sociology as society and social psychology as the study of small group dynamics, I was already identifying the opinion leader, the emotional leader, early on in my career. I was breaking down every group into the categories I studied while I was in college, and it actually was really helpful,” Siegel said. The inspirationThe Los Angeles native held executive-level positions at six different companies over 15 years. In hindsight, he sees the connective tissue that inspired ZipRecruiter. “I had to do my own recruiting,” Siegel said, “posting positions to different job boards, each with a different mechanism. For years I was saying, ‘This is crazy. Why isn’t there a magic button I can push and send the same job to all the different job boards and bring all the candidates onto one list, just make it easy and efficient to hire somebody?’” The lessonSiegel was suffering massive guilt at one of those early jobs, managing a technology team on an interim basis for a West Hollywood firm called Citysearch from 1996 to 1998. He actually apologized to his team for being so unqualified, having studied only non-tech subjects in college. “They told me I was the best manager they ever had, because I listened,” Siegel said. “People didn’t need me to be an engineer. They needed me to be clear about the problem I wanted solved, and they needed the autonomy and the resources to go do it the way they wanted to do it.” Leadership style“Listen more than you talk,” Siegel said of his approach. “Describe the problem we’re trying to solve, describe what success looks like, and then keep listening, because your job is not to do all the work, your job is not to figure out the optimal solution, your job is to create space for all the smart people that you’ve hired to go work on that problem.” ‘Build the solution’“I pulled together three friends. Two of them were engineers, one a designer,” Siegel said. “The four of us worked at my kitchen table at night and on weekends, and we built the first version of ZipRecruiter, and literally the day we launched it, it was like a rocket ship, like right out of the gate, product market fit.” Comfortable fitSiegel had three co-founders who were essential to the start-up days, he said. Ward Poulos had worked with Siegel “at three different companies. When I was mulling on this idea, he was the first person I talked to.” Will Redd “was an engineer that we had both worked with at companies in the past.” Software wizard Joe Edmonds rounded out the group. “We were really aligned in terms of approach and personality, so it was very easy to work together,” Siegel said. All three are still with the company. Growing painsZipRecruiter found that fast growth creates its own problems, Siegel said. “It’s always difficult to scale fast,” he said. “Things always break. There’s this cliche saying that the person that’s right for a 10-person company isn’t right for a 100-person company, the person that’s right for a 100-person company isn’t right for a 1,000-person company, and it’s absolutely true.” Corporate raiders“As we grew, we literally cherry-picked the top 5% of talent that we had worked with across multiple businesses,” Siegel said, “and then we got all their No. 1 referenced friends as well. We have a development office in Israel staffed with some of the best data scientists in the world doing R&D for us. It’s high-level algorithmic work. We’re just applying it to the job category.” Embracing AI talentMany companies are stumbling as they attempt to embrace artificial intelligence and harness it to their business models. Siegel said AI has given his company a built-in advantage by more quickly extracting data from resumes and more efficiently generating likely matches. “We’re ZipRecruiter. We think we’re literally the easiest way to hire, so when we need to add all these bodies, all this expertise, we can eat our own dog food, because we have hired most of the people who work at ZipRecruiter, through ZipRecruiter, so that was probably our ace in the hole.” PersonalSiegel has been married to his wife, Rochelle, for 18 years. They have a 15-year-old daughter and an 11-year-old son. To clear his mind, Siegel prefers running to meditation, and he loves to read. “I’m fascinated by entrepreneurs telling their true truths, not the gilded PR-ready, ‘we were awesome from the beginning’ stories. I love the stories from the trenches. The ugly way that soup got made. I just find it reassuring, and it reminds me that it’s not easy for anyone.”",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LmNvbnN0cnVjdGlvbnNwZWNpZmllci5jb20vaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWlzLWNoYW5naW5nLXRoZS1pbmR1c3RyeS1hLWNzaS1leGNsdXNpdmUv0gEA?oc=5,How artificial intelligence is changing the industry: A CSI exclusive - Construction Specifier - The Construction Specifier,2018-11-12,The Construction Specifier,https://www.constructionspecifier.com,"Machine learning, algorithms, and specialized artificial intelligence (AI) are impacting the construction industry, largely in the area of design. While jobs may not be eliminated, it will change. Certain aspects of a specifier’s work, such as activities requiring minimal complex thinking, can be done better and faster by some form of AI. Removing these job functions may also be welcomed by many professionals.",,"Machine learning, algorithms, and specialized artificial intelligence (AI) are impacting the construction industry, largely in the area of design. While jobs may not be eliminated, it will change. Certain aspects of a specifier’s work, such as activities requiring minimal complex thinking, can be done better and faster by some form of AI. Removing these job functions may also be welcomed by many professionals.",,https://schema.org,,,,,,,,,,,,,,,"

Digital craftsmanship in stone designModern technology has made its mark on stone design as well as fabrication. Today, project teams taking advantage of technology are experiencing increased freedom in control of the design concept, from development through to fabrication. 

",,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/#article', 'isPartOf': {'@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/'}, 'author': {'name': 'nithya_caleb', '@id': 'https://www.constructionspecifier.com/#/schema/person/b98ef8acdc4f61ec3c542bdb863ee469'}, 'headline': 'How artificial intelligence is changing the industry: A CSI exclusive', 'datePublished': '2018-11-12T17:31:54+00:00', 'dateModified': '2018-11-12T17:31:54+00:00', 'mainEntityOfPage': {'@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/'}, 'wordCount': 229, 'commentCount': 0, 'publisher': {'@id': 'https://www.constructionspecifier.com/#organization'}, 'image': {'@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/#primaryimage'}, 'thumbnailUrl': 'https://www.constructionspecifier.com/wp-content/uploads/2018/11/featured-4.jpg', 'keywords': ['Artificial Intelligence', 'CSI', 'Industry Trends'], 'articleSection': ['Columns', 'Inside CSI'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/', 'url': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/', 'name': 'How artificial intelligence is changing the industry: A CSI exclusive - Construction Specifier', 'isPartOf': {'@id': 'https://www.constructionspecifier.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/#primaryimage'}, 'image': {'@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/#primaryimage'}, 'thumbnailUrl': 'https://www.constructionspecifier.com/wp-content/uploads/2018/11/featured-4.jpg', 'datePublished': '2018-11-12T17:31:54+00:00', 'dateModified': '2018-11-12T17:31:54+00:00', 'breadcrumb': {'@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/#primaryimage', 'url': 'https://www.constructionspecifier.com/wp-content/uploads/2018/11/featured-4.jpg', 'contentUrl': 'https://www.constructionspecifier.com/wp-content/uploads/2018/11/featured-4.jpg', 'width': 600, 'height': 401}, {'@type': 'BreadcrumbList', '@id': 'https://www.constructionspecifier.com/how-artificial-intelligence-is-changing-the-industry-a-csi-exclusive/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.constructionspecifier.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How artificial intelligence is changing the industry: A CSI exclusive'}]}, {'@type': 'WebSite', '@id': 'https://www.constructionspecifier.com/#website', 'url': 'https://www.constructionspecifier.com/', 'name': 'Construction Specifier', 'description': 'Solutions for the Construction Industry', 'publisher': {'@id': 'https://www.constructionspecifier.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.constructionspecifier.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.constructionspecifier.com/#organization', 'name': 'The Construction Specifier', 'url': 'https://www.constructionspecifier.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.constructionspecifier.com/#/schema/logo/image/', 'url': 'https://www.constructionspecifier.com/wp-content/uploads/2017/09/CS_Logo_BW_LR.jpg', 'contentUrl': 'https://www.constructionspecifier.com/wp-content/uploads/2017/09/CS_Logo_BW_LR.jpg', 'width': 288, 'height': 70, 'caption': 'The Construction Specifier'}, 'image': {'@id': 'https://www.constructionspecifier.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.constructionspecifier.com/#/schema/person/b98ef8acdc4f61ec3c542bdb863ee469', 'name': 'nithya_caleb', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.constructionspecifier.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/7a28b8c910d60115947aa67b1242a27b?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/7a28b8c910d60115947aa67b1242a27b?s=96&d=mm&r=g', 'caption': 'nithya_caleb'}, 'url': 'https://www.constructionspecifier.com/author/nithya_caleb/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMi2gFodHRwczovL3d3dy5mb3JkZm91bmRhdGlvbi5vcmcvbmV3cy1hbmQtc3Rvcmllcy92aWRlb3MvaG93LWNhbi1wdWJsaWMtaW50ZXJlc3QtdGVjaC1jaGFuZ2Utb3VyLXdvcmxkLWZvci1nb29kL2pveS1idW9sYW13aW5pLWZpZ2h0aW5nLXRoZS1jb2RlZC1nYXplLWhvdy13ZS1tYWtlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWJlbmVmaXQtYWxsLXB1YmxpYy1pbnRlcmVzdC10ZWNoL9IBAA?oc=5,Joy Buolamwini - Fighting the “coded gaze:” How we make artificial intelligence benefit all. Public Interest Tech - Ford Foundation,2018-11-13,Ford Foundation,https://www.fordfoundation.org,Artificial intelligence can be coded to be more inclusive. Joy Buolamwini shows how.,,Artificial intelligence can be coded to be more inclusive. Joy Buolamwini shows how.,,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/joy-buolamwini-fighting-the-coded-gaze-how-we-make-artificial-intelligence-benefit-all-public-interest-tech/', 'url': 'https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/joy-buolamwini-fighting-the-coded-gaze-how-we-make-artificial-intelligence-benefit-all-public-interest-tech/', 'name': 'Joy Buolamwini - Fighting the “coded gaze:” How we make artificial intelligence benefit all. Public Interest Tech - Ford Foundation', 'isPartOf': {'@id': 'https://www.fordfoundation.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/joy-buolamwini-fighting-the-coded-gaze-how-we-make-artificial-intelligence-benefit-all-public-interest-tech/#primaryimage'}, 'image': {'@id': 'https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/joy-buolamwini-fighting-the-coded-gaze-how-we-make-artificial-intelligence-benefit-all-public-interest-tech/#primaryimage'}, 'thumbnailUrl': 'https://www.fordfoundation.org/wp-content/uploads/2022/08/joy-thumbnail.jpeg', 'datePublished': '2018-11-13T05:00:00+00:00', 'dateModified': '2023-08-29T19:04:02+00:00', 'description': 'Artificial intelligence can be coded to be more inclusive. Joy Buolamwini shows how.', 'breadcrumb': {'@id': 'https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/joy-buolamwini-fighting-the-coded-gaze-how-we-make-artificial-intelligence-benefit-all-public-interest-tech/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/joy-buolamwini-fighting-the-coded-gaze-how-we-make-artificial-intelligence-benefit-all-public-interest-tech/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/joy-buolamwini-fighting-the-coded-gaze-how-we-make-artificial-intelligence-benefit-all-public-interest-tech/#primaryimage', 'url': 'https://www.fordfoundation.org/wp-content/uploads/2022/08/joy-thumbnail.jpeg', 'contentUrl': 'https://www.fordfoundation.org/wp-content/uploads/2022/08/joy-thumbnail.jpeg', 'width': 1280, 'height': 720, 'caption': 'Joy Buolamwini is a Black person wearing a bright pink blazer and matching glasses. Joy holds a faceless white mask to her face. The phrase ""Can you see me now?"" appears to the left.'}, {'@type': 'BreadcrumbList', '@id': 'https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/joy-buolamwini-fighting-the-coded-gaze-how-we-make-artificial-intelligence-benefit-all-public-interest-tech/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.fordfoundation.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Videos', 'item': 'https://www.fordfoundation.org/news-and-stories/videos/'}, {'@type': 'ListItem', 'position': 3, 'name': 'How can Public Interest Tech change our world for good?', 'item': 'https://www.fordfoundation.org/news-and-stories/videos/how-can-public-interest-tech-change-our-world-for-good/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Joy Buolamwini &#8211; Fighting the “coded gaze:” How we make artificial intelligence benefit all. Public Interest Tech'}]}, {'@type': 'WebSite', '@id': 'https://www.fordfoundation.org/#website', 'url': 'https://www.fordfoundation.org/', 'name': 'Ford Foundation', 'description': '', 'publisher': {'@id': 'https://www.fordfoundation.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.fordfoundation.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.fordfoundation.org/#organization', 'name': 'Ford Foundation', 'url': 'https://www.fordfoundation.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fordfoundation.org/#/schema/logo/image/', 'url': 'https://www.fordfoundation.org/wp-content/uploads/2023/05/Ford-Foundation.svg', 'contentUrl': 'https://www.fordfoundation.org/wp-content/uploads/2023/05/Ford-Foundation.svg', 'caption': 'Ford Foundation'}, 'image': {'@id': 'https://www.fordfoundation.org/#/schema/logo/image/'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMioQFodHRwczovL3d3dzIuZGVsb2l0dGUuY29tL3NnL2VuL3BhZ2VzL2ZpbmFuY2lhbC1hZHZpc29yeS9hcnRpY2xlcy90aGUtY2FzZS1mb3ItYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tY29tYmF0aW5nLW1vbmV5LWxhdW5kZXJpbmctYW5kLXRlcnJvcmlzdC1maW5hbmNpbmcuaHRtbNIBAA?oc=5,The case for artificial intelligence in combating money laundering and terrorist financing - Deloitte,2018-11-14,Deloitte,https://www2.deloitte.com,A Balancing Act In Trade Based Money Laundering Compliance,,A Balancing Act In Trade Based Money Laundering Compliance,A Balancing Act In Trade Based Money Laundering Compliance,,,,,,,,,,,,,,,,"











The case for artificial intelligence in combating money laundering and terrorist financing has been saved 





My Deloitte 




×














The case for artificial intelligence in combating money laundering and terrorist financing has been removed 




Undo
My Deloitte 



×














An Article Titled The case for artificial intelligence in combating money laundering and terrorist financing already exists in Saved items 





My Deloitte 




×




















                                Perspectives
                            


The case for artificial intelligence in combating money laundering and terrorist financing
Machine learning technology























Save for later 






















Combating money laundering is an enormous task, and it comes with substantial costs and risks, including but not limited to regulatory, reputational and financial crime risks.
Managing these risks rest with the guardians of the financial system. Moreover, criminals continue to evolve in their laundering techniques, finding and exploiting loopholes in the system to move money. These criminal minds are also capable of using new technologies such as online banking, electronic payments, and cryptocurrencies to move illicit funds across borders at breakneck speed. This creates complex and layered transactions that are increasingly real-time, making it difficult to monitor and to detect with traditional approaches.
At the heart of criminal activity are sophisticated money launderers with the ability to move illicit funds seamlessly through the formal financial system. These money launderers are sophisticated and pose a serious threat to financial institutions across the globe, and their activities have a devastating consequence for society as well. As a result, societal ills such as terrorism, drug and human trafficking challenge social structures and order, societal governance, as well as open and fair commerce. For these reasons, the importance of continuous improvement of an organisation’s financial transaction monitoring and name screening effectiveness has never been more critical in the digital age.
Download the joint whitepaper by Deloitte and United Overseas Bank (UOB)entitled “The case for artificial intelligence in combating money laundering and terrorist financing” that discusses the promise of machine learning in compliance and its potential applications. The whitepaper also highlights a case study that depicts UOB’s journey to tap machine learning to augment and to enhance its existing systems to spot and to prevent illicit money flows.









                        The case for artificial intelligence in combating money laundering and terrorist financing
                     

                     
                        Download whitepaper here
                     
                     
                  

















Contact us





Submit RFP








",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9rYXJsLWZyaXN0b24tZnJlZS1lbmVyZ3ktcHJpbmNpcGxlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,The Genius Neuroscientist Who Might Hold the Key to True AI - WIRED,2018-11-13,WIRED,https://www.wired.com,"Karl Friston’s free energy principle might be the most all-encompassing idea since the theory of natural selection. But to understand it, you need to peer inside the mind of Friston himself.","['the big story', 'science', 'psychology and neuroscience', 'ai hub', 'research', 'neural network', 'health care', 'machine learning', 'magazine-26.12', 'artificial intelligence', 'ai', 'neuroscience', 'wired classic', 'longreads', '_no-homepage', '_syndication_noshow', 'paywall subscriber only content', 'textaboveleftgridwidth', 'magazine']",Karl Friston’s free energy principle might be the most all-encompassing idea since the theory of natural selection. And Friston may be the only person who truly understands it.,Karl Friston’s free energy principle might be the most all-encompassing idea since the theory of natural selection. And Friston may be the only person who truly understands it.,https://schema.org/,BreadcrumbList,https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/,"['https://media.wired.com/photos/5be3712d72ce4c601115b2f8/16:9/w_2399,h_1349,c_limit/Karl_Friston_24349.jpg', 'https://media.wired.com/photos/5be3712d72ce4c601115b2f8/4:3/w_2396,h_1797,c_limit/Karl_Friston_24349.jpg', 'https://media.wired.com/photos/5be3712d72ce4c601115b2f8/1:1/w_1642,h_1642,c_limit/Karl_Friston_24349.jpg']","[{'@type': 'Person', 'name': 'Shaun Raviv', 'sameAs': 'https://www.wired.com/author/shaun-raviv/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",The Genius Neuroscientist Who Might Hold the Key to True AI,2018-11-13T06:00:00.000-05:00,2018-11-13T06:00:00.000-05:00,the big story,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'The Big Story', 'item': 'https://www.wired.com/big-story/'}, {'@type': 'ListItem', 'position': 2, 'name': 'magazine-26.12', 'item': 'https://www.wired.com/tag/magazine-2612/'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Genius Neuroscientist Who Might Hold the Key to True AI'}]",tags,,"Shaun RavivThe Big StoryNov 13, 2018 6:00 AMThe Genius Neuroscientist Who Might Hold the Key to True AIKarl Friston’s free energy principle might be the most all-encompassing idea since the theory of natural selection. But to understand it, you need to peer inside the mind of Friston himself.Photograph: Kate PetersSave this storySaveSave this storySaveThe AI Database →End UserResearchSectorResearchHealth careTechnologyNeural NetworkMachine learningWhen King George III of England began to show signs of acute mania toward the end of his reign, rumors about the royal madness multiplied quickly in the public mind. One legend had it that George tried to shake hands with a tree, believing it to be the King of Prussia. Another described how he was whisked away to a house on Queen Square, in the Bloomsbury district of London, to receive treatment among his subjects. The tale goes on that George’s wife, Queen Charlotte, hired out the cellar of a local pub to stock provisions for the king’s meals while he stayed under his doctor’s care.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDThis article is exclusive to subscribers. Subscribe Now. If you're already a subscriber sign in.","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/'}","Karl Friston’s free energy principle might be the most all-encompassing idea since the theory of natural selection. But to understand it, you need to peer inside the mind of Friston himself.",,,,,"{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,,,,,,,"More than two centuries later, this story about Queen Square is still popular in London guidebooks. And whether or not it’s true, the neighborhood has evolved over the years as if to conform to it. A metal statue of Charlotte stands over the northern end of the square; the corner pub is called the Queen’s Larder; and the square’s quiet rectangular garden is now all but surrounded by people who work on brains and people whose brains need work. The National Hospital for Neurology and Neurosurgery—where a modern-day royal might well seek treatment—dominates one corner of Queen Square, and the world-renowned neuroscience research facilities of University College London round out its perimeter. During a week of perfect weather last July, dozens of neurological patients and their families passed silent time on wooden benches at the outer edges of the grass.
On a typical Monday, Karl Friston arrives on Queen Square at 12:25 pm and smokes a cigarette in the garden by the statue of Queen Charlotte. A slightly bent, solitary figure with thick gray hair, Friston is the scientific director of University College London’s storied Functional Imaging Laboratory, known to everyone who works there as the FIL. After finishing his cigarette, Friston walks to the western side of the square, enters a brick and limestone building, and heads to a seminar room on the fourth floor, where anywhere from two to two dozen people might be facing a blank white wall waiting for him. Friston likes to arrive five minutes late, so everyone else is already there.
His greeting to the group is liable to be his first substantial utterance of the day, as Friston prefers not to speak with other human beings before noon. (At home, he will have conversed with his wife and three sons via an agreed-upon series of smiles and grunts.) He also rarely meets people one-on-one. Instead, he prefers to hold open meetings like this one, where students, postdocs, and members of the public who desire Friston’s expertise—a category of person that has become almost comically broad in recent years—can seek his knowledge. “He believes that if one person has an idea or a question or project going on, the best way to learn about it is for the whole group to come together, hear the person, and then everybody gets a chance to ask questions and discuss. And so one person’s learning becomes everybody’s learning,” says David Benrimoh, a psychiatry resident at McGill University who studied under Friston for a year. “It’s very unique. As many things are with Karl.”
At the start of each Monday meeting, everyone goes around and states their questions at the outset. Friston walks in slow, deliberate circles as he listens, his glasses perched at the end of his nose, so that he is always lowering his head to see the person who is speaking. He then spends the next few hours answering the questions in turn. “A Victorian gentleman, with Victorian manners and tastes,” as one friend describes Friston, he responds to even the most confused questions with courtesy and rapid reformulation. The Q&A sessions—which I started calling “Ask Karl” meetings—are remarkable feats of endurance, memory, breadth of knowledge, and creative thinking. They often end when it is time for Friston to retreat to the minuscule metal balcony hanging off his office for another smoke.
Friston first became a heroic figure in academia for devising many of the most important tools that have made human brains legible to science. In 1990 he invented statistical parametric mapping, a computational technique that helps—as one neuroscientist put it—“squash and squish” brain images into a consistent shape so that researchers can do apples-to-apples comparisons of activity within different crania. Out of statistical parametric mapping came a corollary called voxel-­based morphometry, an imaging technique that was used in one famous study to show that the rear side of the hippocampus of London taxi drivers grew as they learned “the knowledge.”1
A study published in Science in 2011 used yet a third brain-imaging-analysis software invented by Friston—dynamic causal modeling—to determine if people with severe brain damage were minimally conscious or simply vegetative.
When Friston was inducted into the Royal Society of Fellows in 2006, the academy described his impact on studies of the brain as “revolutionary” and said that more than 90 percent of papers published in brain imaging used his methods. Two years ago, the Allen Institute for Artificial Intelligence, a research outfit led by AI pioneer Oren Etzioni, calculated that Friston is the world’s most frequently cited neuroscientist. He has an h-­index—a metric used to measure the impact of a researcher’s publications—nearly twice the size of Albert Einstein’s. Last year Clarivate Analytics, which over more than two decades has successfully predicted 46 Nobel Prize winners in the sciences, ranked Friston among the three most likely winners in the physiology or medicine category.
What’s remarkable, however, is that few of the researchers who make the pilgrimage to see Friston these days have come to talk about brain imaging at all. Over a 10-day period this summer, Friston advised an astrophysicist, several philosophers, a computer engineer working on a more personable competitor to the Amazon Echo, the head of artificial intelligence for one of the world’s largest insurance companies, a neuroscientist seeking to build better hearing aids, and a psychiatrist with a startup that applies machine learning to help treat depression. And most of them had come because they were desperate to understand something else entirely.
For the past decade or so, Friston has devoted much of his time and effort to developing an idea he calls the free energy principle. (Friston refers to his neuroimaging research as a day job, the way a jazz musician might refer to his shift at the local public library.) With this idea, Friston believes he has identified nothing less than the organizing principle of all life, and all intelligence as well. “If you are alive,” he sets out to answer, “what sorts of behaviors must you show?”
First the bad news: The free energy principle is maddeningly difficult to understand. So difficult, in fact, that entire rooms of very, very smart people have tried and failed to grasp it. A Twitter account2 with 3,000 followers exists simply to mock its opacity, and nearly every person I spoke with about it, including researchers whose work depends on it, told me they didn’t fully comprehend it.
But often those same people hastened to add that the free energy principle, at its heart, tells a simple story and solves a basic puzzle. The second law of thermodynamics tells us that the universe tends toward entropy, toward dissolution; but living things fiercely resist it. We wake up every morning nearly the same person we were the day before, with clear separations between our cells and organs, and between us and the world without. How? Friston’s free energy principle says that all life, at every scale of organization—from single cells to the human brain, with its billions of neurons—is driven by the same universal imperative, which can be reduced to a mathematical function. To be alive, he says, is to act in ways that reduce the gulf between your expectations and your sensory inputs. Or, in Fristonian terms, it is to minimize free energy.
To get a sense of the potential implications of this theory, all you have to do is look at the array of people who darken the FIL’s doorstep on Monday mornings. Some are here because they want to use the free energy principle to unify theories of the mind, provide a new foundation for biology, and explain life as we know it. Others hope the free energy principle will finally ground psychiatry in a functional understanding of the brain. And still others come because they want to use Friston’s ideas to break through the roadblocks in artificial intelligence research. But they all have one reason in common for being here, which is that the only person who truly understands Karl Friston’s free energy principle may be Karl Friston himself.
But if you ask him, this output isn’t just the fruit of an ambitious work ethic; it’s a mark of his tendency toward a kind of rigorous escapism.
Friston draws a carefully regulated boundary around his inner life, guarding against intrusions, many of which seem to consist of “worrying about other people.” He prefers being onstage, with other people at a comfortable distance, to being in private conversations. He does not have a mobile phone. He always wears navy-blue suits, which he buys two at a time at a closeout shop. He finds disruptions to his weekly routine on Queen Square “rather nerve-racking” and so tends to avoid other human beings at, say, international conferences. He does not enjoy advocating for his own ideas.
At the same time, Friston is exceptionally lucid and forthcoming about what drives him as a scholar. He finds it incredibly soothing—not unlike disappearing for a smoke—to lose himself in a difficult problem that takes weeks to resolve. And he has written eloquently about his own obsession, dating back to childhood, with finding ways to integrate, unify, and make simple the apparent noise of the world.
Friston traces his path to the free energy principle back to a hot summer day when he was 8 years old. He and his family were living in the walled English city of Chester, near Liverpool, and his mother had told him to go play in the garden. He turned over an old log and spotted several wood lice—small bugs with armadillo-shaped exoskeletons—moving about, he initially assumed, in a frantic search for shelter and darkness. After staring at them for half an hour, he deduced that they were not actually seeking the shade. “That was an illusion,” Friston says. “A fantasy that I brought to the table.”
He realized that the movement of the wood lice had no larger purpose, at least not in the sense that a human has a purpose when getting in a car to run an errand. The creatures’ movement was random; they simply moved faster in the warmth4 of the sun.
Friston calls this his first scientific insight, a moment when “all these contrived, anthropomorphized explanations of purpose and survival and the like all seemed to just peel away,” he says. “And the thing you were observing just was. In the sense that it could be no other way.”
Friston’s father was a civil engineer who worked on bridges all around England, and his family moved around with him. In just his first decade, the young Friston attended six different schools. His teachers often didn’t know what to do with him, and he drew most of his fragile self-esteem from solitary problem solving. At age 10 he designed a self-righting robot that could, in theory, traverse uneven ground while carrying a glass of water, using self-correcting feedback actuators and mercury levels. At school, a psychologist was brought in to ask him how he came up with it. “You’re very intelligent, Karl,” Friston’s mother reassured him, not for the last time. “Don’t let them tell you you’re not.” He says he didn’t believe her.
When Friston was in his mid-teens, he had another wood-lice moment. He had just come up to his bedroom from watching TV and noticed the cherry trees in bloom outside the window. He suddenly became possessed by a thought that has never let go of him since. “There must be a way of understanding everything by starting from nothing,” he thought. “If I’m only allowed to start off with one point in the entire universe, can I derive everything else I need from that?” He stayed there on his bed for hours, making his first attempt. “I failed completely, obviously,” he says.
Toward the end of secondary school, Friston and his classmates were the subjects of an early experiment in computer-­assisted advising. They were asked a series of questions, and their answers were punched into cards and run through a machine to extrapolate the perfect career choice. Friston had described how he enjoyed electronics design and being alone in nature, so the computer suggested he become a television antenna installer. That didn’t seem right, so he visited a school career counselor and said he’d like to study the brain in the context of mathematics and physics. The counselor told Friston he should become a psychiatrist, which meant, to Friston’s horror, that he had to study medicine.
Both Friston and the counselor had confused psychiatry with psychology, which is what he probably ought to have pursued as a future researcher. But it turned out to be a fortunate error, as it put Friston on a path toward studying both the mind and body,5 and toward one of the most formative experiences of his life—one that got Friston out of his own head.
After completing his medical studies, Friston moved to Oxford and spent two years as a resident trainee at a Victorian-era hospital called Littlemore. Founded under the 1845 Lunacy Act, Littlemore had originally been instituted to help transfer all “pauper lunatics” from workhouses to hospitals. By the mid-1980s, when Friston arrived, it was one of the last of the old asylums on the outskirts of England’s cities.
Friston was assigned a group of 32 chronic schizophrenic patients, the worst-off residents of Littlemore, for whom treatment mostly meant containment. For Friston, who recalls his former patients with evident nostalgia, it was an introduction to the way that connections in the brain were easily broken. “It was a beautiful place to work,” he says. “This little community of intense and florid psychopathology.”
Twice a week he led 90-minute group therapy sessions in which the patients explored their ailments together, reminiscent of the Ask Karl meetings today. The group included colorful characters who still inspire Friston’s thinking more than 30 years later. There was Hillary,6 who looked like she could play the senior cook on Downton Abbey but who, before coming to Littlemore, had decapitated her neighbor with a kitchen knife, convinced he had become an evil, human-sized crow.
There was Ernest, who had a penchant for pastel Marks & Spencer cardigans and matching plimsoll shoes, and who was “as rampant and incorrigible a pedophile as you could ever imagine,” Friston says.
And then there was Robert, an articulate young man who might have been a university student had he not suffered severe schizophrenia. Robert ruminated obsessively about, of all things, angel shit; he pondered whether the stuff was a blessing or a curse and whether it was ever visible to the eye, and he seemed perplexed that these questions had not occurred to others. To Friston, the very concept of angel shit was a miracle. It spoke to the ability of people with schizophrenia to assemble concepts that someone with a more regularly functioning brain couldn’t easily access. “It’s extremely difficult to come up with something like angel shit,” Friston says with something like admiration. “I couldn’t do it.”
After Littlemore, Friston spent much of the early 1990s using a relatively new technology—PET scans—to try to understand what was going on inside the brains of people with schizophrenia. He invented statistical parametric mapping along the way. Unusually for the time, Friston was adamant that the technique should be freely shared rather than patented and commercialized, which largely explains how it became so widespread. Friston would fly across the world—to the National Institutes of Health in Bethesda, Maryland, for example—to give it to other researchers. “It was me, literally, with a quarter of biometric tape, getting on an airplane, taking it over there, downloading it, spending a day getting it to work, teaching somebody how to use it, then going home for a rest,” Friston says. “This is how open source software worked in those days.”
Friston came to Queen Square in 1994, and for a few years his office at the FIL sat just a few doors down from the Gatsby Computational Neuroscience Unit. The Gatsby—where researchers study theories of perception and learning in both living and machine systems—was then run by its founder, the cognitive psychologist and computer scientist Geoffrey Hinton. While the FIL was establishing itself as one of the premier labs for neuroimaging, the Gatsby was becoming a training ground for neuroscientists interested in applying mathematical models to the nervous system.
Friston, like many others, became enthralled by Hinton’s “childlike enthusiasm” for the most unchildlike of statistical models, and the two men became friends.7
Over time, Hinton convinced Friston that the best way to think of the brain was as a Bayesian probability machine. The idea, which goes back to the 19th century and the work of Hermann von Helmholtz, is that brains compute and perceive in a probabilistic manner, constantly making predictions and adjusting beliefs based on what the senses contribute. According to the most popular modern Bayesian account, the brain is an “inference engine” that seeks to minimize “prediction error.”
In 2001, Hinton left London for the University of Toronto, where he became one of the most important figures in artificial intelligence, laying the groundwork8 for much of today’s research in deep learning.
Before Hinton left, however, Friston visited his friend at the Gatsby one last time. Hinton described a new technique he’d devised to allow computer programs to emulate human decisionmaking more efficiently—a process for integrating the input of many different probabilistic models, now known in machine learning as a “product of experts.”
The meeting left Friston’s head spinning. Inspired by Hinton’s ideas, and in a spirit of intellectual reciprocity, Friston sent Hinton a set of notes about an idea he had for connecting several seemingly “unrelated anatomical, physiological, and psychophysical attributes of the brain.” Friston published those notes in 2005—the first of many dozens of papers he would go on to write about the free energy principle.
It’s a white fleece throw, custom-printed with a black-and-white portrait of a stern, bearded Russian mathematician named Andrei Andreyevich Markov, who died in 1922. The blanket is a gag gift from Friston’s son, a plush, polyester inside joke about an idea that has become central to the free energy principle. Markov is the eponym of a concept called a Markov blanket, which in machine learning is essentially a shield that separates one set of variables from others in a layered, hierarchical system. The psychologist Christopher Frith—who has an h-index on par with Friston’s—once described a Markov blanket as “a cognitive version of a cell membrane, shielding states inside the blanket from states outside.”
In Friston’s mind, the universe is made up of Markov blankets inside of Markov blankets. Each of us has a Markov blanket that keeps us apart from what is not us. And within us are blankets separating organs, which contain blankets separating cells, which contain blankets separating their organelles. The blankets define how biological things exist over time and behave distinctly from one another. Without them, we’re just hot gas dissipating into the ether.
“That’s the Markov blanket you’ve read about. This is it. You can touch it,” Friston said dryly when I first saw the throw in his office. I couldn’t help myself; I did briefly reach out to feel it under my fingers. Ever since I first read about Markov blankets, I’d seen them everywhere. Markov blankets around a leaf and a tree and a mosquito. In London, I saw them around the postdocs at the FIL, around the black-clad protesters at an antifascist rally, and around the people living in boats in the canals. Invisible cloaks around everyone, and underneath each one a different living system that minimizes its own free energy.
The concept of free energy itself comes from physics, which means it’s difficult to explain precisely without wading into mathematical formulas. In a sense that’s what makes it powerful: It isn’t a merely rhetorical concept. It’s a measurable quantity that can be modeled, using much the same math that Friston has used to interpret brain images to such world-­changing effect. But if you translate the concept from math into English, here’s roughly what you get: Free energy is the difference between the states you expect to be in and the states your sensors tell you that you are in. Or, to put it another way, when you are minimizing free energy, you are minimizing surprise.
According to Friston, any biological system9 that resists a tendency to disorder and dissolution will adhere to the free energy principle—whether it’s a protozoan or a pro basketball team.
A single-celled organism has the same imperative to reduce surprise that a brain does.
The only difference is that, as self-organizing biological systems go, the human brain is inordinately complex: It soaks in information from billions of sense receptors, and it needs to organize that information efficiently into an accurate model of the world. “It’s literally a fantastic organ in the sense that it generates hypotheses or fantasies that are appropriate for trying to explain these myriad patterns, this flux of sensory information that it is in receipt of,” Friston says. In seeking to predict what the next wave of sensations is going to tell it—and the next, and the next—the brain is constantly making inferences and updating its beliefs based on what the senses relay back, and trying to minimize prediction-error signals.
So far, as you might have noticed, this sounds a lot like the Bayesian idea of the brain as an “inference engine” that Hinton told Friston about in the 1990s. And indeed, Friston regards the Bayesian model as a foundation of the free energy principle (“free energy” is even a rough synonym for “prediction error”). But the limitation of the Bayesian model, for Friston, is that it only accounts for the interaction between beliefs and perceptions; it has nothing to say about the body or action. It can’t get you out of your chair.
This isn’t enough for Friston, who uses the term “active inference” to describe the way organisms minimize surprise while moving about the world. When the brain makes a prediction that isn’t immediately borne out by what the senses relay back, Friston believes, it can minimize free energy in one of two ways: It can revise its prediction—absorb the surprise, concede the error, update its model of the world—or it can act to make the prediction true. If I infer that I am touching my nose with my left index finger, but my proprioceptors tell me my arm is hanging at my side, I can minimize my brain’s raging prediction-error signals by raising that arm up and pressing a digit to the middle of my face.
And in fact, this is how the free energy principle accounts for everything we do: perception, action, planning, problem solving. When I get into the car to run an errand, I am minimizing free energy by confirming my hypothesis—my fantasy—through action.
For Friston, folding action and movement into the equation is immensely important. Even perception itself, he says, is “enslaved by action”: To gather information, the eye darts, the diaphragm draws air into the nose, the fingers generate friction against a surface. And all of this fine motor movement exists on a continuum with bigger plans, explorations,10 and actions.
“We sample the world,” Friston writes, “to ensure our predictions become a self-fulfilling prophecy.”
So what happens when our prophecies are not self-fulfilling? What does it look like for a system to be overwhelmed by surprise? The free energy principle, it turns out, isn’t just a unified theory of action, perception, and planning; it’s also a theory of mental illness. When the brain assigns too little or too much weight to evidence pouring in from the senses, trouble occurs. Someone with schizophrenia, for example, may fail to update their model of the world to account for sensory input from the eyes. Where one person might see a friendly neighbor, Hillary might see a giant, evil crow. “If you think about psychiatric conditions, and indeed most neurological conditions, they are just broken beliefs or false inference—hallucinations and delusions,” Friston says.
Over the past few years, Friston and a few other scientists have used the free energy principle to help explain anxiety, depression, and psychosis, along with certain symptoms of autism, Parkinson’s disease, and psychopathy. In many cases, scientists already know—thanks to Friston’s neuroimaging methods—which regions of the brain tend to malfunction in different disorders and which signals tend to be disrupted. But that alone isn’t enough to go on. “It’s not sufficient to understand which synapses, which brain connections, are working improperly,” he says. “You need to have a calculus that talks about beliefs.”
So: The free energy principle offers a unifying explanation for how the mind works and a unifying explanation for how the mind malfunctions. It stands to reason, then, that it might also put us on a path toward building a mind from scratch.
This kind of pattern-matching technology—which is roughly similar to the techniques that have taught machines to recognize faces, images of cats, and speech patterns—has driven huge advances in computing over the past several years. But it requires a lot of up-front data and human supervision, and it can be brittle. Another approach to AI, called reinforcement learning, has shown incredible success at winning games: Go, chess, Atari’s Breakout. Reinforcement learning doesn’t require humans to label lots of training data; it just requires telling a neural network to seek a certain reward, often victory in a game. The neural network learns by playing the game over and over, optimizing for whatever moves might get it to the final screen, the way a dog might learn to perform certain tasks for a treat.
But reinforcement learning, too, has pretty major limitations. In the real world, most situations are not organized around a single, narrowly defined goal. (Sometimes you have to stop playing Breakout to go to the bathroom, put out a fire, or talk to your boss.) And most environments aren’t as stable and rule-bound as a game is. The conceit behind neural networks is that they are supposed to think the way we do; but reinforcement learning doesn’t really get us there.
To Friston and his enthusiasts, this failure makes complete sense. After all, according to the free energy principle, the fundamental drive of human thought isn’t to seek some arbitrary external reward. It’s to minimize prediction error. Clearly, neural networks ought to do the same. It helps that the Bayesian formulas behind the free energy principle—the ones that are so difficult to translate into English—are already written in the native language of machine learning.
Julie Pitt, head of machine-learning infrastructure at Netflix, discovered Friston and the free energy principle in 2014, and it transformed her thinking. (Pitt’s Twitter bio reads, “I infer my own actions by way of Active Inference.”) Outside of her work at Netflix, she’s been exploring applications of the principle in a side project called Order of Magnitude Labs. Pitt says that the beauty of the free energy model is that it allows an artificial agent to act in any environment, even one that’s new and unknown. Under the old reinforcement-learning model, you’d have to keep stipulating new rules and sub-rewards to get your agent to cope with a complex world. But a free energy agent always generates its own intrinsic reward: the minimization of surprise. And that reward, Pitt says, includes an imperative to go out and explore.
In late 2017, a group led by Rosalyn Moran, a neuroscientist and engineer at King’s College London, pitted two AI players against one another in a version of the 3D shooter game Doom. The goal was to compare an agent driven by active inference to one driven by reward-maximization.
The reward-based agent’s goal was to kill a monster inside the game, but the free-energy-driven agent only had to minimize surprise. The Fristonian agent started off slowly. But eventually it started to behave as if it had a model of the game, seeming to realize, for instance, that when the agent moved left the monster tended to move to the right.
After a while it became clear that, even in the toy environment of the game, the reward-­maximizing agent was “demonstrably less robust”; the free energy agent had learned its environment better. “It outperformed the reinforcement-­learning agent because it was exploring,” Moran says. In another simulation that pitted the free-energy-minimizing agent against real human players, the story was similar. The Fristonian agent started slowly, actively exploring options—epistemically foraging, Friston would say—before quickly attaining humanlike performance.
Moran told me that active inference is starting to spread into more mainstream deep-learning research, albeit slowly. Some of Friston’s students have gone on to work at DeepMind and Google Brain, and one of them founded Huawei’s Artificial Intelligence Theory lab. “It’s moving out of Queen Square,” Moran says. But it’s still not nearly as common as reinforcement learning, which even undergraduates learn. “You don’t teach undergraduates the free energy principle—yet.”
The first time I asked Friston about the connection between the free energy principle and artificial intelligence, he predicted that within five to 10 years, most machine learning would incorporate free energy minimization. The second time, his response was droll. “Think about why it’s called active inference,” he said. His straight, sparkly white teeth showed through his smile as he waited for me to follow his wordplay. “Well, it’s AI,” Friston said. “So is active inference the new AI? Yes, it’s the acronym.” Not for the first time, a Fristonian joke had passed me by.
The next morning, I asked Friston if he thought the talk went well, considering that few of those bright young minds seemed to understand him. “There is going to be a substantial proportion of the audience who—it’s just not for them,” he said. “Sometimes they get upset because they’ve heard that it’s important and they don’t understand it. They think they have to think it’s rubbish and they leave. You get used to that.”
In 2010, Peter Freed, a psychiatrist at Columbia University, gathered together 15 brain researchers to discuss one of Friston’s papers. Freed described what happened in the journal Neuropsychoanalysis: “There was a lot of mathematical knowledge in the room: three statisticians, two physicists, a physical chemist, a nuclear physicist, and a large group of neuroimagers—but apparently we didn’t have what it took. I met with a Princeton physicist, a Stanford neurophysiologist, a Cold Springs Harbor neurobiologist to discuss the paper. Again blanks, one and all: too many equations, too many assumptions, too many moving parts, too global a theory, no opportunity for questions—and so people gave up.”
But for all the people who are exasperated by Friston’s impenetrability, there are nearly as many who feel he has unlocked something huge, an idea every bit as expansive as Darwin’s theory of natural selection. When the Canadian philosopher Maxwell Ramstead first read Friston’s work in 2014, he had already been trying to find ways to connect complex living systems that exist at different scales—from cells to brains to individuals to cultures. In 2016 he met Friston, who told him that the same math that applies to cellular differentiation—the process by which generic cells become more specialized—can also be applied to cultural dynamics. “This was a life-changing conversation for me,” Ramstead says. “I almost had a nosebleed.”
“This is absolutely novel in history,” Ramstead told me as we sat on a bench in Queen Square, surrounded by patients and staff from the surrounding hospitals. Before Friston came along, “We were kind of condemned to forever wander in this multidisciplinary space without a common currency,” he continued. “The free energy principle gives you that currency.”
In 2017, Ramstead and Friston coauthored a paper, with Paul Badcock of the University of Melbourne, in which they described all life in terms of Markov blankets. Just as a cell is a Markov-blanketed system that minimizes free energy in order to exist, so are tribes and religions and species.
After the publication of Ramstead’s paper, Micah Allen, a cognitive neuroscientist then at the FIL, wrote that the free energy principle had evolved into a real-life version of Isaac Asimov’s psychohistory,11 a fictional system that reduced all of psychology, history, and physics down to a statistical science.
And it’s true that the free energy principle does seem to have expanded to the point of being, if not a theory of everything, then nearly so. (Friston told me that cancer and tumors might be instances of false inference, when cells become deluded.) As Allen asked: Does a theory that explains everything run the risk of explaining nothing?
On the last day of my trip, I visited Friston in the town of Rickmansworth, where he lives in a house filled with taxidermied animals12 that his wife prepares as a hobby.
As it happens, Rickmansworth appears on the first page of The Hitchhiker’s Guide to the Galaxy; it’s the town where “a girl sitting on her own in a small café” suddenly discovers the secret to making the world “a good and happy place.” But fate intervenes. “Before she could get to a phone to tell anyone about it, a terrible stupid catastrophe occurred, and the idea was lost forever.”
It’s unclear whether the free energy principle is the secret to making the world a good and happy place, as some of its believers almost seem to think it might be. Friston himself tended to take a more measured tone as our talks went on, suggesting only that active inference and its corollaries were quite promising. Several times he conceded that he might just be “talking rubbish.” During the last group meeting I attended at the FIL, he told those in attendance that the free energy principle is an “as if” concept—it does not require that biological things minimize free energy in order to exist; it is merely sufficient as an explanation for biotic self-organization.
Friston’s mother died a few years ago, but lately he has been thinking back to her frequent reassurances during his childhood: You’re very intelligent, Karl. “I never quite believed her,” he says. “And yet now I have found myself suddenly being seduced by her argument. Now I do believe I’m actually quite bright.” But this newfound self-esteem, he says, has also led him to examine his own egocentricity.
Friston says his work has two primary motivations. Sure, it would be nice to see the free energy principle lead to true artificial consciousness someday, he says, but that’s not one of his top priorities. Rather, his first big desire is to advance schizophrenia research, to help repair the brains of patients like the ones he knew at the old asylum. And his second main motivation, he says, is “much more selfish.” It goes back to that evening in his bedroom, as a teenager, looking at the cherry blossoms, wondering, “Can I sort it all out in the simplest way possible?”
“And that is a very self-indulgent thing. It has no altruistic clinical compassion behind it. It is just the selfish desire to try and understand things as completely and as rigorously and as simply as possible,” he says. “I often reflect on the jokes that people make about me—sometimes maliciously, sometimes very amusingly—that I can’t communicate. And I think: I didn’t write it for you. I wrote it for me.”
Friston told me he occasionally misses the last train home to Rickmansworth, lost in one of those problems that he drills into for weeks. So he’ll sleep in his office, curled on the futon under his Markov blanket, safe and securely separated from the external world.

This article appears in the December 2018 issue. Subscribe now.
Listen to this story, and other WIRED features, on the Audm app.
Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.","https://media.wired.com/photos/5be3712d72ce4c601115b2f8/1:1/w_1642,h_1642,c_limit/Karl_Friston_24349.jpg",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiqwFodHRwczovL3d3dy5tY2tpbnNleS5jb20vY2FwYWJpbGl0aWVzL21ja2luc2V5LWRpZ2l0YWwvb3VyLWluc2lnaHRzL2hvdy1ib3RzLWFsZ29yaXRobXMtYW5kLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFyZS1yZXNoYXBpbmctdGhlLWZ1dHVyZS1vZi1jb3Jwb3JhdGUtc3VwcG9ydC1mdW5jdGlvbnPSAQA?oc=5,"How bots, algorithms, and artificial intelligence are reshaping the future of corporate support functions - McKinsey",2018-11-15,McKinsey,https://www.mckinsey.com,Industrial companies are discovering additional sources of value in applying advanced technology to general and administrative support functions. The results can be impressive for businesses that can adapt to the disruption of legacy systems.,,Industrial companies are discovering additional sources of value in applying advanced technology to general and administrative support functions. The results can be impressive for businesses that can adapt to the disruption of legacy systems.,Industrial companies are discovering additional sources of value in applying advanced technology to general and administrative support functions. The results can be impressive for businesses that can adapt to the disruption of legacy systems.,https://schema.org,Article,https://www.mckinsey.com,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/how%20bots%20algorithms%20ai%20are%20reshaping/hero-bots-algorithms-and-artificial-intelligence.jpg,"[{'@type': 'Person', 'name': 'Alexander Edlich', 'url': 'https://www.mckinsey.com/our-people/alexander-edlich'}, {'@type': 'Person', 'name': 'Fanny Ip'}, {'@type': 'Person', 'name': 'Rob Whiteman'}]","{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,2018-11-15T00:00:00Z,2018-11-15T00:00:00Z,,,,,,,,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/how-bots-algorithms-and-artificial-intelligence-are-reshaping-the-future-of-corporate-support-functions'}",,,,,,,,,,,,,,,,,,2018-09-19T14:22:27Z,,,,,,"How bots, algorithms, and artificial intelligence are reshaping the future of corporate support functions",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vd3d3Lmdlb3NwYXRpYWx3b3JsZC5uZXQvYmxvZ3MvcHV0dGluZy10cmFmZmljLXNpZ25zLW9uLXRoZS1tYXAv0gEA?oc=5,Putting traffic signs on the map: How artificial intelligence can help - Geospatial World,2018-11-14,Geospatial World,https://www.geospatialworld.net,"The GIS market is booming. It’s set to surge from $5.81 billion in 2017 to $10.03 billion by 2023, but in spite of this, many small cities across the US still just have a one-person GIS shop",,"The GIS market is booming. It’s set to surge from $5.81 billion in 2017 to $10.03 billion by 2023, but in spite of this, many small cities across the US still just have a one-person GIS shop",,http://schema.org,BreadcrumbList,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.geospatialworld.net/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.geospatialworld.net/blogs/', 'name': 'Blogs'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/', 'name': 'Putting traffic signs on the map: How artificial intelligence can help'}}]",,,"

Home  Blogs  Putting traffic signs on the map: How artificial intelligence can help
Blogs

Putting traffic signs on the map: How artificial intelligence can help

By Madelen Arnesdotter -   11/14/2018      4 Minutes Read 




The GIS market is booming. It’s set to surge from $5.81 billion in 2017 to $10.03 billion by 2023, but in spite of this, many small cities across the US still just have a one-person GIS shop, tasked with everything from informing and analyzing urban planning to doing street-level inventory. Time is scarce, and if you work for a city council, money tends to be as well—yet you’re expected to keep track of street assets and their overall conditions.
Steven Hewett’s situation was no different. A GIS specialist at the City of Clovis in New Mexico, a town of 39,000, Steven needed to undertake a complete traffic sign inventory of the approximately 24 square mile city–something that had never been done before. City managers assumed this task could be completed fairly easily and within a month, but no-one knew how many signs were actually out there.
Steven in his office
Asset data collection can be painstakingly time-consuming and expensive. It usually involves either going out yourself to every location and manually recording the data you need, or hiring a contractor to do it for you. With manual traffic sign inventory costing upwards of $4-6 per sign, this would cost a city like Clovis, which Steven now knows has about 4000 traffic signs, somewhere around $16,000-24,000. To a small city council, this is not an insignificant sum of cash.
Like many cities around the world, Clovis had never done a traffic sign inventory before and had little idea how many traffic signs were even out there and what shape they were in (pun intended!). After some investigation, Steven ended up using Mapillary, an AI-powered street-level imagery platform. Instead of hiring a contractor to do surveying, Steven mounted some cameras on his car and captured 200,000 images of the streets of Clovis. Once uploaded to Mapillary, the images are processed with computer vision, a form of artificial intelligence, to automatically detect and analyze data such as traffic signs.
Steven mounting cameras on his car to go out and capture imagery of the streets of Clovis. He mapped all of Clovis in just a few months, but thinks he could have done it in just a few days if he had done it in one go.
Even though Steven was the only person collecting images, and though he juggled it alongside other day-to-day tasks, the entire process took a couple of months. Had he done it in one go, Steven says it could have been done in just a few days—a huge time saving compared to doing the work manually:
“Doing all this work manually, it wouldn’t surprise me if it had taken up to a decade to walk through each and every block to get every sign that is out there. There is no telling how many changes would come through to traffic signs in that time.”
Traffic signs automatically identified by Mapillary’s computer vision algorithms in the city of Clovis, New Mexico.
Soon after the images had been uploaded to Mapillary, Steven was able to access the automatically detected traffic sign data. The data downloaded from Mapillary is compatible with ArcGIS, allowing Steven to ensure that all traffic signs are visible, and to check whether they are in need of repair or replacement. With a full inventory, it is also possible to see where more or fewer signs may be necessary for a particular area.
The Mapillary web platform, showing the location of every identified traffic sign.
Mapillary supports a total of 1,500 traffic signs from 100 different countries. Janine Yoong, VP of Business Development at Mapillary, says traffic sign inventory represents a particular pain point for cities:
“Both small and large cities struggle with keeping tabs on their street assets, but smaller cities are often under a different kind of pressure as they tend to have fewer people working with GIS. Because it takes so long to do manual inventories, most cities just haven’t done it at all. Using computer vision to automatically identify traffic signs saves GIS officers both time and money, and opens up opportunities to focus on other areas”.
Steven working with the Mapillary traffic sign data in ArcGIS
Mapillary works with cities all over the world, ranging from Amsterdam to Stockholm and Los Angeles. As for Steven in Clovis, some of his findings included traffic signs that were so old that they’d actually been completely bleached by the sun, inevitably causing confusion on the streets.
“With this data, we’ll now look into what traffic signs need replacing and where,” Steven says.
This is a guest blog by Madelen Arnesdotter, Customer Success Manager at Mapillary
Also Read: Mapillary fixes maps with computer vision


 

 TAGSArtificial IntelligenceFuture TechnologiesgeospatialGIS & Mapping 


Facebook


Twitter


WhatsApp


Linkedin


  Madelen ArnesdotterCustomer Success Manager at Mapillary

 
",,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/#article', 'isPartOf': {'@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/'}, 'author': {'name': 'Madelen Arnesdotter', '@id': 'https://www.geospatialworld.net/#/schema/person/60f9d8ac2683cfb1a65a7b6258057224'}, 'headline': 'Putting traffic signs on the map: How artificial intelligence can help', 'datePublished': '2018-11-14T12:22:25+00:00', 'dateModified': '2018-11-14T12:26:44+00:00', 'mainEntityOfPage': {'@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/'}, 'wordCount': 823, 'publisher': {'@id': 'https://www.geospatialworld.net/#organization'}, 'image': {'@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/#primaryimage'}, 'thumbnailUrl': 'https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2018/11/4.jpg', 'keywords': ['Artificial Intelligence', 'Future Technologies', 'geospatial', 'GIS &amp; Mapping'], 'articleSection': ['Blogs'], 'inLanguage': 'en-US', 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://www.geospatialworld.net/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/', 'url': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/', 'name': 'Putting traffic signs on the map: How artificial intelligence can help', 'isPartOf': {'@id': 'https://www.geospatialworld.net/#website'}, 'primaryImageOfPage': {'@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/#primaryimage'}, 'image': {'@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/#primaryimage'}, 'thumbnailUrl': 'https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2018/11/4.jpg', 'datePublished': '2018-11-14T12:22:25+00:00', 'dateModified': '2018-11-14T12:26:44+00:00', 'description': 'The GIS market is booming. It’s set to surge from $5.81 billion in 2017 to $10.03 billion by 2023, but in spite of this, many small cities across the US still just have a one-person GIS shop', 'breadcrumb': {'@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/#primaryimage', 'url': 'https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2018/11/4.jpg', 'contentUrl': 'https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2018/11/4.jpg', 'width': 1743, 'height': 1080, 'caption': 'The Mapillary web platform, showing the location of every identified traffic sign.'}, {'@type': 'BreadcrumbList', '@id': 'https://www.geospatialworld.net/blogs/putting-traffic-signs-on-the-map/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.geospatialworld.net/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Putting traffic signs on the map: How artificial intelligence can help'}]}, {'@type': 'WebSite', '@id': 'https://www.geospatialworld.net/#website', 'url': 'https://www.geospatialworld.net/', 'name': 'Geospatial World', 'description': 'Top destination for geospatial industry trends', 'publisher': {'@id': 'https://www.geospatialworld.net/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.geospatialworld.net/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.geospatialworld.net/#organization', 'name': 'Geospatial Media & Communications', 'url': 'https://www.geospatialworld.net/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geospatialworld.net/#/schema/logo/image/', 'url': 'https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2017/10/geospatial-world-logo.png', 'contentUrl': 'https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2017/10/geospatial-world-logo.png', 'width': 378, 'height': 181, 'caption': 'Geospatial Media & Communications'}, 'image': {'@id': 'https://www.geospatialworld.net/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/GeospatialMedia/', 'https://x.com/geoworldmedia', 'https://www.instagram.com/geospatialmedia/', 'https://www.linkedin.com/company/2391107', 'https://www.pinterest.com/geospatialworld/', 'https://www.youtube.com/channel/UC2UaNw8A-fQhIBBnaZPKEmA']}, {'@type': 'Person', '@id': 'https://www.geospatialworld.net/#/schema/person/60f9d8ac2683cfb1a65a7b6258057224', 'name': 'Madelen Arnesdotter', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geospatialworld.net/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/22add6bd6a7db9dd4ea8e588bdfd056c?s=96&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/22add6bd6a7db9dd4ea8e588bdfd056c?s=96&r=g', 'caption': 'Madelen Arnesdotter'}, 'description': 'Customer Success Manager at Mapillary', 'url': 'https://www.geospatialworld.net/author/madelen-arnesdotter/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS8zLWNoYWxsZW5nZXMtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tY29tcHV0ZXItZ3JhcGhpY3MtMjIzZTA2YmQ4NDZi0gEA?oc=5,3 Challenges of Artificial Intelligence in Computer graphics | by Mauro Comi - Towards Data Science,2018-11-15,Towards Data Science,https://towardsdatascience.com,"Computer graphics is not only stunning Visual effects. It gives us the tool to reconstruct the physical world for different kind of purposes, such as industrial or medical applications.
The Graphics…",,Reducing the gap between Virtual and Real world,Reducing the gap between Virtual and Real world,http://schema.org,NewsArticle,https://towardsdatascience.com/3-challenges-of-artificial-intelligence-in-computer-graphics-223e06bd846b,['https://miro.medium.com/v2/resize:fit:1200/1*krDCIwwB_YFiNHIVYEGlkA.jpeg'],"{'@type': 'Person', 'name': 'Mauro Comi', 'url': 'https://towardsdatascience.com/@mauro_ai'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",3 Challenges of Artificial Intelligence in Computer graphics,2018-11-15T20:40:58.674Z,2018-11-15T22:19:17.983Z,,3 Challenges of Artificial Intelligence in Computer graphics,,,,,"3 Challenges of Artificial Intelligence in Computer graphicsReducing the gap between Virtual and Real worldMauro Comi·FollowPublished inTowards Data Science·6 min read·Nov 15, 201872ListenShareComputer graphics is not only stunning Visual effects. It gives us the tool to reconstruct the physical world for different kind of purposes, such as industrial or medical applications.The Graphics Turing Test in this field was passed a long time ago, as the current state of Photography and Cinematography proves. Reality and Fantasy are virtually indistinguishable, and animators can create photorealistic worlds in a matter of days.Graphics Turing Test: The subject views and interacts with a real or computer generated scene. The test is passed if the subject can not determine reality from simulated reality better than a random guess.A considerable help in this topic comes from the very recent advances in AI. Ian Goodfellow introduced a few years ago a new type of Neural Network Architecture called Generative Adversarial Network (GAN), able to push the boundaries of what is possible in Computer graphics. The applications are endless, but as Stan Lee taught us, great powers come with great responsibilities. Indeed generating images and videos indistinguishable from reality might pose a real threat to our Society, if not properly controlled. Watch this video of a Fake Obama generated with AI to understand what I mean.Deep Fake Obama-Generative Adversarial NetworkEmergent field of artificial intelligence for Fluid simulationsSimulating the dynamics of a fluid has always been a huge mathematical challenge. State-of-the-art techniques require massive computing power, even more for real-time simulations. First, it’s important to remind that the term fluid includes liquids, gases and plasmas. Smoke, wind, water, fire are some examples of fluids.If you are familiar with Computational Fluid Dynamics (CFD), you have encountered Navier-Stokes equations multiple times on your path. These partial differential equations relate the velocity, pressure, temperature and density of a moving fluid, extending the previous simpler models introducing the effect of viscosity. We are not going to describe them since they are very complex and not suitable without a proper background in fluid mechanics, but if you’re interested in them you can check the link at the end of the article.Finding the solutions of these equations is not suitable for two reasons: they are data-dependent, so methods are truncated to fit within a computational budget, and might exhibit really slow asymptotic convergence.To solve these issues, machine learning has recentrly introduceda novel way to model fluid dynamics environments as a supervised regression problem. Neural networks and Regression forests gave good results, but they require a dataset of solutions provided by an exact solver. This is not possible during the test on simulations since the initial frames are generated by the model itself (which is not an exact solver). Results are imperfect, and the applications of this model get limited.A new exciting approach to describe the physical world involves the concept of intuitive or naïve physics. This new field of AI concerns the ability to predict outcomes of physical interactions involving macroscopic objects based on experience. Let’s see an example: babies do not know what gravity is, but through experience, they own the concept of it. The idea is to create artificial neural models able to model intuitive physics. Into this camp falls the work of Tompson et al. (link at the end), who developed a novel and tailored ConvNet architecture to replace existing Eulerian-based solvers and introduced a new training-loss which guarantees faster convergence.Nonlinear Soft-tissue dynamics: model the skinObtaining realistic human body modelling is one of the main goals in computer graphics. The surface of the body needs to deform naturally. In real-time applications, the body is controlled by skeletal movements. For this reason, the surface is linked to its skeletal pose and the animation of the skin is a function of it. How is this achieved?The most common algorithm is Linear blend skinning (LBS), used also by Unity and Unreal. It is not computationally intensive and gives good results in the majority of situations. Still, there are some drawbacks. The main issue is the excessive loss of volume for strong bends or unrealistic effects during rotation of joints.A second important strategy is data-driven body models. This model divides the parameters for pose and shape and permits a deeper control of the body. The main problem here is the absence of control for non-linear dynamics. What do I mean with non-linear dynamics? Soft tissues, like the belly of a person, do not react in a linear way to forces. It bounces, rotates, jiggles. These movements cannot be properly described by non-linear models.To solve this problem, data-driven dynamics models were introduced. These algorithms are typically used for facial movements or cloth dynamics. A very interesting application of this last category was applied recently by Casas and Otaduy (link of the paper at the end). They successfully developed a data-driven model to simulate non-linear soft-tissue dynamics trained with publicly available skeletal motion data. As every machine learning model, also this novel methodology cannot properly describe deformations far from the training set. The only way to overcome this limitation, when necessary, is to adopt physics-based body models. These models are extremely precise but significantly more complex.Cloth and Material understanding in Computer GraphicsA third great challenge is the simulation of cloth. Cloth material recovery methods need complex experimental set up to acquire physical properties. Reproducing the correct behaviour of fabric might be extremely complicated, and researchers are applying machine learning methods to recreate the dynamics of it. Understanding properties of cloth do not find its application only in Animations, but also in totally different fields. Let’s consider a virtual try-on system for clothing: capturing the dynamics of this material can open to a new broad range of services offered in e-commerce. This is especially true if we consider the advances in Virtual Reality, which would allow a more realistic virtual shopping giving us the possibility to try clothes virtually.Retrieving physical properties of a dynamical system is achieved in multiple ways at the moment. The most straightforward approach is through measurements, sampling physical quantities and estimating dependent properties. A second important strategy is to simulate, optimize and iterate the dynamical system, extracting features progressively closer to the real value.ConclusionWe have just seen three challenges of AI in Computer Graphics. In the reproduction of the physical world, these three categories are blended: think of a flag moved by the wind. In this case, all three concepts are present in a single event.There is, of course, a whole set of unsolved problems, and I am going to analyse them in a following article. If you enjoyed this article, I’d love it if you hit the clap button 👏 so others might stumble upon it. For any comments or suggestions don’t hesitate to leave a comment!To check more of my Stories:Is Artificial Intelligence Racist? (And Other Concerns)How to teach an AI to play Games: Deep Reinforcement LearningArtificial Intelligence meets Art: Neural Transfer StyleI am a Data Science major in love with Machine learning and its endless applications. You can find more about me and my projects at maurocomi.com. You can also find me on Linkedin, Twitter, or email me directly. I am always up for a chat, or to collaborate on new amazing projects.Referenceshttps://www.grc.nasa.gov/www/k-12/airplane/nseqs.htmlYang, S., Liang, J., & Lin, M. C. (2017, October). Learning-based cloth material recovery from video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 4383–4393).CASAS, D., & OTADUY, M. A. (2018). Learning Nonlinear Soft-Tissue Dynamics for Interactive Avatars.Tompson, J., Schlachter, K., Sprechmann, P., & Perlin, K. (2016). Accelerating eulerian fluid simulation with convolutional networks. arXiv preprint arXiv:1607.03597.",https://towardsdatascience.com/3-challenges-of-artificial-intelligence-in-computer-graphics-223e06bd846b,,,,,,,,,,,,,,,,,,2018-11-15T20:40:58.674Z,,,,,,,,223e06bd846b,['Mauro Comi'],,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LnRlY2hmdW5uZWwuY29tL2hyLXRlY2gvZmFjaWFsLWV4cHJlc3Npb24tZGV0ZWN0aW9uLXVzaW5nLWFpLWhvdy1pdC1jYW4taW1wcm92ZS10aGUtaGlyaW5nLXByb2Nlc3Mv0gEA?oc=5,Facial Expression Detection Using AI: How It Can Improve the Hiring Process - TechFunnel,2018-11-13,TechFunnel,https://www.techfunnel.com,"AI is already replacing parts of the interview process, resume screening but facial expression detection could add a whole new dimension to hiring process.",,"AI is already replacing parts of the interview process, resume screening but facial expression detection could add a whole new dimension to hiring process.",,https://schema.org/,WebSite,https://www.techfunnel.com/,,,,,,,,TechFunnel,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/#article', 'isPartOf': {'@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/'}, 'author': {'name': 'Danni White', '@id': 'https://www.techfunnel.com/#/schema/person/55746dbe674b75c6397c423dcf47539e'}, 'headline': 'Facial Expression Detection Using AI: How It Can Improve the Hiring Process', 'datePublished': '2018-11-13T15:41:44+00:00', 'dateModified': '2018-11-13T15:41:44+00:00', 'mainEntityOfPage': {'@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/'}, 'wordCount': 882, 'publisher': {'@id': 'https://www.techfunnel.com/#organization'}, 'image': {'@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/#primaryimage'}, 'thumbnailUrl': 'https://www.techfunnel.com/wp-content/uploads/2018/11/Facial-Expression-Detection-Using-AI_-How-It-Can-Improve-the-Hiring-Process.jpg', 'keywords': ['Image Recognition'], 'articleSection': ['HR Tech'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/', 'url': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/', 'name': 'Facial Expression Detection Using AI: How It Can Improve the Hiring Process', 'isPartOf': {'@id': 'https://www.techfunnel.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/#primaryimage'}, 'image': {'@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/#primaryimage'}, 'thumbnailUrl': 'https://www.techfunnel.com/wp-content/uploads/2018/11/Facial-Expression-Detection-Using-AI_-How-It-Can-Improve-the-Hiring-Process.jpg', 'datePublished': '2018-11-13T15:41:44+00:00', 'dateModified': '2018-11-13T15:41:44+00:00', 'description': 'AI is already replacing parts of the interview process, resume screening but facial expression detection could add a whole new dimension to hiring process.', 'breadcrumb': {'@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/#primaryimage', 'url': 'https://www.techfunnel.com/wp-content/uploads/2018/11/Facial-Expression-Detection-Using-AI_-How-It-Can-Improve-the-Hiring-Process.jpg', 'contentUrl': 'https://www.techfunnel.com/wp-content/uploads/2018/11/Facial-Expression-Detection-Using-AI_-How-It-Can-Improve-the-Hiring-Process.jpg', 'width': 769, 'height': 445, 'caption': 'Facial Expression Detection Using AI: How It Can Improve the Hiring Process'}, {'@type': 'BreadcrumbList', '@id': 'https://www.techfunnel.com/hr-tech/facial-expression-detection-using-ai-how-it-can-improve-the-hiring-process/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.techfunnel.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Blog', 'item': 'https://www.techfunnel.com/blog/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Facial Expression Detection Using AI: How It Can Improve the Hiring Process'}]}, {'@type': 'WebSite', '@id': 'https://www.techfunnel.com/#website', 'url': 'https://www.techfunnel.com/', 'name': 'Techfunnel', 'description': '', 'publisher': {'@id': 'https://www.techfunnel.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.techfunnel.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.techfunnel.com/#organization', 'name': 'Techfunnel', 'url': 'https://www.techfunnel.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techfunnel.com/#/schema/logo/image/', 'url': 'https://www.techfunnel.com/wp-content/uploads/2023/11/TF_NEWLOGOWHITE_New_logo.png', 'contentUrl': 'https://www.techfunnel.com/wp-content/uploads/2023/11/TF_NEWLOGOWHITE_New_logo.png', 'width': 256, 'height': 91, 'caption': 'Techfunnel'}, 'image': {'@id': 'https://www.techfunnel.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.techfunnel.com/#/schema/person/55746dbe674b75c6397c423dcf47539e', 'name': 'Danni White', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techfunnel.com/#/schema/person/image/', 'url': 'https://www.techfunnel.com/wp-content/uploads/2024/01/Danni_image-150x150.jpg', 'contentUrl': 'https://www.techfunnel.com/wp-content/uploads/2024/01/Danni_image-150x150.jpg', 'caption': 'Danni White'}, 'description': 'Danni White is the CEO of DW Creative Consulting Agency, a digital marketing firm specializing in elevating the visibility of small-to-midsize businesses and nonprofits. She is the author of 17 books and hosts the #Hashtags and Habits Podcast, which merges digital marketing, entrepreneurship, and personal growth.', 'url': 'https://www.techfunnel.com/author/daniella/'}]",,,,,,,,,,,,,,,,,,,,"{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.techfunnel.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9mZWktZmVpLWxpLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWh1bWFuaXR5L9IBAA?oc=5,How Fei-Fei Li Will Make Artificial Intelligence Better for Humanity - WIRED,2018-11-13,WIRED,https://www.wired.com,AI has a problem: The biases of its creators are getting hard-coded into its future. Fei-Fei Li has a plan to fix that—by rebooting the field she helped invent.,"['business', 'the big story', 'ai hub', 'content moderation', 'ethics', 'google', 'alphabet', 'research', 'images', 'machine learning', 'machine vision', 'neural network', 'magazine-26.12', 'longreads', 'artificial intelligence', 'ai', '_no-homepage', '_syndication_noshow', 'magazine']",Artificial intelligence has a problem: The biases of its creators are getting hard-coded into its future. Fei-Fei Li has a plan to fix that—by rebooting the field she helped invent.,Artificial intelligence has a problem: The biases of its creators are getting hard-coded into its future. Fei-Fei Li has a plan to fix that—by rebooting the field she helped invent.,https://schema.org/,BreadcrumbList,https://www.wired.com/story/fei-fei-li-artificial-intelligence-humanity/,"['https://media.wired.com/photos/5bd8ac3e66f3912cf4bdb747/16:9/w_2400,h_1350,c_limit/WI120118_AI_FeiFei_01.jpg', 'https://media.wired.com/photos/5bd8ac3e66f3912cf4bdb747/4:3/w_1944,h_1458,c_limit/WI120118_AI_FeiFei_01.jpg', 'https://media.wired.com/photos/5bd8ac3e66f3912cf4bdb747/1:1/w_730,h_730,c_limit/WI120118_AI_FeiFei_01.jpg']","[{'@type': 'Person', 'name': 'Jessi Hempel', 'sameAs': 'https://www.wired.com/author/jessi-hempel/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",How Fei-Fei Li Will Make Artificial Intelligence Better for Humanity,2018-11-13T06:00:00.000-05:00,2018-11-13T06:00:00.000-05:00,business,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.wired.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'magazine-26.12', 'item': 'https://www.wired.com/tag/magazine-2612/'}, {'@type': 'ListItem', 'position': 3, 'name': ""Fei-Fei Li's Quest to Make AI Better for Humanity""}]",tags,,"Jessi HempelBusinessNov 13, 2018 6:00 AMFei-Fei Li's Quest to Make AI Better for HumanityArtificial intelligence has a problem: The biases of its creators are getting hard-coded into its future. Fei-Fei Li has a plan to fix that—by rebooting the field she helped invent.Artificial intelligence has a problem: The biases of its creators are getting hard-coded into its future. Fei-Fei Li has a plan to fix that—by rebooting the field she helped invent.Christie Hemm KlokSave this storySaveSave this storySaveThe AI Database →ApplicationContent moderationEthicsCompanyGoogleAlphabetSectorResearchSource DataImagesTechnologyMachine learningMachine visionNeural NetworkSometime around 1 am on a warm night last June, Fei-Fei Li was sitting in her pajamas in a Washington, DC, hotel room, practicing a speech she would give in a few hours. Before going to bed, Li cut a full paragraph from her notes to be sure she could reach her most important points in the short time allotted. When she woke up, the 5'3"" expert in artificial intelligence put on boots and a black and navy knit dress, a departure from her frequent uniform of a T-shirt and jeans. Then she took an Uber to the Rayburn House Office Building, just south of the US Capitol.Before entering the chambers of the US House Committee on Science, Space, and Technology, she lifted her phone to snap a photo of the oversize wooden doors. (“As a scientist, I feel special about the committee,” she said.) Then she stepped inside the cavernous room and walked to the witness table.AdChoicesADVERTISEMENTThe hearing that morning, titled “Artificial Intelligence—With Great Power Comes Great Responsibility,” included Timothy Persons, chief scientist of the Government Accountability Office, and Greg Brockman, cofounder and chief technology officer of the nonprofit ­OpenAI. But only Li, the sole woman at the table, could lay claim to a groundbreaking accomplishment in the field of AI. As the researcher who built ImageNet, a database that helps computers recognize images, she’s one of a tiny group of scientists—a group perhaps small enough to fit around a kitchen table—who are responsible for AI’s recent remarkable advances.Trending NowWIRED25: Kai-Fu Lee and Fei Fei Li On What's Next for Artificial IntelligenceThat June, Li was serving as the chief AI scientist at Google Cloud and was on leave from her position as director of the Stanford Artificial Intelligence Lab. But she was appearing in front of the committee because she was also the cofounder of a nonprofit focused on recruiting women and people of color to become builders of artificial intelligence.It was no surprise that the legislators sought her expertise that day. What was surprising was the content of her talk: the grave dangers brought on by the field she so loved.December 2018. Subscribe to WIRED.
Illustration: Axis of StrengthThe time between an invention and its impact can be short. With the help of artificial intelligence tools like ImageNet, a computer can be taught to learn a specific task and then act far faster than a person ever could. As this technology becomes more sophisticated, it’s being deputized to filter, sort, and analyze data and make decisions of global and social consequence. Though these tools have been around, in some way or another, for more than 60 years, in the past decade we’ve started using them for tasks that change the trajectory of human lives: Today artificial intelligence helps determine which treatments get used on people with illnesses, who qualifies for life insurance, how much prison time a person serves, which job applicants get interviews.Those powers, of course, can be dangerous. Amazon had to ditch AI recruiting software that learned to penalize résumés that included the word “women.” And who can forget Google’s 2015 fiasco, when its photo identification software mislabeled black people as gorillas, or Microsoft’s AI-powered social chatbot that started tweeting racial slurs. But those are problems that can be explained and therefore reversed. In the pretty near future, Li believes, we will hit a moment when it will be impossible to course-correct. That’s because the technology is being adopted so fast, and far and wide.SIGN UP TODAYGet the Backchannel newsletter for the best features and investigations on WIRED.Li was testifying in the Rayburn building that morning because she is adamant her field needs a recalibration. Prominent, powerful, and mostly male tech leaders have been warning about a future in which artificial-intelligence-driven technology becomes an existential threat to humans. But Li thinks those fears are given too much weight and attention. She is focused on a less melodramatic but more consequential question: how AI will affect the way people work and live. It’s bound to alter the human experience—and not necessarily for the better. “We have time,” Li says, “but we have to act now.” If we make fundamental changes to how AI is engineered—and who engineers it—the technology, Li argues, will be a transformative force for good. If not, we are leaving a lot of humanity out of the equation.At the hearing, Li was the last to speak. With no evidence of the nerves that drove her late-night practice, she began. “There’s nothing artificial about AI.” Her voice picked up momentum. “It’s inspired by people, it’s created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.” Around her, faces brightened. The woman who kept attendance agreed audibly, with an “mm-hmm.”JackRabbot 1, a Segway platform mobile robot, at Stanford University's AI Lab.Christie Hemm KlokFei-Fei Li grew up in Chengdu, an industrial city in southern China. She was a lonely, brainy kid, as well as an avid reader. Her family was always a bit unusual: In a culture that didn’t prize pets, her father brought her a puppy. Her mother, who had come from an intellectual family, encouraged her to read Jane Eyre. (“Emily is my favorite Brontë,” Li says. “Wuthering Heights.”) When Li was 12, her father emigrated to Parsippany, New Jersey, and she and her mother didn’t see him for several years. They joined him when she was 16. On her second day in America, Li’s father took her to a gas station and asked her to tell the mechanic to fix his car. She spoke little English, but through gestures Li figured out how to explain the problem. Within two years, Li had learned enough of the language to serve as a translator, interpreter, and advocate for her mother and father, who had learned only the most basic English. “I had to become the mouth and ears of my parents,” she says.She was also doing very well in school. Her father, who loved to scour garage sales, found her a scientific calculator, which she used in math class until a teacher, sizing up her mistaken calculations, figured out that it had a broken function key. Li credits another high school math instructor, Bob Sabella, for helping her navigate her academic life and her new American identity. Parsippany High School didn’t have an advanced calculus class, so he concocted an ad hoc version and taught Li during lunch breaks. Sabella and his wife also included her in their family, bringing her on a Disney vacation and lending her $20,000 to open a dry-cleaning business for her parents to run. In 1995, she earned a scholarship to study at Prince­ton. While there, she traveled home nearly every weekend to help run the family business.At college, Li’s interests were expansive. She majored in physics and studied computer science and engineering. In 2000, she began her doctorate at Caltech in Pasadena, working at the intersection of neuroscience and computer science.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDHer ability to see and foster connections between seemingly dissimilar fields is what led Li to think up ImageNet. Her computer-vision peers were working on models to help computers perceive and decode images, but those models were limited in scope: A researcher might write one algorithm to identify dogs and another to identify cats. Li began to wonder if the problem wasn’t the model but the data. She thought that, if a child learns to see by experiencing the visual world­—by observing countless objects and scenes in her early years—maybe a computer can learn in a similar way, by analyzing a wide variety of images and the relationships between them. The realization was a big one for Li. “It was a way to organize the whole visual concept of the world,” she says.AdvertisementBut she had trouble convincing her colleagues that it was rational to undertake the gargantuan task of tagging every possible picture of every object in one gigantic database. What’s more, Li had decided that for the idea to work, the labels would need to range from the general (“mammal”) to the highly specific (“star-nosed mole”). When Li, who had moved back to Princeton to take a job as an assistant professor in 2007, talked up her idea for ImageNet, she had a hard time getting faculty members to help out. Finally, a professor who specialized in computer architecture agreed to join her as a collaborator.Her next challenge was to get the giant thing built. That meant a lot of people would have to spend a lot of hours doing the tedious work of tagging photos. Li tried paying Princeton students $10 an hour, but progress was slow going. Then a student asked her if she’d heard of Amazon Mechanical Turk. Suddenly she could corral many workers, at a fraction of the cost. But expanding a workforce from a handful of Princeton students to tens of thousands of invisible Turkers had its own challenges. Li had to factor in the workers’ likely biases. “Online workers, their goal is to make money the easiest way, right?” she says. “If you ask them to select panda bears from 100 images, what stops them from just clicking everything?” So she embedded and tracked certain images—such as pictures of golden retrievers that had already been correctly identified as dogs—to serve as a control group. If the Turks labeled these images properly, they were working honestly.In 2009, Li’s team felt that the massive set—3.2 million images—was comprehensive enough to use, and they published a paper on it, along with the database. (It later grew to 15 million.) At first the project got little attention. But then the team had an idea: They reached out to the organizers of a computer-vision competition taking place the following year in Europe and asked them to allow competitors to use the Image­Net database to train their algorithms. This became the ImageNet Large Scale Visual Recognition Challenge.Around the same time, Li joined Stanford as an assistant professor. She was, by then, married to Silvio Savarese, a roboticist. But he had a job at the University of Michigan, and the distance was tough. “We knew Silicon Valley would be easier for us to solve our two-body problem,” Li says. (Savarese joined Stanford’s faculty in 2013.) “Also, Stanford is special because it’s one of the birthplaces of AI.”The A.I. IssueThe A.I. IssueHow to Teach Artificial Intelligence Some Common SenseClive ThompsonThe A.I. IssueThe DIY Tinkerers Harnessing the Power of AITom SimoniteThe A.I. IssueThe Genius Neuroscientist Who Might Hold the Key to True AIShaun RavivIn 2012, University of Toronto researcher Geoffrey Hinton entered the ImageNet competition, using the database to train a type of AI known as a deep neural network. It turned out to be far more accurate than anything that had come before—and he won. Li hadn’t planned to go see Hinton get his award; she was on maternity leave, and the ceremony was happening in Florence, Italy. But she recognized that history was being made. So she bought a last-minute ticket and crammed herself into a middle seat for an overnight flight. Hinton’s ImageNet-­powered neural network changed everything. By 2017, the final year of the competition, the error rate for computers identifying objects in images had been reduced to less than 3 percent, from 15 percent in 2012. Computers, at least by one measure, had become better at seeing than humans.ImageNet enabled deep learning to go big—it’s at the root of recent advances in self-driving cars, facial recognition, phone cameras that can identify objects (and tell you if they’re for sale).Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDNot long after Hinton accepted his prize, while Li was still on maternity leave, she started to think a lot about how few of her peers were women. At that moment she felt this acutely; she saw how the disparity was increasingly going to be a problem. Most scientists building AI algorithms were men, and often men of a similar background. They had a particular worldview that bled into the projects they pursued and even the dangers they envisioned. Many of AI’s creators had been boys with sci-fi dreams, thinking up scenarios from The Terminator and Blade Runner. There’s nothing wrong with worrying about such things, Li thought. But those ideas betrayed a narrow view of the possible dangers of AI.Deep learning systems are, as Li says, “bias in, bias out.” Li recognized that while the algorithms that drive artificial intelligence may appear to be neutral, the data and applications that shape the outcomes of those algorithms are not. What mattered were the people building it and why they were building it. Without a diverse group of engineers, Li pointed out that day on Capitol Hill, we could have biased algorithms making unfair loan application decisions, or training a neural network only on white faces—creating a model that would perform poorly on black ones. “I think if we wake up 20 years from now and we see the lack of diversity in our tech and leaders and practitioners, that would be my doomsday scenario,” she said.It was critical, Li came to believe, to focus the development of AI on helping the human experience. One of her projects at Stanford was a partnership with the medical school to bring AI to the ICU in an effort to cut down on problems like hospital-­acquired infections. It involved developing a camera system that could monitor a hand-washing station and alert hospital workers if they forgot to scrub properly. This type of interdisciplinary collaboration was unusual. “No one else from computer science reached out to me,” says Arnold Milstein, a professor of medicine who directs Stanford’s Clinical Excellence Research Center.That work gave Li hope for how AI could evolve. It could be built to complement people’s skills rather than simply replace them. If engineers would engage with people in other disciplines (even people in the real world!), they could make tools that expand human capacity, like automating time-­consuming tasks to allow ICU nurses to spend more time with patients, rather than building AI, say, to automate someone’s shopping experience and eliminate a cashier’s job.Considering that AI was developing at warp speed, Li figured her team needed to change the roster—as fast as possible.Fei-Fei Li in the Artificial Intelligence Lab at Stanford University.Christie Hemm KlokLi has always been drawn to math, so she recognizes that getting women and people of color into computer science requires a colossal effort. According to the National Science Foundation, in 2000, women earned 28 percent of bachelor’s degrees in computer science. In 2015 that figure was 18 percent. Even in her own lab, Li struggles to recruit underrepresented people of color and women. Though historically more diverse than your typical AI lab, it remains predominantly male, she says. “We still do not have enough women, and especially underrepresented minorities, even in the pipeline coming into the lab,” she says. “Students go to an AI conference and they see 90 percent people of the same gender. And they don’t see African Americans nearly as much as white boys.”Olga Russakovsky had almost written off the field when Li became her adviser. Russakovsky was already an accomplished computer scientist—with an undergraduate degree in math and a master’s in computer science, both from Stanford—but her dissertation work was dragging. She felt disconnected from her peers as the only woman in her lab. Things changed when Li arrived at Stanford. Li helped Russakovsky learn some skills required for successful research, “but also she helped build up my self-confidence,” says Russakovsky, who is now an assistant professor in computer science at Princeton.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDFour years ago, as Russakovsky was finishing up her PhD, she asked Li to help her create a summer camp to get girls interested in AI. Li agreed at once, and they pulled volunteers together and posted a call for high school sophomores. Within a month, they had 200 applications for 24 spots. Two years later they expanded the program, launching the nonprofit AI4All to bring underrepresented youth—including girls, people of color, and people from economically disadvantaged backgrounds—to the campuses of Stanford and UC Berkeley.AI4All is on the verge of growing out of its tiny shared office at the Kapor Center in downtown Oakland, California. It now has camps at six college campuses. (Last year there were 900 applications for 20 spots at the newly launched Carnegie Mellon camp.) One AI4All student worked on detecting eye diseases using computer vision. Another used AI to write a program ranking the urgency of 911 calls; her grandmother had died because an ambulance didn’t reach her in time. Confirmation, it would seem, that personal perspective makes a difference for the future of AI tools.The case for Toyota’s Human Support Robot at Stanford University's AI Lab.Christie Hemm KlokAfter three years running the AI Lab at Stanford, Li took a leave in 2016 to join Google as chief scientist for AI of Google Cloud, the company’s enterprise computing business. Li wanted to understand how industry worked and to see if access to customers anxious to deploy new tools would shift the scope of her own cross-­disciplinary research. Companies like Facebook, Google, and Microsoft were throwing money into AI in search of ways to harness the technology for their businesses. And companies often have more and better data than universities. For an AI researcher, data is fuel.Initially the experience was enlivening. She met with companies that had real-world uses for her science. She led the rollout of public-facing AI tools that let anyone create machine learning algorithms without writing a single line of code. She opened a new lab in China and helped to shape AI tools to improve health care. She spoke at the World Economic Forum in Davos, rubbing elbows with heads of state and pop stars.But working in a private company came with new and uncomfortable pressures. Last spring, Li was caught up in Google’s very public drubbing over its Project Maven contract with the Defense Department. The program uses AI to interpret video images that could be used to target drone strikes; according to Google, it was “low-res object identification using AI” and “saving lives was the overarching intent.” Many employees, however, objected to the use of their work in military drones. About 4,000 of them signed a petition demanding “a clear policy stating that neither Google nor its contractors will ever build warfare technology.” Several workers resigned in protest.LEARN MOREThe WIRED Guide to Artificial IntelligenceThough Li hadn’t been involved directly with the deal, the division that she worked for was charged with administering Maven. And she became a public face of the controversy when emails she wrote that looked as if they were trying to help the company avoid embarrassment were leaked to The New York Times. Publicly this seemed confusing, as she was well known in the field as someone who embodied ethics. In truth, before the public outcry she had considered the technology to be “fairly innocuous”; she hadn’t considered that it could cause an employee revolt.But Li does recognize why the issue blew up: “It wasn’t exactly what the thing is. It’s about the moment—the collective sense of urgency for our responsibility, the emerging power of AI, the dialog that Silicon Valley needs to be in. Maven just became kind of a convergence point,” she says. “Don’t be evil” was no longer a strong enough stance.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDThe controversy subsided when Google announced it wouldn’t renew the Maven contract. A group of Google scientists and executives—including Li—also wrote (public) guidelines pledging that Google would focus its AI research on technology designed for social good, would avoid implementing bias into its tools, and would avoid technology that could end up facilitating harm to people. Li had been preparing to head back to Stanford, but she felt it was critical to see the guidelines through. “I think it’s important to recognize that every organization has to have a set of principles and responsible review processes. You know how Benjamin Franklin said, when the Constitution was rolled out, it might not be perfect but it’s the best we’ve got for now,” she says. “People will still have opinions, and different sides can continue the dialog.” But when the guidelines were published, she says, it was one of her happiest days of the year: “It was so important for me personally to be involved, to contribute.”In June, I visited Li at her home, a modest split-level in a cul-de-sac on the Stanford campus. It was just after 8 in the evening, and while we talked her husband put their young son and daughter through their bedtime routines upstairs. Her parents were home for the night in the in-law unit downstairs. The dining room had been turned into a playroom, so we sat in her living room. Family photos rested on every surface, including a broken 1930s-era telephone sitting on a shelf. “Immigrant parents!” she said when I ask her about it. Her father still likes to go to yard sales.As we talked, text messages started pinging on Li’s phone. Her parents were asking her to translate a doctor’s instructions for her mother’s medication. Li can be in a meeting at the Googleplex or speaking at the World Economic Forum or sitting in the green room before a congressional hearing and her parents will text her for a quick assist. She responds without breaking her train of thought.For much of Li’s life, she has been focused on two seemingly different things at the same time. She is a scientist who has thought deeply about art. She is an American who is Chinese. She is as obsessed with robots as she is with humans.Late in July, Li called me while she was packing for a family trip and helping her daughter wash her hands. “Did you see the announcement of Shannon Vallor?” she asks. Vallor is a philosopher at Santa Clara University whose research focuses on the philosophy and ethics of emerging science and technologies, and she had just signed on to work for Google Cloud as a consulting ethicist. Li had campaigned hard for this; she’d even quoted Vallor in her testimony in Washington, saying: “There are no independent machine values. Machine values are human values.” The appointment wasn’t without precedent. Other companies have also started to put guardrails on how their AI software can be used, and who can use it. Microsoft established an internal ethics board in 2016. The company says it has turned down business with potential customers owing to ethical concerns brought forward by the board. It’s also begun placing limits on how its AI tech can be used, such as forbidding some applications in facial recognition.Related StoriesWIRED@25An AI Pioneer, and the Researcher Bringing Humanity to AIMaria Streshinsky and Jessi HempelWired25Microsoft's Nadella Says AI Can Make the World More InclusiveTom SimoniteSocial SmartsHow Artificial Intelligence Can—and Can't—Fix FacebookTom SimoniteBut to speak on behalf of ethics from inside a corporation is, to some extent, to acknowledge that, while you can guard the henhouse, you are indeed a fox. When we talked in July, Li already knew she was leaving Google. Her two-year sabbatical was coming to an end. There was plenty of speculation about her stepping down after the Project Maven debacle. But she said the reason for her return to Stanford was that she didn’t want to forfeit her academic position. She also sounded tired. After a tumultuous summer at Google, the ethics guidelines she helped write were “the light at the end of the tunnel,” she says.And she was eager to start a new project at Stanford. This fall, she and John Etchemendy, the former Stanford provost, announced the creation of an academic center that will fuse the study of AI and humanity, blending hard science, design research, and interdisciplinary studies. “As a new science, AI never had a field-wide effort to engage humanists and social scientists,” she says. Those skill sets have long been viewed as inconsequential to the field of AI, but Li is adamant that they are key to its future.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David GilbertPoliticsElon Musk ‘Fully Endorses’ Donald Trump After Deadly Rally ShootingBy Makena Kelly, WIREDLi is fundamentally optimistic. At the hearing in June, she told the legislators, “I think deeply about the jobs that are currently dangerous and harmful for humans, from fighting fires to search and rescue to natural disaster recovery.” She believes that we should not only avoid putting people in harm’s way when possible, but that these are often the very kind of jobs where technology can be a great help.There are limits, of course, to how much a single program at a single institution—even a prominent one—can shift an entire field. But Li is adamant she has to do what she can to train researchers to think like ethicists, who are guided by principle over profit, informed by a varied array of backgrounds.On the phone, I ask Li if she imagines there could have been a way to develop AI differently, without, perhaps, the problems we’ve seen so far. “I think it’s hard to imagine,” she says. “Scientific advances and innovation come really through generations of tedious work, trial and error. It took a while for us to recognize such bias. I only woke up six years ago and realized ‘Oh my God, we’re entering a crisis.’ ”On Capitol Hill, Li said, “As a scientist, I’m humbled by how nascent the science of AI is. It is the science of only 60 years. Compared to classic sciences that are making human life better every day—physics, chemistry, biology—there’s a long, long way to go for AI to realize its potential to help people.” She added, “With proper guidance AI will make life better. But without it, the technology stands to widen the wealth divide even further, make tech even more exclusive, and reinforce biases we’ve spent generations trying to overcome.” This is the time, Li would have us believe, between an invention and its impact.Hair and Makeup by Amy Lawson for Makeup ForeverJessi Hempel wrote about Uber CEO Dara Khosrowshahi in issue 26.05. Additional reporting by Gregory Barber.This article appears in the December issue. Subscribe now.Listen to this story, and other WIRED features, on the Audm app.Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.Enter your email to get the Wired newsletterclose dialogRecommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialogMore Great WIRED StoriesThe DIY tinkerers harnessing the power of AIThe ‘pink tax’ and how women spend more on NYC transitPHOTOS: The secret tools magicians use to fool youThe Butterball Turkey Talk-Line gets new trimmingsAn aging marathoner tries to run fast after 40Hungry for even more deep dives on your next favorite topic? Sign up for the Backchannel newsletter","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/fei-fei-li-artificial-intelligence-humanity/'}",AI has a problem: The biases of its creators are getting hard-coded into its future. Fei-Fei Li has a plan to fix that—by rebooting the field she helped invent.,,,,,"{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,,,,,,,"Before entering the chambers of the US House Committee on Science, Space, and Technology, she lifted her phone to snap a photo of the oversize wooden doors. (“As a scientist, I feel special about the committee,” she said.) Then she stepped inside the cavernous room and walked to the witness table.
The hearing that morning, titled “Artificial Intelligence—With Great Power Comes Great Responsibility,” included Timothy Persons, chief scientist of the Government Accountability Office, and Greg Brockman, cofounder and chief technology officer of the nonprofit ­OpenAI. But only Li, the sole woman at the table, could lay claim to a groundbreaking accomplishment in the field of AI. As the researcher who built ImageNet, a database that helps computers recognize images, she’s one of a tiny group of scientists—a group perhaps small enough to fit around a kitchen table—who are responsible for AI’s recent remarkable advances.
That June, Li was serving as the chief AI scientist at Google Cloud and was on leave from her position as director of the Stanford Artificial Intelligence Lab. But she was appearing in front of the committee because she was also the cofounder of a nonprofit focused on recruiting women and people of color to become builders of artificial intelligence.
It was no surprise that the legislators sought her expertise that day. What was surprising was the content of her talk: the grave dangers brought on by the field she so loved.
The time between an invention and its impact can be short. With the help of artificial intelligence tools like ImageNet, a computer can be taught to learn a specific task and then act far faster than a person ever could. As this technology becomes more sophisticated, it’s being deputized to filter, sort, and analyze data and make decisions of global and social consequence. Though these tools have been around, in some way or another, for more than 60 years, in the past decade we’ve started using them for tasks that change the trajectory of human lives: Today artificial intelligence helps determine which treatments get used on people with illnesses, who qualifies for life insurance, how much prison time a person serves, which job applicants get interviews.
Those powers, of course, can be dangerous. Amazon had to ditch AI recruiting software that learned to penalize résumés that included the word “women.” And who can forget Google’s 2015 fiasco, when its photo identification software mislabeled black people as gorillas, or Microsoft’s AI-powered social chatbot that started tweeting racial slurs. But those are problems that can be explained and therefore reversed. In the pretty near future, Li believes, we will hit a moment when it will be impossible to course-correct. That’s because the technology is being adopted so fast, and far and wide.
Li was testifying in the Rayburn building that morning because she is adamant her field needs a recalibration. Prominent, powerful, and mostly male tech leaders have been warning about a future in which artificial-intelligence-driven technology becomes an existential threat to humans. But Li thinks those fears are given too much weight and attention. She is focused on a less melodramatic but more consequential question: how AI will affect the way people work and live. It’s bound to alter the human experience—and not necessarily for the better. “We have time,” Li says, “but we have to act now.” If we make fundamental changes to how AI is engineered—and who engineers it—the technology, Li argues, will be a transformative force for good. If not, we are leaving a lot of humanity out of the equation.
At the hearing, Li was the last to speak. With no evidence of the nerves that drove her late-night practice, she began. “There’s nothing artificial about AI.” Her voice picked up momentum. “It’s inspired by people, it’s created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.” Around her, faces brightened. The woman who kept attendance agreed audibly, with an “mm-hmm.”
She was also doing very well in school. Her father, who loved to scour garage sales, found her a scientific calculator, which she used in math class until a teacher, sizing up her mistaken calculations, figured out that it had a broken function key. Li credits another high school math instructor, Bob Sabella, for helping her navigate her academic life and her new American identity. Parsippany High School didn’t have an advanced calculus class, so he concocted an ad hoc version and taught Li during lunch breaks. Sabella and his wife also included her in their family, bringing her on a Disney vacation and lending her $20,000 to open a dry-cleaning business for her parents to run. In 1995, she earned a scholarship to study at Prince­ton. While there, she traveled home nearly every weekend to help run the family business.
At college, Li’s interests were expansive. She majored in physics and studied computer science and engineering. In 2000, she began her doctorate at Caltech in Pasadena, working at the intersection of neuroscience and computer science.
Her ability to see and foster connections between seemingly dissimilar fields is what led Li to think up ImageNet. Her computer-vision peers were working on models to help computers perceive and decode images, but those models were limited in scope: A researcher might write one algorithm to identify dogs and another to identify cats. Li began to wonder if the problem wasn’t the model but the data. She thought that, if a child learns to see by experiencing the visual world­—by observing countless objects and scenes in her early years—maybe a computer can learn in a similar way, by analyzing a wide variety of images and the relationships between them. The realization was a big one for Li. “It was a way to organize the whole visual concept of the world,” she says.
But she had trouble convincing her colleagues that it was rational to undertake the gargantuan task of tagging every possible picture of every object in one gigantic database. What’s more, Li had decided that for the idea to work, the labels would need to range from the general (“mammal”) to the highly specific (“star-nosed mole”). When Li, who had moved back to Princeton to take a job as an assistant professor in 2007, talked up her idea for ImageNet, she had a hard time getting faculty members to help out. Finally, a professor who specialized in computer architecture agreed to join her as a collaborator.
Her next challenge was to get the giant thing built. That meant a lot of people would have to spend a lot of hours doing the tedious work of tagging photos. Li tried paying Princeton students $10 an hour, but progress was slow going. Then a student asked her if she’d heard of Amazon Mechanical Turk. Suddenly she could corral many workers, at a fraction of the cost. But expanding a workforce from a handful of Princeton students to tens of thousands of invisible Turkers had its own challenges. Li had to factor in the workers’ likely biases. “Online workers, their goal is to make money the easiest way, right?” she says. “If you ask them to select panda bears from 100 images, what stops them from just clicking everything?” So she embedded and tracked certain images—such as pictures of golden retrievers that had already been correctly identified as dogs—to serve as a control group. If the Turks labeled these images properly, they were working honestly.
In 2009, Li’s team felt that the massive set—3.2 million images—was comprehensive enough to use, and they published a paper on it, along with the database. (It later grew to 15 million.) At first the project got little attention. But then the team had an idea: They reached out to the organizers of a computer-vision competition taking place the following year in Europe and asked them to allow competitors to use the Image­Net database to train their algorithms. This became the ImageNet Large Scale Visual Recognition Challenge.
Around the same time, Li joined Stanford as an assistant professor. She was, by then, married to Silvio Savarese, a roboticist. But he had a job at the University of Michigan, and the distance was tough. “We knew Silicon Valley would be easier for us to solve our two-body problem,” Li says. (Savarese joined Stanford’s faculty in 2013.) “Also, Stanford is special because it’s one of the birthplaces of AI.”
In 2012, University of Toronto researcher Geoffrey Hinton entered the ImageNet competition, using the database to train a type of AI known as a deep neural network. It turned out to be far more accurate than anything that had come before—and he won. Li hadn’t planned to go see Hinton get his award; she was on maternity leave, and the ceremony was happening in Florence, Italy. But she recognized that history was being made. So she bought a last-minute ticket and crammed herself into a middle seat for an overnight flight. Hinton’s ImageNet-­powered neural network changed everything. By 2017, the final year of the competition, the error rate for computers identifying objects in images had been reduced to less than 3 percent, from 15 percent in 2012. Computers, at least by one measure, had become better at seeing than humans.
ImageNet enabled deep learning to go big—it’s at the root of recent advances in self-driving cars, facial recognition, phone cameras that can identify objects (and tell you if they’re for sale).
Not long after Hinton accepted his prize, while Li was still on maternity leave, she started to think a lot about how few of her peers were women. At that moment she felt this acutely; she saw how the disparity was increasingly going to be a problem. Most scientists building AI algorithms were men, and often men of a similar background. They had a particular worldview that bled into the projects they pursued and even the dangers they envisioned. Many of AI’s creators had been boys with sci-fi dreams, thinking up scenarios from The Terminator and Blade Runner. There’s nothing wrong with worrying about such things, Li thought. But those ideas betrayed a narrow view of the possible dangers of AI.
Deep learning systems are, as Li says, “bias in, bias out.” Li recognized that while the algorithms that drive artificial intelligence may appear to be neutral, the data and applications that shape the outcomes of those algorithms are not. What mattered were the people building it and why they were building it. Without a diverse group of engineers, Li pointed out that day on Capitol Hill, we could have biased algorithms making unfair loan application decisions, or training a neural network only on white faces—creating a model that would perform poorly on black ones. “I think if we wake up 20 years from now and we see the lack of diversity in our tech and leaders and practitioners, that would be my doomsday scenario,” she said.
It was critical, Li came to believe, to focus the development of AI on helping the human experience. One of her projects at Stanford was a partnership with the medical school to bring AI to the ICU in an effort to cut down on problems like hospital-­acquired infections. It involved developing a camera system that could monitor a hand-washing station and alert hospital workers if they forgot to scrub properly. This type of interdisciplinary collaboration was unusual. “No one else from computer science reached out to me,” says Arnold Milstein, a professor of medicine who directs Stanford’s Clinical Excellence Research Center.
That work gave Li hope for how AI could evolve. It could be built to complement people’s skills rather than simply replace them. If engineers would engage with people in other disciplines (even people in the real world!), they could make tools that expand human capacity, like automating time-­consuming tasks to allow ICU nurses to spend more time with patients, rather than building AI, say, to automate someone’s shopping experience and eliminate a cashier’s job.
Considering that AI was developing at warp speed, Li figured her team needed to change the roster—as fast as possible.
Olga Russakovsky had almost written off the field when Li became her adviser. Russakovsky was already an accomplished computer scientist—with an undergraduate degree in math and a master’s in computer science, both from Stanford—but her dissertation work was dragging. She felt disconnected from her peers as the only woman in her lab. Things changed when Li arrived at Stanford. Li helped Russakovsky learn some skills required for successful research, “but also she helped build up my self-confidence,” says Russakovsky, who is now an assistant professor in computer science at Princeton.
Four years ago, as Russakovsky was finishing up her PhD, she asked Li to help her create a summer camp to get girls interested in AI. Li agreed at once, and they pulled volunteers together and posted a call for high school sophomores. Within a month, they had 200 applications for 24 spots. Two years later they expanded the program, launching the nonprofit AI4All to bring underrepresented youth—including girls, people of color, and people from economically disadvantaged backgrounds—to the campuses of Stanford and UC Berkeley.
AI4All is on the verge of growing out of its tiny shared office at the Kapor Center in downtown Oakland, California. It now has camps at six college campuses. (Last year there were 900 applications for 20 spots at the newly launched Carnegie Mellon camp.) One AI4All student worked on detecting eye diseases using computer vision. Another used AI to write a program ranking the urgency of 911 calls; her grandmother had died because an ambulance didn’t reach her in time. Confirmation, it would seem, that personal perspective makes a difference for the future of AI tools.
Initially the experience was enlivening. She met with companies that had real-world uses for her science. She led the rollout of public-facing AI tools that let anyone create machine learning algorithms without writing a single line of code. She opened a new lab in China and helped to shape AI tools to improve health care. She spoke at the World Economic Forum in Davos, rubbing elbows with heads of state and pop stars.
But working in a private company came with new and uncomfortable pressures. Last spring, Li was caught up in Google’s very public drubbing over its Project Maven contract with the Defense Department. The program uses AI to interpret video images that could be used to target drone strikes; according to Google, it was “low-res object identification using AI” and “saving lives was the overarching intent.” Many employees, however, objected to the use of their work in military drones. About 4,000 of them signed a petition demanding “a clear policy stating that neither Google nor its contractors will ever build warfare technology.” Several workers resigned in protest.
Though Li hadn’t been involved directly with the deal, the division that she worked for was charged with administering Maven. And she became a public face of the controversy when emails she wrote that looked as if they were trying to help the company avoid embarrassment were leaked to The New York Times. Publicly this seemed confusing, as she was well known in the field as someone who embodied ethics. In truth, before the public outcry she had considered the technology to be “fairly innocuous”; she hadn’t considered that it could cause an employee revolt.
But Li does recognize why the issue blew up: “It wasn’t exactly what the thing is. It’s about the moment—the collective sense of urgency for our responsibility, the emerging power of AI, the dialog that Silicon Valley needs to be in. Maven just became kind of a convergence point,” she says. “Don’t be evil” was no longer a strong enough stance.
The controversy subsided when Google announced it wouldn’t renew the Maven contract. A group of Google scientists and executives—including Li—also wrote (public) guidelines pledging that Google would focus its AI research on technology designed for social good, would avoid implementing bias into its tools, and would avoid technology that could end up facilitating harm to people. Li had been preparing to head back to Stanford, but she felt it was critical to see the guidelines through. “I think it’s important to recognize that every organization has to have a set of principles and responsible review processes. You know how Benjamin Franklin said, when the Constitution was rolled out, it might not be perfect but it’s the best we’ve got for now,” she says. “People will still have opinions, and different sides can continue the dialog.” But when the guidelines were published, she says, it was one of her happiest days of the year: “It was so important for me personally to be involved, to contribute.”
As we talked, text messages started pinging on Li’s phone. Her parents were asking her to translate a doctor’s instructions for her mother’s medication. Li can be in a meeting at the Googleplex or speaking at the World Economic Forum or sitting in the green room before a congressional hearing and her parents will text her for a quick assist. She responds without breaking her train of thought.
For much of Li’s life, she has been focused on two seemingly different things at the same time. She is a scientist who has thought deeply about art. She is an American who is Chinese. She is as obsessed with robots as she is with humans.
Late in July, Li called me while she was packing for a family trip and helping her daughter wash her hands. “Did you see the announcement of Shannon Vallor?” she asks. Vallor is a philosopher at Santa Clara University whose research focuses on the philosophy and ethics of emerging science and technologies, and she had just signed on to work for Google Cloud as a consulting ethicist. Li had campaigned hard for this; she’d even quoted Vallor in her testimony in Washington, saying: “There are no independent machine values. Machine values are human values.” The appointment wasn’t without precedent. Other companies have also started to put guardrails on how their AI software can be used, and who can use it. Microsoft established an internal ethics board in 2016. The company says it has turned down business with potential customers owing to ethical concerns brought forward by the board. It’s also begun placing limits on how its AI tech can be used, such as forbidding some applications in facial recognition.
But to speak on behalf of ethics from inside a corporation is, to some extent, to acknowledge that, while you can guard the henhouse, you are indeed a fox. When we talked in July, Li already knew she was leaving Google. Her two-year sabbatical was coming to an end. There was plenty of speculation about her stepping down after the Project Maven debacle. But she said the reason for her return to Stanford was that she didn’t want to forfeit her academic position. She also sounded tired. After a tumultuous summer at Google, the ethics guidelines she helped write were “the light at the end of the tunnel,” she says.
And she was eager to start a new project at Stanford. This fall, she and John Etchemendy, the former Stanford provost, announced the creation of an academic center that will fuse the study of AI and humanity, blending hard science, design research, and interdisciplinary studies. “As a new science, AI never had a field-wide effort to engage humanists and social scientists,” she says. Those skill sets have long been viewed as inconsequential to the field of AI, but Li is adamant that they are key to its future.
Li is fundamentally optimistic. At the hearing in June, she told the legislators, “I think deeply about the jobs that are currently dangerous and harmful for humans, from fighting fires to search and rescue to natural disaster recovery.” She believes that we should not only avoid putting people in harm’s way when possible, but that these are often the very kind of jobs where technology can be a great help.
There are limits, of course, to how much a single program at a single institution—even a prominent one—can shift an entire field. But Li is adamant she has to do what she can to train researchers to think like ethicists, who are guided by principle over profit, informed by a varied array of backgrounds.
On the phone, I ask Li if she imagines there could have been a way to develop AI differently, without, perhaps, the problems we’ve seen so far. “I think it’s hard to imagine,” she says. “Scientific advances and innovation come really through generations of tedious work, trial and error. It took a while for us to recognize such bias. I only woke up six years ago and realized ‘Oh my God, we’re entering a crisis.’ ”
On Capitol Hill, Li said, “As a scientist, I’m humbled by how nascent the science of AI is. It is the science of only 60 years. Compared to classic sciences that are making human life better every day—physics, chemistry, biology—there’s a long, long way to go for AI to realize its potential to help people.” She added, “With proper guidance AI will make life better. But without it, the technology stands to widen the wealth divide even further, make tech even more exclusive, and reinforce biases we’ve spent generations trying to overcome.” This is the time, Li would have us believe, between an invention and its impact.
Hair and Makeup by Amy Lawson for Makeup Forever

Jessi Hempel wrote about Uber CEO Dara Khosrowshahi in issue 26.05. Additional reporting by Gregory Barber.
This article appears in the December issue. Subscribe now.
Listen to this story, and other WIRED features, on the Audm app.
Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.

More Great WIRED Stories

The DIY tinkerers harnessing the power of AI
The ‘pink tax’ and how women spend more on NYC transit
PHOTOS: The secret tools magicians use to fool you
The Butterball Turkey Talk-Line gets new trimmings
An aging marathoner tries to run fast after 40
Hungry for even more deep dives on your next favorite topic? Sign up for the Backchannel newsletter","https://media.wired.com/photos/5bd8ac3e66f3912cf4bdb747/1:1/w_730,h_730,c_limit/WI120118_AI_FeiFei_01.jpg",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vZWRyaS5vcmcvb3VyLXdvcmsvdW4tc3BlY2lhbC1yYXBwb3J0ZXVyLXJlcG9ydC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbXBhY3QtaHVtYW4tcmlnaHRzL9IBAA?oc=5,UN Special Rapporteur analyses AI’s impact on human rights - European Digital Rights (EDRi),2018-11-07,European Digital Rights (EDRi),https://edri.org,,,"In October 2018, the United Nations (UN) Special Rapporteur for the promotion and protection of the right to freedom of opinion and expression, David Kaye, released his report on the implications of artificial intelligence (AI) technologies for human rights. The report was submitted to the UN General Assembly on 29 August 2018 but has only been published recently.",,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://edri.org/our-work/un-special-rapporteur-report-artificial-intelligence-impact-human-rights/', 'url': 'https://edri.org/our-work/un-special-rapporteur-report-artificial-intelligence-impact-human-rights/', 'name': 'UN Special Rapporteur analyses AI’s impact on human rights - European Digital Rights (EDRi)', 'isPartOf': {'@id': 'https://edri.org/#website'}, 'primaryImageOfPage': {'@id': 'https://edri.org/our-work/un-special-rapporteur-report-artificial-intelligence-impact-human-rights/#primaryimage'}, 'image': {'@id': 'https://edri.org/our-work/un-special-rapporteur-report-artificial-intelligence-impact-human-rights/#primaryimage'}, 'thumbnailUrl': 'https://edri.org/wp-content/uploads/2018/11/KayeEthics-2.jpg', 'datePublished': '2018-11-07T00:00:00+00:00', 'dateModified': '2020-08-27T15:39:37+00:00', 'breadcrumb': {'@id': 'https://edri.org/our-work/un-special-rapporteur-report-artificial-intelligence-impact-human-rights/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://edri.org/our-work/un-special-rapporteur-report-artificial-intelligence-impact-human-rights/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://edri.org/our-work/un-special-rapporteur-report-artificial-intelligence-impact-human-rights/#primaryimage', 'url': 'https://edri.org/wp-content/uploads/2018/11/KayeEthics-2.jpg', 'contentUrl': 'https://edri.org/wp-content/uploads/2018/11/KayeEthics-2.jpg', 'width': 1920, 'height': 960, 'caption': ''}, {'@type': 'BreadcrumbList', '@id': 'https://edri.org/our-work/un-special-rapporteur-report-artificial-intelligence-impact-human-rights/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://edri.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Resources', 'item': 'https://edri.org/our-work/'}, {'@type': 'ListItem', 'position': 3, 'name': 'UN Special Rapporteur analyses AI’s impact on human rights'}]}, {'@type': 'WebSite', '@id': 'https://edri.org/#website', 'url': 'https://edri.org/', 'name': 'European Digital Rights (EDRi)', 'description': 'Protecting digital rights in Europe.', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://edri.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vd3d3LmJidmEuY29tL2VuL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW1hZGUtd2F5LWxpdGVyYXR1cmUv0gEA?oc=5,Artificial intelligence has made its way to literature - BBVA,2018-11-06,BBVA,https://www.bbva.com,Sunspring | A Sci-Fi Short Film,,"Machines started by offering us recommendations on what to read, and now they’re capable of writing poetry, stories and even screenplays. Computers have gone from tools to help human creators to becoming creative entities themselves, explains Ramón López de Mántaras in the book “The Next Step: Exponential Life”, which can be downloaded at no charge on BBVA OpenMind’s website.",,http://schema.org,VideoObject,,"{'@type': 'ImageObject', 'url': 'https://www.bbva.com/wp-content/uploads/en/2017/07/2607-Apertura-IAliteratura-BBVA-1024x416.jpg', 'width': '1024', 'height': '416'}","{'@type': 'Person', 'name': ['Marta Torres Briegas']}","{'@type': 'Organization', 'name': 'BBVA', 'logo': {'@type': 'ImageObject', 'url': 'https://www.bbva.com/wp-content/themes/coronita-bbvacom/assets/images/logos/bbva-logo-900x269.png', 'width': '900', 'height': '269'}}",Artificial intelligence has made its way to literature,2017-08-21T04-52-31.000Z,2018-11-06T16-53-24.000Z,,Sunspring | A Sci-Fi Short Film,,,,,"




Share






facebook








 twitter





linkedin





whatsapp






Up









Literature Updated: 06 Nov 2018

Artificial intelligence has made its way to literature



 







Machines started by offering us recommendations on what to read, and now they’re capable of writing poetry, stories and even screenplays. Computers have gone from tools to help human creators to becoming creative entities themselves, explains Ramón López de Mántaras in the book “The Next Step: Exponential Life”, which can be downloaded at no charge on BBVA OpenMind’s website.



 



























Marta Torres Briegas








 







Listen to audio



Leer en español












A recent survey conducted by the Future of Life Institute’s AI Impacts project predicts that artificial intelligence will be capable of writing a best seller by 2050. But there’s no need to wait that long to read literature written by software.
Google has been working with Stanford University and the University of Massachusetts to improve machines’ natural language. To do so, researchers have introduced artificial intelligence to more than 11,000 novels. The first step was for the software to understand the variances of human language. Once this goal was achieved, they gave it two sentences – a starting sentence and a closing sentence – from which the machine wrote several poems, as they explain in their report.
A robot’s creation reaches bookstores 
The Chinese publishing company Cheers Publishing has gone a step farther, offering the collection of poetry “Sunshine Misses Windows”, signed by the previously unknown author Microsoft Little Ice, for sale in bookstores. This algorithm created by the computer giant memorized more than 500 sonnets, from which it created 10,000 poems. Of these, 139 were published. Some of the poems have been shared on social networks under different pseudonyms. Very few Internet users were able to identify the nature of the author of poems such as the one below:
“The rain is blowing through the sea
A bird in the sky
A night of light and calm
Sunlight
Now in the sky
Cool heart
The savage north wind
When I found a new world…”
WASP is an artificial intelligence software that was created by Pablos Gervás, who holds a Ph.D. in Computer Science from the Complutense University of Madrid.  This researcher has spent 17 years perfecting his robot poet. WASP has learned to write, inspired by sonnets from Spain’s Golden Age. His creator says that the purpose of his research is to understand the structure of poetry and study the creative process, to make writers’ work easier. They are not trying to replace poets, as their writing lacks emotion.
Robots’ rap 
Poetry is not the only field where artificial intelligence dominates. Several researchers from Aalto University in Finland have created DeepBeat, software that is capable of writing rap lyrics. This program uses machine learning techniques to create lyrics to songs by combining lines from other songs that already exist, as well as different types of beats. On the project’s website, users can suggest a word or beat from which to create a song.





















DopeLearning: A Computational Approach to Rap Lyrics Generation





 



In Japan, computers are already participating in literary competitions. The Nikkei Hoshi Shinichi Literary Award allows non-human authors to present their work without the judges knowing the nature of the competitors. Of the 1,450 applications they received in the last edition, 11 were partially written by a machine. One of them, “The Day a Computer Writes a Novel” made it past the first round of the contest.
“I writhed with joy, which I experienced for the first time, and kept writing with excitement. The day a computer wrote a novel. The computer, placing priority on the pursuit of its own joy, stopped working for humans.”
The judges of the competition say that even though they are incredibly well structured, novels of this kind are still really lacking when it comes to describing the psychology of the characters.
A machine screenwriter named Benjamin
Artificial intelligence has already made it to the world of movies, and not just as part of the plot. Scientist Ross Goodwin and his team have created a Long Short-Term Memory (LSTM) which renamed itself Benjamin. The first screenwriting software has already released its first debut film, a short film called Sunspring, directed by the filmmaker Oscar Sharp




















Sunspring, a Sci-Fi Short Film





 



In the words of Sharp, the result of this experiment has been “a combination of the delusions of a madman and a poetic absurdity that is strangely appealing.” Sunspring uses disconnected phrases and its characters answer to the names of H, H2 and C. However, its creators decided to present it at Sci-Fi London, where it was selected as one of the 10 best short films.












Download for free 































Keep reading about

Literature
Music
Artificial Intelligence
Innovation
Science and technology










 
","{'@type': 'WebPage', '@id': 'https://www.bbva.com/en/artificial-intelligence-made-way-literature/'}",,,,,,,,,,,,,"['https://www.facebook.com/BBVAGroup/', 'https://twitter.com/bbva', 'https://www.linkedin.com/company/bbva', 'https://www.youtube.com/channel/UCx7HhFsmIlxx9fXnMpnERbQ', 'https://es.wikipedia.org/wiki/BBVA', 'https://instagram.com/bbva/', 'https://www.tiktok.com/@bbva']","[{'@type': 'WebSite', '@id': 'https://www.bbva.com/en/#website', 'url': 'https://www.bbva.com/en/', 'name': 'NEWS BBVA', 'description': 'NEWS BBVA', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://search.bbva.com/en/bbva?searchbbvaen={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://www.bbva.com/en/artificial-intelligence-made-way-literature/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://www.bbva.com/wp-content/uploads/en/2017/07/2607-Apertura-IAliteratura-BBVA.jpg', 'width': 1170, 'height': 475, 'caption': '2607-apertura-ialiteratura-bbva'}, {'@type': 'WebPage', '@id': 'https://www.bbva.com/en/artificial-intelligence-made-way-literature/#webpage', 'url': 'https://www.bbva.com/en/artificial-intelligence-made-way-literature/', 'name': 'Artificial intelligence has made its way to literature | BBVA', 'isPartOf': {'@id': 'https://www.bbva.com/en/#website'}, 'primaryImageOfPage': {'@id': 'https://www.bbva.com/en/artificial-intelligence-made-way-literature/#primaryimage'}, 'datePublished': '2017-08-21T01:52:31+00:00', 'dateModified': '2018-11-06T14:53:24+00:00', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.bbva.com/en/artificial-intelligence-made-way-literature/']}]}]",,,https://www.bbva.com/wp-content/uploads/en/2017/07/inteligencia-artificial-corto-bbva.jpg,,,,,,,,,,,,,,,2017-07-27 12:46:02,,,https://www.youtube.com/embed/LY7x2Ihqjmc,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAxOC8xMS8wOS90aGUtYW1hemluZy13YXlzLXRveW90YS1pcy11c2luZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1iaWctZGF0YS1yb2JvdHMv0gEA?oc=5,"The Amazing Ways Toyota Is Using Artificial Intelligence, Big Data & Robots - Forbes",2018-11-09,Forbes,https://www.forbes.com,"Toyota is preparing for the 4th industrial revolution with investments in AI, big data and robots. They are enhancing AI technology to power autonomous vehicles, create better connection between humans and machines, provide solutions that enhance the life and work of humans and more.",,"Toyota is preparing for the 4th industrial revolution with investments in AI, big data and robots. They are enhancing AI technology to power autonomous vehicles, create better connection between humans and machines, provide solutions that enhance the life and work of humans and more.","Toyota is preparing for the 4th industrial revolution with investments in AI, big data and robots. They are enhancing AI technology to power autonomous vehicles, create better connection between humans and machines, provide solutions that enhance the life and work of humans and more.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2018/11/09/the-amazing-ways-toyota-is-using-artificial-intelligence-big-data-robots/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2018/11/AdobeStock_176308970-1200x743.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","The Amazing Ways Toyota Is Using Artificial Intelligence, Big Data & Robots",2018-11-09T00:06:00-05:00,2018-12-12T10:03:02-05:00,Enterprise & Cloud,"The Amazing Ways Toyota Is Using Artificial Intelligence, Big Data & Robots",True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryInnovationEnterprise TechThe Amazing Ways Toyota Is Using Artificial Intelligence, Big Data & RobotsBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 9, 2018,12:06am ESTUpdated Dec 12, 2018, 10:03am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinA great way to understand the future priorities for a company is to see where they invest resources. When you look at where Toyota, the Japanese industry giant, has recently invested, it’s clear the company is preparing to remain relevant and competitive in the 4th industrial revolution as a result of its investments and innovation in artificial intelligence, big data and robots.








Adobe Stock
Adobe Stock






Toyota AI Ventures Invests in AI Start-ups
With initial funding of $100 million, Toyota AI Ventures invests in tech start-ups and entrepreneurs around the world that are committed to autonomous mobility, data and robotics. Toyota’s investments help accelerate getting critical new technologies to market. One of the organization’s investments is in May Mobility, a company that is developing self-driving shuttles for college campuses and other areas such as central business districts where low-speed applications are warranted. This is just one of the services that could blaze a trail to fully autonomous vehicles of the future.
Additionally, Silicon-based Toyota AI Ventures contributed funding as well as mentorship, incubation facilities and validation to Nauto, a company that’s creating a shared data platform to prevent accidents caused by distracted driving; SLAMcore, a visual tracking and mapping algorithm developer for smart tech; Intuition Robotics, an organization that creates social companion technologies that are accessible and intuitive for seniors; Boxbot, a company that’s building self-driving delivery robots; and more. Like many disruptors, Toyota AI Ventures seeks out other innovators to tackle important challenges to propel the latest technologies.
PROMOTED
AI Enhancements to Automobiles
Innovation has always been omnipresent at Toyota from its earliest days and it’s clear the company is continuing that innovative tradition. While Toyota was originally a company that produced wooden hand looms, the majority of people know the company for its automobile division. Their aim is to use artificial intelligence (AI) technology to make “cars an object of affection again” as soon as 2020 and is investing $1 billion in self-driving cars and AI between now and then to achieve it. Through Toyota’s investments in tech start-ups such as Perceptive Automata it hopes to create the technology to allow autonomous vehicles more human-like intuition when they are on the road more similar to how human drivers interact with pedestrians.
Toyota’s Concept-i fully electric autonomous vehicles demonstrate the company’s “Learn, Protect, Inspire” philosophy. The Concept-i artificial intelligence system, nicknamed “Yui,” learns about its driver by listening to conversations, monitoring social media activity and schedules, and analyzing facial expressions and driving habits to sense when a driver might be sleepy or stressed or what might enhance the driver’s comfort and then adjusts lighting, music or to the seats accordingly. The full vision is “intelligent talking cars” where cars equipped with AI can have conversations back and forth with passengers.
Toyota also announced the Concept-i Ride for users with wheelchairs or other disabilities and the Concept-i Walk, that’s designed for pedestrians to use on sidewalks similar to a Segway. Both additions to the Concept-i product line feature the same sensing abilities as the Concept-i vehicle.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



In an effort to bring AI efficiency to ridesharing, Toyota has collaborated with Japan Taxi to test out its new AI-propelled taxi dispatch system. Not only does the company expect to enhance Tokyo’s taxi service, company leaders believe the driving data and real-time video will be instrumental in boosting efficiency and profits.
Toyota and Robotics
As a result of deep learning technologies and the millions of images uploaded to the internet via social media and other websites, machines are getting better at being able to “see” like a human. Toyota’s Human Support Robot (HSR) algorithms help it understand the world and can be life-changing for individuals with impaired mobility. The company also announced a T-HR3 humanoid robot, a third-generation version that uses an immersive “Master Maneuvering System” that mirrors a human user’s movements or can operate autonomously to support humans in a variety of settings.
Toyota is also innovating warehouse logistics with automation and artificial intelligence for lean approaches to material handling. With AI on board every vehicle, the future of logistics is when the right truck or piece of equipment—pallet drone, mid-lifter, ultra-lifer—is used for the right task every time. The company’s innovations aim to minimize energy use, prevent delays and eliminate waste thanks to teamwork between trucks, lifts, loaders and other equipment.
Toyota is a company that’s worth paying attention to as it progresses further into the 4th industrial revolution with investments in AI, big data and robotics.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3LmVudHJlcHJlbmV1ci5jb20vc2NpZW5jZS10ZWNobm9sb2d5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXdpbGwtYmUtdGhlLWdyZWF0ZXN0LWpvYnMtZW5naW5lLzMyMjE0MdIBAA?oc=5,Artificial Intelligence Will Be the Greatest Jobs Engine the World Has Ever Seen - Entrepreneur,2018-11-06,Entrepreneur,https://www.entrepreneur.com,Fears that AI will make many types of workers unemployable are unfounded.,"Science & Technology,Technology,Disruption,Employment,Artificial Intelligence",Fears that AI will make many types of workers unemployable are unfounded.,Fears that AI will make many types of workers unemployable are unfounded.,https://schema.org,BreadcrumbList,https://www.entrepreneur.com,,,,,,,,,,"[{'@type': 'ListItem', 'position': 0, 'name': 'Science & Technology', 'item': 'https://www.entrepreneur.com/science-technology'}]",Artificial Intelligence Will Be the Greatest Jobs Engine the World Has Ever Seen | Entrepreneur,,"


  Artificial Intelligence Will Be the Greatest Jobs Engine the World Has Ever Seen
  
    Fears that AI will make many types of workers unemployable are unfounded.
  





                  By          
            Byron Reese
          

            Edited by 
                          
                Dan Bova
              


            Nov 6, 2018
          




          Share        


Copy


 






Subscribe to the Entrepreneur Daily newsletter to get business news, tips and inspiration sent to your inboxSubscribeI understand that the data I am submitting will be used to provide me with the above-described products and/or services and communications in connection therewith.Read our privacy policy for more information.



    Opinions expressed by Entrepreneur contributors are their own.  








PhonlamaiPhoto | Getty Images


In the past few years, artificial intelligence has advanced so quickly that it now seems that hardly a month goes by without a newsworthy AI breakthrough. In areas as wide-ranging as speech translation, medical diagnosis and game play, we have seen computers outperform humans in startling ways. This has sparked a discussion about what impact AI will have on employment.Related: Artificial Intelligence Is Likely to Make a Career in Finance, Medicine or Law a Lot Less LucrativeSome fear that as AI improves, it will supplant workers in the job force, creating an ever-growing pool of unemployable humans who cannot economically compete with machines in any meaningful way. This concern, while understandable, is unfounded.



AI will be the greatest job engine the world has ever seen.Technology has progressed nonstop for 250 years, and in the U.S. unemployment has stayed within a narrow band of 5 to 10 percent for almost all that time, even when radical new technologies such as steam power and electricity came on the scene.


AI is the most empowering of all technologies because it effectively makes anyone who uses it smarter. It increases the productivity of anyone who can apply it to their job. Once again, you hear the same refrain: ""It will destroy jobs."" And sure, you can look around and find jobs that it might well eliminate, such as order taker at a fast-food restaurant. But, that is not in any way the entire story.No, the whole story involves the other part of the equation. What will this technology enable?Related: AI Won't Replace Us Until It Becomes Much More Like UsConsider the ATM. If you had to point to a technology that looked as though it would replace people, the ATM might look like a good bet. It is, after all, an automated teller machine. And yet, there are more tellers now than when ATMs were widely released. How can this be? Simple: ATMs lowered the cost of opening bank branches, and banks responded by opening more, which required hiring more tellers.


This is one of the fundamental dynamics of technology and employment. As technology lowers costs, people respond by one of two things: They either buy more of the item (as banks did with branches) or they spend their saved money elsewhere, creating new jobs in those areas.In this manner, AI is going to create many millions of jobs that are far beyond my meager ability to imagine. But, examples already abound. For instance, AI is getting really good at language translation. What do you expect that to do to the demand for human translators? According to the U.S. Bureau of Labor Statistics, it is skyrocketing. Why? If you lower the cost of basic translation to nearly zero, the cost of doing business with those who speak other languages falls. Thus, it emboldens companies to do more business overseas, creating more work for human translators. AI may do the ""simple"" translations, but humans are needed for the nuanced kind.In fact, the BLS forecasts faster-than-average job growth in many occupations that AI is going to have a large impact on: accountants, forensic scientists, geological technicians, technical writers, MRI operators, dietitians, financial specialists, web developers, loan officers, medical secretaries and customer service representatives, to name a very few. These fields will not experience job growth in spite of AI, but through it. These are all areas in which AI can aid humans and increase their productivity and wages.Related: 4 Industries That Are Being Disrupted by AIBut, just as with the internet, the real gains in jobs will come from places where our imaginations cannot yet take us.But, what of the skills gap? Will AI eliminate low-skill jobs and create only high-skill ones? This is far from certain, but let's entertain the idea. If this happens, are all those low-skill workers unemployable? Far from it.The relevant question is whether most people can do a job that's just a little more complicated than the one they currently have. If you agree with me that the answer is yes, then no worries. The whole workforce just shifts up a notch. Everyone, from entry level to PhD, just moves up the job ladder a bit. This is exactly what happened with the industrial revolution: Farmers became factory workers, factory workers became factory managers, and so on.New jobs created at the top are opportunities for everyone to get a promotion.


A January 2018 Accenture report ""Reworking the Revolution"" estimates that new applications of AI combined with human collaboration can boost employment worldwide 10 percent by 2020.Electricity changed the world, as did mechanical power, as did the assembly line. No one can reasonably claim that we would be better off without those technologies. Each of them bettered our lives, created jobs and boosted wages. AI will be bigger than electricity, bigger than mechanization, bigger than anything that has come before it. It, too, will make the world a better place and, yes, create jobs.

",,,,,,,,https://assets.entrepreneur.com/static/20240220061344-entrepreneur-logo-black.svg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vbmV3cy5hcnRuZXQuY29tL21hcmtldC85LWFydGlzdHMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtMTM4NDIwN9IBUWh0dHBzOi8vbmV3cy5hcnRuZXQuY29tL21hcmtldC85LWFydGlzdHMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtMTM4NDIwNy9hbXAtcGFnZQ?oc=5,Has Artificial Intelligence Brought Us the Next Great Art Movement? Here Are 9 Pioneering Artists Who Are Exploring AI’s Creative Potential - artnet News,2018-11-06,artnet News,https://news.artnet.com,"Sure, a blurry portrait of a fake nobleman just sold for a lot of money. But there's a lot more going on in the world of art and AI.","AI art, Sougwen Chung, Sofia Crespo, Samim Winiger, Gene Kogan, Helena Sarin, Tom White, Anna Ridler, Mario Klingemann, Robbie Barrat, artificial intelligence and art, creative coding, artnet-news","Sure, a blurry portrait of a fake nobleman just sold for a lot of money. But there's a lot more going on in the world of art and AI.",,https://schema.org,,,,,,,,,,,,,Analysis,,"





Analysis

Has Artificial Intelligence Brought Us the Next Great Art Movement? Here Are 9 Pioneering Artists Who Are Exploring AI’s Creative Potential
There's a lot going on in the world of art and AI.





Anna Ridler, Tulips from Mosaic Virus (2018). Image courtesy the artist.










Naomi Rea 
November 5, 2018


 ShareShare This Article




Art-market history was made late last month when a work created using a neural network—one type of technology now commonly, if somewhat reductively, classified as an artificial intelligence—sold at Christie’s auction house in New York for $432,500.
The print was made using a form of machine learning called a Generative Adversarial Network, or a GAN (which you can read more about here). The Christie’s sale wasn’t the first time a work using so-called AI has been sold at auction, but it did mark the first time that a major auction house paid attention to the field—and helped drive the price up to nearly half a million dollars. 
The sale has also stirred controversy in the close-knit generative-art community. Many artists working in the field point out that Obvious, the collective behind the AI that made the pricey work, was handsomely rewarded for an idea that was neither very original nor very interesting. The savvy marketers behind the sale seemingly took advantage of the fact that the wider public is not very educated about the sector. Even the Christie’s expert who put the sale together admitted that he first learned about Obvious’s work from an article that appeared on artnet News in April.
As for the other major auction houses, a spokesman for Bonhams, interestingly, told us it is not considering hopping on the algorithmic trend now or in the future. Neither Sotheby’s nor Phillips responded to requests for comment on the matter.
While we wait for the next AI-generated work to hit the block, there’s a lot more to learn. To find out about the interesting work being created with machine learning—and the complex boundaries it’s pushing—we’ve assembled a list of nine pioneering artists to watch.
 
Mario Klingemann
An image of Albert Barqué-Duran carrying out the live painting inspired by the muse generated by Klingemann’s algorithm. Image courtesy the artists.
WHO: Klingemann is an artist whose preferred tools, rather than a paintbrush and paints, are neural networks, code, and algorithms. He taught himself how to program in the ’80s, so you could see his algorithms as Outsider AI-artists. (Just kidding!) He’s currently an artist-in-residence at Google Arts and Culture (which brought us that viral art historical face-matching app). He also runs a gallery space in Munich called Dog & Pony, and his works have been shown at the Ars Electronica Festival, the Museum of Modern Art in New York, the Metropolitan Museum of Art, London’s Photographers Gallery, and the Centre Pompidou, among others.
WHAT: Klingemann works with generative models (i.e. GANs) a lot, which he sees as “creative collaborators.” Recently, he collaborated with one of these neural network partners as well as a more traditional artist, Albert Barqué-Duran, on a project titled My Artificial Muse. The project sought to create a computer-generated “muse” to inspire a painting. For this, Klingemann trained his network on a database of more than 200,000 photographs of human poses until it was able to generate new ones. Then, based on the information it was fed about poses and paintings, the network generated an image, which was scaled up and then painted in mural form during a live performance by Barqué-Duran.
WHY: In exploring machine learning, Klingemann hopes to understand, question, and subvert the inner workings of systems of all kinds. He has a particularly deep interest in human perception and aesthetic theory, subjects he hopes to illuminate through his work creating algorithms that show almost autonomous creative behavior.
 
Anna Ridler
Tulips from Mosaic Virus (2018). Image courtesy the artist.
WHO: Ridler has a more traditional artistic background than some of the others on this list. She has degrees from the Royal College of Art, Oxford University, and University of the Arts London. Although her work essentially uses the same code architecture as Klingemann’s, she generates her own data sets to train her models rather than using existing images. She says this gives her more “creative control” over the end result. Creating bespoke data sets is demanding: it consumes around 60 to 70 percent of the total time it takes her to create a work. She’s shown her work at Ars Electronica, Tate Modern, and the V&A, among other institutions. 
WHAT: Ridler usually uses GANs, as she believes they produce some of the most visually interesting results. For her current project, Mosaic Virus, she’s using something called spectral normalization (a new technique that helps the algorithm generate better-quality images). She created a training set by taking 10,000 photos of tulips over the course of tulip season and categorizing them by hand. Then, she used the software to generate a video showing her tulips blooming—but their appearance was controlled by the fluctuations in the price of bitcoin, with the stripes on the petals reflecting the value of the cryptocurrency. The work draws historical parallels between the “tulip mania” that swept Europe in the 1630s (when prices for tulips with striped petals caused by the mosaic virus soared) and the current speculation on cryptocurrencies. For other works, such as The Fall of the House of Usher, she trained her neural network on her own ink drawings.
WHY: “The most interesting part of working with machine learning is the way that it repeats your idea back to you, but in a way that is looser and wilder and freer than I could ever make by myself,” Ridler tells artnet News. “Looking at the work that I’ve made with AI is always like catching a glimpse of yourself in a mirror before you recognize that it is you—you but also not you.”
 
Robbie Barrat



WHO: Barrat is a 19-year-old artist and coder who currently works in a research lab at Stanford University. He is notable not only for his youth, but also for the humor and originality of his creations. When he was in high school, he created this rapping neural network trained on Kanye West’s entire discography. Back in 2017, he also uploaded the code for a very similar project to the one Obvious just cashed in on at Christie’s for anyone to play around with (which is looking increasingly suspect for Obvious). Another of his models, interestingly, misinterpreted the data set of nude portraits that it was fed, giving too much attention to things like rolls of flesh and bellybuttons to generate a series of trippy, Francis Bacon-esque nudes.
WHAT: For a recent project, Barrat has been working at the intersection of fashion and machine learning. Using Balenciaga’s catalogues as training data, he is having a series of neural networks generate new outfits, and even a brand new runway show. So far, he tells artnet News, “the outfits that the machine makes are a lot more strange and more asymmetric than anything Balenciaga has put out.” He and a designer collaborator Mushbuh are currently working with a factory in Pakistan to make some of the algorithm-generated designs a reality. I don’t know about you, but I can definitely see the shin-bag becoming a thing.
WHY: Like other artists working with machine learning, Barrat sees AI as a tool or medium. He views it as a collaboration between artist and machine.
Tom White
The latest print by Tom White, Mustard Dream (2018). Courtesy the artist.
WHO: Tom White is a New Zealand-based artist who is currently working as a lecturer in computational design at the University of Wellington. He specializes in “creative coding” and was included in the first mainstream gallery show dedicated to art made using artificial intelligence, which we wrote about earlier this summer.
WHAT: White works with neural networks called Convolutional Neural Networks, or CNNs. These networks are used in today’s computer vision applications to give modern machine-learning systems the ability to perceive the world through vision—for example, systems that filter obscene images from your Google search. In his work, White investigates the perceptual abilities of these systems by finding abstract forms that are meaningful to them. Trained on a set of images of real-life objects, the machine creates abstract representational prints until the forms created register as the specific objects, such as a starfish or a cabbage, when they are run through other AI systems to confirm. Some of the results register as “very likely obscene” when they are run through systems trained to filter obscene content, even though they might not register that way to us humans. See the above “obscene” print by White for reference.
WHY: White says working with artificial intelligence is like coming up against a staunchly different culture with completely foreign ways of seeing. In his own words, “By using AI techniques to generate my prints, I both learn and communicate how these systems differ in what they understand visually. This gives some insight in how the intelligences we are creating often agree but sometimes differ in their understanding of the world we share.”
 
Helena Sarin
Helena Sarin, Pretty in GAN courtesy the artist.
WHO: Sarin is a traditional artist who uses GAN variants to transform and enhance her own pencil-on-paper sketches. She has been building commercial software for a long time, but only recently, with the discovery of GANs, has she been able to align her twin passions of coding and art.
WHAT: Sarin pretty much exclusively uses something called CycleGAN, a GAN variant that does image-to-image translation. She essentially trains a network to transform images with the form of one data set to have the textures of another data set. For example, she translates her photos of food and drink into the style of her still-lifes and sketches of flowers. She explains that one of the perks of using CycleGAN is that she can work in high resolution, even with small data sets. Plus, the model trains relatively quickly.
WHY: “As a software engineer and an artist, I always wanted to combine these two tracks of my life,” Sarin explains. “But the generative art in processing was too abstract for my taste. On the other hand, the generative models trained on my art keep producing organic folksy imagery that almost never fails to excite and surprise me.”
 
Gene Kogan
Gene Kogan, Style Collage—Jackson Pollock (2018). Courtesy the artist.
WHO: Kogan is an artist and programmer interested in how generative systems, computer science, and software can be used creatively for self-expression. He collaborates on several open-source software projects and lectures about the intersections of code and art. He’s also literally written the book on machine learning for artists.
WHAT: Like many of the people on this list, Kogan trains neural networks, a popular type of machine-learning software, on images, audio, and text. He says his primary goal is to develop generative models, or to help teach the software to output fresh, varied work based on inputs. He is particularly interested in cross-pollinating media—teaching the neural networks to output music based on a drawing of an instrument, for example. 
WHY: “It lets me try to find out interesting things about the collective mind or ‘hive mind,’ a bank of knowledge composed of all of our data,” Kogan explains of AI’s appeal. “I am interested in the collective imagination, what we reveal about ourselves by our data in aggregate. I am also interested in using neural networks to create new forms of interaction which can respond to rich sensory data, like vision, sound, and natural language.”
 
Samim Winiger
Samim Winiger, from DeepGagosian (2018). Courtesy Samim Winiger.
WHO: Winiger is a self-described “designer and code magician” who used to produce dance music for the likes of Diplo and Shaggy. The Berlin-based developer, who doesn’t define himself as an artist per se, is known for his experiments with artistic computational creativity experiments.
WHAT: Winiger says his network of choice “very much depends on the occasion.” (They range from Convolutional Neural Nets (CNNs) to Recurrent Neural Nets (RNNs) to Dimensionality Reduction techniques (TSNE etc.) and beyond, but we won’t get into that here.) Recently, he’s been using neural networks to explore “DeepFakes,” living hoaxes created by software taught to, say, swap one person’s head onto another’s body in one or more images. Once it has been trained on enough examples for the task at hand, a machine can produce an entire video hoax without the need for frame-by-frame manipulation on the programmer’s part. (In fact, since some DeepFake software now uses graphical interfaces—think: clicking and dragging icons—rather than coding, almost anyone can do this now.) Just for artnet News, and for fun, he trained a custom neural network he calls “DeepGagosian,” which places the face of the famous art dealer Larry Gagosian in different scenes. He’s used this to insert Mr. Gagosian into a few unusual contexts, such as a drug gang bust and a gathering of heads of state (see above).
WHY: Asked to pinpoint the most interesting part of working with neural networks for creative purposes, Winiger says: “When using machines to assist with the creation of creative artifacts, questions of authorship and agency are very much blurred. By using augmentation tools, the human creator is (in the best case) freed up to focus on the core message of the piece.” And with generative toolboxes like DeepFakes becoming more readily available, gone are the days when you needed mad Photoshop skills to pull off a convincing faked image (like the ones in DeepGagosian). Winiger explains: “We are currently at a major inflection point, where the cost of high quality image manipulation has dropped to close to 0. This concludes a 100+-year relationship with photography, where the common ‘photography equals reality’ assumption is breaking down.”
 
 Sofia Crespo
Sofia Crespo, {External_Anatomy 1020}. Courtesy the artist.
WHO: Crespo is a Berlin-based artist and art director. Her previous work includes Trauma Doll, an algorithm-powered doll that “suffers” from PTSD, anxiety, depression, and other mental health issues. As a coping mechanism, the doll creates collages using pattern recognition from online texts including memes, philosophical texts, and news headlines.
WHAT: Crespo is currently working on a project called Neural Zoo, which explores how creativity combines known elements in a specific way in order to create something entirely new. In her view, the creator in this case would be the algorithm itself, but with a human artist as its muse. “Isn’t all art made by humans an execution or reshaping of data absorbed through biological neurons?” Crespo asks. “How can we continue to inspire machines to create art for us as emotional human beings?”
WHY: “An interesting thing this experience gave me is the change of perspective in the design role,” Crespo says. “I originally went from designing a layout and features for an image, to actually designing the data and letting a program decide those features by itself. I guess my role became trying to anticipate what the model could create with the given data, and it never stops surprising me.”
 
Sougwen Chung
Sougwen Chung, Drawing Operations (2017). Courtesy the artist.
WHO: Chung is a Canadian-born, Chinese-raised, New York-based interdisciplinary artist and former research fellow at MIT’s Media Lab. She’s currently E.A.T.’s artist-in-residence in partnership with the New Museum and Bell Labs. Her work, which spans installation, sculpture, drawing, and performance, explores mark-making by both hand and machine in order to better understand the interactions between humans and computers. She has exhibited at institutions including The Drawing Center in New York and the National Art Center in Tokyo.
WHAT: For her current project, Drawing Operations, Chung uses Google’s TensorFlow, an open-source software library used for machine learning, to classify archives of her own drawings. The software then transfers what it has learned about Chung’s style and approach to a robotic arm that draws alongside her. She’s also working on a few new projects using pix2pix (a neural network trained to produce variations on an image, like the nighttime version of a daytime photo) and sketch-rnn (which tries to continue or complete a digital sketch based on where the human leaves off) to expand on this idea of human and machine collaboration.
WHY: “As an artist working with these tools, the promise of AI offers a new way of seeing,” Chung explains. “Seeing as self reflection, seeing through the ground truth of ones own artworks as data. There is a lot of talk about biases evident in AI systems and that is absolutely true within AI systems trained on art. You could describe visual language as a kind of visual bias, a foregrounding of the subjective view of the artist. By translating that into machine behavior, I am attempting to create a shared intersubjectivity between human and machine.”
Follow Artnet News on Facebook: 

Want to stay ahead of the art world? Subscribe to our newsletter to get the breaking news, eye-opening interviews, and incisive critical takes that drive the conversation forward.








 Share This ArticleShare This Article






 
 
 Naomi Rea
Acting Editor-in-Chief
 




 








            The best of Artnet News in your inbox.
        

            Sign up to our daily newsletter.
        








Please enter a valid email address
Signup failed. Please try again later.



Thank you!
You have successfully subscribed to Artnet News.











 

                Related Articles
            










Art & Exhibitions




A High-Tech Museum Show in San Francisco Will Tackle Algorithmic Bias and the Low-Wage AI Economy—Just a Stone’s Throw From Silicon Valley


			By
							Sarah Cascone,
							Sep 26, 2019
						


 









Art World




Artists Create a Sinister ‘Deepfake’ of Mark Zuckerberg to Teach Facebook (and the Rest of Us) a Lesson About Digital Propaganda


			By
							Naomi Rea,
							Jun 12, 2019
						


 









Market




Sotheby’s First Auction of an AI Artwork Fails to Incite a Robo-Frenzy, Fetching a Modest $51,000


			By
							Naomi Rea,
							Mar 6, 2019
						


 





            The best of Artnet News in your inbox.
        

            Sign up to our daily newsletter.
        








Please enter a valid email address
Signup failed. Please try again later.



Thank you!
You have successfully subscribed to Artnet News.




 




                                More Trending Stories
                            



Books
                                                    







                                                            Art Lovers, Here Are 7 New Non-Fiction Books to Add to Your Summer Reading List
                                                        





Art & Exhibitions
                                                    







                                                            There’s More to Rome Than Ancient History. Check Out These Must-See Contemporary Gems
                                                        





Art & Exhibitions
                                                    







                                                            The Story Behind a Rare 19th-Century Portrait of a Person of Color Emerges
                                                        





Artists
                                                    







                                                            ‘The More Repellent You Are, the More Attractive You Become’: George Condo on Contemporary Mythmaking
                                                        









                                                            Books
                                                        


                                                                Art Lovers, Here Are 7 New Non-Fiction Books to Add to Your Summer Reading List
                                                            













                                                            Art & Exhibitions
                                                        


                                                                There’s More to Rome Than Ancient History. Check Out These Must-See Contemporary Gems
                                                            













                                                            Art & Exhibitions
                                                        


                                                                The Story Behind a Rare 19th-Century Portrait of a Person of Color Emerges
                                                            













                                                            Artists
                                                        


                                                                ‘The More Repellent You Are, the More Attractive You Become’: George Condo on Contemporary Mythmaking
                                                            











",,,,,,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://news.artnet.com/#organization', 'name': 'Artnet News', 'url': 'https://news.artnet.com/', 'sameAs': [], 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/#/schema/logo/image/', 'url': 'https://news.artnet.com/app/news-upload/2023/02/news-logo-64x64-1.png', 'contentUrl': 'https://news.artnet.com/app/news-upload/2023/02/news-logo-64x64-1.png', 'width': 64, 'height': 64, 'caption': 'Artnet News'}, 'image': {'@id': 'https://news.artnet.com/#/schema/logo/image/'}}, {'@type': 'WebSite', '@id': 'https://news.artnet.com/#website', 'url': 'https://news.artnet.com/', 'name': 'Artnet News', 'description': 'The world’s most-read and best trusted art publication', 'publisher': {'@id': 'https://news.artnet.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.artnet.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#primaryimage', 'url': 'https://news.artnet.com/app/news-upload/2018/10/test_60.png', 'contentUrl': 'https://news.artnet.com/app/news-upload/2018/10/test_60.png', 'width': 1024, 'height': 768, 'caption': 'Anna Ridler, Tulips from Mosaic Virus (2018). Image courtesy the artist.'}, {'@type': 'WebPage', '@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#webpage', 'url': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207', 'name': 'Has Artificial Intelligence Brought Us the Next Great Art Movement? Here Are 9 Artists Who Are Exploring AI’s Creative Potential', 'isPartOf': {'@id': 'https://news.artnet.com/#website'}, 'primaryImageOfPage': {'@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#primaryimage'}, 'datePublished': '2018-11-06T07:00:30+00:00', 'dateModified': '2018-11-06T15:05:19+00:00', 'description': ""Sure, a blurry portrait of a fake nobleman just sold for a lot of money. But there's a lot more going on in the world of art and AI."", 'breadcrumb': {'@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.artnet.com/market/9-artists-artificial-intelligence-1384207']}]}, {'@type': 'BreadcrumbList', '@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.artnet.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Has Artificial Intelligence Brought Us the Next Great Art Movement? Here Are 9 Pioneering Artists Who Are Exploring AI’s Creative Potential'}]}, {'@type': 'NewsArticle', '@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#article', 'isPartOf': {'@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#webpage'}, 'author': {'@id': 'https://news.artnet.com/#/schema/person/ba743d578bca1480ede0230f5a0e91be'}, 'headline': 'Has Artificial Intelligence Brought Us the Next Great Art Movement? Here Are 9 Pioneering Artists Who Are Exploring AI’s Creative Potential', 'datePublished': '2018-11-06T07:00:30+00:00', 'dateModified': '2018-11-06T15:05:19+00:00', 'mainEntityOfPage': {'@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#webpage'}, 'wordCount': 2860, 'publisher': {'@id': 'https://news.artnet.com/#organization'}, 'image': {'@id': 'https://news.artnet.com/market/9-artists-artificial-intelligence-1384207#primaryimage'}, 'thumbnailUrl': 'https://news.artnet.com/app/news-upload/2018/10/test_60.png', 'articleSection': 'Analysis', 'inLanguage': 'en-US', 'isAccessibleForFree': 'True', 'hasPart': {'@type': 'WebPageElement', 'isAccessibleForFree': 'True', 'cssSelector': '.article-body'}, 'alternativeHeadline': 'Has Artificial Intelligence Brought Us the Next Great Art Movement? Here Are 9 Pioneering Artists Who Are Exploring AI’s Creative Potential | Artnet News', 'description': {}, 'keywords': []}, {'@type': 'Person', '@id': 'https://news.artnet.com/#/schema/person/ba743d578bca1480ede0230f5a0e91be', 'name': 'Naomi Rea', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/a36033d037b111ee6cd86f7936667840?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/a36033d037b111ee6cd86f7936667840?s=96&d=mm&r=g', 'caption': 'Naomi Rea'}, 'description': ""Naomi Rea is Artnet News's Acting Editor-in-Chief, where she has worked since 2017. She is based in London, U.K."", 'sameAs': ['https://www.instagram.com/naomikrea/', 'https://twitter.com/naomikrea'], 'url': 'https://news.artnet.com/about/naomi-rea-419'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vd3d3LmNvZS5pbnQvZW4vd2ViL2N1bHR1cmUtYW5kLWhlcml0YWdlLy0vZS1yZWxldmFuY2Utb2YtY3VsdHVyZS1pbi10aGUtYWdlLW9mLWFp0gEA?oc=5,E-relevance of Culture in the Age of AI - Council of Europe,2018-11-07,Council of Europe,https://www.coe.int,,"slider,news,digitisation,dgii_portal,2018,directorate of democratic governance,public,cultural heritage,culture,english,french,democratic governance,general",," Rijeka, Croatia 12-13 October 2018",https://schema.org,WebPage,,"{'@type': 'ImageObject', 'url': 'https://www.coe.int/documents/15456573/19675704/leonard.jpg/452a6311-89e1-aa2a-ae7d-aef6bf7259ea', 'height': 489, 'width': 870}","{'@type': 'Organization', 'name': 'Council of Europe'}","{'@type': 'Organization', 'name': 'Council of Europe', 'logo': {'@type': 'ImageObject', 'url': 'https://static.coe.int/pics/logos/desktop/logo-coe-google-news.png', 'width': 78, 'height': 60}}",E-relevance of Culture in the Age of AI,2018-11-07T11:56:00+00:00,2024-04-18,,Culture and Cultural Heritage: newsroom,,,,,"

Rijeka, Croatia
12-13 October 2018


                Diminuer la taille du texte
            

                Augmenter la taille du texte
            

                Imprimer la page
            





Culture, Creativity and Artificial Intelligence were discussed at an expert seminar in Rijeka, Croatia on 12-13 October 2018. The seminar “E-relevance of Culture in the Age of AI”, organised in the framework of the Croatian Chairmanship of the Committee of Ministers of the Council of Europe, offers sector-specific input to the Council of Europe’s work on artificial intelligence.
In the presence of the representatives of the Ministry of Culture of Croatia, experts, practitioners/ artists and policy makers from the Steering Committee for Culture, Heritage and Landscape (CDCPP) discussed orientations for working towards a culture of responsible innovation, empowering citizens and laying the foundations for the emergence of a modern Leonardo da Vinci. Questions for debate included:

How can culture maintain its important human imprint and guidance role in a time where AI already heavily impacts people’s creativity?
Can it contribute to a more human- and citizen-centred technological future by proposing and developing alternative concepts?
How does AI impact on the perception of human uniqueness/genius, the role of artists, intellectual property? Can culture still represent a mirror of society in a time when AI intelligence blends with human creativity?

Experts, including Régine Debatty, Luba Elliott, Philippe Kern, Davor Misković, Matteo Pasquinelli, Felix Stalder, Vuk Ćosić and Gerfried Stocker, shed light on AI-related challenges and opportunities that actually present not just a technical revolution, but also a cultural and social one.  
The seminar highlighted that:
1. Arts & Culture need to be part of the dialogue about information society (be it about digital transformation at large, or AI in particular).
2. Arts & Culture are providing essential contributions to the deliberations about our common technology-influenced future, both in terms of realistic insight (through critical media art) and sense of direction (reflexive and holistic approach).
3. Arts & Culture stimulate active engagement and creativity in citizens and hence diversity in production, against the odds of global cultural standardisation and homogenisation.
4. Arts & Culture are an irreplaceable means of expression of the human genius, its iinite innate inventiveness and creativity, its power of self-determination and its manifest human rights.
5. Arts & Culture are key vectors in generating the necessary social intelligence and emancipation to accompany new life practices marked by increasing human- machine interaction.
***
Indeed, artists and cultural workers can elaborate alternative models of development, with a cultural agenda - beyond economic/commercial logics. They are able to reveal a multiplicity of readings, narratives and views and they attract media attention. As the seminar agreed, they will not easily be replaced by machines “although some AI generated art work may look more convincing than work shown at Art Fairs”..
Yet, people seem to appreciate the physical presence of a human, the imperfection of human creation and the concepts, narration, intention, effort and biographical context coming from humans.
However, AI might have a substantial impact on cultural and creative industries (music, film, journalism, design,…), challenging prevailing business models. Also, power inequalities in terms of representation may grow, due to uneven archival traditions in different world regions: cultures with strong archival traditions will be able to better feed the data needs of AI systems and hence be more ""present"" in global perception and markets.
A current initiative in Rijeka to teach AI about a threatened local language can serve as good practice and inspire similar initiatives at protecting and promoting European cultural diversity. Hence, combining high-quality business and technology assets with ethics and values would provide the competitive edge for a -also commercially successful- European model that should be robust since built on long-standing values rather than mere commercial rules.
In all this, communication seems key. Mostly, people seem either to fear loss of control through AI, or simply ignore the challenges involved. There was also a mythological dimension to AI and at the same time, a rational one: people vote for being operated on by robots rather than doctors, given the higher success rates of AI-based surgery. But when it comes to the nursing, people clearly prefer the human touch.
The event also hosted the exhibition opening of “Anatomy of an AI System”, a map that guides through the birth, life and death of an individual networked device based on a centralised artificial intelligence system, created by Vladan Joler, Share Foundation founder and Professor at the University of Novi Sad.
The results of the Rijeka expert seminar on Culture, Creativity and Artificial Intelligence will be conveyed to the Council of Europe’s forthcoming conference “Governing the Game Changer – Implications of AI development on human rights, democracy and the rule of law” (Helsinki, 26-27 February 2019).

Documents

Programme
Conclusions
Action proposals

Videos

Trailer
Testimonials

","{'@type': 'WebPage', '@id': 'https://www.coe.int/en/web/culture-and-heritage/-/e-relevance-of-culture-in-the-age-of-ai'}",,,,,,,,,,,,,,,,,,2016-03-17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LmRpZ2l0YWxoZWFsdGgubmV0LzIwMTgvMTEvbm9ydGgtb2YtZW5nbGFuZC1yZWNlaXZlcy0xMG0tYm9vc3QtZm9yLWFpLWFuZC1kaWdpdGFsLXBhdGhvbG9neS13b3JrL9IBAA?oc=5,North of England receives £10m boost for AI and digital pathology work - Digital Health,2018-11-06,Digital Health,https://www.digitalhealth.net,"The programme aims to develop new ways to speeding up diagnosis of diseases like cancer using AI, to improve outcomes for patients.",,"The programme aims to develop new ways to speeding up diagnosis of diseases like cancer using AI, to improve outcomes for patients.","The programme aims to develop new ways to speeding up diagnosis of diseases like cancer using AI, to improve outcomes for patients.",https://schema.org,,,,,,,,,,,,,AI and Data,,"


North of England receives £10m boost for AI and digital pathology work





AI and Data, News







                     6 November 2018









Is Technology the missing piece of the puzzle for cancer?














            
            Owen Hughes
        
October 24, 2017






  
  
  







Researchers in Leeds have been awarded a £10.1m investment from UK Research and Innovation to expand a digital pathology and artificial intelligence (AI) programme across the North of England.
The programme aims to explore new ways of speeding up the diagnosis of diseases – including cancer – through the application of AI.
It will also address whether regional clinical pathology services can be better integrated to support improved patient outcomes.
The investment was secured following a bid led by Leeds Teaching Hospitals NHS Trust and the University of Leeds.
The organisations form part of a wider consortium called the Northern Pathology Imaging Co-operative (NPIC), established to foster collaboration in diagnostics across clinicians, academia and health technology companies.
Sir Alan Langlands, vice-chancellor of the University of Leeds, said: “Leeds Teaching Hospitals NHS Trust is a global leader in the area of digital pathology for cancer diagnosis, thanks to the close links with academic researchers.
“We are now expanding this digitisation across the north through this exciting partnership between universities, the NHS and industry. Going forward, new technologies such as artificial intelligence have the potential to transform how we diagnose cancer and other diseases, and the University is making great advances in this area.”
NPIC comprises nine NHS hospitals, seven universities, nine medical technology companies and Swiss company Roche Diagnostics.
The investment was announced on 6 November by Greg Clark, Secretary of State for Business, Energy and Industrial Strategy (BEIS), as part of the Industrial Strategy Challenge Fund.
Dr Yvette Oade, chief medical officer at Leeds Teaching Hospitals NHS Trust, said the investment presented “a huge opportunity for Yorkshire to lead in this new area and further enhance our position as a hub for medical technology”.
Dr Oade added: “This is a really exciting step for patients because computers using artificial intelligence can be trained to recognise the patterns of disease.
“Machines will support clinically trained pathologists to diagnose cancer faster, better and at lower cost.
“We can also explore how to use digital pathology as part of precision medicine to ensure patients receive treatments tailored to their disease.
Pushing the joined-up agenda
The project also aims to develop more integrated ways of working across regional clinical pathology services.
NPIC said it would involve the public regarding the use of anonymised images for AI research. It will also help inform the development of a national pathology exchange, which will allow pathology images to be shared between NHS sites nationally similar to efforts underway in NHS Scotland.
Geoff Twist, managing director for Roche Diagnostics, said: “We are delighted to be a partner in this pioneering project that will introduce digital pathology and AI to a large network across the North of England covering a population of approximately 15 million people.
“This is a true collaboration with partners from across healthcare delivery and industry, coming together with a common goal to improve diagnostic capabilities to offer cancer patients the best care possible. The ultimate aim is to develop an exemplar model that can be replicated across the UK for the benefit of cancer patients.”
Health Secretary and health IT fanatic, Matt Hancock, added: “Artificial intelligence will play a crucial role in the future of the NHS – and we need to embrace it by introducing systems which can speed up diagnoses, improve patient outcomes, make every pound go further and give clinicians more time with their patients.
“As part of our long-term plan, we will transform the NHS into an ecosystem of enterprise and innovation that allows technology to flourish and evolve.”













Subscribe to our newsletter 



 







								Email							





Subscribe


















 Subscribe To Our Newsletter 



First Name



Last Name



Email Address: 



Job Title: 



Organisation: 






Leave this field empty if you're human: 













Subscribe To Our Newsletter 



 









Sign up


Leave this field empty if you're human: 











 Tags



                 AI
              




                 artificial intelligence
              




                 digital pathology
              




                 integrated pathology
              



",,,,,,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://www.digitalhealth.net/#organization', 'name': 'Digital Health Intelligence', 'url': 'https://www.digitalhealth.net/', 'sameAs': ['https://www.facebook.com/DigitalHealthNews2/', 'https://www.linkedin.com/company/digital-health-intelligence-ltd', 'https://twitter.com/digitalhealth2'], 'logo': {'@type': 'ImageObject', '@id': 'https://www.digitalhealth.net/#logo', 'url': 'https://www.digitalhealth.net/wp-content/uploads/2017/01/dhi_masthead.png', 'width': 425, 'height': 129, 'caption': 'Digital Health Intelligence'}, 'image': {'@id': 'https://www.digitalhealth.net/#logo'}}, {'@type': 'WebSite', '@id': 'https://www.digitalhealth.net/#website', 'url': 'https://www.digitalhealth.net/', 'name': 'Digital Health', 'publisher': {'@id': 'https://www.digitalhealth.net/#organization'}, 'potentialAction': {'@type': 'SearchAction', 'target': 'https://www.digitalhealth.net/?s={search_term_string}', 'query-input': 'required name=search_term_string'}}, {'@type': 'ImageObject', '@id': 'https://www.digitalhealth.net/2018/11/north-of-england-receives-10m-boost-for-ai-and-digital-pathology-work/#primaryimage', 'url': 'https://www.digitalhealth.net/wp-content/uploads/2018/11/digital-pathology-puzzle-2.jpg', 'width': 555, 'height': 330, 'caption': 'A picture of a pathology image as a jigsaw puzzle, missing a piece'}, {'@type': 'WebPage', '@id': 'https://www.digitalhealth.net/2018/11/north-of-england-receives-10m-boost-for-ai-and-digital-pathology-work/#webpage', 'url': 'https://www.digitalhealth.net/2018/11/north-of-england-receives-10m-boost-for-ai-and-digital-pathology-work/', 'inLanguage': 'en-GB', 'name': 'North of England receives £10m boost for AI and digital pathology work', 'isPartOf': {'@id': 'https://www.digitalhealth.net/#website'}, 'primaryImageOfPage': {'@id': 'https://www.digitalhealth.net/2018/11/north-of-england-receives-10m-boost-for-ai-and-digital-pathology-work/#primaryimage'}, 'datePublished': '2018-11-06T14:00:55+00:00', 'dateModified': '2018-11-05T16:24:07+00:00', 'description': 'The programme aims to develop new ways to speeding up diagnosis of diseases like cancer using AI, to improve outcomes for patients.'}, {'@type': 'Article', '@id': 'https://www.digitalhealth.net/2018/11/north-of-england-receives-10m-boost-for-ai-and-digital-pathology-work/#article', 'isPartOf': {'@id': 'https://www.digitalhealth.net/2018/11/north-of-england-receives-10m-boost-for-ai-and-digital-pathology-work/#webpage'}, 'author': {'@id': 'https://www.digitalhealth.net/#/schema/person/1506f4524ae1b5e26e1ea804b0153ae5'}, 'headline': 'North of England receives £10m boost for AI and digital pathology work', 'datePublished': '2018-11-06T14:00:55+00:00', 'dateModified': '2018-11-05T16:24:07+00:00', 'commentCount': 0, 'mainEntityOfPage': {'@id': 'https://www.digitalhealth.net/2018/11/north-of-england-receives-10m-boost-for-ai-and-digital-pathology-work/#webpage'}, 'publisher': {'@id': 'https://www.digitalhealth.net/#organization'}, 'image': {'@id': 'https://www.digitalhealth.net/2018/11/north-of-england-receives-10m-boost-for-ai-and-digital-pathology-work/#primaryimage'}, 'keywords': 'AI,artificial intelligence,digital pathology,integrated pathology', 'articleSection': 'AI and Data,News'}, {'@type': ['Person'], '@id': 'https://www.digitalhealth.net/#/schema/person/1506f4524ae1b5e26e1ea804b0153ae5', 'name': 'Owen Hughes', 'image': {'@type': 'ImageObject', '@id': 'https://www.digitalhealth.net/#authorlogo', 'url': 'https://secure.gravatar.com/avatar/6f5a1e92f82cbae53e0aec2ea92b221a?s=96&d=mm&r=g', 'caption': 'Owen Hughes'}, 'sameAs': []}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vd3d3Lm5hdG8uaW50L2Nwcy9lbi9uYXRvaHEvbmV3c18xNjAxMjIuaHRtP3NlbGVjdGVkTG9jYWxlPWVu0gEA?oc=5,"Deputy Secretary General Rose Gottemoeller in Beijing: “We need to defend ourselves in the digital age, and in the ... - NATO HQ",2018-11-06,NATO HQ,https://www.nato.int,"The NATO Deputy Secretary General Rose Gottemoeller visited Beijing on 24-26 October 2018 and participated in 8th Xiangshan Forum. Speaking at a special session on Artificial Intelligence, Gottemoeller highlighted how technological advances provide challenges as well as opportunities and discussed how NATO is working to ensure it stays ahead of the curve. “We do this by working together, among our 29 members and with our partners and international organisations. And of course, we work with the private sector to take full advantage of the latest innovations and to maintain our technological edge”.",News,"The NATO Deputy Secretary General Rose Gottemoeller visited Beijing on 24-26 October 2018 and participated in 8th Xiangshan Forum. Speaking at a special session on Artificial Intelligence, Gottemoeller highlighted how technological advances provide challenges as well as opportunities and discussed how NATO is working to ensure it stays ahead of the curve. “We do this by working together, among our 29 members and with our partners and international organisations. And of course, we work with the private sector to take full advantage of the latest innovations and to maintain our technological edge”.",,,,,,,,,,,,,,,,,"



Deputy Secretary General Rose Gottemoeller in Beijing: “We need to defend ourselves in the digital age, and in the age of artificial intelligence”


            24 Oct. 2018 - 26 Oct. 2018
          
 | 
Last updated: 06 Nov. 2018 16:27





English

French


Russian


Ukrainian







 

 The NATO Deputy Secretary General Rose Gottemoeller visited Beijing on 24-26 October 2018 and participated in 8th Xiangshan Forum. Speaking at a special session on Artificial Intelligence, Gottemoeller highlighted how technological advances provide challenges as well as opportunities and discussed how NATO is working to ensure it stays ahead of the curve. “We do this by working together, among our 29 members and with our partners and international organisations. And of course, we work with the private sector to take full advantage of the latest innovations and to maintain our technological edge”. 






NATO’s Strategic Command located in Norfolk Virginia, Allied Command Transformation, is leading NATO’s work on innovation and disruptive technologies, including big data, artificial intelligence, and robotics. “We know that we cannot fight tomorrow’s threats with today’s tools”, Gottemoeller said.  “Defending ourselves is no longer about just looking at a map and deciding where to position troops and equipment. We need to defend ourselves in the digital age, and in the age of artificial intelligence. That work is incredibly complex. And we are thinking about it in terms of both policy and practice”.
The Deputy Secretary General said that NATO continues to adapt in order to remain at the forefront of new technologies. “On the positive side of the ledger, we are drawing on AI-related technologies to improve our response to natural disasters”, she said. “At our disaster response exercise in Serbia in early October, NATO successfully tested disaster relief tools powered by artificial intelligence. These are incredibly powerful means to help save lives. We had drones flying over the site where the disaster occurred. They sent the information collected to other machines to process the images and the data collected in order to identify victims on the ground at record speed”. 
During her visit, the Deputy Secretary General met with senior Chinese officials and delivered a lecture at the PLA National Defence University. Gottemoeller also met with officials from NATO member and partner countries. 











    High resolution photos
  

Previous








NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller arrives at Beijing Airport and is welcomed by senior officer Zhang Li Ting










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller meets with the Australian ambassador, Jan Adams.










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller meets with Tony Lynch, Deputy Secretary of Defence of New Zealand.










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller meets with Tony Lynch, Deputy Secretary of Defence of New Zealand.










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller and Aleksandar Vulin, Minister of Defence of Serbia










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participates in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participated in the special session on the Military Application of Artificial Intelligence in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum 
25 Oct. 2018
NATO Deputy Secretary General, Rose Gottemoeller participated in the special session on the Military Application of Artificial Intelligence in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller participated in the special session on the Military Application of Artificial Intelligence in the 8th Beijing Xiangshan Forum










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller meets with Lieutenant General Yang Xuejun, President of the Academy of Military Sciences










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller meets with Lieutenant General Yang Xuejun, President of the Academy of Military Sciences










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

NATO Deputy Secretary General, Rose Gottemoeller meets with Lieutenant General Yang Xuejun, President of the Academy of Military Sciences










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

Lecture at the PLA National Defence University on the Position and the role of NATO in European Security. NATO Deputy Secretary General, Rose Gottemoeller is welcomed by Lieutenant General Zheng He










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

Lecture at the PLA National Defence University on the Position and the role of NATO in European Security. NATO Deputy Secretary General, Rose Gottemoeller is welcomed by Lieutenant General Zheng He










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

Lecture at the PLA National Defence University on the Position and the role of NATO in European Security. NATO Deputy Secretary General, Rose Gottemoeller is welcomed by Lieutenant General Zheng He










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

Lecture at the PLA National Defence University on the Position and the role of NATO in European Security by NATO Deputy Secretary General Rose Gottemoeller










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

Lecture at the PLA National Defence University on the Position and the role of NATO in European Security by NATO Deputy Secretary General Rose Gottemoeller










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

Lecture at the PLA National Defence University on the Position and the role of NATO in European Security by NATO Deputy Secretary General Rose Gottemoeller










NATO Deputy Secretary General participates in the 8th Beijing Xiangshan Forum

Lecture at the PLA National Defence University on the Position and the role of NATO in European Security by NATO Deputy Secretary General Rose Gottemoeller





































Next12345678910111213141516171819202122232425262728293031323334












      Opinions
    





Remarks by NATO Deputy Secretary General Rose Gottemoeller at the Xiangshan Forum in Beijing, China

25 Oct. 2018



















",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vd3d3LmVkYy5jYS9lbi9hcnRpY2xlL3RoZS1yaXNlLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLmh0bWzSAQA?oc=5,The rise of artificial intelligence | EDC - Export Development Canada,2018-11-06,Export Development Canada,https://www.edc.ca,"Artificial intelligence has been described as both a risk and an opportunity. As Canada creates a leadership position, how can women be at the fore.","Build an Export Plan,Exporting 101,Article",Artificial intelligence has been described as both a risk and an opportunity.,Artificial intelligence has been described as both a risk and an opportunity.,http://schema.org,Article,,"{'@type': 'ImageObject', 'url': 'www.edc.ca/content/dam/edc/en/solution/the-rise-of-artificial-intelligence-ahero-t.jpg', 'width': '160', 'height': '90'}","{'url': 'https://www.edc.ca', '@type': 'Organization', 'name': 'Export Development Canada'}","{'@type': 'Organization', 'name': 'Export Development Canada', 'logo': {'@type': 'ImageObject', 'url': 'www.edc.ca/content/dam/edc/logo_EDC_Black.png', 'width': '160', 'height': '90'}}",The rise of artificial intelligence: Canada can lead with women at the fore,2019-06-11T09:41:10.446-04:00,2019-06-11T09:41:10.446-04:00,,,,,,,"
















TradeInsights


Article



The rise of artificial intelligence: Canada can lead with women at the fore








                
                
                    November 06, 2018
                
            AttentionThis content is over a year old, and the information within may be out of date.



                            Build an Export Plan
                        

Part 2 of 2 in series 












Retailing giant Amazon Inc. is a top of mind organization using artificial intelligence (AI) and machine learning (ML) to drive innovation and create market disruption. So it came as a bit of surprise when it was reported in October that the company had decided to scrap its new AI-driven recruiting tool. The tool was designed to give potential job candidates a rating from one to five stars, but the team behind the HR engine discovered it was not rating candidates for software developer and technical jobs in a gender-neutral way. Female candidates were consistently scored lower.
The reason? The tool was working with a dataset of resumes submitted to the company over a 10-year period, most of which came from men, reflecting male dominance in the tech industry. Even after neutralizing certain terms, the development team behind the tool could not guarantee it wouldn’t find other ways to introduce gender bias in hiring recommendations.
Amazon’s experience with the tool underscores both opportunities and risks involved with the emergence of AI into all aspects of business operations, from customer service to human resources. It also draws attention to the need for greater diversity and gender balance in the field of AI research itself and its applications.





        AI is driving innovation across industries and work functions
    



Using AI to drive innovation in companies and how AI is transforming the modern workforce are two themes of discussion at the Fortune Most Powerful Women Summit in Montreal on November 5-6. The location for these discussions was apt, given that Montreal is increasingly regarded as a leading global hub for research in artificial intelligence and machine learning.
Broadly speaking, artificial intelligence is the ability of a machine to observe information from its environment, which it can then use to learn, solve problems and make decisions. In many industries, AI is doing cognitive work that was formerly the province of human workers making decisions. These are just a few.

AI applications are common and growing in industries where there is already a labour shortage. Agriculture is a good example. Robots are being developed to harvest crops at higher volumes and at a faster pace than humans, perform crop and soil monitoring, and machine learning models are being developed to predict environmental impacts on crop yield.
 Industries ranging from retail to travel and hospitality that have high-touch customer service requirements are increasingly using chatbots as part of their customer experience.
Energy and mining companies are using cognitive AI to reduce friction from port scheduling and to track tankers to determine when they leave port, where they’re going, and how much petroleum or liquified natural gas they are transporting.
AI can be used in software development help. Functions here include modeling new applications with the right architecture and user experiences, or analyzing the business value and impact for the organization. 

The rise of automation and technology holds many potential advantages for Canadian exporters, including lower costs and new efficiencies.





        Risks of artificial intelligence
    



But automation also poses risks for the global economy.
Advances in AI and machine learning have accelerated in recent years, increasing the potential applications into areas long thought of as human-only jobs. Automation and technology is now considered one of the top risks Canadian exporters have to manage as they move into new markets.
If automation and technology expand at a rapid pace, large numbers of people could be quickly out of work.
The example of Amazon’s failed recruiting engine highlights another potential pitfall of artificial intelligence: biased data sets. IBM, for example, is working on building machines that apply human values and ethics to decision-making to overcome biases, such as gender bias.





        Women exporters and innovation
    



For Canadian companies looking to compete in the global economy, continual innovation is key to developing a unique selling proposition and maintaining relevance. Innovation is also closely tied to the success of your export strategy. In fact, research shows Canadian companies that sell outside of Canada are 25 per cent more innovative on average compared to companies that don’t.
Innovation can be a key to greater export success for Canadian women entrepreneurs. Our research shows that while 13.5 to 16% of Canadian SMEs are owned by women, only 7.5% of them sell their products or services outside of Canada. Women entrepreneurs face unique barriers to exporting and recognition of their innovation is one of them.
Research co-funded by BMO, the Government of Canada, Carleton University and The Beacon Agency found that most policies and financial assistance programs currently equate innovation solely with technological advances, and therefore don’t consider how women are innovating much more broadly. Additionally, many women entrepreneurs interviewed said they don’t feel welcome or included in the focus of mainstream networks, incubators and accelerators. They also feel there is an underrepresentation of female mentors and potential investors.





        Canada’s AI landscape
    



A major challenge for Canadian companies that want to leverage AI is talent. Research shows that 42% of startup businesses in Canada plan to adopt AI into their business, but face major barriers in the time, cost and skills required to keep up with rapidly advancing technology. Similarly, an IBM survey of 5,000 CEOs found that 63% say they lack the talent to confidently manage AI, while 60% say adoption has been hindered by customer trust and compliance concerns.
Development of AI capabilities and know-how for Canadian small and medium-sized business to help them scale and be globally competitive is central to the government’s innovation strategy.





        Pan-Canadian AI strategy
    



The Pan-Canadian Artificial Intelligence Strategy is designed to increase the number of highly-skilled researchers and graduates, by enhancing research capabilities and discoveries through collaboration across three centres of excellence. It also seeks to demonstrate global leadership around the economic, ethical, policy and legal implications of AI advancement.
The strategy is led by the Canadian Institute for Advanced Research (CIFAR) with $125 million support from the federal government.





        Canada’s AI Supercluster
    



As part of Canada’s Innovation and Skills plan the federal government has invested $950 million over five years to support business led innovation superclusters. One of the five superclusters is the AI-Powered Supply Chains Supercluster (SCALE.AI), based in Quebec and encompassing the Quebec-Windsor corridor.
The mission of SCALE.AI is to bring the retail, manufacturing, transportation, infrastructure, and information and communications technology sectors together to build intelligent supply chains through artificial intelligence and robotics. Its main goal is to help Canadian small and medium-sized businesses scale up and help ensure Canada is a globally competitive export leader. Over 100 companies, institutions and associations are working together to achieve this goal.
A key objective of SCALE.AI is fostering more diversity and inclusion in the field of AI through college and university curriculums and employee re-skilling programs.








Related topics
Build an Export Plan
Exporting 101




 





























Receive, via email, EDC’s TradeInsights e-newsletter, trade information and other promotional messages to make smarter export decisions.



By submitting this form, I consent to receive EDC’s e-newsletters, trade information and promotional messages, and can withdraw consent at any time.

Submit



Thank you for reaching out to EDC.
Please watch your inbox for our email.








","{'@type': 'WebPage', '@id': 'https://www.edc.ca/en/article/the-rise-of-artificial-intelligence.html'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMTEvMDcvYnVzaW5lc3Mvcm9ib3RpY3MtYXV0b21hdGlvbi1wcm9kdWN0aXZpdHktam9icy5odG1s0gEA?oc=5,When Robots Ring the Bell - The New York Times,2018-11-07,The New York Times,https://www.nytimes.com,A recent episode at the New York Stock Exchange was designed to prove that robots and people can happily coexist. Business research proves it’s possible — with certain caveats.,,A recent episode at the New York Stock Exchange was designed to prove that robots and people can happily coexist. Business research proves it’s possible — with certain caveats.,A recent episode at the New York Stock Exchange was designed to prove that robots and people can happily coexist. Business research proves it’s possible — with certain caveats.,https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/11/09/business/09productivity1/09productivity1-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2018/11/09/business/09productivity1/09productivity1-videoSixteenByNineJumbo1600.jpg', 'caption': 'One of Universal Robots’ collaborative robots recently rang the closing bell while surrounded by Robo Global executives in a celebratory moment at the New York Stock Exchange.', 'creditText': ''}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/11/09/business/09productivity1/09productivity1-superJumbo.jpg', 'height': 1366, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2018/11/09/business/09productivity1/09productivity1-superJumbo.jpg', 'caption': 'One of Universal Robots’ collaborative robots recently rang the closing bell while surrounded by Robo Global executives in a celebratory moment at the New York Stock Exchange.', 'creditText': ''}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': '', 'name': 'Janet Morrissey'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",When Robots Ring the Bell,2018-11-07T16:50:04.000Z,2018-12-05T18:36:56.000Z,,The New York Times,False,,Business,,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTWhen Robots Ring the BellShare full articleRead in appOne of Universal Robots’ collaborative robots recently rang the closing bell while surrounded by Robo Global executives in a celebratory moment at the New York Stock Exchange.By Janet MorrisseyNov. 7, 2018When Robo Global’s team recently gathered at the New York Stock Exchange to celebrate the fifth anniversary of its robotics index and exchange-traded fund, it marked the event in true robotic fashion: A robot, propped on a table, reached out its arm and rang the closing bell as 15 company executives applauded wildly next to it.This clever, eye-catching gesture was aimed to show the world how easy — and increasingly common — it is for humans to work alongside robots.“It was symbolic,” said Travis Briggs, chief executive of Robo Global’s operations in the United States. “We’re in the first inning of this transition to automation and artificial intelligence, and there is a massive amount of growth potential.”Indeed, robotics and automation are no longer viewed as a passing fad or a cool technology for geeks to gush over. Instead, more companies are turning to artificial intelligence to boost productivity and stay relevant in a fiercely competitive market. Experts call it the fourth industrial revolution and compare today’s robotics in the workplace to the early days of the internet.AdvertisementSKIP ADVERTISEMENTAt a recent conference hosted by Robo Global, experts showed photos and videos of robotic prototypes of all shapes and sizes: Robots that climb stairs and around corners to find an object and A.I.-laced pills that can retrieve foreign objects from a person’s stomach. They even included a video of a woman, with electrodes attached to her head, using thoughts to tell a robot where to place an object.“We’re starting to see robots and automated systems penetrate every sector of the economy,” said Jeremie Capron, director of research at Robo Global. “The pace of change is really accelerating, so, yes, it’s a revolution.”Robo Global, which researches, advises and invests in robotics, automation and A.I. companies, knows all about the sector’s growth. Since setting up its Robo Global Robotics & Automation Index ETF (Robo), which tracks more than 80 companies, the corporation reports that its assets have soared to $3.46 billion from $43 million its first year.Several other robotic ETFs, like iShares Robotics and Artificial Intelligence ETF (IRBO) and Global X Robotics & Artificial Intelligence Thematic ETF (BOTZ), have since been established to tap this growing sector.AdvertisementSKIP ADVERTISEMENTThe phenomenon strikes both admiration and fear into a nervous American work force: A video by Boston Dynamics, showing human-looking robots running and jumping over blocks, drew more than five million views on YouTube in one week this fall. Yet many Americans, who grew up watching science fiction and “Terminator” movies in which robots were the enemy, worry about robots stealing their jobs.“‘Terminator’ and those kinds of images have a significant impact on the way people perceive technology,” said Raffaello D’Andrea, professor of dynamic systems and control at ETH Zurich University, and a co-founder of Kiva Systems, a robotics company that was sold to Amazon.A recent report, “The Future of Jobs 2018,” by the World Economic Forum, forecasts that machines will perform more than half of all current workplace tasks by 2025, up from 29 percent today. It also predicts that 75 million jobs will be displaced by 2022, but that 133 million jobs will be created. Of the new jobs, 54 percent will require new skills.A McKinsey Global Institute report is gloomier, predicting that by 2030, as many as 800 million people worldwide may have been displaced by automation and will need to find new jobs.The retail giant Amazon was one of the earliest to embrace this technology, with its $775 million acquisition of Kiva — now called Amazon Robotics — in 2012. Amazon had been under pressure to deliver orders to its Amazon Prime customers within the promised 48-hour window without losing money, Mr. Capron said. Amazon immediately deployed 3,000 robots into its fulfillment centers.AdvertisementSKIP ADVERTISEMENT“We need advanced technology and automation to meet customer demand — it’s that simple,” said Tye Brady, chief technologist at Amazon Robotics.The robots wander up and down the aisles, bringing shelves of items directly to associates to package and ship, significantly slashing costs and shortening the time to process and deliver an order. Today, Amazon has more than 100,000 robots navigating 26 fulfillment centers around the world.ImageInside Amazon’s fulfillment center in Kent, Wash., where robots transport shelves of products to the people who will pack and ship them.Credit...Grant Hindsley/Agence France-Presse — Getty Images“Amazon delivered more than five billion items under two business days in 2017 to their Prime program members, based on our research, including discussions with Amazon Robotics,” Mr. Capron said. All of this bolstered customer loyalty and demand, resulting in more orders, sales revenue and jobs.Mr. Brady said it was a myth that automation always destroys jobs.“Since the acquisition of Kiva, we’ve added 300,000 full-time jobs globally,” he said. “Last year alone, we added 130,000.”AdvertisementSKIP ADVERTISEMENTAs robots have become faster, smaller, cheaper and safer in recent years, more and more companies — large and small — have been seeking robotics to step up productivity, increase precision or cut costs, said Stuart Shepherd, regional sales director for Universal Robots USA and chairman of the Association for Advancing Automation.The average hourly cost of a manufacturing worker to an employer is $36 in the United States, while the hourly cost of a robot is $4, according to a recent Pew Research report.All Axls Machining, a business in Dallas, was struggling to find enough workers to operate its metal-fabrication equipment and to sand and inspect metal parts manually for the medical, aerospace, defense and industrial sectors.Without workers to run the machines and the assembly lines, production lagged. “After 5 p.m., we’d have a skeleton shift, with only half the machines running,” said Gary Kuzmin, the company’s owner. “It was costing me orders that I couldn’t get to my customers on time.”But then Mr. Kuzmin discovered Universal Robots, which makes collaborative robots, or cobots, which are small, affordable and designed to operate safely side by side with workers. They are easy to program to do multiple tasks and allow the company to crank out parts around the clock.AdvertisementSKIP ADVERTISEMENTAfter introducing the robots, one job that was expected to take six months to complete was finished in less than half that time, Mr. Kuzmin said. “We saw a 60 percent profit increase on that job alone.”The company became so adept at programming the robots for different jobs that it formed an All Axls Robotics unit, which sells its specially programmed robots to other machine shops.Mr. Kuzmin said the increased productivity allowed him to hire — rather than fire — more workers, boosting his work force to 22 from 16.Early in 2017, another company, Zippertubing, of Chandler, Ariz., was having a tough time finding extra workers to help fulfill a big automotive order for its cable management products.“We had a lot of people who would come in, work for maybe a week, and then leave because they didn’t like the repetitive work environment,” said Tim Mead, operations manager at Zippertubing. It brought in Universal Robots’ cobots and immediately saw productivity surge.AdvertisementSKIP ADVERTISEMENT“It used to take three people to do all of the operations that the robot now does,” Mr. Mead saidThe robots have also increased the company’s accuracy in spotting faulty manufactured parts. When operators look at thousands of parts a day, they sometimes become “snow-blind” to defects, Mr. Mead said. But that never happens to robots.In certain sectors — consumer electronics, automobile manufacturing and logistics — “we’re moving into an era where automation has really gone from a competitive advantage right now to absolutely necessary,” Mr. Briggs said. “Automate or fail.”ImageA worker monitoring a robotic arm as it operates inside a factory in Huaian, China.Credit...ReutersAll of this has stoked fears, especially among Americans, that robots, automation and A.I. will throw millions of people onto the unemployment line.Some industry experts play down these concerns, saying that in any industrial revolution, jobs are lost and new ones created.AdvertisementSKIP ADVERTISEMENT“Fifty years ago, or even 15 years ago, who knew what an app developer was, or the amount of programming that we’d need,” Mr. Briggs said.Over the next decade, the biggest job losses will most likely affect low-skilled workers performing repetitive tasks, like machine operators, assembly line workers, dishwashers, drivers and preparers of fast food. Certain white-collar areas, like data entry, accounting and payroll, will suffer as well.Demand, however, will probably surge for data analysts, software developers, web designers, IT experts, e-commerce specialists, health care providers, entrepreneurs and social media experts, according to the World Economic Forum report. Sectors that involve human skills, like sales, marketing, customer service and even art and entertainment, will also be in high demand, the report said.While new jobs will offset losses, retraining and education will be critical. As many as 375 million workers globally will need to change job categories and learn new skills to survive the transition, according to the McKinsey Global Institute report.“The days are gone where somebody learns to do a task, and that’s what they do for the rest of their life,” Mr. D’Andrea said.AdvertisementSKIP ADVERTISEMENTHow quickly and how deeply A.I. and robotics penetrate the job market will ultimately dictate how rapidly people need to be retrained.“History tells me that every prior technological revolution has resulted in more wealth and more jobs,” Mr. Capron said. “So it would have to be very different this time around for history not to repeat itself.”But A.I. has its critics. The visionary billionaire Elon Musk has described it as humanity’s “biggest existential threat,” while the renowned physicist Stephen Hawking, who died this year, predicted that “the development of full artificial intelligence could spell the end of the human race.” Mr. Musk is particularly concerned about the use of A.I. to develop autonomous lethal weapons that could select targets without human intervention — a development with potentially apocalyptic repercussions.Mr. D’Andrea said A.I. was a long way off from being a real threat. He does believe, however, that regulations will be needed to safeguard its use in autonomous weapons.Mr. Briggs was less concerned. “I think Elon Musk is being overly dramatic,” he said, noting that he did not believe that A.I. should be regulated. “I think regulation is a slippery slope — it certainly stifles creativity.”A correction was made on Nov. 12, 2018: Because of an editing error, an earlier version of a picture caption with this article misstated the company that owns a robot that rang the bell at the New York Stock Exchange. It is owned by Universal Robots, not by Robo Global.A correction was made on Dec. 5, 2018: In an earlier version of this article, the second reference to a professor at ETH Zurich University and co-founder of Kiva Systems, a robotics company, was incorrect. It was Mr. D’Andrea, not Mr. Raffaella.When we learn of a mistake, we acknowledge it with a correction. If you spot an error, please let us know at nytnews@nytimes.com.Learn moreA version of this article appears in print on Dec. 16, 2018, Section F, Page 2 of the New York edition with the headline: When Robots Join the Work Force. Order Reprints | Today’s Paper | SubscribeShare full articleRead in appAdvertisementSKIP ADVERTISEMENTTell us about yourself. Take the survey.",https://www.nytimes.com/2018/11/07/business/robotics-automation-productivity-jobs.html,When Robots Join the Work Force,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vYmV0YWtpdC5jb20vZmlubi1haXMtbmF0YWxpZS1jYXJ0d3JpZ2h0LXdlaWdocy10aGUtYmVuZWZpdHMtb2YtZGF0YS1hbmQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,Finn AI's Natalie Cartwright weighs the benefits of data and artificial intelligence - BetaKit - Canadian Startup News,2018-11-07,BetaKit - Canadian Startup News,https://betakit.com,Finn AI co-founder Natalie Cartwright talks about building a company at the intersection of FinTech and AI.,"finn ai,natalie cartwright,dell small business,small biz stories,sponsored",Finn AI co-founder Natalie Cartwright talks about building a company at the intersection of FinTech and AI.,Finn AI co-founder Natalie Cartwright talks about building a company at the intersection of FinTech and AI.,https://schema.org,,,,,,,,,,,,,,,"
As part of a regular series powered by Dell Small Business, BetaKit asks business leaders to share their advice for growing small businesses.

Vancouver-based Finn AI is no stranger to scaling for success – the FinTech and AI company, which provides chatbots and personalized banking software for financial institutions, previously won the Serge Kampf Entrepreneurship and Innovation Award at Capgemini’s InnovatorsRace50. 
Fresh off the company’s recent $14 million Series A round of funding, co-founder and COO Natalie Cartwright discussed with BetaKit how she sees the future of consumer-facing artificial intelligence (hint: it’s not The Terminator), as well as better ways to serve data back to your customers.
What were some of the biggest struggles you had getting your business off the ground in the early days?
“I don’t think we’re going to reach the Terminator or anything, but it’s going to be other types of technologies where there’s lot of data and you can make predictions.”
I think it’s a bit of a catch-22 – once things are up and running, it’s not easy to maintain them, but the struggle is how you get from zero to 100. It’s about trying to grow a business incrementally, and that includes all the different stages: the financing, how do you get enough money to be able to grow, how do you get enough employees to be able to move, how do you get your product to a stage where it can actually be put forward? It’s all those different pieces, but it’s also trying to scale appropriately over the right amount of time.
A second big piece that’s undervalued is the psychological journey that you go through – the doubts, the fear, the excitement, the wins and losses. There’s lot of things that I think people speak to more often, but those were two pieces that I didn’t expect as much.
 How does Finn AI define its culture, and what does it do to foster that culture?
The fundamental vision of our company is to ensure the financial well-being of 100 million people by 2025. We do that through working with banks to help their users improve their financial well-being; we help banks move up the value chain. 
It’s not helping them with new channels or existing channels, but instead really thinking about how they can help people better manage their money with things like financial literacy coaches or information about what’s actually going on with bank accounts. We have this really nice opportunity where we can do something where you feel like you’re doing something good for the world, but it also solves a real business problem. 
I think the people and the culture are a real reflection of that, and also a reflection of the type of technology we work with, which is a lot of artificial intelligence and machine learning. We also have lots of stuff that isn’t artificial intelligence and machine learning, and that’s a scenario that’s very new and moving very quickly. We’re very much a learning organization where people are very eager to try new things.
Natalie Cartwright with co-founder Jake Tyler.
Another thing we’re focused on is making sure that we serve the world, too. We work with banks across four continents and in three languages. In our business, we really have to have a diverse workforce, so when we talk about diversity, we talk about that from different dimensions. When we think about diversity, it’s from the perspective of trying to bring a convergence of ideas around the table. We acknowledge that bringing together diversity on a number of dimensions is more challenging to put together, because we don’t necessarily share the same ideas, but that means we just talk with each other more. You fundamentally build a ground-layer respect in bringing so many different ideas, and bringing so many ideas together to solve big problems makes it stronger.
What do you think is the next big trend in technology and how will it impact the way we live and work? 
We work in artificial intelligence and in FinTech, but consumer expectations are really about to change. The way that I would describe it is that we’re at the stage of artificial intelligence – consumer-facing artificial intelligence – where we’re going to see it fail very quickly. It changes technology in that data becomes much more valuable than it’s ever been before, and consumers will be happy to share data with you to the extent that they think that you’re using the data to better serve them. So, I don’t think people are going to tolerate companies having that valuable data but not actually using it to better help consumers.
“I think what the next generation looks like is, ‘how happy did I make this customer today?'”
I think we’re going to see wins when people figure out how to use data to better serve people. Two great examples of that are Netflix recommendations and Spotify recommendations, where you get value out of them knowing what movies you’re watching or what music you’re listening to, because they can then serve you better recommendations.
That’s what we’re doing in the banking world. There’s lots of information about how you’re spending money, where you’re spending money, where you might be having trouble with your money, and there’s lots of ways to serve that data back to people in a proactive way, so they can avoid certain situations or optimize their finances. But the principle will be that you have to provide a much more proactive and predictive experience for customers when you’re using their data and that can play out in lots of different ways.
So where do you think the future is headed when it comes to artificial intelligence?
I don’t think we’re going to reach the Terminator or anything, but it’s going to be other types of technologies where there’s lot of data and you can make predictions. There’ll be an enhancement of AI, and what we’ll need more of is human deference around that, so it’s not like everything is suddenly AI. 
It’s very similar to when ATMs rolled out, and there was this narrative of “oh, now tellers will disappear.” But that’s not true – what happened was that people went to get their cash from an ATM, and the metrics for tellers weren’t, “how many customers did I serve today?” or “how many products did I serve today?” And I think what the next generation looks like is, “how happy did I make this customer today?”
",,,,,,,,,,,,,,,"[{'@type': 'BreadcrumbList', '@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://betakit.com/#listItem', 'position': 1, 'name': 'Home', 'item': 'https://betakit.com/', 'nextItem': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#listItem'}, {'@type': 'ListItem', '@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#listItem', 'position': 2, 'name': ""Finn AI's Natalie Cartwright weighs the benefits of data and artificial intelligence"", 'previousItem': 'https://betakit.com/#listItem'}]}, {'@type': 'NewsArticle', '@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#newsarticle', 'name': ""Finn AI's Natalie Cartwright weighs the benefits of data and artificial intelligence | BetaKit"", 'headline': 'Finn AI&#8217;s Natalie Cartwright weighs the benefits of data and artificial intelligence', 'author': {'@id': 'https://betakit.com/author/caitlin-hotchkiss/#author'}, 'publisher': {'@id': 'https://betakit.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://cdn.betakit.com/wp-content/uploads/2018/11/nataliecartwright.jpg', 'width': 715, 'height': 560, 'caption': 'natalie cartwright'}, 'datePublished': '2018-11-07T11:43:56-05:00', 'dateModified': '2018-11-07T11:44:24-05:00', 'inLanguage': 'en-CA', 'mainEntityOfPage': {'@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#webpage'}, 'isPartOf': {'@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#webpage'}, 'articleSection': 'Canadian Startup News, Technology, Small Biz Stories, Sponsored', 'dateline': 'Published on November 7, 2018.'}, {'@type': 'Organization', '@id': 'https://betakit.com/#organization', 'name': 'Betakit Inc.', 'description': 'Canadian Startup News & Tech Innovation', 'url': 'https://betakit.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.betakit.com/wp-content/uploads/2024/06/BetaKit.png', '@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#organizationLogo', 'width': 400, 'height': 400}, 'image': {'@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#organizationLogo'}, 'sameAs': ['https://www.youtube.com/user/Betakit/', 'https://www.linkedin.com/company/betakit']}, {'@type': 'Person', '@id': 'https://betakit.com/author/caitlin-hotchkiss/#author', 'url': 'https://betakit.com/author/caitlin-hotchkiss/', 'name': 'Caitlin Hotchkiss', 'image': {'@type': 'ImageObject', '@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#authorImage', 'url': 'https://cdn.betakit.com/wp-content/uploads/2021/12/Caitlin-Hotchkiss.jpg', 'width': 96, 'height': 96, 'caption': 'Caitlin Hotchkiss'}}, {'@type': 'WebPage', '@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#webpage', 'url': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/', 'name': ""Finn AI's Natalie Cartwright weighs the benefits of data and artificial intelligence | BetaKit"", 'description': 'Finn AI co-founder Natalie Cartwright talks about building a company at the intersection of FinTech and AI.', 'inLanguage': 'en-CA', 'isPartOf': {'@id': 'https://betakit.com/#website'}, 'breadcrumb': {'@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#breadcrumblist'}, 'author': {'@id': 'https://betakit.com/author/caitlin-hotchkiss/#author'}, 'creator': {'@id': 'https://betakit.com/author/caitlin-hotchkiss/#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://cdn.betakit.com/wp-content/uploads/2018/11/nataliecartwright.jpg', '@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#mainImage', 'width': 715, 'height': 560, 'caption': 'natalie cartwright'}, 'primaryImageOfPage': {'@id': 'https://betakit.com/finn-ais-natalie-cartwright-weighs-the-benefits-of-data-and-artificial-intelligence/#mainImage'}, 'datePublished': '2018-11-07T11:43:56-05:00', 'dateModified': '2018-11-07T11:44:24-05:00'}, {'@type': 'WebSite', '@id': 'https://betakit.com/#website', 'url': 'https://betakit.com/', 'name': 'BetaKit', 'description': 'Canadian Startup News & Tech Innovation', 'inLanguage': 'en-CA', 'publisher': {'@id': 'https://betakit.com/#organization'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmFiYy5uZXQuYXUvbmV3cy8yMDE4LTExLTA5L2NoaW5hLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW5ld3MtYW5jaG9ycy1yZXZlYWxlZC8xMDQ4MDczMNIBJ2h0dHBzOi8vYW1wLmFiYy5uZXQuYXUvYXJ0aWNsZS8xMDQ4MDczMA?oc=5,China's AI news anchor vows to 'work tirelessly to keep you informed' - ABC News,2018-11-08,ABC News,https://www.abc.net.au,"China's state-run Xinhua news agency releases footage of its newest stars: virtual news presenters, which use artificial intelligence to copy human voices and facial expressions.","deepfake,artificial intelligence,ai,virtual newsreader,china,technology,xinhua,news,journalism,anchor","China's state-run Xinhua news agency releases footage of its newest stars: virtual news presenters, which use artificial intelligence to copy human voices and facial expressions.",,http://schema.org,NewsArticle,,"{'@type': 'ImageObject', 'height': 485, 'url': 'https://live-production.wcms.abc-cdn.net.au/30d523e76cb7e252f0ce20f5e28b1640?impolicy=wcms_crop_resize&cropH=576&cropW=1023&xPos=0&yPos=0&width=862&height=485', 'width': 862}","{'@type': 'Organization', 'name': 'ABC News', 'logo': {'@type': 'ImageObject', 'height': 60, 'url': 'https://www.abc.net.au/res/abc/logos/amp-news-logo-60x240.png', 'width': 240}}","{'@type': 'Organization', 'name': 'ABC News', 'logo': {'@type': 'ImageObject', 'height': 60, 'url': 'https://www.abc.net.au/res/abc/logos/amp-news-logo-60x240.png', 'width': 240}}",China's AI news anchor vows to 'work tirelessly to keep you informed',2018-11-09T00:47:35+00:00,2018-11-09T00:50:02+00:00,,,,,,,"China's AI news anchor vows to 'work tirelessly to keep you informed'Posted Thu 8 Nov 2018 at 7:47pmThursday 8 Nov 2018 at 7:47pmThu 8 Nov 2018 at 7:47pm, updated Thu 8 Nov 2018 at 7:50pmThursday 8 Nov 2018 at 7:50pmThu 8 Nov 2018 at 7:50pmSorry, this video is not yet available or has expired Xinhua said the AI news presenters improve the more they broadcast.abc.net.au/news/china-artificial-intelligence-news-anchors-revealed/10480730Copy linkLink copiedShareShare articleChina's state-run Xinhua news agency has released footage of its newest stars: virtual news presenters which use artificial intelligence to copy human voices and facial expressions.Key points:Xinhua said the virtual anchors ""can work 24 hours a day""The news agency said the virtual anchors would help cut down production costsThe AI anchors are modelled on real life Xinhua news presentersThe pair of suit-wearing, male AI news anchors — one speaking Chinese and the other speaking English — made their debut at the World Internet Conference in east China's Zhejiang province.""Hello, you are watching English news program, I'm AI News anchor,"" the English speaking reader said at the beginning of its first broadcast.Can you spot a fake?Can't tell whether it's real or a completely computer-generated fake? Deepfakes explainedRead moreXinhua said its newest recruits ""can work 24 hours a day"", allowing it to cut down on production costs.Rounding out a two-minute bulletin, the English-speaking virtual newsreader said it would improve with experience.""As an AI news anchor under development, I know there is a lot for me to improve,"" the AI anchor said.In a separate introductory video, it added it would ""work tirelessly to keep you informed as texts will be typed into my system uninterrupted"".Xinhua developed the AI news anchors in cooperation with the Chinese search engine company Sogou.This article contains external content that failed to load. It may have been removed or is no longer available.According to the videos, the looks and features of the English-speaking anchor are based on the flesh-and-blood Xinhua news presenter Zhang Zhao, while the Chinese version is modelled on fellow Xinhua presenter Qiu Hao.Xinhua said the new digital presenters ""[learn] from live broadcasting videos"" by themselves.The agency said the readers ""can read texts as naturally as a professional newsreader"" — although that may be a matter of debate if their first bulletins are any indication.China is aiming to become a world leader in artificial intelligence by 2030, as the country aims to remodel itself as a high-tech powerhouse and move away from cheap manufactured goods.Posted 8 Nov 20188 Nov 2018Thu 8 Nov 2018 at 7:47pm, updated 8 Nov 20188 Nov 2018Thu 8 Nov 2018 at 7:50pmShareCopy linkFacebookX (formerly Twitter)Related StoriesChinese university recruits talented 'patriotic' teens to help develop AI weaponsCan you tell which world leader is real, and which was made by a computer?Made in China 2025: Forget cheap goods, think world's best artificial intelligenceMore on:ChinaJournalismMedia IndustryRoboticsTop StoriesThe 'army' being recruited for the next Trump presidencyDonald Trump picks Senator JD Vance as his nominee for vice-presidentDoctor claimed 21,000 COVID tests in a single day: How some pathology companies 'rorted' Medicare during the pandemicHow politics, engagement bait and money opened up a firehose of falsehoods after Trump's shootingJudge tosses Trump documents case, ruling prosecutor unlawfully appointedAustralian MP safety review after Donald Trump assassination attemptInvestors slash more than $200 million from value of land lease operator after ABC investigationWe came for the spectacle of a Trump rally. We left frazzled and shell-shockedJust after surviving a shooting, Trump's the star at the Republican National Convention. Here's what to expectSealed away in steel and concrete is Australia's nuclear waste legacyReady for the State of Origin decider? Here's what you need to know ahead of kick-offDemocracy is 'backsliding' and needs to adapt, Clare O'Neil warnsSpanish rescuers find remains thought to be of missing British teenager Jay SlaterTrump rally shooter's motives remain unknown as investigators find explosive materials in carVeteran sports commentator Bruce McAvaney picks up mic for Paris OlympicsPopular NowDon't miss news that matters to you. Log in to ABC today to get a more personalised experience tailored to your preferences.GET STARTED1.Donald Trump picks Senator JD Vance as his nominee for vice-president2.Judge tosses Trump documents case, ruling prosecutor unlawfully appointed3.The 'army' being recruited for the next Trump presidency4.Doctor claimed 21,000 COVID tests in a single day: How some pathology companies 'rorted' Medicare during the pandemic5.Bunnings under fire for selling plants that become 'a ticking time bomb'6.Investors slash more than $200 million from value of land lease operator after ABC investigationTop StoriesThe 'army' being recruited for the next Trump presidencyDonald Trump picks Senator JD Vance as his nominee for vice-presidentDoctor claimed 21,000 COVID tests in a single day: How some pathology companies 'rorted' Medicare during the pandemicHow politics, engagement bait and money opened up a firehose of falsehoods after Trump's shootingJudge tosses Trump documents case, ruling prosecutor unlawfully appointedJust InResearchers are helping people break a 'vicious cycle' of dental anxiety10m ago10 minutes agoMon 15 Jul 2024 at 3:36pmChina's renewable rollout is creating five large nuclear power plants' worth of capacity a week16m ago16 minutes agoMon 15 Jul 2024 at 3:30pmLandlords, agents call for more protection in proposed Tasmanian laws allowing pets in rentals17m ago17 minutes agoMon 15 Jul 2024 at 3:29pmDonald Trump picks Senator JD Vance as his nominee for vice-president24m ago24 minutes agoMon 15 Jul 2024 at 3:21pmMore Just InBack to top",https://www.abc.net.au/news/2018-11-09/china-artificial-intelligence-news-anchors-revealed/10480730,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LnRlbGVzdXJlbmdsaXNoLm5ldC9uZXdzL0NoaW5lc2UtU3RhdGUtTWVkaWEtRGVidXRzLUFydGlmaWNpYWwtSW50ZGVsaWdlbmNlLUFuY2hvci0yMDE4MTExMC0wMDAzLmh0bWzSAXRodHRwczovL3d3dy50ZWxlc3VyZW5nbGlzaC5uZXQvYW1wL25ld3MvQ2hpbmVzZS1TdGF0ZS1NZWRpYS1EZWJ1dHMtQXJ0aWZpY2lhbC1JbnRlbGxpZ2VuY2UtQW5jaG9yLTIwMTgxMTEwLTAwMDMuaHRtbA?oc=5,Chinese State Media Debuts Artificial Intelligence Anchor - teleSUR English,2018-11-10,teleSUR English,https://www.telesurenglish.net,"Xinhua noted advantages of&nbsp;the AI anchor, saying it &quot;can work 24 hours a day on its official website and various social media platforms, reducing news production costs and improving efficiency.&quot;&nbsp;","world’s first artificial intelligence television anchor, AI television anchor, Xinhua AI anchor","Xinhua noted advantages of&nbsp;the AI anchor, saying it &quot;can work 24 hours a day on its official website and various social media platforms, reducing news production costs and improving efficiency.&quot;&nbsp;","Xinhua noted advantages of the AI anchor, saying it ""can work 24 hours a day on its official website and various social media platforms, reducing news production costs and improving efficiency."" ",http://schema.org,NewsArticle,,"{'@type': 'ImageObject', 'url': 'https://www.telesurtv.net/__export/1541834352000/sites/telesur/img/news/2018/11/10/chinese_ai_anchor_x1x.jpg', 'height': '340', 'width': '600'}","{'@type': 'Person', 'name': 'teleSUR/GB'}","{'@type': 'Organization', 'name': 'teleSUR', 'logo': {'@type': 'ImageObject', 'url': 'https://www.telesurtv.net/arte/Logo-Telesur-web.png', 'width': '160', 'height': '68'}}",Chinese State Media Debuts Artificial Intelligence Anchor,2018-11-10T02:56:12 -0400,2018-11-10T02:56:00 -0400,News,,,,,,"







The West and the Majority World - Repression Versus Openn...
by
							
							
								
									 
								
									
										 teleSUR/MS 
									










Migration, Trump, Biden and What is to Come
by
							
							
								
									 
								
									
										 Jose Cabañas Rodriguez 
									



","{'@type': 'WebPage', '@id': 'https://www.telesurenglish.net/news/Chinese-State-Media-Debuts-Artificial-Intdeligence-Anchor-20181110-0003.html'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMimQFodHRwczovL25ld3MuYWJwbGl2ZS5jb20vbmV3cy93b3JsZC93YXRjaC1jaGluYS11bnZlaWxzLXJvYm90aWMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbmV3cy1hbmNob3Itc2F5cy13aWxsLXdvcmstdGlyZWxlc3NseS10by1rZWVwLXlvdS1pbmZvcm1lZC03NzgyODjSAZ0BaHR0cHM6Ly9uZXdzLmFicGxpdmUuY29tL25ld3Mvd29ybGQvd2F0Y2gtY2hpbmEtdW52ZWlscy1yb2JvdGljLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW5ld3MtYW5jaG9yLXNheXMtd2lsbC13b3JrLXRpcmVsZXNzbHktdG8ta2VlcC15b3UtaW5mb3JtZWQtNzc4Mjg4L2FtcA?oc=5,"WATCH: China Unveils ‘Robotic’ Artificial Intelligence News Anchor, Says ‘Will Work Tirelessly To Keep You Informed ’ - ABP Live",2018-11-09,ABP Live,https://news.abplive.com,"China's Artificial Intelligence News Anchor: In an introductory video, AI News Anchor  said: “I will work tirelessly to keep you informed as texts will be typed into my system uninterrupted.”","CHINA Artificial Intelligence ANCHOR, Artificial Intelligence, Artificial Intelligence news anchor, Xinhua Artificial Intelligence anchor","China's Artificial Intelligence News Anchor: In an introductory video, AI News Anchor  said: “I will work tirelessly to keep you informed as texts will be typed into my system uninterrupted.”","China's Artificial Intelligence News Anchor: In an introductory video, AI News Anchor  said: “I will work tirelessly to keep you informed as texts will be typed into my system uninterrupted.”",https://schema.org,NewsArticle,https://news.abplive.com/news/world/watch-china-unveils-robotic-artificial-intelligence-news-anchor-says-will-work-tirelessly-to-keep-you-informed-778288,"{'@type': 'ImageObject', 'url': 'https://static.abplive.com/wp-content/uploads/2018/11/09161719/ssssssssss.jpg?impolicy=abp_cdn&imwidth=1200&height=675', 'caption': '', 'description': '', 'width': '1200', 'height': '675'}","{'@type': 'Person', 'name': 'ABP News Bureau', 'url': 'https://news.abplive.com/authors/abp-news-bureau'}","{'@type': 'Organization', 'name': 'ABPLive', 'url': 'https://news.abplive.com', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.abplive.com/logo/live_600x60_bg.png', 'width': 600, 'height': 60}}","WATCH: China Unveils ‘Robotic’ Artificial Intelligence News Anchor, Says ‘Will Work Tirelessly To Keep You Informed ’",2018-11-09T16:21:56+05:30,2018-11-09T16:21:57+05:30,World Cup 2019,"WATCH: China Unveils ‘Robotic’ Artificial Intelligence News Anchor, Says ‘Will Work Tirelessly To Keep You Informed ’",,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://news.abplive.com', 'name': 'Home', 'image': 'https://cdn.abplive.com/logo/live_600x60_bg.png'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://news.abplive.com/news', 'name': 'News', 'image': 'https://cdn.abplive.com/logo/live_600x60_bg.png'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://news.abplive.com/news/world', 'name': 'World', 'image': 'https://cdn.abplive.com/logo/live_600x60_bg.png'}}]",,,,https://news.abplive.com/news/world/watch-china-unveils-robotic-artificial-intelligence-news-anchor-says-will-work-tirelessly-to-keep-you-informed-778288,,,,,,,"{'@type': 'ImageObject', 'url': 'https://cdn.abplive.com/logo/live_600x60_bg.png', 'width': '600', 'height': '60'}",,,,,,"['https://www.facebook.com/abplive', 'https://x.com/abplive', 'https://www.youtube.com/@abp_live', 'https://www.instagram.com/abplivenews/', 'https://in.pinterest.com/abplive_english/']",,"{'@type': 'SpeakableSpecification', 'xPath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}","NEW DELHI: With a robotic voice and awkward delivery, Xinhua, China’s state-run press agency, unveiled its new “AI anchors” in order to deliver headlines 24 hours a day. This “artificial intelligence news anchor” which is a lifelike digitised reporter, can read out text by mimicking a real human presenter. The new agency claims that the presenter “can read texts as naturally as a professional news anchor”.

According to reports from South China Morning Post, Xinhua said “AI anchors have officially become members of the Xinhua News Agency reporting team. They will work with other anchors to bring you authoritative, timely and accurate news information in both Chinese and English,”

Xinhua’s AI anchor has been modelled on Zhang Zhao, a human Xinhua presenter and AI claim that “I will work tirelessly to keep you informed as texts will be typed into my system uninterrupted.”



In order to watch the AI new presenter, the user will have to access Xinhua’s internet and mobile platforms. The new agency claims that their achievement is “breakthrough in the field of global AI synthesis.”",,,,,,,,,,,,,,,,,,"{'@type': 'SearchAction', 'target': 'https://news.abplive.com/search?q={search_term_string}', 'query-input': 'required name=search_term_string'}",,en,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmRxaW5kaWEuY29tL2NoaW5hcy1haS1uZXdzLWFuY2hvci1jcmVhdGluZy1yaXBwbGVzLXRyaWdnZXJzLW1hY2hpbmUtc3RlYWxpbmctam9icy1kZWJhdGUv0gFlaHR0cHM6Ly93d3cuZHFpbmRpYS5jb20vY2hpbmFzLWFpLW5ld3MtYW5jaG9yLWNyZWF0aW5nLXJpcHBsZXMtdHJpZ2dlcnMtbWFjaGluZS1zdGVhbGluZy1qb2JzLWRlYmF0ZS8?oc=5,"AI News Anchor Creates Ripples, Triggers Machine Stealing Jobs Debate - DATAQUEST",2018-11-09,DATAQUEST,https://www.dqindia.com,AI news anchor has managed to create ripples with people lauding the new technology but few raised concerns of technology stealing jobs meant for humans,,AI news anchor has managed to create ripples with people lauding the new technology but few raised concerns of technology stealing jobs meant for humans,AI news anchor has managed to create ripples with people lauding the new technology but few raised concerns of technology stealing jobs meant for humans,https://schema.org,ItemList,"['www.dqindia.com', 'https://www.dqindia.com/news', 'https://www.dqindia.com/interview', 'https://www.dqindia.com/opinion', 'https://www.dqindia.com/editors-blog', 'https://www.dqindia.com/features', 'https://www.dqindia.com/business-technologies', 'https://www.dqindia.com/dqdeeptech', 'https://www.dqindia.com/annuals', 'https://www.dqindia.com/tag/dq40years', 'https://www.dqindia.com/events', 'https://www.dqindia.com/business-solutions', 'https://tech4growth.dqindia.com/', 'https://dqconclave.com/', 'https://techschools.in/', 'https://resources.dqindia.com/dq-rsr/dataquestarchive/']",['https://img-cdn.thepublive.com/fit-in/1200x675/filters:format(webp)/dq/media/post_banners/wp-content/uploads/2015/03/smart-machines.jpg'],"[{'@type': 'Person', 'name': 'DQINDIA Online', 'url': 'https://www.dqindia.com/author/dq-online'}]","{'@type': 'Organization', 'name': 'DQ', 'SameAs': ['https://www.facebook.com/dataquestindia/', 'https://www.linkedin.com/company/dataquestindia/', 'https://twitter.com/dataquestindia', 'https://www.instagram.com/dataquestindia/', 'https://www.youtube.com/@dataquestindia9605', 'None'], 'logo': {'@type': 'ImageObject', 'url': 'https://img-cdn.thepublive.com/fit-in/600x60/filters:format(webp)/dq/media/agency_attachments/UPxQAOdkwhCk8EYzqyvs.png', 'width': 600, 'height': 60}}","AI News Anchor Creates Ripples, Triggers Machine Stealing Jobs Debate",2018-11-09T08:17:42+05:30,,,"['home', 'NEWS', 'Interview', 'Opinion', 'Editors Blog', 'Features', 'BUSINESS TECHNOLOGIES', 'DQDEEPTECH', 'ANNUALS', 'DQ40YEARS', 'EVENTS', 'BUSINESS SOLUTIONS', 'Tech4Growth', 'DQConclave Event Site', 'TechSchools Event Site', 'Magazine']",True,[],,,"






                                Business Technologies
                            




AI News Anchor Creates Ripples, Triggers Machine Stealing Jobs Debate
                        


AI news anchor has managed to create ripples with people lauding the new technology but few raised concerns of technology stealing jobs meant for humans
                            









DQINDIA Online






                                                    09 Nov 2018 08:17 IST
                                                































  Follow Us






























New Update










While the artificial intelligence invasion is a beneficial development, it has always brought along with it concerns of human jobs being occupied by machines. In a latest development, the World's first AI news anchor has been unveiled. Jointly developed by Xinhua and Chinese search engine company Sogou, the AI news anchor has a male image modeled on a real anchor with Xinhua called Zhang Zhao.
Advertisment


The AI news anchor imitates the voice, facial expressions and actions of a real person and looks like a professional news reader. The AI news anchor learns from live broadcasting videos and can read texts as naturally as a professional news anchor all by himself.
“The development of the media industry calls for continuous innovation and deep integration with the international advanced technologies. I will work tirelessly as texts will be typed into my system uninterrupted. I look forward to bringing you the brand new news experiences,” says the AI news anchor in a video shared by Xinhua News Agency on Twitter.
While the AI news anchor has managed to create ripples with people lauding the new technology, there are others who have raised concerns of such a technology stealing jobs meant for humans. “China Unveils An Artificial Intelligence Virtual News Anchor. The replacement of humans with AI programs for jobs is just a matter of time now,” says William Okafor, a web developer, on Twitter.
Advertisment

Several other are calling this development as an ‘exciting’ yet ‘scary’ technological advancement. “Who's that journalist who said our jobs were not at risk....yet? Hehehe. The revolution might actually be televised,” tweeted Moderator and Host at BBC Africa Georgie Ndirangu.
Nevertheless, there a few who are welcoming this development for it may prove to be extremely beneficial for cash strapped media houses. The AI news anchor can pick up news from across different platforms, work for 24 hours a day, improve efficiency, and get much better over the coming years thus saving media houses a lot of time and money. Although the artificial intelligence product currently looks dull and mechanical, experts are of the view that it will gradually get better and become more lifelike. “As an AI news anchor under development, I know there is a lot for me to improve,” says the AI news anchor in another video.
However, what do you as viewers have to say about this development? Will the advent of AI lead to job loss or create new jobs? Is it a necessary trend that will need to be adopted regardless of the collateral damage it may cause? Do let us know in the comment section below.




                                    ai-news-anchor

                                    artificial-intelligence


Advertisment
















Subscribe to our Newsletter!

              Be the first to get exclusive offers and the latest news













Subscribe Now
















Related Articles










































          LIVE
      




                                                      The Future of Money? Exploring the Potential of Gen AI in Fintech
                                                    












































          LIVE
      




                                                      Cloudera launches Enhanced Observability for Hybrid Data Centers
                                                    












































          LIVE
      




                                                      Future mobility: Quantum technologies on the campaign trail
                                                    












































          LIVE
      




                                                      Cloud and AI: A Match Made in Business Heaven, But Data Holds the Key
                                                    












































          LIVE
      




                                                      Integrating Responsible AI in Enterprises: A Strategic Imperative for Sustainable Growth
                                                    












































          LIVE
      




                                                      Modern Hospitality: How Marketing and Technology Drive Innovation
                                                    



















                    Read the Next Article
                     





","{'@type': 'WebPage', '@id': 'https://www.dqindia.com/chinas-ai-news-anchor-creating-ripples-triggers-machine-stealing-jobs-debate/'}",,,,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['//title', ""//meta[@name='description']/@content""]}",,,,,,,,,,,,,,,,,,,"{'@type': 'SearchAction', 'target': 'https://www.dqindia.com/search?title={search_term_string}', 'query-input': 'required name=search_term_string'}",,en,https://schema.org/NewsMediaOrganization,News,"{'@type': 'ImageObject', 'url': 'https://img-cdn.thepublive.com/fit-in/1200x675/filters:format(webp)/dq/media/post_banners/wp-content/uploads/2015/03/smart-machines.jpg', 'width': 1200, 'height': 675}",,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vd3d3LmFiYy5uZXQuYXUvbmV3cy8yMDE4LTExLTA5L2NoaW5hLXJlY3J1aXRzLXRhbGVudGVkLXRlZW5zLXRvLWhlbHAtZGV2ZWxvcC1haS13ZWFwb25zLzEwNDc3MDk40gEnaHR0cHM6Ly9hbXAuYWJjLm5ldC5hdS9hcnRpY2xlLzEwNDc3MDk4?oc=5,Killer robots: Chinese university recruits talented 'patriotic' teens to help develop AI weapons - ABC News,2018-11-08,ABC News,https://www.abc.net.au,A Chinese university is enlisting kids straight from high school to work on a new experimental program aimed at developing artificial intelligence (AI) based weapons.,"artificial intelligence,china,chinese military,us-china,ai weapons,killer robots,military technology,beijing institute of technology",A Chinese university is enlisting kids straight from high school to work on a new experimental program aimed at developing artificial intelligence (AI) based weapons.,,http://schema.org,NewsArticle,,"{'@type': 'ImageObject', 'height': 485, 'url': 'https://live-production.wcms.abc-cdn.net.au/aff28d81ee8e8aafb713d7fab84ea08c?impolicy=wcms_crop_resize&cropH=1279&cropW=2272&xPos=0&yPos=45&width=862&height=485', 'width': 862}","[{'@type': 'Person', 'name': 'Jack Kilbride'}]","{'@type': 'Organization', 'name': 'ABC News', 'logo': {'@type': 'ImageObject', 'height': 60, 'url': 'https://www.abc.net.au/res/abc/logos/amp-news-logo-60x240.png', 'width': 240}}",Killer robots: Chinese university recruits talented 'patriotic' teens to help develop AI weapons,2018-11-08T18:59:45+00:00,2018-11-08T18:59:45+00:00,,,,,,,"Killer robots: Chinese university recruits talented 'patriotic' teens to help develop AI weaponsBy Jack KilbridePosted Thu 8 Nov 2018 at 1:59pmThursday 8 Nov 2018 at 1:59pmThu 8 Nov 2018 at 1:59pm The US military have made developing AI robots a focus in recent years.(Supplied)abc.net.au/news/china-recruits-talented-teens-to-help-develop-ai-weapons/10477098Copy linkLink copiedShareShare articleA Chinese university has enlisted teenagers straight from high school to work on a new experimental program aimed at developing artificial intelligence (AI) weapons.Key points:The teenagers selected had to be bright and patrioticOnly 31 students were selected from among 5,000 candidatesUnited States is the world leader in AI weaponry, but China is closing inThe Beijing Institute of Technology (BIT) group of teenagers included 27 boys and four girls chosen to train as the world's youngest AI weapons scientists, according to the BIT website.Those selected for the ""experimental program for intelligent weapons systems"" were all under the age of 18 and carefully chosen from a list of 5,000 candidates, the BIT website said.One BIT professor who was involved in the screening process told the South China Morning Post that candidates needed to be more than just a bright student.""We are looking for other qualities such as creative thinking, willingness to fight, a persistence when facing challenges,"" the BIT professor told the Post, preferring to remain anonymous.""A passion for developing new weapons is a must … and they must also be patriots."" The inaugural class of BIT's experimental intelligent weapons program.(Supplied: Beijing Institute of Technology)The program, which launched on October 28, is the latest move in an international race to utilise AI technology for modern warfare, with the US and China leading the way.15-page resume for a 5-year-oldIn the cutthroat world of Chinese education, kids are not just expected to excel academically — they have to be the best at everything.Read more""We are walking a new path, doing things that nobody has done before,"" student representative Cui Liyuan said at the launch.""It sounds like a brag when you say we are leading the modern war trend … but we should be down-to-earth and inherit the spirit of the older generation … who are not afraid of difficulties and hardships.""According to the Post students on the course will be mentored by two senior weapons scientists, and after completing a semester of course work, be asked to choose a speciality field and be assigned to a relevant defence laboratory for hands-on experience.Following the four-year course, the students will then be expected to take on a PhD at the university and become China's next AI weapons leaders, according to the BIT website.China competing with the USSorry, this video is not yet available or has expired Autonomous weapons or 'killer robots' on the riseIn 2017, Chinese President Xi Jinping explicitly called for a greater national focus on military AI research.Earlier this year, Chinese scientists said they were developing ""giant"" AI submarines that can carry out complex missions without on-board human control, ready to deploy by 2020.China also has the world's largest testing facility for drone boats and has other projects focused on land and air-based drone weaponry.Get ready for the AI raceFrom truckies to lawyers and doctors, artificial intelligence will change every job and profession. Read all of Lateline's coverage of the AI race.Read moreIn a demonstration of China's expanding military technology, a Chinese state-owned company announced on Thursday that it was developing a stealth combat drone that could ""fly long hours, scout and strike the target when necessary"".But, despite their ramped up operations, the US still leads the world in the use of drone and AI technology for the military, utilising the expertise of companies Google and Boeing to develop new technology.According to the US Department of Defence, the US is developing a range of tactical robot strike teams, land based decision making robots, and mass drone 'swarms' that could overwhelm enemy bases with the ability to scramble communications.In September, the US Defence Advanced Research Projects Agency (DARPA) — which is tasked with ensuring the US is never ""the victim of strategic technological surprises"" — announced a $US2 billion ($2.7 billion) campaign to develop next wave of AI technologies that could be utilised in making, among other things, new age weapons. Drone technology is one of the main examples of AI at work in defence forces.(US Air Force: Tech Sgt. Effrain Lopez)The announcement came as thousands of scientists, engineers and entrepreneurs including Elon Musk signed a pledge to not work on entirely autonomous robotic weapons amid growing ethical concerns about the creation of killer robots.Posted 8 Nov 20188 Nov 2018Thu 8 Nov 2018 at 1:59pmShareCopy linkFacebookX (formerly Twitter)Related StoriesElon Musk wants to ban 'killer robots'. Here's why it's a bad ideaSouth Korea's top university denies developing killer robots'Killer robots' could be used in terrorism, tech leaders warnMore on:AsiaChinaDefence and National SecurityRoboticsUnrest, Conflict and WarTop StoriesThe 'army' being recruited for the next Trump presidencyDonald Trump picks Senator JD Vance as his nominee for vice-presidentDoctor claimed 21,000 COVID tests in a single day: How some pathology companies 'rorted' Medicare during the pandemicHow politics, engagement bait and money opened up a firehose of falsehoods after Trump's shootingJudge tosses Trump documents case, ruling prosecutor unlawfully appointedAustralian MP safety review after Donald Trump assassination attemptInvestors slash more than $200 million from value of land lease operator after ABC investigationWe came for the spectacle of a Trump rally. We left frazzled and shell-shockedJust after surviving a shooting, Trump's the star at the Republican National Convention. Here's what to expectSealed away in steel and concrete is Australia's nuclear waste legacyReady for the State of Origin decider? Here's what you need to know ahead of kick-offDemocracy is 'backsliding' and needs to adapt, Clare O'Neil warnsSpanish rescuers find remains thought to be of missing British teenager Jay SlaterTrump rally shooter's motives remain unknown as investigators find explosive materials in carVeteran sports commentator Bruce McAvaney picks up mic for Paris OlympicsPopular NowDon't miss news that matters to you. Log in to ABC today to get a more personalised experience tailored to your preferences.GET STARTED1.Donald Trump picks Senator JD Vance as his nominee for vice-president2.Judge tosses Trump documents case, ruling prosecutor unlawfully appointed3.Doctor claimed 21,000 COVID tests in a single day: How some pathology companies 'rorted' Medicare during the pandemic4.The 'army' being recruited for the next Trump presidency5.Bunnings under fire for selling plants that become 'a ticking time bomb'6.Investors slash more than $200 million from value of land lease operator after ABC investigationTop StoriesThe 'army' being recruited for the next Trump presidencyDonald Trump picks Senator JD Vance as his nominee for vice-presidentDoctor claimed 21,000 COVID tests in a single day: How some pathology companies 'rorted' Medicare during the pandemicHow politics, engagement bait and money opened up a firehose of falsehoods after Trump's shootingJudge tosses Trump documents case, ruling prosecutor unlawfully appointedJust InEnd of era as Wise family plans to sell all 39 hectares of farmland on prime Sunshine Coast site7m ago7 minutes agoMon 15 Jul 2024 at 3:52pmLady Macbeth is one of literature’s biggest female villains, two new works plug the gaps in her story9m ago9 minutes agoMon 15 Jul 2024 at 3:51pmEscaping the rat race and rental rut of city life, millennials are on the move again11m ago11 minutes agoMon 15 Jul 2024 at 3:48pmResearchers are helping people break a 'vicious cycle' of dental anxiety24m ago24 minutes agoMon 15 Jul 2024 at 3:36pmMore Just InBack to top",https://www.abc.net.au/news/2018-11-09/china-recruits-talented-teens-to-help-develop-ai-weapons/10477098,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9mZWF0dXJlZC1pbnNpZ2h0cy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9hcHBseWluZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mb3Itc29jaWFsLWdvb2TSAQA?oc=5,Applying AI for social good - McKinsey,2018-11-28,McKinsey,https://www.mckinsey.com,Using AI for social good could help solve some of the world’s most challenging problems. Here's how.,,Using AI for social good could help solve some of the world’s most challenging problems. Here's how.,Using AI for social good could help solve some of the world’s most challenging problems. Here's how.,https://schema.org,Discussion Paper,https://www.mckinsey.com,https://www.mckinsey.com/~/media/mckinsey/featured%20insights/artificial%20intelligence/applying%20artificial%20intelligence%20for%20social%20good/applying-artificial-intelligence-1536x1536-200.jpg,"[{'@type': 'Person', 'name': 'Michael Chui', 'url': 'https://www.mckinsey.com/our-people/michael-chui'}, {'@type': 'Person', 'name': 'Martin Harrysson', 'url': 'https://www.mckinsey.com/our-people/martin-harrysson'}, {'@type': 'Person', 'name': 'James Manyika', 'url': 'https://www.mckinsey.com/our-people/james-manyika'}, {'@type': 'Person', 'name': 'Roger Roberts', 'url': 'https://www.mckinsey.com/our-people/roger-roberts'}, {'@type': 'Person', 'name': 'Rita Chung'}, {'@type': 'Person', 'name': 'Pieter Nel'}, {'@type': 'Person', 'name': 'Ashley van Heteren'}]","{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,2018-11-28T00:00:00Z,2018-11-28T00:00:00Z,,,,,,,,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/featured-insights/artificial-intelligence/applying-artificial-intelligence-for-social-good'}",,,,,,,,,,,,,,,,,,2018-11-22T10:51:48Z,,,,,,Applying artificial intelligence for social good,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LmZtLW1hZ2F6aW5lLmNvbS9pc3N1ZXMvMjAxOC9kZWMvZXRoaWNhbC1pbXBsaWNhdGlvbnMtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UuaHRtbNIBAA?oc=5,Ethical implications of artificial intelligence - FM - FM | Financial Management,2018-11-30,FM | Financial Management,https://www.fm-magazine.com,"Executives must consider ethical matters related to AI and machine learning, such as algorithm bias and societal impact.",,"Executives must consider ethical matters related to AI and machine learning, such as algorithm bias and societal impact.",,http://schema.org,NewsArticle,,"{'@type': 'ImageObject', 'url': 'https://www.fm-magazine.com/content/dam/fmm/issues/2018/dec/ai-ethics-720.jpg', 'height': 380, 'width': 720}","{'@type': 'Person', 'name': 'By Jeff Drew, Ken Tysiac, and Samantha White'}","{'@type': 'NewsMediaOrganization', '@id': 'https://www.fm-magazine.com', 'name': 'FM | Financial Management magazine', 'logo': {'@type': 'ImageObject', 'url': 'https://www.fm-magazine.com/content/dam/fmm/icons/fm-logo-black-600.jpg', 'width': 600, 'height': 253}}",Ethical implications of artificial intelligence,2018-12-01T01:00:00.000-05:00,2018-12-01T01:00:00.000-05:00,,,,,,,"

        Ethical implications of artificial intelligence

            AI presents a new set of ethical challenges for business leaders whose deployment of mechanisation may have profound effects on the workforce and society.

            By Jeff Drew, Ken Tysiac, and Samantha White
1 December 2018
EthicsTechnology and analytics










In the race to adopt rapidly developing technologies, organisations run the risk of overlooking potential ethical implications. And that could produce unwelcome results, especially in artificial intelligence (AI) systems that employ machine learning.
Machine learning is a subset of AI in which computer systems are taught to learn on their own. Algorithms allow the computer to analyse data to detect patterns and gain knowledge or abilities without having to be specifically programmed. It is this type of technology that empowers voice-enabled assistants such as Apple's Siri or the Google Assistant, among myriad other uses. In the accounting space, the many potential applications of AI include real-time auditing and analysis of company financials.
Data is the fuel that powers machine learning. But what happens if the data fed to the machine are flawed or the algorithm that guides the learning isn't properly configured to assess the data it's receiving? Things could go very wrong remarkably quickly.
Microsoft learned this lesson in 2016 when the company designed a chatbot called Tay to interact with Twitter users. A group of those users took advantage of a flaw in Tay's algorithm to corrupt it with racist and otherwise offensive ideas. Within 24 hours of launch, the chatbot had said the Holocaust was ""made up"", expressed support for genocide, and had to be taken offline.
With regulatory and legal frameworks struggling to keep pace with the rapid pace of technological change, public demand is growing for greater transparency as to how these tools and technologies are being used. The UK's Institute of Business Ethics (IBE) recently issued a briefing urging organisations to examine the risks, impacts, and side effects that AI might have for their business and their stakeholders, as well as wider society. Tackling the issues requires these diverse groups to work together. (See ""10 Questions to Ask About Adopting or Using AI"", at bottom of page, for key considerations listed in the IBE report.)
The research identifies a number of challenges facing business leaders. These include:

What degree of control can we (as an organisation) retain over our machines' decision-making processes?
How can we ensure that the systems act in line with the organisation's core values?
Since biased algorithms can lead to a discriminatory impact, how can we ensure fairness and accuracy?

The report also encourages companies to ""improve their communications around AI, so that people feel that they are part of its development and not its passive recipients or even victims"". For this to be achieved, ""[e]mployees and other stakeholders need to be empowered to take personal responsibility for the consequences of their use of AI, and they need to be provided with the skills to do so"".
The report proposes a framework outlining ten core values and principles for the use of AI in business. These are intended to ""minimise the risk of ethical lapses due to an improper use of AI technologies"". The values are:

Accuracy.
Respect of privacy.
Transparency.
Interpretability.
Fairness.
Integrity.
Control.
Impact.
Accountability.
Learning.

Avoiding the 'black box' problem
Companies applying AI to the finance function face the challenge of designing algorithms that produce unbiased results and are not too complex for users to understand how they work and make decisions.
MindBridge Analytics, based in Ottawa, Canada, develops computer-aided audit tech powered by AI. The product uses a hybrid of advanced algorithmic techniques to enhance a human auditor's ability to detect and address unusual financial circumstances.
A key aspect of the MindBridge application is that it explains why certain transactions have been highlighted and then leaves final decision-making authority to a human, said chief technology officer Robin Grosset.
""The algorithms give weighted scores to features of transactions for subsequent human review in order to identify the risk of irregular circumstances,"" he said.
This transparency is essential to avoid the ""black box"" problem, in which a computer or other system produces results but provides little to no explanation for how those results were produced. In the case of machine learning, the greater the complexity of an algorithm, the more difficult it is for users to understand why the machine has made a certain decision.
""Almost all concerns that relate to 'improperly set up AI' can be solved by the AI explaining its thinking,"" Grosset said. ""If the human counterpart of the AI can understand why something is flagged, then they can make better informed decisions. Human judgement is still a key component of a balanced AI system.""
Avoiding bias in the data
Another challenge is to avoid bias in the algorithm and in the dataset the algorithm uses for learning.
One way of mitigating bias is to use combinations of learning types, including unsupervised learning, Grosset said. ""Supervised learning is based on label data, and often the labels themselves create bias,"" he said. ""Humans essentially bring their own biases to machine-learning scenarios. By contrast, unsupervised learning has no labels and essentially will find what is in the data without any bias.
""The key piece of advice here is to curate the data that is used as input to a system to ensure the signals in the data support the training objectives. For example, if you are creating an AI to automate driving a car, you want your AI to learn from good drivers and not from bad drivers,"" Grosset said.
MindBridge's testing process includes validation testing for algorithm intent, with regression testing. The process involves synthetic and real data.
Amy Vetter, CPA/CITP, CGMA, author of the book Integrative Advisory Services: Expanding Your Accounting Services Beyond the Cloud and CEO of The B3 Method Institute, advises organisations to seek alternative perspectives from professionals who do the work today that may be automated in the future.
""It's important to include them in the discussion and decision-making about how to incorporate prospective uses of AI into future workflow of the firm and what skills the staff will need so the appropriate training and goal setting is incorporated into any implementation plan,"" she said.
At MindBridge, the chief information security officer and chief technology officer are responsible for key aspects of technical use of AI and related privacy issues. The staff also includes research scientists who focus on privacy-preserving algorithm design.
Implications for society
AI provides a difficult set of ethical questions for society as well. One question centres on the preservation of the workforce. In the accounting profession, for example, AI can extract data from thousands of lease contracts to enable faster implementation of new lease accounting standards.
This can enable the people who would have handled data extraction to perform more complicated accounting tasks and perhaps even contribute to strategy. This can be a positive development as those people perform more meaningful work.
But if the people whose tasks are replaced by AI lose their jobs rather than being promoted to higher-level work, the implications for society can be ominous. If people who perform repetitive tasks across multiple professions and industries all lose their jobs instead of being promoted, implementation of AI could leave many people without options for work and damage their lives and the economy.
The trucking and haulage industry alone could experience enormous job losses if self-driving vehicles replace human drivers. In 2016, more than 3.3 million drivers were employed in trucking in the US and an additional 318,700 heavy goods vehicle drivers were working in the UK, according to the US Bureau of Labor Statistics and the UK Department for Transport.
""That creates an ethical problem without a shadow of a doubt, but also a pragmatic problem because these populations [people who perform tasks that can be automated] were in the heart of the economic system,"" said Jeremy Ghez, affiliate professor of economics and international affairs at HEC Paris — a management sciences teaching and research institute. ""And if they're not there anymore, then the system becomes unstable. There isn't anyone to sell stuff to.""
Ghez said it's understandable that businesses will look at AI as a way to cut costs. But he said it's also imperative for business leaders to be more imaginative with their human resources now, utilising more effectively the things that people can do — and machines can't do. The human skills of using intuition and building relationships with customers might be differentiators for businesses whose competitors may take automation to an extreme and perhaps frustrate customers with chatbots and other applications that remove a personal touch from customer-facing positions.
While businesses attempt to solve their own AI-related ethical issues, the public sector also will have a role to play. Regulators obviously will have a say in whether self-driving vehicles will be permitted on the roads. That will be the easy part. It will be more challenging to consider other issues such as workforce preservation and how to protect segments of the population that may be disadvantaged by biases in algorithms.
The technology may be here now, but the ethical rules for managing AI will take time to develop.
""It opens up a whole wide range of questions that the private sector is not going to feel very comfortable to answer immediately altogether,"" Ghez said. ""I think it's going to require a multidisciplinary effort and bridges to be built to figure out how to go to win-win situations.""

10 questions to ask about adopting or using AI
1. What is the purpose of our job, and what AI do we need to achieve it?
2. Do we understand how these systems work? Are we in control of this technology?
3. What are the risks of its usage? Who benefits and who carries the risks related to the adoption of the new technology?
4. Who bears the costs for it? Would it be considered fair if it became widely known?
5. What are the ethical dimensions, and what values are at stake?
6. What might be the unexpected consequences?
7. Do we have other options that are less risky?
8. What is the governance process for introducing AI?
9. Who is responsible for AI? Because machines are not moral agents, who is responsible for the outcome of the decision-making process of an artificial agent?
10. How is the impact of AI to be monitored?
Source: IBE Business Ethics Briefing, “Business Ethics & Artificial Intelligence”.

Jeff Drew is an FM magazine senior editor; Ken Tysiac is FM magazine's editorial director; and Samantha White is a writer and editor based in the UK. To comment on this article or to suggest an idea for another article, contact Jeff Drew at Jeff.Drew@aicpa-cima.com.


","{'@type': 'WebPage', '@id': 'https://www.fm-magazine.com/issues/2018/dec/ethical-implications-of-artificial-intelligence.html'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Executives must consider ethical matters related to AI and machine learning, such as algorithm bias and societal impact.",,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vd3d3LmJiYy5jb20vZnV0dXJlL2FydGljbGUvMjAxODExMjctdGhlLXdlaXJkLXdheS1tYWNoaW5lcy13aXRoLWFpLXNlZS10aGUtd29ybGTSAQA?oc=5,Why machines dream of spiders with 15 legs - BBC.com,2018-11-27,BBC.com,https://www.bbc.com,Look carefully at each of the following images – none of them show real things. They have all been dreamed up by a machine. And they provide insights into how our own brains work.,,Look carefully at each of the following images – none of them show real things. They have all been dreamed up by a machine. And they provide insights into how our own brains work.,Look carefully at each of the following images – none of them show real things. They have all been dreamed up by a machine. And they provide insights into how our own brains work.,https://schema.org,NewsArticle,,['https://ychef.files.bbci.co.uk/1280x720/p06t5404.jpg'],"{'@type': 'Person', 'name': 'Richard Gray', 'url': ''}","{'@type': 'Organization', 'name': 'BBC'}",Why machines dream of spiders with 15 legs,2018-11-27T17:39:50.000Z,2022-02-24T18:17:04.591Z,,,,,,,"Why machines dream of spiders with 15 legs27 November 2018By Richard Gray, @chalkmark, Features correspondentShareDeepMindLook carefully at each of the following images – none of them show real things. They have all been dreamed up by a machine. And they provide insights into how our own brains work.DeepMindAdvances in artificial intelligence are allowing algorithms to be trained to not only recognise objects in the world around them, but draw them too (Credit: DeepMind)Advances in artificial intelligence are allowing algorithms to be trained to not only recognise objects in the world around them, but draw them too. Much like a human artist, they can create images based on what they have seen.But rather than building up a picture with brush strokes, they do it pixel by pixel until they produce something of photographic quality. The resulting images look real at first sight, but closer inspection reveals something is very wrong with each big cat in these pictures.DeepMindAlgorithms like BigGan can reproduce textures but don't know that spiders should only have eight legs (Credit: DeepMind)How do we know that spiders have eight legs, or that cars need wheels that all point in the same direction in order to work properly? The answer lies in the information we begin to absorb about the world from an early age. The networks of neurons in our brains are shaped by the information sent to them by our eyes and our other senses as we experience our lives.Machine learning algorithms are trained in a similar way – they are shown many, many examples and slowly, over time, learn to recognise them. The main difference is that while our brains can learn from just a few examples, an AI requires millions before it starts to recognise patterns.DeepMindThe cars dreamed up by BigGan often have wheels in the wrong place and body shapes that seem to defy physics (Credit: DeepMind)These images were generated by an AI algorithm called BigGan, developed by researchers at DeepMind, the Alphabet-owned AI company. It is a type of machine learning approach that uses systems known as Generative Adversarial Networks, or Gans.These are algorithms that work in opposition to each other – one trained to produce images of objects and another that looks at what it has produced to spot the differences between the AI-generated pictures and those of real life objects. This network feeds back on itself, continually improving.“Over time, the model learns what these features are and how these features are composed,” says Andrew Brock, a computer scientist at Heriot-Watt University who helped to develop BigGan during a placement with DeepMind.But as we can see here, while it recognises that cars and school buses should have wheels and certain shapes of bodywork, it doesn’t quite understand how they fit together.DeepMindWould you want to get on board an aircraft or boat that looked like this (Credit: DeepMind)Few people would want to get on board an aircraft or a boat that looks like it defies the laws of physics.DeepMindThe BigGan algorithm often leaves out crucial details like eyes and beaks (Credit: DeepMind)All this training can help the AI to learn what features make an image compared to a square of random pixels. These features can be textures like fur or feathers, structures like a face, or building, or photographic elements like lighting or reflections.“Studying generative image models in isolation helps us tease out what they are currently good at understanding, and what they struggle with,” says Brock. “Two obvious examples with BigGan are that it’s good at generating textures like fur, grass and the sky, but it struggles with counting, hence spiders with too many legs.”This might be why at first glance the images look right, but on closer inspection we can see that something occurs too often, or is missing entirely.DeepMindElephants appear with too many legs, or no trunk (Credit: DeepMind)“There’s nothing in the BigGan algorithm that explicitly learns to count,” says Brock. “So, it doesn’t really have the capacity to say ‘there’s too many legs’ or ‘there’s not enough toes.’”DeepMindThe houses it creates have a dystopian feel to them (Credit: DeepMind)Where Gans appear to fall down is their understanding how things can vary when viewed from different angles, for example. The human brain is very good at this task: We can often imagine what might lie behind a newspaper behind held by someone on a train, for example, or roughly what shape a house might be if we are presented with one view of it.Machines are not so good at this. Instead, they rely upon the data they are trained on and variations in the angle or viewpoint can confuse it. To overcome this, the algorithm needs many more examples to learn. But researchers at DeepMind are already developing systems that can do some of this mental ‘filling in’ to help them produce more realistic images.DeepMindThe dogs look realistic but all have something out of place (Credit: DeepMind)Ask a four-year-old child to draw a dog and she’ll probably give you something that doesn’t look anything like man’s best friend. What it would have is the right number of legs, ears, eyes and a nose.AI algorithms, by comparison, can produce dogs that look very like the real thing, but should their eyes really be that high up on their face (top left) or should they have that many legs (bottom left)? Sometimes it decides to give them none of these things at all and concentrates on what it can do really well – fur.DeepMindThese poor dogs are missing eyes and legs (Credit: DeepMind)DeepMindPictures of Queen's guards and swimmers look terrifying (Credit: DeepMind)When it comes to replicating images of humans, AI can have mixed results. These BigGan images of members of the Queen's Guard look far from the well-polished facade of the real thing while the swimmers look like they have surfaced from some sort of surreal nightmare.According to Jeff Donahue and Karen Simonyan, who worked with Brock on BigGan, this is due to the high variation that exists between people in the first place. We all look different, so the algorithm gets confused about what a typical human should look like.“BigGan needs a lot more images than there are in the dataset we trained it on for the paper,” they say. But there are other Gans that are already producing photo-realistic pictures of entirely fictitious people (see “g is for…” in our recent a-z of AI).DeepMindBigGan can create beautiful looking soap bubbles but as it has never handled a wine glass or coffee cup, it does less well with this (Credit: DeepMind)Capturing something like the beauty of a soap bubble is something most of us would struggle with, but the AI does it almost perfectly here. Yet, never having drunk wine from a glass or a coffee cup, it struggles to know why the designs it comes up with are not ideal.“This model is only trained on still images, so it doesn’t learn anything about how objects move or interact with each other or the environment – it only sees snapshots,” says Brock. “It also doesn’t have any sort of decision making or interaction capabilities, so it can’t reach out and touch something in the image to see how the image would change.""DeepMindHaving never touched or handled objects, the AI does not learn in the same way as we do and has no concept how things work (Credit: DeepMind)""Exploration and observation is a big part of how we learn, but it’s not something that’s incorporated into this particular algorithm,” says Brock.DeepMindThese look like turtles, but on closer examination they are not (Credit: DeepMind)Producing near picture-perfect images is a useful parlour trick (although these turtles are far from perfect), but why train a machine to do this in the first place?“Looking forward, we expect our findings to be useful in the development of more complex intelligent systems,” says Brock. “For example, we would like to create models which understand the rich structure that underlies our complex visual world.”This would enable machines to start making more sense of the baffling, data-rich environment we live in. Our brains have an astonishing ability to make sense of this, picking out what it needs and discarding useless details.“Learning to generate realistic images is one way to do that,” adds Brock. “In order to draw something, one must, on some level, understand it.”DeepMindCats have odd features like their ears or eyes in BigGan's world  (Credit: DeepMind)With ears cocked at strange angles and eyes woefully misplaced, these cats are far from being unrecognisable – but they also look utterly wrong.Humans can almost instantly recognise a picture of a cat or dog. Images of these pets are among the most shared things on the internet. So why do machines seem to see them differently from us? DeepMindShopping trolleys in BigGan's world look a mess while teapots have an air of the improbable (Credit: DeepMind)“The kinds of deep learning neural networks used by today’s engineers operate nothing like the brain,” says Simon Stringer, head of the laboratory for theoretical neuroscience and artificial intelligence at the University of Oxford.The human brain, he explains, is able to understand the relationships between visual features at every scale in a scene. It can tell that an edge, for example, is part of one object, while another edge belongs to something else. An algorithm like BigGan does not understand this, and so it creates shopping trolleys that look like tangled messes and teapots that no-one would be able to drink from.“This obviously underpins the ability of the brain to interpret and make sense of complex visual scenes,” says Stringer.Solving this problem in AI could lead to smarter machines that can think far more like humans do.Artificial intelligence",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMimQFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Jlcm5hcmRtYXJyLzIwMTgvMTEvMzAvdGhlLWFtYXppbmctd2F5cy1ob3ctbWFzdGVyY2FyZC11c2VzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvLXN0b3AtZnJhdWQtYW5kLXJlZHVjZS1mYWxzZS1kZWNsaW5lcy_SAQA?oc=5,The Amazing Ways How Mastercard Uses Artificial Intelligence To Stop Fraud And Reduce False Declines - Forbes,2018-11-30,Forbes,https://www.forbes.com,Here we look at how financial services giant Mastercard uses artificial intelligence and machine learning to deliver a better customer experience by reducing false declines and by stopping fraud in real time.,,Here we look at how financial services giant Mastercard uses artificial intelligence and machine learning to deliver a better customer experience by reducing false declines and by stopping fraud in real time.,Here we look at how financial services giant Mastercard uses artificial intelligence and machine learning to deliver a better customer experience by reducing false declines and by stopping fraud in real time.,http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2018/11/30/the-amazing-ways-how-mastercard-uses-artificial-intelligence-to-stop-fraud-and-reduce-false-declines/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2018/11/AdobeStock_98231241-1200x800.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",The Amazing Ways How Mastercard Uses Artificial Intelligence To Stop Fraud And Reduce False Declines,2018-11-30T00:11:00-05:00,2018-12-12T09:41:23-05:00,Enterprise & Cloud,The Amazing Ways How Mastercard Uses Artificial Intelligence To Stop Fraud And Reduce False Declines,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryInnovationEnterprise TechThe Amazing Ways How Mastercard Uses Artificial Intelligence To Stop Fraud And Reduce False DeclinesBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 30, 2018,12:11am ESTUpdated Dec 12, 2018, 09:41am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinHaving a card transaction declined at the checkout can be a frustrating and embarrassing occurrence. So much so that it can seriously damage brand loyalty – according to research by Mastercard, a third of us have withdrawn our custom from a retailer due to our cards being refused.
Often this is due to the transaction being incorrectly flagged as fraudulent in some way – the algorithms which make the call on whether a payment is valid have erred on the side of caution, and sometimes they get it wrong.









Adobe Stock
Adobe Stock





Aside from the inconvenience, it causes us, the cost to businesses and the wider economy of these false declines is around $118 billion – an amount 13 times higher than the cost of actual card fraud.
PROMOTED
But fear not because, once again, AI has come to the rescue. Through its Decision Intelligence and AI Express platforms, Mastercard has used predictive analytics powered by machine learning to cut the rate that this happens by 50%.
I had the chance to speak to Ajay Bhalla, the company’s president for global enterprise, risk and security, about how this technology works and how AI is now helping Mastercard achieve more of its strategic objectives.
Real time analytics means more accurate results 
Bhalla tells me that the quantum leap in the ability to both detect fraud and reduce false declines has come about through its acquisition of California-based artificial intelligence specialists Brighterion.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Technology developed with Brighterion has enabled it to move to analysing data in real time. Machine learning algorithms must be incredibly efficient to handle the 75 billion transactions per year happening at 45 million global locations, which are processed by the Mastercard network.
Today, the decisions of whether or not to decline a transaction are based on a constantly flowing stream of data, and self-teaching algorithms, rather than a static sample dataset and fixed rules, which has had impressive results.
Bhalla tells me that the artificial intelligence systems, because they are self-learning, are always current and there is no longer a learning lag happening.
He states: “What it does is goes through billions of transactions and figures out what is the propensity of the transaction being fraudulent, and it gives this advice to the bank in the system, when the transaction goes through for authorisation.
“It’s helped us to catch billions of dollars’ worth of fraud.”
The system uses a real time stream of transactional data, along with external data including anonymised and aggregated customer information, and geographical information.
Geographical information is highly useful because not only does it give an overview of the types of transactions which are “normal” for a particular area, it also reveals what patterns of fraudulent activity are associated with it. Again, all of this information is aggregated in real time as it happens.
This means that patterns of fraud – which is often carried out at large scale by organised gangs, who will target businesses in a particular location, or attempt to “cash out” at ATMs spread across a city - can be detected, tracked and stopped.
“This is really good from a consumer standpoint because it means faster approval for the consumer, and it means more genuine transactions get approved. And merchants love it because for merchants, more approvals mean more business,” says Bhalla.
The challenges of AI
Building smart, automated systems has been a core strategy at Mastercard for many years, Bhalla tells me, but the acquisition of Brighterion and the incorporation of its technology into Mastercard systems has been a move towards “pure” AI. Many areas of its business, from customer service to anti-money-laundering measures, are set to benefit from an AI overhaul.
One key challenge has been ensuring a consistently high quality of data – as errors in transaction records or other data stores will inevitably lead to even the smartest machines making bad decisions.
Bhalla puts his company’s success with this down to the more than 50 years’ experience it has at generating and verifying transactional records – “We have been doing it for many, many years,” he tells me, “but that’s generally the challenge – you have to make sure your data is very, very good.”
A second challenge is determining the priorities when it comes to making decisions on where in the business to deploy potentially costly AI infrastructure.
A decision was made early on that increasing customer satisfaction levels was most likely to bring about the biggest long-term benefits.
“It’s a question of prioritisation – which are the five key things we need to solve?” Bhalla tells me.
“And you know, our biggest thing we wanted to solve is customer experience, making sure that when you’re doing a transaction at the point-of-sale, you’re able to do it seamlessly – that’s our first priority.”
Beating the money launderers
To tackle money laundering, many of the AI principles involved are similar to those used in reducing false declines.
AI algorithms examine patterns in the transaction data, enabling them to see when groups of people or businesses are acting in a co-ordinated way, to set up accounts and push through transactions which may involve dirty money.
Another technology – natural language processing (NLP) is also deployed here, however. NLP uses algorithms designed to interpret natural human language essentially allowing computers to understand what humans are saying. This means they can draw insights from speech and writing, rather than just the numbers and code they traditionally process.
NLP can detect and determine connections between names, and groups of people, and is useful in scenarios where groups of people often use false names and go by aliases, or just subtly alter the spelling of their name, to avoid detection.
The IoT – looking ahead…
As for the future, Bhalla says that he is certain AI is going to become increasingly essential across the entire financial services industry, as transaction numbers grow, more and more commerce is done digitally, and criminals become increasingly sophisticated.
In particular the growth of the Internet of Things (IoT) means that payment systems will have to handle an increasing number of automated transactions. This means AI routines will have to get stronger and faster to cope with the demand and increasingly complex use cases.
“The future world is getting more and more complicated – with your fridge making transactions, and your car driving itself to the charging station and making a transaction there.
“These are all going to be autonomous transactions – all the data that’s going to come out of these transactions will be very useful in helping us with our decisioning and also helping consumers manage their day-to-day lives better.”Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vbXl0ZWNoZGVjaXNpb25zLmNvbS9pdC1pbmZyYXN0cnVjdHVyZS9ob3ctZGVlcC1sZWFybmluZy1pcy1pbXByb3ZpbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,How Deep Learning is Improving Artificial Intelligence - TechDecisions,2018-11-26,TechDecisions,https://mytechdecisions.com,"Deep learning, machine learning, and artificial intelligence - it isn't always understood how these terms work together. Find out more about how deep learning plays into artificial intelligence.","['artificial intelligence', 'machine learning']","Deep learning, machine learning, and artificial intelligence - it isn't always understood how these terms work together. Find out more about how deep learning plays into artificial intelligence.",,https://schema.org,NewsArticle,http://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/,"{'@type': 'ImageObject', 'url': 'https://mytechdecisions.com/wp-content/uploads/2018/08/artificial_intelligence_brain.jpg'}","[{'@type': 'Person', 'name': 'Guest Authors'}]","{'@type': 'Organization', 'name': 'My TechDecisions', 'logo': 'https://mytechdecisions.com/wp-content/uploads/2017/03/cropped-TD-icon1-1.png'}",How Deep Learning is Improving Artificial Intelligence,2018-11-26T10:00:15Z,2018-11-26T10:00:15Z,IT Infrastructure,,,,,,"



IT InfrastructureHow Deep Learning is Improving Artificial Intelligence
Deep learning, machine learning, and artificial intelligence - it isn't always understood how these terms work together. Find out more about how deep learning plays into artificial intelligence.November 26, 2018 Catherine Metcalf 6 Comments  


Most people have a tendency to think of artificial intelligence (AI) in the context of science fiction, but it’s become a very real technology that’s having a significant impact on the world. From the chat programs that help us resolve customer service issues to incorporation during on-demand app development to the robots that work on assembly lines, AI is everywhere. Its prevalence is only going to increase as the technology continues to develop.
Deep learning is one of the key factors in the rapid expansion and improvement of AI capabilities. Here are a few ways deep learning is improving AI.
What is Deep Learning?
Deep learning is a subset of machine learning. With machine learning, an algorithm is designed to help a machine learn from data. Deep learning performs a similar task, but on a much larger scale. It works with more data and can also learn with a greater degree of independence.
One of the key features behind deep learning is the application of neural networks. Neural networks are computer system modeled after the human brain; they’re made up of nodes that perform a similar function to that of neurons in the brain. When the system is fed data, it creates networks between the nodes as it learns.
The Impact of Deep Learning
Technologies supported by deep learning are now moving into different areas of the lives of consumers. The following are a few examples of the deep learning technologies that are currently available:
Smart Homes
Common household items like thermostats, refrigerators, and lights are now connecting to the internet and using AI to offer increased efficiency and convenience to homeowners. These items can connect to systems that use deep learning to find patterns in human behavior to predict things like the need for heating and lighting. 
Speech Recognition
Natural Language Processing is a field of artificial intelligence that provides machines with the ability to process, understand, and generate human language. When you interact with something like Amazon Alexa or Siri, you are using a system that applies Natural Language Processing that is supported by deep learning algorithms.
Image Recognition 
Deep learning provides machines with the ability to recognize objects and images in ways that were previously impossible. 
A good example of this is the way Facebook can recognize the people in a photo without being told by the user. To do this, it creates templates of the faces and then uses deep learning to compare the templates and find a match. In the future, this deep learning capability could be used to train machines to analyze medical images and diagnose diseases with greater accuracy.
The Future of Deep Learning
Applications that depend on deep learning are going to become more common, and more businesses are going to experiment with this technology in the future. While this future is essentially inevitable, there are still some hurdles that need to be overcome.
The first is a matter of hardware. Neural networks are massive computer systems that are far more powerful and complex than anything most businesses would have access to. Additionally, these systems require incredible amounts of data in order to learn. For a business that is interested in deep learning, being able to provide the necessary hardware and data will be essential.

If you enjoyed this article and want to receive more valuable industry content like this, click here to sign up for our digital newsletters!






Tagged With: Artificial Intelligence, Machine LearningRelated Content: Top Three Network Concerns for Technology Decision Makers Four Questions to Guide High-Impact Enterprise AI Integrations Top AV/IT Integration Trends Shaping Enterprise Operations in…  5 Things You Need to Know About the… Free downloadable guide you may like:Practical Design Guide for Office SpacesRecent Gartner research shows that workers prefer to return to the office for in-person meetings for relevant milestones, as well as for face-to-face time with co-workers. When designing the office spaces — and meeting spaces in particular — enabling that connection between co-workers is crucial. But introducing the right collaboration technology in meeting spaces can […]Reader InteractionsComments




Jatin Bhalla says 
December 4, 2018 at 3:56 am 

Human is evolving yet in bringing technological revolutions. Artificial intelligence or AI is a technology that deals with computer science that directs in the making of intelligent machines that work and respond like humans. New technologies are emerging regularly using AI. This is wonderful article with upcoming AI projects. I am obliged for this information.

Reply






deep learning training in hyderabad says 
March 15, 2019 at 7:01 am 

Great Information useful to all the aspirants of deep learning!
Thank You!

Reply






naveen says 
March 27, 2019 at 6:59 am 

Thanks for sharing information about deep learning

Reply






Deep learning says 
April 4, 2019 at 1:04 pm 

As deep as we can get…

Reply


Trackbacks 



Overcome the Challenges of Deploying Artificial Intelligence - My TechDecisions says: 

December 4, 2018 at 2:00 pm 


[…] difficult is it to deploy artificial intelligence at your organization? Are you left scratching your head or just throwing up your arms in defeat? […]

Reply 





Google Artificial Intelligence Power Demonstrated in Object-Placing - My TechDecisions says: 

December 24, 2018 at 10:00 am 


[…] Related:How Deep Learning is Improving Artificial Intelligence […]

Reply 

 
Leave a Reply Cancel replyYour email address will not be published. Required fields are marked *Comment * Name * 
Email * 
Website 
 Save my name, email, and website in this browser for the next time I comment.
 

Δ 
","{'@type': 'WebPage', '@id': 'http://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/'}",,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/', 'url': 'https://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/', 'name': 'How Deep Learning is Improving Artificial Intelligence - My TechDecisions', 'isPartOf': {'@id': 'https://mytechdecisions.com/#website'}, 'primaryImageOfPage': {'@id': 'https://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://mytechdecisions.com/wp-content/uploads/2018/08/artificial_intelligence_brain.jpg', 'datePublished': '2018-11-26T10:00:15+00:00', 'dateModified': '2018-11-14T19:07:03+00:00', 'author': {'@id': 'https://mytechdecisions.com/#/schema/person/a5b79dad2e4aa577038397acdbe53cab'}, 'description': ""Deep learning, machine learning, and artificial intelligence - it isn't always understood how these terms work together. Find out more about how deep learning plays into artificial intelligence."", 'breadcrumb': {'@id': 'https://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/#primaryimage', 'url': 'https://mytechdecisions.com/wp-content/uploads/2018/08/artificial_intelligence_brain.jpg', 'contentUrl': 'https://mytechdecisions.com/wp-content/uploads/2018/08/artificial_intelligence_brain.jpg', 'width': 1000, 'height': 500}, {'@type': 'BreadcrumbList', '@id': 'https://mytechdecisions.com/it-infrastructure/how-deep-learning-is-improving-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://mytechdecisions.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How Deep Learning is Improving Artificial Intelligence'}]}, {'@type': 'WebSite', '@id': 'https://mytechdecisions.com/#website', 'url': 'https://mytechdecisions.com/', 'name': 'My TechDecisions', 'description': 'The end user’s first and last stop for making technology decisions', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://mytechdecisions.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://mytechdecisions.com/#/schema/person/a5b79dad2e4aa577038397acdbe53cab', 'name': 'Guest Authors', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://mytechdecisions.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/9bece1f833905603f2c8a0163f3a54b2?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/9bece1f833905603f2c8a0163f3a54b2?s=96&d=mm&r=g', 'caption': 'Guest Authors'}, 'url': 'https://mytechdecisions.com/author/guestauthors/'}]",,,https://mytechdecisions.com/wp-content/uploads/2018/08/artificial_intelligence_brain-150x150.jpg,2018-11-26T10:00:15Z,,,,,,,,,['Guest Authors'],,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMirgFodHRwczovL3d3dy5yZXNlYXJjaGdhdGUubmV0L3Bvc3QvV2lsbC10ZWNobm9sb2dpY2FsLWRldmVsb3BtZW50LXNlbGYtbWFsdGluZy1hbmQtcm9ib3RpemF0aW9uLUlULWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW1hY2hpbmUtbGVhcm5pbmctaW5jcmVhc2UtdW5lbXBsb3ltZW50LWluLXRoZS1mdXR1cmXSAQA?oc=5,"Will technological development, self-malting and robotization, IT, artificial intelligence, machine learning increase ... - ResearchGate",2018-11-26,ResearchGate,https://www.researchgate.net,"Read 20 answers by scientists with 2 recommendations from their colleagues to the question asked by Dariusz Prokopowicz on Nov 26, 2018",,"Read 20 answers by scientists with 2 recommendations from their colleagues to the question asked by Dariusz Prokopowicz on Nov 26, 2018","At present, the economies of developed countries are entering the period of the fourth technological revolution known as Industry 4.0.
The previous three technological revolutions:
1. The...",https://schema.org/,QAPage,https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{'@type': 'Question', 'name': 'Will technological development, self-malting and robotization, IT, artificial intelligence, machine learning increase unemployment in the future?', 'answerCount': 20, 'upvoteCount': 14, 'text': 'At present, the economies of developed countries are entering the period of the fourth technological revolution known as Industry 4.0.\nThe previous three technological revolutions:\n1. The industrial revolution of the eighteenth and nineteenth centuries, determined mainly by the industrial application of the invention of a steam engine.\n2. Electricity era of the late nineteenth century and early twentieth century.\n3. The IT revolution of the second half of the twentieth century determined by computerization, computerization, the widespread use of the Internet and the beginning of the development of robotization.\nThe current fourth technological revolution, known as Industry 4.0, is motivated by the development of the following factors:\n- artificial intelligence,\n- cloud computing,\n- machine learning,\n- Big Data database technologies,\n- Internet of Things.\nIn every previous technological revolution, the same question was repeated many times. However, economies developed and changed structurally and labor markets returned to balance. Periodically, short-term economic crises appeared, but their negative economic effects, such as falling income and rising unemployment, were quickly reduced by active state intervention.\nIt seems to me that self-malting and robotization, IT, artificial intelligence, learning machines will change the labor markets, but this does not necessarily mean a large increase in unemployment. New professions, occupations, specialties in these areas of knowledge and technology will be created. Someone, after all, these machines, robots, etc. must design, create, test, control, and implement into production processes.\nTherefore, I am asking you:\nWill the technological development based on self-mulization, robotization, IT development, artificial intelligence, machine learning increase unemployment in the future?\n\nPlease reply. I invite you to the discussion', 'dateCreated': '2018-11-26T22:10:11+00:00', 'dateModified': '2018-12-22T19:37:13+00:00', 'keywords': 'Database Technologies,Internet Technologies,Cloud Computing,Professions,Automation &#x26; Robotics,Autonomous Robot,Robot Vision,Technology,Science, Technology &#x26; Society Studies (STS),Unemployment,Future,Future Research,Labor,Labor Economics,Labor Market', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}, 'acceptedAnswer': {'@type': 'Answer', 'upvoteCount': 5, 'text': 'We do care AI and other Technological  approaches and apply them for better environment and humanity ,love and affection but still human is at the center as human intelligence is sentiment oriented and this will be lost or decay .Thus hybrid approach paradigms should be adopted .', 'dateCreated': '2022-03-15T01:58:31+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=622ff2c7682cdb6947257fe7', 'author': {'@type': 'Person', 'name': 's.M.Aqil Burney', 'url': 'https://www.researchgate.net/profile/Smaqil-Burney-2'}}, 'suggestedAnswer': [{'@type': 'Answer', 'upvoteCount': 2, 'text': 'Nothing can replace human but their people role will be changed', 'dateCreated': '2018-11-27T12:04:53+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5bfd32e5979fdc8e0c755c53', 'author': {'@type': 'Person', 'name': 'Anjay Kumar Mishra', 'url': 'https://www.researchgate.net/profile/Anjay-Mishra'}}, {'@type': 'Answer', 'upvoteCount': 1, 'text': 'Hi Dariusz, in  attach a paper on topic. \nI hope usefull... have a good day\nEmi', 'dateCreated': '2018-11-28T08:21:22+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5bfe5002a4714b355260ed69', 'author': {'@type': 'Person', 'name': 'Emiliano Mandrone', 'url': 'https://www.researchgate.net/profile/Emiliano-Mandrone'}}, {'@type': 'Answer', 'upvoteCount': 3, 'text': 'Yes if neither schools adjust the course and materials accordingly nor individuals seek training to upgrade skills in the short run. Labor shortage and unemployment can coexist. \n\nBut not in the long run as schools and individuals have enough time to adjust to that.', 'dateCreated': '2018-11-29T08:23:04+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5bffa1e8f0fb624a0f7c8209', 'author': {'@type': 'Person', 'name': 'Yi Zhang', 'url': 'https://www.researchgate.net/profile/Yi-Zhang-61'}}, {'@type': 'Answer', 'upvoteCount': 1, 'text': 'Which technologies will determine the development of civilization in the 21st century?\nIn my opinion, the combination of technologies typical of the technological revolution known as Industry 4.0 may turn out to be one of the key determinants of civilization progress in the 21st century.\nAt present, in the age of the technological revolution known as the 4.0 industry, new concepts of technological management or Internet-based companies are being created.\nThe technological revolution in recent years, known as Industry 4.0, is motivated by the development of the following factors:\nBig Data database technologies, cloud computing, machine learning, Internet of Things, artificial intelligence.\nIn addition, in the knowledge-based economy, the important areas of knowledge and technologies that are developed are primarily the development of data processing analytics in Business Intelligence enterprises, the development of life science technologies, biotechnology, eco-innovation, energy, medical intelligence, etc.\nOn the basis of the development of the new technological solutions mentioned in recent years, the processes of innovatively organized analyzes of large information collections gathered in Big Data database systems dynamically develop.\nIn view of the above, I would like to ask you: Which technologies will determine the development of civilization in the 21st century?\nPlease, answer, comments. I invite you to the discussion.', 'dateCreated': '2018-12-02T06:28:45+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5c037b9db93ecd185572bc4b', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}, {'@type': 'Answer', 'upvoteCount': 0, 'text': 'It is not easy to forecast development trends to answer this type of question:  Will  technological development, self-malting and robotization, IT,  artificial intelligence, machine learning increase unemployment in the  future? Many determinants affect the development of data processing platforms in the cloud, in Big Data technology, artificial intelligence, sentiment analyzes, etc.At present, in the age of the technological revolution known as the 4.0 industry, new technology management or Internet-based companies are emerging.\nThe technological revolution in recent years, known as Industry 4.0, is motivated by the development of the following factors:\nBig Data database technologies, cloud computing, machine learning, Internet of Things, artificial intelligence.\nAdded to this is the development of data processing analytics in Business Intelligence enterprises, the development of life science technologies, biotechnology, eco-innovation, energy, medical intelligence, etc.\nOn the basis of the development of the new technological solutions mentioned in recent years, the processes of innovatively organized analyzes of large information collections gathered in Big Data database systems dynamically develop.\nIn the context of this problem, many questions arise:\nWhat other technological improvements, innovative organizational, technical and IT solutions will be developed in the future based on the development of the above-mentioned factors?\nWhat kinds of innovations will be able to be created in the coming years, in the future based on the integration of the above-mentioned main determinants of the development of the current technological revolution known as Industry 4.0?\nWhat kind of new categories of added value may be created in the future if the above-mentioned technological solutions are more involved in the creation of biotechnological, ecological, product and other innovations.\nWill new technologies be created in this way, with the help of which it will be possible to generate solutions to the problems of excessive exploitation of Earth resources in the process of civilization development?\nDo business management processes play a particularly important role in the context of the effective functioning of business entities in currently developing economies based on knowledge, information and technology?\nIs e-management a new concept of managing virtual enterprises or rather managing online technology companies?\nAre new management concepts of innovative enterprises and start-ups based mainly on knowledge, information, entrepreneurship and creation of innovations?\nDoes the development of data processing technology in Big Data database systems and other technologies developed in the field of technological revolution Industry 4.0 generates the emergence of new business management concepts?\nPlease reply. I invite you to the discussion', 'dateCreated': '2018-12-02T06:32:07+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5c037c67f8ea52756a1a99c2', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}, {'@type': 'Answer', 'upvoteCount': 0, 'text': 'Perhaps the current technological revolution 4.0 will cause different effects on the labor market? \nThe above question inspired me to the following considerations:\nWhat  new professions will be created on the labor market in the future due  to the development of the Industry 4.0 technological revolution?\nThe technological revolution Industry 4.0 is currently one of the major determinants of the economic development of highly developed and developing countries.Therefore,  the issue of Industry 4.0 should be introduced as an additional subject  in studies in the fields of management, administration, economics, IT,  master of business administration, etc.In view of the above, I am asking you: What new professions will be created on the labor market in the future due to the development of the Industry 4.0 technological revolution?Please reply. I invite you to the discussion ', 'dateCreated': '2018-12-22T20:01:14+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5c1e980af0fb623dfd0361f7', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}, {'@type': 'Answer', 'upvoteCount': 1, 'text': 'Dear Friends and Colleagues of RG\nIn every previous technological revolution, the same question was repeated many times. However, economies developed and changed structurally and labor markets returned to balance. Periodically, short-term economic crises  appeared, but their negative economic effects, such as falling income  and rising unemployment, were quickly reduced by active state  intervention.\nIt  seems to me that self-malting and robotization, IT, artificial  intelligence, learning machines will change the labor markets, but this  does not necessarily mean a large increase in unemployment. New professions, occupations, specialties in these areas of knowledge and technology  will be created. Someone, after all, these machines, robots, etc. must  design, create, test, control, and implement into production processes.\n\nDo you agree with me on the above matter?\n\nPlease reply\n\nI invite you to the discussion\n\nBest wishes', 'dateCreated': '2019-02-09T01:17:09+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5c5e2a15d7141b92cb654bd5', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}, {'@type': 'Answer', 'upvoteCount': 1, 'text': 'Dear Dariusz, dear friends and colleagues, I attach a paper in which formal conditions for the emergence of either some of the possibilities you pose, or even alternative paths, can occur. The path may depend on very specific conditions shown in the paper.', 'dateCreated': '2019-02-09T23:45:52+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5c5f6630c7d8ab24626424dd', 'author': {'@type': 'Person', 'name': 'Deleted profile'}}, {'@type': 'Answer', 'upvoteCount': 0, 'text': 'In the context of the above considerations, I also propose the following research problem:\nWill as part of the progress in robotization create autonomous intelligent robots replacing people in many activities and functions?\n\nIn some activities it is possible and robots are already produced, which replace people in specific repetitive activities. \nHowever, will robots replace people in future in all activities and functions? \nIn my opinion, it is not possible for this type of futurological vision to be realized. \nPeople are afraid of such a scenario of the future development of civilization. \n\nThe expression of these fears is the predominance of negative futurological visions known from fictional literature and films that such a development of civilization in which autonomous robots replace people in almost all activities, difficult work, production processes and achieve a high level of artificial intelligence generates serious threats to humanity.\n\nPlease answer\n\nBest wishes', 'dateCreated': '2019-05-18T12:16:22+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=5cdff796a4714b1746199d55', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}, {'@type': 'Answer', 'upvoteCount': 1, 'text': 'It depends on many afctors, see the attached survey', 'dateCreated': '2021-12-27T12:54:37+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=61c9b78da55b0f35182541c8', 'author': {'@type': 'Person', 'name': 'Marco Vivarelli', 'url': 'https://www.researchgate.net/profile/Marco-Vivarelli'}}, {'@type': 'Answer', 'upvoteCount': 0, 'text': 'Dear Marco,\nThat&#x27;s right. Development of new information technologies ICT and Industry 4.0, including the development of machine-learning technologies, artificial intelligence, Internet of Things, cloud computing, Big Data, robotization, horizontal and vertical data system integration, multi-criteria simulation models, additive manufacturing, smart technologies, Virtual and Augmented Reality etc. and the increase in the scale of application of these technologies in business entities and institutions operating in various branches and sectors of the economy may significantly affect the labor markets in the future. However, it will also depend on many economic, social, demographic, etc. factors. As a result, the current long-term forecasts of future changes in the labor markets vary considerably. This differentiation concerns, for example, the issue of the potential loss of jobs by people employed in positions, which, according to certain forecasts, will change in the future as part of a greater use of technology and an increase in the scale of objectification of work in manufacturing processes, including production processes, and offering services provided in companies and enterprises.  \nThank you very much, \nRegards, \nDariusz', 'dateCreated': '2022-02-07T08:44:44+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=6200dbfce6bc3b57961a879e', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}, {'@type': 'Answer', 'upvoteCount': 3, 'text': 'Dariusz Prokopowicz What you stated is true; everytime there is technology revolution; there is hugh fear of unemployment. What I believe it that all above technologies would great new employment opportunities; however challenge this time would be for human workforce to come upto speed with transition. Since with the combination of AI, Robotics, IOT and so forth; solution development life cycle would be shortened; and new solutions would come up in much shorter timeframe; makes sure that existing once soon become legacy. So we as humans will have to buckle up and also prepare our future generations!', 'dateCreated': '2022-03-02T19:51:26+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=621fcabee8c1170ea60a7657', 'author': {'@type': 'Person', 'name': 'Dhaval Sahija', 'url': 'https://www.researchgate.net/profile/Dhaval-Sahija-2'}}, {'@type': 'Answer', 'upvoteCount': 2, 'text': 'Dear Dhaval Sahija,\nYes. I fully agree with what you wrote in this topic. The dynamic development of ICT and Industry 4.0 information technologies, including artificial intelligence, robotics, learning machines, the Internet of Things, smart technologies, Big Data, etc. causes and will cause changes in the labor markets in the coming years. On the one hand, some human occupations will be taken over by artificial intelligence and other Industry 4.0 technologies. On the other hand, new professions performed by people will be created, which will be a derivative of the integration of various Industry 4.0 technologies in their various new industrial and service applications.  \nThank you very much, \nBest regards, \nDariusz', 'dateCreated': '2022-03-05T08:33:45+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=62232069791f030c883866b7', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}, {'@type': 'Answer', 'upvoteCount': 3, 'text': 'The use of technology means less people required to do more work with consistency , accuracy in less time and less cost But human endeavour makes its own way.There is need of balance between technology and human effectiveness with creation.But  there is need of knowledge coupling of various attributes affecting technology and human ', 'dateCreated': '2022-03-14T17:51:18+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=622f8096f996945e8433cb08', 'author': {'@type': 'Person', 'name': 's.M.Aqil Burney', 'url': 'https://www.researchgate.net/profile/Smaqil-Burney-2'}}, {'@type': 'Answer', 'upvoteCount': 2, 'text': 'Dear S.M.Aqil Burney,\nThat&#x27;s right. As part of the rapid advances in technology, new Industry 4.0 technologies are being developed, including artificial intelligence, machine learning, robotization, the Internet of Things, cloud computing, Big Data Analytics, etc. These new technologies are used in various industries and branches of the economy. On a multi-annual scale, economies are undergoing structural sectoral and branch changes. Despite the fact that these technologies will cause changes in the labor markets also in the coming years, technological unemployment should not arise, because technological progress is also a source of new types of products, services, new professions, professions, professional specialties, etc.  \nThank you very much, \nBest wishes,  \nDariusz', 'dateCreated': '2022-03-20T17:29:01+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=6237645dbde62b146402919c', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}, {'@type': 'Answer', 'upvoteCount': 1, 'text': 'I think technological development, self-malting, and robotization, IT, artificial intelligence, machine learning will not affect unemployment in the future. It will give efficient and accurate solutions to real-world problems.', 'dateCreated': '2022-03-28T05:30:41+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=624148010a655914af3df71c', 'author': {'@type': 'Person', 'name': 'Prasad Patil', 'url': 'https://www.researchgate.net/profile/Prasad-Patil-17'}}, {'@type': 'Answer', 'upvoteCount': 1, 'text': 'Dear Prasad,\nThanks for your reply. Yes, other problems and crises are more likely to cause economic downturns, economic recessions and increased unemployment in the relatively short term than technological progress. In the longer, multi-year period, economies, through adjustments to their sectoral and industry structure, adapt to certain processes in operation, including the effects of technological progress, including the current fourth technological revolution based, inter alia, on the development of Industry 4.0 technology, including, inter alia, the development of technologies such as artificial intelligence, learning machines, the Internet of things, the development of robotisation, etc., and the development of the Internet of Things. On the other hand, the increasingly negative effects of climate change, including the progressive process of global warming, will be the source of a growing scale of various crises in the future, including food, economic, social, migration, natural, political, etc. crises. There may also be an increasing scale of economic downturns and recessions, which may result in periodic increases in unemployment. On the other hand, technological progress, in which new technologies and innovations are created, is also a source of increased efficiency in production processes, increased labour productivity, the creation of new professions, new sectors in the economy, etc.\n\nThank you very much,\n\nBest regards,\n\nDariusz\n', 'dateCreated': '2022-07-25T16:27:26+00:00', 'url': 'https://www.researchgate.net/post/Will-technological-development-self-malting-and-robotization-IT-artificial-intelligence-machine-learning-increase-unemployment-in-the-future#view=62dec46e23e8d7129f09850a', 'author': {'@type': 'Person', 'name': 'Dariusz Prokopowicz', 'url': 'https://www.researchgate.net/profile/Dariusz-Prokopowicz'}}]}",,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3LnBvcHVsYXJtZWNoYW5pY3MuY29tL21pbGl0YXJ5L25hdnktc2hpcHMvYTI1MzIyNjg0L3JlbW90ZS13YXJzaGlwcy1haS12ci_SAQA?oc=5,"Future Warships Could Be Sailed Remotely with Artificial Intelligence, Virtual Reality - Popular Mechanics",2018-11-27,Popular Mechanics,https://www.popularmechanics.com,The technology could allow naval personnel to remain on shore while operating warships at sea.,['content-type: News'],The technology could allow naval personnel to remain on shore while operating warships at sea.,,http://schema.org,NewsArticle,https://www.popularmechanics.com/military/navy-ships/a25322684/remote-warships-ai-vr/,"[{'@type': 'ImageObject', 'height': 1200, 'thumbnail': 'https://hips.hearstapps.com/hmg-prod/images/staff-at-bae-system-wave-as-duncan-the-type-45-destroyer-news-photo-849845812-1543349243.jpg?crop=0.65857xw:1xh;center,top&resize=100:*', 'url': 'https://hips.hearstapps.com/hmg-prod/images/staff-at-bae-system-wave-as-duncan-the-type-45-destroyer-news-photo-849845812-1543349243.jpg?crop=0.65857xw:1xh;center,top&resize=1200:*', 'width': 1200}, {'@type': 'ImageObject', 'height': 900, 'thumbnail': 'https://hips.hearstapps.com/hmg-prod/images/staff-at-bae-system-wave-as-duncan-the-type-45-destroyer-news-photo-849845812-1543349243.jpg?crop=0.65857xw:1xh;center,top&resize=100:*', 'url': 'https://hips.hearstapps.com/hmg-prod/images/staff-at-bae-system-wave-as-duncan-the-type-45-destroyer-news-photo-849845812-1543349243.jpg?crop=0.8781xw:1xh;center,top&resize=1200:*', 'width': 1200}, {'@type': 'ImageObject', 'height': 675, 'thumbnail': 'https://hips.hearstapps.com/hmg-prod/images/staff-at-bae-system-wave-as-duncan-the-type-45-destroyer-news-photo-849845812-1543349243.jpg?crop=0.65857xw:1xh;center,top&resize=100:*', 'url': 'https://hips.hearstapps.com/hmg-prod/images/staff-at-bae-system-wave-as-duncan-the-type-45-destroyer-news-photo-849845812-1543349243.jpg?crop=1xw:0.85412xh;center,top&resize=1200:*', 'width': 1200}]","{'name': 'Kyle Mizokami', 'url': 'https://www.popularmechanics.com/author/14085/kyle-mizokami/', '@type': 'Person', 'description': ""<p>Kyle Mizokami is a writer on defense and security issues and has been at <em>Popular Mechanics</em> since 2015. If it involves explosions or projectiles, he's generally in favor of it. Kyle’s articles have appeared at <em>The Daily Beast, U.S. Naval Institute News, The Diplomat, Foreign Policy, Combat Aircraft Monthly, VICE News</em>, and others. He lives in San Francisco.</p>"", 'image': 'https://hips.hearstapps.com/rover/profile_photos/bf2f096f-4d0a-456b-a131-44babf768632.jpg', 'sameAs': ['www.twitter.com/kylemizokami']}","{'@type': 'NewsMediaOrganization', 'name': 'Popular Mechanics', 'sameAs': ['https://twitter.com/PopMech', 'https://www.tiktok.com/@popularmechanics', 'https://www.youtube.com/c/popularmechanics', 'https://www.facebook.com/popularmechanics', 'https://www.instagram.com/popularmechanics/', 'https://www.pinterest.com/popmech/'], 'logo': {'@type': 'ImageObject', 'url': 'https://www.popularmechanics.com/_assets/design-tokens/popularmechanics/static/images/logos/logo-jsonld.2362803.png', 'width': 312, 'height': 60}, 'parentOrganization': {'@type': 'NewsMediaOrganization', 'name': 'Hearst Corporation'}}","Future Warships Could Be Sailed Remotely with Artificial Intelligence, Virtual Reality",2018-11-27T22:26:51.660062 EST,,Military,,False,,Naval Vessels,,,"{'@id': 'https://www.popularmechanics.com/military/navy-ships/a25322684/remote-warships-ai-vr/', '@type': 'WebPage'}",,"[{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.content-container'}]",,,,,,,,,,,,,,"Navies of the future could use technology to allow sailors to work remotely. Technologies such as artificial intelligence and virtual reality would allow some crew members to work from shore, operating key sections of ships from thousands of miles away. The result could be semiautonomous warships that sail with smaller crews, putting fewer in harm’s way.The Telegraph reports that the Royal Navy could use A.I. and VR tech in the future to reduce the size of ship’s crews. The principle is similar to that used by unmanned aerial vehicle operators who control drones flying thousands of miles away. Sailors who can do their jobs remotely, such as operating sensors or weapons, could do so from bases on land where they are safe from enemy fire. Even ship captains could remain on shore, commanding their ships from naval bases on land. According to The Telegraph, BAE Systems has been pitching the concept as something useful to the UK Royal Navy. “Unlike on-board control rooms where officers are usually seated, in case the ship is struck by an enemy munition that would knock them off their feet, in an on-land control room officers could be allowed to walk freely around the room,” the newspaper quoted a BAE representative as stating. Aircraft were logically the first weapon systems to be remotely operated. Airplanes typically fly with small crews of two or less, fly short missions that don’t require maintenance, and are relatively disposable. Ships on the other hand are operated by crews numbering in the dozens to manage hundreds of tasks, remain at sea for months on end, require maintenance by trained personnel often while hundreds of miles from shore, and can easily cost a half-billion dollars or more. The complexity involved with operating warships is a tall order for A.I.- and VR-equipped sailors or land.Another problem with some ship personnel working from shore: Navies need to assume that their warships will be jammed or forced to operate without emitting radar and communications signals that enemy forces could use to locate them. Warships could also be jammed by the enemy or sustain damage that knocks out power or communications. If the link between ship and shore goes down, those jobs outsourced to land-based personnel don’t get done, at the worst possible time. In the meantime, BAE Systems is experimenting with augmented reality onboard the ship, allowing an “Officer of the Watch, responsible for the ship’s safety, to work outside of the operations room and still be able to see tactical data and other vital information.” The technology will use Microsoft’s Hololens and will debut at the Royal Navy’s Information Warrior 19 exercises in 2019. Source: The Telegraph","https://hips.hearstapps.com/hmg-prod/images/staff-at-bae-system-wave-as-duncan-the-type-45-destroyer-news-photo-849845812-1543349243.jpg?crop=0.65857xw:1xh;center,top&resize=100:*",,,,,,,,https://www.popularmechanics.com/military/navy-ships/a25322684/remote-warships-ai-vr/,,,,,,,,,,,,,,,,,444.0,,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMTEvMjYvc3R5bGUvaGFpci1jYXJlLWN1c3RvbWl6ZS5odG1s0gEA?oc=5,Can Artificial Intelligence Eliminate Your Bad Hair Days? (Published 2018) - The New York Times,2018-11-26,The New York Times,https://www.nytimes.com,That’s the premise behind one of the hottest developments in the beauty business: customizable hair care.,,That’s the premise behind one of the hottest developments in the beauty business: customizable hair care.,That’s the premise behind one of the hottest developments in the beauty business: customizable hair care.,https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/11/29/fashion/29SKINDEEP-Customized/29SKINDEEP-Customized-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2018/11/29/fashion/29SKINDEEP-Customized/29SKINDEEP-Customized-videoSixteenByNineJumbo1600.jpg', 'creditText': 'Jeff Hinchee'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/11/29/fashion/29SKINDEEP-Customized/merlin_147164883_2e6853d4-c5e8-49a6-adf0-52ef09449268-superJumbo.jpg', 'height': 2048, 'width': 1463, 'contentUrl': 'https://static01.nyt.com/images/2018/11/29/fashion/29SKINDEEP-Customized/merlin_147164883_2e6853d4-c5e8-49a6-adf0-52ef09449268-superJumbo.jpg', 'creditText': 'Jeff Hinchee'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': '', 'name': 'Courtney Rubin'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",Can Artificial Intelligence Eliminate Your Bad Hair Days?,2018-11-26T20:10:03.000Z,2018-11-27T15:33:34.000Z,,The New York Times,False,,Style,,"AdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTSkin DeepCan Artificial Intelligence Eliminate Your Bad Hair Days?That’s the premise behind one of the hottest developments in the beauty business: customizable hair care.Share full articleRead in appCredit...Jeff HincheeBy Courtney RubinNov. 26, 2018When Renée Bibby has a good hair day, people stop her on the street and tell her they love her short curly hair. On a bad hair day, though, “I look like a dandelion puff,” said Ms. Bibby, 41, a graphic designer in Tucson. Over the years, Ms. Bibby, who is of mixed race descent and describes her hair as “coarse, but not black hair,” has spent hundreds of dollars trying products to maximize the good days and minimize the bad. Six months ago, she found a winner: a custom-made $25 conditioner from a start-up called Prose. (She does not shampoo her hair.)“The first day I used it, I got out of the shower and the curl was already in my hair,” said Ms. Bibby, who used to have to work to bring the curl back. “It’s probably taken 10 minutes off my routine.”Prose, whose founders include a former L’Oréal vice president, uses a quiz, artificial intelligence algorithms and a 6,000-square-foot production space in the Sunset Park section of Brooklyn to create what it hopes is each customer’s ideal product. AdvertisementSKIP ADVERTISEMENTThe company has shipped 110,000 bottles and will reach $1 million in monthly sales by its first birthday in January, and it is one of the biggest and most successful entrants in what has fast become one of the hottest spaces in the beauty industry: customizable hair care. On Monday the company announced that it had raised $18 million in new funding.Another start-up, the four-year-old Function of Beauty, uses its own quiz and algorithms (along with a Willy Wonka-esque 50,000-square-foot factory of custom-built machines). It has sold a million bottles, according to Zahir Dossa, a Massachusetts Institute of Technology-trained computer scientist and the company’s chief executive. (Prices start at $36 for an eight-ounce set of shampoo and conditioner.)There is more competition coming. Schwarzkopf, a global cosmetics giant, is conducting trials of custom products in Japan (with plans to bring them to the United States). Its system includes a hand-held device with an infrared sensor that can detect the hair’s molecular structure and analyze its moisture levels. An in-salon machine that looks like the world’s fanciest coffee maker whips up products in 50 seconds, along with a label printed with a bar code for reordering.Unlike brands that offer different products for each hair “goal” (say, preserving color or thickening hair), companies that customize say they can combine ingredients that will fulfill all your hair needs in a single shampoo, conditioner or hair mask. Prose also adjusts based on environmental factors, which it gleans from your ZIP code. For example, if it thinks you may be spending a lot of time in indoor heating because it’s cold outside, it adds corn derivatives that smooth and condition to fight static.AdvertisementSKIP ADVERTISEMENT“We tackle all your problems,” said Arnaud Plas, the chief executive of Prose, sitting in the company’s SoHo conference room, which is decorated with illustrations of coconut, mint and other good-for-hair ingredients. “We’re not going to make you compromise.” (The company says it has tested which ingredients could cancel one another’s benefits.)It’s probably not surprising that there are skeptics. Maryanne Senna, a dermatologist and the director of the Hair Academic Innovative Research Unit at Massachusetts General Hospital in Boston, is unconvinced that customizable shampoos and conditioners work much better than standard ones.“There are some things we very clearly know can be drying, but then there’s a lot of stuff they use that has no evidence to back it up,” Dr. Senna said. “Whether it’s the hair holy grail comes down to perception.” Unless patients have very oily hair or dandruff or a known sensitivity or allergy, she does not recommend specific products. She tells them that everyone is different, and they have to find one that works for them.Perry Romanowski, a cosmetic chemist and a founder of thebeautybrains.com, a site where scientists examine product ingredients and industry claims, called customization “a marketing gimmick.”“There is nothing measurably different about their formulas in terms of performance,” Mr. Romanowski said.AdvertisementSKIP ADVERTISEMENTHe has run blinded home-use tests of the 10 top-selling shampoos and conditioners. Pantene turned out to make the best performing product. Moreover, he found that expensive shampoos don’t work better than cheap ones, but expensive conditioners work better than really inexpensive ones, like V05 or Suave, he said. That’s because the pricey conditioners have more types of nourishing ingredients, which all work differently, and together are more effective. Still, he said, “super-expensive ones aren’t better than Pantene.”But this is where things get knotty. A major driver of whether a product works — or really, whether a customer thinks it does — is fragrance, which of course has no visible effect (unless you’re allergic to it). In its early days, Function of Beauty had to spend more time tweaking scents than algorithms.“Man, people care a lot more about fragrance than I ever thought they would,” said Mr. Dossa, who, when he started the company, had a shaved head, but now has a man bun so he can test products. “Customers won’t properly assess your product if they’re not happy with the fragrance.”Prose does not offer customers who want a moisturizing shampoo the option of choosing a citrus fragrance. Mr. Plas learned from his time at L’Oréal that customers will insist the product doesn’t work because they associate that smell with grease removal. “Then we give them the exact same formula with a different scent, and they think it’s great,” he said, shaking his head.Another thing customers can’t (yet) choose easily: to ban a particular ingredient because of allergies and sensitivities. (Function of Beauty is vegan and gluten free; Prose allows you to choose those options. Both allow you to avoid fragrance, but you have to contact customer service to ban a specific ingredient.) AdvertisementSKIP ADVERTISEMENTLacey Harris, 35, an athletic trainer in Lemoore, Calif., is allergic to coconut oil, an ingredient contained in her Function of Beauty products. She switched to Prose, which, purely by luck, didn’t add that to her shampoo and conditioner.Ms. Harris said she could really tell how much volume and wave the Prose products added to her hair when she bought Dove, which she once used, to share with her husband on a backpacking trip. “I couldn’t wait to get back to my custom shampoo,” she said.A version of this article appears in print on Nov. 29, 2018, Section D, Page 4 of the New York edition with the headline: Can Artificial Intelligence  Eliminate Bad Hair Days?. Order Reprints | Today’s Paper | SubscribeShare full articleRead in appAdvertisementSKIP ADVERTISEMENTTell us about yourself. Take the survey.",https://www.nytimes.com/2018/11/26/style/hair-care-customize.html,Can Artificial Intelligence  Eliminate Bad Hair Days?,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMWh0dHBzOi8vZm9ydHVuZS5jb20vMjAxOC8xMS8yOS9haS1qb2JzLXdvcmxkd2lkZS_SAQA?oc=5,These Countries Are Leading the Way With Jobs in A.I. - Fortune,2018-11-29,Fortune,https://fortune.com,UiPath ranked industry-leading countries by the number of A.I. jobs listed. China and the U.S. had the most jobs in artificial intelligence.,"AI jobs, jobs in ai, artificial intelligence, uipath, china ai, us artificial intelligence, jobs in artificial intelligence, software development jobs",Software company UiPath ranked the 15 industry-leading countries by number of A.I. jobs available.,Software company UiPath ranked the 15 industry-leading countries by number of A.I. jobs available.,,,,,,,,,,,,,,,,"Finance - Donald TrumpGun and ammo shares jump after Trump assassination attemptBYGreg McKennaJuly 15, 2024",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmM0aXNybmV0LmNvbS90aG91Z2h0LWxlYWRlcnNoaXAvMjAxOC8xMS8yOC9ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY2FuLWltcHJvdmUtY3liZXItc3lzdGVtcy_SAQA?oc=5,Three ways artificial intelligence can improve cybersecurity - C4ISRNET,2018-11-27,C4ISRNET,https://www.c4isrnet.com,Federal agencies should utilize AI technologies to gain more actionable insights,"['ai', 'artificial-intelligence', 'AI', 'artificial-intelligence', 'circulated-undefined', 'circulated-c4isrnet']",Federal agencies should utilize AI technologies to gain more actionable insights,,http://schema.org,NewsArticle,https://www.c4isrnet.com/thought-leadership/2018/11/28/how-artificial-intelligence-can-improve-cyber-systems/,"{'url': 'https://www.c4isrnet.com/resizer/gXxS7gQtllR4OsvF0Mk99RtuNxo=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/NGSNMVM225GADCIWRLHSUIKHNY.jpg', '@type': 'ImageObject'}","[{'@type': 'Person', 'name': 'Jeffrey I. Cooper'}]","{'@type': 'Organization', 'name': 'C4ISRNet', 'url': 'https://www.c4isrnet.com/', 'logo': {'@type': 'ImageObject', 'url': '/resources/img/c4isrnet-logo-white.png?d=124'}}",Three ways artificial intelligence can improve cybersecurity,2018-11-28T03:48:00.931Z,2022-08-19T07:41:55.023Z,,C4ISRNet,,,,,"This past summer, the Internal Revenue Service issued a request for information to learn more about how artificial intelligence can improve cyber security.The request went beyond just using machine-learning technologies to improve cyber operations. The agency wanted to know how to create a system that continuously learns its environment, triages alerts, identifies previously unknown trends and analyzes data to provide actionable context for officials.Artificial intelligence has been one of the most prominent buzzwords in the federal government over the past year. The federal government has made strides to bring artificial intelligence into agencies, but it has only begun to scratch the surface of its capabilities and use cases.One of the most important potential use cases for artificial intelligence in government is cyber security. Most cyber security solutions use rules-based or signature-based methodology that requires too much human intervention and institutional knowledge. These systems require constant updates to those rules – taking up employee time – and typically forcing analysts to only look at a single part of the enterprise, failing to get a holistic picture of the environment. Artificial intelligence can augment that human element to make the time spent on cyber security more productive.At its core, artificial intelligence is the science of training systems to emulate human intelligence through continuous learning. Although the role of the human will always be an important component for cyber security, the ability for a system to learn about the environment it must protect, automatically handling tasks and searching for anomalies in user behavior, is critical. Artificial intelligence can analyze large volumes of data, recognizing complex patterns of malicious behavior, and drive rapid detection of incidents and automated response.Artificial intelligence can also help eliminate visibility gaps within an enterprise. To date, the federal government has largely pieced together its cyber security systems, resulting in a fragmented approach to protecting systems. Analytics help close those gaps that are a result of this approach, analyzing the data generated in a system to identify malicious activity in areas that human analysts might miss.Artificial intelligence relies on the security analytics lifecycle, which is made up of three pillars: data, discovery and deployment. For artificial intelligence to be successful, it must be able to flow through these three pillars quickly and successfully. This lifecycle provides the ability for agencies to gain insight into their security ecosystem to quickly identify incidents and gain an understanding of their posture. Let’s look at each area:Data - For artificial intelligence to work, it first needs data to analyze, either stored or streaming data. Both types of data sources can be valuable in analyzing a cyber environment. The federal government has long produced large amounts of data and with the right streams, the key will be to identify the right pieces of data to get the best results. Additionally, better information sharing between the private sector and federal government can enhance this data inventory, increasing the data available to get a more comprehensive understanding of the threat landscape, as well as best practices for mitigating those threats.Discovery - This is the process of taking data and using technology to provide insights into security networks. With machine learning and artificial intelligence, agency personnel will build models for supervised and unsupervised purposes. Supervised models take advantage of datasets with known outcomes and build a model to predict or classify the behavior that drove that outcome. Unsupervised models do the same thing, except it works with data where there is no known outcome. It looks for outliers in the data that can show anomalies that are indicative of security incidents and finds areas of concern that human analysts would have a difficult time finding. That said, there is not a lot of labeled data in the cyber domain, so a combination of these approaches – or a semi-supervised learning approach – is often used to bridge the gap.Deployment - This is where the value of analytics is realized. Organizations take the findings from the discovery phase and make changes to their system to combat these issues. This could include patching a commonly attacked area or increasing the monitoring of a specific network. It is important to reemphasize, however, that better data collection, sharing and utilization is needed to adopt more advanced capabilities like artificial intelligence.These three steps work in concert to provide valuable insights across a government enterprise.The IRS and other federal agencies are taking the right steps by first investing in advanced data analytics solutions and looking at artificial intelligence to strengthen their security posture. The technology has proven to help organizations in all industries in a myriad of ways, cyber being chief among them. Federal agencies should look for analytics solutions that help them better understand their environment and drive actionable change. Artificial intelligence enhances an agency’s visibility into its systems, offering a continuously “learned” capability that works to identify and remediate suspicious activity that would otherwise go unnoticed.Jeffrey I. Cooper is an executive industry consultant for SAS. Prior to joining SAS in October, Mr. Cooper was the Executive Director of IRS Criminal Investigation – Office of International Operations.Share:More In South Korea to deploy laser weapons to intercept North Korean dronesThe Defense Acquisition Program Administration said it will deploy at least one anti-air laser weapons system — called “Block-I” — this year.US to send Tomahawks, hypersonics, other long-range fires to GermanyThe move is in-line with the Army's plan to provide such capability to its Multidomain Task Force there.Beavers takes reins from Sherman as acting DOD information officerAs the most senior IT advisor to the secretary of defense, Beavers is taking over from former CIO John Sherman.Quieting Discord: A new frontier in military leaks and extremismFrom secret Pentagon leaks to radicalization in the military community, Discord is continuing to grapple with keeping bad actors off the popular platform.Astronauts say Boeing space capsule can safely return them to EarthNASA test pilots Butch Wilmore and Suni Williams launched aboard Starliner capsule early last month.","{'type': 'WebPage', '@id': 'https://www.c4isrnet.com/thought-leadership/2018/11/28/how-artificial-intelligence-can-improve-cyber-systems/'}",,,,,,,/resources/img/c4isrnet-logo-white.png,https://www.c4isrnet.com/#publisher,,,,,"['https://www.facebook.com/https://www.facebook.com/C4ISRNet', 'https://twitter.com/c4isrnet']",,,,,,,,,,,,https://www.c4isrnet.com/thought-leadership/2018/11/28/how-artificial-intelligence-can-improve-cyber-systems/,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vcHJpY2Vvbm9taWNzLmNvbS93aGljaC1pbmR1c3RyaWVzLWFyZS1pbnZlc3RpbmctaW4tYXJ0aWZpY2lhbC_SAQA?oc=5,Which Industries Are Investing in Artificial Intelligence? - Priceonomics,2018-11-28,Priceonomics,https://priceonomics.com,"Analyzing which industries are adopting AI, what they use it for, and what that means for the talent market.",,"Analyzing which industries are adopting AI, what they use it for, and what that means for the talent market.",,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/#article', 'isPartOf': {'@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/'}, 'author': {'name': 'Team Recurrency', '@id': 'https://priceonomics.com/#/schema/person/297e897747de2daedfa1a8011c3f42ea'}, 'headline': 'Which Industries Are Investing in Artificial Intelligence?', 'datePublished': '2018-11-28T17:36:14+00:00', 'dateModified': '2022-03-20T00:40:35+00:00', 'mainEntityOfPage': {'@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/'}, 'wordCount': 1812, 'commentCount': 0, 'publisher': {'@id': 'https://priceonomics.com/#organization'}, 'image': {'@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/#primaryimage'}, 'thumbnailUrl': 'https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/800px-Culture_of_rat_brain_cells_stained_with_antibody_to_MAP2_green_Neurofilament_red_and_DNA_blue.jpg?strip=all&lossy=1&ssl=1', 'articleSection': ['Business Models', 'Economics'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://priceonomics.com/which-industries-are-investing-in-artificial/#respond']}]}, {'@type': 'WebPage', '@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/', 'url': 'https://priceonomics.com/which-industries-are-investing-in-artificial/', 'name': 'Which Industries Are Investing in Artificial Intelligence? - Priceonomics', 'isPartOf': {'@id': 'https://priceonomics.com/#website'}, 'primaryImageOfPage': {'@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/#primaryimage'}, 'image': {'@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/#primaryimage'}, 'thumbnailUrl': 'https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/800px-Culture_of_rat_brain_cells_stained_with_antibody_to_MAP2_green_Neurofilament_red_and_DNA_blue.jpg?strip=all&lossy=1&ssl=1', 'datePublished': '2018-11-28T17:36:14+00:00', 'dateModified': '2022-03-20T00:40:35+00:00', 'description': 'Analyzing which industries are adopting AI, what they use it for, and what that means for the talent market.', 'breadcrumb': {'@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://priceonomics.com/which-industries-are-investing-in-artificial/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/#primaryimage', 'url': 'https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/800px-Culture_of_rat_brain_cells_stained_with_antibody_to_MAP2_green_Neurofilament_red_and_DNA_blue.jpg?strip=all&lossy=1&ssl=1', 'contentUrl': 'https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/800px-Culture_of_rat_brain_cells_stained_with_antibody_to_MAP2_green_Neurofilament_red_and_DNA_blue.jpg?strip=all&lossy=1&ssl=1', 'width': 800, 'height': 600}, {'@type': 'BreadcrumbList', '@id': 'https://priceonomics.com/which-industries-are-investing-in-artificial/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://priceonomics.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Home', 'item': 'https://priceonomics.com/home/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Which Industries Are Investing in Artificial Intelligence?'}]}, {'@type': 'WebSite', '@id': 'https://priceonomics.com/#website', 'url': 'https://priceonomics.com/', 'name': 'Priceonomics', 'description': 'In Data We Trust', 'publisher': {'@id': 'https://priceonomics.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://priceonomics.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://priceonomics.com/#organization', 'name': 'Priceonomics', 'url': 'https://priceonomics.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://priceonomics.com/#/schema/logo/image/', 'url': 'https://priceonomics.wpengine.com/wp-content/uploads/2022/02/10505463_637940796301629_5372104385303524186_n.png', 'contentUrl': 'https://priceonomics.wpengine.com/wp-content/uploads/2022/02/10505463_637940796301629_5372104385303524186_n.png', 'width': 509, 'height': 380, 'caption': 'Priceonomics'}, 'image': {'@id': 'https://priceonomics.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/priceonomics', 'https://x.com/priceonomics', 'https://www.linkedin.com/company/priceonomics']}, {'@type': 'Person', '@id': 'https://priceonomics.com/#/schema/person/297e897747de2daedfa1a8011c3f42ea', 'name': 'Team Recurrency', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://priceonomics.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/e4a79ab340cdc4d4e107c6f9dcf96ec2?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/e4a79ab340cdc4d4e107c6f9dcf96ec2?s=96&d=mm&r=g', 'caption': 'Team Recurrency'}, 'sameAs': ['https://priceonomics.wpengine.com'], 'url': 'https://priceonomics.com/author/admin/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vdGhlY29udmVyc2F0aW9uLmNvbS81LXdheXMtdG8taGVscC1yb2JvdHMtd29yay10b2dldGhlci13aXRoLXBlb3BsZS0xMDE0MTnSAQA?oc=5,5 ways to help robots work together with people - The Conversation,2018-11-28,The Conversation,https://theconversation.com,Years of research into how humans work best together yield lessons useful for designing robots to interact with people.,,Years of research into how humans work best together yield lessons useful for designing robots to interact with people.,,,,,,,,,,,,,,,,,"






        Making the most of human-robot collaborations will require good teamwork.
        WeStudio/Shutterstock.com









            5 ways to help robots work together with people
          




Published: November 28, 2018 6:42am EST












Nancy Cooke, Arizona State University



Author





        Nancy Cooke
      


      Professor of Human Systems Engineering, Arizona State University
    





Disclosure statement
Nancy Cooke receives funding from the Office of Naval Research Science of Autonomy program, the Air Force Office of Scientific Research Trust and Influence program and the Army Research Laboratory.


Partners

Arizona State University provides funding as a member of The Conversation US.
View all partners

We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)26


 Facebook32


 LinkedIn


 WhatsApp


 Messenger

 Print


For most people today, robots and smart systems are servants that work in the background, vacuuming carpets or turning lights on and off. Or they’re machines that have taken over repetitive human jobs from assembly-line workers and bank tellers. But the technologies are getting good enough that machines will be able work alongside people as teammates – much as human-dog teams handle tasks like hunting and bomb detection.
There are already some early examples of robots and people teaming up. For example, soldiers use drones for surveillance and ground robots for bomb disposal as they carry out military missions. But the U.S. Army envisions increased teaming of soldiers, robots and autonomous systems in the next decade. Beyond the military, these human-robot teams will soon start working in fields as diverse as health care, agriculture, transportation, manufacturing and space exploration. 
Researchers and companies are exploring lots of avenues for improving how robots and artificial intelligence systems work – and technical advances are important. As an applied cognitive scientist who has conducted research on human teaming in highly technical settings, I can say human-robot systems won’t be as good as they could be if the designers don’t understand how to engineer technologies that work most effectively with real people. A few basic concepts from the deep body of scholarly research into human teamwork can help develop and manage these new relationships.
1. Different jobs
Teams are necessarily groups of people with separate, though interdependent, roles and responsibilities. A surgical team, for instance, might include a nurse, a surgeon and an anesthesiologist. Similarly, members of a human-robot team should be assembled to take on different elements of a complex task. 
Robots should do things they are best at, or that people don’t want to do – like lifting heavy items, testing chemicals and crunching data. That frees up people to do what they’re best at – like adapting to changing situations and coming up with creative solutions to problems. 



Doctors confer during the first robot-assisted surgery aboard the hospital ship USNS Mercy.
Kelsey L. Adams/U.S. Navy


A human-robot surgical team might have a human surgeon conducting laparoscopic or minimally invasive surgery with assistance from a robot manipulator with cameras that is inserted into the patient and operated externally by the surgeon. The view can be augmented by overlaying medical imaging data on the patient’s internal anatomy on the camera view.
Planning for this sort of division of labor suggests people shouldn’t replicate themselves in machines. In fact, humanoid-shaped robots or robots and AI that mimic human social behavior may mislead their human teammates into having unrealistic expectations of what they can do.
2. Mutual backup
Effective teams’ members know that everyone has a different role – but are available to support each other when necessary. The disastrously fatal response to Hurricane Katrina in 2005 was partly the result of confusion and lack of coordination among government agencies and other groups like the Red Cross.
Teammates need to understand their own roles and those of the rest of the team, and how they fit together. They also need to be able to use this knowledge to avoid stepping on teammates’ toes, while anticipating others’ potential needs. Robots and artificial intelligence need to understand how their parts of the task relate to the parts their teammates are doing, and how they might be able to help as needed.
3. Common understanding
Effective teams share knowledge about the team goals and the current situation and this facilitates their interactions – even when direct communication is not possible.
The benefit of shared knowledge allows all sorts of collaborations and coordinations. For instance, when inflating a hot air balloon, the pilot is at one end, in the basket monitoring the burner. A crew member must be at the far end of the balloon, steadying it by holding a rope attached to its top. They can’t see or hear each other because the balloon blocks the view and the propane burner drowns out any other sound. But if they’re trained well, neither needs to communicate to know what the other is doing, and know what needs to happen next. 



The two people at this end of the balloon also have to trust what their team members at the other end of the balloon are doing.
Mongkolp/Shutterstock.com


The connection team members have comes not only from information they all know, but shared knowledge developed through experience working together. Some scholars have suggested that robots can’t build experience and shared knowledge with humans, while other researchers are working on finding ways to actually do that. Machine learning will likely be a key factor in helping robots develop expectations of their coworkers’ behavior. Coupled with human intelligence, each side will learn about the other’s capabilities, limitations and idiosyncrasies.
4. Effective interaction and communication
Team members need to interact; effective teaming depends greatly on the quality of those interactions. In hospital teams for emergency resuscitation of patients, team interaction and communication are crucial. Those teams are often made up of whatever medical personnel are nearest to the patient, and members need to know right away what happened before the patient’s heart stopped – a life is at stake.
Yet even between people, communication isn’t always seamless. Between people and robots there are even more challenges – like making sure they share understandings of how words are used or what appropriate responses are to questions. Artificial intelligence researchers are making great strides in advancing computers’ ability to understand, and even produce, natural language – as many people experience with their smart assistant devices like Amazon’s Alexa and Google Home, and mobile and car-based GPS directions systems.
It’s not even clear if typical human communication is the best model for human-robot teams. Human-dog teams do fine without the use of natural language. Navy SEALs can work together at highly effective levels without uttering a word. Bees communicate location of resources with a dance. Communication does not have to involve words; it could include sound signals and visual cues. If a robot was tending the patient when their heart stopped, it could indicate what happened on a monitor that all resuscitation team members could see.
5. Mutual trust
Interpersonal trust is important in human teams. If trust breaks down among a team of firefighters, they’ll be less effective and may cost lives – each other’s or members of the public they’re trying to help. The best robot teammates will be trustworthy and reliable – and any breaches in reliability need to be explained. 
But even with an explanation, technology that is chronically unreliable is likely to be rejected by human teammates. That’s even more vital in safety-critical technology, like autonomous vehicles.
Robots are not automatically capable of teaming with humans. They need to be assigned effective roles on the team, understand other team roles, train with human team members to develop common understanding, develop an effective way to communicate with humans, and be reliable and trustworthy. Most importantly, humans should not be asked to adapt to their nonhuman teammates. Rather, developers should design and create technology to serve as a good team player alongside people.





Teamwork


Robots


Collaboration


Human-computer interaction


Home robots


Robot workers


Robot jobs









",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vZW1lcmouY29tL2FpLXNlY3Rvci1vdmVydmlld3MvcHJlZGljdGl2ZS1hbmFseXRpY3Mtb2lsLWdhcy1pbmR1c3RyeS1jdXJyZW50LWFwcGxpY2F0aW9ucy_SAQA?oc=5,Predictive Analytics in the Oil and Gas Industry - Emerj,2018-11-29,Emerj,https://emerj.com,Discover how the oil and gas industry are using AI-based predictive analytics applications to predict well yield and when their equipment needs maintenance.,,Discover how the oil and gas industry are using AI-based predictive analytics applications to predict well yield and when their equipment needs maintenance.,,https://schema.org,Article,,https://emerj.com/wp-content/uploads/2018/10/oil-and-gas-predict-2-690x388.jpg,Ayn de Jesus,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",Predictive Analytics in the Oil and Gas Industry &#8211; Current Applications,2018-10-16,2018-11-29,,,,,,," Business intelligence and analyticsHeavy industryLogisticsNatural resources Predictive Analytics in the Oil and Gas Industry – Current Applications Ayn de JesusLast updated on November 29, 2018  Last updated on November 29, 2018, published by Ayn de Jesus Ayn serves as AI Analyst at Emerj - covering artificial intelligence use-cases and trends across industries. She previously held various roles at Accenture. Share to: LinkedIn Twitter Facebook Email  McKinsey reported that most oil and gas operators have not maximized the production potential of their assets. A typical offshore platform, according to the 2017 report, runs at about 77% of its maximum production potential. Industry-wide, the shortfall comes to about 10 million barrels per day, or $200 billion in annual revenue.  To help optimize production, operators might consider adopting advanced analytics, which combines engineering, data science, and computing power to enable businesses to forecast yields or maximize industry assets. In adopting analytics, it follows that AI would find its way into the oil and gas industry. As of now, numerous companies claim to assist engineers and data scientists in aspects of their roles, such as predictive maintenance on equipment, predicting supply and demand, and streamlining routine processes. We researched the space to better understand where predictive analytics comes into play in the oil and gas industry and to answer the following questions: What types of predictive analytics applications are currently in use in oil and gas? What tangible results have predictive analytics driven in oil and gas? Are there common trends among these innovation efforts? How could these trends affect the future of oil and gas? This report covers vendors offering software across two applications: Predictive Maintenance Business Intelligence This article intends to provide business leaders in the oil and gas space with an idea of what they can currently expect from AI in this industry. We hope that this article allows business leaders in the oil and gas industry to garner insights they can confidently relay to their executive teams so they can make informed decisions when thinking about AI adoption. At the very least, this article intends to reduce the time business leaders spend researching AI companies with whom they may (or may not) be interested in working. Predictive Maintenance GE Digital’s Predix GE Digital, a subsidiary of General Electric, offers Predix, which the company claims can help oil and gas businesses create automated analytics models that could help in the predictive maintenance of its industrial equipment using machine learning. Predix explains that the application’s machine learning algorithms are able to process data that sensors collect, such as equipment or parts performance, environmental data, and weather conditions, among others. The algorithms then compare these against the ideal performance data contained in the database. If the algorithms find discrepancies between the current and ideal state, the application is triggered to send an alert to technicians. who in turn conduct predictive maintenance or part replacement.  For instance, in a wind farm, one turbine is performing below optimum levels. The technician gathers the data collected by sensors about the parts of the turbine, such as the wind blades and turbine axle. The technician might also consider reviewing the wind speed. The turbine’s performance history will then be compared with that of other turbines at the wind farm.  The in-house technician may share the information with the field technician through a connected tablet or smartphone, who is prompted to inspect the underperforming turbine in person. Repairs are then conducted if needed. Below is a short 3-minute video demonstrating how Predix works:  GE Digital claims to have helped the Administracion Nacional de Combustibles, Alcohol y Portland (ANCAP) of Uruguay. The state-owned company provides the fuel that heats homes and business and fuels cooking equipment, agricultural machines, and transportation. The company was faced with the challenge of managing large amounts of data and needed a solution to make processes more efficient, optimize energy consumption, integrate operational data from various sources, and ensure the sustainability of the company. The company turned to Predix’s human-machine interface and supervisory control and data acquisition (HMI-SCADA) application called iFIX. The project was implemented in five distribution plants, with more than 1,000 screens deployed. Employees at each location learned to use the system to input critical data. With the centralized system, ANCAP was reportedly able to track field data, such as gas and liquid flow rates, composition analyzers, and tank levels and volumes. The system also enabled the company to monitor the performance rates of equipment, daily throughputs from process units, and weather conditions. This data was automatically processed, formatted to a spreadsheet, and uploaded to the government’s website. With this data, ANCAP was able to calculate and project the efficiency of its furnaces using this data. although the case study did not explain how efficiency was defined. The data was recorded in the server to enable the team to study trends related to the furnace’s performance. According to GE Digital, implementing Predix allowed ANCAP to cut the time spent on routine processes by 60% and save 20% more fuel. Management also reportedly stopped asking employees for manual reports GE Digital also lists Exelon, Gerdau, Spomlek, Lek Pharmaceuticals, and the City of San Luis Obispo as some of its clients. Vincent Yates is the Chief Data Scientist at GE Digital. He holds a PhD in Statistics from the University of California, Berkeley. Previously, Yates served as Head of Data Science in Seattle at Uber, Director of Analytics Engineering at Zillow Group, and Office Analytics Team Manager at Microsoft.  Maana  Maana is a California-based company with over 100 employees. The company offers a software called the Knowledge Platform, which they claim can help oil and gas companies predict operational outcomes and help employees make better-informed decisions using machine learning and natural language processing. Maana claims its software can mine, process, and analyze a company’s unstructured data, such as job reports, maintenance records, equipment sensors, weather data, call center records, and other types of media from disparate company sources. Then, Knowledge Platform’s natural language processing algorithms interpret the data from these reports. The machine learning algorithms crawl through the platform’s database to find patterns that are similar to the current problem the company is aiming to solve.  When the algorithms find similarities, the system then provides feedback in the form of graphs to show the trend of, for instance, equipment performance or expenditures. This allows the company’s subject matter experts to interpret the graphs and make recommendations on how to solve the problem. Below is a short 2-minute video demonstrating how the Knowledge Platform works:  Maana claims to have helped an unnamed Fortune 20 oil company make optimal pump selections, increase billable hours and reduce overall costs using the application. The company’s maintenance experts used the platform to collect data related to existing pump operations. The data came in the form of run-and-pull reports, pump failure reports, pump sensor data and high-frequency data flows. Much of the data described past inspections of failed pumps retrieved from wells and was reported by field employees.  Aside from language-based data, the company also collected detailed sensor data during pump operations. The application was able to classify the data and recognize the patterns that could lead to pump failure. According to Maana, this enabled employees to validate their hypotheses and identify the causes of pump failures, predict similar scenarios in the future, and choose the right pump for each kind of well. Overall, this allowed the company to conduct maintenance that would reduce the risk of pump failures and production downtime. Maana also lists Shell, General Electric, Airbus, Maersk, Chevron as some of their clients. Steven Gustafson is Chief Scientist at Maana. He holds a PhD in Computer Science from the University of Nottingham. Previously, Gustafson served as R&D Leader, Knowledge Discovery Lab at General Electric Global Research. Business Intelligence HortonWorks HortonWorks is a San Francisco-based company with about 1,300 employees. The company offers a software called Hybrid Data Platform (HDP), an open-source application that processes large datasets from multiple sources, which they claim can help oil and gas companies predict well yield do maintenance on equipment. Hortonworks claims that HDP can store and process its structured and unstructured data, such as sensor or seismic data, weather, drilling and completions data, geolocation, text files, video, social media, email, and more. These are stored in a data repository.  For instance, an oil and gas company may want to set standards of yield per well to achieve the highest margins. To set the benchmarks, the engineers might use seismic data, pump rates, fluid temperatures, and other factors that influence yield.  The software’s machine learning model would then take these predefined benchmarks, search the HDP database for similar standards, and compare the corresponding well yields. If the algorithms find that the current yields are lower, based on the influencing factors, the system informs the users through the dashboard. Below is a short 2-minute video demonstrating how HDP works:  Horton claims to have helped Noble Energy predict and prevent downtime in its hydrocarbon infrastructure. The case study reports that HDP was used to look for potential lost opportunity through downtime, but did not provide details. However, we can infer that the application’s machine learning model reviewed the data from sensor streams, drilling reports, location data, engineering notes, and technical manuals, etc.   Then, the algorithms may have matched these with historical data related to factors that could affect production, such as equipment failure and decline in the output of existing oil wells, among others. This would have enabled Noble Energy to take measures to maintain equipment and possibly discover new wells. In the future, Noble Energy intends to use HDP to improve safety and prevent injuries among employees in its locations.  Hortonworks also lists Fuso, Johns Hopkins University, Nissan, Yahoo! Japan, Mayo Clinic, SoftBank, Expedia, and Symantec as some of its clients. Scott Gnau is CTO at Hortonworks. He holds a BS in Electrical Engineering from Drexel University. Previously, Gnau served as President of at Teradata labs for nine years, where he provided direction for research, development, and sales support activities related to Teradata integrated data warehousing and big data analytics. SAS SAS offers a predictive software called Enterprise Miner, which they claim can help oil and gas businesses streamline the data mining process to develop predictive models using deep learning, computer vision, and natural language processing (NLP). SAS claims that NLP algorithms are capable of extracting business insights and emerging trends from texts, speech and sound, while computer vision algorithms determine the objects inside images and videos. The information extracted by these technologies are then processed and analyzed by deep learning algorithms, which recognize patterns in the data to create predictions and preventive recommendations. Below is a short 3-minute video demonstrating how SAS artificial intelligence-driven applications work:   SAS does not have oil and gas-related case studies but claims to have helped Old Dominion Electric Cooperative (ODEC) forecast energy demand and save its utility customers millions in its first year of using SAS Analytics, according to the case study.  ODEC provides wholesale power to 11 distribution cooperatives in Virginia, Maryland, and Delaware that serve 1 million member customers. For energy purchases, the cooperative must contract energy months in advance to ensure affordable supply at wholesale prices. Wrong forecasts might force ODEC to buy energy at higher spot prices In the past, ODEC used traditional spreadsheets to create forecasts. SAS enabled ODEC to forecast more accurately using a variety of industry-specific models that support system analysis, hedging, financial forecasts, and future resources for energy and demand. According to the case study, using SAS allowed ODEC to understand each cooperative’s market while providing a big-picture look. This enabled the client to plan for its markets’ power needs five, 10, or 20 years into the future. The company did not provide further details or specific numbers. SAS also lists Honda, Bank of America, Nestle, Lufthansa, Konica Minolta, and World Wildlife Fund as some of its past clients. Wayne Thompson is Chief Data Scientist at SAS where he has served for 26 years. He holds a PhD in Agronomy and Statistics and another in Plant Sciences; Minor Statistics. Both are from the University of Tennessee. Takeaways for Business Leaders in the Oil and Gas industry Most of the companies covered in this report offer solutions for preventive maintenance and production-related analytics. Worthy of note is that all of the companies’ AI efforts are spearheaded by PhD-level talent except Hortonworks.  That said, only Maana offers solutions exclusively for industrial production and oil and gas companies; the other companies covered in this report service multiple industries. Maana’s specificity could work in its favor, as its machine learning models might be trained exclusively on industrial databases, which could increase its models’ accuracies. This is speculation, however.  Although no company provided hard times on how long their software would take to integrate, based on one case study, we infer that the integration product could be long. Overall, predictive analytics applications for the oil and gas industry seem to legitimately involve AI, unlike other sectors that are more nascent in terms of AI.   Header Image Credit: Oil and Gas People Related Posts AI for Exploration & Production (Upstream) in the Oil and Gas Industry - Current ApplicationsThe oil and gas industry is usually divided into three major operational sectors: upstream, midstream,… Internet of Things in the Oil and Gas Industry - Current ApplicationsAccording to McKinsey, global gas demand is expected to reach 4,503 billion cubic meters (bcm)… Predictive Analytics - 5 Examples of Industry ApplicationsBusinesses today around the world have some portion of their operations being automated, which concurrently… Artificial Intelligence in Oil and Gas - Comparing the Applications of 5 Oil GiantsOil remains one of the most highly valued commodities in the energy sector. Estimates of… Predictive Analytics in Insurance - An Overview of Current ApplicationsThe insurance industry is making use of various artificial intelligence applications to solve business problems,… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",https://emerj.com/ai-sector-overviews/predictive-analytics-oil-gas-industry-current-applications,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,AI Sector Overviews,2120.0,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vbmV3cy5taWNyb3NvZnQuY29tL2VuLWF1L2ZlYXR1cmVzL2Zpc2h5LWJ1c2luZXNzLXB1dHRpbmctYWktdG8td29yay1pbi1hdXN0cmFsaWFzLWRhcndpbi1oYXJib3VyL9IBAA?oc=5,Fishy business: Putting AI to work in Australia's Darwin Harbour - Microsoft Australia News Centre - Microsoft,2018-11-30,Microsoft,https://news.microsoft.com,,,,,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://news.microsoft.com/en-au/features/fishy-business-putting-ai-to-work-in-australias-darwin-harbour/', 'url': 'https://news.microsoft.com/en-au/features/fishy-business-putting-ai-to-work-in-australias-darwin-harbour/', 'name': 'Fishy business: Putting AI to work in Australia’s Darwin Harbour - Microsoft Australia News Centre', 'isPartOf': {'@id': 'https://news.microsoft.com/en-au/#website'}, 'primaryImageOfPage': {'@id': 'https://news.microsoft.com/en-au/features/fishy-business-putting-ai-to-work-in-australias-darwin-harbour/#primaryimage'}, 'image': {'@id': 'https://news.microsoft.com/en-au/features/fishy-business-putting-ai-to-work-in-australias-darwin-harbour/#primaryimage'}, 'thumbnailUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/66/2018/11/Northern-Territories-Fisheries_feature_hero_1920x1080_29-11-2018.jpg', 'datePublished': '2018-11-29T21:32:15+00:00', 'dateModified': '2019-04-12T01:17:26+00:00', 'breadcrumb': {'@id': 'https://news.microsoft.com/en-au/features/fishy-business-putting-ai-to-work-in-australias-darwin-harbour/#breadcrumb'}, 'inLanguage': 'en-AU', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.microsoft.com/en-au/features/fishy-business-putting-ai-to-work-in-australias-darwin-harbour/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://news.microsoft.com/en-au/features/fishy-business-putting-ai-to-work-in-australias-darwin-harbour/#primaryimage', 'url': 'https://news.microsoft.com/wp-content/uploads/prod/sites/66/2018/11/Northern-Territories-Fisheries_feature_hero_1920x1080_29-11-2018.jpg', 'contentUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/66/2018/11/Northern-Territories-Fisheries_feature_hero_1920x1080_29-11-2018.jpg', 'width': 1920, 'height': 1080, 'caption': 'Dr Shane Penny, Fisheries Research Scientist at NT Fisheries, is leading the work with Microsoft AI, placing conservation at the heart of Darwin Harbour.'}, {'@type': 'BreadcrumbList', '@id': 'https://news.microsoft.com/en-au/features/fishy-business-putting-ai-to-work-in-australias-darwin-harbour/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.microsoft.com/en-au/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Features', 'item': 'https://news.microsoft.com/en-au/features/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Fishy business: Putting AI to work in Australia’s Darwin Harbour'}]}, {'@type': 'WebSite', '@id': 'https://news.microsoft.com/en-au/#website', 'url': 'https://news.microsoft.com/en-au/', 'name': 'Microsoft Australia News Centre', 'description': 'Microsoft Australia News Centre', 'publisher': {'@id': 'https://news.microsoft.com/en-au/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.microsoft.com/en-au/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-AU'}, {'@type': 'Organization', '@id': 'https://news.microsoft.com/en-au/#organization', 'name': 'Microsoft', 'url': 'https://news.microsoft.com/en-au/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://news.microsoft.com/en-au/#/schema/logo/image/', 'url': 'https://news.microsoft.com/wp-content/uploads/prod/sites/66/2014/12/storelogo.png', 'contentUrl': 'https://news.microsoft.com/wp-content/uploads/prod/sites/66/2014/12/storelogo.png', 'width': 52, 'height': 52, 'caption': 'Microsoft'}, 'image': {'@id': 'https://news.microsoft.com/en-au/#/schema/logo/image/'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvdG9tdmFuZGVyYXJrLzIwMTgvMTEvMjgvd2h5LXNvY2lhbC1zdHVkaWVzLWlzLWJlY29taW5nLWFpLXN0dWRpZXMv0gEA?oc=5,Why Social Studies Is Becoming AI Studies - Forbes,2018-11-28,Forbes,https://www.forbes.com,"We’ve all witnessed how artificial intelligence (AI) is reshaping lives and changing the world. AI is not a tech issue, it’s a social studies issue and it’s time to start bringing youth into the conversation and preparing them for the future of work.",,"We’ve all witnessed how artificial intelligence (AI) is reshaping lives and changing the world. AI is not a tech issue, it’s a social studies issue and it’s time to start bringing youth into the conversation and preparing them for the future of work.","We’ve all witnessed how artificial intelligence (AI) is reshaping lives and changing the world. AI is not a tech issue, it’s a social studies issue and it’s time to start bringing youth into the conversation and preparing them for the future of work.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/tomvanderark/2018/11/28/why-social-studies-is-becoming-ai-studies/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/tomvanderark/files/2018/11/Screen-Shot-2018-11-27-at-2.50.35-PM-1.png?format=png&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Tom Vander Ark', 'url': 'https://www.forbes.com/sites/tomvanderark/', 'description': ""I am an advocate for better learning for everyone. As CEO of Getting Smart, I advise schools, districts, networks, foundations and learning organizations on the path forward. I've written or co-authored more than 50 books and papers including Getting Smart, Smart Cities, Smart Parents, Better Together, and The Power of Place. I served as a public school superintendent and the first Executive Director of Education for the Bill & Melinda Gates Foundation. I serve on the boards of nonprofits including Education Board Partners, 4.0 Schools, Digital Learning Institute, eduInnovation and advise One Stone, Teton Science Schools, Whittle School & Studios, and Mastery Transcript Consortium."", 'sameAs': ['https://www.twitter.com/@tvanderark']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Why Social Studies Is Becoming AI Studies,2018-11-28T04:00:00-05:00,2018-11-28T14:34:07-05:00,Education,Why Social Studies Is Becoming AI Studies,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Leadership', 'item': 'https://www.forbes.com/leadership/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Education', 'item': 'https://www.forbes.com/education/'}]",Education,,"More From ForbesJul 15, 2024,09:05am EDTQuizlet Reports Pace Of AI Adoption Slowing, Becoming More IntentionalJul 15, 2024,07:39am EDTNew Survey Reveals Low Level Of Civics Literacy Among College StudentsJul 15, 2024,06:30am EDTThe College Admissions Taboo: 5 Reasons To Discuss College Transfer With The Class Of 2028Jul 13, 2024,07:35pm EDTWhat Does Project 2025 Actually Plan For Education?Jul 12, 2024,05:40pm EDTEducation Freedom Not In The Presidential Debate But In The StatesJul 12, 2024,08:34am EDTCal Poly Humboldt President To Resign Months After Protests, No Confidence VoteJul 12, 2024,06:00am EDTThe Supreme Court Puts An End To Higher Education Regulatory WhiplashEdit StoryForbesLeadershipEducationWhy Social Studies Is Becoming AI StudiesTom Vander ArkContributorOpinions expressed by Forbes Contributors are their own.I write about the future of learning, work and human development.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 28, 2018,04:00am ESTUpdated Nov 28, 2018, 02:34pm ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







Brown Middle School, El Paso
Tom Vander Ark





Artificial intelligence (AI) is reshaping life and livelihoods. It’s curating every screen; making or influencing decisions about hiring, loans, and jail sentences; and aggregating wealth and opportunity at a staggering pace. 

AI, particularly machine learning (ML), and related exponential technologies (ET) are quickly augmenting many tasks at home and work. They will increasingly displace jobs while creating new entrepreneurial opportunities. They will swamp communities with complex issues and a combination of predictable and unanticipated consequences.  
AI is not just a tech issue, it’s a social studies issue. Teaching youth to code may be part of the response, but even more important is asking them to consider issues of the changing civic and employment landscape.  
PROMOTED
“The aim of social studies is the promotion of civic competence,” says the National Council for the Social Studies. Their standards are built around 10 themes that are being shaped by AI and ET.  

1. Culture: Social studies programs should include experiences that provide for the study of culture and cultural diversity.

ML promotes screentime addiction which changing social interaction.









CxO
US


CEO: C-suite news, analysis, and advice for top decision makers right to your inbox.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the CEO newsletter!


                More Newsletters
            


You’re all set! Enjoy the CEO newsletter!

                More Newsletters
            



ML has been used to manipulate social media manipulation in an effort to change election outcomes.

2. Time, Continuity and Change: Social studies programs should include experiences that provide for the study of the past and its legacy.

ET means we’re living on a curve where everyone is experiencing more novelty and complexity as manmade and natural systems collide in unexpected ways. 

3. People, Places and Environments: Social studies programs should include experiences that provide for the study of people, places, and environments.

Lots of cameras and facial recognition software makes it possible to track people with accuracy. It’s used to issue jaywalking tickets in China. 
Your stock trades are not as you think. In China, a social credit score increasingly shapes life options. 

4. Individual Development and Identity: Social studies programs should include experiences that provide for the study of individual development and identity.

ML is quickly augmenting human capacity in every aspect of life. It will increasingly be combined with biological augmentation. How will this change human identities and interactions?
Advances in gene editing and DNA analysis is beginning to give parents control over the traits their children will inherit.

5. Individuals, Groups and Institutions: Social studies programs should include experiences that provide for the study of interactions among individuals, groups, and institutions.

ML is beginning to automate the middle of the job market leading to job dislocation  
“Algorithmic bias is shaping up to be a major societal issue at a critical moment in the evolution of machine learning and AI,” said the MIT Tech Review. 
Chinese algorithms use observed behaviors to create a credit score that defines access to credit. 
ML is increasingly used to allocate police resources, set prison sentences, inform hiring, make loans. Algorithmic bias can disadvantage groups with little transparency. 

6. Power, Authority and Governance: Social studies programs should include experiences that provide for the study of how people create, interact with, and change structures of power, authority, and governance.

Some societies are mobilizing and skilling up and using framing legislation to guide the use of ML/ET. The US federal government appears particularly unwilling and unable to respond  
Killer drones and automated warfare 

7. Production, Distribution and Consumption: Social studies programs should include experiences that provide for the study of how people organize for the production, distribution, and consumption of goods and services.

ML/ET is accelerating wealth aggregation 
Large sections of the workforce are experiencing anxiety; wages are lagging. 

8. Science, Technology and Society: Social studies programs should include experiences that provide for the study of relationships among science, technology, and society.

ML is improving diagnosis and treatment of disease; who will gain access to lifesaving technology?
ML/ET cause new privacy and security concerns 
False news is spreading online farther and faster than the truth

9. Global Connections: Social studies programs should include experiences that provide for the study of global connections and interdependence.

ET will, in less than a decade, connect most of the world with mobile devices and 5G connectivity  

10. Civic Ideals and Practices: Social studies programs should include experiences that provide for the study of the ideals, principles, and practices of citizenship in a democratic republic.

ML/ET is sending waves of issues at communities (e.g., climate change, autonomous vehicles, employment dislocation, privacy) testing civic ideas and practices. 

Artificial intelligence isn’t a tech issue, it’s a social studies issue. Like the Montour School District in Pittsburgh, the ethics of AI should be introduced in middle school. Educational institutions should be leading community conversations about what’s happening, what it means and how to prepare. 
For more see: 

Curbing Killer Robots And Other Misuses of AI
Let's Talk About AI Ethics; We're On a Deadline
Ask About AI: The Future of Work and Learning 
Tom Vander ArkFollowingFollowI am an advocate for better learning for everyone. As CEO of Getting Smart, I advise schools, districts, networks, foundations and learning organizations on... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LmJiYy5jb20vZnV0dXJlL2FydGljbGUvMjAxODExMjktdGhlLWFpLXRyYW5zZm9ybWluZy10aGUtd2F5LWFpcmNyYWZ0LWFyZS1idWlsdNIBAA?oc=5,The designer changing the way aircraft are built - BBC.com,2018-11-29,BBC.com,https://www.bbc.com,"By dreaming up radical new structures, designers are helping aircraft to become lighter, stronger and more efficient. Yet the minds behind these innovations are not human.",,"By dreaming up radical new structures, designers are helping aircraft to become lighter, stronger and more efficient. Yet the minds behind these innovations are not human.","By dreaming up radical new structures, designers are helping aircraft to become lighter, stronger and more efficient. Yet the minds behind these innovations are not human.",https://schema.org,NewsArticle,,['https://ychef.files.bbci.co.uk/1280x720/p06t67d3.jpg'],"{'@type': 'Person', 'name': 'Douglas Heaven', 'url': ''}","{'@type': 'Organization', 'name': 'BBC'}",The designer changing the way aircraft are built,2018-11-29T16:22:22.499Z,2022-02-24T18:17:15.021Z,,,,,,,"The designer changing the way aircraft are built29 November 2018By Douglas Heaven, Features correspondentShareAutodesk, IncUsing a silicon-based designer allowed Nasa to reduce the weight of the legs of its interplanetary lander concept by more than a third (Credit: Autodesk, Inc)By dreaming up radical new structures, designers are helping aircraft to become lighter, stronger and more efficient. Yet the minds behind these innovations are not human.It looks more like a chicken carcass than a drone. Wishbone-thin struts hold together a skeletal scaffold that seems too fragile to fly.But don’t be fooled. It may not look it, but this design is one of the strongest among thousands of alternatives. We know because an artificial intelligence has dreamed up and tested every one of them.The use of massive computing power to conjure radical new designs automatically – a process known as generative design –  is revolutionising the way human designers work, letting us build things we previously couldn’t have imagined.You might also like: • The A-Z of how artificial intelligence is changing the world • Why machines dream of spiders with 15 legs • The goldmine hidden in your pocketThe technology is already designing everyday industrial components from seatbelt brackets in cars and motorbike chassis to cabin partitions in passenger aircraft. Not only are these computer-generated designs stronger and lighter than human-crafted solutions but they’re weird – designs that no human would have come up with in the first place.“The computer can really surprise you,” says Lilli Smith at Autodesk in Boston, a software design company which has several generative designs under its belt, including the unusual drone chassis. 0:25Artificial intelligence designed this drone bodyInstead of waiting for inspiration to hit, computers go looking. Handed a set of design constraints – such as making it lightweight, strong and low-cost – generative design software identifies and assesses hundreds or thousands of candidates that all fit the bill, before selecting the pick of the crop.Humans switch from being creators to curatorsBy trawling through an exhaustive set of options, computers typically find ones that a human would have missed. Designers can simply choose from a handful that the software predicts will do the job better than the rest. Humans switch from being creators to curators.The basic idea is simple: here’s what I want, show me the best. But the software and cloud-based computing power needed to pull it off have only appeared in the last few years. For one of its first generative design projects, in 2015, Autodesk Research teamed up with the Bandito Bros, a US multimedia studio known for its wacky stunts, and asked an AI to design a car.The team wired up a custom-built off-road buggy with hundreds of sensors and raced it around the Mojave Desert. This let them capture a vast amount of data about the stresses that extreme driving placed on different parts of the vehicle. They then fed this to the generative design system with the instruction to produce something that could handle this. The resulting design, dubbed the Hack Rod, gave a glimpse of the future: more strength from less material – and alien-looking.There’s a reason generative designs look weird, as if they were the result of a natural process rather than made, says Erin Bradner at Autodesk Research in San Francisco. “The algorithm will fine tune the structure so that not a single piece of material is added that’s not needed,” she says. “Some people relate it to erosion.”Autodesk, IncGenerative design combined with 3D printing allows structures to be made that were impossible before (Credit: Autodesk, Inc)This process of elimination applies not only to the amount of material in a structure but also the number of parts needed to make it. “That can mean fewer suppliers, faster assembly and fewer points of failure,” says Bradner.The trouble with favouring organic structures is that they can be hard to manufacture with traditional machines. Additive manufacturing – or 3D printing – can be used to make most shapes, but not all industries yet use it. To get around that, you can instruct the design software to generate something that can be made by certain kinds of equipment.“A designer can specify that she wants to make a part on a three-axis mill with a specific diameter cutting tool and the algorithm will only produce parts that can be made by that mill, with that cutter,” says Bradner.Manufacturing limitations become yet another design constraint that the software takes on board. “Designers are faced with a myriad of choices every day that they don’t have the time or mental resources to fully explore,” she says. “If I could make my part in aluminium or steel what would it look like? If I could manufacture by 3D printing or milling, what alternatives could I consider?”AlamyThe cabin partitions in passenger aircraft can be made lighter but stronger when designed by AI (Credit: Alamy)Generative design is still a new technology, with many projects one-off experiments, such as the Hack Rod and drone. But companies like Autodesk and Frustum, based in Colorado, are starting to take the tech mainstream via collaborations with a range of major manufacturers. “We’re doing a lot of work with aerospace companies,” says Frustum’s chief executive Jesse Blankenship.When designing components for aircraft, a small reduction in weight can makes a big differenceWhen designing components for aircraft, a small reduction in weight can makes a big difference. Blankenship says his company’s software has been used to design lighter components like heat exchangers and acoustic baffling. Frustum has clients in the defence industry as well, but they’re tight-lipped about what they’re designing. “I just know they buy the software,” he says.Autodesk has also been helping aircraft lose weight. The Airbus A320 now has lightweight partitions between cabins that were designed by an AI that Autodesk Research co-developed with New York-based software company The Living. The partition’s skeletal design has rods criss-crossing at odd angles.Others have also been looking at AI’s ability to improve aircraft design. Researchers at the German Aerospace Centre (DLR) have been investigating its role in helping to tune combat aircraft to specific missions. Aerospace engineers at Delft University in the Netherlands have also been developing a tool that produces conceptual aircraft designs.AirbusAirbus estimates that the new cabin partition design can save up to 465,000 metric tons of carbon dioxide emissions a year (Credit: Airbus)It’s not only planes that benefit from being lighter. Autodesk has worked with US car maker General Motors to create a seatbelt bracket that is 40 percent lighter and 20 percent stronger than the previous version. At its annual trade show in November this year, Autodesk also showed off an AI-designed suspension system for a Mercedes-Benz Formula 1 racing car and a frame for a BMW motorcycle.Even Nasa is in on it. Next to the car and bike parts was a lander that Nasa is developing for missions to the moons of Jupiter and Saturn. Autodesk’s generative design for the lander’s legs is 35 percent lighter than previous human-made designs.For David Kirsh, a cognitive scientist at the University of California, San Diego and visiting researcher at University College London’s Bartlett School of Architecture, generative design lets us outsource a kind of hands-on problem solving.Kirsh is interested in how human thinking is embedded in our physical environment. Imagine you’re putting together a jigsaw puzzle. You could try to fit all the pieces together in your head, using what we might call the mind’s eye. Or you could build it. For any puzzle with more than a handful of pieces, solving the problem with our hands rather than our head is far easier. “Cognition is a product of the interaction between brains, bodies and the world,” he says.Autodesk, IncThe intritcate legs of Nasa's new interplanetary lander are nearly a third lighter than anything a human could come up with (Credit: Autodesk, Inc)Many problems can’t be solved (just) in our head at all, which is why design typically involves prototyping to see how pieces fit together and work as a whole. Here’s another example. If you have a peg that you need to fit into a tight hole you don’t study the peg and the hole and calculate how it’s going to go in. “The trick is actually to put it part-way in and then jiggle it,” says Kirsh. “There is no counterpart in the mind for jiggling.”Trying out thousands of different ways to meet a set of design constraints &ndash; like different positions for the peg in the hole &ndash; is a form of virtual jigglingBut generative design could be the next best thing. Trying out thousands of different ways to meet a set of design constraints – like different positions for the peg in the hole – is a form of virtual jiggling.In fact, some design problems are a lot like puzzles. When Autodesk Research wanted to set up a new office in Toronto, they worked with The Living again to design the layout. Most offices stick to a standard floor plan, with meeting rooms in the middle or around the edges and the desks grouped together.The design generated for the Toronto office is different. As with the Hack Rod, the designers collected as much data as they could, this time about people’s working preferences – how much natural light, how much social interaction, their working hours and so on. They also noted which groups needed to be close to which other groups.AirbusThe designs often appear similar to shapes and structures found in the natural world (Credit: Airbus)Feeding these constraints to the software produced hundreds of possible layouts for the office’s desks, meeting rooms and social spaces. The one that the designers picked from the few most recommended by the AI has small groups of desks interspersed with communal areas and teams arranged in a way that maximises interaction.Van Wijnen, a construction company based in the Netherlands, is doing the same thing for entire neighbourhoods. The firm has changed its entire construction process to make the most of its generative design tools.Its houses are now made from prefabricated parts, which means working out the best way for them to be built and arranged along a street becomes another puzzle.To design its neighbourhoods, Van Wijnen gives its software a large number of constraints, from the requirement that all apartments should have at least 3,000 square metres of floor space and at least one parking space to the requirement that all roof-mounted solar panels get enough sunlight and that there is a variety of different house designs in a street.For now, arranging these pre-designed pieces of a large puzzle pushes the software as far as it can go. Designing a whole house from scratch would involve many more variables – and regulations – than designing a new part for a vehicle. But eventually we might get computers to come up with new architectural designs. It might possible to teach them to design a building in the style of Le Corbusier, the famous Swiss-French architect, says Smith. Or the load-bearing structure of a skyscraper could be designed in the same way as a car chassis, which could let us build taller buildings than we ever could on our own.AlamyAI-aided design could lead to exciting new buildings that rival those created by architect Le Corbusier like the Notre-Dame-du-Haut chapel in Ronchamp, France (Credit: Alamy)There is certainly an appetite for using AI in design. According to Blankenship, sportswear companies like New Balance and Adidas have started looking at generative design as a way to make personalised trainers, offering customers huge variety in the style and function of their footwear. Add in 3D printing –letting you manufacture unorthodox shapes on the spot – and you could generate your customised design on a website and have it made in the shoe shop down the street.This changes the relationship between product designers and their customers. To paraphrase Maurice Conti, who helped pioneer generative design at Autodesk before moving to experimental tech company Alpha in Barcelona: instead of making people want to buy your stuff, you invite them to make stuff they want to buy.There are of course limitations to the technology. ”It’s not magic,” says Kirsh. Some things will be harder for computers to make. For example, many of our most celebrated objects or buildings give us a particular experience or make us feel a certain way. But that’s hard to put into code. “We might not be able to pin down what causes that feeling,” says Kirsh.What’s clear is that designers have a powerful new tool and the best designs will come from a back and forth between human and machine. “Computers will do what computers are good at, people will do what people are good at,” says Bradner.“It’s a fascinating opportunity to think in new ways,” says Smith. “People think it’s going to take away their jobs but it’s going to make them so much better.”  Blankenship agrees. “We could certainly get to a future where a lot of design work is fully automated,” he says. But you still want people to sign off on it. Is it any good? Is it better than the last one? Is it what we want?These are questions only a human can answer. “Otherwise what are we doing it all for? A machine without people doesn’t make any sense,” he says.  Join 900,000+ Future fans by liking us on Facebook, or follow us on Twitter or Instagram. If you liked this story, sign up for the weekly bbc.com features newsletter, called “If You Only Read 6 Things This Week”. A handpicked selection of stories from BBC Future, Culture, Capital, and Travel, delivered to your inbox every Friday.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vZm9ydHVuZS5jb20vMjAxOC8xMS8yOC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1maW5nZXJwcmludHMtc2VjdXJpdHkv0gEA?oc=5,How A.I.-Created Fake Fingerprints Can Fool Biometric Security Systems - Fortune,2018-11-28,Fortune,https://fortune.com,New York University researchers used AI techniques to create fake fingerprints called DeepMasterPrints that fool biometric security systems.,"artificial intelligence, neural network, deep learning, deep fakes, biometric security, cybersecurity, fingerprints, fingerprint scanner",The problem raises the risk of hackers gaining access to online bank accounts.,The problem raises the risk of hackers gaining access to online bank accounts.,,,,,,,,,,,,,,,,"Leadership - Elon MuskElon Musk mulls building an Iron Man ‘flying metal suit of armor’ after Trump assassination attemptBYEva RoytburgJuly 15, 2024",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvc2hvdXJqeWFzYW55YWwvMjAxOC8xMS8yNi80LXdheXMtaW4td2hpY2gtYWktaXMtcmV2b2x1dGlvbml6aW5nLXJlc3BpcmF0b3J5LWNhcmUv0gEA?oc=5,4 Ways In Which AI Is Revolutionizing Respiratory Care - Forbes,2018-11-27,Forbes,https://www.forbes.com,"Since controlling lifestyle choices are a big part of managing chronic pulmonary diseases, smart medical devices such as smart inhalers and smart spirometers could have a significant impact on health outcomes. Here are 5 different ways in which AI is redefining respiratory care.",,"Since controlling lifestyle choices are a big part of managing chronic pulmonary diseases, smart medical devices such as smart inhalers and smart spirometers could have a significant impact on health outcomes. Here are 5 different ways in which AI is redefining respiratory care.","Since controlling lifestyle choices are a big part of managing chronic pulmonary diseases, smart medical devices such as smart inhalers and smart spirometers could have a significant impact on health outcomes. Here are 5 different ways in which AI is redefining respiratory care.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/shourjyasanyal/2018/11/26/4-ways-in-which-ai-is-revolutionizing-respiratory-care/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/dam/imageserve/1072561732/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Shourjya Sanyal', 'url': 'https://www.forbes.com/sites/shourjyasanyal/', 'description': 'I am a CEO and co-founder of a leading AI-powered medical device startup. I have raised VC investments in US and EU, won multiple awards (Luminate in Rochester NY, Irish Laboratory Award 2018-19, Irish SME Business Awards 2018, Top 20 health and Medtech startup by Silicon republic, Deloitte Top Technology Award 2016), given TEDx talks on the topics that I write about. I have a PhD in theoretical physics, and I am a serial entrepreneur with a passion for developing and commercializing cutting-edge technology. I also taught Data Science for a semester in Digital Skills Academy in Dublin.', 'sameAs': ['https://www.twitter.com/@ShourjyaSanyal']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",4 Ways In Which AI Is Revolutionizing Respiratory Care,2018-11-26T22:43:00-05:00,2018-11-27T14:26:36-05:00,AI & Big Data,4 Ways In Which AI Is Revolutionizing Respiratory Care,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI & Big Data', 'item': 'https://www.forbes.com/ai-big-data/'}]",AI & Big Data,,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryInnovationAI & Big Data4 Ways In Which AI Is Revolutionizing Respiratory CareShourjya SanyalFormer ContributorOpinions expressed by Forbes Contributors are their own.I write about AI in Healthcare, data visualisation, and data scienceClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 26, 2018,10:43pm ESTUpdated Nov 27, 2018, 02:26pm ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin300 million people are affected by asthma globally, and 100 million are suffering from the chronic obstructive pulmonary disease (COPD). The treatment of these two diseases costs over €80 billion in the US and Europe each. The direct costs make up almost $50.1 billion, and hospital stays are the most significant part of that cost. For adults, asthma is one of the top reason for underperformance at work. Sufferers miss about 14 million workdays each year, and this equals about $2 billion of indirect asthma costs.
Patients first realize that they have a chronic pulmonary disease like asthma or COPD if symptoms like recurrent wheezing, coughing or difficulty in breathing appear. A pulmonologist would then use a spirometer to formally diagnose the condition. The pulmonologist then managed by a combination of lifestyle choices and medication. Lifestyle choices include avoiding triggers such as cigarette smoke, pets, or aspirin. Medication is generally inhaled using an inhaler and can be quick-relief medications (such as beta2-adrenoceptor agonists or salbutamol) or long-term control medication (such as corticosteroids or Long-acting beta-adrenoceptor agonists).

Given that controlling lifestyle choices are a big part of preventing and managing chronic pulmonary diseases, smart medical devices such as smart inhalers and smart spirometers could have a significant impact on health outcomes. Here are 5 different ways in which AI is redefining respiratory care,








Lungs human organ of respiration from futuristic polygonal red lines and glowing stars for banner,... [+] poster, greeting card. Vector illustration.
Getty




PROMOTED
1. AI aided inhaler based medication adherence solutions
Since the delivery of respiratory medication is primarily achieved through inhalers which involves several steps, 50% of all patients fail to take their daily medication as prescribed. Monitoring the correctness of the drug delivery technique, as well as tracking whether the patient is adhering to the prescribed regimen is vital to improving the effectiveness of respiratory care pathways. Amiko's Respiro® Sense technology is a CE Marked smart inhaler that can track both patient adherence and delivery technique and report it back to the physician. The Respiro® Sense technology is available to consumers as either standalone smart inhalers or can be integrated as an add-on device to their current inhalers. Respiro® Sensors have built-in artificial intelligence that can offer individualized guidance to patients such as smart dose reminders and how to improve the quality of the inhalation technique. Adherium's Hailie™ solution is an FDA 510(k) approved and CE Marked devices and software, that provides similar medication reminders and to monitor inhaler usage. Adherium claims that the Hailie™ platform increases adherence to preventative medication by 180% in children and 59% in adults. Propeller Health's smart inhaler platform has eight FDA 510(k) approvals and provides similar medication reminders. Propeller Health has done studies showing 58% improvement in medication adherence. Other smart inhaler platforms such as Inspiro Medical was bought by Opko in 2014, and Gecko Health Innovations was acquired by Teva Pharmaceuticals in 2015.








A flat lay of red asthma inhaler device against white background
Getty





2. AI aided early warning system
The Propeller spirometer and app uses advanced analytics to help patients identify triggers, symptoms, trends and other personalized insights. Also, Propeller's Air is an open API that uses machine learning from Propeller devices and environmental sources and can predict how asthma may be affected by local environmental conditions.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



3. AI aided diagnostics
Smart spirometers such as NUVOair's Air Next can provide automatic pre and post-bronchodilator analysis and automated data interpretation. Smart spirometers such as Cohero Health's FDA approved mSpirometer® sensor and BreatheSmart® app provides clinical metrics and their interpretations.
4. AI aided lung imaging
Companies such as Fluidda are using artificial intelligence to combine High-resolution CT Scan images with advanced Computational Fluid Dynamics (CFD) tools to help pulmonologists visualize both structural and functional parameters of the lungs. They provide pulmonologists with detailed color-coded images, allowing pulmonologists to provide patient-specific parameters such as airway resistance and aerosol deposition characteristics.Shourjya SanyalI am a CEO and co-founder of a leading AI-powered medical device startup. I have raised VC investments in US and EU, won multiple awards (Luminate in... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiLGh0dHBzOi8vZmVkc2Nvb3AuY29tL2hvdy10by13b3JrLXdpdGgtZGFycGEv0gEA?oc=5,"How to work with DARPA, according to DARPA - FedScoop",2018-11-29,FedScoop,https://fedscoop.com,"""Do your homework beforehand.""","['defense advanced research projects agency (darpa)', 'department of defense (dod)', 'fed tech', 'military', 'national security', 'research', 'science', 'startups']","""Do your homework beforehand.""",,https://schema.org,NewsArticle,http://fedscoop.com/how-to-work-with-darpa/,"{'@type': 'ImageObject', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2017/06/LUKE-Arm-Fist-Bump-Original.jpg'}","[{'@type': 'Person', 'name': 'Tajha Chappellet-Lanier'}]","{'@type': 'Organization', 'name': 'FedScoop', 'logo': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/cropped-fs_favicon-3.png'}","How to work with DARPA, according to DARPA",2018-11-29T20:36:32Z,2018-11-29T20:37:11Z,Defense,,,,,,"






Defense




								How to work with DARPA, according to DARPA							

								""Do your homework beforehand.""							


By
Tajha Chappellet-Lanier



November 29, 2018






 
											DARPA's prosthetic LUKE arm gets a fist bump at Walter Reed National Military Medical Center in December 2016. (DARPA.mil)										





Entrepreneurs and startup companies wishing to work with the Defense Advanced Research Projects Agency (DARPA) would be well-advised to do a little homework prior.
In a presentation at a pitch day for the most recent cohort of federal technology accelerator Fed Tech on Tuesday, DARPA’s senior adviser for commercial strategy, David Henshall, offered this and other tips.
“The key is — be familiar with the opportunities of national security,” Henshall said. “The first thing is what are the problems we’re trying to solve, and become familiar with that.” He suggested that a bit of good old-fashioned internet sleuthing can go a long way. “Read our website and find out what we’re working on. Find out who’s there. And then find out the program manager that’s interested in the technology space you’re dealing with.”
Once you’ve identified a program manager in your area of expertise, Henshall said, contact that person. Most will be very willing to take a short meeting with an entrepreneur or company working in their subject matter area. But don’t waste that time.


Advertisement



“Make sure you’re not asking him questions that you could have read on the website because your 30 minutes is being used up,” he said. “Do your homework beforehand.”
And lastly, be patient. “People say it’s like dating,” Henshall joked. You won’t walk out of a first meeting with research grant money in hand, so that shouldn’t be the goal. Use the first meeting to get to the second meeting, and so on.
Follow these tips, and partnership with DARPA presents the opportunity to work on some big and interesting research challenges. For example, in September the agency announced that it plans to spend $2 billion on research into so-called “third wave” artificial intelligence capacities over the next few years.
The initiative, called “AI Next,” is concerned with moving AI beyond the mode where it needs lots of high-quality training data in myriad situations to develop an algorithm. The goal is to get the technology to a place where machines adapt to changing situations the way human intelligence does.








Written by Tajha Chappellet-Lanier
			Tajha Chappellet-Lanier is a technology reporter at FedScoop. She previously worked for Technical.ly DC, NPR and USA Today. If she had a superpower, it'd be navigating foreign metro systems.		


In This Story



														national security													



														startups													



														research													



														Department of Defense (DOD)													



														Science													



														Defense Advanced Research Projects Agency (DARPA)													



														Military													



														Fed Tech													








Share




Facebook





LinkedIn





Twitter





Copy Link











Advertisement






Advertisement





More Like This






								Bipartisan Senate bill aims to ban U.S. agency purchases of counterfeit electronics 			



By 

						Madison Alder					










								How the IRS’s ‘cautious’ approach with Direct File prevented its ‘failure’			



By 

						Matt Bracken					










								ACLU seeks AI records from NSA, Defense Department in new lawsuit			



By 

						Madison Alder					









Advertisement





Top Stories






								FedRAMP ‘undeniably’ in state of limbo without final OMB modernization guidance, Rep. Connolly says			



By 

						Caroline Nihill					










								Energy Department’s national labs get AI boost in bipartisan Senate bill			



By 

						Matt Bracken					










								GSA begins FedRAMP pilot to change request process			



By 

						Caroline Nihill					










								White House to require increased cybersecurity protocols for R&D institutions			



By 

						Caroline Nihill					










								Chevron’s downfall highlights need for clear artificial intelligence laws			



By 

						Madison Alder					

						Rebecca Heilweil					










								FTC modernization, enforcement efforts jeopardized by cuts, officials say			



By 

						Caroline Nihill					










Advertisement






","{'@type': 'WebPage', '@id': 'http://fedscoop.com/how-to-work-with-darpa/'}",,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://fedscoop.com/how-to-work-with-darpa/', 'url': 'https://fedscoop.com/how-to-work-with-darpa/', 'name': 'How to work with DARPA, according to DARPA | FedScoop', 'isPartOf': {'@id': 'https://fedscoop.com/#website'}, 'primaryImageOfPage': {'@id': 'https://fedscoop.com/how-to-work-with-darpa/#primaryimage'}, 'image': {'@id': 'https://fedscoop.com/how-to-work-with-darpa/#primaryimage'}, 'thumbnailUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2017/06/LUKE-Arm-Fist-Bump-Original.jpg', 'datePublished': '2018-11-29T20:36:32+00:00', 'dateModified': '2018-11-29T20:37:11+00:00', 'description': '""Do your homework beforehand.""', 'breadcrumb': {'@id': 'https://fedscoop.com/how-to-work-with-darpa/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://fedscoop.com/how-to-work-with-darpa/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/how-to-work-with-darpa/#primaryimage', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2017/06/LUKE-Arm-Fist-Bump-Original.jpg', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2017/06/LUKE-Arm-Fist-Bump-Original.jpg', 'width': 1920, 'height': 1280, 'caption': ""DARPA's prosthetic LUKE arm gets a fist bump at Walter Reed National Military Medical Center in December 2016. (DARPA.mil)""}, {'@type': 'BreadcrumbList', '@id': 'https://fedscoop.com/how-to-work-with-darpa/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://fedscoop.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How to work with DARPA, according to DARPA'}]}, {'@type': 'WebSite', '@id': 'https://fedscoop.com/#website', 'url': 'https://fedscoop.com/', 'name': 'FedScoop', 'description': 'FedScoop delivers up-to-the-minute breaking government tech news and is the government IT community&#039;s platform for education and collaboration through news, events, radio and TV. FedScoop engages top leaders from the White House, federal agencies, academia and the tech industry both online and in person to discuss ways technology can improve government, and to exchange best practices and identify how to achieve common goals.', 'publisher': {'@id': 'https://fedscoop.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://fedscoop.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://fedscoop.com/#organization', 'name': 'FedScoop', 'url': 'https://fedscoop.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/#/schema/logo/image/', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'width': 1231, 'height': 182, 'caption': 'FedScoop'}, 'image': {'@id': 'https://fedscoop.com/#/schema/logo/image/'}}]",,,https://fedscoop.com/wp-content/uploads/sites/5/2017/06/LUKE-Arm-Fist-Bump-Original.jpg?w=150&h=150&crop=1,2018-11-29T20:36:32Z,,,,,,,,,['Tajha Chappellet-Lanier'],,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vZW1lcmouY29tL2FpLWZ1dHVyZS1vdXRsb29rL21lcmNlZGVzLXRvLXJlcGxhY2Utcm9ib3RzLXdpdGgtaHVtYW4tYmVpbmdzL9IBAA?oc=5,Mercedes-Benz to Replace Robots with Human Beings - Emerj,2018-11-29,Emerj,https://emerj.com,,,How many times have you heard tales of automation and job loss? How fervently have these harbingers announced the arrival of robot-run industries? The,,https://schema.org,Article,,https://emerj.com/wp-content/uploads/2018/04/AutoRobots-690x255.jpg,Dyllan Furness,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",Mercedes-Benz to Replace Robots with Human Beings,2016-03-01,2018-11-29,,,,,,," AI Future Outlook Mercedes-Benz to Replace Robots with Human Beings Dyllan FurnessLast updated on November 29, 2018  Last updated on November 29, 2018, published by Dyllan Furness Dyllan explores technology and the human condition for Tech Emergence. His interests include but are not limited to whiskey, kimchi, and Catahoulas. Share to: LinkedIn Twitter Facebook Email  How many times have you heard tales of automation and job loss? How fervently have these harbingers announced the arrival of robot-run industries? The International Federation of Robotics recently projected that about 1.3 million industrial robots will be put into operation within the next couple years. From experts to laymen, automation is too tempting and unsettling a topic to ignore.  And yet, one of the world’s biggest automobile manufacturers is flipping this trend by replacing robots with human beings. According to Bloomberg, Mercedes-Benz’s move towards vehicle customization has lead them to rethink the role of unmanned machines in their factories. “Robots can’t deal with the degree of individualization and the many variants that we have today,” Markus Schaefer – who heads Mercedes’s production – told Bloomberg. “We’re saving money and safeguarding our future by employing more people.” Schaefer has a tall task ahead of him, with his want to decrease production hours from 61 in 2005 to just 30 moving forward.  Cars like the Mercedes’s S-Class sedan offers buyers options like carbon-fiber trim, temperature controlled cupholders, and various caps for tire valves. The number of options may be overwhelming for some buyers – and they’re also too complex for factory robots to process and install efficiently. Robots may be highly adept at performing programmed tasks but the need for versatile leaves them at a loss. Bloomberg points out how, just in the past 15 years, the number of car models has more than doubled for luxury car makers like Mercedes, BMW, and Audi.  With robots replaced by skilled human workers, Mercedes is able to rearrange their production line to build a new vehicle in just a few days. It would take weeks to accomplish this same task with robots, who’s defined functions would need to be reprogrammed. “The variety is too much to take on for the machines, Schaefer told Bloomberg, “They can’t work with all the different options and keep pace with changes.” To be sure, Mercedes doesn’t intend to sack robots entirely. Instead, they plan on implementing what they call “robot farming” – which is much less malicious than it sounds. Rather than using massive robots to perform a myriad of tasks, the manufacturer will equip their human workers with more mobile, more compact, and more flexible robots. In an immediate example, Mercedes plans to replace two of its larger, immobile robots with one lighter, mobile one or an actual human worker. They hope this degree of flexibility will help streamline installation of their new E-Class’s head-up display, which use be installed directly onto the car’s windshield. “We’re moving away from trying to maximize automation with people taking a bigger part in the industrial processes again,” Schaefer says. “We need to be more flexible.” Image credit: Siemens Related Posts Making Robots More Humane at Brown UniversityBefore we welcome a new technology into our lives, it’s wise to consider what effect… Should the United Nations Play a Role in Guiding Post-Human Artificial Intelligence?This article is the fifth installment in the AI FutureScape series, and in it, we… The Role of Business and Government Leaders in Guiding Post-Human IntelligenceWe've reached the sixth and final installment of the AI FutureScape series. In this article,… How Will We Reach the Singularity? - AI, Neurotechnologies, and MoreIn this installment of the FutureScape series, we discuss what our survey participants had to… Soylent and How Ideals Drive the FutureOkay, I give. Soylent has made it's way onto 3/4 of the blogs that I… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",https://emerj.com/ai-future-outlook/mercedes-to-replace-robots-with-human-beings,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,AI Future Outlook,462.0,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vYW5hbHl0aWNzaW5kaWFtYWcuY29tLzUtd2F5cy1pbi13aGljaC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1oYXMtY2hhbmdlZC1zbWFydHBob25lLWNhbWVyYXMv0gEA?oc=5,5 Ways In Which Artificial Intelligence Has Changed Smartphone Cameras – AIM - AIM,2018-11-26,AIM,https://analyticsindiamag.com,,,,,,,,,,,,,,,,,,,,"










				Vector Databases are Ridiculously Good			



			Anshul Vipat		

			15/07/2024		


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMinAFodHRwczovL20uZWNvbm9taWN0aW1lcy5jb20vdGVjaC9zb2Z0d2FyZS9ob3ctYWktY2FuLWluY3JlYXNlLXRoZS1yZWFjaC1vZi1pbmRpYXMtcHVibGljLXdlbGZhcmUtcHJvZ3JhbW1lcy1hbmQtbWFrZS10aGVtLWVmZmljaWVudC9hcnRpY2xlc2hvdy82Njg0MTUyNy5jbXPSAaABaHR0cHM6Ly9tLmVjb25vbWljdGltZXMuY29tL3RlY2gvc29mdHdhcmUvaG93LWFpLWNhbi1pbmNyZWFzZS10aGUtcmVhY2gtb2YtaW5kaWFzLXB1YmxpYy13ZWxmYXJlLXByb2dyYW1tZXMtYW5kLW1ha2UtdGhlbS1lZmZpY2llbnQvYW1wX2FydGljbGVzaG93LzY2ODQxNTI3LmNtcw?oc=5,How AI can increase the reach of India's public welfare programmes and make them efficient - The Economic Times,2018-11-28,The Economic Times,https://m.economictimes.com,"While India gears up for a brighter future powered by its ‘AI for All mission, policymakers must put processes in place to fully harness the power of this disruptive technology. ","['artificial intelligence', 'public welfare schemes', 'AI for All mission', 'ai', 'india news']","While India gears up for a brighter future powered by its ‘AI for All mission, policymakers must put processes in place to fully harness the power of this disruptive technology. ","While India gears up for a brighter future powered by its ‘AI for All mission, policymakers must put processes in place to fully harness the power of this disruptive technology. ",https://schema.org/,WebPage,https://economictimes.indiatimes.com/tech/software/how-ai-can-increase-the-reach-of-indias-public-welfare-programmes-and-make-them-efficient/articleshow/66841527.cms,"{'@type': 'ImageObject', 'url': 'https://img.etimg.com/thumb/msid-66841527,resizemode-4,width-1200,height-900,imgsize-656590,overlay-ettech/photo.jpg', 'width': 1200, 'height': 900}","{'@type': 'Thing', 'name': 'ET CONTRIBUTORS'}","{'@type': 'NewsMediaOrganization', 'name': 'Economic Times', 'logo': {'@type': 'ImageObject', 'url': 'https://img.etimg.com/thumb/msid-76939477,width-600,height-60,quality-100/economictimes.jpg', 'width': 600, 'height': 60}}",How AI can increase the reach of India's public welfare programmes and make them efficient,2018-11-28T12:53:00+05:30,2018-11-28T12:53:00+05:30,Tech,How AI can increase the reach of India's public welfare programmes and make them efficient,https://schema.org/False,,,,"Getty ImagesA study by consultancy firm Accenture showed AI could boost India’s annual growth rate by 1.3 percentage points by 2035. Let us see how AI can transform critical areas of public spending. By Sanjeev Sharma India, the second most populous country in the world, runs a host of socially beneficial programs. Most of such programs aim to reach the millions of people who live in remote areas of our extensive nation. From providing mid-day meals for under-privileged school children to making modern healthcare accessible to residents of far-flung rural areas, our nation spends significant resources to ensure its policies reach the right people at the right time.Elevate Your Tech Prowess with High-Value Skill CoursesOffering CollegeCourseWebsiteIIT DelhiCertificate Programme in Data Science & Machine LearningVisitMIT xPROMIT Technology Leadership and InnovationVisitIndian School of BusinessProfessional Certificate in Product ManagementVisitMaking sure government services reach all 1.3 billion citizens, including those residing in remote regions, is a daunting task. AI-powered systems can become leapfrog technologies for our nation, transforming the reach and effectiveness of public welfare programs.     by Taboolaby TaboolaSponsored LinksSponsored LinksPromoted LinksPromoted LinksYou May LikeTop Doctors 'Anti-Lazy' Drops Are Going Viral This JulyHealth HeadlinesBuy NowUndoThe implications are profound. A study by consultancy firm Accenture showed AI could boost India’s annual growth rate by 1.3 percentage points by 2035. Let us see how AI can transform critical areas of public spending. Despite increased investment, India’s public healthcare system has struggled to cope with the needs of its vast, growing population. Only a third of Indians have any medical insurance and government spending on health is equivalent to just 1.1 percent of GDP. Private healthcare is a steep cost for most Indians. Play VideoPlaySkip BackwardSkip ForwardUnmuteCurrent Time 0:00/Duration 56:25Loaded: 0.92%00:00Stream Type LIVESeek to live, currently behind liveLIVERemaining Time -56:25 1xPlayback RateChaptersChaptersDescriptionsdescriptions off, selectedCaptionscaptions settings, opens captions settings dialogcaptions off, selectedAudio Trackdefault, selectedPicture-in-PictureFullscreenThis is a modal window.Beginning of dialog window. Escape will cancel and close the window.TextColorWhiteBlackRedGreenBlueYellowMagentaCyanOpacityOpaqueSemi-TransparentText BackgroundColorBlackWhiteRedGreenBlueYellowMagentaCyanOpacityOpaqueSemi-TransparentTransparentCaption Area BackgroundColorBlackWhiteRedGreenBlueYellowMagentaCyanOpacityTransparentSemi-TransparentOpaqueFont Size50%75%100%125%150%175%200%300%400%Text Edge StyleNoneRaisedDepressedUniformDrop shadowFont FamilyProportional Sans-SerifMonospace Sans-SerifProportional SerifMonospace SerifCasualScriptSmall CapsReset restore all settings to the default valuesDoneClose Modal DialogEnd of dialog window.Advertisement: 0:17According to recent media reports, every year some 36 million families, or 14 percent of households, face an unexpected medical bill equal to the entire annual living expenses of one member of the family.Discover the stories of your interestBlockchain5 StoriesCyber-safety7 StoriesFintech9 StoriesE-comm9 StoriesML8 StoriesEdtech6 StoriesTechnology might have the answer to this complex problem. For instance, an AI-powered digital platform that collates data on symptoms and suggests treatment based on similar cases will make the diagnostic process far more accurate in public hospitals. Also, such a system can be quickly scaled up to cover major urban centers and remote areas, which lack adequate medical infrastructure. The Indian government recently launched, what is possibly the world’s largest public health insurance scheme. A scheme of such scope and scale can benefit from technologies like AI on allocation, geographic spread, checking veracity of health records and applicants, claim patterns and trends, ensuring the scheme reaches those who need it the most. The government’s mid-day meal scheme, among the nation’s better-known federal programs, aims to reduce malnutrition in children and increase enrolment rates in schools. On the flipside, the program diverted attention of teachers and students away from education and toward carrying out tasks such as inspecting the quality and quantity of the food, according to a government report. AI technologies can help overcome this challenge. Machine learning technology and supply chain planning could forecast inventory, while process automation technology would ensure the right amount of high quality food reaches schools on time.Another major focus of the government’s public spending is alleviating water shortages. Despite having over 18 percent of the world's population, India has only 4 percent of the total available water resources. A study by the National Institute for Transforming India (NITI Aayog), the government’s think tank, said that about 100 million people are at risk of losing access to drinking water by 2030. To prevent that, our cities will need to double their existing water availability. Steps such as desalination and rain-water harvesting will help, but won’t be enough to bridge the shortage. AI-powered smart water management systems, such as digital flowmeters that track, measure and optimize water consumption in real time, can be the answer. This has already been implemented in parts of India and Africa. In Surat, such flowmeters have helped the municipality do a more effective job of monitoring water consumption at 500 textile mills and make smarter decisions on distribution. A similar solution in Algeria resulted in fresh drinking water for nearly 160,000 people in water-scare regions.Clearly, AI-powered systems can help make public spending better targeted, and much more efficient than it is today. AI-powered platforms that have a large number of connected devices will provide a strong foundation to integrate devices into services such as cloud storage that reduce dependency on physical systems and strengthen information security. Yet more needs to be done to realize AI’s potential transformative impact. The government and private organizations must work together to overcome existing challenges such as lack of awareness among stakeholders and unclear privacy and security regulations. According to latest reports on India’s AI potential, India needs more robust systems to assimilate, analyze and store high-quality data securely, something that companies like ours can help the government with. It is encouraging to see that the government is moving forward with the intent to tackle these challenges. The budgetary allocation to research, training and skill development in AI, digital manufacturing and robotics – part of “Digital India” program - has been doubled this year. NITI Aayog has started working with major companies, including ours, to work on various aspects of AI, and increase awareness about emerging areas like advanced manufacturing powered by AI and robotics. Over time, such actions will lead to concrete proposals that the government can implement to usher in the Fourth Industrial Revolution, which will bring people, technology and data together. This will help India close the loop between data and action and pave the way for the nation’s emergence as a global economic and technological superpower. (The author is Managing Director, ABB India)(Disclaimer: The opinions expressed in this column are that of the writer. The facts and opinions expressed here do not reflect the views of www.economictimes.com.)    by Taboolaby TaboolaSponsored LinksSponsored LinksPromoted LinksPromoted LinksYou May LikeNew and Permanent Teeth in 24 Hours - Life Changing!Now offering No Credit Check in-house financing. Low Down payment - 0% Interest - Extended monthly terms - Payments from $250 a month for full-mouth dental implantsG4 By GolpaLearn MoreUndoHorror Stories Of Entitled PeopleA family of 5 gets on my flight. I was in the bathroom at the time, as I returned to my seat, my stuff was gone and the mother was sitting in my spot. “Wait at the back of the plane” she says. Nope. She messed with the wrong man.MoneyMadeRead MoreUndoAmazon's Worst Nightmare: Thousands Canceling Prime for This Clever HackThis simple trick can save tons of money on Amazon, but most Prime members are ignoring it.Coupon Code FinderUndo2 Cards Charging 0% Interest Until Nearly 2026With no annual fee and no interest until nearly 2026, this card is helping Americans pay off debt in record time.CompareCreditUndoSurgeon Reveals: Don't Laser Your Dark Spots! (Use This Household Item Instead)Miami M.D.UndoSeniors are Paying Next to Nothing for Viking River Cruises (See How)River CruiseLearn MoreUndoThis New AC Cooler Cools the Room In SecondsSherumLearn MoreUndoUnbelievable: Calculator Shows The Value Of Your House Instantly (Take a Look)search by your address to see your home's value instantlyHome Value Calculator | Search Ads Search NowUndoDon't Pay For New Gutters. Get This 3-In-1 System InsteadLeaf Filter USALearn MoreUndoRead More News onartificial intelligencepublic welfare schemesAI for All missionaiindia news",https://economictimes.indiatimes.com/tech/software/how-ai-can-increase-the-reach-of-indias-public-welfare-programmes-and-make-them-efficient/articleshow/66841527.cms,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'https://schema.org/False', 'cssSelector': '.paywall'}",,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Economic Times', 'productID': 'prime.economictimes.indiatimes.com:prime'}","{'@type': 'ImageObject', 'url': 'https://img.etimg.com/thumb/msid-76939477,width-600,height-60,quality-100/economictimes.jpg', 'width': 600, 'height': 60}",,,,,,,,"{'@type': 'SpeakableSpecification', 'cssSelector': ['.article_wrap h1', '.artSyn h2']}","By Sanjeev Sharma India, the second most populous country in the world, runs a host of socially beneficial programs. Most of such programs aim to reach the millions of people who live in remote areas of our extensive nation. From providing mid-day meals for under-privileged school children to making modern healthcare accessible to residents of far-flung rural areas, our nation spends significant resources to ensure its policies reach the right people at the right time.Making sure government services reach all 1.3 billion citizens, including those residing in remote regions, is a daunting task. AI-powered systems can become leapfrog technologies for our nation, transforming the reach and effectiveness of public welfare programs. The implications are profound. A study by consultancy firm Accenture showed AI could boost India’s annual growth rate by 1.3 percentage points by 2035. Let us see how AI can transform critical areas of public spending. Despite increased investment, India’s public healthcare system has struggled to cope with the needs of its vast, growing population. Only a third of Indians have any medical insurance and government spending on health is equivalent to just 1.1 percent of GDP. Private healthcare is a steep cost for most Indians. According to recent media reports, every year some 36 million families, or 14 percent of households, face an unexpected medical bill equal to the entire annual living expenses of one member of the family.Technology might have the answer to this complex problem. For instance, an AI-powered digital platform that collates data on symptoms and suggests treatment based on similar cases will make the diagnostic process far more accurate in public hospitals. Also, such a system can be quickly scaled up to cover major urban centers and remote areas, which lack adequate medical infrastructure. The Indian government recently launched, what is possibly the world’s largest public health insurance scheme. A scheme of such scope and scale can benefit from technologies like AI on allocation, geographic spread, checking veracity of health records and applicants, claim patterns and trends, ensuring the scheme reaches those who need it the most. The government’s mid-day meal scheme, among the nation’s better-known federal programs, aims to reduce malnutrition in children and increase enrolment rates in schools. On the flipside, the program diverted attention of teachers and students away from education and toward carrying out tasks such as inspecting the quality and quantity of the food, according to a government report. AI technologies can help overcome this challenge. Machine learning technology and supply chain planning could forecast inventory, while process automation technology would ensure the right amount of high quality food reaches schools on time.Another major focus of the government’s public spending is alleviating water shortages. Despite having over 18 percent of the world's population, India has only 4 percent of the total available water resources. A study by the National Institute for Transforming India (NITI Aayog), the government’s think tank, said that about 100 million people are at risk of losing access to drinking water by 2030. To prevent that, our cities will need to double their existing water availability. Steps such as desalination and rain-water harvesting will help, but won’t be enough to bridge the shortage. AI-powered smart water management systems, such as digital flowmeters that track, measure and optimize water consumption in real time, can be the answer. This has already been implemented in parts of India and Africa. In Surat, such flowmeters have helped the municipality do a more effective job of monitoring water consumption at 500 textile mills and make smarter decisions on distribution. A similar solution in Algeria resulted in fresh drinking water for nearly 160,000 people in water-scare regions.Clearly, AI-powered systems can help make public spending better targeted, and much more efficient than it is today. AI-powered platforms that have a large number of connected devices will provide a strong foundation to integrate devices into services such as cloud storage that reduce dependency on physical systems and strengthen information security. Yet more needs to be done to realize AI’s potential transformative impact. The government and private organizations must work together to overcome existing challenges such as lack of awareness among stakeholders and unclear privacy and security regulations. According to latest reports on India’s AI potential, India needs more robust systems to assimilate, analyze and store high-quality data securely, something that companies like ours can help the government with. It is encouraging to see that the government is moving forward with the intent to tackle these challenges. The budgetary allocation to research, training and skill development in AI, digital manufacturing and robotics – part of “Digital India” program - has been doubled this year. NITI Aayog has started working with major companies, including ours, to work on various aspects of AI, and increase awareness about emerging areas like advanced manufacturing powered by AI and robotics. Over time, such actions will lead to concrete proposals that the government can implement to usher in the Fourth Industrial Revolution, which will bring people, technology and data together. This will help India close the loop between data and action and pave the way for the nation’s emergence as a global economic and technological superpower. (The author is Managing Director, ABB India)",,,,,,,,,,,,,,,,,,,,en,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmRpZ2l0YWxpbmZvcm1hdGlvbndvcmxkLmNvbS8yMDE4LzExL2luZm9ncmFwaGljLWZvcmVjYXN0aW5nLWEtcm9ib3QtZHJpdmVuLXdvcmtwbGFjZS5odG1s0gEA?oc=5,The Chances of Automation Taking Away Your Livelihood (infographic) - Digital Information World,2018-11-26,Digital Information World,https://www.digitalinformationworld.com,A recent study by the Mckinsey Global Institute forecasts up to 800 million workers worldwide could lose their jobs to automation by 2030. The following infographic is going to tell you what jobs are going to become fully automated in the near future. This will help you understand if your job is in danger in the first place.,,A recent study by the Mckinsey Global Institute forecasts up to 800 million workers worldwide could lose their jobs to automation by 2030. The following infographic is going to tell you what jobs are going to become fully automated in the near future. This will help you understand if your job is in danger in the first place.,,https://schema.org,,,,,,,,,,,,,,,"



The Chances of Automation Taking Away Your Livelihood (infographic)







Zia Muhammad


11/26/2018 11:30:00 AM










We live in a day and age where everything is becoming increasingly automated. What this means is that robots are going to start doing a lot of things for us. Pretty much everything can be automated. Indeed, you would be surprised at just how many things robots can already do, let alone what they might be able to accomplish in the future.

There are a number of benefits associated with automation. Things will happen more efficiently, a lot of the more dangerous jobs that humans have had to do will be done by robots which means that fewer people will end up getting injured or potentially even killed in the line of duty. All of that being said, while it is definitely a good sign that tasks are going to end up becoming increasingly automated, it is also true that the robots that will be doing these jobs are going to end up putting real human beings out of work.

Related: Protecting Your Job Against Robots And Artificial Intelligence (infographic)
This is pretty understandable. After all, why would anyone hire and pay a regular salary person to do a job that a robot will end up doing for free. Previous stages of automation meant that humans could be hired to maintain the robots that were taking their jobs, but now automation is getting to a point where it is becoming self sustaining.

What this means is that you might end up losing your job because of automation and not have any other options to look into. You don’t need to panic just yet, though. The infographic below is going to tell you what jobs are going to become fully automated in the near future. This will help you understand if your job is in danger in the first place.



Key Stats from above visual:

Nearly one fifth of the global workforce could feel the impact of artificial intelligence (AI) advancements in their workplace by 2020.

Roles like data entry, accounting and assembly workers are likely to become redundant, after the revolution of automation.

While AI will make some jobs obsolete, experts predict it will make way for job creation in other areas, including, robotics engineers, innovation professionals and solution designers.



Tags:
AI
artificial-intelligence
Automation
infographic
news
robots
Technology




Facebook
Twitter






",,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.digitalinformationworld.com/2018/11/infographic-forecasting-a-robot-driven-workplace.html'}, 'headline': 'The Chances of Automation Taking Away Your Livelihood (infographic)', 'description': ' We live in a day and age where everything is becoming increasingly automated. What this means is that robots are going to start doing a lot...', 'datePublished': '2018-11-26T11:30:00+05:00', 'dateModified': '2018-11-26T11:30:19+05:00', 'image': {'@type': 'ImageObject', 'url': 'https://lh3.googleusercontent.com/blogger_img_proxy/AEn0k_tRCKKPHAhs-TCkJxisF-m1C1wurK0UZVHsYhOL_7TZRsFMyALckm8fouZn8OnCjPZXuexF6dOa5t8gtlSefXYzW1Y=w1200-h675-p-k-no-nu', 'height': 675, 'width': 1200}, 'author': {'@type': 'Person', 'name': 'Zia Muhammad', 'url': 'https://www.blogger.com/profile/07437506889676219023'}, 'publisher': {'@type': 'Organization', 'name': 'Digital Information World', 'logo': {'@type': 'ImageObject', 'url': 'https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_2G7rZnwmyZTDMLFoY-riJL0i1M8mrCeMuoh49crmbIg85m29MrYPmPukirz-B7Cr9oHirJvr-Sq7FcQW5vpQxtGdoZDCFxeHphbeU0uSuBl5kKuG-JF5QilaaloAH-QVs0zNBib5ub7VFixG30fqmfQbQr5z9MGrcJ_V5GfVVevCiRTeOpnvy7Ii/s200/digital-information-world-logo.png', 'width': 206, 'height': 60}}}, {'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.digitalinformationworld.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'AI', 'item': 'https://www.digitalinformationworld.com/search/label/AI'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Chances of Automation Taking Away Your Livelihood (infographic)', 'item': 'https://www.digitalinformationworld.com/2018/11/infographic-forecasting-a-robot-driven-workplace.html'}]}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vc2xvYW5yZXZpZXcubWl0LmVkdS9hcnRpY2xlL3VzaW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvLXByb21vdGUtZGl2ZXJzaXR5L9IBAA?oc=5,Using Artificial Intelligence to Promote Diversity - MIT Sloan Management Review,2018-11-21,MIT Sloan Management Review,https://sloanreview.mit.edu,"What if, instead of perpetuating harmful biases, AI helped us overcome them?",,"What if, instead of perpetuating harmful biases, AI helped us overcome them?","What if, instead of perpetuating harmful biases, AI helped us overcome them?
",,,,,,,,,,,,,,,,"


Magazine Winter 2019 Issue Frontiers Research Highlight Using Artificial Intelligence to Promote Diversity
AI can help us overcome biases instead of perpetuating them, with guidance from the humans who design, train, and refine its systems.


Paul R. Daugherty, H. James Wilson, and Rumman Chowdhury

November 21, 2018

Reading Time: 7 min 





Topics


Data, AI, & Machine Learning


Leadership


Managing Technology


Workplace, Teams, & Culture


Leadership Skills


Leading Change


AI & Machine Learning


Automation


Technology Innovation Strategy


Equality


Diversity & Inclusion


Organizational Behavior




Frontiers

            An MIT SMR initiative exploring how technology is reshaping the practice of management.        

              
           More in this series
                      




 subscribe-icon

Subscribe
 












Permissions and PDF
 










Share



 Twitter



Facebook







Linkedin










What to Read Next

 How to Create Slides That Suit Your Superiors: 11 Tips | Nancy Duarte
 Will AI Help or Hurt Sustainability? Yes | Andrew Winston
 Eight Essential Interview Questions CEOs Swear By
 Make a Stronger Business Case for Sustainability
















Artificial intelligence has had some justifiably bad press recently. Some of the worst stories have been about systems that exhibit racial or gender bias in facial recognition applications or in evaluating people for jobs, loans, or other considerations.1 One program was routinely recommending longer prison sentences for blacks than for whites on the basis of the flawed use of recidivism data.2
But what if instead of perpetuating harmful biases, AI helped us overcome them and make fairer decisions? That could eventually result in a more diverse and inclusive world. What if, for instance, intelligent machines could help organizations recognize all worthy job candidates by avoiding the usual hidden prejudices that derail applicants who don’t look or sound like those in power or who don’t have the “right” institutions listed on their résumés? What if software programs were able to account for the inequities that have limited the access of minorities to mortgages and other loans? In other words, what if our systems were taught to ignore data about race, gender, sexual orientation, and other characteristics that aren’t relevant to the decisions at hand?
AI can do all of this — with guidance from the human experts who create, train, and refine its systems. Specifically, the people working with the technology must do a much better job of building inclusion and diversity into AI design by using the right data to train AI systems to be inclusive and thinking about gender roles and diversity when developing bots and other applications that engage with the public.


Get Updates on Leading With AI and Data

Get monthly insights on how artificial intelligence impacts your organization and what it means for your company and customers.


















                sign up            




Please enter a valid email address
Thank you for signing up
Privacy Policy


Design for Inclusion
Software development remains the province of males — only about one-quarter of computer scientists in the United States are women3 — and minority racial groups, including blacks and Hispanics, are underrepresented in tech work, too.4 Groups like Girls Who Code and AI4ALL have been founded to help close those gaps. Girls Who Code has reached almost 90,000 girls from various backgrounds in all 50 states,5 and AI4ALL specifically targets girls in minority communities. 



Topics


Data, AI, & Machine Learning


Leadership


Managing Technology


Workplace, Teams, & Culture


Leadership Skills


Leading Change


AI & Machine Learning


Automation


Technology Innovation Strategy


Equality


Diversity & Inclusion


Organizational Behavior




Frontiers

            An MIT SMR initiative exploring how technology is reshaping the practice of management.        

              
           More in this series
                      



About the Authors
Paul R. Daugherty is Accenture’s chief technology and innovation officer. He tweets @pauldaugh. H. James Wilson is managing director of IT and business research at Accenture Research. He tweets @hjameswilson. Rumman Chowdhury is a data scientist and social scientist, and Accenture’s global lead for responsible AI. She tweets @ruchowdh.



References (15)

1. L. Hardesty, “Study Finds Gender and Skin-Type Bias in Commercial Artificial Intelligence Systems,” MIT News Office, Feb. 11, 2018.
2. E.T. Israni, “When an Algorithm Helps Send You to Prison,” The New York Times, Oct. 26, 2017.
3. L. Camera, “Women Can Code — as Long as No One Knows They’re Women,” U.S. News & World Report, Feb. 18, 2016.
4. M. Muro, A. Berube, and J. Whiton, “Black and Hispanic Underrepresentation in Tech: It’s Time to Change the Equation,” The Brookings Institution, March 28, 2018.
5. “About Us,” girlswhocode.com.
6. F. Dobbin and A. Kalev, “Why Diversity Programs Fail,” Harvard Business Review 94, no. 7/8 (July-August 2016).
7. R. Locascio, “Thousands of Sexist AI Bots Could Be Coming. Here’s How We Can Stop Them,” Fortune, May 10, 2018.
8. “Inclusive Design,” Microsoft.com.
9. T. Halloran, “How Atlassian Went From 10% Female Technical Graduates to 57% in Two Years,” Textio, Dec. 12, 2017.
10. C. DeBrusk, “The Risk of Machine-Learning Bias (and How to Prevent It),” MIT Sloan Management Review, March 26, 2018.
11. J. Zou and L. Schiebinger, “AI Can Be Sexist and Racist — It’s Time to Make It Fair,” Nature, July 12, 2018.
12. D. Bass and E. Huet, “Researchers Combat Gender and Racial Bias in Artificial Intelligence,” Bloomberg.com, Dec. 4, 2017.
13. B. Lovejoy, “Sexism Rules in Voice Assistant Genders, Show Studies, but Siri Stands Out,” 9to5Mac.com, Feb. 22, 2017.
14. J. Elliot, “Let’s Stop Talking to Sexist Bots: The Future of Voice for Brands,” Fast Company, March 7, 2018.
15. S. Paul, “Voice Is the Next Big Platform, Unless You Have an Accent,” Wired, March 20, 2017. 
Show All References

Tags: 

Artificial Intelligence
Diversity
Talent Acquisition and Management



Reprint #: 
60216




More Like This
           Why Territorial Managers Stifle Innovation — and What to Do About It                Use Open Source for Safer Generative AI Experiments                The Potency of Shortcuts in Decision-Making              Will AI Help or Hurt Sustainability? Yes | Andrew Winston     
 


Add a comment Cancel replyYou must sign in to post a comment.First time here? Sign up for a free account: Comment on articles and get access to many more articles. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvY2hhcmxlc3Rvd2Vyc2NsYXJrLzIwMTgvMTEvMjIvdXNpbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdG8tZml4LWhlYWx0aGNhcmUv0gEA?oc=5,Using Artificial Intelligence To Fix Healthcare - Forbes,2018-11-22,Forbes,https://www.forbes.com,"The healthcare industry should be using Artificial Intelligence (AI) to a far greater degree than at present, but unique challenges in the sector make comprehensive systems difficult to achieve. But more specific projects are helping patients already, without overhauling the entire industry.",,"The healthcare industry should be using Artificial Intelligence (AI) to a far greater degree than at present, but unique challenges in the sector make comprehensive systems difficult to achieve. But more specific projects are helping patients already, without overhauling the entire industry.","The healthcare industry should be using Artificial Intelligence (AI) to a far greater degree than at present, but unique challenges in the sector make comprehensive systems difficult to achieve. But more specific projects are helping patients already, without overhauling the entire industry.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/charlestowersclark/2018/11/22/using-artificial-intelligence-to-fix-healthcare/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/charlestowersclark/files/2018/11/Medical-Realities-360-surgery-1200x675.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Charles Towers-Clark', 'url': 'https://www.forbes.com/sites/charlestowersclark/', 'description': 'I research and write about organizational structures, proactiveness and culture (especially in relevance to AI) in organisations and other human skills. In my last company, I implemented a management structure that promotes our human skills, in order to help us take full advantage of being human whilst working with AI. My book ‘The WEIRD CEO’ discusses the impact of AI on the future of work and how organisations can be run differently. Follow me on Linkedin. If you have any comments please feel to email me on ctc@human-dynamics.io', 'sameAs': ['https://www.linkedin.com/in/charlestowersclark/', 'https://human-dynamics.io']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Using Artificial Intelligence To Fix Healthcare,2018-11-22T10:50:00-05:00,2018-11-26T15:12:56-05:00,Business,Using Artificial Intelligence To Fix Healthcare,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",Business,,"More From ForbesJul 15, 2024,12:38pm EDTHere’s Where All Of Trump’s Criminal Cases Stand After Cannon Dismisses Documents ChargesJul 15, 2024,11:29am EDTGuns Still Allowed In Area Outside RNC Despite Trump Assassination Attempt—Here’s WhyJul 15, 2024,11:29am EDTProject 2025 Explained: What To Know About The Controversial Right-Wing Policy Map For Trump—As RNC Kicks OffJul 15, 2024,10:06am EDTDrugs Like Ozempic, Wegovy, Zepbound And Mounjaro Could Treat Other Conditions—Here’s What Scientists Are Looking AtJul 15, 2024,10:04am EDTTrump Classified Documents Case Dismissed By Judge CannonJul 15, 2024,07:59am EDTTrump Media Shares Surge And Bitcoin Climbs Above $63,000 After Assassination AttemptJul 15, 2024,07:12am EDTPain Management in the Wake of the Opioid CrisisEdit StoryForbesInnovationAIUsing Artificial Intelligence To Fix HealthcareCharles Towers-ClarkContributorOpinions expressed by Forbes Contributors are their own.I write about AI, human skills. digital transformation & educationFollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 22, 2018,10:50am ESTUpdated Nov 26, 2018, 03:12pm ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







Surgery filmed in 360° and live-streamed to remote doctors could already be happening in a hospital... [+] near you.
Medical Realities - YouTube screenshot




The healthcare industry should be using Artificial Intelligence (AI) to a far greater degree than at present, but progress has been painfully slow. The same factors that make the healthcare system so attractive to AI developers - fragmented or non-existent data repositories, outdated computer systems and doctor shortages - are the same things that have stopped AI from providing the gains that should be created.

The healthcare sector also presents unique obstacles for AI: data must flow freely through AI systems to achieve real results, but extracting data from handwritten patient files or PDFs is cumbersome for us, and difficult for AI. Despite technical and operational challenges, new research suggests that the arrival of the tech giants into the industry may provide the data and the capital required to digitize this fairly untapped market.
Where AI can help now
Severe fragmentation between different branches of healthcare, and life-threatening miscommunication within institutions (in 2016, ~10% of all US deaths were caused by medical errors), presents an opportunity for AI to ease the burden on doctors in more creative, less intrusive ways. Mabu is a humanoid robot developed by Catalia Health and works with the American Heart Association to help patients keep on top of at-home treatment for congestive heart failure. Acting as a personal health assistant, Mabu asks patients how they are feeling, makes activity suggestions and provides medication reminders. ‘There are key points we make sure Mabu covers,’ says Catalia Health founder Cory Kidd, ‘but the conversation is adaptive to what is going on with that patient at that moment,’ much like a home nurse’s visits might be scripted to a certain degree while relying on some human intuition.
PROMOTED
Mabu is a promising step towards integrating AI into the healthcare system without disturbing doctors within facilities - the data Mabu gathers can be fed into Electronic Medical Records (EMRs) via email or text, and ‘daily conversations’ with the device mean that Catalia Health can collect patient information consensually ‘without depending on access to their medical data.’ The implementation of AI throughout healthcare institutions or an entire country will remain a huge task even for data-rich multi-nationals, but solutions like this may help to improve outpatient care and reduce readmission rates for long-term conditions without setting foot in a hospital.

The grand scheme
The move towards integrating AI with hospitals and healthcare centers is gaining pace. The UK government has announced its intentions to put the UK ‘at the forefront of the use of AI and data in early diagnosis, innovation, prevention and treatment’ by 2030. While this may be ambitious given the current status of technological advancement in the NHS, hospitals are working with a wide range of companies to tackle immediate problems on the ground. Chatbots, DeepMind, and voice biometrics are all being used to alleviate unique problems in the sector, and some companies are taking a different approach to ensure that AI is used to its full extent.
Dr. Shafi Ahmed is a cancer specialist in practice for more than 20 years, and as such is in high demand from people who need his expertise. In a conversation with Steve Dann, who at the time was working in visual effects, Dr. Ahmed related that of the 300 students under his care he was only able to directly train two at a time because the operating theatre could not fit any more people. Dann suggested he filmed an operation using 360° cameras, which enabled Dr. Ahmed to show students exactly what to do without having 300 people breathing down his neck.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



This led Steve Dann to found Medical Realities, and use his skills in CGI and virtual reality to train medical students without making more work for doctors. Following the success of the 360° operation, Dann created a virtual Dr. Ahmed to answer questions for him, which is now used in conjunction with teleconferencing to help Dr. Ahmed’s cancer patients feel more comfortable in follow-up appointments. Using this combination of AI, virtual reality and CGI, Dann is working with Leeds and Queen Mary University hospitals to create virtual surgeons that can train new doctors or assist in surgeries where one or more doctors cannot be physically present.
Bit by bit transformation
Bringing about an artificially intelligent healthcare landscape will be a significant challenge, due to the sheer amount of mission-critical work on doctors’ shoulders, outdated systems and handwritten records, and fragmentation between care facilities. But Rome wasn’t built in a day, and there is already significant progress being made that does not disrupt the daily work of doctors and nurses on the ground, while still offering improved care to patients.
The AI healthcare sector is ripe for development and investment, but while the data giants figure out how to transform the system as a whole, smaller-scale projects are making real changes. Piece by piece, patient by patient, AI is on its way to fixing healthcare once and for all.Follow me on LinkedIn. Check out my website or some of my other work here. Charles Towers-ClarkFollowingFollowI research and write about organizational structures, proactiveness and culture (especially in relevance to AI) in organisations and other human skills.... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMTEvMjUvYnVzaW5lc3MvY2hpbmEtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbGFiZWxpbmcuaHRtbNIBAA?oc=5,How Cheap Labor Drives China’s A.I. Ambitions - The New York Times,2018-11-25,The New York Times,https://www.nytimes.com,"If China is the Saudi Arabia of data, its data factories are the refineries, turning raw data into the fuel that can power China’s goal of A.I. supremacy.",,"If China is the Saudi Arabia of data, its data factories are the refineries, turning raw data into the fuel that can power China’s goal of A.I. supremacy.","If China is the Saudi Arabia of data, its data factories are the refineries, turning raw data into the fuel that can power China’s goal of A.I. supremacy.",https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/11/26/business/26newworld-1/26newworld-1-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2018/11/26/business/26newworld-1/26newworld-1-videoSixteenByNineJumbo1600.jpg', 'caption': 'Workers at the headquarters of Ruijin Technology Company in Jiaxian, in central China’s Henan Province. They identify objects in images to help artificial intelligence make sense of the world.', 'creditText': 'Yan Cong for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/11/26/business/26newworld-1/26newworld-1-superJumbo.jpg', 'height': 1366, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2018/11/26/business/26newworld-1/26newworld-1-superJumbo.jpg', 'caption': 'Workers at the headquarters of Ruijin Technology Company in Jiaxian, in central China’s Henan Province. They identify objects in images to help artificial intelligence make sense of the world.', 'creditText': 'Yan Cong for The New York Times'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/li-yuan', 'name': 'Li Yuan'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",How Cheap Labor Drives China’s A.I. Ambitions,2018-11-25T19:55:27.000Z,2018-11-25T19:55:27.000Z,,The New York Times,False,,Business,,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTThe New New WorldHow Cheap Labor Drives China’s A.I. AmbitionsShare full article17Read in appWorkers at the headquarters of Ruijin Technology Company in Jiaxian, in central China’s Henan Province. They identify objects in images to help artificial intelligence make sense of the world.Credit...Yan Cong for The New York TimesBy Li YuanNov. 25, 2018阅读简体中文版閱讀繁體中文版Some of the most critical work in advancing China’s technology goals takes place in a former cement factory in the middle of the country’s heartland, far from the aspiring Silicon Valleys of Beijing and Shenzhen. An idled concrete mixer still stands in the middle of the courtyard. Boxes of melamine dinnerware are stacked in a warehouse next door.Inside, Hou Xiameng runs a company that helps artificial intelligence make sense of the world. Two dozen young people go through photos and videos, labeling just about everything they see. That’s a car. That’s a traffic light. That’s bread, that’s milk, that’s chocolate. That’s what it looks like when a person walks.“I used to think the machines are geniuses,” Ms. Hou, 24, said. “Now I know we’re the reason for their genius.”In China, long the world’s factory floor, a new generation of low-wage workers is assembling the foundations of the future. Start-ups in smaller, cheaper cities have sprung up to apply labels to China’s huge trove of images and surveillance footage. If China is the Saudi Arabia of data, as one expert says, these businesses are the refineries, turning raw data into the fuel that can power China’s A.I. ambitions.AdvertisementSKIP ADVERTISEMENTConventional wisdom says that China and the United States are competing for A.I. supremacy and that China has certain advantages. The Chinese government broadly supports A.I. companies, financially and politically. Chinese start-ups made up one third of the global computer vision market in 2017, surpassing the United States. Chinese academic papers are cited more often in research papers. In a key policy announcement last year, the China government said that it expected the country to become the world leader in artificial intelligence by 2030.Most importantly, this thinking goes, the Chinese government and companies enjoy access to mountains of data, thanks to weak privacy laws and enforcement. Beyond what Facebook, Google and Amazon have amassed, Chinese internet companies can get more because people there so heavily use their mobile phones to shop, pay for meals and buy movie tickets.ImageHou Xiameng runs a data factory out of her in-laws’ former cement factory in the Hebei city of Nangongshi.Credit...Yan Cong for The New York TimesStill, many of those claims are iffy. Chinese papers and patents can be suspect. Government money may go to waste. It isn’t clear that the A.I. race is a zero sum game, in which the winner gets the spoils. Data is useless unless somebody can parse and catalog it.But the ability to tag that data may be China’s true A.I. strength, the only one that the United States may not be able to match. In China, this new industry offers a glimpse of a future that the government has long promised: an economy built on technology rather than manufacturing.AdvertisementSKIP ADVERTISEMENT“We’re the construction workers in the digital world. Our job is to lay one brick after another,” said Yi Yake, co-founder of a data labeling factory in Jiaxian, a city in central Henan province. “But we play an important role in A.I. Without us, they can’t build the skyscrapers.”While A.I. engines are superfast learners and good at tackling complex calculations, they lack cognitive abilities that even the average 5-year-old possesses. Small children know that a furry brown cocker spaniel and a black Great Dane are both dogs. They can tell a Ford pickup from a Volkswagen Beetle, and yet they know both are cars.A.I. has to be taught. It must digest vast amounts of tagged photos and videos before it realizes that a black cat and a white cat are both cats. This is where the data factories and their workers come in.Taggers helped AInnovation, a Beijing-based A.I. company, fix its automated cashier system for a Chinese bakery chain. Users could put their pastry under a scanner and pay for it without help from a human. But nearly one-third of the time, the system had trouble telling muffins from doughnuts or pork buns thanks to store lighting and human movement, which made images more complex. Working with photos from the store’s interior, the taggers got the accuracy up to 99 percent, said Liang Rui, an AInnovation project manager.AdvertisementSKIP ADVERTISEMENT“All the artificial intelligence is built on human labor,” Mr. Liang said.AInnovation has fewer than 30 taggers, but a surge in labeling start-ups has made it easy to farm out the work. Once, Mr. Liang needed to get about 20,000 photos in a supermarket labeled in three days. Colleagues got it done with the help of data factories for only a couple thousand dollars.“We’re the assembly lines 10 years ago,” said Mr. Yi, the co-founder of the data factory in Henan.The data factories are popping up in areas far from the biggest cities, often in relatively remote areas where both labor and office space are cheap. Many of the data factory workers are the kinds of people who once worked on assembly lines and construction sites in those big cities. But work is drying up, wage growth has slowed and many Chinese people prefer to live closer to home.Mr. Yi, 36, was out of a job and trying to get other ventures going with elementary school classmates when someone mentioned A.I. tagging. After online searches, he decided it wasn’t super technical but needed cheap labor, something Henan has in abundance.In March, Mr. Yi and his friends set up Ruijin Technology, which rents offices the size of two professional basketball courts in an industrial park for $21,000 a year. It was previously the park’s Communist Party committee’s event space, so the ceiling lights are covered with red hammers and sickles.Ruijin, which means smart gold, now employs 300 workers but plans to expand to 1,000 after the Chinese New Year holiday, when many migrant workers come home.AdvertisementSKIP ADVERTISEMENTUnlike workers and business around the world, Mr. Yi isn’t worried that A.I. will take his job.“The machines aren’t smart enough to teach themselves yet,” he said.Hiring is a bigger worry.Ruijin’s pay of $400 to $500 a month is higher than average in Jiaxian. Some potential job candidates worry that they don’t know anything about A.I. Others find the work boring.Jin Weixiang, 19, said he would quit Ruijin after the Chinese New Year and go to sell furniture in a physical store in southern city Guangzhou.Image“We’re the construction workers in the digital world. Our job is to lay one brick after another,” said Yi Yake, co-founder of Ruijin Technology.Credit...Yan Cong for The New York Times“I’m a people’s person,” said Mr. Jin. “I’m doing labeling for the money.”But for some former migrant workers, the job is better than working on assembly lines.AdvertisementSKIP ADVERTISEMENT“It was the same work, same movement, day after day,” said Yi Zhenzhen, a 28-year-old Ruijin employee who once worked at an electronic component company. “Now I have to use my brain a little bit.”Most of the time, customers don’t tell these data factories what the task is for. Some are obvious. Labeling traffic lights, road signs and pedestrians are usually for autonomous driving. Labeling many types of camellia flowers could be for search engines.Once Ruijin was given the task of labeling the images of millions of human mouths. Mr. Yi said he wasn’t sure what it was for. Maybe facial recognition?Roughly 300 miles to the north, in the Hebei city of Nangongshi, Hou Xiameng runs her data factory out of her in-laws’ former cement factory. Her first job out of college was labeling faces for Megvii, the Chinese facial recognition company with a $2 billion valuation that’s most famous for its technology platform called Face++. To this day, some facial recognition systems recognize her before they do her friends because, she says, “my face is in the original database.”But life in Beijing was too tough and expensive. She and her then-fiancé, Zhao Yacheng, decided to move back to their hometown and start a data factory. Ms. Hou’s parents would pay for computers and desks. They are renovating the warehouse next door to hire 80 more people.AdvertisementSKIP ADVERTISEMENTLike Mr. Yi, Ms. Hou doesn’t spend time thinking about the implications of her work. Are they contributing to a surveillance state and a dystopian future that machines will control human?“Cameras make me feel safe,” she said. “We’re in control of the machines for now.”Follow Li Yuan on Twitter:@LiYuan6. A version of this article appears in print on Nov. 26, 2018, Section B, Page 1 of the New York edition with the headline: Doing Time on the A.I. Assembly Line. Order Reprints | Today’s Paper | SubscribeRead 17 CommentsShare full article17Read in appAdvertisementSKIP ADVERTISEMENTComments 17How Cheap Labor Drives China’s A.I. AmbitionsSkip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Tell us about yourself. Take the survey.",https://www.nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html,Doing Time on the A.I. Assembly Line,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,{'@id': '#commentsContainer'},17.0,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vZW5nbGlzaC5lbHBhaXMuY29tL2VscGFpcy8yMDE4LzExLzIzL2luZW5nbGlzaC8xNTQyOTc2Nzk2XzE1OTkzMi5odG1s0gFcaHR0cHM6Ly9lbmdsaXNoLmVscGFpcy5jb20vZWxwYWlzLzIwMTgvMTEvMjMvaW5lbmdsaXNoLzE1NDI5NzY3OTZfMTU5OTMyLmh0bWw_b3V0cHV0VHlwZT1hbXA?oc=5,The dangers of letting algorithms make decisions for you - EL PAÍS USA,2018-11-23,EL PAÍS USA,https://english.elpais.com,"Experts warn that AI systems used by recruiters, banks and even judges learn from data that can contain an undesired bias",['Spanish Way Of Life'],"Experts warn that AI systems used by recruiters, banks and even judges learn from data that can contain an undesired bias",,https://schema.org/,"['NewsArticle', 'Article']",,"{'@type': 'ImageObject', 'url': ['https://imagenes.elpais.com/resizer/v2/4LHWPSE5GDYLRKRCVZ6XUYT4WY.jpg?auth=92a9071a86354ce080fa612ed46d2486208aae495ed5ab60a9fd3dc86af1c97c&width=1960&height=1103&smart=true', 'https://imagenes.elpais.com/resizer/v2/4LHWPSE5GDYLRKRCVZ6XUYT4WY.jpg?auth=92a9071a86354ce080fa612ed46d2486208aae495ed5ab60a9fd3dc86af1c97c&width=1960&height=1470&smart=true', 'https://imagenes.elpais.com/resizer/v2/4LHWPSE5GDYLRKRCVZ6XUYT4WY.jpg?auth=92a9071a86354ce080fa612ed46d2486208aae495ed5ab60a9fd3dc86af1c97c&width=980&height=980&smart=true']}","[{'@type': 'Person', 'name': 'Isabel Rubio', 'url': 'https://english.elpais.com/author/isabel-rubio-arroyo/'}]","{'@type': ['NewsMediaOrganization', 'Organization'], 'sameAs': ['https://twitter.com/elpaisinenglish', 'https://www.facebook.com/elpaisinenglish', 'https://www.youtube.com/user/elpaiscom', 'https://en.wikipedia.org/wiki/El_Pa%C3%ADs'], 'logo': {'@type': 'ImageObject', 'url': 'https://static.elpais.com/dist/resources/images/logos/amp/default.png', 'height': 60, 'width': 262}, 'name': 'Ediciones EL PAÍS S.L.', 'actionableFeedbackPolicy': 'https://elpais.com/estaticos/code-of-ethics/#contacto', 'correctionsPolicy': 'https://elpais.com/estaticos/code-of-ethics/#cambios', 'diversityPolicy': 'https://elpais.com/estaticos/code-of-ethics/#diversidad', 'diversityStaffingReport': 'https://elpais.com/estaticos/code-of-ethics/#diversidad', 'ethicsPolicy': 'https://elpais.com/estaticos/code-of-ethics/#principios', 'foundingDate': '1976-05-04', 'masthead': 'https://elpais.com/estaticos/code-of-ethics/#estructura', 'missionCoveragePrioritiesPolicy': 'https://elpais.com/estaticos/code-of-ethics/#mision', 'noBylinesPolicy': 'https://elpais.com/estaticos/code-of-ethics/', 'ownershipFundingInfo': 'https://elpais.com/estaticos/code-of-ethics/#estructura', 'unnamedSourcesPolicy': 'https://elpais.com/estaticos/code-of-ethics/#fuentes', 'verificationFactCheckingPolicy': 'https://elpais.com/estaticos/code-of-ethics/#verificacion'}",The dangers of letting algorithms make decisions for you,2018-11-23T18:34:49+01:00,2018-11-23T18:34:49+01:00,Life,,True,,Life,,"TECHNOLOGYThe dangers of letting algorithms make decisions for youExperts warn that AI systems used by recruiters, banks and even judges learn from data that can contain an undesired biasIsabel RubioNOV 23, 2018 - 12:34 ESTWhatsappFacebookTwitterLinkedinCopy linkRobot waiters at a restaurant in Kathmandu.PRAKASH MATHEMA (AFP)In 2014, Amazon developed an artificial intelligence (AI) recruitment tool that began to discriminate against female job applicants. A year later, a user of Google Photos discovered that the program was labeling his black friends as gorillas. And in 2018 it emerged that an algorithm that analyzed the risk of recidivism by a million US defendants made as many mistakes as any human being with no training in criminal justice.Decisions that were once made by human beings are now being made by AI systems. Some programs deal with hiring, others with loan approvals, medical diagnoses and even court rulings. But there is a risk involved, because the data used to “train” the algorithms is itself conditioned by our own knowledge and prejudices.The data is a reflection of reality. If reality is prejudiced, so is the dataRichard Benjamins, Telefónica“The data is a reflection of reality. If reality is prejudiced, so is the data,” explains Richard Benjamins, the Big Data and AI ambassador at Telefónica, a global telco and tech company, in a telephone conversation with EL PAÍS. To prevent an algorithm from discriminating against certain groups, he says, it is necessary to check that the training data does not contain a bias, and to analyze the false positive and negative ratios. “It is much more serious to have an algorithm that discriminates in an undesired way in the fields of law, loans or school admissions than in the fields of movie recommendations or advertising.”Isabel Fernández, a managing director of applied intelligence at consulting firm Accenture, brings up the example of automatic loan grants. “Imagine that in the past, most of the applicants were men, and the few women who were approved for a loan had to overcome such stringent criteria that they all repaid their debt. If we used this data and nothing else, the system would conclude that women are better at paying back than men, which is merely a reflection of a past prejudice.”Yet on many occasions it is women who are harmed by this kind of bias. “Algorithms are generally developed because a group of mostly white men between the ages of 25 and 50 have decided so at a meeting. With this kind of starting point, it is difficult to include the opinion or perception of minority groups or of the other 50% of the population, which is made up of women,” says Nerea Luis Mingueza, a robotics and AI researcher at Carlos III University who holds that underrepresented groups will always be affected to a greater degree by technological products. “For instance, the voices of women and children fail more often in voice recognition systems.”Today's society generates huge amounts of data, but using it correctly still poses a challenge.GettyMinorities are more likely to feel the effects of this bias for statistical reasons, says José María Lucia, who heads the AI and data analysis center at EY Wavespace: “The number of available cases for training is going to be lower,” he notes. “And any groups who have suffered discrimination of any type in the past are open to this, because by using historical data we could be unwittingly including this bias in the training.”This is the case with the African-American population in the United States, according to Juan Alonso, a senior manager at Accenture. “It’s been proven that if caught over the same kind of misdemeanor, such as smoking a joint in public or possessing small amounts of marijuana, a white person will not get arrested but a black person will.” This means that there is a higher percentage of black people on the database, and an algorithm that is trained with this information will incorporate a racist bias.Sources at Google explain that it is essential to “be very careful” about giving decision-making power to a machine-learning system. “Artificial intelligence produces answers based on existing data, and so humans must recognize that they won’t necessarily provide impeccable results.”Algorithms are generally developed because a group of mostly white men between the ages of 25 and 50 have so decided at a meetingNerea Luis Mingueza, Carlos III UniversityMachines often end up being a black box filled with secrets that are undecipherable even to their own developers, who are unable to figure out what path the model followed to reach a certain conclusion. Alonso holds that “normally, when you are tried, you get an explanation for the decision in a ruling. But the problem is that this type of algorithm is opaque. It’s like being in the presence of an oracle who is going to hand down a verdict.”“Imagine you are going to an open-air festival and when you reach the front row, the security team kicks you out without any kind of explanation. You would be incensed. But if you are told that the first row is reserved for people in wheelchairs, you would not be angry about moving back. It’s the same with these algorithms: if we don’t know what’s going on, it can generate a feeling of dissatisfaction,” explains Alonso.To end this dilemma, researchers working on machine learning advocate greater transparency and providing explanations for training models. Major tech companies like Microsoft defend a set of principles for a responsible use of AI, and they are sponsoring initiatives to try to crack open the black box of algorithms and explain why decisions get made the way they are.Telefonica is organizing a Challenge for a Responsible Use of AI at its Big Data business unit, LUCA, with the aim of creating new tools to detect undesired bias. Accenture has developed AI Fairness and IBM has also come up with its own bias-detection tool. For Francesca Rossi, director of ethics and AI at IBM, the key lies in making AI systems transparent and trustworthy. “People have the right to ask how an intelligent system suggests certain decisions over others, and companies have a duty to help people understand the decision-making process.”English version by Susana Urra.More informationA woman’s place is in the home – at least according to AI...Javier SalasBeyond Trump: the hidden threat robots pose to the Mexican economyIgnacio Fariza | Mexico CityArchived InSpanish Way Of LifeAdheres toMore informationIf you are interested in licensing this content, please contact ventacontenidos@prisamedia.com","{'@type': ['WebPage', 'ItemPage'], '@id': 'https://english.elpais.com/elpais/2018/11/23/inenglish/1542976796_159932.html', 'name': 'The dangers of letting algorithms make decisions for you'}",,"[{'@type': 'ImageObject', 'url': 'https://imagenes.elpais.com/resizer/v2/FNUMMOXNCFWYLCJ344NDX4MULM.jpg?auth=4e6c824b548b8592ee61f7e1432a48f105edad56cdb805b236172fca43645cb9&width=1960', 'caption': 'Todays society generates huge amounts of data, but using it correctly still poses a challenge.', 'height': 720, 'width': 1960, 'copyrightHolder': [{'name': 'Getty', '@type': ['NewsMediaOrganization', 'Organization']}]}]",,,2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'Ediciones EL PAÍS S.L.', 'productID': 'english.elpais.com:basic'}",,,,,,,,,"{'@type': 'SpeakableSpecification', 'cssSelector': 'h1.a_t'}","In 2014, Amazon developed an artificial intelligence (AI) recruitment tool that began to discriminate against female job applicants. A year later, a user of Google Photos discovered that the program was labeling his black friends as gorillas. And in 2018 it emerged that an algorithm that analyzed the risk of recidivism by a million US defendants made as many mistakes as any human being with no training in criminal justice. Decisions that were once made by human beings are now being made by AI systems. Some programs deal with hiring, others with loan approvals, medical diagnoses and even court rulings. But there is a risk involved, because the data used to “train” the algorithms is itself conditioned by our own knowledge and prejudices. Richard Benjamins, Telefónica “The data is a reflection of reality. If reality is prejudiced, so is the data,” explains Richard Benjamins, the Big Data and AI ambassador at Telefónica, a global telco and tech company, in a telephone conversation with EL PAÍS. To prevent an algorithm from discriminating against certain groups, he says, it is necessary to check that the training data does not contain a bias, and to analyze the false positive and negative ratios. “It is much more serious to have an algorithm that discriminates in an undesired way in the fields of law, loans or school admissions than in the fields of movie recommendations or advertising.” Isabel Fernández, a managing director of applied intelligence at consulting firm Accenture, brings up the example of automatic loan grants. “Imagine that in the past, most of the applicants were men, and the few women who were approved for a loan had to overcome such stringent criteria that they all repaid their debt. If we used this data and nothing else, the system would conclude that women are better at paying back than men, which is merely a reflection of a past prejudice.” Yet on many occasions it is women who are harmed by this kind of bias. “Algorithms are generally developed because a group of mostly white men between the ages of 25 and 50 have decided so at a meeting. With this kind of starting point, it is difficult to include the opinion or perception of minority groups or of the other 50% of the population, which is made up of women,” says Nerea Luis Mingueza, a robotics and AI researcher at Carlos III University who holds that underrepresented groups will always be affected to a greater degree by technological products. “For instance, the voices of women and children fail more often in voice recognition systems.” Minorities are more likely to feel the effects of this bias for statistical reasons, says José María Lucia, who heads the AI and data analysis center at EY Wavespace: “The number of available cases for training is going to be lower,” he notes. “And any groups who have suffered discrimination of any type in the past are open to this, because by using historical data we could be unwittingly including this bias in the training.” This is the case with the African-American population in the United States, according to Juan Alonso, a senior manager at Accenture. “It’s been proven that if caught over the same kind of misdemeanor, such as smoking a joint in public or possessing small amounts of marijuana, a white person will not get arrested but a black person will.” This means that there is a higher percentage of black people on the database, and an algorithm that is trained with this information will incorporate a racist bias. Sources at Google explain that it is essential to “be very careful” about giving decision-making power to a machine-learning system. “Artificial intelligence produces answers based on existing data, and so humans must recognize that they won’t necessarily provide impeccable results.” Nerea Luis Mingueza, Carlos III University Machines often end up being a black box filled with secrets that are undecipherable even to their own developers, who are unable to figure out what path the model followed to reach a certain conclusion. Alonso holds that “normally, when you are tried, you get an explanation for the decision in a ruling. But the problem is that this type of algorithm is opaque. It’s like being in the presence of an oracle who is going to hand down a verdict.” “Imagine you are going to an open-air festival and when you reach the front row, the security team kicks you out without any kind of explanation. You would be incensed. But if you are told that the first row is reserved for people in wheelchairs, you would not be angry about moving back. It’s the same with these algorithms: if we don’t know what’s going on, it can generate a feeling of dissatisfaction,” explains Alonso. To end this dilemma, researchers working on machine learning advocate greater transparency and providing explanations for training models. Major tech companies like Microsoft defend a set of principles for a responsible use of AI, and they are sponsoring initiatives to try to crack open the black box of algorithms and explain why decisions get made the way they are. Telefonica is organizing a Challenge for a Responsible Use of AI at its Big Data business unit, LUCA, with the aim of creating new tools to detect undesired bias. Accenture has developed AI Fairness and IBM has also come up with its own bias-detection tool. For Francesca Rossi, director of ethics and AI at IBM, the key lies in making AI systems transparent and trustworthy. “People have the right to ask how an intelligent system suggests certain decisions over others, and companies have a duty to help people understand the decision-making process.” English version by Susana Urra.",,,,,,,,,,,,,,,,,,,,en,,,,,,,,,,,"{'@type': 'CreativeWork', 'url': 'https://elpais.com/estaticos/code-of-ethics/'}",https://elpais.com/estaticos/terms-and-conditions/
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3Lm5wci5vcmcvMjAxOC8xMS8yMS82NjAxNjgzMjUvb3B0aW1pemVkLXByaW1lLWhvdy1haS1hbmQtYW50aWNpcGF0aW9uLXBvd2VyLWFtYXpvbnMtMS1ob3VyLWRlbGl2ZXJpZXPSAQA?oc=5,Amazon Prime: How AI And Forecasting Power One-Hour Deliveries - NPR,2018-11-21,NPR,https://www.npr.org,"Amazon executives often evoke magic when talking about fast shipping. Now in a race for one-hour deliveries, few retailers can afford to keep up. And few rely quite so much on artificial intelligence.",,"Amazon executives often evoke magic when talking about fast shipping. Now in a race for one-hour deliveries, few retailers can afford to keep up. And few rely quite so much on artificial intelligence.",,http://schema.org,NewsArticle,,"[{'@type': 'ImageObject', 'url': 'https://media.npr.org/assets/img/2018/11/08/_dsc1608_slide-24fc3058fab297b0420fc823866d57d41c7c946a.jpg'}, {'@type': 'ImageObject', 'url': 'https://media.npr.org/assets/img/2018/11/08/_dsc1514_slide-81164a64bf85aa84a34e351ccdf740c4cbddf00d.jpg'}, {'@type': 'ImageObject', 'url': 'https://media.npr.org/assets/img/2018/11/08/_dsc1693_slide-02c0b75a02a6a73ca6ff6a181e75707eeea06c65.jpg'}, {'@type': 'ImageObject', 'url': 'https://media.npr.org/assets/img/2018/11/02/gettyimages-461841920_custom-789bbbf2f1be146cb2f81f6b70f51f43d6fc4c45.jpg'}, {'@type': 'ImageObject', 'url': 'https://media.npr.org/assets/img/2018/11/08/_dsc1746_slide-debb995c2356aa653158ed03824fbad01b343dcf.jpg'}]","{'@type': 'Person', 'name': ['Alina Selyukh']}","{'@type': 'Organization', 'name': 'NPR', 'logo': {'@type': 'ImageObject', 'url': 'https://media.npr.org/chrome/npr-logo.jpg'}}",Optimized Prime: How AI And Anticipation Power Amazon's 1-Hour Deliveries,2018-11-21T07:22:00-05:00,2018-11-21T07:22:00-05:00,,,,,,,WAMU 88.5All Things Considered,"{'@type': 'WebPage', '@id': 'https://www.npr.org/2018/11/21/660168325/optimized-prime-how-ai-and-anticipation-power-amazons-1-hour-deliveries'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmluZHkxMDAuY29tL25ld3Mvc2V4aXNtLWdlbmRlci1iaWFzLWFpcnBvcnQtZmVtYWxlLWFzdHJvcGh5c2ljaXN0LWxhcHRvcHMtdmlyYWwtdHdpdHRlci10aHJlYWQtODY0Njg1MdIBAA?oc=5,A female astrophysicist's story about 2 laptops and airport security inspired a conversation about gender bias - indy100,2018-11-22,indy100,https://www.indy100.com,A female astrophysicist who shared a story about a man who was rude to her for carrying two laptops at the airport has ignited a discussion about gender bias.Amber Roberts is an astrophysicist and an artificial intelligence program director.She decided to share an interaction she had with a man at a...,[],A female astrophysicist who shared a story about a man who was rude to her for carrying two laptops at the airport has ignited a discussion about gender bias.Amber Roberts is an astrophysicist and an artificial intelligence program director.She decided to share an interaction she had with a man at a...,,https://schema.org,NewsArticle,https://www.indy100.com/news/sexism-gender-bias-airport-female-astrophysicist-laptops-viral-twitter-thread-8646851,"{'@type': 'ImageObject', 'height': 600, 'url': 'https://www.indy100.com/media-library/picture.jpg?id=28115688&width=1200&height=600&coordinates=0%2C0%2C0%2C0', 'width': 1200}","{'@type': 'Person', 'description': '', 'identifier': '24817415', 'image': {'@type': 'ImageObject', 'url': 'https://www.indy100.com/res/avatars/default'}, 'name': 'Narjas Zatat', 'url': 'https://www.indy100.com/author/narjas-zatat'}","{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.indy100.com/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy8yNzk5MTA3OS9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc2MDM1Njc2MH0.744deFHthkRlcmJ6oqc9vO20TOUS0rUNpL4ARF3A8nA/image.png?width=210'}, 'name': 'indy100'}",A female astrophysicist's experience at airport security inspired a discussion about gender bias | indy100,2018-11-23T10:24:22Z,2018-11-23T10:24:22Z,News,indy100,,"[{'@type': 'ListItem', 'id': 'https://www.indy100.com/news/', 'item': 'https://www.indy100.com/news/', 'name': 'News', 'position': 1}]",News,,"News
        A female astrophysicist's experience at airport security inspired a discussion about gender bias
    ","{'@id': 'https://www.indy100.com/news/sexism-gender-bias-airport-female-astrophysicist-laptops-viral-twitter-thread-8646851', '@type': 'WebPage'}",,,,,,,"{'@type': 'ImageObject', 'url': 'https://www.indy100.com/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy8yNzk5MTA3OS9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc2MDM1Njc2MH0.744deFHthkRlcmJ6oqc9vO20TOUS0rUNpL4ARF3A8nA/image.png?width=210'}",,,,,,"['https://www.pinterest.com/indy100/', 'https://www.instagram.com/indy100/', 'https://www.facebook.com/meetIndy100/', 'https://www.linked.com/in/indy100', 'https://twitter.com/indy100', 'https://www.youtube.com/user/indy100']",,,,https://www.indy100.com/media-library/picture.jpg?id=28115688&amp;width=210,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LmJvc3RvbmhlcmFsZC5jb20vMjAxOC8xMS8yNS9oYm8tZG9jdW1lbnRhcnktYS1jcmVlcHktbG9vay1hdC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAWVodHRwczovL3d3dy5ib3N0b25oZXJhbGQuY29tLzIwMTgvMTEvMjUvaGJvLWRvY3VtZW50YXJ5LWEtY3JlZXB5LWxvb2stYXQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYW1wLw?oc=5,HBO documentary a creepy look at artificial intelligence - Boston Herald,2018-11-25,Boston Herald,https://www.bostonherald.com,"In 1942, author Isaac Asimov postulated the Three Laws of Robotics:A robot shall not harm a human nor allow a human to become harmed through inaction.A robot shall obey a human so long as the orders do not interfere with the First Law.A robot shall protect itself so long as it does not interfere with […]",[],"In 1942, author Isaac Asimov postulated the Three Laws of Robotics:A robot shall not harm a human nor allow a human to become harmed through inaction.A robot shall obey a human so long as the order…",,https://schema.org,NewsArticle,https://www.bostonherald.com/2018/11/25/hbo-documentary-a-creepy-look-at-artificial-intelligence/,"{'@type': 'ImageObject', 'url': 'https://www.bostonherald.com/wp-content/uploads/migration/1969/12/31/3ebf6e54-edcb-11e8-89c1-f33a59017696.jpg?w=1024'}",[],"{'@type': 'Organization', 'name': 'Boston Herald', 'logo': 'https://www.bostonherald.com/wp-content/uploads/2018/11/Herald_BridgePhoto.jpg?w=600'}",HBO documentary a creepy look at artificial intelligence,2018-11-25T05:00:00Z,2018-11-29T17:25:56Z,Things To Do,,True,,,,"



Breaking News





			Trump picks Sen. JD Vance of Ohio, a once-fierce critic turned loyal ally, as his GOP running mate		


July 15, 2024 at 3:52 pm						
					





Things To Do



			HBO documentary a creepy look at artificial intelligence		

Share this:Click to share on Facebook (Opens in new window)Click to share on Twitter (Opens in new window)Click to share on Reddit (Opens in new window)Click to print (Opens in new window)





Click to share a free article with a friend




GIFT THIS ARTICLE
What is article sharing?
Subscribers are entitled to 10 gift sharing articles each month. These can be shared with friends and family who are not subscribers.

 Subscribe now! or log in to your account.
Share Button Disabled

Subscribe
Log in



 
						A robot hotel clerk, “The Truth About Killer Robots” – photo: HBO		

By UPDATED: November 29, 2018 at 5:25 p.m.In 1942, author Isaac Asimov postulated the Three Laws of Robotics:A robot shall not harm a human nor allow a human to become harmed through inaction.A robot shall obey a human so long as the orders do not interfere with the First Law.A robot shall protect itself so long as it does not interfere with the two previous laws.Those principles had a profound impact not just on science fiction but the w  . . .  Share this:Click to share on Facebook (Opens in new window)Click to share on Twitter (Opens in new window)Click to share on Reddit (Opens in new window)Click to print (Opens in new window)





Click to share a free article with a friend




GIFT THIS ARTICLE
What is article sharing?
Subscribers are entitled to 10 gift sharing articles each month. These can be shared with friends and family who are not subscribers.

 Subscribe now! or log in to your account.
Share Button Disabled

Subscribe
Log in

Around the WebWhy Doctors in the Know No Longer Prescribe Blood Pressure DrugsPrimal HealthThe Car Barron Trump Drives At 18 Is Hard To BelieveReportinglyHow To: Move Your Ira/401k out of Stocks- Tax FreeAmerican Hartford GoldGreta Thunberg's House Shocks the Whole World, the Proof in PicsDoctortianDistrict of Columbia Residents, Don't Miss out on This Incredible Baking Soda Toilet Hack!Life Hacks NinjaDiscover the Genius Reason to Put a Bottle on Your Tire While Traveling!Life Hacks NinjaA Simple Method to Reduce Neuropathy (Watch)Health Today NewsIt's Time to Say Goodbye to Bulky Air Conditioners That Take Up SpaceOutfanyNew! Three Banks in Washington Offering 12% Interest on Savings Accounts!Savings Accounts | Search adsPrimary Immunodeficiency - Important Indicators and Signals You Should Check!immunodeficiencyHere is the Cost of One Day Full Mouth Dental Implants in 2024!Dental ImplantsA 70-year-old Engineer Designed This Nail Clipper for Seniors All Over the WorldSherumNew: This Diabetes-linked Discovery is Leaving Doctors PetrifiedHealthStorm -EdtCaitlin Clark Steps out With Her New Partner and Stun FansCash RoadsterHere's How Much You Should Pay for Affordable Gutter GuardsLeafFilter PartnerKeurig Alert: the Shocking Fact That Almost Ended Many Users' Loyalty!Coffee MagazineA Pair of Reading Glasses That Can See Both Far and Near！Outfany Warning Signs That You Have Tnbc (Look Now!)TNBCPlace a Dryer Sheet in Your Mailbox, Here's WhySogoodlyDo You Know What Crohn's Disease in Females is Like Take a Look!Crohn's Disease TreatmentTop-rated Oil Change Services for Seniors in Washington: Find the BestOil change | Search ads1 Simple Trick to Cut Your Electric Bill by 90% (Try Tonight)GadgetVanguardDo You Know What Causes Tnbc? Common Tnbc Signs Will Surprise YouTNBC TreatmentDangerous Signs That You Have Tnbc (Take a Look!)TNBC TreatmentRestore Your Eyes to 20/20 Vision (Naturally)Health News | Vision15 Best Dog Breeds for Seniors - No. 7 Will Surprise YouMom Life Weekly30+ Coolest Gifts Nobody Would Think ofGadgets LaboratoryNеurоpathу Breakthrough: Experts SpeechlessWellness Gaze NueroBelly Fat Removal Without Surgery in Washington! (See the Prices)Fat RemovalStop Lower Back Pain & Sciatica With One Stretch (Do This Immediately)WellnessGaze Back HealthThe First Red Flag of Bipolar Disorder! (Quick Test) Bipolar DisorderUnderstanding Hepatitis: Early Signals and TreatmentsHepatitis TreatmentWhat Are the First Symptoms of Hep C in Women? Learn Here!Hepatitis CUnsold Lab Diamonds on Clearance Sale: See the List!Lab DiamondsNever Put Mustard in Your Fridge, Here's WhyLife Hacks GardenMedical Expert Found a Way to Wipe out Lung Mucus, Phlegm, TarWellnessGaze Lung Health 

 

Most Popular
Recommended For You                                                                
    


Sharks spotted feasting on dead whale in Cape Cod Bay: ‘Something I have never seen before’




4 must-read Indigenous books for young readers




‘A significant security failure’ Bill Bratton says as questions fly about Trump assassination attempt




Battenfeld: Assassination attempt elevates Trump, forces Democrats to dial back rhetoric




Ticker: ISO braces for heat; Hotel workers protest Wednesday




Travel: What I’ve seen on 33 cruises I’ve taken since the pandemic




Why “The Bear” is the best TV depiction of a chef’s hectic mind




Dear Abby: Wife ready to bolt with hubby’s best man




Lowry: Buttigieg defends dearth of EV charging stations




Who is JD Vance? Things to know about Donald Trump’s pick for vice president




 



Trending Nationally


 

","{'@type': 'WebPage', '@id': 'https://www.bostonherald.com/2018/11/25/hbo-documentary-a-creepy-look-at-artificial-intelligence/'}",,,,,,,,,,,,,,,,,https://www.bostonherald.com/wp-content/uploads/migration/1969/12/31/3ebf6e54-edcb-11e8-89c1-f33a59017696.jpg?w=150,2018-11-25T05:00:00Z,,,,,,,https://www.bostonherald.com/2018/11/25/hbo-documentary-a-creepy-look-at-artificial-intelligence/,,[],,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vd3d3Lm15aXUub3JnL3N0b3JpZXMvaXUtYWktbGF3LXNwZWVjaC1hbmQtdGhlLXdvcmxkLW9mLXdvcmsv0gEA?oc=5,"IU & AI: Law, Speech, and the World of Work : Pride of IU Stories - My IU",2018-11-21,My IU,https://www.myiu.org,,,Experts employed and trained by IU are exploring the many aspects and influences of artificial intelligence. There’s the alum and legal scholar talking about AI systems as they relate to…,,https://schema.org,,,,,,,,,,,,,,,"

November 21, 2018 / Research & Innovation


IU & AI: Law, Speech, and the World of Work



0 

  



 share  
  



 post  
  



 share  
  



 email  







Experts employed and trained by IU are exploring the many aspects and influences of artificial intelligence. There’s the alum and legal scholar talking about AI systems as they relate to privacy, safety, and liability; the IU professor working to teach speech-recognition systems the nuances of human language; and, finally, a pair of IU experts—a computer historian and a radiologist—giving their views of AI’s impact on human employment.
For those in the legal field, artificial intelligence systems bring with them a host of new legal issues that will no doubt be explored through the courts in years to come, says Drew Simshaw, JD’12, a legal method/communication fellow at Elon University School of Law. For Simshaw, who coauthored a chapter on “Cybersecurity and the Legal Profession” for the National Cybersecurity Institute’s Cybersecurity in Our Digital Lives, legal issues surrounding new technologies are a specialty.
The legal issues stemming from artificial intelligence largely fall into three buckets: privacy, safety, and liability. Questions of privacy might stem from the healthcare field, where medical information gathered by technology systems would not be covered by existing privacy petitions, whereas questions of apportioning blame will likely arise when something goes wrong with a new technology, such as an autonomous vehicle or robotic surgical procedure.
“There’s an increasingly large ecosystem with new players and new entities working together to makes these technologies a reality, and it is hard to allocate risk when we don’t know what the risks are,” he says.
Right now, there are few clear answers to questions of liability when it comes to artificially intelligent systems, Simshaw says. This is a major reason we are seeing a “slow rollout” of some new forms of technology, he says.
“As recently as a few years ago, it was predicted we’d see driverless cars become ubiquitous very, very quickly, and we are of course seeing that’s not the case. Even with things like robotic surgery and driverless cars, you are seeing humans not being taken far out of the loop, which makes it easier for humans to intervene when those machines don’t behave the way we think they will.”
Artificial Intelligence and Language
Damir Cavar, associate professor of computational linguistics at IU, is at work on a group of projects that develops data sets and algorithms aimed at teaching speech-recognition systems the nuances of human language. Right now, most industrial speech recognition systems are trained to take a series of audio signals and simply identify the words being used. Such systems can’t understand the significance of the way something is said—yet.
“Imagine, I see my dog chewing a shoe and ask, ‘What did you do’ with a non-interrogative intonation, rather the intonation of ‘Bad dog, I see what you did, this is not good,’” Cavar says. “We build the data sets for such speech properties and train algorithms to detect this, to identify irony, sentiment, and sarcasm using spoken language signal, intonation, specific accent, or stress patterns.”
Artificial Intelligence and Employment
The rise of AI also triggers perhaps one of the oldest fears about any new technology, the potential displacement of workers.
“Computers in some way have always been about replacing human workers, and so always, whether you are talking about computers in a conventional sense or artificial intelligence, there is always a concern of, ‘What human labor will this replace?’” says Nathan Ensmenger, chair of IU’s School of Informatics, Computing, and Engineering and a longtime researcher of the history of computing.
In the United States, for instance, automation has been a major cause of the reduction in manufacturing jobs once available.
In another field—radiology—many have feared that automation could mean a reduced need for trained radiologists; one leader in the field, Geoffrey Hinton, has even argued that medical schools should stop training people as radiologists. However, Dr. Himanshu Shah, chair of the Department of Radiology and Imaging Science at the Indiana University School of Medicine, strongly disagrees.
Shah believes that artificial intelligence will play an important role in radiology in the years to come, but not to replace humans. Rather, he believes such systems will help radiologists—who he describes as being “maxed out”—cope with the enormous amounts of data now available to them. As imaging technology has improved, radiologists now have many hundreds, even thousands, of images to review from each individual patient, when in the past they would have had perhaps 100.
“There are a lot of applications that are getting increasing hype,” Shah says of artificial intelligence systems in radiology. “Not how to replace the radiologists, but how to make the radiologists more productive; [how to] provide a second set of eyes or elevate the performance of generalists to get them closer to specialists levels.”
While there can be no dispute that some jobs have been lost to automation, Ensmenger believes that job losses on a massive scale in the future are less likely than people think. More likely, facets of jobs will be shifted to computers, but humans will retain the roles for which they are better suited.
“This idea that in 10 years we’ll all have nothing to do and our big problem will be figuring out what to do with our spare time is as absurd now as it was when people were predicting that in the 1950s, which was as absurd as when John Maynard Keynes was predicting that in the 1920s,” Shah says. “It’s a fantasy.”

To read about other IU people at work on the impact of artificial intelligence, check out the “Thinking Machines” feature story in the Winter 2018 issue of the IU Alumni Magazine, a magazine for members of the IU Alumni Association. View current and past issues of the IUAM.
 


Tags from the story
IU Alumni Magazine 

Written By
Kasey Husk
Kasey Husk, BA’08, is a freelance writer/blogger living in Sicily, Italy.

",,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.myiu.org/stories/iu-ai-law-speech-and-the-world-of-work/', 'url': 'https://www.myiu.org/stories/iu-ai-law-speech-and-the-world-of-work/', 'name': 'IU & AI: Law, Speech, and the World of Work : Pride of IU Stories: My IU: Indiana University', 'isPartOf': {'@id': 'https://www.myiu.org/stories/#website'}, 'primaryImageOfPage': {'@id': 'https://www.myiu.org/stories/iu-ai-law-speech-and-the-world-of-work/#primaryimage'}, 'image': {'@id': 'https://www.myiu.org/stories/iu-ai-law-speech-and-the-world-of-work/#primaryimage'}, 'thumbnailUrl': 'https://www.myiu.org/stories/wp-content/uploads/2018/11/AI_headerimage_1050x700.jpg', 'datePublished': '2018-11-21T13:22:23+00:00', 'dateModified': '2023-03-20T15:07:20+00:00', 'author': {'@id': 'https://www.myiu.org/stories/#/schema/person/db397acadf1b9442aa9a61d181c7910c'}, 'breadcrumb': {'@id': 'https://www.myiu.org/stories/iu-ai-law-speech-and-the-world-of-work/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.myiu.org/stories/iu-ai-law-speech-and-the-world-of-work/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.myiu.org/stories/iu-ai-law-speech-and-the-world-of-work/#primaryimage', 'url': 'https://www.myiu.org/stories/wp-content/uploads/2018/11/AI_headerimage_1050x700.jpg', 'contentUrl': 'https://www.myiu.org/stories/wp-content/uploads/2018/11/AI_headerimage_1050x700.jpg', 'width': 1050, 'height': 700, 'caption': 'photo of a robot ""thinking""'}, {'@type': 'BreadcrumbList', '@id': 'https://www.myiu.org/stories/iu-ai-law-speech-and-the-world-of-work/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.myiu.org/stories/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Recent stories', 'item': 'https://www.myiu.org/stories/recent-stories/'}, {'@type': 'ListItem', 'position': 3, 'name': 'IU &#038; AI: Law, Speech, and the World of Work'}]}, {'@type': 'WebSite', '@id': 'https://www.myiu.org/stories/#website', 'url': 'https://www.myiu.org/stories/', 'name': 'Pride of IU Stories', 'description': 'For all IU alumni and friends', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.myiu.org/stories/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.myiu.org/stories/#/schema/person/db397acadf1b9442aa9a61d181c7910c', 'name': 'Kasey Husk', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.myiu.org/stories/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/e7c39342dd7bde87ec1b75643fe78743?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/e7c39342dd7bde87ec1b75643fe78743?s=96&d=mm&r=g', 'caption': 'Kasey Husk'}, 'description': 'Kasey Husk, BA’08, is a freelance writer/blogger living in Sicily, Italy.'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vd3d3LmNvbnN0cnVjdGlvbmtlbnlhLmNvbS82NTUyL2JvYmNhdC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,Doosan Bobcat Bets on AI to Tackle Job Site Inefficiencies | CK - Construction Kenya,2018-11-21,Construction Kenya,https://www.constructionkenya.com,Doosan Bobcat North America is betting on artificial intelligence (AI) for its future construction equipment as it seeks to boost efficiency on site.,,Firm wants to help equipment operators to maximise their productivity.,Firm wants to help equipment operators to maximise their productivity.,https://schema.org,,,,,,,,,,,,,,,"





Tools & Supplies
Doosan Bobcat Bets on AI to Tackle Job Site Inefficiencies
Firm wants to help equipment operators to maximise their productivity.



 


Updated on  November 21, 2018


By Patrick Thuita  












































Share




Tweet





























Doosan Bobcat is seeking to boost efficiency on the job site. PHOTO | COURTESY
Doosan Bobcat North America is betting on artificial intelligence (AI) for its future construction equipment as the heavy machinery maker seeks to boost efficiency on the job site.
The U.S. and Canadian unit of Doosan Bobcat Inc., has partnered with SafeAI – a Silicon Valley startup – to explore how AI technologies can be amalgamated into Bobcat equipment.
Through this partnership, SafeAI will demonstrate how its AI technologies, Deep Neural Network (DNN), and Deep Reinforcement Learning (DRL) can be used to perceive environments around construction equipment and provide auto-control.






“Through our partnership with SafeAI, we hope to work toward our ultimate goal of enabling our customers to work more efficiently on the job site,” Joel Honeyman, VP of global innovation Doosan Bobcat North America said in a press statement.
Maximise productivity
The partnership is part of Doosan Bobcat North America’s initiative to identify forward-looking solutions to help construction equipment operators to maximise their productivity.
Bibhrajit Halder, chief executive and co-founder of SafeAI said his company is “building a safe, AI-enabled autonomous platform for the equipment industry.”
RELATED: Caterpillar Foresees Major AI Disruption in Construction
The partnership comes at a time when the construction industry is increasingly turning to AI as a means to make job sites safer and more efficient.
Secure construction sites
Japanese equipment giant Komatsu recently signed a deal with California-based Nvidia and two others to deploy an Artificial Intelligence (AI) computing platform in the heavy machinery industry in a bid to improve efficiency and make construction sites safer.






The partnership also involves OPTiM, a management software firm, which will provide an app to identify individuals and machinery collected from surveillance cameras, and SkyCatch, which will provide drones to gather and map 3D images for visualizing the terrain at the edge.
RELATED: Japan’s Komatsu Adds AI to Its Machinery
According to the deal, Komatsu will integrate Nvidia’s AI platform – a credit card-sized device designed to drive robots and drones – which will serve as the brain of heavy machinery, thereby improving efficiency and worker safety on site.
Movement of workers
SkyCatch’s drone views and pictures captured through cameras mounted on Komatsu’s heavy equipment will be processed with Nvidia’s deep learning-based AI, enabling the firm to track the movement of workers and equipment, thus minimising the chances of fatal accidents.






Through robotics, construction managers can utilise intelligent machines that can perform tedious tasks that were once completed by humans, such as bricklaying.
On the other hand, AI systems can gather and organise information for engineers to use within project planning and design implementation.
 Join 15,000+ pros getting our weekly digest of news and insights.

Read Next...




Related Topics:Construction Equipment






 


Patrick Thuita










Patrick Thuita holds a degree in Mechanical Engineering from the University of Nairobi. With 10+ years of experience in the construction equipment industry, he brings a wealth of expertise to our coverage.























    ADVERTISEMENT
  




TRENDING






  



Materials & Supplies

Chinese Roofing Giant Opens Factory in Machakos
The plant will produce 4m tiles and 3m metres of iron sheets annually.









  



Infrastructure

Sh82bn Thwake Dam Set to Open in December
The government has so far spent over Sh36 billion on the project.







TOOLS & SUPPLIES






  



Tools & Supplies

JCB Machine That Seals Potholes in Under 8 Minutes
The JCB Pothole Pro is four times faster than traditional methods.









  



Tools & Supplies

Concrete Finishing Robot Cuts Labour Costs by 30%
The robot cuts costs while improving quality and safety.









  



Tools & Supplies

Rebar Tying Robot Works Its Magic on Highway Project
The robot can tie up to 1,100 rebar intersections per hour.







 
Advertisement



 
  



",,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/#article', 'isPartOf': {'@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/'}, 'author': {'name': 'Patrick Thuita', '@id': 'https://www.constructionkenya.com/#/schema/person/384c969f9e815587d3c96bcb3379b289'}, 'headline': 'Doosan Bobcat Bets on AI to Tackle Job Site Inefficiencies', 'datePublished': '2018-11-21T05:19:48+00:00', 'dateModified': '2024-07-11T05:35:35+00:00', 'mainEntityOfPage': {'@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/'}, 'wordCount': 451, 'publisher': {'@id': 'https://www.constructionkenya.com/#organization'}, 'image': {'@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.constructionkenya.com/wp-content/uploads/2018/11/Doosan-Bobcat-Equipment.jpg', 'keywords': ['Construction Equipment'], 'articleSection': ['Tools &amp; Supplies'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/', 'url': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/', 'name': 'Doosan Bobcat Bets on AI to Tackle Job Site Inefficiencies | CK', 'isPartOf': {'@id': 'https://www.constructionkenya.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.constructionkenya.com/wp-content/uploads/2018/11/Doosan-Bobcat-Equipment.jpg', 'datePublished': '2018-11-21T05:19:48+00:00', 'dateModified': '2024-07-11T05:35:35+00:00', 'description': 'Doosan Bobcat North America is betting on artificial intelligence (AI) for its future construction equipment as it seeks to boost efficiency on site.', 'breadcrumb': {'@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/#primaryimage', 'url': 'https://www.constructionkenya.com/wp-content/uploads/2018/11/Doosan-Bobcat-Equipment.jpg', 'contentUrl': 'https://www.constructionkenya.com/wp-content/uploads/2018/11/Doosan-Bobcat-Equipment.jpg', 'width': 740, 'height': 410, 'caption': 'Doosan Bobcat is seeking to boost efficiency on the job site. PHOTO/COURTESY'}, {'@type': 'BreadcrumbList', '@id': 'https://www.constructionkenya.com/6552/bobcat-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.constructionkenya.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Doosan Bobcat Bets on AI to Tackle Job Site Inefficiencies'}]}, {'@type': 'WebSite', '@id': 'https://www.constructionkenya.com/#website', 'url': 'https://www.constructionkenya.com/', 'name': 'CK', 'description': 'Delivering Industry Insights', 'publisher': {'@id': 'https://www.constructionkenya.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.constructionkenya.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.constructionkenya.com/#organization', 'name': 'CK', 'url': 'https://www.constructionkenya.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.constructionkenya.com/#/schema/logo/image/', 'url': 'https://www.constructionkenya.com/wp-content/uploads/2020/09/Nav.png', 'contentUrl': 'https://www.constructionkenya.com/wp-content/uploads/2020/09/Nav.png', 'width': 188, 'height': 60, 'caption': 'CK'}, 'image': {'@id': 'https://www.constructionkenya.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/constructionkenya', 'https://x.com/ConstructKe', 'https://www.linkedin.com/company/constructionkenya', 'https://www.youtube.com/channel/UC6st5X4g9GCsq49vFhTmVZQ/videos']}, {'@type': 'Person', '@id': 'https://www.constructionkenya.com/#/schema/person/384c969f9e815587d3c96bcb3379b289', 'name': 'Patrick Thuita', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.constructionkenya.com/#/schema/person/image/', 'url': 'https://www.constructionkenya.com/wp-content/uploads/2019/08/Author-150x150.png', 'contentUrl': 'https://www.constructionkenya.com/wp-content/uploads/2019/08/Author-150x150.png', 'caption': 'Patrick Thuita'}, 'description': 'Patrick Thuita holds a degree in Mechanical Engineering from the University of Nairobi. With 10+ years of experience in the construction equipment industry, he brings a wealth of expertise to our coverage.', 'sameAs': ['https://www.facebook.com/constructionkenya', 'https://www.instagram.com/construction.kenya/', 'https://www.pinterest.com/BuildersCK', 'https://x.com/https://twitter.com/BuildersCK']}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd3d3LnNlbnRpbmVsYXNzYW0uY29tL2J1c2luZXNzL2FwcGxlLWFjcXVpcmVzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFpLXN0YXJ0dXAtc2lsay1sYWJzP2FtcNIBdmh0dHBzOi8vd3d3LnNlbnRpbmVsYXNzYW0uY29tL2FtcC9zdG9yeS9tb3JlLW5ld3MvYnVzaW5lc3MvYXBwbGUtYWNxdWlyZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWktc3RhcnR1cC1zaWxrLWxhYnM?oc=5,Apple Acquires Artificial Intelligence (AI) Startup Silk Labs - The Sentinel Assam,2018-11-22,The Sentinel Assam,https://www.sentinelassam.com,,Apple,San Francisco: Apple has acquired a Startup called Silk Labs that work on Artificial Intelligence (AI)-based personal assistant technology for smartphones and s,San Francisco: Apple has acquired a Startup called Silk Labs that work on Artificial Intelligence (AI)-based personal assistant technology for smartphones and s,http://schema.org,NewsArticle,https://www.sentinelassam.com/more-news/business/apple-acquires-artificial-intelligence-ai-startup-silk-labs,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/english-sentinelassam/import/wp-content/uploads/2018/11/Apple-2.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Sentinel Digital Desk', 'name': 'Sentinel Digital Desk', 'url': 'https://www.sentinelassam.com/author/sentinel-digital-desk'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Sentinel Assam', 'url': 'https://www.sentinelassam.com', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'sentinelassam-english', 'contentUrl': 'https://images.assettype.com/sentinelassam-english/2023-11/b2197df0-9eaa-40ea-b054-29dfcdd64e5e/Header.png', 'url': 'https://images.assettype.com/sentinelassam-english/2023-11/b2197df0-9eaa-40ea-b054-29dfcdd64e5e/Header.png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.facebook.com/thesentinel.assam/', 'https://www.instagram.com/thesentineldigital/', 'https://www.youtube.com/channel/UC1b9a3Rk0aJ643armkHW2ZA', 'https://twitter.com/sentinel_assam/'], 'id': 'https://www.sentinelassam.com'}",Apple Acquires Artificial Intelligence (AI) Startup Silk Labs,2018-11-22T22:31:54Z,2018-11-22T22:31:54Z,Business,Apple Acquires Artificial Intelligence (AI) Startup Silk Labs,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.sentinelassam.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'More', 'item': 'https://www.sentinelassam.com/more-news'}, {'@type': 'ListItem', 'position': 3, 'name': 'Business', 'item': 'https://www.sentinelassam.com/more-news/business'}, {'@type': 'ListItem', 'position': 4, 'name': 'Apple Acquires Artificial Intelligence (AI) Startup Silk Labs', 'item': 'https://www.sentinelassam.com/more-news/business/apple-acquires-artificial-intelligence-ai-startup-silk-labs'}]",,,,"{'@type': 'WebPage', '@id': 'https://www.sentinelassam.com/more-news/business/apple-acquires-artificial-intelligence-ai-startup-silk-labs'}",,,,,,"{'@type': 'WebPage', 'url': 'https://www.sentinelassam.com/more-news/business/apple-acquires-artificial-intelligence-ai-startup-silk-labs', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/english-sentinelassam/import/wp-content/uploads/2018/11/Apple-2.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,"San Francisco: Apple has acquired a Startup called Silk Labs that work on Artificial Intelligence (AI)-based personal assistant technology for smartphones and smart home devices. According to a report in The Registrar, the quietly-done acquisition for an undisclosed sum is aimed at strengthening Apple’s Artificial Intelligence capabilities towards smart home devices. Silk Labs had about a dozen employees and raised approximately $4 million in funding, said the report. According to TechCrunch, Silk Labs is the brainchild of Andreas Gal, the former CTO of Mozilla, who had also created the mobile platform Firefox OS and Michael Vines from Qualcomm. Apple is working hard towards improving its AI-enabled products, including HomePod smart speaker which is behind Amazon Alexa and Google Home. Amazon and Google accounted for 70 percent share of the global smart speaker shipments in the first quarter of 2018, with Apple selling 600,000 HomePods in the period. According to market research firm Strategy Analytics, global smart speaker shipments reached 9.2 million units in the first quarter of 2018. (IANS)",https://media.assettype.com/english-sentinelassam/import/wp-content/uploads/2018/11/Apple-2.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,2018-11-22T22:31:54Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,

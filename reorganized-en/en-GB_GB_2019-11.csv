URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,mainEntityOfPage,headline,image,author,datePublished,dateModified,publisher,itemListElement,article:section,article:summary,article text,name,thumbnailUrl,articleSection,@graph,url,potentialAction,logo,sameAs,@id,isBasedOn,video,creator,dateCreated,mainEntity,inLanguage,alternativeHeadline,hasPart,copyrightHolder,sourceOrganization,copyrightYear,isAccessibleForFree,isPartOf,diversityPolicy,ethicsPolicy,masthead,foundingDate,legalName,telephone,address,speakable,interactivityType,contentLocation,articleBody,heading,alternateName,contactPoint,genre,wordcount,uploadDate,duration,contentUrl,embedUrl,interactionStatistic,timeRequired,wordCount,specialty,mainContentOFPage,lastReviewed,target,slogan,founder,numberOfEmployees,associatedMedia,editor
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LmZpbmV4dHJhLmNvbS9uZXdzYXJ0aWNsZS8zNDY4MC9haS13aWxsLW5vdC1iZS1qb2Ita2lsbGVyLS0taWJtLXJlc2VhcmNo0gEA?oc=5,AI will not be job killer - IBM research - Finextra,2019-11-01,Finextra,https://www.finextra.com,"Contrary to the conventional wisdom, new technologies such as AI will actually kill off few jobs, according to research from the MIT-IBM Watson AI Lab.","Finextra,news,online,bank,banking,technology,finance,financial,fin,tech,fintech,IT,breaking,latest,retail,transaction,trade,execution,headlines,blockchain,digital,investment,mobile,business,challenger,payments,regtech,insurtech,services","Contrary to the conventional wisdom, new technologies such as AI will actually kill off few jobs, according to research from the MIT-IBM Watson AI Lab.","Contrary to the conventional wisdom, new technologies such as AI will actually kill off few jobs, according to research from the MIT-IBM Watson AI Lab.",http://schema.org,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://www.finextra.com/newsarticle/34680/ai-will-not-be-job-killer---ibm-research'}",AI will not be job killer - IBM research,"{'@type': 'ImageObject', 'url': 'https://www.finextra.com/finextra-images/top_pics/xl/ai brain.jpg', 'height': 270, 'width': 480}","{'@type': 'Person', 'name': 'Editorial Team'}",2019-11-01T00:01:00,2019-11-01T09:07:57,"{'@type': 'Organization', 'name': 'Finextra', 'logo': {'@type': 'ImageObject', 'url': 'https://www.finextra.com/about/finextra-logo.png', 'width': 512, 'height': 512}}","[{'@type': 'ListItem', 'position': 1, 'name': 'home page', 'item': 'https://www.finextra.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'latest news', 'item': 'https://www.finextra.com/latest-news'}, {'@type': 'ListItem', 'position': 3, 'name': 'ai', 'item': 'https://www.finextra.com/channel/ai'}, {'@type': 'ListItem', 'position': 4, 'name': 'news-article', 'item': 'https://www.finextra.com/newsarticle/34680/ai-will-not-be-job-killer---ibm-research'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LnNpbGljb24uY28udWsvZS1pbm5vdmF0aW9uL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2dvb2dsZS1kaXNiYW5kcy1haS1jb3VuY2lsLTI0MzY0N9IBZGh0dHBzOi8vd3d3LnNpbGljb24uY28udWsvZS1pbm5vdmF0aW9uL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2dvb2dsZS1kaXNiYW5kcy1haS1jb3VuY2lsLTI0MzY0Ny9hbXA?oc=5,Google Disbands AI Advisory Council - Silicon UK,2019-11-05,Silicon UK,https://www.silicon.co.uk,That lasted long. Google pulls the plug on AI council over concern of a couple of its female members,,That lasted long. Google pulls the plug on AI council over concern of a couple of its female members,,https://schema.org,BreadcrumbList,"{'@type': 'WebPage', 'id': 'https://www.silicon.co.uk/e-innovation/artificial-intelligence/google-disbands-ai-council-243647'}",Google Disbands AI Advisory Council,"{'@type': 'ImageObject', 'url': 'https://www.silicon.co.uk/wp-content/uploads/2015/01/Google3.jpg', 'width': '1000', 'height': '667'}","{'@type': 'Person', 'name': 'Tom Jowitt'}",2019-04-05T08:55:37+01:00,2019-11-05T21:15:23+00:00,"{'@type': 'Organization', 'name': 'Silicon UK', 'logo': {'@type': 'ImageObject', 'url': 'https://www.silicon.co.uk/wp-content/themes/kamino/assets/images/favicons_silicon/mstile-70x70.png', 'width': '', 'height': ''}}","[{'@type': 'ListItem', 'position': 1, 'item': 'https://www.silicon.co.uk/', 'name': 'All Tech News'}, {'@type': 'ListItem', 'position': 2, 'item': 'https://www.silicon.co.uk/news/e-innovation', 'name': 'Innovation'}, {'@type': 'ListItem', 'position': 3, 'item': 'https://www.silicon.co.uk/news/e-innovation/artificial-intelligence', 'name': 'Artificial Intelligence'}, {'@type': 'ListItem', 'position': 4, 'item': 'https://www.silicon.co.uk/e-innovation/artificial-intelligence/google-disbands-ai-council-243647', 'name': 'Google Disbands AI Advisory Council'}]",,,"


Google Disbands AI Advisory Council

Tom Jowitt, April 5, 2019, 8:55 am | Updated on 5 November 2019, 21:15 















That lasted long. Google pulls the plug on AI council over concern of a couple of its female members

 Google has said it is “going back to the drawing board” as it considers the best guidance on ethical issues relating to artificial intelligence (AI) and machine learning.
Late last month Google created the ‘Advanced Technology External Advisory Council (ATEAC)’, to offer guidance on the ethical use of AI.
Yet just a week later Google has announced it is “ending the council”, apparently due to staff concerns at the inclusion of two female members in the council.

Troubled week
“It’s become clear that in the current environment, ATEAC can’t function as we wanted,” Google said in a statement. “So we’re ending the council and going back to the drawing board. We’ll continue to be responsible in our work on the important issues that AI raises, and will find different ways of getting outside opinions on these topics.”
The eight-member council includes Joanna Bryson, an associate professor in computing at the University of Bath; William J. Burns, a former US deputy secretary of state, and leading mathematician Bubacarr Bah.
The creation of the council had come after Alphabet CEO Sundar Pichai in June 2018 created new principles for AI use at Google, and pledged not to use AI for technology that causes injury to people.
But according to Vox.com, Google took the decision because of tensions with its staff and cancelled the council after less than one week.
Specifically the staff were angered about the inclusion of one person and the comments she had made about transsexual people.
And the inclusion of a drone company executive also prompted anger considering Google’s withdraw from a Pentagon drone project that utilised Google’s AI technology.
“Thousands of Google employees signed a petition calling for the removal of one board member, Heritage Foundation president Kay Coles James, over her comments about trans people and her organisation’s scepticism of climate change,” Vox reported. “Meanwhile, the inclusion of drone company CEO Dyan Gibbens reopened old divisions in the company over the use of the company’s AI for military applications.”
Board member Alessandro Acquisti had also announced his resignation from the board on Twitter, saying it wasn’t the right forum for him to continue dealing with “key ethical issues of fairness, rights & inclusion in AI.”
Project Maven
Google has had a chequered time with its AI development.
Last year it would not renew a contract to do artificial intelligence work for the US Pentagon.
The project was codenamed Project Maven, and Google’s decision to withdraw came after internal pressure from Google staff, some of whom had resigned over the matter.
Google’s involvement in Project Maven aimed to speed up the analysis of drone footage.
Essentially, the search engine giant was said to be using machine-learning algorithms and AI to help the US military assess drone footage quickly, in order to distinguish people and objects in drone videos.
Put your knowledge of artificial intelligence (AI) to the test. Try our quiz!
Advertising
 Read also : 
Japan’s SoftBank Acquires AI Chip Start-up Graphcore
Silicon UK In Focus PodcastsponsoriséSilicon In Focus Podcast: The Value of Data00:0000:0000:0000:00SubscribeEdisoundRSS FeedSpotifyDeezerAmazon MusicApple PodcastsShare EpisodeFacebookXLinkedInEpisode linkCopied !





 
Recommend this article:




                    0                









                    0                










 NEWSLETTER 
 Subscribe to our best articles 









 


 Facebook
                            




  Twitter




  Linkedin









Advertising



",Google Disbands AI Advisory Council,https://www.silicon.co.uk/wp-content/uploads/2015/01/Google3-600x400.jpg,Artificial Intelligence,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vd3d3LnBicy5vcmcvd2diaC9mcm9udGxpbmUvYXJ0aWNsZS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hbGdvcml0aG1pYy1iaWFzLXdoYXQteW91LXNob3VsZC1rbm93L9IBAA?oc=5,Artificial Intelligence Can Be Biased. Here's What You Should Know. - PBS,2019-11-05,PBS,https://www.pbs.org,Artificial intelligence has already started to shape our lives in ubiquitous and occasionally invisible ways. A researcher in algorithmic bias talks to FRONTLINE about what she thinks the public needs to know about these systems.,,Artificial intelligence has already started to shape our lives in ubiquitous and occasionally invisible ways. A researcher in algorithmic bias talks to FRONTLINE about what she thinks the public needs to know about these systems.,Artificial intelligence has already started to shape our lives in ubiquitous and occasionally invisible ways. A researcher in algorithmic bias talks to FRONTLINE about what she thinks the public needs,https://schema.org,,,,,,,,,,,,"



Artificial Intelligence Can Be Biased. Here’s What You Should Know.

Share:



Twitter


Facebook


E-mail


 








A display shows a facial recognition system for law enforcement during the NVIDIA GPU Technology Conference in Washington, DC, Nov. 1, 2017. (SAUL LOEB/AFP via Getty Images)





November 5, 2019

by


Priyanka Boghani





Artificial intelligence has already started to shape our lives in ubiquitous and occasionally invisible ways. In its new documentary, In The Age of AI, FRONTLINE examines the promise and peril this technology. AI systems are being deployed by hiring managers, courts, law enforcement, and hospitals — sometimes without the knowledge of the people being screened. And while these systems were initially lauded for being more objective than humans, it’s fast becoming clear that the algorithms harbor bias, too.
It’s an issue Joy Buolamwini, a graduate researcher at the Massachusetts Institute of Technology, knows about firsthand. She founded the Algorithmic Justice League to draw attention to the issue, and earlier this year she testified at a congressional hearing on the impact of facial recognition technology on civil rights.
“One of the major issues with algorithmic bias is you may not know it’s happening,” Buolamwini told FRONTLINE. We spoke to her about how she encountered algorithmic bias, about her research, and what she thinks the public needs to know.
This interview has been edited for length and clarity.
On her first encounter with algorithmic bias.
The first time I had issues with facial detection technology was actually when I was an undergraduate at Georgia Tech, and I was working on a robot. The idea with this robot was to see if I could get it to play peek-a-boo with me. And peek-a-boo doesn’t really work if your robot can’t see you, and my robot couldn’t see me. To get my project done, I borrowed my roommate’s face. She was lighter skinned than I was. …That was my first time really using facial analysis technology and seeing that it didn’t work for me the same way it worked for other people. …
I went on to do many things and became a graduate student at MIT and I started working on projects that used facial analysis technology, face detection. So one project I did was something called the Aspire Mirror. You look into a mirror, a camera detects your face and then a lion can appear on you, or you can be somebody you’re inspired by…
[I]t wasn’t detecting my face consistently, so I got frustrated. So what do you do when you get frustrated with your program? You debug. I started trying to figure out ways to make it work. I actually drew a face on my hand, and the system detected the face on my palm. And I was like, “Wait, wait, wait, if it’s detecting the face I just drew on my palm, then anything’s a possibility now.” So I looked around my office and the white mask was there. So I was like, “There’s no way! But why not?”
I pick up the white mask, and I put it on and it’s instantaneous when I put on that white mask, and I mean just — the symbolism of it was not lost to me. This is ridiculous that the system can detect this white mask that is not a real person, but cannot necessarily detect my face. So this is really when I started thinking, “Okay, let’s a dig a bit deeper with what’s going on with these systems.” …
On digging a bit deeper into facial analysis technology.
Here was a question: Do these systems perform differently on various faces? There was already a 2012 report that actually came out from an FBI facial analysis expert showing that facial recognition systems in particular worked better on white faces than black faces. They didn’t work as well on youthful faces. And they didn’t work as well on women as compared to men. This was 2012, and why I keep bringing that up is this was before the deep learning revolution…
Now we had a different approach that was supposed to be working much better. My question was, given these new approaches to facial analysis and facial recognition, are there still biases? Because what I’m experiencing, what my friends are experiencing — and what I’m reading about with reports that say, “Oh, we’ve solved face recognition,” or “We’re 97% accurate from benchmarks” — those reports were not lining up to my reality. …
What I focused on specifically was gender classification. …I wanted to choose something that I thought would be straightforward to explain, not that gender is straightforward — it’s highly complex. But insomuch as we were seeing binary gender classification, I thought that would be a place to start. By this time my weekend hobby was literally running my face through facial analysis and seeing what would happen. So some wouldn’t detect my face and others would label me male. And I do not identify as male. This is what led down that corridor.
On finding the “gold standard benchmarks” were not representative.
When I ran this test, the first issue that I ran into which gave me some more insight with the issue we’re talking about — algorithmic bias — was that our measures for how well these systems perform were not representative of the world. …We’ve supposedly done well on gold standard benchmarks. So I started looking at the benchmarks. These are essentially the data sets we use to analyze how well we’re doing as a research community or as an industry on specific AI tasks. So facial recognition is one of these tasks that people are benchmarked on all the time.
“What I started to see was something I call ‘power shadows’ — when either the inequalities or imbalances that we have in the world become embedded in our data.”
The thing is, we often times don’t question the status quo or the benchmark. This is the benchmark, why would I question it? But sometimes the gold standard turns out to be pyrite. And that is what was happening in this case. When I went to look at the research on the breakdown of various facial analysis systems, what I found was one of the leading gold standards, labeled “Faces in the Wild,” was over 70% male and 80% white. This is when I started looking into more and more data sets and seeing that you had massive skews. Sometimes you had massive skews because you were using celebrities. I mean, celebrities don’t necessarily look like the rest of the world. What I started to see was something I call “power shadows” — when either the inequalities or imbalances that we have in the world become embedded in our data. …
All this to say, the measures that we had for determining progress with facial analysis technology were misleading because they weren’t representative of people — at least the U.S. in that case. …We didn’t have data sets that were actually reflective of the world, so for my thesis at MIT, I created what I call the Pilot Parliaments Benchmark. I went to UN women’s websites, I got a list of the top 10 nations in the world by their representation of women in parliament. … So I chose European countries and African nations to try to get a spread on opposite ends of skin types, lighter skin and darker skin. After I ran into this issue that the benchmarks were misleading, I needed to make the benchmark.
On what her research found.
Then finally, I could get to the research question. …So I wanted to know how accurate are they at this reduced task of binary gender classification — which is not at all inclusive — when it comes to guessing the gender of the face? And it turned out that there were major gaps. This was surprising because these were commercially sold products. … You know how the story goes. It turns out, the systems work better on male-labeled faces than female-labeled faces, they work better on lighter faces than darker-skinned faces.
But one thing we did for this study, which I would stress for anybody who’s thinking about doing research in algorithmic bias or concerned with algorithmic bias and AI harms, is we did an intersectional analysis. We didn’t just look at skin type. We didn’t just look at gender. We looked at the intersection. And the inspiration for this was from Kimberlé Crenshaw, a legal scholar who in 1989 introduced the term of intersectionality. …What would happen with the analysis is if you did it in aggregate just based on race, or if you did it in aggregate based on just gender, you might find based on those axes that there isn’t substantial evidence of discrimination. But if you did it at the intersection, you would find there was a difference. And so I started looking at the research studies around facial analysis technologies and facial recognition technologies and I saw that usually we just have aggregate results — just one number for accuracy. People are just optimizing for that overall accuracy, which means we don’t get a sense of the various ways in which the system performs for different types of people. It’s the differences in the performance, the accuracy disparities that I was fascinated by, but not just on a single axis but also on the intersection. So when we did the intersectional breakdown — oooh, it was crazy. …
We weren’t doing anything to try to trick the system. It was an optimistic test. This is why I was very surprised, because even with this optimistic test, in the worst-case scenario for the darkest-skinned women, you actually had error rates as high as 47% on a binary classification task. …
I shared the results with the companies and I got a variety of responses. But I think the overall response, at least with the first study, was there was an acknowledgement of an issue with algorithmic bias.
On how AI is already affecting people’s lives.
There’s a paper that just came out from Science which is devastating, showing risk assessment algorithms used in health care… actually have racial bias against black patients. We’re talking about health care where the whole point is to try to optimize the benefit and what they were seeing was because they used how much money is spent on an individual as a proxy for how sick they were, it turned out it was not a good proxy because black patients who were actually sick were being said to be not as sick as they were. …
“When these systems fail, they fail most the people who are already marginalized, the people who are already vulnerable.”
You also have AIs that are determining the kind of ads people see. And so there have been studies that show you can have discriminatory ad targeting. Or you can have a situation where you have an ad for CEO and the system over time learns to present that CEO ad to mainly men. You were saying, how do you know if you’ve encountered bias — the thing is you might never know if you’ve encountered the bias. …Something that might happen to other people — you see phenotypic fails with passport renewals. So you have a report from a New Zealand man of Asian descent being told that his eyes are closed and he needs to upload another photo. Meanwhile, his eyes are not closed. You have, in the UK, a black man being told his mouth is open. His mouth was not open. You have these systems that are seeping into every day.
You have AI systems that are meant to verify if you’re who you say you are. And so one way that can happen is with ride share apps. Uber, for example, will ping drivers to have them verify their ID. There’s actually a report from trans drivers who were saying that they were being repeatedly [asked] to submit their IDs because they were not matching. They were being either kicked out of the system or having to stop the car, test it again, which means you’re not getting the same level of economic opportunity. …
When these systems fail, they fail most the people who are already marginalized, the people who are already vulnerable. And so when we think about algorithmic bias, we really have to be thinking about algorithmic harm. That’s not to say we don’t also have the risk of mass surveillance, which impacts everybody. We also have to think about who’s going to be encountering the criminal justice system more often because of racial policing practices and injustices.
On what the public needs to know about algorithmic bias.
There’s no requirement for meaningful transparency, so these systems can easily be rolled out without our ever knowing. So one thing I wish people would do more of and something that companies also ought to do more of is having transparency so that you even know that an AI system was used in the first place. You just might never get the callback. You just might pay the higher price. You would never actually know. What I want the public to know is AI systems are being used in hidden ways that we should demand are made public.
The other thing I want the public to have is actually choice — affirmative consent. Not only should I know if an AI system is being used, but let’s say it makes the wrong decision or something that I contest. There’s no path to due process that’s mandated right now. So if something goes wrong, what do you do?
Sometimes I’ll hear, at least in the research community, efforts to “de-bias” AI or eradicate algorithmic bias. And it’s a tempting notion, let’s just get rid of the bias and make the systems more fair, more inclusive, some ideal. And I always ask, but have we gotten rid of the humans? Because even if you create some system you believe is somehow more objective, it’s being used by humans at the end of the day. …I don’t think we can ever reach a true state of something being unbiased, because there are always priorities. This is something I call the “coded gaze.” The “coded gaze” is a reflection of the priorities, the preferences and also the prejudices of those who are shaping technology. This is not to say we can’t do our best to try to create systems that don’t produce harmful outcomes. I’m not saying that at all. What I am saying is we also have to accept the fact that being human we’re going to miss something. We’re not going to get it all right. …
“What I want the public to know is AI systems are being used in hidden ways that we should demand are made public.”
Instead of thinking about “Oh, we’re going to get rid of bias,” what we can think about is bias mitigation — knowing that we have flaws, knowing that our data has flaws, understanding that even systems we try to perfect to the best of our abilities are going to be used in the real world with all of its problems. …
Before we get to the point where it’s having major harms with real world consequences, there need to be processes in place to check through different types of bias that could happen. So, for example, AI [systems] now have algorithmic risk assessments that they have as a process of really thinking through what the societal impact of the system are in its design and development stages before you get to the deployment. Those kinds of approaches, I believe, are extremely helpful, because then we can be proactive instead of reacting to the latest headline and playing bias whack-a-mole. …
On proposals for oversight and regulation.
You have a proposal for an Algorithmic Accountability Act, this is a nationwide push that would actually require assessing systems for their social impact. And I think that’s really important. We have something with the Algorithmic Justice League that’s called the Safe Face Pledge, which outlines actionable steps companies can take to mitigate harms of AI systems. …
I absolutely think regulation needs to be the first and foremost tool, but alongside regulation providing not just the critique of what’s wrong with the system, but also steps that people can take to do better. Sometimes the step to take to do better is to commit to not developing a particular kind of technology or particular use case for technology. So with facial analysis systems, one of our banned uses is any situation where lethal force can be used. So it would mean we’re not supporting facial recognition on police body cameras. Or facial recognition on lethal autonomous weapons. …
And I think the most important thing about the Safe Face Pledge that I’ve seen is one, the conversations that I’ve had with different vendors, where whether or not they adopt it actually going through those steps and thinking about their process and changes they can make in the process I believe has made internal shifts that likely would not hit the headlines. Because people would rather quietly make certain kinds of changes. The other thing is making it where the commitments have to be part of your business processes. Not a scouts’ honor pledge, just trust us. If you are committed to actually making this agreement, it means you have to change your terms of service and your business contracts to reflect what these commitments are. …
On what should be done to fix the problem.
One, I think, demand transparency and ask questions. Ask questions if you’re using a platform, if you’re going to a job interview. Is AI being used? The other thing I do think is supporting legislative moves. …
When I started talking about this, I think in 2016, it was such a foreign concept in the conversations that I would have. And now, today, I can’t go online without seeing some kind of news article or story about a biased AI system of some shape or form. I absolutely think there has been an increase in public awareness, whether through books like Cathy O’Neil’s Weapons of Math Destruction. There’s a great new book out by Dr. Ruha Benjamin — Race After Technology.
People know it’s an issue and so I’m excited about that. Has there been enough done? Absolutely not. Because people are just now waking up to the fact that there’s a problem. Awareness is good, and then that awareness needs to lead to action. That is the phase we’re in. Companies have a role to play, governments have a role to play and individuals have a role to play.
When you see the bans in San Francisco [of facial recognition technology by the city’s agencies]… what you saw was a very powerful counter-narrative. What we were hearing was that this technology is inevitable, there’s nothing you can do. …When you hear there’s nothing you can do, you stop trying. But what was extremely encouraging to me with the San Francisco ban — and then you have Somerville that came from the folks who are in Boston — people have a voice and people have a choice. This technology is not inherently inevitable. We have to look at it and say: What are the benefits and what are the harms? If the harms are too great, we can put restrictions and we can put limitations. And this is necessary. I do look to those examples and they give me hope.








Priyanka Boghani, Digital Editor, FRONTLINE


Email:
priyanka_boghani@wgbh.org


Twitter:
@priyankaboghani







Journalistic Standards











Watch the Documentary
In the Age of AI






    Support Provided By
    Learn more







See What FRONTLINE Is Working On Now






Get Our Newsletter





Related Articles




How China’s Government Is Using AI on Its Uighur Muslim Population
November 21, 2019





The Jobs Robots Can't Do (At Least Not Yet)
November 5, 2019





Could the Rise of Artificial Intelligence Put Truckers’ Jobs in Peril?
November 5, 2019





Topics


Social Issues






",,,,"[{'@type': 'NewsArticle', '@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/#article', 'isPartOf': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/'}, 'author': [{'@type': 'Person', 'name': 'Priyanka Boghani', 'url': 'https://www.pbs.org/wgbh/frontline/person/priyanka-boghani/', 'affiliation': {'@type': 'NewsMediaOrganization', 'name': 'FRONTLINE', 'url': 'https://www.pbs.org/wgbh/frontline/about-us/contact-us/'}, 'knowsAbout': [{'@type': 'Thing', 'name': 'foreign policy'}]}], 'headline': 'Artificial Intelligence Can Be Biased. Here&#8217;s What You Should Know.', 'datePublished': '2019-11-06T00:23:31+00:00', 'dateModified': '2019-11-06T01:32:48+00:00', 'mainEntityOfPage': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/'}, 'wordCount': 3285, 'publisher': {'@type': 'Organization', 'name': 'Frontline PBS', 'logo': {'@type': 'ImageObject', 'url': 'https://www.pbs.org/wgbh/frontline/wp-content/themes/fl-responsive-theme/library/images/frontline_logo_og.png'}}, 'image': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/#primaryimage'}, 'thumbnailUrl': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2019/11/GettyImages-869082432.jpg', 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/', 'url': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/', 'name': ""Artificial Intelligence Can Be Biased. Here's What You Should Know. | FRONTLINE"", 'isPartOf': {'@id': 'https://www.pbs.org/wgbh/frontline/#website'}, 'primaryImageOfPage': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/#primaryimage'}, 'image': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/#primaryimage'}, 'thumbnailUrl': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2019/11/GettyImages-869082432.jpg', 'datePublished': '2019-11-06T00:23:31+00:00', 'dateModified': '2019-11-06T01:32:48+00:00', 'description': 'Artificial intelligence has already started to shape our lives in ubiquitous and occasionally invisible ways. A researcher in algorithmic bias talks to FRONTLINE about what she thinks the public needs to know about these systems.', 'breadcrumb': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/#primaryimage', 'url': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2019/11/GettyImages-869082432.jpg', 'contentUrl': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2019/11/GettyImages-869082432.jpg', 'width': 1920, 'height': 1221, 'caption': 'A display shows a facial recognition system for law enforcement during the NVIDIA GPU Technology Conference in Washington, DC, Nov. 1, 2017.'}, {'@type': 'BreadcrumbList', '@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-algorithmic-bias-what-you-should-know/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.pbs.org/wgbh/frontline/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Articles', 'item': 'https://www.pbs.org/wgbh/frontline/articles/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Social Issues', 'item': 'https://www.pbs.org/wgbh/frontline/topic/social-issues/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Artificial Intelligence Can Be Biased. Here&#8217;s What You Should Know.'}]}, {'@type': 'WebSite', '@id': 'https://www.pbs.org/wgbh/frontline/#website', 'url': 'https://www.pbs.org/wgbh/frontline/', 'name': 'FRONTLINE', 'description': 'FRONTLINE', 'publisher': {'@id': 'https://www.pbs.org/wgbh/frontline/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.pbs.org/wgbh/frontline/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.pbs.org/wgbh/frontline/#organization', 'name': 'FRONTLINE | PBS', 'url': 'https://www.pbs.org/wgbh/frontline/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pbs.org/wgbh/frontline/#/schema/logo/image/', 'url': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2020/10/frontline_logo_opengraph.png', 'contentUrl': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2020/10/frontline_logo_opengraph.png', 'width': 1200, 'height': 630, 'caption': 'FRONTLINE | PBS'}, 'image': {'@id': 'https://www.pbs.org/wgbh/frontline/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/frontline', 'https://twitter.com/frontlinepbs', 'https://www.instagram.com/frontlinepbs/', 'https://www.youtube.com/user/pbsfrontline'], 'publishingPrinciples': 'https://www.pbs.org/wgbh/frontline/about-us/editorial-standards-and-ethics', 'noBylinePolicy': 'https://www.pbs.org/wgbh/frontline/about-us/editorial-standards-and-ethics/#verification-and-fact-checking-standards'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vaGJyLm9yZy8yMDE5LzExL2FzLWpvYnMtYXJlLWF1dG9tYXRlZC13aWxsLW1lbi1hbmQtd29tZW4tYmUtYWZmZWN0ZWQtZXF1YWxsedIBAA?oc=5,"As Jobs Are Automated, Will Men and Women Be Affected Equally? - HBR.org Daily",2019-11-01,HBR.org Daily,https://hbr.org,"What will work look like for the next generation of women, especially as more of their roles are being automated — or even replaced — by artificial intelligence (AI)? And how can leaders ensure that AI does not lead to gender bias in their organizations? Recent research is beginning to answer these questions, and the outlook is mixed: on the one hand, women may be spared from the job disruptions men will face in the longer-term. On the other, the lack of gender diversity in AI-related jobs could be reflected in the tools that are created, affecting whether women are hired or promoted. Employers should be thinking about this job re-distribution in advance, to help ensure that a wave of redundancies following technological change does not lead to a sudden worsening in organizational gender balance.",,"What will work look like for the next generation of women, especially as more of their roles are being automated — or even replaced — by artificial intelligence (AI)? And how can leaders ensure that AI does not lead to gender bias in their organizations? Recent research is beginning to answer these questions, and the outlook is mixed: on the one hand, women may be spared from the job disruptions men will face in the longer-term. On the other, the lack of gender diversity in AI-related jobs could be reflected in the tools that are created, affecting whether women are hired or promoted. Employers should be thinking about this job re-distribution in advance, to help ensure that a wave of redundancies following technological change does not lead to a sudden worsening in organizational gender balance.",,https://schema.org,WebSite,,,,,,,,,Gender,,,,,,,https://hbr.org/,"{'@type': 'SearchAction', 'target': 'https://hbr.org/search?term={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vY2FyZGlvdmFzY3VsYXJidXNpbmVzcy5jb20vdG9waWNzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2hvdy1haS13aWxsLWltcGFjdC1oZWFsdGhjYXJlLXdvcmtmb3JjZdIBAA?oc=5,How AI Will Impact the Healthcare Workforce - Cardiovascular Business,2019-11-04,Cardiovascular Business,https://cardiovascularbusiness.com,The American Hospital Association predicts how hospitals will operate when AI and machine learning are on board.,"Artificial Intelligence, Patient Care",The American Hospital Association predicts how hospitals will operate when AI and machine learning are on board.,The American Hospital Association predicts how hospitals will operate when AI and machine learning are on board.,https://schema.org,,,,,,,,,,,,"  How AI Will Impact the Healthcare WorkforceAmy Baxter | November 04, 2019 | Artificial Intelligencetweetprintsharesharemail   In the not-too-distant future, hospitals will operate very differently than they do today thanks to the artificial intelligence (AI) boom, according to a new Market Insights report by the American Hospital Association’s (AHA) Center for Health Innovation. For many members of the healthcare workforce, the most tangible changes will manifest in how their work is completed, with AI, machine learning and robotic process automation (RPA) all having an impact. The AHA cites research concluding that 40 percent of the tasks currently performed by non-clinical staff and 33 percent of clinicians’ jobs could be done by AI. In the future, some tasks will be outsourced to technology, and healthcare workers will see their roles change. Make way for automation … The AHA expects that RPA will have the biggest impact on most healthcare jobs because of its potential to add capacity, cut staffing costs and reduce human error by automating manual, repetitive and rules-based tasks. Such tasks will include billing, claims submission, patient enrollment, insurance verification, patient scheduling, inventory management and contract management.For many, RPA will be a welcome entrant into their workflow, freeing them to spend more time assisting and caring for patients or tackling other duties that technology can’t perform. For workers who specialize in tasks like these, however, RPA also could result in job loss and the need to shift to other work. … And a data influx Clinicians may find the benefits of AI extending beyond automating tasks and toward incorporating more data into their decision-making. Machine-learning models with clinical decision support capabilities already are being woven into healthcare workflows, with predictive tasks improving diagnoses and disease classification. “In the future, AI will make sense of the overwhelming amount of data created from genomics, biosensors, smartphone apps, the electronic health record, unstructured notes and data on social determinants of health, and create a broader context for clinicians to deliver high-quality, patient-centered care,” the AHA report reads.However, for machine learning to be useful to clinicians, the data will need to be accurate—a requirement that could result in healthcare workers taking on new tasks related to ensuring data integrity. They may need to learn new digital skills, such as digital and AI acumen, data appreciation and agility.“With AI as their new co-worker, staff will need to acquire new skill sets and competencies to take advantage of AI capabilities, and the educational pipeline needs to equip those entering the health care workforce with new skills,” the AHA says.As new jobs emerge … One result of having these new technologies in the healthcare workplace will be the premium placed on positions that facilitate the technology. Among them: data scientists, AI engineers, data governance experts, data entry experts, data engineers and chief AI officers.… Patient-centric priorities will endureTo its hospital and health system constituents who are considering how to prepare for such changes, the AHA urges a continued prioritization of people skills and the patient relationship. Those aspects of healthcare aren’t likely to change, the organization predicts.“The workforce of the future not only will need people with technical skills, but also soft skills like communication and empathy to take full advantage of what AI gives them to do their jobs,” the AHA says. More...  November/December 2019   Cardiology’s Challenge for the 2020s: Turning the Trend on Rising Mortality   The Art of Storytelling: Innovation, Advocacy & the War on ‘Fake News’ in Medicine    Destination Question: Should All STEMI Patients Recover in the ICU?    Spread Too Thin? Strategies for Deploying Cardiology Teams Across Sites of Service    How AI Will Impact the Healthcare Workforce   Look Before You Leap & Other Advice for Cardiologists Considering Telemedicine   Employers Clamp Down on Rising Healthcare Benefit Costs   Making a Statement: ACC Takes a Stand on Workplace Equity   Performance Report: Critical Characteristics of High-performing Cardiology Programs—Start at the Top   Storytelling Is AdvocacyAmy BaxterAmy joined TriMed Media as a Senior Writer for HealthExec after covering home care for three years. When not writing about all things healthcare, she fulfills her lifelong dream of becoming a pirate by sailing in regattas and enjoying rum. Fun fact: she sailed 333 miles across Lake Michigan in the Chicago Yacht Club ""Race to Mackinac.""Related ContentAI creates accurate 4D heart scans in secondsFemale cardiologists much more likely to receive negative reviewsRemote monitoring, AI to play key roles in the future of cardiologyFDA clears new AI algorithm for 1-year AFib riskDual approvals: AliveCor gains FDA clearance for advanced AI model, handheld ECG systemAI-powered platform for arrhythmia detection gains FDA approvalAround the webHealth Imaging New imaging protocols proposed to curb rise of cardiovascular infectionsEleven medical societies have signed on to a consensus statement aimed at standardizing imaging for suspected cardiovascular infections.Radiology Business What does radiology have to do with climate change?Kate Hanneman, MD, explains why many vendors and hospitals want to lower radiology's impact on the environment. ""Taking steps to reduce the carbon footprint in healthcare isn’t just an opportunity,"" she said. ""It’s also a responsibility.""Radiology Business Philips launches new AI-enabled CT scanner aimed at cardiology at ECR 2024Philips introduced a new CT system at ECR aimed at the rapidly growing cardiac CT market, incorporating numerous AI features to optimize workflow and image quality.",,,,"[{'@type': 'NewsArticle', 'headline': 'How AI Will Impact the Healthcare Workforce', 'name': 'How AI Will Impact the Healthcare Workforce', 'image': {'@type': 'ImageObject', 'url': 'https://cardiovascularbusiness.com/sites/default/files/styles/facebook/public/2019-11/ai_ci.jpg?h=75e7b748&itok=Axkz0w62', 'width': '1200', 'height': '630'}, 'datePublished': '2019-11-04T17:46:34+0000', 'dateModified': '2022-02-07T19:24:20+0000', 'publisher': {'@type': 'Organization', 'name': 'Cardiovascular Business', 'url': 'https://cardiovascularbusiness.com/'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vYnVpbHRpbi5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvZGVzaWduaW5nLWFpLXdpdGgtaHVtYW4tdG91Y2jSAQA?oc=5,How Humility Helps AI Work Better With Human Users - Built In,2019-11-05,Built In,https://builtin.com,Making AI smarter is just the first step. Getting users to like it can be just as important.,,Making AI smarter is just the first step. Getting users to like it can be just as important.,Making AI smarter is just the first step. Getting users to like it can be just as important.,https://schema.org,,,,,,,,,,,,"
























In the 1950s, Alan Turing proposed a contest that would become the gold standard for measuring AI sophistication: the Turing Test, wherein a machine attempts to trick people into thinking it’s human. 
But as AI’s ability to interact with humans has progressed, so, too, have companies’ understanding of what it should feel like to talk to a robot. 

“Even if you can make AI feel human, you don’t necessarily want to.” 

“Even if you can make AI feel human, you don’t necessarily want to,” said David Vandegrift, who is a former investor turned co-founder and CTO of an AI startup. “Because people will feel betrayed if they find that they’ve been talking to something that felt human, but wasn’t actually.”
Vandegrift’s Chicago startup, 4Degrees, leverages artificial intelligence to help individuals identify their most important professional relationships. Their challenge lies in designing an AI system that nudges professionals to network with the right people, without being annoying or creepy about it. It’s a practice that has long proved resistant to disruption by tech, because it requires a human touch. 
Networking brings up feelings of anxiety for many, Vandegrift said, which can stop someone from reaching out to their old boss to catch up over lunch, for example. It’s hard to use technology to convince someone to do something they feel fundamentally uncomfortable about. It’s also tough when a machine reveals you know fewer people than you thought you did. And who wants AI telling them their connections are shallow? 
Even building a system for predicting who would be a good professional match presents a complication. Because the outcome of an AI system is dependent on the information it’s trained on, ensuring a system presents a nuanced perspective — and not just, say, a venture capitalist’s thoughts on who’s important to know — can be tricky. 
“For the most part, people today are still building relationships the same way they were 10, or 100, or even 1,000 years ago,” Vandegrift said. “It’s a problem that people have been trying to solve for quite awhile. But it’s a problem that’s proven very resilient, in terms of like, nobody's solved it.” 
In taking on the challenge, Vandegrift and his team learned some hard-earned lessons about what humans really want from AI. 
Even if you could build an AI that seems human, you may not want to. Many people respond poorly to being tricked by computers.
	 
Think carefully about the “voice” and tone of your application. Don’t make your users feel like they're being bossed around. 
	 
Your AI will inevitably get things wrong. Interactions that emphasize humility will make the user more likely to forgive you. 
	 
Building nuanced AI requires nuanced training data. Your models won’t incorporate perspectives they’ve never been exposed to.
Image via 4degreesNuanced AI needs nuanced training data
4Degrees derives most of its insights from email and calendar data. It currently focuses on metadata, like whom you email, how often they reply and how long it takes them to do so. It also leverages a set of approximately 250 tags to comb data from users’ Twitter, LinkedIn and other sources to find the most accurate way to categorize them by profession, industry, interests and skills. 
“Based on essentially the words that they’re using, we can infer [whether they are VCs or healthtech entrepreneurs]’ — things like that,” Vandegrift said.
Vandegrift — who recently published the book The Future of Business, about AI and its practical implications — said the main challenge in building an AI system is being thoughtful about the underlying data the system is trained on. Using training data that is reflective of a variety of perspectives is essential in ensuring that an AI model makes the best suggestions for everyone. 

“What data are you actually feeding into the model? Who are the people you asked, ‘Is this someone worth knowing or not?’” 

“What data are you actually feeding into the model? Who are the people you asked, ‘Is this someone worth knowing or not?’” Vandegrift asked. “Because that’s all going to show up in the outcomes of the model.”
4Degrees has steered clear of ranking an individual’s connections because that can introduce bias into the AI system. For example, CEOs of Fortune 500 companies are important people for any venture capitalist or investor to know, Vandegrift said. But the vast majority of company heads are also white men. Training the AI system to prioritize those relationships would inadvertently cause the system to discriminate against women and people of color.   
“We’re being proactive in what we’re not developing,” Vandegrift said.  
 
4Degrees cofounders David vandegrift (left) and Ablorde Ashigbi (right) Good UX isn’t always about making things easier
4Degrees aims to change what it means to network. In the process, it has altered users’ understanding of their own connections. 
Most people think they have “hundreds or thousands” of connections in their industry, Vandegrift said. But after two years on the market, he’s convinced their reality really lies in Dunbar’s number, a theory that states there is a cognitive limit to the number of stable social relationships an individual can hold. Most people have about 100 strong connections, he said. After that, the quality of an individual’s relationships starts to falter. 
Vandegrift said most of 4Degrees users were surprised — or insulted — when the platform first revealed how few connections they actually had.
When people inflate the size of their networks, they tend to spend less time than they need to on growing their professional base. And because networking isn’t a task that requires immediate attention, it’s easy to prioritize other items instead. But, Vandegrift cautions people against cutting corners. For example: 4Degrees receives a lot of requests from users to build features that simply write and send emails for them — say, congratulating a CEO friend for receiving an award, or an old coworker for starting a new job. 
It sounds good in theory, but Vandegrift is reluctant to try it.

“We believe that the relationship component should come from you and it should be thoughtful.” 

“We believe that the relationship component should come from you and it should be thoughtful,” he said. 
 
People don’t like being bossed around by AI
Google CEO Sundar Pichai presents Duplex at Google's annual I/O conference in 2018. (Image via Google)  In 2018, Google unveiled its Duplex assistant at its annual developer conference. In front of a crowd numbered in the thousands, the machine called a hair salon and showcased conversational skills so strong that the receptionist on the other line had no idea they were talking with a robot. Attendees of Google’s I/O conference were shocked by Duplex’s technological advances — and a little creeped out. 
The machine passed the Turing Test, but was that a good thing? Google eventually committed to notifying all end users of Duplex that they were engaging with a robot.
In Vandegrift’s mind, an AI system should accomplish its task and leave people feeling comfortable after their interaction. For 4Degrees, comfort comes in the form of how it structures its suggestions and illustrates its emails. 
When the company first launched, Vandegrift said 4Degrees’ system was designed so that, if a user failed to contact their connection during the suggested amount of time, 4Degrees would issue them a warning message, calling them out for missing a deadline the robot imposed. 
Vandegrift said 4Degrees eventually removed the feature because it made people feel bad for missing a deadline they hadn’t really agreed to. Instead of admonishing users for missing an opportunity to connect, now when the time comes for an individual to reach out, 4Degrees suggests additional opportunities for users to call up their professional connections, subtly nudging them to invite their old boss to coffee. 
“We’re prioritizing updates about those people now, rather than saying, ‘It’s so bad that you haven’t reached out,’” Vandegrift said.  
 
Humility will make your AI easier to forgive
In its suggestions about when to connect, 4Degrees also structures its findings as suggestions, rather than declarative statements. If the system notices a flight booked to San Francisco, for example, it will ask about the upcoming trip, rather than go straight to making suggestions. By structuring its ask with humility, Vandegrift said it helps users forgive the system when it inevitably gets things wrong — AI operates on educated guesses, after all.
To Vandegrift, the key to building an AI systems’ user experience is to highlight the fact that it’s not human. In the emails 4Degrees sends to users with opportunities to reach out, for example, the firm features an illustrated cartoon robot.
Vandegrift named the Seattle-based Textio as an example of an AI company that is thoughtful about its user experience. Textio analyzes company job postings and helps firms make them better by focusing on its own research, which, for example, found that postings with the word “rockstar” in them attract half as many women candidates as career advertisements that do not. 
After running its AI through a company’s job posting, Textio then presented its suggestions to the client with an explanation of why they chose to eliminate certain words, as well as add others. The customer determines for themselves how they want to use the AI’s recommendations. By explaining the research that backs the AI system, Vandegrift said Textio drives human trust in the machine. 

""You actually need to approach the design of AI systems fundamentally differently than traditional systems."" 

“You actually need to approach the design of AI systems fundamentally differently than traditional systems,” Vandegrift said. “You have to bring humility to that suggestion versus the confidence of like, ‘No, I know that.’ It’s actually a skill set that you should look for in your product manager, your designer and your engineers.” 
Want to read more about AI?Check out our guide to artificial intelligence.



",,,,"[{'@context': 'https://schema.org', '@type': 'Article', 'headline': 'How Humility Helps AI Work Better With Human Users', 'name': 'How Humility Helps AI Work Better With Human Users', 'description': 'In the 1950s, Alan Turing proposed a contest that would\xa0become the gold standard for measuring AI sophistication: the Turing Test, wherein a machine attempts to trick people into thinking it’s human.\xa0&#13;', 'image': {'@type': 'ImageObject', 'url': 'https://builtin.com/sites/www.builtin.com/files/artificial%2520intelligence%2520networking.jpg', 'representativeOfPage': True}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://builtin.com/artificial-intelligence/designing-ai-with-human-touch', 'name': 'How Humility Helps AI Work Better With Human Users'}, 'url': 'https://builtin.com/artificial-intelligence/designing-ai-with-human-touch', 'about': {'@type': 'Thing', 'name': 'Artificial Intelligence'}, 'author': {'@type': 'Person', '@id': 'https://builtin.com/authors/nona-tepper', 'name': 'Nona Tepper', 'description': 'Nona Tepper is a former Built In staff reporter covering technology industry trends. She holds a masters of journalism from Northwestern University and a bachelor of arts in journalism and english from Indiana University Bloomington. Prior to joining Built In, Tepper was a reporter and editor for Forest Park Review and Wednesday Journal, and her work has appeared in The Washington Post, Crain’s Chicago Business, Slate, VICE and MarketWatch. She is currently a staff reporter at Modern Healthcare.\r\n', 'jobTitle': 'Staff Reporter', 'sameAs': 'https://www.linkedin.com/in/nona-tepper-71534346/', 'url': 'https://builtin.com/authors/nona-tepper'}, 'datePublished': '2019-11-05T16:49:54+00:00', 'publisher': {'@type': 'Organization', '@id': 'https://builtin.com', 'name': 'Built In', 'url': 'https://builtin.com', 'sameAs': ['https://www.facebook.com/BuiltInHQ/', 'https://twitter.com/builtin', 'https://www.instagram.com/builtin/', 'https://www.linkedin.com/company/built-in'], 'brand': {'@type': 'Brand', 'name': 'Built In'}, 'logo': {'@type': 'ImageObject', 'url': 'https://static.builtin.com/dist/images/built-logo.png', 'representativeOfPage': True}}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiO2h0dHBzOi8vd3d3LmNhdGFseXN0Lm9yZy9yZXNlYXJjaC93b21lbi1mdXR1cmUtd29yay1yZXBvcnQv0gEA?oc=5,Women and the Future of Work (Report) - Catalyst,2019-11-05,Catalyst,https://www.catalyst.org,"Catalyst explores the future of work with a gender, diversity, and inclusion lens.",,Catalyst's new report on the future of work and women examines how to reimagine diversity and inclusion for the 21st century.,"Catalyst explores the future of work with a gender, diversity, and inclusion lens.",https://schema.org,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.catalyst.org/research/women-future-work-report/', 'url': 'https://www.catalyst.org/research/women-future-work-report/', 'name': 'Women and the Future of Work (Report) | Catalyst', 'isPartOf': {'@id': 'https://www.catalyst.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.catalyst.org/research/women-future-work-report/#primaryimage'}, 'image': {'@id': 'https://www.catalyst.org/research/women-future-work-report/#primaryimage'}, 'thumbnailUrl': 'https://www.catalyst.org/wp-content/uploads/2019/11/woman-futuristic-office.png', 'datePublished': '2019-11-05T12:34:36+00:00', 'dateModified': '2023-08-21T22:05:22+00:00', 'description': 'Catalyst explores the future of work with a gender, diversity, and inclusion lens.', 'breadcrumb': {'@id': 'https://www.catalyst.org/research/women-future-work-report/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.catalyst.org/research/women-future-work-report/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.catalyst.org/research/women-future-work-report/#primaryimage', 'url': 'https://www.catalyst.org/wp-content/uploads/2019/11/woman-futuristic-office.png', 'contentUrl': 'https://www.catalyst.org/wp-content/uploads/2019/11/woman-futuristic-office.png', 'width': 1200, 'height': 800, 'caption': 'women in futuristic office space'}, {'@type': 'BreadcrumbList', '@id': 'https://www.catalyst.org/research/women-future-work-report/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.catalyst.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Research Elements', 'item': 'https://www.catalyst.org/research/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Women and the Future of Work (Report)'}]}, {'@type': 'WebSite', '@id': 'https://www.catalyst.org/#website', 'url': 'https://www.catalyst.org/', 'name': 'Catalyst', 'description': 'Catalyst, a global nonprofit organization, helps build workplaces that work for women with preeminent thought leadership and actionable solutions.', 'publisher': {'@id': 'https://www.catalyst.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.catalyst.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.catalyst.org/#organization', 'name': 'Catalyst', 'url': 'https://www.catalyst.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.catalyst.org/#/schema/logo/image/', 'url': 'https://www.catalyst.org/wp-content/uploads/2019/03/Catalyst-Logo-1200x630.png', 'contentUrl': 'https://www.catalyst.org/wp-content/uploads/2019/03/Catalyst-Logo-1200x630.png', 'width': 1200, 'height': 630, 'caption': 'Catalyst'}, 'image': {'@id': 'https://www.catalyst.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/catalystinc/', 'https://x.com/CatalystInc', 'https://www.instagram.com/catalystinc/', 'https://www.linkedin.com/company/catalystinc/', 'https://www.youtube.com/user/CatalystClips', 'https://en.wikipedia.org/wiki/Catalyst_(nonprofit_organization)']}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LmM0aXNybmV0LmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS8yMDE5LzExLzA0LzUtY29uY2VybnMtdGhlLXVzLW11c3QtdGFja2xlLXRvLWNvbXBldGUtaW4tYWkv0gEA?oc=5,5 concerns the US must tackle to compete in AI - C4ISRNET,2019-11-04,C4ISRNET,https://www.c4isrnet.com,The National Security Commission on Artificial Intelligence hopes to roll its recommendations into congressional budgets as time goes on.,"['artificial-intelligence', 'eric-schmidt', 'National-Security-Commission-on-Artificial-Intelligence', 'eric-schmidt', 'bob-work', 'ai-commission', 'artificial-intelligence', 'stop-killer-robots', 'ai-warfare', 'artificial-intelligence-war', 'killer-robots', 'trump-robots', 'pentagon-ai', 'defense-AI', 'five-eyes', 'circulated-c4isrnet', 'circulated-undefined', 'circulated-defense-news', 'circulated-federal-times']",The National Security Commission on Artificial Intelligence hopes to roll its recommendations into congressional budgets as time goes on.,,http://schema.org,NewsArticle,"{'type': 'WebPage', '@id': 'https://www.c4isrnet.com/artificial-intelligence/2019/11/04/5-concerns-the-us-must-tackle-to-compete-in-ai/'}",5 concerns the US must tackle to compete in AI,"{'url': 'https://www.c4isrnet.com/resizer/iJlRTQZy6DeUA6SMpQFuZABbbVY=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/C5ZAKRQUJFBRVMC745AIBMCF3A.jpg', '@type': 'ImageObject'}","[{'@type': 'Person', 'name': 'Aaron Mehta'}]",2019-11-04T20:08:15.483Z,2022-08-19T15:10:17.951Z,"{'@type': 'Organization', 'name': 'C4ISRNet', 'url': 'https://www.c4isrnet.com/', 'logo': {'@type': 'ImageObject', 'url': '/resources/img/c4isrnet-logo-white.png?d=124'}}",,Artificial Intelligence,,"A group of technology experts chartered by Congress to guide American efforts in artificial intelligence have released their initial report on how to ensure AI development stays on track inside the United States. And, overall, there’s a lot of work to do.Created by the National Defense Authorization Act in 2018, the National Security Commission on Artificial Intelligence is explicitly tasked with reviewing “advances in artificial intelligence, related machine learning developments, and associated technologies,” for the express purpose of addressing “the national and economic security needs of the United States, including economic risk, and any other associated issues.”The Commission — led by Eric Schmidt, the former head of Google parent Alphabet, and Bob Work, the former deputy secretary of defense — released its interim findings Nov. 4, focusing on five key areas of concern.While warning of the need to go fast, the Commission will not deliver its full conclusions until March 2021, which could mean that the recommendations from the group will not appear until the fiscal year 2023 budget. However, Work told reporters Monday morning that there is a plan to slowly roll in recommendations as they are finalized.“As recommendations become locked in as a consensus of the group, and we’re ready to do it, we will be giving those directly to Congress, since they’re our primary customer, and they can use them as we see fit,” Work said, particularly calling out Rep. Elise Stefanek, R-NY., whose legislative push helped created the Commission, as someone who has asked for rolling updates.In the meantime, the interim report shows the Commission has narrowed its focus onto the following five key areas:Invest in AI research and development: “Despite the transformative potential of AI, the U.S. government has not yet responded with the resources necessary to meet current research needs and set conditions for future innovation,” the Commission writes, warning that “over the past five years, federal R&D funding for computer science (which houses AI) increased by 12.7 percent, barely sustaining a field in which tenure track positions grew by 118 percent over the same period.”Put simply, the U.S. government needs to increase its funding for AI research and development if it wants to be able to compete with China. “The country benefits from broad scale investments in science, in particular in the competition we expect from other global leaders,” said Schmidt. “That investment is key.”It’s not just money, either, but the ever-present threat of government bureaucracy.“We have found that red tape in the DoD-owned lab network slows its ability to innovate,” the report reads. ""Layers of management and long approval processes lead researchers to choose older hardware and software for their work, because these can be obtained more quickly than the best products available. Such issues are creating risks that DoD labs will fall behind the curve of current AI research and development.”Apply AI to national security missions. Getting technology from paper to the battlefield is always a challenge for the Pentagon, and once again the Commission flags the DoD’s bureaucratic nature as a potential hurdle. To make AI systems valuable in the battlefield, it will take serious “top-down leadership,” the report reads.One question that the Commission has yet to tackle is the role of lethal autonomous systems, a hot-button topic. As part of their study, the Commission plans to invite groups like the Ban Killer Robots campaign to have a discussion about those concerns.Train and recruit AI talent. One theme the Commission expects to tackle going forward is the question of how to recruit top technological talent to the Pentagon — certainly not a new problem, but one that takes on extra urgency given the expected importance of AI in the near-future.That’s not just STEM talent, however. Both men said that part of that talent base needs to include ethicists looking at questions of AI in order to ensure that American artificial intelligence systems come from a base of American values.Protect and build upon U.S. technology advantages. China, while extremely capable in the AI realm, is still a follower, according to Schmidt. But they are a “fast follower,” one who is able to quickly pick up on American innovations and incorporate them for its own needs.Hence, export control mechanisms will remain important in the future, the Commission found; however, changes will be needed, as “item-based export controls and narrowly scoped foreign investment reviews are by themselves insufficient to sustain U.S. competitiveness in AI.”Both men acknowledged there is a camp in Washington that wants to “decouple” from China entirely and try to set strict firewalls that would keep Chinese researches away from American AI R&D efforts. Work said the Commission will attempt to “thread the needle” on that issue, acknowledging those concerns while not pushing to lock Chinese researchers out.Schmidt went further, stating flatly that “We are dependent on Chinese researchers and Chinese graduate students"" and adding that “a decoupling at the human level would hurt the United States … If you take those people out of our research chain, it will hurt the United States. Because they are strong, helpful, many of them stay within the country if they can get visas.”Work added that the United States has “been the magnet for global innovation talent for the last 70 years,” and that AI competition means the United States has to maintain that edge.Marshal global AI cooperation. The report highlights the importance of working with allies and partner nations on developing AI technologies. The United States must “establish a network of like-minded nations dedicated to collectively building AI expertise and capabilities,” the authors write. “The government should organize itself as soon as possible to conduct a sustained, long-term diplomatic campaign to support America’s AI agenda.”The panel suggests starting to work through the Five Eyes intelligence-sharing nations, as that network is likely the easiest to share key classified technologies through. While NATO may represent another path forward in the future, the Commission feels that is more difficult given the wide range of budgets, budget planning procedures and domestic requirements.The report also calls for the United States and its partners to “lower the barriers to the movement of people and data among nations” in order to benefit from the best brains around the world — an opinion that appears unaligned with many of the Trump administration’s immigration stances, but one Schmidt has relayed in the past.Overall, both men acknowledged that the interim report doesn’t contain any shocking findings that have not been already flagged as concerns elsewhere in the government — something they said is a good sign, as it shows broad consensus around how to attack the AI problem.Still, Work stressed that the Commission’s decision to come at the problem with a whole-of-America focus, as opposed to just national or economic security, means the final report will prove valuable recommendations across the board.“One thing this report may do is it makes very, very clear what the stakes of the competition are,” Work said. “This is a competition between authoritarian regimes and democratic governments, and technologies reflect the values of the governments that implement them.”About  Aaron MehtaAaron Mehta was deputy editor and senior Pentagon correspondent for Defense News, covering policy, strategy and acquisition at the highest levels of the Defense Department and its international partners.Share:More In Artificial IntelligenceSouth Korea to deploy laser weapons to intercept North Korean dronesThe Defense Acquisition Program Administration said it will deploy at least one anti-air laser weapons system — called “Block-I” — this year.US to send Tomahawks, hypersonics, other long-range fires to GermanyThe move is in-line with the Army's plan to provide such capability to its Multidomain Task Force there.Beavers takes reins from Sherman as acting DOD information officerAs the most senior IT advisor to the secretary of defense, Beavers is taking over from former CIO John Sherman.Quieting Discord: A new frontier in military leaks and extremismFrom secret Pentagon leaks to radicalization in the military community, Discord is continuing to grapple with keeping bad actors off the popular platform.Astronauts say Boeing space capsule can safely return them to EarthNASA test pilots Butch Wilmore and Suni Williams launched aboard Starliner capsule early last month.",C4ISRNet,,Artificial Intelligence,,https://www.c4isrnet.com/artificial-intelligence/2019/11/04/5-concerns-the-us-must-tackle-to-compete-in-ai/,,/resources/img/c4isrnet-logo-white.png,"['https://www.facebook.com/https://www.facebook.com/C4ISRNet', 'https://twitter.com/c4isrnet']",https://www.c4isrnet.com/#publisher,https://www.c4isrnet.com/artificial-intelligence/2019/11/04/5-concerns-the-us-must-tackle-to-compete-in-ai/,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vcmVzdGF1cmFudGJ1c2luZXNzb25saW5lLmNvbS9maW5hbmNpbmcvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdGFrZXMtaG9sZC11cy1yZXN0YXVyYW50c9IBAA?oc=5,Artificial intelligence takes hold at U.S. restaurants - Restaurant Business Online,2019-11-01,Restaurant Business Online,https://restaurantbusinessonline.com,Working Lunch: The podcast from Align Public Strategies also delves into an idea to eliminate taxes on tips as well as developments in Ohio and Massachusetts. ,"News, Quick_Service, technology","Machines are doing a lot more work at chains such as McDonald’s, Starbucks and Taco Bell, and there’s evidence it’s working.","Machines are doing a lot more work at chains such as McDonald’s, Starbucks and Taco Bell, and there’s evidence it’s working.",http://schema.org,Article,"{'@type': 'WebPage', '@id': 'https://restaurantbusinessonline.com/operations/how-will-supreme-courts-chevron-ruling-affect-restaurants'}",How will the Supreme Court’s Chevron ruling affect restaurants?,"{'@type': 'ImageObject', 'url': 'https://cdn.winsightmedia.com/platform/files/public/2024-07/background/Align%20Small%20Square%20%281%29.jpg?VersionId=WTlmywoEdcgpz0hidKsyhGXnKUeO3pTT'}","[{'@type': 'Person', 'name': 'Restaurant Business Staff', 'url': '/profile/restaurant-business-staff'}]",2024-07-15T18:06:20+00:00,2024-07-15T18:56:26+00:00,"{'@type': 'Organization', 'name': 'Restaurant Business', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.winsightmedia.com/platform/files/rb/images/logo-rb-json-ld.png', 'width': 600, 'height': 60}}",,Quick Service,,"FacebookTwitterLinkedInPhotograph courtesy of McDonald's Corp.Machines are doing a lot more work inside U.S. fast-food restaurants.At Starbucks, artificial intelligence helps with labor scheduling. Taco Bell is using AI in its in-store kiosks to suggest certain items, the same thing McDonald’s is doing at its drive-thru menu boards. The Chicago-based giant then doubled down on the idea by acquiring an artificial intelligence company called Apprente. Machines are taking voice orders at 40 Domino’s Pizza locations.To be sure, artificial intelligence has a growing role inside many industries, particularly as internet-enabled businesses have taken hold. But it takes on a different meaning in a restaurant industry that employs a lot of people who frequently interact directly with consumers.The chains’ investments promise to change how customers interact with restaurants not only over the phone but also inside the locations themselves. And there’s evidence it’s already having an impact on what customers order. Starbucks has been working with an artificial intelligence effort over the past year that it calls “Deep Brew.” That system powers the company’s personalization engine and helps manage inventory. But it also optimizes labor.That system has helped reduce the number of administrative tasks inside restaurants, which has freed employees to interact with customers. That’s been driving sales: Same-store sales at the Seattle-based coffee giant rose 6% last quarter thanks to a mix of traffic and higher average check.“We continue to see a strong correlation between Starbucks partner engagement and customer connection, which leads to increased consumer frequency,” CEO Kevin Johnson said on the company’s earnings call this week. “We are making targeted investments to elevate the partner experience with clear evidence that this in turn elevates the customer experience and drives growth.”The industry is making these investments at a time of intense competition. Traffic for many chains is difficult to come by, and companies are investing in more technology to give themselves an advantage.At the same time, the efforts are coming as restaurants face more labor pressure than at any time in recent history. Chains believe the technology can not only help sales but also can ease some of the labor challenges inside their restaurants.Many of these efforts are customer-facing. Earlier this year, McDonald’s acquired Dynamic Yield, a company that gives Amazon-like abilities to its digital drive-thru menu boards. The boards display items based on the time of day, the weather and how busy the store is. Operators say the technology is already paying dividends in the form of higher average check.As if to double down on this idea, the company turned around and bought an artificial intelligence company called Apprente that will ultimately use voice technology to take orders in the chain’s drive-thrus.“We see voice technology playing an increasing role in all of our lives,” McDonald’s CEO Steve Easterbrook said on the company’s earnings call. “At McDonald’s, this is particularly significant because of the importance of drive-thrus to our portfolio.”McDonald’s isn’t the only one. Taco Bell has kiosks in 6,100 locations. Those kiosks feature AI-driven product recommendations, David Gibbs, chief operating officer for Taco Bell parent company Yum Brands, said this week.Sister company KFC, meanwhile, is planning to test artificial intelligence to take orders in its drive-thrus. “What I’m focused on from a tech perspective is to continue to drive sales by making our brand easier,” said Christopher Caldwell, chief information officer for KFC U.S., in an interview with Restaurant Business. It’s not just big chains, either. Breakfast and lunch chain Snooze, an A.M. Eatery and burger chain Good Times are both testing AI-powered software to take orders. The program has already demonstrated an ability to get consumers to add more items to their orders.AI-enabled ordering is also coming to an unexpected area: phone calls.Wingstop and Domino’s are both working to add voice ordering capabilities to their phone orders. For those companies, the strategy is practical: Despite the rapid growth in online ordering for items such as pizza and chicken wings, a percentage of the consumer still prefers to simply call the restaurant.Digitizing those orders frees up workers to make pizzas and chicken wings. Domino’s voice-ordering test is in 40 restaurants, and the Ann Arbor, Mich.-based pizza chain is eager to get it into more locations.Those efforts take time, however, because voice ordering technology needs to learn how to interact with humans. “It’s complex to do,” Domino’s Chief Technology Officer Kelly Garcia said. “I’d argue that our bot is way ahead of other technology.”Members help make our journalism possible. Become a Restaurant Business member today and unlock exclusive benefits, including unlimited access to all of our content. Sign up here.News 
															Quick_Service 
															technology 
													
						Restaurant Business Editor-in-Chief Jonathan Maze is a longtime industry journalist who writes about restaurant finance, mergers and acquisitions and the economy, with a particular focus on quick-service restaurants.
					View All Articles by This Author",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3Lm1pY3Jvc29mdC5jb20vZW4tdXMvbWljcm9zb2Z0LTM2NS9ibG9nLzIwMTkvMTEvMDQvYWktY29ydGFuYS1taWNyb3NvZnQtMzY1LXBlb3BsZS1hdC10aGUtY2VudGVyL9IBAA?oc=5,AI and Cortana in Microsoft 365 put people at the center - Microsoft,2019-11-04,Microsoft,https://www.microsoft.com,"At Ignite 2019, Microsoft announced AI and Cortana features in Microsoft 365 that empower people to be more productive on the go.",,"At Ignite 2019, Microsoft announced AI and Cortana features in Microsoft 365 that empower people to be more productive on the go.","The new AI and Cortana features in Microsoft 365 put people at the center with Play my Emails, Scheduler and more.",http://schema.org,WebPage,,,,,,,,,,,"


 




					
						January 27, 2022					
				

						5 min read read					



From empowering frontline workers to accessibility improvements—here’s what’s new in Microsoft 365 




",,,,"[{'@type': 'Article', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/#article', 'isPartOf': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/'}, 'author': [{'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#/schema/person/image/c6068ba13fb8f8212a60f0e054e752ce'}], 'headline': 'AI and Cortana in Microsoft 365 put people at the center', 'datePublished': '2019-11-04T14:00:32+00:00', 'dateModified': '2022-06-28T19:14:18+00:00', 'mainEntityOfPage': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/'}, 'wordCount': 1432, 'publisher': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#organization'}, 'image': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/#primaryimage'}, 'thumbnailUrl': 'https://www.microsoft.com/en-us/microsoft-365/blog/wp-content/uploads/sites/2/2019/11/AI-and-Cortana-in-Microsoft-365-card.jpg', 'keywords': ['Mac'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/', 'url': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/', 'name': 'AI and Cortana in Microsoft 365 put people at the center | Microsoft 365 Blog', 'isPartOf': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#website'}, 'primaryImageOfPage': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/#primaryimage'}, 'image': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/#primaryimage'}, 'thumbnailUrl': 'https://www.microsoft.com/en-us/microsoft-365/blog/wp-content/uploads/sites/2/2019/11/AI-and-Cortana-in-Microsoft-365-card.jpg', 'datePublished': '2019-11-04T14:00:32+00:00', 'dateModified': '2022-06-28T19:14:18+00:00', 'description': 'At Ignite 2019, Microsoft announced AI and Cortana features in Microsoft 365 that empower people to be more productive on the go.', 'breadcrumb': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/#primaryimage', 'url': 'https://www.microsoft.com/en-us/microsoft-365/blog/wp-content/uploads/sites/2/2019/11/AI-and-Cortana-in-Microsoft-365-card.jpg', 'contentUrl': 'https://www.microsoft.com/en-us/microsoft-365/blog/wp-content/uploads/sites/2/2019/11/AI-and-Cortana-in-Microsoft-365-card.jpg', 'width': 440, 'height': 268}, {'@type': 'BreadcrumbList', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/2019/11/04/ai-cortana-microsoft-365-people-at-the-center/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.microsoft.com/en-us/microsoft-365/blog/'}, {'@type': 'ListItem', 'position': 2, 'name': 'AI and Cortana in Microsoft 365 put people at the center'}]}, {'@type': 'WebSite', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#website', 'url': 'https://www.microsoft.com/en-us/microsoft-365/blog/', 'name': 'Microsoft 365 Blog', 'description': 'Microsoft 365 brings together Office 365, Windows 10, and Enterprise Mobility + Security. It delivers a complete, intelligent, and secure solution to empower people.', 'publisher': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.microsoft.com/en-us/microsoft-365/blog/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#organization', 'name': 'Microsoft 365 Blog', 'url': 'https://www.microsoft.com/en-us/microsoft-365/blog/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#/schema/logo/image/', 'url': 'https://www.microsoft.com/en-us/microsoft-365/blog/wp-content/uploads/sites/2/2019/08/ms-logo-amp.png', 'contentUrl': 'https://www.microsoft.com/en-us/microsoft-365/blog/wp-content/uploads/sites/2/2019/08/ms-logo-amp.png', 'width': 279, 'height': 60, 'caption': 'Microsoft 365 Blog'}, 'image': {'@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#/schema/person/image/c6068ba13fb8f8212a60f0e054e752ce', 'name': 'Andrew Shuman', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.microsoft.com/en-us/microsoft-365/blog/#/schema/person/image/b1c83d0c765c4833531958fcbb993bd7', 'url': 'https://www.microsoft.com/en-us/microsoft-365/blog/wp-content/uploads/sites/2/2022/06/logo_whitespace-62bcba38c32e9-150x150.webp', 'contentUrl': 'https://www.microsoft.com/en-us/microsoft-365/blog/wp-content/uploads/sites/2/2022/06/logo_whitespace-62bcba38c32e9-150x150.webp', 'width': 150, 'height': 150, 'caption': 'Andrew Shuman'}, 'description': 'Corporate Vice President, Experience and Devices', 'url': 'https://www.microsoft.com/en-us/microsoft-365/blog/author/andrew-shuman/'}]",,,,,,,"[{'@type': 'VideoObject', 'contentUrl': 'https://www.microsoft.com/en-us/videoplayer/embed/RE46Eiu\r', 'description': 'AI in Microsoft 365 is driving a significant shift in how people interact with Microsoft 365 applications.', 'name': 'Play My Emails', 'uploadDate': '2019-11-04T23:04:39', 'thumbnailUrl': ['http://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE46Eiv?ver=8632', 'http://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE46Eiv?ver=8632', 'http://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE46Eiv?ver=8632', 'http://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE46Eiv?ver=8632']}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LnNpbGljb24uY28udWsvZS1pbm5vdmF0aW9uL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3JvYm90cy1oaXQtbG93LXBhaWQtaGFyZGVzdC0yMjY1MTPSAWVodHRwczovL3d3dy5zaWxpY29uLmNvLnVrL2UtaW5ub3ZhdGlvbi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9yb2JvdHMtaGl0LWxvdy1wYWlkLWhhcmRlc3QtMjI2NTEzL2FtcA?oc=5,Workplace Robots To Hit Low Paid The Hardest - Silicon UK,2019-11-05,Silicon UK,https://www.silicon.co.uk,"Bad robot? Increasing automation must not drive workplace wage inequality, think tank warns",,"Bad robot? Increasing automation must not drive workplace wage inequality, think tank warns",,https://schema.org,BreadcrumbList,"{'@type': 'WebPage', 'id': 'https://www.silicon.co.uk/e-innovation/artificial-intelligence/robots-hit-low-paid-hardest-226513'}",Workplace Robots To Hit Low Paid The Hardest,"{'@type': 'ImageObject', 'url': 'https://www.silicon.co.uk/wp-content/uploads/2017/04/Robots-making-a-car.jpg', 'width': '1024', 'height': '576'}","{'@type': 'Person', 'name': 'Tom Jowitt'}",2017-12-28T10:42:54+00:00,2019-11-05T20:00:12+00:00,"{'@type': 'Organization', 'name': 'Silicon UK', 'logo': {'@type': 'ImageObject', 'url': 'https://www.silicon.co.uk/wp-content/themes/kamino/assets/images/favicons_silicon/mstile-70x70.png', 'width': '', 'height': ''}}","[{'@type': 'ListItem', 'position': 1, 'item': 'https://www.silicon.co.uk/', 'name': 'All Tech News'}, {'@type': 'ListItem', 'position': 2, 'item': 'https://www.silicon.co.uk/news/e-innovation', 'name': 'Innovation'}, {'@type': 'ListItem', 'position': 3, 'item': 'https://www.silicon.co.uk/news/e-innovation/artificial-intelligence', 'name': 'Artificial Intelligence'}, {'@type': 'ListItem', 'position': 4, 'item': 'https://www.silicon.co.uk/e-innovation/artificial-intelligence/robots-hit-low-paid-hardest-226513', 'name': 'Workplace Robots To Hit Low Paid The Hardest'}]",,,"


Workplace Robots To Hit Low Paid The Hardest

Tom Jowitt, December 28, 2017, 10:42 am | Updated on 5 November 2019, 20:00 















Bad robot? Increasing automation must not drive workplace wage inequality, think tank warns

 The government is being warned by a leading think tank that robots and workplace automation must be carefully managed, if predictions of mass unemployment and economic disruption are to be avoided.
According to the Institute for Public Policy Research, the government specifically needs to intervene to stop automation driving up wage inequality, although it did state that automation will ‘significantly increase productivity’ and that jobs would be reallocated, rather than lost.
The report comes amid a debate over the future where artificial intelligence (AI), robots, and increasing levels of automation are common-place. Some experts such as  renowned physicist Dr Stephen Hawking has previously warned that that artificial intelligence could spell the end of life as we know it on Planet Earth.

Careful Rollout
The report starts off by stating that despite what some would have us believe, we are not on the “cusp of a ‘post-human’ economy,” where robots do all the jobs that humans currently do.
“Automation will produce significant productivity gains that will reshape specific sectors and occupations,” the report stated. “In aggregate, however, these gains are likely to be recirculated, with jobs reallocated rather than eliminated, economic output increased, and new sources of wealth created.”
However it warned that the challenge for governments and regulators is to ensure that the benefits of automation are fairly shared, although there is no guarantee that this will occur, and it could impact the poorest in society the hardest.
“Managed poorly, automation could create a ‘paradox of plenty’: society would be far richer in aggregate, but, for many individuals and communities, technological change could reinforce inequalities of power and reward.”
And the report did warn that lower-skilled jobs were much more likely to be phased out in the coming decades, with only higher-skilled workers would be able to command better wages.
The sectors most at risk from increasing levels of automation are transportation (where 63 percent of jobs could be automated); manufacturing (58 percent of jobs could be automated); and wholesale and retail trade (where 65 percent of jobs could be automated).
“Automation is likely to lead to the steady redeployment of labour over a period of decades, rather than a sudden and rapid elimination of employment,” said the report. “The task contents of most jobs will evolve, changing the nature of work.”
“In the absence of policy intervention, the most likely outcome of automation is an increase in inequalities of wealth, income and power,” said the report. “The economic dividends of automation are likely to flow to the owners of technologies and businesses, and the highly skilled, as income shifts from labour to capital and the labour market polarises between high- and low-skilled jobs.”
And it said jobs with the highest potential for automation typically have lower wages.
However, automation can potentially deliver a powerful boost to UK productivity, the report stated. “An accelerated trajectory of automation could raise productivity growth by between 0.8 to 1.4 percent annually, boosting GDP by 10 percent by 2030.”
The report also said that “an authority for the ethical use of Robotics and Artificial Intelligence should be established to regulate the use of automating technologies.”
A spokesman for the Department for Business, Energy and Industrial Strategy was quoted by the BBC as saying that the UK’s labour market was “resilient and diverse” and that advances in technology were helping to “bring new jobs”.
“The government is committed to ensuring that the UK is to able to seize the opportunities and overcome the obstacles that exist in this area,” he said.
“Government is working closely with industry to ensure the benefits of new technologies are felt across different sectors of the economy up and down the country, while creating new high-skill, well-paid jobs,” the spokesman said.
AI Concern
The report comes amid a debate as to the possible uses of artificial intelligence and robots in the years ahead.
Professor Stephen Hawking has previously said that a thinking machine could “redesign itself at an ever-increasing rate” and “supersede” humans.
Elon Musk, the South Africa-born inventor and entrepreneur best known as the co-founder of PayPal and chief executive of both SpaceX and Tesla Motors, has called AI “our biggest existential threat”.
And Microsoft co-founder Bill Gates has said he was “concerned” about AI and that he agreed with Musk’s view.
In October Google’s DeepMind division announced a significant breakthrough after its AI system became even smarter without any human input at all, after it learnt how to defeat the leading system playing the ancient Chinese game of Go.
Put your knowledge of artificial intelligence to the test. Try our quiz!
Advertising
 Read also : 
Samsung AI-Upgraded Bixby Voice Assistant Coming This Year
Silicon UK In Focus PodcastsponsoriséSilicon In Focus Podcast: The Value of Data00:0000:0000:0000:00SubscribeEdisoundRSS FeedSpotifyDeezerAmazon MusicApple PodcastsShare EpisodeFacebookXLinkedInEpisode linkCopied !





 
Recommend this article:




                    0                









                    4                










 NEWSLETTER 
 Subscribe to our best articles 









 


 Facebook
                            




  Twitter




  Linkedin









Advertising



",Workplace Robots To Hit Low Paid The Hardest,https://www.silicon.co.uk/wp-content/uploads/2017/04/Robots-making-a-car-600x338.jpg,Artificial Intelligence,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3Lmluc2lkZWhpZ2hlcmVkLmNvbS9uZXdzLzIwMTkvMTEvMDQvYWktYXNzZXNzZWQtam9iLWludGVydmlld2luZy1ncm93cy1jb2xsZWdlcy10cnktcHJlcGFyZS1zdHVkZW50c9IBAA?oc=5,"As AI-assessed job interviewing grows, colleges try to prepare students - Inside Higher Ed",2019-11-03,Inside Higher Ed,https://www.insidehighered.com,"Getting a job increasingly requires going through an interview on an AI platform. Some colleges are trying to prepare their students for these nonhuman interactions, but many institutions are just getting acclimated to this new technology.","Higher, Education, News, Jobs, Events, Career",,,https://schema.org,,,,,,,,,,,,"



You have 4/5 articles left.Sign up for a free account or log in.

Sign Up, It’s FREE
Login




 

Istockphoto.com/karelnoppe


Miguel Santiago, a senior at Baruch College in Manhattan, is graduating soon and already considering his next move -- maybe to a job at Goldman Sachs or somewhere else in banking.
In at least six of his interviews, he's been questioned by a computer and not a live person.
“They’ve basically replaced the first round with the HireVue,” he said, referring to the video and artificial intelligence platform increasingly being used by employers for job interviews.
When a candidate applies to a job at a company that uses HireVue, they are asked to go on to the platform, allow use of their webcam and respond to interview questions on video. The candidate’s answers are recorded and then saved to the platform.
Santiago helped bring Goldman and Bank of America employees to his campus to discuss the HireVue process when he was events director for Baruch’s chapter of the Association of Latino Professionals for America.
“What they really want the students to know is that the camera that they’re speaking to when they’re answering the questions from HireVue, it’s just another person,” he said. The banking employees told him that a human would be reviewing the footage, he said.
But according to HireVue’s own advertising materials and recent reporting by The Washington Post, that’s not the only way employers use the platform. Employers can choose to have the recorded answers evaluated by artificial intelligence. If the proprietary technology that HireVue uses to evaluate the recordings concludes that a candidate does well in matching the demeanor, enthusiasm, facial expressions or word choice of current employees of the company, it recommends the candidate for the next round. If the candidate is judged by the software to be out of step, that candidate is not likely to move on.
Although colleges are ostensibly preparing students to enter the workforce, many institutions appear to be unfamiliar with or unprepared for this latest trend in the job market. Unilever, Atlanta Public Schools, Hilton Hotels and Resorts, and nearly 100 other employers now use HireVue, but little advice concerning HireVue interviews can be found on university websites.
To many people who study workforce and AI issues, the software is something of a black box. What the artificial intelligence is looking for -- a smile, a loud speaking voice or a particular keyword -- can’t really be ascertained. Helping prepare students for AI-assessed interviews is challenging, as a result.
“No one is really sure what they look for when it comes to who moves on and who doesn’t,” Santiago said. “It’s definitely kind of a weird experience to have.”
Alex Engler, a former data scientist and a current fellow at the Brookings Institution, where he focuses on AI, is doubtful about the AI's qualification assessment capabilities.
Engler contrasted HireVue's evaluation with other AI-based hiring software such as résumé scanners, which he said are concerning but are based on a plausible connection between résumé qualifications and job readiness.
“HireVue is doing something that goes past that, which is looking at how candidates act in interviews. Their gestures and pose, if they’re leaning with their arms on the table, their tone and cadence,” he said. “Inferring personality traits from a 25-minute video interview, I think, is probably incredibly difficult or impossible. And to tie it to outcomes like, can you be an investment banker or an accountant, is to me very far-fetched.”
HireVue says its assessments are based on ""100 percent validated science.""
""We follow leading psychological research showing the behaviors, skills, traits, thinking styles, and competencies that predict success at work,"" a HireVue spokesperson said via email.
Supporters of such AI-based hiring methods say traditional in-person interviews are even more unfair, and that human evaluators might judge job candidates on arbitrary or illegal criteria such as their physical attributes, dress style or ethnicity.
“People are rejected all the time based on how they look, their shoes, how they tucked in their shirts and how ‘hot’ they are,” Loren Larsen, HireVue’s chief technology officer, told The Washington Post. “Algorithms eliminate most of that in a way that hasn’t been possible before.”
Ifeoma Ajunwa, a professor of labor and employment law at Cornell University who has previously written about AI-based hiring, says that line of thinking is misguided.
“We have to remember that automated hiring platforms are still created by humans,” she said. “The same biases that humans have would also be transferred to any platforms they create.”
HireVue works by having current employees answer the questions on video and then evaluating the candidates on how well they match those employees.
Annelies Goger, a fellow at the Brookings Institution who focuses on workforce development, said the use of the platform could create anxiety for job seekers trying to access industries that are historically segregated and exclusive.
For example, she said, in an occupation primarily filled by young, white men, the system is likely trained to recognize success as young, white men exhibit it.
“If I’m a woman of color and trying to get in,” she said, “I would be pretty anxious about, is this system really going to assess me fairly?”
The HireVue spokesperson said the company's AI assessments are actually increasing diversity at companies, because the algorithms don't notice appearance.
""Each algorithm or assessment model is trained not to 'notice' age, gender, ethnicity, and other personal characteristics that are irrelevant to job success, so it helps to level the playing field,"" the spokesperson wrote in the email.
But to critics, the things that the AI does notice -- faces and gestures -- are the root of the problem, not appearance. Motions like these can vary widely based on culture and ability status, they say.
""You have to exhibit similar qualities to the people already in those jobs and performing well,"" said Engler. ""That doesn’t actually have to mean qualities that are actually useful for the job -- you just have to share the same qualities.""
The effects for people with disabilities could be drastic, he said.
“The way that disabilities can affect people is very broad, and as a result some of the characteristics that people with disabilities exhibit are unlikely to exist in the AI’s training data.”
""HireVue offers various accommodations for people with disabilities and is actively working with international disability groups, as well as with Integrate Autism Employment Advisors to ensure that the tools and processes are fair and accessible,"" the company spokesperson wrote.
Goger said no established ""legal infrastructure"" exists to protect a person facing discrimination from AI.
“Who’s going to check for ADA compliance in these systems?” she said.
Trying to Prepare
Some colleges are trying to prepare their students with the little knowledge that career counselors do have about how HireVue's AI evaluation works. Oftentimes that advice doesn’t look very different from the guidance they provide for in-person interviews.
Michael Kalish, associate director of on-campus recruiting at Baruch’s career center, says career counselors commonly suggest that students dress in a full suit and use industry-specific lingo, since it has been suggested that HireVue scans a candidate's answers for keywords.
“We instruct students in general that when they’re interviewing they should always be using that kind of terminology regardless,” Kalish said. “Not even just to be prepared for [HireVue] interviews, but just, in general, to show the interviewer that they are prepared, that they’ve done their homework, that they’re generally interested in that field.”
Students can also practice for interviews using a mock interview platform called Symplicity that asks industry-specific interview questions and records their answers via webcam. This software predates the widespread use of virtual interviews, Kalish said. Unlike with HireVue, students can rewatch their answers on the Symplicity software.
“They can actually watch it and learn from their mistakes,” Kalish said. “They can meet with a counselor. We can watch it with them and give them constructive criticism and feedback on areas that they should improve upon.”
At Duke University, a document from the economics department lists typical HireVue questions (“Tell me about a time you worked on a team?” and “What does integrity mean to you?”) as well as a few tips for students. The suggestions range from the general interview advice (“Try to give structured concise responses”) to the more technical (ridding the screen of your own image makes it easier to look into the camera), but they don’t really touch on how to nail the mannerisms of past employees other than to “act natural.”
Brigham Young University Idaho is one of the few colleges that advertise mock interviews specifically for HireVue on the university's website. Students can schedule a HireVue mock interview and meet with a career mentor to hear feedback, according to the website. BYU Idaho career center staff declined to discuss these resources, which they said are still in their early stages.
The University of Colorado at Boulder also uses HireVue, but not to help prepare students for interviews. The college uses the software for nearly all of its own hiring.
Andrew Horovitz, an assistant director of talent acquisition at Boulder, said that HireVue makes the process more efficient and lends flexibility to both hiring managers and candidates who don't have to travel or take off work for the video interview. The college does not use HireVue's AI assessment tool, only the video interviewing, he said. The AI feature is an add-on that the university would have to pay for.
""I don’t foresee us using that any time in the near future,"" he said of the AI tool. ""We do a lot of work on our campus around mitigating bias in the interview and hiring process as it is already, and so we want to make sure any tool we introduce or functionality we introduce is in line with that.”
Yajin Wang, a professor of marketing at the University of Maryland, says that most of the things students can do to prepare for HireVue job interviews will make them better public speakers.
The University of Maryland’s business school posted an article in June of this year featuring Wang giving advice to students on how to do their best on HireVue and other platforms.
“Ace an AI interview by incorporating keywords and phrases that explain what you can contribute, echoing the exact language of the job posting,” the article said. “Use gestures, smile, and nod frequently.”
Wang suggested candidates record themselves and watch their answers to prepare.
HireVue advised that students visit the company candidate center and focus on giving examples from relevant work.
""We encourage candidates to 'show what they know,' give specific examples of successful projects when asked, and 'be themselves,'"" the company spokesperson said in the email.
The HireVue Effect
Frederick Hess, director of education policy studies at the American Enterprise Institute, said while he is “not impressed” by HireVue's platform, which he called “dystopian” and “pseudoscience,” the overall trend toward assessment-based hiring may undermine the economic value of a college degree. He said if companies begin to hire based on skills tests that are, unlike HireVue, non-prejudicial and legally sound, they will stop using college degrees as a proxy for knowledge and employability.
“I think these efforts to build new tools, hiring platforms, hiring systems, which will stand up to legal scrutiny because they are specific and clearly attached to the job you’re going to do, and can be defended that they are non-prejudicial, that stuff should worry the heck out of colleges,” he said. “If you can apply without having to go through all the stuff for the degree, then employers can pay less, and you still feel like you’re getting enough.”
“In terms of value as a proxy for skill and talent, I think college degrees themselves are limited, and they’re one instrument that is probably overused in the labor market,” said Goger, the Brookings fellow. But HireVue “is replacing one flawed instrument with another.”
She said colleges could focus on providing students more opportunities for face-to-face interaction and getting a foot in the door.
“They can help candidates understand how to communicate their value to an employer in a specific role,” she said.
Ajunwa, the Cornell professor, said job candidates being assessed by AI should use keywords from the job description, avoid hinting at gender or ethnicity on their résumé, and explain employment gaps by saying what they were specifically doing, such as having a child.
“I worry that these systems might be sending a wrong message to students,” she said. “They’re so anxious and focused on cracking the résumé or cracking the CV to beat the system and then feeling perhaps that their work experience or their skills that they acquired in school aren’t that important. College should be a time to explore and should be a time to learn various skills … I want students to really focus on that, more than worrying about beating these automated hiring systems.”





Want articles like this sent straight to your inbox?

Subscribe to a Newsletter



",,,,"[{'@type': 'Article', 'headline': 'As AI-assessed job interviewing grows, colleges try to prepare students', 'image': {'@type': 'ImageObject', 'url': '/sites/default/files/media/iStock-1022348426.jpg'}, 'datePublished': '2019-11-03EST14:00:00EST', 'dateModified': '2023-02-28EST11:44:03EST', 'author': {'@type': 'NewsMediaOrganization', 'name': 'Lilah Burke'}}, {'@type': 'ImageObject', 'url': ''}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LnBicy5vcmcvd2diaC9mcm9udGxpbmUvYXJ0aWNsZS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS13b3JrLWpvYnMtcm9ib3RzLXYtaHVtYW5zL9IBAA?oc=5,Experts Weigh in on the Work Robots Can't Do (Yet) - PBS,2019-11-05,PBS,https://www.pbs.org,"In the age of artificial intelligence, predicting which jobs will fall to automation is as much about what machines can do as it is about what they can’t.",,"In the age of artificial intelligence, predicting which jobs will fall to automation is as much about what machines can do as it is about what they can’t.","In the age of artificial intelligence, predicting which jobs will fall to automation is as much about what machines can do as it is about what they can’t.
More than half of all jobs in America —",https://schema.org,,,,,,,,,,,,"



The Jobs Robots Can’t Do (At Least Not Yet)

Share:



Twitter


Facebook


E-mail


 








(FRONTLINE) 





November 5, 2019

by


Zoe Todd





In the age of artificial intelligence, predicting which jobs will fall to automation is as much about what machines can do as it is about what they can’t.
More than half of all jobs in America — both blue and white-collar — are resistant to automation, according to an acclaimed study published in 2013 by two Oxford University researchers.
Co-author Carl Benedikt Frey, who directs Oxford’s Technology and Employment program, broke down three areas where human intelligence still beats artificial intelligence: perception and manipulation, social intelligence; and creativity. Each type has what Frey calls a “bottleneck,” which slows the pace at which certain workforces can be automated.
The premise is simple: Technology won’t replace human workers if it can’t do the job. Six years later, Frey said the argument holds. Here’s a look at the sectors proving to be robot resistant:
Perception and Manipulation
Humans outpace robots when it comes to perception and motor skills, especially in so-called “unstructured work environments” – spaces cluttered with many different objects. Until technology catches up, work such as surgery is best left to humans, Frey said. Similarly, jobs in unstructured environments, such as homes, are more difficult to automate than jobs in predictable, structured environments such as factories, warehouses, airports and hospitals.
Social Intelligence
Social intelligence is another bottleneck, as machines can’t yet compete with humans at work involving negotiation, persuasion or care. In particular, machines struggle to recognize and respond to human emotions. Work requiring high social intelligence is therefore less susceptible to automation. Frey lists public relations and event planning as examples.
Creativity
Robots also can’t keep up with human creativity: the ability to form new and valuable ideas such as poetry, music, recipes, jokes, fashion design or scientific theories. Though technology is capable of randomly combining old ideas to create new ones, the result doesn’t necessarily make sense — or have value. In this case, the novelty of a random, machine-generated idea should not be confused with creativity, Frey said.
What About the Rest? 
Of course, that leaves roughly half the jobs in the U.S. with tasks machines can now do better than humans. But Frey emphasized that doesn’t mean those jobs will vanish outright, either.
“There are a lot of people that took our estimates to suggest that all of these jobs are going to disappear within 10 to 20 years, but the paper did not really say that,” he said.
If anything, technology will likely create new kinds of work for humans, says James Bessen, who heads the Technology and Policy Research Initiative at Boston University.
“People are focusing on the aspects of the technology where the machines can replace humans at certain tasks,” Bessen said. “Most of what technology does, is actually enhance humans at doing certain tasks.”
He uses bank tellers as an example. The profession was largely mechanized decades ago by the ATM – literally, “automated teller machine.” Yet, despite becoming a fixture at banks across the country, ATMs did not push out human tellers. On the contrary, research shows the number of bank tellers in America rose nearly in tandem with the number of machines.
Though ATMs did replace some workers, the cost savings allowed banks to open new branches for which they then hired additional people, Bessen explained. As such, the human jobs were not replaced but displaced. Moreover, the ATMs freed their flesh-and-blood colleagues from routine tasks such as depositing money. Instead, they were able to focus on inherently human work like interacting with clients.
Still, researchers acknowledge the transition to a new American workforce as these industries adapt to and integrate automation will be painful.
People will continue to lose jobs to new technology, and some workers may be pushed into long periods of unemployment, Bessen said. Already, many are forced to relocate or retrain, and those who can’t afford to do so will be left behind.
Women disproportionately hold the jobs at highest risk of automation, according to Molly Kinder, who studies the future of work at a D.C. think tank called Work, Workers and Technology.
“That’s not really being talked about,” Kinder said. “And that’s in part because women are overrepresented in some of these marginalized occupations like a cashier or a fast-food worker, and also in a large numbers in clerical jobs in offices.”
“There’s real pain involved,” Bessen said. “There’s a real question about how these gains get distributed, about who’s suffering, who’s bearing the brunt in these transitions.”
For American workers, finding ways to navigate the transition to new technology is the real challenge, Bessen said, adding that their success will in part be up to government policies — and pushback by workers themselves.








Zoe Todd, Former Abrams Journalism Fellow, FRONTLINE/Columbia Journalism School Fellowships


Twitter:
@ZoeHTodd







Journalistic Standards











Watch the Documentary
In the Age of AI






    Support Provided By
    Learn more







See What FRONTLINE Is Working On Now






Get Our Newsletter





Related Articles




How China’s Government Is Using AI on Its Uighur Muslim Population
November 21, 2019





Artificial Intelligence Can Be Biased. Here's What You Should Know.
November 5, 2019





Could the Rise of Artificial Intelligence Put Truckers’ Jobs in Peril?
November 5, 2019





Topics


Business and Economy






",,,,"[{'@type': 'NewsArticle', '@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/#article', 'isPartOf': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/'}, 'author': [{'@type': 'Person', 'name': 'Zoe Todd', 'url': 'https://www.pbs.org/wgbh/frontline/person/zoe-todd/'}], 'headline': 'The Jobs Robots Can&#8217;t Do (At Least Not Yet)', 'datePublished': '2019-11-05T22:52:15+00:00', 'dateModified': '2019-11-05T22:52:15+00:00', 'mainEntityOfPage': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/'}, 'wordCount': 797, 'publisher': {'@type': 'Organization', 'name': 'Frontline PBS', 'logo': {'@type': 'ImageObject', 'url': 'https://www.pbs.org/wgbh/frontline/wp-content/themes/fl-responsive-theme/library/images/frontline_logo_og.png'}}, 'image': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/#primaryimage'}, 'thumbnailUrl': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2019/11/3805_Screengrabs200.jpg', 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/', 'url': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/', 'name': ""Experts Weigh in on the Work Robots Can't Do (Yet)"", 'isPartOf': {'@id': 'https://www.pbs.org/wgbh/frontline/#website'}, 'primaryImageOfPage': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/#primaryimage'}, 'image': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/#primaryimage'}, 'thumbnailUrl': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2019/11/3805_Screengrabs200.jpg', 'datePublished': '2019-11-05T22:52:15+00:00', 'dateModified': '2019-11-05T22:52:15+00:00', 'description': 'In the age of artificial intelligence, predicting which jobs will fall to automation is as much about what machines can do as it is about what they can’t.', 'breadcrumb': {'@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/#primaryimage', 'url': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2019/11/3805_Screengrabs200.jpg', 'contentUrl': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2019/11/3805_Screengrabs200.jpg', 'width': 1920, 'height': 1080, 'caption': '(FRONTLINE)'}, {'@type': 'BreadcrumbList', '@id': 'https://www.pbs.org/wgbh/frontline/article/artificial-intelligence-work-jobs-robots-v-humans/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.pbs.org/wgbh/frontline/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Articles', 'item': 'https://www.pbs.org/wgbh/frontline/articles/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Business and Economy', 'item': 'https://www.pbs.org/wgbh/frontline/topic/business-and-economy/'}, {'@type': 'ListItem', 'position': 4, 'name': 'The Jobs Robots Can&#8217;t Do (At Least Not Yet)'}]}, {'@type': 'WebSite', '@id': 'https://www.pbs.org/wgbh/frontline/#website', 'url': 'https://www.pbs.org/wgbh/frontline/', 'name': 'FRONTLINE', 'description': 'FRONTLINE', 'publisher': {'@id': 'https://www.pbs.org/wgbh/frontline/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.pbs.org/wgbh/frontline/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.pbs.org/wgbh/frontline/#organization', 'name': 'FRONTLINE | PBS', 'url': 'https://www.pbs.org/wgbh/frontline/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pbs.org/wgbh/frontline/#/schema/logo/image/', 'url': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2020/10/frontline_logo_opengraph.png', 'contentUrl': 'https://www.pbs.org/wgbh/frontline/wp-content/uploads/2020/10/frontline_logo_opengraph.png', 'width': 1200, 'height': 630, 'caption': 'FRONTLINE | PBS'}, 'image': {'@id': 'https://www.pbs.org/wgbh/frontline/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/frontline', 'https://twitter.com/frontlinepbs', 'https://www.instagram.com/frontlinepbs/', 'https://www.youtube.com/user/pbsfrontline'], 'publishingPrinciples': 'https://www.pbs.org/wgbh/frontline/about-us/editorial-standards-and-ethics', 'noBylinePolicy': 'https://www.pbs.org/wgbh/frontline/about-us/editorial-standards-and-ethics/#verification-and-fact-checking-standards'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiO2h0dHBzOi8vZmVkc2Nvb3AuY29tL2dvb2dsZS1wcm9qZWN0LW1hdmVuLWNhbmFyeS1jb2FsLW1pbmUv0gEA?oc=5,Google's departure from Project Maven was a 'little bit of a canary in a coal mine' - FedScoop,2019-11-05,FedScoop,https://fedscoop.com,"Leaders of the artificial intelligence project failed to be transparent upfront and did not control the narrative, says Lt. Gen. Jack Shanahan.","['artificial intelligence (ai)', 'department of defense (dod)', 'google', 'jack shanahan', 'joint artificial intelligence center (jaic)', 'kent walker', 'national security commission on artificial intelligence', 'project maven']","Leaders of the artificial intelligence project failed to be transparent upfront and did not control the narrative, says Lt. Gen. Jack Shanahan.",,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'http://fedscoop.com/google-project-maven-canary-coal-mine/'}",Google&#8217;s departure from Project Maven was a &#8216;little bit of a canary in a coal mine&#8217;,"{'@type': 'ImageObject', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/03/5099102.jpg'}","[{'@type': 'Person', 'name': 'Billy Mitchell'}]",2019-11-05T20:10:02Z,2019-11-05T20:18:47Z,"{'@type': 'Organization', 'name': 'FedScoop', 'logo': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/cropped-fs_favicon-3.png'}",,,,"






Defense




								Google’s departure from Project Maven was a ‘little bit of a canary in a coal mine’							

								Leaders of the artificial intelligence project failed to be transparent upfront and did not control the narrative, says Lt. Gen. Jack Shanahan.							


By
Billy Mitchell



November 5, 2019






 
											The director of the Joint Artificial Intelligence Center, U.S. Air Force Lt. Gen. Jack Shanahan, listens during a round table meeting at the Pentagon on Feb. 12, 2019. (DOD / U.S. Army Sgt. Amber I. Smith)										





There’s nothing controversial about the Department of Defense’s Project Maven, if you ask Lt. Gen. Jack Shanahan.
Shanahan, who has led the military’s program to use artificial intelligence for full-motion video analysis since its inception, said Tuesday that Google‘s decision to back away from involvement with Maven came from a lack of transparency around the project. As a result, the DOD lost the narrative around its work, he said.
“This idea of transparency and a willingness to talk about what each side is trying to achieve may be the biggest lessons of all that I took from it,” Shanahan, who now heads DOD’s Joint AI Center, said of Project Maven at an event in conjunction with the National Security Commission on AI’s release of its interim report.
Because Google and DOD weren’t minding the public perception what Project Maven was meant to do, “we started hearing these wild stories and assumptions about what Project Maven was and was not to the point where if you Googled it today … the adjective ‘controversial’ has now been permanently inserted in front of Project Maven, Shanahan said. “It was not controversial to me. It was not controversial to the team. I say it’s not controversial to anybody right now beyond some people who just don’t like what we’re doing.”


Advertisement



The project was, quite simply, created to provide computer vision on drones to detect objects from above, Shanahan said. It certainly wasn’t “a weapons project” — although the project’s official name, the Algorithmic Warfare Cross-Functional Team, does sound very weapon-y.
Those impressions were enough to set off protests by Google employees. Google eventually announced it would not renew its contract. It also stepped out of the running for DOD’s Joint Enterprise Defense Infrastructure (JEDI) cloud contract around the same time, reportedly because of ethical concerns centering on the department’s use of artificial intelligence.
Lesson learned, Shanahan said. On Tuesday he seemed to almost take a tone of acceptance about the situation, saying that “it happened,” and if it didn’t happen to his team, “it would have happened to somebody else at some point.”
“I view what happened with Google and Maven as a little bit of a canary in a coal mine,” Shanahan said. “The fact that it happened when it did as opposed to on the verge of a conflict or a crisis where we’re asking for help, we’ve gotten some of that out of the way,” and can now move on.
Shanahan said reports that Google seemingly didn’t want to work with the Pentagon in the aftermath were unfortunate, because “some of the software engineers on the project, they got to the point where they almost felt a little bit ostracized because others criticized them for working with the Department of Defense” on Project Maven. “But day-to-day, from the senior-most leaders down to the people working on the Project Maven team, we had tremendous support in Maven from Google” and “got products we were very pleased with.”


Advertisement




Google’s take on Project Maven
It just so happened that Shanahan was joined on stage at the event by Kent Walker, senior vice president of global affairs for Google, who also wanted to take the moment to clear the air and “set the record straight.”
“It’s been frustrating to hear concerns around our commitment to national security and defense,” he said. Not only has Google been criticized as soft in its support of U.S. defense and national security since its withdrawal from Project Maven, but it’s also been condemned for its work providing AI in China.
Walker explained Google stepping away from Maven as “an area where it’s right that we decided to press the reset button until we had the opportunity to develop our own set of AI principles, our own work with regard to internal standards and review processes. But that was a decision focused on a discrete contract — not a broader statement about our willingness or our history of working with the Department of Defense.”
He said Google continues to work with the U.S. military on countless other efforts and pointed such partnerships as part of “a long tradition of work throughout [Silicon Valley] on national security generally.”


Advertisement




“It’s important to remember the history of the Valley in large measure builds on government technologies from radar to the internet to GPS to some of the work on autonomous vehicles and personal assistants that you’re seeing now,” Walker said. “This is a shared responsibility to get this right.”
Shanahan agreed, alluding to a necessary equilateral triangle of partnership among the government, industry and academia for the U.S. to succeed in developing and using AI competitively.
Even for those who are “suspicious” of the federal government or have trouble with the fact that the U.S. is in strategic competition with China, Shanahan said, “I would hope they would still agree with us that AI is a critical component of our nation’s prosperity, vitality and self-sufficiency. In other words, no matter where you stand with respect to the government’s future use of AI-enabling technologies, I submit that we can never attain [ the nation’s vision for it] without industry and academia with us together in an equal partnership. There’s too much at stake to do otherwise.”








Written by Billy Mitchell
			Billy Mitchell is Senior Vice President and Executive Editor of Scoop News Group's editorial brands. He oversees operations, strategy and growth of SNG's award-winning tech publications, FedScoop, StateScoop, CyberScoop, EdScoop and DefenseScoop. 

After earning his journalism degree at Virginia Tech and winning the school's Excellence in Print Journalism award, Billy received his master's degree from New York University in magazine writing while interning at publications like Rolling Stone.		


In This Story



														Google													



														Artificial Intelligence (AI)													



														Department of Defense (DOD)													



														Project Maven													



														Joint Artificial Intelligence Center (JAIC)													



														Jack Shanahan													



														National Security Commission on Artificial Intelligence													



														Kent Walker													








Share




Facebook





LinkedIn





Twitter





Copy Link











Advertisement






Advertisement





More Like This






								MPEs gain momentum for sharing information with allied partners			



By 

						Scoop News Group					










								State Department officials say they’re trying to set the tone globally on AI usage, as lawmakers question if it’s enough			



By 

						Caroline Nihill					










								VA plans to award AI tech sprint winners contracts for ambient medical transcription services			



By 

						Caroline Nihill					









Advertisement





Top Stories






								FedRAMP ‘undeniably’ in state of limbo without final OMB modernization guidance, Rep. Connolly says			



By 

						Caroline Nihill					










								After 2023 outage that paused flights nationwide, FAA now has backup system			



By 

						Rebecca Heilweil					










								How the IRS’s ‘cautious’ approach with Direct File prevented its ‘failure’			



By 

						Matt Bracken					










								Social Security Administration transitioning long-time users to Login.gov			



By 

						Rebecca Heilweil					










								Energy Department’s national labs get AI boost in bipartisan Senate bill			



By 

						Matt Bracken					










								GSA begins FedRAMP pilot to change request process			



By 

						Caroline Nihill					










								White House to require increased cybersecurity protocols for R&D institutions			



By 

						Caroline Nihill					










Advertisement






",,https://fedscoop.com/wp-content/uploads/sites/5/2019/03/5099102.jpg?w=150&h=150&crop=1,Defense,"[{'@type': 'WebPage', '@id': 'https://fedscoop.com/google-project-maven-canary-coal-mine/', 'url': 'https://fedscoop.com/google-project-maven-canary-coal-mine/', 'name': ""Google's departure from Project Maven was a 'little bit of a canary in a coal mine' | FedScoop"", 'isPartOf': {'@id': 'https://fedscoop.com/#website'}, 'primaryImageOfPage': {'@id': 'https://fedscoop.com/google-project-maven-canary-coal-mine/#primaryimage'}, 'image': {'@id': 'https://fedscoop.com/google-project-maven-canary-coal-mine/#primaryimage'}, 'thumbnailUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/03/5099102.jpg', 'datePublished': '2019-11-05T20:10:02+00:00', 'dateModified': '2019-11-05T20:18:47+00:00', 'description': 'Leaders of the artificial intelligence project failed to be transparent upfront and did not control the narrative, says Lt. Gen. Jack Shanahan.', 'breadcrumb': {'@id': 'https://fedscoop.com/google-project-maven-canary-coal-mine/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://fedscoop.com/google-project-maven-canary-coal-mine/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/google-project-maven-canary-coal-mine/#primaryimage', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/03/5099102.jpg', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/03/5099102.jpg', 'width': 2805, 'height': 1543, 'caption': 'The director of the Joint Artificial Intelligence Center, U.S. Air Force Lt. Gen. Jack Shanahan, listens during a round table meeting at the Pentagon on Feb. 12, 2019. (DOD / U.S. Army Sgt. Amber I. Smith)'}, {'@type': 'BreadcrumbList', '@id': 'https://fedscoop.com/google-project-maven-canary-coal-mine/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://fedscoop.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Google&#8217;s departure from Project Maven was a &#8216;little bit of a canary in a coal mine&#8217;'}]}, {'@type': 'WebSite', '@id': 'https://fedscoop.com/#website', 'url': 'https://fedscoop.com/', 'name': 'FedScoop', 'description': 'FedScoop delivers up-to-the-minute breaking government tech news and is the government IT community&#039;s platform for education and collaboration through news, events, radio and TV. FedScoop engages top leaders from the White House, federal agencies, academia and the tech industry both online and in person to discuss ways technology can improve government, and to exchange best practices and identify how to achieve common goals.', 'publisher': {'@id': 'https://fedscoop.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://fedscoop.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://fedscoop.com/#organization', 'name': 'FedScoop', 'url': 'https://fedscoop.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/#/schema/logo/image/', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'width': 1231, 'height': 182, 'caption': 'FedScoop'}, 'image': {'@id': 'https://fedscoop.com/#/schema/logo/image/'}}]",http://fedscoop.com/google-project-maven-canary-coal-mine/,,,,,,,['Billy Mitchell'],2019-11-05T20:10:02Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LnNoZWVwY2VudHJhbC5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbWFrZXMtYWNjdXJhdGUtc2hlZXAtY291bnRpbmctYS1yZWFsaXR5L9IBAA?oc=5,Artificial intelligence makes accurate sheep counting a reality - Sheep Central,2019-11-01,Sheep Central,https://www.sheepcentral.com,,,A LIVESTOCK counting system using artificial intelligence will be ready for the live export industry this year and for use in sheep saleyards by April 2020...Read More,,https://schema.org,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.sheepcentral.com/artificial-intelligence-makes-accurate-sheep-counting-a-reality/', 'url': 'https://www.sheepcentral.com/artificial-intelligence-makes-accurate-sheep-counting-a-reality/', 'name': 'Artificial intelligence makes accurate sheep counting a reality - Sheep Central', 'isPartOf': {'@id': 'https://www.sheepcentral.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.sheepcentral.com/artificial-intelligence-makes-accurate-sheep-counting-a-reality/#primaryimage'}, 'image': {'@id': 'https://www.sheepcentral.com/artificial-intelligence-makes-accurate-sheep-counting-a-reality/#primaryimage'}, 'thumbnailUrl': 'https://www.sheepcentral.com/wp-content/uploads/2019/11/Sheep-counting-above-the-loading-ramps-of-a-live-export-vessel.-167x300.jpg', 'datePublished': '2019-11-01T03:39:17+00:00', 'dateModified': '2019-11-10T00:57:53+00:00', 'author': {'@id': 'https://www.sheepcentral.com/#/schema/person/b1057e1f39f3486b508db95e0235faf9'}, 'breadcrumb': {'@id': 'https://www.sheepcentral.com/artificial-intelligence-makes-accurate-sheep-counting-a-reality/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.sheepcentral.com/artificial-intelligence-makes-accurate-sheep-counting-a-reality/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.sheepcentral.com/artificial-intelligence-makes-accurate-sheep-counting-a-reality/#primaryimage', 'url': 'https://www.sheepcentral.com/wp-content/uploads/2019/11/Sheep-counting-above-the-loading-ramps-of-a-live-export-vessel..jpg', 'contentUrl': 'https://www.sheepcentral.com/wp-content/uploads/2019/11/Sheep-counting-above-the-loading-ramps-of-a-live-export-vessel..jpg', 'width': 436, 'height': 784}, {'@type': 'BreadcrumbList', '@id': 'https://www.sheepcentral.com/artificial-intelligence-makes-accurate-sheep-counting-a-reality/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.sheepcentral.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial intelligence makes accurate sheep counting a reality'}]}, {'@type': 'WebSite', '@id': 'https://www.sheepcentral.com/#website', 'url': 'https://www.sheepcentral.com/', 'name': 'Sheep Central', 'description': 'Sheep News Australia', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.sheepcentral.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.sheepcentral.com/#/schema/person/b1057e1f39f3486b508db95e0235faf9', 'name': 'Terry Sim', 'url': 'https://www.sheepcentral.com/author/terry/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvd2hhdC1qb2JzLWFyZS1hZmZlY3RlZC1ieS1haS1iZXR0ZXItcGFpZC1iZXR0ZXItZWR1Y2F0ZWQtd29ya2Vycy1mYWNlLXRoZS1tb3N0LWV4cG9zdXJlL9IBAA?oc=5,"What jobs are affected by AI? Better-paid, better-educated workers face the most exposure | Brookings - Brookings Institution",2019-11-20,Brookings Institution,https://www.brookings.edu,This analysis demonstrates a new way to identify the kinds of tasks and occupations likely to be affected by AI’s machine learning capabilities.,,This analysis demonstrates a new way to identify the kinds of tasks and occupations likely to be affected by AI’s machine learning capabilities.,,https://schema.org,,,,,,,,,,,,"

 Back to Janesville 









                        Back to Janesville 
",,,,"[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/what-jobs-are-affected-by-ai-better-paid-better-educated-workers-face-the-most-exposure/', 'url': 'https://www.brookings.edu/articles/what-jobs-are-affected-by-ai-better-paid-better-educated-workers-face-the-most-exposure/', 'name': 'What jobs are affected by AI? Better-paid, better-educated workers face the most exposure | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/what-jobs-are-affected-by-ai-better-paid-better-educated-workers-face-the-most-exposure/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/what-jobs-are-affected-by-ai-better-paid-better-educated-workers-face-the-most-exposure/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2019/11/banner.jpg?quality=75', 'datePublished': '2019-11-14T20:45:59+00:00', 'dateModified': '2022-03-09T04:38:13+00:00', 'description': 'This analysis demonstrates a new way to identify the kinds of tasks and occupations likely to be affected by AI’s machine learning capabilities.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/what-jobs-are-affected-by-ai-better-paid-better-educated-workers-face-the-most-exposure/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/what-jobs-are-affected-by-ai-better-paid-better-educated-workers-face-the-most-exposure/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/what-jobs-are-affected-by-ai-better-paid-better-educated-workers-face-the-most-exposure/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2019/11/banner.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2019/11/banner.jpg?quality=75', 'width': 7360, 'height': 2367, 'caption': 'Banner image'}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/what-jobs-are-affected-by-ai-better-paid-better-educated-workers-face-the-most-exposure/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'What jobs are affected by AI? Better-paid, better-educated workers face the most exposure'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vZm9ydHVuZS5jb20vMjAxOS8xMS8xOS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS13aWxsLW9ibGl0ZXJhdGUtdGhlc2Utam9icy1ieS0yMDMwL9IBAA?oc=5,Types of Jobs Artificial Intelligence Will Eliminate By 2030 - Fortune,2019-11-19,Fortune,https://fortune.com,"Forrester projects that artificial intelligence will severely impact jobs like cubicle workers, location-based workers, and loan processors.","artificial intelligence, jobs eliminated by artificial intelligence, ai jobs, what is ai doing to jobs, does ai destroy jobs, the future of artificial intelligence, what is ai, what is artificial intelligence, jobs safe from artificial intelligence","""All gone.""","""All gone.""",,,,,,,,,,,,,"Newsletters - Data SheetThe security company that Alphabet may buy for $23 billion launched at the perfect timeBYDavid MeyerJuly 16, 2024",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LnN0YXJ0cmVrLmNvbS9uZXdzL2hvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pcy1nZXR0aW5nLXVzLWNsb3Nlci10by1zdGFyLXRyZWtzLXVuaXZlcnNhbC10cmFuc2xhdG9yc9IBAA?oc=5,How Artificial Intelligence Is Getting Us Closer to Star Trek's Universal Translators - Star Trek,2019-11-20,Star Trek,https://www.startrek.com,"Current automatic translation can’t compete with the 24th century’s, but it’s made astronomical progress in the past decade.",,"Current automatic translation can’t compete with the 24th century’s, but it’s made astronomical progress in the past decade.",,https://schema.org,Organization,"{'@type': 'WebPage', '@id': 'https://www.StarTrek.com/news/how-artificial-intelligence-is-getting-us-closer-to-star-treks-universal-translators'}",How Artificial Intelligence Is Getting Us Closer to Star Trek’s Universal Translators,"['https://images.prismic.io/star-trek-untold/MGRlZjhhYzAtYTBlNC00MTkwLWEyYWUtYjQxOWJhYzA5OGFm_universal_translator_001.png?auto=compress,format&rect=0,0,2000,1080&w=2000&h=1080']","[{'@type': 'Person', 'name': 'Lorelei Laird'}]",2023-07-25T00:09:31+0000,2023-08-08T20:43:04+0000,"{'@type': 'Organization', 'name': 'Star Trek', 'logo': {'@type': 'ImageObject', 'url': 'https://www.startrek.com/delta-serp.png'}}",,,,,,,,,https://www.startrek.com,,https://www.startrek.com/delta-serp.png,"['https://twitter.com/StarTrek', 'https://www.instagram.com/startrek/', 'https://www.facebook.com/StarTrek/', 'https://www.startrek.com/', 'https://www.youtube.com/startrek', 'https://en.wikipedia.org/wiki/Star_Trek']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMWh0dHBzOi8vd3d3Lm5hdHVyZS5jb20vYXJ0aWNsZXMvczQxNzQ2LTAxOS0wMTg5LTfSAQA?oc=5,Human–machine partnership with artificial intelligence for chest radiograph diagnosis | npj Digital Medicine - Nature.com,2019-11-18,Nature.com,https://www.nature.com,"Human-in-the-loop (HITL) AI may enable an ideal symbiosis of human experts and AI models, harnessing the advantages of both while at the same time overcoming their respective limitations. The purpose of this study was to investigate a novel collective intelligence technology designed to amplify the diagnostic accuracy of networked human groups by forming real-time systems modeled on biological swarms. Using small groups of radiologists, the swarm-based technology was applied to the diagnosis of pneumonia on chest radiographs and compared against human experts alone, as well as two state-of-the-art deep learning AI models. Our work demonstrates that both the swarm-based technology and deep-learning technology achieved superior diagnostic accuracy than the human experts alone. Our work further demonstrates that when used in combination, the swarm-based technology and deep-learning technology outperformed either method alone. The superior diagnostic accuracy of the combined HITL AI solution compared to radiologists and AI alone has broad implications for the surging clinical AI deployment and implementation strategies in future practice.",,,npj Digital Medicine - Human–machine partnership with artificial intelligence for chest radiograph diagnosis,https://schema.org,WebPage,,,,,,,,,,,"




Download PDF








Article

Open access

Published: 18 November 2019

Human–machine partnership with artificial intelligence for chest radiograph diagnosis
Bhavik N. Patel 
            ORCID: orcid.org/0000-0001-5157-99031, Louis Rosenberg2, Gregg Willcox2, David Baltaxe2, Mimi Lyons2, Jeremy Irvin3, Pranav Rajpurkar3, Timothy Amrhein 
            ORCID: orcid.org/0000-0002-9354-94864, Rajan Gupta4, Safwan Halabi 
            ORCID: orcid.org/0000-0003-1317-984X1, Curtis Langlotz 
            ORCID: orcid.org/0000-0002-8972-80511, Edward Lo1, Joseph Mammarappallil4, A. J. Mariano1, Geoffrey Riley1, Jayne Seekins1, Luyao Shen1, Evan Zucker1 & …Matthew P. Lungren1 Show authors

npj Digital Medicine
volume 2, Article number: 111 (2019)
            Cite this article




19k Accesses


93 Citations


201 Altmetric


Metrics details










An Author Correction to this article was published on 10 December 2019







This article has been updated



AbstractHuman-in-the-loop (HITL) AI may enable an ideal symbiosis of human experts and AI models, harnessing the advantages of both while at the same time overcoming their respective limitations. The purpose of this study was to investigate a novel collective intelligence technology designed to amplify the diagnostic accuracy of networked human groups by forming real-time systems modeled on biological swarms. Using small groups of radiologists, the swarm-based technology was applied to the diagnosis of pneumonia on chest radiographs and compared against human experts alone, as well as two state-of-the-art deep learning AI models. Our work demonstrates that both the swarm-based technology and deep-learning technology achieved superior diagnostic accuracy than the human experts alone. Our work further demonstrates that when used in combination, the swarm-based technology and deep-learning technology outperformed either method alone. The superior diagnostic accuracy of the combined HITL AI solution compared to radiologists and AI alone has broad implications for the surging clinical AI deployment and implementation strategies in future practice.



Similar content being viewed by others






Collaborative strategies for deploying artificial intelligence to complement physician diagnoses of acute respiratory distress syndrome
                                        


Article
Open access
08 April 2023









Deep learning for distinguishing normal versus abnormal chest radiographs and generalization to two unseen diseases tuberculosis and COVID-19
                                        


Article
Open access
01 September 2021









A multistage framework for respiratory disease detection and assessing severity in chest X-ray images
                                        


Article
Open access
29 May 2024








IntroductionRecent notable applications of deep learning in medicine include automated detection of diabetic retinopathy, classification of skin cancers, and detection of metastatic lymphadenopathy in patients with breast cancer, all of which demonstrated expert level diagnostic accuracy.1,2,3 Recently, a deep-learning model was found to match or outperform human expert radiologists in diagnosing 10 or more pathologies on chest radiographs.4,5 The success of AI in diagnostic imaging has fueled a growing debate6,7,8,9 regarding the future role of radiologists in an era, where deep-learning models are capable of performing important diagnostic tasks autonomously and speculation surrounds whether the comprehensive diagnostic interpretive skillsets of radiologist can be replicated in algorithms. However, AI is also plagued with several disadvantages including biases due to limited training data, lack of cross-population generalizability, and inability of deep-learning models to contextualize.8,10,11,12Human-in-the-loop (HITL) AI may offer advantages where both radiologists and machine-learning algorithms fall short.13,14 This paradigm allows leveraging all the advantages of AI models (i.e. rapid automated detection) but having a human at various checkpoints to fill gaps where algorithms are not confident in their probabilities or where they may fall short due to underlying biases. For example, a machine-learning algorithm could analyze a large dataset and provide output for the presence of disease in a short period of time, some with high confidence (i.e. high probability of the presence or absence of the disease relative to the probabilistic threshold for the detection of that disease) and others with low. The lower confidence outputs could then be validated by a human to create a combined better decision on the input; this approach could harness the best of human intelligence and artificial intelligence to create a collective super intelligence. Recent work has shown superior task performance of a combined human and AI augmented model compared to either human15 or machine alone.15,16 To date, however, no studies have harvested the full collective intelligence of a group of radiologists and then examined the performance of an augmented model.In this study, we employ a novel collective intelligence platform called Swarm17,18,19 designed to amplify the accuracy of networked human groups by enabling the groups to work together in real-time systems modeled after biological swarms. In contrast to traditional crowds, swarm intelligence refers to stigmergic collaborative behavior of large groups of independent agents that form a closed-loop system, resulting in an collective super intelligence whose capacity exceeds that of any individual agent.17,19 The most studied form of swarm intelligence in nature is the honeybee swarm, which has been shown to make decisions through a process that is surprisingly similar to neurological brains.20,21,22 Both employ large populations of simple excitable units (i.e., bees and neurons) that work in unison to integrate noisy and incomplete information, weigh competing alternatives and converge on unified decisions in real-time synchrony. In both brains and swarms, outcomes are arrived at through a real-time competition among sub-populations of excitable units. When one sub-population exceeds threshold support, the corresponding alternative is chosen. In honeybees, this enables the colonies to converge on optimal decisions to highly complex problems, such as selecting an optimal home location from among a large set of alternatives.21,22,23When using the platform with groups of radiologists, the swarm-based technology was applied to the diagnosis of pneumonia on chest radiographs. Diagnostic accuracy of the swarm-based technology was compared against the human experts alone and two state-of-the-art deep-learning AI models that have demonstrated expert level performance in automated pneumonia and multiple diagnosis detection, respectively.5,6 In addition, a novel combination of the swarm-based technology and the deep-learning AI models was compared against each of the methods in isolation.ResultsExperiment designComplete details regarding the chest radiograph dataset, two deep-learning model architectures, and swarm-based collective intelligence platform is discussed in the online methods section. In brief, a total of 13 expert radiologists split over two sessions (7 radiologists in group A; 6 radiologists in group B) provided their estimate of the probability of the presence or absence of pneumonia on 50 chest radiographs, first alone then collectively using the real-time swarm platform. Two state-of-the art deep-learning models, CheXNet and CheXMax, were also used to evaluate the chest radiographs and the performance between individual human experts, real-time swarms, and AI were compared. Finally, a novel combination of the real-time swarm platform and the deep-learning models was compared against each method in isolation.The aggregate performance of individual human experts was calculated in two ways: first, the average probability of all radiologists in each group was calculated and used as the crowd-based mean performance. Second, a crowd-based majority diagnosis was calculated using a vote—if more radiologists diagnosed pneumonia than no pneumonia using a 50% probability cutoff, the crowd-based majority diagnosis was pneumonia.The probabilistic diagnoses from CheXNet and CheXMax were turned into binary classifications of pneumonia using a discrimination threshold—any probabilistic diagnosis above the threshold is assigned a prediction of “Pneumonia” and any diagnosis below the threshold is assigned a prediction of “No Pneumonia”. The thresholds for these algorithms were set to maximize the performance of the algorithms on their respective training data sets. The discrimination threshold for CheXNet is 50%, and the discrimination threshold for CheXMax is 4.008%.Diagnostic performance resultsResults of the diagnostic performance of individuals, real-time swarms, and AI models are summarized in Tables 1 and 2. The individual radiologists outperformed CheXNet in diagnosing pneumonia in this study (AUC of 0.698 vs. 0.545, p < 0.01). CheXMax on the other hand, outperformed the individual radiologists (AUC of 0.938 vs. 0.698, p < 0.01). The swarm platform also outperformed the individual radiologists. For both swarm sessions, swarm interpolation achieved higher diagnostic accuracy than individual human performance, crowd-based performance, and CheXNet (Fig. 1). For group A, swarm achieved a statistically higher AUC of 0.840 [0.691, 0.937] compared to 0.763 [0.709, 0.817] (p < 0.05) average AUC of all radiologists in group A and to 0.685 [0.520, 0.854] (p < 0.01) AUC for CheXNet. For group B, the swarm had a statistically higher diagnostic accuracy than individual radiologists and CheXNet for all performance metrics (e.g. AUC of 0.889 vs. 0.810 and 0.685, respectively). When results from both swarm sessions were combined, swarm-based diagnoses resulted in statistically higher (p < 0.01) accuracies compared to radiologists and CheXNet (e.g. AUC of 0.868 vs. 0.785 and 0.685, respectively) (Fig. 1). There was no difference between CheXMax and the combined swarms in terms of accuracy or F1 score (accuracy of 82% vs. 84%, p = 0.423; F1 of 0.788 vs. 0.800, p = 0.34). CheXMax outperformed the combined swarm in AUC (0.938 vs. 0.868, p < 0.01), but the swarm outperformed CheXMax in terms of Brier score and mean absolute error (Brier scores of 0.287 vs. 0.134, p < 0.01; MAE of 0.357 vs. 0.233, p < 0.01).Table 1 Diagnostic performance parameters for individual particpants, swarm sessions, and AI models.Full size tableTable 2 Sensitvity and specificity for individual particpants, swarm sessions, and AI models.Full size tableFig. 1Bootstrapped average AUC curves. AUC curves show that the swarms (blue bars) outperform group A (left image), group B (middle image), and combined group (right image). Radiologists (orange bars) performances in diagnosing pneumonia. Swarm also outperforms CheXNet (green bars).Full size imageThe sensitivity and specificity of each of the diagnostic methods is compared in Table 2. In terms of the sensitivity of each diagnostic method, the swarm outperforms CheXNet in all groups (a combined group sensitivity of 0.700 [0.578, 0.814] versus CheXNet’s 0.450 [0.326, 0.579], p < 0.01), while CheXMax and the combined model outperform the swarm in all groups, with sensitivities of 0.900 [0.773, 1.00] (p < 0.05) and 0.875 [0.783, 0.956] (p < 0.05), respectively. In terms of the specificity of each diagnostic method, the swarm outperforms CheXMax, with a specificity of 0.933 [0.855, 0.968] compared to CheXMax’s specificity of 0.767 [0.672, 0.857] (p < 0.01). The Augmented HITL model obtains a specificity of 0.933 [0.877, 0.983], the same as the swarm. Interestingly, the human diagnostic methods all show a lower sensitivity than specificity, while CheXMax shows a higher sensitivity than specificity. The swarm shows the highest specificity of any of the diagnostic methods, while CheXMax shows the highest sensitivity of any of the diagnostic methods.Due to the differences in sensitivity and specificity between the swarm and CheXMax, it is clear that these two diagnostic methods have different strengths and advantages when diagnosing pneumonia: CheXMax has a higher sensitivity, so this machine-learning model is more precise at detecting pneumonia if it does exist, whereas the swarm has a higher specificity, so this human-driven model is more precise at detecting when pneumonia does not exist in an image. An augmentation model was created to determine whether these two strengths could be combined into a single model to achieve higher accuracy as compared to either model alone. CheXMax was used first to diagnose the probability of pneumonia across all 50 cases. Cases in which CheXMax yielded a low-confidence diagnosis were then passed on to swarm. Low-confidence was defined as a CheXMax probability between 2.5% and 5.5%, resulting in 20 cases passed on to swarm for final prediction of pneumonia. This selection was chosen as a fair low-confidence band around the average CheXMax prediction (p = 4.008%) and yielded 20 cases on which to swarm: 13 negative predictions and 7 positive predictions. Each swarm’s probabilistic diagnoses on these 20 cases were then used as the augmented model’s final diagnoses, in place of the ML system’s low-confidence diagnoses. All other cases remained diagnosed exclusively by the ML system.This augmented combined system achieved a statistically higher diagnostic performance than either CheXNet or CheXMax and combined swarm alone using two of the performance metrics (e.g. accuracy 92% vs. 82% and 84%; F1 score of 0.89 vs. 0.80 and 0.78, respectively; p < 0.01) (Table 1). The augmented model system achieves the lowest diagnostic error rate, in terms of number of diagnoses incorrect, compared to any of the other examined diagnostic methods (error rates of 9% augmented model; 16% combined swarm; 18% CheXMax; 24% individuals). Moreover, the augmented system achieves near-best performance in both sensitivity and specificity, with a sensitivity of 0.875 [0.783, 0.956] and a specificity of 0.933 [0.877, 0.983]. It appears that this augmented model is therefore able to combine the best aspects of both the machine-learning system (CheXMax), which has high sensitivity, and the swarm, which has high specificity.To better visualize how the HITL augmentation process changed the probabilistic diagnoses of CheXMax and why these changes resulted in a more accurate system, a scatterplot of probabilistic diagnoses is shown in Fig. 2. Over all 100 of the evaluated cases, the swarm and CheXMax disagreed on a total of 24, of which the vast majority (21, or 87.5%) were cases where the swarm gave a negative diagnosis, but CheXMax gave a positive diagnosis. Over all 24 cases where the Swarm and CheXMax disagreed, the swarm was correct on 12 diagnoses, while CheXMax was correct on the other 12 diagnoses.Fig. 2Scatterplot of swarm vs. CheXMax probabilistic diagnoses, with cases colored by ground truth. The scatterplots show that CheXMax and human swarms assign very different probabilities to each case (left image). The gray “Augmented Cases” range shows cases that were sent from CheXMax to the Swarm for augmentation. CheXMax has a high incidence of True Positives (blue-colored cases below the horizontal CheXMax Threshold line), but when the CheXMax gives a weak positive diagnosis (between 0.04008 and 0.055 on the y-axis), it is often incorrect (11 out of 15 cases correct, or an accuracy of 73%). Using a human swarm to re-classify these weak positive cases results in correctly labeling 14 out of 15 of the cases—an accuracy improvement of 20%. The cases on which the two diagnostic methods disagreed are more clearly visualized in the scatterplot of diagnostic disagreement (right image).Full size imageThe gray band across each image represents the range of cases that CheXMax diagnosed with low confidence (probabilistic diagnosis between 0.025 and 0.055), and subsequently sent to the swarm for a second opinion. These 20 cases were each evaluated by both Group A and Group B, for a total of 40 diagnoses generated by the swarms in the augmented system. Of these 40 diagnoses, 29 agreed with CheXMax’s original evaluation: three cases where both diagnostic methods gave a positive reading, with 100% accuracy, and 26 cases where both methods gave a negative reading, with 84.6% accuracy. Only 11 diagnoses disagreed with CheXMax’s original evaluation, all of which were low-confidence positive diagnoses by CheXMax, and high confidence negative diagnoses by swarm (less than a 20% probability of pneumonia). Of these 11 cases, the swarm correctly changed CheXMax’s original diagnosis 10 out of 11 times (91%). Figure 3 provides examples of correct diagnosis by CheXMax over swarm, and vice-versa, as well as an augmented case with correct diagnosis changed by swarm from CheXMax.Fig. 3Case examples. Each of the three rows a–c represent three different patients. Grayscale image is on the left with the corresponding class activation map to its right. The top row example a includes a patient with pneumonia in the left lung, correctly predicted by CheXMax but incorrectly by swarm. The middle row b is an example of a patient with metastatic disease but without pneumonia, correctly predicted by swarm and incorrectly by CheXMax. The bottom row c is an example of an augmented case, where CheXMax provided a low confidence positive prediction (p = 0.41) but was correctly predicted as negative by swarm.Full size imageBecause the boost in performance of the augmented model depends on the selection of cases (i.e. how “low confidence” is defined) sent to the swarm, a sensitivity analysis was performed to determine the impact of the quantity of cases selected to be sent to the swarm on the accuracy of the augmented model. In this sensitivity analysis, cases are selected based on their distance to the discrimination threshold (4.008%) of CheXMax, starting with the lowest-confidence cases (those closest to the discrimination threshold). An equal number of positive and negative cases are selected to be diagnosed with Swarm at each cutoff, where the number of cases selected ranges from 0 to 50 (0–100% of the data). The number of cases correctly diagnosed by the augmented system is calculated for each cutoff.A bootstrapping analysis with 1000 bootstraps is used to find the 90% confidence interval of accuracy for each cutoff by randomly re-sampling a full set of cases from the observed population 1000 times and calculating the observed accuracy for each resampled set of cases. The average accuracy increases of this augmented system relative to CheXMax and 90% confidence interval of this accuracy increase are shown in Figs. 4 and 5. This sensitivity analysis suggests that the success of the augmented model is only slightly sensitive to the choice of threshold at which a case is deemed “low-confidence”. Regardless of the choice of threshold, the average accuracy of the augmented system is greater than or equal to that of the ML system (Fig. 6). When the proportion of cases sent to the swarm is between 6% and 32%, however, the augmented system diagnoses more cases correctly than the ML system alone (p < 0.05), indicating that the augmented model outperforms CheXMax across a wide range of “low confidence” thresholds.Fig. 4Sensitivity analysis of augmented model accuracy. The shape of the average accuracy line shows a consistent increase in the accuracy of the augmented model when the 0–14% lowest-confidence cases are sent to the swarm, from 82% correct of CheXMax (sending 0% of cases) to 90% correct when sending the 14% of lowest-confidence positive and negative cases to the swarm. The model performs similarly when 16–32% of cases are sent to the swarm, achieving between 88% and 92% accuracy across this sensitivity range. If more than 32% of cases are sent to the swarm, the accuracy of the system decreases, until the limit of sending all diagnoses to the swarm is reached (100% of cases swarmed), where the accuracy returns to the swarm score of 84%.Full size imageFig. 5Sensitivity analysis of accuracy increase relative to CheXMax. Sensitivity analysis shows a band between 6% and 34%, where the 90% confidence interval is only ever >0%. This indicates that when sending between 6% and 34% of the lowest-confidence cases to the swarm using this method, there is high confidence that the augmented model would diagnose the cases more accurately than the CheXMax alone. If the range is limited between 14% and 28%, the average improvement in accuracy is 7.75% correct.Full size imageFig. 6Bootstrapped average specificity and sensitivity of aggregate diagnostic methods. The bootstrapped specificity histograms show that the swarms in the combined group (blue bars) outperform CheXMax (green bars) in terms of specificity (left image), but CheXMax outperforms the swarms in terms of sensitivity (right image). The HITL Combined model combines the best of both the CheXMax and swarm diagnostic methods, by attaining swarm-level specificity and CheXMax-level sensitivity.Full size imageDiscussionOur study shows that, using a test set of 50 chest radiographs with strong ground truth using clinical outcomes, highest diagnostic performance can be achieved with HITL AI when radiologists and AI technologies work together. We combined a novel real-time interactive platform that utilizes the biological concept of swarm intelligence with a deep-learning model and found the maximum diagnostic performance that neither alone was able to achieve.Using a swarm platform, we found that the diagnostic performance was higher than individual radiologist performance in diagnosing pneumonia. Moreover, when results of both swarm sessions were combined, swarm-based diagnoses outperformed crowd-based majority vote. This has important implications as many studies involving deep-learning models often use either individual expert, consensus, or majority vote to provide ground truth labels for validation and test sets when stronger metrics, such as pathology results, are unavailable or not applicable.4,15,24,25 Results from our study shows that swarm-based diagnoses outperforms crowd-based diagnoses, and thus may represent a novel means for generating image labels that provide more accurate ground truth than conventional consensus labeling methods for training datasets for deep-learning algorithms. Moreover, some centers may not readily have access to experts, and labeling images through swarm sessions may allow such centers to achieve expert level labels.It has been well-established that crowds of people can outperform individuals and achieve estimates close to the true value that would otherwise not be possible with individual estimates, a concept known as “wisdom of crowd effect”.26,27,28,29,30 In fact, the use of this effect specifically for medical decision making has also been described.31,32,33,34 However, this effect is a statistical aggregation of individual estimates. Traditionally, its power is shown through votes, conducting polls, or collecting surveys such that the input from each individual member is captured in isolation (or near isolation) and then combined with the data collected from other members to then pass through a post-hoc statistical processing. Thus, the dynamics of a real-time collaboration and negotiation are void within these types of “crowds.” Studies have also shown that wisdom of crowd effect could be undermined by social influence, and that the crowd-based decision can be biased resulting in tending away from higher accuracy compared to the individual.28,35,36 This is, however, dependent on how the communication network for information exchange is structured.37Modeled after complex decision processes used by swarming honeybees, the real-time algorithms that connect users of the Swarm platform enable human groups to work together to integrate noisy and incomplete information, weigh competing alternatives, and converge on unified decisions in real-time synchrony. In this way, the swarm-based technology utilized in this study enabled networked groups of radiologists to outperform individual radiologists, groups of radiologists taking a traditional vote, and the CheXNet deep-learning system when diagnosing pneumonia on chest radiographs.Similar to the human experiment in which we aimed to harness the maximum diagnostic potential, we retrained CheXNet,38 which was originally trained on a publicly available NIH dataset,39 on a recently released large dataset of chest radiographs with radiologist level validation and test sets.5 This newly trained deep-learning algorithm, CheXMax, outperformed the average radiologist for the detection of pneumonia (e.g. 82% vs. 76% accuracy, respectively). Moreover, this newly trained algorithm outperformed the swarm-based method when using the AUC metric (the standard measure of diagnostic classification accuracy) and underperformed the swarm-based method when using mean absolute error and Brier score (the standard measures of probabilistic accuracy) (Table 1). Since the AUC metric measures the success of ordering the cases from least to most likely to contain pneumonia, while the Brier score and mean absolute error scores measure the probabilistic accuracy of the diagnoses—e.g. whether a diagnosis of a 10% chance of pneumonia actually contained pneumonia only 10% of the time—this result suggests that the CheXMax is better at ordering the cases from least to most likely to contain pneumonia, while the swarm is better at assessing the probabilistic likelihood of pneumonia in a specific case.As deep-learning models continue to improve though larger and higher quality dataset for training, as we found with retraining CheXNet,5 an unanswered question remains as to what the exact scenario of implementation within clinical workflow will be. Advantages of deep-learning algorithms include rapidity in diagnosis proving to be useful as a triage tool. Disadvantages include biases introduced by training dataset and inability to contextualize to clinical context.8,11,12,40 Thus, many have advocated that a clinical workflow model in which healthcare workers leverage AI might yield the greatest benefit to patients.40,41 To that extent, few studies have shown superior performance of human augmented by AI compared to either human or machine alone.15,16 In our study, we showed the ability of a deep-learning algorithm in CheXMax to provide rapid confident diagnoses for pneumonia for over a half of the cases in the test set. Low-confidence cases were then passed on to the human through swarm to yield the final diagnosis and the combined HITL model resulted in higher diagnostic accuracy than either radiologists or AI models alone. The clinical significance of this could imply that, in a landscape of increasing clinical volumes, complexity of cases, and medical record documentation, physicians could leverage deep learning to improve operational efficiency; deep-learning algorithms could provide automated rapid diagnosis for high confident cases as a triage tool so that physicians could spend less time on high confidence cases evaluated by an AI model and more time on relatively complex cases. In such HITL scenarios, active learning could be provided to AI algorithms through feedback from radiologists in the form of additional training data, which the model did not initially provide a confident diagnosis. Further studies are needed to determine the optimal workflow and implementation of deep-learning algorithms in the healthcare setting.Several limitations of our study merit consideration, including those that are attributed to a retrospective design; despite having a strong clinical reference standard, we utilized a very small test set of 50 cases which, though achieving the best available clinical ground truth, nonetheless, it is possible that patients who were included may have had other pathologies that were clinically treated as pneumonia in routine clinical care, which may have confounded the diagnosis had the follow-up period been prospectively designed or more invasive testing been performed (i.e. sputum cultures, bronchoscopy, direct sampling), which may have altered the results of the study. This size was chosen as to practically perform swarm sessions with synchronous groups of radiologists in a timely manner, and judging by the statistical analysis in this pilot it is possible that larger sample sizes would have observed a similar trend. While we studied the improved diagnostic accuracy of combining the capabilities of CheXMax with swarm, we did not perform a simulation experiment where CheXMax results are given real-time during the swarm sessions. The cutoff for the model decisions were selected by maximizing Youden’s J on the validation set and this low probability leads to a good tradeoff between sensitivity and specificity for this task. Finally, one could argue that such a platform as swarm may not be practically necessary for decisions and tasks as relatively simple as diagnosing pneumonia on chest radiographs.In conclusion, we demonstrated increased diagnostic performance of radiologists in diagnosing pneumonia on chest radiographs through swarm intelligence using a novel platform, superior performance of a deep-learning algorithm trained on higher quality data compared to individual radiologists and achieved the maximum diagnostic accuracy using an HITL AI approach through an augmented model combining both radiologists (through swarm) and AI (using a deep-learning model). Although we focused on one common medical-imaging task, future work could assess the feasibility and application for other various medical diagnostic tasks and decision making.MethodsThis Health Insurance Portability and Accountability Act-compliant study was approved by the Institutional Review Board of Stanford University, and a waiver of informed consent was obtained.Chest radiograph pneumonia datasetWe retrospectively searched our electronic medical record database and picture and archiving communications system (PACS) for patients who underwent chest radiographs (anterioposterior or posterioanterior) in the emergency room or in the outpatient clinic setting over a 2-year period between 2015 and 2017. The search yielded an initial target population of 7826 unique patients with 11,127 chest radiographs. Patients were eligible for inclusion in the study if they presented with clinical signs and symptoms concerning for pneumonia, such as fever, cough, shortness of breath, elevated white blood cell count, crackles on physical examination, etc.42,43 Subjects were excluded from the study if: (a) the clinical reference standard was inadequate (see below) or (b) an inadequate examination due to a suboptimal technique or incomplete imaging data available. The first consecutive 50 unique patients who met the aforementioned eligibility were included in the final population. A test set size cutoff of 50 chest radiographs was used in order to practically perform the human reader evaluation in a timely fashion and so as not to introduce reader fatigue that might occur with larger datasets. The final retrospective cohort was comprised of 27 males and 23 females (mean age ± standard deviation, 62.1 ± 21.0 years; range, 19–100 years) with a test set of 50 frontal chest radiographs.Clinical reference standardOnly those patients and their frontal chest radiographs were included, if they are presented with aforementioned signs and symptoms and clinical concern for pneumonia. An image was labeled negative if all of the following criteria were met: (a) chest radiograph was interpreted as negative for pneumonia by a board-certified diagnostic radiologist at the time of examination; (b) a follow-up chest computed tomography (CT) within 1 day after the index chest radiograph confirmed lack of pneumonia on imaging; (c) the patient was not administered antibiotics. An image was labeled positive for pneumonia if all of the following criteria were met: (a) chest radiograph was interpreted as positive for pneumonia by a board-certified diagnostic radiologist at the time of examination; (b) patient was treated with antibiotics; (c) a follow-up chest CT or chest radiograph within 7 days after treatment showed interval improvement or resolution of pneumonia; (d) patient showed clinical signs of improvement after treatment on follow-up visit. Using this reference standard, the test set contained a class balance of 30 negative and 20 positive exams for pneumonia.Deep-learning models and architecturesTwo previously developed and described state-of-the-art convolutional neural networks for chest radiographs were used.4,5 First, a 121-layer dense convolutional neural network (DenseNet), CheXNet, was used on the 50 test cases. This model was trained using the publicly available dataset released by Wang et al.39 CheXNet was previously tested on 14 different chest radiograph pathologies, including pneumonia, and outperformed a group of board-certified diagnostic radiologists5 as well as previous models39,44 using the same dataset. Though large datasets, such as the one released by Wang et al. 39 have allowed progress in deep-learning automation of chest radiographs, those efforts can only achieve a certain advancement before reaching a plateau. This is due to the fact that large well-labeled datasets with strong clinical reference standards are needed. Publicly available large datasets are often limited as the labels are derived from automatic labelers that extract information from existing radiology reports.39 Additionally, these labelers cannot account for uncertainty that may be conveyed in free text radiology reports. Thus, the advantages of access to available large datasets can come at a cost of weak labels. A recent large dataset of chest radiographs was released that addresses these limitations with labels that account for uncertainty and has strong reference standards with radiologist labeled validation and test sets.5 Using the this recently released database, we retrained CheXNet model (the newly trained model referred to as CheXMax), hypothesizing that the improved training dataset would boost the diagnostic potential of this deep-learning algorithm for chest radiographs. The test set of 50 chest radiographs were evaluated with CheXMax and probabilities of pneumonia for each exam were derived.RadiologistsA total of 13 board certified diagnostic radiologists (average years of experience: 7.8 years; range 1–23 years) across two major busy tertiary care centers (Stanford University and Duke University) participated in this study. The 13 radiologists were arbitrarily divided into two groups (group A—7 radiologists, average(range) of experience: 6.6 (1–11); group B—6 radiologists, average(range) of experience: 9.2 (1–23)) based on their availability. Each group participated in a 2-h session (see the “Swarm sessions” section) to evaluate a test set of 50 chest radiographs, first individually and then as a swarm.Swarm platform and model architectureIn order to assess both individual diagnostic performance and maximal collective human diagnostic performance, we employed a novel real-time collaborative software platform called Swarm that has been assessed in a variety of prior studies and has been shown to amplify the combined intelligence of networked human groups.23,45,46,47 While traditional systems that harness the intelligence of groups collect data from participants in isolation, usually through an online survey, and then combine the input statistically to determine the group response, the Swarm platform enables participants to work together in real-time, converging on a group decision as a unified system that employs biological principle of Swarm Intelligence. This is achieved using a unique system architecture that includes a central processing engine that runs swarming algorithms on a cloud-based server (Fig. 7a). The processing engine is connected over the internet to a set of remote workstations used by the human participants (Fig. 7b). Each workstation runs a client application that provides a unique graphical interface for capturing real-time behavioral input from participants and for providing real-time feedback generated by the processing engine.Fig. 7Swarm platform. A system diagram (left image) of the Swarm platform shows the connection of networked human users. A Swarm engine algorithm received continuous input from the humans as they are making their decision and provides real-time collaborative feedback back to the humans to create a dynamic feedback loop. Swarm Platform positioned next to a second screen for viewing radiograph (middle image). A snapshot (right image) of the real-time swarm of six radiologists (group B) shows small magnets controlled by radiologists pulling on the circular puck in the process of collectively converging towards a probability of pneumonia. To view a video of the above question being answered in the Swarm platform, visit the following link: https://unanimous.ai/wp-content/uploads/2019/05/Radiology-Swarm.gif.Full size imageThe processing engine employs algorithms modeled on the decision-making process of honeybee swarms. The underlying algorithms enable networked groups to work together in parallel to (a) integrate noisy and incomplete information, (b) weigh competing alternatives, and (c) converge in synchrony on optimized decision, all while allowing participants to react to the collective impact they are having on the changing system in real-time, thereby closing a feedback loop around the whole group.21 To use this platform, distributed groups of participants (in this case radiologists) log on to a central server from their own individual workstations and are simultaneously asked a series of questions to be answered together as a swarm. In this study, each question in the series involved assessing the probability of a patient having pneumonia based upon a displayed chest radiograph.To answer each question, the participants collaboratively move a graphical pointer represented as a glass puck (Fig. 7c). An answer is reached when the group moves the puck from the center of the screen to a target associated with one of the available answer options. In this study, the displayed question was “What is the probability this patient has pneumonia?” and the answer options were five percentage ranges that the participants could choose among. The ranges were (0–5%), (5–25%), (25–65%), (65–85%), and (85–100%).To influence the motion of the puck, each participant controls a graphical magnet using their mouse or touchscreen. The magnet enables each participant to express their intent upon the collaborative system by pulling the graphical puck in the direction they believe it should go. It is important to note that these user inputs are not discrete votes, but continuous streams of vectors provided simultaneously by the full set of participants, enabling the group to collectively pull on the system in opposing and/or supporting directions until they converge, moving the puck to one solution they can best agree upon. It is also important to note that the impact that each user has on the motion of the puck is determined by the swarm algorithms at every time step. The algorithms evaluate the relative conviction that each participant has at each moment based on their behaviors over time (i.e. how their magnets move as compared to each of the other participants). In this way, the software enables real-time control system such that (i) the participants provide behavioral input at every time-step, (ii) the swarming algorithms determine how the graphical pointer should move based on the behavioral input, (iii) the participants to react to the updated motion of the pointer, updating their behaviors in real-time, and (iv) the swarming algorithms react to the updated behaviors, thereby creating a real-time, closed-loop feedback system. This process repeats in real-time until the participants converge on a final answer by positioning the pointer upon one of the five targets.Using this method, the distributed group of users quickly converge on solutions, each answer being generated in under 60 s. After the solutions is reached, the behavioral data is fed into an interpolation algorithm which computes a refined probability as to the likelihood that patient associated with the displayed radiograph is positive for pneumonia. This interpolation is performed because the group of participants were provided a simple set of five options to choose from, each representing a wide range of probabilities. By interpolating the behavioral data captured while the group guided the puck to the target, a refined probability value can be computed with a high degree of precision.Swarm sessionsTwo groups (A and B) of radiologists participated in two separate swarm sessions, split randomly based on the availability of each radiologist to participate on a given date. Each session diagnosed 50 cases. For each case, participants were first asked to view a DICOM image of a frontal chest radiograph using their own independent workstation with a DICOM viewer of their preference. Individual assessments of the probability of pneumonia within this image were made through an online questionnaire using the swarm platform. These individual assessments were not revealed to other participants. Individuals were not given a time limit for the completion of the online questionnaire, and never took more than 1 min to review each image and complete the questionnaire. Subsequently, the group worked together as a real-time swarm, converging on a probabilistic diagnosis as to the likelihood that the patient has pneumonia using the aforementioned magnets to move the puck. The radiologists had no direct communication during the swarm and were anonymous to one another. The diagnosis was arrived at through a two-step process in which the swarm first converged on a coarse range of probabilities and then converged on a refined value within the chosen range. The full process of deliberation for each case, as moderated by the real-time swarm artificial intelligence algorithm, generally took between 15 and 60 s. No swarm failed to reach an answer within 60 s. Each swarm session took 2 h to complete the entire test set.Statistical analysisProbabilities produced by CheXNet and CheXMax were converted to binary prediction using a discrimination threshold (p = 50.0% for CheXNet and p = 4.006% for CheXMax). Similarly, for the human assessments of chest radiographs prior to the swarm-based decision, probabilities of pneumonia were converted to binary prediction using a 50% threshold—any diagnoses >50% probability were labeled as “pneumonia predicted”. This was performed for individual radiologist diagnoses, the average of all radiologist diagnoses for a single image, as well as by a crowd-based majority vote. For the swarm session, results of the two separate sessions were analyzed separately as well as together. The final probability selected by the swarm was further refined through using underlying data generated during the convergence process. This was done using a weighted averaging process referred to as squared impulse interpolation or swarm interpolation. This process, as outlined in equations below, calculates a weighted average of the probabilities in the swarm using the squared net “pull” towards each answer as weights. The pull is represented as the force (F) imparted by members of the swarm and the weight for each answer wi is calculated as the squared impulse towards that answer (Eq. (1)). The weighted average over the answer choice values vi is then computed (Eq. (2)). The answer choice values vi are taken as the midpoint of each bin. For example, the bin “0–5%” has a midpoint vi of 2.5%.$$w_i = \frac{{F(i)^2}}{{\mathop {\sum}\nolimits_{a \in {\mathrm {Answers}}} F(a)^2}}$$
                    (1)
                $${\mathrm {Refined}}\,{\mathrm {probabilistic}}\,{\mathrm {diagnosis}}\,{\sum} {w_iv_i}$$
                    (2)
                This process can be visualized by plotting the net vector force of each radiologist over the course of the swarm, as shown in Fig. 8.Fig. 8Support density visualization. In this support density visualization corresponding to the swarm in Fig. 1, the puck’s trajectory is shown as a white dotted line, and the distribution of force over the hex is plotted as a Gaussian kernel density heatmap. Notice that this swarm was split between the “5–25%” and “0–5%” bins, and more force was directed towards the 5–25%. This aggregate behavior is reflected in the swarm’s interpolated diagnosis of 11.1%.Full size imageFinal diagnostic performance was compared between radiologists (average performance of individual radiologists, averaging individual diagnoses on an image within a group to calculate the group’s average probabilistic diagnosis, and taking a vote of individual radiologist diagnoses to label the image in a binary manner), the AI models, and diagnosis by swarm. Five different diagnostic performance metrics were used to make the comparisons: (a) percent correct, (b) mean absolute error, (c) Brier score, (d) AUC, and (e) F1 score.Reporting summaryFurther information on research design is available in the Nature Research Reporting Summary linked to this article.


Data availability
Data are available on request due to privacy or other restrictions. The data that support the findings of this study are available on request from the corresponding author (B.N.P.). The data are not publicly available due to privacy information embedded directly within the data.
Code availability
Restrictions apply regarding the release of source code used in this study.
Change history10 December 2019An amendment to this paper has been published and can be accessed via a link at the top of the paper.ReferencesDe Fauw, J. et al. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat. Med. 24, 1342–1350 (2018).Article 
    
                    Google Scholar 
                Ehteshami Bejnordi, B. et al. Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. JAMA 318, 2199–2210 (2017).Article 
    
                    Google Scholar 
                Gulshan, V. et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA 316, 2402–2410 (2016).Article 
    
                    Google Scholar 
                Rajpurkar, P. et al. Deep learning for chest radiograph diagnosis: a retrospective comparison of the CheXNeXt algorithm to practicing radiologists. PLoS Med. 15, e1002686 (2018).Article 
    
                    Google Scholar 
                Irvin, J. et al. CheXpert: a large chest radiograph dataset with uncertainty labels and expert comparison. In: Proc. AAAI Conference on Artificial Intelligence, North America (2019).Recht, M. & Bryan, R. N. Artificial intelligence: threat or boon to radiologists? J. Am. Coll. Radiol. 14, 1476–1480 (2017).Article 
    
                    Google Scholar 
                Schier, R. Artificial intelligence and the practice of radiology: an alternative view. J. Am. Coll. Radiol. 15, 1004–1007 (2018).Article 
    
                    Google Scholar 
                Obermeyer, Z. & Emanuel, E. J. Predicting the future—big data, machine learning, and clinical medicine. N. Engl. J. Med. 375, 1216–1219 (2016).Article 
    
                    Google Scholar 
                Kressel, H. Y. Setting sail: 2017. Radiology 282, 4–6 (2017).Article 
    
                    Google Scholar 
                Chartrand, G. et al. Deep learning: a primer for radiologists. Radiographics 37, 2113–2131 (2017).Article 
    
                    Google Scholar 
                Gianfrancesco, M. A., Tamang, S., Yazdany, J. & Schmajuk, G. Potential biases in machine learning algorithms using electronic health record data. JAMA Intern. Med. 178, 1544–1547 (2018).Article 
    
                    Google Scholar 
                Gehrmann, S. et al. Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives. PLoS ONE 13, e0192360 (2018).Article 
    
                    Google Scholar 
                Verghese, A., Shah, N. H. & Harrington, R. A. What this computer needs is a physician: humanism and artificial intelligence. JAMA 319, 19–20 (2018).Article 
    
                    Google Scholar 
                Liew, C. The future of radiology augmented with artificial intelligence: a strategy for success. Eur. J. Radiol. 102, 152–156 (2018).Article 
    
                    Google Scholar 
                Bien, N. et al. Deep-learning-assisted diagnosis for knee magnetic resonance imaging: development and retrospective validation of MRNet. PLoS Med. 15, e1002699 (2018).Article 
    
                    Google Scholar 
                Lakhani, P. & Sundaram, B. Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks. Radiology 284, 574–582 (2017).Article 
    
                    Google Scholar 
                Beni, G. From Swarm Intelligence to Swarm Robotics. 1–9 (Springer, Berlin, Heidelberg, 2005).Wang, J. & Beni, G. Pattern generation in cellular robotic systems. In: Proc. IEEE International Symposium on Intelligent Control, 63–69 (IEEE, 1988).Rosenberg, L. Artificial swarm intelligence, a human-in-the-loop approach to A.I. In: Proc. 13th AAAI Conference on Artificial Intelligence, 4381–4382 (AAAI Press, Phoenix, AZ, 2016).Marshall, J. A. et al. On optimal decision-making in brains and social insect colonies. J. R. Soc. Interface 6, 1065–1074 (2009).Article 
    
                    Google Scholar 
                Seeley, T. D. et al. Stop signals provide cross inhibition in collective decision-making by honeybee swarms. Science 335, 108–111 (2012).Article 
    CAS 
    
                    Google Scholar 
                Seeley, T. D. & Buhrman, S. C. Nest-site selection in honey bees: how well do swarms implement the “best-of-N” decision rule? Behav. Ecol. Sociobiol. 49, 416–427 (2001).Article 
    
                    Google Scholar 
                Rosenberg, L. Artificial Swarm Intelligence, a Human-in-the-Loop Approach to A.I. Thirtieth AAAI Conference on Artificial Intelligence. (2016).Esteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017).Article 
    CAS 
    
                    Google Scholar 
                Titano, J. J. et al. Automated deep-neural-network surveillance of cranial images for acute neurologic events. Nat. Med. 24, 1337–1341 (2018).Article 
    CAS 
    
                    Google Scholar 
                Galton, F. Vox populi (The wisdom of crowds). Nature 75, 450–451 (1907).Article 
    
                    Google Scholar 
                Lorge, I., Fox, D., Davitz, J. & Brenner, M. A survey of studies contrasting the quality of group performance and individual performance, 1920–1957. Psychol. Bull. 55, 337–372 (1958).Article 
    CAS 
    
                    Google Scholar 
                Lorenz, J., Rauhut, H., Schweitzer, F. & Helbing, D. How social influence can undermine the wisdom of crowd effect. Proc. Natl Acad. Sci. USA 108, 9020–9025 (2011).Article 
    CAS 
    
                    Google Scholar 
                Miner, T. The wisdom of crowds: why the many are smarter than the few, and how collective wisdom shapes business, economies, societies, and nations. J. Exp. Educ. 27, 351 (2005).
                    Google Scholar 
                Rauhut, H. & Lorenz, J. The wisdom of crowds in one mind: how individuals can simulate the knowledge of diverse societies to reach better decisions. J. Math. Psychol. 55, 191–197 (2011).Article 
    
                    Google Scholar 
                Sonabend, A. M. et al. Defining glioblastoma resectability through the wisdom of the crowd: a proof-of-principle study. Neurosurgery 80, 590–601 (2017).PubMed 
    PubMed Central 
    
                    Google Scholar 
                King, A. J., Gehl, R. W., Grossman, D. & Jensen, J. D. Skin self-examinations and visual identification of atypical nevi: comparing individual and crowdsourcing approaches. Cancer Epidemiol. 37, 979–984 (2013).Article 
    
                    Google Scholar 
                McKenna, M. T. et al. Strategies for improved interpretation of computer-aided detections for CT colonography utilizing distributed human intelligence. Med. Image Anal. 16, 1280–1292 (2012).Article 
    
                    Google Scholar 
                Lee, Y. J., Arida, J. A. & Donovan, H. S. The application of crowdsourcing approaches to cancer research: a systematic review. Cancer Med. 6, 2595–2605 (2017).Article 
    
                    Google Scholar 
                Moussaid, M., Kammer, J. E., Analytis, P. P. & Neth, H. Social influence and the collective dynamics of opinion formation. PLoS ONE 8, e78433 (2013).Article 
    CAS 
    
                    Google Scholar 
                Baddeley, M. Herding, social influence and economic decision-making: socio-psychological and neuroscientific analyses. Philos. Trans. R. Soc. Lond. B 365, 281–290 (2010).Article 
    
                    Google Scholar 
                Becker, J., Brackbill, D. & Centola, D. Network dynamics of social influence in the wisdom of crowds. Proc. Natl Acad. Sci. USA 114, E5070–E5076 (2017).Article 
    CAS 
    
                    Google Scholar 
                Rajpurkar, P. et al. CheXNet: radiologist-level pneumonia detection on chest X-rays with deep learning. Preprint at arXiv:1711.05225 (2017).Wang, X. et al. ChestX-ray8: Hospital-scale Chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. Proceedings of the IEEE conference on computer vision and pattern recognition. Preprint at arXiv:1705.02315 (2017).Hosny, A., Parmar, C., Quackenbush, J., Schwartz, L. H. & Aerts, H. Artificial intelligence in radiology. Nat. Rev. Cancer 18, 500–510 (2018).Article 
    CAS 
    
                    Google Scholar 
                Jha, S. & Topol, E. J. Adapting to artificial intelligence: radiologists and pathologists as information specialists. JAMA 316, 2353–2354 (2016).Article 
    
                    Google Scholar 
                Prina, E., Ranzani, O. T. & Torres, A. Community-acquired pneumonia. Lancet 386, 1097–1108 (2015).Article 
    
                    Google Scholar 
                Metlay, J. P., Kapoor, W. N. & Fine, M. J. Does this patient have community-acquired pneumonia? Diagnosing pneumonia by history and physical examination. JAMA 278, 1440–1445 (1997).Article 
    CAS 
    
                    Google Scholar 
                Yao, L. et al. Learning to diagnose from scratch by exploiting dependencies among labels. Preprint at arXiv:1710.10501 (2017).Rosenberg, L. & Pescetelli, N. Amplifying Prediction Accuracy Using Swarm A.I. In: Intelligent Systems Conference (IntelliSys). (IEEE, 2017).Rosenberg, L., Baltaxe, D. & Pescetelli, N. Crowds vs. swarms, a comparison of intelligence. In: Proc. 2016 Swarm/Human Blended Intelligence Workshop (SHBI), 1–4 (2016).Rosenberg, L. et al. Artificial swarm intelligence employed to amplify diagnostic accuracy in radiology. In: Proc. 2018 IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON) 1186–1191 (2018).Download referencesAuthor informationAuthors and AffiliationsDepartment of Radiology, Stanford University School of Medicine, 300 Pasteur Dr., H1307, Stanford, CA, 94305, USABhavik N. Patel, Safwan Halabi, Curtis Langlotz, Edward Lo, A. J. Mariano, Geoffrey Riley, Jayne Seekins, Luyao Shen, Evan Zucker & Matthew P. LungrenUnanimous AI, 2443 Fillmore Street #116, San Francisco, CA, 94115-1814, USALouis Rosenberg, Gregg Willcox, David Baltaxe & Mimi LyonsDepartment of Computer Science, Stanford University School of Medicine, 353 Serra Mall (Gates Building), Stanford, CA, 94305, USAJeremy Irvin & Pranav RajpurkarDepartment of Radiology, Duke University Medical Center, Box 3808 Erwin Rd, Durham, NC, 27710, USATimothy Amrhein, Rajan Gupta & Joseph MammarappallilAuthorsBhavik N. PatelView author publicationsYou can also search for this author in
                        PubMed Google ScholarLouis RosenbergView author publicationsYou can also search for this author in
                        PubMed Google ScholarGregg WillcoxView author publicationsYou can also search for this author in
                        PubMed Google ScholarDavid BaltaxeView author publicationsYou can also search for this author in
                        PubMed Google ScholarMimi LyonsView author publicationsYou can also search for this author in
                        PubMed Google ScholarJeremy IrvinView author publicationsYou can also search for this author in
                        PubMed Google ScholarPranav RajpurkarView author publicationsYou can also search for this author in
                        PubMed Google ScholarTimothy AmrheinView author publicationsYou can also search for this author in
                        PubMed Google ScholarRajan GuptaView author publicationsYou can also search for this author in
                        PubMed Google ScholarSafwan HalabiView author publicationsYou can also search for this author in
                        PubMed Google ScholarCurtis LanglotzView author publicationsYou can also search for this author in
                        PubMed Google ScholarEdward LoView author publicationsYou can also search for this author in
                        PubMed Google ScholarJoseph MammarappallilView author publicationsYou can also search for this author in
                        PubMed Google ScholarA. J. MarianoView author publicationsYou can also search for this author in
                        PubMed Google ScholarGeoffrey RileyView author publicationsYou can also search for this author in
                        PubMed Google ScholarJayne SeekinsView author publicationsYou can also search for this author in
                        PubMed Google ScholarLuyao ShenView author publicationsYou can also search for this author in
                        PubMed Google ScholarEvan ZuckerView author publicationsYou can also search for this author in
                        PubMed Google ScholarMatthew P. LungrenView author publicationsYou can also search for this author in
                        PubMed Google ScholarContributionsAll authors contributed extensively to the work presented in this paper. B.N.P. and M.L. designed the experiments and wrote the manuscript while all other authors commented on the manuscript. L.R., G.W., D.B. and M.L. provided technical support. B.N.P., J.I., P.R., T.A., R.G., S.H., C.L., E.L., J.M., A.J.M., G.R., J.S., L.S., E.Z. and M.L. carried out experiments.Corresponding authorCorrespondence to
                Bhavik N. Patel.Ethics declarations
Competing interests
The authors had control of the data and the information submitted for publication. Four authors (L.R., D.B., G.W. and M.L.) are employees of Unanimous AI, who developed the swarm platform used in this study. All other authors are not employees of or consultants for Unanimous AI and had control of the study methodology, data analysis, and results. There was no industry support specifically for this study. This study was supported in part by NSF through Award ID 1840937.
Additional informationPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Supplementary informationReporting Summary ChecklistRights and permissions
Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.
Reprints and permissionsAbout this articleCite this articlePatel, B.N., Rosenberg, L., Willcox, G. et al. Human–machine partnership with artificial intelligence for chest radiograph diagnosis.
                    npj Digit. Med. 2, 111 (2019). https://doi.org/10.1038/s41746-019-0189-7Download citationReceived: 25 February 2019Accepted: 23 October 2019Published: 18 November 2019DOI: https://doi.org/10.1038/s41746-019-0189-7Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        
Subjects

Computer scienceRadiography





This article is cited by





                                        Deep Learning for Chest X-ray Diagnosis: Competition Between Radiologists with or Without Artificial Intelligence Assistance
                                    


Lili GuoChangsheng ZhouGuangming Lu

Journal of Imaging Informatics in Medicine (2024)




                                        Human–AI collaboration enables more empathic conversations in text-based peer-to-peer mental health support
                                    


Ashish SharmaInna W. LinTim Althoff

Nature Machine Intelligence (2023)




                                        Evaluating efficiency and accuracy of deep-learning-based approaches on study selection for psychiatry systematic reviews
                                    


Aaron J. GorelikMark G. GorelikManpreet K. Singh

Nature Mental Health (2023)




                                        DEEP MOVEMENT: Deep learning of movie files for management of endovascular thrombectomy
                                    


Brendan KellyMesha MartinezEdward H. Lee

European Radiology (2023)




                                        “I’m afraid I can’t let you do that, Doctor”: meaningful disagreements with AI in medical contexts
                                    


Hendrik KemptJan-Christoph HeilingerSaskia K. Nagel

AI & SOCIETY (2023)






",,,,,,,,,,,,,,"{'headline': 'Human–machine partnership with artificial intelligence for chest radiograph diagnosis', 'description': 'Human-in-the-loop (HITL) AI may enable an ideal symbiosis of human experts and AI models, harnessing the advantages of both while at the same time overcoming their respective limitations. The purpose of this study was to investigate a novel collective intelligence technology designed to amplify the diagnostic accuracy of networked human groups by forming real-time systems modeled on biological swarms. Using small groups of radiologists, the swarm-based technology was applied to the diagnosis of pneumonia on chest radiographs and compared against human experts alone, as well as two state-of-the-art deep learning AI models. Our work demonstrates that both the swarm-based technology and deep-learning technology achieved superior diagnostic accuracy than the human experts alone. Our work further demonstrates that when used in combination, the swarm-based technology and deep-learning technology outperformed either method alone. The superior diagnostic accuracy of the combined HITL AI solution compared to radiologists and AI alone has broad implications for the surging clinical AI deployment and implementation strategies in future practice.', 'datePublished': '2019-11-18T00:00:00Z', 'dateModified': '2019-12-10T00:00:00Z', 'pageStart': '1', 'pageEnd': '10', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'sameAs': 'https://doi.org/10.1038/s41746-019-0189-7', 'keywords': ['Computer science', 'Radiography', 'Medicine/Public Health', 'general', 'Biomedicine', 'Biotechnology'], 'image': ['https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-019-0189-7/MediaObjects/41746_2019_189_Fig1_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-019-0189-7/MediaObjects/41746_2019_189_Fig2_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-019-0189-7/MediaObjects/41746_2019_189_Fig3_HTML.jpg', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-019-0189-7/MediaObjects/41746_2019_189_Fig4_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-019-0189-7/MediaObjects/41746_2019_189_Fig5_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-019-0189-7/MediaObjects/41746_2019_189_Fig6_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-019-0189-7/MediaObjects/41746_2019_189_Fig7_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-019-0189-7/MediaObjects/41746_2019_189_Fig8_HTML.png'], 'isPartOf': {'name': 'npj Digital Medicine', 'issn': ['2398-6352'], 'volumeNumber': '2', '@type': ['Periodical', 'PublicationVolume']}, 'publisher': {'name': 'Nature Publishing Group UK', 'logo': {'url': 'https://www.springernature.com/app-sn/public/images/logo-springernature.png', '@type': 'ImageObject'}, '@type': 'Organization'}, 'author': [{'name': 'Bhavik N. Patel', 'url': 'http://orcid.org/0000-0001-5157-9903', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'bhavikp@stanford.edu', '@type': 'Person'}, {'name': 'Louis Rosenberg', 'affiliation': [{'name': 'Unanimous AI', 'address': {'name': 'Unanimous AI, San Francisco, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Gregg Willcox', 'affiliation': [{'name': 'Unanimous AI', 'address': {'name': 'Unanimous AI, San Francisco, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'David Baltaxe', 'affiliation': [{'name': 'Unanimous AI', 'address': {'name': 'Unanimous AI, San Francisco, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Mimi Lyons', 'affiliation': [{'name': 'Unanimous AI', 'address': {'name': 'Unanimous AI, San Francisco, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Jeremy Irvin', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Computer Science, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Pranav Rajpurkar', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Computer Science, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Timothy Amrhein', 'url': 'http://orcid.org/0000-0002-9354-9486', 'affiliation': [{'name': 'Duke University Medical Center', 'address': {'name': 'Department of Radiology, Duke University Medical Center, Durham, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Rajan Gupta', 'affiliation': [{'name': 'Duke University Medical Center', 'address': {'name': 'Department of Radiology, Duke University Medical Center, Durham, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Safwan Halabi', 'url': 'http://orcid.org/0000-0003-1317-984X', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Curtis Langlotz', 'url': 'http://orcid.org/0000-0002-8972-8051', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Edward Lo', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Joseph Mammarappallil', 'affiliation': [{'name': 'Duke University Medical Center', 'address': {'name': 'Department of Radiology, Duke University Medical Center, Durham, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'A. J. Mariano', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Geoffrey Riley', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Jayne Seekins', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Luyao Shen', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Evan Zucker', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Matthew P. Lungren', 'affiliation': [{'name': 'Stanford University School of Medicine', 'address': {'name': 'Department of Radiology, Stanford University School of Medicine, Stanford, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}], 'isAccessibleForFree': True, '@type': 'ScholarlyArticle'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOGh0dHBzOi8vd3d3LnViZXIuY29tL2VuLUFVL2Jsb2cvYWktbWVldC10aGUtdGVhbS16aGFsZWgv0gEA?oc=5,Artificial Intelligence - Meet the Team - Uber,2019-11-20,Uber,https://www.uber.com,Uber’s AI team work on some amazing features within the app! Zhaleh’s team have been working on the hands-free voice assistant for drivers.,,Uber’s AI team work on some amazing features within the app! Zhaleh’s team have been working on the hands-free voice assistant for drivers.,Uber’s AI team work on some amazing features within the app! Zhaleh’s team have been working on the hands-free voice assistant for drivers.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vYmR0ZWNodGFsa3MuY29tLzIwMTkvMTEvMTgvd2hhdC1pcy1zeW1ib2xpYy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAVBodHRwczovL2JkdGVjaHRhbGtzLmNvbS8yMDE5LzExLzE4L3doYXQtaXMtc3ltYm9saWMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYW1wLw?oc=5,What is symbolic artificial intelligence? - TechTalks,2019-11-18,TechTalks,https://bdtechtalks.com,"Everything you need to know about symbolic artificial intelligence, the branch of AI that dominated for five decades.",,"Everything you need to know about symbolic artificial intelligence, the branch of AI that dominated for five decades.","Everything you need to know about symbolic artificial intelligence, the branch of AI that dominated for five decades.",http://schema.org,BreadcrumbList,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://bdtechtalks.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/category/what-is/', 'name': 'What is...'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/', 'name': 'What is symbolic artificial intelligence?'}}]",,,"

What is...

What is symbolic artificial intelligence?

By Ben Dickson -   November 18, 2019 




Facebook


Twitter


ReddIt


Linkedin




Image credit: Depositphotos
This article is part of Demystifying AI, a series of posts that (try to) disambiguate the jargon and myths surrounding AI.
Today, artificial intelligence is mostly about artificial neural networks and deep learning. But this is not how it always was. In fact, for most of its six-decade history, the field was dominated by symbolic artificial intelligence, also known as “classical AI,” “rule-based AI,” and “good old-fashioned AI.”
Symbolic AI involves the explicit embedding of human knowledge and behavior rules into computer programs. The practice showed a lot of promise in the early decades of AI research. But in recent years, as neural networks, also known as connectionist AI, gained traction, symbolic AI has fallen by the wayside.
The role of symbols in artificial intelligence
Symbols are things we use to represent other things. Symbols play a vital role in the human thought and reasoning process. If I tell you that I saw a cat up in a tree, your mind will quickly conjure an image.
We use symbols all the time to define things (cat, car, airplane, etc.) and people (teacher, police, salesperson). Symbols can represent abstract concepts (bank transaction) or things that don’t physically exist (web page, blog post, etc.). They can also describe actions (running) or states (inactive). Symbols can be organized into hierarchies (a car is made of doors, windows, tires, seats, etc.). They can also be used to describe other symbols (a cat with fluffy ears, a red carpet, etc.).
Being able to communicate in symbols is one of the main things that make us intelligent. Therefore, symbols have also played a crucial role in the creation of artificial intelligence.
The early pioneers of AI believed that “every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.” Therefore, symbolic AI took center stage and became the focus of research projects. Scientists developed tools to define and manipulate symbols.
Many of the concepts and tools you find in computer science are the results of these efforts. Symbolic AI programs are based on creating explicit structures and behavior rules.
An example of symbolic AI tools is object-oriented programming. OOP languages allow you to define classes, specify their properties, and organize them in hierarchies. You can create instances of these classes (called objects) and manipulate their properties. Class instances can also perform actions, also known as functions, methods, or procedures. Each method executes a series of rule-based instructions that might read and change the properties of the current and other objects.
Using OOP, you can create extensive and complex symbolic AI programs that perform various tasks.
The benefits and limits of symbolic AI
Symbolic artificial intelligence showed early progress at the dawn of AI and computing. You can easily visualize the logic of rule-based programs, communicate them, and troubleshoot them.
Flowcharts can depict the logic of symbolic AI programs very clearly
Symbolic artificial intelligence is very convenient for settings where the rules are very clear cut,  and you can easily obtain input and transform it into symbols. In fact, rule-based systems still account for most computer programs today, including those used to create deep learning applications.
But symbolic AI starts to break when you must deal with the messiness of the world. For instance, consider computer vision, the science of enabling computers to make sense of the content of images and video. Say you have a picture of your cat and want to create a program that can detect images that contain your cat. You create a rule-based program that takes new images as inputs, compares the pixels to the original cat image, and responds by saying whether your cat is in those images.
This will only work as you provide an exact copy of the original image to your program. A slightly different picture of your cat will yield a negative answer. For instance, if you take a picture of your cat from a somewhat different angle, the program will fail.
One solution is to take pictures of your cat from different angles and create new rules for your application to compare each input against all those images. Even if you take a million pictures of your cat, you still won’t account for every possible case. A change in the lighting conditions or the background of the image will change the pixel value and cause the program to fail. You’ll need millions of other pictures and rules for those.
And what if you wanted to create a program that could detect any cat? How many rules would you need to create for that?
The cat example might sound silly, but these are the kinds of problems that symbolic AI programs have always struggled with. You can’t define rules for the messy data that exists in the real world. For instance, how can you define the rules for a self-driving car to detect all the different pedestrians it might face?
Also, some tasks can’t be translated to direct rules, including speech recognition and natural language processing.
There have been several efforts to create complicated symbolic AI systems that encompass the multitudes of rules of certain domains. Called expert systems, these symbolic AI models use hardcoded knowledge and rules to tackle complicated tasks such as medical diagnosis. But they require a huge amount of effort by domain experts and software engineers and only work in very narrow use cases. As soon as you generalize the problem, there will be an explosion of new rules to add (remember the cat detection problem?), which will require more human labor. As some AI scientists point out, symbolic AI systems don’t scale.
Neural networks vs symbolic AI

Neural networks are almost as old as symbolic AI, but they were largely dismissed because they were inefficient and required compute resources that weren’t available at the time. In the past decade, thanks to the large availability of data and processing power, deep learning has gained popularity and has pushed past symbolic AI systems.
The advantage of neural networks is that they can deal with messy and unstructured data. Take the cat detector example. Instead of manually laboring through the rules of detecting cat pixels, you can train a deep learning algorithm on many pictures of cats. The neural network then develops a statistical model for cat images. When you provide it with a new image, it will return the probability that it contains a cat.
Deep learning and neural networks excel at exactly the tasks that symbolic AI struggles with. They have created a revolution in computer vision applications such as facial recognition and cancer detection. Deep learning has also driven advances in language-related tasks.
Deep neural networks are also very suitable for reinforcement learning, AI models that develop their behavior through numerous trial and error. This is the kind of AI that masters complicated games such as Go, StarCraft, and Dota.
But the benefits of deep learning and neural networks are not without tradeoffs. Deep learning has several deep challenges and disadvantages in comparison to symbolic AI. Notably, deep learning algorithms are opaque, and figuring out how they work perplexes even their creators. And it’s very hard to communicate and troubleshoot their inner-workings.
Neural networks are also very data-hungry. And unlike symbolic AI, neural networks have no notion of symbols and hierarchical representation of knowledge. This limitation makes it very hard to apply neural networks to tasks that require logic and reasoning, such as science and high-school math.
The current state of symbolic AI
Some believe that symbolic AI is dead. But this assumption couldn’t be farther from the truth. In fact, rule-based AI systems are still very important in today’s applications. Many leading scientists believe that symbolic reasoning will continue to remain a very important component of artificial intelligence.
There are now several efforts to combine neural networks and symbolic AI. One such project is the Neuro-Symbolic Concept Learner (NSCL), a hybrid AI system developed by the MIT-IBM Watson AI Lab. NSCL uses both rule-based programs and neural networks to solve visual question-answering problems. As opposed to pure neural network–based models, the hybrid AI can learn new tasks with less data and is explainable. And unlike symbolic-only models, NSCL doesn’t struggle to analyze the content of images.
Maybe in the future, we’ll invent AI technologies that can both reason and learn. But for the moment, symbolic AI is the leading method to deal with problems that require logical thinking and knowledge representation.
Like this:Like Loading... 


TAGSArtificial intelligence (AI)Demystifying AIsymbolic artificial intelligence 


Facebook


Twitter


ReddIt


Linkedin


 Previous articleHow does Google Stadia compare to hardware gaming?Next articleSocial artificial intelligence: intuitive or intrusive? Ben DicksonBen is a software engineer and the founder of TechTalks. He writes about technology, business and politics.




  
",,,,"[{'@type': 'BlogPosting', '@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#blogposting', 'name': 'What is symbolic artificial intelligence? - TechTalks', 'headline': 'What is symbolic artificial intelligence?', 'author': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'publisher': {'@id': 'https://bdtechtalks.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2019/11/human-brain-gears.jpg?fit=4300%2C2580&ssl=1', 'width': 4300, 'height': 2580, 'caption': 'Image credit: Depositphotos'}, 'datePublished': '2019-11-18T14:00:25+00:00', 'dateModified': '2019-11-17T17:29:21+00:00', 'inLanguage': 'en-US', 'commentCount': 3, 'mainEntityOfPage': {'@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#webpage'}, 'isPartOf': {'@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#webpage'}, 'articleSection': 'What is..., Artificial intelligence (AI), Demystifying AI, symbolic artificial intelligence, bendee983'}, {'@type': 'BreadcrumbList', '@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://bdtechtalks.com/#listItem', 'position': 1, 'name': 'Home', 'item': 'https://bdtechtalks.com/', 'nextItem': 'https://bdtechtalks.com/2019/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2019/#listItem', 'position': 2, 'name': '2019', 'item': 'https://bdtechtalks.com/2019/', 'nextItem': 'https://bdtechtalks.com/2019/11/#listItem', 'previousItem': 'https://bdtechtalks.com/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2019/11/#listItem', 'position': 3, 'name': 'November', 'item': 'https://bdtechtalks.com/2019/11/', 'nextItem': 'https://bdtechtalks.com/2019/11/18/#listItem', 'previousItem': 'https://bdtechtalks.com/2019/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2019/11/18/#listItem', 'position': 4, 'name': '18', 'item': 'https://bdtechtalks.com/2019/11/18/', 'nextItem': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#listItem', 'previousItem': 'https://bdtechtalks.com/2019/11/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#listItem', 'position': 5, 'name': 'What is symbolic artificial intelligence?', 'previousItem': 'https://bdtechtalks.com/2019/11/18/#listItem'}]}, {'@type': 'Organization', '@id': 'https://bdtechtalks.com/#organization', 'name': 'TechTalks', 'description': 'Technology solving problems... and creating new ones', 'url': 'https://bdtechtalks.com/'}, {'@type': 'Person', '@id': 'https://bdtechtalks.com/author/bendee983/#author', 'url': 'https://bdtechtalks.com/author/bendee983/', 'name': 'Ben Dickson', 'image': {'@type': 'ImageObject', '@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#authorImage', 'url': 'https://secure.gravatar.com/avatar/5184782561a26df20cb56c8eb87eef27?s=96&d=identicon&r=g', 'width': 96, 'height': 96, 'caption': 'Ben Dickson'}}, {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#webpage', 'url': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/', 'name': 'What is symbolic artificial intelligence? - TechTalks', 'description': 'Everything you need to know about symbolic artificial intelligence, the branch of AI that dominated for five decades.', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://bdtechtalks.com/#website'}, 'breadcrumb': {'@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#breadcrumblist'}, 'author': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'creator': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2019/11/human-brain-gears.jpg?fit=4300%2C2580&ssl=1', '@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#mainImage', 'width': 4300, 'height': 2580, 'caption': 'Image credit: Depositphotos'}, 'primaryImageOfPage': {'@id': 'https://bdtechtalks.com/2019/11/18/what-is-symbolic-artificial-intelligence/#mainImage'}, 'datePublished': '2019-11-18T14:00:25+00:00', 'dateModified': '2019-11-17T17:29:21+00:00'}, {'@type': 'WebSite', '@id': 'https://bdtechtalks.com/#website', 'url': 'https://bdtechtalks.com/', 'name': 'TechTalks', 'description': 'Technology solving problems... and creating new ones', 'inLanguage': 'en-US', 'publisher': {'@id': 'https://bdtechtalks.com/#organization'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTkvMTEvMTkvdGVjaG5vbG9neS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1kYXduLXNvbmcuaHRtbNIBAA?oc=5,Building a World Where Data Privacy Exists Online (Published 2019) - The New York Times,2019-11-19,The New York Times,https://www.nytimes.com,"Dawn Song, an expert in computer security and trustworthy artificial intelligence, is working on making that vision a reality.",,"Dawn Song, an expert in computer security and trustworthy artificial intelligence, is working on making that vision a reality.","Dawn Song, an expert in computer security and trustworthy artificial intelligence, is working on making that vision a reality.",https://schema.org,NewsMediaOrganization,https://www.nytimes.com/2019/11/19/technology/artificial-intelligence-dawn-song.html,Building a World Where Data Privacy Exists Online,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/11/20/multimedia/20sp-women-song-1/20sp-women-song-1-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2019/11/20/multimedia/20sp-women-song-1/20sp-women-song-1-videoSixteenByNineJumbo1600.jpg', 'caption': 'Dawn Song, a professor at the University of California, Berkeley, is an expert in computer security and trustworthy artificial intelligence.', 'creditText': 'Jason Henry for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/11/20/multimedia/20sp-women-song-1/merlin_163691466_e9950b00-e8da-4d87-a704-514a4c31dfd1-superJumbo.jpg', 'height': 1638, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2019/11/20/multimedia/20sp-women-song-1/merlin_163691466_e9950b00-e8da-4d87-a704-514a4c31dfd1-superJumbo.jpg', 'caption': 'Dawn Song, a professor at the University of California, Berkeley, is an expert in computer security and trustworthy artificial intelligence.', 'creditText': 'Jason Henry for The New York Times'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/craig-s-smith', 'name': 'Craig S. Smith'}]",2019-11-10T13:00:14.000Z,2019-11-19T14:50:07.000Z,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,Technology,,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTBuilding a World Where Data Privacy Exists OnlineDawn Song, an expert in computer security and trustworthy artificial intelligence, is working on making that vision a reality.Share full articleRead in appDawn Song, a professor at the University of California, Berkeley, is an expert in computer security and trustworthy artificial intelligence.Credit...Jason Henry for The New York TimesBy Craig S. SmithPublished Nov. 10, 2019Updated Nov. 19, 2019This article is part of our Women and Leadership special section, which focuses on approaches taken by women, minorities or other disadvantaged groups challenging traditional ways of thinking.Data is valuable — something that companies like Facebook, Google and Amazon realized far earlier than most consumers did. But computer scientists have been working on alternative models, even as the public has grown weary of having their data used and abused.Dawn Song, a professor at the University of California, Berkeley, and one of the world’s foremost experts in computer security and trustworthy artificial intelligence, envisions a new paradigm in which people control their data and are compensated for its use by corporations. While there have been many proposals for such a system, Professor Song is one actually building the platform to make it a reality.“As we talk about data as the new oil, it’s particularly important to develop technologies that can utilize data in a privacy-preserving way,” Professor Song said recently from her San Francisco office with an expansive view of the bay.AdvertisementSKIP ADVERTISEMENTIt is an unlikely trajectory for Professor Song, who grew up in Dalian, China, a seaport in the northeastern province of Liaoning. She is the daughter of two local civil servants with no background in computers. And while she was an exceptional student in high school, she dreamed of being a National Geographic-style nature photographer. One of her teachers, a mentor, gently dissuaded her.Her mother wanted her to study business and filled out an application on her behalf for a well-known business school. Then, shortly before the national college entrance exams, her mentor intervened again, convincing her mother that a brighter future lay ahead for her daughter in science. Professor Song applied instead to Tsinghua University, China’s top science university, to study physics. She went on to study physics at Cornell University but transferred to Carnegie Mellon University, where she received an M.S. in computer science before settling at Berkeley to finally finish her Ph.D. in computer science. By then, she was focused on computer security.Professor Song drew attention while still a graduate student at Berkeley with pioneering work that showed a machine-learning algorithm can infer what someone is typing from the timing of their keystrokes picked up by eavesdropping on a network. Since then, she has been at the forefront of trustworthy A.I., including improving the resilience of machine-learning models themselves, the recursive blocks of computer code that learn to recognize patterns in the data they consume.ImageProfessor Song with examples of stop signs that, with a few stickers attached, were able to fool computer-vision systems.Credit...Jason Henry for The New York TimesMachine-learning models, as amazing as they are at identifying everything from tumors in X-ray images to words in slurred speech, remain disturbingly easy to fool. Professor Song and her students were the first ones to demonstrate that computer-vision systems could be fooled into identifying a stop sign as a 40-miles-per-hour speed limit sign simply by applying a few innocuous stickers to the sign. Examples of these altered traffic signs have been on exhibit at London’s Science Museum.AdvertisementSKIP ADVERTISEMENT“Her work on the stop sign was among the first to craft adversarial examples in the physical domain rather than just manipulating image pixels on a computer,” said Battista Biggio, an assistant professor at Italy’s University of Cagliari and one of the first people to study the vulnerabilities of such systems.Professor Song, who has taught at Berkeley for a dozen years, has been working to develop techniques and systems that not only can provide security to computer systems, but also privacy. She envisions a world of secure networks where individuals control their personal data and even derive income from it. She compares the world today to a time in human history when people did not have a clear notion of property rights. Once those rights were institutionalized and protected, she notes, it helped revolutionize economies.She recently started a company, Oasis Labs, that is building a platform that can give people the ability to control their data and audit how it is used. She believes that once data is viewed as property, it can propel the global economy in ways unseen before. “New business models can be built on this,” she said.Data, of course, is not like a physical object. If a person gives a friend an apple, then someone else cannot have that apple. But data is different, with a property that scientists call nonrivalry. People can give (or sell) as many copies as they want.AdvertisementSKIP ADVERTISEMENTMost people give away their data, signing it over to companies by clicking “accept,” not even bothering to read the fine print. Either people online accept the terms and participate in the digital world or they unplug — something that is not really an option for anyone operating in the global economy. Fortunes were built on that data, enriching a handful of entrepreneurs.“Our data has never been more at risk, and our need for new kinds of robust privacy solutions has never been greater,” said Guy Zyskind, co-founder and chief executive of Enigma, another company building a decentralized private computation protocol.When people go online, data is collected and stored on centralized servers that are vulnerable to attack. But Professor Song and her colleagues believe that by marrying specialized computer chips and blockchain technology, they can build a system that provides greater scalability and privacy protection.ImageProfessor Song with Bennet Yee, left, and Rebekah Kim, right, both software engineers at Oasis Labs in San Francisco.Credit...Jason Henry for The New York TimesSome computer chips — those in most cellphones, for example — already incorporate a secure zone, called a trusted execution environment, that protects software from most kinds of attack. Professor Song’s group is working on enhancing the security of those zones by building an open-source secure enclave, Keystone. Within the secure enclave, bits of computer code, called smart contracts, allow data owners to control who has access to their data and how it is used.AdvertisementSKIP ADVERTISEMENT“You can actually have the integrity that the blockchain ledger provides and also you can have privacy or confidentiality for the smart contract execution that’s provided by the secure enclave,” said Professor Song, who speaks rapidly as if rushing to keep pace with her thoughts. “No central server ever sees the data.”Oasis Labs has been building a platform to support enterprises and developers. They have begun a pilot with Nebula Genomics, a direct-to-consumer gene-sequencing company, that offers whole genome sequencing reports on ancestry, wellness, and genetic traits with weekly updates. Using Oasis Labs’ privacy-preserving tools, Nebula customers will retain full control and ownership over their genomic data, while enabling Nebula to run specific analysis on the data without exposing the underlying information.Another application, called  Kara, a collaboration with Dr. Robert Chang at the Stanford University School of Medicine, gives eye patients the option to share retina scans and other medical data with researchers who use the data to train machine-learning models to recognize disease. Part of the Kara project is studying what kind of incentives patients will find meaningful in return for contributing their data for medical research.“Her approach is unique from other data aggregators,” Dr. Chang said. “This project is really asking the important question — who really owns the data?”AdvertisementSKIP ADVERTISEMENTSomeday, Professor Song believes, people will have an individual revenue stream from their data. It may not be significant on a monthly or even annual basis, but the fees that accumulate over the course of a lifetime from companies using personal data could contribute to retirement savings, for example. Or revenue from groups of people could be used to fund particular causes. The unlocking of data, meanwhile, could lead to improved services for consumers.“Today, companies are taking users’ data and essentially using it as a product; they monetize it,” Professor Song said. “The world can be very different if this is turned around and users maintain control of the data and get revenue from it.”Craig S. Smith is a former correspondent for The Times and now hosts the podcast Eye on A.I.A version of this article appears in print on Nov. 18, 2019 in The New York Times International Edition. Order Reprints | Today’s Paper | SubscribeShare full articleRead in appAdvertisementSKIP ADVERTISEMENTTell us about yourself. Take the survey.",The New York Times,,,,https://www.nytimes.com/,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://en.wikipedia.org/wiki/The_New_York_Times,https://www.nytimes.com/#publisher,,,,,,en-US,Turning the tables,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy5hdW50bWlubmllLmNvbS9pbWFnaW5nLWluZm9ybWF0aWNzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2FydGljbGUvMTU2MjQ2NzAvbXVsdGlwbGUtYWktYWxnb3JpdGhtcy13b3JrLWJldHRlci10b2dldGhlctIBAA?oc=5,Multiple AI algorithms work better together - AuntMinnie,2019-11-20,AuntMinnie,https://www.auntminnie.com,"Employing multiple artificial intelligence (AI) algorithms to attack a task together results in better performance compared with using a single AI algorithm on its own, according to a study published online November 20 in Radiology: Artificial Intelligence.",,"Employing multiple artificial intelligence (AI) algorithms to attack a task together results in better performance compared with using a single AI algorithm on its own, according to a study published online November 20 in Radiology: Artificial Intelligence.","Employing multiple artificial intelligence (AI) algorithms to attack a task together results in better performance compared with using a single AI algorithm on its own, according to a study published online November 20 in Radiology: Artificial Intelligence.",https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.auntminnie.com/imaging-informatics/artificial-intelligence/article/15624670/multiple-ai-algorithms-work-better-together'}",Multiple AI algorithms work better together,['https://img.auntminnie.com/files/base/smg/all/image/2019/11/am.2017_03_30_10_29_47_941_computer_data_400.png?auto=format%2Ccompress&fit=max&q=70&w=1200'],"{'@type': 'Person', 'name': 'Brian Casey'}",2019-11-21T00:00:00.000Z,2019-11-20T17:31:00.000Z,,,,,"Imaging InformaticsArtificial IntelligenceMultiple AI algorithms work better togetherBrian CaseyNov 20, 2019Facebook IconLinkedIn IconTwitter X iconPinterest Icon
Employing multiple artificial intelligence (AI) algorithms to attack a task together results in better performance compared with using a single AI algorithm on its own, according to a study published online November 20 in Radiology: Artificial Intelligence.
Called ensemble learning, the technique is designed to combine the best aspects of multiple machine learning algorithms into a single model to perform a task, such as identifying suspicious lung lesions or estimating bone age based on skeletal x-rays. Ensemble learning works best when each of the models performs well in their own right and correlation between the predictions of each model is relatively low.
To test ensemble learning, a research team led by medical student Ian Pan of the Warren Alpert Medical School at Brown University in Providence, RI, started with 48 algorithms that were submitted as part of the RSNA's pediatric bone age challenge competition at RSNA 2017.
They then used combinations of up to 10 algorithms at a time that were trained on a dataset of over 12,000 pediatric hand x-rays in which radiologists had determined true bone age. Then, the ensemble combinations were used to analyze 200 x-rays, with the combined model producing a mean absolute deviation (MAD) of bone age, with higher deviation indicating less accuracy.
The group found that a single algorithm had a mean absolution deviation of 4.55 months, while the best-performing ensemble -- consisting of four algorithms -- had a MAD of 3.79 months.
Pan et al noted that the findings could be important as artificial intelligence begins to transition from research environments to clinical settings. Clinicians might benefit from using different AI algorithms on the same task, much like having multiple radiologists interpret an image.
The researchers also believe that competitions like the 2017 bone age challenge are important because they provide a standardized use case, a common training set, and an objective assessment method that can be applied equally to all models.
""Machine learning competitions within radiology should be encouraged to spur development of heterogeneous models whose predictions can be combined to achieve optimal performance,"" Pan noted.Facebook IconLinkedIn IconTwitter X iconPinterest Icon Stay in the Know Delivered right to your inbox, Aunt Minnie's newsletters. Subscribe to get exclusive access! Email Address *I have read and agree to the privacy policy & terms of service and wish to opt-in. Sign Up  Comments  Post a Comment  You must be signed in to leave a comment. To sign in or create an account, enter your email address and we'll send you a one-click sign-in link.  Email Address * Continue  This article hasn’t received any comments yet. Want to start the conversation? View All CommentsLatest in Artificial IntelligenceBreast Cancer Canada launches research funding fellowshipJuly 15, 2024AI in radiology: The kids are alrightJuly 15, 2024Experts outline how best to deploy AI in radiologyJuly 11, 2024AI improves evaluations of knee osteoarthritis on x-raysJuly 9, 2024Related StoriesDigital X-RayThai researchers bolster forensic radiology studies with AIDigital X-RayAI aids assessment of skeletal age on radiographsArtificial IntelligencePractical Considerations of AI: Part 6 -- Ready, fire, aimDigital X-RayDeep-learning algorithm bolsters lung cancer detection",Multiple AI algorithms work better together,https://img.auntminnie.com/files/base/smg/all/image/2019/11/am.2017_03_30_10_29_47_941_computer_data_400.png?auto=format%2Ccompress&fit=max&q=70&w=1200,,,https://www.auntminnie.com/imaging-informatics/artificial-intelligence/article/15624670/multiple-ai-algorithms-work-better-together,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmdlZWt3aXJlLmNvbS8yMDE5L3N0dWR5LXN1Z2dlc3RzLWFpcy1kaXNydXB0aXZlLWVmZmVjdC1qb2JzLXdpbGwtaGl0LWhpZ2hlci1lY29ub21pYy1lZHVjYXRpb24tc2NhbGVzL9IBAA?oc=5,Study suggests AI's disruptive effect on jobs will hit higher on economic and education scales - GeekWire,2019-11-20,GeekWire,https://www.geekwire.com,"When experts talk about the disruptive effects of artificial intelligence, they tend to focus on low-paid laborers — but a newly published study suggests",,"When experts talk about the disruptive effects of artificial intelligence, they tend to focus on low-paid laborers — but a newly published study suggests",,https://schema.org,,,,,,,,,,,,"


Study suggests AI’s disruptive effect on jobs will hit higher on economic and education scales
by Alan Boyle on November 20, 2019 at 2:56 pmNovember 20, 2019 at 3:32 pm




 Share  11
 Tweet
 Share
 Reddit
 Email




Subscribe to GeekWire Newsletters today!






 
 

BOT or NOT? This special series explores the evolving relationship between humans and machines, examining the ways that robots, artificial intelligence and automation are impacting our work and lives.






A map by the Brookings Institution uses shades of pink and red to indicate which cities are expected to be hard-hit by job disruption related to AI. (Brookings Graphic / Source: Brookings Analysis of Webb, 2019)
When experts talk about the disruptive effects of artificial intelligence, they tend to focus on low-paid laborers — but a newly published study suggests higher-paid, more highly educated workers will be increasingly exposed to job challenges.
The study puts Seattle toward the top of the list for AI-related job disruption.
The analysis, which draws on work by researchers at Stanford University and the Brookings Institution, makes use of a novel technique that connects AI-related patents with the job descriptions for different professions.
Stanford researcher Michael Webb extracted entries from the tens of millions of patents in a Google database, as well as the 964 job descriptions indexed by the U.S. Department of Labor.
The goal was to match up noun-verb descriptions from the patents related to automation and AI with the job descriptions, on the theory that a particular job might face more exposure to future disruption if there are more patents associated with the description of that job.
For example, a patent for a device that monitors the operating conditions of power equipment could affect someone whose job description mentions monitoring operating conditions of equipment at a wastewater treatment plant. If there are a lot of patents for such devices, that would increase the job exposure index in Webb’s analytical model.
Webb looked at job exposure assessments for robotics, software applications and AI, and ranked the highest and lowest job exposure for each category:

Robotics: High-exposure occupations included forklift drivers, crane operators and janitors. Low-exposure occupations included payroll clerks, art/entertainment performers and clergy.
Software: High-exposure occupations: broadcast equipment operators, water and sewage treatment plant operators, parking lot attendants, and packers and packagers by hand. Low-exposure: barbers, podiatrists, college instructors and postal carriers.
AI: High-exposure occupations: clinical lab technicians, chemical engineers, optometrists, power plant operators. Low-exposure: non-farm animal caretakers, food preparation workers, college instructors, art/entertainment performers.

Why did highly skilled workers such as lab technicians end up on top of the AI list? Webb noted that AI is getting better and better at matching human performance in some of these jobs. In contrast, some job categories that may seem closely related — for example, lab researchers — “involve reasoning about situations that have never been seen before.” Others, such as food preparation or massage therapy, require the sorts of interpersonal skills that aren’t as suited for AI.
Lawyers who interact with the public have less to worry about than paralegals who merely review documents. Podiatrists who make judgment calls about patients’ feet have less to worry about optometrists whose diagnostic processes are easier to computerize. “Optometry is the area of medicine that has seen perhaps the most success of AI algorithms to date,” Webb wrote.
The Brookings Institution built upon Webb’s study by looking at how job exposure was distributed geographically, demographically and across occupational groups. For AI, the exposure scores are highest for agriculture, engineering and science. They’re lowest for education, food service and personal care.
Job exposure is relatively higher for men as opposed to women, for white and Asian-American workers as opposed to black and Hispanic/Latino workers, and for workers in the 25-64 age bracket as opposed to workers who are younger or older.
Bigger, higher-tech metro areas and manufacturing centers are more prone to AI job disruption. As a result, the Seattle area and California’s Silicon Valley have high scores on the disruption scale — but not as high as, say, Elkhart, an Indiana city that’s considered the nation’s capital of RV manufacturing.

Webb’s calculations suggest that AI’s effect on high-wage occupations will have an impact on the nation’s income inequality — up to a point. “Under the assumption that the historical pattern of long-run substitution will continue, I estimate that AI will reduce 90-10 wage inequality, but will not affect the top 1%,” he said.
He and his colleagues at Brookings acknowledged that there’s still a lot of uncertainty about how AI will play out. Changes in population trends, investment levels or education programs could reduce job exposure, or heighten it. And the rise of AI could well lead to new products, services and occupations.
“While the present assessment predicts areas of work in which some kind of impact is expected, it doesn’t specifically predict whether AI will substitute for existing work, complement it, or create entirely new work for humans,” the Brookings Institution’s research team said. “That means much more inquiry — qualitative and empirical — is needed to tease out AI’s special genius and coming impacts.”
For the full details, check out Webb’s study, “The Impact of Artificial Intelligence on the Labor Market,” and the Brookings report, “What Jobs Are Affected by AI?”


Message from the UnderwriterPutting AI-driven insights, productivity tools,
and security in the hands of businesses

We’re all experiencing a real-time revolution with the rise of generative AI. The opportunity is huge—but it requires a new approach to cloud computing. Organizations are already leveraging Google Cloud’s AI capabilities to unlock data, lower costs, embrace hybrid work, and protect against threats.
Learn how they’re succeeding at Transform with Google Cloud.
Learn more about underwritten and sponsored content on GeekWire.
More Bot or NotHow clean tech companies can take advantage of AI — without draining energy from the planetAI has trouble identifying sarcasm from Seattle satirical news site The Needling‘We know something big is happening’: Tech vets encourage experimentation, education with AIGeekWire contributing editor Alan Boyle is an award-winning science writer and veteran space reporter. Formerly of NBCNews.com, he is the author of ""The Case for Pluto: How a Little Planet Made a Big Difference."" Follow him via CosmicLog.com, on Twitter @b0yle, and on Facebook and MeWe. Reach him via email at alan@geekwire.com. 
 Share  11
 Tweet
 Share
 Reddit
 Email




Previous StoryAmazon defends Ring’s relationship with police as U.S. senator resurfaces privacy concerns 

Next StorySpotify opens its free tier to Amazon Alexa devices, as Sonos acquires voice assistant startup Snips 

 Filed Under: Bot or Not • Science  Tagged With: AI • artificial intelligence • Employment








GeekWire Newsletters

Subscribe to GeekWire's free newsletters to catch every headline




Email address

Subscribe







GeekWire Daily - Top headlines daily
                                    




GeekWire Weekly - Most-read stories of the week, delivered Sunday
                                    




Breaking News Alerts - Important news as it happens
                                    




GeekWire Startups - News, analysis, insights from the Pacific Northwest startup ecosystem, delivered Friday
                                    




GeekWire Mid-week Update — Most-read stories so far this week, delivered Wednesday
                                    




GeekWire Local Deals — Special offers for Pacific Northwest area readers
                                    







Send Us a Tip
Have a scoop that you'd like GeekWire to cover? Let us know.

Send Us a Tip








",,,,"[{'@type': 'NewsArticle', '@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/#article', 'isPartOf': {'@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/'}, 'author': [{'@id': 'https://www.geekwire.com/#/schema/person/9641ab4b8b61dd1b5a6d0ebc6236d5ab'}], 'headline': 'Study suggests AI&#8217;s disruptive effect on jobs will hit higher on economic and education scales', 'datePublished': '2019-11-20T22:56:12+00:00', 'dateModified': '2019-11-20T23:32:45+00:00', 'mainEntityOfPage': {'@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/'}, 'wordCount': 844, 'commentCount': 0, 'publisher': {'@id': 'https://www.geekwire.com/#organization'}, 'image': {'@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/#primaryimage'}, 'thumbnailUrl': 'https://cdn.geekwire.com/wp-content/uploads/2019/11/191120-jobs3.jpg', 'keywords': ['AI', 'artificial intelligence', 'Employment'], 'articleSection': ['Bot or Not', 'Science'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/', 'url': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/', 'name': ""Study suggests AI's disruptive effect on jobs will hit higher on economic and education scales &#8211; GeekWire"", 'isPartOf': {'@id': 'https://www.geekwire.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/#primaryimage'}, 'image': {'@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/#primaryimage'}, 'thumbnailUrl': 'https://cdn.geekwire.com/wp-content/uploads/2019/11/191120-jobs3.jpg', 'datePublished': '2019-11-20T22:56:12+00:00', 'dateModified': '2019-11-20T23:32:45+00:00', 'description': 'When experts talk about the disruptive effects of artificial intelligence, they tend to focus on low-paid laborers — but a newly published study suggests', 'breadcrumb': {'@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/#primaryimage', 'url': 'https://cdn.geekwire.com/wp-content/uploads/2019/11/191120-jobs3.jpg', 'contentUrl': 'https://cdn.geekwire.com/wp-content/uploads/2019/11/191120-jobs3.jpg', 'width': 1113, 'height': 677, 'caption': 'A map by the Brookings Institution uses shades of pink and red to indicate which cities are expected to be hard-hit by job disruption related to AI. (Brookings Institution Graphic / Source: Brookings Analysis of Webb, 2019)'}, {'@type': 'BreadcrumbList', '@id': 'https://www.geekwire.com/2019/study-suggests-ais-disruptive-effect-jobs-will-hit-higher-economic-education-scales/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.geekwire.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Bot or Not', 'item': 'https://www.geekwire.com/bot-or-not/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Study suggests AI&#8217;s disruptive effect on jobs will hit higher on economic and education scales'}]}, {'@type': 'WebSite', '@id': 'https://www.geekwire.com/#website', 'url': 'https://www.geekwire.com/', 'name': 'GeekWire', 'description': 'Breaking News in Technology &amp; Business', 'publisher': {'@id': 'https://www.geekwire.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.geekwire.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.geekwire.com/#organization', 'name': 'GeekWire', 'url': 'https://www.geekwire.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/#/schema/logo/image/', 'url': 'https://cdn.geekwire.com/wp-content/uploads/2017/10/GeekWire-Logo.png', 'contentUrl': 'https://cdn.geekwire.com/wp-content/uploads/2017/10/GeekWire-Logo.png', 'width': 400, 'height': 400, 'caption': 'GeekWire'}, 'image': {'@id': 'https://www.geekwire.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/geekwire', 'https://x.com/geekwire', 'https://www.instagram.com/geekwire/', 'https://www.youtube.com/geekwire', 'https://www.pinterest.com/geekwire/', 'https://en.wikipedia.org/wiki/GeekWire', 'https://www.linkedin.com/company/geekwire/']}, {'@type': 'Person', '@id': 'https://www.geekwire.com/#/schema/person/9641ab4b8b61dd1b5a6d0ebc6236d5ab', 'name': 'Alan Boyle', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/#/schema/person/image/fe58e4d63645669100f65958faeb8f2f', 'url': 'https://secure.gravatar.com/avatar/8aeeff7d40870308f9c2c5796cd026d0?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8aeeff7d40870308f9c2c5796cd026d0?s=96&d=mm&r=g', 'caption': 'Alan Boyle'}, 'description': 'Alan Boyle is an award-winning science writer and space reporter and GeekWire contributing editor. Formerly of NBCNews.com, he is the author of ""The Case for Pluto: How a Little Planet Made a Big Difference."" Follow him via CosmicLog.com, on Twitter @b0yle,\xa0on Facebook and on MeWe.', 'sameAs': ['https://cosmiclog.com/', 'https://www.facebook.com/alan.boyle', 'https://instagram.com/alanb0yle', 'https://www.linkedin.com/in/alan-boyle-97a874', 'https://x.com/b0yle', 'https://en.wikipedia.org/wiki/Alan_Boyle'], 'url': 'https://www.geekwire.com/author/alanboyle/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LnNlYXR0bGV0aW1lcy5jb20vYnVzaW5lc3MvdGVjaG5vbG9neS9zdHVkeS1zdWdnZXN0cy13aGl0ZS1jb2xsYXItd29ya2Vycy13aWxsLWJlLW1vc3QtYWZmZWN0ZWQtaW4tdGhlLW5ldy1lY29ub215L9IBAA?oc=5,"White collar workers will be most affected by AI in the new economy, study suggests - The Seattle Times",2019-11-19,The Seattle Times,https://www.seattletimes.com,"The Brookings Institution report revealed that workers with higher education and wages will experience the greatest changes in their jobs due to AI, for better or worse. Washington state stood...",,"The Brookings Institution report revealed that workers with higher education and wages will experience the greatest changes in their jobs due to AI, for better or worse. Washington state stood out in the state-by-state comparison of the role of AI,...","The Brookings Institution report revealed that workers with higher education and wages will experience the greatest changes in their jobs due to AI, for better or worse. Washington state stood out in the state-by-state comparison of the role of AI,...",https://schema.org,BreadcrumbList,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.seattletimes.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Technology', 'item': 'https://www.seattletimes.com/business/technology/'}, {'@type': 'ListItem', 'position': 3, 'name': 'White collar workers will be most affected by AI in the new economy, study suggests'}]",,,"


BusinessTechnology 

    White collar workers will be most affected by AI in the new economy, study suggests  

 Nov. 19, 2019 at 9:01 pm  Updated Nov. 25, 2019 at 7:47 pm  







 

Skip Ad 


 
By 

Melissa Hellmann

Seattle Times staff reporter 


In 2015, Stanford University Ph.D. student Michael Webb watched as his classmates in the computer science program became increasingly interested in the advancements of artificial intelligence (AI). An outlier, he was more focused on the economic implications of the technologies.But there was a dearth of reports that solely focused on the impact AI has on different sectors and occupations. Instead, most analyses generalized technology to include a wide range of automation and software.Although often used interchangeably, AI and automation are not one and the same: AI technologies are designed to mimic human thinking and actions, while automation performs repetitive tasks.The A.I. Age | This 12-month series of stories explores the social and economic questions arising from the fast-spreading uses of artificial intelligence. The series is funded with the help of the Harvard-MIT Ethics and Governance of AI Initiative. Seattle Times editors and reporters operate independently of our funders and maintain editorial control over the coverage.Then it struck Webb to analyze the overlap between the language in patents — which offer insight into the commercial use of technologies — and the text of job descriptions, which provide a wide-ranging view of the labor market.Equipped with a blueprint, Webb set about to create a machine learning system that would accurately shed light on the economic impacts of a rapidly changing field. His results were the basis of a new report by the D.C.-based research group Brookings Institution focused on the potential impact of AI on the workforce.Webb’s findings revealed that workers with higher education and wages will experience the greatest changes in their jobs due to AI, for better or worse.
Advertising

Skip AdSkip AdSkip Ad 

“While earlier waves of automation have led to disruption across the lower half of the wage distribution, AI appears likely to have different impacts, with its own windfalls and challenges,” wrote the authors of the Brookings Institution report.Washington state stood out in the Brookings Institution’s state-by-state comparison of the role of AI, which the researchers attributed to the Puget Sound region’s focus on technology and manufacturing.In the report titled “What Jobs are Affected by AI?”, released Wednesday, Brookings researchers extrapolated on Webb’s statistics and analyzed the impact of AI on various industries, demographics and geographies.



        Related
        More on The A.I. Age


Seattle faith groups reckon with AI — and what it means to be ‘truly human’ These AI earbuds could help travelers seamlessly translate conversations Video: Will artificial intelligence make work better — or worse? Experts explore the future of work


AI 101: What is artificial intelligence and where is it going? Face-scanning algorithm increasingly decides whether you deserve the job 



More



Using over 16,000 patents that contained words describing AI technologies, Webb trained a natural language processing algorithm — a mathematical formula that amounts to a set of processing instructions — to identify thousands of verb-object pairs to quantify the usage of AI in nearly 800 job applications from a U.S. Department of Labor database.For example, his system would extract the words “diagnose disease” in the description of an AI patent, and then find a similar phrase in job descriptions to determine if, say, a doctor’s task will be affected by the technology.Webb’s analysis revealed that 740 out of the 769 job posts he analyzed matched with AI patent language, showing that the occupations may be impacted by AI technologies.
Advertising

Skip Ad 

Higher paid and educated workers, as well as some agriculture and manufacturing positions will be the most affected by AI, the report noted. The motor vehicle manufacturing and textile industries will experience the most changes due to AI deployment, which is already seen in production lines where AI systems are used to identify defective clothes.Demographic groups including men, white and Asian Americans, as well as workers ages 25 to 54, will be disproportionately involved with or impacted by AI, the study found.Webb believes the difference in impact between automation and AI on different demographics is because AI is particularly adept at performing tasks that involve optimization, judgment, and learning from experience. Meanwhile, AI is less skilled at roles that involve human interaction – tasks typically fulfilled by less-educated workers in service jobs.Will interacting with AI be helpful or detrimental to highly paid workers? That’s hard to say, says Webb: “On the one hand, AI could make them more productive, and increase their wages. On the other, it could reduce employment.”Mark Muro, one of the report’s authors, stressed that involvement with AI doesn’t equate to job replacement. In fact, higher-wage workers may be the best equipped to weather the changes brought about by AI.“White-collar workers with higher education levels may have better resources to roll with it and adjust more than, say lower-educated manufacturing workers in the U.S. with fewer skills,” said Muro.
Advertising

Skip AdSkip AdSkip Ad 

The report’s findings drastically differed from the results of a January Brookings Institution report that looked at the impact of automation and robotics on jobs; it found that less-educated, lower-wage workers would potentially face more change due to automation technologies and robotics than employees in higher-wage jobs.Joseph Wilcox, co-manager of the Future of Work Task Force, finds it surprising that AI could potentially affect higher-wage workers more than than lower-wage ones. “It doesn’t surprise me that the nature of the job would change, but I would be surprised if there’s a lot of displacement,” Wilcox said.Over the past year, Wilcox has attended hundreds of meetings, held formal outreach in rural areas, and talked with workers, educators and unions throughout Washington about how new technology is impacting them and gathering suggestions for best practices.Launched last September, the task force was the result of a 2018 legislative mandate designed to explore policies for businesses and communities to thrive in what is referred to as the fourth industrial revolution, a time heavily dependent upon AI. He said he’s seen firsthand that lower-paying jobs are the most likely to be automated.“The impact on each industry is going to be different, but it is significant,” said Wilcox. “It’s going to require lifelong learning and continuous upskilling to keep yourself competitive in the job market.” 



         Melissa Hellmann      

 


Most Read Business Stories


European Union adds porn site XNXX to list of online platforms facing strictest digital scrutiny  
 
Kroger-Albertsons deal would remake Seattle-area grocery map  
 
Amazon sold a used diaper. It tanked a mom-and-pop business  
 
Turnaround for ‘really strange’ housing market is a year off | Analysis  
 
Boeing 777X finally gets FAA green light for certification flights   WATCH






 View Comments

Posting comments is now limited to subscribers only. View subscription offers here. For more information, visit our FAQ's.

The opinions expressed in reader comments are those of the author only and do not reflect the opinions of The Seattle Times.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiggFodHRwczovL3d3dy5yb3V0ZS1maWZ0eS5jb20vZGlnaXRhbC1nb3Zlcm5tZW50LzIwMTkvMTEvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY291bGQtaGF2ZS1iaWdnZXN0LWltcGFjdC13aGl0ZS1jb2xsYXItam9icy8xNjE0NDUv0gEA?oc=5,Artificial Intelligence Could Have Biggest Impact on White-Collar Jobs - Route Fifty,2019-11-20,Route Fifty,https://www.route-fifty.com,New research suggests that white collar jobs are more likely to feel the impacts of artificial intelligence in the workplace than blue-collar positions. ,"artificial intelligence, jobs, economy, ai impact",New research suggests that white collar jobs are more likely to feel the impacts of artificial intelligence in the workplace than blue-collar positions.,New research suggests that white collar jobs are more likely to feel the impacts of artificial intelligence in the workplace than blue-collar positions.,http://schema.org,Article,https://www.route-fifty.com/digital-government/2019/11/artificial-intelligence-could-have-biggest-impact-white-collar-jobs/161445/,Artificial Intelligence Could Have Biggest Impact on White-Collar Jobs,"{'url': 'https://cdn.route-fifty.com/media/img/cd/2019/11/20/shutterstock_380832685/route-fifty-lead-image.jpg?1627439893', 'width': 1200, '@type': 'ImageObject', 'height': 550}","{'url': '/voices/andrea-noble/14689/', '@type': 'Person', 'name': 'Andrea Noble'}",2019-11-20T18:03:00,2023-07-10T21:04:16,"{'logo': {'url': 'https://cdn.route-fifty.com/media/logos/route-fifty-logo.png', 'width': 241, '@type': 'ImageObject', 'height': 60}, '@type': 'Organization', 'name': 'Route Fifty'}",,,,"

Artificial Intelligence Could Have Biggest Impact on White-Collar Jobs
                    Shutterstock /  XiXinXing 
                  
Sponsor Message

Sponsor Message


      Sign up for Route Fifty Today
    
      Your daily read on state and local government
    email
Sponsor Message

Sponsor Message

Connect with state & local government leadersJoin Our CommunityFeatured eBooks





            
              
                
                  




  


By

Andrea Noble,Staff Correspondent








 
Connecting state and local government leaders








































            
              
                
                  



  By


Andrea Noble

|

             November 20, 2019
            

New research suggests that white collar jobs are more likely to feel the impacts of artificial intelligence in the workplace than blue-collar positions. 






                  New Technology
                









                  Innovation
                












































The fear used to be that robots would entirely replace manufacturing and production jobs.But new research shows that developments in artificial intelligence could also have drastic effects on the white-collar workforce, particularly in cities and states with a high number of technology-related jobs. The new report from the Brookings Institution examines the jobs that are most likely to change or—in the worst case scenario—be eliminated because of the evolution of artificial intelligence in the workplace. Researchers believe that many well-paying, white-collar professions, ranging from market research analysts and sales managers to programmers and engineers, will see encroachment by artificial intelligence in their fields.“Often analytic or supervisory, these roles appear heavily involved in pattern-oriented or predictive work, and may therefore be especially susceptible to the data-driven inroads of AI,” the report states.To analyze the potential impact of artificial intelligence in the economy, researchers compared language included in artificial intelligence-related patents with job descriptions to determine which type of jobs are most likely to encounter artificial intelligence.The researchers found that “workers with graduate or professional degrees will be almost four times as exposed to AI as workers with just a high school degree.” By contrast, low-paying jobs that require hands-on services, such as health care or food preparation, are unlikely to be as vulnerable to artificial intelligence.Jacob Whiton, a research analyst with the Metropolitan Policy Program at Brookings, stressed that the research does not provide a definitive guide of the type of jobs that will be replaced by artificial intelligence, rather the research informs the industries in which AI has the potential to be used in the future.“This is an indication of the direction towards which a technology could be used and is not meant to imply anything about how in particular it is going to change a given job,” Whiton said.One key insight in the report is that the effects of artificial intelligence on the workforce will not be felt evenly across the country.Cities identified as being at the highest risk of exposure to workforce disruption include those with large technology industries like San Jose, California; Seattle, Washington; Boulder, Colorado; and Salt Lake City and Ogden, Utah. Other cities that are highly reliant on the agriculture and manufacturing industries—including Bakersfield, California; Greenville, South Carolina; Detroit, Michigan; Columbus, Ohio; and Louisville, Kentucky—were also identified as having a high risk for disruption.Smaller, rural communities “are significantly less exposed to technological disruption than larger, dense urban ones,” the report states.
Brookings Institution
When it comes to the impact on manufacturing industries, states in the Midwest and south—including Wisconsin, Michigan, Indiana, Kentucky, Alabama and Georgia—are likely to see higher levels of exposure to artificial intelligence, specifically in the textile and auto manufacturing sectors, where machine learning is making significant advancements, according to the report.

Story Continues Below Sponsor Message

Story Continues Below Sponsor Message


The findings may provide new insight for state and local government officials looking to develop or improve workforce development programs, Whiton said.“So much of the discourse has been equipping workers with tech skills,” he said.The new analysis on the impact that artificial intelligence can have on white-collar jobs may prompt some officials to reexamine the type of durable skills that office workers need to be competitive in the modern workplace, he said.






Andrea Noble is a staff correspondent with Route Fifty. 








              New technology Case Studies
            




                  Powered By
                  










Browse The Atlas full case study database or read more case studies about
            New technology.
          














                            Smart Loading Zones in Pittsburgh Manage Curbside Congestion
                          



                          Pittsburgh, PA
                      

















                            Applied Learning at Wichita State Gives Students Real-World Technology Experience
                          



                          Wichita, KS
                      

















                            Pilot project comparing Utilis to traditional acoustic: Prince William County, VA
                          



                          Prince William County, VA
                      










                BROWSE LOCAL GOV CASE STUDIES
              









Share This:



NEXT STORY:

              When not to automate
            













Midwest states launch new rail service, 12 years in the making







Why the fight over abortion pills isn’t over yet







The 'silver tsunami' is here. Is government ready?







Auditing reimagined: Looking beyond the public dollar







Utah Gov. Cox to homeless providers: Produce results, or you could lose funding






sponsor content

Transforming Lives by Transforming Government: Enterprise Performance Management for Strategic and Operational Excellence in State Government








Midwest states launch new rail service, 12 years in the making






Why the fight over abortion pills isn’t over yet






The 'silver tsunami' is here. Is government ready?






Auditing reimagined: Looking beyond the public dollar






Utah Gov. Cox to homeless providers: Produce results, or you could lose funding





sponsor content

Transforming Lives by Transforming Government: Enterprise Performance Management for Strategic and Operational Excellence in State Government






",Route Fifty,,,,https://www.route-fifty.com,,https://cdn.route-fifty.com/b/route_fifty/img/social/route-fifty-logo.png,"['https://www.facebook.com/RouteFifty', 'https://twitter.com/routefifty', 'https://www.linkedin.com/company/route-fifty/']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMilgFodHRwczovL3d3dy5idXNpbmVzc3dpcmUuY29tL25ld3MvaG9tZS8yMDE5MTExOTAwNTA0Ni9lbi9DZXJlYnJhcy1TeXN0ZW1zLVVudmVpbHMtQ1MtMS10aGUtSW5kdXN0cnklRTIlODAlOTlzLUZhc3Rlc3QtQXJ0aWZpY2lhbC1JbnRlbGxpZ2VuY2UtQ29tcHV0ZXLSAQA?oc=5,"Cerebras Systems Unveils CS-1, the Industry's Fastest Artificial Intelligence Computer - Business Wire",2019-11-19,Business Wire,https://www.businesswire.com,"Cerebras Systems Unveils CS-1, the Industry’s Fastest Artificial Intelligence Computer",,"Cerebras Systems Unveils CS-1, the Industry’s Fastest Artificial Intelligence Computer","Cerebras Systems Unveils CS-1, the Industry’s Fastest Artificial Intelligence Computer",,,,,,,,,,,,,"




Cerebras Systems Unveils CS-1, the Industry’s Fastest Artificial Intelligence Computer






Optimized for AI, CS-1 Delivers Unprecedented Compute Performance at a Fraction of the Size and Power of Conventional Systems














Download







Cerebras Systems Unveils CS-1, the Industry’s Fastest Artificial Intelligence Computer (Photo: Business Wire)












Cerebras Systems Unveils CS-1, the Industry’s Fastest Artificial Intelligence Computer (Photo: Business Wire)





Full Size








Small








Preview








Thumbnail


















Full Size








Small








Preview








Thumbnail














November 19, 2019 08:00 AM Eastern Standard Time



LOS ALTOS, Calif.--(BUSINESS WIRE)--Cerebras Systems, a company dedicated to accelerating Artificial Intelligence (AI) compute, today unveiled its CS-1 system, the world’s fastest AI computer. With every component optimized for AI work, the CS-1 delivers more compute performance at less space and less power than any other system. At only 26 inches tall, the CS-1 fits in one-third of a standard data center rack, but replaces clusters of hundreds or thousands of graphics processing units (GPUs) that consume dozens of racks and use hundreds of kilowatts of power.

.@CerebrasSystems Unveils CS-1, the Industry’s Fastest Artificial Intelligence ComputerPost this

In August, Cerebras delivered the Wafer Scale Engine (WSE), the only trillion transistor wafer scale processor in existence. The Cerebras WSE is 56.7 times larger and contains 78 times more compute cores than the largest GPU, setting a new bar for AI processors. The CS-1 system design and Cerebras software platform combine to extract every ounce of processing power from the 400,000 compute cores and 18 Gigabytes of high performance on-chip memory on the WSE.


In AI compute, chip size is profoundly important. Big chips process information more quickly, producing answers in less time. However, exceptional processor performance is necessary but not sufficient to guarantee industry leading AI performance. Innovative, high performance processors, like the WSE, must be combined with dedicated hardware systems and extraordinary software to achieve record-breaking performance. For this reason, every aspect of the Cerebras CS-1 system and the Cerebras software platform was designed for accelerated AI compute.


“The CS-1 is the industry’s fastest AI computer, and because it is easy to install, quick to bring up and integrates with existing AI models in TensorFlow and PyTorch, it delivers value the day it is deployed,” said Andrew Feldman, Founder and Chief Executive Office, Cerebras Systems. “Depending on workload, the CS-1 delivers hundreds or thousands of times the performance of legacy alternatives at one-tenth the power draw and one-tenth the space per unit compute.”


Cerebras is the only company to undertake the ambitious task of building a dedicated system from the ground up. By optimizing every aspect of chip design, system design, and software, the CS-1 delivers unprecedented performance. With the CS-1, AI work that today takes months can now be done in minutes, and work that takes weeks now can be completed in seconds. Not only does the CS-1 radically reduce training time, but also it sets a new bar for latency in inference. For deep neural networks, single image classification can be accomplished in microseconds, thousands of times faster than alternative solutions.


Early customer deployments include Argonne National Laboratory where the CS-1 is being used to accelerate neural networks in pathbreaking cancer studies, to better understand the properties of black holes, and to help understand and treat traumatic brain injuries. The sheer performance of the CS-1 makes it an exceptional solution for the largest and most complex problems in AI.


“The CS-1 is a single system that can deliver more performance than the largest clusters, without the overhead of cluster set up and management,” said Kevin Krewell, Principal Analyst, TIRIAS Research. “By delivering so much compute in a single system, the CS-1 not only can shrink training time but also reduces deployment time. In total, the CS-1 could substantially reduce overall time to answer, which is the key metric for AI research productivity.”


About the CS-1


The CS-1 solution is the fastest AI computer system. It is comprised of three major technical innovations: the CS-1 system, the Cerebras software platform and the WSE.


The CS-1 System


Optimized exclusively for accelerating AI work and built from the ground up by Cerebras Systems, the CS-1 is 15 rack units (26 inches) tall and fits in one-third of a standard data center rack. The CS-1 integrates the Cerebras WSE and feeds its massive 400,000 AI optimized compute cores with 1.2 Terabits per second of data. The combination of the massive Input/Output bandwidth – 12 x 100 Gigabit Ethernet lanes – and the 18 Gigabytes of on-chip memory enable the CS-1 to deliver vastly more calculations per unit time than legacy offerings. Since all of the compute and communication remains on-chip, the CS-1 uses less than one-tenth the power and takes one-tenth the space of alternative solutions.


Unlike clusters of GPUs, which can take weeks or months to set up, require extensive modifications to existing models, consume dozens of data center racks and require complicated proprietary InfiniBand to cluster, the CS-1 takes minutes to set up. Users can simply plug in the standards-based 100 Gigabit Ethernet links to a switch and are ready to start training models at record-breaking speed.


Cerebras Software Platform 


The CS-1 is easy to deploy and simple to use. Cerebras’s mission is to accelerate not only time-to-train, but also the end-to-end time it takes for researchers to achieve new insights – from model definition to training to debugging to deployment.


The Cerebras software platform is designed for Machine Learning (ML) researchers to leverage CS-1 performance without changing their existing workflows. Users can define their models for the CS-1 using industry-standard ML frameworks such as TensorFlow and PyTorch. A powerful graph compiler automatically converts these models into optimized executables for the CS-1, and a rich set of tools enables intuitive model debugging and profiling.


The Cerebras software platform is comprised of four primary elements:



Integration with common ML frameworks like TensorFlow and PyTorch


Optimized Cerebras Graph Compiler (CGC)


Flexible library of high-performance kernels and a Kernel API


Development tools for debug, introspection, and profiling



The Cerebras Graph Compiler


The Cerebras Graph Compiler (CGC) takes as input a user-specified neural network. For maximum workflow familiarity and flexibility, researchers can use both existing ML frameworks and well-structured graph algorithms written in other general-purpose languages, such as C and Python, to program for the CS-1.


CGC begins the translation of a deep learning network into an optimized executable by extracting a static graph representation from the source language and converting it into the Cerebras Linear Algebra Intermediate Representation (CLAIR). As ML frameworks evolve rapidly to keep up with the needs of the field, this consistent input abstraction allows CGC to quickly support new frameworks and features, without changes to the underlying compiler.


Using its knowledge of the unique WSE architecture, CGC then allocates compute and memory resources to each part of the graph and then maps them to the computational array. Finally, a communication path, unique to each network, is configured onto the fabric.


Because of the massive size of the WSE, every layer in the neural network can be placed onto the fabric at once, and run simultaneously in parallel. This approach to whole-model acceleration is unique to the WSE -- no other device has sufficient on-chip memory to hold all layers at once on a single chip, or the enormous high-bandwidth and low-latency communication advantages that are only possible on silicon.


The final result is a CS-1 executable, customized to the unique needs of each neural network, so that all 400,000 compute cores and 18 Gigabytes of on-chip SRAM can be used at maximum utilization towards accelerating the deep learning application.


Development Tools and APIs


CGC’s integrations with popular ML frameworks means that industry-standard tools such as TensorBoard are supported out of the box. In addition, Cerebras provides a fully-featured set of debugging and profiling tools to make deeper introspection and development easy.


For ML practitioners, Cerebras provides a debugging suite that allows visibility into every step of the compilation and training run. This enables visual introspection into details like:



Validity of the compilation on the fabric


Latency evaluations across a single kernel versus through the entire program


Hardware utilization on a per-kernel basis to help identify bottlenecks



For advanced developers interested in deeper flexibility and customization, Cerebras provides a Kernel API and a C/C++ compiler based on LLVM that allows users to program custom kernels for CGC. Combined with extensive hardware documentation, example kernels, and best practices for kernel development, Cerebras provides users with the tools they need to create new kernels for unique research needs.


The WSE


The Cerebras WSE is the largest chip ever made and the industry’s only trillion transistor processor. It contains more cores, with more local memory, and more fabric bandwidth, than any chip in history. This enables fast, flexible computation at lower latency and with less energy. The WSE is 46,255 millimeters square, which is 56 times larger than the largest GPU. In addition, with 400,000 cores, 18 Gigabytes of on-chip SRAM, 9.6 Petabytes/sec of memory bandwidth, and 100 Petabits/sec of interconnect bandwidth, the WSE contains 78 times more compute cores, 3,000 times more high speed, on-chip memory, 10,000 times more memory bandwidth and 33,000 times more fabric bandwidth than its GPU competitors.


For more information on Cerebras Systems and the Cerebras CS-1, please visit www.cerebras.net. Imagery and digital photography for the Cerebras CS-1 can be found linked here.


About Cerebras Systems


Cerebras Systems is a team of pioneering computer architects, computer scientists, deep learning researchers, and engineers of all types. We have come together to build a new class of computer to accelerate artificial intelligence work by three orders of magnitude beyond the current state of the art. The CS-1 is the fastest AI computer in existence. It contains a collection of industry firsts, including the Cerebras Wafer Scale Engine (WSE). The WSE is the largest chip ever built. It contains 1.2 trillion transistors and covers more than 46,225 square millimeters of silicon. The largest graphics processor on the market has 21.1 billion transistors and covers 815 square millimeters. In artificial intelligence work, large chips process information more quickly producing answers in less time. As a result, neural networks that in the past took months to train, can now train in minutes on the Cerebras WSE.



Contacts

Kim Ziesemer
Email: pr@zmcommunications.com




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMmh0dHBzOi8vd3d3Lm5hdHVyZS5jb20vYXJ0aWNsZXMvZDQyNDczLTAxOS0wMDMzMS0w0gEA?oc=5,Artificial intelligence turns to antibody selection - Nature.com,2019-11-17,Nature.com,https://www.nature.com,A new machine-learning platform scours the scientific literature in search of experimentally suitable antibodies.,,A new machine-learning platform scours the scientific literature in search of experimentally suitable antibodies.,,,,,,,,,,,,,,"




ADVERTISEMENT FEATURE Advertiser retains sole responsibility for the content of this article

Artificial intelligence turns to antibody selection


                    A new machine-learning platform scours the scientific literature in search of experimentally suitable antibodies.
                





Produced by














Twitter





Facebook





Email














Bench Sci marries a database of 6.9 million commercially available antibodies with a machine learning algorithm that searches scientific literature for relevant, high-affinity antibodies.Credit: MF3d/Getty Images


Getting through graduate school is hard enough. But Tom Leung encountered a particularly frustrating obstacle while studying epigenetic changes in cultured cells during his PhD at the University of Toronto. “I had to stay in the lab for 12 hours at a time to collect all the samples, and in the end, when I ran the western blot to analyze my results, it didn’t work,” he says. “It wasn’t because I did anything wrong in the experiment. It was because the antibody quality was poor.”Leung’s experience is common. A 2008 high-profile, proteome-scale study of antibody performance from 2008 found that nearly half of the thousands of reagents tested by the authors did not deliver the expected affinity or specificity. Leung wanted a solution, and along with University of Toronto colleagues, Elvis Wianda, David Chen and Liran Belenzon, founded BenchSci, an artificial intelligence (AI) platform that allows researchers to search for optimal reagents based on figures from published experiments and make data-driven antibody choices.The burden of choiceThere are millions of antibodies available, sold by hundreds of vendors. One recent article reports that more than 5,000 antibodies exist for the human epidermal growth factor receptor protein (EGFR) alone. “Scientists know that every antibody is not going to work in every experimental context,” says Casandra Mangroo, Head of Science at BenchSci. “Even if the vendor has done some sort of testing, they don't have the capacity to test every antibody in every single experimental context.”David Rimm, a pathologist at Yale University, has been a vocal advocate for antibody quality testing and validation. In 2016, he was part of a push to get makers of antibodies to agree to a set of best practices for quality control.“At first, they all agreed to a sort of ‘scoring system’, but after thinking about it for a bit, they changed their mind,” he says. Without a clear-cut way to confidently rank and compare antibodies, scientists can only rely on the data in the literature, but extracting this information is labor intensive.“PubMed and Google Scholar let you quickly look for results, and you can find a lot of papers,” Leung says. “But if you have to go down to the supplementary data, or one of the figures, to find a reagent, it’s not that easy.”Matchmaking for antibodiesBenchSci’s AI-Assisted Antibody Selection platform automates this work, scouring text and figures in the literature to identify antibodies that might support a particular experiment. Leung notes that the company initially benefited from the wealth of publications in repositories such as PubMed Central.“We were able to get a lot of high-tier journals and open-access journals and then use them to train a machine learning model,” he says. “Then later on, we forged a lot of partnerships with different closed-access publishers.” Springer Nature, which publishes Nature, Wiley, and Wolters Kluwer, are among the publishers that have since agreed to share article data with BenchSci.Leung says that BenchSci’s timing was also fortuitous. “If this idea was hatched two years earlier, it probably wasn't going to work because deep learning and machine learning were not as mature yet,” he says. It helped that Chan and Wianda had extensive familiarity with these tools from their own graduate research.BenchSci’s database contains 6.9 million antibodies from over 220 vendors, with coupled data drawn from 10 million research papers. That dataset is continually growing, both in the number of reagents and journals, as are the demands on BenchSci’s computational capacity. “We do monthly runs to update data on the platform and train our algorithms. We basically had to create a whole wall of computers to do that,” Mangroo says.When scientists search BenchSci’s database for antibodies against a particular protein, the AI assembles a simple set of figures depicting the use of various products in different experimental contexts. One can just look for antibodies that have been used in immunohistochemistry, ELISA or flow cytometry experiments, and then assess the performance of different reagents in different studies. Today more than 15 of the top 20 pharmaceutical companies are using the BenchSci platform, as are more than 31,000 scientists at 3,600 institutions.Rimm has found the platform quite valuable. “Because it gives you access to the figures in which an antibody was used, you can have your own criteria for what you accept as validation,” he says. “It just saves a lot of time spent digging in the literature.”In addition to being helpful for product selection, Rimm says the platform can also streamline the experimental process. If, for example, BenchSci uncovers a published track record for a given antibody in a particular validation assay, researchers can cite prior work rather than wasting effort repeating the experiment. Conversely, Mangroo says that image search makes it easy to recognize reagents that are low quality or poorly matched for a given assay, should a figure show results that are inconsistent with other experimental data.Network effectsMany antibody manufacturers have now lined up behind BenchSci’s efforts, sharing their catalogues and associated validation data for incorporation into the company’s database. Rimm says that even though these reagent manufacturers were hesitant about universal validation standards, many still recognized the need for better quality control. “The system sort of policed itself, and made the competitive marketplace the scoring system, where many vendors competed with each other in who could show the most validated antibody,” he says.BenchSci builds on that sentiment. Users benefit from access to validation data while antibody companies benefit from having their products directly linked with successful published experiments. Importantly, BenchSci remains a neutral platform in terms of recommendations, allowing the data to speak for itself. “I like that BenchSci doesn’t have skin in the game,” Rimm says. “They don’t advertise or rate antibodies.”The ability to make informed decisions about antibodies can reduce waste and lost time, but antibodies are only one part of the reproducibility problem. Researchers also rely on a host of other reagents, including molecular probes, protein-specific inhibitors and activators, and primers for sequencing and PCR amplification. Leung ultimately hopes to turn BenchSci’s AI platform toward this broader constellation of products as well.“By linking these other reagents together, we can provide a much more complete picture of what has transpired in different publications,” Leung says. “Then we'll be able to help scientists in a much fuller regard to planning their experiments.”
To learn more about how AI could help researchers more accurately select suitable antibodies, visit benchsci.com.


Related Articles




                        
                        For researchers, antibody selection is a risky decision
                    



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vd3d3LnNocm0ub3JnL3RvcGljcy10b29scy9uZXdzL2FsbC10aGluZ3Mtd29yay9maXZlLXJlY3J1aXRpbmctdHJlbmRzLW5ldy1kZWNhZGXSAQA?oc=5,Five Recruiting Trends for the New Decade - SHRM,2019-11-16,SHRM,https://www.shrm.org,"From relying on predictive analytics and chatbots to using enhanced candidate vetting strategies—and myriad other up-and-coming trends—the recruiting industry is shedding old habits and trying some potentially game-changing new approaches as a new, tec...","News,Workforce Planning,Feature,All Things Work,Vendors and Software,Talent Acquisition,Technology,Recruiting","From relying on predictive analytics and chatbots to using enhanced candidate vetting strategies—and myriad other up-and-coming trends—the recruiting industry is shedding old habits and trying some potentially game-changing new approaches as a new, tec...","From relying on predictive analytics and chatbots to using enhanced candidate vetting strategies—and myriad other up-and-coming trends—the recruiting industry is shedding old habits and trying some potentially game-changing new approaches as a new, tec...",https://schema.org,NewsArticle,,Five Recruiting Trends for the New Decade,,"{'@type': 'Person', 'name': 'Brian O’Connell', 'url': ''}",,2024-05-31T17:40:24.699Z,,,,,"
 














 




Share












 







Linked In


 
 
Facebook


 
 
Twitter


  

Email



 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus
            convallis sem tellus, vitae egestas felis vestibule ut.  





 

 
Error message details.

 
 




Copy button
 



 


















 



 
 
 
Reuse Permissions
              













Request permission to republish or redistribute SHRM content and materials.
            






 
 

 
Learn More
  

  



 





          Feature

Five Recruiting Trends for the New Decade

New technologies and practices are changing the way companies recruit talent, and it's all happening at lightning speed.

November 16, 2019

          | 



          

          
                      Brian O’Connell
                             







Share



Bookmark


i
Reuse
                            Permissions








",SHRM,,,,https://www.shrm.org/,"{'@type': 'SearchAction', 'target': 'https://www.shrm.org/search-results#q={search_term_string}', 'query-input': 'required name=search_term_string'}",https://shrm-res.cloudinary.com/image/upload/v1703622970/shrm-logo.png,"['http://twitter.com/SHRM', 'http://www.linkedin.com/company/shrm', 'https://www.facebook.com/SHRMHQ', 'http://www.youtube.com/shrmofficial', 'https://instagram.com/shrmofficial/', 'https://en.wikipedia.org/wiki/Society_for_Human_Resource_Management', 'https://www.wikidata.org/wiki/Q1527909', 'https://www.crunchbase.com/organization/shrm']",,,,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'false', 'cssSelector': '.content-metering-wrapper'}",,,,False,,,,,,Society for Human Resource Management,1-800-283-7476,"{'@type': 'PostalAddress', 'streetAddress': '1800 Duke Street', 'addressLocality': 'Alexandria', 'postalCode': '22314', 'addressCountry': 'United States'}",,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vZm9ydHVuZS5jb20vMjAxOS8xMS8xOS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jZXJlYnJhcy1zdXBlcmNvbXB1dGVyL9IBAA?oc=5,Artificial Intelligence: Cerebras Unveils A Speedy and Small Supercomputer - Fortune,2019-11-19,Fortune,https://fortune.com,"The CS-1 could rapidly speed up the research involved in cancer-drug development, among other disciplines.","ai artificial intelligence, a.i., artificial intelligence, supercomputers, ultrafast computing, machine learning, best artificial intelligence, a.i. solutions, Cerebras, Cerebras Systems, deep learning, neural nets, neural networks, drug research, drug development, cancer drugs, cancer research, Argonne Labs, Argonne National Laboratory","The CS-1 from Cerebras could rapidly speed up the research involved in cancer-drug development, among other disciplines.","The CS-1 from Cerebras could rapidly speed up the research involved in cancer-drug development, among other disciplines.",,,,,,,,,,,,,"Newsletters - Data SheetThe security company that Alphabet may buy for $23 billion launched at the perfect timeBYDavid MeyerJuly 16, 2024",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vZGFpbHl0aW1lcy5jb20ucGsvNTAzODY3L2lzLXRoZS1yaXNlLWluLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXN1cGVyc2VkaW5nLWh1bWFuLWVtcGxveW1lbnQv0gFpaHR0cHM6Ly9kYWlseXRpbWVzLmNvbS5way81MDM4NjcvaXMtdGhlLXJpc2UtaW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3VwZXJzZWRpbmctaHVtYW4tZW1wbG95bWVudC9hbXAv?oc=5,Is the rise in Artificial Intelligence superseding human employment? - Daily Times,2019-11-20,Daily Times,https://dailytimes.com.pk,,,This century belongs to the advancement of technology. The technology of the present era baffles human beings with its wonderful services. Invention of machines with an association of Artificial Intelligence (AI) and automation are the products of technology. These days amenities provided by AI are invaluable. One couldn’t contemplate in the past that one would […],,https://schema.org,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://dailytimes.com.pk/503867/is-the-rise-in-artificial-intelligence-superseding-human-employment/'}",Is the rise in Artificial Intelligence superseding human employment?,,"{'@type': 'Person', 'name': 'DailyTimes.pk'}",2019-11-20T23:31:45,2019-11-20T23:31:46,"{'@type': 'Organization', 'name': 'Daily Times', 'logo': {'@type': 'ImageObject', 'url': 'https://dailytimes.com.pk/assets/uploads/2020/08/app-icon-192x192-1-60x60.png'}}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://dailytimes.com.pk/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://dailytimes.com.pk/503867/is-the-rise-in-artificial-intelligence-superseding-human-employment/', 'name': 'Is the rise in Artificial Intelligence superseding human employment?'}}]",,,"This century belongs to the advancement of technology. The technology of the present era baffles human beings with its wonderful services. Invention of machines with an association of Artificial Intelligence (AI) and automation are the products of technology. These days amenities provided by AI are invaluable. One couldn’t contemplate in the past that one would make visible contact with one’s dear ones sitting in far-flung areas. Now even a low-income citizen can make video contact-a widespread phenomenon-withhis relatives or friends.Theexample that I have cited is a very ordinary one of the services provided by technology.
However, with the rise in technologically sophisticated machines, coupled with AI and automation, there is an imminent hazard of growing unemployment. The concerned debate revolves around the pivot that is this idea paranoia or is it categorically conquering the prospects of human employment.
Before examining the effects of technology, let’s discuss what brought about advancement in technology to such a great extent.The answer to this question is globalisation. It is globalisation that has helped in the propagation of technology at a wide scale. Interconnectivity among countries and relaxed trade conditions-some of the outcomes of globalisation-have allowed manufactured tech-products from the developed world to reach developing and under-developing world.Now the question emanates whether the rampant advancement in technology is contributing to unemployment or not.



The advancement in technology has enlarged the invention of robots with the help of automation and AI. There is no denying that robots can perform activities and tasks with ample accuracy and efficiency than human beings. However, the rise of robots has led to some scary warnings about the future of work. These warnings have brought forth the growing risks of unemployment. A recent study foundthat up to 0.7 million jobs were lost to robots in the US from 1990 to 2007. This dilemma doesn’t start from the 1990s as it began when the Industrial Revolution caught momentum during the late 19th century.
The World Economic Forum predicts that millions of jobs will be lost to robots by 2020. The Industrial Revolution brought ease for humans, but it is also important to mention that each invention came at a cost for humans. Let’s take the example of bronze’s arrival; stones tools were replaced, and when iron tools were made, workers who used bronze tools lost their job. With industrial advancement, millions of cobblers and weavers’ jobs were put at stake. They had to endeavour a lot to keep pace with the ever-advancing technology.
Our daily routine jobs are getting automated. One prime illustration is the introduction of live railway tracking software in Pakistan Railways, which has provided passengers with unmatched comfort as they don’t have to wait for hours. They just track the train on their mobiles and reach the station on time. However, jobs of many inquiry providers havebeen affected because of this technology. Another example is ATM-Automated Teller Machine-whichhas replaced the job of scores of bankers.



Seven in ten Americans, six in ten Canadians, and six in ten UK residents believe the advent of artificial intelligence will eliminate more jobs than it creates
There isample evidence that the rise in AI and automated appliances have affected human jobs. Various reports published by prestigious institutions shed light on the effects on jobs due to rise in AI technology. McKinsey reckons tha depending upon various adoption scenarios, automation will displace between 400 and 800 million jobs by 2030, requiring as many as 375 million people to switch job categories entirely. According to Oxford Economics, up to 20 million manufacturing jobs worldwide will be lost to robots by 2030.
There is another impact of technology that can affect our jobs by increasing the demand for labour in industries or jobs that arise or develop due to technological progress. The World Economic Forum says that automation will displace 75 million jobs but generate 133 million new ones worldwide by 2022. According to Gartner, AI-related job creation will reach two million net-new jobs in 2025.AI is creating “a surge in new career opportunities,” says a ZipRecruiter report.A recent Gallup and Northeastern University online survey of 4,394 Americans, 3,049 Canadians and 3,208 UK adults found mixed attitudes towards AI, reflecting the mix of apocalyptic and human-friendly scenarios.There is a general pessimistic attitude about the impact of AI adoption on the overall economy, but adults in the US, UK and Canada remainoptimistic about their own jobs.Seven in ten Americans, six in ten Canadians, and six in ten UK residents believe the advent of artificial intelligence will eliminate more jobs than it creates.
It is obvious that rampant use of technology can cause reduction in employment and can also boost it. But the need of the hour is to harness the opportunities that are practical for supporting the employment sector. For this purpose, government needs to take steps that boost employment.One of the best ways to fight redundancy created by technology is to provide the masses opportunities to gain technical and updated education.
Human beings are the supreme creatures, adorned with an intellectual power that no technology can replace. Technology is the upshot of human efforts. Humans create machines, it is not machines that create humans. Machines are operated and controlled by human beings. However, the current chaos in employment is the result of miscalculation of the rise in technology. If the problems in jobs created by automation are addressed in due time, technology will create employment prospects. And if the issues are not addressed,it would create a void in the area of employment.
The writer is a freelancer
0Shares
 
                            Read More
                            
            


",Daily Times,,,"[{'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'HOME', 'url': 'https://dailytimes.com.pk/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Latest', 'url': 'https://dailytimes.com.pk/tag/latest/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Pakistan', 'url': 'https://dailytimes.com.pk/blog/pakistan-blog/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Balochistan', 'url': 'https://dailytimes.com.pk/balochistan/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Gilgit Baltistan', 'url': 'https://dailytimes.com.pk/gilgit-baltistan/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Khyber Pakhtunkhwa', 'url': 'https://dailytimes.com.pk/khyber-pakhtunkhwa/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Punjab', 'url': 'https://dailytimes.com.pk/punjab/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Sindh', 'url': 'https://dailytimes.com.pk/sindh/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'World', 'url': 'https://dailytimes.com.pk/blog/world-blog/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Editorials & Opinions', 'url': 'https://dailytimes.com.pk/editorials/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Editorials', 'url': 'https://dailytimes.com.pk/editorial/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Op-Eds', 'url': 'https://dailytimes.com.pk/opeds/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Commentary / Insight', 'url': 'https://dailytimes.com.pk/commentary/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Perspectives', 'url': 'https://dailytimes.com.pk/perspectives/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Cartoons', 'url': 'https://dailytimes.com.pk/cartoons/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Letters to the Editor', 'url': 'https://dailytimes.com.pk/letters/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Featured', 'url': 'https://dailytimes.com.pk/features/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Blogs', 'url': 'https://dailytimes.com.pk/blog/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Ramblings', 'url': 'https://dailytimes.com.pk/blog/ramblings/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Lifestyle', 'url': 'https://dailytimes.com.pk/lifestyle/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Culture', 'url': 'https://dailytimes.com.pk/blog/culture/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Sports', 'url': 'https://dailytimes.com.pk/sports/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Business', 'url': 'https://dailytimes.com.pk/business/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Arts, Culture &amp; Books', 'url': 'https://dailytimes.com.pk/dtculture/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'E-PAPER', 'url': 'https://dailytimes.com.pk/epapers/'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Lahore', 'url': 'https://dailytimes.com.pk/e-paper/?city=lhr'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Islamabad', 'url': 'https://dailytimes.com.pk/e-paper/?city=isb'}, {'@context': 'https://schema.org', '@type': 'SiteNavigationElement', 'id': 'site-navigation', 'name': 'Karachi', 'url': 'https://dailytimes.com.pk/e-paper/?city=khi'}]",https://dailytimes.com.pk,"[{'@type': 'SearchAction', 'target': 'https://dailytimes.com.pk/?s={search_term_string}', 'query-input': 'required name=search_term_string'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vbmV3cy55YWxlLmVkdS8yMDE5LzExLzA2L2VsaXNhLWNlbGlzLWFuZC1maWdodC1mYWlybmVzcy1hcnRpZmljaWFsLWludGVsbGlnZW5jZdIBAA?oc=5,Elisa Celis and the fight for fairness in artificial intelligence - Yale News,2019-11-06,Yale News,https://news.yale.edu,"Celis, an assistant professor of statistics and data science, discusses her work to advance fairness, inclusion — and ethics — in AI research.","Yale University, news, OPA, OPAC, press releases","Celis, an assistant professor of statistics and data science, discusses her work to advance fairness, inclusion — and ethics — in AI research.","Celis, an assistant professor of statistics and data science, discusses her work to advance fairness, inclusion — and ethics — in AI research.",,,,,,,,,,,,,"
Russian environmentalists bring conservation skills and insights to YSE",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Jlcm5hcmRtYXJyLzIwMTkvMTEvMDgvdGhlLTctYmlnZ2VzdC10ZWNobm9sb2d5LXRyZW5kcy10by1kaXNydXB0LWJhbmtpbmctLWZpbmFuY2lhbC1zZXJ2aWNlcy1pbi0yMDIwL9IBAA?oc=5,The 7 Biggest Technology Trends To Disrupt Banking & Financial Services In 2020 - Forbes,2019-11-08,Forbes,https://www.forbes.com,"New technology changes the operations and realities of organizations in all industries when it is widely adopted. It's no different with the latest innovation introduced by artificial intelligence, blockchain, and other technology.","fintech,financial,banking,ai,technology,trends","New technology changes the operations and realities of organizations in all industries when it is widely adopted. It's no different with the latest innovation introduced by artificial intelligence, blockchain, and other technology.","New technology changes the operations and realities of organizations in all industries when it is widely adopted. It's no different with the latest innovation introduced by artificial intelligence, blockchain, and other technology.",http://schema.org,BreadcrumbList,,The 7 Biggest Technology Trends To Disrupt Banking & Financial Services In 2020,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5dc50777ca425400073c4d09/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}",2019-11-08T01:14:37-05:00,2021-01-06T14:46:10-05:00,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise TechThe 7 Biggest Technology Trends To Disrupt Banking & Financial Services In 2020Bernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 8, 2019,01:14am ESTUpdated Jan 6, 2021, 02:46pm ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinEven though banking and financial services have been slower than other industries to adopt the latest technology into their operations, financial organizations are trying to catch up by incorporating artificial intelligence, blockchain, and other technology to benefit their customers, remain competitive and improve business results. Here are the 7 biggest technology trends that will disrupt banking and financial services in 2020.
The 7 Biggest Technology Trends To Disrupt Banking & Financial Services In 2020Adobe Stock

Artificial Intelligence (AI)

Although banking and financial services tend to be slower to adopt new technologies, a PricewaterhouseCooper study confirms the majority of financial services decision-makers are investing in artificial intelligence (AI)—52 percent of executives confirmed they are making “substantial” investments in AI while 72 percent believe it will be a business advantage. One thing that will likely make the rest believe in artificial intelligence’s potential for the industry are the cost savings that are expected to be $447 billion by 2023.

So, how do financial institutions use artificial intelligence? The most visible way the banking industry uses artificial intelligence (AI) is for customer service from chatbots and robots. Many of the largest financial institutions, such as Bank of America and JPMorgan Chase, use AI to streamline customer service. Another customer-facing way AI is deployed is to facilitate mobile banking that allows 24/7 access for consumers to conduct banking operations. AI is also instrumental in the way financial institutions enhance security and prevent and detect fraud. The technology helps financial institutions with risk management and lending decisions and is foundational in making other technology such as big data analytics, robotic process automation, and voice interfaces work.

PROMOTED
Blockchain
Blockchain technology, first used in the cryptocurrency Bitcoin, is a distributed database that can keep track of transactions in a verifiable and permanent way. The Harvard Business Review predicts that blockchain will disrupt banks the way the internet disrupted media. Blockchains are transparent, highly secure, and are relatively cheap to operate. As more financial institutions realize how blockchain can improve security, save money, and improve customer satisfaction, more will adopt the technology.
MORE FROMFORBES ADVISORWhy Do You Need A Brick-And-Mortar Bank?ByBen Grancontributor6 Things To Look For From Your Online BankByBen Grancontributor
Blockchain can support banking in several ways. Bitcoin showed how it can be used for payments, but it can also be transformative in the way our capital markets work by tokenizing traditional bonds, stocks, and other assets and putting them on public blockchains. Blockchains would remove the gatekeepers and third parties in the loans and credit system while also making it more secure to borrow money and lowering interest rates. Blockchain could also eliminate manual data reconciliation for bank ledgers. The way information and money are exchanged today will be altered by smart contracts that operate from blockchain technology.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Big Data
One of the ways to determine a technology’s influence on an industry is to look at how an industry is investing in it. The banking sector is currently one of the top investors by industry in big data and business analytics solutions according to the IDC Semiannual Big Data and Analytics Spending Guide. The amount of data generated by the financial industry—credit card transactions, ATM withdrawals, credit scores—is mind-boggling. And being able to put that data to use to make business decisions and process it effectively to glean actionable insights will be critical to staying competitive in the future.


1/100:05Forbes Innovation





Skip Ad
 
Continue watchingCall Of Duty Black Ops 6 Beta Dates And More Revealedafter the adVisit Advertiser websiteGO TO PAGE
Financial institutions can use big data to learn more about customers and be able to make business decisions in real-time including learning about a customer's spending habits, sales management such as segmenting customers to optimize marketing as well as product cross-selling, fraud management, risk assessment, and reporting, and customer feedback analysis. Not only does big data analysis help identify market trends, but it also helps financial institutions streamline internal processes and reduce risk.
Robotic Process Automation (RPA)
Since robotic process automation can save labor, operational costs, and minimize errors, many financial institutions are starting to leverage this technology to create the best possible user experience for customers and to remain competitive. In RPA, software is programmed to enable robots and virtual assistants to complete repetitive and labor-intensive tasks correctly and quickly without human intervention.
RPA, through customer service chatbots helps banks deal with the low-priority queries from customers such as account and payment questions to free up human customer agents to deal with the high-priority concerns. In insurance companies, RPA is used to automate parts of the claims-handling processes. Another way RPA influences financial institutions is to help ensure compliance in the highly regulated industry. Today, thanks to RPA, customers can get a decision on their credit card application within a few hours but sometimes almost immediately after they submit the information. It’s also optimizing mortgage processing.
Cloud Computing
Cloud computing is technology for storing data and delivering computing services, including servers, databases, networking, software, analytics and more over the internet. When an individual or a business wants to use the cloud, they will pay a cloud provider based on usage with pay-as-you-go pricing.
Cloud computing makes 24/7 customer service from anywhere possible. In addition, cloud computing enhances the agility of financial institutions and makes scaling up services easier and quicker. Since they only pay for services they use, cloud computing can help financial institutions control costs. Cloud computing also enables secure online payments, digital wallets, and online transfers.
Voice Interfaces
Chatbot solutions, enabled by sophisticated artificial intelligence, are being deployed by financial institutions to reduce costs and meet customers' expectations regarding quick response and effective issue resolution. Traditional forms of two-way communication such as email, phone, and text can be replaced with a chatbot. By 2020, chatbots are expected to handle no less than 85 percent of customer service interactions, according to Gartner.
Chatbots offer a nearly instant conversational experience that that can be personalized, so customers get premium service expeditiously. Bank of America, Capital One and Wells Fargo have used chatbots for years for simple account queries, but today’s advanced chatbots could even offer financial advice. Bots are also able to provide centralized financial management over the multiple channels that customers interact with their financial institution, correcting what had in the past felt disjointed. This technology continues to improve and will empower customers to connect with their bank on their terms.
Cyber Security and Resilience
In an industry dealing with sensitive personal and financial information, and that's an attractive target of cybercriminals, security is paramount for financial institutions. It would be a good idea for financial institutions to assume there will be a security breach and plan for how to minimize the damage, because preventing all cyberattacks is nearly impossible due to the diverse ways consumers interact with their money and the numerous vulnerabilities that exist regardless of how much time and energy is put forth to prevent cyberattacks. From mobile apps and web portals to third-party networks and even susceptibilities introduced by employees and customers themselves, safety is never ensured even if you can thwart an attack periodically.
Financial institutions must do more than invest in technical measures to protect against cyberattacks. They must share knowledge and best practices with each other, work with governments to ensure cybersecurity is prioritized, be proactive about educating employees regarding their cybersecurity responsibilities and the importance of following protocols, and reaching out to the public to help them understand the situation and their role in keeping their personal data safe. 
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing... Read MoreEditorial StandardsPrintReprints & Permissions
1/100:00Zindi's Data Scientist Explains How AI Can Be Tapped Into Every Business Sector





Skip Ad
 
Continue watchingZindi's Data Scientist Explains How AI Can Be Tapped Into Every Business Sectorafter the adVisit Advertiser websiteGO TO PAGE",The 7 Biggest Technology Trends To Disrupt Banking & Financial Services In 2020,,Enterprise & Cloud,,https://www.forbes.com/sites/bernardmarr/2019/11/08/the-7-biggest-technology-trends-to-disrupt-banking--financial-services-in-2020/,,,,,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vd3d3LmNuYmMuY29tLzIwMTkvMTEvMDcvdGhlc2UtYW1lcmljYW4td29ya2Vycy1hcmUtdGhlLW1vc3QtYWZyYWlkLW9mLWFpLXRha2luZy10aGVpci1qb2JzLmh0bWzSAWtodHRwczovL3d3dy5jbmJjLmNvbS9hbXAvMjAxOS8xMS8wNy90aGVzZS1hbWVyaWNhbi13b3JrZXJzLWFyZS10aGUtbW9zdC1hZnJhaWQtb2YtYWktdGFraW5nLXRoZWlyLWpvYnMuaHRtbA?oc=5,These American workers are the most afraid of A.I. taking their jobs - CNBC,2019-11-07,CNBC,https://www.cnbc.com,"Most American workers are not worried about robots taking their jobs, but the level of fear about automation does rise significantly among the youngest workers in the country, according to a new CNBC survey.","['cnbc', 'Articles', 'Momentive Global Inc', 'Robotics', 'Artificial intelligence', 'Technology', 'Careers', 'Jobs', 'Special Reports', 'Human Resources and Employment Services', 'CEOs', 'Technology: Trends', 'At Work', 'source:tagname:CNBC US Source']","Most American workers are not worried about robots taking their jobs, but the level of fear about automation does rise significantly among the youngest workers in the country, according to a new CNBC survey.","Most American workers are not worried about robots taking their jobs, but the level of fear about automation does rise significantly among the youngest workers in the country, according to a new CNBC survey.",https://schema.org,NewsArticle,https://www.cnbc.com/2019/11/07/these-american-workers-are-the-most-afraid-of-ai-taking-their-jobs.html,These American workers are the most afraid of A.I. taking their jobs,"{'@type': 'ImageObject', 'url': 'https://image.cnbcfm.com/api/v1/image/105927121-190522fordrobot.jpg?v=1558524346', 'width': 740, 'height': 493}","[{'@type': 'Person', 'name': 'Jacob Douglas', 'url': 'https://www.cnbc.com/jacob-douglas/'}]",2019-11-07T15:30:49+0000,2019-12-11T14:48:50+0000,"{'@type': 'NewsMediaOrganization', 'name': 'CNBC', 'url': 'https://www.cnbc.com/', 'foundingDate': '1989-04-17', 'logo': {'@type': 'ImageObject', 'url': 'https://sc.cnbcfm.com/applications/cnbc.com/staticcontent/img/cnbc-hdr-logo2.png', 'width': 378, 'height': 98}, 'sameAs': ['https://www.facebook.com/cnbc', 'https://www.instagram.com/cnbc', 'https://www.linkedin.com/company/cnbc', 'https://twitter.com/cnbc', 'https://en.wikipedia.org/wiki/CNBC', 'https://www.youtube.com/cnbc']}",,At Work,,,,https://image.cnbcfm.com/api/v1/image/105927121-190522fordrobot.jpg?v=1558524346&w=720&h=405,Technology,,https://www.cnbc.com/2019/11/07/these-american-workers-are-the-most-afraid-of-ai-taking-their-jobs.html,,,,,,"{'@type': 'VideoObject', 'contentUrl': 'http://pdl.iphone.cnbc.com/VCPS/Y2019/M11D04/7000106829/1572886535600-191104SAatwork_L.mp4', 'description': ""CNBC's Jon Fortt breaks down a new survey conducted by CNBC and SurveyMonkey that examines Americans' workplace optimism."", 'duration': 'PT1M2S', 'name': 'Survey: Majority of Americans hopeful for technology changes in the workplace', 'thumbnailUrl': 'https://image.cnbcfm.com/api/v1/image/106222238-191104saatwork.jpg?v=1572885946', 'uploadDate': '2019-11-04T16:43:28+0000'}",,2019-11-07T15:30:49+0000,,,,,,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', '/html/head/meta[@name=""description""]/@content'], 'cssSelector': ['.group p']}",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMipQFodHRwczovL3d3dy53YXNoaW5ndG9ucG9zdC5jb20vdGVjaG5vbG9neS8yMDE5LzExLzA2L3Byb21pbmVudC1yaWdodHMtZ3JvdXAtZmlsZXMtZmVkZXJhbC1jb21wbGFpbnQtYWdhaW5zdC1haS1oaXJpbmctZmlybS1oaXJldnVlLWNpdGluZy11bmZhaXItZGVjZXB0aXZlLXByYWN0aWNlcy_SAQA?oc=5,HireVue faces FTC complaint over ‘unfair and deceptive’ practices - The Washington Post,2019-11-06,The Washington Post,https://www.washingtonpost.com,"The Electronic Privacy Information Center urged the FTC to investigate HireVue’s business practices, saying its face-scanning technology threatens job candidates’ privacy rights and livelihoods.","HireVue, EPIC, FTC, facial recognition, unfair and deceptive, artificial intelligence, AI","The Electronic Privacy Information Center urged the FTC to investigate HireVue’s business practices, saying its face-scanning technology threatens job candidates’ privacy rights and livelihoods.","The Electronic Privacy Information Center urged the FTC to investigate HireVue’s business practices, saying its face-scanning technology threatens job candidates’ privacy rights and livelihoods.",https://schema.org,BreadcrumbList,https://www.washingtonpost.com/technology/2019/11/06/prominent-rights-group-files-federal-complaint-against-ai-hiring-firm-hirevue-citing-unfair-deceptive-practices/,"Rights group files federal complaint against AI-hiring firm HireVue, citing ‘unfair and deceptive’ practices","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/ATL7NYGPDEI6TJRABKIWK3L5WY.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/ATL7NYGPDEI6TJRABKIWK3L5WY.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/ATL7NYGPDEI6TJRABKIWK3L5WY.jpg&w=800&h=600', 'height': 800, 'width': 600}]","{'@type': 'Person', 'name': 'Drew Harwell', 'url': 'https://www.washingtonpost.com/people/drew-harwell/'}",2019-11-06T16:50:36.121Z,2019-11-06T22:31:36.447Z,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}","[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}]",Technology,,"The Federal Trade Commission building in Washington. (Alex Brandon/AP)By  Drew HarwellNovember 6, 2019 at 11:50 a.m. ESTA prominent rights group is urging the Federal Trade Commission to take on the recruiting-technology company HireVue, arguing that the firm has turned to unfair and deceptive trade practices in its use of face-scanning technology to assess job candidates’ “employability.”Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeThe Electronic Privacy Information Center, known as EPIC, on Wednesday filed an official complaint calling on the FTC to investigate HireVue’s business practices, saying the company’s use of unproven artificial intelligence systems that scan people’s faces and voices constituted a wide-scale threat to American workers.Share10 CommentsNewsletterAs news breaksTech News AlertsBreaking news email alerts on technology and the tech industry.Sign upSubscribe to comment and get the full experience. Choose your plan →",,,,,,,,,,,,,,,,HireVue faces FTC complaint over ‘unfair and deceptive’ practices,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vbmV3cy5hc3UuZWR1LzIwMTkxMTA4LXJvYm90LWNvd29ya2Vycy1ob3ctYWktaW1wYWN0cy1mdXR1cmUtd29ya9IBAA?oc=5,Robot coworkers: How AI impacts the future of work | ASU News - ASU News Now,2019-11-08,ASU News Now,https://news.asu.edu,"What happens when technology advancements threaten to automate people’s jobs?That question is on the minds of many as research and development in artificial intelligence and machine learning rapidly advances.A new project led by Siddharth Srivastava, an assistant professor in the School of Computing, Informatics, and Decision Systems Engineering at Arizona State University, aims to help alleviate this concern.",,,,,,,,,,,,,,,,"












Science and technology










Robot coworkers: How AI impacts the future of work






















Pulkit Verma, a graduate student member of Siddharth Srivastava’s research team, helps with efforts to reprogram autonomous robots using artificial intelligence. The new robots will not only be more adaptable to the manufacturing industry as it evolves, but they will also be equipped with intelligent tutoring systems to train factory workers to operate the robots. Photo by Erika Gronek/ASU























By Karishma Albal | 

November 08, 2019












ShareFacebookTwitterLinkedInEmail
















What happens when technology advancements threaten to automate people’s jobs?That question is on the minds of many as research and development in artificial intelligence and machine learning rapidly advances.A new project led by Siddharth Srivastava, an assistant professor in the School of Computing, Informatics, and Decision Systems Engineering at Arizona State University, aims to help alleviate this concern.Srivastava and his multidisciplinary team are creating autonomous systems that are not only more adaptable and efficient in manufacturing environments, but also have built-in intelligent tutoring systems that will cooperate with factory workers and retrain them to use AI technology so they are not displaced from their jobs.Funded by a $1 million grant from the National Science Foundation as one of its Convergence Accelerator awards, the project is highly focused on using AI to augment the workplace rather than replace workers.“Suppose you have this new robot, it’s very efficient, but you need to hire five computer science graduates to operate and maintain it instead of five current factory workers,” Srivastava said. “That’s not feasible, first of all because we don’t have that many computer science graduates in society. Our idea is that instead of getting people to enroll in a new college program again, what we can do instead is design our AI systems, our robots, in a way that will help people to come on board.”Srivastava is collaborating with ASU faculty members in the Ira A. Fulton Schools of Engineering and the School for the Future of Innovation in Society to bring the project to life.“We have 10 team members, including experts in robot control, tutoring systems and human systems engineering — a field that involves thinking about how the robot and the human would interact and how you would build a situation where the human trusts the robot,” Srivastava said. “We also have experts in law to help solve the sociotechnical aspects of the problem.”How artificial intelligence can preserve jobsTraditionally, AI has mostly been developed with a mind to automate human-performed tasks — that is, to perform tasks in place of a human. For example, machines play chess better than humans do and are also faster at distinguishing patterns and performing calculations. One example of AI working to augment human-performed tasks rather than replace them can be found in intelligent tutoring systems.The ASU team is focusing on this interaction, particularly in implementing the intelligent training systems for factory workers. This eliminates the concern about driving up the demand for highly educated workers to unsustainable levels and also empowers human workers to incorporate AI into their work.According to Subbarao Kambhampati, a professor of computer science, this education-based relationship is the key to successful collaboration between AI and humans. In particular, the AI systems need to learn to model the mental states of the humans they collaborate with, and use those models to guide their interactions with the humans.“We are now considering scenarios in which the AI system teaches humans on the job,” Kambhampati said. “If you are using one machine, and there is a big technological advancement, then the question is what is the best way to get people to come up to speed in using these new machines?”This retraining process is essential to helping factory workers in the evolving manufacturing industry keep their jobs. It’s a necessary transition into a future when machines can augment human activities without replacing the people who have traditionally performed them.In that scenario, workers would be able to assign robots a wider variety of tasks while the robots teach workers how to use the robots and why robots are making the decisions they do.“(Robots) are more adaptable in that their behavior adapts to the changes in their environment, they adapt to the tasks that you give them and at the same time they can answer your questions,” Srivastava said. “A worker who doesn’t know the internals of the robot can ask it, ‘Why did you go along this path when I think you should have just gone straight?’ And the robot can answer, ‘If I go this way then my hand might collide with that table.’ So, in that process, the worker learns about the robot’s constraints and how to operate it.”Moving toward a more robotic futureCould machines ever replace humans? Is it cheaper to have an all-robotic workforce?The answer is complicated, said Katina Michael, a professor jointly appointed in the School for the Future of Innovation in Society and the School of Computing, Informatics and Decision Systems Engineering, one of the six Fulton Schools.“At face value, initially it seems that robots would do better than the operational expenditure of the human labor force,” she said, “but when you look at this quite clinically, you’re almost shifting costs from the human labor force to the robotic labor force. It’s quite debatable as to whether costs will be reduced.”While robots can operate 24/7, people need breaks, time off, insurance coverage and compensation. However, robots must be updated and maintained, and they also need power to operate — human workers are still extremely necessary in the workplace.Although the research project is focused on AI development, it is ultimately centered around training human workers and ensuring job security. The team wants to enhance communication between both humans and robots to obtain the best of both worlds in the manufacturing industry.“Sadly, training diminishes with the increased cost of the capital investment,” Michael said. “Many corporations are trying to save money somewhere, but training is where we need to invest more money in order to have a successful integration of workers and autonomous systems so we can minimize safety risks. If we don’t have adequate training, we don’t have adequate responses to reducing the incidence of on-the-job disasters.”An interdisciplinary interactionIn highly multidisciplinary projects involving diverse skill sets and expertise in multiple areas, there are many factors to consider when humans team up with robots.“We’re interested primarily in how humans and robots work together,” Michael said. “With the humans doing their bit and the robots doing their bit, we want to see if there is any incongruousness or congruousness that can be observed. I’m also looking not only at the economic impact but also the societal impact, seeing if the workers who are interacting with these robots are receiving adequate training.”Erin Chiou, an assistant professor of human systems engineering at The Polytechnic School, one of the six Fulton Schools, is studying the interactions of humans and machines for data to guide the design of systems that prioritize the collaboration of humans and robots.“Ultimately, it’s getting that multidisciplinary conversation going between people who actually build the machines and people who think very critically about job design and human workers,” Chiou said. “It is relatively easy to optimize technology when you aren't thinking too deeply about how to involve people, because once you involve people, you introduce variation into the system. This makes the problem much more difficult. At the same time, this variation — or the ability for a system to adapt to different situations — is crucial for technology acceptance and for overall system performance.”The ASU team also has experts looking at the legal, social and economic implications of implementing such technology in the workplace, all of which will be considered when designing the new systems.“It’s not about changing the hardware, it’s about how to change the software,” Srivastava said. “We’re thinking about how it should act and what it should do. We are rethinking how a robot’s ‘mind’ should work in order to make it more amenable to providing on-the-job training and collaborating with humans.”




















Innovation School of Computing and Augmented Intelligence Faculty Polytechnic campus Tempe campus The Polytechnic School Engineering Science and technology Technology Ira A. Fulton Schools of Engineering Research School for the Future of Innovation in Society












More Science and technology

 
















Telescopes in Atacama Desert capture extreme starburst galaxy warped into fiery ring


Ten billion years in the past, a rare population of extreme galaxies formed stars at rates more than 1,000 times faster than our…




July 15, 2024





Read more



Grants / Awards Science Space exploration Research










AI has a future in learning


Arizona State University recognizes the importance of ethical considerations and is actively building safeguards to ensure…




July 15, 2024





Read more



Artificial intelligence Education Expert Q-and-A Technology










Study challenges traditional views of evolution


In new research, Arizona State University scientists and their colleagues investigated genetic changes occurring in a naturally…




July 12, 2024





Read more



Bioscience Research











Pagination




              Current page
            1




              Page
            2




              Page
            3




              Page
            4



              Next
            












",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmFiYy5uZXQuYXUvbmV3cy8yMDE5LTExLTA3L2V0aGljcy1mcmFtZXdvcmstdG8tb3ZlcnNlZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS8xMTY3ODQ2ONIBJ2h0dHBzOi8vYW1wLmFiYy5uZXQuYXUvYXJ0aWNsZS8xMTY3ODQ2OA?oc=5,Government's ethical artificial intelligence vision a far cry from Terminator-style robots - ABC News,2019-11-06,ABC News,https://www.abc.net.au,"Artificial intelligence should respect human rights, diversity and privacy, according to an ethics framework the Government hopes will prevent people from being exploited.","ai,artificial intelligence,karen andrews,ethical framework,robots","Artificial intelligence should respect human rights, diversity and privacy, according to an ethics framework the Government hopes will prevent people from being exploited.",,http://schema.org,NewsArticle,https://www.abc.net.au/news/2019-11-07/ethics-framework-to-oversee-artificial-intelligence/11678468,Government's ethical artificial intelligence vision a far cry from Terminator-style robots,"{'@type': 'ImageObject', 'height': 485, 'url': 'https://live-production.wcms.abc-cdn.net.au/7a59aaacc702a75c34e4a0552fe72694?impolicy=wcms_crop_resize&cropH=360&cropW=640&xPos=0&yPos=25&width=862&height=485', 'width': 862}","[{'@type': 'Person', 'name': 'Brett Worthington'}]",2019-11-06T17:31:21+00:00,2019-11-06T20:38:31+00:00,"{'@type': 'Organization', 'name': 'ABC News', 'logo': {'@type': 'ImageObject', 'height': 60, 'url': 'https://www.abc.net.au/res/abc/logos/amp-news-logo-60x240.png', 'width': 240}}",,,,"PoliticsGovernment's ethical artificial intelligence vision a far cry from Terminator-style robotsBy political correspondent Brett WorthingtonPosted Wed 6 Nov 2019 at 12:31pmWednesday 6 Nov 2019 at 12:31pmWed 6 Nov 2019 at 12:31pm, updated Wed 6 Nov 2019 at 3:38pmWednesday 6 Nov 2019 at 3:38pmWed 6 Nov 2019 at 3:38pm The government will release an eight-point guidance they want companies to adopt for AI technology.abc.net.au/news/ethics-framework-to-oversee-artificial-intelligence/11678468Copy linkLink copiedShareShare articleArtificial intelligence should respect human rights, diversity and privacy — while being a far cry from Terminator-style robots — according to new federal ethics guidelines.Key points:The Federal Government has released eight ethics guidelines it wants instilled into artificial intelligenceIt calls for AI to prevent discrimination, be inclusive and have human oversight capabilitiesTechnology Minister Karen Andrews insists people shouldn't fear losing their jobs to AITechnology Minister Karen Andrews will today release an eight-point guidance she wants companies to adopt in a bid to prevent people from being exploited.The guidelines stipulate all AI should benefit individuals, society and the environment. It should prevent discrimination, respect privacy and only operate in accordance with their intended purpose.The guidelines also recommend human oversight of AI always be enabled and there should be timely processes to allow people to challenge the use or output of information.""People do think of the Terminator when they think about artificial intelligence and robotics and those sorts of things,"" Ms Andrews said.""But that's not what we should be doing with artificial intelligence. It [AI] is positive, it will help people in their daily lives.""Ms Andrews conceded that while AI would change jobs, she was adamant people shouldn't fear it putting them out of work.She argued greater adoption of technology would give people opportunities to develop skills to better suit a future economy. Karen Andrews says an ethics framework could encourage businesses to make decisions in people's best interests.(ABC News: Matt Roberts)""It's important that we get the framework right for this because artificial intelligence can be quite scary to a lot of people,"" Ms Andrews said.""They seem to think it's robots taking over the world, robots taking their job, that machines are going to be making the decision for them.""The guidelines also urge companies to ensure people know when they are engaging with and being ""significantly impacted by an AI system"". The list of principles comes after Ms Andrews released an AI discussion paper in April.That paper was developed in conjunction with the CSIRO and designed to create an environment that would allow Australians to have greater trust in how AI was designed, developed and used by businesses and governments.You decide: Driverless carsDriverless cars could make our roads safer and reduce congestion. But the algorithms driving them will also have to make life-or-death decisions.Read moreThe Government received 130 submissions to the discussion paper and then brought together academics and the business community to develop the ethics guidelines.Telstra, Microsoft, NAB, Commonwealth Bank and Flamingo AI have agreed to test the eight points to see if they can be implemented in the real world.Ms Andrews said she hoped companies that were already using AI would review the guidelines and assess if they needed to make changes.""We want to make sure that we're setting it up for the future,"" Ms Andrews said.""There might well be many companies that have relied on principles that have been developed elsewhere around the world. What we wanted to do as a Government was look at what we could develop that was really targeted [and] focused on Australian needs."" The Government has released an artificial intelligence ethics framework it wants businesses to follow.(Reuters: Denis Balibouse)Given the guidelines are voluntary, there are no consequences for businesses that fail to develop ethical AI.""At this point, I'm not looking at bringing out the big stick that obviously sits there as a possibility but that would be a long way off before we got to that point,"" Ms Andrews said.""I think there is a strong willingness at the early stages of artificial intelligence for businesses wanting to get it right so this should prove the framework that they need.""Posted 6 Nov 20196 Nov 2019Wed 6 Nov 2019 at 12:31pm, updated 6 Nov 20196 Nov 2019Wed 6 Nov 2019 at 3:38pmShareCopy linkFacebookX (formerly Twitter)Related StoriesYou're approaching an intersection. A child runs out. What happens next is up to technologyCould a robot do your job? Find out nowIntelligent robots are coming, whether we have the policies to deal with them or not: reportMore on:AustraliaEthicsFederal GovernmentGovernment and PoliticsRoboticsTop StoriesSally McManus issues multiple denials over whether she knew of alleged criminality in CFMEUSuspected army spy's Instagram page reveals visit to sensitive Woomera military training areaHow Trump's bandaged ear stole the show on day one of the Republican conventionAnalysis by Kathryn DissTrump's near-assassination is part of long history of violence in the US. Here's why this feels differentIf all goes to plan this man will make Donald Trump one of the most powerful presidents of all timeWhy the current bird flu outbreak is unlike others we've had in the past'Our hearts are broken': Jay Slater's family speaks as Spanish authorities confirm his body has been foundIsraeli strikes across Gaza kill at least 50, Palestinian health officials sayTenacious D's remaining Australian concerts cancelled amid Trump joke controversyBoy, 11, killed after being hit by school bus while riding his bike at Sunshine CoastEizabeth Struhs was 'emaciated, malnourished' in hospital admission three years before her death, clinician tells court Gareth Southgate resigns as England football manager after Euro 2024 loss'Swan-uppers' will put on an eccentric show on the Thames for five days. Here's what to know about the 800-year-old royal traditionGiants' Bedford and Lions' Cameron have bans upheld at AFL TribunalA reclusive whale scientists know virtually nothing about is found stranded at a New Zealand beachPopular NowDon't miss news that matters to you. Log in to ABC today to get a more personalised experience tailored to your preferences.GET STARTED1.Tenacious D's remaining Australian concerts cancelled amid Trump joke controversy2.'Our hearts are broken': Jay Slater's family speaks as Spanish authorities confirm his body has been found3.Sally McManus issues multiple denials over whether she knew of alleged criminality in CFMEU4.Freak bus crash in Spain leaves dozens injured after vehicle becomes nearly vertical at tunnel exit5.If all goes to plan this man will make Donald Trump one of the most powerful presidents of all time6.Analysis by Kathryn Dissanalysis:Trump's near-assassination is part of long history of violence in the US. Here's why this feels differentTop StoriesSally McManus issues multiple denials over whether she knew of alleged criminality in CFMEUSuspected army spy's Instagram page reveals visit to sensitive Woomera military training areaHow Trump's bandaged ear stole the show on day one of the Republican conventionAnalysis by Kathryn DissTrump's near-assassination is part of long history of violence in the US. Here's why this feels differentIf all goes to plan this man will make Donald Trump one of the most powerful presidents of all timeJust InIsraeli strikes across Gaza kill at least 50, Palestinian health officials say3h ago3 hours agoTue 16 Jul 2024 at 9:22am'Our hearts are broken': Jay Slater's family speaks as Spanish authorities confirm his body has been found3h ago3 hours agoTue 16 Jul 2024 at 8:53amFreak bus crash in Spain leaves dozens injured after vehicle becomes nearly vertical at tunnel exit5h ago5 hours agoTue 16 Jul 2024 at 7:32amSally McManus issues multiple denials over whether she knew of alleged criminality in CFMEU5h ago5 hours agoTue 16 Jul 2024 at 7:29amMore Just InBack to top",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmFzaWFuYWdlLmNvbS9idXNpbmVzcy9pbi1vdGhlci1uZXdzLzA3MTExOS9pbmRpYW4td29tZW4tbWFrZS1hLW1hcmstaW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc2tpbGxzLmh0bWzSAXpodHRwczovL3d3dy5hc2lhbmFnZS5jb20vYW1wL2J1c2luZXNzL2luLW90aGVyLW5ld3MvMDcxMTE5L2luZGlhbi13b21lbi1tYWtlLWEtbWFyay1pbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1za2lsbHMuaHRtbA?oc=5,Indian women make a mark in artificial intelligence skills - The Asian Age,2019-11-07,The Asian Age,https://www.asianage.com,"The country's gender inequality is difficult to tackle, as women in India have a low 27 per cent rate of workforce participation.","Indian women, artificial intelligence","The country's gender inequality is difficult to tackle, as women in India have a low 27 per cent rate of workforce participation.","The country's gender inequality is difficult to tackle, as women in India have a low 27 per cent rate of workforce participation.",https://schema.org,WebPage,"{'@type': 'WebPage', '@id': 'https://www.asianage.com/business/in-other-news/071119/indian-women-make-a-mark-in-artificial-intelligence-skills.html'}",Indian women make a mark in artificial intelligence skills,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'contentUrl': 'https://s3.ap-southeast-1.amazonaws.com/images.asianage.com/images/aa-Cover-uinpbfugod1k6t50tpchcjplc5-20191107044029.Medi.jpeg', 'height': 900, 'width': 1500, 'url': 'https://s3.ap-southeast-1.amazonaws.com/images.asianage.com/images/aa-Cover-uinpbfugod1k6t50tpchcjplc5-20191107044029.Medi.jpeg'}","{'@type': 'Person', 'name': 'asian'}",2019-11-07T04:40:46+05:30,2019-11-07T04:40:46+05:30,"{'@type': 'Organization', 'name': 'asian', 'url': 'https://www.asianage.com', 'sameAs': [], 'logo': {'@context': 'https://schema.org', '@type': 'ImageObject', 'contentUrl': 'https://www.asianage.com/images/logo.png', 'height': '60', 'width': '600', 'name': 'asian - Logo', 'url': 'https://www.asianage.com/images/logo.png'}}","[{'@type': 'ListItem', 'position': '1', 'item': {'@id': 'https://www.asianage.com', '@type': 'Thing', 'name': 'Home'}}, {'@type': 'ListItem', 'position': '2', 'item': {'@id': 'https://www.asianage.com/business', '@type': 'WebPage', 'name': 'Business'}}, {'@type': 'ListItem', 'position': '3', 'item': {'@id': 'https://www.asianage.com/business/in-other-news/071119/indian-women-make-a-mark-in-artificial-intelligence-skills.html', '@type': 'WebPage', 'name': 'Indian women make a mark in artificial intelligence skills'}}]",Business,,,Indian women make a mark in artificial intelligence skills,,Business,,https://www.asianage.com/business/in-other-news/071119/indian-women-make-a-mark-in-artificial-intelligence-skills.html,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'contentUrl': 'https://www.asianage.com/images/logo.png', 'height': '60', 'width': '600', 'name': 'asian - Logo', 'url': 'https://www.asianage.com/images/logo.png'}",[],,,,,,,en,Indian women make a mark in artificial intelligence skills | Indian women make a mark in artificial...,,The Asian Age,,,,,,,,,,,,,mixed,,"Chennai: India is inconsistent when it comes to women advancement in the workforce, finds a global study. While India has a low 27 per cent women participation in workforce, it has a higher-than-average share of women with artificial intelligence skill sets.  Heidrick and Struggles, a global provider of executive search, leadership assessment and development, found that India has an inconsistent history of women&rsquo;s advancement, shaped by cultural norms that strongly favour males from birth. The country&rsquo;s gender inequality is difficult to tackle, as women in India have a low 27 per cent rate of workforce participation. The report finds that the low participation rate is attributed to various cultural factors, as well as challenges faced by women in the workplace, such as healthcare access, gender bias, and lack of flexible working opportunities.  But there have been some positive trends as well. Indian has higher-than-average share of women with artificial intelligence skill sets (22 per cent) compared to other countries.  &ldquo;Thanks to the growing involvement of leaders committed to creating a more inclusive work environment, we are seeing a growing trend of more women becoming equipped with the latest technology skill sets. This indicates an increasing number of women in India are entering a space which was commonly seen as a male-dominated domain,&rdquo; Gauri Padmanabhan, Partner, Heidrick & Struggles said.  The study found that the government has taken a number of initiatives such as furthering girls&rsquo; education, improved healthcare, and maternity benefits, which tackle some of the basic challenges faced by women in the workplace. The Sebi has formulated guidelines for the inclusion of women on the boards of listed companies by early 2020 and companies are also implementing their own programmes. Many IT companies are computer programming boot camp specifically for women developers who have left the field but are interested in reskilling and rejoining the technical workforce.  &ldquo;Most academic excellence entrance examinations have been showcasing the growing dominance of women amongst rank holders and across all streams including science and engineering hence the findings are not surprising as well as equally welcoming. However the question that arise in my mind is how many of these women actually find their way into the active formal workforce as well as stay there,&rsquo; said Rituparna Chakraborty,  co-founder and executive vice president of TeamLease Services.     Though Diversity and Inclusion programmes in Asia are focusing on women in leadership, race and ethnicity and sexual orientation, in India the programmes are dominated by women-focused initiatives. Programmes focused on race and ethnicity and LGBTQ engagement are still at a nascent stage in the country.  &ldquo;Going forward, Indian businesses need to widen the scope of D&I with the objective of including the LGBTQ community and differently-abled people. Tackling gender disparity in India is currently the foremost concern, given our cultural norms. But as women break barriers and step forward in every area, we will gradually be able to create pathways for inclusion of other communities and this will indeed be welcome progress,&rdquo; said Padmanabhan.",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMipAFodHRwczovL3d3dy50aGV3ZWVrbHlqb3VybmFsLmNvbS90b3Atc3Rvcmllcy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jb3VsZC1iZS1rZXktdG8tcHVlcnRvLXJpY28tcy1lY29ub21pYy1ncm93dGgvYXJ0aWNsZV81NGExZDU2OC0wMDBkLTExZWEtYmY2Yy1jNzM5MmJlMGFkYTEuaHRtbNIBAA?oc=5,Artificial Intelligence Could be Key to Puerto Rico's Economic Growth - The Weekly Journal,2019-11-07,The Weekly Journal,https://www.theweeklyjournal.com,Study aims to demystify misconceptions about AI to boost productivity earnings and create new jobs,,Study aims to demystify misconceptions about AI to boost productivity earnings and create new jobs,,https://schema.org,Organization,,,,,,,,,,,"Puerto Rico and The CaribbeanEditor's Picks
",,,,,http://www.theweeklyjournal.com,,,"['https://www.facebook.com/wjournalpr', 'https://twitter.com/wjournalpr', 'https://www.linkedin.com/company/35641743']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vYW5hbHl0aWNzaW5kaWFtYWcuY29tL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWdyYWRlLWVzc2F5LXN0dWRlbnQv0gEA?oc=5,Can AI Replace Teachers To Grade Student Essays? A Lesson From US Schools - AIM,2019-11-08,AIM,https://analyticsindiamag.com,,,,,,,,,,,,,,,,,"










				Meta AI Glasses Miss The Mark 			



			Tarunya S		

			16/07/2024		


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigQFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL3BhdHJpY2lhZ2Jhcm5lcy8yMDE5LzExLzEwL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXBvc2VzLW5ldy10aHJlYXQtdG8tZXF1YWwtZW1wbG95bWVudC1vcHBvcnR1bml0eS_SAQA?oc=5,Artificial Intelligence Poses New Threat to Equal Employment Opportunity - Forbes,2019-11-11,Forbes,https://www.forbes.com,"Just when we thought it was safe to go back in the water, a new threat has emerged to equal employment opportunity as employers base hiring decisions on artificial intelligence powered video and game-based “pre-employment” assessments of job candidates.","Electronic Frontier Foundation,HireVue,artificial intelligence,algorithm,video games,Amazon,Unviersity of Maryland Robert H. Smith School of Business,robots,Federal Trade Commission","Just when we thought it was safe to go back in the water, a new threat has emerged to equal employment opportunity as employers base hiring decisions on artificial intelligence powered video and game-based “pre-employment” assessments of job candidates.","Just when we thought it was safe to go back in the water, a new threat has emerged to equal employment opportunity as employers base hiring decisions on artificial intelligence powered video and game-based “pre-employment” assessments of job candidates.",http://schema.org,BreadcrumbList,,Artificial Intelligence Poses New Threat to Equal Employment Opportunity,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5dc85b3ce0af7b0006b100ed/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Patricia Barnes', 'url': 'https://www.forbes.com/sites/patriciagbarnes/', 'description': 'I am an attorney, former judge, and recognized authority on age discrimination in employment. After experiencing age discrimination during the Great Recession, I began researching the problem. I was surprised to learn that older workers have far fewer protections under U.S. law than victims of discrimination based on race, sex, religion, color and national origin. In addition, age discrimination is correlated with ill health, poverty and suffering in old age. I began writing about the problem and became a consultant for employers and employees who are confronting age discrimination in the workplace. I am the author of Overcoming Age Discrimination In Employment (2016) and Betrayed: The Legalization Of Age Discrimination In The Workplace (2014). I also write the blog, AgeDiscriminationInEmployment.com. Over the years, I have been interviewed by many national media outlets, including The New York Times, Bloomberg, CNBC, Fast Company, etc. The Society for Human Resource Management has called me a “diversity and inclusion” leader and a “nationally recognized expert on age discrimination.”', 'sameAs': ['https://www.agediscriminationinemployment.com/']}",2019-11-10T13:57:46-05:00,2019-11-11T13:09:58-05:00,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Leadership', 'item': 'https://www.forbes.com/leadership/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Diversity, Equity & Inclusion', 'item': 'https://www.forbes.com/diversity-equity-inclusion/'}]","Diversity, Equity & Inclusion",,"More From ForbesJul 16, 2024,07:00am EDT2024 Disability Equality Index Offers Snapshot Of Global Corporate Disability InclusionJul 15, 2024,06:48pm EDTHow PBS Kids’ ‘City Island’ Is Making Learning About Civics, Community More Accessible To Every ChildJul 15, 2024,01:42pm EDTApple’s Refreshed HomePod Mini Reminds Smart Speakers Are Invaluable Tools For AccessibilityJul 15, 2024,10:11am EDTToxic Workplaces Are Wellbeing Killers — Here's What You Can DoJul 15, 2024,10:09am EDTImmigration Continues To Drive Population Growth In England And WalesJul 14, 2024,08:00am EDTHow To Talk About DEI At Work In A Polarizing Political ClimateJul 12, 2024,01:30pm EDTRazer CEO Min-Liang Tan Talks Better Gaming For Lefties, Diversity And Inclusion, More In InterviewEdit StoryForbesLeadershipDiversity, Equity & InclusionEditors' PickArtificial Intelligence Poses New Threat to Equal Employment OpportunityPatricia BarnesFormer ContributorOpinions expressed by Forbes Contributors are their own.I am an attorney, author and consultant on employment discrimination.Click to save this article.You'll be asked to sign into your Forbes account.Got itNov 10, 2019,01:57pm ESTUpdated Nov 11, 2019, 01:09pm ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinGetty
Just when we thought it was safe to go back in the water, a new threat has emerged to equal employment opportunity as employers base hiring decisions on artificial intelligence powered video and game-based “pre-employment” assessments of job candidates.


The Electronic Privacy Information Center, a public interest research center based in Washington, D.C., recently asked the Federal Trade Commission to investigate HireVue, a recruiting company based in Utah that purports to evaluate a job applicant’s job qualifications through online “video interview” and/or “game-based challenge.”

According to its web site, HireVue has more than 700 customers worldwide including over one-third of the Fortune 100 and such leading brands such as Unilever, Hilton, JP Morgan Chase, Delta Air Lines, Vodafone, Carnival Cruise Line, and Goldman Sachs. The company states it has hosted more than ten million on-demand interviews and one million assessments.

PROMOTED
The EPIC complaint follows a wave of lawsuits in recent years charging that employers are using software algorithms to discriminate against older workers by targeting internet job advertisements exclusively to younger workers.

HireVue uses a proprietary algorithm to assess “tens of thousands of data points” from candidate video interviews, including the candidate’s “intonation,” “inflection” and “emotions.” These and other data points are input into “predictive algorithms” that compare candidates with a company’s top performers.
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report Says
HireVue states its video-based algorithmic assessments provide “excellent insight into attributes like social intelligence (interpersonal skills), communication skills, personality traits, and overall job aptitude.”









CxO
US


CEO: C-suite news, analysis, and advice for top decision makers right to your inbox.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the CEO newsletter!


                More Newsletters
            


You’re all set! Enjoy the CEO newsletter!

                More Newsletters
            



EPIC states HireVue’s “business practices produce results that are biased, unprovable and not replicable.”
Video Games And Older Workers
The EPIC complaint focuses upon potential bias against women and minorities but the concept of using video game-based assessments seems particularly suspect with respect to older workers.


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
The  average age of video game players is in the mid-30s.  Many older workers do not play video games and it is likely that fewer older women than men have done so.  Even if they have, their response would likely be slower than a skilled young gamer.
Loren Larsen, Chief Technology Officer at HireVue, states in a press release that game-based assessments measure ‘emotional IQ” and “build upon the understanding of cognitive ability, enabling hiring managers to understand more about a candidate’s abilities.”
Do Video Interviews Penalize ‘Out of the Box’ Candidates?
EPIC says HireVue “collects facial data from job candidates to evaluate expressions of emotion and personality” It says so-called “facial action units” make up to 29 percent of a candidate’s score.
But how does HireVue’s algorithm assess overweight candidates, those who suffer from depression or non-native English speakers? What about candidates with autism who tend to look at people’s mouths and avoid direct eye contact?
HireVue issued a press release in September announcing it has partnered with Integrate Autism Employment Advisors, a nonprofit organization that helps companies recruit “qualified professionals on the autism spectrum.” The 600 candidates in Integrate Autism’s network will be coached on how to use HireVue’s platform more “efficiently and effectively.” Would such an effort be necessary if HireVue’s algorithm didn’t penalize autistic candidates.
EPIC states the University of Maryland Robert H. Smith School of Business tells students preparing for AI interviews, “Robots compare you against existing success stories; they don’t look for out of-the-box candidates.”
EPIC notes that Amazon abandoned an AI recruiting tool after learning that historical employment data preferred male candidates over women.  In that case, the system penalized resumes that included the word “women’s” and the names of all-women’s colleges. EPIC contends the only way to really tell if a hiring algorithm is non-biased is to  “turn it off and hire someone using other criteria to figure out if they meet or fall short of the same performance standards.”
The Algorithm is Secret
The bottom line is that HireVue’s algorithm is secret so the public has no way of knowing whether it discriminates against older workers, women, the disabled and minorities, etc. EPIC says HireVue refuses to provide job applicants with their assessment score.
EPIC charges that HireVue violates the Federal Trade Communications Act because it lacks a  “reasonable basis” to support its claims and cannot be held accountable for the proper functioning of its secret algorithmic assessments. EPIC also disputes HireVue’s contention that it does not use facial recognition technology for identity recognition purposes, which has been found to be a violation of the FTC Act.
EPIC alleges HireVue’s platform also fails to meet minimal standards for AI-based decision-making set out in AI Principles approved by the 36-member countries of the Organisation for Economic Co-Operation and Development (OECD), including the U.S. These principles say everyone has a right to know the basis for an AI decision that concerns them, AI systems should be deployed only after an adequate evaluation of its risks and institutions must ensure that AI systems do not reflect unfair bias.
Check out my website. Patricia BarnesI am an attorney, former judge, and recognized authority on age discrimination in employment. 
 
After experiencing age discrimination during the Great... Read MoreEditorial StandardsPrintReprints & Permissions",Artificial Intelligence Poses New Threat to Equal Employment Opportunity,,"Diversity, Equity & Inclusion",,https://www.forbes.com/sites/patriciagbarnes/2019/11/10/artificial-intelligence-poses-new-threat-to-equal-employment-opportunity/,,,,,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMikgFodHRwczovL3d3dy5jb2UuaW50L2VuL3dlYi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS8tL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWludGVyZ292ZXJubWVudGFsLWNvbW1pdHRlZS1leGFtaW5lcy1mZWFzaWJpbGl0eS1vZi1hLWxlZ2FsLWZyYW1ld29ya9IBAA?oc=5,First meeting of the Ad hoc Committee on Artificial Intelligence (CAHAI) - Artificial Intelligence - Council of Europe,2019-11-15,Council of Europe,https://www.coe.int,Latest news of the Council of Europe's work related to AI,"newsroom,ai,dg1 human rights and rule of law,central division dg1,public,compulsory,general, news, ai, council of europe",Latest news of the Council of Europe's work related to AI, strasbourg 15/11/2019,https://schema.org,WebPage,"{'@type': 'WebPage', '@id': 'https://www.coe.int/en/web/artificial-intelligence/-/artificial-intelligence-intergovernmental-committee-examines-feasibility-of-a-legal-framework'}",First meeting of the Ad hoc Committee on Artificial Intelligence (CAHAI),"{'@type': 'ImageObject', 'url': 'https://www.coe.int/documents/40452431/43029712/CAHAI+first+meeting+room.jpg/0a35eab2-a87c-680d-4230-f2aeb3f42470', 'height': 489, 'width': 870}","{'@type': 'Organization', 'name': 'Council of Europe'}",2019-11-15T17:17:00+00:00,2024-05-17,"{'@type': 'Organization', 'name': 'Council of Europe', 'logo': {'@type': 'ImageObject', 'url': 'https://static.coe.int/pics/logos/desktop/logo-coe-google-news.png', 'width': 78, 'height': 60}}",,,,"

strasbourg
15/11/2019


                Diminuer la taille du texte
            

                Augmenter la taille du texte
            

                Imprimer la page
            





The Ad hoc Committee on Artificial Intelligence (CAHAI), an intergovernmental committee set up by Committee of Ministers of the Council of Europe to examine the feasibility of a legal framework for the development, design and application of artificial intelligence based on the organisation´s standards on human rights, democracy and the rule of law, is holding its first meeting in Strasbourg from 18 to 20 November.
The committee, which brings together representatives from the organisation´s 47 Member States, will have an exchange of views with leading experts on the impact of AI applications on individuals and society, the existing soft law instruments specifically dealing with AI and the existing legally binding international frameworks applicable to AI. It will also examine different national initiatives, policies and strategies, as well as the work undertaken so far by the Council of Europe and other organisations in this field.
In addition, the CAHAI will discuss the content of a feasibility study on a Council of Europe legal framework on AI, which will be completed following broad multi-stakeholder consultations with the private sector and civil society. Important issues which might be addressed by the feasibility study include the need for a common definition of AI, the mapping of the risks and opportunities arising from AI, notably its impact on human rights, rule of law and democracy, as well the opportunity to move towards a binding legal framework.
Deputy Secretary General Gabriella Battaini-Dragoni will deliver a speech at the opening.

Council of Europe and Artificial Intelligence
Speech by Gabriella Battaini-Dragoni 

",News,,,,,,,,,,,,2018-11-28,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9jYXBhYmlsaXRpZXMvbWNraW5zZXktZGlnaXRhbC9vdXItaW5zaWdodHMvZ2V0dGluZy10by1zY2FsZS13aXRoLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Scaling AI in business - McKinsey,2019-11-13,McKinsey,https://www.mckinsey.com,Companies scaling AI across the organization are investing as much in people and processes as in technology.,,Companies scaling AI across the organization are investing as much in people and processes as in technology.,Companies scaling AI across the organization are investing as much in people and processes as in technology.,https://schema.org,Podcast,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/getting-to-scale-with-artificial-intelligence'}",,https://www.mckinsey.com/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/getting%20to%20scale%20with%20artificial%20intelligence/getting-to-scale-5050-offset200-1536x1536.jpg,,2019-11-13T00:00:00Z,2019-11-13T00:00:00Z,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,,,,,,,,https://www.mckinsey.com,,,,,,,,2023-02-22T13:03:49Z,,,,,,,,,,,,,,,,,,,,,Getting to scale with artificial intelligence,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvcmlza3MtYW5kLXJlbWVkaWVzLWZvci1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1oZWFsdGgtY2FyZS_SAQA?oc=5,Risks and remedies for artificial intelligence in health care | Brookings - Brookings Institution,2019-11-14,Brookings Institution,https://www.brookings.edu,AI already plays a major role in health care.,,AI already plays a major role in health care.,,https://schema.org,,,,,,,,,,,,"

 Back to Janesville 









                        Back to Janesville 
",,,,"[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/risks-and-remedies-for-artificial-intelligence-in-health-care/', 'url': 'https://www.brookings.edu/articles/risks-and-remedies-for-artificial-intelligence-in-health-care/', 'name': 'Risks and remedies for artificial intelligence in health care | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/risks-and-remedies-for-artificial-intelligence-in-health-care/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/risks-and-remedies-for-artificial-intelligence-in-health-care/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2019/07/primary-care.jpg?quality=75', 'datePublished': '2019-11-14T16:15:12+00:00', 'dateModified': '2022-03-09T04:38:10+00:00', 'description': 'AI already plays a major role in health care.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/risks-and-remedies-for-artificial-intelligence-in-health-care/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/risks-and-remedies-for-artificial-intelligence-in-health-care/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/risks-and-remedies-for-artificial-intelligence-in-health-care/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2019/07/primary-care.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2019/07/primary-care.jpg?quality=75', 'width': 3500, 'height': 2149, 'caption': ""Doctors Jordan Klein (2nd R) and Chane Price (R) confer as University of Miami interns Ignatios Papas (L) and Tim Sterrenberg (2nd L) look on in the Rehabilitation Unit of Jackson Memorial Hospital in Miami, September 30, 2013. The Obama administration accelerated its push to persuade individual Americans to sign up for the most extensive overhaul of the U.S. healthcare system in 50 years, the Affordable Care Act (commonly referred to as \x93Obamacare\x94) even as the program's foes in Congress fought to delay its launch with the threat of a federal government shutdown. The Jackson Health System is the largest in Florida and one of the largest in the U.S. REUTERS/Joe Skipper (UNITED STATES - Tags: HEALTH) - RTR3FGCZ""}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/risks-and-remedies-for-artificial-intelligence-in-health-care/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Risks and remedies for artificial intelligence in health care'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMinQFodHRwczovL25ld3Nyb29tLmFjY2VudHVyZS5jb20vbmV3cy8yMDE5L2ZhaWx1cmUtdG8tc2NhbGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY291bGQtcHV0LTc1LXBlcmNlbnQtb2Ytb3JnYW5pemF0aW9ucy1vdXQtb2YtYnVzaW5lc3MtYWNjZW50dXJlLXN0dWR5LXNob3dz0gEA?oc=5,"Failure to Scale Artificial Intelligence Could Put 75% of Organizations Out of Business, Accenture Study Shows - Newsroom | Accenture",2019-11-14,Newsroom | Accenture,https://newsroom.accenture.com,"NEW YORK; Nov. 14, 2019 - Three-quarters of C-level executives believe if they don&rsquo;t move beyond experimentation to aggressively deploy artificial intelligence","AI, built to scale","NEW YORK; Nov. 14, 2019 - Three-quarters of C-level executives believe if they don&rsquo;t move beyond experimentation to aggressively deploy artificial intelligence","NEW YORK; Nov. 14, 2019 - Three-quarters of C-level executives believe if they don&rsquo;t move beyond experimentation to aggressively deploy artificial intelligence",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAxOS8xMS8xMS8xMy1taW5kLWJsb3dpbmctdGhpbmdzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNhbi1hbHJlYWR5LWRvLXRvZGF5L9IBAA?oc=5,13 Mind-Blowing Things Artificial Intelligence Can Already Do Today - Forbes,2019-11-11,Forbes,https://www.forbes.com,"Artificial intelligence (AI) is gaining ground in our everyday lives, but some of the specific skills it can do might still be a surprise. It is intriguing to consider the power of a machine who could do all these things. Here are 13 mind-blowing things AI can already do today.","ai,artificial intelligence","Artificial intelligence (AI) is gaining ground in our everyday lives, but some of the specific skills it can do might still be a surprise. It is intriguing to consider the power of a machine who could do all these things. Here are 13 mind-blowing things AI can already do today.","Artificial intelligence (AI) is gaining ground in our everyday lives, but some of the specific skills it can do might still be a surprise. It is intriguing to consider the power of a machine who could do all these things. Here are 13 mind-blowing things AI can already do today.",http://schema.org,BreadcrumbList,,13 Mind-Blowing Things Artificial Intelligence Can Already Do Today,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5dc8f17dea103f00065224b7/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}",2019-11-11T00:31:15-05:00,2021-12-10T08:30:38-05:00,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise Tech13 Mind-Blowing Things Artificial Intelligence Can Already Do TodayBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 11, 2019,12:31am ESTUpdated Dec 10, 2021, 08:30am ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinBy now, most of us are aware of artificial intelligence (AI) being an increasingly present part of our everyday lives. But, many of us would be quite surprised to learn of some of the skills AI already knows how to do. Here are 13 mind-blowing skills artificial intelligence can already do today.
13 Mind-Blowing Things Artificial Intelligence Can Already Do TodayAdobe Stock

1.           Read

Is one of your wishes to save time by only having to pay attention to the salient points of communication? Your wish has come true with artificial intelligence-powered SummarizeBot. Whether it's news articles, weblinks, books, emails, legal documents, audio and image files, and more, automatic text summarization by artificial intelligence and machine learning reads communication and reports back the essential information. Currently, SummarizeBot can be used in Facebook Messenger or Slack and relies on natural language processing, machine learning, artificial intelligence, and blockchain technologies.

2.           Write

Would you believe that along with professional journalists, news organizations such as The New York Times, Washington Post, Reuters, and more rely on artificial intelligence to write? They do, and although this does include many ""who, what, where, when, and how"" formulaic pieces, AI is able to expand beyond this to more creative writing as well. Many marketers are turning to artificial intelligence to craft their social media posts. Even a novel has even been generated by artificial intelligence that was short-listed for an award.
PROMOTED
3.           See
Machine vision is when computers can “see” the world, analyze visual data, and make decisions about it. There are so many amazing ways machine vision is used today, including enabling self-driving cars, facial recognition for police work, payment portals, and more. In manufacturing, the ability for machines to see helps in predictive maintenance and product quality control.
MORE FROMFORBES ADVISORBest High-Yield Savings Accounts Of 2024ByKevin PayneContributorBest 5% Interest Savings Accounts of 2024ByCassidy HortonContributor
4.           Hear and understand
Did you know artificial intelligence is able to detect gunshots, analyze the sound, and then alert relevant agencies? This is one of the mind-blowing things AI can do when it hears and understands sounds. And who can refute the helpfulness of digital voice assistants to respond to your queries whether you want a weather report or your day's agenda? Business professionals love the convenience, efficiency, and accuracy provided by AI through automated meeting minutes.  









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



5. Speak
Artificial intelligence can also speak. While it’s helpful (and fun) to have Alexa and Google Maps respond to your queries and give you directions, Google Duplex takes it one step further and uses AI to schedule appointments and complete tasks over the phone in very conversational language. It can respond accurately to the responses given by the humans it’s talking to as well. 


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
6. Smell
There are artificial intelligence researchers who are currently developing AI models that will be able to detect illnesses—just by smelling a human's breath. It can detect chemicals called aldehydes that are associated with human illnesses and stress, including cancer, diabetes, brain injuries, and detecting the ""woody, musky odor"" emitted from Parkinson's disease even before any other symptoms are identified. Artificially intelligent bots could identify gas leaks or other caustic chemicals, as well. IBM is even using AI to develop new perfumes.
7. Touch
Using sensors and cameras, there's a robot that can identify ""supermarket ripe"" raspberries and even pick them and place them into a basket! Its creator says that it will eventually be able to pick one raspberry every 10 seconds for 20 hours a day! The next step for AI tactile development is to link touch with other senses.
8. Move
Artificial intelligence propels all kinds of movement from autonomous vehicles to drones to robots. The Alter 3 production at Tokyo’s New National Theatre features robots that can generate motion autonomously. 
9. Understand emotions
Market research is being aided by AI tools that track a person’s emotions as they watch videos. Artificial emotional intelligence can gather data from a person's facial expressions, body language, and more, analyze it against an emotion database to determine what emotion is likely being expressed, and then determine an action based on that info.  
10. Play games
It's not all serious business with artificial intelligence—it can learn to play games such as chess, Go, and poker (which was an incredible feat)! And, turns out that AI can learn to play these games plus compete and even beat humans at them!
11. Debate
IBM’s Project Debater showed us that artificial intelligence can even be successful at debating humans in complex subjects. Not only is it able to research a topic, but it can also create an engaging point of view and craft rebuttals against a human opponent.
12. Create
Artificial intelligence can even master creative processes, including making visual art, writing poetry, composing music, and taking photographs. Google's AI was even able to create its own AI “child”—that outperformed human-made counterparts.
13.   Read your mind
This is truly mind-boggling—AI that can read your mind! It can interpret brain signals and then create speech. Impressive and life-changing for those with speech impairment, but a little bit unnerving when you consider the mind-reading aspect of the skill. It's no surprise that some of the biggest tech giants, including Facebook and Elon Musk have their own projects underway to capitalize on AI's mind-reading potential.
Now imagine if these 13 mind-blowing skills were all combined into one super artificial intelligence! Frightening or exhilarating? That’s up to you to decide, but I think we can all agree, it would be mind-blowing!
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",13 Mind-Blowing Things Artificial Intelligence Can Already Do Today,,Enterprise & Cloud,,https://www.forbes.com/sites/bernardmarr/2019/11/11/13-mind-blowing-things-artificial-intelligence-can-already-do-today/,,,,,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3Lm1pYy5jb20vaW1wYWN0L2hvdy1kb2VzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXdvcmstd2hhdC1kby1wZW9wbGUtbWVhbi13aGVuLXRoZXktc2F5LWFpLTE5Mjg1NTc20gEA?oc=5,"How does artificial intelligence work, and what do people mean when they say 'AI?' - Mic",2019-11-12,Mic,https://www.mic.com,"If you spend any modicum of your time on the internet, or even dabbling in the tech world, you've no doubt seen mentions of ""AI,"" or artificial intelligence, here and there. In the past few years it's become something of a buzzy catchword in the…",,"If you spend any modicum of your time on the internet, or even dabbling in the tech world, you've no doubt seen mentions of ""AI,"" or artificial intelligence, here and there. In the past few years it's become something of a buzzy catchword in the…",,https://schema.org,,,,,,,,,,,,"How artificial intelligence came to be almost everywhereShutterstockImpactByBrittany VincentUpdated: Feb. 20, 2024Originally Published: November 12, 2019If you spend any modicum of your time on the internet, or even dabbling in the tech world, you've no doubt seen mentions of ""AI,"" or artificial intelligence, here and there. In the past few years it's become something of a buzzy catchword in the industry. And it seems like every website, app, and game is using it. There's a website that uses AI to rate how ""cool"" your selfies are. People ""feed"" AI scripts of popular movies and TV shows to have software spit out a new script based on what it ""learned"" from the source material. Recently, you may have even seen that an AI had ""mastered"" the video game StarCraft II, and performs at a level that's better than 99.8% of human players. But what do people typically mean when they say something is powered by AI? What all does it encompass, and how do you interact with AI on a daily basis? If you're unsure about how all of these pieces fall into place, here's how you can understand the world of artificial intelligence and its various applications. What is artificial intelligence (AI), and what do people typically mean when they say they're using it?In the 1950s, when Marvin Minsky built the first neural network simulator alongside John McCarthy, the pair described artificial intelligence as tasks performed by a program or a machine that you couldn't reasonably determine if a human had performed or not instead. To put it in even simpler terms: ""It’s just another way of writing software. Relax!"" Michael Capps, PhD, former president of Epic Games, and cofounder and CEO of AI startup Diveplane tells Mic. ""Company.com from the 90s became eCompany and then iCompany and then CloudCompany are now Company.ai. Who cares?""So we have two definitions: Artificial intelligence is both the latest ""trendy"" way to write software, so to speak, as well as a way of automating tasks that humans could do in a way that makes it hard to tell if a human or computer performed them. But the most important core component of AI constructs and programs, given that they're modeled after human intelligence, is the fact that they learn. In fact, they'll display some of the same behaviors as humans when they're beginning to understand something. Learning is an important tenet of any artificial intelligence project as well as problem-solving and knowledge. ""There’s really two terms that matter,"" says Capps. ""One is machine learning, or 'ML' — when a machine learns how to do something.  And the other is AI — which basically means, 'I have no idea how the computer did that, whoa.'""The bottom line of determining whether or not you're actually dealing with AI in terms of an app you're using or even an online service is, according to Kishore Rajgopal, founder and CEO of intelligent adapting pricing software firm NextOrbit, is ""the fact that your decisions and your actions change with time, and it [the AI] learns."" Learning is the key point there. ""AI is the hot thing, so just about everybody says AI. 'Oh, my product is AI enabled.' But when you look deeper, what makes it AI? It's all about the rules engine. It's a decision engine. It's a decision tree,"" Rajgopal explains. ""The question really is: does the program learn with time? You must ask this question of something purported to use AI. Does it get better with time? Probably not. The only way it can get better with time is if I, as a programmer, go back and change it.""How does the average person interact with AI on a daily basis?You're likely using AI daily and don't even realize it — that's how ubiquitous the technology has become. It's in such widespread use, even though most individuals aren't quite sure exactly what it even means. Capps says the average person interacts with AI on a ""nonstop"" basis, for example, ""from automated fraud detection on your credit cards, to air conditioning in large buildings, to airplane scheduling, to the sale prices of gold in your Clash of Clans game.""If you unlocked your phone using Face ID, you relied on machine learning to make a call or send some texts. If you then took a photo in the pitch black night and found that your phone automatically lightened it up, you can thank AI for that as well. What's more, that DoorDash customer service agent who helped ensure you got a discount for your missing milkshake? That was probably a bot powered by AI. ""It’s getting harder and harder to discern who is real and who isn’t,"" says Capps. ""Right now it’s chat agents, but that will be voice and then fully generated video soon — it will get harder and harder to tell the real from the virtual, and it may not matter!""How has AI changed over the past few years and what does the future look like?AI has certainly become more ubiquitous over the last few years. It's more than just a buzzword. It's now the core focus of several businesses and a simple fact of life when it comes to innovation. ""Ten years ago, nobody could really afford AI. It was too expensive. It's only in the last two years that it's come out into the open, like using it in commercial software. That's just going to increase. You're going to find that line of programming will become prevalent. It'll no longer be a luxury. It'll just be part of the way [you program.],"" says Rajgopal of the burgeoning AI revolution that's already beginning to take hold. ""In the next five years the exponential curve of technology will continue. You’ll have insanely powerful virtual assistants, automated cars, genetically targeted drugs, and the like. In 10 years, we’ll be like cute house pets for our AI overlords,"" concludes Capps.  What is the key to retaining the human element of AI to avoid any unforeseen mishaps?With machines and programs that are literally created to learn, adapt, and continually improve themselves over time, there are obvious concerns that arise. For instance, what happens if an AI becomes ""too smart,"" or if it ""decides"" that it knows best? ""Today, we’re building “black box” systems, where we don’t know what the system is actually doing,"" Capps says of some of the potential dangers AI has brought forth. ""We’re trusting them at scale, and only later do we realize they might have been trained with biased data. Imagine a residential loan approval algorithm that’s been trained on 60 years of data in the Deep South — what are the chances it might incorporate some racial bias? And we’ve already seen issues with parole determination systems, etc."" We've already seen similar pitfalls of using AI to complete tasks as simple as a smart camera from Facebook's AR/VR team that was meant to focus on one female person of color telling a story that, instead, focused on her ""white, male colleague"" instead. With these potential biases in mind, how do we ensure the programs we're building still retain their human elements? ""Being able to look inside the ‘black box’ is crucial,"" says Capps. ""It’s how we build software, with a debugger so we can see how it’s operating.  AI and machine learning need the same ability to look inside, before we can trust it to make decisions with human lives on the line, or even just decisions that can be impacted by biased data.""The bottom line is that, even if we manage to create super-intelligent software that can perform at the same capacity as humans do, there's still the very real possibility that machines may end up reaching a state of intelligence that's eerily similar to a human's. ""Basically, if we can build a machine that learns like a human, it won’t be long before it’s smarter than a human..."" Capps posited. ""And then who’s in charge?""Stories that Fuel ConversationsMic CheckUp NextSubmitBy subscribing to this BDG newsletter, you agree to our Terms of Service and Privacy Policy",,,,"[{'@type': 'Article', 'headline': ""How does artificial intelligence work, and what do people mean when they say 'AI?'"", 'description': 'If you spend any modicum of your time on the internet, or even dabbling in the tech world, you\'ve no doubt seen mentions of ""AI,"" or artificial intelligence, here and there. In the past few years it\'s become something of a buzzy catchword in the…', 'datePublished': '2019-11-12T16:39:03+00:00', 'dateModified': '2024-02-20T22:21:01+00:00', 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.mic.com/impact/how-does-artificial-intelligence-work-what-do-people-mean-when-they-say-ai-19285576'}, 'image': [{'@type': 'ImageObject', 'url': 'https://imgix.bustle.com/uploads/shutterstock/2019/10/31/cf2d0e92-dcb9-4431-a68f-d4ba33d5b89f-shutterstock-1033541044.jpg?w=1200&h=675&fit=crop&crop=faces&fm=jpg', 'width': '1200', 'height': '675'}, {'@type': 'ImageObject', 'url': 'https://imgix.bustle.com/uploads/shutterstock/2019/10/31/cf2d0e92-dcb9-4431-a68f-d4ba33d5b89f-shutterstock-1033541044.jpg?w=1200&h=900&fit=crop&crop=faces&fm=jpg', 'width': '1200', 'height': '900'}, {'@type': 'ImageObject', 'url': 'https://imgix.bustle.com/uploads/shutterstock/2019/10/31/cf2d0e92-dcb9-4431-a68f-d4ba33d5b89f-shutterstock-1033541044.jpg?w=1200&h=1200&fit=crop&crop=faces&fm=jpg', 'width': '1200', 'height': '1200'}], 'author': [{'@type': 'Person', 'name': 'Brittany Vincent', 'url': 'https://www.mic.com/profile/brittany-vincent-16761860'}], 'publisher': {'@type': 'Organization', 'name': 'Mic', 'url': 'https://www.mic.com', 'logo': 'https://cdn2.bustle.com/2024/mic/icon-d9ec10ae77.png'}, 'articleSection': 'Impact', 'creator': ['Brittany Vincent'], 'keywords': ['Tech', 'tech', 'homepage', 'innovation', 'adex-no-bid-density-75-evergreen']}, {'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebPage', '@id': 'https://www.mic.com/impact', 'name': 'Impact'}}]}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDE5LzExLzEzLzIwOTYxNzg4L3VzLWdvdmVybm1lbnQtYWktY29weXJpZ2h0LXBhdGVudC10cmFkZW1hcmstb2ZmaWNlLW5vdGljZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZdIBAA?oc=5,The USPTO wants to know if artificial intelligence can own the content it creates - The Verge,2019-11-13,The Verge,https://www.theverge.com,"The US office responsible for patents and trademarks is trying to figure out how AI might call for changes to copyright law, and it’s asking the public for opinions on the topic. The United States Patent and Trademark Office (USPTO) published a notice in the Federal Register last month saying it’s seeking comments.",,Can an algorithm create copyrightable work?,,http://schema.org/,NewsArticle,,The USPTO wants to know if artificial intelligence can own the content it creates,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/yGLmlhcv9Unv107w5IUeCP0pnnI=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/16125019/acastro_190416_1777_music_ai_0001.0.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/hM-DlGrWKijVA5sFyN3uKljFxUc=/0x0:2040x1360/1400x1050/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/16125019/acastro_190416_1777_music_ai_0001.0.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/XajVNGOVfEWevL7iGa_AqOlJdZ4=/0x0:2040x1360/1400x1400/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/16125019/acastro_190416_1777_music_ai_0001.0.jpg', 'width': 1400, 'height': 1400}]","[{'@type': 'Person', 'name': 'Dani Deahl', 'url': 'https://www.theverge.com/authors/dani-deahl'}]",2019-11-13T18:45:46.000Z,2019-11-13T18:45:46.000Z,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",,,,"Policy/Tech/Artificial IntelligenceThe USPTO wants to know if artificial intelligence can own the content it createsThe USPTO wants to know if artificial intelligence can own the content it creates / And it wants the public to weigh inBy  Dani Deahl Nov 13, 2019, 1:45 PM ESTShare this story0 Comments / 0 New Illustration by Alex Castro / The VergeThe US office responsible for patents and trademarks is trying to figure out how AI might call for changes to copyright law, and it’s asking the public for opinions on the topic. The United States Patent and Trademark Office (USPTO) published a notice in the Federal Register last month saying it’s seeking comments, as spotted by TorrentFreak.The office is gathering information about the impact of artificial intelligence on copyright, trademark, and other intellectual property rights. It outlines thirteen specific questions, ranging from what happens if an AI creates a copyright-infringing work to if it’s legal to feed an AI copyrighted material.It starts off by asking if output made by AI without any creative involvement from a human should qualify as a work of authorship that’s protectable by US copyright law. If not, then what degree of human involvement “would or should be sufficient so that the work qualifies for copyright protection?”Other questions ask if the company that trains an AI should own the resulting work, and if it’s okay to use copyrighted material to train an AI in the first place. “Should authors be recognized for this type of use of their works?” asks the office. “If so, how?”The office, which, among other things, advises the government on copyright, often seeks public opinion to understand new developments and hear from people who actually deal with them. Earlier this year, the office similarly asked for public opinion on AI and patents.“if it’s really a push button thing, and you get a result, I don’t think there’s any copyright in that.”None of these questions have concrete answers in US law, but people have been debating the potential outcomes for years. The situation might be a little clearer when you’re looking at something like an AI-based app where a user has to make a lot of decisions to shape the end result. “I think what’s protectable is conscious steps made by a person to be involved in authorship,” Zvi S. Rosen, lecturer at the George Washington University School of Law, tells The Verge. But if someone uses an AI that spits out a result with a single click, that could be a different matter. “My opinion is if it’s really a push button thing, and you get a result, I don’t think there’s any copyright in that.”But it’s not always cut and dry. Already, coders have claimed authorship over the “push button” works their AI software creates, which happened earlier this year in a distribution deal Warner Music brokered with the startup Endel. “That’s where it gets more complicated,” Rosen says. “I don’t have a clear answer on that.”As The Verge previously examined, questions like these are at the heart of ongoing discussions around AI and copyright law. It’s a downright messy subject with no clear answers. There is some basic guidance in the Compendium of US Copyright Office Practices, which says that works produced by a machine with no creative input or intervention from a human can’t be given authorship. But it looks like the Patent and Trademark Office feels this definition won’t hold up as AI’s hand in creative works continues to get more complicated and nuanced.AI’s hand in creative works continues to get more complicated and nuancedUsually, the USPTO only gets a few responses from the public when it makes these types of inquiries, with the bulk coming from law firms, companies, and various interest groups. But anyone can send in a comment, and Rosen says it would be beneficial for individual creators to contribute. “[The office] is looking for specific concerns and interactions,” he says, “so if, for example, a musician has worked with AI and can attest to a particular experience or grievance, that’s helpful.”As AI becomes increasingly advanced, commonplace in the creative workflow, and capable of making its own material, the questions the office is posing have ceased being theoretical and will have to be answered. “It’s not surprising [the office] is doing this,” says Rosen. “I think everyone sees it coming. Given how long these things take, any legislative response is going to be late, but by trying to get out in front of it on the study end, it’s not going to be as late. That’s just how things work.”The full list of the questions, along with directions on how to email your comments to the office are available in the Federal Register notice. The comment period closes on December 16th.Comments0 Comments / 0 NewFeatured Videos From The VergeApple and OpenAI make a deal | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge's Nilay Patel, Alex Cranz, and David Pierce discuss takeaways from WWDC, this week's gadget news, and Elon Musk dropping his lawsuit against OpenAI.Most PopularMost PopularIt’s never been easier for the cops to break into your phoneThe FBI says it has ‘gained access’ to the Trump rally shooter’s phoneGoogle is reportedly planning its biggest startup acquisition everThe Google Pixel 9 just leaked againFBI is working to break into the phone of the Trump rally shooterVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",,https://cdn.vox-cdn.com/thumbor/yGLmlhcv9Unv107w5IUeCP0pnnI=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/16125019/acastro_190416_1777_music_ai_0001.0.jpg,,,https://www.theverge.com/2019/11/13/20961788/us-government-ai-copyright-patent-trademark-office-notice-artificial-intelligence,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The US office responsible for patents and trademarks is trying to figure out how AI might call for changes to copyright law, and it’s asking the public for opinions on the topic. The United States Patent and Trademark Office (USPTO) published a notice in the Federal Register last month saying it’s seeking comments, as spotted by TorrentFreak.

The office is gathering information about the impact of artificial intelligence on copyright, trademark, and other intellectual property rights. It outlines thirteen specific questions, ranging from what happens if an AI creates a copyright-infringing work to if it’s legal to feed an AI copyrighted material.

It starts off by asking if output made by AI without any creative involvement from a human should qualify as a work of authorship that’s protectable by US copyright law. If not, then what degree of human involvement “would or should be sufficient so that the work qualifies for copyright protection?”

Other questions ask if the company that trains an AI should own the resulting work, and if it’s okay to use copyrighted material to train an AI in the first place. “Should authors be recognized for this type of use of their works?” asks the office. “If so, how?”

The office, which, among other things, advises the government on copyright, often seeks public opinion to understand new developments and hear from people who actually deal with them. Earlier this year, the office similarly asked for public opinion on AI and patents.

""“if it’s really a push button thing, and you get a result, I don’t think there’s any copyright in that.”""

None of these questions have concrete answers in US law, but people have been debating the potential outcomes for years. The situation might be a little clearer when you’re looking at something like an AI-based app where a user has to make a lot of decisions to shape the end result. “I think what’s protectable is conscious steps made by a person to be involved in authorship,” Zvi S. Rosen, lecturer at the George Washington University School of Law, tells The Verge. But if someone uses an AI that spits out a result with a single click, that could be a different matter. “My opinion is if it’s really a push button thing, and you get a result, I don’t think there’s any copyright in that.”

But it’s not always cut and dry. Already, coders have claimed authorship over the “push button” works their AI software creates, which happened earlier this year in a distribution deal Warner Music brokered with the startup Endel. “That’s where it gets more complicated,” Rosen says. “I don’t have a clear answer on that.”

As The Verge previously examined, questions like these are at the heart of ongoing discussions around AI and copyright law. It’s a downright messy subject with no clear answers. There is some basic guidance in the Compendium of US Copyright Office Practices, which says that works produced by a machine with no creative input or intervention from a human can’t be given authorship. But it looks like the Patent and Trademark Office feels this definition won’t hold up as AI’s hand in creative works continues to get more complicated and nuanced.

""AI’s hand in creative works continues to get more complicated and nuanced""

Usually, the USPTO only gets a few responses from the public when it makes these types of inquiries, with the bulk coming from law firms, companies, and various interest groups. But anyone can send in a comment, and Rosen says it would be beneficial for individual creators to contribute. “[The office] is looking for specific concerns and interactions,” he says, “so if, for example, a musician has worked with AI and can attest to a particular experience or grievance, that’s helpful.”

As AI becomes increasingly advanced, commonplace in the creative workflow, and capable of making its own material, the questions the office is posing have ceased being theoretical and will have to be answered. “It’s not surprising [the office] is doing this,” says Rosen. “I think everyone sees it coming. Given how long these things take, any legislative response is going to be late, but by trying to get out in front of it on the study end, it’s not going to be as late. That’s just how things work.”

The full list of the questions, along with directions on how to email your comments to the office are available in the Federal Register notice. The comment period closes on December 16th.
",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd3d3LmJidmEuY29tL2VuL2lubm92YXRpb24vbWFjaGluZS1sZWFybmluZy13aGF0LWlzLWl0LWFuZC1ob3ctZG9lcy1pdC13b3JrL9IBAA?oc=5,'Machine learning': ¿qué es y cómo funciona? - BBVA,2019-11-11,BBVA,https://www.bbva.com,The origin of this technology as a branch of artificial intelligence dates began several decades ago. Why is this technology so important now?,,The origin of this technology as a branch of artificial intelligence dates began several decades ago. Why is this technology so important now?,The origin of this technology as a branch of artificial intelligence dates began several decades ago. Why is this technology so important now?,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.bbva.com/en/innovation/machine-learning-what-is-it-and-how-does-it-work/'}",Machine learning: What is it and how does it work?,"{'@type': 'ImageObject', 'url': 'https://www.bbva.com/wp-content/uploads/2019/11/BBVA-Machine-learning-08112019-1024x629.png', 'width': '1024', 'height': '629'}","{'@type': 'Person', 'name': ['Communications ']}",2019-11-08T03-20-21.000Z,2019-11-11T14-49-54.000Z,"{'@type': 'Organization', 'name': 'BBVA', 'logo': {'@type': 'ImageObject', 'url': 'https://www.bbva.com/wp-content/themes/coronita-bbvacom/assets/images/logos/bbva-logo-900x269.png', 'width': '900', 'height': '269'}}",,,,"




Share






facebook








 twitter





linkedin





whatsapp






Up









Technology>
            Artificial Intelligence
Updated: 11 Nov 2019
 Machine learning: What is it and how does it work?



 







Machines’ current ability to learn is present in many aspects of everyday life. Machine learning is behind the recommendations for movies we receive on digital platforms, virtual assistants’ ability to recognize speech, or self-driving cars’ ability to see the road. But its origin as a branch of artificial intelligence dates began several decades ago. Why is this technology so important now, and what makes it so revolutionary?



 



























Communications 








 







Listen to audio



Leer en español












Machine learning, or automated learning, is a branch of artificial intelligence that allows machines to learn without being programmed for this specific purpose. An essential skill to make systems that are not only smart, but autonomous, and capable of identifying patterns in the data to convert them into predictions. This technology is currently present in an endless number of applications, such as the Netflix and Spotify recommendations, Gmail’s smart responses or Alexa and Siri’s natural speech.






Big Data
Artificial Intelligence: the challenge of turning data into tangible value


Representatives of three leading organizations - Google, Telefónica and BBVA - spoke during the Open Summit event about the different applications of artificial intelligence (AI) in the business world and how to extract tangible value from data for people and for society as a whole, at a scale and in a structured way.






“Ultimately, machine learning is a master at pattern recognition, and is able to convert a data sample into a computer program that can extract interferences from new data sets it has not been previously trained for,” explains José Luis Espinoza, data scientist at BBVA Mexico. This ability to learn is also used to improve search engines, robotics, medical diagnosis or even fraud detection for credit cards.
Although now is the time when this discipline is getting headlines thanks to its ability to beat Go players or solve Rubik cubes, its origin dates back to the last century. “Without a doubt, statistics are the fundamental foundation of automated learning, which basically consists of a series of algorithms capable of analyzing large amounts of data to deduct the best result for a certain problem,” adds Espinoza.























 



Old math, new computing
We have to go back to the 19th century to find of the mathematical challenges that set the stage for this technology. For example, Bayes’ theorem (1812) defined the probability of an event occurring based on knowledge of the previous conditions that could be related to this event. Years later, in the 1940s, another group of scientists laid the foundation for computer programming, capable of translating a series of instructions into actions that a computer could execute. These precedents made it possible for the mathematician Alan Turing, in 1950, to ask himself the question of whether it is possible for machines to think. This planted the seed for the creation of computers with artificial intelligence that are capable of autonomously replicating tasks that are typically performed by humans, such as writing or image recognition.
It was a little later, in the 1950s and 1960s, when different scientists started to investigate how to apply the human brain neural network's biology to attempt to create the first smart machines. The idea came from the creation of artificial neural networks, a computing model inspired in the way neurons transmit information to each other through a network of interconnected nodes. One of the first experiments in this regard was conducted by Marvin Minksy and Dean Edmonds, scientists from the Massachusetts Institute of Technology (MIT), who managed to create a computer program capable of learning from experience to find its way out of a maze.

""Machine learning is a master at pattern recognition""

This was the first machine capable of learning to accomplish a task on its own, without being explicitly programmed for this purpose. Instead, it did so by learning from examples provided at the outset. The accomplishment represented a paradigm shift from the broader concept of artificial intelligence. “Machine learning’s great milestone was that it made it possible to go from programming through rules to allowing the model to make these rules emerge unassisted thanks to data,” explains Juan Murillo, BBVA’s Data Strategy Manager.
Despite the success of the experiment, the accomplishment also demonstrated the limits that the technology had at the time. The lack of data available and the lack of computing power at the time meant that these systems did not have sufficient capacity to solve complex problems. This led to the arrival of the so-called “first artificial intelligence winter” - several decades when the lack of results and advances led scholars to lose hope for this discipline.
The rebirth of AI
The panorama started to change at the end of the 20th Century with the arrival of the Internet, the massive volumes of data available to train models, and computers’ growing computing power. “Now we can do the same thing as before, but a billion times faster. The algorithms can test the same combination of data 500 billion times to give us the optimal result in a matter of hours or minutes, when it used to take weeks or months,” says Espinoza.
In 1997, a famous milestone marked the rebirth of automated learning: the IBM Deep Blue system, which is trained from watching thousands of successful chess matches, managed to beat the world champion, Garry Kasparov. This accomplishment was possible thanks to deep learning, a subcategory of machine learning described for the first time in 1960, which allows systems to not only learn from experience, but to be capable of training themselves do so better and better using data. This milestone was possible then - and not 30 years before - thanks to the growing availability of data to train the model: “What this system did was statistically calculate which move had more probabilities of winning the game based on thousands of examples of matches previously watched,” adds Espinoza.

“The ability to adapt to changes in the data as they occur in the system was missing from previous techniques”

This technology has advanced exponentially in the past 20 years, and is also responsible for AlphaGo, the program capable of beating any human player at the game Go. And what is even more important: of training itself by constantly playing against itself to continue improving.
The system that AlphaGo uses to do this, in particular, is reinforcement learning, which is one of the three major trends currently used to train these models:

Reinforcement learning takes place when a machine learns through trial and error until it finds the best way to complete a given task. For example, Microsoft uses this technique in game environments like Minecraft to see how “software agents” improve their work. The system learns through them to modify its behavior based on “rewards” for completing the assigned task, without being specifically programmed to do it in a certain way.


Supervised learning occurs when machines are trained with labeled data. For example, photos with descriptions of the things that appear in them. The algorithm the machine uses is able to select these labels in other databases. Therefore, if a group of images has been labeled that show dogs, the machine can identify similar images.


Finally, in the case of unsupervised learning, machines do not identify patterns in labeled databases. Instead, they look for similarities. The algorithms are not programmed to detect a specific type of data, such as images of dogs, but to look for examples that are similar and can be grouped together. This is what occurs, for example, in facial recognition where the algorithm does not look for specific features, but for a series of common patterns that “tell” it that it’s the same face.

Flexibility, adaptation and creativity
Machine learning models, and specifically reinforcement learning, have a characteristic that make them especially useful for the corporate world. “It’s their flexibility and ability to adapt to changes in the data as they occur in the system and learn from the model’s own actions. Therein lies the learning and momentum that was missing from previous techniques,” adds Juan Murillo.
In the case of AlphaGo, this means that the machine adapts based on the opponent's movements and it uses this new information to constantly improve the model. The latest version of this computer called AlphaGo Zero is capable of accumulating thousands of years of human knowledge after working for just a few days. Furthermore, ""AlphaGo Zero also discovered new knowledge, developing unconventional strategies and creative new moves,"" explains DeepMind, the Google subsidiary that is responsible for its development, in an article.






Innovation and Technology
Artificial Intelligence, an ally against climate change


The extinction of species, the rise in temperatures and major natural disasters are some of the consequences of climate change. Countries and industries are aware and work to combat the planet’s accelerating pollution. Are there any viable solutions? According to some researches, using big data and machine learning could help drive energy efficiency, transforms industries such as the agriculture and find new eco-friendly construction materials.






This unprecedented ability to adapt has enormous potential to enhance scientific disciplines as diverse as the creation of synthetic proteins or the design of more efficient antennas. “The industrial applications of this technique include continuously optimizing any type of ‘system’,” explains José Antonio Rodríguez, Senior Data Scientist at BBVA’s AI Factory. In the banking world, deep learning also makes it possible to “create algorithms that can adjust to changes in market and customer behavior in order to balance supply and demand, for example, offering personalized prices,” concludes Rodríguez.
Another example is the improvement in systems like those in self-driving cars, which have made great strides in recent years thanks to deep learning. It allows them to progressively enhance their precision; the more they drive, the more data they can analyze. The possibilities of machine learning are virtually infinite as long as data is available they can use to learn. Some researchers are even testing the limits of what we call creativity, using this technology to create art or write articles.











Keep reading about

Artificial Intelligence
Big Data
Innovation










 
",,,,"[{'@type': 'WebSite', '@id': 'https://www.bbva.com/en/#website', 'url': 'https://www.bbva.com/en/', 'name': 'NEWS BBVA', 'description': 'NEWS BBVA', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://search.bbva.com/en/bbva?searchbbvaen={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://www.bbva.com/en/innovation/machine-learning-what-is-it-and-how-does-it-work/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://www.bbva.com/wp-content/uploads/2019/11/BBVA-Machine-learning-08112019.png', 'width': 1920, 'height': 1180, 'caption': 'BBVA-Machine-learning-virtual-algortimos-patrones-identificación-datos'}, {'@type': 'WebPage', '@id': 'https://www.bbva.com/en/innovation/machine-learning-what-is-it-and-how-does-it-work/#webpage', 'url': 'https://www.bbva.com/en/innovation/machine-learning-what-is-it-and-how-does-it-work/', 'name': ""'Machine learning': ¿qué es y cómo funciona?"", 'isPartOf': {'@id': 'https://www.bbva.com/en/#website'}, 'primaryImageOfPage': {'@id': 'https://www.bbva.com/en/innovation/machine-learning-what-is-it-and-how-does-it-work/#primaryimage'}, 'datePublished': '2019-11-08T01:20:21+00:00', 'dateModified': '2019-11-11T12:49:54+00:00', 'description': 'The origin of this technology as a branch of artificial intelligence dates began several decades ago. Why is this technology so important now?', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.bbva.com/en/innovation/machine-learning-what-is-it-and-how-does-it-work/']}]}]",,,,"['https://www.facebook.com/BBVAGroup/', 'https://twitter.com/bbva', 'https://www.linkedin.com/company/bbva', 'https://www.youtube.com/channel/UCx7HhFsmIlxx9fXnMpnERbQ', 'https://es.wikipedia.org/wiki/BBVA', 'https://instagram.com/bbva/', 'https://www.tiktok.com/@bbva']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vd3d3LmJidmFvcGVubWluZC5jb20vZW4vdGVjaG5vbG9neS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9ob3ctdG8tcmlkLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW9mLWh1bWFuLXByZWp1ZGljZS_SAQA?oc=5,How to Rid Artificial Intelligence of Human Prejudice | OpenMind - BBVA OpenMind,2019-11-13,BBVA OpenMind,https://www.bbvaopenmind.com,"Technologists and sociologists work to develop artificial intelligences free of racial, economic or gender biases.",,"Technologists and sociologists work to develop artificial intelligences free of racial, economic or gender biases.","Technologists and sociologists work to develop artificial intelligences free of racial, economic or gender biases.",http://schema.org,WebSite,,,,,,,,,,,"



Start
How to Rid Artificial Intelligence of Human Prejudice    



			Technology        

			Artificial Intelligence        


	13 November 2019

How to Rid Artificial Intelligence of Human Prejudice

Artificial Intelligence | Big Data | Machine Learning | Sociology | Technology 











Ventana al Conocimiento (Knowledge Window)



              Scientific journalism            



Estimated reading time
Time

  4  
to read





























In 2015, Google had to issue an apology when its photo app mistook a black user for a gorilla—revealing that algorithms are not free of bias, despite their apparent impartiality. The incident brought attention to a problem which had been slowly developing for years. Already in 2009, asiatic users reported that a digital camera was asking them not to blink when they took a photograph with their eyes open. The camera was sold by Nikon, a japanese firm.
It’s not surprising that artificial intelligence (AI) programs have inherited society’s biases, conscious or not, given that they are trained on human decisions and on datasets collected by people. The problem is that algorithms have a sheen of neutrality which can obscure insidious social prejudice. In 2018, for instance, Amazon had to scrap an AI recruiting tool trained on job applications which the company had received over a ten-year period—their program, true to the tech industry’s track record, was showing bias against women.
Many facial recognition programs have a racial bias. Credit: NIST
Gemma Galdon, founder and director of the consulting firm Eticas, recalls a case where one person changed from a male to a female name on InfoJobs, an online job bank. The career site’s algorithm started listing traditionally female jobs with less pay, despite there being no change to the candidate’s qualifications. “All companies are required to follow an equal-opportunity strategy: if they only employ men, they can be sued,” Galdon says: “Why isn’t InfoJobs also forced to check for bias in its algorithm?”
Artificial intelligence already takes decisions (or aids decision-making processes) in finance, in the judicial system, in healthcare and in national security, dealing out unfair treatment to social minorities. Eradicating prejudice baked into these programs has become a matter of urgency. For some digital services, the solution appears straightforward: if a facial recognition algorithm struggles to discern black and asian faces, for instance, the training dataset probably needs greater diversity.
However, problems which run deeper have no clear-cut answers. This year, a study published in the journal Science revealed that an important triage algorithm used in the United States underestimated the medical needs of black patients. Surprisingly, it did this with no prior knowledge of their ethnicity, because it was programed to assign patients risk scores based on their healthcare costs. As it happens, the United States spends less money, on average, on black patients’ health.
Why are robots prejudiced?
In this case, the developers chose healthcare cost because they thought it was a suitable, unbiased proxy for the actual healthcare needs, but they got it wrong. In other words, they had trained the algorithm to correctly solve a poorly defined problem. “There are several reasons why an algorithm may be biased or unfair. First, because it reflects society, reproducing the unfair dynamics which already exist. It could also be that the training data are skewed or the problem has been incorrectly defined. Or it could be that the engineers add in their own prejudice. We have realised that every algorithm with social impact is biased,” says Galdon.
Several recruitment and job search algorithms have proved sexist biases. Source: MaxPixel
The first challenge is to pinpoint unfair decisions, in order to stop them and to avoid them being repeated in the future. Nicolas Kayser-Bril, a reporter for the non-profit AlgorithmWatch, is an expert at identifying biased tech. “You can recognise them by old-fashioned eye discrimination, but it’s hard to prove bias,” he says. Part of the problem is that AI code is usually inscrutable, like a black box—even its creators aren’t privy to the decision-making process.
“When I know the type of algorithm being used, I know which questions to ask,” says Kayser-Bril. “In the case of machine learning, I want to know which data training set was used”. At this point, his efforts are usually foiled by the lack of transparency from developing companies and institutions. “There is AI designed to detect bias in other AIs, but as long as the algorithm is proprietary, we, the journalists, can’t analyse it,” he explains. For Kayser-Bril, the situation is akin to a sanitary inspection at a restaurant. “You want to find out if the restaurant is being run hygienically, so you can look at the dishes that are being served, but what you really want to do is go into the kitchen to inspect how the dishes are made,” he says.
Nipping bias in the bud
Galdon’s company does visit clients’ “kitchens” to help them solve and avoid bias in their algorithms. “We audit the machine learning, but that only accounts for a small part where we find problems, perhaps 20%,” she says. The remaining 80% is more “substantial” work, Galdon claims, which involves analysing the entire decision chain, from the definition of the problem and the technologists’ assumptions to the specific training provided for end-users, those who will use the algorithm in a job with social outcomes.
Technologists involuntarily perpetuate stereotypes and prejudices of society. Source: MaxPixel
According to the experts, teams developing artificial intelligence must strive for greater social and professional diversity—this will be key to building a fairer future for the field. In the United States, only 2.5% of Google’s workforce is black. Furthermore, technologists rarely work with social scientists to ensure their assumptions are sound before they launch a project. But Galdon says times are changing: “Engineers encounter problems which they are aware they have no training for, and our intervention is always welcome,” she says, referring to her company’s consulting services.
Beyond computer programs which result in outright discrimination, there is an overarching inequity problem in the tech industry. In short, algorithms are only developed for those who can afford them, setting up unequal power dynamics from the get-go. Taryn Southern, director of the neurotechnology film I Am Human, told the online portal Big Think that brain-machine interfaces designed to make us “smarter, better, faster” reflect the “Western bias to favor productivity and efficiency”. Why assume everyone shares those values? “Perhaps in other Eastern cultures they would orient the use of an interface to induce greater states of calm or create more empathy”, Southern suggests.
Bruno Martín
@TurbanMinor







    Related publications  


Drones That Kill on Their Own: Will Artificial Intelligence Reach the Battlefield?


Transmission of Culture: Revolutions, Cultural Bias and Physical Media


Explainable AI Systems: Understanding the Decisions of the Machines


GAN, the Rise of Imagination in Machines






 




",OpenMind,,,,https://www.bbvaopenmind.com/en/,"{'@type': 'SearchAction', 'target': 'https://www.bbvaopenmind.com/en/?s={search_term_string}', 'query-input': 'required name=search_term_string'}",,,#website,,,,,,,,,,,,,,,,,,,,,,,,,,OpenMind,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vYmxvZ3MubnZpZGlhLmNvbS9ibG9nL2FpLWFjY2VsZXJhdGluZy1kaXNhc3Rlci1yZWxpZWYtZWZmb3J0cy_SAQA?oc=5,In the AI of the Storm: Accelerating Disaster Relief Efforts with Artificial Intelligence - NVIDIA Blog,2019-11-11,NVIDIA Blog,https://blogs.nvidia.com,,,"With lives at stake, and the clock ticking, mastering disaster may be the ultimate AI challenge. Teams from Johns Hopkins University, Lockheed Martin, the U.S. Department of Defense’s Joint Artificial Intelligence Center and NVIDIA Wednesday outlined how they’re working to put AI to work speeding disaster relief to where it’s needed most. The teams spoke  Read Article",,https://schema.org,,,,,,,,,,,,"



In the AI of the Storm: Accelerating Disaster Relief Efforts with Artificial Intelligence

November 11, 2019 by Brian Caulfield 










					Share			


 
 
 
 
Email0 


  With lives at stake, and the clock ticking, mastering disaster may be the ultimate AI challenge.
Teams from Johns Hopkins University, Lockheed Martin, the U.S. Department of Defense’s Joint Artificial Intelligence Center and NVIDIA Wednesday outlined how they’re working to put AI to work speeding disaster relief to where it’s needed most.
The teams spoke about their work at GTC DC, the Washington edition of NVIDIA’s GPU Technology Conference, which brought together more than 3,500 registered attendees — policymakers, business leaders and researchers among them — to discuss and learn about the latest in AI and data science.
Their presentations underscored GTC DC’s role as Washington’s premier AI conference. They represent the latest efforts, detailed at the event over the past several years, to put the benefits of AI into the hands of policymakers and first-responders.
Detecting Damage with Satellite Imagery
A team from the Johns Hopkins Applied Physics Laboratory and the Joint AI Center (JAIC) spoke about how they’re using GPU-powered deep learning algorithms to track the damage caused by major storms from airborne and satellite imagery data processing.
Speakers included software engineer Beatrice Garcia and senior engineer Gordon Christie, both from the university’s Applied Physics Laboratory, and Captain Dominic Garcia, project lead at JAIC.
While their work hasn’t been deployed — yet — in disaster zones, their goal is to create AI systems that harness satellite and aerial imagery, along with other data, to point first responders and military and government decision-makers and analysts to where the need is greatest.
Such images will help first responders see, at a glance, where to deploy their resources, Christie said, as he showed an AI-enhanced map assessing the damage caused by a tornado that struck Joplin, Mississippi, in 2011.
The lab and JAIC have applied deep learning algorithms to the imagery of a number of severe storms collected from airborne platforms to accelerate detection of flooding and damaged infrastructure.
Based on the algorithms they developed and techniques they learned, the joint team is now creating a scalable environment that would provide these capabilities to any analysts. Users would have access to AI and machine learning algorithms, enabling a faster response to a variety of natural disasters.
Lockheed Prepares with Earthquake Simulation
Andrew Walsh, a senior staff systems engineer at Lockheed Martin, explained how the company is building an open dataset that can be used to train AI for better responses to earthquakes.
Lockheed Martin next explained the work that they’ve done in conjunction with a team from NVIDIA to build an open dataset for multi-platform, multi-sensor machine learning research and development.
The dataset, focused on humanitarian assistance and disaster relief, is being developed using a combination of real-world data collection events as well as simulation.  The current emphasis is on earthquake scenarios.
Andrew Walsh, a senior staff systems engineer at Lockheed Martin, joined May Casterline, a senior solutions architect at NVIDIA, to explain how they choreographed a real-world collection event that  included multiple sensors, aircraft, ground vehicles and teams of actors in a series of simulated earthquake scenarios. They also detailed the effort required to spatiotemporally align all the disparate data sources and described the challenges around labeling such a massive dataset.
Their dataset will be used to train AI and machine learning systems to improve responses to real earthquakes.
Disaster Planning with Data Science
Sean Griffin, president of Disaster Intelligence, spoke late Wednesday afternoon about his company’s approach to disaster prevention and response. His D.C.-based firm is working to create a common web platform that collects datasets relevant to natural and manmade disasters, which are then displayed graphically.
Users — from first responders to everyday citizens — can access the data to make more educated choices before and after a disaster.
“We used to share situational awareness by PDF or sharepoint sites,” said Griffin. But high performance computing is making it possible to update larger audiences with more relevant data.
“It’s our objective as a company to have complete saturation across the U.S. to have outage data in our platforms so that not only do we know that the power’s out, but that we can intersect that information with other key points of interest like healthcare facilities or water systems.”
Griffin presented two use cases. The first showed how Disaster Intelligence’s platform can model the consequences, cost and options for different disaster relief strategies. The second addressed how the platform improves coastal evacuations during hurricanes.
Route Planning with RAPIDS
NVIDIA is hosting a webinar on how RAPIDS, the company’s GPU-accelerated data science software stack, can help speed up route replanning for civilian and military disaster response assets. Register for the webinar, taking place Dec. 17 at 10 am PT, here.


Categories: Data Center | Deep LearningTags: Events | GTC 2019 | Public Sector | Social Impact 


 




All NVIDIA News 







Meet the Designer Creating Spaces Where NVIDIANs Do Their Life’s Work 













Next-Gen Video Editing: Wondershare Filmora Adds NVIDIA RTX Video HDR Support, RTX-Accelerated AI Features 













Jensen Huang, Mark Zuckerberg to Discuss Future of Graphics and Virtual Worlds at SIGGRAPH 2024 













Mile-High AI: NVIDIA Research to Present Advancements in Simulation and Gen AI at SIGGRAPH 













‘Once Human,’ Twice the Thrills on GeForce NOW 





 Stay up to date on the latest enterprise news.Thank you for subscribing.* Professional Email AddressSubscribe NowUnsubscribe at any time. Read the NVIDIA Privacy Policy.


",,,,"[{'@type': 'WebPage', '@id': 'https://blogs.nvidia.com/blog/ai-accelerating-disaster-relief-efforts/', 'url': 'https://blogs.nvidia.com/blog/ai-accelerating-disaster-relief-efforts/', 'name': 'Accelerating Disaster Relief Efforts with Artificial Intelligence | NVIDIA Blog', 'isPartOf': {'@id': 'https://blogs.nvidia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://blogs.nvidia.com/blog/ai-accelerating-disaster-relief-efforts/#primaryimage'}, 'image': {'@id': 'https://blogs.nvidia.com/blog/ai-accelerating-disaster-relief-efforts/#primaryimage'}, 'thumbnailUrl': 'https://blogs.nvidia.com/wp-content/uploads/2018/10/washington-sunrise.jpg', 'datePublished': '2019-11-11T11:43:32+00:00', 'dateModified': '2022-04-26T21:00:15+00:00', 'author': {'@id': 'https://blogs.nvidia.com/#/schema/person/a0d59392bc576d66169f89afb479a672'}, 'breadcrumb': {'@id': 'https://blogs.nvidia.com/blog/ai-accelerating-disaster-relief-efforts/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://blogs.nvidia.com/blog/ai-accelerating-disaster-relief-efforts/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://blogs.nvidia.com/blog/ai-accelerating-disaster-relief-efforts/#primaryimage', 'url': 'https://blogs.nvidia.com/wp-content/uploads/2018/10/washington-sunrise.jpg', 'contentUrl': 'https://blogs.nvidia.com/wp-content/uploads/2018/10/washington-sunrise.jpg', 'width': 1920, 'height': 1016, 'caption': 'Morning Sunrise Washington Dc Washington Monument'}, {'@type': 'BreadcrumbList', '@id': 'https://blogs.nvidia.com/blog/ai-accelerating-disaster-relief-efforts/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://blogs.nvidia.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'In the AI of the Storm: Accelerating Disaster Relief Efforts with Artificial Intelligence'}]}, {'@type': 'WebSite', '@id': 'https://blogs.nvidia.com/#website', 'url': 'https://blogs.nvidia.com/', 'name': 'NVIDIA Blog', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://blogs.nvidia.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://blogs.nvidia.com/#/schema/person/a0d59392bc576d66169f89afb479a672', 'name': 'Brian Caulfield', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://blogs.nvidia.com/#/schema/person/image/3da481c857fb301b7841a05490bfaf46', 'url': 'https://secure.gravatar.com/avatar/5e3de3b7f4b11bbc9757868b4f926a7c?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/5e3de3b7f4b11bbc9757868b4f926a7c?s=96&d=mm&r=g', 'caption': 'Brian Caulfield'}, 'description': ""Brian Caulfield is NVIDIA's chief blogger. Previously, he was a journalist with Forbes, Red Herring and Business 2.0. He has also written for Wired magazine."", 'sameAs': ['https://blogs.nvidia.com'], 'url': 'https://blogs.nvidia.com/blog/author/brian-caulfield/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LnNlY3VyaXR5bWFnYXppbmUuY29tL2FydGljbGVzLzkxMjQyLXJlZHVjaW5nLXRoZS1yaXNrcy1wb3NlZC1ieS1hcnRpZmljaWFsLWludGVsbGlnZW5jZdIBAA?oc=5,Reducing the Risks Posed by Artificial Intelligence - Security Magazine,2019-11-11,Security Magazine,https://www.securitymagazine.com,"<p>Artificial Intelligence (AI) is creating a new frontier in information security. Systems that independently learn, reason and act will increasingly replicate human behavior.</p>","['cyber security', 'machine learning', 'cybersecurity', 'Artificial Intelligence (AI)']","Artificial Intelligence (AI) is creating a new frontier in information security. Systems that independently learn, reason and act will increasingly replicate human behavior.","Artificial Intelligence (AI) is creating a new frontier in information security. Systems that independently learn, reason and act will increasingly replicate human behavior.",http://schema.org,NewsArticle,,Reducing the Risks Posed by Artificial Intelligence,"{'@type': 'ImageObject', 'url': 'https://www.securitymagazine.com/ext/resources/Issues/2019/Novmeber/SEC1119-AI1-Feat-slide_900px.jpg?t=1573246670&width=696'}","{'@type': 'Person', 'name': 'Steve Durbin'}",2019-11-11T00:00:00-05:00,2019-11-11T11:12:46-05:00,"{'@type': 'Organization', 'name': 'Security Magazine', 'logo': {'@type': 'ImageObject', 'url': 'https://www.securitymagazine.com/ext/resources/files/Security-Magazine.png'}}",,,,"
CybersecurityManagementSecurity Leadership and ManagementSecurity & Business ResilienceSecurity Education & Training
Reducing the Risks Posed by Artificial Intelligence
To thrive in the new era, enterprise security needs to reduce the risks posed by AI and make the most of the opportunities it offers.
By Steve Durbin




November 11, 2019













Artificial Intelligence (AI) is creating a new frontier in information security. Systems that independently learn, reason and act will increasingly replicate human behavior. Like humans, they will be flawed, but also capable of achieving great things.AI poses new information risks and makes some existing ones more dangerous. However, it can also be used for good and should become a key part of every organization’s defensive arsenal. Business and information security leaders alike must understand both the risks and opportunities before embracing technologies that will soon become a critically important part of everyday business.Already, AI is finding its way into many mainstream business use cases. Organizations use variations of AI to support processes in areas including customer service, human resources and bank fraud detection. However, the hype can lead to confusion and skepticism over what AI actually is and what it really means for business and security. It is difficult to separate wishful thinking from reality. What Are the Information Risks Posed by AI?As AI systems are adopted by organizations, they will become increasingly critical to day-to-day business operations. Some organizations already have, or will have, business models entirely dependent on AI technology. No matter the function for which an organization uses AI, such systems and the information that supports them have inherent vulnerabilities and are at risk from both accidental and adversarial threats. Compromised AI systems make poor decisions and produce unexpected outcomes.Simultaneously, organizations are beginning to face sophisticated AI-enabled attacks – which have the potential to compromise information and cause severe business impact at a greater speed and scale than ever before. Taking steps both to secure internal AI systems and defend against external AI-enabled threats will become vitally important in reducing information risk.While AI systems adopted by organizations present a tempting target, adversarial attackers are also beginning to use AI for their own purposes. AI is a powerful tool that can be used to enhance attack techniques, or even create entirely new ones. Organizations must be ready to adapt their defenses in order to cope with the scale and sophistication of AI-enabled cyber-attacks. Defensive Opportunities Provided by AISecurity practitioners are always fighting to keep up with the methods used by attackers, and AI systems can provide at least a short-term boost by significantly enhancing a variety of defensive mechanisms. AI can automate numerous tasks, helping understaffed security departments to bridge the specialist skills gap and improve the efficiency of their human practitioners.Protecting against many existing threats, AI can put defenders a step ahead. However, adversaries are not standing still – as AI-enabled threats become more sophisticated, security practitioners will need to use AI-supported defenses simply to keep up.The benefit of AI in terms of response to threats is that it can act independently, taking responsive measures without the need for human oversight and at a much greater speed than a human could. Given the presence of malware that can compromise whole systems almost instantaneously, this is a highly valuable capability.The number of ways in which defensive mechanisms can be significantly enhanced by AI provide grounds for optimism, but as with any new type of technology, it is not a miracle cure. Security practitioners should be aware of the practical challenges involved when deploying defensive AI.Questions and considerations before deploying defensive AI systems have narrow intelligence and are designed to fulfil one type of task. They require sufficient data and inputs in order to complete that task. One single defensive AI system will not be able to enhance all the defensive mechanisms outlined previously – an organization is likely to adopt multiple systems. Before purchasing and deploying defensive AI, security leaders should consider whether an AI system is required to solve the problem, or whether more conventional options would do a similar or better job.Questions to ask include:
Is the problem bounded? (i.e. can it be addressed with one dataset or type of input, or does it require a high understanding of context, which humans are usually better at providing?)
Does the organization have the data required to run and optimize the AI system?
Security leaders also need to consider issues of governance around defensive AI, such as:
How do defensive AI systems fit into organizational security governance structures?
How can the organization provide security assurance for defensive AI systems?
How can defensive AI systems be maintained, backed up, tested and patched?
Does the organization have sufficiently skilled people to provide oversight for defensive AI systems?
AI will not replace the need for skilled security practitioners with technical expertise and an intuitive nose for risk. These security practitioners need to balance the need for human oversight with the confidence to allow AI-supported controls to act autonomously and effectively. Such confidence will take time to develop, especially as stories continue to emerge of AI proving unreliable or making poor or unexpected decisions.AI systems will make mistakes – a beneficial aspect of human oversight is that human practitioners can provide feedback when things go wrong and incorporate it into the AI’s decision-making process. Of course, humans make mistakes too – organizations that adopt defensive AI need to devote time, training and support to help security practitioners learn to work with intelligent systems.Given time to develop and learn together, the combination of human and artificial intelligence should become a valuable component of an organization’s cyber defenses. Preparation Begins NowComputer systems that can independently learn, reason and act herald a new technological era, full of both risk and opportunity. The advances already on display are only the tip of the iceberg – there is a lot more to come. The speed and scale at which AI systems ‘think’ will be increased by growing access to big data, greater computing power and continuous refinement of programming techniques. Such power will have the potential to both make and destroy a business.AI tools and techniques that can be used in defense are also available to malicious actors including criminals, hacktivists and state-sponsored groups. Sooner rather than later these adversaries will find ways to use AI to create completely new threats such as intelligent malware – and at that point, defensive AI will not just be a ‘nice to have’. It will be a necessity. Security practitioners using traditional controls will not be able to cope with the speed, volume and sophistication of attacks.To thrive in the new era, organizations need to reduce the risks posed by AI and make the most of the opportunities it offers. That means securing their own intelligent systems and deploying their own intelligent defenses. AI is no longer a vision of the distant future: the time to start preparing is now.


KEYWORDS:  Artificial Intelligence (AI) cyber security cybersecurity machine learning


Share This Story















 



Steve Durbin is CEO at the Information Security Forum (ISF). His main areas of focus include strategy, information technology, cybersecurity and the emerging security threat landscape across both the corporate and personal environments. Previously, he was senior vice president at Gartner.



",,https://www.securitymagazine.com/ext/resources/Issues/2019/Novmeber/SEC1119-AI1-Feat-slide_900px.jpg?t=1573246670&width=696,Cybersecurity,,https://www.securitymagazine.com/articles/91242-reducing-the-risks-posed-by-artificial-intelligence,,,,,,,['Steve Durbin'],2019-11-11T00:00:00-05:00,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vYml6dGVjaG1hZ2F6aW5lLmNvbS9hcnRpY2xlLzIwMTkvMTEvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3lzdGVtcy1hcmUtY2F0Y2hpbmctZmVlbGluZ3PSAQA?oc=5,Artificial Intelligence Systems Are Catching Feelings - BizTech Magazine,2019-11-12,BizTech Magazine,https://biztechmagazine.com,"By tapping into human emotion, advanced AI systems will forever change how consumers interact with brands.","Hyperconverged, HCI, data center","By tapping into human emotion, advanced AI systems will forever change how consumers interact with brands.","By tapping into human emotion, advanced AI systems will forever change how consumers interact with brands.",https://schema.org,Organization,,,,,,,,,,,"





    Enterprise
  

A Data Center Building Boom Is About to Begin
 
",,,,"[{'speakable': {'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}, '@type': 'NewsArticle', 'name': 'Artificial Intelligence Systems Are Catching Feelings', 'headline': 'Artificial Intelligence Systems Are Catching Feelings', 'description': 'By tapping into human emotion, advanced AI systems will forever change how consumers interact with brands.', 'thumbnailUrl': 'https://biztechmagazine.com/sites/biztechmagazine.com/files/styles/trending_thumb/public/articles/201911/emotional%20robot.jpg?itok=-NuLiabe', 'image': 'https://biztechmagazine.com/sites/biztechmagazine.com/files/styles/trending_thumb/public/articles/201911/emotional%20robot.jpg?itok=-NuLiabe', 'datePublished': '2019-11-12T18:02:30Z', 'isAccessibleForFree': 'True', 'dateModified': '2020-05-06T05:04:24Z', 'author': {'@type': 'Person', 'name': 'Erin Cunningham', 'url': 'https://biztechmagazine.com/author/erin-cunningham'}, 'publisher': {'@type': 'Organization', 'name': 'Publisher', 'url': 'https://biztechmagazine.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://biztechmagazine.com/themes/cdw/images/logo-cdw_biztech.png'}, 'contactPoint': [{'@type': 'ContactPoint', 'telephone': '+1-847-465-6000', 'contactType': 'customer service'}]}, 'mainEntityOfPage': 'https://biztechmagazine.com/article/2019/11/artificial-intelligence-systems-are-catching-feelings'}]",https://biztechmagazine.com/,"[{'@type': 'SearchAction', 'target': 'https://biztechmagazine.com/search?search_api_fulltext={biztech}', 'query-input': 'required name=biztech', 'sameAs': ['https://twitter.com/BizTechMagazine']}]","{'@type': 'ImageObject', 'url': 'https://biztechmagazine.com/themes/cdw/images/logo-cdw_biztech.png'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'ContactPoint', 'telephone': '+1-847-465-6000', 'contactType': 'customer service'}]",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vcm9sbGNhbGwuY29tLzIwMTkvMTEvMTIvZ29vZ2xlLWxvb2tzLXBhc3QtcHJvamVjdC1tYXZlbi10by13b3JrLWFuZXctd2l0aC10aGUtcGVudGFnb24v0gEA?oc=5,Google looks past Project Maven to work anew with the Pentagon - Roll Call,2019-11-12,Roll Call,https://rollcall.com,,,"More than a year after pulling out of a contract with the Pentagon that relied on technologies based on artificial intelligence to sort through drone videos, Google says it is ready to work with the Defense Department on a wide variety of applications that don’t involve weapons. Google’s decision to engage with the Pentagon on non-weapons-related […]",,https://schema.org,,,,,,,,,,,,"




        Policy
      




        Google looks past Project Maven to work anew with the Pentagon
      


        Company’s 2018 withdrawal from drone video program sent shockwaves through national security world
  




A Google sign at its 2019 Developer Days conference in Shanghai, China. (Lyu Liang/VCG via Getty Images)  








By
Gopal Ratnam

Posted November 12, 2019 at 6:01am






Facebook







Twitter







Email







Reddit






More than a year after pulling out of a contract with the Pentagon that relied on technologies based on artificial intelligence to sort through drone videos, Google says it is ready to work with the Defense Department on a wide variety of applications that don’t involve weapons.Google’s decision to engage with the Pentagon on non-weapons-related technologies stems from the company’s artificial intelligence principles published last year, said Kent Walker, senior vice president for global affairs at Google.The principles rule out Google’s role in developing technologies that could cause harm or could be used for surveillance in violation of laws.“It’s right that we decided to press the reset button until we had an opportunity to develop our own set of AI principles, our own internal standards and review processes,” Walker said last week at an event organized by the National Security Commission on Artificial Intelligence.The decision to stop working with the Pentagon on the drone video contract was a “discrete” one and not indicative of a “broader principle or an unwillingness” to work with the Defense Department, he said.[Lawmakers Pushing Drone Legislation Hear Threat Warnings]The commission was created by Congress in the 2019 Pentagon policy bill to figure out how the Pentagon can harness artificial intelligence and related technologies for national security purposes. The panel is chaired by Eric Schmidt, the former chairman of Google’s parent company Alphabet, where he continues to be an outside adviser.Google is working with the Pentagon on a “number of national mission initiatives,” Walker said, listing cybersecurity, health care, tools to identify deepfake videos, and other AI projects with the Defense Advanced Research Projects Agency, or DARPA, to ensure the “robustness of AI.”“At the end of the day we are a proud American company and we are committed to the defense of the United States, our allies and the safety and security of the world,” Walker said.[jwp-video n=”1″]
Without a close partnership between the government, academia and industry, the Pentagon could never achieve global superiority in artificial intelligence technologies that are likely to be central to military dominance in the future, said Lt. Gen. John N.T. “Jack” Shanahan, director of the Pentagon’s Joint Artificial Intelligence Center, which is overseeing the military’s pursuit of such technologies.“Even those for various reasons who view [the Defense Department] with suspicion, and reluctant to accept that we are in a strategic competition with China, would agree that artificial intelligence is key” to the future of national security, Shanahan said.Google’s withdrawal in June 2018 from Project Maven, a Pentagon program that used the company’s artificial intelligence toolkit called TensorFlow to sift through thousands of hours of drone video, sent shockwaves through the national security world, raising fears that other technology companies could follow suit and handicap the Pentagon’s efforts.Google’s decision came after thousands of Google’s engineers had protested its work with the Pentagon and wrote a letter to CEO Sundar Pichai saying that it shouldn’t be “in the business of war.”The Pentagon turned to Google for help in developing AI technologies because it did not want to “reinvent the wheel,” and the company had the best minds working on machine learning algorithms, Shanahan said.Although the Pentagon was “very pleased” with the results of the project and the cooperation it got from Google, “we lost the narrative very quickly,” Shanahan said.Although the project was not aimed at developing a weapon, critics of the effort inside and outside Google labeled it as a weapons program, Shanahan said.When Google withdrew from Project Maven, several top U.S. officials pilloried the company for choosing to withdraw from the Pentagon program while continuing its work in China.The company’s withdrawal could put Americans at risk, former U.S. Deputy Secretary of Defense Robert Work said at the time. Work is now the vice chairman of the artificial intelligence commission.
Google and China
While Google employees were protesting the company’s engagement with the Pentagon, fearing that they were aiding in the development of potential weapons, the company was working in China on artificial intelligence systems, Work said. Beijing’s military is closely tied with commercial entities, and whatever technologies that are developed for commercial purposes could be used by the People’s Liberation Army, Work said.The chairman of the Joint Chiefs of Staff, Gen. Joseph Dunford, also echoed fears about Google’s work in China. Any work by U.S. companies in aiding China’s development of artificial intelligence systems would “help an authoritarian government assert control over its own population” and “enable the Chinese military to take advantage” of U.S. technology, Dunford said in March this year. Dunford has since retired.Google’s Walker said the company’s work in China was limited in its scope.In 2010, large-scale cyberattacks from China aimed at Google’s operations within the People’s Republic resulted in loss of the company’s intellectual property, Google said at the time. “We learned a lot from that experience,” Walker said. “While many of our peer companies have significant AI operations in China, we have chosen to scope our operations in China very carefully.”The company’s work in China is limited to “advertising and work supporting an open source platform,” Walker said.Last year, Google engineers leaked details of the company’s work in China to develop a search engine code-named Dragonfly that would have allowed Beijing to censor and monitor its citizens. In July, Google said it had terminated its work on the project.Chinese President Xi Jinping has pledged to spend $150 billion on artificial intelligence technologies with the goal of becoming a world leader in the field by 2030.



 






Around the Web New Way to Cool Down Hot RoomsChillWell4 Foods Linked to Dementia (Avoid)Primal Health4 Worst Blood Pressure Drugs (Avoid)Primal HealthA 70-year-old Engineer Designed This Nail Clipper for Seniors All Over the WorldSherumAll Natural Solution for Nerve PainPrimal HealthTry Not to Gag When You See Barron's GirlfriendDaily Sports Reporter



    Recent Stories
  







Which swing-district Republicans are skipping party’s convention?








With Roe overturned, Trump’s GOP turns to transgender health care








Capitol Lens | Republican National Convention, Day 1








Not your father’s (or grandfather’s or great-grandfather’s) GOP








Bandaged Trump met with thunderous reaction at RNC light on policy plans








Congress launches investigations of security failure at Trump rally








",,,,"[{'@type': 'Article', '@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/#article', 'isPartOf': {'@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/'}, 'author': {'name': '', '@id': ''}, 'headline': 'Google looks past Project Maven to work anew with the Pentagon', 'datePublished': '2019-11-12T11:01:32+00:00', 'dateModified': '2019-12-13T14:26:19+00:00', 'mainEntityOfPage': {'@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/'}, 'wordCount': 971, 'publisher': {'@id': 'https://rollcall.com/#organization'}, 'image': {'@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/#primaryimage'}, 'thumbnailUrl': 'https://cdn.media.rollcall.com/author/2019/11/GettyImages-11737417121.jpg', 'keywords': ['Business', 'Cybersecurity', 'Defense', 'Drones', 'Executive Branch', 'Fintech', 'Health Care', 'Intelligence'], 'articleSection': ['Defense', 'Includephoto', 'Policy', 'Technology'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/', 'url': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/', 'name': 'Google looks past Project Maven to work anew with the Pentagon - Roll Call', 'isPartOf': {'@id': 'https://rollcall.com/#website'}, 'primaryImageOfPage': {'@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/#primaryimage'}, 'image': {'@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/#primaryimage'}, 'thumbnailUrl': 'https://cdn.media.rollcall.com/author/2019/11/GettyImages-11737417121.jpg', 'datePublished': '2019-11-12T11:01:32+00:00', 'dateModified': '2019-12-13T14:26:19+00:00', 'breadcrumb': {'@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/#primaryimage', 'url': 'https://cdn.media.rollcall.com/author/2019/11/GettyImages-11737417121.jpg', 'contentUrl': 'https://cdn.media.rollcall.com/author/2019/11/GettyImages-11737417121.jpg', 'caption': 'A Google sign at its 2019 Developer Days conference in Shanghai, China. (Lyu Liang/VCG via Getty Images)'}, {'@type': 'BreadcrumbList', '@id': 'https://rollcall.com/2019/11/12/google-looks-past-project-maven-to-work-anew-with-the-pentagon/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://rollcall.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Google looks past Project Maven to work anew with the Pentagon'}]}, {'@type': 'WebSite', '@id': 'https://rollcall.com/#website', 'url': 'https://rollcall.com/', 'name': 'Roll Call', 'description': 'Covering Capitol Hill Since 1955', 'publisher': {'@id': 'https://rollcall.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://rollcall.com/search/{search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://rollcall.com/#organization', 'name': 'Roll Call', 'url': 'https://rollcall.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://rollcall.com/#/schema/logo/image/', 'url': '/app/uploads/2021/02/rollcall-placeholder-image-1.png', 'contentUrl': '/app/uploads/2021/02/rollcall-placeholder-image-1.png', 'width': 1280, 'height': 1024, 'caption': 'Roll Call'}, 'image': {'@id': 'https://rollcall.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/RollCall', 'https://twitter.com/rollcall']}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LmNvbnN1bHRhbmN5LmluL25ld3MvMjYxNC90aGUtbWl4ZWQtcmVjZXB0aW9uLXRvLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLWluZGlh0gFgaHR0cHM6Ly93d3cuY29uc3VsdGFuY3kuaW4vbmV3cy9hbXAvMjYxNC90aGUtbWl4ZWQtcmVjZXB0aW9uLXRvLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLWluZGlh?oc=5,The mixed reception to artificial intelligence in India - Consultancy.in,2019-11-11,Consultancy.in,https://www.consultancy.in,"Investment in artificial intelligence (AI) might be on the rise across the Indian market, although few of these investments are part of broader AI strategies, according to new PwC analysis.",,"Investment in artificial intelligence (AI) might be on the rise across the Indian market, although few of these investments are part of broader AI strategies, according to new PwC analysis.","Investment in artificial intelligence (AI) might be on the rise across the Indian market, although few of these investments are part of broader AI strategies, according to new PwC analysis.",http://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.consultancy.in/news/2614/the-mixed-reception-to-artificial-intelligence-in-india'}",The mixed reception to artificial intelligence in India,['https://www.consultancy.in/illustrations/news/spotlight/2019-11-10-104649139-AI-in-India---PwC.jpg'],"{'@type': 'Organization', 'name': 'Consultancy.in'}",2019-11-11T05:00:00Z,2019-11-11T05:00:00Z,"{'@type': 'Organization', 'name': 'Consultancy.in', 'logo': {'@type': 'ImageObject', 'url': 'https://www.consultancy.in/img/metaimage/Consultancy_in_metaimage.png'}}",,Consulting,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiiAFodHRwczovL3dvcmxkdmlldy5zdHJhdGZvci5jb20vYXJ0aWNsZS9nb29nbGUtYWktd29yay1jaGluYS1zdGlycy1xdWVzdGlvbnMtYWxsZWdpYW5jZS1uYXRpb25hbC1zZWN1cml0eS1taWxpdGFyeS10ZWNobm9sb2d5LXBldGVyLXRoaWVs0gEA?oc=5,Google's AI Work in China Stirs Questions of Allegiance and National Security - Stratfor Worldview,2019-11-12,Stratfor Worldview,https://worldview.stratfor.com,"Artificial intelligence is the next big disruptor, and the lines are unclear between national and corporate interests.","Worldview, news","Artificial intelligence is the next big disruptor, and the lines are unclear between national and corporate interests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vZW1pcmF0ZXN3b21hbi5jb20vbG9yZWFsLXVuZXNjby1mb3Itd29tZW4taW4tc2NpZW5jZS1taWRkbGUtZWFzdC1mZWxsb3dzaGlwL9IBAA?oc=5,Meet the Arab scientist recognised for her work with Artificial intelligence – Emirates Woman - Emirates Woman,2019-11-14,Emirates Woman,https://emirateswoman.com,"At the sixth edition of L’Oréal-UNESCO for Women in Science Middle East Fellowship, six Arab female scientists were recognised for their contribution",[],"At the sixth edition of L’Oréal-UNESCO for Women in Science Middle East Fellowship, six Arab female scientists were recognised for their contribution",,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'http://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/'}",Meet the Arab scientist recognised for her work with Artificial intelligence,"{'@type': 'ImageObject', 'url': 'https://emirateswoman.com/wp-content/uploads/2019/11/Maryam-Al-Yammahi.jpg'}","[{'@type': 'Person', 'name': 'Diana Bellheather'}]",2019-11-14T13:25:19Z,2019-11-14T13:25:25Z,"{'@type': 'Organization', 'name': 'Emirates Woman', 'logo': 'https://emirateswoman.com/wp-content/uploads/2022/05/ew_icon_logo_128.png'}",,,,,,https://emirateswoman.com/wp-content/uploads/2019/11/Maryam-Al-Yammahi-150x75.jpg,Lifestyle,"[{'@type': 'Article', '@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/#article', 'isPartOf': {'@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/'}, 'author': {'name': 'Diana Bellheather', '@id': 'https://emirateswoman.com/#/schema/person/e64d724b614dddd08ff88f96b83fce77'}, 'headline': 'Meet the Arab scientist recognised for her work with Artificial intelligence', 'datePublished': '2019-11-14T13:25:19+00:00', 'dateModified': '2019-11-14T13:25:25+00:00', 'mainEntityOfPage': {'@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/'}, 'wordCount': 776, 'publisher': {'@id': 'https://emirateswoman.com/#organization'}, 'image': {'@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/#primaryimage'}, 'thumbnailUrl': 'https://emirateswoman.com/wp-content/uploads/2019/11/Maryam-Al-Yammahi.jpg', 'articleSection': ['Lifestyle'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/', 'url': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/', 'name': 'Meet the Arab scientist recognised for her work with Artificial intelligence &ndash; Emirates Woman', 'isPartOf': {'@id': 'https://emirateswoman.com/#website'}, 'primaryImageOfPage': {'@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/#primaryimage'}, 'image': {'@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/#primaryimage'}, 'thumbnailUrl': 'https://emirateswoman.com/wp-content/uploads/2019/11/Maryam-Al-Yammahi.jpg', 'datePublished': '2019-11-14T13:25:19+00:00', 'dateModified': '2019-11-14T13:25:25+00:00', 'description': 'At the sixth edition of L’Oréal-UNESCO for Women in Science Middle East Fellowship, six Arab female scientists were recognised for their contribution', 'breadcrumb': {'@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/#primaryimage', 'url': 'https://emirateswoman.com/wp-content/uploads/2019/11/Maryam-Al-Yammahi.jpg', 'contentUrl': 'https://emirateswoman.com/wp-content/uploads/2019/11/Maryam-Al-Yammahi.jpg', 'width': '800', 'height': '400', 'caption': 'L’Oréal-UNESCO for Women in Science Middle East Fellowship'}, {'@type': 'BreadcrumbList', '@id': 'https://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://emirateswoman.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Meet the Arab scientist recognised for her work with Artificial intelligence'}]}, {'@type': 'WebSite', '@id': 'https://emirateswoman.com/#website', 'url': 'https://emirateswoman.com/', 'name': 'Emirates Woman', 'description': 'Lifestyle, Culture, News &amp; Fashion in Dubai', 'publisher': {'@id': 'https://emirateswoman.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://emirateswoman.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://emirateswoman.com/#organization', 'name': 'Emirates Woman', 'url': 'https://emirateswoman.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://emirateswoman.com/#/schema/logo/image/', 'url': 'https://emirateswoman.com/wp-content/uploads/2024/05/EW-logo.jpg', 'contentUrl': 'https://emirateswoman.com/wp-content/uploads/2024/05/EW-logo.jpg', 'width': 2550, 'height': 518, 'caption': 'Emirates Woman'}, 'image': {'@id': 'https://emirateswoman.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/EmiratesWomanMagazine', 'https://twitter.com/EW_Magazine', 'https://www.instagram.com/emirateswoman/', 'https://www.tiktok.com/@emirateswoman']}, {'@type': 'Person', '@id': 'https://emirateswoman.com/#/schema/person/e64d724b614dddd08ff88f96b83fce77', 'name': 'Diana Bellheather', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://emirateswoman.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/09846cad89d626066c7baaf7f74cbd61?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/09846cad89d626066c7baaf7f74cbd61?s=96&d=mm&r=g', 'caption': 'Diana Bellheather'}, 'url': 'https://emirateswoman.com/author/diana/'}]",http://emirateswoman.com/loreal-unesco-for-women-in-science-middle-east-fellowship/,,,,,,,['Diana Bellheather'],2019-11-14T13:25:19Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vbmVwYWxpdGltZXMuY29tL2Jhbm5lci9icmluZ2luZy1zaWxpY29uLXZhbGxleS10by1rYXRobWFuZHUtdmFsbGV50gEA?oc=5,Bringing Silicon Valley to Kathmandu Valley - Nepali times,2019-11-15,Nepali times,https://nepalitimes.com,,,,,,,,,,,,,,,Multimedia,,"Bringing Silicon Valley to Kathmandu ValleyArtificial Intelligence is here, better get used to it15 November 2019Sonia Awale For those who think that Nepal is too underdeveloped to make full use of artificial intelligence (AI), think again. That is exactly what they used to say about computers and mobile phones in the 1990s.It may come as a surprise to many that Nepal has been gaining ground in AI, developing not only software using machine learning algorithms but producing world-class engineers. One company at the forefront is Fusemachines Nepal, which has started using industry experts to train AI students with cutting-edge technology to deliver intelligent solutions.“I wanted to see if I can contribute in bringing the best AI education to Nepal and make Nepal known around the world as one of the best sources of AI talent,” says the Nepali founder of Fusemachines, Sameer Maskey, a professor at Columbia University.All Photos: MONIKA DEUPALA/SONIA AWALEThis is the age of surveillance capitalism, where algorithms determine election outcomes, Siri knows what you want before you do, wearables correctly deduce the state of the heart and Facebook recognises friends.Read also:Natural Intelligence, Duksangh SherpaKathmandu's Silicon Alley and the Law, Sonia AwaleAI simply imitates human thinking by recognising patterns in data, so that repetitive everyday work can be done by machines that learn as they go along.Nepal missed the bus on natural resource processing, manufacturing and information technology. But experts say that training a critical mass of engineers in AI can allow the country’s economy to leapfrog and become globally competitive.    Fusemachines Director of Academic Affairs Bülent Uyaniker, who was in Nepal recently, rejects the notion that Nepal is not ready for artificial intelligence applications. “It is happening already, it is inevitable. If there can be 8.5 million Facebook users in Nepal, then it has the special conditions for AI.”Proof of this is the increasing number of software companies in Nepal using local engineering talent to work on software solutions for customers in North America or Europe. However, most of the engineers and recent graduates need training in AI to keep up with customer requirements. America alone will need 200,000 data scientists in the next five years, and most of these will come from the UK, Finland, Canada, Singapore, China and India.Which is why Fusemachines Nepal is also emphasising education. Says the head of its global operations and strategy, Sumana Shrestha: “You cannot learn AI in a one-day bootcamp, it needs intelligent mathematics, but there is a huge demand versus supply gap for engineers proficient in machine learning or other AI components everywhere.”Read also:It's all about IT, Sahina ShresthaDrones to the rescue, Lucia de VriesNepal established itself as a sought after destination in the past 20 years for outsourcing services such as software and app development, website design and big data management to overseas clients, mostly due to the country’s inexpensive English-speaking workforce.This move from IT to AI will not just create jobs in Nepal, but also allow the country to increase efficiency and productivity in the workplace. General practitioners in rural hospitals will be able to make diagnoses faster so they can spend more time with patients, high-risk individuals can be identified with cancer screening, and targeted advertising and customised itineraries will lure potential tourists during Visit Nepal 2020.Recently, a group of engineering students developed a model to help poultry entrepreneurs understand fowl behaviour and the state of their animals’ health, helping them to raise the farm’s business profile.“With precision livestock farming we can generate patterns to help farmers recognise symptoms before an outbreak of a disease by implementing AI components such as image processing and deep learning,” explained engineering student Sajil Awale at Pulchok Engineering Campus. “This allows for timely intervention to prevent mass deaths and reduce losses.”Read also: Tap and tour, Clara BullockComputer vision (which enables computers to see and process images as humans would) can also help identify rotten fruit swiftly, and prevent misuse of pesticides by identifying areas on the farm that require chemicals, and the amounts needed. AI can also estimate future harvests, allowing farmers time to find markets for produce.Engineers at Fusemachines Nepal are working on Nepal’s first optical character recognition (OCR) system so forms filled out with Nepali handwriting can be digitised and translated into English. This will have huge scope in Nepal’s banking, hospital and government sectors, where pen and paper continues to be the norm.Sixit Bhatta, CEO of ride-sharing startup Tootle, says Nepal is ripe for AI applications: “Our efforts now should be on preparing for a world in which machines perform skills-oriented tasks and for humans to take on the roles that require creativity and empathy. But before that, the government should design policies that allow AI to grow, and not restrict it.”Sumana Shrestha at Fusemachines Nepal says that as long as salaries for clerical staff are low, there is less potential for AI to flourish. But she adds: “The curse of cheap labour means companies will prefer to employ people to do repetitive work. But sooner or later, AI will be here. Nepal needs to develop despite government. And the private sector needs to prepare itself for disruption.”Coming to terms with AI Artificial Intelligence: Ability of computer systems or machines to make a decision like humans, or the ability to perform tasks requiring human intelligenceMachine Learning: A subset of artificial intelligence that provides a system with the ability to automatically learn and improve from experience without being explicitly programmed, relying on patterns generated from dataDeep Learning: Machine learning that is applied on a large set of data, also known as deep neural learning that uses deep neural networks to model complicated dataNatural Language Processing: Interaction between computers and human languages, deals with programming computers to process and analyse natural (human) language, this field of AI processes, analyses, interprets and distills information from human languagesComputer Vision: Enables computers to see, identify and process images in the same way that human vision doesImage Processing: Part of computer vision that entails analysis and manipulation to find insights from a digitised imageBig Data: Extremely large data sets on which AI is applied to reveal patterns, trends and associations and make decisionsMaking Nepalis artificially intelligent During a visit to Nepal six years ago, Columbia University professor Sameer Maskey handpicked three students from engineering schools across Kathmandu who were able to solve a mathematical equation. The three went on to become the core of Fusemachines, a global company that aims to democratise artificial intelligence (AI) through education and software solutions.Headquartered in New York, Fusemachines has since opened branches in Canada, UK and the Dominican Republic to develop intelligent software solutions that have transformed brands and businesses around the world. One of its biggest operations is in Nepal, Fusemachines employs 100 top Nepali software engineers who work on projects that use AI applications in fields ranging from telecommunications and banking to hospitals and governance.Unlike other back office companies that work on outsourced software development, Fusemachines is a school in itself, training engineers while coming up with product solutions.“We employ senior engineers and industry experts with PhDs along with upcoming engineers, who work together to solve client-specific problems though AI,” explains Sumana Shrestha who heads Fusemachines’ global operations and strategy. “Such collaborative approach allows young talent to continuously learn and grow.”Following Maskey’s vision, Fusemachines tries to make AI accessible to everyone through education, which is why it initially offered training fellowships and then, to meet the demand for engineers, launched AI Shikshya — a year-long, in-house training program.“With our own proprietary platform and content we have partnered with engineering colleges in Kathmandu to offer AI,” says Shrestha. “The program is a blend of online and on-site, the course material is not too academic, is industry focused and instructors are seasoned engineers up to date with new algorithms.”The company also has its own AI schools, open to professionals who want to grow their business or anyone interested. Fusemachines also offers a foundation course, open to high school graduates. A year-long, micro-degree program consisting of four major courses — including machine learning, deep thinking, natural language processing and computer vision — will be the next step.“In school we were always presented with clean data sets to work on but that is rarely the case on the job. But this year-long training program gets people ready to take on real-life problems and provide AI solutions,” says Rojesh Shikharkar, engineer at Fusemachines Nepal and a post-grad at Pulchok Engineering Campus.Apart from training, Fusemachines has given engineers who would otherwise have migrated to work in the US and Europe an opportunity to find meaningful work in Nepal.Says Shrestha: “If you create opportunities here, people might actually stay, and once we have mass education in artificial intelligence, companies here will start adopting and see the value of AI products, ensuring more opportunities at home.”Sonia AwalewriterSonia Awale is Executive Editor of Nepali Times where she also serves as the health, science and environment correspondent. She has extensively covered the climate crisis, disaster preparedness, development and public health -- looking at their political and economic interlinkages. Sonia is a graduate of public health, and has a master’s degree in journalism from the University of Hong Kong.TagsNepalsmartphonestudentsfacebookengineersAIartificial intelligencemachine learningcomputermobileITTootleInformation technologydataFusemachinesSumana Shresthaalgorithmappsbig datacomputationcomputer visiondeep learningdroneFusemachines Nepalimage processingnatural language processingOCR productsPrecision Livestock FarmingPulchok CampusroboticsSajil AwaleSameer MaskeySiriSixit Bhattasoftwarewearables",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LnRlY2hmdW5uZWwuY29tL2hyLXRlY2gvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYmFzZWQtZW1wbG95ZWUtZW5nYWdlbWVudC10b29scy_SAQA?oc=5,Top 15 Artificial Intelligence-Based Employee Engagement Tools for 2020 - TechFunnel,2019-11-12,TechFunnel,https://www.techfunnel.com,Employee engagement is a critical aspect of HR management. How artificial intelligence-based employee engagement tools are improving the HR processes,,Employee engagement is a critical aspect of HR management. How artificial intelligence-based employee engagement tools are improving the HR processes,,https://schema.org/,WebSite,,,,,,,,,,,,TechFunnel,,,"[{'@type': 'Article', '@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/#article', 'isPartOf': {'@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/'}, 'author': {'name': 'Danni White', '@id': 'https://www.techfunnel.com/#/schema/person/55746dbe674b75c6397c423dcf47539e'}, 'headline': 'Top 15 Artificial Intelligence-Based Employee Engagement Tools for 2020', 'datePublished': '2019-11-12T09:45:29+00:00', 'dateModified': '2019-11-12T09:45:29+00:00', 'mainEntityOfPage': {'@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/'}, 'wordCount': 1038, 'publisher': {'@id': 'https://www.techfunnel.com/#organization'}, 'image': {'@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/#primaryimage'}, 'thumbnailUrl': 'https://www.techfunnel.com/wp-content/uploads/2019/11/Top-15-Artificial-Intelligence-Based-Employee-Engagement-Tools-for-2020.jpg', 'keywords': ['AI employee engagement tools', 'employee engagement tools 2020', 'HR Management', 'machine learning in HR', 'recruitment automation software'], 'articleSection': ['HR Tech', 'Latest'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/', 'url': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/', 'name': 'Top 15 Artificial Intelligence-Based Employee Engagement Tools for 2020', 'isPartOf': {'@id': 'https://www.techfunnel.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/#primaryimage'}, 'image': {'@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/#primaryimage'}, 'thumbnailUrl': 'https://www.techfunnel.com/wp-content/uploads/2019/11/Top-15-Artificial-Intelligence-Based-Employee-Engagement-Tools-for-2020.jpg', 'datePublished': '2019-11-12T09:45:29+00:00', 'dateModified': '2019-11-12T09:45:29+00:00', 'description': 'Employee engagement is a critical aspect of HR management. How artificial intelligence-based employee engagement tools are improving the HR processes', 'breadcrumb': {'@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/#primaryimage', 'url': 'https://www.techfunnel.com/wp-content/uploads/2019/11/Top-15-Artificial-Intelligence-Based-Employee-Engagement-Tools-for-2020.jpg', 'contentUrl': 'https://www.techfunnel.com/wp-content/uploads/2019/11/Top-15-Artificial-Intelligence-Based-Employee-Engagement-Tools-for-2020.jpg', 'width': 769, 'height': 445, 'caption': 'AI - Employee Engagement'}, {'@type': 'BreadcrumbList', '@id': 'https://www.techfunnel.com/hr-tech/artificial-intelligence-based-employee-engagement-tools/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.techfunnel.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Blog', 'item': 'https://www.techfunnel.com/blog/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 15 Artificial Intelligence-Based Employee Engagement Tools for 2020'}]}, {'@type': 'WebSite', '@id': 'https://www.techfunnel.com/#website', 'url': 'https://www.techfunnel.com/', 'name': 'Techfunnel', 'description': '', 'publisher': {'@id': 'https://www.techfunnel.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.techfunnel.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.techfunnel.com/#organization', 'name': 'Techfunnel', 'url': 'https://www.techfunnel.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techfunnel.com/#/schema/logo/image/', 'url': 'https://www.techfunnel.com/wp-content/uploads/2023/11/TF_NEWLOGOWHITE_New_logo.png', 'contentUrl': 'https://www.techfunnel.com/wp-content/uploads/2023/11/TF_NEWLOGOWHITE_New_logo.png', 'width': 256, 'height': 91, 'caption': 'Techfunnel'}, 'image': {'@id': 'https://www.techfunnel.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.techfunnel.com/#/schema/person/55746dbe674b75c6397c423dcf47539e', 'name': 'Danni White', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techfunnel.com/#/schema/person/image/', 'url': 'https://www.techfunnel.com/wp-content/uploads/2024/01/Danni_image-150x150.jpg', 'contentUrl': 'https://www.techfunnel.com/wp-content/uploads/2024/01/Danni_image-150x150.jpg', 'caption': 'Danni White'}, 'description': 'Danni White is the CEO of DW Creative Consulting Agency, a digital marketing firm specializing in elevating the visibility of small-to-midsize businesses and nonprofits. She is the author of 17 books and hosts the #Hashtags and Habits Podcast, which merges digital marketing, entrepreneurship, and personal growth.', 'url': 'https://www.techfunnel.com/author/daniella/'}]",https://www.techfunnel.com/,"{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.techfunnel.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vc2NpdGVjaGRhaWx5LmNvbS9uZXctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZ2VuZXRpYy1hbGdvcml0aG0tYXV0b21hdGljYWxseS1ldm9sdmVzLXRvLWV2YWRlLWludGVybmV0LWNlbnNvcnNoaXAv0gEA?oc=5,New Artificial Intelligence Genetic Algorithm Automatically Evolves to Evade Internet Censorship - SciTechDaily,2019-11-14,SciTechDaily,https://scitechdaily.com,,,"Researchers at the University of Maryland developed a new tool based on genetic evolution that automatically learned to evade censorship in China, India and Kazakhstan. Internet censorship by authoritarian governments prohibits free and open access to information for millions of people around the w","Researchers at the University of Maryland developed a new tool based on genetic evolution that automatically learned to evade censorship in China, India and Kazakhstan. Internet censorship by authoritarian governments prohibits free and open access to information for millions of people around the w",https://schema.org,,,,,,,,,,Technology,," New Artificial Intelligence Genetic Algorithm Automatically Evolves to Evade Internet CensorshipTOPICS:Artificial IntelligenceComputer ScienceInternetUniversity of Maryland By University of Maryland November 13, 2019Researchers at the University of Maryland developed a new tool based on genetic evolution that automatically learned to evade censorship in China, India and Kazakhstan.Internet censorship by authoritarian governments prohibits free and open access to information for millions of people around the world. Attempts to evade such censorship have turned into a continually escalating race to keep up with ever-changing, increasingly sophisticated internet censorship. Censoring regimes have had the advantage in that race, because researchers must manually search for ways to circumvent censorship, a process that takes considerable time.






New work led by University of Maryland computer scientists could shift the balance of the censorship race. The researchers developed a tool called Geneva (short for Genetic Evasion), which automatically learns how to circumvent censorship. Tested in China, India, and Kazakhstan, Geneva found dozens of ways to circumvent censorship by exploiting gaps in censors’ logic and finding bugs that the researchers say would have been virtually impossible for humans to find manually.  The researchers will introduce Geneva during a peer-reviewed talk at the Association for Computing Machinery’s 26th Conference on Computer and Communications Security in London on November 14, 2019.“With Geneva, we are, for the first time, at a major advantage in the censorship arms race,” said Dave Levin, an assistant professor of computer science at UMD and senior author of the paper. “Geneva represents the first step toward a whole new arms race in which artificial intelligence systems of censors and evaders compete with one another. Ultimately, winning this race means bringing free speech and open communication to millions of users around the world who currently don’t have them.”All information on the internet is broken into data packets by the sender’s computer and reassembled by the receiving computer. One prevalent form of internet censorship used by authoritarian regimes works by monitoring the data packets sent during an internet search. The censor blocks requests that either contain flagged keywords (such as “Tiananmen Square” in China) or prohibited domain names (such as “Wikipedia” in many countries).When Geneva is running on a computer that is sending out web requests through a censor, Geneva modifies how data is broken up and sent, so that the censor does not recognize forbidden content or is unable to censor the connection.Known as a genetic algorithm, Geneva is a biologically inspired type of artificial intelligence that Levin and his team developed to work in the background as a user browses the web from a standard internet browser. Like biological systems, Geneva forms sets of instructions from genetic building blocks. But rather than using DNA as building blocks, Geneva uses small pieces of code. Individually, the bits of code do very little, but when composed into instructions, they can perform sophisticated evasion strategies for breaking up, arranging, or sending data packets.






Geneva evolves its genetic code through successive attempts (or generations). With each generation, Geneva keeps the instructions that work best at evading censorship and kicks out the rest. Geneva mutates and crossbreeds its strategies by randomly removing instructions, adding new instructions, or combining successful instructions and testing the strategy again. Through this evolutionary process, Geneva is able to identify multiple evasion strategies very quickly.“This completely inverts how researchers typically approach the problem of censorship,” said Levin, who holds a joint appointment in the University of Maryland Institute for Advanced Computer Studies. “Ordinarily we identify how a censorship strategy works and then devise strategies to evade it. But now we let Geneva figure out how to evade the censor, and then we learn what censorship strategies are being used by seeing how Geneva defeated them.”The team tested Geneva in the laboratory against mock censors and in the real world against real censors. In the lab, the researchers developed censors that functioned like those known from previous research to be deployed by autocratic regimes. Within days, Geneva identified virtually all the packet-manipulation strategies that had been discovered by previously published work.To demonstrate that Geneva worked in the real world against undiscovered censorship strategies, the team ran Geneva on a computer in China with an unmodified Google Chrome browser installed. By deploying strategies identified by Geneva, the user was able to browse free of keyword censorship. The researchers also successfully evaded censorship in India, which blocks forbidden URLs, and Kazakhstan, which was eavesdropping on certain social media sites at the time. In all cases, Geneva successfully circumvented censorship.“Currently, the evade-detect cycle requires extensive manual measurement, reverse engineering, and creativity to develop new means of censorship evasion,” said Kevin Bock (B.S. ’17, M.S. ’18, computer science), a computer science Ph.D. student at UMD and lead author of the paper. “With this research, Geneva represents an important first step in automating censorship evasion.”The researchers plan to release their data and code in the hopes that it will provide open access to information in countries where the internet is restricted. The team acknowledges that there may be many reasons why individuals living under autocratic regimes might not want or be able to install the tool on their computers. However, they remain undeterred. The researchers are exploring the possibility of deploying Geneva on the computer supplying the blocked content (known as the server) rather than on the computer searching for blocked content (known as the client). That would mean websites such as Wikipedia or the BBC could be available to anyone inside countries that currently block them, such as China and Iran, without requiring the users to configure anything on their computer.






“If Geneva can be deployed on the server side and work as well as it does on the client side, then it could potentially open up communications for millions of people,” Levin said. “That’s an amazing possibility, and it’s a direction we’re pursuing.”###In addition to Levin, Bock and George Hughey (B.S. ’19, computer science) at UMD, Xiao Qiang of UC Berkeley also co-authored the paper. Seven UMD undergraduate students worked on this project as part of Levin’s Breakerspace lab in the UMD Department of Computer Science.Reference: “Geneva: Evolving Censorship Evasion Strategies” by Kevin Bock, George Hughey, Xiao Qian and Dave Levin, 14 November 14, CCS ’19: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. DOI: 10.1145/3319535.3363189






",,,,"[{'@type': 'NewsArticle', '@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/#article', 'isPartOf': {'@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/'}, 'author': 'University of Maryland', 'headline': 'New Artificial Intelligence Genetic Algorithm Automatically Evolves to Evade Internet Censorship', 'datePublished': '2019-11-13T18:03:01+00:00', 'dateModified': '2022-12-15T17:32:17+00:00', 'mainEntityOfPage': {'@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/'}, 'wordCount': 1051, 'commentCount': 0, 'publisher': {'@id': 'https://scitechdaily.com/#organization'}, 'image': {'@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/#primaryimage'}, 'thumbnailUrl': 'https://scitechdaily.com/images/AI-Internet-Censorship-Illustration.jpg', 'keywords': ['Artificial Intelligence', 'Computer Science', 'Internet', 'University of Maryland'], 'articleSection': ['Technology'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/#respond']}]}, {'@type': 'WebPage', '@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/', 'url': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/', 'name': 'New Artificial Intelligence Genetic Algorithm Automatically Evolves to Evade Internet Censorship', 'isPartOf': {'@id': 'https://scitechdaily.com/#website'}, 'primaryImageOfPage': {'@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/#primaryimage'}, 'image': {'@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/#primaryimage'}, 'thumbnailUrl': 'https://scitechdaily.com/images/AI-Internet-Censorship-Illustration.jpg', 'datePublished': '2019-11-13T18:03:01+00:00', 'dateModified': '2022-12-15T17:32:17+00:00', 'breadcrumb': {'@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/#primaryimage', 'url': 'https://scitechdaily.com/images/AI-Internet-Censorship-Illustration.jpg', 'contentUrl': 'https://scitechdaily.com/images/AI-Internet-Censorship-Illustration.jpg', 'width': 2000, 'height': 1200, 'caption': 'AI Internet Censorship Illustration'}, {'@type': 'BreadcrumbList', '@id': 'https://scitechdaily.com/new-artificial-intelligence-genetic-algorithm-automatically-evolves-to-evade-internet-censorship/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'SciTechDaily', 'item': 'https://scitechdaily.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'New Artificial Intelligence Genetic Algorithm Automatically Evolves to Evade Internet Censorship'}]}, {'@type': 'WebSite', '@id': 'https://scitechdaily.com/#website', 'url': 'https://scitechdaily.com/', 'name': 'SciTechDaily', 'description': 'Science, Space and Technology News 2024', 'publisher': {'@id': 'https://scitechdaily.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://scitechdaily.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://scitechdaily.com/#organization', 'name': 'SciTechDaily', 'url': 'https://scitechdaily.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://scitechdaily.com/#/schema/logo/image/', 'url': 'https://scitechdaily.com/images/scitechdaily-slogo.png', 'contentUrl': 'https://scitechdaily.com/images/scitechdaily-slogo.png', 'width': 200, 'height': 200, 'caption': 'SciTechDaily'}, 'image': {'@id': 'https://scitechdaily.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/scitechdaily', 'https://x.com/SciTechDaily1', 'https://www.youtube.com/@scitechdaily']}, {'@type': 'Person', '@id': 'https://scitechdaily.com/#/schema/person/0835c4deb3d8fede6625aa47fc21e767', 'name': ""Mike O'Neill"", 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://scitechdaily.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/d49dd0dcc99d9bf36b008d53f1d2aa2b?s=96&d=identicon&r=pg', 'contentUrl': 'https://secure.gravatar.com/avatar/d49dd0dcc99d9bf36b008d53f1d2aa2b?s=96&d=identicon&r=pg', 'caption': ""Mike O'Neill""}, 'sameAs': ['http://www.scitechdaily.com']}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LmNoYW5uZWxzdHYuY29tLzIwMTkvMTEvMTMvYXJ0LW1lZXRzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvbXB1dGVyLWdlbmVyYXRlZC13b3Jrcy1vbi1kaXNwbGF5L9IBcGh0dHBzOi8vd3d3LmNoYW5uZWxzdHYuY29tLzIwMTkvMTEvMTMvYXJ0LW1lZXRzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvbXB1dGVyLWdlbmVyYXRlZC13b3Jrcy1vbi1kaXNwbGF5L2FtcC8?oc=5,Art Meets Artificial Intelligence: Computer-Generated Works On Display - Channels Television,2019-11-13,Channels Television,https://www.channelstv.com,Art Meets Artificial Intelligence: Computer-Generated Works On Display,,  Two paintings up for auction in New York highlight a growing interest in artificial intelligence-created works — a technique that could transform how art is … Continue reading Art Meets Artificial Intelligence: Computer-Generated Works On Display,,https://schema.org,,,,,,,,,,,,"



 A picture taken on November 1, 2019 at Sotheby’s in New york shows two paintings, from left, “La Baronne de Belamy,” (est. $20,000 – $30,000) a portrait from the same Famille de Belamy series that Christie’s offered last year and “Katsuwaka of the



 A picture taken on November 1, 2019 at Sotheby’s in New York shows two paintings, from left, “La Baronne de Belamy,” (est. $20,000 – $30,000) a portrait from the same Famille de Belamy series that Christie’s offered last year and “Katsuwaka of the Dawn Lagoon,” (est. $8,000 – $12,000) a new work from the group’s second and more recent series (produced in 2019) of works called Electric Dreams of Ukiyo. PHOTO: Thomas URBAIN / AFP





 
Two paintings up for auction in New York highlight a growing interest in artificial intelligence-created works — a technique that could transform how art is made and viewed but is also stirring up passionate debate.

Advertisement





The art world was stunned last year when an AI painting sold for $432,500, and auctioneers are keen to further test demand for computer-generated works.
“Art is a true reflection of what our society, what our environment responds to,” said Max Moore of Sotheby’s.
“And so it’s just a natural continuation of the progression of art,” he added.
Sotheby’s will put two paintings by the French art collective Obvious up for sale on Thursday, including “Le Baron De Belamy.”

Advertisement





The European classic style portrait is part of the same series as “Portrait of Edmond Belamy”, which sold for more than 60 times the lowest estimate at Christie’s during the 2018 fall auctions.
The paintings were made using a technique called “generative adversarial network,” or GAN.
GAN involves feeding thousands of images of the same style into a computer until the machine concludes that it has created a new portrait that it thinks accurately reflects that style.
“Katsuwaka of the Dawn Lagoon” was created in a Japanese style using the same GAN algorithm.

Advertisement





Auctioneers have put modest prices on the two paintings. “Katsuwaka” has a pre-sale estimate between $8,000 and $12,000, while “Le Baron” has been priced between $20,000 and $30,000.
“We do not expect as big a result as last year,” said Pierre Fautrel, one of the three members of Obvious.
“We just want to see if there are people who are ready to buy around these prices and if the market will continue to build,” he added.
Moore said the sale of “Portrait of Edmond Belamy” showed that there is “a marketplace for this new body of work” but that it’s still “in the very early stages.”

Advertisement





“That will be a good indicator of where the market is,” he said.
In the fledgling artificial intelligence market, Obvious is not the most sought-after group of artists.
Not for everyone
Steven Sacks, owner of the bitforms gallery in New York says his client, the Canadian-Mexican artist Rafael Lozano-Hemmer has already made around $600,000 for an AI artwork.
Whereas Obvious’s paintings are fixed, most of Lozano-Hemmer’s works use software to change in real time according to data about each viewer’s perspective.
Other prominent AI artists who are exhibiting their work across the world include Germany’s Mario Klingemann and Turkish-born Refik Anadol.
Klingemann also makes portraits, sometimes tweaking the input data with voluntary glitches to avoid replication. Anadol uses mostly video to produce abstract data-based animations.
Klingemann’s “Memories of Passersby I”, a stream of portraits created by a machine, sold for $40,000 at Sotheby’s in London in March.
Sacks and several other artists AFP spoke to were critical of the “Bellamy” sale last year.
They feel that that painting is not representative of the potential of AI and argue that Obvious is imitating other works whereas they are creating something new.
“For me it was a problem because it wasn’t authentic,” said Sacks, who subscribes to a school of thought that works made by AI should constantly be changing, usually on screens.
Some also criticize Obvious for giving the impression that AI can create works of art without human interference.
“An artist chooses. He lightens, he reinforces. Can a computer do that?” asks French painter Ronan Barrot, who has collaborated with British AI artist Robbie Barrat.
The debate continues to rage. Fautrel of Obvious denies that his collective merely imitates other artworks and sees AI as a “tool” and not an end in itself.
Despite their differences, they all agree the market for AI paintings is growing and that the sale of “Bellamy” has drawn attention to the burgeoning technique.
“I don’t think this new style is for everyone but I think you’re going to start catching the attention of a lot of people that aren’t necessarily art collectors but are very interested in the technology behind AI,” said Sotheby’s Moore.
AFP




 





In This Article:


Artificial Intelligence Art works Computer-Generated Works New York Sotheby 








More Stories








 



Actor Tom Hanks Warns Of Ad With AI Imposter










 



Clickbait Or Creativity? The Art World Wrestles With AI











Please enable JavaScript to view the comments powered by Disqus.

",,,,"[{'@type': 'Article', '@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#article', 'isPartOf': {'@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/'}, 'author': {'name': 'Ronke Sanya Idowu', '@id': 'https://www.channelstv.com/#/schema/person/f595fa3160363d679d6e4befbb474aec'}, 'headline': 'Art Meets Artificial Intelligence: Computer-Generated Works On Display', 'datePublished': '2019-11-13T15:24:33+00:00', 'dateModified': '2019-11-13T15:24:33+00:00', 'mainEntityOfPage': {'@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/'}, 'wordCount': 750, 'commentCount': 0, 'publisher': {'@id': 'https://www.channelstv.com/#organization'}, 'image': {'@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#primaryimage'}, 'thumbnailUrl': 'https://www.channelstv.com/wp-content/uploads/2019/11/Artificial-Intelligence-artwork.jpg', 'keywords': ['Artificial Intelligence Art works', 'Computer-Generated Works', 'New York', 'Sotheby'], 'articleSection': ['Info Tech'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#respond']}], 'copyrightYear': '2019', 'copyrightHolder': {'@id': 'https://www.channelstv.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/', 'url': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/', 'name': 'Art Meets Artificial Intelligence: Computer-Generated Works On Display &#8226; Channels Television', 'isPartOf': {'@id': 'https://www.channelstv.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#primaryimage'}, 'image': {'@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#primaryimage'}, 'thumbnailUrl': 'https://www.channelstv.com/wp-content/uploads/2019/11/Artificial-Intelligence-artwork.jpg', 'datePublished': '2019-11-13T15:24:33+00:00', 'dateModified': '2019-11-13T15:24:33+00:00', 'breadcrumb': {'@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#primaryimage', 'url': 'https://www.channelstv.com/wp-content/uploads/2019/11/Artificial-Intelligence-artwork.jpg', 'contentUrl': 'https://www.channelstv.com/wp-content/uploads/2019/11/Artificial-Intelligence-artwork.jpg', 'width': 650, 'height': 350, 'caption': ""A picture taken on November 1, 2019 at Sotheby's in New york shows two paintings, from left, “La Baronne de Belamy,” (est. $20,000 - $30,000) a portrait from the same Famille de Belamy series that Christie’s offered last year and “Katsuwaka of the""}, {'@type': 'BreadcrumbList', '@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.channelstv.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Info Tech', 'item': 'https://www.channelstv.com/category/info-tech/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Art Meets Artificial Intelligence: Computer-Generated Works On Display'}]}, {'@type': 'WebSite', '@id': 'https://www.channelstv.com/#website', 'url': 'https://www.channelstv.com/', 'name': 'Channels Television', 'description': 'The Latest News from Nigeria and Around the World', 'publisher': {'@id': 'https://www.channelstv.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.channelstv.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': ['Organization', 'Place'], '@id': 'https://www.channelstv.com/#organization', 'name': 'Channels Television', 'url': 'https://www.channelstv.com/', 'logo': {'@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#local-main-organization-logo'}, 'image': {'@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#local-main-organization-logo'}, 'sameAs': ['https://www.facebook.com/channelsforum', 'https://twitter.com/channelstv', 'https://instagram.com/channelstelevision', 'https://www.tiktok.com/@channelstv'], 'description': 'Channels Television is a multiple award winning 24-hour news and media organization which was founded in 1992 by Nigerian veteran broadcasters and business moguls: John Momoh and Sola Momoh. The Company commenced operations in Lagos, south western Nigeria and has since grown to include three other Stations in Abuja, Edo and Kano states. The Company also has bureaus in almost every state in Nigeria, including stringers and affiliates in other parts in Africa. Operating in Nigeria’s hugely popular broadcast media market, Channels Television is the first and only thriving national TV brand, dedicated solely to the dissemination of news.', 'legalName': 'Channels Television', 'foundingDate': '1992-07-01', 'geo': {'@type': 'GeoCoordinates', 'latitude': '6.639953', 'longitude': '3.396932'}, 'telephone': ['+234-1-2131214, +234-1-2131215', '+234-704-520-3063'], 'openingHoursSpecification': [{'@type': 'OpeningHoursSpecification', 'dayOfWeek': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], 'opens': '09:00', 'closes': '17:00'}], 'email': 'info@channelstv.com'}, {'@type': 'Person', '@id': 'https://www.channelstv.com/#/schema/person/f595fa3160363d679d6e4befbb474aec', 'name': 'Ronke Sanya Idowu', 'url': 'https://www.channelstv.com/author/ronke/'}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.channelstv.com/2019/11/13/art-meets-artificial-intelligence-computer-generated-works-on-display/#local-main-organization-logo', 'url': 'https://www.channelstv.com/wp-content/uploads/2024/03/logo.png', 'contentUrl': 'https://www.channelstv.com/wp-content/uploads/2024/03/logo.png', 'width': 85, 'height': 84, 'caption': 'Channels Television'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LmtoYWxlZWp0aW1lcy5jb20vdWFlL3JvYm90cy1jYW4td29yay1iZXR0ZXItd2l0aC1jb25jZWFsZWQtaWRlbnRpdHktc3VydmV50gFcaHR0cHM6Ly93d3cua2hhbGVlanRpbWVzLmNvbS91YWUvcm9ib3RzLWNhbi13b3JrLWJldHRlci13aXRoLWNvbmNlYWxlZC1pZGVudGl0eS1zdXJ2ZXk_YW1wPTE?oc=5,Robots can work better with concealed identity: Survey - Khaleej Times,2019-11-15,Khaleej Times,https://www.khaleejtimes.com,Recent technological breakthroughs in artificial intelligence (AI) have made it possible for machines or robots to pass as humans. ,"Robots, work, better, concealed identity, Survey, artificial intelligence, AI, humans, ", Recent technological breakthroughs in artificial intelligence (AI) have made it possible for machines or robots to pass as humans.  , Recent technological breakthroughs in artificial intelligence (AI) have made it possible for machines or robots to pass as humans.  ,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.khaleejtimes.com/uae/robots-can-work-better-with-concealed-identity-survey'}",Robots can work better with concealed identity: Survey  - News | Khaleej Times,"{'@type': 'ImageObject', 'url': 'https://image.khaleejtimes.com?uuid=d09b8b16-f2ac-4e9c-be46-5d8109a86d73&function=cropresize&type=preview&source=false&q=75&crop_w=0.99999&crop_h=0.87209&x=0&y=0&width=1200&height=675', 'width': 780, 'height': 435}","[{'@type': 'Person', 'name': 'Ismail Sebugwaawo', 'URL': 'https://www.khaleejtimes.com/ismail-sebugwaawo'}]",2019-11-15T18:00:00+04:00,2019-11-15T20:06:22+04:00,"{'@type': 'Organization', 'name': 'Khaleej Times', 'url': 'https://www.khaleejtimes.com', 'logo': {'@type': 'ImageObject', 'url': 'https://static.khaleejtimes.com/wp-content/uploads/sites/2/2021/10/12171006/khaleej-times-logo.png', 'width': 200}}",,,,uaeDubai traffic alert: Vehicle breakdown on Al Khail road causes delays Motorists have been advised to remain extra cautious uae,Robots can work better with concealed identity: Survey  - News | Khaleej Times,https://image.khaleejtimes.com?uuid=d09b8b16-f2ac-4e9c-be46-5d8109a86d73&function=cropresize&type=preview&source=false&q=75&crop_w=0.99999&crop_h=0.87209&x=0&y=0&width=1200&height=675,UAE,,,,,"['https://twitter.com/khaleejtimes', 'https://www.facebook.com/khaleejtimes', 'https://www.linkedin.com/company/khaleejtimes', 'https://www.instagram.com/khaleejtimes/', 'https://www.youtube.com/c/khaleejtimes', 'https://en.wikipedia.org/wiki/Khaleej_Times']",,,,,,,en,,,"{'type': 'Organization', 'name': 'Galadari Printing and Publishing LLC'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vd3d3Lm9ucmVjLmNvbS9uZXdzL25ld3MtYXJjaGl2ZS9yZXBvcnQtZmluZHMtbmVnYXRpdmUtaW1wYWN0LW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFpLWpvYi1zZWVraW5nLWNhbmRpZGF0ZXPSAQA?oc=5,Report finds negative impact of artificial intelligence (AI) on job seeking candidates and employer brands - Onrec,2019-11-26,Onrec,https://www.onrec.com,"Online Recruitment magazine for HR Directors, Personnel Managers, Job Boards and Recruiters with information on the internet recruitment industry","Recruitment, Online Recruitment, Internet Recruitment, Human Resources, Job Sites, Job Boards, e-recruitment, job hunting, recruitment sites, jobs, employment, e-business, e-commerce, management, HR, CVs, resumes, vacancies, recruitment advertising, job",,,,,,,,,,,,,,,"



Stuart Gentle Publisher at Onrec

26 Nov 2019|News archive

Report finds negative impact of artificial intelligence (AI) on job seeking candidates and employer brandsPoor candidate experience due to increased use of artificial intelligence during application process has been found to alienate skilled candidates and potentially damage employer brands:
9 in 10 job seekers don’t want to deal with automated CV tools during application stage 

86 per cent of applicants want their CVs assessed by a person, not a machine

Three-quarters of candidates look negatively on employer’s who include AI at point of application
Increased automation of the hiring process is seeing many organisations miss out on top talent at all levels of the organisation, according to new research published by global executive search firm Carmichael Fisher.
Examining the use of AI in typical candidate selection processes, the report’s aim was to identify the areas of hiring that were putting off candidates, as well as where technology could be better utilised.
Authored by James Wright in association with the West East Institute (WEI), the findings of ‘The impact of artificial intelligence within the recruitment industry: defining a new way of recruiting’ paper were presented recently at the Harvard Faculty Club in Boston, USA which played host to the 2019 WEI International Academic Conference on Business, Economics, Management and Finance
Key among them was that nine out of 10 job seekers reject the notion of artificial intelligence being used to parse CV’s. Accordingly, 86 per cent of respondents would prefer their application to be reviewed by a human, rather than an applicant tracking system.
Interestingly, most candidates said they would not want a business to make a hiring decision based on their CV alone. Artificial intelligence is highly effective at streamlining the recruitment process, but unless the applicant’s CV contains sufficient keywords relating to the position being recruited for, it runs the risk of elimination from the process.
Video interviewing has been seen by many as an alternative to the CV, but the research found that this format is equally unpopular among candidates.
As with application parsing technologies, one in five respondents stated a “dislike” of video interviews. Nine in 10 stated they would favour of human interaction over that of a robot with four-fifths of respondents saying that they would normally ask questions about the company in an interview.
This further demonstrates the desire among job seekers for personal communication in hiring, particularly as top talent remains in the driving seat in an increasingly candidate-driven employment market where employment is at a record-high.
The study also asked whether the complete automation of the hiring process was favourable and three-quarters (73 per cent) of respondents stated that it actively worsened their perception of a business and its overall employer brand.
Overall, the research indicates that the traditional recruitment process needs to change – with 84 per cent of candidates labelling the current procedure as ineffective.
Significantly, the study indicates positivity towards AI for its ability to lessen bias and improve diversity levels as part of the wider hiring process. It outlines that the use of smart assessment tools such as gamification and video analysis technologies will deliver more objective assessments of candidates. The report also found that AI will enable faster and fairer applications – reducing fallout rates and improving diversity.
Speaking on the findings of the research, James Wright, Technology Consultant from Carmichael Fisher said:
“The use of AI in the preliminary stages of recruitment is useful to analyse the market and to assist with areas of potential human error such as unconscious bias.
“However, once you have a candidate shortlist, the process becomes intrinsically human and interactive. One of the most common words we found used in the study, when asking participants about using AI for the whole hiring process was ‘impersonal’.
“The role of a recruiter is entirely based on consolidating solid and trustworthy relationships with candidates, getting to know them and their wants and desires. While the future of HR and hiring certainly will welcome AI to take over those more administrative tasks, the role of the human recruiter isn’t going anywhere yet.”
To access the full report, CLICK HERE.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vc2lmdGVkLmV1L2FydGljbGVzLzMwLWFpLXBlb3BsZS1pbi1ldXJvcGUtdG8tZm9sbG93LW9uLXR3aXR0ZXLSAQA?oc=5,The AI experts in Europe you should follow on Twitter - Sifted,2019-11-27,Sifted,https://sifted.eu,Our list of Europe&apos;s AI experts you should follow on Twitter includes top minds working at companies like Facebook and DeepMind.,,Our list of Europe's AI experts you should follow on Twitter includes top minds working at companies like Facebook and DeepMind.,,https://schema.org,Organization,"{'@type': 'WebPage', '@id': 'https://sifted.eu/articles/30-ai-people-in-europe-to-follow-on-twitter'}",The AI experts in Europe you should follow on Twitter | Sifted,"['https://images.sifted.eu/wp-content/uploads/2019/11/26162233/Catherine-Breslin.jpeg?w=1000&amp;h=667&amp;q=75&amp;fit=crop&amp;auto=compress,format']","[{'@type': 'Person', 'name': 'Sam Shead', 'url': 'https://sifted.eu/author/sam-shead'}]",,2022-05-12T11:00:06+00:00,"{'@type': 'Organization', 'name': 'Sifted', 'logo': {'@type': 'ImageObject', 'url': 'https://images.sifted.eu/wp-content/uploads/2018/11/25141406/Sifted-1A.png?w=2000&amp;h=443&amp;q=75&amp;fit=crop&amp;auto=compress,format'}}",,,,"Home to some of the world's top artificial intelligence (AI) labs, Europe is brimming with AI experts and many of them are using Twitter to talk about their work.They're sharing academic papers, job opportunities, AI news and other bits of information that can be hard to come by through a standard Google search.But finding these people on Twitter isn't always easy, so Sifted has curated a handy list of AI gurus for you to follow and thrive off.Advertisement1. Neil Lawrence (University of Cambridge)Neil Lawrence is a researcher at the University of Cambridge's Department of Computer Science and Technology. He announced he was joining the university in September as the inaugural DeepMind professor of machine learning. That essentially means DeepMind is paying him to carry out AI research at the university.Prior to taking up the professorship, Lawrence was director of machine learning at Amazon Cambridge.Likes to tweet about: Safe AI, Cambridge, diversityTwitter handle: @lawrennd2. Demis Hassabis (DeepMind)It feels like this man needs no introduction, but for anyone who doesn't know who Demis Hassabis is, here's the lowdown. He's the cofounder and chief executive of the London-headquartered DeepMind AI lab, which was acquired by Google in 2014 for £400m. Prior to DeepMind, Hassabis had his own computer games company called Elixir Studios, but his passion for games goes way back. He was a chess master at the age of 13 and the second-highest-rated under 14 player in the world at one time.Likes to tweet about: Science, games, DeepMind breakthroughsTwitter handle: @demishassabis3. Catherine Breslin (Cobalt Speech)Catherine Breslin is a machine learning scientist and consultant based in Cambridge. After completing her PhD at the University of Cambridge, Catherine went on to work on automatic speech recognition, natural language understanding and human-computer dialogue systems for the likes of Toshiba Research and the Amazon Alexa team.Likes to tweet about: AI pioneers, jobs, education, AmazonTwitter handle: @catherinebuk4. Samim Winiger (Ecospace)Not one to shy away from complex world issues, Berlin-based Samim Winiger recently worked for Google on interactive machine learning projects. He's also the cofounder of a startup called Ecospace, which is on a mission to cultivate nature with digital tools and practices that are open-sourced to everyone.Likes to tweet about: Mental health, Japanese culture, inequality, harmful AITwitter handle: @samim5. Beth Singler (University of Cambridge)Beth Singler is a research fellow anthropologist at the University of Cambridge who, according to her Twitter bio, is ""thinking about how you think about AI/robots"". Among her main concerns are the social, ethical, philosophical and religious implications of advances in AI and robotics.Likes to Tweet about: Crazy robots, memes, tea, religionTwitter handle: @BVLSingler6. Odette Scharenborg (Delft University of Technology)Odette Scharenborg is an associate professor at Delft University of Technology, where she works on speech processing. She's interested in areas like non-nativeness, under-resourced languages, background noise, and emotion.Likes to tweet about: Diversity in AI, baby animals, fantasy novels, runningTwitter handle: @OScharenborg7. Andrew Trask (DeepMind) Andrew Trask is a PhD student at the University of Oxford and a senior research scientist at DeepMind, where he studies privacy and AI. He's also written a book about deep learning, an AI technique, which has sold over 10,000 copies.Likes to tweet about: Privacy, deep learningTwitter handle: @iamtrask 8. Jack Kelly (Open Climate Fix)Jack Kelly left DeepMind (not many people do) in order to set up a non-profit climate change startup. “Open Climate Fix is entirely focused on using open-science to mitigate climate change,” Kelly told Sifted earlier this month. “The aim of our first project is to reduce emissions from the electricity system by building the best near-term solar electricity forecasting system. We’re using machine learning, satellite imagery and numerical weather predictions.”Likes to tweet about: Emissions, startups, National GridTwitter handle: @jack_kelly9. Nando de Freitas (DeepMind)Nando de Freitas sold his startup, Dark Blue Labs (a spinout from Oxford University), to DeepMind in October 2014. In his Twitter bio, he writes: ""I research intelligence to understand what we are, and to harness it wisely.""AdvertisementLikes to tweet about: The brain, climate change, DeepMind researchTwitter handle: @NandoDF10. Danielle Belgrave (Microsoft Research)Danielle Belgrave is a computer scientist at Microsoft Research. Among other things, she focuses on how machine learning can be applied to healthcare. For example, she's currently looking at using machine learning models to understand disease progression and heterogeneity disease.Likes to tweet about: Healthcare, climate change, automationTwitter handle: @DaniCMBelg11. Rob McCargow (PwC)Director of AI at PwC, Rob McCargow certainly breaks the mould of a ""boring accountant"" working at one of the ""Big Four"". A keen retweeter/news sharer, McCargow does a good job of keeping on top of AI news and sharing it with his followers.Likes to tweet about: Responsible AI, veganism, UK techTwitter handle: @RobMcCargow12. Edward Grefenstette (Facebook AI Research)Edward Grefenstette left DeepMind in November 2018 and joined Facebook AI Research in January 2019, raising a few eyebrows in the process. One of his main areas of interest is natural language understanding, which has wide applications across Facebook's platform.Likes to tweet about: Politics, AI research papersTwitter handle: @egrefen13. James Vincent (The Verge) James Vincent is one of the best-known AI journalists in the UK. Funny, yet smart, he has a knack for sifting through complex AI research papers and pulling out the most interesting bits. He's also working on a book on the history of measurement.Likes to tweet about: AI breakthroughs, scary robots, science, weird things on the internetTwitter handle: @jjvincent14. William Tunstall-Pedoe (Startup mentor, advisor, investor)William Tunstall-Pedoe is responsible for building a lot of the technology inside one of the world's most popular voice assistants: Alexa. He sold his voice recognition startup, Evi Technologies, to Amazon in 2012 for what was reported to be around $26 million (£21 million). Amazon used Evi as the foundation for Amazon Cambridge, which now employs hundreds of people.Likes to tweet about: Politics, startups, AlexaTwitter handle: @williamtp15. Murray Shanahan (DeepMind)Murray Shanahan splits his time across the Department of Computing at Imperial College London, one of the leading universities in the world, and DeepMind, where he is a senior research scientist. He's also written a book called ""The Technological Singularity"".Likes to tweet about: Robotics, computational neuroscience, and philosophy of mindTwitter handle: @mpshanahan16. Verena Rieser (Heriot Watt University)Verena Riser is a professor in conversational AI at Heriot Watt University in Edinburgh. Her particular area of interest is at the intersection of language technology and machine learning. She has worked on interdisciplinary applications spanning decision support, human-robot interaction, spoken dialogue systems and natural language generation.Likes to tweet about: Academia, feminismTwitter handle: @verena_rieser17. Joanna Bryson (University of Bath) Joanna Bryson founded the Bath AI Group at the University of Bath. She is set to become a professor of ethics and technology at Berlin's Hertie School of Governance in February.Likes to tweet about: AI ethics and policyTwitter handle: @j2bryson18. Noel Sharkey (University of Sheffield)Best known for his appearances on Robot Wars, Noel Sharkey is also a professor of AI and robotics at the University of Sheffield.Likes to tweet about: Biologically inspired robotics, cognitive processes, history of automataTwitter handle: @NoelSharkey19. Tabitha Goldstaub (CognitionX)Tabitha Goldstaub is the brains behind CognitionX, the UK's biggest AI conference. The event attracts employees from companies like Amazon and Palantir, as well as investors looking to back the next big thing. Goldstaub is also chair of the UK Government's AI Council.Likes to tweet about: AI conferences, women in techTwitter handle: @tabithagold20. Alan Winfield (University of the West of England, Bristol)Alan Winfield is a professor of robotics ethics at UWE Bristol, where his work spans research and public engagement. He spends a chunk of his time at the Bristol Robotics Lab and has a particular interest in cognitive robotics.Likes to tweet about: Politics, robot ethicsTwitter handle: @alan_winfield21. John Danaher (National University of Ireland, Galway)  <br/>Photograph by Aengus McMahonJohn Danaher is an academic and lecturer at the National University of Ireland, Galway. He teaches in the university's School of Law but he's an affiliate scholar at the Institute for Ethics and Emerging Technologies. His research involves looking at the ethical, social and legal implications of emerging technologies, such as AI.Likes to tweet about: The mind, surveillanceTwitter handle: @johndanaher22. Maria Axente (PwC)The second PricewaterhouseCoopers (PwC) employee to make the list. Who'd have thought it? Maria Axente is the artificial intelligence programme driver and AI for Good Lead at PwC in London. In her role, Axente advises PwC's partners across industry, academia, governments and more on how to harness the power of AI in an ethical and responsible manner.Likes to tweet about: AI regulation, ethicsTwitter handle: @maria_axente23. Sarah Porter (Inspired Minds)Sarah Porter is the founder and chief executive of Inspired Minds, which is a community of 52,000 people that are trying to do good with AI.Likes to tweet about: Climate change, ethics, the EUTwitter handle: @SColesPorter24. Kate Devlin (King's College London) Kate Devlin is a senior lecturer in the Department of Digital Humanities at King's College London, where she is ""investigating how people interact with and react to technology in order to understand how emerging and future technologies will affect us and the society in which we live"". She started her career as an archaeologist, before moving into computer science. Devlin has also written a book on sex robots called ""Turned On"".Likes to tweet about: Sex robotsTwitter handle: @drkatedevlin25. Kriti Sharma (Sage)Kriti Sharma is the vice president of artificial intelligence and ethics at Sage, which is often referred to as one of the UK's largest tech companies. Sharma built her first robot at the age of 15 and went on to be appointed as United Nations Young Leader for the Sustainable Development Goals (SDGs) in 2018.Likes to tweet about: Human bias in AI, AI for Good, SageTwitter handle: @sharma_kriti26. Dame Wendy Hall (University of Southampton)Dame Wendy Hall wears many hats. In addition to being a professor at the University of Southampton, she's also the UK's AI skills champion and she co-chaired the UK government’s AI Review. She's also a fellow of the prestigious Royal Society.Likes to tweet about: Women in science and engineeringTwitter handle: @DameWendyDBE27. Jess Williams (Opearlo)Y Combinator graduate Jess Williams is the chief executive of Opearlo, which is trying to build the best voice apps for Google Home and Amazon Alexa. Before getting into the startup world, Williams spent three and a half years at Accenture as a consultant and a product manager.Likes to tweet about: Education, diversity in AITwitter handle: @Jess_P_Williams28. Katja Hofmann (Microsoft Research)
Katja Hofmann, a principal researcher at Microsoft Research's Game Intelligence group, has been doing some pioneering work in reinforcement learning, which is a subfield of AI. Her particular focus is building agents that can play video games.Likes to tweet about: Games, Microsoft, reinforcement learningTwitter handle: @katjahofmann29. Julia Shaw (Spot)Psychological scientist Julia Shaw is the cofounder of Spot, which is a software platform that aims to help companies tackle harassment and discrimination. It comes with harassment training, surveys and anonymous reporting. There is also an AI bot that employees can talk to when there's something wrong.Likes to tweet about: Discrimination, psychologyTwitter handle: @drjuliashaw30. Ivan Beckley (UCL)Ivan Beckley is a medical student at University College London (UCL). The South Londoner impressed DeepMind so much that the company decided to sponsor his master's degree.Likes to tweet about: Healthcare, medicine, DeepMindTwitter handle: @ivanbeckley",Sifted,,,,https://sifted.eu,,,"['https://www.facebook.com/siftedeu/', 'https://twitter.com/siftedeu', 'https://uk.linkedin.com/company/siftedeu', 'https://www.instagram.com/siftedeu/']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vd3d3LnRoZW1hbnVmYWN0dXJlci5jb20vYXJ0aWNsZXMvaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWlzLWltcHJvdmluZy1hdXRvbW90aXZlLW1hbnVmYWN0dXJpbmctc3RhbmRhcmRzL9IBAA?oc=5,How artificial intelligence is improving automotive manufacturing standards - The Manufacturer,2019-11-27,The Manufacturer,https://www.themanufacturer.com,"Amir Hever, CEO of UVeye, recalls the company’s beginnings and explains how artificial intelligence is setting the standard for automotive manufacturing.",,"Amir Hever, CEO of UVeye, recalls the company’s beginnings and explains how artificial intelligence is setting the standard for automotive manufacturing.",,https://schema.org,,,,,,,,,,,,"
How artificial intelligence is improving automotive manufacturing standards
Posted on 27 Nov 2019 by The Manufacturer


Share this article:
Share on Linkedin
Share on Twitter
Share on facebook
Copy Link
 








Amir Hever, CEO of UVeye, recalls the company’s beginnings and explains how its range of AI-based products is setting the future standard for automotive manufacturing.
UVeye is a provider of solutions for the automatic external inspection of vehicles. With roots in the security and defence sector, the company’s threat-detection products have already been deployed in numerous high-security facilities around the world.
More recently, UVeye has extended and adapted its product suite for the wider automotive market. Not only is the company’s technology targeted at improving quality standards in garages and dealerships, but also in vehicle manufacturing plants, particularly in end-of-line inspection.

Image courtesy of Depositphotos.

It was after a visit to the premises of a government agency in Tel Aviv that my brother, Ohad, and I had the idea for UVeye – short for Under Vehicle eye.
When we arrived, a security guard stopped us and laid down on the ground next to our car. I asked him what he was doing, and he told me that he was looking to see if I had anything hidden under the vehicle.
“Do you see anything?” I asked. “Nope, I can never see anything,’’ was his swift reply.
From the resulting conversation, I discovered that, even in a country like Israel, where the highest safety standards are expected, and even in a world where digital technology has made leaps and bounds in recent years, many vehicle inspections still consist of rudimentary visual checks.
In the hope of offering an alternative method, in June 2016 we decided to set up UVeye with the aim of utilising high-resolution cameras and AI-based software solutions to take external vehicle inspections into the digital era.

This article first appeared in the November issue of The Manufacturer magazine. Click here to subscribe


The power of three
Naturally, developing technology that could examine the undercarriage of a vehicle was a good place to start, given our experience at the government agency.
However, after introducing the system as a tool in the security sector, we also saw the potential to take this technology further and bring it to the automotive industry.
Just as the technology could be used to detect threats on a vehicle, so too could it be used to detect faults, maintenance issues, and cosmetic damage.
A key area for its application is during end-of-line inspection in an automotive manufacturing plant, where the vehicle is visually inspected for imperfections.

Image courtesy of Depositphotos.

With AI-based technology, it’s possible to increase the efficiency, objectivity and accuracy of work on vehicle production lines, while enhancing safety and enabling a higher volume of work with the same amount of resources.
By detecting faults at an early stage, we can prevent a potential breakdown and reduce maintenance costs over the lifetime of the vehicle. These faults might include loose bolts, incorrectly routed cables, damage to paintwork or underinflated tyres, to name a few examples.
What’s more, with manual checks, manufacturers not only risk overlooking faults on their vehicles, but also waste time that could be more productively allocated elsewhere in the factory.
An intelligent AI-based system greatly enhances speed and efficiency, improving the flow of vehicles through and out of the plant.
With all of this in mind, we expanded the breadth and capabilities of UVeye’s technology to other areas of a vehicle’s exterior, such as the tyres and bodywork.
Today, we have three product offerings: Helios, Artemis, and Atlas.
Helios
Helios is the undercarriage inspection system, which comes in stationary or portable iterations.



UVeye’s Helios undercarriage inspection system – image courtesy of UVeye.


The hardware comprises five high-resolution cameras in its stationary version and three in the portable version, which capture images from multiple angles to ensure that no spot on the vehicle goes uninspected.
Helios produces a high-resolution image within three seconds of a vehicle driving over the hardware – at speeds of up to 30km/h – and a full analysis within 10 seconds. The system provides the user with a detailed view of the complex componentry on a vehicle’s undercarriage.
UVeye’s deep learning algorithms then process the image to detect anomalies that would otherwise go unnoticed by the human eye.
The technology is able to accurately identify what the individual parts of the undercarriage look like under a wide range of different conditions, such as lighting, stages of wear and tear, and moisture.
If an anomaly is detected, the Helios system automatically alerts the employee at the manufacturing plant and directs them to the exact spot where the anomaly was found.
This makes it easy for them to take action, while reducing the learning curve and other factors like fatigue or stress.



Artemis



UVeye’s Artemis tyre inspection product – image courtesy of UVeye.


Artemis is UVeye’s tyre inspection product. The system comprises two tyre scanners that stand at the side of the vehicle while it drives past at speeds up to 20 km/h.
In a matter of seconds, Artemis reads and recognises the tyre brand, markings, and technical specifications, as well as crucial safety-related data such as tyre condition, pressure, abrasions and to cross-reference the pressure of each tyre to the manufacturer’s standards and measurements, and report any incorrect pressure levels.
The system can even provide a comparison across all of the vehicle’s tyres to determine any irregularities. Presented with this wealth of information and a high-resolution image that highlights any faults or anomalies, technicians at the manufacturing plant can then take the necessary steps to repair or replace the vehicle’s tyres.
It can also bring to their attention any repetitive issues that could be indicative of a larger problem in the production process that must be corrected.
Atlas
The 360° full-body scanner, Atlas, completes UVeye’s portfolio and is used to detect dents, scratches or other cosmetic issues on the vehicle’s upper bodywork.



Atlas – UVeye’s 360° full-body scanner – image courtesy of UVeye.


Atlas looks similar to the large light tunnels found in vehicle factories, taking the form of a bright arc that encircles the vehicle. However, it is far more compact and incorporates the same deep-learning algorithms as Helios and Artemis.
With these, the system can automatically detect scratches as short as a few millimetres, in addition to any broken parts.
Unlike conventional methods, vehicles can be driven or moved on a conveyor through Atlas at up to 20km/h, allowing an uninterrupted flow across the production line. Only if a fault is found does the line need to be stopped.
Working together with Helios and Artemis, the three systems are capable of producing a full 360° scan of the vehicle, so that no fault goes unnoticed.



How does the technology work?
UVeye’s sophisticated piece of technology solution is based on deep learning and image processing. It uses advanced computer-vision algorithms to provide a detailed visual analysis of a vehicle’s exterior and highlights any areas of concern.
Our advanced algorithm meets the challenge of automating anomaly detection for new and unfamiliar ‘first pass’ vehicles. The technology analyses each vehicle part separately, detecting anomalies within seconds – but crucially without the need to reference a previous scan or undercarriage image provided by a vehicle manufacturer.
This allows us to catch issues not simply because it failed to match an ideal image of what the manufacturer thinks their vehicle is supposed to look like, but because we have trained our algorithm to truly understand what the parts of the vehicle look like under a range of conditions.
Everything from the lighting, moisture levels and other natural conditions can change how an image may appear, thus requiring us to train our deep-learning systems to detect and identify anomalies regardless of the situation in the field.
A key aspect of our technology is our ability to compile the images using an area patching methodology that ensures that no part of the vehicle is missed as it moves speedily through the scanners.
Investment for the future



UVeye co-founders Ohad (left) and Amir Hever


We recently closed our Series B of funding, raising $31m, led by Toyota Tsusho, Volvo Cars, and WR Berkley.
The investment we’ve received from leading automotive strategic partners is an important signal that we believe paves the way for UVeye to become the standard of automotive inspection and safety.
The latest round of funding enables us to continue enhancing our product suite and further expand our international footprint as the emerging global standard for automatic vehicle inspection.



AISensors






",,,,"[{'@type': 'WebPage', '@id': 'https://www.themanufacturer.com/articles/how-artificial-intelligence-is-improving-automotive-manufacturing-standards/', 'url': 'https://www.themanufacturer.com/articles/how-artificial-intelligence-is-improving-automotive-manufacturing-standards/', 'name': 'How artificial intelligence is improving automotive manufacturing standards - The Manufacturer', 'isPartOf': {'@id': 'https://www.themanufacturer.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.themanufacturer.com/articles/how-artificial-intelligence-is-improving-automotive-manufacturing-standards/#primaryimage'}, 'image': {'@id': 'https://www.themanufacturer.com/articles/how-artificial-intelligence-is-improving-automotive-manufacturing-standards/#primaryimage'}, 'thumbnailUrl': 'https://themanufacturer-cdn-1.s3.eu-west-2.amazonaws.com/wp-content/uploads/2019/11/14113222/Untitleood.jpg', 'datePublished': '2019-11-27T07:30:44+00:00', 'dateModified': '2020-03-31T11:28:15+00:00', 'description': 'Amir Hever, CEO of UVeye, recalls the company’s beginnings and explains how artificial intelligence is setting the standard for automotive manufacturing.', 'breadcrumb': {'@id': 'https://www.themanufacturer.com/articles/how-artificial-intelligence-is-improving-automotive-manufacturing-standards/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.themanufacturer.com/articles/how-artificial-intelligence-is-improving-automotive-manufacturing-standards/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.themanufacturer.com/articles/how-artificial-intelligence-is-improving-automotive-manufacturing-standards/#primaryimage', 'url': 'https://themanufacturer-cdn-1.s3.eu-west-2.amazonaws.com/wp-content/uploads/2019/11/14113222/Untitleood.jpg', 'contentUrl': 'https://themanufacturer-cdn-1.s3.eu-west-2.amazonaws.com/wp-content/uploads/2019/11/14113222/Untitleood.jpg', 'width': 1145, 'height': 1035, 'caption': 'Atlas – UVeye’s 360° full-body scanner - image courtesy of UVeye.'}, {'@type': 'BreadcrumbList', '@id': 'https://www.themanufacturer.com/articles/how-artificial-intelligence-is-improving-automotive-manufacturing-standards/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.themanufacturer.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Articles', 'item': 'https://www.themanufacturer.com/articles/'}, {'@type': 'ListItem', 'position': 3, 'name': 'How artificial intelligence is improving automotive manufacturing standards'}]}, {'@type': 'WebSite', '@id': 'https://www.themanufacturer.com/#website', 'url': 'https://www.themanufacturer.com/', 'name': 'The Manufacturer', 'description': 'Manufacturing news, articles and insights', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.themanufacturer.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiS2h0dHBzOi8vZW1lcmouY29tL2FpLXNlY3Rvci1vdmVydmlld3MvYWlybGluZXMtdXNlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,How the 4 Largest Airlines Use Artificial Intelligence - Emerj,2019-11-28,Emerj,https://emerj.com,"Discover how the top four U.S. airlines are using artificial intelligence today, including AI initiatives at Delta, American Airlines, Southwest, and more.",,"Discover how the top four U.S. airlines are using artificial intelligence today, including AI initiatives at Delta, American Airlines, Southwest, and more.",,https://schema.org,Article,https://emerj.com/ai-sector-overviews/airlines-use-artificial-intelligence,How the 4 Largest Airlines Use Artificial Intelligence,https://emerj.com/wp-content/uploads/2018/04/how-the-4-largest-airlines-use-artificial-intelligence-690x285.png,Kumba Sennaar,2017-10-09,2019-11-28,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",,,," Business intelligence and analyticsTransportationCustomer service How the 4 Largest Airlines Use Artificial Intelligence Kumba SennaarLast updated on November 28, 2019  Last updated on November 28, 2019, published by Kumba Sennaar Kumba is an AI Analyst at Emerj, covering financial services and healthcare AI trends. She has performed research through the National Institutes of Health (NIH), is an honors graduate of Rensselaer Polytechnic Institute and a Master’s candidate in Biotechnology at Johns Hopkins University. Share to: LinkedIn Twitter Facebook Email  The U.S. commercial airline system is an economic engine which generated an estimated $168.2 billion in operating revenue in 2016. Ticket fares represented 74.5 percent of operating revenue or $125.2 billion. In 2016, the overall category of transportation represented approximately 2.7 percent of the national GDP. Airline passenger traffic is projected to double over the next two decades. Today, leading airlines are exploring how AI can help them keep pace with customer demand and improve operational efficacy, speed and customer satisfaction. To learn how the top four U.S. airlines are using AI, we researched this sector in depth to help answer questions business leaders are asking today, including: How are industry leaders like American Airlines and Delta Airlines using AI today? What have been the tangible results of these airline AI applications? What are the trends across airline AI applications – and how will they impact the industry’s future? This article aims to present a comprehensive look at how the four leading commercial passenger airlines are using AI. Companies were ranked based on 2016 operation revenue sourced from company financial reports.  Before we begin exploring each company, we’ll present the common patterns that emerged throughout our research in this sector. Artificial Intelligence in the Airline Sector – Insights Up Front The most popular AI applications from the top four industry leaders currently using AI appear to be:  AI Assistants: Responding to customer inquiries and responding to voice commands for domestic airline flight info and ticket availability through interactions using natural language (see American Airlines and United below) Smart Logistics: Machine learning algorithms are being applied to data to help automate airline operations. (see Southwest below). Facial Recognition: Facial recognition technology is being used to perform customer identity verification and to match passengers to their luggage through kiosks (see Delta below, and you may want to read our full “facial recognition use-cases” article here) In the full article below, we’ll explore the AI applications of each airline individually. We will begin with American Airlines, the #1 ranking U.S. commercial airline based on 2016 revenue figures. American Airlines In 2017, the current leading airline focused its annual app development competition, HackWars, on “artificial intelligence, drones and augmented and virtual reality” technologies. HackWars IV, was a 24-hour hack-a-thon that reportedly brought out over 700 “designers, developers and IT” professionals. Participants worked in teams aiming to come up with an idea for an innovative app that would be beneficial for both “customers and employees.” The 1st place team, “Team Avatar,” reportedly designed an app that would allow users to determine the size of their luggage in advance of arriving to airport or at a kiosk before proceeding to the gate. The winning team also claimed that their app would allow users to “prepay for any potential expenses” associated with their luggage.  Most likely in an effort to protect the idea, American Airlines did not show a demonstration of how “Team Avatar’s” application would function in the official video. Based on the three categories of interest in the competition, it is possible that the winning app was developed using AI but this is not confirmed. Emerj Founder Dan Faggella states:  “If anything, ‘HackWars’ is a demonstration of AA’s eagerness to innovate (and to let the press know about it), but it’s symbolic of the current nascent stage of AI: Businesses all know they should be applying AI, but are having a hard time finding where and how. If nothing else, AA seems to at least be making the effort, and we hope to see more traction with the firm over the years ahead.” Delta Airlines In May 2017, Delta announced a reported $600,000 investment in four automated self-service bag checking kiosks, including one that will incorporate facial recognition technology. The airline selected Minneapolis-St. Paul International Airport to debut the four self-service kiosks, and claims that facial recognition technology will be used to verify customer identity by matching customer faces to passport photos.  While Delta Airlines doesn’t seem to have their own YouTube video of the new self-service bag check kiosk, WCCO – CBS Minnesota explained the technology well in a video from earlier this year:  Evidence of the airlines interest in integrating more self-service and automation into its operations is evident in its previous initiatives such as “ticketing kiosks and check-in via the Fly Delta Mobile app”.  “We are dependent on technology initiatives to provide customer service and operational effectiveness in order to compete in the current business environment. For example, we have made and continue to make significant investments in delta.com, mobile device applications, check-in kiosks, customer service applications, airport information displays and related  initiatives, including security for these initiatives. The performance, reliability and security of the technology are critical to our ability to serve customers.” -2017 Annual Report Delta claims that previous innovations mentioned above have helped to streamline customer traffic in airports and have also “drastically improved customer satisfaction scores.” However, the airline does not specifically provide any data pertaining to customer feedback in the press release.  (Readers interested in customer service AI applications may want to read about the innovative AI kiosk ideas that we covered in our fast food AI uses cases article.) Southwest The airline shows limited evidence of AI implementation, but there is some evidence of Southwest using machine learning to improve operations. Jeff Hamlet, former Director of Air Operations Assurance at Southwest Airlines has stated that he and his team used machine learning techniques such as time series analysis and pattern recognition to enhance their data mining capabilities.  Time series analysis refers to a method for evaluating a series of data points that are ordered according to time. This type of analysis is often used to identify trends or patterns. Hamlet claims that these approaches enabled his team to identify potential flight glitches found in pilots’ data reports. These findings were then relayed to air traffic control at the site of arrival. Hamlet concludes that in this reported instance, contributed to the avoidance of an incident. United Airlines In September 2017, United Airlines announced a collaboration with Amazon Alexa called “United skill.” The app reportedly allows Alexa users to find answers to the most common questions about United flights by communicating through natural language. A screen shot from United’s blog post announcing their Alexa skill Once users add “United skill” to their existing Alexa app, they are able to ask Alexa common questions about flight statuses, flight times and amenities. Though United skill, examples of commands that Alexa can process include: “Alexa, ask United: what is the status of flight 959?”  “Alexa, ask United: does flight 869 have Wi-Fi?” “Alexa, ask United to check me in.” However, the app has some limitations. For example, commands must be phrased in a very specific way and information on certain features such as airline check-in are restricted to domestic flights.  Based on reviews published on Amazon’s website, so far, United skill has had a mixed reception. Some complaints include incorrect flight times and routine misunderstanding of crucial elements of vocal commands such as “flight number.”  As the pioneering airline to integrate Alexa functionality, it is expected that there will be a learning curve. It will be interesting to see what improvements Amazon will make over time and if the collaboration will ultimately prove mutually beneficial for both companies. (Readers with a strong interest in Amazon’s conversational interface technology may want to read our full article titled: “Chatbot Comparison – Facebook, Microsoft, Amazon, and Google“.) Concluding Thoughts on AI in Commercial Airline Sector  AI is being explored in the commercial airline segment of the aviation industry and is being integrated across multiple areas including customer service, airport and flight operations. Airport development will be a particular area of importance according to an annual report published by the International Air Transport Association.  The association anticipates that the cost of airport development, specifically improving and modernizing existing infrastructure and operations, will exceed $1 trillion over the next fifteen years. Therefore, innovation will be a critical building block of these efforts. Specifically, AI and self-service airport kiosks and apps should mesh well into this industry outlook. In aviation, the transmission and translation of data is fundamental to market competition and safe flying. Jeff Hamlet former Director of Air Operations Assurance at Southwest Airlines and Ashok N. Srivastava, the project manager for the Aviation Safety Program at NASA posit that efficient data management is achieved through the continued creation of new algorithms.  These algorithms or apps would be tailored to the new problems that are being reported by pilots, the FAA, and others involved in aeronautics space. Policies and procedures that affect the transmission of data are of fundamental importance to the future of machine learning in aeronautics.  Thus, we can anticipate that machine learning algorithms will continue to play an important role in how leading airlines translate their data interpretation into valuable outcomes for their companies.  It is also important to consider the economic impact as it pertains to job growth. As a bustling multi-billion dollar industry, it is anticipated that over the next 20 years we will see widespread and lasting growth in the commercial aviation job market. Global economic expansion has contributed to airlines “expanding their fleets and flight schedules” to satisfy growing consumer demand. In 2016, the aviation industry sustained an estimated 67.7 million supply chain jobs  and produced $3.0 trillion in global value-added output. While the leading commercial passenger airlines are relatively early-adopters of AI, industry projections depict a business environment primed for innovation and automation. We will continue to monitor how AI emerges throughout the industry as we anticipate wider implementation in the coming years.   Header image credit: Infosys Related Posts Applications of Artificial Intelligence in Elderly Care RoboticsThe number of persons aged 60 or above is expected to grow from 962 million… Artificial Intelligence at UBS - Current Applications and InitiativesUBS is a Swiss multinational investment banking and financial services company ranked 30th on S&P… Stock Brokerage Firms and Artificial Intelligence - Current ApplicationsThis article aims to explore the current state of artificial intelligence applications in stock brokerage… Artificial Intelligence for Credit Card Companies - Current ApplicationsCredit card companies could make use of AI applications across multiple business areas. AI-based fraud… Business Intelligence in Retail - Current ApplicationsIn 2017, Emerj conducted research into the applications of machine learning in marketing with 51… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,AI Sector Overviews,1606.0,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LmNuYmMuY29tLzIwMTkvMTEvMjcvaGlnaC1wYWlkLXdlbGwtZWR1Y2F0ZWQtd2hpdGUtY29sbGFyLWpvYnMtaGVhdmlseS1hZmZlY3RlZC1ieS1haS1uZXctcmVwb3J0Lmh0bWzSAXRodHRwczovL3d3dy5jbmJjLmNvbS9hbXAvMjAxOS8xMS8yNy9oaWdoLXBhaWQtd2VsbC1lZHVjYXRlZC13aGl0ZS1jb2xsYXItam9icy1oZWF2aWx5LWFmZmVjdGVkLWJ5LWFpLW5ldy1yZXBvcnQuaHRtbA?oc=5,"High-paid, well-educated white collar workers will be heavily affected by AI, says new report - CNBC",2019-11-27,CNBC,https://www.cnbc.com,"Service jobs aren't the only ones that could be disrupted in the face of artificial intelligence, a new report finds.","['makeit', 'Articles', 'Stanford University', 'GEE Group Inc', 'Hiring and recruitment', 'Technology', 'Artificial intelligence', 'Careers', 'NVIDIA Corp', 'Make It', 'Make It - Get Ahead', 'Make It - Work', 'source:tagname:CNBC US Source']","Service jobs aren't the only ones that could be disrupted in the face of artificial intelligence, a new report finds.","Service jobs aren't the only ones that could be disrupted in the face of artificial intelligence, a new report finds.",https://schema.org,NewsArticle,https://www.cnbc.com/2019/11/27/high-paid-well-educated-white-collar-jobs-heavily-affected-by-ai-new-report.html,"High-paid, well-educated white collar workers will be heavily affected by AI, says new report","{'@type': 'ImageObject', 'url': 'https://image.cnbcfm.com/api/v1/image/106259573-1574377450550gettyimages-104821104.jpg?v=1574377498', 'width': 2000, 'height': 1333}","[{'@type': 'Person', 'name': 'Jennifer Liu', 'url': 'https://www.cnbc.com/jennifer-liu/'}]",2019-11-27T15:39:49+0000,2019-11-27T16:31:57+0000,"{'@type': 'NewsMediaOrganization', 'name': 'CNBC', 'url': 'https://www.cnbc.com/', 'foundingDate': '1989-04-17', 'logo': {'@type': 'ImageObject', 'url': 'https://sc.cnbcfm.com/applications/cnbc.com/staticcontent/img/cnbc-hdr-logo2.png', 'width': 378, 'height': 98}, 'sameAs': ['https://www.facebook.com/CNBCMakeIt', 'https://www.twitter.com/CNBCMakeit', 'https://www.linkedin.com/showcase/cnbc-make-it']}",,Make It - Work,,,,https://image.cnbcfm.com/api/v1/image/106259573-1574377450550gettyimages-104821104.jpg?v=1574377498&w=720&h=405,Make It,,https://www.cnbc.com/2019/11/27/high-paid-well-educated-white-collar-jobs-heavily-affected-by-ai-new-report.html,,,,,,"{'@type': 'VideoObject', 'contentUrl': 'http://pdl.iphone.cnbc.com/VCPS/Y2019/M11D21/7000109867/1574346624568-MakeIt_191121_MM_Graham_JF_L.mp4', 'description': ""Graham Stephan, 29, lives in Los Angeles, California, and earns $1.6 million a year as a real estate agent, real estate investor and YouTuber. This is an installment of CNBC Make It's Millennial Money series, which profiles people around the world and details how they earn, spend and save their money."", 'duration': 'PT10M10S', 'name': 'How a 29-year-old YouTube millionaire in Los Angeles spends his money', 'thumbnailUrl': 'https://image.cnbcfm.com/api/v1/image/106258613-mm_graham_carbon_02.jpg?v=1574348648', 'uploadDate': '2019-11-20T22:55:47+0000'}",,2019-11-27T15:39:49+0000,,,,,,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', '/html/head/meta[@name=""description""]/@content'], 'cssSelector': ['.group p']}",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvd29ybGQvYWdlbnRzLWZvci1jaGFuZ2Uvd2h5LXRoZXNlLWNvbXBhbmllcy1hcmUtcmV0aGlua2luZy10aGUtdXNlLW9mLWFpLWluLWhpcmluZ9IBc2h0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvYW1wL3dvcmxkL2FnZW50cy1mb3ItY2hhbmdlL3doeS10aGVzZS1jb21wYW5pZXMtYXJlLXJldGhpbmtpbmctdGhlLXVzZS1vZi1haS1pbi1oaXJpbmc?oc=5,Why these companies are rethinking the use of AI in hiring - PBS NewsHour,2019-11-26,PBS NewsHour,https://www.pbs.org,"A growing body of research indicates that artificial intelligence systems used for job recruitment reinforce racial and gender inequality. Now, innovators are developing software that promises more accountability, and combats — rather than perpetuates — employment discrimination.",,"A growing body of research indicates that artificial intelligence systems used for job recruitment reinforce racial and gender inequality. Now, innovators are developing software that promises more accountability, and combats — rather than perpetuates — employment discrimination.","A growing body of research indicates that artificial intelligence systems used for job recruitment reinforce racial and gender inequality. Now, innovators are developing software that promises more accountability, and combats — rather than perpetuates — employment discrimination.",,,,,,,,,,,Agents for Change,,"






Full Episode










Monday, Jul 15


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMijQFodHRwczovL3d3dy5zbWl0aHNvbmlhbm1hZy5jb20vc21hcnQtbmV3cy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yZXZlYWxzLXNlY29uZC1wbGF5d3JpZ2h0cy1jb250cmlidXRpb25zLXNoYWtlc3BlYXJlcy1oZW5yeS12aWlpLTE4MDk3MzY2NC_SAQA?oc=5,Artificial Intelligence Reveals Second Playwright's Contributions to Shakespeare's 'Henry VIII' - Smithsonian Magazine,2019-11-27,Smithsonian Magazine,https://www.smithsonianmag.com,"Scholars have long suspected the play, written in 1613, was a collaborative effort. Now, an algorithm has mapped out who wrote what","['Smart News', 'Artificial Intelligence', 'British History', 'British Writers', 'England', 'Literature', 'London', 'Renaissance', 'Theater', 'William Shakespeare', 'Smart News Science', 'Smart News Ideas & Innovations', 'Smart News History & Archaeology', 'Smart News Arts & Culture']","Scholars have long suspected the play, written in 1613, was a collaborative effort. Now, an algorithm has mapped out who wrote what","Scholars have long suspected the play, written in 1613, was a collaborative effort. Now, an algorithm has mapped out who wrote what",https://schema.org,NewsArticle,https://www.smithsonianmag.com/smart-news/artificial-intelligence-reveals-second-playwrights-contributions-shakespeares-henry-viii-180973664/,Artificial Intelligence Reveals Second Playwright’s Contributions to Shakespeare’s &#x27;Henry VIII&#x27;,"['https://th-thumbnailer.cdn-si-edu.com/foOu7H24IF1zy9lm2G79xWVr76c=/800x800/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer/73/f5/73f5f982-5eba-45bd-a9d0-eacb54b9f7cd/untitled-1.jpg', 'https://th-thumbnailer.cdn-si-edu.com/k_Ch38hD_r-MvV9TkEfENfmmicU=/800x600/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer/73/f5/73f5f982-5eba-45bd-a9d0-eacb54b9f7cd/untitled-1.jpg', 'https://th-thumbnailer.cdn-si-edu.com/iOhvJqEPbjTJjl8rQOfPlpDIqAE=/800x450/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer/73/f5/73f5f982-5eba-45bd-a9d0-eacb54b9f7cd/untitled-1.jpg']","[{'@type': 'Person', 'name': 'Theresa Machemer', 'url': 'https://www.smithsonianmag.com/author/theresa-machemer/'}]",2019-11-27T13:30:11-05:00,2019-11-27T13:22:16-05:00,"{'@type': 'Organization', 'name': 'Smithsonian Magazine', 'logo': {'@type': 'ImageObject', 'url': 'https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/4e/c9/4ec98b8b-b9d1-4086-858b-84984e84d164/576x164_smithsonianmagazine_logo.png', 'width': 576, 'height': 164}}",,"Smart News, Smart News Science, , Smart News Ideas & Innovations, , Smart News History & Archaeology, , Smart News Arts & Culture",,"



SMART NEWS


Artificial Intelligence Reveals Second Playwright’s Contributions to Shakespeare’s ‘Henry VIII’
Scholars have long suspected the play, written in 1613, was a collaborative effort. Now, an algorithm has mapped out who wrote what




Theresa Machemer

Correspondent
November 27, 2019










              
                William Shakespeare (left) and John Fletcher (right) both contributed to Henry VIII, a new study suggests.
              Public domain



In the summer of 1613, an early performance of William Shakespeare’s Henry VIII—then titled All is True—found the Globe Theater packed with spectators. Cannon fire sounded as the play’s eponymous monarch walked onstage toward the end of the first act, captivating audience members to such an extent that they failed to notice a fiery prop landing on the theater’s thatched roof. Within an hour, the Globe had been reduced to ash.
New research suggests Shakespeare didn’t pen the history play-turned-tragedy by himself. Since literary analyst James Spedding first raised the possibility in 1850, scholars have speculated that Henry VIII was actually a collaboration between the Bard and John Fletcher, who succeeded Shakespeare as house playwright of the King’s Men acting company. Now, an algorithm created by Petr Plecháč of Prague’s Czech Academy of Sciences has revealed that the inflammatory cannon scene—and roughly half of the play—were likely written by Fletcher. Plecháč’s findings are published in the pre-print server arXiv.
Powered By                         10 Sec      The Untold Secrets of King Tut’s Tomb         NextStaySkip Ad    


“The scenes that are written by Fletcher are creaky,” Grace Ioppolo, a Shakespearean scholar at the University of Reading, told BBC News’ Tim Masters in 2015, when the rebuilt Globe Theater was preparing to host the play once again. “You can see in some scenes it doesn't have that Shakespearean touch that we are used to.""
Researchers have used machine learning to identify distinguishing differences in authors’ voices before, according to a press release. Plecháč trained an algorithm to recognize Shakespeare’s and Fletcher’s writing styles by feeding it four of each playwright’s individual works. The algorithm learned to distinguish differences in the duo’s rhythm and word choice, and was then put to the task of combing through Henry VIII line-by-line.



    
      Shakespearean qualities appear above the mid-line in purple, while qualities associated with Fletcher show up below the line in green.
    
    
      Petr Plecháč


“This turned out to be a very reliable discriminator for both authors’ styles. When applied to the text of Henry VIII, the result clearly indicated that both authors were involved,” Plecháč tells the Guardian’s Alison Flood.
As Flood notes, the algorithm even ruled out another speculated collaborator: playwright Philip Massinger.
The new study visualizes the algorithm’s analysis as a purple and green graph. Shakespearean qualities appear above the mid-line in purple, and qualities associated with Fletcher show up below the line in green. Instead of limiting the assessment to an either-or distinction, the algorithm accounts for such factors as transitions and truly collaborative sections.
Per the paper, Shakespeare probably wrote the play’s first two scenes, while Fletcher took the next four. But starting at line 2081, the algorithm found that the playwrights shared writing duties—at least until line 2200, when the Bard’s voice returns to prominence.
This analysis provides granular evidence for co-authorship, but as Spedding noted in 1850, a gut feeling and close reading can also reveal shifts in style.
“There are certain scenes when you suddenly think ‘this is Shakespeare’—the writing is richer,” Mark Rosenblatt, director of the 2015 production, told BBC News at the time. “You feel you are in the hands of a truly great writer as opposed to a very fine writer.”




Get the latest stories in your inbox every weekday.










Theresa Machemer
| READ MORE

Theresa Machemer is a freelance writer based in Washington DC. Her work has also appeared in National Geographic and SciShow. Website: tkmach.com





Filed Under:
                
                  
                    Artificial Intelligence, 
                  
                
                  
                    British History, 
                  
                
                  
                    British Writers, 
                  
                
                  
                    England, 
                  
                
                  
                    Literature, 
                  
                
                  
                    London, 
                  
                
                  
                    Renaissance, 
                  
                
                  
                    Theater, 
                  
                
                  
                    William Shakespeare







Report this ad

Most Popular





Meet Vivian Maier, the Reclusive Nanny Who Secretly Became One of the Best Street Photographers of the 20th Century





Melting Ice Reveals Body of American Mountaineer Missing for 22 Years in the Peruvian Andes





Nine Things You Didn't Know About the Ancient Olympic Games





How the Rise of the Camera Launched a Fight to Protect Gilded Age Americans' Privacy





Ancient DNA Unravels the Mysteries of the Dingo, Australia's Wild Dog





Report this ad

",,https://th-thumbnailer.cdn-si-edu.com/emndxGsREPO8b5GUgaaCyeRJJl0=/1072x720/filters:no_upscale()/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer/73/f5/73f5f982-5eba-45bd-a9d0-eacb54b9f7cd/untitled-1.jpg,Smart News,,https://www.smithsonianmag.com/smart-news/artificial-intelligence-reveals-second-playwrights-contributions-shakespeares-henry-viii-180973664/,,,,,,,,,,,,,,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LnpkbmV0LmNvbS9hcnRpY2xlL2FpLWluLWhlYWx0aGNhcmUtdXNpbmctYWxnb3JpdGhtcy10by1wcmVkaWN0LXlvdXItcmlzay1vZi1lbmRpbmctdXAtaW4taG9zcGl0YWwv0gEA?oc=5,This algorithm can predict your risk of ending up in hospital - ZDNet,2019-11-26,ZDNet,https://www.zdnet.com,It can be hard to focus on future tech if you're struggling to keep the basic IT necessities in place. Here's how CIOs in the NHS are delivering infrastructure while also starting to think about life-changing innovations.,,Artificial intelligence in healthcare might be at a nascent stage of development but one NHS trial shows how the application of emerging technology could have a positive impact on patient care.,Artificial intelligence in healthcare might be at a nascent stage of development but one NHS trial shows how the application of emerging technology could have a positive impact on patient care.,https://schema.org,VideoObject,,,,,,,,,,,,How healthcare CIOs are winning the battle for funding,https://www.zdnet.com/a/img/resize/064b260fa3ee5918fe88aa1bc3a6aea468ff3682/2019/11/18/2f4a1489-3d31-42e4-9b0f-eb8957393207/how-healthcare-cios-are-winning-the-batt-5dd264bc125506000122f54b-1-nov-18-2019-11-58-50-poster.jpg?auto=webp&fit=crop&height=675&width=1200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-11-18T12:34:36.000Z,PT0H1M9S,https://mt-rv-v5.zdnet.com/vr/2019/11/18/1643885635554/2019-11-18-wochit-how-healthcare-cios-are-winning-the-battle-for-funding_1979176_742.mp4,https://www.zdnet.com/video/share/how-healthcare-cios-are-winning-the-battle-for-funding/,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiiwFodHRwczovL3d3dy53YXNoaW5ndG9ucG9zdC5jb20vdGVjaG5vbG9neS8yMDE5LzExLzI2L2Jvc3Rvbi1keW5hbWljcy10ZXJyaWZ5aW5nLXJvYm90aWMtZG9ncy1oYXZlLWJlZW4tcHV0LXdvcmstYnktbGVhc3Qtb25lLXBvbGljZS1hZ2VuY3kv0gEA?oc=5,Boston Dynamics' 'terrifying' robotic dogs have been put to work by at least one police agency - The Washington Post,2019-11-26,The Washington Post,https://www.washingtonpost.com,Boston Dynamics began began leasing their robotic dogs to the public this year. One of their first customers: The Massachusetts State Police.,"boston dynamics, law enforcement, privacy, aclu, robots, robot dog, spot, massachusettes",Boston Dynamics began began leasing their robotic dogs to the public this year. One of their first customers: The Massachusetts State Police.,Boston Dynamics began began leasing their robotic dogs to the public this year. One of their first customers: The Massachusetts State Police.,https://schema.org,BreadcrumbList,https://www.washingtonpost.com/technology/2019/11/26/boston-dynamics-terrifying-robotic-dogs-have-been-put-work-by-least-one-police-agency/,Boston Dynamics’ ‘terrifying’ robotic dogs have been put to work by at least one police agency ,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/QTJE3HXAUAI6TPT7JTEFAF6DN4.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/QTJE3HXAUAI6TPT7JTEFAF6DN4.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/QTJE3HXAUAI6TPT7JTEFAF6DN4.jpg&w=800&h=600', 'height': 800, 'width': 600}]","{'@type': 'Person', 'name': 'Peter Holley', 'url': 'https://www.washingtonpost.com/people/peter-holley/'}",2019-11-26T22:43:42.108Z,2019-11-27T15:45:17.605Z,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}","[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}, {'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Artificial Intelligence', 'position': 2, 'item': 'https://www.washingtonpost.com/technology/innovations/'}]",Artificial Intelligence,,"A Boston Dynamics robotic dog has been used by a police force in at least two operations. (Charles Krupa/AP)By  Peter HolleyNovember 26, 2019 at 5:43 p.m. ESTSeveral years ago, when Boston Dynamics began releasing videos of Spot, a sturdy, semiautonomous four-legged robot, the public was captivated.In the videos, the nimble doglike robot was seen climbing up and down stairs, dancing to Bruno Mars, hauling a large truck and even opening a door with ease, offering a futuristic glimpse of robotic potential that many online observers found shocking.Share228 CommentsNewsletterAs news breaksTech News AlertsBreaking news email alerts on technology and the tech industry.Sign up



PAID PROMOTED STORIES
 







Subscribe to comment and get the full experience. Choose your plan →",,,,,,,,,,,,,,,,,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihAFodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9hbmFseXRpY3MtaW5zaWdodC1yZWNvZ25pemVzLXRvcC0xMDAtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY29tcGFuaWVzLTIwMTnSAY4BaHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2FuYWx5dGljcy1pbnNpZ2h0LXJlY29nbml6ZXMtdG9wLTEwMC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jb21wYW5pZXMtMjAxOQ?oc=5,Analytics Insight Recognizes ‘Top 100 Artificial Intelligence Companies of 2019’ - Analytics Insight,2019-11-26,Analytics Insight,https://www.analyticsinsight.net,,"Analytics Insight,Analytics Insight Top 100,Top 100 Artificial Intelligence Companies,Artificial Intelligence,Top Artificial Intelligence","Analytics Insight Magazine, a brand of Stravium Intelligence has named &quot;Top 100 Artificial Intelligence Companies of 2019&quot;. The publication recognizes","Analytics Insight Magazine, a brand of Stravium Intelligence has named &quot;Top 100 Artificial Intelligence Companies of 2019&quot;. The publication recognizes",http://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/analytics-insight-recognizes-top-100-artificial-intelligence-companies-2019'}",Analytics Insight Recognizes ‘Top 100 Artificial Intelligence Companies of 2019’,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2019/11/AI-Top-100-Rectangle.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Market Trends', 'name': 'Market Trends', 'url': 'https://www.analyticsinsight.net/author/market-trends'}]",2019-11-26T04:50:19Z,2019-11-26T04:50:19Z,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.linkedin.com/company/analytics-insight/', 'https://www.facebook.com/analyticsinsight.net', 'https://twitter.com/analyticsinme', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/'], 'id': 'https://www.analyticsinsight.net'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Analytics Insight Recognizes ‘Top 100 Artificial Intelligence Companies of 2019’', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/analytics-insight-recognizes-top-100-artificial-intelligence-companies-2019'}]",,,"Ready for iOS 18? Here's How to Install the Public Beta
",Analytics Insight Recognizes ‘Top 100 Artificial Intelligence Companies of 2019’,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2019/11/AI-Top-100-Rectangle.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,Artificial Intelligence,,https://www.analyticsinsight.net/artificial-intelligence/analytics-insight-recognizes-top-100-artificial-intelligence-companies-2019,,,,,,,,2019-11-26T04:50:19Z,,,,,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/analytics-insight-recognizes-top-100-artificial-intelligence-companies-2019', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2019/11/AI-Top-100-Rectangle.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,"Analytics Insight Magazine, a brand of Stravium Intelligence has named &quot;Top 100 Artificial Intelligence Companies of 2019&quot;..The publication recognizes Top 100 Artificial Intelligence Companies leveraging their efficiency to reduce human efforts and introducing innovation across various sectors. The enlisted companies are flourishing across many businesses with varied deployment while showcasing how their technology provides new business opportunities to companies and individuals. Here are the companies who made it to the list: link.Artificial Intelligence and its subsets including Machine Learning, Deep Learning, Computer Vision and others are undoubtedly driving new-wave of innovation across different business operations in current times. With a consistent increase in employee count, the companies are creating effective employment and job opportunities in various parts of the world..The enlisted companies are influencing the ravishing trends across major industries while empowering the skills of face recognition, autonomous technology, business acceleration, among certain others. Among all the 100 companies nearly 21% of companies are using image/facial recognition along with computer vision technology, while around 9% of them employ autonomous vehicle driving technology..Where almost every country around the globe is betting big on AI while driving futuristic opportunities for the next-gen workforce, the report reveals that 84% of the AI companies are situated in North America, 9% of companies are situated in European region, 4% of companies are situated in Asia-Pacific and only 3% are located in Middle-East and Africa (MEA)..Additionally, every industry has a high demand for AI capabilities, be it for question answering systems or legal assistance, patent searches or risk notification. Some of the significant sectors incorporating artificial intelligence are – healthcare, manufacturing, retail, banking, and significant others..As it stands now, the technology has been breaking records and catering to new industries and sectors with skyrocketing adoption rates. As of 2019, Enterprise AI has the highest number of companies (26%) working with AI whereas automotive sector is second in the lead with 16% of companies employing this technology. Hitting the lowest adoption rate among all, only 2% of the AI companies belong to the Semiconductor sector..With remarkable traits, the AI companies are subject to heavy funding and investments to establish their product abundance in the market. More and more hefty investments and monetary circulation can be noticed today at the emerging frontier of artificial intelligence. However, among the enlisted 100 companies, only 4% of them receive funding in billions of dollars accounting for some great work in the field of AI research, development, and advancements. Moreover, the third quarter of 2019 witnessed a record of US$13.5 billion invested in AI start-ups in the US alone..Eventually, tools and solutions deployed, the sector in which they operate, quantity and quality of workforce they shelter and their ever-expanding boundaries are some key factors that determine the progress and prosperity of AI-empowered companies. While thriving along with their respective innovations, the enlisted companies transforming the market which undoubtedly influences the industry verticals and fortifies the frontier of technological advancements..The future roadmap of the tech-savvy world majorly relies on the revolutionized offerings of such companies that drive the league of digital transformation across various industries. Such prevailing advents of AI-power companies and their innovative offerings have obliged us to present with the research recognizing the Top 100 Artificial Intelligence Companies of 2019 who are ready to hustle with eminence in the coming years..For more information, please visit https://www.analyticsinsight.net.About Analytics Insight®.Analytics Insight is an influential platform dedicated to insights, trends, and opinion from the world of data-driven technologies. It monitors developments, recognition, and achievements made by AI, big data and analytics companies across the globe. The Analytics Insight Magazine features opinions and views from top leaders and executives in the industry who share their journey, experiences, success stories, and knowledge to grow profitable businesses..To set up an interview or advertise your brand, contact info@analyticsinsight.net..Contacts:.Ashish Sukhadeve.Founder &amp; CEO.Email: ashishsukhadeve@analyticsinsight.net.Tel: +91-40-23055215.Media:.Email: press@analyticsinsight.net.Tel: +1-408-380-2566.Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3LmV4cHJlc3Njb21wdXRlci5pbi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1haS81LW1vbm90b25vdXMtdGFza3MtYWktd2lsbC1oZWxwLXlvdXItb3JnYW5pc2F0aW9uLXdpdGgvNDM5NDYv0gF7aHR0cHM6Ly93d3cuZXhwcmVzc2NvbXB1dGVyLmluL2FtcC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1haS81LW1vbm90b25vdXMtdGFza3MtYWktd2lsbC1oZWxwLXlvdXItb3JnYW5pc2F0aW9uLXdpdGgvNDM5NDYv?oc=5,5 Monotonous Tasks AI Will Help Your Organisation With - Express Computer,2019-11-27,Express Computer,https://www.expresscomputer.in,Human beings have an innate need for being productive. There are times when regular tasks can become repetitive and boring if not done quickly or differently. The popular phrase “working like a robot” holds extremely true in the case of AI. Maybe not,,Replacing certain tasks with AI can benefit people and organizations as it ensures accurate data analysis with no trace of human error.,,http://schema.org/,BlogPosting,https://www.expresscomputer.in/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/,5 Monotonous Tasks AI Will Help Your Organisation With,https://cdn1.expresscomputer.in/wp-content/uploads/2019/11/27142050/New-Project.jpg,"{'@type': 'Person', '@id': '#person-RadhikaUdas', 'name': 'Radhika Udas'}",2019-11-27,2019-11-27,{'@id': '#organization'},,,,"


5 Monotonous Tasks AI Will Help Your Organisation With
Exploring ways in which AI can make our regular lives easier by taking over our mundane tasks.  
Artificial Intelligence AINews

By Radhika Udas 
On Nov 27, 2019



 




 1 1,733 


 Share

 

Human beings have an innate need for being productive. There are times when regular tasks can become repetitive and boring if not done quickly or differently. The popular phrase “working like a robot” holds extremely true in the case of AI. Maybe not as negative for an actual robot, but AI is at a stage where it can be used for dangerous or repetitive tasks. 
Using AI can benefit people and organizations by getting accurate data analysis with no trace of human error. As AI development increases multifold, the future can be quite ‘exciting’ with AI taking over monotonous tasks for you. 
5 Monotonous Tasks AI Will Take Over For You:
1. AI becomes a Voice, Chat Assistant
The transition from producer oriented to customer-oriented businesses has created a whole new dynamic for AI. There is a reason this is the first point. AI has already become a personal assistant for people. Reliance on Amazon’s Alexa or iPhone Siri is proof enough to say that AI has seeped into our lives tremendously. Millennials are doing 50% of their online searches via Voice Search and most enterprises can capitalize on this. 
IBM has developed a voice integration tool that responds to queries related to reports using Voice. This way an enterprise can capitalize on integrating well with Voice assistants that a consumer is getting used to. 
Sephora, personal care products company, uses a colour matching chatbot where the user can upload a picture of celebrity lipstick colour and the bot finds the exact one for them. 
Online fashion stores remembering your preferences and suggesting new ones to you are also great examples of how AI assistant can be used by an enterprise. 
2. AI helps in Managing Data
For sectors that require a lot of data processing, storing and reviving, AI comes to the rescue.  Manually managing data can become highly strenuous and result in more human errors for complex processing. When you automate these processes with AI, it gives the employees more time to reflect on their strategies and think creatively. 
For example, a marketing firm can find good suggestions for content topics, categorize products and help with search engines. The hours spent on managing these aspects of marketing can be freed with AI taking over. This will leave them with abundant time to work on their creative processes and map out a strategy. 
Another example would be that of the Agriculture sector. AI-based machinery could help bring in more efficiency in crop production and help farmers reduce wastage. Farmers can find more time in finding the right market and selling crops there. Since AI also would be great for weather predictions and farming suggestions based on data acquired, the latter be able to make informed decisions. 
3. AI does your Office Work
How many times have you asked yourself “Is there an easy or quick way to do this?” It’s not just you. Even scientists and researchers have been trying to make products that answer your question. A growing discussion of AI’s use cases proves that it has more than one benefit, and now, even for the usual office work!
AI applications could be useful for repetitive administrative work which just requires checking calendars and inviting for meetings. It could also help in hiring and training of employees by providing suggestions for job descriptions and help trainees conduct regular tasks more effectively. Along with this, AI can help strengthen security by preventing malware attacks. 
An employee can spend more time on their work and productivity and automate repetitive tasks with the help of AI.
4. AI predictions used for Customer Experience
Augmented AI is a fairly new and broad topic but holds relevance in our discussion. Don’t we love it when people remember the smallest details about us and are able to predict what we will enjoy? Just like your best friend, AI also has the same powers. 
Your Netflix suggestions, shopping preferences, spam filters, car ride information, phone customization, etc, are all examples of AI filtering content based on how you like to consume it. Over time, AI notices your behaviour towards certain things and by storing data analyses your likes/dislikes. 
So, when you receive messages from a shopping app saying “We know you’ve been eyeing this, it’s available at half price now,” it’s actually AI understanding you. When you begin to text, the predictions are provided based on observing how you have been texting all through this while. 
On the producer front, AI can help them record customer data and preferences easily and optimize their strategies based on data provided. 
The integration of AI in your apps and regular habits helps you do things at a faster pace. While some argue this is giving AI too much control, there is an option of limiting AI’s access to your data as well. 
5. AI makes you self-sufficient 
Waiting to receive information to go ahead with your regular activities can be quite frustrating. For example, you have Google Maps telling you how much time you’ll take to reach home and which route should you opt for. You don’t have to constantly keep track of what the status of traffic will be at that particular time. If you are in a foreign country, you can easily translate your words and converse with people there. If you wish to teach yourself something, AI could come with great suggestions for your reference. You can learn a language or a new recipe, anything that you don’t want to depend on someone else for. 
In conclusion…
What once was believed to be imagination, now becomes reality. We are already living a world with AI which worked thoroughly in being of use to human beings. There are a lot of ways in which AI can help humans reach their potential and be self-reliant. All you need to know to use AI is – ask the right questions. 


 


AIAI AssistantAI at WorkAI Chatbotcustomer experienceData Innovation 


 1 1,733 


 Share

 
",Express Computer,,,"[{'@type': 'WebPage', '@id': 'https://www.expresscomputer.in/amp/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/', 'url': 'https://www.expresscomputer.in/amp/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/', 'name': '5 Monotonous Tasks AI Will Help Your Organisation With - Express Computer', 'isPartOf': {'@id': 'https://www.expresscomputer.in/#website'}, 'primaryImageOfPage': {'@id': 'https://www.expresscomputer.in/amp/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/#primaryimage'}, 'image': {'@id': 'https://www.expresscomputer.in/amp/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/#primaryimage'}, 'thumbnailUrl': 'https://cdn1.expresscomputer.in/wp-content/uploads/2019/11/27142050/New-Project.jpg', 'datePublished': '2019-11-27T08:58:49+00:00', 'dateModified': '2019-11-27T08:58:49+00:00', 'author': {'@id': 'https://www.expresscomputer.in/#/schema/person/8d827e50c670bb04fd58182b23c994b1'}, 'description': 'Replacing certain tasks with AI can benefit people and organizations as it ensures accurate data analysis with no trace of human error.', 'breadcrumb': {'@id': 'https://www.expresscomputer.in/amp/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.expresscomputer.in/amp/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.expresscomputer.in/amp/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/#primaryimage', 'url': 'https://cdn1.expresscomputer.in/wp-content/uploads/2019/11/27142050/New-Project.jpg', 'contentUrl': 'https://cdn1.expresscomputer.in/wp-content/uploads/2019/11/27142050/New-Project.jpg', 'width': 750, 'height': 430, 'caption': 'AI tasks'}, {'@type': 'BreadcrumbList', '@id': 'https://www.expresscomputer.in/amp/artificial-intelligence-ai/5-monotonous-tasks-ai-will-help-your-organisation-with/43946/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.expresscomputer.in/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence AI', 'item': 'https://www.expresscomputer.in/category/artificial-intelligence-ai/'}, {'@type': 'ListItem', 'position': 3, 'name': '5 Monotonous Tasks AI Will Help Your Organisation With'}]}, {'@type': 'WebSite', '@id': 'https://www.expresscomputer.in/#website', 'url': 'https://www.expresscomputer.in/', 'name': 'Express Computer', 'description': 'Digital Magazine, Latest Computer Magazine, India', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.expresscomputer.in/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.expresscomputer.in/#/schema/person/8d827e50c670bb04fd58182b23c994b1', 'name': 'Radhika Udas', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.expresscomputer.in/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/9b74d1bc3cf23bee97b3743bfd628e5f?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/9b74d1bc3cf23bee97b3743bfd628e5f?s=96&d=mm&r=g', 'caption': 'Radhika Udas'}, 'description': 'Radhika Udas is a Correspondent with Express Computer. She reports and analyses news from the IT-sphere. You can reach her at radhika.udas@indianexpress.com', 'url': 'https://www.expresscomputer.in/author/radhika-udas/'}]",https://www.expresscomputer.in/,,"{'@type': 'ImageObject', 'url': 'https://cdn1.expresscomputer.in/wp-content/uploads/2021/07/26171226/standard-250px.webp'}",,#organization,,,,,,,,,,,,,,,,,,,,,,,,,,"Digital Magazine, Latest Computer Magazine, India",,,,,,,,"[{'@type': 'InteractionCounter', 'interactionType': 'http://schema.org/CommentAction', 'userInteractionCount': '1'}]",,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvY29nbml0aXZld29ybGQvMjAxOS8xMS8yNC9pcy1haS1hLWpvYi1raWxsZXItb3Itam9iLWNyZWF0b3Iv0gEA?oc=5,Is AI A Job Killer Or Job Creator? - Forbes,2019-11-24,Forbes,https://www.forbes.com,"AI brings mixed emotions and opinions when referenced in the context of jobs. AI will eliminate the need for many different kinds of jobs in many different categories. But at the same time, AI will create new jobs in many categories. Is AI an overall job killer or job creator? ","ai,artificial intelligence,ML,machine learning,job,job creator,jobs","AI brings mixed emotions and opinions when referenced in the context of jobs. AI will eliminate the need for many different kinds of jobs in many different categories. But at the same time, AI will create new jobs in many categories. Is AI an overall job killer or job creator? ","AI brings mixed emotions and opinions when referenced in the context of jobs. AI will eliminate the need for many different kinds of jobs in many different categories. But at the same time, AI will create new jobs in many categories. Is AI an overall job killer or job creator? ",http://schema.org,BreadcrumbList,,Is AI A Job Killer Or Job Creator?,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5dd9bb64e0af7b0006b225bf/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Kathleen Walch', 'url': 'https://www.forbes.com/sites/kathleenwalch/', 'description': ""Kathleen is managing partner and founder of Cognilytica. She co-developed the firm's Cognitive Project Management for AI (CPMAI) methodology in use by Fortune 1000 firms and government agencies worldwide to effectively run and manage their AI and advanced data projects. CPMAI+E certified, Kathleen is a lead instructor on CPMAI courses and training. Her experience as a data-focused analyst with a background in marketing along with her expertise in project management issues around organizational adoption of data led to the development of the CPMAI methodology. Learn more about the methodology at cognilytica.com/cpmai. A dynamic presenter, researcher and thought leader on emerging technology best practices, Kathleen is a frequent speaker and keynoter at industry events. She helped launch the AI-focused working group at ATARC and serves as the AI working group chair, helping organizations and government agencies apply AI best practices. Kathleen was selected to join OECD's ONE AI and Expert Group on AI risk and accountability in 2019 at the OECD ONE group launch. Kathleen is also a co-host of Cognilytica's AI Today podcast, a regular Forbes contributor, a contributor to TechTarget Editorial's Enterprise AI site and an SXSW Innovation Awards judge. Prior to her work at Cognilytica, Kathleen founded tech startup HourlyBee, an online scheduling system for home services, where she quickly became an expert in grassroots marketing, networking and employee management. Before that, Kathleen was a key part of the direct marketing operation for Harte Hanks, managing large-scale direct mail campaigns for marquee clients. Kathleen received a degree in marketing from Loyola University."", 'sameAs': ['https://www.linkedin.com/in/kathleen-walch-50185112/', 'https://www.twitter.com/kath0134', 'https://www.cognilytica.com/']}",2019-11-24T01:00:00-05:00,2019-12-02T09:38:25-05:00,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI,,"More From ForbesJul 16, 2024,09:30am EDTIn Superconvergence, Jamie Metzl Unravels AI MysteriesJul 15, 2024,09:30pm EDTAnswering Your Most Frequently Asked Questions (FAQs) About Artificial Intelligence In Honor Of National AI Appreciation DayJul 15, 2024,06:06pm EDTNot Just A Maker Space: Fab Labs Spark Innovation WorldwideJul 15, 2024,02:57pm EDTIBM InstructLab And Granite Models Revolutionizing LLM TrainingJul 15, 2024,09:42am EDTHow Generative AI Is Driving HyperpersonalizationJul 15, 2024,08:00am EDTThe Clever ‘Rephrase And Respond’ Prompting Strategy Provides Big Payoffs For Prompt EngineeringJul 13, 2024,09:00am EDTBig Tech Involvement With OpenAI Sparks Unease Among RegulatorsEdit StoryForbesInnovationAIIs AI A Job Killer Or Job Creator?Kathleen WalchContributorCOGNITIVE WORLDContributor GroupOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 24, 2019,01:00am ESTUpdated Dec 2, 2019, 09:38am ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinAI brings mixed emotions and opinions when referenced in the context of jobs.  If you ask the question “Do you think Artificial Intelligence will be a net job killer or net job creator?” to colleagues, friends, or strangers you’re bound to get some very strong opinions on this subject. For sure you will hear an interesting and conflicting set of opinions that range from “AI will destroy all jobs as we know it” to “AI will enable us to work better and do new things we’ve never been able to do”. If you look at various economic and analyst predictions, their assessments are all over the place, ranging from dramatic job losses across most economic sectors to large increases in employment due to dramatic increases in job productivity. Of course, as with everything, the true answer will be somewhere in the middle. There’s no doubt that AI will eliminate the need for many different kinds of jobs in many different categories. But at the same time, AI will create new jobs in categories that we know of, and many more in categories that have yet to be created.


 Getty

Is AI a Job Killer?

A Gallup poll from 2018 reveals that many people think AI will destroy jobs, but just not theirs. In fact, in that poll, over 73% of Americans believe that AI will be a net job destroyer, but only 23% of these same surveyed adults were worried about it. How can you reconcile those two positions?  In that same survey, over 90% of those polled believed that AI will destroy at least half of all jobs, but 91% of them believed it wouldn’t impact their employment. The general consensus from the average person is that AI is continuing the unimpeded progress of automation and technology that brings increasing levels of productivity. Businesses will be able to do more with their existing resources, and perhaps do more with fewer resources, with those resources being primarily human labor and the costs associated with it.

Automation has been embraced by companies for many decades, but automation is not intelligence and there is no doubt that the addition of more cognitive capabilities in the technologies that companies use will allow organizations to rethink their usage of human labor for activities as wide ranging as call center operations, warehouse activities, trucking and transportation, brick-and-mortar retail, and even mining, oil, and gas activities. Many make the argument that job losses won’t be felt at the top or bottom of the pay scale, but rather in the middle. There will be less management by humans, and more management by machines and AI colleagues. Collectively these middle income jobs employ a very large percentage of the American population so this will no doubt have an impact on jobs and the workforce.
PROMOTED
A Bureau of Labor & Statistics report from 2017 reports that most employment is in retail, professional services, healthcare, and government. It’s no surprise then that AI may take a chunk out of retail, government, and professional services employment.  In fact, a workforce adjustment is already being experienced in areas that require human-intensive labor moving paper or bits and bytes around from one place to another. These highly repetitive, regulatory intensive, and error-prone processes jobs are being replaced by computer systems. Why have a human move information around when a computer can do just as good a job, especially with the ability to understand the meaning and context of information?  Furthermore, while we’re still in the very early (and possibly dangerous) days of autonomous vehicles, there’s no question that the future direction of the transportation, warehouse, and logistics industries is rapidly heading to an autonomous future. Truck driving, which represents the largest employer by number of people employed by category in many US states will clearly be a job position in jeopardy in the future.
Is AI a Job Creator?
The argument with every wave of technology, from the automatic weaving looms of the early industrial revolution to the computers of today is that jobs are not destroyed, but rather employment shifts from one place to another as entirely new categories of employment are created. The Luddites might have wrecked the mills as a protest against machine-enabled automation, but today, those same workers would be defending manufacturing against the disappearance of those jobs. In fact, if you look back far enough, you’ll see the trend away from manufacturing and towards professional services started just after World War II and the irresistible move towards globalization. Some have even made the stark point that the only reason why American manufacturing stayed a significant employer until the late 1970s was because World War II destroyed so much manufacturing capacity in Europe and Asia that the United States was the de facto manufacturing leader for many decades afterward.
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report Says
In 1910, manufacturing, transportation, retail, and domestic services were the major employers.  Inventions such as the washing machine, dishwasher, microwave, and cooktops / ranges put an end to domestic service as a major employer. Yet, the US didn’t experience massive waves of unemployment, because we invented whole new major sectors of the economy in professional services which barely even existed as a category in 1910. Likewise, the evolution of major employer by category shifted significantly from even 1978, when secretaries were the largest category of employee type.  Along came computers and out went entire rooms of typewriters, filing cabinets, and people handling the scheduling of management staff. Yet, again, the United States didn’t have a major economic collapse or massive waves of unemployment because new employment categories emerged before the old ones were fully retired.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Furthermore, there are many categories of employment that will be relatively un-impacted by even super-cognitive AI-enabled systems. The government, healthcare, education, leisure and hospitality, and many professional services categories (notably real estate) will continue being major employers. Even with the addition of AI to these industries humans will still be needed, they will just be better at their jobs and more responsive to the needs of other humans, rather than replacing them. After all there’s nothing more human than government or lounging in a hotel. As long as there are humans, we’ll have government, teachers, doctors, and cabanas. Even in areas where robotics have had a significant impact, we see puzzling contradictions. Amazon is employing more people than ever in its warehouses even though it has one of the highest penetrations of intelligent automation.


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
AI Will Kill Jobs in Some Categories, but Create Entirely New Categories of Jobs
The real job creator will be entirely new categories of jobs that we can’t even think of yet. If you went back in time 20 or 30 years and told someone that they would work as a social media marketer they would have no idea what you were talking about. Likewise, if you go forward 20 to 30 years there will be whole sectors of the economy and major employers that are not even possible today. Yesterday’s manufacturers are today’s programmers. Yesterday’s secretaries are today’s database administrators. Yesterday’s milkmen are today’s Uber drivers. Indeed, it’s not that jobs have been created or destroyed, but rather entire job categories are gone and new ones have taken their place.
Humans have a very, very hard time imagining what sort of new jobs and new sectors will come to be. Since we can only truthfully envision what might be gone tomorrow, but have a hard time imagining what will be possible, our limited human minds make the mental calculation that the net impact will be negative. But that’s simply not the case. There is no doubt that there will be new categories of jobs that relate directly to the creation of AI-enabled capabilities, whether in software or hardware.  However, no one can argue that any number of those jobs will make up for the decline in workers that come from using those products. Data scientists, robotic engineers, and ML programmers will not make up for fewer truck drivers or call center workers. Rather, the creation will be where we least expect it. Will there be entirely new categories of professional services that would be impossible without the use of advanced intelligence as a helper? Will we see a massive wave of self-employment enabled by intelligent assistants and third-party services that turn individuals into major powerhouse corporations of one?
There is no question that the world’s economies are undergoing a revolutionary shift as we move from one age of industrialization to another — something that many in the industry are calling Industry 4.0. The transition between each wave of industrialization is not necessarily a clean one. If new job categories are not created before old job categories are retired, then the transition can be a messy one. However, it’s clear that we’re already embarked on the transition, and now it remains to be seen what the future will create with the new capabilities that are being developed. Only time will tell what new jobs will appear and which ones will disappear.
Follow me on Twitter or LinkedIn. Check out my website. Kathleen WalchFollowingFollowKathleen is managing partner and founder of Cognilytica. She co-developed the firm's Cognitive Project Management for AI (CPMAI) methodology in use... Read MoreEditorial StandardsPrintReprints & Permissions",Is AI A Job Killer Or Job Creator?,,AI,,https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a-job-killer-or-job-creator/,,,,,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9mZWF0dXJlZC1pbnNpZ2h0cy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9nbG9iYWwtYWktc3VydmV5LWFpLXByb3Zlcy1pdHMtd29ydGgtYnV0LWZldy1zY2FsZS1pbXBhY3TSAQA?oc=5,"Global AI Survey: AI proves its worth, but few scale impact - McKinsey",2019-11-22,McKinsey,https://www.mckinsey.com,"Most companies report measurable benefits from AI where it has been deployed; however, much work remains to scale impact, manage risks, and retrain the workforce. A group of high performers with AI capabilities show the way.",,"Most companies report measurable benefits from AI where it has been deployed; however, much work remains to scale impact, manage risks, and retrain the workforce. A group of high performers with AI capabilities show the way.","Most companies report measurable benefits from AI where it has been deployed; however, much work remains to scale impact, manage risks, and retrain the workforce. A group of high performers with AI capabilities show the way.",https://schema.org,Survey,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/featured-insights/artificial-intelligence/global-ai-survey-ai-proves-its-worth-but-few-scale-impact'}",,https://www.mckinsey.com/~/media/mckinsey/featured%20insights/artificial%20intelligence/global%20ai%20survey%20ai%20proves%20its%20worth%20but%20few%20scale%20impact/global-ai-survey-standard-1536x1536.jpg,,2019-11-22T00:00:00Z,2019-11-22T00:00:00Z,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,,,,,,,,https://www.mckinsey.com,,,,,,,,2019-11-20T16:41:35Z,,,,,,,,,,,,,,,,,,,,,"Global AI Survey: AI proves its worth, but few scale impact",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiNmh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMTkvYWktd29yay1mdXR1cmUtY29uZ3Jlc3MtMTEyMtIBAA?oc=5,MIT conference focuses on preparing workers for the era of artificial intelligence - MIT News,2019-11-22,MIT News,https://news.mit.edu,"At MIT’s day-long AI and the Work of the Future Congress, a series of expert panels focused on preparing workers for the era of artificial intelligence.","MIT, Daniela Rus, Michael Kratsios, David Mindell, Erik Brynjolfsson, Daron Acemoglu, Elisabeth Reynolds, Andrew McAfee, ai, artificial intelligence, machine learning, AI and the Work of the Future Congress, employment, jobs, automation, robots, CSAIL, Initiative on the digital economy, future of work, unemployment, labor market","At MIT’s day-long AI and the Work of the Future Congress, a series of expert panels focused on preparing workers for the era of artificial intelligence.",,,,,,,,,,,,,,"


As automation rises in the workplace, speakers explore ways to train students and reskill workers.




Rob Matheson
|
MIT News Office


 Publication Date:
 November 22, 2019





Press Inquiries

  Press Contact:



      
            Abby        

            Abazorius        

  

      Email:
     abbya@mit.edu


      Phone:
              617-253-2709      
  

      
            MIT News Office        

  


 Media Download



 


          ↓ Download Image



 Caption:
        
              Daniela Rus (far right), director of the Computer Science and Artificial Intelligence Laboratory (CSAIL), moderated a panel on dispelling the myths of AI technologies in the workplace. The AI and the Work of the Future Congress was co-organized by CSAIL, the MIT Initiative on the Digital Economy, and the MIT Work of the Future Task Force.      
 Credits:
        
              Image: Andrew Kubica      






 


          ↓ Download Image



 Caption:
        
              During a “media spotlight” session, David Fanning, founder and producer of the investigative documentary series FRONTLINE, briefly discussed the profound effect AI is having on workplaces in the developing world, which rely heavily on manual labor, such as manufacturing lines.      
 Credits:
        
              Image: Andrew Kubica      






 


          ↓ Download Image



 Caption:
        
              During a panel focused on tech-industry diversity, Radha Basu (second from left), who founded Hewlett Packard’s operations in India in the 1970s, discusses how her new AI-based startup, iMerit, hired a workforce that’s half young women and more than 80 percent from underserved populations.       
 Credits:
        
              Image: Andrew Kubica      






 


          ↓ Download Image



 Caption:
        
              During the panel, “Innovation and Experimentation in Delivering Education and Skills,” Jacob Hsu talks about how his company, Catalyte, uses AI to predict a candidate’s ability to succeed as a software engineer, and hires and trains those who are most successful.      
 Credits:
        
              Image: Andrew Kubica      






 


          ↓ Download Image



 Caption:
        
              The panel, “Work of the Future Policy Levers: People, Places and Institutions,” which focused on how public policy can be shaped to help technology benefit society, included (from left): Daron Acemoglu, Michael Kratsios, Erik Brynjolfsson, Sarita Gupta, and Alastair Fitzpayne.      
 Credits:
        
              Image: Andrew Kubica      





*Terms of Use:

    Images for download on the MIT News office website are made available to non-commercial entities, press and the general public under a 
    Creative Commons Attribution Non-Commercial No Derivatives license.
    You may not alter the images provided, other than to crop them to size. A credit line must be used when reproducing images; if one is not provided 
    below, credit the images to ""MIT."" 
  







 Close














 Caption:
          Daniela Rus (far right), director of the Computer Science and Artificial Intelligence Laboratory (CSAIL), moderated a panel on dispelling the myths of AI technologies in the workplace. The AI and the Work of the Future Congress was co-organized by CSAIL, the MIT Initiative on the Digital Economy, and the MIT Work of the Future Task Force.      
          

 Credits:
          Image: Andrew Kubica      
          









 Caption:
          During a “media spotlight” session, David Fanning, founder and producer of the investigative documentary series FRONTLINE, briefly discussed the profound effect AI is having on workplaces in the developing world, which rely heavily on manual labor, such as manufacturing lines.      
          

 Credits:
          Image: Andrew Kubica      
          









 Caption:
          During a panel focused on tech-industry diversity, Radha Basu (second from left), who founded Hewlett Packard’s operations in India in the 1970s, discusses how her new AI-based startup, iMerit, hired a workforce that’s half young women and more than 80 percent from underserved populations.       
          

 Credits:
          Image: Andrew Kubica      
          









 Caption:
          During the panel, “Innovation and Experimentation in Delivering Education and Skills,” Jacob Hsu talks about how his company, Catalyte, uses AI to predict a candidate’s ability to succeed as a software engineer, and hires and trains those who are most successful.      
          

 Credits:
          Image: Andrew Kubica      
          









 Caption:
          The panel, “Work of the Future Policy Levers: People, Places and Institutions,” which focused on how public policy can be shaped to help technology benefit society, included (from left): Daron Acemoglu, Michael Kratsios, Erik Brynjolfsson, Sarita Gupta, and Alastair Fitzpayne.      
          

 Credits:
          Image: Andrew Kubica      
          

















Previous image
Next image






















In opening yesterday’s AI and the Work of the Future Congress, MIT Professor Daniela Rus presented diverging views of how artificial intelligence will impact jobs worldwide.By automating certain menial tasks, experts think AI is poised to improve human quality of life, boost profits, and create jobs, said Rus, director of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and the Andrew and Erna Viterbi Professor of Electrical Engineering and Computer Science.Rus then quoted a World Economic Forum study estimating AI could help create 133 million new jobs worldwide over the next five years. Juxtaposing this optimistic view, however, she noted a recent survey that found about two-thirds of Americans believe machines will soon rob humans of their careers. “So, who is right? The economists, who predict greater productivity and new jobs? The technologists, who dream of creating better lives? Or the factory line workers who worry about unemployment?” Rus asked. “The answer is, probably all of them.”Her remarks kicked off an all-day conference in Kresge Auditorium that convened experts from industry and academia for panel discussions and informal talks about preparing humans of all ages and backgrounds for a future of AI automation in the workplace. The event was co-sponsored by CSAIL, the MIT Initiative on the Digital Economy (IDE), and the MIT Work of the Future Task Force, an Institute-wide effort launched in 2018 that aims to understand and shape the evolution of jobs during an age of innovation.Presenters were billed as “leaders and visionaries” rigorously measuring technological impact on enterprise, government, and society, and generating solutions. Apart from Rus, who also moderated a panel on dispelling AI myths, speakers included Chief Technology Officer of the United States Michael Kratsios; executives from Amazon, Nissan, Liberty Mutual, IBM, Ford, and Adobe; venture capitalists and tech entrepreneurs; representatives of nonprofits and colleges; journalists who cover AI issues; and several MIT professors and researchers.Rus, a self-described “technology optimist,” drove home a point that echoed throughout all discussions of the day: AI doesn’t automate jobs, it automates tasks. Rus quoted a recent McKinsey Global Institute study that estimated 45 percent of tasks that humans are paid to do can now be automated. But, she said, humans can adapt to work in concert with AI — meaning job tasks may change dramatically, but jobs may not disappear entirely. “If we make the right choices and the right investments, we can ensure that those benefits get distributed widely across our workforce and our planet,” Rus said.Avoiding the “job-pocalypse”Common topics throughout the day included reskilling veteran employees to use AI technologies; investing heavily in training young students in AI through tech apprenticeships, vocational programs, and other education initiatives; ensuring workers can make livable incomes; and promoting greater inclusivity in tech-based careers. The hope is to avoid, as one speaker put it, a “job-pocalypse,” where most humans will lose their jobs to machines.A panel moderated by David Mindell, the Dibner Professor of the History of Engineering and Manufacturing and a professor of aeronautics and astronautics, focused on how AI technologies are changing workflow and skills, especially within sectors resistant to change. Mindell asked panelists for specific examples of implementing AI technologies into their companies.In response, David Johnson, vice president of production and engineering at Nissan, shared an anecdote about pairing an MIT student with a 20-year employee in developing AI methods to autonomously predict car-part quality. In the end, the veteran employee became immersed in the technology and is now using his seasoned expertise to deploy it in other areas, while the student learned more about the technology’s real-world applications. “Only through this synergy, when you purposely pair these people with a common goal, can you really drive the skills forward … for mass new technology adoption and deployment,” Johnson said.In a panel about shaping public policies to ensure technology benefits society — which included U.S. CTO Kratsios — moderator Erik Brynjolfsson, director of IDE and a professor in the MIT Sloan School of Management, got straight to the point: “People have been dancing around this question: Will AI destroy jobs?”“Yes, it will — but not to the extent that people presume,” replied MIT Institute Professor Daron Acemoglu. AI, he said, will mostly automate mundane operations in white-collar jobs, which will free up humans to refine their creative, interpersonal, and other high-level skills for new roles. Humans, he noted, also won’t be stuck doing low-paying jobs, such as labeling data for machine-learning algorithms.“That’s not the future of work,” he said. “The hope is we use our amazing creativity and all these wonderful and technological platforms to create meaningful jobs in which humans can use their flexibility, creativity, and all the things … machines won’t be able to do — at least in the next 100 years.”
Kratsios emphasized a need for public and private sectors to collaborate to reskill workers. Specifically, he pointed to the Pledge to the America’s Worker, the federal initiative that now has 370 U.S. companies committed to retraining roughly 4 million American workers for tech-based jobs over the next five years.Responding to an audience question about potential public policy changes, Kratsios echoed sentiments of many panelists, saying education policy should focus on all levels of education, not just college degrees. “A vast majority of our policies, and most of our departments and agencies, are targeted toward coaxing people toward a four-year degree,” Kratsios said. “There are incredible opportunities for Americans to live and work and do fantastic jobs that don’t require four-year degrees. So, [a change is] thinking about using the same pool of resources to reskill, or retrain, or [help students] go to vocational schools.”Inclusivity and underserved populationsEntrepreneurs at the event explained how AI can help create diverse workforces. For instance, a panel about creating economically and geographically diverse workforces, moderated by Devin Cook, executive producer of IDE’s Inclusive Innovation Challenge, included Radha Basu, who founded Hewlett Packard’s operations in India in the 1970s. In 2012, Basu founded iMerit, which hires employees — half are young women and more than 80 percent come from underserved populations — to provide AI services for computer vision, machine learning, and other applications.A panel hosted by Paul Osterman, co-director of the MIT Sloan Institute for Work and Employment Research and an MIT Sloan professor, explored how labor markets are changing in the face of technological innovations. Panelist Jacob Hsu is CEO of Catalyte, which uses an AI-powered assessment test to predict a candidate’s ability to succeed as a software engineer, and hires and trains those who are most successful. Many of their employees don’t have four-year degrees, and their ages range from anywhere from 17 to 72.A “media spotlight” session, in which journalists discussed their reporting on the impact of AI on the workplace and the world, included David Fanning, founder and producer of the investigative documentary series FRONTLINE, which recently ran a documentary titled “In the Era of AI.” Fanning briefly discussed how, during his investigations, he learned about the profound effect AI is having on workplaces in the developing world, which rely heavily on manual labor, such as manufacturing lines.“What happens as automation expands, the manufacturing ladder that was opened to people in developing countries to work their way out of rural poverty — all that manufacturing gets replaced by machines,” Fanning said. “Will we end up across the world with people who have nowhere to go? Will they become the new economic migrants we have to deal with in the age of AI?”Education: The great counterbalanceElisabeth Reynolds, executive director for the MIT Task Force on the Work of the Future and of the MIT Industrial Performance Center, and Andrew McAfee, co-director of IDE and a principal research scientist at the MIT Sloan School of Management, closed out the conference and discussed next steps.Reynolds said the MIT Task Force on the Work of the Future, over the next year, will further study how AI is being adopted, diffused, and implemented across the U.S., as well as issues of race and gender bias in AI. In closing, she charged the audience with helping tackle the issues: “I would challenge everybody here to say, ‘What on Monday morning is [our] organization doing in respect to this agenda?’” In paraphrasing economist Robert Gordon, McAfee reemphasized the shifting nature of jobs in the era of AI: “We don’t have a job quantity problem, we have a job quality problem.”AI may generate more jobs and company profits, but it may also have numerous negative effects on employees. Proper education and training are keys to ensuring the future workforce is paid well and enjoys a high quality of life, he said: “Tech progress, we’ve known for a long time, is an engine of inequality. The great counterbalancing force is education.”








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print







Related Links

AI and the Work of the Future CongressComputer Science and Artificial Intelligence Laboratory MIT Work of the Future Task ForceMIT Initiative on the Digital Economy






Related Topics

Research
Computer science and technology
Algorithms
Computer Science and Artificial Intelligence Laboratory (CSAIL)
MIT Sloan School of Management
Technology and society
Labor and jobs
Economics
Policy
Artificial intelligence
Machine learning
Innovation and Entrepreneurship (I&E)
Business and management
Manufacturing
Careers
Special events and guest speakers



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMGh0dHBzOi8vd3d3LnViZXIuY29tL2Jsb2cvYWktbWVldC10aGUtdGVhbS1qYW5lL9IBAA?oc=5,Artificial Intelligence - Meet the Team - Uber,2019-11-21,Uber,https://www.uber.com,"We sat down with Jane Hung, on of our Research Engineers from Uber's AI Labs Team to understand what it's like to work on the team.",,"We sat down with Jane Hung, on of our Research Engineers from Uber's AI Labs Team to understand what it's like to work on the team.","We sat down with Jane Hung, on of our Research Engineers from Uber's AI Labs Team to understand what it's like to work on the team.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiS2h0dHBzOi8vZW1lcmouY29tL2FpLXNlY3Rvci1vdmVydmlld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZXBpZGVtaW9sb2d5L9IBAA?oc=5,Artificial Intelligence in Epidemiology - Current Use-Cases - Emerj,2019-11-21,Emerj,https://emerj.com,Discover how predictive analytics applications may be a great fit for epidemiologists at government bodies and healthcare organizations in use-cases such...,,Discover how predictive analytics applications may be a great fit for epidemiologists at government bodies and healthcare organizations in use-cases such...,,https://schema.org,Article,https://emerj.com/ai-sector-overviews/artificial-intelligence-epidemiology,Artificial Intelligence in Epidemiology &#8211; Current Use-Cases,https://emerj.com/wp-content/uploads/2019/06/Doctor-Globe-Stethoscope-iStock_000006373054Large-690x327.jpg,Ayn de Jesus,2019-06-13,2019-11-21,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",,,," Business intelligence and analyticsHealthcare Artificial Intelligence in Epidemiology – Current Use-Cases Ayn de JesusLast updated on November 21, 2019  Last updated on November 21, 2019, published by Ayn de Jesus Ayn serves as AI Analyst at Emerj - covering artificial intelligence use-cases and trends across industries. She previously held various roles at Accenture. Share to: LinkedIn Twitter Facebook Email  Artificial intelligence is changing the way healthcare networks do business and physicians perform their routine activities from medical transcription to robot-assisted surgery. Although the more mature use-cases for AI in healthcare are those built on algorithms that have applications in various other industries (namely white-collar automation), we believe that in the coming three to five years, AI solutions for healthcare will become increasingly specialized to individual use-cases.  In phase two of the AI zeitgeist, leadership teams at healthcare networks will have familiarized themselves with basic AI concepts, and they’ll be able to work with vendors that offer AI solutions for very specific healthcare concerns. In this article, we look at the state of AI for epidemiology, the study of the incidence and spread of disease. The large majority of AI applications for epidemiology are predictive analytics applications, perhaps unsurprisingly.  Predictive analytics involves AI algorithms that use historical data to predict future outcomes. As such, there’s some evidence that they can help government bodies, community health organizations, and researchers figure out how a disease might originate in a population and how it might spread based on these predictions. Predictive analytics applications for epidemiology almost always require clients to supply very large quantities of anonymized patient data, which may prove challenging for research institutions that do not have robust partnerships with healthcare organizations.  Leaders interested in using AI for epidemiology should consider the data requirements of a vendor’s AI solution well before they choose to do business with a vendor. We cover four AI vendors offering artificial intelligence solutions for epidemiology: IBM. Saama, SAS, and Orion Health. We begin our analysis of the space with IBM Watson Health. IBM Watson Health IBM Watson Health offers the Explorys data set and analytics solution, which the company claims can provide life sciences companies and epidemiologists a better understanding of  disease history, epidemiology, and disease progression, and determine the economic impact for select populations. The company claims that knowing this will also enable organizations to identify efforts for deeper study and identify populations most likely to benefit from a treatment. The company states the machine learning model behind the analytics software was trained on ambulatory, inpatient, and adjudicated claims data of 50 million anonymized patients sourced from electronic medical record systems. The data would then be run through the software’s machine learning algorithm.  This would have trained the algorithm to discern which data points correlate to the rates of health events in a population, the history of disease, and their most successful treatments. The software would then be able to predict the incidence and prevalence of a disease in populations, disease treatment patterns, and treatment-related risks. Below is a short 5-minute video explaining how IBM Explorys Data integrates data from multiple care settings. This includes 3 to 4 years worth of individual patient data, encompassing ambulatory, in-patient, specialty care, and post-acute care. Other types of data include lab results, vitals, biometrics, and patient-reported outcomes. The video reports that data is updated daily and weekly:  IBM Watson claims to have helped Smart Analytics study the treatment journey of more than 6,500 psoriasis patients using IBM Explorys. One of SmartAnalytics’s customers, a pharmaceutical company, wanted to know how long it took for psoriasis patients to transition from topical to oral treatments and finally to injectable treatments.  SmartAnalyst turned to IBM Watson Health and used Explorys to discover that over the course of three years, patients tended to skip oral medications and immediately transition from topical remedies to injectables.  The Explorys dataset revealed that a large number of patients transitioned from topical therapy to injectables within 206 days, not enough time for some topical treatments to take effect. However, patients who tried oral treatments before switching to injectables took an average of 488 days. As a result of having this information, SmartAnalytics’s customer developed a communication plan to educate patients and doctors on the importance of giving oral medications time to take effect, and that the more expensive injectables are a last resort treatment. IBM Watson Health also lists AHMC Healthcare, Schneck Medical Center, SmartAnalyst, Edward-Elmhurst Healthcare, Harrow Council, Floyd Health Care System, and Hallmark Health Medical Associates as some of their past clients. Scott Spangler is the Chief Data Scientist and a Distinguished Engineer at IBM Watson Health. He holds an MS in Computer Science from the University of Texas at Austin. Previously, Spangler served first as Sr Tech. Staff Member and then as Principal Data Scientist, Distinguished Engineer at IBM Watson Innovations for 19 years. Saama Technologies Saama offers Real World Analytics, which it claims can help life sciences companies mine data that will allow them to monitor million-wide populations during clinical trials and forecast disease incidence or prevalence using machine learning. Saama claims that the application resides in the cloud. The company adds that the machine learning model behind the software was trained on data consisting of billions of patients’ electronic medical and health records. The data would then be run through the software’s machine learning algorithm. This would have trained the algorithm to discern which data points correlate to the efficacy of a drug.  The software would be able to predict treatment patterns such as shifts in the type of drug, the ideal duration of a treatment, and the prevalence and incidence rates of a disease. Below is a short 3-minute video demonstrating how Saama’s Real World Analytics uncovers data about treatment pathways of patients, in this case, with lung cancer. Users select the data source, diagnosis, and therapies to show the number of patients by gender and age, and reveal the popular treatments administered to them.  The results also show the duration of therapy as well as the period when patients change from one treatment to the another:  Saama claims to have helped Pharmacyclics, a company that developed and marketed small-molecule medicines to treat cancers and other autoimmune diseases, aggregate all its clinical operations data for a singular, central view. As its clinical operations grew, Pharmacyclics needed to maximize its clinical data better. However, the data silos made it difficult to generate automated and accurate reports. Pharmacyclics turned to Saama, which deployed its Clinical Development Optimizer (CDO), part of the Life Science Analytics Cloud.  The case study reports that the implementation of the CDO resulted in: A comprehensive view of clinical operations data Consolidated data and automated, error-free reports  More transparency and consistency in clinical operations data Enhanced collaboration among the business team members Standardized data and business definitions Improved data flow, data management, and governance Saama also lists Actelion, Astellas, Bill and Melinda Gates Foundation, Brocade, Broadcom, Cisco, CSAA Insurance Group, Dignity Health, GoPro, Motorists Insurance Group, Otsuka, PayPal, Roche, and Unilever as some of its past clients. Rajeev Dadia is the CTO at Saama. He holds an MS in Computer Science from the California State University-Chico. Previously, Dadia served as IT Manager. SAS SAS offers its Real World Evidence, which it claims can help healthcare providers and life sciences companies better understand a population and improve population health and treatments by providing data from a wide variety of sources.  These sources include: The environment Electronic medical and health records Genomics  Socioeconomic data  Clinical trials,  Case reports Healthcare insurance claims,  Public health investigations The data will then be analyzed using machine learning and predictive analytics. The company states that the machine learning model behind the software was trained on point-of-care systems, electronic medical records, insurance claims, patient-reported outcomes, and third-party data.  The data would then be run through the software’s machine learning algorithm. This would have trained the algorithm to discern which data points correlate to, for instance, a drug’s utilization and performance, as well as the patient’s adherence to the treatment and treatment preferences. The software would be able to predict how the therapeutic value of an existing drug can be expanded by identifying new illnesses it can treat and new customers. This may or may not require the user to upload information about their new customer segments or plans for a marketing campaign into the software beforehand. SAS claims to be helping Renown Institute for Health Innovation (Renown IHI) better understand how genetic, clinical, environmental and socioeconomic factors affect population health. Renown IHI in September 2016 embarked on the Healthy Nevada Project and needed to develop an application that would reveal population health risks of patients based on gender, age, and personal or family health history.  The application will also be used to uncover public health risks of diseases, illnesses, and environmental factors such as air quality. According to the case study, the pilot phase of the project had enlisted 10,000 participants whose DNA samples had been collected in 60 working days. The project’s second phase opened to 40,000 more Nevadans last March 2018. SAS reported that using its application could potentially predict how environmental factors contribute to the Nevada population’s health, and understand what role age, gender, or genetics play. The results could then be used to progress precision medicine and other health innovations and research. SAS also lists Honda, Nestle, HSBC, Lufthansa, Health Data Essentials, OhioHealth, Stockholm County Council, University of new hampshire, and Western Australia Department of Health as some of its past clients. Orion Health Orion Health offers Amadeus, a population health management and precision medicine software, which it claims can help healthcare organizations handle large volumes of data to predict and differentiate the health risks in a population using machine learning. The company explains that having this capability will allow healthcare organizations to make quick and informed decisions. The company states the machine learning model behind the software was trained on claims, clinical, and non-traditional data such as omics, social, and behavioral data. The data would then be run through the software’s machine learning algorithm. This would have trained the algorithm to discern which data points correlate to the health risks of a population. The software would be able to predict which patients are at risk, the treatments that can be administered, as well as the accompanying costs. This may or may not require the user to upload information about their care-coordination programs or personalized care plans into the software beforehand. Below is a short 2-minute video demonstrating how Amadeus integrates health data such as claims, clinical, behavioural, social, genomic and device to ensure that physicians have complete patient records. The application then enables users to analyze this data to identify at-risk patients and provide specific treatments:  Orion Health claims to have helped the Scottsdale Health Partners (SHP), a physician-led clinical network that covers more than 60,000 patients, set up a health information exchange (HIE) that would provide complete, accurate patient data. The SHP turned to Orion Health to establish the HIE that would allow its more than 700 participating clinicians using disparate EMR software to share health information. The HIE also enabled the clinicians to identify at-risk patients, find data related to appropriate treatments, and simplify reporting. Using the application, the SHP was able to predict patients at-risk of readmission and the contributing factors after being discharged. This enabled them to develop programs to reduce the risks, resulting in a 9% decrease in readmissions within one year of the application’s deployment.  The case study also claims that within the same period, SHP was able to reduce costs by 10%, attributed to the predictions provided by the application. The case study also claims that SHP is the only Arizona Medicare Shared Savings Program to achieve an almost $3.75 million in savings, attributed to the application’s predictions. Orion Health also lists New Mexico Health Information Exchange, University of Louisville Hospital, Oregon Health Authority, Penn State Health Milton S. Hershey Medical Center, and Maine HealthInfoNet as some of their past clients. Ian McCrae is CEO at Orion Health. He holds an MS in Electrical Engineering from the University of Auckland. Previously, McCrae served as telecommunications consultant at Ernst & Young, Senior Business Analyst at the London Stock Exchange, and as a scientist at the Department of Scientific and Industrial Research.   Header Image Credit: CIR Vitals Related Posts Artificial Intelligence in Cybersecurity - Current Use-Cases and CapabilitiesAI has made some inroads in the cybersecurity sector and several AI vendors claim to… Artificial Intelligence at Goldman Sachs - Current InitiativesThe top 100 global banks, including Goldman Sachs, are beginning to take AI strategies very… Artificial Intelligence at Morgan Stanley - Current InitiativesMorgan Stanley is a US financial institution known mostly for its financial advisory services. According… Artificial Intelligence at Barclays - Current InitiativesBarclays is a UK bank ranked 20th on S&P Global’s list of the top 100 banks.… Artificial Intelligence at HSBC - 2 Use-CasesHSBC Holdings is a multinational banking and financial services holding company and is ranked 99th… Share to: LinkedIn Twitter Facebook Email  3 Ways to Discover AI Trends in Any SectorSee critical AI applications and trends faster than ever. Uncover AI opportunity and ROI without getting caught up in hype.

Download this succinct 4-page white paper: Get the White Paper",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,AI Sector Overviews,1996.0,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPWh0dHBzOi8vd3d3LmljdHdvcmtzLm9yZy9wYWlkLWdvb2dsZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,Apply Now: Paid Google Artificial Intelligence Residency Program - ICTworks,2019-11-25,ICTworks,https://www.ictworks.org,,,"Machine learning is fast becoming a critical area for a broad range of applications, and people from a wide range of disciplines are beginning to realize the importance of evolving research goals to include a breadth of artificial intelligence subfields. Sign up now to get more opportunities like this! With growing interest in the field, […]",,https://schema.org,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/#article', 'isPartOf': {'@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/'}, 'author': {'name': 'Wayan Vota', '@id': 'https://www.ictworks.org/#/schema/person/247a6f576e8030448f5ac5b3418f17f8'}, 'headline': 'Apply Now: Paid Google Artificial Intelligence Residency Program', 'datePublished': '2019-11-25T05:51:23+00:00', 'dateModified': '2019-11-11T16:34:49+00:00', 'mainEntityOfPage': {'@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/'}, 'wordCount': 322, 'publisher': {'@id': 'https://www.ictworks.org/#organization'}, 'image': {'@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://i0.wp.com/www.ictworks.org/wp-content/uploads/2019/01/google-ai-grant-funding.png?fit=1200%2C628&ssl=1', 'keywords': ['Artificial Intelligence', 'Google', 'Machine Learning', 'Mentorship', 'STEM'], 'articleSection': ['Featured', 'Funding'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/', 'url': 'https://www.ictworks.org/paid-google-artificial-intelligence/', 'name': 'Apply Now: Paid Google Artificial Intelligence Residency Program - ICTworks', 'isPartOf': {'@id': 'https://www.ictworks.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://i0.wp.com/www.ictworks.org/wp-content/uploads/2019/01/google-ai-grant-funding.png?fit=1200%2C628&ssl=1', 'datePublished': '2019-11-25T05:51:23+00:00', 'dateModified': '2019-11-11T16:34:49+00:00', 'breadcrumb': {'@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.ictworks.org/paid-google-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/#primaryimage', 'url': 'https://i0.wp.com/www.ictworks.org/wp-content/uploads/2019/01/google-ai-grant-funding.png?fit=1200%2C628&ssl=1', 'contentUrl': 'https://i0.wp.com/www.ictworks.org/wp-content/uploads/2019/01/google-ai-grant-funding.png?fit=1200%2C628&ssl=1', 'width': 1200, 'height': 628}, {'@type': 'BreadcrumbList', '@id': 'https://www.ictworks.org/paid-google-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.ictworks.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Apply Now: Paid Google Artificial Intelligence Residency Program'}]}, {'@type': 'WebSite', '@id': 'https://www.ictworks.org/#website', 'url': 'https://www.ictworks.org/', 'name': 'ICTworks', 'description': 'Expertise in sustainable ICT4D for the developing world', 'publisher': {'@id': 'https://www.ictworks.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.ictworks.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.ictworks.org/#organization', 'name': 'ICTworks', 'url': 'https://www.ictworks.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.ictworks.org/#/schema/logo/image/', 'url': 'https://i0.wp.com/www.ictworks.org/wp-content/uploads/2020/08/ictworks.png?fit=150%2C150&ssl=1', 'contentUrl': 'https://i0.wp.com/www.ictworks.org/wp-content/uploads/2020/08/ictworks.png?fit=150%2C150&ssl=1', 'width': 150, 'height': 150, 'caption': 'ICTworks'}, 'image': {'@id': 'https://www.ictworks.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/ICTworks/', 'https://x.com/ICT_works']}, {'@type': 'Person', '@id': 'https://www.ictworks.org/#/schema/person/247a6f576e8030448f5ac5b3418f17f8', 'name': 'Wayan Vota', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.ictworks.org/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/b94941f6a8bc374844f084add8e01460?s=96&d=monsterid&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/b94941f6a8bc374844f084add8e01460?s=96&d=monsterid&r=g', 'caption': 'Wayan Vota'}, 'description': 'Wayan Vota co-founded ICTworks. He also co-founded Technology Salon, MERL Tech, ICTforAg, ICT4Djobs, ICT4Drinks, JadedAid, Kurante, OLPC News and a few other things. Opinions expressed here are his own and do not reflect the position of his employer, any of its entities, or any ICTWorks sponsor.', 'sameAs': ['https://www.wayan.com', 'wayan.vota', 'https://x.com/wayan_vota'], 'url': 'https://www.ictworks.org/author/wayan-vota/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvam9obmN1bWJlcnMvMjAxOS8xMS8yMy9jYW4tc3ludGhldGljLWJpb2xvZ3ktaW5zcGlyZS1haS_SAQA?oc=5,Can Synthetic Biology Inspire The Next Wave Of AI? - Forbes,2019-11-23,Forbes,https://www.forbes.com,"Computers can beat humans at sophisticated tasks like the game Go, but can they also drive a car, speak languages, play soccer, and perform a myriad of other tasks like humans? Here’s what AI can learn from biology. ","synthetic biology,AI,artificial intelligence","Computers can beat humans at sophisticated tasks like the game Go, but can they also drive a car, speak languages, play soccer, and perform a myriad of other tasks like humans? Here’s what AI can learn from biology. ","Computers can beat humans at sophisticated tasks like the game Go, but can they also drive a car, speak languages, play soccer, and perform a myriad of other tasks like humans? Here’s what AI can learn from biology. ",http://schema.org,BreadcrumbList,,Can Synthetic Biology Inspire The Next Wave Of AI?,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/688972574/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'John Cumbers', 'url': 'https://www.forbes.com/sites/johncumbers/', 'description': ""I am the founder and CEO of SynBioBeta, the leading community of innovators, investors, engineers, and thinkers who share a passion for using synthetic biology to build a better, more sustainable universe. I publish the weekly SynBioBeta Digest, host the SynBioBeta Podcast, and wrote “What’s Your Biostrategy?”, the first book to anticipate how synthetic biology is going to disrupt virtually every industry in the world. I also founded BetaSpace, a space settlement innovation network and community of visionaries, technologists, and investors accelerating the industries needed to sustain human life here and off-planet. I’ve been involved with multiple startups, I am an operating partner and investor at the hard tech investment fund Data Collective, and I'm a former bioengineer at NASA. I earned my PhD in Molecular Biology, Cell Biology, and Biochemistry from Brown University and am originally from the UK."", 'sameAs': ['https://www.linkedin.com/in/john-cumbers-542220/', 'https://www.twitter.com/johncumbers', 'https://www.synbiobeta.com/']}",2019-11-23T07:30:00-05:00,2019-11-23T08:51:54-05:00,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Business', 'item': 'https://www.forbes.com/business/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Manufacturing', 'item': 'https://www.forbes.com/manufacturing/'}]",Manufacturing,,"More From ForbesJul 15, 2024,05:23pm EDTIt’s Time Manufacturers Get Serious About Protecting Their IPJul 10, 2024,09:01am EDTOne Start-Up’s $20M Boost To Bring Injection Molding Back To The U.S.Jul 9, 2024,03:04pm EDTWill This Czech Company Dominate Desktop 3D Printing In America?Jul 8, 2024,07:00am EDTProtecting Workers From Extreme HeatJul 2, 2024,01:21pm EDTAI: The Supply Chain Leaders’ Build or Buy Software DilemmaJun 28, 2024,11:45am EDTOnline Training From SolidProfessor Helps Solve The Skilled Worker ShortageJun 27, 2024,05:00pm EDTClosing The Manufacturing Skills Gap Means Giving Talent A Capital TEdit StoryForbesBusinessManufacturingEditors' PickCan Synthetic Biology Inspire The Next Wave Of AI?John CumbersSenior ContributorOpinions expressed by Forbes Contributors are their own.Synthetic biology author.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 23, 2019,07:30am ESTUpdated Nov 23, 2019, 08:51am ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinComputers can beat humans at sophisticated tasks like the game Go, but can they also drive a car, ... [+] speak languages, play soccer, and perform a myriad of other tasks like humans? Here’s what AI can learn from biology.AFP via Getty Images
In building the world’s first airplane at the dawn of the 20th century, the Wright Brothers took inspiration from the “insightful” movements of birds. They observed and reverse-engineered aspects of the wing in nature, which in turn helped them make important discoveries about aerodynamics and propulsion. 


Similarly, to build machines that think, why not seek inspiration from the three pounds of matter that operates between our ears? Geoffrey Hinton, a pioneer of artificial intelligence and winner of the Turing Award, seemed to agree: “I have always been convinced that the only way to get artificial intelligence to work is to do the computation in a way similar to the human brain.” 

So what’s next for artificial intelligence (AI)? Could the next wave of AI be inspired by rapid advances in biology? Can the tools for understanding brain circuits at the molecular level lead us to a higher, systems-level understanding of how the human mind works? 

PROMOTED
The answer is likely yes, and the flow of ideas between learning about biological systems and developing artificial ones has actually been going on for decades. 

The origins of machine learning: human brain science
First of all, what does biology have to do with machine learning? It may surprise you to learn that much of the progress in machine learning stems from insights from psychology and neuroscience. Reinforcement learning (RL) — one of the three paradigms of machine learning (the two others being supervised learning and unsupervised learning) — originates from animal and cognitive neuroscience studies going all the way back to the 1940s. RL is central to some of today’s most advanced AI systems, such as AlphaGo, the widely-publicized AI agent developed by leading AI company Google DeepMind. AlphaGo defeated the world’s top-ranked players at Go, a Chinese board game that comprises more board combinations than there are atoms in the universe. 
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report Says
Despite AlphaGo’s superhuman performance in the game of Go, its human opponent still possesses far more general intelligence. He can drive a car, speak languages, play soccer, and perform a myriad of other tasks in any kind of environment. Current AI systems are largely incapable of using the knowledge learned to play poker and transfer it to another task, like playing a game of Cluedo. These systems are focused on a single, narrow environment and require vast amounts of data, and training time. And still, they make simple errors like mistaking a chihuahua for a muffin! 









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



The internet meme asks, “Is this a chihuahua or a muffin?” But developing an AI system to solve this ... [+] seemingly simple human task is not that easy.Mariya Yao - TopBots


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
What children and AI systems have in common
Similar to child learning, reinforcement learning is based on the AI system’s interaction with its environment. It performs actions that seek to maximize the reward and avoid punishments. Driven by curiosity, children are active learners that simultaneously explore their surrounding environment and predict their actions’ outcomes, allowing them to build mental models to think causally. If, for example, they decide to push the red car, spill the flower vase, or crawl the other direction, they will adjust their behavior based on the outcomes of their actions. 
Children experience different environments in which they find themselves navigating and interacting with various contexts and objects’ dispositions, often in unusual manners. Just as child brain development could inspire the development of AI systems, the RL agent’s learning mechanisms are parallel to the brain’s learning mechanisms driven by the release of dopamine - a neurotransmitter key to the central nervous system - which trains the prefrontal cortex in response to experiences and thus shapes stimulus-response associations as well as outcome predictions. 
Synthetic biology and AI
Biology is one of the most promising beneficiaries of artificial intelligence. From investigating mind-boggling combinations of genetic mutations that contribute to obesity to examining the byzantine pathways that lead some cells to go haywire and produce cancer, biology produces an inordinate amount of complex, convoluted data. But the information contained within these datasets often offers valuable insights that could be used to improve our health.
In the field of synthetic biology, where engineers seek to “rewire” living organisms and program them with new functions, many scientists are harnessing AI to design more effective experiments, analyze their data, and use it to create groundbreaking therapeutics. I recently highlighted five companies that are integrating machine learning with synthetic biology to pave the way for better science and better engineering.
Artificial general intelligence: The holy grail of AI
Artificial general intelligence (AGI) describes a system that is capable of mimicking human-like abilities such as planning, reasoning, or emotions. Billions of dollars have been invested in this exciting and potentially lucrative area, leading some to make claims like “data is the new oil.”
Among the many companies working on general artificial intelligence are Google’s DeepMind, the Swiss AI lab IDSIA, Nnaisense, Vicarious, Maluuba, the OpenCog Foundation, Adaptive AI, LIDA, and Numenta. Organizations such as the Machine Intelligence Research Institute and OpenAI also state AGI as their main goal. One of the goals of the international Human Brain Project is to simulate the human brain.
Despite a growing body of talent, tools, and high-quality data needed to achieve AGI, we still have a long way to go to achieve this.
AI in our daily lives
Today, AI techniques such as Machine Learning (ML) are ubiquitous in our society, reaching from healthcare and manufacturing to transportation and warfare but are qualified as “narrow AI”. They indeed process and learn powerfully large amounts of data to identify insightful and informative patterns for a single task, such as predicting airline ticket prices, distinguishing dogs from cats in images, and generating your movie recommendations on Netflix.
In biology, AI is also changing your health care. It is generating more and better drug candidates (Insitro), sequencing your genome (Veritas Genetics), and detecting your cancer earlier and earlier (Freenom). 
Where do we go from here?
As humans, we are able to quickly acquire knowledge in one context and generalize it to another environment across novel multiple situations and tasks, which would allow us to develop more efficient self-driving car systems as they need to perform many tasks on the road concurrently. In AI research, this concept is known as transfer learning. It assists an AI system in learning from just a few examples — instead of the millions that traditional computing systems usually need — to build a system that learns from first principles, abstracts the acquired knowledge, and generalizes it to new tasks and contexts. 
To produce more advanced AI, we need to better understand the brain’s inner workings that allow us to portray the world around us. There is a synergistic mission between understanding biological intelligence and creating an artificial one, seeking inspiration from our brain might help us bridge that gap.
Acknowledgment: Thank you to Louis N. Andre for additional research and reporting in this article. I’m the founder of SynBioBeta, and some of the companies that I write about — including some named in this article — are sponsors of the SynBioBeta conference (click here for a full list of sponsors).
Follow me on Twitter or LinkedIn. Check out my website. John CumbersFollowingFollowI am the founder and CEO of SynBioBeta, the leading community of innovators, investors, engineers, and thinkers who share a passion for using... Read MoreEditorial StandardsPrintReprints & Permissions",Can Synthetic Biology Inspire The Next Wave Of AI?,,Manufacturing,,https://www.forbes.com/sites/johncumbers/2019/11/23/can-synthetic-biology-inspire-ai/,,,,,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vd3d3LmNubi5jb20vMjAxOS8xMS8yMS90ZWNoL2FpLWdlbmRlci1yZWNvZ25pdGlvbi1wcm9ibGVtL2luZGV4Lmh0bWzSAQA?oc=5,AI software defines people as male or female. That's a problem - CNN,2019-11-21,CNN,https://www.cnn.com,Artificial intelligence doesn’t know what to make of Os Keyes.,"amazon.com inc, artificial intelligence, business and industry sectors, business, economy and trade, companies, company activities and management, company strategy, computer science and information technology, sex and gender, society, software and applications, startups, technology, transgender persons",Artificial intelligence doesn’t know what to make of Os Keyes.,Artificial intelligence doesn’t know what to make of Os Keyes.,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@context': 'https://schema.org', 'url': 'https://www.cnn.com/2019/11/21/tech/ai-gender-recognition-problem/index.html', 'dateModified': '2019-11-21T16:32:27Z', 'inLanguage': 'en', 'additionalType': 'article_fullwidth', 'publisher': {'@type': 'NewsMediaOrganization', 'name': 'CNN', 'logo': 'https://media.cnn.com/api/v1/images/stellar/prod/cnnlogo.png?q=w_60,h_61', 'foundingDate': '1980-06-01', 'url': 'https://www.cnn.com', 'sameAs': ['https://www.facebook.com/cnn/', 'https://twitter.com/CNN', 'https://www.instagram.com/cnn/', 'https://www.youtube.com/cnn']}, 'name': 'AI software defines people as male or female. That’s a problem', 'headline': 'AI software defines people as male or female. That’s a problem', 'description': 'Artificial intelligence doesn’t know what to make of Os Keyes.', 'datePublished': '2019-11-21T16:01:30Z'}",AI software defines people as male or female. That’s a problem,"[{'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/191120155705-20191120-ai-gender-identification-main.jpeg?q=w_3000,h_1688,x_0,y_0,c_fill', 'sourceOrganization': {'@type': 'Organization', 'name': 'CNN'}, 'width': '3000', 'height': '1688', 'creditText': 'Photo Illustration: Aakanksha Aggarwal/ Shutterstock', 'dateCreated': '2019-11-20T21:04:49Z', 'dateModified': '2019-11-20T21:04:50Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/191118134734-ai-gender-identification-os-keyes.jpg?q=w_2500,h_1667,x_0,y_0,c_fill', 'caption': 'Os Keyes, a graduate student at the University of Washington, worries that artificial intelligence could put transgender people ""on a collision course with law enforcement"" based on how it categorizes gender.', 'sourceOrganization': {'@type': 'Organization', 'name': 'Os Keyes'}, 'width': '2500', 'height': '1667', 'creditText': 'Dorothy Edwards/Crosscut', 'dateCreated': '2019-11-18T19:20:07Z', 'dateModified': '2019-11-18T19:20:08Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/20191120-ai-gender-identification-instory1-v2.jpg?q=h_750,w_600,x_0,y_0', 'width': '600', 'height': '750'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/191118130655-ai-gender-identification-morgan.jpg?q=w_3000,h_1688,x_0,y_0,c_fill', 'caption': 'Morgan Klaus Scheuerman, a graduate student at the University of Colorado Boulder, ran the same image of his face through facial analysis systems from two different companies. One determined his face was male, while the other identified it as female.', 'sourceOrganization': {'@type': 'Organization', 'name': 'CNN'}, 'width': '3000', 'height': '1688', 'creditText': 'Morgan Klaus Scheuerman', 'dateCreated': '2019-11-18T18:07:59Z', 'dateModified': '2019-11-18T21:18:04Z'}]","[{'@type': 'Person', 'name': 'Rachel Metz', 'url': 'https://www.cnn.com/profiles/rachel-metz'}]",2019-11-21T16:01:30Z,2019-11-21T16:32:27Z,"{'@type': 'NewsMediaOrganization', 'name': 'CNN', 'logo': 'https://media.cnn.com/api/v1/images/stellar/prod/cnnlogo.png?q=w_60,h_61', 'foundingDate': '1980-06-01', 'url': 'https://www.cnn.com', 'sameAs': ['https://www.facebook.com/cnn/', 'https://twitter.com/CNN', 'https://www.instagram.com/cnn/', 'https://www.youtube.com/cnn']}",,,,"






















Video Ad Feedback



How AI is changing the way we work
                


                                01:11
                            
 - Source:
                CNN Business
    








Latest in tech
16 videos














Video Ad Feedback



Experts raising alarm over 'crisis' of TikTok's impact on mental health
                




                                03:12
                            
Now playing
 - Source:
                CNN














Video Ad Feedback



How AI is changing the way we work
                




                                01:11
                            
Now playing
 - Source:
                CNN Business
    














Video Ad Feedback



Experts warn AI could pose 'extinction' risk for humanity
                




                                02:06
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



CNN tried an AI flirt app. It was shockingly pervy
                




                                03:19
                            
Now playing
 - Source:
                CNN Business















Video Ad Feedback



These two moments show how Twitter's choices helped former President Trump
                




                                01:55
                            
Now playing
 - Source:
                CNN Business
    














Video Ad Feedback



These newscasters you may have seen online are not real people
                




                                03:15
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Lawsuit says celebrities were paid to fuel hype behind these NFTs
                




                                07:29
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Video: This tiny shape-shifting robot can melt its way out of a cage
                




                                01:08
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Hear why this teacher says schools should embrace ChatGPT, not ban it
                




                                01:29
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



'Make my dad famous': A daughter's quest to showcase her dad's artwork
                




                                01:33
                            
Now playing
 - Source:
                CNN Business
    














Video Ad Feedback



Are Musk's Twitter actions a speed bump for Tesla?
                




                                02:14
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



He loves artificial intelligence. Hear why he is issuing a warning about ChatGPT
                




                                04:38
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Twitter competitor to Elon Musk: Get off the internet
                




                                02:57
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Tinder is reportedly testing a $500 per month subscription plan. Is it worth it?
                




                                02:05
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



See the first electrified and fastest-accelerating Corvette
                




                                01:16
                            
Now playing
 - Source:
                CNN Business
    














Video Ad Feedback



Facebook could soon reinstate Trump. Two former senior staffers debate the decision
                




                                03:35
                            
Now playing
 - Source:
                CNN Business















Video Ad Feedback



Experts raising alarm over 'crisis' of TikTok's impact on mental health
                




                                03:12
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



How AI is changing the way we work
                




                                01:11
                            
Now playing
 - Source:
                CNN Business
    




See More Videos


















San Francisco
CNN
         — 
    


            Artificial intelligence doesn’t know what to make of Os Keyes. 
    

            The 29-year-old graduate student is dark-haired, tattooed and openly transgender, using the pronouns “they” or “them.” Facial analysis software, however, typically assigns each face it analyzes one of two labels: male or female.
    

            The software literally can’t categorize Keyes correctly.
    

            Yet for Keyes, who studies gender, technology and power at the University of Washington, this technology is not simply software that doesn’t get it right. According to them, it’s also representative of how companies are not thinking through how power is distributed and norms are reinforced by such software. And Keyes — like a number of other experts in AI and in gender issues who spoke with CNN Business — is concerned about how these AI classifications could police, restrict, or otherwise harm transgender people, as well as those who don’t look stereotypically male or female. 
    

            “The people producing this software are producing something that, in a small way, makes people like me miserable and keeps us miserable,” Keyes told CNN Business. 
    


   


            Top tech companies including Microsoft, Amazon and, until recently, IBM, have all invested in technology that can tag pictures of faces fed to their AI systems with binary labels such as “male” and “female,” along with predicting other characteristics, such as whether they are wearing glasses or makeup. A company might, as Amazon suggests in a company blog post, use this gender-prediction feature to analyze footage of shoppers at their stores to learn about how many are men and how many are women. The technology is often offered alongside facial recognition software, though they may be separate systems.
    




Ad Feedback





            But there is a fatal flaw: The way a computer sees gender isn’t always the same way people see it. A growing number of terms for describing one’s gender are becoming common in everyday life. Over a dozen states and Washington, DC, currently or will soon offer a third gender option, “X,” on drivers’ licenses. Companies such as United Airlines now let customers pick the pronoun “X” or the gender-neutral honorific “Mx” when booking a ticket. On Instagram, 9 million posts are tagged as “transgender” and over 7 million as “trans.” Well over 3 million posts are tagged with the hashtag “nonbinary.” Gender diversity is on smartphones, too, as both Apple and Google offer nonbinary emoji.
    



        “We need to push back on the idea that these systems should exist at all, and look at these kind of assumptions—that someone’s body or face or style or hair can kind of detect their interior state or identity.”
    

            Meredith Whittaker, former Google employee and cofounder of NYU's AI Now Institute
        


            As these societal changes proliferate, AI-driven conclusions have become more than a gender identity concern. Some AI experts and members of the transgender community are worried about the potential for serious repercussions if gender recognition, as it exists today, is put to use for more complicated and sensitive tasks, whether it be using AI to help screen job candidates or nab criminal suspects. 


            Keyes is personally afraid it could enable a surveillance system to issue alerts when someone of the “wrong gender” walks into a bathroom or changing room. Indeed, one AI startup told CNN Business that it offers a gender prediction system that could help security guards flag men who are in an all-female dormitory, or vice versa.
    

            “What you’re talking about is deliberately putting trans people, who don’t have the best relationship with law enforcement, on a collision course with law enforcement,” Keyes said. 
    
Enter your email to subscribe to the CNN Five Things Newsletter.close dialogYou give us five minutes, we’ll give you five things you must know for the day.Please enter aboveSign me upBy subscribing you agree to ourprivacy policy.Success! Thanks for Subscribing Get a daily roundup of the top stories you may have missed, unique to your interests. Create your free CNN account to sign-upGet my recommended storiesclose dialog
            Already, AI that scans your face is being used for security applications at concerts, airports, sports arenas and more. These sensitive use cases only raise the stakes for how peoples’ lives could be upended by a few lines of code.
    

            “I think we need to push back on the idea that these systems should exist at all, and look at these kind of assumptions — that someone’s body or face or style or hair can kind of detect their interior state or identity,” said Meredith Whittaker, a former Google employee and cofounder of New York University’s AI Now Institute, which studies social impacts of AI. 
    




Ad Feedback










Os Keyes, a graduate student at the University of Washington, worries that artificial intelligence could put transgender people ""on a collision course with law enforcement"" based on how it categorizes gender.

Dorothy Edwards/Crosscut



        Tech (mostly) doesn’t want to talk about it


            The tech companies are mostly staying quiet on these concerns. Amazon and Microsoft declined to comment for this story. IBM, which appeared to stop offering facial-analysis services in September, also declined to comment. Kairos and Megvii, both AI startups that offer such services, didn’t respond to requests for comment. (Google, which offers image-identification features through its Cloud Vision service, doesn’t appear to offer a gender-labeling feature as part of its facial analysis tools, but the company declined to confirm whether or not this is the case.)
    











            Only one company contacted by CNN Business, New York-based startup Clarifai, was willing to speak. Kyle Martinowich, VP of commercial sales and marketing, said Clarifai built its AI model for predicting gender in response to customer demand. He said those customers now range from bricks-and-mortar stores — who may use Clarifai’s technology to figure out how many women walk down a particular aisle — to the US government — which may use it for gathering information about the types of people walking through airports or into federal buildings.
    

            Clarifai’s system for recognizing gender was trained on a data set of over 30 million images, each of which was annotated as masculine or feminine by three different people. Given how small the trans population is — an estimated 1.4 million adults in the US alone, or 0.6% of the adult population — there’s no training data available to help the company incorporate trans individuals into its gender predictions, according to Martinowich. And he argued it’s not worth the money it would cost to source such data. But if a customer offered to pay the company to make such a product, and brought its own data, he said Clarifai would comply.
    

            Martinowich stressed there are limits to what Clarifai would allow customers to do with its services. For instance, he said that “if the Congolese government called us and said, ‘We want to stop females from entering an all-male building,’ we wouldn’t sell them that. And if we found out, we would cut our service off to them.”
    

            Yet, he also said Clarifai is talking to companies that offer single-sex dormitories about how the startup’s automated gender-identification could be used for safety and security purposes — not to deny someone entry to a building, but to flag a security guard “who would need to make the human determination” about whether a person should be rejected from a building.
    

        How well does the technology work?


            The automated facial analysis systems used by tech companies invariably compute gender as one of two groups — male or female. This may come with a numerical score indicating how confident the computer is that the face it sees looks like one gender or the other.
    




Ad Feedback





            Yet a small but growing area of research indicates there are a number of issues with using AI to spot gender, such as increased error rates when it comes to identifying women of color and concerns about accuracy in general. 
    

            There’s also the question of how well the technology works when it encounters pictures of people that identify themselves differently than the software might. As Morgan Klaus Scheuerman, a graduate student at the University of Colorado Boulder, found in a recent study, facial analysis systems from major tech companies were all markedly worse at determining gender when confronted with images of people who are trans. 
    

            Scheuerman and other researchers built a dataset of 2,450 photos of faces from Instagram that had been labeled by their authors with one of seven different gender-related hashtags such as “transman”, “transwoman”, “man”, “woman” and “nonbinary.” Then they ran the images through facial-analysis services from Microsoft, Amazon, IBM, and Clarifai.
    

            The results? On average, the services classified photos tagged “woman” as “female” 98.3% of the time, and photos tagged “man” as “male” 97.6% of the time. 
    

            When it came to images tagged “transwoman” or “transman”, however, they fared far worse. Photos with the “transwoman” tag were identified as “female” over 87.3% of the time, but photos tagged as “transman” were labeled as “male” just 70.5% of the time. Amazon did most poorly when it came to labeling “transman”-tagged photos as male, which it did just 61.7% of the time.
    



        “Any time you try to codify gender norms, either into laws or into algorithms, you’re bound to have an impact on anyone who’s not Ron Swanson or Barbie.”
    

            Gillian Branstetter, former spokesperson for the National Center for Transgender Equality
        


            Scheuerman said this may indicate that images of trans men are not included in training these AI systems to determine what men look like.
    

            “I think the real danger is this notion of objectivity,” said Scheuerman, a long-haired, facial-piercing-bedecked student who studies gender and technology and has repeatedly been misidentified by these systems. “The idea that because this is trained, this system is super advanced, then it must be making these objective, data-driven decisions that have to be correct.”
    

            It may also be seen as another way in which the technology humans build falls short when it comes to analyzing a more diverse population than may be found on some tech engineering teams — which are often largely male and white. Human biases, such as sexist notions, can seep into machine-learning software in particular, regardless of creators’ intentions.
    

        Even tech companies can’t control how gender ID is used


            As with so many other use cases of artificial intelligence, it can be hard to understand the full impact of the technology’s gender identifications — or misidentifications — on peoples’ lives because the systems frequently operate in a black box. Often the deployment of AI that analyzes faces, whether it’s done by a police department or a department store, is not publicly disclosed, and many countries (including the US) have few laws governing its use.
    

            This concerns Gillian Branstetter, spokesperson for the National Center for Transgender Equality until November, who points out it can impact not just trans people, but anyone. “Any time you try to codify gender norms, either into laws or into algorithms, you’re bound to have an impact on anyone who’s not Ron Swanson or Barbie,” she said.
    

            To make matters more complicated, companies are already using commercially available AI to deduce gender for a number of reasons — and they’re not always using it in the ways the creators intended. 
    

            For instance, Amazon writes in its online Rekognition developer guide that gender predictions from its facial analysis service are “not designed to categorize a person’s gender identity” and shouldn’t be used to do so. (According to the version of the developer guide that Amazon maintains on Github, this kind of language was added in late September; previously, it included no guidance about how the technology was intended to be used.) 
    






Morgan Klaus Scheuerman, a graduate student at the University of Colorado Boulder, ran the same image of his face through facial analysis systems from two different companies. One determined his face was male, while the other identified it as female.

Morgan Klaus Scheuerman



            Yet Woo, an Indian dating app that matches heterosexual couples, uses Rekognition’s gender-identifying feature mainly to help make sure the gender that users state in their profile matches up with the images of themselves they post within the app, said Woo cofounder and CEO Sumesh Menon. 
    

            If there’s a perceived mismatch, a human worker will be notified, and they may contact the user to ask if their gender is incorrectly stated in the app, Menon said. Men, for instance, have accidentally labeled themselves as women in the past, then complained that they were only seeing other men as potential matches.
    

            “It’s not very nuanced; it’s very straightforward,” he said. “But it is super helpful in how we are able to present profiles to the right gender.”
    

            However, it shows that companies selling this AI technology can’t control its deployment once it’s in the hands of customers. (Woo is listed, along with a testimonial from Menon, on an Amazon Rekognition Customers page.)
    

            “That’s in a way proving the point that there’s no way to really ensure your client is using this in an ethical way or a way you intended it to be used,” said Scheuerman.
    

        Nix it, or fix it?


            Despite the ethical concerns, businesses believe there is a clear value in having this gender data — but only if the data itself is accurate. To that end, rather than abandon the feature, some companies are now wrestling with how to improve its predictive capabilities.
    

            Limbik, a startup that calls itself a “data studio for short-form video,” uses AI to analyze videos and predict what people will want to watch. The startup turns to AI from Amazon and IBM to identify gender in videos and analyze all manner of things, such as how frequently men pop up in a certain kind of commercial.
    

            But Limbik CEO Zach Schwitzky said his company has “struggled with binary classification.” Two common issues he encounters with the software include short-haired females being classified as males, and people who appear to be teenagers being misclassified as either gender. In his experience, existing automated gender identification works well for anyone who’s between 25 and 35, but that it’s not as helpful for people who are older or younger.
    


   


            Now, Limbik is building its own software to label gender in images, which to start includes three categories: male, female, and other. Eventually, the company may add more categories, too. Right now, the company is sorting images by hand from sites like Facebook, Twitter, Instagram; these will be used to train an AI model, Schwitzky said.
    

            “I just struggle to think about how to do it in a way that it could be done accurately and effectively,” Schwitzky said.
    

            The research community, too, is wrestling with how to represent gender. Aaron Smith, director of Data Labs at Pew Research Center, said the issue of how to accurately represent gender and gender identity “is a topic of huge interest,” particularly to those who study AI.
    

            Yet whether AI can be built that could accurately identify gender on a broader spectrum, or perhaps consider any characteristics beyond outward appearances, is still largely unknown.
    

            Smith isn’t sure whether technology will eventually be able to suss out a person’s internal identity. He notes that that identity can be “inherently opaque” to AI systems making assessments based on outward appearances.


            For those like Keyes, who are worried about the consequences of using AI to recognize gender, there’s a belief that no amount of tinkering will make these systems work or even worthwhile. 
    

            “You could add a million categories, and unless you’re adding one category per person you’re never going to get to a place where you can work out someone’s gender from their face,” Keyes said.
    






",,"https://media.cnn.com/api/v1/images/stellar/prod/191120155705-20191120-ai-gender-identification-main.jpeg?q=w_3000,h_1688,x_0,y_0,c_fill","['business', 'tech']",,,,,,,,"[{'@context': 'https://schema.org', '@type': 'VideoObject', 'dateModified': '2019-08-24T14:03:57Z', 'uploadDate': '2019-05-01T13:21:50Z', 'embedUrl': 'https://fave.api.cnn.io/v1/fav/?video=business/2019/05/01/artificial-intelligence-changing-work-orig.cnn-business&stellarUri=archive.cms.cnn.com/_components/video-resource/instances/h_6fe67f94109b7aea0f837afe9e3c3da9@published&stellarUdk=rn06132f&customer=cnn&edition=domestic&env=prod', 'duration': 'PT00H01M11S', 'inLanguage': 'en', 'name': 'How AI is changing the way we work', 'headline': 'How AI is changing the way we work', 'description': 'Artificial intelligence has the potential to revolutionize many parts of business, from marketing to supply chain. The number of companies using AI is still relatively low, but early adopters will have the most to gain. ', 'thumbnail': {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/181211153659-artificial-intelligence.jpg?q=w_1600,h_900,x_0,y_0,c_fill', 'sourceOrganization': {'@type': 'Organization', 'name': 'Getty'}, 'width': '1600', 'height': '900', 'creditText': 'Getty Images/Westend61', 'dateCreated': '2018-12-11T20:37:58Z', 'dateModified': '2018-12-11T20:37:58Z'}, 'thumbnailUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/181211153659-artificial-intelligence.jpg?q=w_1600,h_900,x_0,y_0,c_fill', 'mainEntityOfPage': 'https://www.cnn.com/videos/business/2019/05/01/artificial-intelligence-changing-work-orig.cnn-business'}]",,,,en,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article__content'}",,,,False,,,,,,,,,,,,"Artificial intelligence doesn’t know what to make of Os Keyes.  The 29-year-old graduate student is dark-haired, tattooed and openly transgender, using the pronouns “they” or “them.” Facial analysis software, however, typically assigns each face it analyzes one of two labels: male or female. The software literally can’t categorize Keyes correctly. Yet for Keyes, who studies gender, technology and power at the University of Washington, this technology is not simply software that doesn’t get it right. According to them, it’s also representative of how companies are not thinking through how power is distributed and norms are reinforced by such software. And Keyes — like a number of other experts in AI and in gender issues who spoke with CNN Business — is concerned about how these AI classifications could police, restrict, or otherwise harm transgender people, as well as those who don’t look stereotypically male or female.  “The people producing this software are producing something that, in a small way, makes people like me miserable and keeps us miserable,” Keyes told CNN Business.  Top tech companies including Microsoft, Amazon and, until recently, IBM, have all invested in technology that can tag pictures of faces fed to their AI systems with binary labels such as “male” and “female,” along with predicting other characteristics, such as whether they are wearing glasses or makeup. A company might, as Amazon suggests in a company blog post, use this gender-prediction feature to analyze footage of shoppers at their stores to learn about how many are men and how many are women. The technology is often offered alongside facial recognition software, though they may be separate systems. But there is a fatal flaw: The way a computer sees gender isn’t always the same way people see it. A growing number of terms for describing one’s gender are becoming common in everyday life. Over a dozen states and Washington, DC, currently or will soon offer a third gender option, “X,” on drivers’ licenses. Companies such as United Airlines now let customers pick the pronoun “X” or the gender-neutral honorific “Mx” when booking a ticket. On Instagram, 9 million posts are tagged as “transgender” and over 7 million as “trans.” Well over 3 million posts are tagged with the hashtag “nonbinary.” Gender diversity is on smartphones, too, as both Apple and Google offer nonbinary emoji. As these societal changes proliferate, AI-driven conclusions have become more than a gender identity concern. Some AI experts and members of the transgender community are worried about the potential for serious repercussions if gender recognition, as it exists today, is put to use for more complicated and sensitive tasks, whether it be using AI to help screen job candidates or nab criminal suspects.  Keyes is personally afraid it could enable a surveillance system to issue alerts when someone of the “wrong gender” walks into a bathroom or changing room. Indeed, one AI startup told CNN Business that it offers a gender prediction system that could help security guards flag men who are in an all-female dormitory, or vice versa. “What you’re talking about is deliberately putting trans people, who don’t have the best relationship with law enforcement, on a collision course with law enforcement,” Keyes said.  Already, AI that scans your face is being used for security applications at concerts, airports, sports arenas and more. These sensitive use cases only raise the stakes for how peoples’ lives could be upended by a few lines of code. “I think we need to push back on the idea that these systems should exist at all, and look at these kind of assumptions — that someone’s body or face or style or hair can kind of detect their interior state or identity,” said Meredith Whittaker, a former Google employee and cofounder of New York University’s AI Now Institute, which studies social impacts of AI.   Tech (mostly) doesn’t want to talk about it The tech companies are mostly staying quiet on these concerns. Amazon and Microsoft declined to comment for this story. IBM, which appeared to stop offering facial-analysis services in September, also declined to comment. Kairos and Megvii, both AI startups that offer such services, didn’t respond to requests for comment. (Google, which offers image-identification features through its Cloud Vision service, doesn’t appear to offer a gender-labeling feature as part of its facial analysis tools, but the company declined to confirm whether or not this is the case.) Only one company contacted by CNN Business, New York-based startup Clarifai, was willing to speak. Kyle Martinowich, VP of commercial sales and marketing, said Clarifai built its AI model for predicting gender in response to customer demand. He said those customers now range from bricks-and-mortar stores — who may use Clarifai’s technology to figure out how many women walk down a particular aisle — to the US government — which may use it for gathering information about the types of people walking through airports or into federal buildings. Clarifai’s system for recognizing gender was trained on a data set of over 30 million images, each of which was annotated as masculine or feminine by three different people. Given how small the trans population is — an estimated 1.4 million adults in the US alone, or 0.6% of the adult population — there’s no training data available to help the company incorporate trans individuals into its gender predictions, according to Martinowich. And he argued it’s not worth the money it would cost to source such data. But if a customer offered to pay the company to make such a product, and brought its own data, he said Clarifai would comply. Martinowich stressed there are limits to what Clarifai would allow customers to do with its services. For instance, he said that “if the Congolese government called us and said, ‘We want to stop females from entering an all-male building,’ we wouldn’t sell them that. And if we found out, we would cut our service off to them.” Yet, he also said Clarifai is talking to companies that offer single-sex dormitories about how the startup’s automated gender-identification could be used for safety and security purposes — not to deny someone entry to a building, but to flag a security guard “who would need to make the human determination” about whether a person should be rejected from a building. How well does the technology work? The automated facial analysis systems used by tech companies invariably compute gender as one of two groups — male or female. This may come with a numerical score indicating how confident the computer is that the face it sees looks like one gender or the other. Yet a small but growing area of research indicates there are a number of issues with using AI to spot gender, such as increased error rates when it comes to identifying women of color and concerns about accuracy in general.  There’s also the question of how well the technology works when it encounters pictures of people that identify themselves differently than the software might. As Morgan Klaus Scheuerman, a graduate student at the University of Colorado Boulder, found in a recent study, facial analysis systems from major tech companies were all markedly worse at determining gender when confronted with images of people who are trans.  Scheuerman and other researchers built a dataset of 2,450 photos of faces from Instagram that had been labeled by their authors with one of seven different gender-related hashtags such as “transman”, “transwoman”, “man”, “woman” and “nonbinary.” Then they ran the images through facial-analysis services from Microsoft, Amazon, IBM, and Clarifai. The results? On average, the services classified photos tagged “woman” as “female” 98.3% of the time, and photos tagged “man” as “male” 97.6% of the time.  When it came to images tagged “transwoman” or “transman”, however, they fared far worse. Photos with the “transwoman” tag were identified as “female” over 87.3% of the time, but photos tagged as “transman” were labeled as “male” just 70.5% of the time. Amazon did most poorly when it came to labeling “transman”-tagged photos as male, which it did just 61.7% of the time. Scheuerman said this may indicate that images of trans men are not included in training these AI systems to determine what men look like. “I think the real danger is this notion of objectivity,” said Scheuerman, a long-haired, facial-piercing-bedecked student who studies gender and technology and has repeatedly been misidentified by these systems. “The idea that because this is trained, this system is super advanced, then it must be making these objective, data-driven decisions that have to be correct.” It may also be seen as another way in which the technology humans build falls short when it comes to analyzing a more diverse population than may be found on some tech engineering teams — which are often largely male and white. Human biases, such as sexist notions, can seep into machine-learning software in particular, regardless of creators’ intentions.  Even tech companies can’t control how gender ID is used As with so many other use cases of artificial intelligence, it can be hard to understand the full impact of the technology’s gender identifications — or misidentifications — on peoples’ lives because the systems frequently operate in a black box. Often the deployment of AI that analyzes faces, whether it’s done by a police department or a department store, is not publicly disclosed, and many countries (including the US) have few laws governing its use. This concerns Gillian Branstetter, spokesperson for the National Center for Transgender Equality until November, who points out it can impact not just trans people, but anyone. “Any time you try to codify gender norms, either into laws or into algorithms, you’re bound to have an impact on anyone who’s not Ron Swanson or Barbie,” she said. To make matters more complicated, companies are already using commercially available AI to deduce gender for a number of reasons — and they’re not always using it in the ways the creators intended.  For instance, Amazon writes in its online Rekognition developer guide that gender predictions from its facial analysis service are “not designed to categorize a person’s gender identity” and shouldn’t be used to do so. (According to the version of the developer guide that Amazon maintains on Github, this kind of language was added in late September; previously, it included no guidance about how the technology was intended to be used.)  Yet Woo, an Indian dating app that matches heterosexual couples, uses Rekognition’s gender-identifying feature mainly to help make sure the gender that users state in their profile matches up with the images of themselves they post within the app, said Woo cofounder and CEO Sumesh Menon.  If there’s a perceived mismatch, a human worker will be notified, and they may contact the user to ask if their gender is incorrectly stated in the app, Menon said. Men, for instance, have accidentally labeled themselves as women in the past, then complained that they were only seeing other men as potential matches. “It’s not very nuanced; it’s very straightforward,” he said. “But it is super helpful in how we are able to present profiles to the right gender.” However, it shows that companies selling this AI technology can’t control its deployment once it’s in the hands of customers. (Woo is listed, along with a testimonial from Menon, on an Amazon Rekognition Customers page.) “That’s in a way proving the point that there’s no way to really ensure your client is using this in an ethical way or a way you intended it to be used,” said Scheuerman. Nix it, or fix it? Despite the ethical concerns, businesses believe there is a clear value in having this gender data — but only if the data itself is accurate. To that end, rather than abandon the feature, some companies are now wrestling with how to improve its predictive capabilities. Limbik, a startup that calls itself a “data studio for short-form video,” uses AI to analyze videos and predict what people will want to watch. The startup turns to AI from Amazon and IBM to identify gender in videos and analyze all manner of things, such as how frequently men pop up in a certain kind of commercial. But Limbik CEO Zach Schwitzky said his company has “struggled with binary classification.” Two common issues he encounters with the software include short-haired females being classified as males, and people who appear to be teenagers being misclassified as either gender. In his experience, existing automated gender identification works well for anyone who’s between 25 and 35, but that it’s not as helpful for people who are older or younger. Now, Limbik is building its own software to label gender in images, which to start includes three categories: male, female, and other. Eventually, the company may add more categories, too. Right now, the company is sorting images by hand from sites like Facebook, Twitter, Instagram; these will be used to train an AI model, Schwitzky said. “I just struggle to think about how to do it in a way that it could be done accurately and effectively,” Schwitzky said. The research community, too, is wrestling with how to represent gender. Aaron Smith, director of Data Labs at Pew Research Center, said the issue of how to accurately represent gender and gender identity “is a topic of huge interest,” particularly to those who study AI. Yet whether AI can be built that could accurately identify gender on a broader spectrum, or perhaps consider any characteristics beyond outward appearances, is still largely unknown. Smith isn’t sure whether technology will eventually be able to suss out a person’s internal identity. He notes that that identity can be “inherently opaque” to AI systems making assessments based on outward appearances. For those like Keyes, who are worried about the consequences of using AI to recognize gender, there’s a belief that no amount of tinkering will make these systems work or even worthwhile.  “You could add a million categories, and unless you’re adding one category per person you’re never going to get to a place where you can work out someone’s gender from their face,” Keyes said.",,,,,,,,,,,P0Y0M0DT0H10M18S,2319.0,,,,,,,,,
https://news.google.com/rss/articles/CBMikAFodHRwczovL29nbGV0cmVlLmNvbS9pbnNpZ2h0cy1yZXNvdXJjZXMvYmxvZy1wb3N0cy90aGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdmlkZW8taW50ZXJ2aWV3LWFjdC1wcml2YWN5LWltcGxpY2F0aW9ucy1vZi1pbGxpbm9pc3MtYWktc3RhdHV0ZS_SAQA?oc=5,The Artificial Intelligence Video Interview Act: Privacy Implications of Illinois's AI Statute - Ogletree Deakins,2019-11-22,Ogletree Deakins,https://ogletree.com,,,"It’s time for employers to start preparing for legislation recently signed into law in Illinois, the Artificial Intelligence Video Interview Act. The new law, which takes effect on January 1, 2020, regulates Illinois employers’ use of artificial intelligence (AI) in the interview and hiring process.",,https://schema.org,,,,,,,,,,,,"
It’s time for employers to start preparing for legislation recently signed into law in Illinois, the Artificial Intelligence Video Interview Act. The new law, which takes effect on January 1, 2020, regulates Illinois employers’ use of artificial intelligence (AI) in the interview and hiring process.
Under the AI Video Interview Act, employers that record video interviews and use AI technology to analyze applicants’ suitability for employment must:

inform applicants that AI technology may be used to evaluate their interviews;
provide applicants with a written explanation of the technology’s mechanics, including the traits that will be reviewed and analyzed by AI and the characteristics the AI program uses to evaluate applicants; and
acquire applicants’ prior consent to be assessed by AI technology.

Employers that conduct such interviews may not distribute videos to other parties, except as necessary to obtain expert assistance in evaluating a candidate’s fitness for a particular position. In addition, an employer has only 30 days to destroy all video copies of the interview if an applicant seeks such destruction.
This law highlights a myriad of privacy concerns for employers evaluating the costs and benefits of incorporating AI technology into their hiring practices. As a preliminary matter, employers should consider designing, maintaining, and testing their security systems to ensure that they can (1) comply with their 30-day destruction obligation and (2) prevent unauthorized third parties from acquiring interview videos.
Passage of the Act further highlights how companies may need to implement effective breach-detection processes, act in a timely manner upon receipt of system alerts and warnings, and maintain industry-standard data security measures to prevent unauthorized access to confidential information. Employers with inadequate security precautions may be liable for the negligent distribution of interview videos. In an era when recordings can be reproduced in seconds, potential security breaches may make it difficult—if not impossible—for employers to ensure that they have adequately confirmed the destruction of all video copies.
The potential for information security breaches concerning interview videos poses a host of privacy concerns. For instance, third parties illegally acquiring interview videos could use voice and facial recognition software to mine identifier data. Voice and facial recognition software uses videos to detect and transform voice and facial images into digital data, and data of this type resides in large databases.
Progressively more governmental and other private entities are using this technology as a sophisticated alternative to established biometric measurements, such as fingerprints. This, in turn, creates an increased fear of function creep, or the use of technology outside its intended purpose, and employers may want to take prophylactic measures to protect video interviews and avoid the liabilities associated with having such data land in the wrong hands.
Employers that currently use (or plan to use) AI to analyze applicants should consider preparing the documentation and consents required by the AI Video Interview Act to ensure compliance with the Act’s January 1, 2020, effective date. In addition, those employers may want to provide employees who have the authority to hire or interview applicants with training and written guidance to ensure compliance with the statute’s mandates.
Balancing the above-described risks of using such information against the benefits of AI technology, which can help employers quickly evaluate applicants, make more informed hiring decisions, and potentially reduce attrition and terminations, will be a very company-specific calculation. Those who decide to rely on technology will need to keep current with new legislation such as this statute, protect their applicants’ privacy rights, and prevent technology use outside its intended function. Because Illinois increasingly follows California in introducing progressive employment legislation, employers may wish to contact their state representatives and senators to provide feedback and recommended changes to pending legislation.

",,,,"[{'@type': 'WebPage', '@id': 'https://ogletree.com/insights-resources/blog-posts/the-artificial-intelligence-video-interview-act-privacy-implications-of-illinoiss-ai-statute/', 'url': 'https://ogletree.com/insights-resources/blog-posts/the-artificial-intelligence-video-interview-act-privacy-implications-of-illinoiss-ai-statute/', 'name': 'The Artificial Intelligence Video Interview Act: Privacy Implications of Illinois’s AI Statute - Ogletree', 'isPartOf': {'@id': 'https://ogletree.stage.sevaa.site/#website'}, 'primaryImageOfPage': {'@id': 'https://ogletree.com/insights-resources/blog-posts/the-artificial-intelligence-video-interview-act-privacy-implications-of-illinoiss-ai-statute/#primaryimage'}, 'image': {'@id': 'https://ogletree.com/insights-resources/blog-posts/the-artificial-intelligence-video-interview-act-privacy-implications-of-illinoiss-ai-statute/#primaryimage'}, 'thumbnailUrl': 'https://ogletree.com/app/uploads/2023/04/illinois.png', 'datePublished': '2019-11-22T00:00:00+00:00', 'dateModified': '2023-10-06T13:58:48+00:00', 'breadcrumb': {'@id': 'https://ogletree.com/insights-resources/blog-posts/the-artificial-intelligence-video-interview-act-privacy-implications-of-illinoiss-ai-statute/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://ogletree.com/insights-resources/blog-posts/the-artificial-intelligence-video-interview-act-privacy-implications-of-illinoiss-ai-statute/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://ogletree.com/insights-resources/blog-posts/the-artificial-intelligence-video-interview-act-privacy-implications-of-illinoiss-ai-statute/#primaryimage', 'url': 'https://ogletree.com/app/uploads/2023/04/illinois.png', 'contentUrl': 'https://ogletree.com/app/uploads/2023/04/illinois.png', 'width': 2000, 'height': 1200, 'caption': 'Illinois State Flag'}, {'@type': 'BreadcrumbList', '@id': 'https://ogletree.com/insights-resources/blog-posts/the-artificial-intelligence-video-interview-act-privacy-implications-of-illinoiss-ai-statute/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://ogletree.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Blog Posts', 'item': 'https://ogletree.com/insights-resources/blog-posts/'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Artificial Intelligence Video Interview Act: Privacy Implications of Illinois’s AI Statute'}]}, {'@type': 'WebSite', '@id': 'https://ogletree.stage.sevaa.site/#website', 'url': 'https://ogletree.stage.sevaa.site/', 'name': 'Ogletree', 'description': 'Employers and lawyers. Working Together', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://ogletree.stage.sevaa.site/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMikAFodHRwczovL2luZGlhbmV4cHJlc3MuY29tL2FydGljbGUvdGVjaG5vbG9neS90ZWNoLW5ld3MtdGVjaG5vbG9neS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS13aWxsLWFzc2lzdC1odW1hbnMtdG8tZG8td29yay1iZXR0ZXItZGVsb2l0dGUtNjEzNTUwNy_SAZUBaHR0cHM6Ly9pbmRpYW5leHByZXNzLmNvbS9hcnRpY2xlL3RlY2hub2xvZ3kvdGVjaC1uZXdzLXRlY2hub2xvZ3kvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utd2lsbC1hc3Npc3QtaHVtYW5zLXRvLWRvLXdvcmstYmV0dGVyLWRlbG9pdHRlLTYxMzU1MDcvbGl0ZS8?oc=5,Artificial Intelligence will assist humans to do work better: Deloitte - The Indian Express,2019-11-25,The Indian Express,https://indianexpress.com,"According to a new report by Deloitte and the Confederation of Indian Industry (CII), AI could prove to be most beneficial in areas like agriculture, manufacturing, education and health care services in India.","['Artificial Intelligence', ' AI in India', ' AI use case in India', ' What is artificial Intelligence', ' AI report Deloitte', ' Deloitte Report on AI in india']","According to a new report by Deloitte and the Confederation of Indian Industry (CII), AI could prove to be most beneficial in areas like agriculture, manufacturing, education and health care services in India. ","According to a new report by Deloitte and the Confederation of Indian Industry (CII), AI could prove to be most beneficial in areas like agriculture, manufacturing, education and health care services in India. ",https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://indianexpress.com/article/technology/tech-news-technology/artificial-intelligence-will-assist-humans-to-do-work-better-deloitte-6135507/'}",Artificial Intelligence will assist humans to do work better: Deloitte,https://images.indianexpress.com/2019/11/artificial-intelligence.jpg,"[{'@type': 'Person', 'name': 'Shruti Dhapola', 'url': 'https://indianexpress.com/profile/author/shruti-dhapola/'}]",2019-11-25T10:03:04+05:30,2019-11-25T10:03:04+05:30,"{'@type': 'NewsMediaOrganization', 'name': 'The Indian Express', 'url': 'https://indianexpress.com/', 'foundingDate': '1932', 'ethicsPolicy': 'https://indianexpress.com/privacy-policy/', 'SameAs': ['https://www.facebook.com/indianexpress', 'https://twitter.com/IndianExpress', 'https://www.youtube.com/@indianexpress', 'https://www.instagram.com/indianexpress/', 'https://www.linkedin.com/company/indian-express/'], 'logo': {'@type': 'ImageObject', 'url': 'https://images.indianexpress.com/2019/11/ienewlogo3_new.png', 'width': '600', 'height': '60'}}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://indianexpress.com/', 'name': 'News'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://indianexpress.com/section/technology/', 'name': 'Technology'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://indianexpress.com/section/technology/tech-news-technology/', 'name': 'Tech'}}]",,,,"['Home', 'Subscribe', 'India News', 'Cities', 'Videos', 'Audio', 'Explained', 'Education', 'Political Pulse', 'Opinion', 'Entertainment', 'Investigations', 'Lifestyle', 'Technology', 'Sports', 'Express Premium', 'Latest News', 'World News', 'Trending', 'Photos', 'Elections 2023', 'Web Stories', 'Bollywood', 'Cricket', 'Science', 'Business', 'Horoscope', 'Delhi News', 'Mumbai News', 'Hyderabad News', 'Bengaluru News', 'What Is', 'When Is', 'Who Is', 'How To', ""Today's Paper"", 'Brand Solutions']",,technology,,https://indianexpress.com/article/technology/tech-news-technology/artificial-intelligence-will-assist-humans-to-do-work-better-deloitte-6135507/,"{'@type': 'SearchAction', 'target': 'https://indianexpress.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}","{'@type': 'ImageObject', 'url': 'https://indianexpress.com/wp-content/themes/indianexpress/images/indian-express-logo-n.svg', 'inLanguage': 'en-US', 'width': 600, 'height': 60, 'caption': 'The Indian Express'}","['https://www.facebook.com/indianexpress', 'https://twitter.com/IndianExpress', 'https://www.linkedin.com/company/indian-express', 'https://www.instagram.com/indianexpress/', 'https://www.youtube.com/channel/UCJEDFSxHHOW1PpBccdSxOTA']",,,,,,,en,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.ie-premium-content-block', 'video': [], 'audio': []}",,,2024.0,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'IE Premium', 'productID': 'indianexpress.com:showcase'}",,,,1932.0,The Indian Express,,"{'@type': 'PostalAddress', 'streetAddress': 'Express Building, B-1/B, Sector-10', 'addressLocality': 'Noida', 'addressRegion': 'India', 'postalCode': '201301'}","{'@type': 'SpeakableSpecification', 'xpath': ['//title', ""//meta[@name='description']/@content""]}",,"{'@type': 'AdministrativeArea', 'name': 'Noida, India'}","“This (AI) is about augmenting human intelligence. When you step back and look at AI, yes there is hype, it will replace all jobs. We say look that's not the right way to approach it. The correct way to say is that this set of artificial intelligence technologies will augment and assist humans to do their work better,” Ashvin Vellody, Partner, Deloitte India told indianexpress.com during an interaction. According to a new report by Deloitte and the Confederation of Indian Industry (CII), AI could prove to be most beneficial in areas like agriculture, manufacturing, education and health care services in India. Regarding AI and the ‘jobs’ crisis that often comes up, he said nothing is further from the truth. “AI will free the person to explore other upscaling areas that he or she might be interested in. It'll allow mundane activity to be taken away,” he said pointing out that in many cases they are already seeing examples of dangerous activity being handed over to machines who can do the job better. “It is activities, not the job that gets outsourced. We have seen in energy mining. The trends from both private sector and public sector organisations working in space show active use of AI. To inspect level of this natural resources in different parts of the ground, AI is being used, ” he pointed out. Vellody says one needs to take a more holistic view when viewing the growing implementation of AI in enterprises across India. “In manufacturing, whether it is large scale production of goods, we see a substantial input of AI, ML. One way is to manage demand, to know how many units to produce, what not to produce. Then the other part is to understand your customers demand, and the customers better,” he said. But he also notes that there are several challenges, including one where senior leadership in organisations will have to embrace AI. “Many times what is happening is these technologies suffer from what I call being in perpetual proof of concept (POC). We found that a large number of projects stop at the POC level. Second is that the data sets have to be good to make the use cases possible,” he said. In his view, India has a unique potential for data sets to solve different problems, but notes that privacy issues and anonymisation of data cannot be ignored. He acknowledges there is hesitation and lack of clarity around privacy and AI, which pose a challenge. According to the report, AI can also impact agriculture in India by helping the sector with accurate climate patterns, more sustainable irrigation and water management, which will be crucial in light of the growing water crisis in the country. But there are challenges to AI implementation as the report notes. Cultural barriers, bridging the skills gap and the need of good quality data sets for reliable AI, along with the relatively higher costs of AI computation still need to be solved. Further the lack of transparency in decision making and poor accountability structures along potential bias and discrimination in AI decision add to the challenges.",,,"{'@type': 'ContactPoint', 'telephone': '+91-120-6651500', 'areaServed': 'IN', 'availableLanguage': 'English', 'hoursAvailable': {'opens': '09:30', 'closes': '18:30'}}",,,,,,,,,,https://schema.org/NewsMediaOrganization,News,2024-07-16,"{'type': 'EntryPoint', 'urlTemplate': 'https://indexpress.page.link/shareDL'}",JOURNALISM OF COURAGE,"{'@type': 'Person', 'name': 'Ramnath Goenka', 'url': 'https://indianexpress.com/ramnath-goenka/', 'sameAs': 'https://indianexpress.com/ramnath-goenka/'}","{'@type': 'QuantitativeValue', 'value': 153}","{'@type': 'ImageObject', 'url': 'https://images.indianexpress.com/2019/11/artificial-intelligence.jpg', 'caption': 'AI can reduce hiring lag in an organization through remote communication.', 'description': 'Advent of AI in recruitment', 'width': 1200, 'height': 675}",
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vZW1lcmouY29tL2V0aGljcy1hbmQtcmVndWxhdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1nb3Zlcm5tZW50LXN1cnZlaWxsYW5jZS_SAQA?oc=5,Artificial Intelligence for Government Surveillance – 7 Unique Use-Cases - Emerj,2019-11-24,Emerj,https://emerj.com,"AI surveillance technology is a lot more than mounted security cameras. From robotic birds to trackable wristbands, from the US to China, explore 7 unique...",,"AI surveillance technology is a lot more than mounted security cameras. From robotic birds to trackable wristbands, from the US to China, explore 7 unique...",,https://schema.org,Article,https://emerj.com/ethics-and-regulatory/artificial-intelligence-government-surveillance,Artificial Intelligence for Government Surveillance &#8211; 7 Unique Use-Cases,https://emerj.com/wp-content/uploads/2019/05/ai-surveillance-690x345.png,Daniel Faggella,2019-05-22,2019-11-24,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",,,," SecurityGovernment Artificial Intelligence for Government Surveillance – 7 Unique Use-Cases Daniel FaggellaLast updated on November 24, 2019  Last updated on November 24, 2019, published by Daniel Faggella Daniel Faggella is Head of Research at Emerj. Called upon by the United Nations, World Bank, INTERPOL, and leading enterprises, Daniel is a globally sought-after expert on the competitive strategy implications of AI for business and government leaders. Share to: LinkedIn Twitter Facebook Email  It isn’t surprising that many Google search results for “artificial intelligence for government surveillance” involve China. The consensus is that China is either catching up or overtaking the US in AI research, and it’s quite open about using AI for government surveillance of its own people.  While it might be the most aggressive surveillance state on earth – China isn’t the only nation to deploy AI for surveillance purposes – and in this article we set out to explore the new and unique uses of domestic surveillance and spying applications of AI around the world. Emerj CEO Daniel Faggella presenting Emerj research and predictions about AI for law enforcement and surveillance at INTERPOL’s innovation center in Singapore, 2018 (Read the full article) The US has a long history with government surveillance, starting in 1928 with wiretapping. Many people still remember the startling revelations in 2013 of National Security Agency whistleblower Edward Snowden about exactly what the US government is compelling phone companies to do with their personal calls. Government surveillance is also a growing concern in Russia, the UK and Australia as well as the UAE. This is not to say that government surveillance is always a bad thing. As with most technology, AI has its pros and cons, and with the correct application, the benefits (say, for crime prevention) could be argued to outweigh the costs. However, AI technology is often challenging to regulate, so misuse and abuse is a real concern. Video monitoring is the most prevalent and well-known use of AI-based government surveillance. Whether it is through closed circuit television (CCTV) or unmanned drone, many people believe that someone is watching at all times, especially in public areas and secure areas such as airports.  Today’s surveillance technologies take many forms – well beyond the stationary security camera in a mall or airport. In this article, we explore seven specific, unique AI surveillance use-cases around the world: Robotic birds Smart glasses AI-enabled body cameras EEG headbands Uniforms Wristbands Social Credit Score We’ll begin by exploring one of the more unique use-cases on our list: Robotic Birds Though extensive of discussion on robotics and drones as an instrument for covert civilian surveillance is available elsewhere, some tactics to bring this about is worth mentioning for sheer cleverness.One of these is drones that look and move like birds, but take much more interest in the people below them than real ones will ever do. Birds are everywhere, and most people do not give them much attention. This fact has brought about an interest in using bird forms to carry out surveillance. Robotic birds capable of autonomy and staying in the air for more than a few minutes have been around since 2011 with Festo’s Smartbird, which looks and moves like a herring gill.  However, the first iteration of robotic birds for video surveillance is doves rather than gulls. Appropriately called the Dove program, a team of top scientists at the Northwestern Polytechnical University, Xian led by Song Bifeng developed bird drones for deployment in several areas in China, particularly Xinjiang. While the program is still in its early stages, Dove team member Yang Wenqingsays she believes it “has some unique advantages to meet the demand for drones in the military and civilian sectors.” Of particular benefit is the ability of these drones to go about largely undetected, even by radar. Here is an illustration of the Dove itself: Source: SCMP SCMP hosts a one-minute video showing this robotic dove in flight. The US Army reportedly invested in bird-like drone technology in 2013, purchasing 30 microdrones called Maveric fromPrioria Robotics. However, these are much chunkier than the Chinese Dove, and one company claimed it is a substandard product overall.  Whatever the case, there is no indication that the US has progressed any further in bird-like technology for domestic video surveillance. The nearest the US has come to this type of aerial drone surveillance was during an NYC new year’s celebration – and the effort was foiled by the rain. Smart Glasses Another way the government might be monitoring its citizens is through “smart” glasses equipped with facial recognition software to scan faces and match them to persons of interest in second. Developed byXloong, these augmented reality (AR) eyewear (such as the AR Boss Smart Glasses Techlens T2) provide law enforcement with a quick way to patrol a large number of people. With China’s plans to create adatabase of its 1.3 billion citizens for facial recognition, it is definitely a good match.  Below is the sports version of the Xloong AR glasses:  According to this article, expanded use of such smart glasses to Southeast Asian countries and the US is in the works. However, such technology is already available in the US. In fact, the company LLVision that supplied the AR product GLXSS to Chinese law enforcement is remarkably similar to the commercially less-than-successful Google Glass, which incidentally is making a comeback as an enterprise rather than consumer product. AI-enabled Body Cameras Wearable surveillance tech is also making its debut in Malaysia through body cameras. The Auxiliary Force Sdn. Bhd. (AFSB) struck a deal with YITU Technology to supply them with video systems using facial recognition to look for criminals. AFSB CEO Dato’ Rosmadi Bin Ghazali stated: “This is a significant step forward for us as we leverage artificial intelligence to increase public safety and security.” Unlike China, however, the AFSB facial recognition system analyzes captured footage rather than live feeds, although the AFSB plans to expand it in that direction.  At leastone law enforcement agency in the US is using Amazon’s facial recognition systemRekognition in a similar, though less obtrusive way. Instead of body cameras, the police use the system to collate videos and images online, dash cams, and from other sources to find matches to a database of persons of interest. While apparently very useful in identifying criminates, concerns aboutaccuracy and racial profiling continue to restrict its widespread use in law enforcement. The Washington Post hosts a 6:11-minute video on law enforcement uses of the Rekognition system, and the resulting questions about privacy that they stir up. The Wall Street Journal summarizes China’s growing us of surveillance technology in the short video below:  China is also beginning to employ facial recognition and computer vision in classrooms, inuring students to surveillance at a young age, and – purportedly – encouraging greater concentration and focus in the classroom:  For better or for worse, artificial intelligence applications for government surveillance are likely to proliferate as these use-cases (in airports, schools, shopping malls) gain traction and prove valuable from an economic or security perspective. EEG Headbands An interesting development in AI wearable tech is brainwave monitoring. North America boasts dozens of electroencephalography (EEG) startups – including brands like Muse, Thync, and others. Most of these brands claim to aide in some kind of mood control (aiding with focus or meditation, for example), while others serve as open platforms for brain-computer interface experiments. The Chinese government sanctioned the use of brain monitoring equipment on employees to capture data on emotions and other brain activities. Employees wear sensor-equipped caps and special cameras developed by Deayea Technology Co., Ltd.. Dubbed “emotional surveillance,” the project targets train operators, military personnel, production workers in some sectors, and perhaps schoolchildren in the future, to increase productivity and efficiency. US-based company BrainCo plans to provide headband brain-reading units called Focus for a pilot study in China. The idea is to help teachers identify students that might need extra help. Below is a 3:21-minute video demonstrating how the Focus system works:  Uniforms It would be difficult to decide if this is as worrisome when it comes to extreme control as “intelligent uniforms” students at 10 schools in Guizhou Province have to wear. Chips integrated into these uniforms track and identify students, enabling parents, teachers, and other figures of authority to know where they are at all times. Yet China is not alone in using AI to monitor schoolchildren. Federally funded schools have to install Safety Management Platforms (SMPs) – such as Securly, and GoGuardian – in school computers to monitor student activity.  These SMPs use natural language processing to scan the millions of words typed by students into these computer to look for undesirable acts (bullying) or harmful behavior (self harm).  A school in France is using Nestor software for two online classes to see if students are paying attention to a lecture. Below is a 1-minute promotion video for GoGuardian, highlighting its value proposition for teachers, and reviewing its basic features:  Wristbands Students are not the only targeted population segment under scrutiny, however. Prison inmates expect to be under constant surveillance, such as cameras covering most of the prison, including cells. However, Yancheng Prison in Hong Kong is apparently prepared to go a bit farther, including robotic arms checking waste matter for drug stashes (such at pills wrapped in plastic), and wristbands. According to SCMP: Woo said other new technology, such as a wristband to be tested at Lo Wu Correctional Institution, would help officers prevent suicides. … The wristband, which is similar to fitness products sold on the market, would allow officers to monitor an inmate’s heart rate and whereabouts in real time. “If the pulse is irregular, staff will be alerted,” [Commissioner of Correctional Services Danny Woo Ying-ming] said. Should an inmate try to remove the wristband, the alarm will also be triggered. Below is a one-minute video illustrating how camera surveillance might work in Yancheng Prison – according to a report by the South China Morning Post:  It isn’t entirely clear whether the wristbands of waste-inspecting robots leverage artificial intelligence at this time – but the technologies could certainly be combined with computer vision to create a tighter perspective on Artificial Intelligence for “Social Credit” Scoring There is an episode in the Twilight Zone-esque British television series Black Mirror entitled “Nosedive” that explored a world where social media, eye implants, and a star rating system dictates each person’s place in that world. A high star rating system means more privileges, while a low star rating means becoming a virtual outcast. While the basis of the premise is on peer acceptance and largely subjective and arbitrary, an eerily similar scenario is in the making with the Social Credit Score program – a national reputation system being developed by the Chinese government. The premise behind the program is basic governance: Punish the bad, reward the good. The idea is to motivate Chinese citizens to be good members of society so they can enjoy the benefits. The national rollout of the program will be in 2020, but dozens of pilot programs are gathering data to make it more responsive. The problem with this system is not the bad things that can happen to people with low scores, but the sources of data used to separate the good from the bad. As might be expected, the data from social media and other online activities would definitely be part of the mix. Such a comprehensive sweep of each person’s private and personal information is certainly a disturbing thought, especially in the hands of an openly authoritarian state. Add to that the fact that there is no transparency to the algorithms used to determine ranking. In a very real sense, the government can control a person’s socioeconomic success or failure. France 24 put together a 4-minute video exploring the social scoring system from the perspective of Chinese citizens:  Its hard to keep 1.4 billion people in line, and China’s social score (combined with a more obedient Confucian culture) might help the ruling party do just that.  Some experts – including Emerj founder Daniel Faggella – believe that China’s surveillance technologies will lift AI-based monitoring to a level of new “normal” – potentially spreading the more invasive use-cases of these technologies to Western nations. European countries, including the UK, might consider implementing a similar program for its citizens, although survey results indicate a majority (78%) or participants thought it was a bad idea. The growing awareness of China’s scoring system has prompted mostly a dystopian sentiment from Western citizens and news outlets. Concluding Thoughts on AI for Government Surveillance Government surveillance is integral to national security. It is necessary to ensure the safety and security of its citizens from internal and external factors. However, it is not always easy to discern the fine line between security and control. That said, there is also a fine line that separates advocacy from paranoia. The key is achieving the right balance in either case, depending on the context. China features quite prominently in many of current applications of artificial intelligence for government surveillance, and frequently in a negative light. However, it is important for privacy advocates to understand that the cultural and ideological differences between China and Western countries are huge. China’s policies on privacy and personal freedom work for them, and condemning them from a Western point of view is ineffectual as well as offensive. There is even theidea that when it comes to AI for government surveillance and data protection, China has a better understanding of the best way to engage with AI. Whether this is true or not, the fact is China is handling the disruptive influence of AI technology in a much more proactive manner than other countries, especially the US. As Daniel Faggella points out, “The West needs a new strategy to both maintain it’s own values, and compete on the international stage. The default is not good enough if the West wants to ensure its values and prosperity continue.” While the US and other countries might eventually benefit from its more cautious and circumspect approach to AI, China is currently reaping the economic benefits from the gaps left in the consumption and implementation of AI for government surveillance. It may be the case that squashing individual rights and freedoms can be done in a way the promotes economic and technological predominance on the global scale.  Only time will tell.   Header image credit: Abode Stock Related Posts Three Factors for Job Security in the Age of Artificial IntelligenceIn this post, we point out three factors that could ensure job security as artificial… AI and Machine Vision for Law Enforcement - Use-Cases and Policy ImplicationsThis article is based on a presentation at a joint United Nations / INTERPOL conference… Establishing AI Ethics - Public and Private Sector InitiativesThe Institute of Electrical and Electronics Engineers (IEEE) comprises about 421,000 members in over 160… Aligning AI with Business Practices - A Decision ModelThis article was written and contributed by Tom Gilbert, PhD Student in Machine Ethics and… AI Ethics vs. Virtue Signaling - Transparency, Accountability, and Solving Real ProblemsDaniel Faggella, CEO and founder at Emerj, kicked off the Technology Association of Georgia's first… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Ethics and Regulatory,2352.0,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiNWh0dHBzOi8vd3d3LnV0c2EuZWR1L3RvZGF5LzIwMTkvMTEvc3RvcnkvQUlNSVRSRS5odG1s0gEA?oc=5,Artificial intelligence rolls out across academic disciplines | UTSA Today - The University of Texas at San Antonio,2019-11-21,The University of Texas at San Antonio,https://www.utsa.edu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LmJ1c2luZXNzaW5zaWRlci5jb20vaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXdpbGwtaW1wYWN0LXN0ZW0tZWR1Y2F0aW9u0gFaaHR0cHM6Ly93d3cuYnVzaW5lc3NpbnNpZGVyLmNvbS9ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utd2lsbC1pbXBhY3Qtc3RlbS1lZHVjYXRpb24_YW1w?oc=5,How AI will impact STEM education and the skills gap in the US - Business Insider,2019-11-21,Business Insider,https://www.businessinsider.com,A Brookings report raises questions on how profitable or employable STEM college graduates will be in the future.,"AI, Artificial Intelligence, Tech",A Brookings report raises questions on how profitable or employable STEM college graduates will be in the future.,,http://schema.org,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://www.businessinsider.com/how-artificial-intelligence-will-impact-stem-education'}",How AI will impact STEM education and the skills gap in the US,"{'@type': 'ImageObject', 'url': 'https://i.insider.com/5d2f73ac911b7039293c5ac3?width=1136&format=jpeg', 'width': 1136, 'height': 852, 'caption': ""Alibaba employees watch an artificial intelligence robot named ET writing Spring Festival couplets at Alibaba's Xixi District on January 16, 2017 in Hangzhou, Zhejiang Province of China.""}","{'@type': 'Person', 'name': 'Allana Akhtar', 'sameAs': 'https://www.businessinsider.com/author/allana-akhtar'}",2019-11-21T20:56:15Z,2019-11-21T20:56:21Z,"{'@context': 'http://schema.org', '@type': 'Organization', 'name': 'Insider', 'legalName': 'Insider Inc.', 'foundingDate': '2007', 'url': 'www.businessinsider.com', 'sameAs': ['https://www.instagram.com/insiderbusiness', 'https://www.twitter.com/businessinsider', 'https://www.facebook.com/businessinsider', 'https://www.linkedin.com/company/businessinsider', 'https://www.youtube.com/@InsiderBusiness'], 'founder': {'@type': 'Person', 'name': 'Henry Blodget'}, 'logo': {'@type': 'ImageObject', 'url': 'https://www.businessinsider.com/public/assets/logos/structured-data.png', 'width': 305, 'height': 60}}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.businessinsider.com/', 'name': 'Business Insider'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.businessinsider.com/strategy', 'name': 'Strategy'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.businessinsider.com/careers', 'name': 'Careers'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://www.businessinsider.com/how-artificial-intelligence-will-impact-stem-education', 'name': ""AI is coming for white-collar tech jobs. Here's what that will mean for your pricey STEM degree.""}}]",,,"




                                    Strategy
                                  
 
AI is coming for white-collar tech jobs. Here's what that will mean for your pricey STEM degree.








Allana Akhtar 
Nov 21, 2019, 3:56 PM EST 







Share icon
An curved arrow pointing right.

 Share





Facebook Icon
The letter F.


Facebook
 



Email icon
An envelope. It indicates the ability to send an email.


Email
 



Twitter icon
A stylized bird with an open mouth, tweeting.


Twitter
 



LinkedIn icon


LinkedIn
 



Link icon
An image of a chain link. It symobilizes a website link url.


Copy Link
 





lighning bolt icon
An icon in the shape of a lightning bolt.

 
Impact Link

 
 



Save Article Icon
A bookmark

 Save





 
                                      Read in app
                                  











Angle down icon
An icon in the shape of an angle pointing down.

 

White-collar jobs in science and tech will likely be impacted the most by AI.
 

                              US Army RDECOM/Flickr/CC 2.0 Attribution
                                




 

This story is available exclusively to Business Insider
                      subscribers.
                      Become an Insider
                      and start reading now.
Have an account? Log in.






White-collar, college-educated workers in business, tech, and finance are at greatest risk of having artificial intelligence impact their jobs, according to a new study from Brookings. The report raises questions on how profitable or employable STEM (science, technology, engineering, and mathematics) college graduates will be in the future.STEM grads currently have higher median household incomes and lower unemployment rates compared to the general graduate population.Visit Business Insider's homepage for more stories.










 


                                    Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview








 















Thanks for signing up!


                              Access your favorite topics in a personalized feed while you're on the go.
                              
                                download the app
                               





Email address





                                      Sign up
                                     



                                  By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy. You can opt-out at any time by visiting our Preferences page or by clicking ""unsubscribe"" at the bottom of the email.
                              








 


Advertisement

Majoring in engineering might not guarantee you a lofty job much longer.A new study from Brookings found that workers with bachelor's and graduate degrees are five and four times more likely, respectively, to get impacted by AI than people with just a high school degree. Brookings can't predict whether the impact would mean job loss, but the technology will likely replace some job functions.
This story is available exclusively to Business Insider
                            subscribers.
                            Become an Insider
                            and start reading now.
Have an account? Log in.
In addition to manufacturers, white-collar workers in business, finance, and tech industries face greater career consequences of AI impact when the technology becomes more advanced. These findings differ from other reports that say low-income workers will be the ones getting replaced by AI.Mark Muro, a senior fellow at Brookings and lead author on the study, told Business Insider that the report suggests a college degree won't give graduates a ""pass"" on avoiding AI's potentially negative impact on jobs. STEM (science, technology, engineering, math) graduates, who currently have lower unemployment than general grads, might not have as much job security when AI becomes more advanced. 
Advertisement

""I think this raises questions about whether STEM analysis, STEM education, or college degrees per se, offer a way to completely avoid these kinds of technology transitions at work,"" Muro said in an interview. ""I think this throws attention on what we educate for and what we train for.""Unlike other surveys, Brookings analyzed the ""exposure,"" or how much of the job will get replaced or supplemented by AI, by comparing job descriptions to patents that have been filed for the technology. Other reports tend to be more subjective by using expert commentary, Muro said.The study comes at a time when college degrees are pricier than ever. As Business Insider's Hillary Hoffower reported, the cost of undergraduate degrees rose by 213% for public schools and 129% for private schools, adjusting for inflation.Plus, the total amount of student loans in the US has topped $1 trillion. Hoffower has also reported that nearly half of college grads with debt don't think their college degree helped them earn more money.
Advertisement

The report may shock some STEM graduates who for years have been practically guaranteed high-paying work after graduation. All but two of the 20 highest-paying college majors are in some kind of engineering occupation, and the STEM college majors have higher median incomes and lower unemployment rates compared to the general graduate population. Muro said exposure to AI does not necessarily mean job loss, and AI might just supplement work. But he said that AI exposure will likely lower wages and lead to job replacement if human workers can no longer bring ""extra value"" that AI can't.Jobs that AI won't have as much impact on include relatively low-paying work in food preparation and education. The reason might be because these jobs require interpersonal skills that are difficult for machines to replicate. For instance, there are already machines that can flip burgers, yet fast food workers are cheaper and better at it so companies haven't invested much in the tech, wrote Ellen Ruppel Shell in her book, ""The Job: Work and Its Future in a Time of Radical Change.""""It may be that college education, or educational training in general, should be [focused] on things like interpersonal relations and judgement ethical decision making,"" Muro said. ""A college degree won't give someone a pass on dealing with these transitions but it also may be useful if it allows for people to be better equipped to do things that machines can't.""
Advertisement

Read more:Apple, Google, and Netflix don't require employees to have 4-year degrees, and this could soon become an industry normBlue-collar jobs like plumbing pay $90,000 without a college degree, and it's driving more workers to trade schoolThe 20 most popular jobs of 20193 million older Americans can't find high-paying jobs, and it has nothing to do with skills. Here's the one barrier they face that no one's addressing.

 







                                Read next
                              





 
Online Shopping ToolsAmazon's Worst Nightmare: Thousands Canceling Prime for This Clever HackThis simple trick can save tons of money on Amazon, but most Prime members are ignoring it.Online Shopping Tools|SponsoredSponsoredUndoPressreachNYPD Robot Ready For New YorkNYPD's Innovative Robot Police May Elevate This Stock to New HeightsPressreach|SponsoredSponsoredGet QuoteUndostockstreetnewsThe Lithium Miner That Is On Everyone's Watch listDiscover 2024's hidden gem that is currently trading under $2 per share. Unravel its secrets right here and now.stockstreetnews|SponsoredSponsoredGet QuoteUndoNew report reveals a major reason Michelle Obama isn't campaigning for BidenMichelle Obama is unhappy with how the Bidens have ostracized her friend, sources told Axios, claims the former first lady and White House deny.Business InsiderUndoKaty Perry's new song ""Woman's World"" is already being criticized before releaseKaty Perry recently shared a snippet of her new song, ""Woman's World,"" out next month. The clip has already been met with mockery online.Business InsiderUndoHistory Strategy GameGame shows what the world without US military interventions would look likeThis strategy games makes you become a player in the crucial situations of history.History Strategy Game|SponsoredSponsoredPlay NowUndoBlinkist MagazineApple Recommends: Blinkist, The Best App For Intellectuals Around The WorldApple recommends Blinkist for lifelong learners, top thinkers, and anyone who wishes they had more time to learn the powerful ideas in nonfiction books.Blinkist Magazine|SponsoredSponsoredUndoUltimate Pet NutritionPaw Licking Driving You Crazy? Top Vet Says To Make One Small ChangeMost dog owners don't know this.Ultimate Pet Nutrition|SponsoredSponsoredLearn MoreUndoNorth Korea executed 30 teens for watching South Korean shows: reportsAccording to South Korean news outlets, around 30 middle schoolers were publicly shot last week in North Korea for watching South Korean shows.Business InsiderUndoZacks Investment Research5 Forever Dividend StocksZacks Investment Research|SponsoredSponsoredLearn MoreUndoFree Covid TestUS Government is Providing Free Covid Test Kits Again, Get Yours Now Before They Are All Gone AgainSearch your address to see free test kit availability instantlyFree Covid Test|SponsoredSponsoredSearch NowUndoBarefoot VitalityNeurologists Amazed: Barefoot Shoes are The Best Thing You Can Do in 2024Discover 10 Reasons Why These Shoes have Shocked the Healthcare Industry!Barefoot Vitality|SponsoredSponsoredUndoJD Vance has only been in the Senate for 18 months. Here's what he did in that time.Vance's short tenure has been defined by his undying loyalty to Trump, his opposition to Ukraine aid, and his periodic populist gestures.Business InsiderUndoI've worked on cruises for nearly 10 years. Here are 7 things I'd never do a ship.As a cruise employee, there are things I'd never do on a ship, from paying for a virtual balcony to booking excursions from independent vendors.Business InsiderUndoChaikin AnalyticsOwn Nvidia? Prepare for a “cash avalanche”Chaikin Analytics|SponsoredSponsoredUndo
































 


Close icon
Two crossed lines that form an 'X'. It indicates a way to close an interaction, or dismiss a notification.
                    



",AI is coming for white-collar tech jobs. Here's what that will mean for your pricey STEM degree.,,"Strategy, Careers, Nordic",,,,,,,,,,,,,AI is coming for white-collar tech jobs. Here's what that will mean for your pricey STEM degree.,"[{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.content-lock-content'}]",,,,False,,,,,,,,,,,,"Majoring in engineering might not guarantee you a lofty job much longer.A new study from Brookings found that workers with bachelor's and graduate degrees are five and four times more likely, respectively, to get impacted by AI than people with just a high school degree. Brookings can't predict whether the impact would mean job loss, but the technology will likely replace some job functions.In addition to manufacturers, white-collar workers in business, finance, and tech industries face greater career consequences of AI impact when the technology becomes more advanced. These findings differ from other reports that say low-income workers will be the ones getting replaced by AI.Mark Muro, a senior fellow at Brookings and lead author on the study, told Business Insider that the report suggests a college degree won't give graduates a ""pass"" on avoiding AI's potentially negative impact on jobs. STEM (science, technology, engineering, math) graduates, who currently have lower unemployment than general grads, might not have as much job security when AI becomes more advanced. ""I think this raises questions about whether STEM analysis, STEM education, or college degrees per se, offer a way to completely avoid these kinds of technology transitions at work,"" Muro said in an interview. ""I think this throws attention on what we educate for and what we train for.""Unlike other surveys, Brookings analyzed the ""exposure,"" or how much of the job will get replaced or supplemented by AI, by comparing job descriptions to patents that have been filed for the technology. Other reports tend to be more subjective by using expert commentary, Muro said.The study comes at a time when college degrees are pricier than ever. As Business Insider's Hillary Hoffower reported, the cost of undergraduate degrees rose by 213% for public schools and 129% for private schools, adjusting for inflation.Plus, the total amount of student loans in the US has topped $1 trillion. Hoffower has also reported that nearly half of college grads with debt don't think their college degree helped them earn more money.The report may shock some STEM graduates who for years have been practically guaranteed high-paying work after graduation. All but two of the 20 highest-paying college majors are in some kind of engineering occupation, and the STEM college majors have higher median incomes and lower unemployment rates compared to the general graduate population. Muro said exposure to AI does not necessarily mean job loss, and AI might just supplement work. But he said that AI exposure will likely lower wages and lead to job replacement if human workers can no longer bring ""extra value"" that AI can't.Jobs that AI won't have as much impact on include relatively low-paying work in food preparation and education. The reason might be because these jobs require interpersonal skills that are difficult for machines to replicate. For instance, there are already machines that can flip burgers, yet fast food workers are cheaper and better at it so companies haven't invested much in the tech, wrote Ellen Ruppel Shell in her book, ""The Job: Work and Its Future in a Time of Radical Change.""""It may be that college education, or educational training in general, should be [focused] on things like interpersonal relations and judgement ethical decision making,"" Muro said. ""A college degree won't give someone a pass on dealing with these transitions but it also may be useful if it allows for people to be better equipped to do things that machines can't.""",,,,,,,,,,,,,,,,,,,,,"{'@type': 'Person', 'name': 'Joel Marino'}"
https://news.google.com/rss/articles/CBMiM2h0dHBzOi8vaGF5c3Bvc3QuY29tL3Bvc3RzLzVkZDU1ZThlODk3ZDE0N2FkNGJiMTIxNdIBAA?oc=5,Startup uses artificial intelligence to help colleges retain students - Hays Post,2019-11-24,Hays Post,https://hayspost.com,"Carolina Recchi, co-founder of EdSights, speaks Tuesday during the Entrepreneur Direct lecture series at FHSU.By CRISTINA JANNEYHays PostThe",,"Carolina Recchi, co-founder of EdSights, speaks Tuesday during the Entrepreneur Direct lecture series at FHSU.By CRISTINA JANNEYHays PostThe","Carolina Recchi, co-founder of EdSights, speaks Tuesday during the Entrepreneur Direct lecture series at FHSU.By CRISTINA JANNEYHays PostThe",,,,,,,,,,,,,"Carolina Recchi, co-founder of EdSights, speaks Tuesday during the Entrepreneur Direct lecture series at FHSU.By CRISTINA JANNEYHays PostThe co-founder of a company that created a chat bot to help colleges retain students spoke at Fort Hays State University on Tuesday.Carolina Recchi, co-founder of EdSights, spoke to students and faculty about her company as well as she and her sister's failures and successes in launching the startup. Recchi's lecture was part of the FHSU Entrepreneur Direct lecture series.Carolina and her sister grew up in Italy, and Carolina came to the United States to study at Babson College where she earned her degree in international business. Carolina is only five years out of college. She initially went to work for Bloomberg, where she was selling data to universities. She soon learned she loved working with higher education clients, and this eventually lead she and her sister to strike out on their own.Recchi's current company — EdSights — uses artificial intelligence to help students navigate their college experience. The ultimate goal is to increase student success and increase graduation rates.Some of the schools EdSights is currently working with include Pittsburg State University, Northwestern and Baker University. The sisters have raised a $1 million in venture capital for their company and graduated from the the Techstars accelerator program in Kansas City.However, EdSights was not the original concept for the sisters' business. They first created an app called ClassPulse, which allowed students to give professors real-time feedback on their performance.Recchi and her sister realized course evaluations were flawed. Students fill them out without paying attention, she said. Faculty don't have good ways of receiving real-time feedback, and it ends up penalizing both faculty and students, she said.The Chronicle of Higher Education published a story about the app while the sisters were testing it at Georgetown. The sisters were inundated with requests for the app.Carolina quit her job at Bloomberg to pursue ClassPulse and her sister turned down a job at Amazon., which she said was a mistake.The company scaled quickly with as many as 200 colleges using the app, but the sisters realized they had no way of monetizing the app. Students didn't want to pay for it. Professors liked it, but not enough to pay for it. Universities did not see enough value in it to pay for it.They realized they didn't have a business model and they needed to pivot the focus of their company.""This is embarrassing to admit, but it keeps happening,"" she said. ""I keep seeing founders, even second-time founders, who say I will just grow this thing and get so many users, and they'll figure out the money part later. This is like the Instagram model. You don't want to do that.""Recchi went back to her customers and asked them what problems they were facing and what they would be willing to pay for. They found universities were eager for help with student retention.Twenty million students enroll in college every year, but only about half of them graduate in six years. Six thousand students drop out of college every day. College dropouts earn about 35 percent less than their peers and are four times more likely to default on student debt.An average college loses $10 million annually due to student dropouts. The higher education system in North America as a whole loses about $41 billion annually because of student dropouts.EdSights built a chat bot, a robot, that engages with students over text message. They name the bot after the school mascot. The bot can answer questions, such as 'How do I drop a class?' or 'How do I find a tutor?'.""As we talk to students, we are doing two things. We are connecting students with helpful resources, and we are looking at the data and making suggestions to universities on which populations or demographics may need extra resources,"" Recchi said.Students responded well to the chat bot. EdSights had a 95 percent opt in from students. Seventy percent of student were active engagers.The bot helped increase retention by 7.3 percent and saved universities $1.7 million.Recchi concluded her talk by sharing some lessons she and her sister learned in launching their startup.""As a first-time founder, inevitably you make so many mistakes, because you don't know what you don't know and you kind of learn it in the process,"" Recchi said. ""Work hard, you are smart enough I hope you know that.""But there are some specific actionable things that over time will create luck for you because there is such thing is luck but you can create it for yourself.""Don't plan, prototype""What I mean by that is don't overthink your idea because it probably is not going to be what you end up with,"" Recchi said. ""Your idea is your starting point. Your idea is not your business. It is just an idea. Pick a business or a space that you are passionate about.""She said you can try out an idea without blowing through your 401k by using a minimum buy-in product and testing it.""You have to be lean,"" she said. ""You have to be able to change everything and not just jump into it and see how people respond to it.""Embrace change and pivot""If something isn't working, ask yourself why,"" she said. ""I see so many founders banging their head against the wall, but the wall isn't going to move.""As a startup, you are at a disadvantage at almost everything, including money and employees. However, you can do more a lot faster, she said.""You have nothing to lose and everything to gain,"" Recchi said. ""So if something isn't working, start from scratch, pivot, make small changes. You have to be nimble. You have to move fast, learn fast, throw thing away if they are not working. There is no real big repercussions.""Ask for help and make it easy for people to help youAsk for something very specific. If you want to be introduced to an investor, name a specific investor. EdSights seeks introductions to specific university officials to pitch their products.Follow upRecchi said she is very direct with her potential investors and clients. She said she contacted one investor eight times before the investor finally agreed to invest in the company. Now that investor is one of the biggest investors in EdSights.Listen to feedback(But pick mentors wisely)The Recchies are using mentors who are five to 10 years ahead of them in the growth of their companies, in their industry and successful.Recchi said avoid mentors who want something from you. Don't pay a consultant and don't give up equity in your company for advice, she said.Choose a co-founder wiselyRecchi was lucky because she has her sister as a co-founder, but one of the top reasons why startups don't do well is problems between founders.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAxOS8xMS8yMi90aGUtNS1iaWdnZXN0LXRlY2hub2xvZ3ktdHJlbmRzLWRpc3J1cHRpbmctZW5naW5lZXJpbmctYW5kLWRlc2lnbi1pbi0yMDIwL9IBAA?oc=5,The 5 Biggest Technology Trends Disrupting Engineering And Design In 2020 - Forbes,2019-11-22,Forbes,https://www.forbes.com,"There are many changes to design and engineering being ushered in by today's new technologies from digital twins to AI. The human professionals in these industries are being challenged to acquire new skills, be comfortable with change, and to adapt to collaborating with machines.","trends,disrupting,engineering,design,2020,ai,robots","There are many changes to design and engineering being ushered in by today's new technologies from digital twins to AI. The human professionals in these industries are being challenged to acquire new skills, be comfortable with change, and to adapt to collaborating with machines.","There are many changes to design and engineering being ushered in by today's new technologies from digital twins to AI. The human professionals in these industries are being challenged to acquire new skills, be comfortable with change, and to adapt to collaborating with machines.",http://schema.org,BreadcrumbList,,The 5 Biggest Technology Trends Disrupting Engineering And Design In 2020,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5dd77dbdea103f0006530bb4/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}",2019-11-22T01:20:22-05:00,2019-11-22T01:20:22-05:00,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise TechThe 5 Biggest Technology Trends Disrupting Engineering And Design In 2020Bernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 22, 2019,01:20am ESTUpdated Nov 22, 2019, 01:20am ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinThe way products are designed and engineered is changing thanks to new technologies. These technologies, from digital twins to 3D printing, not only support humans in their design and engineering work, but they can also efficiently uncover new ways of solving problems that humans hadn't thought of before. The human professionals in design and engineering roles in organizations will see changes to their job duties, will be challenged to acquire new skills and flexibility, and learn new ways of collaborating with machines. They also need to learn how to work with new design, engineering, and product development tools enabled by these new technologies. Things are changing rapidly. Organizations and professionals in engineering and design roles can't ignore the changes if they want to remain competitive. Here are the five biggest technology trends that are disrupting engineering and design. 
The 5 Biggest Technology Trends Disrupting Engineering And Design In 2020Adobe Stock

Digital Twins

Imagine the power of being able to design and build something virtually to see how everything comes together before you expend real-world resources and then figure out a flaw in the design. You no longer have to imagine. While the concept for digital twins has existed for quite some time, the adoption of the Internet of Things (IoT) makes digital twins affordable. Digital twins create an exact virtual replica of something in the physical world using data and algorithms instead of materials. The transformative potential of digital twins is so incredible, the technology was listed on Gartner’s Top 10 Strategic Technology Trends for 2017 and 2018. Digital twin technology has been deployed in Formula 1 car racing to evaluate the performance and reliability of new parts. Ultimately, a digital twin provides design and engineering teams real-time information about how whatever they are creating will perform under a variety of circumstances.

Artificial Intelligence (AI)

Artificial intelligence continues to be one of the fastest-growing emerging technologies, so you likely aren't surprised that it is also disrupting design and engineering now that Industry 4.0 is here. Engineers will need to learn how to collaborate with artificial intelligence to produce better products and to be open to evolving to work with the latest tools available to them. Engineers must embrace flexibility and adapt to changes that artificial intelligence will bring to the way they work from robotics, natural language processing, automation, and more.
PROMOTED
Generative Design
Generative design uses artificial intelligence (AI) software and the computing power of the cloud to create design solutions that would never have been conceived by the human mind—or at least as quickly. Engineers have a new partner in designing solutions and can collaborate with generative design algorithms to co-create. To start the process, an engineer or designer gives the algorithm design parameters, and then the software explores all possible combinations and generates hundreds or even thousands of design options. Then, the engineer or designer takes those options and explores the feasibility of the design solutions. Generative design has been used to design everyday objects such as chairs and power tools as well as help solve larger engineering feats such as when Airbus used generative design to redesign an interior partition for its A320 aircraft. In that example, the collaboration between man and machine came up with a solution that shaved off 45 percent of the part’s weight. 
Robotics
Most organizations will benefit from enhanced performance, improved products, higher productivity, and more with the adoption of new technology. Robots that are deployed today can do much more than provide physical strength to tasks or move items around a warehouse—they can complement human work in a variety of ways, even with cognitive tasks. Engineering time and risk have been reduced thanks to software that can simulate robotic applications and maintenance. Robots can now ""think out-of-the-box"" rather than just be programmed to do repetitive tasks.
MORE FOR YOUSuspected Trump Shooter Remembered By Rifle Team Member As ‘Comically Bad Shot’: What We Know About Thomas Matthew Crooks‘House Of The Dragon’ Season 2, Episode 5 Recap And Review: The Seeds Of The DragonBiden Vs. Trump 2024 Election Polls: Biden Narrowly Leads Trump In Virginia, After 10-Point Win There In 2020
3D Printing
Additive manufacturing, more commonly known as 3D printing for three-dimensional printing, is transforming the way business is done as well as how things are designed and made. From 3D printed parts on commercial airplanes to those implanted in humans through innovative healthcare applications, 3D printing is incorporated in many areas of our lives. Now that 3D printing is a critical part of how businesses and manufacturers design and make products, it’s changing the future of engineering and the engineering degree. This technology allows for prototypes to be made quickly and economically.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",The 5 Biggest Technology Trends Disrupting Engineering And Design In 2020,,Enterprise & Cloud,,https://www.forbes.com/sites/bernardmarr/2019/11/22/the-5-biggest-technology-trends-disrupting-engineering-and-design-in-2020/,,,,,,,,,,,,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vZW1lcmouY29tL2FpLW1hcmtldC1yZXNlYXJjaC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1pbmRpYS_SAQA?oc=5,"Artificial Intelligence in India – Opportunities, Risks, and Future Potential - Emerj",2019-11-24,Emerj,https://emerj.com,We present an extensive research on artificial intelligence adoption in India today and take a look at how the country might leverage AI in the future,,We present an extensive research on artificial intelligence adoption in India today and take a look at how the country might leverage AI in the future,,https://schema.org,Article,https://emerj.com/ai-market-research/artificial-intelligence-in-india,"Artificial Intelligence in India &#8211; Opportunities, Risks, and Future Potential",https://emerj.com/wp-content/uploads/2018/07/2019-03-01-690x392.jpg,Daniel Faggella,2018-07-09,2019-11-24,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",,,," AI Market Research Artificial Intelligence in India – Opportunities, Risks, and Future Potential Daniel FaggellaLast updated on November 24, 2019  Last updated on November 24, 2019, published by Daniel Faggella Daniel Faggella is Head of Research at Emerj. Called upon by the United Nations, World Bank, INTERPOL, and leading enterprises, Daniel is a globally sought-after expert on the competitive strategy implications of AI for business and government leaders. Share to: LinkedIn Twitter Facebook Email  Over the last two years, we have witnessed a steady increase in our percent of readership in India. Sometime in 2017, Bangalore became one of our largest sources of job applicants, and our single biggest city in terms of readers – overtaking both London and NYC. Given the Indian government’s recent focus on developing a plan for artificial intelligence, we decided to apply our strengths (deep analysis of AI applications and implications) to determine (a) the state of AI innovation in India, and (b) strategic insights to help India survive and thrive in a global market with the help of AI initiatives. We traveled to Bangalore in an effort to speak with experts from the Government of India, Indian AI startups, AI academic researchers in India and data science executives at some of the largest companies operating in India, including Reliance ADA, Amazon, AIG, Equifax, Infosys, NVIDIA and many more. Through the course of this research our objective was threefold: To understand the state of AI adoption in India To determine the opportunities and risks that artificial intelligence poses for Indian industry and society To provide the Indian government and tech community leaders with strategic recommendations for using AI to promote prosperity in India We have broken our analysis down into the following sections below: AI Adoption and Potential in India – an Overview Strengths and Opportunities for India in Artificial Intelligence Weaknesses and Risks for India in Artificial Intelligence Strategic Recommendations for Success in the Indian Artificial Intelligence Ecosystem The Big Themes Strategic Recommendations – The High-Level View We’ll begin by examining what we learned about AI adoption in India: 1 – AI Adoption and Potential in India – an Overview  The Initiatives of the Indian Government Thus Far Since the early 90s, the IT and ITeS services sector in India has been of tremendous importance to its economy eventually growing to account for 7.7% of India’s GDP in 2016. In an attempt to capitalize on this foundation, the current Indian administration announced in February 2018 that the government think-tank, National Institution for Transforming India (NITI) Aayog (Hindi for Policy Commission), will spearhead a national programme on AI focusing on research.  This development comes on the heels of the launch of a Task Force on Artificial Intelligence for India’s Economic Transformation by the Commerce and Industry Department of the Government of India in 2017.  The industry experts we interviewed seemed to agree that artificial intelligence has certainly caught the attention of the Indian government and the tech community in recent years. According to Komal Sharma Talwar, Co-founder XLPAT Labs and member of India’s AI Task Force: “I think the government has realized that we need to have a formal policy in place so that there’s a mission statement from them as to how AI should evolve in the country so it’s beneficial at large for the country.” Indeed it’s comments like Komal’s that made us realize that we should aid in determining a strategic direction for artificial intelligence development in India – and learn as much as possible about the possible strategic value of the technology. In our research and interviews, we saw consensus (from executives, non-profits, and researchers alike) that healthcare and agriculture would be among the most important sectors of focus in order to improve living conditions for India’s citizens.  Just as Google, Oracle, Microsoft, and Amazon are battling to serve the cloud computing and machine learning needs of the US government, the next three to five years may lead to a similar dynamic within India. As the Indian government pushes for digitization and enacts more AI initiatives, private firms will flock to win big contracts – adding to the pool of funds to develop new technologies and spin out new AI and data science-related startups. Mayank Kapur, CTO of Indian AI startup Gramener, says that the government is still the largest potential customer for data science services in the country. Other experts we spoke with have enunciated that more and more Indian startups and established tech firms are beginning to implement AI in their products and services.  Mr. Avik Sarkar, the Head of the Data Analytics Cell for NITI Aayog explains that the think-tank – which has been tasked with spearheading India’s AI strategy – is currently engaged in the following public sector initiatives: “The current areas of focus for AI applications in India are majorly focused in 3 areas: Precision Agriculture – The government has initiated a proof of concept pilot in 15 districts (counties) in India to use artificial intelligence based real-time advisory based on satellite imagery, weather data, etc. to increase farm yields where the farm production levels are low Healthcare – Pathologists and Radiologists are very few in number India relative to the overall population, (especially in rural areas) and these are applications which can be augmented through image recognition AI. We are working on augmenting the productivity of existing pathologists and radiologists as the first (of many planned) pilot project in healthcare. NITI Aayog is working on early diagnosis and detection of Diabetic Retinopathy and Cardiac Risk based on the AI models. Such initiatives would in the long run help patients on proactive medication in early stages rather than reactive healthcare in advanced stages – bringing down healthcare costs and better chances of recovery.  Indian Languages Project – We have initiated a long-term project to build a complete natural language processing platform for Indian languages. This would aid in the development of several applications, like conversational general and career counseling through chatbots and assistants, conversing in 22 Indian languages.” How is AI Interest in India Manifesting Itself Today? With the government’s growing interest around AI applications in India, Deepak Garg the Director at NVIDIA-Bennett Center of Research in Artificial Intelligence (and Director LeadingIndia.ai) believes that there has been a significant growth in interest levels around AI across all industry sectors in India. He explains that although AI attention is considerably smaller in India than in China or the USA, the increased AI interest has manifested itself in the following three ways:  “1) Industries have started working to skill their manpower to enable themselves to compete with other global players 2) Educational institutions have started working on their curricula to include courses on machine learning and other relevant areas  3) Individuals and professionals have started acquiring these skills and are comfortable investing in upgrading their own skills.” The Current Challenges to AI Traction in India Despite the initial enthusiasm for AI, there were also a few opinions from experts about a sense of unfulfilled potential and that the country could be doing far more to adopt and integrate AI technologies. Another common theme we heard often during our interviews was that – culturally speaking – the cost of failure is much higher in India than the West. While failing in an attempt at bold innovation and grand goals might be seen as noble or brave in Silicon Valley or New York City (or even Boston), failure often implies a loss of face in India and some Asian countries. This has historically meant a lack of room for innovative experimentation. Dr. Nishant Chandra, the Data Science Leader of Science group at AIG adds a valuable insight about the high stakes for failure in India and that cultural and economic factors play into raising these stakes: “Indian society is not as forgiving to failure in entrepreneurship as US or Europe. So far, this has led to ideas borrowed from other places and implemented after customization. Yet I believe, entrepreneurs will build upon the success of IT services industry and establish globally competitive AI companies in near future.” At the IIIT Banglore University Campus where we caught up with Mr. Professor Manish Gupta, CEO of VideoKen We caught up with Professor Manish Gupta at IIIT Bangalore – Manish is also a startup founder (VideoKen) and former AI researcher at Xerox and Goldman Sachs India. He expressed his disappointment in India’s lack of global AI participation: “I think that we are not doing enough justice to our potential [in India]; I think we are really far behind some of the other leaders. I see a lot of American and Chinese companies at global AI conference like NIPS / AAAI and these two countries seem to be far ahead of the rest of the pack. I look at India as a country that ought to be doing a lot more.” A number of our interviewees mentioned the prevalence of copy-catting business models in India (taking a famous or successful business model in the USA or Europe and reconstructing it in India), as opposed to the invention of entirely new business models.  Google is not the copy-cat of another business in another country, nor is Facebook, Amazon, or Microsoft – and many of the same interviewees we spoke with are hopeful that India will have its own global trend-setters as it’s technology ecosystem develops. Next Steps for AI Development in India Our previous research on AI enterprise adoption seems to indicate that it may be another 2-5 years until AI adoption becomes mainstream in the Fortune 500 – and even that is only at the level of pilots and initiatives, not of revolutionary results.  This “learning” phase – evident given the state of AI adoption the Western markets – may last longer in India’s relatively underdeveloped economy. Aakrit Vaish, CEO of Haptik, Inc. also seems to suggest that in the next 10 years we can expect that understanding of AI and how it works will potentially be more commonplace among most technical industry executives: “India may go in the direction that China has gone, become their own economies. There are probably going to be pockets, Bangalore might be good at deep tech like robotics or research / Hyderabad being good at data/ AI training, Mumbai being good at BFSI and  Delhi for agriculture and government. Like China, most solutions will probably be applied to the local economy.” India’s services sector (call centers, BPOs, etc – roughly 18% of the Indian GDP) have a significant potential opportunity to cater to the coming demand for data cleaning and human-augmented AI training (data labeling, search engine training, content moderation, etc).  Komal Talwar from Government of India’s AI Task Force added her views on what the Indian government’s future strategy around AI might be focused on: “We think AI could have a great impact in health sector. There is a scarcity for good doctors and nurses, with AI the machine can do the first round of diagnostics. Staff can carry machines with them to help cut down in the physical presence needed for doctors.  The government is really encouraging startups to have AI applications that really have a social impact (AI in health, AI in education, etc), where startups compete to solve social problems.” Key Points: Has India “woken up” to artificial intelligence? Expert opinions on this topic seem mixed, yet through our analysis, we managed to distill the following themes:  Most experts agreed that there is some indication of grassroots level AI adoption today in India, yet the pace of innovation around establishing a comprehensive AI strategy for the future isn’t comparable to America or China today. Most of the traction today in India seems to be in the form of AI pilot projects from the government in agriculture and healthcare and the emergence of AI startups in Indian software hubs like Bangalore and Hyderabad. Some of the experts we interviewed believe that India’s underdeveloped economy will considerably slow broad AI adoption. The Indian government and Indian tech hubs are certainly aware of (and often excited about) AI, but adoption lags interest. India could become the hub for data cleaning around the world. The IT services industry could easily transition into human-trainers of AI, a need that already exists (as evidenced by Figure Eight, Clickworker, Gengo.ai, and other players in the human-assisted AI training market). In India, the government push is towards AI applications that have social benefits like health care, education and agriculture. The direct financial impact of these sectors is massive, but the government seems to be focused first on improving the health and well-being of its citizens. Interested readers can learn more about AI applications in India today from our other articles about AI traction in some of India’s largest sectors: Artificial Intelligence in Indian Agriculture – An Industry and Startup Overview Artificial Intelligence at India’s Top eCommerce Firms – Use Cases from Flipkart, Myntra, and Amazon India Artificial Intelligence Initiatives at India’s Top IT Services Firms AI Applications in the Top 4 Indian Banks 2 – Artificial Intelligence in India – Strengths and Opportunities  The majority of our Indian AI respondents and interviewees showed optimism about India’s potential to be one of the key global players in the future of AI. Optimism about the prospects of one’s own nation’s success seems a natural bias (and one that we’ve seen before in our geography-specific coverage in Montreal, Boston, and more) – but India’s optimism isn’t unwarranted. Since the early 90’s when the Indian economy opened up to foreign investment, the country has been considered by some economists as the “dark horse” among the larger economies in the world.  An Existing Foundation For Taking Advantage of AI Historically, the slower adoption of IT services by domestic Indian companies (in some cases by even by a period of around 10 years) as compared to global competitors was an indicator of the unfulfilled potential according to some experts we spoke to.  Yet, most of the interviewees seemed bullish on the fact that this time around in the wave of AI, India is firmly backing its strengths as represented in the quote below from Aakrit Vaish Co-founder and CEO of Haptik, Inc.  “The Indian foundation of IT services and business process outsourcing makes me believe that such AI training jobs will be even more lucrative for India than elsewhere in the future.” During the interview with him, Aakrit explained his stance with an example about the possibility that Indian BPO services providers could potentially be attractive in terms of skills and cost for tasks (which he believes will for a long time remain a manual effort) like cleaning and tagging of data in the near future. We heard opinions from other experts favoring the view that India may be positioned well to take advantage of the AI disruption. Sundara Ramalingam Nagalingam, Head of Deep Learning Practice at NVIDIA India, shares his thoughts on some of the advantages India may have over other countries in terms of AI: “India is the third largest startup ecosystem in the world, with three to four startups being born here daily. We believe India has a major advantage over other countries in terms of talent, a vibrant startup ecosystem, strong IT services and an offshoring industry to harness the power of AI.” Kiran Rama, the Director of Data Sciences at the VMware Center of Excellence (CoE) in Bangalore also seems to agree that the cost-competitive talent in India will be an opportunity for companies looking to open offices in India: “There seems to be a lot of opportunity for companies that are setting u shop in India. Especially since there is a supply of data science talent at a good cost advantage. I also think there Indians are starting to contribute to the advancement of machine learning libraries and algorithms.” Strong IT Services and Existing IT Ecosystem Subramanian Mani, who heads the analytics wing at BigBasket.com, an online Indian grocery e-commerce firm, reiterates the idea that the IT services background in India is an advantage.  We are seemingly joined by Bollywood star Shah Rukh Khan (their brand ambassador) during our visit to the BigBasket Offices to interview Subramaniam Mani, their Analytics Head. He believes that the major difference between the software and AI waves is that although India was slow to adopt software service as compared to America, this time around with the AI wave, adoption will be much faster and only slightly behind the leading countries.  “This is the second wave. The software wave was 30 years ago. Folks in India realized that they’ve been able to scale software and I think AI / ML is an extension of software development.” While software was often taught through books and in classrooms exclusively, many of the latest artificial intelligence approaches are available to learn online – along with huge suites of open-source tools (from scikit-learn to TensorFlow and beyond). Going in, we knew that one of the key advantages for India would, in fact, be the very IT and ITeS sectors which will make it easy for Indian tech providers to transition into AI services, given that well-developed ecosystems have evolved over the past 25 years in cities like Bangalore and Hyderabad.  Manish Gupta, Director of Machine Learning & Data Science at American Express India, expressed optimism in Bangalore as an innovation hub: “Bangalore has always been seen as the Silicon Valley of India and today there are lots of analytics companies here. It has all the ingredients to be a leader in the AI space. The state government is interested in planning and grooming for startups in this space as witnessed by the launch of the Center for Excellence (CoE) in AI setup by the GOI and NASSCOM in Bangalore.” Diversity (at Scale) May be a Massive Opportunity With Rony Thomas (Right) and Madhusudan Shekar (Far right) from Amazon AWS right after our breakfast meeting at Novotel, Bangalore While the advantage from the existing Indian IT sector may have been more intuitive, Madhusudan Shekar, Principal Technology Evangelist at Amazon AWS explains through an example how India’s diversity and scale (generally considered a challenge) can be an opportunity to make the best out of a tough situation: “In India, people speak over 40+ formal languages in about 800+ dialects. There are 22 national languages and if you want to build a neural network for speech, India is the best place to build that neural net. If you can build for India, you can most likely build it for other parts of the world.” In this respect, India – with all of its language challenges – could be a petri dish for translation-oriented AI applications. The market for this technology – especially when backed by the Indian government – may well rival the kind of AI innovations developed around translation in other parts of the world. Hundreds of Millions of People Coming Online Another insight that was oft repeated by the experts was around the potential to have access to vast amounts of data in India. To further explain,  According to a report by the Telecom Regulatory Authority of India (TRAI) the total number of internet subscribers in the country as a percentage of the overall population increased by 12.01% from December 2013 to reach 267.39 million in December 2014.  Along these lines, Mayank Kapur Co-founder of Gramener cites the increased level of data collection and the scale to which it could potentially grow as an opportunity for India in public sector AI applications: “In the public sector, we have an advantage of scale the amount of data that can potentially be gathered is huge. For example, leveraging data to provide access to services is a huge differentiator in the healthcare sector for applications like disease prevention or nutrition.” Figure. Number of internet subscribers  in India in 2014 by access type (Source)  Juergen Hase the CEO of Unlimit- A Reliance Group Company, one of India’s largest private sector companies, expressed his thoughts during our research: “The direct switch to mobile platforms in India means that there are no legacy systems to deal with and new technologies can be developed from scratch.” As shown in the figure to the right, an overwhelming majority of India’s Internet subscribers gain access through mobile wireless networks.  As Juergen points out, what this means is that large-scale AI projects in India can be somewhat insulated from issues cropping up from legacy systems. This might also lead to a greater immediate mobile-fluency for India’s startup and developer communities, who need to appeal to an almost exclusively mobile market. Juergen adds, in the future, we can expect that AI software will also potentially have this advantage in India as compared to developed countries where the ratio is more evenly distributed among mobile and fixed wireless users. Take-Aways At InMobi’s swanky office with Avi Patchava, VP Data Science right after our interview We think our business audience will indeed find the next quote from Avi Patchava, Vice President, Data Sciences, ML & AI – InMobi, highly insightful in terms of gaining an overview of India’s biggest strengths with respect to the country’s ability to leverage AI. Avi neatly summed up what he believes are India’s four biggest strengths to face the upcoming AI disruption: “India has an abundance of engineering talent which has been trained over the last 2 decades which needs to be funneled into a new direction due to the automation of IT services. This core base of engineering is required to do things with AI at scale” “India has a culture that produces a large number of mathematicians, coders, and statisticians (independent of the engineers) Bangalore and to some extent Hyderabad already have decent ecosystem set up. London essentially tried to build its tech ecosystem in the past 5 years Bangalore has been at it for the last 25 years.” “Data – We’ve got a country that is rapidly moving towards digitization – For example, the Aadhar or UIDAI Project in India is the largest ever unique identifier project in the world. India is actively pushing more and more into creating public datasets and the fact that it is a democracy helps with this fact over China where public data may be restricted to the government” You’ve got over 3 million people who are either directly engaged in the IT services world in India and its around 14% of the Indian GDP. It was skilled work, but it was routine, which makes it a key opportunity for machine learning and automation. The IT services players like Infosys, Wipro etc have noticed this and started internal reorganizations to adopt AI” The following points became evident through our interviews about India’s AI strengths and opportunities: India’s current focus on mobile platform first approach has meant that the most Indians’ first access to the internet is likely to be a mobile device. There were over 1 billion mobile telephone subscribers in India in 2016. What this means for AI in the country is that in many cases of B2C and B2B applications there are no standardization or compatibility issues cropping from legacy systems (like PCs or Macs) for new technologies which are being developed from scratch. The scale and diversity inherent in India can be an opportunity in terms of access to vast amounts of data which is an underlying necessity for any large scale AI project.  Every year, India’s many universities produce a huge number of engineers and mathematicians; these are skills which play a key role in developing any AI system. The internet promises to limit the lag from first-world computer science classrooms to Indian companies and researchers, allowing a nation with a swelling young population to potentially keep pace (at least in some sectors or cities) with the genuine cutting-edge of AI. There seems to be a government push towards digitalization indicated by the launch of AI-oriented government initiatives like the AI Task Force and NITI Aayog – and these efforts are likely to spurn more artificial intelligence enthusiasm, companies, and research investment. 3 – Artificial Intelligence in India – Weaknesses and Risks  While there were many favorable views on the future outlook of the Indian AI ecosystem, there seemed to be different views among experts regarding the challenges that the country might have to overcome to survive and thrive in the AI disruption. AI Hype vs AI Reality – and Often Stark Difference We heard a significant number of experts allude to the fact that the hype around AI may still be very real in India and there exists here a common tendency to view AI as a discrete industry rather than the broad, core technology that it is (like the internet).  In addition to being misunderstood and not being properly leveraged, many of the experts we spoke with were candid about addressing what they see as relative weaknesses of the Indian AI ecosystem. Aakrit Vaish from Haptik, Inc. shares his thoughts on the AI hype that he sees in the Indian tech scene today: “Today AI is getting a lot of attention in India but nobody knows what it is or what are the best applications for it. There’s a little of a spray-and-pray attitude across the board.” While AI hype is hard to escape in the tech press in any country – our speaking engagements in India seemed to affirm the state ambiguity around AI. We received post-presentation questions from attendees (about AI taking jobs, about the definition of AI itself, about the ongoings of Google and Facebook) that seemed like less informed questions than we might hear from a similarly technical audience in Boston or San Francisco.  This may mostly be due to the fact that AI applications are less well understood, and genuinely knowledgeable AI talent is rarer. We might suspect that over the coming few years – particularly in a tech hub like Bangalore – we’d see this knowledge lessen over time. Venture Capital in AI still in Early Stages Co-founder of XLPAT Labs and member of India’s AI Task Force Komal Sharma specifically points out that even some of the government projects have faced issues in terms of receiving funding for initiating AI pilot projects. She seems to indicate that the current Indian AI and startup funding ecosystem is not mature enough to be comparable to the US or even China. “The problem that we have faced I think is funding in areas where our field is very niche. In India, IP is developing lots of interest, but we’re nowhere near the US or other countries.” Komal was far from being alone in her lamenting AI’s lack of VC funding, and the sentiment of our respondents seems to be backed up by the data. The World Economic Forum chart below features information from Ernst & Young:  Taken as a percent of GDP, Israel’s VC investments represent about 0.006% of GDP, while India’s investments represent around 0.002%. As the Indian economy continues to develop – and if India’s entrepreneurship trend continues – we should expect to see investment increase. Lack of Collaboration Between Industry and Academia Madhu Gopinathan Vice President, Data Science at MakeMyTrip, India’s largest online travel company, touches on a point repeated by other experts as well. He thinks that the two underlying factors here are larger salaries lie in the corporate sector, which is potentially creating a dearth of mentors for the next generation of software developers looking to transition into AI and the availability of data. 
“Academia and Industry collaboration is a serious issue in India. Although we have a lot of universities, the incentives are skewed towards the corporate sector. For example, people like me who have an understanding of the technology may not be inclined to teach the next generation at universities, since working at the larger companies is far more lucrative today. “ Madhu believes that much of the “AI upskilling” of India’s development talent will occur on the job in the cutting-edge work environments of venture-backed companies, as opposed to in the classroom. As Nishant Chandra from AIG puts it, the boom in the Indian IT services sector in the early 90s was partially born out of necessity – India just did not have a good “products ecosystem”. India has historically not done well with products and according to the experts, there also seems to be a dearth of good talent specifically for design and user-interface functions.  Sumit Borar, Sr. Director – Data Sciences at Myntra, the Indian fashion eCommerce firm, is of the opinion that the scale of AI talent in India is still very nascent although he expects this to change in the next three years: “Talent will be the biggest strength for India with respect to AI. But AI is still new, so current talent in the market is very limited but in 3 years time I think that will become a strength.  Industry-university partnerships where students can work with real world data science applications and reskilling of existing workforces (example: getting software engineers to look at statistics or vice versa) are just beginning to take shape in India (starting with the unicorns).” Cultural Factors The cultural factors in India play a role in talent development here as explained by Nimilita Chatterjee SVP, Data and Analytics at Equifax: At Bangalore’s Equifax offices after our interview with Namilita “I see issues in AI talent in India are at 3 levels: Data science courses in India are tailored to technique and not to business context and application. Due to the high demand for data scientists with an experience level of 0 to 2 or 0 to 3 years, they are being recruited by other companies quite soon after you hire them; therefore, there is a risk of losing talented employees. At Equifax, we know that in order to attract and retain talent, we have to invest in a culture that people want to be a part of. We are providing employees with skill set training, offering collaborative projects, and investing in creating the next generation of leaders. The third problem is that it is sometimes tough to transition analysts to leaders. Many of our analysts are great individual contributors and although young talent in India are encouraged to be studious, there is not a very capable system in place for ensuring technically strong people transition well into ‘inspiring leaders.’ We are seeking to change this at Equifax. We’re offering rotational development programs that train our employees, offering them access to different parts of the business, as well as networking opportunities.” The issues that Nimilita addresses above aren’t all that different from what we see in the United States (indeed in Silicon Valley) on a daily basis. It does seem safe to say, however, that experienced data science talent (more specifically: Talent who have applied data science and AI skills in a real business context) is much more sparse in India than it is in the USA – at least for now. Access to Large Amounts of Data in the Finance Sector Is Still an Issue Nilmilita also believes that another weakness for India today in terms of data access for AI applications in the finance sector stems from the fact that the Indian economy still operates primarily on cash. As of 2017, India’s Economic Times claims that cash comprises 95% of the Indian economy. Although there is a small percentage of the population that is making the switch to digital transactions, she believes that this segment of the population is still not significant enough before AI adoption in this sector becomes widespread in India. “India moving away from cash and being comfortable on a mobile phone, however that part of the population is still small. It will come into play in the future, but today it is still an issue in the finance sector.” Professor Manish Gupta, CEO of VideoKen is of the opinion that the Indian tech community and government efforts around AI have not been “thinking big” in terms of how India can effectively leverage AI. Professor Gupta also mentions the lack of collaboration between academia and industry: “One of the things we lack is courage… I think we lack the courage to set ambitious enough goals and to go solve those problems.  Just being cheaper than a Western idea is not true innovation… that’s not ALL that we should be thinking about.” Take-Aways The following points became evident through our interviews about India’s AI risks and weaknesses: Although there are VCs in AI starting to emerge, access to venture funding is rare. Lack of collaboration between the industry and academia specifically in the AI domain. Lack of ambitious or creative goal setting from the tech community. Language and translation issues are rife in India, making collaboration from state to state very challenging – slowing down information transfer and posing difficulty expanding businesses. A general lack of AI fluency – even in the tech community – compared to tech hubs in Europe or the United States. 4 – Strategic Recommendations for Success in the Indian Artificial Intelligence Ecosystem In light of NITI Aayog’s recent report, and in light of our research on AI in India (and our understanding of AI’s economic possibilities in various tech ecosystems), we were determined to contribute to the national conversation about AI in India. The purpose of this final section of our AI in India analysis is to provide the Indian government and Indian tech community with a set of actionable ideas for making the most of AI in terms of economic and social benefit. We’ve broken this conclusion down into two sections: Maximizing the Economic Impact of AI. We highlight the area that we believe is of the greatest import for India’s economic prosperity (IT services) – including an analysis of possible future of paths and action steps. This section was written by Daniel Faggella, Founder of Emerj. AI in India SWOT Analysis Highlights. We provide an overview of what we believe to be the most important 1 or 2 strengths, weaknesses, opportunities, and risks of AI in India. This section was written by Raghav Bharadwaj of Emerj. This final section – as with the rest of this research – is grounded in our conversations with dozens of AI experts in India, in addition to our analysis of other research efforts and precedents of AI’s impact in other tech ecosystems. We hope that the advice that follows will be of value for the tech and government leaders who will carry India into an age of AI disruption. Maximizing the Economic Impact of AI: “Skills and IT Services at the Speed of Now” With Madhu Gopinathan of MakeMyTrip at their Bangalore office. MakeMyTrip is one of India’s most prominent tech “unicorns” (companies valued at over $1B) India picked up on the software wave and the internet wave well behind the USA and Europe.  With the AI wave, there is the potential to catch up immediately thanks to  substantial and continuing growth in internet connectivity, and India’s swollen population of young engineers could hypothetically leap directly to the cutting edge of programming, development, and data science. India has a bulging population of young people and a clear academic focus on information technologies. If India can marshall this next generation of the tech-savvy workforce people into the right skills, they can form a huge base of just the kind of engineers and data scientists experts that the world will need most in the years ahead.  Hopefully, with access to all the latest algorithms, approaches, and use-cases thanks to the internet, Indian companies and schools can upgrade their skills nearly as quickly as do their peers in Boston or San Francisco. We suspect that the business process outsourcing (BPO) and IT services sectors has It is an industry in which India plays a strong global role, giving Indian firms a base of knowledge and skills to allow them to potentially leap over It is capable of absorbing India’s young technology graduates, allowing India to retain its best tech talent The IT services sector could serve as an additional education period, keeping talent strong in the most modern and important technology skills (including data science, data infrastructure, machine learning) Artificial intelligence isn’t destined for a necessarily positive impact on the Indian BPO and IT services sector. Automation and new technology solutions could erode India’s dominance in this back-office IT domain. With IT services being such an important center of growth for the Indian economy – it behooves India to make sure that AI technologies make their economic engine stronger, not weaker. With the advent of artificial intelligence, there seem to be three main transitions that could happen to the BPO and IT services sectors in India: 1. They could be eaten away by companies that automate their work (basic IT services, customer service work, human resources work, payroll, etc…). There’s almost certainly nothing good about this situation, unless India itself creates these new companies, and is able to retrain many of its talent to work in these new firms (which would involve significant upskilling). 2. They could stay at the bottom of the value chain, basically being relegated to tagging images, combing through data for edge cases, training algorithms, etc (we might name this scenario “The nation of mechanical turks”). India already fills the role of the world’s outsourcing destination, and many of the firms in the crowdsourced data cleaning and tagging space (Figure Eight, Mighty.ai, etc…) have large teams in India, and for good reason: Costs are low. It seems unlikely that this work will bring much additional economic value to India. Staying at the bottom of the value chain is economically limiting, and completely unlikely to position India as a technology leader. 3. They could take their deep expertise in different business processes, and be the first to automate or augment them with artificial intelligence. This would involve taking their existing expertise in BPO and IT services and finding new and better ways to solve those business problems with AI and ML This could pull out of a “copycatting” mentality (i.e. being a cheaper version of some Western business model), and become the kind of firms that the rest of the world references as “leading” and “premier,” not merely “less expensive.” The services sector is where much of India’s current and future growth is likely to come from (https://www.ibef.org/industry/services.aspx), with IT services and business process outsourcing (BPO) services employing millions of Indians.  We believe this area is worthy of focus because: IT services firms are the low-hanging fruit of practical tech experience for India’s millions and millions of technology graduates who want to stay within the country after leaving school. If these firms move their services up the value chain, they are more likely to keep India’s top graduates inside the country (paying higher wages, doing more interesting and valuable work), as opposed to losing them as many of India’s most promising graduates leave for the USA, Europe, or elsewhere. Keeping young talent in the country – and giving them more engaging and cutting-edge problems – seems to be a natural step in the direction of new innovation, as opposed to technology and service “copy-catting” (simply taking a business model created elsewhere and trying to do it cheaper in India). Having young talent working on more high-level problems in the IT services space seems likely to spin out startups, as young people engage with hard problems together. Only with more promising talent and projects will VC investments continue to grow (the base of young companies needs to be there for investment to increase). India should think about its competitive advantage the same way that Silicon Valley VCs think about the AI advantage of their portfolio companies. Namely, India should assess its areas of expertise areas and the areas where it collects masses of proprietary data. So what is the “proprietary data plume” (a term we heard first in our interview with Silicon Valley investor Ben Narasin), or self-feeding data ecosystem that India can “own” and continue to build more and more value around? Focusing on BPO and IT services sector, it seems safe to say that India has tremendous expertise in: Customer service operations (chatbots, routing, directing customers to support resources, etc) Call center operations (automating voice and conversation, routing calls, providing analytics and feedback on call performance, etc) Data entry, data management, and quality assurance workflows HR and payment processing workflows Leading in the field of white-collar and business process automation would indeed force India to compete on technical developments, rather than price. Automating office and IT work is an opportunity for all businesses and markets. For this reason, should India decide to lead the world in automating and augmenting its BPO and IT services businesses, it will be competing with startups and with large consulting firms (such as McKinsey, Accenture, Deloitte) on many fronts. The key for Indian BPO, IT, and tech firms will be to pick the domains of focus where their expertise is strongest (relative to the rest of the world), and where economic opportunity is the largest. AI in India SWOT Analysis Highlights Strengths: India has historically produced a large number of engineers, mathematicians and software developers every year. In addition to this, nearly two-thirds of Indians are under the age of 35 and almost half are under 25. By 2020, India will be the youngest country in the world, with a median age of 29 years, compared with a median age of 37 years in China at that point. India will need to put to work its growing number of young engineers and scientists in the coming decade. Enacting any AI policy at the scale of a country like India will require this foundation of this young talented workforce.  Existing IT ecosystem in India will enable a relatively easier transition into AI services. Over the last 25 years, the IT and ITeS sectors have accounted for a major chunk of the country’s GDP (see figure below). Cities like Bangalore and Hyderabad are developing hubs for IT service exports today. India is also the third largest startup ecosystem in the world today with Bangalore again being at the top of that list. The industry is now somewhat mature and added to the cheaper labor costs, a strong foundation for the upskilling using AI is already in place and economically makes sense. Source: NASSCOM Timely government funding initiatives to create good building blocks for an AI ecosystem. (Historically the Indian Government has been slow to react to technology waves – The domestic Indian IT sector was a decade slower to fully arrive in comparison to the US or China)  In terms of providing financial support for AI programmes, the Ministry of Electronics and Information Technology, Government of India, has been funding projects by educational institutions in the areas of ubiquitous computing and wireless sensor networks for real-time landslide monitoring and perception engineering (e.g. artificial sensing, perceptual robotics). The ministry has also been operating a Technology Incubation and Development of Entrepreneurs (TIDE) scheme for facilitating technology innovation over the last decade.  Although this is a start in the right direction, the level of funding from the government so far is much smaller in India compared to US and China. The recommendation here would be to develop more such public sector initiative where private sector firms can gain large contracts, strengthening the government-industrial complex in AI  Weaknesses: Industry and academic collaboration has been historically very underdeveloped. According to this report by Fujitsu in 2005, on university-industry collaborations in Asian countries, such collaborations in India were only significant (comparable) in number after 2003. Building a network of alliances between the services and products industries, academia, government organizations and start-ups. For example like the Danish ROBOCLUSTER initiative in Denmark focused on Robotics. Centers of Excellence are a good start in this regard. Opportunities: Leveraging BPO and back-office expertise, India’s IT services firms could potentially develop the world’s best office automation and BPO AI applications. This would allow India to develop a higher margin product industry, in addition to their wide low-cost services sector. Data cleaning and data tagging is a huge opportunity for near-term business. The BPO industry in India may find an opportunity in data cleaning and tagging in massive datasets, which will eventually be used to train and error-correct AI. Cheap skilled IT labor can potentially enable this opportunity. (Note: We believe that reliance on this method of AI-related work could be a detriment in the long term, which we cover in the “risks” below.) Upgrading the IT education to be on par with USA and China. There should be no “gap” between India and other nations in IT learning, and the internet could help to ensure that India’s youth bulge could receive exposure to the most modern AI approaches. Having access to a young and skilled data science workforce with graduates right at the cutting edge of the technology could be a massive boost for innovation. Risks: AI may automate low-end services work, call center work, and BPO work: The fear that AI is stealing jobs is not unique to India, but it could hit this country particularly hard because a big of its economy comes from IT services which involve relatively routine work that is prime for computers to take over. Looking ahead five years in the future, in some cases, Indian IT services companies will automate the work themselves (requiring upskilling of the workforce). In other cases, companies in the West will do it, so they no longer have to outsource work out to humans in India (resulting in loss of business). We believe that if the Indian tech services sector doesn’t embrace AI, or if they only embrace low-end data entry and data labeling work, automation and encroachment from foreign tech firms could be a significant financial blow to the country. While the NITI Aayog released the National Strategy for AI which addresses what would be India’s strategy in AI, the Ministry of IT and the Ministry of Commerce and Industry have also made similar efforts in the past.  According to Mr. P. Anandan, CEO of Wadhwani AI, nonprofit independent research institute with mission of AI for social good (and previously the Founder and Managing Director of Microsoft Research India, Professor of AI at Yale University and a member of Board of Governors of IIT Madras), the most prominent area of convergence among all these efforts has been around answering the question – What could be India’s leadership position in AI?  Anandan goes on to add:  “Germany, Japan, France etc. all have AI strategies tailored for their own countries needs and opportunities. India can be a country that leads ‘AI for all’ simply because that is necessary problem for us to solve and if we do, it will be useful for the rest of the world as well. India’s real opportunity is doing AI for social good as we have historically always been a technology test bed for social efforts and we possess the technological know-how to get it done reasonably well here.” We certainly hope that India can make the most of artificial intelligence – both for the wellbeing of its citizens and to ensure the health of its economy. The next five years will be a time to set both the pace and trend of AI adoption in the country.   Header image credit: trendingus Related Posts How Investors Feel About Artificial Intelligence - from 29 AI Founders and ExecutivesAI investments have become more and more prevalent over the last 5 years, and articles… AI and ML Adoption Survey Results from Applied Artificial Intelligence Conference 2017Artificial intelligence and machine learning adoption among different industries represents a new chapter in digital… Could Artificial Intelligence Become Conscious? 33 Researchers Contribute Their OpinionOver the last five months, we've combined a mix of interviews and surveys with some of… Artificial Intelligence in Atlanta - Strengths, Weaknesses, and Trends in the Atlanta AI EcosystemLast September I had the chance to do a series of AI-related speaking engagements in… Risks of AI - What Researchers Think is Worth Worrying AboutThe year 2015 might be seen as the year that ""artificial intelligence risk"" or ""artificial… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,AI Market Research,7881.0,,,,,,,,,,,,,,,,

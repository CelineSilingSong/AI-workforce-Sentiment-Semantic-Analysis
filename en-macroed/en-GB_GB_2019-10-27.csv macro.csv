URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,@graph,potentialAction,alternativeHeadline,mainEntityOfPage
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvY29nbml0aXZld29ybGQvMjAxOS8xMC8zMS9zaG91bGQtd2UtYmUtYWZyYWlkLW9mLWFpL9IBAA?oc=5,Should We Be Afraid of AI? - Forbes,2019-10-31,Forbes,https://www.forbes.com,"If AI is transformative, then it has the power to be transformative both for good reasons as well as bad. So, is AI something we should be scared of? ","artificial intelligence,AI,superintelligence,malicious AI,fears,ethics,transparency,anxiety","If AI is transformative, then it has the power to be transformative both for good reasons as well as bad. So, is AI something we should be scared of? ","If AI is transformative, then it has the power to be transformative both for good reasons as well as bad. So, is AI something we should be scared of? ",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/cognitiveworld/2019/10/31/should-we-be-afraid-of-ai/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/1129149103/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Ron Schmelzer', 'url': 'https://www.forbes.com/sites/ronschmelzer/', 'description': ""Ron is managing partner and founder of Cognilytica. He co-developed the firm's Cognitive Project Management for AI (CPMAI) methodology in use by Fortune 1000 firms and government agencies worldwide to effectively run and manage their AI and advanced data projects. Learn more about the Cognilytica methodology at cognilytica.com/cpmai. Ron is CPMAI+E certified, and is a lead instructor on CPMAI courses and training and is a sought-after expert on AI project management. He serves as chair of a number of industry groups focused on AI adoption and best practices, helping launch the AI working group at ATARC. Ron is co-host of Cognilytica's AI Today podcast, regular Forbes contributor, a contributor to TechTarget Editorial's Enterprise AI site and SXSW Innovation Awards judge. Prior to founding Cognilytica, Ron founded and ran ZapThink, an industry analyst firm focused on service-oriented architecture, cloud computing, web services, XML and enterprise architecture. The firm was acquired by Dovel Technologies in August 2011, which was subsequently acquired by Guidehouse. Ron received a bachelor's degree in computer science and electrical engineering from MIT, where his undergraduate advisor was well-known AI researcher Rodney Brooks. Ron also received an MBA from Johns Hopkins University."", 'sameAs': ['https://www.linkedin.com/company/cognilytica', 'https://www.twitter.com/rschmelzer', 'https://www.cognilytica.com']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Should We Be Afraid of AI?,2019-10-31T21:15:07-04:00,2022-04-14T14:03:59-04:00,AI,Should We Be Afraid of AI?,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI,N/A,"More From ForbesJul 16, 2024,09:30am EDTIn Superconvergence, Jamie Metzl Unravels AI MysteriesJul 15, 2024,09:30pm EDTAnswering Your Most Frequently Asked Questions (FAQs) About Artificial Intelligence In Honor Of National AI Appreciation DayJul 15, 2024,06:06pm EDTNot Just A Maker Space: Fab Labs Spark Innovation WorldwideJul 15, 2024,02:57pm EDTIBM InstructLab And Granite Models Revolutionizing LLM TrainingJul 15, 2024,09:42am EDTHow Generative AI Is Driving HyperpersonalizationJul 15, 2024,08:00am EDTThe Clever ‘Rephrase And Respond’ Prompting Strategy Provides Big Payoffs For Prompt EngineeringJul 13, 2024,09:00am EDTBig Tech Involvement With OpenAI Sparks Unease Among RegulatorsEdit StoryForbesInnovationAIShould We Be Afraid of AI?Ron SchmelzerContributorCOGNITIVE WORLDContributor GroupOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itOct 31, 2019,09:15pm EDTUpdated Apr 14, 2022, 02:03pm EDTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinIs AI something to fear?Getty
Recently major names in the technology industry have been talking about why the potential applications of artificial intelligence could be something we should be worried about. Their argument comes from two different places. One the one hand, they see AI as one of the most fundamental transformative technologies that we have ever seen in the history of mankind, and on the other hand, that transformative power is something we should be scared of and be wary about. If AI is transformative, then it has the power to be transformative both for good reasons as well as bad. 


However, fear of the unknown has always been the case with technology from the wheel to the internet. So, is AI something we should be scared of? The fears of AI seem to stem from a few common causes: general anxiety about machine intelligence, the fear of mass unemployment, concerns about super-intelligence, putting the power of AI into the wrong people’s hands, and general concern and caution when it comes to new technology.

General Anxiety about AI

One of the most widespread fears of AI is just general anxiety about it and what it’s potentially capable of. A recurring theme in movies and science fiction is AI systems that go rogue - think HAL from 2001: A Space Odyssey or the Terminator movie series. People don’t like machines that get too smart, because we fear we can’t control it. This popular representation of AI gone bad is causing a general wariness in the public surrounding the development of intelligent systems technologies. The fear is generally surrounding the unknown that as AI systems are becoming more intelligent and human intelligence surrounding these systems is increasing, these two unknowns don’t really give us a clear direction for where things could go. 

PROMOTED
However, just as we have examples of HAL and Terminator, we also have examples as C3PO and the computers from Star Trek. These are highly intelligent systems that are well within the control of humans. The future could be as great and benign as Star Trek if we had that perspective on the possibilities of intelligent machines. A good antidote to general anxiety is the realization that whenever human society has faced a major change or shift due to technological advances, humans has developed and adapted right along with it.
Fear of AI: AI is a Job Killer
Another major fear of AI is rooted in the idea of mass unemployment of human workers due to their replacement by AI workers. A big concern is that in the previous wave of automation, it was mostly blue collar jobs like manufacturing oriented jobs that were automated away, but in this new wave, it will be mostly white collar service-oriented jobs that are based around knowledge workers that will bear the brunt of intelligent forms of automation. The need for trained human workers in many areas of the economy will go away as the use of AI grows and increasingly permeates the business world. AI also has an effect on blue collar workers such as delivery drivers, cab drivers and many more aspects of supply chain, logistics, and manufacturing. The fact is the technology is in place that 80% of any of these jobs can be done by machines that are smart enough, so the reality already exists. 
MORE FROMFORBES ADVISORBest Travel Insurance CompaniesByAmy DaniseEditorBest Covid-19 Travel Insurance PlansByAmy DaniseEditor
The counterargument here is that some of these systems aren’t to a point where they can reliably replace many human jobs. While AI systems provide a lot of capabilities, they simply can’t operate in a fully autonomous mode. In fact, most successful AI implementations are being done such that the AI system is providing an augmented intelligence role, supporting the human at what they do best, and not fully replacing them. In general, as technology waves disrupt industries and workers, they replace job categories, but don’t take away overall jobs. In fact overall jobs continue to grow and find new niches while machines simply replace the old ways of doing things. Companies aren’t completely throwing things out that have been working for them. It’s a more general transition into the world of new technologies such as AI. As is often said, AI isn’t a job killer, it’s a job category killer.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



The fact is that a lot of industries are already being disrupted by the advancement of technology and a lot of it has nothing to do with AI. Rather, it is due to automation and streamlining processes that make it easier and quicker to go about inputting work for ourselves and not relying on businesses and other organizations to be the middleman when it comes to getting things done.


1/100:03Forbes Innovation





Skip Ad
 
Continue watchingCall Of Duty Black Ops 6 Beta Dates And More Revealedafter the adVisit Advertiser websiteGO TO PAGE
Fear of AI: Bad People Doing Bad Things
Another common fear of AI is that bad actors can do bad things when it comes to AI. Leaders in Russia made a pronouncement that whoever leads the advancement of AI is going to be one of the top rulers of the world. It is no surprise that countries are pouring significant amounts of investment and research into developing AI systems from everything to military advancement to intelligence systems that can influence the news. We can expect governments to continue to use AI systems in ways that will make us increasingly uncomfortable in the ways they are applied to warfare, surveillance, law enforcement, and other purposes. 
Yet, while we can expect governments and countries to compete with each other for AI dominance, it’s not the governments we have to fear. After all, laws and governance are there to keep an eye on government behavior. We have more to fear from bad actors, criminals, and mischief makers taking AI technologies and bending them to their ill-conceived purposes. As AI systems tend to learn from their creators, that can call into question the intention of the creator and those who are teaching the systems and what all they hope to accomplish. The fear is all stemming from the unknown. In addition, there hasn’t really been a strong counter argument as to what could be the best way to approach this particular scenario and what it means for the future.
Fear of AI: The SuperIntelligence
Probably the biggest fear of AI making media waves is that of super intelligence or that AI will reach a point where it doesn’t care for or about the existence of humanity anymore, such as what happens with Skynet in the Terminator series of movies. The technology will get to a point where it can teach itself and improve and invent on its own, and instead of becoming a force for the betterment of humanity, humanity becomes a servant of technology. The fear is that our brains will just not be able to keep up with advancement, development and invention after a certain point because things will be moving way too fast.
Computing systems could very well reach a point where they outstrip their human creators, and what will that mean for humanity when we reach that point? It makes us question what exactly intelligence is, and how we measure and define intelligence as concept for both humanity and computers, and how that new definition will fit into the world both now and moving forward. But all of this is assuming that systems can and will be able to achieve the goal of Artificial General Intelligence (AGI) and that we as a species or a society will not be able to put safeguards in place to keep the computers from reaching that point.
The big counterargument to all of this is that we are still much farther away from achieving AGI than we really think we are. While a lot of the technology is moving quickly to realizing goals of narrow AI, there are parts that aren’t working particularly well. Data is still the cornerstone of AI, and a lot of it is still messy and dirty — the Achilles Heel of AI.
All of these fears boil down to the fact that we just don’t know where AI is going and how soon it will take us to get there. Technology makes surprising and unusual leaps and bounds in ways we never think it will and things we think will take a while don’t. On the other hand things we thought would be here sooner aren’t there yet. It’s just a situation where we have to wait and see what comes.
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Ron SchmelzerFollowingFollowRon is managing partner and founder of Cognilytica. He co-developed the firm's Cognitive Project Management for AI (CPMAI) methodology in use by... Read MoreEditorial StandardsPrintReprints & Permissions",,,,
https://news.google.com/rss/articles/CBMiNmh0dHBzOi8vZW1wbG95ZWViZW5lZml0cy5jby51ay9tYXJrLWJyaWxsLWFpLXdpemFyZC1vetIBAA?oc=5,Mark Brill: Artificial intelligence and the Wizard of Oz effect - Employee Benefits,2019-10-31,Employee Benefits,https://employeebenefits.co.uk,"AI offers the potential to do amazing things, but it is not there yet; most of us would prefer to get on a plane with a pilot.",N/A,"AI offers the potential to do amazing things, but it is not there yet; most of us would prefer to get on a plane with a pilot.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

Opinion Benefits technology Benefits technology 
Mark Brill: Artificial intelligence and the Wizard of Oz effect 

31st October 2019
6:15 am


1st November 2019
3:59 pm






In the last 18 months, a painting created by artificial intelligence (AI) was sold at Christie’s for €400,000, a writing bot at tech magazine TNW out-performed its journalist colleagues, and Google announced that it had achieved quantum supremacy in a computation that would have taken a binary computer 10,000 years. AI seems to be coming of age.
In spite of all the hype, it is not quite as it appears, and the above examples actually highlight some of the challenges with the current state of AI. The painting sold at Christie’s, called Portrait of Edmund Belamy, was made by an AI algorithm, but the data input and the final selection was made by humans from the French art collective Obvious. They saw the role of AI in much the same way as other artists view a paintbrush: a tool to produce the work.
Journalists at TNW, meanwhile, pre-programmed sets of phrases into a bot called Stoshi Nagaboto which collected data about Bitcoin and turned it into short articles. Unlike its human counterparts, Stoshi did not need to pause to eat or sleep.




The machine’s performance was measured in terms of views, but this is not necessarily a good gauge of success. Journalists will spend time finely crafting insightful long-form articles that may have fewer views, but offer a much deeper level of engagement.
Google’s claims of quantum supremacy have also been disputed, with IBM stating that Google had exaggerated the speed claims, and that the calculation could have been achieved conventionally in a couple of days.
So, AI is not yet doing the job it promises, in spite of significant investments in the technology. Instead, the vast sums of money spent on development has led to a ‘fake it ’til you make it’ approach. Organisations such as Facebook, Spinvox, Clara, Expensify have all been found playing Wizard of Oz, by employing people to undertake tasks that should be done by AI.
Putting aside the deception, though, maybe it is not such a bad thing that humans remain part of the process. Amazon, for example, had to abandon using AI for recruitment, as it eliminated women from jobs, due to historical prejudice in the data used. There is a risk that this kind of data bias could also apply to the employee benefits sector.
AI offers the potential to do amazing things, but we are not there yet. While we are not that far from aeroplanes being able to fly themselves, most of us would prefer to get on one with a pilot.
We want the reassurance of a highly skilled individual on hand in case something goes wrong, so perhaps we should apply the pilot analogy to other areas of AI. Where we are making important decisions that impact on both individual and societal futures, we need skilled, knowledgeable people to ensure the machines make the right choices.
Mark Brill is senior lecturer in future media at Birmingham City University 

Read more…
How will AI change the world of benefits and HR communications?



Sign up to our newsletters
Receive news and guidance on a range of HR issues direct to your inbox

Email(Required)

OptOut

From time to time, we will send you emails about selected products, events and services from Employee Benefits – but you can choose to opt-out at any time. If you do not wish to receive these emails, please tick this box.
NameThis field is for validation purposes and should be left unchanged.
 








Δ


Ricoh uses chatbot to engage remote staff with financial wellness communications
Johnson Matthey uses intuitive technology to make pensions personal







Employee wellbeing How can Artificial Intelligence impact employee engagement? 

29th October 2018
11:23 am


29th October 2018
11:23 am







Analysis Benefits technology How artificial intelligence is influencing the world of employee benefits 

4th September 2018
6:00 am


7th September 2018
9:47 am







Analysis Benefits technology How can benefits technology create a more connected workforce? 

11th April 2019
6:00 am


16th October 2022
9:34 pm

















Sign up for the leading independent source of news and expert analysis delivered straight to your inbox.
Sign up


 Latest ArticlesComments
 

 

news Benefits for carers BT Group to roll out new family leave policy 

16th July 2024
12:14 pm


16th July 2024
12:14 pm







news Tax-efficient-benefits XPO Logistics introduces electric vehicle and hybrid salary sacrifice scheme 

16th July 2024
12:06 pm


16th July 2024
12:06 pm







news Financial education Utility Warehouse introduces personalised financial education for employees 

16th July 2024
9:00 am


15th July 2024
5:01 pm







Analysis Total reward How far can a reward and benefits strategy truly impact recruitment and retention? 

16th July 2024
6:00 am


16th July 2024
10:07 am






  


 
 



Name



Email







Cancel reply 


Threaded commenting powered by interconnect/it code.Δ 
 
 




","[{'@type': 'Article', '@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/#article', 'isPartOf': {'@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/'}, 'author': [{'@id': 'https://employeebenefits.co.uk/#/schema/person/6e8824effa854c6a097380cd98769e46'}], 'headline': 'Mark Brill: Artificial intelligence and the Wizard of Oz effect', 'datePublished': '2019-10-31T06:15:25+00:00', 'dateModified': '2019-11-01T15:59:13+00:00', 'mainEntityOfPage': {'@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/'}, 'wordCount': 534, 'commentCount': 0, 'publisher': {'@id': 'https://employeebenefits.co.uk/#organization'}, 'image': {'@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/#primaryimage'}, 'thumbnailUrl': 'https://employeebenefits.co.uk/content/uploads/2017/02/Mark-Brill.jpg', 'keywords': ['Benefits technology'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/#respond']}], 'copyrightYear': '2019', 'copyrightHolder': {'@id': 'https://employeebenefits.co.uk/#organization'}}, {'@type': 'WebPage', '@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/', 'url': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/', 'name': 'Mark Brill: Artificial intelligence and the Wizard of Oz effect', 'isPartOf': {'@id': 'https://employeebenefits.co.uk/#website'}, 'primaryImageOfPage': {'@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/#primaryimage'}, 'image': {'@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/#primaryimage'}, 'thumbnailUrl': 'https://employeebenefits.co.uk/content/uploads/2017/02/Mark-Brill.jpg', 'datePublished': '2019-10-31T06:15:25+00:00', 'dateModified': '2019-11-01T15:59:13+00:00', 'description': 'AI offers the potential to do amazing things, but it is not there yet; most of us would prefer to get on a plane with a pilot.', 'breadcrumb': {'@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/#primaryimage', 'url': 'https://employeebenefits.co.uk/content/uploads/2017/02/Mark-Brill.jpg', 'contentUrl': 'https://employeebenefits.co.uk/content/uploads/2017/02/Mark-Brill.jpg', 'width': 700, 'height': 451}, {'@type': 'BreadcrumbList', '@id': 'https://employeebenefits.co.uk/mark-brill-ai-wizard-oz/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://employeebenefits.co.uk/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Mark Brill: Artificial intelligence and the Wizard of Oz effect'}]}, {'@type': 'WebSite', '@id': 'https://employeebenefits.co.uk/#website', 'url': 'https://employeebenefits.co.uk/', 'name': 'Employee Benefits', 'description': 'Employee Benefits', 'publisher': {'@id': 'https://employeebenefits.co.uk/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://employeebenefits.co.uk/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://employeebenefits.co.uk/#organization', 'name': 'Employee Benefits', 'url': 'https://employeebenefits.co.uk/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://employeebenefits.co.uk/#/schema/logo/image/', 'url': 'https://employeebenefits.co.uk/content/uploads/2015/10/EB_RGB-new.png', 'contentUrl': 'https://employeebenefits.co.uk/content/uploads/2015/10/EB_RGB-new.png', 'width': 1300, 'height': 500, 'caption': 'Employee Benefits'}, 'image': {'@id': 'https://employeebenefits.co.uk/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://employeebenefits.co.uk/#/schema/person/6e8824effa854c6a097380cd98769e46', 'name': 'Jessica Bird', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://employeebenefits.co.uk/#/schema/person/image/27af6215545608266d8802c642ac0079', 'url': '//www.gravatar.com/avatar/6befd35de12c412c3b2e1891aa19ce8b?s=96&#038;r=g&#038;d=mm', 'contentUrl': '//www.gravatar.com/avatar/6befd35de12c412c3b2e1891aa19ce8b?s=96&#038;r=g&#038;d=mm', 'caption': 'Jessica Bird'}, 'url': 'https://employeebenefits.co.uk/author/jessica-bird/'}]",,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vd3d3LndidXIub3JnL29ucG9pbnQvMjAxOS8xMC8zMC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1qb2ItaW50ZXJ2aWV30gEA?oc=5,Your AI Interviewer Will See You Now - WBUR News,2019-10-30,WBUR News,https://www.wbur.org,Your next job interview might be conducted by a robot recruiter who's judging your competency on your facial expression and words.,N/A,Your next job interview might be conducted by a robot recruiter who's judging your competency on your facial expression and words.,Your next job interview might be conducted by a robot recruiter who's judging your competency on your facial expression and words.,,,,,,,,,,,,,,N/A,N/A,"AdvertisementHome//Radio//On PointYour AI Interviewer Will See You Now47:17Download AudioEmbed on your websiteClose×Copy the code below to embed the WBUR audio player on your site<iframe width=""100%"" height=""124"" scrolling=""no"" frameborder=""no"" src=""https://player.wbur.org/onpoint/2019/10/30/artificial-intelligence-job-interview""></iframe>Copy embed codeResumeOctober 30, 2019Meghna ChakrabartiStefano KotsonisfacebookEmail(HireVue)This article is more than 4 years old.Your next job interview might be conducted by a robot recruiter who's judging your competency on your facial expression and words.GuestsDrew Harwell, technology reporter for the Washington Post covering artificial intelligence and the algorithms that are changing our lives. (@drewharwell)Ifeoma Ajunwa, professor at Cornell University’s Industrial and Labor Relations School and a faculty member at Cornell Law School. (@iajunwa)Tomas Chamorro-Premuzic, chief talent scientist at ManpowerGroup. Professor of business psychology at University College London and at Columbia University. Associate at Harvard’s Entrepreneurial Finance Lab. Author of ""Why Do So Many Incompetent Men Become Leaders? (And How to Fix It)."" (@drtcp)Mary Cheddie, divisional director for the Eastern United States and the Caribbean at the Society of Human Resource Managers, and serves on its board of directors. Served for 30 years as the top human resources executive at major companies, for one of which she developed an AI interviewing system. (@SHRMMaryCheddie)From The Reading ListWashington Post: ""A face-scanning algorithm increasingly decides whether you deserve the job"" — ""An artificial intelligence hiring system has become a powerful gatekeeper for some of America’s most prominent employers, reshaping how companies assess their workforce — and how prospective employees prove their worth.""Designed by the recruiting-technology firm HireVue, the system uses candidates’ computer or cellphone cameras to analyze their facial movements, word choice and speaking voice before ranking them against other applicants based on an automatically generated 'employability' score.WBUR is a nonprofit news organization. Our coverage relies on your financial support. If you value articles like the one you're reading right now,  give today.""HireVue’s 'AI-driven assessments' have become so pervasive in some industries, including hospitality and finance, that universities make special efforts to train students on how to look and speak for best results. More than 100 employers now use the system, including Hilton and Unilever, and more than a million job seekers have been analyzed.""Harvard Business Review: ""Recruiting"" — ""Goldman Sachs is a people-centric business—every day our employees engage with our clients to find solutions to their challenges. As a consequence, hiring extraordinary talent is vital to our success and can never be taken for granted. In the wake of the 2008 financial crisis we faced a challenge that was, frankly, relatively new to our now 150-year-old firm. For decades investment banking had been one of the most sought-after, exciting, and fast-growing industries in the world. That made sense—we were growing by double digits and had high returns, which meant that opportunity and reward were in great supply. However, the crash took some of the sheen off our industry; both growth and returns moderated. And simultaneously, the battle for talent intensified—within and outside our industry. Many of the candidates we were pursuing were heading off to Silicon Valley, private equity, or start-ups. Furthermore, we were no longer principally looking for a specialized cadre of accounting, finance, and economics majors: New skills, especially coding, were in huge demand at Goldman Sachs—and pretty much everywhere else. The wind had shifted from our backs to our faces, and we needed to respond.""Not long ago the firm relied on a narrower set of factors for identifying 'the best' students, such as school, GPA, major, leadership roles, and relevant experience—the classic résumé topics. No longer. We decided to replace our hiring playbook with emerging best practices for assessment and recruitment, so we put together a task force of senior business leaders, PhDs in industrial and organizational psychology, data scientists, and experts in recruiting. Some people asked, 'Why overhaul a recruiting process that has proved so successful?' and 'Don’t you already have many more qualified applicants than available jobs?' These were reasonable questions. But often staying successful is about learning and changing rather than sticking to the tried-and-true.""Each year we hire up to 3,000 summer interns and nearly as many new analysts directly from campuses. In our eyes, these are the firm’s future leaders, so it made sense to focus our initial reforms there. They involved two major additions to our campus recruiting strategy—video interviews and structured interviewing.""Washington Post: ""The new way your boss can tell if you’re about to quit your job"" — ""IBM wants to keep its employees from quitting, and it’s using artificial intelligence to do it.""In a recent CNBC interview, chief executive Ginni Rometty said that thanks to AI, the tech and consulting giant can predict with 95 percent accuracy the employees who are likely to leave in the next six months. The 'proactive retention' tool — which IBM uses internally but is also selling to clients — analyzes thousands of pieces of data and then nudges managers toward the employees who may be on their way out, telling them to 'do something now so it never enters their mind,' Rometty said.""IBM’s efforts to use AI to learn who might quit is one of the more high-profile recent examples of the way data science, 'deep learning' and 'predictive analytics' are increasingly infiltrating the traditionally low-tech human resources department, arming personnel chiefs with more rigorous tools and hard data around the tricky art of managing people.""This program aired on October 30, 2019.Thank you for choosing journalism from WBUR and On Point. I’m here to ask if you would make another choice. Journalism is experiencing a profound disruption. Digital technologies and platforms are upending how we fund our work. No one is immune to this disruption. Not non-profit journalism. Not WBUR. Please consider donating to WBUR. Your contribution isn’t simply funding WBUR today; it’s an investment in the future of informed citizenship.It is taking a stand for unbiased truth, and against disinformation. You'll become an essential part of the solution we all need to protect and preserve American democracy through the free exchange of ideas, analysis and voices that would otherwise go unheard. That’s why I believe your choice to support WBUR isn’t just admirable; it’s transformative. Will you make that choice?I am grateful for your consideration. Thank you for trusting WBUR.

Meghna ChakrabartiOn Point Host, WBUR

Make a GiftIncrease Gift",,,,
https://news.google.com/rss/articles/CBMiPmh0dHBzOi8vaGJyLm9yZy8yMDE5LzEwL3VzaW5nLWFpLXRvLWVsaW1pbmF0ZS1iaWFzLWZyb20taGlyaW5n0gEA?oc=5,Using AI to Eliminate Bias from Hiring - HBR.org Daily,2019-10-29,HBR.org Daily,https://hbr.org,"AI holds the greatest promise for eliminating bias in hiring for two primary reasons. It can eliminate unconscious human bias, and it can assess the entire pipeline of candidates rather than forcing time-constrained humans to implement biased processes to shrink the pipeline from the start.",N/A,"AI holds the greatest promise for eliminating bias in hiring for two primary reasons. It can eliminate unconscious human bias, and it can assess the entire pipeline of candidates rather than forcing time-constrained humans to implement biased processes to shrink the pipeline from the start.",N/A,https://schema.org,WebSite,https://hbr.org/,,,,,,,,,,,Technology and analytics,N/A,N/A,,"{'@type': 'SearchAction', 'target': 'https://hbr.org/search?term={search_term_string}', 'query-input': 'required name=search_term_string'}",,
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vd3d3LnRoZXBhcmxpYW1lbnRtYWdhemluZS5ldS9wYXJ0bmVyL2FydGljbGUvd2h5LXRoZS1taWRkbGUtZWFzdC1pcy1mYXN0LWJlY29taW5nLWEtaHViLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Why the Middle East is fast becoming a hub of artificial intelligence - The Parliament Magazine,2019-10-28,The Parliament Magazine,https://www.theparliamentmagazine.eu,N/A,N/A,The recent announcement that the world’s first university dedicated to artificial intelligence (AI) will open its doors in Abu Dhabi in 2020 marks ...,"The recent announcement that the world’s first university dedicated to artificial intelligence (AI) will open its doors in Abu Dhabi in 2020 marks the latest move in the Middle East’s growing efforts to become a global tech hub, writes&nbsp;Guy Burton.",,,,,,,,,,,,,,N/A,N/A,N/A,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd2Fyb250aGVyb2Nrcy5jb20vMjAxOS8xMC93aXRoLWFpLXdlbGwtc2VlLWZhc3Rlci1maWdodHMtYnV0LWxvbmdlci13YXJzL9IBAA?oc=5,"With AI, We’ll See Faster Fights, but Longer Wars - War On The Rocks",2019-10-29,War On The Rocks,https://warontherocks.com,"This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric",N/A,"This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,N/A,"[{'@type': 'WebSite', '@id': 'https://warontherocks.com/#website', 'url': 'https://warontherocks.com/', 'name': 'War on the Rocks', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://warontherocks.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://warontherocks.com/2019/10/with-ai-well-see-faster-fights-but-longer-wars/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://warontherocks.com/wp-content/uploads/2019/10/RITA-II.jpg', 'width': 1330, 'height': 850}, {'@type': 'WebPage', '@id': 'https://warontherocks.com/2019/10/with-ai-well-see-faster-fights-but-longer-wars/#webpage', 'url': 'https://warontherocks.com/2019/10/with-ai-well-see-faster-fights-but-longer-wars/', 'name': 'With AI, We’ll See Faster Fights, but Longer Wars - War on the Rocks', 'isPartOf': {'@id': 'https://warontherocks.com/#website'}, 'primaryImageOfPage': {'@id': 'https://warontherocks.com/2019/10/with-ai-well-see-faster-fights-but-longer-wars/#primaryimage'}, 'datePublished': '2019-10-29T07:45:18+00:00', 'dateModified': '2019-10-29T15:46:46+00:00', 'author': {'@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8'}, 'description': 'This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://warontherocks.com/2019/10/with-ai-well-see-faster-fights-but-longer-wars/']}]}, {'@type': ['Person'], '@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8', 'name': 'Shane Mason', 'image': {'@type': 'ImageObject', '@id': 'https://warontherocks.com/#personlogo', 'inLanguage': 'en-US', 'url': 'https://secure.gravatar.com/avatar/83a68cf34a391d145ac9f37117795a86?s=96&d=identicon&r=g', 'caption': 'Shane Mason'}}]",,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvaGlzdG9yeXMtbWVzc2FnZS1hYm91dC1yZWd1bGF0aW5nLWFpL9IBAA?oc=5,History's message about regulating AI | Brookings - Brookings Institution,2019-10-31,Brookings Institution,https://www.brookings.edu,How lessons from the past can help us regulate the technologies of today.,N/A,How lessons from the past can help us regulate the technologies of today.,N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

 Back to Janesville 









                        Back to Janesville 
","[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/historys-message-about-regulating-ai/', 'url': 'https://www.brookings.edu/articles/historys-message-about-regulating-ai/', 'name': 'History’s message about regulating AI | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/historys-message-about-regulating-ai/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/historys-message-about-regulating-ai/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2019/10/Eniac.jpg?quality=75', 'datePublished': '2019-10-31T04:02:38+00:00', 'dateModified': '2022-03-09T04:36:33+00:00', 'description': 'How lessons from the past can help us regulate the technologies of today.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/historys-message-about-regulating-ai/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/historys-message-about-regulating-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/historys-message-about-regulating-ai/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2019/10/Eniac.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2019/10/Eniac.jpg?quality=75', 'width': 1340, 'height': 1024, 'caption': 'ENIAC (Electronic Numerical Integrator And Computer) in Philadelphia, Pennsylvania. Glen Beck (background) and Betty Snyder (foreground) program the ENIAC in building 328 at the Ballistic Research Laboratory (BRL).'}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/historys-message-about-regulating-ai/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'History’s message about regulating AI'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vdGhlY29udmVyc2F0aW9uLmNvbS9iZWhpbmQtdGhvc2UtaGVhZGxpbmVzLXdoeS1ub3QtdG8tcmVseS1vbi1jbGFpbXMtcm9ib3RzLXRocmVhdGVuLWhhbGYtb3VyLWpvYnMtMTI1OTM10gEA?oc=5,Behind those headlines. Why not to rely on claims robots threaten half our jobs - The Conversation,2019-10-30,The Conversation,https://theconversation.com,"Automation does threaten jobs, but the most widely cited study exaggerates the effect and pointed to job losses in places where they didn’t happen.",N/A,"Automation does threaten jobs, but the most widely cited study exaggerates the effect and pointed to job losses in places where they didn’t happen.",N/A,,,,,,,,,,,,,,N/A,N/A,"






        Most of the headlines derive from a single study. Over the past six years its predictions have been anything but accurate.
        Collage









            Behind those headlines. Why not to rely on claims robots threaten half our jobs
          




Published: October 30, 2019 2:51pm EDT












Michael Coelli, Jeff Borland, The University of Melbourne



Authors





        Michael Coelli
      


      Senior Lecturer, The University of Melbourne
    





        Jeff Borland
      


      Professor of Economics, The University of Melbourne
    





Disclosure statement
Michael Coelli receives funding from the Australian Research Council. 
Jeff Borland receives funding from the Australian Research Council.


Partners

University of Melbourne provides funding as a founding partner of The Conversation AU.
View all partners

We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)12


 Facebook180


 LinkedIn


 WhatsApp


 Messenger

 Print


Should we believe headlines claiming nearly half of all jobs will be lost to robots and artificial intelligence? 
We think not, and in a newly released study we explain why. 
Headlines trumpeting massive job losses have been in abundance for five or so years. 
Even The Conversation has had its had its share. 
Most come from a common source.  
It is a single study, conducted in 2013 by Oxford University’s Carl Benedict Frey and Michael Osborne.
This study lies behind the claim that 47% of jobs in the United States were at “high risk” of automation over the next ten or so years. 
Many claims, one source
Google Scholar says it has been cited more than 4,300 times, a figure that doesn’t count newspaper headlines.
The major predictions of job losses due to automation in Australia are based directly on its findings. Commentaries about the future of work in Australia have also drawn extensively on the study. 



What if robots can do less than we think?
Shutterstock


In Australia and elsewhere the study’s predictions have led to calls for a Universal Basic Income and for a “work guarantee” that would allocate the smaller number of jobs fairly. 
Our new research paper concludes the former study’s predictions are not well-founded. 
It has two weaknesses. 
First, the method used to make predictions has major flaws.
Second, the predictions have not fared well when compared to actual changes in employment in the United States in the time since they were made.
Flawed method
The study authors asked a group of machine learning experts to identify jobs from a long list that could be automated. 
The experts concluded that half of the jobs on the list could be done by robotics and artificial intelligence in the near future. 
What’s wrong with that?
While those interviewed were experts in machine learning, they were not experts in the many jobs they considered. They were simply asked to look at a short text description of each job along with a list of tasks associated with it. 
Some of their predictions might make sense, such as most driving-related jobs being at risk. 




      Read more:
      Driverless cars: once they're on the road, human drivers should be banned




Those jobs seem unlikely to vanish entirely in the next decade; but given recent developments in driverless cars, their demise might not be far away. 
But other predictions are harder to understand, such as the claim the jobs of accountants, marketing specialists and claims investigators are at risk over the next decade or so. 
Standard descriptions of the tasks undertaken by accountants include interpretation of information about accounting records and organisational performance. Interpretation is usually regarded as outside the scope of work that can be done by artificial intelligence. 
The work of accountants may well change with advances in artificial intelligence, but it is unlikely to be lost.
Exaggerated retelling
Equally troubling, we show the study’s predictions are inconsistent with the study authors’ views about how robots and artificial intelligence will affect jobs. 
The authors write that recent advances in robotics are still struggling with the challenge of manipulating small objects. Yet their study ends up predicting many jobs that require this sort of manipulation are at high risk of being lost in ten to 15 years.
Keep in mind the authors did not themselves claim all the jobs they identified would be lost. Instead, they claimed it would become technologically feasible to replace them.
Unfortunately, that was a distinction almost entirely lost in the headlines – which portrayed the study’s predictions as forecasts of what would happen. 




      Read more:
      Machines on the march threaten almost half of modern jobs




But replacing workers with machines requires more than having the machines available. 
It requires investment in new (and likely very expensive) technologies. It requires governments to permit their use (as with driverless cars). And it requires workers be trained in their installation and maintenance.
Little predictive power
The study was initially published in 2013, six years ago, so it is possible to evaluate the predictions that were made by comparing them against actual changes in employment.
When we do this, we find the predictions don’t add anything to our understanding of actual employment changes in the United States.
Economists already had developed a well-grounded and empirically supported framework for understanding the effect of technological change on employment. 




      Read more:
      Why we are still convinced robots will take our jobs despite the evidence




That framework is built on the concept robots and computers are very good at undertaking tasks that are routine, not so good at less routine tasks.
It has performed well in explaining employment in Australia and internationally and did so in the US between 2013 to 2018.
Our calcuations show this framework better explains what happened to the number of people in jobs by occupation in the US from 2013 to 2018 than the study’s predictions. 
Note that we did not examine whether the study correctly forecast what would happen (that would have been a big ask), merely whether its framework produced better forecasts than or added value to the existing framework. It did neither.
Some jobs will grow, others will die
Routine jobs will indeed dwindle as machines replace workers, but other jobs are likely to flourish. One occupation that stands out is personal care. Classified by the study as at high risk of automation, employment in it in the US has nearly doubled since the study was published.
Reality is often more complex (and interesting) than headlines.
For a more believable account of what is likely to happen we suggest a paper from the leading labour economist in the field, David Autor.
Its title: Why Are There Still So Many Jobs? The History and Future of Workplace Automation.





Artificial intelligence (AI)


Unemployment


Automation


Robots


Jobs of the future









",,,,
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vcHVyc3VpdC51bmltZWxiLmVkdS5hdS9hcnRpY2xlcy90aGUtcGVyc29uYWxpdHktaW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2XSAQA?oc=5,The 'personality' in artificial intelligence | Pursuit by the University of Melbourne - Pursuit,2019-10-27,Pursuit,https://pursuit.unimelb.edu.au,"As artificial intelligence (AI) and deep learning continue to impact many human industries, would understanding the ‘personality’ within the algorithm make us trust AI more?",N/A,"As artificial intelligence impacts many human industries, University of Melbourne research looks at whether an algorithm with ‘personality’ would build trust.","As artificial intelligence impacts many human industries, University of Melbourne research looks at whether an algorithm with ‘personality’ would build trust.",http://schema.org,NewsArticle,,"{'@type': 'ImageObject', 'url': 'https://pursuit.unimelb.edu.au/__data/assets/image/0026/91547/a7d3545b3f47a23493421776c5a4538e820c7848.jpg', 'height': 1200, 'width': 1800}",[],"{'@type': 'Organization', 'name': 'The University of Melbourne', 'logo': {'@type': 'ImageObject', 'url': 'https://pursuit.unimelb.edu.au/__data/assets/file/0020/929/UOMLogo.svg', 'width': 80, 'height': 80}}",The ‘personality’ in artificial intelligence,2019-10-27T17:54:27+11:00,2024-07-10T21:17:53+10:00,,,,,N/A,N/A,Sciences & TechnologyThe very human language of AI ,,,,"{'@type': 'WebPage', '@id': 'https://pursuit.unimelb.edu.au/articles/the-personality-in-artificial-intelligence'}"
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vd3d3LmdzYi5zdGFuZm9yZC5lZHUvaW5zaWdodHMvZXhwbG9yaW5nLWh1bWFuLXNpZGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2XSAQA?oc=5,Exploring the Human Side of Artificial Intelligence | Stanford Graduate School of Business - Stanford Graduate School of Business,2019-10-28,Stanford Graduate School of Business,https://www.gsb.stanford.edu,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,N/A,N/A,"



Innovation 



  Exploring the Human Side of Artificial Intelligence 



At an AI forum, experts say the arrival of superhuman machine intelligence will be one of the biggest events in human history.



November 07, 2019


| by 
Clifton B. Parker





Twitteropen in new window
LinkedInopen in new window
Facebookopen in new window
Emailopen in new window











Image
 

HAI Distinguished Fellow Erik Brynjolfsson and Stanford GSB Professor Susan Athey discuss the ethics of AI at a recent conference. | Holly Hernandez


An underlying theme emerged from the Stanford Institute for Human-Centered Artificial Intelligence’s fall conference: AI must be truly beneficial for humanity and not undermine people in a cold calculus of efficiency.
Titled AI Ethics, Policy, and Governanceopen in new window, the event brought together more than 900 people from academia, industry, civil society, and government to discuss the future of AI (or automated computer systems able to perform tasks that normally require human intelligence).
Discussions at the conference highlighted how companies, governments, and people around the world are grappling with AI’s ethical, policy, and governance implications.
Expanding Human Experience
Susan Athey, the Economics of Technology Professor at Stanford Graduate School of Business and faculty associate director at Stanford HAI, spoke about AI’s impact on the economy. It’s critical, she said, that AI creates shared prosperity and expands — rather than replaces — the human experience in life and at work. Humans, after all, understand things in a way that may be difficult to codify in AI. How we organize and think about the future of work for people as well as machines is important, as it is all interconnected, she added.
“The real benefits of AI come when we dive into the applications and understand the entire vertical, everything through implementation, including the ethics and the feelings of people adopting it,” Athey said.
Erik Brynjolfssonopen in new window, director of the Initiative on the Digital Economy at MIT, said companies building AI need to focus on the human side in addition to the eye-popping technology. “We need to understand first what our values are so we can understand how best to use these technologies.” He said it’s necessary to rethink the whole organizational and business process in terms of how AI fits in with the human culture.
Other panelists discussed the roles of public entities and private enterprise when it comes to regulating AI.
Eric Schmidtopen in new window, the former CEO of Google and technical advisor to Alphabet Inc., spoke with Marietje Schaakeopen in new window, a Dutch member of the European Parliament who played a role in the European Union’s regulation of big tech and is the Stanford Cyber Policy Centeropen in new window’s international policy director.
Schmidt noted that ethics matter in how a human decision is combined with an AI decision and said that “liberal, Western values” are important to support at a time when countries like China are using AI technology to repress and surveil their own people. “We want to make sure the systems we’re building are built on our values, human values,” he said.
Schaake urged that policymakers worldwide should take a citizen-oriented approach to AI policies and regulations, rather than follow a more corporate user-oriented framework. She advocated greater regulation of how tech companies use big data and stronger privacy protections for individuals, and urged that regulation should happen sooner rather than later in the case of artificial intelligence.
“We need a deeper debate about which tasks need to stay in the hands of the public and out of the market,” she said.
Ethics, Geopolitics, and Diversity
Reid Hoffmanopen in new window, cofounder of LinkedIn, talked about his concept of “blitzscalingopen in new window,” a set of techniques learned at Silicon Valley companies to develop innovations quickly. Hoffman said this should happen in AI simultaneously with a sense of ethics and responsibility.
 

Quote
We need a deeper debate about which tasks need to stay in the hands of the public, and out of the market.


Attribution
Marietje Schaake

For example, when fast-growing companies plan for the future and quickly build up their engineering or sales capabilities, they also need to anticipate risk and what could go wrong on the road ahead. This means hiring people who understand risk and ethics and developing a risk framework for the company that is combined with a sense of ethics.
In the area of health care and disease, DJ Patilopen in new window, the head of technology for Devoted Health, noted how AI holds tremendous promise for treating people and saving lives: “We need to go at maximum warp speed to help those people.” The challenge is how to bring those cures and treatments to market quickly while also adhering to the necessary health care safeguards and ethical sensibilities.
Patil also called for more cooperation on data sharing around the world. “We have climate change, the potential for pandemics. What we need is better international frameworks, treaty mechanisms to share data across regional lines so that we can actually work on human problems.”
AI and National Security
In an AI and Geopolitics breakout session, led by Amy Zegartopen in new window, a senior fellow at the Freeman Spogli Institute for International Studiesopen in new window and at the Hoover Institutionopen in new window, panelists analyzed the nature of artificial intelligence, its role in national security, intelligence, and safety systems, and how it may affect strategic stability — or instability.
On the latter, Colin H. Kahlopen in new window, codirector of Stanford’s Center for International Security and Cooperationopen in new window, raised concerns about whether AI would increase economic tensions among the world’s most powerful nations and alter the global military balance of power if some countries move ahead quickly on AI while others fall behind. Another concern he mentioned was the possibility of someone using AI-enabled cyber weapons against nuclear command and control centers.
Zegart added that machine learning can help lighten the cognitive load when intelligence specialists are analyzing and sifting through data, which today is being produced at an accelerated rate. The challenge is organizational, as bureaucracies are slow to adopt game-changing technology.







Innovation ,
Technology & AI 




Twitteropen in new window
LinkedInopen in new window
Facebookopen in new window
Emailopen in new window



Share this
https://stanford.io/33sl5sn



Sign up for more insights and ideas.








For media inquiries, visit the Newsroom.




Explore More






March 05, 2024



 To Discover Breakthrough Ideas, Look to the Outsiders



An AI-boosted search for prescient ideas finds they’re more likely to come from the periphery than the core.



Innovation










February 08, 2023



 Quick Thinks: AI Has Entered the Chat — a “Conversation” with ChatGPT



In this podcast episode, Matt Abrahams interviews an algorithm. 



Innovation










October 14, 2022



 How to Survive the A.I. Revolution



A human-centered approach to artificial intelligence envisions a future where people and machines are collaborators, not competitors.



Innovation











Editor’s Picks
Editor’s Picks

 
  Oh, the Humanity! How Relating to Robots May Change Us
 
  Redefining Success: Adopt the Journey Mindset to Move Forward
 
  From Dreaming to Doing: How We Set and Achieve Goals





Related
Related






 




                  Susan Athey
              

                                          Professor, Economics
              


@Susan_Atheyopen in new window 













October 28, 2019



 Big Data and Racial Bias: Can That Ghost Be Removed from the Machine?



Credit-market algorithms may violate anti-discrimination laws even when they’re designed not to. A Stanford researcher looks for a fix.













February 08, 2019



 Don’t Let Artificial Intelligence Pick Your Employees



A Stanford GSB scholar shares why algorithms aren’t sophisticated enough to make these strategic decisions ... yet.











Learn More About Stanford HAIopen in new window 

Watch the Conference: Day Oneopen in new window 

Watch the Conference: Day Twoopen in new window 






",,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LnJzdHJlZXQub3JnL2NvbW1lbnRhcnkvZml2ZS1teXRocy1hYm91dC1vbmxpbmUtY29udGVudC1tb2RlcmF0aW9uLWZyb20tYS1mb3JtZXItY29udGVudC1tb2RlcmF0b3Iv0gEA?oc=5,"Five myths about online content moderation, from a former content moderator - R Street",2019-10-30,R Street,https://www.rstreet.org,N/A,N/A,"The internet has altered every aspect of our lives. It has helped us launch political campaigns, begin romantic relationships, discover faraway places, document human rights abuses, and ensure that those subject to disasters are safe and have access to the resources they need. Much like any other great innovation, however, it also has its dark...",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"



Real Solutions Five myths about online content moderation, from a former content moderator 


by 
Daisy Soderberg-Rivkin 
Oct 30, 2019 


 Print





Share via Email: Five%20myths%20about%20online%20content%20moderation,%20from%20a%20former%20content%20moderator





Share via Facebook: Five%20myths%20about%20online%20content%20moderation,%20from%20a%20former%20content%20moderator





Share via Twitter: Five%20myths%20about%20online%20content%20moderation,%20from%20a%20former%20content%20moderator





 Share






issues: 
Artificial Intelligence, Online Content Policy, Technology and Innovation 




 



The internet has altered every aspect of our lives. It has helped us launch political campaigns, begin romantic relationships, discover faraway places, document human rights abuses, and ensure that those subject to disasters are safe and have access to the resources they need. Much like any other great innovation, however, it also has its dark side.
Indeed, the internet has become a breeding ground for terrorists, a marketplace for human trafficking, a platform for child sexual exploitation, and a stage for hate speech and violence. To combat the presence of such terrible things, the job of content moderator was born.
Content moderators review and analyze user reports of abusive content found on platforms and decide, based on a predetermined set of rules and guidelines as well as the law, whether the content should stay up or come down.
The debates stirring in Congress and society relating to the role of content moderators have fueled many a baseless claim. Here are five of the most repeated myths.
Myth No. 1: Content moderators are part-time employees who work in less-than-ideal conditions. 
The conditions tied to this type of work have spawned horror stories of content moderators working as contractors for as little as $28,800 per year under extreme micromanagement. In the Philippines, workers operate out of jam-packed malls where they spend over nine hours a day moderating content for as little as $480 a month. With few workday breaks and no access to counseling, many of these individuals end up suffering from insomnia, depression and post-traumatic stress disorder.
These workers are real, and these stories are true. However, another set of content moderators exists. These employees also often struggle to deal with what they come across online due to the nature of the job, but their working conditions are significantly better. They live in the Bay Area and are paid well. They are lawyers, veterans, former teachers, economists and consultants. They speak over 15 languages. They represent the initial vision for the content moderator.
The appalling working conditions of contractors are a direct result of the internet’s unforeseen explosion. None of these platforms ever could have fathomed having so many users, and no one could have foreseen the horrific videos, photos and posts that would someday find their way onto the internet. As a result, there has been significant outside pressure to further moderate this content, leading some companies to resort to hiring contractors to perform this work.
Many believe the answer is to simply bring all moderators in-house. While tech companies can afford to do so, the mental health impacts of the job remain. Indeed, in many ways, content moderators’ work resembles that of first responders and crime scene investigators. The difference is that for those jobs, employers have come up with ways to help their employees cope with trauma, including peer support programs, individual counseling, physical fitness programs and an allotted amount of time for work. Incorporating these solutions would make a world of difference for content moderators.
Myth No. 2: Content moderation is censorship .
Some see content moderation as a form of censorship; a way for organizations to exercise control over users’ speech by blocking comments, posts, reviews, search results and other types of content they deem undesirable.
The truth is, content moderation is not about censorship; it is about providing a healthy and safe environment where users can upload their own products, posts or comments and comfortably engage with others. It’s a tool to improve user experience, ensure that platforms adhere to local and global laws, and helps users trust that they can interact through a platform or use a service without fear of being deceived.
Flags and report buttons allow users to notify site owners when something seems out of place. Human moderators ensure that all users comply with community standards. Well-trained AI moderation solutions use filters to screen for inappropriate words, phrases and images to help weed out trolls, bullies and spammers. In other words, content moderators keep online spaces great places to be.
In a cyber world filled with extremism, violence, child sexual abuse imagery and revenge porn, there is scarcely time to think about censoring speech that does not align with an individual’s particular politics or viewpoint. Admittedly, moderators are human beings, so mistakes can be made. However, chances are that if content has come down, it is because it is at odds with the platform’s terms of service or policies, or the law, not with the moderator’s personal bias.
Myth No. 3: Tech companies can vet all content before it is uploaded. 
Content moderation was never meant to operate at the scale of billions of users. Yet currently, 300 hours of video content is uploaded to YouTube every minute, over 95 million photos are uploaded to Instagram each day, and over 500 million tweets are sent on Twitter each day (that is 6,000 tweets per second). It is simply impossible for human moderators to vet every piece of content that is uploaded before it goes live.
Myth No. 4: Artificial Intelligence (AI) can moderate content on its own. 
Automated systems using AI and machine learning are certainly doing quite a bit to help with this unfathomably enormous task. They act as triage systems, for example, by pushing suspect content to human moderators and weeding out some unwanted material on their own. However, AI cannot solve the online content moderation problem without human help.
AI either uses visual recognition to identify a relatively broad category of objectionable content, or it matches content to an index of banned items. The latter approach is used in cases of obvious illicit material, such as terrorist content or child sexual abuse imagery. In these cases, content is given a “hash,” or an ID, so that if it is detected again, the uploading process will be disabled. Regardless of which method is used, the parameters must be set by human beings.
What’s more, while these AI-driven processes are mostly reliable, problems can arise. As Tarleton Gillespsie writes in “Custodians of the Internet,” “Automated detection is just not an easy task — arguably it’s an impossible one, given that offense depends so critically on both interpretation and context.” Indeed, AI has trouble looking for context and understanding certain dynamics, such as the varying legal regimes in different countries. AI also lacks the ability to account for the constant changes in how humans classify and define problematic content. These complexities make it difficult for people to moderate content, so how can we expect a machine, which is programmed by humans, to get the job done?
This is not to say that there is no hope for AI. Yet for the moment, it will remain a complement to human-driven content moderation as opposed to a replacement.
Myth No. 5: A removal of Section 230 will make for better moderation practices. 
Under Section 230 of the Communications Decency Act, websites and internet service providers are not liable for the comments, pictures and videos that their users and subscribers post, no matter how bad they are (with certain exceptions). By providing this immunity, the hope was that companies would be free to adopt basic conduct codes and delete material that the companies deemed inappropriate. The law also prevents platforms from being held liable for good faith actions to block “obscene, lewd, lascivious, filthy, excessively violent, harassing or otherwise objectionable material.” In fact, Section 230 can be thought of as giving birth to, and making possible, content moderation.
If lawmakers rescind Section 230 protection, tech companies will be open to a lawsuit every time a moderator decides to remove content or leave it on the platform. As a result, these companies would be forced to do one of two things: Either allow everything that anyone posts to remain — including horrific content like terrorist execution videos, Ku Klux Klan propaganda, etc. — or only allow approved content to be published. Given the astronomical amount of content uploaded to platforms each day (see Myth No. 3), many companies would likely opt to allow the vilest content to remain on their platforms rather than risking the myriad lawsuits and fines that could easily put them out of business.
In short, removal of Section 230 immunity does not make for more “fair” moderation practices; it removes the incentive to moderate altogether.
Yet this past June, Sen. Josh Hawley unveiled a bill entitled the “Stop Internet Censorship Act.” Under the Hawley bill, the Federal Trade Commission would audit major platforms’ moderation practices every two years to determine whether those practices were “biased against a political party, political candidate or political viewpoint.” Platforms that are not able to satisfy this standard would lose their Section 230 immunity. This would not only eliminate the incentive for these platforms to moderate their users’ content, it would effectively grant the government control over online speech.
Conclusion
For years now, many have demanded that various internet platforms “do more” in relation to content moderation. In response, large tech companies have hired thousands of content moderators to do this work. These moderators must perform a complex balancing act: They must follow the law, keep users safe, protect free speech online, and ensure that the product still thrives in the marketplace. Doing so requires moderators drown themselves in a sea of beheading videos, rape videos, and crime scenes photos for hours on end, every day. Even in-house content moderators, with good pay, and good working conditions, are plagued by the content they see on a constant basis.
Many assume that large tech companies can easily hide the worst parts of humanity that find their way onto the internet. But there is no easy solution to what is happening online. With billions of users, there will never be enough moderators to make sure everything is checked. Legal complaints and methods for reporting abuse helps to narrow it down, but even so, the task is overwhelming. As someone who once did this work, it is frustrating to watch so many politicians demand that companies “do something” without realizing the complexities involved. What’s more, many proposed solutions will not work and would instead create harmful unintended consequences.
What is happening online is a reflection on our society. Tech companies — and content moderators in particular — cannot magically fix the evil found within humanity, nor can we prevent it from finding its way online.
Can improvements be made? Certainly. This is why I left the tech world to work in the policy space. I understand these issues thanks to my first-hand experience and I want to raise awareness and advocate for intelligent change. But I can’t do it on my own. Lawmakers and the public need to understand just what content moderation is, and the consequences of tinkering with it, before drawing conclusions or making demands. (Image credit: GaudiLab)



Get the latest in AI policy right in your inbox. Sign up for R Street’s newsletter today. 

Email(Required)


  

















More artificial intelligence policy



 

Real Solutions Artificial Intelligence, Electoral Reform, Governance, Technology and Innovation 
AI can make our elections safer—if we use it correctly


					Ann Phelan				
June 11, 2024 


 

Analysis Artificial Intelligence, Cybersecurity Policy, Data Security and Data Privacy, Federal Government Affairs, Technology and Innovation 
The U.S. Senate Takes a Swing at Data Privacy and AI


					Steven Ward				
July 11, 2024 


 

Analysis Artificial Intelligence, Technology and Innovation 
AI and Public Health Series: Introduction


					Adam Thierer				
July 9, 2024 


 

Analysis Artificial Intelligence, Technology and Innovation 
AI and Public Health Series: How AI can advance medical knowledge and improve the patient experience


					Adam Thierer				
July 9, 2024 


 

In the News Artificial Intelligence, Technology and Innovation 
Trump pledges to ax Biden’s AI executive order


					Adam Thierer				
July 9, 2024 NextGov



 

Op-Eds Artificial Intelligence, South, State Policy, Technology and Innovation 
Georgia Legislature searches for (artificial) intelligence


					Marc Hyden				
July 8, 2024 Newnan Times-Herald



 

Analysis Artificial Intelligence, Cyber Threats, Cybersecurity, Cybersecurity Policy, Data Security and Data Privacy, Technology and Innovation 
Preparing for the Next AI Frontier: Leveraging AI Compute Security to Counter Threats in Edge Devices


					Haiman Wong				
July 8, 2024 


 

Analysis Artificial Intelligence, Electoral Reform, Governance, South, State Policy, Technology and Innovation 
Louisiana Governor Wisely Vetoes AI Bills That Restrict Political Speech


					Chris McIsaac				
July 3, 2024 


 

Real Solutions Artificial Intelligence, Electricity Policy, Energy and Environment, Low-Energy Fridays, Technology and Innovation 
Low-Energy Fridays: Should we care about AI’s electricity consumption?


					Philip Rossetti				
June 14, 2024 


 

Analysis Artificial Intelligence, Federal Government Affairs, Open Government, Technology and Innovation 
Potential for AI Deepfakes Tomorrow Does Not Justify Government Secrecy Today


					Chris McIsaac				
June 13, 2024 


 

Real Solutions Artificial Intelligence, Electoral Reform, Governance, Technology and Innovation 
AI can make our elections safer—if we use it correctly


					Ann Phelan				
June 11, 2024 


 

Analysis Artificial Intelligence, Cybersecurity Policy, Data Security and Data Privacy, Federal Government Affairs, Technology and Innovation 
The U.S. Senate Takes a Swing at Data Privacy and AI


					Steven Ward				
July 11, 2024 


 

Analysis Artificial Intelligence, Technology and Innovation 
AI and Public Health Series: Introduction


					Adam Thierer				
July 9, 2024 


 

Analysis Artificial Intelligence, Technology and Innovation 
AI and Public Health Series: How AI can advance medical knowledge and improve the patient experience


					Adam Thierer				
July 9, 2024 


 

In the News Artificial Intelligence, Technology and Innovation 
Trump pledges to ax Biden’s AI executive order


					Adam Thierer				
July 9, 2024 NextGov



 

Op-Eds Artificial Intelligence, South, State Policy, Technology and Innovation 
Georgia Legislature searches for (artificial) intelligence


					Marc Hyden				
July 8, 2024 Newnan Times-Herald



 

Analysis Artificial Intelligence, Cyber Threats, Cybersecurity, Cybersecurity Policy, Data Security and Data Privacy, Technology and Innovation 
Preparing for the Next AI Frontier: Leveraging AI Compute Security to Counter Threats in Edge Devices


					Haiman Wong				
July 8, 2024 


 

Analysis Artificial Intelligence, Electoral Reform, Governance, South, State Policy, Technology and Innovation 
Louisiana Governor Wisely Vetoes AI Bills That Restrict Political Speech


					Chris McIsaac				
July 3, 2024 


 

Real Solutions Artificial Intelligence, Electricity Policy, Energy and Environment, Low-Energy Fridays, Technology and Innovation 
Low-Energy Fridays: Should we care about AI’s electricity consumption?


					Philip Rossetti				
June 14, 2024 


 

Analysis Artificial Intelligence, Federal Government Affairs, Open Government, Technology and Innovation 
Potential for AI Deepfakes Tomorrow Does Not Justify Government Secrecy Today


					Chris McIsaac				
June 13, 2024 


 

Real Solutions Artificial Intelligence, Electoral Reform, Governance, Technology and Innovation 
AI can make our elections safer—if we use it correctly


					Ann Phelan				
June 11, 2024 





","[{'@type': 'WebPage', '@id': 'https://www.rstreet.org/commentary/five-myths-about-online-content-moderation-from-a-former-content-moderator/', 'url': 'https://www.rstreet.org/commentary/five-myths-about-online-content-moderation-from-a-former-content-moderator/', 'name': 'Five myths about online content moderation, from a former content moderator - R Street Institute', 'isPartOf': {'@id': 'https://www.rstreet.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.rstreet.org/commentary/five-myths-about-online-content-moderation-from-a-former-content-moderator/#primaryimage'}, 'image': {'@id': 'https://www.rstreet.org/commentary/five-myths-about-online-content-moderation-from-a-former-content-moderator/#primaryimage'}, 'thumbnailUrl': 'https://www.rstreet.org/wp-content/uploads/2019/10/shutterstock_390162664.jpg', 'datePublished': '2019-10-30T16:24:57+00:00', 'dateModified': '2023-07-24T12:56:49+00:00', 'breadcrumb': {'@id': 'https://www.rstreet.org/commentary/five-myths-about-online-content-moderation-from-a-former-content-moderator/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.rstreet.org/commentary/five-myths-about-online-content-moderation-from-a-former-content-moderator/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.rstreet.org/commentary/five-myths-about-online-content-moderation-from-a-former-content-moderator/#primaryimage', 'url': 'https://www.rstreet.org/wp-content/uploads/2019/10/shutterstock_390162664.jpg', 'contentUrl': 'https://www.rstreet.org/wp-content/uploads/2019/10/shutterstock_390162664.jpg', 'width': 1000, 'height': 668}, {'@type': 'BreadcrumbList', '@id': 'https://www.rstreet.org/commentary/five-myths-about-online-content-moderation-from-a-former-content-moderator/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.rstreet.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Commentary', 'item': 'https://www.rstreet.org/commentary/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Five myths about online content moderation, from a former content moderator'}]}, {'@type': 'WebSite', '@id': 'https://www.rstreet.org/#website', 'url': 'https://www.rstreet.org/', 'name': 'R Street Institute', 'description': 'Free Markets. Real Solutions.', 'publisher': {'@id': 'https://www.rstreet.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.rstreet.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.rstreet.org/#organization', 'name': 'R Street Institute', 'url': 'https://www.rstreet.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.rstreet.org/#/schema/logo/image/', 'url': 'https://www.rstreet.org/wp-content/uploads/2022/09/Frame.svg', 'contentUrl': 'https://www.rstreet.org/wp-content/uploads/2022/09/Frame.svg', 'caption': 'R Street Institute'}, 'image': {'@id': 'https://www.rstreet.org/#/schema/logo/image/'}}]",,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvZm9yLXNvbWUtZW1wbG95bWVudC1hbGdvcml0aG1zLWRpc2FiaWxpdHktZGlzY3JpbWluYXRpb24tYnktZGVmYXVsdC_SAQA?oc=5,"For some employment algorithms, disability discrimination by default | Brookings - Brookings Institution",2019-10-31,Brookings Institution,https://www.brookings.edu,Alex Engler considers how algorithms analyzing video of job interviews may discriminate against disabilities not represented in training data.,N/A,Alex Engler considers how algorithms analyzing video of job interviews may discriminate against disabilities not represented in training data.,N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

 Back to Janesville 









                        Back to Janesville 
","[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/for-some-employment-algorithms-disability-discrimination-by-default/', 'url': 'https://www.brookings.edu/articles/for-some-employment-algorithms-disability-discrimination-by-default/', 'name': 'For some employment algorithms, disability discrimination by default | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/for-some-employment-algorithms-disability-discrimination-by-default/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/for-some-employment-algorithms-disability-discrimination-by-default/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2019/05/facial_recognition.jpg?quality=75', 'datePublished': '2019-10-31T16:56:08+00:00', 'dateModified': '2022-03-09T04:36:52+00:00', 'description': 'Alex Engler considers how algorithms analyzing video of job interviews may discriminate against disabilities not represented in training data.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/for-some-employment-algorithms-disability-discrimination-by-default/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/for-some-employment-algorithms-disability-discrimination-by-default/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/for-some-employment-algorithms-disability-discrimination-by-default/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2019/05/facial_recognition.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2019/05/facial_recognition.jpg?quality=75', 'width': 3600, 'height': 2400, 'caption': 'Visitors check their phones behind the screen advertising facial recognition software during Global Mobile Internet Conference (GMIC) at the National Convention in Beijing, China April 27, 2018. REUTERS/Damir Sagolj - RC1838EC3EA0'}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/for-some-employment-algorithms-disability-discrimination-by-default/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'For some employment algorithms, disability discrimination by default'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vb25jdWJhbmV3cy5jb20vZW4vY3ViYS9jdWJhLWFuZC1jaGluYS1hZ3JlZS10by1kZXZlbG9wLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW9uLXRoZS1pc2xhbmQv0gEA?oc=5,Cuba and China agree to develop artificial intelligence on the island | OnCubaNews English - OnCubaNews,2019-10-29,OnCubaNews,https://oncubanews.com,A second agreement was signed to enhance the teaching of Spanish between the two countries.,N/A,Authorities from Cuba and China signed a cooperation agreement with the aim of creating an artificial intelligence center on the,Authorities from Cuba and China signed a cooperation agreement with the aim of creating an artificial intelligence center on the,https://schema.org,,,,,,,,,,,,,Cuba,N/A,"





Cuba on WhatsApp: between viruses, hurricanes and capped prices

 July 15, 2024

","[{'@type': 'WebPage', '@id': 'https://oncubanews.com/en/cuba/cuba-and-china-agree-to-develop-artificial-intelligence-on-the-island/', 'url': 'https://oncubanews.com/en/cuba/cuba-and-china-agree-to-develop-artificial-intelligence-on-the-island/', 'name': 'Cuba and China agree to develop artificial intelligence on the island | OnCubaNews English', 'isPartOf': {'@id': 'https://oncubanews.com/en/#website'}, 'primaryImageOfPage': {'@id': 'https://oncubanews.com/en/cuba/cuba-and-china-agree-to-develop-artificial-intelligence-on-the-island/#primaryimage'}, 'image': {'@id': 'https://oncubanews.com/en/cuba/cuba-and-china-agree-to-develop-artificial-intelligence-on-the-island/#primaryimage'}, 'thumbnailUrl': 'https://oncubanews.com/en/wp-content/uploads/2019/10/ia-cub-chn-1.jpg', 'datePublished': '2019-10-29T23:06:09+00:00', 'dateModified': '2019-10-29T23:06:09+00:00', 'author': [{'@type': 'Person', '@id': 'https://oncubanews.com/en/#/schema/person/d7171bf311032ab1f557dd8332e714af', 'name': 'OnCuba Staff', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://oncubanews.com/en/#/schema/person/image/46fbae0226674e4421bf7a0d3af05995', 'url': 'https://oncubanews.com/en/wp-content/wphb-cache/gravatar/e89/e897e84fb5d45e532ec53b2712a47acfx96.jpg', 'contentUrl': 'https://oncubanews.com/en/wp-content/wphb-cache/gravatar/e89/e897e84fb5d45e532ec53b2712a47acfx96.jpg', 'caption': 'OnCuba Staff'}, 'url': 'https://oncubanews.com/en/author/oncuba-editorial-staff/'}, {'@type': 'Person', '@id': 'https://oncubanews.com/en/#/schema/person/d7171bf311032ab1f557dd8332e714af', 'name': 'OnCuba editorial staff', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://oncubanews.com/en/#/schema/person/image/46fbae0226674e4421bf7a0d3af05995', 'url': 'https://oncubanews.com/en/wp-content/wphb-cache/gravatar/e89/e897e84fb5d45e532ec53b2712a47acfx96.jpg', 'contentUrl': 'https://oncubanews.com/en/wp-content/wphb-cache/gravatar/e89/e897e84fb5d45e532ec53b2712a47acfx96.jpg', 'caption': 'OnCuba editorial staff'}, 'url': 'https://oncubanews.com/en/author/oncuba-editorial-staff/'}], 'description': 'A second agreement was signed to enhance the teaching of Spanish between the two countries.', 'breadcrumb': {'@id': 'https://oncubanews.com/en/cuba/cuba-and-china-agree-to-develop-artificial-intelligence-on-the-island/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://oncubanews.com/en/cuba/cuba-and-china-agree-to-develop-artificial-intelligence-on-the-island/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://oncubanews.com/en/cuba/cuba-and-china-agree-to-develop-artificial-intelligence-on-the-island/#primaryimage', 'url': 'https://oncubanews.com/en/wp-content/uploads/2019/10/ia-cub-chn-1.jpg', 'contentUrl': 'https://oncubanews.com/en/wp-content/uploads/2019/10/ia-cub-chn-1.jpg', 'width': 750, 'height': 422, 'caption': 'Image: esan.edu.pe'}, {'@type': 'BreadcrumbList', '@id': 'https://oncubanews.com/en/cuba/cuba-and-china-agree-to-develop-artificial-intelligence-on-the-island/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Portada', 'item': 'https://oncubanews.com/en/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Cuba and China agree to develop artificial intelligence on the island'}]}, {'@type': 'WebSite', '@id': 'https://oncubanews.com/en/#website', 'url': 'https://oncubanews.com/en/', 'name': 'OnCubaNews English', 'description': 'Revista sobre Cuba', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://oncubanews.com/en/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://oncubanews.com/en/#/schema/person/d7171bf311032ab1f557dd8332e714af', 'name': 'OnCuba Staff', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://oncubanews.com/en/#/schema/person/image/46fbae0226674e4421bf7a0d3af05995', 'url': 'https://oncubanews.com/en/wp-content/wphb-cache/gravatar/e89/e897e84fb5d45e532ec53b2712a47acfx96.jpg', 'contentUrl': 'https://oncubanews.com/en/wp-content/wphb-cache/gravatar/e89/e897e84fb5d45e532ec53b2712a47acfx96.jpg', 'caption': 'OnCuba Staff'}, 'url': 'https://oncubanews.com/en/author/oncuba-editorial-staff/'}]",,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vd2Fyb250aGVyb2Nrcy5jb20vMjAxOS8xMC9haS1hbmQtaXJyZWd1bGFyLXdhcmZhcmUtYW4tZXZvbHV0aW9uLW5vdC1hLXJldm9sdXRpb24v0gEA?oc=5,"AI and Irregular Warfare: An Evolution, Not a Revolution - War On The Rocks",2019-10-31,War On The Rocks,https://warontherocks.com,"This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric",N/A,"This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,N/A,"[{'@type': 'WebSite', '@id': 'https://warontherocks.com/#website', 'url': 'https://warontherocks.com/', 'name': 'War on the Rocks', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://warontherocks.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://warontherocks.com/2019/10/ai-and-irregular-warfare-an-evolution-not-a-revolution/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://warontherocks.com/wp-content/uploads/2019/10/EGEL.jpg', 'width': 1330, 'height': 850}, {'@type': 'WebPage', '@id': 'https://warontherocks.com/2019/10/ai-and-irregular-warfare-an-evolution-not-a-revolution/#webpage', 'url': 'https://warontherocks.com/2019/10/ai-and-irregular-warfare-an-evolution-not-a-revolution/', 'name': 'AI and Irregular Warfare: An Evolution, Not a Revolution - War on the Rocks', 'isPartOf': {'@id': 'https://warontherocks.com/#website'}, 'primaryImageOfPage': {'@id': 'https://warontherocks.com/2019/10/ai-and-irregular-warfare-an-evolution-not-a-revolution/#primaryimage'}, 'datePublished': '2019-10-31T07:45:08+00:00', 'dateModified': '2020-01-27T15:46:40+00:00', 'author': {'@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8'}, 'description': 'This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://warontherocks.com/2019/10/ai-and-irregular-warfare-an-evolution-not-a-revolution/']}]}, {'@type': ['Person'], '@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8', 'name': 'Shane Mason', 'image': {'@type': 'ImageObject', '@id': 'https://warontherocks.com/#personlogo', 'inLanguage': 'en-US', 'url': 'https://secure.gravatar.com/avatar/83a68cf34a391d145ac9f37117795a86?s=96&d=identicon&r=g', 'caption': 'Shane Mason'}}]",,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vdGhlbWFsYXlzaWFucmVzZXJ2ZS5jb20vMjAxOS8xMC8zMC9tb3JlLWpvYi1sb3NzLXNlZW4tZHVlLXRvLWFpLXJvYm90aWNzLWJ1dC1uZXctb25lcy13aWxsLWVtZXJnZS_SAQA?oc=5,"More job loss seen due to AI, robotics, but new ones will emerge - The Malaysian Reserve",2019-10-30,The Malaysian Reserve,https://themalaysianreserve.com,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,N/A,N/A,N/A,,,,

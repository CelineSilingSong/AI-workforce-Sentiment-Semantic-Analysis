URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,article:section,article:summary,article text,@context,@graph,articleSection,headline,inLanguage,author,datePublished,dateModified,publisher,@type,mainEntityOfPage,url,image,name,isAccessibleForFree,dateCreated,isPartOf,mentions,hasPart,address,diversityPolicy,email,legalName,leiCode,telephone,logo,brand,itemListElement,@id,contactPoint,sameAs,alternativeHeadline,articleBody,genre,locationCreated,publishingPrinciples
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vbWl0c2xvYW4ubWl0LmVkdS9pZGVhcy1tYWRlLXRvLW1hdHRlci9ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVpbWFnaW5pbmctd29ya9IBAA?oc=5,How artificial intelligence is reimagining work - MIT Sloan News,2018-05-14,MIT Sloan News,https://mitsloan.mit.edu,Accenture tech leaders detail new executive roles and new responsibilities AI is creating.,N/A,Accenture tech leaders detail new executive roles and new responsibilities AI is creating.,Accenture tech leaders detail new executive roles and new responsibilities AI is creating.,N/A,N/A,"
 










recent




0 sec ago
How to tap AI’s potential while avoiding its pitfalls 




Jul 10, 2024
Banks’ climate pledges don’t add up to change, research finds




Jul 9, 2024
The impact of misleading headlines on Facebook 

































Ideas Made to Matter

                                            Artificial Intelligence
                                        

How artificial intelligence is reimagining work

By
Brian Eastwood

May 14, 2018






Why It Matters		



Artificial intelligence isn’t advancing work processes. It’s completely reimagining them. These shifts will require new executives, new jobs, and new responsibilities.



















Share













































































facebook
X
linkedin
email
print

open share links
close share links

Paul Daugherty, chief technology and innovation officer at Accenture, sees three myths surrounding artificial intelligence: Robots are coming for us, machines will take our jobs, and current approaches to business processes will still apply.
The three myths represent “conventional changes to linear processes,” he said. The reality is more transformative. An example: Newark, New Jersey-based AeroFarms grows seeds indoors without soil or sunlight. Seeds are harvested in less than three weeks and the process requires 95 percent less water than conventional farming methods.
AI plays a key role, Daugherty said. AeroFarms’ scientists monitor 130,000 data points, analyzing everything from light sensitivity to nutrient absorption.
“How do we get the conventional mindset [of AI] from  beating Go to reimagining business?” he said. “That’s what we like to think about.”
Along with H. James Wilson, who leads Accenture’s information technology and business research, Daugherty co-wrote the book “Human + Machine: Reimagining Work in the Age of AI.” The pair spoke May 9 in Simon Johnson and Jonathan Ruane’s Global Business of AI and Robotics class at MIT Sloan.
Here’s what will be new as artificial intelligence helps us reimagine work.
New executive, management roles
The increased use of AI for day-to-day business operations will force enterprises to create new executive and management roles, the authors said.
First and foremost is a chief AI officer, Daugherty said. This person will understand and manage an organization’s data and ensure that AI is used responsibly. The role will merge the skill sets of the chief information officer and the human resources manager, requiring a leader who is comfortable introducing people into a process that is heavily dependent on technology.
Meanwhile, new management roles will focus on the use of data, though they will not necessarily be traditional STEM — science, technology, engineering, and math — roles, Wilson said. A data compliance officer will help a company make ethical decisions about how data is used, he said, while an algorithm forensic analyst will explain the data models to internal and external stakeholders.
However, as with previous technology trends — client/server, internet, cloud, mobile, cybersecurity, and so on — AI will be so firmly integrated into the business that it will be a priority for all executives. “What we learned from digital transformation is that it requires CEO and board-level sponsorship,” Daugherty said.
New concerns about responsibility
Executives managing AI must ensure the validity of the data sets that AI systems use, the authors said. The MIT Media Lab’s Algorithmic Justice League has  demonstrated that biased data sets can lead to biased results, whether companies realize it or not.
“You need data custodians and stewards, algorithm evaluators, to make sure they don’t amplify biases that were inherent in the data,” Daugherty said.
In addition, executives must apply their own intuition when an AI system recommends a course of action. Uber is under investigation in Massachusetts for  keeping surge pricing in place during a state of emergency in March 2018. An algorithm may say that is a good idea, but a machine is not accountable for a company’s business decisions, Daugherty said.
“I tell executives, it’s going to be you in front of Congress if you don’t pay attention to these types of issues,” he said.
New approach to work
Reimagining work is more than automating processes that humans currently do, the authors said. Even Elon Musk recently admitted that there is such as a thing as  too much automation. Instead, Daugherty said, companies should develop a type of “collaborative intelligence” where humans help machines just as much as machines help humans.
Five characteristics define a process that can be reimagined, Wilson said: Flexibility, speed, scale, decision making, and personalization.
After realizing that even a multinational firm does not have enough recruiters, Unilever  has automated the first two rounds of its interview process, he said. AI can do the initial vetting and sorting of candidates, which shortens the timeline and also allows Unilever to draw candidates from a larger, more diverse pool.
“This frees up recruiters to focus on the more important, later rounds of interviews, where the recruiters’ social acumen and feel for whether a candidate is a good fit is so important,” Wilson said.
New front-line skills
Unilever’s recruiters are just one set of workers who will have  redefined roles as enterprises adopt AI. Accenture automated the process of loan and mortgage claims verification, then transitioned the operations staff that had previously verified claims into a role where they analyzed claims, Daugherty said.
The authors take this issue of “mid-career re-skilling” seriously. Royalties from sales of “Human + Machine” will be donated to organizations such as Skillful that help train workers for jobs in a digital economy. One key focus is  developing soft skills such as problem solving and analysis, which allow workers to do more than basic data entry.
“There’s a lot of human labor that goes into making algorithms work effectively,” Wilson said. “How can we upskill them to do more sophisticated AI tasks, making their jobs more interesting, so it’s not a hidden form of global labor?”









































For more info
Zach Church
Editorial & Digital Media Director

(617) 324-0804


zchurch@mit.edu






Related Articles












Ideas Made to Matter

How to tap AI’s potential while avoiding its pitfalls 












Ideas Made to Matter

How can we preserve human ability in the age of machines?












Ideas Made to Matter

The AI Playbook: 6 steps for launching predictive AI projects 



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vdG5zci5vcmcvMjAxOC8wNS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbnRlcm5hdGlvbmFsLWNvbXBldGl0aW9uLWFuZC10aGUtYmFsYW5jZS1vZi1wb3dlci_SAQA?oc=5,"Artificial Intelligence, International Competition, and the Balance of Power - Texas National Security Review",2018-05-15,Texas National Security Review,https://tnsr.org,N/A,N/A,"World leaders, CEOs, and academics have suggested that a revolution in artificial intelligence is upon us. Are they right, and what will advances in artificial intelligence mean for international competition and the balance of power? This article evaluates how developments in artificial intelligence (AI) — advanced, narrow applications in particular — are poised to influence military power and international politics. It describes how AI more closely resembles “enabling” technologies such as the combustion engine or electricity than a specific weapon. AI’s still-emerging developments make it harder to assess than many technological changes, especially since many of the organizational decisions about the adoption and uses of new technology that generally shape the impact of that technology are in their infancy. The article then explores the possibility that key drivers of AI development in the private sector could cause the rapid diffusion of military applications of AI, limiting first-mover advantages for innovators. Alternatively, given uncertainty about the technological trajectory of AI, it is also possible that military uses of AI will be harder to develop based on private-sector AI technologies than many expect, generating more potential first-mover advantages for existing powers such as China and the United States, as well as larger consequences for relative power if a country fails to adapt. Finally, the article discusses the extent to which U.S. military rhetoric about the importance of AI matches the reality of U.S. investments.",N/A,N/A,N/A,"




 The Scholar





								PDF Download							


Vol 1, Iss 3
May 2018				
  | 36–57



Stable URL: 
https://doi.org/10.15781/T2639KP49


Artificial Intelligence 

				-
				

Artificial Intelligence, International Competition, and the Balance of Power



Artificial Intelligence
May 15, 2018



Michael C. Horowitz



World leaders, CEOs, and academics have suggested that a revolution in artificial intelligence is upon us. Are they right, and what will advances in artificial intelligence mean for international competition and the balance of power? This article evaluates how developments in artificial intelligence (AI) — advanced, narrow applications in particular — are poised to influence military power and international politics. It describes how AI more closely resembles “enabling” technologies such as the combustion engine or electricity than a specific weapon. AI’s still-emerging developments make it harder to assess than many technological changes, especially since many of the organizational decisions about the adoption and uses of new technology that generally shape the impact of that technology are in their infancy. The article then explores the possibility that key drivers of AI development in the private sector could cause the rapid diffusion of military applications of AI, limiting first-mover advantages for innovators. Alternatively, given uncertainty about the technological trajectory of AI, it is also possible that military uses of AI will be harder to develop based on private-sector AI technologies than many expect, generating more potential first-mover advantages for existing powers such as China and the United States, as well as larger consequences for relative power if a country fails to adapt. Finally, the article discusses the extent to which U.S. military rhetoric about the importance of AI matches the reality of U.S. investments.

Facebook ShareLinkedin ShareGoogle Plus ShareTwitter ShareMail Share 

In early September 2017, Russian President Vladimir Putin brought artificial intelligence from the labs of Silicon Valley, academia, and the basement of the Pentagon to the forefront of international politics. “Artificial intelligence is the future, not only for Russia, but for all humankind,” he said. “It comes with colossal opportunities, but also threats that are difficult to predict. Whoever becomes the leader in this sphere will become the ruler of the world.”1
Putin’s remarks reflect a belief, growing in sectors and regions across the world, that advances in artificial intelligence will be critical for the future — in areas as varied as work, society, and military power. Artificial intelligence is a critical element of what Klaus Schwab, head of the World Economic Forum, calls the Fourth Industrial Revolution.2 Eric Schmidt, the former CEO of Google, argues that artificial intelligence is so important to the future of power that the United States needs a national strategy on artificial intelligence, just as it had one for the development of space technology during the Cold War.3 Elon Musk, the head of Tesla and SpaceX, has even said that growth in artificial intelligence technology, left unchecked, could risk sparking World War III.4 These statements suggest that artificial intelligence will have a large and potentially deterministic influence on global politics and the balance of power.5
Whether artificial intelligence has revolutionary consequences or merely incremental effects, it is critical to grasp how and why it could matter in the national security arena. Despite a wave of articles about artificial intelligence in the popular press and trade journals, there has been less in the way of systematic academic work on the national security consequences of such developments. This article attempts to fill that gap by examining the effects on national security of narrow artificial intelligence, or systems designed to do deliberately constrained tasks, such as the Jeopardy-playing version of IBM’s Watson or AlphaGo, designed to play the board game Go. Specifically, it assesses the issues AI stands to raise for the balance of power and international competition through the lens of academic research on military innovation, technological change, and international politics.
Popular writing on AI tends to focus almost exclusively on technology development. Technology has played a vital role in shaping global politics throughout history.6 Hundreds of years ago, technologies such as the printing press allowed the written word to flourish. These set the stage for new forms of political protest and activity.7 In the 20th century, nuclear weapons significantly increased the destructive capabilities of numerous countries.8
Yet the relative impact of technological change often depends as much or more on how people, organizations, and societies adopt and utilize technologies as it does on the raw characteristics of the technology.9 Consider the aircraft carrier, which the British Navy invented in 1918. As the best in the world at using battleships, the Royal Navy initially imagined the utility of aircraft carriers as providing airplanes to serve as spotters for the battleship. The Japanese and U.S. navies, however, innovated by using the aircraft carrier as a mobile airfield, fundamentally transforming naval warfare in the 20th century.10 Or, consider the printing press again: Its role in accelerating nationalist political movements depended on the incentives that originally motivated those movements and the movements’ ability to take advantage of the new technology’s capability to spread information.11
What role will artificial intelligence play? In many ways it is too soon to tell, given uncertainty about the development of the technology. But AI seems much more akin to the internal combustion engine or electricity than a weapon. It is an enabler, a general-purpose technology with a multitude of applications. That makes AI different from, and broader than, a missile, a submarine, or a tank.
Advances in narrow AI could create challenges as well as opportunities for governments and military organizations. For example, narrow AI applications such as image recognition would help those militaries that are already wealthy and powerful and that can afford to keep up. It is harder to predict how AI applications could affect the heart of military organizations, influencing planning as well as questions of recruiting, retention, and force structure. What happens as militaries increasingly need soldiers who have training in coding and who understand how algorithms work? Or if swarming, uninhabited systems make large conventional military platforms seem costly and obsolete? Leading militaries often struggle in the face of organizationally disruptive innovations because it is hard to make the bureaucratic case for change when a military perceives itself as already leading.
What countries benefit from AI will depend in part on where militarily-relevant innovations come from. Non-military institutions, such as private companies and academic departments, are pushing the boundaries of what is possible in the realm of artificial intelligence. While some AI and robotics companies, such as Boston Dynamics, receive military research and development funding, others, such as DeepMind, do not, and actively reject engaging with military organizations.12 Unlike stealth technology, which has a fundamentally military purpose, artificial intelligence has uses as varied as shopping, agriculture, and stock trading.
If commercially-driven AI continues to fuel innovation, and the types of algorithms militaries might one day use are closely related to civilian applications, advances in AI are likely to diffuse more rapidly to militaries around the world. AI competition could feature actors across the globe developing AI capabilities, much like late-19th-century competition in steel and chemicals. The potential for diffusion would make it more difficult to maintain “first-mover advantages” in applications of narrow AI. This could change the balance of power, narrowing the gap in military capabilities not only between  the United States and China but between others as well.
Experts disagree about the potential trajectory of the technology, however, which means that forecasts of the consequences of AI developments for the international security environment are necessarily tentative.13 While the basic science underlying AI is applicable to both civilian and military purposes, it is plausible that the most important specific military uses of AI will not be dual use. Technological advances that are more exclusively based in military research are generally harder to mimic. It follows that military applications of AI based more exclusively in defense research will then generate larger first-mover advantages for early adopters. Moreover, if the computational power necessary to generate new, powerful algorithms prices out all but the wealthiest companies and countries, higher-end AI capabilities could help the rich get richer from a balance-of-power perspective. On the other hand, if leading militaries fail to effectively incorporate AI, the potential for disruption would also be larger.

AI seems much more akin to the internal combustion engine or electricity than a weapon. 
This article defines artificial intelligence and examines what kind of technology AI is. It then turns to key questions and assumptions about the trajectory of narrow AI development that will influence potential adoption requirements for military applications of AI, a factor critical to shaping AI’s influence on the balance of power. The paper then assesses how narrow artificial intelligence will affect the balance of power in a world where dual-use AI has great military relevance and diffuses rapidly as well as a scenario in which military AI developments are more “excludable,” limiting diffusion and generating more first-mover advantages.
How all this will play out over the next decade or more is unclear. Already, China, Russia, and others are investing significantly in AI to increase their relative military capabilities with an eye toward reshaping the balance of power. As the field of AI matures, and more implementations become plausible in arenas such as logistics, personnel, and even deployable units, countries will need to figure out how to use AI in practical ways that improve their ability to generate military power. The risk for the United States in terms of balance of power thus lies in taking its military superiority for granted and ending up like Great Britain’s Royal Navy with the aircraft carrier in the mid-20th century — a technological innovator that is surpassed when it comes to organizational adoption and use of the technology.
What Is Artificial Intelligence?
What is artificial intelligence? There is no broad consensus on the specific meanings of terms such as artificial intelligence, autonomy, and automation. For the purposes of this article, artificial intelligence refers to the use of computers to simulate the behavior of humans that requires intelligence.14 Put another way, AI can be thought of as the ability of an artificial agent to achieve goals in a “wide range of environments.”15 A system with artificial intelligence is distinct from a robot or robotic system, which can be remotely piloted or autonomous.16 For example, the Boston Dynamics SpotMini, which can open a door, is remotely piloted by a human operator so would not qualify as AI.17 Automatic systems, such as a toaster in the civilian world or, to use a military example, an explosive triggered by a tripwire, respond mechanistically to environmental inputs.18 Automated systems, by contrast, operate based on multiple pre-programmed logic steps as opposed to the simplicity of a tripwire.19 Autonomous systems have more latitude and are programmed, within constraints, to achieve goals, optimizing along a set of parameters.20
There are two main approaches to AI, broadly conceived. The first is symbolic artificial intelligence — the creation of expert systems and production rules to allow a machine to deduce behavioral pathways. IBM’s Deep Blue, which defeated Garry Kasparov in chess in 1997, used a symbolic approach.21 Computational, or connectionist, approaches to artificial intelligence, in contrast, typically attempt to allow for problem recognition and action by machines through calculations rather than symbolic representation.22 Machine learning represents a key computational approach to artificial intelligence. Multiple computational techniques are used to create machine-learning algorithms, including Bayesian networks, decision trees, and deep learning. Deep learning, now popularly associated with artificial intelligence, is a technique that harnesses neural networks to train algorithms to do specified tasks, such as image recognition.23 Some researchers are pursuing hybrid approaches that integrate both symbolic and computational approaches to AI. The hope behind hybrid approaches is that creating common languages will enable algorithms that can employ multiple pathways to learn how to do particular tasks, making them more effective.24
For the purposes of this article, the specific methods of AI that generate particular capabilities are less critical than understanding the general trajectory of the technology. In many cases, it is too soon to tell which methods will generate which capabilities.
AI Is an Enabler, Not a Weapon
The impact of the invention of a new technology depends, in part, on its potential basic uses.25 Some communication technologies, such as the telegraph or telephone, were designed to more rapidly connect people in different locations. Munition technologies, such as missiles and bullets, are designed to inflict damage on a target. Railroads are a transportation technology, as is a bicycle. These broad categories of technologies have subcomponents that draw on various technologies themselves. For example, more than 300,000 parts go into an F-35.26 Another category might then be called “enabling technologies,” which are designed not specifically for a single purpose like the examples above but, instead, are general-purpose, with broad applications across many other types of technologies. Electricity is an enabling technology.
So what kind of technology is artificial intelligence? While the rhetoric of the “Third Offset”27 and other discussions in the defense community sometimes make artificial intelligence seem like a munition, AI is actually the ultimate enabler. AI can be part of many specific technologies, analogous to the internal combustion engine as well as electricity.28 Andrew Ng of Stanford University argues that, like the invention of electricity, AI could enable specific technologies in fields as diverse as agriculture, manufacturing, and health care.29
Artificial intelligence can operate in several dimensions. First, it can be used to direct physical objects, such as robotic systems, to act without human supervision. Whether in tanks, planes, or ships, AI can help reduce the need to use humans, even remotely, or as part of human-machine teams.30 Swarm techniques, for example, generally involve the creation of supervised algorithms that direct platforms such as drones. Second, artificial intelligence can assist in processing and interpreting information. Image-recognition algorithms can be used for tagging vacation photos and identifying products in stores as well as in Project Maven, a U.S. military program that seeks to develop algorithms to automate the process of analyzing video feeds captured by drones.31 While the applications in each case are different, the underlying algorithmic task — rapid image identification and tagging — is consistent. Third, overlapping narrow AI systems could be used for new forms of command and control — operational systems, including battle management, that analyze large sets of data and make forecasts to direct human action — or action by algorithms.32
What Type of Artificial Intelligence?
It is useful to think about the degree of artificial intelligence as a continuum. On one end are narrow AI applications such as AlphaGo, able to beat the best human Go players in the world. These are machine-learning algorithms designed to do one specific task, with no prospect of doing anything beyond that task. One can imagine narrow AI as relatively advanced forms of autonomous systems, or machines that, once activated, are designed to complete specific tasks or functions.33
On the other end of the spectrum is a “super-intelligent” artificial general intelligence. This kind of AI would consist of an algorithm, or series of algorithms, that could do not only narrow tasks but also could functionally think for itself and design solutions to a broader class of problems. Describing an extreme version of this, Nick Bostrom writes about the risk of a superintelligent AI that could plausibly take over the world and perhaps even decide to eliminate humans as an inadvertent consequence of its programming.34 In the middle of this spectrum, though perhaps leaning toward artificial general intelligence, is “transformative AI,” or AI that can go beyond a narrow task such as playing a video game but falls short of achieving superintelligence.35
This article focuses on the potential effect that narrow applications of artificial intelligence could have on the balance of power and international competition. Among current AI technologies and advances, narrow applications are most likely to affect militaries — and with them the balance of power — over the next two decades. Moreover, even experts disagree about whether artificial general intelligence of the type that could outpace human capabilities will emerge in the short to medium term or whether it is still hundreds of years away. AI experts also disagree about the overall trajectory of advances in AI.36 Surveys have found that only 50 percent of AI researchers believe that an AI system will be capable of writing a best-selling book by 2049. About 75 percent of AI researchers thought it could be 2090 before an AI system could write a best-selling book. That even highly trained experts disagree about these development issues illustrates a high degree of uncertainty in the field.
Given these questions about which AI technologies will be developed, this article focuses on the capabilities that are most likely to emerge in the next generation.
Technology and the Balance of Power
Emerging technologies primarily shape the balance of power through military and economic means.37 Technologies can directly influence countries’ abilities to fight and win wars. They can also indirectly affect the balance of power by impacting a country’s economic power. After all, countries cannot maintain military superiority over the medium to long term without an underlying economic basis for that power.38 Recall the decline of the Ottoman Empire or Imperial China.
However, it is not yet clear how the invention of specific AI applications will translate into military power. Despite continuing investment, efforts to integrate AI technologies into militaries have been limited.39 Project Maven is the first activity of an “Algorithmic Warfare” initiative in the U.S. military designed to harness the potential of AI and translate it into usable military capabilities. Still, many investments in the United States and elsewhere are in early stages. As Missy L. Cummings writes:
Autonomous ground vehicles such as tanks and transport vehicles are in development worldwide, as are autonomous underwater vehicles. In almost all cases, however, the agencies developing these technologies are struggling to make the leap from development to operational implementation.40

Emerging technologies primarily shape the balance of power through military and economic means. 
It is important to distinguish these potential technological innovations from military innovations. While military innovations are often linked to changes in technology,41 it is not always the case. Military innovations are significant changes in organizational behavior and ways that a military fights that are designed to increase its ability to effectively translate capabilities into power.42 The use of aircraft carriers as mobile airfields by the United States and Japan is a prototypical example. While AI could potentially enable a number of military innovations, it is not a military innovation itself, and no applications of AI have been used in ways that would count as a military innovation at this point.
Because AI research and technology are still in their early stages, usage of AI in warfare is not even yet analogous to the first use of the tank in World War I, let alone effective use of combined arms warfare by the Germans in World War II (the military innovation now known as blitzkrieg). This limits analyses about how narrow AI might one day affect the balance of power and international politics. Most research on technology and international politics focuses on specific, mature technologies, such as nuclear weapons, or on military innovations.43 Since AI is at an early stage, examining it requires adapting existing theories about military technology and military innovation.44
My adoption capacity theory provides insight into how developments in AI will affect the balance of power.45 This theory argues that the relative financial and organizational requirements for adopting a military innovation influence the rate of diffusion of that innovation and its impact on the balance of power. Financial considerations include calculating the unit costs of the hardware involved and determining whether the underlying capability is based on commercial or militarily-exclusive technology. Other considerations include assessing the extent to which adopting the innovation requires disrupting the critical task of the military (i.e., what an organization views itself as attempting to achieve) or the status of key organizational elites (for example, fighter pilots in an air force). Given that adoption capacity theory focuses on major military innovations, however, it requires adaptation to be applied to artificial intelligence at present.
To determine how technological changes will shape the balance of power, adoption capacity theory suggests that three questions must be answered. First, while technology itself is rarely, if ever, determinative, how might use of a technology influence the character of warfare? Consider the machine gun. When deployed asymmetrically, it proved useful for the offense. But in combination with barbed wire, when possessed symmetrically, this technological advance helped create the trench-warfare stalemate of World War I.46 More broadly, the Industrial Revolution and the shift in manufacturing to factories and mass production were behind the rifle’s evolution from a niche, craft weapon possessed by a small number of forces to a widely available capability. This change influenced the relative lethality of battles as well as how militaries organized themselves and developed tactics.47
Second, how might different actors implement a given technology or be bureaucratically constrained from implementation, and what possibilities for military innovation will that generate? This question is particularly relevant because the challenges of organizational adoption and implementation of a technological innovation are closely linked with effectiveness. Those challenges are critical to determining how an innovation will impact international politics.
Decades of research demonstrates that the impact of technological change on global politics — whether it is change in economics, society at large, diplomacy, or military power — depends much more on how governments and organizations make choices about the adoption and use of new capabilities than on the technologies themselves.48 Scholarship on military innovation by Barry Posen, Stephen P. Rosen, and others shows that technological innovation alone rarely shapes the balance of power.49 Instead, it is how militaries use a technology that makes a difference.50 A military’s ability to employ a technology depends in part on the complexity of the technology, how difficult it is to use, and whether it operates in predictable and explainable ways. These factors influence the trust that senior military leaders have in the technology and whether they use it.51 Additionally, the more bureaucratically disruptive it is to adopt a technology, the more challenging it can be for older, more established organizations to do so — particularly if the organization is underinvested in research and development designed to integrate new technologies and ideas.52
Consider that every country in Europe in the mid-19th century had access to railroads, rifles, and the telegraph around the same time. But it was the Prussian military that first figured out how to exploit these technologies, in combination, to rapidly project power. After that, other militaries adapted their organizations to take similar advantage.53
The example of the British Navy and the aircraft carrier further illustrates how organizational processes determine the impact of technology on military power.54 As referenced above, despite having invented the aircraft carrier, the Royal Navy’s institutional commitment to the battleship meant that it initially saw the value of this new technology almost exclusively in its ability to facilitate the use of airplanes to act as “spotters” for battleships. The United States and Japan, as rising naval powers with less invested in the importance of the battleship, thought more creatively about this innovation and realized that the aircraft carrier’s real value lay in the independent striking power it offered.55 Since battleships — and admirals with experience and comfort operating them — dominated the navies of many countries, thinking about the aircraft carrier as a mobile airfield required a difficult conceptual shift.56
Even after it became clear that the optimal use of aircraft carriers was as a mobile airfield, adopting carrier warfare proved challenging. The Chinese navy has been working on carrier operations for two decades and is only just starting to build real competency. The Soviet Union attempted to adopt carrier warfare for decades and failed. Simply put, the systems integration tasks required to operate the ship, launch and recover airplanes from the ship, and coordinate with other naval assets are very difficult to execute.57 The larger the change within the organization required for a military to effectively utilize new technologies, the greater the bureaucratic challenges and, with them, the likelihood that powerful countries will not have the organizational capability to adopt. This is a key mechanism through which the balance of power can change.
Third, how will a new technology spread? The answer to this question will help determine relative first-mover advantages gained from adopting the technology.58 While Kenneth Waltz initially suggested that emulation of military technologies happens quickly, subsequent research demonstrates that it is far more complicated.59 The rate of diffusion matters: In the case of technologies that diffuse slowly, the country that first implements will have a sustainable edge over its competitors. But when other countries can rapidly adopt a new technology, the relative advantages of being first diminish.60
The diffusion of military technology occurs through multiple mechanisms, just like the diffusion of technologies in general.61 Adoption capacity theory suggests a few factors that will be key in influencing the diffusion of narrow AI. The first is the unit cost of creating AI systems. The greater the hardware and compute costs associated with creating militarily-relevant algorithms, the higher the barrier to entry will be. Alternatively, once the algorithms have been created, they become software and can more easily diffuse.
Moreover, technologies that have only military purposes tend to spread more slowly than technologies where commercial incentives drive their development. If a technology has only military uses — such as stealth technology — and it has a high unit cost and level of complexity, the number of actors who can emulate or mimic that technology are minimized.62
On the other hand, technologies with commercial incentives for development generally spread much faster. In the 19th century, the railroad, used as a “military technology,” enabled rapid power projection and the massing of military forces to a greater degree than had previously been possible. Yet it was the commercial incentives for the fast shipping of goods that helped speed the construction of dense railroad networks around the world, making it difficult for countries to gain sustainable advantages in railroad capabilities.63
The Impact of AI on the Balance of Power
If Eric Schmidt, Vladimir Putin, Elon Musk, and others are correct that AI is a competitive battleground, what will be the character of that competition?64 The United States and China seem to be furthest ahead in the development of AI. As the two most powerful countries in the world, the competition for global leadership in AI technology evokes, for many, 20th-century competitions such as the space race. Retired Marine Corps Gen. John Allen and SparkCognition CEO Amir Husain have argued that the United States therefore needs to do more to get and stay ahead.65
Global investments in artificial intelligence for economic and national security purposes are increasingly described as an arms race.66 China published a national strategy on artificial intelligence in 2017 that said AI represents a “major strategic opportunity” and proposed a coordinated strategy to “build China’s first mover advantage” and lead the world in AI technology.67 Russia is investing heavily as well, especially in the military domain. Reports suggest that the Russian military is designing autonomous vehicles to guard its ballistic missile bases as well as an autonomous submarine that could carry nuclear weapons. In robotics, Russia is deploying remotely piloted tanks, such as the Uran-9 and Vehar, on the battlefield.68
China and Russia are not the only actors outside the United States interested in national security applications of AI. The character of AI technology, like robotics, makes many countries well-positioned to design and deploy it for military purposes.69 Commercial incentives for AI developments and the dual-use character of many AI applications mean that countries with advanced information economies are poised to be leaders in AI or at least fast followers.70 In Southeast Asia, Singapore is on the cutting edge of AI investments (both military and non-military). Other Southeast Asian nations are making advances in AI research as well.71 In the military domain, South Korea has developed the SGR-A1, a semi-autonomous weapon system designed to protect the demilitarized zone from attack by North Korea.72

The character of AI technology, like robotics, makes many countries well-positioned to design and deploy it for military purposes. 
AI also provides opportunities for capital-rich countries, which creates incentives to develop the technology. Wealthy, advanced economies that have high levels of capital but also have high labor costs or small populations — middle powers such as Australia, Canada, and many European countries — often face challenges in military recruiting. For these countries, technologies that allow them to substitute capital for labor are highly attractive. Indeed, Gen. Mick Ryan, commander of Australia’s Defence College, argues that countries can take advantage of the intersection of AI and robotics to overcome the problems caused by a small population.73 France’s 2017 defense strategy review points to the development and incorporation of artificial intelligence as critical to the French military’s ability to maintain “operational superiority.”74 Israel, a classic example of an advanced economy with more capital than labor, also funds military AI investments that would predict rocket launches and analyze video footage.75 Lt. Col. Nurit Cohen Inger, who heads the unit of the Israeli Defense Forces (IDF) in charge of assessing the military relevance of AI, said in 2017 that, for the IDF, AI “can influence every step and small decision in a conflict, and the entire conflict itself.”76
Given these investments, how might developments in AI affect military organizations and the character of war, and how might they diffuse?
AI and the Character of War
The “character of warfare” in a period can be defined as the dominant way to fight and win conflicts given existing technologies, organizations, and polities. The character of warfare changes in concert with the tools that become available and how they influence the ways militaries organize themselves to fight wars.77 The shift to mass mobilization in the Napoleonic era exemplifies a non-technological development that changed the character of warfare.
Applications of AI have the potential to shape how countries fight in several macro ways. On the broadest level, autonomous systems, or narrow AI systems, have the potential to increase the speed with which countries can fight, yet another similarity between AI and the combustion engine. Even if humans are still making final decisions about the use of lethal force, fighting at machine speed can dramatically increase the pace of operations.78
There are several military applications of AI currently in development or under discussion that can be considered, though many are at early stages. For example, some research shows that the way that neural networks can utilize imagery databases and classify particular scenes (such as a mountain), allows for a more accurate assessment of specific locations.79 Additionally, the processing power that is possible with narrow AI systems has the potential to increase the speed of data analysis, as Project Maven in the United States aims to do. Investments in image recognition offer the hope of achieving faster, more accurate results than humans can achieve today, and is a likely avenue for continued investment and application (setting aside the questions of accidents, hacking, and other ways that systems could go awry80).
Successful implementation of AI beyond areas such as image recognition might lead to new concepts of operation that could influence force structure and force employment, or how militaries organize themselves and plan operations. One possibility is the use of large numbers of smaller platforms, known as swarms, for military operations. Algorithms and control systems designed to enable “swarming” already exist in the private sector and in academia.81 Military-grade algorithms would require coordination with other military systems, including early-warning aircraft, inhabited aircraft, satellites, and other sensors. Deployed swarms in a combat environment would have to be capable of real-time adaptation to optimize operations if some elements of the swarm were shot down — a challenge that commercial applications would not necessarily face. Methods for developing swarming algorithms could include behavior trees or deep learning.82
Another potential application for narrow AI that could shape the character of war is coordination through layers of algorithms that work together to help manage complex operations. These algorithms could be expert systems that generate decision trees. Or they could involve algorithms developed through generative adversarial networks. In this approach, algorithms compete against each other to teach each other how to do various tasks. Some algorithms will need to be trained to assist in coordinating multiple military assets, both human and machine. In that case, adversarial learning could help compensate for the unique character of decision-making in individual battles and the problem of learning to adapt beyond the available training data.83
The ability to operate faster through algorithms that assist human commanders in optimizing battle plans, including real-time operations, could shift force employment and force structure, especially in the air and at sea. Since World War II, modern militaries have been engaged in a  shift from quantity to quality in military systems. The thinking is that smaller numbers of expensive, high-quality systems are more likely to lead to victory in battles. AI could accelerate trends that challenge these long-running force-structure imperatives, such as the need to defeat adversaries with advanced anti-access, area-denial (A2/AD) networks with tolerable costs.
If algorithms and coordination at machine speed become critical to success on the battlefield, expensive, high-quality platforms could become vulnerable to swarms of sensors and lower-cost weapons platforms that are effectively networked together. AI could thus help bring quantity back into the equation in the form of large numbers of robotic systems. In the near to mid-term, however, optimal use of AI may lie in leveraging machine learning to improve the performance of existing platforms.
Incentives exist for nearly all types of political regimes to develop AI applications for military purposes. For democracies, AI can decrease the relative burden of warfare on the population and reduce the risk to soldiers, even more so than with remotely piloted systems, by reducing the use of personnel. For autocracies, which do not trust their people in the first place, the ability to outsource some elements of military decision-making to algorithms, reducing reliance on humans to fight wars, is inherently attractive.84
Organizational Politics and Artificial Intelligence
Despite uncertainty about specific military applications of AI, the examples of how AI can be used in a military context described above reveal that these capabilities have the potential to significantly disrupt organizational structures. Take the example of battle management coordination (whether in human-machine teams or not): Successfully operating even semi-autonomous battle management systems is likely to require new occupational specialties and shifts in recruiting, training, and promotion to empower individuals who understand both military operations and how particular AI systems function. Rosen shows that altering the promotion of military personnel to empower those with expertise in new areas is critical to adopting military innovations in general. AI should be no exception.85
As described above, the use of AI systems at the operational level could generate options for how militaries organize and plan to use force, due to the potential to use larger numbers of networked systems operating at machine speed instead of relying exclusively on small numbers of high-quality inhabited aircraft. Implementing such concepts, however, could require disruptive organizational shifts that could threaten to change which military occupations provide the highest status and are gateways to leadership roles. Already, this can be seen with the Air Force, dominated by fighter pilots, which has been relatively hesitant when it comes to investments in uninhabited aerial vehicles. It would also challenge entrenched bureaucratic notions about how to weigh quantity versus quality. Adopting narrow AI in the most optimal way could prove challenging for leading militaries, which will need trained personnel who can do quality and reliability assurance for AI applications to ensure their appropriate and effective use.
Other applications, such as Project Maven in the U.S. Department of Defense, are easier to implement because they are sustaining technologies from the perspective of literature on organizational innovation.86 Autonomous systems that can rapidly and accurately process drone footage do not disrupt high-status military occupational specialties, nor do they disrupt how military services operate as a whole. It is when optimal uses of narrow AI would require large shifts to force structure that the adoption requirements, and bureaucratic anti-bodies, ramp up. One example of bureaucratic resistance preventing the production of a new technology that could have proved disruptive is the U.S. military’s failure to fund the X-47B drone, a next-generation system that could take off from and land on aircraft carriers autonomously. This illustrates the way bureaucratic politics and organizational competition can hinder the adoption of innovative technologies.87

Incentives exist for nearly all types of political regimes to develop AI applications for military purposes. 
The strategic or organizational culture of a military or society can also indicate which will be best positioned to exploit potential advances in AI,88 specifically, how open those cultures are to innovation. There is a risk of tautology, of course, in cultural arguments at times since it can be hard to measure whether an organization is capable of adopting a technology until it has tried to do so or done it. However, Emily Goldman’s work on the Ottoman Empire suggests the value of developing metrics of cultural openness when it comes to predicting willingness to experiment and adopt AI systems.89
Interestingly, norms regarding force structure could also play a role in inhibiting the use of AI for certain military tasks. As Theo Farrell’s research on the Irish Army after independence shows, militaries often mimic the functional form of more powerful actors even when doing so is not in their interest. Applying his insight in the case of artificial intelligence, some militaries may be less likely to use AI in ways that are organizationally disruptive, especially if doing so would involve shifts in visible force structure, such as a move from small numbers of advanced inhabited aircraft to swarming concepts that use cheaper, more disposable aircraft.90
Arguments about organizational and strategic culture are generally consistent with adoption capacity theory, since both focus on the challenges that innovations present when they disrupt the identity of an organization.91 After all, militaries that already spend a lot on research and development, that are younger, and that have broad conceptions of their critical task are more likely to be culturally “open” and able to adopt new technologies or full innovations further down the development line.
The Diffusion of Militarily-Relevant AI: Two Scenarios
There is a fundamental question about the extent to which militarily-relevant uses of narrow AI will diffuse easily. Answering this question is necessary for predicting the first-mover advantages associated with a technological innovation, which in turn helps to determine its relative impact on the balance of power and warfare. To determine how easily a new technology will diffuse, adoption capacity theory suggests looking at the unit cost of the technology, especially the physical hardware.
Designing AI capabilities requires both software and hardware. This influences how to think about the “unit cost” of AI. Military capabilities based in hardware often spread more slowly than those based in software, generating more sustainable advantage for the first adopter of a given capability, especially when the unit costs of that capability are relatively high. The high unit cost of flattop aircraft carriers, for example, means that only wealthy and powerful countries adopt them.92
When it comes to platforms, algorithms are software rather than hardware. Take the example of the MQ-9 Reaper, a current-generation U.S. military armed drone. The MQ-9 is remotely piloted, meaning that a pilot at another location directs the airframe and makes decisions about firing weapons against potential targets. The difference between this and an autonomous version that is piloted and operated by an algorithm is software. From the outside, the platform would look the same.
But, if narrow AI is software from the perspective of military technology, it is software that requires substantial hardware for its creation. The associated hardware costs — especially for advanced narrow AI applications — are potentially significant.93 The more complex the algorithm, the more up-front computational hardware is required to “train” that algorithm.94 Thus, corporate and academic AI research leaders have to invest in teraflops of computing power. This is a different kind of hardware than a tank or a cruise missile, but it is hardware all the same. Rapid advances in AI through deep learning and neural networks over the last decade have thus required advances in computing hardware. Joel Emer, an electrical engineering and computer science professor at MIT, states it plainly: “Many AI accomplishments were made possible because of advances in hardware.”95 After an algorithm has been trained, however, it can be applied without access to that computing environment, and the power necessary to run completed algorithms is dramatically reduced.
How rapidly AI capabilities will diffuse via simultaneous invention or mimicry will depend, in part, on the availability of computing power. If the cost of computing power continues to decline as chips become more efficient, then countries that are already home to advanced technology companies will have more access to AI capabilities faster than other countries without those kinds of technology companies.
If, on the other hand, the hardware costs of developing complex algorithms remain beyond the capacity of companies in most countries, diffusion will happen only deliberately, such as through trade or bilateral agreements at the nation-state level, or via espionage (i.e., hacking). This would likely slow the diffusion of most AI advances, increasing the advantages for innovators.
Determining the extent to which militarily-relevant applications of AI are based on commercial technology versus exclusively military research is also a critical question raised by adoption capacity theory. While it is hard to know the answer at present, examining both scenarios will illustrate how that answer might shape the way AI affects the balance of power and the structure of international competition.
Dual-Use AI
Research on the future of work suggests that strong commercial drivers are incentivizing the development of AI around the world. A 2017 McKinsey Global Institute report found a midpoint estimate of 400 million people, or 15 percent of the workforce, that are likely to be disrupted by automation before 2030.96 Widely cited research by Carl B. Frey and Michael A. Osborne estimates that 47 percent of jobs in the United States are at risk of being replaced by automation. That includes lawyers, stock traders, and accountants, not just blue-collar jobs.97 Companies across the economy have incentives to develop and use algorithms.
Commercial interest in AI is so high that some argue it — and the finite number of talented AI engineers — is holding back military developments.98 What’s more, the higher salaries and benefits that commercial companies can offer mean that militaries may have to turn to civilian companies to develop advanced AI capabilities. Google’s decision to partner with the U.S. Defense Department on Project Maven illustrates how the same talent and knowledge that will drive commercial innovation in AI may also be necessary for military technology innovation.99
When technology advances derive primarily from the civilian sector, rapid adoption of new technologies around the world becomes more likely. Commercial companies may spread the technology themselves, and the profit motive incentivizes rapid mimicry by related companies in different countries.100 Companies in Brazil, Germany, Japan, and Singapore could become AI leaders or at least fast followers.
A commitment to open-source development by many of the major players in AI could also increase the rate of diffusion. In 2015, for example, Google opened up TensorFlow, its artificial intelligence engine, to the public.101 Elsewhere, researchers committed to the open development of AI to help reduce the safety risk of algorithms that “break” in high-leverage situations publish their findings in ways that advance their cause — and make it easier for their algorithms to be copied.102
Even though advanced applications of commercial AI would require significant hardware and expertise, adoption capacity theory suggests that as the underlying basis of a technology gets more commercially oriented, it spreads relatively faster, as explained above. Companies like DeepMind have an edge today. But in such a scenario, there would be more companies around the world with relevant technological capacity. It is also easier for governments to leverage private-sector companies when those private-sector actors have non-governmental market incentives for developing or copying technology.
So how would dual-use AI being critical to military applications of AI shape global power? As noted above, the period in which a technological innovator enjoys a market advantage shrinks when countries and companies can acquire or copy others’ advances relatively easily. This makes it hard to stay ahead qualitatively.103 In the AI and robotics realms, it is possible that this will create yet another incentive for countries to focus on quantity in military systems. If leads in AI development prove difficult to sustain, advanced militaries are likely to have systems of approximately the same quality level, presuming they all reach the same conclusion about the general potential of integrating AI into military operations. In that case, countries may be more likely to try to gain advantage by emphasizing quantity again — this is in addition to the inherent incentives for mass that narrow AI might create.
If dual-use AI is critical to military applications of AI, the ability to design forces, training, and operational plans to take advantage of those dual-use applications will be a differentiating factor for leadership in AI among the great powers. The 1940 Battle of France illustrates what could ultimately be at stake in the most extreme case. Both the Germans on one side and the British and French on the other had tanks, trucks, radios, and airplanes that they could, in theory, have used for close air support. What gave the Germans such a large edge was blitzkrieg — a new concept of operations that could overwhelm even another advanced adversary.104
Let’s return to the comparison between AI and the space race. If AI technology diffuses more rapidly because it has both commercial and military purposes, making first-mover advantages more difficult to sustain, comparisons to the space race may be limited. The space race was a bilateral challenge between the United States and the Soviet Union designed to put a person on the moon, which included both developments in rockets and technologies designed to keep humans alive in space, land on the moon, and return safely. The rocket development itself was also part of the creation of intercontinental ballistic missiles (ICBMs). And critical economic spillovers from the space race included development of the satellites that led to GPS and other key enablers of the Information Age. Yet overall, the race to the moon was run by two governments for national purposes — not primarily for dual-use economic gain.
The commercial drivers of AI technology, and the speed with which new algorithms diffuse, would make competition much broader than it was during the bilateral space race. Competition is much more likely to be multilateral, featuring countries and companies around the world. A better analogy might be to the competition surrounding the development of Second Industrial Revolution technologies in the late 19th and early 20th centuries. France, Germany, Britain, Japan, the United States, and others vied for supremacy in steel production, chemicals, petroleum, electricity, and other areas.
For military applications of AI where the underlying technology is driven by commercial developments, the impact of a country getting ahead in AI technology, over time, would have unclear implications for relative power if a rival country was close enough to be a fast follower. Advances in commercially driven AI technology are about building new industries, changing the character of existing industries, and ensuring that the leading corporations in the global economy that emerges are based in one’s own country.
Militarily-Exclusive AI
The alternative to military applications of AI that are based in commercial developments is a world where military applications of AI are driven instead by research that is applicable only to militaries. Copying technological innovations of “excludable” technologies — those not based on widely available commercial technology — requires espionage to steal the technology (as the Soviets did with the atomic bomb) or mimicry based on observable principles of the technology.105 There are several reasons, however, to think that many military applications of narrow AI will be unique in ways that will make them more difficult to copy.
First, the complexity of advanced military systems can make emulation costly and difficult. This is especially true when a number of components are not available on the commercial market and the ability to build them depends, in part, on classified information.106 The same can also be said for some advanced commercial technology, of course, but this is not the norm. The inability to adapt commercial algorithms for some military purposes could limit the capacity of most states to produce relevant AI-based military capabilities, even if they have advanced commercial AI sectors. It could also mean that systems integration challenges for using militarily-relevant algorithms are large enough to deter many militaries from investing heavily.107

When technology advances derive primarily from the civilian sector, rapid adoption of new technologies around the world becomes more likely. 
Whatever the uncertainty about how specific AI advances will translate into military capabilities, some of the most important military applications of narrow AI — those with a potentially substantial impact on larger-scale military operations — may not have obvious civilian counterparts. Battle management algorithms that coordinate a military operation at machine speed do not necessarily have commercial analogues — even if supervised by a human with command authority — excluding the development of a narrow AI designed, say, to run a factory or operational system from top to bottom. In these arenas, military-grade algorithms may require conceptual breakthroughs that other countries may find hard to rapidly mimic.
Second, some military AI applications, such as image recognition, do have obvious commercial counterparts. Even in those cases, however, the cybersecurity concerns and reliability associated with military-grade technology can differ from those for civilian applications. Military AI systems deployed in the field may require hardening for electronic warfare and extra protections from spoofing and hacking that would be of relatively less concern in the civilian world. In military environments, adversaries’ efforts to hack and spoof increase the need for security.
The potential for countries to have strong commercial AI research sectors may mean that even narrow AI developments with applications geared toward military use may be easier to mimic than, say, stealth technology has been over the last generation. But stealth is an outlier: It has proven uniquely difficult to copy relative to other military technologies over the past few hundred years.
For AI developments that do not have clear commercial analogues, there could be substantial first-mover advantages for militaries that swiftly adopt AI technologies, particularly if they can achieve compute-driven breakthroughs that are difficult to copy. What would this mean for AI competition? As described above, China’s AI strategy highlights the way many countries increasingly view AI as a global competition that involves nation-states, rather than as a market in which companies can invest.108 As Elsa Kania writes, the People’s Liberation Army (PLA)
is funding a wide range of projects involving AI, and the Chinese defense industry and PLA research institutes are pursuing extensive research and development, in some cases partnering with private enterprises.109
Adopting militarily-exclusive AI technologies could also generate significant organizational pressure on militaries. Even if it would be hard for most countries to be fast followers, or mimic the advances of other militaries, great-power competition in AI would generate risk for those powers that are unable to adapt in order to organizationally exploit advances in AI, even if they are able to make technical advances. Traditionally, this risk is highest for the world’s leading military power, in this case the United States. Leading military powers often struggle to envision how to use new technologies in ways that are organizationally disruptive. They can also be blind to that fact, believing they are in the lead right up to the point when their failure of creativity matters.110
From a balance-of-power perspective, this scenario would be more likely to feature disruption among emerging and great powers but not a broader leveling of the military playing field. The ability to exclude many countries from advances in AI would concentrate military competition among current leading militaries, such as the United States, China, and Russia. There could be significant disruption within those categories, though. A Chinese military that more rapidly developed critical algorithms for broader battle management, or that was more willing to use them than the United States, might gain advantages that shifted power in the Asia-Pacific. This assumes that these algorithms operate as they are designed to operate. All militarily-useful AI will have to be hardened against hacking and spoofing. Operators will use narrow AI applications only if they are as or more effective or reliable as existing inhabited or remotely-piloted options.111
While this discussion has focused on narrow AI applications, the notion of bilateral competition in AI may be most pressing when thinking about artificial general intelligence.112 Although artificial general intelligence is beyond the scope of this paper, it would matter as a discrete competitive point only if there is a clear reward to being first, as opposed to being a fast follower. For example, developing artificial general intelligence first could lock in economic or military leadership. Then others would not have the ability to adopt it themselves, or their adoptions would be somehow less relevant, and that could be a discrete “end point” to competition. It seems unlikely, however, that such development would be that discrete or that one country would get a lead in this technology that is so large that it can consolidate the impact of being a first mover before others catch up.
Conclusion
Technological innovations, whether the machine gun, the railroad, or the longbow, can influence the balance of power and international conflict. Yet their impact is generally determined by how people and organizations use the technology rather than by the technology itself.113 It is too early to tell what the impact of narrow AI will be, but technology development suggests it will have at least some effect.
As an “enabling” technology that is more like electricity or the combustion engine than a weapon system, narrow AI is likely to have an impact that extends beyond specific questions of military superiority to influence economic power and societies around the world. This article demonstrates that technological innovation in AI could have large-scale consequences for the global balance of power. Whatever the mix of dual-use AI or militarily-exclusive AI that ends up shaping modern militaries over the next few decades, the organizational adoption requirements are likely to be significant. Militaries around the world will have to grapple with how to change recruiting and promotion policies to empower soldiers who understand algorithms and coding, as well as potential shifts in force structure to take advantage of AI-based coordination on the battlefield.
Military and economic history suggests that the effect of narrow AI could be quite large, even if suggestions of AI triggering a new industrial revolution are overstated. Adoption capacity theory shows that changes in relative military power become more likely in cases of military innovations that require large organizational changes and the adoption of new operational concepts. Even if the United States, China, and Russia were to end up with similar levels of basic AI capacity over the next decade, the history of military innovations from the phalanx to blitzkrieg suggests it is how they and others use AI that will matter most for the future of military power.
Whether AI capabilities diffuse relatively slowly or quickly, major military powers will likely face security dilemmas having to do with AI development and deployment. In a slow diffusion scenario, if countries fear that adversaries could get ahead in ways that are hard to rapidly mimic — and small differences in capabilities will matter on the battlefield — that will foster incentives for quick development and deployment. In a rapid diffusion scenario, competitive incentives will also exist, as countries feel like they have to race just to keep up.114 Moreover, it will be inherently difficult to measure competitors’ progress with AI (unlike, say, observing the construction of an aircraft carrier), causing countries to assume the worst of their potential rivals.
Competition in developing AI is underway. Countries around the world are investing heavily in AI, though the United States and China seem to be ahead. Yet even if the space-race analogy is not precise, understanding AI as a competition can still be useful. Such frameworks help people and organizations understand the world around them, from how to evaluate international threats to the potential trajectory of wars.115 If likening competition in AI to the space race clarifies the stakes in ways that generate incentives for bureaucratic action at the government level, and raises corporate and public awareness, the analogy stands to have utility for the United States.
From a research perspective, one limitation of this article is its focus on the balance of power and international competition, as opposed to specific uses of AI. Future research could investigate particular implementations of AI for military purposes or other critical questions. Specific implementations could include the use of autonomous weapon systems able to select and engage targets on their own. These systems could raise ethical and moral questions about human control,116 as well as practical issues surrounding war that is fought at “machine speed.”117 The integration of AI into early-warning systems and its ability to aid in rapid targeting could also affect crisis stability and nuclear weapons.118 In the broader security realm, AI will affect human security missions.119 By laying out an initial framework for how military applications of narrow AI could structure international competition and the balance of power, this article lays the groundwork for thinking through these questions in the future.

China is spending much more than the United States on AI research, and Chinese AI researchers are producing more papers on topics such as deep learning than U.S. researchers. 
This article also raises a series of policy questions. When thinking about AI as an arena for international competition, one question is whether, in response to China’s AI strategy, the United States should launch its own comprehensive AI strategy. In 2016, the Obama White House released an AI policy road map. It acknowledged the importance of U.S. leadership in AI but focused mostly on regulatory policy questions.120 The transition from Barack Obama to Donald Trump led to a pause in these efforts, though the White House recently announced the creation of a new committee of AI experts to advise it on policy choices.121
Some might argue that it is necessary for the United States to develop and announce a formal AI strategy similar to China’s.122 While there are plenty of private-sector incentives for the development of AI technology, only the government can coordinate AI investments and ensure the development of particular implementations that it considers critical for AI leadership.123
On the other hand, it is the free market in the United States, and its connections to the global economy, that have made the United States an engine of global innovation. More centrally planned economies have often struggled with innovation. During the Cold War, the Soviet defense industrial base and military proved effective at perfecting existing technologies or adopting technologies. The centralized Soviet system, however, made true innovation more difficult.124
China is spending much more than the United States on AI research, and Chinese AI researchers are producing more papers on topics such as deep learning than U.S. researchers.125 How that translates into tangible advances in AI technology is unclear. From a balance-of-power perspective, one could argue that the optimal approach would involve a mixed strategy between market and government development of AI. In the economic arena, central planning can stifle innovation, meaning the role of government should be to fund basic research and then let market incentives do the rest.
The defense sector may be different, however. For the United States, it will be up to the Department of Defense to clearly outline what types of AI technologies are most useful and to seed research and development to turn those technologies into a reality. For any strategy, for both the United States and China, a principal challenge will be translating basic research in programs of record into actual capabilities. As Cummings writes about government agencies working on AI systems around the world, “[T]he agencies developing these technologies are struggling to make the leap from development to operational implementation.”126
More broadly, if investing in and appropriately utilizing AI is critical to military power in the 21st century, the U.S. approach is a mixed bag. Optimists can point to investments in connecting cutting-edge research to U.S. military forces through institutions such as the Defense Innovation Unit – Experimental (DIUx), the Strategic Capabilities Office, and the Defense Advanced Research Projects Agency (DARPA). From discussions of the “Third Offset” to “Multi-Domain Battle,” senior military and civilian leaders are also taking the challenge of AI seriously.127
Meanwhile, a great deal of bottom-up innovation is happening in the U.S. military, both in terms of developing technologies and experimenting with novel concepts of operation. It is possible that the research and smaller, experimental programs that the United States is funding will become part of mainstream U.S. military programs, enabling the United States to stay ahead and sustain its military superiority. If narrow AI continues to develop, adopting the technology will require sustained attention by senior leaders.
Pessimists, however, can point to a gap between rhetoric and unit-level experimentation on the one hand and budgetary realities on the other.128 There is a lot of discussion about the importance of artificial intelligence and robotics, as well as a clear desire among senior uniformed leadership to make the U.S. military more networked, distributed, and lethal by taking advantage of AI, among other technologies.129 This rhetoric has not yet caught up to reality in terms of U.S. military spending on AI. When faced with a choice of investing in a next-generation drone, for example, the U.S. Navy used its available programmatic dollars for the MQ-25 air-to-air refueling platform, which will support inhabited aircraft such as the F-35. The MQ-25 program was chosen over an advanced armed system — based on the X-47B demonstrator — with stealthy potential that could operate in dangerous conflict environments.130 The MQ-25 decision may be seen as the canary in the coal mine if the U.S. military falls behind in the coming decades — especially if a failure to appropriately adopt advances in AI and robotics turns out to be a key reason for that relative military decline.
At the end of the day, however, AI’s effect on international politics will depend on much more than choices about one particular military program. The challenge for the United States will be in calibrating, based on trends in AI developments, how fast to move in incorporating narrow AI applications. This will be true whether those applications are dual-use or based in exclusively-military research. And that challenge to leadership in AI in general, as well as in military power, is complicated by the movements of China and other competitors, all of which seem interested in leveraging AI to challenge U.S. military superiority.
Michael C. Horowitz is professor of political science and associate director of Perry World House at the University of Pennsylvania. He is on Twitter: @mchorowitz.
ISSN (Print): 2576-1021
ISSN(Online): 2576-1153
Image: U.S. Air Force




								Endnotes								


1 James Vincent, ""Putin Says the Nation That Leads in AI ‘Will Be the Ruler of the World,’"" Verge, Sept. 4, 2017, https://www.theverge.com/2017/9/4/16251226/russia-ai-putin-rule-the-world.
2 Klaus Schwab, The Fourth Industrial Revolution (New York: Crown Business, 2017).
3 Colin Clark, ""Our Artificial Intelligence ‘Sputnik Moment’ Is Now: Eric Schmidt & Bob Work,"" Breaking Defense, Nov. 1, 2017, https://breakingdefense.com/2017/2011/our-artificial-intelligence-sputnik-moment-is-now-eric-schmidt-bob-work/.
4 Seth Fiegerman, ""Elon Musk Predicts World War III,"" CNN, Sept. 4, 2017, http://money.cnn.com/2017/09/04/technology/culture/elon-musk-ai-world-war/index.html.
5 On technological determinism, see Merritt R. Smith and Leo Marx, Does Technology Drive History? The Dilemma of Technological Determinism (Cambridge, MA: MIT Press, 1994).
6 William H. McNeill, The Pursuit of Power: Technology, Armed Force, and Society Since A.D. 1000 (Chicago: University of Chicago Press, 1982).
7 Jeremiah E. Dittmar, ""Information Technology and Economic Change: The Impact of the Printing Press,"" Quarterly Journal of Economics 126, no. 3 (August 2011): 1133-1172, https://doi.org/10.1093/qje/qjr035.
8 Robert Jervis, The Meaning of the Nuclear Revolution: Statecraft and the Prospect of Armageddon (Ithaca, NY: Cornell University Press, 1989).
9 In the military dimension, see Michael C. Horowitz, The Diffusion of Military Power: Causes and Consequences for International Politics (Princeton, NJ: Princeton University Press, 2010). For a critique of technology-focused thinking about the future of war, see Paul K. Van Riper and Frank G. Hoffman, ""Pursuing the Real Revolution in Military Affairs: Exploiting Knowledge-Based Warfare,"" National Security Studies Quarterly 4, no. 3 (1998): 4; H.R. McMaster, ""Continuity and Change: The Army Operating Concept and Clear Thinking About Future War,"" Military Review (2015), https://www.westpoint.edu/scusa/SiteAssets/SitePages/Keynote Speakers/Continuity and Change by LTG McMaster.pdf.
10 Clark G. Reynolds, The Fast Carriers; The Forging of an Air Navy, 1st ed. (New York: McGraw-Hill, 1968); Mark R. Peattie, Sunburst: The Rise of Japanese Naval Air Power, 1909-1941 (Annapolis, MD: Naval Institute Press, 2001).
11 Marshall McLuhan, The Gutenberg Galaxy: The Making of Typographic Man (Toronto: University of Toronto Press, 1962).
12 Clemency Burton-Hill, ""The Superhero of Artificial Intelligence: Can This Genius Keep It in Check?"" Guardian, Feb. 16, 2016, https://www.theguardian.com/technology/2016/feb/16/demis-hassabis-artificial-intelligence-deepmind-alphago.
13 Katja Grace et al., ""When Will AI Exceed Human Performance? Evidence from AI Experts,"" arXiv (May 2017), https://arxiv.org/abs/1705.08807.
14 This is based on the Russell and Norvig definition that artificial intelligence is about the construction of artificial rational agents that can perceive and act. See Stuart Russell and Peter Norvig, Artificial Intelligence: A Modern Approach, 3rd ed. (Englewood Cliffs, NJ: Prentice Hall, 2009). Also see Calum McClelland, ""The Difference Between Artificial Intelligence, Machine Learning, and Deep Learning,"" Medium.com, Dec. 4, 2017, https://medium.com/iotforall/the-difference-between-artificial-intelligence-machine-learning-and-deep-learning-3aa67bff5991.
15 Shane Legg and Marcus Hutter, ""Universal Intelligence: A Definition of Machine Intelligence,"" arXiv (December 2007): 12, https://arxiv.org/pdf/0712.3329.pdf.
16 Michael C. Horowitz, ""Military Robotics, Autonomous Systems, and the Future of Military Effectiveness,"" in The Sword's Other Edge: Tradeoffs in the Pursuit of Military Effectiveness, ed. Dan Reiter (New York: Cambridge University Press, 2017).
17 Matt Simon, ""Watch Boston Dynamics' SpotMini Robot Open a Door,"" Wired, Feb. 12, 2018,  https://www.wired.com/story/watch-boston-dynamics-spotmini-robot-open-a-door/.
18 This is based on the discussion in Paul Scharre and Michael C. Horowitz, ""An Introduction to Autonomy in Weapon Systems,"" Center for a New American Security working paper (February 2015): 5, https://www.cnas.org/publications/reports/an-introduction-to-autonomy-in-weapon-systems.
19 Michael C. Horowitz, Paul Scharre, and Alex Velez-Green, ""A Stable Nuclear Future? The Impact of Automation, Autonomy, and Artificial Intelligence"" (Philadelphia: University of Pennsylvania, 2017).
20 Scharre and Horowitz, “Autonomy in Weapon Systems,” 6.
21 Murray Campbell, A. Joseph Hoane Jr., and Feng-hsiung Hsu, “Deep Blue,” Artificial Intelligence 134, no. 1-2 (2002): 57-83, https://doi.org/10.1016/S0004-3702(01)00129-1.
22 Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, eds., Machine Learning: An Artificial Intelligence Approach (New York: Springer, 2013); Allen Newell and Herbert Alexander Simon, Human Problem Solving (Englewood Cliffs, NJ: Prentice Hall, 1972).
23 Robert D. Hof, ""Deep Learning,"" MIT Technology Review (2013), https://www.technologyreview.com/s/513696/deep-learning/; Anh Nguyen, Jason Yosinski, and Jeff Clune, ""Deep Neural Networks Are Easily Fooled: High Confidence Predictions for Unrecognizable Images"" (Paper presented at the Institute of Electrical and Electronics Engineers conference on computer vision and pattern recognition, 2015), https://arxiv.org/abs/1412.1897.
24 Antonio Lieto, Antonio Chella, and Marcello Frixione, ""Conceptual Spaces for Cognitive Architectures: A Lingua Franca for Different Levels of Representation,"" Biologically Inspired Cognitive Architectures 19 (January 2017), https://doi.org/10.1016/j.bica.2016.10.005.
25 Calestous Juma, Innovation and Its Enemies: Why People Resist New Technologies (Oxford: Oxford University Press, 2016).
26 Lockheed Martin, ""Building the F-35: Combining Teamwork and Technology,"" accessed May 8, 2018, https://www.f35.com/about/life-cycle/production.
27 The “Third Offset” was a Department of Defense initiative led by Deputy Secretary of Defense Robert Work that was designed to preserve U.S. military superiority through exploiting a generation of emerging technologies. Robert O. Work, Deputy Secretary of Defense Remarks to the Association of the U.S. Army Annual Convention, Oct. 4, 2016, https://www.defense.gov/News/Speeches/Speech-View/Article/974075/remarks-to-the-association-of-the-us-army-annual-convention/.
28 Walter Frick, ""Why AI Can't Write This Article (Yet),"" Harvard Business Review, July 24, 2017, https://hbr.org/cover-story/2017/07/the-business-of-artificial-intelligence#/2017/07/why-ai-cant-write-this-article-yet.
29 Andrew Ng, ""Artificial Intelligence Is the New Electricity,"" Medium, April 28, 2017, https://medium.com/@Synced/artificial-intelligence-is-the-new-electricity-andrew-ng-cc132ea6264.
30 Mick Ryan, ""Building a Future: Integrated Human-Machine Military Organization,"" Strategy Bridge, Dec. 11, 2017, https://thestrategybridge.org/the-bridge/2017/12/11/building-a-future-integrated-human-machine-military-organization; Paul Scharre, Army of None: Autonomous Weapons and the Future of War (New York: W.W. Norton, 2018).
31 Gregory C. Allen, ""Project Maven Brings AI to the Fight Against ISIS,"" Bulletin of the Atomic Scientists, Dec. 21, 2017, https://thebulletin.org/project-maven-brings-ai-fight-against-isis11374.
32 Note that this illustrates the importance of data in training algorithms. While there is some promise to synthetic data for training algorithms, there is not currently a substitute for data based on real-world experience. Thus, access to large quantities of useful data will be critical to designing successful algorithms in particular arenas. For an example of basic defense research on using AI to increase situational awareness, see Heather Roff, “COMPASS: A new AI-driven situational awareness tool for the Pentagon?” Bulletin of the Atomic Scientists, May 10, 2018, https://thebulletin.org/compass-new-ai-driven-situational-awareness-tool-pentagon11816.
33 Scharre and Horowitz, “Autonomy in Weapon Systems,” 5.
34 Nick Bostrom, Superintelligence: Paths, Dangers, Strategies (Oxford: Oxford University Press, 2014).
35 Allan Dafoe, ""Governing the AI Revolution: The Research Landscape"" (New Haven, CT: Yale University, 2018), https://machine-learning-and-security.github.io/slides/Allan-Dafoe-NIPS-s.pdf.
36 Grace et al., “When Will AI Exceed Human Performance?”
37 McNeill, The Pursuit of Power.
38 David A. Baldwin, ""Power Analysis and World Politics: New Trends versus Old Tendencies,"" World Politics 31, no. 2 (January 1979): 161-194, https://www.jstor.org/stable/2009941; Robert Gilpin, War and Change in World Politics (New York: Cambridge University Press, 1981).
39 Scharre and Horowitz, “Autonomy in Weapon Systems.”
40 Missy L. Cummings, ""Artificial Intelligence and the Future of Warfare,"" Chatham House, January 2017, https://www.chathamhouse.org/publication/artificial-intelligence-and-future-warfare.
41 Napoleonic warfare, or levée en masse, is an example of a military innovation not considered tied to technological innovations.
42 On military innovation in general, see Adam Grissom, ""The Future of Military Innovation Studies,"" Journal of Strategic Studies 29, no. 5 (2006): 905-934, https://doi.org/10.1080/01402390600901067.
43 Bernard Brodie et al., eds., The Absolute Weapon: Atomic Power and World Order (New York: Harcourt Brace, 1946); Stephen P. Rosen, Winning the Next War: Innovation and the Modern Military (Ithaca, NY: Cornell University Press, 1991); Barry R. Posen, The Sources of Military Doctrine: France, Britain, and Germany Between the World Wars (Ithaca, NY: Cornell University Press, 1984).
44 Posen, Sources of Military Doctrine; Rosen, Winning the Next War; Dima Adamsky, The Culture of Military Innovation: The Impact of Cultural Factors on the Revolution in Military Affairs in Russia, the U.S., and Israel (Stanford, CA: Stanford University Press, 2010); Theo Farrell, ""World Culture and Military Power,"" Security Studies 14, no. 3 (2005): 448-488, https://doi.org/10.1080/09636410500323187; Emily O. Goldman and Leslie C. Eliason, eds., The Diffusion of Military Technology and Ideas (Stanford, CA: Stanford University Press, 2003).
45 Horowitz, Diffusion of Military Power, 10-11.
46 This relates to questions about the offense/defense implications of technology, though technology itself is rarely predictive. See Keir A. Lieber, War and the Engineers: The Primacy of Politics Over Technology (Ithaca, NY: Cornell University Press, 2005).
47 Stephen D. Biddle, Military Power: Explaining Victory and Defeat in Modern Battle (Princeton, NJ: Princeton University Press, 2004).
48 This is not meant to endorse or reject the notion of technology as a social construction. On that point, see Trevor J. Pinch and Wiebe E. Bijker, ""The Social Construction of Facts and Artefacts: Or How the Sociology of Science and the Sociology of Technology Might Benefit Each Other,"" Social Studies of Science 14, no. 3 (1984): 399-441, http://www.jstor.org/stable/285355. What is key is that it is in the context of organizational behavior that the impact of technological change becomes clearest.
49 Posen, Sources of Military Doctrine; Rosen, Winning the Next War; Adamsky, The Culture of Military Innovation.
50 Nuclear weapons are arguably an exception to this pattern, given their unique destructive power. But they may be the exception that proves the rule.
51 Andrea Gilli and Mauro Gilli, ""Military-Technological Superiority: Systems Integration and the Challenges of Imitation, Reverse Engineering, and Cyber-Espionage,"" International Security (forthcoming).
52 Mancur Olson, The Rise and Decline of Nations: Economic Growth, Stagflation, and Social Rigidities (New Haven, CT: Yale University Press, 1982); Horowitz, Diffusion of Military Power.
53 Dennis E. Showalter, Railroads and Rifles: Soldiers, Technology, and the Unification of Germany (Hamden, CT: Archon Books, 1975); Geoffrey L. Herrera and Thomas G. Mahnken, ""Military Diffusion in Nineteenth-Century Europe: The Napoleonic and Prussian Military Systems,"" in The Diffusion of Military Technology and Ideas, ed. Emily O. Goldman and Leslie C. Eliason (Stanford, CA: Stanford University Press, 2003).
54 Another example is the tank. Applied to AI and drones, see Ulrike E. Franke, ""A European Approach to Military Drones and Artificial Intelligence,"" European Council on Foreign Relations, June 23, 2017, http://www.ecfr.eu/article/essay_a_european_approach_to_military_drones_and_artificial_intelligence. In general, see David E. Johnson, Fast Tanks and Heavy Bombers: Innovation in the U.S. Army, 1917–1945 (Ithaca, NY: Cornell University Press, 1998).
55 Horowitz, Diffusion of Military Power.
56 Horowitz, Diffusion of Military Power.
57 Horowitz, Diffusion of Military Power.
58 See Gilpin, War and Change in World Politics; Daniel R. Headrick, The Tools of Empire: Technology and European Imperialism in the Nineteenth Century (New York: Oxford University Press, 1981); Horowitz, Diffusion of Military Power.
59 Kenneth N. Waltz, Theory of International Politics (New York: McGraw-Hill, 1979).
60 Marvin B. Lieberman and David B. Montgomery, ""First-Mover Advantages,"" Strategic Management Journal 9, no. 1 (1988): 41-58, https://doi.org/10.1002/smj.4250090706; Marvin B. Lieberman and David B. Montgomery, ""First-Mover (Dis)Advantages: Retrospective and Link with the Resource-Based View,"" Strategic Management Journal 19, no. 12 (1998): 1111-1125, https://doi.org/10.1002/(SICI)1097-0266(1998120)19:12<1111::AID-SMJ21>3.0.CO;2-W; Gerard J. Tellis and Peter N. Golder, Will and Vision: How Latecomers Grow to Dominate Markets (New York: McGraw-Hill, 2002).
61 Everett M. Rogers, Diffusion of Innovations, 5th ed. (New York: Free Press, 2003).
62 Horowitz, Diffusion of Military Power. For a recent argument about the complexity of stealth and the challenges of adoption, see Gilli and Gilli, “Military-Technological Superiority.”
63 Showalter, Railroads and Rifles; Geoffrey L. Herrera, Technology and International Transformation: The Railroad, the Atom Bomb, and the Politics of Technological Change (Albany, NY: State University of New York Press, 2006).
64 Eric Schmidt, ""Keynote Address at the Center for a New American Security Artificial Intelligence and Global Security Summit,"" Center for a New American Security, Nov. 13, 2017, https://www.cnas.org/publications/transcript/eric-schmidt-keynote-address-at-the-center-for-a-new-american-security-artificial-intelligence-and-global-security-summit.
65 John R. Allen and Amir Husain, ""The Next Space Race Is Artificial Intelligence,"" Foreign Policy, Nov. 3, 2017, http://foreignpolicy.com/2017/2011/2003/the-next-space-race-is-artificial-intelligence-and-america-is-losing-to-china/.
66 Tom Simonite, ""For Superpowers, Artificial Intelligence Fuels New Global Arms Race,"" Wired, Sept. 8, 2017, https://www.wired.com/story/for-superpowers-artificial-intelligence-fuels-new-global-arms-race/; Zachary Cohen, ""US Risks Losing Artificial Intelligence Arms Race to China and Russia,"" CNN, Nov. 29, 2017, https://www.cnn.com/2017/11/29/politics/us-military-artificial-intelligence-russia-china/index.html; Julian E. Barnes and Josh Chin, ""The New Arms Race in AI,"" Wall Street Journal, Mar. 2, 2018, https://www.wsj.com/articles/the-new-arms-race-in-ai-1520009261.
67 Graham Webster et al., ""China’s Plan to ‘Lead’ in AI: Purpose, Prospects, and Problems,"" New America Foundation, Aug. 1, 2017, https://www.newamerica.org/cybersecurity-initiative/blog/chinas-plan-lead-ai-purpose-prospects-and-problems/.
68 Samuel Bendett, ""Russia Is Poised to Surprise the US in Battlefield Robotics,"" Defense One, Jan. 25 2018, https://www.defenseone.com/ideas/2018/01/russia-poised-surprise-us-battlefield-robotics/145439/; Barnes and Chin, “The New Arms Race in AI”; Samuel Bendett, “Red Robots Rising,” Strategy Bridge, Dec. 12, 2017, https://thestrategybridge.org/the-bridge/2017/12/12/red-robots-rising-behind-the-rapid-development-of-russian-unmanned-military-systems; Valerie Insinna, “Russia’s nuclear underwater drone is real and in the Nuclear Posture Review,” Defense News, Jan. 12, 2018, https://www.defensenews.com/space/2018/01/12/russias-nuclear-underwater-drone-is-real-and-in-the-nuclear-posture-review/.
69 For an overview of AI and national security, see Daniel S. Hoadley and Nathan J. Lucas, “Artificial Intelligence and National Security,” Congressional Research Service, Apr. 26, 2018, https://fas.org/sgp/crs/natsec/R45178.pdf. Also see Benjamin Jensen, Chris Whyte, and Scott Cuomo, Algorithms at War: The Promise, Peril, and Limits of Artificial Intelligence, Working Paper (2018).
70 This is similar to what is going on in robotics. See Horowitz, ""Military Robotics, Autonomous Systems, and the Future of Military Effectiveness.""
71 Sachin Chitturu et al., ""Artificial Intelligence and Southeast Asia's Future,"" McKinsey Global Institute, September 2017, 1, https://www.mckinsey.com/~/media/McKinsey/Global Themes/Artificial Intelligence/Artificial-intelligence-and-Southeast-Asias-future.ashx; Ng Eng Hen, “Speech at Committee of Supply Debate,” Ministry of Defense, Singapore, Mar. 7, 2014, https://www.mindef.gov.sg/web/portal/mindef/news-and-events/latest-releases/article-detail/2014/march/2014mar06-speeches-00341/!ut/p/z0/fY07D4IwFIV_iwNjcy-IMKMOalQWNNjFVLxKFcqjDei_t8hq3M53ch7AIQWuRCfvwshKicLyiQfnMF4uVuh7-3iWuBgdk2Q7m-_XhzCADfD_Abs.
72 Mark Prigg, ""Who Goes There? Samsung Unveils Robot Sentry That Can Kill From Two Miles Away,"" Daily Mail (UK), Sept. 15, 2014, http://www.dailymail.co.uk/sciencetech/article-2756847/Who-goes-Samsung-reveals-robot-sentry-set-eye-North-Korea.html.
73 Ryan, “Building a Future: Integrated Human-Machine Military Organization.”
74 ""Strategic Review of Defence and National Security: 2017,"" French Ministry of Defense, Dec. 22, 2017, 3, https://www.defense.gouv.fr/dgris/politique-de-defense/revue-strategique/revue-strategique. On the European approach to drones and AI, also see Franke, “A European Approach to Military Drones and Artificial Intelligence.”
75 Eliran Rubin, ""Tiny IDF Unit Is Brains Behind Israeli Army Artificial Intelligence,"" Haaretz, Aug. 15, 2017, https://www.haaretz.com/israel-news/tiny-idf-unit-is-brains-behind-israeli-army-artificial-intelligence-1.5442911; Yaakov Lappin, ""Artificial Intelligence Shapes the IDF in Ways Never Imagined,"" Aglemeiner, Oct. 16, 2017, https://www.algemeiner.com/2017/10/16/artificial-intelligence-shapes-the-idf-in-ways-never-imagined/.
76 Lappin, “Artificial Intelligence Shapes the IDF in Ways Never Imagined.”
77 One could also argue AI has the potential to go beyond shaping the character of war and change the nature of war itself. From a Clausewitzian perspective, that war is human fundamentally defines its nature. Carl von Clausewitz, On War, trans. Michael Howard and Peter Paret (Princeton, NJ: Princeton University Press, 1989). Thus, the nature of war is unchanging. In theory, could AI alter the nature of war itself because wars will be fought by robotic systems, not people, and because of AI’s potential to engage in planning and decision-making that were previously human endeavors? U.S. Defense Secretary James Mattis speculated in February 2018 that AI is “fundamentally different” in ways that raise questions about the nature of war. See ""Press Gaggle by Secretary Mattis En Route to Washington, D.C.,"" Department of Defense, Feb. 17, 2018, https://www.defense.gov/News/Transcripts/Transcript-View/Article/1444921/press-gaggle-by-secretary-mattis-en-route-to-washington-dc/. This is an important debate but one beyond the scope of this paper. For elements of this debate, see Kareem Ayoub and Kenneth Payne, ""Strategy in the Age of Artificial Intelligence,"" Journal of Strategic Studies 39, no. 5-6 (2016): 793-819, https://doi.org/10.1080/01402390.2015.1088838; Frank G. Hoffman, ""Will War’s Nature Change in the Seventh Military Revolution?"" Parameters 47, no. 4, (2018): 19-31, https://ssi.armywarcollege.edu/pubs/parameters/issues/Winter_2017-18/5_Hoffman.pdf. Also see Kenneth Payne, Strategy, Evolution, and War: From Apes to Artificial Intelligence (Washington, DC: Georgetown University Press, 2018).
78 Robert O. Work, Deputy Secretary of Defense Speech at Center for a New American Security Defense Forum, Dec. 14, 2015, http://www.defense.gov/News/Speeches/Speech-View/Article/634214/cnas-defense-forum; John R. Allen and Amir Husain, ""On Hyperwar,"" Proceedings of the United States Naval Institute 143, no. 7 (July 2017), https://www.usni.org/magazines/proceedings/2017-07/hyperwar.
79 Bolei Zhou et al., ""Places: A 10 Million Image Database for Scene Recognition,"" IEEE Transactions on Pattern Analysis and Machine Intelligence (July 2017), https://doi.org/10.1109/TPAMI.2017.2723009.
80 Miles Brundage et al., ""The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation,"" Working Paper (2018), https://arxiv.org/abs/1802.07228; Stephanie Carvin, “Normal Autonomous Accidents”, Social Science Research Network (2018), http://dx.doi.org/10.2139/ssrn.3161446.
81 For example, see Vijay Kumar, Aleksandr Kushleyev, and Daniel Mellinger, ""Three-Dimensional Manipulation of Teams of Quadrotors,"" Google Patents, 2017, https://patents.google.com/patent/US20150105946.
82 Simon Jones et al., ""Evolving Behaviour Trees for Swarm Robotics,"" in Distributed Autonomous Robotic Systems, ed. Roderich Grob, et al. (Boulder, CO: Springer, 2018).
83 Tero Karras et al., ""Progressive Growing of GANs for Improved Quality, Stability, and Variation,"" published as a conference paper at International Conference on Learning Representations 2018 (2018), https://arxiv.org/abs/1710.10196.
84 Michael C. Horowitz, ""The promise and peril of military applications of artificial intelligence,” Bulletin of the Atomic Scientists, Apr. 23, 2018, https://thebulletin.org/military-applications-artificial-intelligence/promise-and-peril-military-applications-artificial-intelligence.
85 Rosen, Winning the Next War.
86 Clayton M. Christensen, The Innovator’s Dilemma (Boston, MA: Harvard Business School Press, 1997). This also relates to strategies for innovating within militaries. See Peter Dombrowski and Eugene Gholz, Buying Military Transformation (New York: Columbia University Press, 2006).
87 Cummings, ""Artificial Intelligence and the Future of Warfare,"" 9. Also see Lawrence Spinetta and Missy L. Cummings, ""Unloved Aerial Vehicles: Gutting Its UAV Plan, the Air Force Sets a Course for Irrelevance,"" Armed Forces Journal (November 2012): 8-12, http://hdl.handle.net/1721.1/86940.
88 Adamsky, Culture of Military Innovation.
89 Emily O. Goldman, ""Cultural Foundations of Military Diffusion,"" Review of International Studies 32, no. 1 (2006): 69-91, https://doi.org/10.1017/S0260210506006930.
90 Farrell, ""World Culture and Military Power.""
91 Horowitz, Diffusion of Military Power.
92 Horowitz, Diffusion of Military Power.
93 Tim Hwang, ""Computational Power and the Social Impact of Artificial Intelligence,"" Mar. 23, 2018, https://ssrn.com/abstract=3147971.
94 Hof, “Deep Learning.”
95 Meg Murphy, ""Building the Hardware for the Next Generation of Artificial Intelligence,"" MIT News, Nov. 30 2017, http://news.mit.edu/2017/building-hardware-next-generation-artificial-intelligence-1201.
96 James Manyika et al., ""What the Future of Work Will Mean for Jobs, Skills, and Wages,"" McKinsey Global Institute report, November 2017, https://www.mckinsey.com/global-themes/future-of-organizations-and-work/what-the-future-of-work-will-mean-for-jobs-skills-and-wages.
97 Carl B. Frey and Michael A. Osborne, ""The Future of Employment: How Susceptible Are Jobs to Computerisation?"" Technological Forecasting and Social Change 114 (January 2017): 254-280, https://doi.org/10.1016/j.techfore.2016.08.019.
98 Cummings, “Artificial Intelligence and the Future of Warfare”: 10.
99 Kate Conger and Dell Cameron, ""Google Is Helping the Pentagon Build AI for Drones,"" Gizmodo, Mar. 6, 2018, https://gizmodo.com/google-is-helping-the-pentagon-build-ai-for-drones-1823464533.
100 Horowitz, Diffusion of Military Power.
101 Cade Metz, ""Google Just Open Sourced TensorFlow, Its Artificial Intelligence Engine,"" Wired, Nov. 9, 2015, https://www.wired.com/2015/11/google-open-sources-its-artificial-intelligence-engine/.
102 Dario Amodei et al., ""Concrete Problems in AI Safety,"" arXiv, July 25, 2016, https://arxiv.org/abs/1606.06565. This commitment to openness has limits. Google has many proprietary algorithms, and Microsoft’s Watson (which first came to fame when it defeated Ken Jennings, the greatest living human Jeopardy player) is also proprietary.
103 In extreme examples where first-mover advantages are difficult to generate, there can be advantages for rapid followers that do not have to pay initial R&D costs. Alexander Gerschenkron, Economic Backwardness in Historical Perspective: A Book of Essays (Cambridge, MA: Harvard University Press, 1962).
104 The Germans did not call it blitzkrieg, explicitly. Ernest R. May, Strange Victory: Hitler's Conquest of France (New York: Hill and Wang, 2000); Posen, Sources of Military Doctrine.
105 The issue of algorithm theft raises questions of cybersecurity. This differs from more common questions about whether cyberweapons are autonomous weapons. On cyber in general, see Thomas Rid, Rise of the Machines: A Cybernetic History (New York: W. W. Norton, 2016); Rebecca Slayton, ""What Is the Cyber Offense-Defense Balance? Conceptions, Causes, and Assessment,"" International Security 41, no. 3 (2017): 72-109, https://doi.org/10.1162/ISEC_a_00267; Ben Buchanan, The Cybersecurity Dilemma: Hacking, Trust, and Fear Between Nations (Oxford: Oxford University Press, 2017); Nina Kollars, “The Rise of Smart Machines,” in The Palgrave Handbook of Security, Risk, and Intelligence, ed. Robert Dover, Huw Dylan, and Michael Goodmans (London: Palgrave MacMillan, 2016), 195-211.
106 Stephen G. Brooks, Producing Security: Multinational Corporations, Globalization, and the Changing Calculus of Conflict (Princeton, NJ: Princeton University Press, 2005); Andrea Gilli and Mauro Gilli, ""The Diffusion of Drone Warfare? Industrial, Organizational and Infrastructural Constraints,"" Security Studies 25, no. 1 (2016): 50-84, https://doi.org/10.1080/09636412.2016.1134189.
107 Gilli and Gilli, “Military-Technological Superiority.” Note this extends the argument to AI.
108 Elsa B. Kania, ""Battlefield Singularity: Artificial Intelligence, Military Revolution, and China’s Future Military Power,"" Center for a New American Security, Nov. 28, 2017, https://www.cnas.org/publications/reports/battlefield-singularity-artificial-intelligence-military-revolution-and-chinas-future-military-power.
109 Kania, “Battlefield Singularity”: 4.
110 Gilpin, War and Change in World Politics.
111 Paul Scharre, ""Autonomous Weapons and Operational Risk,"" Center for a New American Security, working paper, (February 2016), https://www.cnas.org/publications/reports/autonomous-weapons-and-operational-risk.
112 Thanks to Heather Roff for making this point clear.
113 H.R. McMaster, ""Continuity and Change: The Army Operating Concept and Clear Thinking About Future War.""
114 On the security dilemma, see Robert Jervis, ""Cooperation Under the Security Dilemma,"" World Politics 30, no. 2 (1978): 167-214, http://www.jstor.org/stable/2009958. This would also make arms control more difficult.
115 Yuen Foong Khong, Analogies at War: Korea, Munich, Dien Bien Phu, and the Vietnam Decisions of 1965 (Princeton, NJ: Princeton University Press, 1992).
116 Michael C. Horowitz, ""The Ethics and Morality of Robotic Warfare: Assessing The Debate Over Autonomous Weapons,"" Daedalus 145, no. 4 (2016): 25-36, https://doi.org/10.1162/DAED_a_00409.
117 On warfare at machine speed, see Robert O. Work, Deputy Secretary of Defense Remarks to the Association of the U.S. Army Annual Convention, Oct. 4, 2016, https://www.defense.gov/News/Speeches/Speech-View/Article/974075/remarks-to-the-association-of-the-us-army-annual-convention/. On AI and the speed of war, see Allen and Husain, ""On Hyperwar.""
118 Horowitz, Scharre, and Velez-Green, “A Stable Nuclear Future?”
119 Heather Roff, ""Advancing Human Security Through Artificial Intelligence,"" Chatham House, May 2017, https://www.chathamhouse.org/publication/advancing-human-security-through-artificial-intelligence.
120 Ed Felten and Terah Lyons, ""The Administration’s Report on the Future of Artificial Intelligence,"" White House, Oct. 12, 2016, https://obamawhitehouse.archives.gov/blog/2016/10/12/administrations-report-future-artificial-intelligence.
121 Aaron Boyd, “White House Announces Select Committee of Federal AI Experts,” Nextgov, May 10, 2018, https://www.nextgov.com/emerging-tech/2018/05/white-house-announces-select-committee-federal-ai-experts/148123/.
122 For a recent example, see William A. Carter, Emma Kinnucan, and Josh Elliot, ""A National Machine Intelligence Strategy for the United States,"" Center for Strategic and International Studies and Booz Allen Hamilton, March 2018, https://www.csis.org/analysis/national-machine-intelligence-strategy-united-states.
123 Allen and Husain, ""The Next Space Race Is Artificial Intelligence.""
124 Matthew Evangelista, Innovation and the Arms Race: How the United States and the Soviet Union Develop New Military Technologies (Ithaca, NY: Cornell University Press, 1988).
125 Cade Metz, ""As China Marches Forward on A.I., the White House Is Silent,"" New York Times, Feb. 12, 2018, https://www.nytimes.com/2018/02/12/technology/china-trump-artificial-intelligence.html.
126 Cummings, 9.
127 Tom Simonite, ""Defense Secretary James Mattis Envies Silicon Valley's AI Ascent,"" Wired, Aug. 11, 2017, https://www.wired.com/story/james-mattis-artificial-intelligence-diux/; Gopal Ratnam, ""DARPA Chief Touts Artificial Intelligence Efforts,"" Roll Call, Mar. 1, 2018, https://www.rollcall.com/news/politics/darpa-chief-touts-artificial-intelligence-efforts.
128 On bottom-up innovation, see Grissom, “The Future of Military Innovation Studies.” On innovation inhibitors, see Adam M. Jungdahl and Julia M. Macdonald, ""Innovation Inhibitors in War: Overcoming Obstacles in the Pursuit of Military Effectiveness,"" Journal of Strategic Studies 38, no. 4 (2015): 467-499, https://doi.org/10.1080/01402390.2014.917628.
129 Adm. Harry B. Harris Jr. et al., ""The Integrated Joint Force: A Lethal Solution for Ensuring Military Preeminence,"" Strategy Bridge, March 2, 2018, https://thestrategybridge.org/the-bridge/2018/3/2/the-integrated-joint-force-a-lethal-solution-for-ensuring-military-preeminence.
130 Sam LaGrone, ""Navy Releases Final MQ-25 Stingray RFP; General Atomics Bid Revealed,"" USNI News, Oct. 10, 2017, https://news.usni.org/2017/10/10/navy-releases-final-mq-25-stingray-rfp-general-atomics-bid-revealed.






Michael C. Horowitz





Michael C. Horowitz


Read more about author Michael C. Horowitz
			Read More
		





Related Articles




Access Denied? Non-Aligned State Decisions to Grant Access During War




Access Denied? Non-Aligned State Decisions to Grant Access During War




scholarly

 Foreign Policy Summer 2024



Emily Ellinger



Access decisions play a crucial role in war, with belligerent states employing various methods to gain access into neutral states. Yet, the decision-making process of potential host nations has largely been unexplored for modern, large-scale conflicts. This…







Why We Write




Why We Write



foundation

 TNSR Summer 2024



Francis J. Gavin



In his introduction to Volume 7, Issue 3, the chair of our editorial board, Frank Gavin, considers the limitations that academic disciplines tend to impose on writing, the value in making such writing more accessible, and the need to consider big questions…







Stuck Onshore: Why the United States Failed to Retrench from Europe during the Early Cold War




Stuck Onshore: Why the United States Failed to Retrench from Europe during the Early Cold War




scholarly

 Grand Strategy Fall 2024



Joshua Byun



A growing number of scholars and policymakers are showing interest in a grand strategy that calls on the United States to retrench from key global regions while devolving the burden of checking the expansion of hegemonic aspirants to local allies. I highlight…







Top
",https://schema.org,"[{'@type': 'Article', '@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#article', 'isPartOf': {'@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/'}, 'author': {'name': 'Michael C. Horowitz', '@id': 'https://tnsr.org/#/schema/person/d82e9095fa63cd4b7ac36dc3e1f6dd03'}, 'headline': 'Artificial Intelligence, International Competition, and the Balance of Power', 'datePublished': '2018-05-15T08:30:40+00:00', 'dateModified': '2022-02-16T20:44:10+00:00', 'mainEntityOfPage': {'@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/'}, 'wordCount': 10207, 'commentCount': 0, 'publisher': {'@id': 'https://tnsr.org/#organization'}, 'image': {'@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#primaryimage'}, 'thumbnailUrl': '/wp-content/uploads/2018/05/size0.jpg', 'articleSection': ['Artificial Intelligence'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#respond']}]}, {'@type': 'WebPage', '@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/', 'url': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/', 'name': 'Artificial Intelligence, International Competition, and the Balance of Power - Texas National Security Review', 'isPartOf': {'@id': 'https://tnsr.org/#website'}, 'primaryImageOfPage': {'@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#primaryimage'}, 'image': {'@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#primaryimage'}, 'thumbnailUrl': '/wp-content/uploads/2018/05/size0.jpg', 'datePublished': '2018-05-15T08:30:40+00:00', 'dateModified': '2022-02-16T20:44:10+00:00', 'breadcrumb': {'@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#primaryimage', 'url': '/wp-content/uploads/2018/05/size0.jpg', 'contentUrl': '/wp-content/uploads/2018/05/size0.jpg', 'width': 640, 'height': 320}, {'@type': 'BreadcrumbList', '@id': 'https://tnsr.org/2018/05/artificial-intelligence-international-competition-and-the-balance-of-power/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://tnsr.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence, International Competition, and the Balance of Power'}]}, {'@type': 'WebSite', '@id': 'https://tnsr.org/#website', 'url': 'https://tnsr.org/', 'name': 'Texas National Security Review', 'description': '', 'publisher': {'@id': 'https://tnsr.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://tnsr.org/search/{search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://tnsr.org/#organization', 'name': 'Texas National Security Review', 'url': 'https://tnsr.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://tnsr.org/#/schema/logo/image/', 'url': '/wp-content/uploads/2018/03/TNSR-Logo-1.png', 'contentUrl': '/wp-content/uploads/2018/03/TNSR-Logo-1.png', 'width': 584, 'height': 200, 'caption': 'Texas National Security Review'}, 'image': {'@id': 'https://tnsr.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/Texas-National-Security-Review-352070491920273/', 'https://x.com/TXNatSecReview']}, {'@type': 'Person', '@id': 'https://tnsr.org/#/schema/person/d82e9095fa63cd4b7ac36dc3e1f6dd03', 'name': 'Michael C. Horowitz', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://tnsr.org/#/schema/person/image/', 'url': '/wp-content/uploads/2017/10/HorowitzPicture1.jpg', 'contentUrl': '/wp-content/uploads/2017/10/HorowitzPicture1.jpg', 'caption': 'Michael C. Horowitz'}, 'description': 'Michael C. Horowitz is a professor of political science and the associate director of Perry World House at the University of Pennsylvania. He recently received the 2017 Karl Deutsch Award from the International Studies Association, presented annually to a scholar under age 40 who is judged to have made the most significant contribution to the study of international relations and peace research. Professor Horowitz is the co-author of the book, Why Leaders Fight, and his award-winning first book, The Diffusion of Military Power: Causes and Consequences for International Politics. His research interests include technology and global politics, military innovation, the role of leaders in international politics, and forecasting. He has published in a wide array of peer reviewed journals, as well as more popular outlets such as the New York Times and Politico. Professor Horowitz previously worked for the Office of the Undersecretary of Defense for Policy in the Department of Defense. He is affiliated with the Foreign Policy Research Institute, the Center for Strategic and International Studies, and the Center for a New American Security. He is also a Term Member of the Council on Foreign Relations. He has held fellowships at the Weatherhead Center, Olin Institute, and Belfer Center at Harvard, where he received his PhD in Government. Professor Horowitz received his BA in political science from Emory University. You can find him on Twitter @mchorowitz.', 'url': 'https://tnsr.org/author/michael-c-horowitz/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vZmluYW5jaWFsaXQubmV0L25ld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uvd2hlbi13aWxsLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXJlcGxhY2UteW91ci1qb2LSAQA?oc=5,When Will Artificial Intelligence Replace Your Job? - Financial IT,2018-05-16,Financial IT,https://financialit.net,- By 2020 AI could replace the current World Poker Champion.,N/A,"- By 2020 AI could replace the current World Poker Champion. - Studies estimate machines will write a top 40 pop song, run all telephone banking and build any Lego set within a decade. - By the century’s halfway point, AI will have written a New York Times Bestseller. - The research is revealed shortly after Google Duplex’s big unveiling. Since the very first computer program, humans have been consumed with the concept of artificial intelligence - the idea that one day machines can think, react and interact with us in a distinctly lifelike manner. The truth is, we’re closer than we think.",N/A,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LnRoZW5ld2h1bWFuaXRhcmlhbi5vcmcvZmVhdHVyZS8yMDE4LzA1LzE2L3doZW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbWVldHMtaHVtYW5pdGFyaWFuLWphcmdvbtIBAA?oc=5,When Artificial Intelligence meets humanitarian jargon - The New Humanitarian,2018-05-16,The New Humanitarian,https://www.thenewhumanitarian.org,"When Artificial Intelligence meets humanitarian jargon - The New Humanitarian puts quality, independent journalism at the service of the millions of people affected by humanitarian crises around the world",N/A,*Updated. We asked a bot to devise new aid agency names and job titles. The results are in...,*Updated. We asked a bot to devise new aid agency names and job titles. The results are in...,N/A,N/A,"



Home




Europe




Switzerland









Solutions and Innovations



Feature


16 May 2018


When Artificial Intelligence meets humanitarian jargon

Could you be the next Hand Officer at Bin Welfare Relief and Training?











Ben ParkerCo-founder, former CEO, and editor














Ben Parker/IRIN
 

Word cloud of humanitarian agencies and job titles












Ben ParkerCo-founder, former CEO, and editor









Share on X (formerly Twitter)




Share on Facebook




Share via WhatsApp




Share via email










GENEVA

On the sidelines of an AI for Good conference in Geneva, where humans and robots mingled and discussed how machine learning could help global development, IRIN rolled up its data science sleeves and deployed a bot on an important new challenge: making up names of aid agencies and aid job titles.
It’s a new take on some of the jargon and repetitiveness that can be found in the relief and development sector, and hopefully gives a taste of the rudiments of machine learning.
*Update 31 May: Following suggestions from readers, we applied the machine learning code to 4,500 project titles from the International Aid Transparency Initiative dataset to generate some surreal but somehow familiar new project ideas. Scroll down for a taste... 
First we downloaded a list of over 9,000 aid organisations from the UN’s Financial Tracking Service (FTS) database. The A-Z list goes from “A Call to Serve International” to “Zwanan Development Organization”. Then we fed them into a machine learning system running open-source code in the Python language.
The aid organisation names were processed by a recurrent neural network built on the TensorFlow system. We won’t (also, can’t) explain how the maths works in detail. However, it functions like any machine learning process – the foundation of the current explosion in “AI” across a range of sectors – it analyses the patterns of letters and words and then attempts to generate new examples using the rules it has deduced from the original data.
(Our idea to explore the jargon and nomenclature in aidspeak owes much to Janelle Shane, who feeds machine learning algorithms with unlikely lists, such as the names of craft beers or the names of pet guinea pigs).
Here are some of our favourites, generated entirely by code.
Update: Aid project titles produced by AI



Here are 12 favourites generated from studying a dataset of 4,500 IATI project titles:

Support to South Savable Girls
Emergency Womens Affected Host Technocons 
Support to complication against agriculture in The Rehabilitation
Tender Support to State Final Emergency II​
Emergency WASH project for Visibility
Develop Award Girls in Good Di Minion
Bossing Support​
Emergency WASH Election Response in South Sudan​
Mid-term Education Most Hard African States in Kosovo
Support to the GBV Livestock Strategy of Integrated Host Communities in IDPs in Laba​
Support to the poops in Emergency​
Transit come response for the improved EU Development of the Sudanian State​

Aid agency names produced by AI
Some sound quite plausible – if you do set one up, please let us know and send the logo.
Support International Aid Foundation
Community Aid Association for Development
Association des Femmes de l'Environnement
Medicultural Community Foundation
Some a little pompous: 
International Council of Society
Internationalist Fund for Rehabilitation
Save Foundation
Others, possibly creative and/or radical:
Sure Vision for Red Cross
Africa Relief and Empower Swedish Family
People Trust of South ye Community Humanitarian Family
Water World Sudan

AI-generated NGO: People Trust of South ye Community Humanitarian Family

Sometimes our bot seemed to get a little lost and confused:
Alliance for Development and Development
Miseration Mission for Comment of Africa
Alliance Save the Development International
Gy Alliance Conflicted Now Women International
El Organisation des Futures
And, some are just plain weird (sorry not sorry):
ACF and Development Porn
Scam for National Aid
Bin Welfare Relief and Training
Association Premirerianista
Next, we moved onto humanitarian job titles. We fed the bot more than 2,000 vacancies on the UN’s ReliefWeb jobs pages. And these are some of the best new jobs titles it came up with. Perhaps some of these fit your current role? Or make you wish you could apply?

AI-generated job title: Regional Regionalization of International Programme for Head of Party  

Humanitarian job titles invented by AI
Senior!
Chief of Party (Sex)
Sneak Specialist
South Changes Manager 
Chef of Finances and Grant & Manager
Regional Leader (Interant) Livelihood and Consultant
Multiple International Director 
Nation demonic Manager
Technical?
Safe Manager
Consultant Africa and Charging and Programme 
Hand Officer
Projectories Analyst
Regional Regionalization of International Programme for Head of Party  
Changing Director
Communications Coordinator and Memaliature Manager
Integration Director (Support) (H/F) 
International Parent (H/F) Adviser
Street Communication Laborator
Development Coordinator – Safety Senior Charge Policy Specialist
And some that sound more like entry level roles:
Engager Programmes Intern 
Responsalialist
Project (unimation volunteer)
Reliefancer Coordinator
Editor Intern Coordinator
As always, comments and reactions are welcome below - tell us your favourites!
bp/ag
 





Share this article



Share on X (formerly Twitter)




Share on Facebook




Share via WhatsApp




Share via email







",https://schema.org,"[{'@type': 'NewsArticle', 'headline': 'When Artificial Intelligence meets humanitarian jargon', 'name': 'When Artificial Intelligence meets humanitarian jargon', 'about': 'Feature', 'description': '*Updated. We asked a bot to devise new aid agency names and job titles. The results are in...', 'image': {'@type': 'ImageObject', 'url': 'https://assets.thenewhumanitarian.org/s3fs-public/styles/social_large/public/legacy_s3_root/word_art_20.jpeg?itok=0MGBmn75'}, 'datePublished': '2018-05-16T15:22:08+0100', 'dateModified': '2018-05-31T15:22:57+0100', 'author': {'@type': 'Person', '@id': 'https://www.thenewhumanitarian.org/authors/ben-parker', 'name': 'Ben Parker', 'url': 'https://www.thenewhumanitarian.org/authors/ben-parker'}, 'publisher': {'@type': 'Organization', 'name': 'The New Humanitarian', 'url': 'https://www.thenewhumanitarian.org'}, 'mainEntityOfPage': 'https://www.thenewhumanitarian.org/feature/2018/05/16/when-artificial-intelligence-meets-humanitarian-jargon'}, {'@type': 'WebSite', '@id': 'https://www.thenewhumanitarian.org', 'name': 'The New Humanitarian', 'url': 'https://www.thenewhumanitarian.org', 'publisher': {'@type': 'Organization', '@id': 'https://www.thenewhumanitarian.org', 'name': 'The New Humanitarian', 'url': 'https://www.thenewhumanitarian.org', 'sameAs': ['https://twitter.com/newhumanitarian', 'https://www.facebook.com/NewHumanitarian', 'https://www.youtube.com/c/newhumanitarian'], 'logo': {'@type': 'ImageObject', 'url': 'https://www.thenewhumanitarian.org/themes/custom/tnh/images/logo.svg'}}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vbmV3cy5zdGFuZm9yZC5lZHUvc3Rvcmllcy8yMDE4LzA1L2hvdy1haS1pcy1jaGFuZ2luZy1zY2llbmNl0gEA?oc=5,How artificial intelligence is changing science | Stanford Report - Stanford University News,2018-05-15,Stanford University News,https://news.stanford.edu,N/A,N/A,"Artificial intelligence is now part of our daily lives, whether in voice recognition systems or route finding apps. But scientists are increasingly drawing on AI to understand society, design new materials and even improve our health.",N/A,N/A,N/A,"



Once a computer scientist’s pipe dream, artificial intelligence and machine learning are now part of our daily lives in the form of voice recognition systems, product recommendation platforms and navigation tools. All of these rely on computer algorithms that process information and solve problems in a way similar to – and sometimes superior to – the human mind.Yet artificial intelligence is doing more than just recommending new restaurants and the best routes to them. It is also changing the way scientists across diverse disciplines are studying the world. Aided by the close proximity of medical researchers, computer scientists, psychologists and more, Stanford researchers are deploying artificial intelligence to map poverty in Africa, find safer alternatives to conventional rechargeable batteries and perhaps even understand our own minds.




Image credit: Getty Images 

AI Advancing Social Science & Humanities
Stanford researchers are finding new ways to study linguistics, politics, psychology and more based on artificial intelligence. They’re also thinking about how to use AI to improve public policy – and whether, for some tasks, AI really is all its cracked up to be.
 

Image credit: Getty Images 

Share this card

Facebook
Twitter
LinkedIn
Email








 
Law & Policy
Policy lab explores how government administers by algorithm
Students contribute to a report on how AI is being used in governmental agencies and where it might go in the future.
 



 
Social Sciences
Don’t Let Artificial Intelligence Pick Your Employees
Algorithms aren't yet sophisticated enough to make hiring decisions, a Stanford GSB scholar argues, in part because of deep misconceptions about hiring's long-term strategic role.
 



 
Social Sciences
Artificial intelligence in the workplace
Artificial intelligence offers both promise and peril as it revolutionizes the workplace, the economy and personal lives, says James Timbie of the Hoover Institution, who studies artificial intelligence and other technologies.
 



 
Science & Technology
Can AI prevent mobile devices from dropping calls?
Today, a weak signal is no big deal, but next-generation wireless devices will need flawless service to perform vital tasks such as telesurgery, or helping guide autonomous cars.
 



 
Science & Technology
Stanford-hosted study examines how AI might affect urban life in 2030
In the first of what will be a century-long series of periodic studies on artificial intelligence, top scientists say, “It is not too soon for social debate on how the fruits of an AI-dominated economy should be shared.”
 



 
Humanities
Ancient myths reveal early fantasies about artificial life
In her latest research, Stanford classics scholar Adrienne Mayor highlights ancient Greek myths that contained ideas about creating artificial, lifelike creatures.
 



 
Social Sciences
Algorithms reveal changes in stereotypes
New Stanford research shows that, over the past century, linguistic changes in gender and ethnic stereotypes correlated with major social movements and demographic changes in the U.S. Census data.
 



 
Social Sciences
At Stanford, experts explore artificial intelligence’s social benefits
Experts from Stanford and elsewhere talked about the future of artificial intelligence in society as part of the Global Entrepreneurship Summit.
 




 
Science & Technology
Stanford scientists combine satellite data, machine learning to map poverty
Accurate and reliable information on the location of impoverished zones is surprisingly lacking for much of the world. Applying machine learning to satellite images could identify impoverished regions in Africa.
 



 
Social Sciences
Robo-journalism is good news for stocks
Automation in the newsroom expands coverage of smaller firms and improves markets.
 



 
Awards
Humanizing robots with humor detection
Three computer science students created a bot that can detect humor in spoken language. The research garnered them an award at a recent conference in Singapore.
 



 
Social Sciences
CASBS tackles interdisciplinary solutions to societal problems
Interdisciplinary research at Stanford’s Center for Advanced Study in the Behavioral Sciences addresses future of work, consequences of evolving technology and other pressing societal issues.
 



 
Social Sciences
Stanford professors discuss ethics involving driverless cars
Self-driving technology presents vast ethical challenges and questions. Several professors and interdisciplinary groups at Stanford who are tackling this issue  offer their perspectives on the topic.
 



 
Social Sciences
Cops speak less respectfully to black community members
Professors Jennifer Eberhardt and Dan Jurafsky, along with other Stanford researchers, detected racial disparities in police officers’ speech after analyzing more than 100 hours of body camera footage from Oakland Police.
 



 
Social Sciences
Tracking fishing from space
Satellite data from thousands of high seas fishing vessels over four years illuminate global fishing’s scope and pattern and hold promise for improving ocean management across the planet.
 



 
Humanities
Stanford historian examines age-old inquiry about what it means to be ‘living’
In research covering four centuries of scientific debate, Stanford historian Jessica Riskin investigates different views of man and machine, and how this debate laid the groundwork for later theories of evolution and science.
 



 
Social Sciences
Chris Manning: How computers are learning to understand language​
A computer scientist discusses the evolution of computational linguistics and where it's headed next. He was recently named the Thomas M. Siebel Professor in Machine Learning.
 



 
Social Sciences
Audrey Shafer: Why Frankenstein still holds a mirror to modern science
Stanford’s Russ Altman and Audrey Shafer reflect on Mary Shelley’s Frankenstein and how it illuminates the moral and ethical challenges of modern science.
 



 
Social Sciences
A neighborhood’s cars indicate its politics
Stanford researchers led by Fei-Fei Li use computer algorithms to analyze millions of publicly available images on Google Street View.
 



 
Social Sciences
​Michael Bernstein: Welcome to the future of crowdsourcing
On The Future of Everything radio show, a computer scientist explores the rise of automation, crowdsourcing communities and the ethical implications of the gig economy.
 



 
Humanities
Which is more fair: a human or a machine?
A team of researchers harness the variability of human decision making to compensate for two flaws in machine-learning models: factoring in the unknown and the unknowable.
 



 
Social Sciences
Algorithm improves integration of refugees
A new machine learning algorithm developed by Stanford researchers could help governments and resettlement agencies find the best places for refugees to relocate, depending on their particular skills and backgrounds.
 






 (Image credit: Getty Images) 

AI Advancing Science & Technology
Like any technology, one of the hopes for artificial intelligence is that it could help us do our jobs better – even if that job is advancing science and technology. Today, Stanford researchers are designing better batteries, building polite pedestrian robots and plumbing the depths of the oceans, all with help from AI.

 (Image credit: Getty Images) 

Share this card

Facebook
Twitter
LinkedIn
Email








 
Science & Technology
Inventory indicates who goes solar and why
Stanford researchers have identified the GPS locations and sizes of almost all U.S. solar power installations from a billion images. Using the data, which are public, they identified factors that promote the use of solar energy and those that discourage it.
 



 
Science & Technology
AI recreates chemistry’s periodic table of elements
In a first step toward generating an artificial intelligence program that can find new laws of nature, a Stanford team created a program that reproduced a complex human discovery – the periodic table.
 




 
Science & Technology
Stanford’s humanoid robotic diver recovers treasures from King Louis XIV’s wrecked flagship
The robot, called OceanOne, is powered by artificial intelligence and haptic feedback systems, allowing human pilots an unprecedented ability to explore the depths of the oceans in high fidelity.
 



 
Science & Technology
Stanford spurs AI navigation for space rendezvous software
Stanford researchers are developing an AI-powered navigation system to direct spaceborne ‘tow trucks’ designed to restart or remove derelict satellites circling aimlessly in graveyard orbits.
 



 
Science & Technology
No more burning batteries? Stanford scientists turn to AI to create safer lithium-ion batteries
Researchers have identified 21 solid materials that could replace flammable liquid electrolytes in lithium-ion batteries, improving the safety of electronic devices like cellphones and laptops.
 



 
Science & Technology
New AI camera could revolutionize autonomous vehicles
Stanford engineers combine two types of computers to create a faster and less energy-intensive image processor for use in autonomous vehicles, security cameras and medical devices.
 



 
Science & Technology
JackRabbot 2: The polite pedestrian robot
Like its predecessor, JackRabbot 2 is learning how to navigate safely through spaces occupied by people, following the rules of human etiquette. What it learns could help it move comfortably among us in the future.
 



 
Science & Technology
Neural networks for neutrinos
Particle physics and computer science have been intertwined since at least the 1960s. Now, scientists are using cutting-edge machine-learning techniques to investigate the phantom particles called neutrinos.
 



 
Science & Technology
Scientists use machine learning to speed discovery of metallic glass
SLAC and its collaborators are transforming the way new materials are discovered. In a new report, they combine artificial intelligence and accelerated experiments to discover potential alternatives to steel in a fraction of the time.
 



 
Science & Technology
All ears: New intelligent listening technologies
Machines are excellent listeners. As you speak or type, circuits inside your smartphone, smartwatch and virtual assistant are collecting information about you, then converting it into digital patterns.
 



 
Science & Technology
SLAC-led project will use artificial intelligence to prevent or minimize electric grid failures
It’s the first to employ AI to help the grid manage power fluctuations, resist damage and bounce back faster from storms, solar eclipses, cyberattacks and other disruptions
 



 
Science & Technology
Stanford students get creative with robots
After learning new software and programming languages, Stanford students in the Artificial Intelligence Laboratory have an opportunity to choose a creative task and design a robot to perform the task for demonstration.
 



 
Science & Technology
Machine learning dramatically streamlines search for more efficient chemical reactions
An advance by SLAC and Stanford researchers greatly reduces the time needed to analyze complex chemical reactions, including catalysis.
 



 
Science & Technology
Artificial intelligence analyzes gravitational lenses 10 million times faster
SLAC and Stanford researchers demonstrate that brain-mimicking neural networks can revolutionize the way astrophysicists analyze their most complex data, including extreme distortions in spacetime that are crucial for our understanding of the universe.
 




 
Science & Technology
Autonomous robotics class integrates theory and practice
Students programmed robots to autonomously navigate an unknown cityscape and aid in a simulated rescue of animals in peril in a class that mimics the programming needed for autonomous cars or robots of the future.
 



 
Science & Technology
Deep learning comes full circle
Artificial intelligence drew much inspiration from the human brain but went off in its own direction. Now, AI has come full circle and is helping neuroscientists better understand how our own brains work.
 



 
Science & Technology
​Maneesh Agrawala: Artificial intelligence comes to multimedia
​Stanford professors Russ Altman and Maneesh Agrawala explore advances in media where AI handles the rough cut, and editing becomes like using word processors for images and sound.
 



 
Science & Technology
Artificial intelligence index tracks emerging field
The initiative measures AI’s technological progress much as the GDP and S&P 500 take the pulse of the U.S. economy and stock market.
 



 
Science & Technology
Artificial intelligence report finds advances in working with human language, global reach
The group’s report helps investors and governmental agencies and provides updates for people whose lives will be affected by new developments in AI.
 



 
Science & Technology
Andrew Ng: Why AI is the new electricity
A computer scientist discusses artificial intelligence’s promise, hype and biggest obstacles.
 






 (Image credit: Getty Images) 

AI Advancing Health
Researchers at the Stanford School of Medicine are working closely with computer scientists to develop algorithms capable of diagnosing ailments without human help – and in some cases, those algorithms outperform doctors. They’re also using AI to search for new drugs, design new prosthetics and improve patient safety – and considering the ethical implications as well.

 (Image credit: Getty Images) 

Share this card

Facebook
Twitter
LinkedIn
Email








 
Science & Technology
AI predicts drug pair side effects
Millions of people take upwards of five medications a day, but testing the side effects of such combinations was impractical – until now.
 



 
Science & Technology
Stanford research could improve counseling on crisis help lines
Many people now text rather than call for help, allowing computer scientists to study anonymous data files and learn which counseling tactics work best.
 



 
Science & Technology
How AI could help veterinarians code their notes
A team led by scientists at the School of Medicine has developed an algorithm that can read the typed-out notes from veterinarians and predict specific diseases that the animal may have.
 



 
Science & Technology
Artificial intelligence rivals radiologists in screening X-rays for certain diseases
In a matter of seconds, a new algorithm read chest X-rays for 14 pathologies, performing as well as radiologists in most cases, a Stanford-led study says.
 



 
Science & Technology
Researchers can forecast risk of deadly vascular condition from genome sequence
By combining genome-sequence information and health records, Stanford scientists have developed a new algorithm that can predict the risk of abdominal aortic aneurysm, and potentially could be used for any number of diseases.
 



 
Science & Technology
Deep learning algorithm could aid drug development
Combining computer science and chemistry, researchers show how an advanced form of machine learning that works off small amounts of data can be used to solve problems in drug discovery.
 



 
Science & Technology
Computers trounce pathologists in predicting lung cancer type, severity
Automating the analysis of slides of lung cancer tissue samples increases the accuracy of tumor classification and patient prognoses, according to a new study.
 



 
Science & Technology
Artificial intelligence used to identify skin cancer
In hopes of creating better access to medical care, Stanford researchers have trained an algorithm to diagnose skin cancer.
 



 
Science & Technology
Researchers say use of artificial intelligence in medicine raises ethical questions
In a perspective piece, Stanford researchers discuss the ethical implications of using machine-learning tools in making health care decisions for patients.
 



 
Science & Technology
Algorithm outperforms radiologists at diagnosing pneumonia
Stanford researchers have developed a deep learning algorithm that evaluates chest X-rays for signs of disease. In just over a month of development, their algorithm outperformed expert radiologists at diagnosing pneumonia.
 



 
Science & Technology
Algorithm diagnoses heart arrhythmias with cardiologist-level accuracy
A new deep learning algorithm can diagnose 14 types of heart rhythm defects, called arrhythmias, better than cardiologists. This could speed diagnosis and improve treatment for people in rural locations.
 



 
Social Sciences
Stanford scholars discuss mental health and technology
Conversational software programs might provide patients a less risky environment for discussing mental health, but they come with some risks to privacy or accuracy. Stanford scholars discuss the pros and cons of this trend.
 



 
Science & Technology
Researchers improve patient safety with bedside computer vision
What if clinician imperfection could be improved by a form of artificial intelligence that continuously detects, and prompts correction of, defects in bedside care?
 



 
Science & Technology
Artificial intelligence in medicine — predicting patient outcomes and beyond
Nigram Shah, an associate professor of medicine, discusses how artificial intelligence could help doctors predict outcomes after patients are hospitalized.
 


Science & Technology
Height may be risk factor for varicose veins
In the largest genetic study of varicose veins ever completed, Stanford researchers and their collaborators provide evidence that being tall is a risk factor for the condition.
 



 
Science & Technology
Virtual competitors vie for a different kind of athletic title
Better models of the bone, muscles and nerves that control our bodies could help doctors manage movement disorders like cerebral palsy. A new competition is crowdsourcing the search for those tools.
 



AuthorNathan CollinsCampus unitStanford School of Humanities & SciencesRelated topicsArts & HumanitiesScience & EngineeringSocial SciencesArtificial IntelligenceShare this storyCopy link



Subscribe to Stanford ReportNews, insights and events delivered to your inbox each weekday morning.Sign upStories for you80,000-plus characters, one keyboardAsian American research center launchesLectures explore data’s place in the humanitiesPopular storiesMichele Rasmussen appointed vice provost for student affairsHow technology is reinventing K-12 educationWhat to know about Gen ZHow the apparel industry could refashion itself‘You’ve got to find what you love,’ Jobs says



Read nextView all Read nextArts & HumanitiesStanford’s winter quarter guest artistsNewsArts & Humanities‘Residual Governance’ dives into South Africa’s mining industryResearchArts & HumanitiesMeet Stanford’s 2023 fall quarter guest artistsNewsArts & Humanities80,000-plus characters, one keyboardBookArts & HumanitiesAsian American research center launchesNewsArts & HumanitiesLectures explore data’s place in the humanitiesAnalysis & InsightsArts & HumanitiesStanford’s winter quarter guest artistsNewsArts & Humanities‘Residual Governance’ dives into South Africa’s mining industryResearchArts & HumanitiesMeet Stanford’s 2023 fall quarter guest artistsNewsArts & Humanities80,000-plus characters, one keyboardBookArts & HumanitiesAsian American research center launchesNewsArts & HumanitiesLectures explore data’s place in the humanitiesAnalysis & InsightsSlide 1Slide 2Slide 3Slide 4Slide 5Slide 6PreviousNext


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3Lm9wZW5nbG9iYWxyaWdodHMub3JnL2FzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXByb2dyZXNzZXMtd2hhdC1kb2VzLXJlYWwtcmVzcG9uc2liaWxpdHktbG9vay1saWtlL9IBAA?oc=5,"As artificial intelligence progresses, what does real responsibility look like? - OpenGlobalRights",2018-05-16,OpenGlobalRights,https://www.openglobalrights.org,"Artificial intelligence is disrupting how we live, work, do business, and govern—but what mechanisms can guide responsible behavior without stifling innovation?",N/A,"Artificial intelligence is disrupting how we live, work, do business, and govern—but what mechanisms can guide responsible behavior without stifling innovation?","Artificial intelligence is disrupting how we live, work, do business, and govern—but what mechanisms can guide responsible behavior without stifling innovation?",N/A,N/A,"
 
EFE/ Michael Reynolds
While Mark Zuckerberg prepares to testify before the Senate, 100 cardboard cutouts of the Facebook founder and CEO stand outside the U.S. Capitol in Washington on Tuesday, April 10, 2018.

Artificial intelligence (AI) technologies—and the data driven business models underpinning them—are disrupting how we live, interact, work, do business, and govern. The economic, social and environmental benefits could be significant, for example in the realms of medical research, urban design, fair employment practices, political participation, public service delivery. But evidence is mounting about the potential negative consequences for society and individuals. These include the erosion of privacy, online hate speech, and the distortion of political engagement. They also include amplifying socially embedded discrimination where algorithms based on bias training data are used in criminal sentencing or job advertising and recruitment. Further, certain vulnerable groups will require special attention. For example, UNICEF has recently published a series of papers on Child Rights and Business in a Digital World elaborating on risks and opportunities children face in the areas of access to education and information, freedom of expression, privacy, digital marketing, and online safety.
All of this means we urgently need a robust view of what responsible conduct looks like, and a vision for how markets and governance mechanisms can guide the right behaviors while also encouraging innovation. We believe that the business and human rights field, in particular the UN Guiding Principles on Business and Human Rights (UNGPs), offers a compelling way forward that perfectly fits the challenge ahead.
In a recent US Senate hearing, Facebook CEO Mark Zuckerberg returned again and again to a sentiment that the company did not take a “broad enough view” of their responsibility. This perfectly captures the state of affairs, not just for Silicon Valley, but for the entire global business community in the midst of developing their digital strategy for the so-called fourth industrial revolution. Zuckerberg spoke of a “broader philosophical shift in how we approach our responsibility as a company” and that “we have to go through all of our relationships with people and make sure that we’re taking a broad enough view of our responsibility”. He said it was a mistake to “view our responsibility as just building tools” and when questioned about the company’s early move fast and break things mantra, admitted: “I do think we made mistakes because of that”.
In a recent US Senate hearing, Facebook CEO Mark Zuckerberg returned again and again to a sentiment that the company did not take a “broad enough view” of their responsibility. 
Yet beyond noting several different legislative proposals (for example around data privacy, online child protection, consent, and campaign advertising) none of the 50 Senators probed for a clear articulation of what “broader responsibility” might mean in practice. We are left with a hopeful sentiment and no clear sense of what society should expect (or require) of organizations and companies developing, selling, buying, and using data-driven and AI technology solutions. Having no framework of responsibility—nor an understanding of how stakeholders can check that responsibility—is not a good result for anyone. Law makers and corporations will endure a tug-of-war between the false choice of libertarianism and government intervention. Civil society and affected people will seek accountability when harms occur but likely lack the technical know-how or resources to achieve their desired results. And entrepreneurs, engineers, technologists, data scientists, sales teams, and business leaders will have no compass to guide their practices. All the while, innovation will continue and more harm to people (especially vulnerable groups) will likely occur. Lots of noise, but no change.
For these reasons, the UN Guiding Principles on Business and Human Rights (UNGPs) could meet the challenge ahead by moving steadily forward to fix what is not working for rights-holders. Several recent developments point in that direction. Initiatives such as the Partnership on AI, the Ethics and Governance of AI Fund, AI Now, and the work of Data & Society are exploring the social, ethical, and human rights implications of AI. Governments are moving forward too. The Australian Human Rights Commission, for example, has launched a project which seeks to ensure human rights are prioritized in the design and regulation of new technologies. And numerous organizations, such as the Information Technology Industry Council, the Software and Information Industry Association, and the Institute of Electrical and Electronics Engineers, have published principles for ethics and AI—some explicitly referring to the UN Guiding Principles.
We see three key questions as critical to this debate and will be writing papers that address them in coming months:

In what ways can the business and human rights field address the potentially negative consequences of disruptive technologies? For example, how can society’s governance of adverse impacts on the most vulnerable (such as children, those living in poverty, and ethnic minorities) keep pace with change? Companies should know and show that they respect all human rights in the course of doing business, and there is a global need to provide swift and meaningful remedy when harms occur. Those working in this area need to reflect on the limits of current frameworks, tools and practices, and identify where innovation is needed—such as methods that address human rights opportunities, as well as human rights risks.
	 
Who needs to be part of realizing a broader practice of responsibility? Large technology firms have a key leadership role to play. But we believe that the human rights issues associated with big data and AI are now a concern for all industries, not just technology companies. The potential impacts on human rights of deploying AI solutions in certain core business activities (such as in sales, marketing, and the workplace) and in diverse industries (such as financial services, retail, healthcare, and transport and logistics) are significant. However, the question of “who” has other important dimensions. Who within large companies should be involved in ensuring respect for human rights (such as technology officers, engineers, data scientists, and lawyers)? What is the role of university research centers, app developers, entrepreneurs, professional bodies, and venture capitalists? How should civil society and rights-holders be involved in defining good corporate practice?
	 
What tools, methodologies or guidance will operationalize business respect for human rights in the context of disruptive technologies? How can analysts and activists map the needs of business leaders while integrating respect for human rights into company decision making? In this aspect of the debate, it is critical to highlight cases of good or emerging practices, whether related to embedding respect for human rights into policies and processes, or related to specific impacts and dilemmas. Polices, guidance, and tools that could help integrate respect for human rights into decision making about disruptive technologies are also of utmost importance. These might include: tools designed to assess the human rights impacts of products, services, and technologies; key human rights-related questions to address in due diligence when developing or procuring technological solutions; guidance on how to ensure rights-holder perspectives inform technology design; or principles for how to address informed consent and remedy in the context of digital complexity.

It is time to define responsibility in real terms and time to figure out how to embed dignity for all and respect for human rights into the fourth industrial revolution. As this debate in OGR develops, we welcome your responses to these questions, and we look forward to testing and refining our ideas with leaders in business, civil society and government.
*** This article is part of a series on technology and human rights co-sponsored with Business & Human Rights Resource Centre and University of Washington Rule of Law Initiative.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPWh0dHBzOi8vd3d3LnZvYW5ld3MuY29tL2EvYmlvbG9neS1hbmQtdGVjaG5vbG9neS80MzkyNjc5Lmh0bWzSAT9odHRwczovL3d3dy52b2FuZXdzLmNvbS9hbXAvYmlvbG9neS1hbmQtdGVjaG5vbG9neS80MzkyNjc5Lmh0bWw?oc=5,Scientists Modify Biology with Technology - Voice of America - VOA News,2018-05-14,Voice of America - VOA News,https://www.voanews.com,"Scientists attempt to improve the brain, store data in DNA and create new materials by combining biology with artificial intelligence and machine learning","Science & Health, Technology, DNA, biology","Scientists attempt to improve the brain, store data in DNA and create new materials by combining biology with artificial intelligence and machine learning","Scientists attempt to improve the brain, store data in DNA and create new materials by combining biology with artificial intelligence and machine learning",N/A,N/A,N/A,https://schema.org,,Technology,Scientists Modify Biology with Technology,en-US,"{'@type': 'Person', 'url': 'https://www.voanews.com/author/elizabeth-lee/__qqy', 'description': '', 'image': {'@type': 'ImageObject', 'url': 'https://gdb.voanews.com/956ef4de-bf51-4d4c-959e-f7657c02ce01.jpg'}, 'name': 'Elizabeth Lee'}",2018-05-14 07:18:26Z,2018-05-14 14:14:26Z,"{'logo': {'width': 512, 'height': 220, '@type': 'ImageObject', 'url': 'https://www.voanews.com/Content/responsive/VOA/en-US/img/logo.png'}, '@type': 'NewsMediaOrganization', 'url': 'https://www.voanews.com', 'sameAs': ['https://www.facebook.com/VOANews', 'https://twitter.com/voanews', 'https://www.youtube.com/user/VOAvideo', 'https://www.instagram.com/voanews/'], 'name': 'Voice of America (VOA News)', 'alternateName': ''}",NewsArticle,https://www.voanews.com/a/biology-and-technology/4392679.html,https://www.voanews.com/a/biology-and-technology/4392679.html,"{'width': 1080, 'height': 608, '@type': 'ImageObject', 'url': 'https://gdb.voanews.com/9b411861-9549-42e6-84e9-998c4512b963_tv_w1080_h608.jpg'}",Scientists Modify Biology with Technology,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihgFodHRwczovL3d3dy5ibG9vbWJlcmcuY29tL25ld3MvYXJ0aWNsZXMvMjAxOC0wNS0xNC9pbnNpZGUtZ29vZ2xlLWEtZGViYXRlLXJhZ2VzLXNob3VsZC1pdC1zZWxsLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvLXRoZS1taWxpdGFyedIBAA?oc=5,"Inside Google, a Debate Rages: Should It Sell Artificial Intelligence to the Military? - Bloomberg",2018-05-14,Bloomberg,https://www.bloomberg.com,"To win in the business of cloud computing, the company tiptoes into the business of war. Some staff fear it’s a first step toward autonomous killing machines.","ALPHABET INC-CL A,Artificial Intelligence,Military,Cloud Computing,Government,Sundar Pichai,Department of Defense,War,Diane B Greene,China,business,politics,technology,cybersecurity","To win in the business of cloud computing, the company tiptoes into the business of war. Some staff fear it’s a first step toward autonomous killing machines.","To win in the business of cloud computing, the company tiptoes into the business of war. Some staff fear it’s a first step toward autonomous killing machines.",N/A,N/A,"TechnologyCybersecurityInside Google, a Debate Rages: Should It Sell Artificial Intelligence to the Military?To win in the business of cloud computing, the company tiptoes into the business of war. Some staff fear it’s a first step toward autonomous killing machines.FacebookTwitterLinkedInEmailLinkGiftExpandPeople walk through a corridor at the Pentagon in Arlington, Virginia.Photographer: Rich Clement/BloombergFacebookTwitterLinkedInEmailLinkGiftGift this articleHave a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MOREFacebookTwitterLinkedInEmailLinkGiftBy Mark BergenMay 14, 2018 at 6:59 AM EDTBookmarkSaveLock This article is for subscribers only.Last July, 13 U.S. military commanders and technology executives met at the Pentagon's Silicon Valley outpost, two miles from Google headquarters. It was the second meeting of an advisory board set up in 2016 to counsel the military on ways to apply technology to the battlefield. Milo Medin, a Google vice president, turned the conversation to using artificial intelligence in war games. Eric Schmidt, Google’s former boss, proposed using that tactic to map out strategies for standoffs with China over the next 20 years.A few months later, the Defense Department hired Google’s cloud division to work on Project Maven, a sweeping effort to enhance its surveillance drones with technology that helps machines think and see.Have a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MORE",http://schema.org,,,"Inside Google, a Debate Rages: Should It Sell Artificial Intelligence to the Military?",,"[{'@type': 'Person', 'name': 'Mark Bergen'}]",2018-05-14T10:59:12.164Z,2018-05-14T10:59:12.158Z,"{'@type': 'Organization', 'name': 'Bloomberg', 'url': 'https://www.bloomberg.com', 'logo': {'@type': 'ImageObject', 'url': 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/bloomberg-logo-amp.bae0aa0a.png', 'width': 262, 'height': 60}}",NewsMediaOrganization,https://www.bloomberg.com/news/articles/2018-05-14/inside-google-a-debate-rages-should-it-sell-artificial-intelligence-to-the-military,https://www.bloomberg.com,"['https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iBRflVf6urwk/v1/1200x767.jpg', 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iBRflVf6urwk/v1/-1x-1.jpg', 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/social-default.cc6ae30e.jpg']",Bloomberg,False,2018-05-14T10:59:12.164Z,"{'@type': ['CreativeWork', 'Product'], 'name': 'Bloomberg', 'productID': 'bloomberg.com:basic'}","[{'name': 'Cybersecurity', '@type': 'CollectionPage', 'url': 'https://www.bloomberg.com/cybersecurity'}, {'@type': 'CollectionPage', 'name': 'Technology', 'url': 'https://www.bloomberg.com/technology'}]","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}","{'@type': 'PostalAddress', 'addressCountry': 'USA', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10022', 'streetAddress': '731 Lexington Avenue'}",https://www.bloomberg.com/diversity-inclusion,inquiry1@bloomberg.net,Bloomberg Finance L.P.,5493001KJTIIGC8Y1R12,(212) 318-2000,https://www.bloomberg.com/logo-bloomberg.svg,"[{'@type': 'Brand', 'name': 'Bloomberg markets', 'url': 'https://www.bloomberg.com/markets'}, {'@type': 'Brand', 'name': 'Bloomberg technology', 'url': 'https://www.bloomberg.com/technology'}, {'@type': 'Brand', 'name': 'Bloomberg pursuits', 'url': 'https://www.bloomberg.com/pursuits'}, {'@type': 'Brand', 'name': 'Bloomberg politics', 'url': 'https://www.bloomberg.com/politics'}, {'@type': 'Brand', 'name': 'Bloomberg opinion', 'url': 'https://www.bloomberg.com/opinion', 'logo': 'https://www.bloomberg.com/logo-bloomberg_opinion.svg'}, {'@type': 'Brand', 'name': 'Bloomberg businessweek', 'url': 'https://www.bloomberg.com/businessweek', 'logo': 'https://www.bloomberg.com/logo-bloomberg_businessweek.svg'}, {'@type': 'Brand', 'name': 'Bloomberg green', 'url': 'https://www.bloomberg.com/green'}, {'@type': 'Brand', 'name': 'Bloomberg equality', 'url': 'https://www.bloomberg.com/equality'}, {'@type': 'Brand', 'name': 'Bloomberg citylab', 'url': 'https://www.bloomberg.com/citylab'}, {'@type': 'Brand', 'name': 'Bloomberg crypto', 'url': 'https://www.bloomberg.com/crypto'}, {'@type': 'Brand', 'name': 'Bloomberg industries', 'url': 'https://www.bloomberg.com/industries'}, {'@type': 'Brand', 'name': 'Bloomberg economics', 'url': 'https://www.bloomberg.com/economics'}, {'@type': 'Brand', 'name': 'Bloomberg ai', 'url': 'https://www.bloomberg.com/ai'}, {'@type': 'Brand', 'name': 'Bloomberg wealth', 'url': 'https://www.bloomberg.com/wealth'}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3Lm5hci5yZWFsdG9yL21hZ2F6aW5lL3JlYWwtZXN0YXRlLW5ld3MvdGVjaG5vbG9neS91c2luZy1haS10by1idWlsZC1yZWxhdGlvbnNoaXBz0gEA?oc=5,Using AI to Build Relationships - National Association of REALTORS®,2018-05-15,National Association of REALTORS®,https://www.nar.realtor,"The term artificial intelligence can spark sci-fi images of a robot army taking over the world. But in reality, AI is simply building on...",N/A,"The term artificial intelligence can spark sci-fi images of a robot army taking over the world. But in reality, AI is simply building on...","The term artificial intelligence can spark sci-fi images of a robot army taking over the world. But in reality, AI is simply building on...",N/A,N/A,"
The term artificial intelligence can spark sci-fi images of a robot army taking over the world. But in reality, AI is simply building on existing technology to help you work more efficiently. 



 © kras99 - Fotolia.com




How many times have you helped a client buy or sell a property and then never spoken to them again? It’s a pretty common scenario. The truth is, humans tend to be lazy and are often easily distracted, according to Greg Cypes, chief technology officer at Contactually, a customer relationship management software company. You have business meetings, soccer games, and other family obligations, so staying in touch with past clients is often put on the back burner. “We don’t do a great job at prioritizing relationships, nor do we understand how to form relationships because we don’t always know what to say or how to say it,” Cypes said.
But artificial intelligence might be able to help this conundrum. During the Emerging Business Issues & Technology Forum at the REALTORS® Legislative Meetings & Trade Expo in Washington, D.C. on May 17, presenters discussed the value and benefits of budding AI technology and how it may help real estate pros develop more authentic relationships with clients, prospects, and colleagues.
“AI isn’t robots; we’re many years away from that,” Cypes said. And we’re not living in a science-fiction thriller where an imperial army of robot soldiers is on the verge of taking over the world. Instead, AI is about augmenting the technology we already use and helping people work more effectively. And it’s already happening. Think about all the times you visit a website and it’s personalized for you, or how Apple helps organize your personal photos based on facial recognition.
In the future, brokers could use AI to propagate their personality and business culture across multiple offices. Automated messages, such as those a broker might send congratulating an agent on a completed deal, could mimic their management style without the need to record a video greeting, for example. Agents could also use this type of technology to form stronger bonds with clients.
Aleksander Velkoski, a data scientist with NAR, showed a video of a Google Duplex(link is external) phone call that debuted during the Google I/O 2018 conference last week, which demonstrates how the AI assistant can make a hair salon appointment while sounding almost indistinguishable from a human. “One of the things that’s exciting about Duplex is that it’s capable of being thrown curve balls and addressing those curve balls,” Velkoski said. For instance, the assistant can call a restaurant to make reservations and handle a scenario where the restaurant doesn’t take reservations. The sophistication of technology depends on training related to real-life scenarios that programmers provide to the AI, he added.







3:58







When it comes to your real estate business, AI can already help in numerous ways. The technology is evolving in its ability to understand and process the nuances of language, including active or passive voice, pleasant or unpleasant tones, and its understanding of text in articles, tweets, and documents, Velkoski said. Through computer vision, AI is now able to identify and extract objects from images, such as pieces of furniture in a photo of a living room. This results in more advanced virtual staging software and platforms such as augmented reality apps that can visualize room concepts for marketing vacant properties. AI tools like Insightpool and Sprout can also help with social media monitoring and listening. And when it comes to the everyday operations of your business, AI can help with customer service and support, IT service monitoring, security and fraud prevention, and electronic commerce help.
Velkoski suggested that agents and broker-owners considering how AI can help their businesses begin by following the trends in emerging technology, and test products out whenever possible. He also advised they set realistic goals and start with small AI initiatives. Finally, business leaders should ensure their team members and agents have access to the education and information they need to use the technology.

",http://schema.org,,,,,,,,,BreadcrumbList,,,,,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'name': 'REALTOR® Magazine', '@id': 'https://www.nar.realtor/magazine'}}, {'@type': 'ListItem', 'position': 2, 'item': {'name': 'Real Estate News', '@id': 'https://www.nar.realtor/magazine/real-estate-news'}}, {'@type': 'ListItem', 'position': 3, 'item': {'name': 'Technology', '@id': 'https://www.nar.realtor/magazine/real-estate-news/technology'}}]",,,,,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3LnNjbXAuY29tL3RlY2gvaW5ub3ZhdGlvbi9hcnRpY2xlLzIxNDY0MjgvdGlhbmppbi1jaXR5LWNoaW5hLWV5ZXMtdXMxNi1iaWxsaW9uLWZ1bmQtYWktd29yay1kd2FyZmluZy1ldXMtcGxhbtIBeGh0dHBzOi8vYW1wLnNjbXAuY29tL3RlY2gvaW5ub3ZhdGlvbi9hcnRpY2xlLzIxNDY0MjgvdGlhbmppbi1jaXR5LWNoaW5hLWV5ZXMtdXMxNi1iaWxsaW9uLWZ1bmQtYWktd29yay1kd2FyZmluZy1ldXMtcGxhbg?oc=5,This Chinese city plans a US$16 billion fund for AI development - South China Morning Post,2018-05-16,South China Morning Post,https://www.scmp.com,"A major Chinese metropolis plans to set up a multibillion-dollar fund to spur development of the artificial intelligence (AI) industry, in what is the latest and probably largest effort by a single Chinese city amid the country’s push to fulfil its ambition to become a world leader in AI by 2030.","Tianjin, AI fund, EU Commission","A major Chinese metropolis plans to set up a multibillion-dollar fund to spur development of the artificial intelligence (AI) industry, in what is the latest and probably largest effort by a single Chinese city amid the country’s push to fulfil its ambition to become a world leader in AI by 2030.",N/A,Tech,N/A,"AdvertisementAdvertisementArtificial intelligence+ FOLLOWGet more with myNEWSA personalised news feed of stories that matter to youLearn more China has set a goal of becoming a key global AI innovation centre worth more than 1 trillion yuan by 2030, according to three-step development road map released by the State Council in 2017. Photo: SCMPTechInnovationTianjin city in China eyes US$16 billion fund for AI work, dwarfing EU’s plan to spend US$1.78 billionArtificial intelligence+ FOLLOWMeng Jing+ FOLLOWPublished: 6:35pm, 16 May 2018Why you can trust SCMPListen to this article A major Chinese metropolis plans to set up a multibillion-dollar fund to spur development of the artificial intelligence (AI) industry, in what is the latest and probably largest effort by a single Chinese city amid the country’s push to fulfil its ambition to become a world leader in AI by 2030.Tianjin, a northeastern port city outside Beijing, said it will establish a 100 billion yuan（(US$15.7 billion)）fund to speed up development of new generation AI technologies, according to a document posted on the city government’s official website on Wednesday.ListenPostAdvertisementAdvertisement",https://schema.org,,Innovation,"Tianjin city in China eyes US$16 billion fund for AI work, dwarfing EU’s plan to spend US$1.78 billion",en-GB,"{'@type': 'Person', 'name': 'Meng Jing', 'sameAs': 'https://www.scmp.com/author/meng-jing'}",2018-05-16T18:35:00+08:00,2018-05-16T23:13:33+08:00,"{'@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'height': {'@type': 'QuantitativeValue', 'value': 512}, 'url': 'https://assets-v2.i-scmp.com/production/icons/scmp-icon-512x512.png', 'width': {'@type': 'QuantitativeValue', 'value': 512}}, 'name': 'South China Morning Post'}",ImageObject,https://www.scmp.com/tech/innovation/article/2146428/tianjin-city-china-eyes-us16-billion-fund-ai-work-dwarfing-eus-plan,"https://img.i-scmp.com/cdn-cgi/image/fit=contain,width=60,format=auto/sites/default/files/styles/300x300/public/images/author/pic/2018/05/16/p6tob3xb_400x400.jpg?itok=zR9EEB-5","{'@type': 'ImageObject', 'height': {'@type': 'QuantitativeValue', 'value': 720}, 'url': 'https://cdn.i-scmp.com/sites/default/files/images/methode/2018/05/16/c859b77c-58ee-11e8-a7d9-186ba932a081_1280x720_183458.JPG', 'width': {'@type': 'QuantitativeValue', 'value': 1280}}",South China Morning Post,False,2018-05-16T18:35:00+08:00,"{'@type': ['CreativeWork', 'Product'], 'name': 'SCMP Digital', 'productID': 'www.scmp.com:digital'}",,"{'@type': 'WebPageElement', 'cssSelector': '.paywalled-content', 'isAccessibleForFree': 'False'}","19/F Tower One, Times Square, 1 Matheson Street, Causeway Bay, Hong Kong",,,,,+852-2680-8888,https://assets-v2.i-scmp.com/production/icons/scmp-icon-512x512.png,,"[{'@type': 'ListItem', 'item': {'@id': 'https://www.scmp.com/tech', 'name': 'Tech'}, 'position': 1}, {'@type': 'ListItem', 'item': {'@id': 'https://www.scmp.com/tech/innovation', 'name': 'Innovation'}, 'position': 2}]",https://www.scmp.com/tech/innovation/article/2146428/tianjin-city-china-eyes-us16-billion-fund-ai-work-dwarfing-eus-plan,"{'@type': 'ContactPoint', 'contactType': 'customer support', 'telephone': '+852-2680-8888'}","['https://www.facebook.com/southchinamorningpost/', 'https://twitter.com/SCMPNews', 'https://www.youtube.com/southchinamorningpost', 'https://www.linkedin.com/company/south-china-morning-post', 'https://www.instagram.com/scmpnews', 'https://plus.google.com/b/109548181662196012156/+SouthChinaMorningPostSCMP']",This Chinese city plans a US$16 billion fund for AI development,"A major Chinese metropolis plans to set up a multibillion-dollar fund to spur development of the artificial intelligence (AI) industry, in what is the latest and probably largest effort by a single Chinese city amid the country’s push to fulfil its ambition to become a world leader in AI by 2030.
Tianjin, a northeastern port city outside Beijing, said it will establish a 100 billion yuan（(US$15.7 billion)）fund to speed up development of new generation AI technologies, according to a document posted on the city government’s official website on Wednesday.
The money will be raised from financial organisations in China and abroad as well as from private enterprises and other market players, it said. The AI industrial fund is part of Tianjin government’s grand plan to “speed up the development of the smart technology industry”, which includes a 10 billion yuan smart manufacturing fund financed by the municipal government and a string of talent incentives – up to 2 million yuan cash reward per person – to attract high-end tech talent.
China’s AI dream is well on its way to becoming a reality
The planned fund comes as competition heats up between China and the United States in dominance of AI technologies, which are vital to enable an array of emerging applications from talking robots to self-driving cars. Tianjin’s fund amount also dwarfs funding announced last month by the European Union Commission, which said it would boost investment in AI by 70 per cent to €1.5 billion (US$1.78 billion) between 2018 and 2020. The investment is expected to boost total private and public European investment in AI to at least €20 billion by 2020.
China’s goal is to develop itself into a key global AI innovation centre and build an AI industry valued at more than 1 trillion yuan by 2030, according to three-step development road map released by the State Council in 2017. The Trump administration vowed last week to maintain the US’s leading position in AI technology through greater funding and other initiatives.
Local governments in China have been investing money and devising policies to spur AI development ever since the central government made AI a national priority.
In January China’s capital Beijing announced a plan to build a 13.8 billion yuan AI development park, aiming to house up to 400 enterprises with an estimated annual output of 50 billion yuan.
At the end of last year Shanghai announced a plan to build a globally competitive AI industry with an output of 100 billion yuan by 2020.
",Tech,"{'@type': 'Place', 'name': 'Hong Kong'}",https://www.scmp.com/policies-and-standards

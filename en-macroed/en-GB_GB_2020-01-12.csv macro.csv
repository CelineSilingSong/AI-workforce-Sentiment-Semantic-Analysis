URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,mainEntity,@context,@type,article:section,article:summary,article text,mainEntityOfPage,name,datePublished,dateModified,text,publisher,image,author,about,headLine,articleBody,itemListElement,url,dateCreated,heading,@graph,isBasedOn,articleSection,headline,thumbnailUrl,isPartOf,isAccessibleForFree,alternativeHeadline,potentialAction,genre,identifier,creator,hasPart,inLanguage,copyrightHolder,timeRequired,wordCount,video,@id,logo,sameAs,entry-title,published,updated
https://news.google.com/rss/articles/CBMiMmh0dHBzOi8vd3d3Lm5hdHVyZS5jb20vYXJ0aWNsZXMvczQxNDY3LTAxOS0xNDEwOC150gEA?oc=5,The role of artificial intelligence in achieving the Sustainable Development Goals - Nature.com,2020-01-13,Nature.com,https://www.nature.com,"The emergence of artificial intelligence (AI) and its progressively wider impact on many sectors requires an assessment of its effect on the achievement of the Sustainable Development Goals. Using a consensus-based expert elicitation process, we find that AI can enable the accomplishment of 134 targets across all the goals, but it may also inhibit 59 targets. However, current research foci overlook important aspects. The fast development of AI needs to be supported by the necessary regulatory insight and oversight for AI-based technologies to enable sustainable development. Failure to do so could result in gaps in transparency, safety, and ethical standards. Artificial intelligence (AI) is becoming more and more common in people’s lives. Here, the authors use an expert elicitation method to understand how AI may affect the achievement of the Sustainable Development Goals.",N/A,"Artificial intelligence (AI) is becoming more and more common in people’s lives. Here, the authors use an expert elicitation method to understand how AI may affect the achievement of the Sustainable Development Goals.","Nature Communications - Artificial intelligence (AI) is becoming more and more common in people’s lives. Here, the authors use an expert elicitation method to understand how AI may affect the...","{'headline': 'The role of artificial intelligence in achieving the Sustainable Development Goals', 'description': 'The emergence of artificial intelligence (AI) and its progressively wider impact on many sectors requires an assessment of its effect on the achievement of the Sustainable Development Goals. Using a consensus-based expert elicitation process, we find that AI can enable the accomplishment of 134 targets across all the goals, but it may also inhibit 59 targets. However, current research foci overlook important aspects. The fast development of AI needs to be supported by the necessary regulatory insight and oversight for AI-based technologies to enable sustainable development. Failure to do so could result in gaps in transparency, safety, and ethical standards. Artificial intelligence (AI) is becoming more and more common in people’s lives. Here, the authors use an expert elicitation method to understand how AI may affect the achievement of the Sustainable Development Goals.', 'datePublished': '2020-01-13T00:00:00Z', 'dateModified': '2020-01-13T00:00:00Z', 'pageStart': '1', 'pageEnd': '10', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'sameAs': 'https://doi.org/10.1038/s41467-019-14108-y', 'keywords': ['Computational science', 'Developing world', 'Energy efficiency', 'Science', 'Humanities and Social Sciences', 'multidisciplinary'], 'image': ['https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-14108-y/MediaObjects/41467_2019_14108_Fig1_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-14108-y/MediaObjects/41467_2019_14108_Fig2_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-14108-y/MediaObjects/41467_2019_14108_Fig3_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-14108-y/MediaObjects/41467_2019_14108_Fig4_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-14108-y/MediaObjects/41467_2019_14108_Fig5_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-14108-y/MediaObjects/41467_2019_14108_Fig6_HTML.png'], 'isPartOf': {'name': 'Nature Communications', 'issn': ['2041-1723'], 'volumeNumber': '11', '@type': ['Periodical', 'PublicationVolume']}, 'publisher': {'name': 'Nature Publishing Group UK', 'logo': {'url': 'https://www.springernature.com/app-sn/public/images/logo-springernature.png', '@type': 'ImageObject'}, '@type': 'Organization'}, 'author': [{'name': 'Ricardo Vinuesa', 'url': 'http://orcid.org/0000-0001-6570-5499', 'affiliation': [{'name': 'Linné FLOW Centre, KTH Mechanics', 'address': {'name': 'Linné FLOW Centre, KTH Mechanics, Stockholm, Sweden', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'rvinuesa@mech.kth.se', '@type': 'Person'}, {'name': 'Hossein Azizpour', 'url': 'http://orcid.org/0000-0001-5211-6388', 'affiliation': [{'name': 'KTH Royal Institute Of Technology', 'address': {'name': 'Division of Robotics, Perception, and Learning, School of EECS, KTH Royal Institute Of Technology, Stockholm, Sweden', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Iolanda Leite', 'affiliation': [{'name': 'KTH Royal Institute Of Technology', 'address': {'name': 'Division of Robotics, Perception, and Learning, School of EECS, KTH Royal Institute Of Technology, Stockholm, Sweden', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Madeline Balaam', 'affiliation': [{'name': 'KTH Royal Institute of Technology', 'address': {'name': 'Division of Media Technology and Interaction Design, KTH Royal Institute of Technology, Stockholm, Sweden', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Virginia Dignum', 'affiliation': [{'name': 'Umeå University', 'address': {'name': 'Responsible AI Group, Department of Computing Sciences, Umeå University, Umeå, Sweden', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Sami Domisch', 'url': 'http://orcid.org/0000-0002-8127-9335', 'affiliation': [{'name': 'Leibniz-Institute of Freshwater Ecology and Inland Fisheries', 'address': {'name': 'Leibniz-Institute of Freshwater Ecology and Inland Fisheries, Berlin, Germany', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Anna Felländer', 'affiliation': [{'name': 'AI Sustainability Center', 'address': {'name': 'AI Sustainability Center, Stockholm, Sweden', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Simone Daniela Langhans', 'affiliation': [{'name': 'Basque Centre for Climate Change (BC3)', 'address': {'name': 'Basque Centre for Climate Change (BC3), Leioa, Spain', '@type': 'PostalAddress'}, '@type': 'Organization'}, {'name': 'University of Otago', 'address': {'name': 'Department of Zoology, University of Otago, Dunedin, New Zealand', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Max Tegmark', 'affiliation': [{'name': 'Massachusetts Institute of Technology', 'address': {'name': 'Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, USA', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Francesco Fuso Nerini', 'url': 'http://orcid.org/0000-0002-4770-4051', 'affiliation': [{'name': 'KTH Royal Institute of Technology', 'address': {'name': 'Unit of Energy Systems Analysis (dESA), KTH Royal Institute of Technology, Stockholm, Sweden', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'francesco.fusonerini@energy.kth.se', '@type': 'Person'}], 'isAccessibleForFree': True, '@type': 'ScholarlyArticle'}",https://schema.org,WebPage,N/A,N/A,"




Download PDF








Perspective

Open access

Published: 13 January 2020

The role of artificial intelligence in achieving the Sustainable Development Goals
Ricardo Vinuesa 
            ORCID: orcid.org/0000-0001-6570-54991, Hossein Azizpour 
            ORCID: orcid.org/0000-0001-5211-63882, Iolanda Leite2, Madeline Balaam3, Virginia Dignum4, Sami Domisch 
            ORCID: orcid.org/0000-0002-8127-93355, Anna Felländer6, Simone Daniela Langhans7,8, Max Tegmark9 & …Francesco Fuso Nerini 
            ORCID: orcid.org/0000-0002-4770-405110 Show authors

Nature Communications
volume 11, Article number: 233 (2020)
            Cite this article




418k Accesses


1000 Citations


928 Altmetric


Metrics details






AbstractThe emergence of artificial intelligence (AI) and its progressively wider impact on many sectors requires an assessment of its effect on the achievement of the Sustainable Development Goals. Using a consensus-based expert elicitation process, we find that AI can enable the accomplishment of 134 targets across all the goals, but it may also inhibit 59 targets. However, current research foci overlook important aspects. The fast development of AI needs to be supported by the necessary regulatory insight and oversight for AI-based technologies to enable sustainable development. Failure to do so could result in gaps in transparency, safety, and ethical standards.



Similar content being viewed by others






A definition, benchmark and database of AI for social good initiatives
                                        


Article
17 February 2021









AI for social good: unlocking the opportunity for positive impact
                                        


Article
Open access
18 May 2020









Building an AI ecosystem in a small nation: lessons from Singapore’s journey to the forefront of AI
                                        


Article
Open access
02 July 2024








IntroductionThe emergence of artificial intelligence (AI) is shaping an increasing range of sectors. For instance, AI is expected to affect global productivity1, equality and inclusion2, environmental outcomes3, and several other areas, both in the short and long term4. Reported potential impacts of AI indicate both positive5 and negative6 impacts on sustainable development. However, to date, there is no published study systematically assessing the extent to which AI might impact all aspects of sustainable development—defined in this study as the 17 Sustainable Development Goals (SDGs) and 169 targets internationally agreed in the 2030 Agenda for Sustainable Development7. This is a critical research gap, as we find that AI may influence the ability to meet all SDGs.Here we present and discuss implications of how AI can either enable or inhibit the delivery of all 17 goals and 169 targets recognized in the 2030 Agenda for Sustainable Development. Relationships were characterized by the methods reported at the end of this study, which can be summarized as a consensus-based expert elicitation process, informed by previous studies aimed at mapping SDGs interlinkages8,9,10. A summary of the results is given in Fig. 1 and the Supplementary Data 1 provides a complete list of all the SDGs and targets, together with the detailed results from this work. Although there is no internationally agreed definition of AI, for this study we considered as AI any software technology with at least one of the following capabilities: perception—including audio, visual, textual, and tactile (e.g., face recognition), decision-making (e.g., medical diagnosis systems), prediction (e.g., weather forecast), automatic knowledge extraction and pattern recognition from data (e.g., discovery of fake news circles in social media), interactive communication (e.g., social robots or chat bots), and logical reasoning (e.g., theory development from premises). This view encompasses a large variety of subfields, including machine learning.Fig. 1: Summary of positive and negative impact of AI on the various SDGs.Documented evidence of the potential of AI acting as (a) an enabler or (b) an inhibitor on each of the SDGs. The numbers inside the colored squares represent each of the SDGs (see the Supplementary Data 1). The percentages on the top indicate the proportion of all targets potentially affected by AI and the ones in the inner circle of the figure correspond to proportions within each SDG. The results corresponding to the three main groups, namely Society, Economy, and Environment, are also shown in the outer circle of the figure. The results obtained when the type of evidence is taken into account are shown by the inner shaded area and the values in brackets.Full size imageDocumented connections between AI and the SDGsOur review of relevant evidence shows that AI may act as an enabler on 134 targets (79%) across all SDGs, generally through a technological improvement, which may allow to overcome certain present limitations. However, 59 targets (35%, also across all SDGs) may experience a negative impact from the development of AI. For the purpose of this study, we divide the SDGs into three categories, according to the three pillars of sustainable development, namely Society, Economy, and Environment11,12 (see the Methods section). This classification allows us to provide an overview of the general areas of influence of AI. In Fig. 1, we also provide the results obtained when weighting how appropriate is the evidence presented in each reference to assess an interlinkage to the percentage of targets assessed, as discussed in the Methods section and below. A detailed assessment of the Society, Economy, and Environment groups, together with illustrative examples, are discussed next.AI and societal outcomesSixty-seven targets (82%) within the Society group could potentially benefit from AI-based technologies (Fig. 2). For instance, in SDG 1 on no poverty, SDG 4 on quality education, SDG 6 on clean water and sanitation, SDG 7 on affordable and clean energy, and SDG 11 on sustainable cities, AI may act as an enabler for all the targets by supporting the provision of food, health, water, and energy services to the population. It can also underpin low-carbon systems, for instance, by supporting the creation of circular economies and smart cities that efficiently use their resources13,14. For example, AI can enable smart and low-carbon cities encompassing a range of interconnected technologies such as electrical autonomous vehicles and smart appliances that can enable demand response in the electricity sector13,14 (with benefits across SDGs 7, 11, and 13 on climate action). AI can also help to integrate variable renewables by enabling smart grids that partially match electrical demand to times when the sun is shining and the wind is blowing13. Fewer targets in the Society group can be impacted negatively by AI (31 targets, 38%) than the ones with positive impact. However, their consideration is crucial. Many of these relate to how the technological improvements enabled by AI may be implemented in countries with different cultural values and wealth. Advanced AI technology, research, and product design may require massive computational resources only available through large computing centers. These facilities have a very high energy requirement and carbon footprint15. For instance, cryptocurrency applications such as Bitcoin are globally using as much electricity as some nations’ electrical demand16, compromising outcomes in the SDG 7 sphere, but also on SDG 13 on Climate Action. Some estimates suggest that the total electricity demand of information and communications technologies (ICTs) could require up to 20% of the global electricity demand by 2030, from around 1% today15. Green growth of ICT technology is therefore essential17. More efficient cooling systems for data centers, broader energy efficiency, and renewable-energy usage in ICTs will all play a role in containing the electricity demand growth15. In addition to more efficient and renewable-energy-based data centers, it is essential to embed human knowledge in the development of AI models. Besides the fact that the human brain consumes much less energy than what is used to train AI models, the available knowledge introduced in the model (see, for instance, physics-informed deep learning18) does not need to be learnt through data-intensive training, a fact that may significantly reduce the associated energy consumption. Although AI-enabled technology can act as a catalyst to achieve the 2030 Agenda, it may also trigger inequalities that may act as inhibitors on SDGs 1, 4, and 5. This duality is reflected in target 1.1, as AI can help to identify areas of poverty and foster international action using satellite images5. On the other hand, it may also lead to additional qualification requirements for any job, consequently increasing the inherent inequalities19 and acting as an inhibitor towards the achievement of this target.Fig. 2: Detailed assessment of the impact of AI on the SDGs within the Society group.Documented evidence of positive or negative impact of AI on the achievement of each of the targets from SDGs 1, 2, 3, 4, 5, 6, 7, 11, and 16 (https://www.un.org/sustainabledevelopment/). Each block in the diagram represents a target (see the Supplementary Data 1 for additional details on the targets). For targets highlighted in green or orange, we found published evidence that AI could potentially enable or inhibit such target, respectively. The absence of highlighting indicates the absence of identified evidence. It is noteworthy that this does not necessarily imply the absence of a relationship. (The content of of this figure has not been reviewed by the United Nations and does not reflect its views).Full size imageAnother important drawback of AI-based developments is that they are traditionally based on the needs and values of nations in which AI is being developed. If AI technology and big data are used in regions where ethical scrutiny, transparency, and democratic control are lacking, AI might enable nationalism, hate towards minorities, and bias election outcomes20. The term “big nudging” has emerged to represent using big data and AI to exploit psychological weaknesses to steer decisions—creating problems such as damaging social cohesion, democratic principles, and even human rights21. AI has been recently utilized to develop citizen scores, which are used to control social behavior22. This type of score is a clear example of threat to human rights due to AI misuse and one of its biggest problems is the lack of information received by the citizens on the type of analyzed data and the consequences this may have on their lives. It is also important to note that AI technology is unevenly distributed: for instance, complex AI-enhanced agricultural equipment may not be accessible to small farmers and thus produce an increased gap with respect to larger producers in more developed economies23, consequently inhibiting the achievement of some targets of SDG 2 on zero hunger. There is another important shortcoming of AI in the context of SDG 5 on gender equality: there is insufficient research assessing the potential impact of technologies such as smart algorithms, image recognition, or reinforced learning on discrimination against women and minorities. For instance, machine-learning algorithms uncritically trained on regular news articles will inadvertently learn and reproduce the societal biases against women and girls, which are embedded in current languages. Word embeddings, a popular technique in natural language processing, have been found to exacerbate existing gender stereotypes2. In addition to the lack of diversity in datasets, another main issue is the lack of gender, racial, and ethnic diversity in the AI workforce24. Diversity is one of the main principles supporting innovation and societal resilience, which will become essential in a society exposed to changes associated to AI development25. Societal resilience is also promoted by decentralization, i.e., by the implementation of AI technologies adapted to the cultural background and the particular needs of different regions.AI and economic outcomesThe technological advantages provided by AI may also have a positive impact on the achievement of a number of SDGs within the Economy group. We have identified benefits from AI on 42 targets (70%) from these SDGs, whereas negative impacts are reported in 20 targets (33%), as shown in Fig. 1. Although Acemoglu and Restrepo1 report a net positive impact of AI-enabled technologies associated to increased productivity, the literature also reflects potential negative impacts mainly related to increased inequalities26,27,28,29. In the context of the Economy group of SDGs, if future markets rely heavily on data analysis and these resources are not equally available in low- and middle- income countries, the economical gap may be significantly increased due to the newly introduced inequalities30,31 significantly impacting SDGs 8 (decent work and economic growth), 9 (industry, innovation and infrastructure), and 10 (reduced inequalities). Brynjolfsson and McAfee31 argue that AI can exacerbate inequality also within nations. By replacing old jobs with ones requiring more skills, technology disproportionately rewards the educated: since the mid 1970s, the salaries in the United States (US) salaries rose about 25% for those with graduate degrees, while the average high-school dropout took a 30% pay cut. Moreover, automation shifts corporate income to those who own companies from those who work there. Such transfer of revenue from workers to investors helps explain why, even though the combined revenues of Detroit's “Big 3” (GM, Ford, and Chrysler) in 1990 were almost identical to those of Silicon Valley's “Big 3” (Google, Apple, and Facebook) in 2014, the latter had 9 times fewer employees and were worth 30 times more on the stock market32. Figure 3 shows an assessment of the documented positive and negative effects on the various targets within the SDGs in the Economy group.Fig. 3: Detailed assessment of the impact of AI on the SDGs within the Economy group.Documented evidence of positive or negative impact of AI on the achievement of each of the targets from SDGs 8, 9, 10, 12, and 17 (https://www.un.org/sustainabledevelopment/). The interpretation of the blocks and colors is as in Fig. 2.  (The content of of this figure has not been reviewed by the United Nations and does not reflect its views).Full size imageAlthough the identified linkages in the Economy group are mainly positive, trade-offs cannot be neglected. For instance, AI can have a negative effect on social media usage, by showing users content specifically suited to their preconceived ideas. This may lead to political polarization33 and affect social cohesion21 with consequences in the context of SDG 10 on reduced inequalities. On the other hand, AI can help identify sources of inequality and conflict34,35, and therewith potentially reduce inequalities, for instance, by using simulations to assess how virtual societies may respond to changes. However, there is an underlying risk when using AI to evaluate and predict human behavior, which is the inherent bias in the data. It has been reported that a number of discriminatory challenges are faced in the automated targeting of online job advertising using AI35, essentially related to the previous biases in selection processes conducted by human recruiters. The work by Dalenberg35 highlights the need of modifying the data preparation process and explicitly adapting the AI-based algorithms used for selection processes to avoid such biases.AI and environmental outcomesThe last group of SDGs, i.e., the one related to Environment, is analyzed in Fig. 4. The three SDGs in this group are related to climate action, life below water and life on land (SDGs 13, 14, and 15). For the Environment group, we identified 25 targets (93%) for which AI could act as an enabler. Benefits from AI could be derived by the possibility of analyzing large-scale interconnected databases to develop joint actions aimed at preserving the environment. Looking at SDG 13 on climate action, there is evidence that AI advances will support the understanding of climate change and the modeling of its possible impacts. Furthermore, AI will support low-carbon energy systems with high integration of renewable energy and energy efficiency, which are all needed to address climate change13,36,37. AI can also be used to help improve the health of ecosystems. The achievement of target 14.1, calling to prevent and significantly reduce marine pollution of all kinds, can benefit from AI through algorithms for automatic identification of possible oil spills38. Another example is target 15.3, which calls for combating desertification and restoring degraded land and soil. According to Mohamadi et al.39, neural networks and objective-oriented techniques can be used to improve the classification of vegetation cover types based on satellite images, with the possibility of processing large amounts of images in a relatively short time. These AI techniques can help to identify desertification trends over large areas, information that is relevant for environmental planning, decision-making, and management to avoid further desertification, or help reverse trends by identifying the major drivers. However, as pointed out above, efforts to achieve SDG 13 on climate action could be undermined by the high-energy needs for AI applications, especially if non carbon-neutral energy sources are used. Furthermore, despite the many examples of how AI is increasingly applied to improve biodiversity monitoring and conservation40, it can be conjectured that an increased access to AI-related information of ecosystems may drive over-exploitation of resources, although such misuse has so far not been sufficiently documented. This aspect is further discussed below, where currently identified gaps in AI research are considered.Fig. 4: Detailed assessment of the impact of AI on the SDGs within the Environment group.Documented evidence of positive or negative impact of AI on the achievement of each of the targets from SDGs 13, 14, and 15 (https://www.un.org/sustainabledevelopment/). The interpretation of the blocks and colors is as in Fig. 2. (The content of of this figure has not been reviewed by the United Nations and does not reflect its views).Full size imageAn assessment of the collected evidence on the interlinkagesA deeper analysis of the gathered evidence was undertaken as shown in Fig. 1 (and explained in the Methods section). In practice, each interlinkage was weighted based on the applicability and appropriateness of each of the references to assess a specific interlinkage—and possibly identify research gaps. Although accounting for the type of evidence has a relatively small effect on the positive impacts (we see a reduction of positively affected targets from 79% to 71%), we observe a more significant reduction (from 35% to 23%) in the targets with negative impact of AI. This can be partly due the fact that AI research typically involves quantitative methods that would bias the results towards the positive effects. However, there are some differences across the Society, Economy and Environment spheres. In the Society sphere, when weighting the appropriateness of evidence, positively affected targets diminish by 5 percentage points (p.p.) and negatively affected targets by 13 p.p. In particular, weighting the appropriateness of evidence on negative impacts on SDG 1 (on no poverty) and SDG 6 (on clean water and sanitation) reduces the fraction of affected targets by 43 p.p. and 35 p.p., respectively. In the Economy group instead, positive impacts are reduced more (15 p.p.) than negative ones (10 p.p.) when taking into account the appropriateness of the found evidence to speak of the issues. This can be related to the extensive study in literature assessing the displacement of jobs due to AI (because of clear policy and societal concerns), but overall the longer-term benefits of AI on the economy are perhaps not so extensively characterized by currently available methods. Finally, although the weighting of evidence decreases the positive impacts of AI on the Environment group only by 8 p.p., the negative impacts see the largest average reduction (18 p.p.). This is explained by the fact that, although there are some indications of the potential negative impact of AI on this SDG, there is no strong evidence (in any of the targets) supporting this claim, and therefore this is a relevant area for future research.In general, the fact that the evidence on interlinkages between AI and the large majority of targets is not based on tailored analyses and tools to refer to that particular issue provides a strong rationale to address a number of research gaps, which are identified and listed in the section below.Research gaps on the role of AI in sustainable developmentThe more we enable SDGs by deploying AI applications, from autonomous vehicles41 to AI-powered healthcare solutions42 and smart electrical grids13, the more important it becomes to invest in the AI safety research needed to keep these systems robust and beneficial, so as to prevent them from malfunctioning, or from getting hacked43. A crucial research venue for a safe integration of AI is understanding catastrophes, which can be enabled by a systemic fault in AI technology. For instance, a recent World Economic Forum (WEF) report raises such a concern due to the integration of AI in the financial sector44. It is therefore very important to raise awareness on the risks associated to possible failures of AI systems in a society progressively more dependent on this technology. Furthermore, although we were able to find numerous studies suggesting that AI can potentially serve as an enabler for many SDG targets and indicators, a significant fraction of these studies have been conducted in controlled laboratory environments, based on limited datasets or using prototypes45,46,47. Hence, extrapolating this information to evaluate the real-world effects often remains a challenge. This is particularly true when measuring the impact of AI across broader scales, both temporally and spatially. We acknowledge that conducting controlled experimental trials for evaluating real-world impacts of AI can result in depicting a snapshot situation, where AI tools are tailored towards that specific environment. However, as society is constantly changing (also due to factors including non-AI-based technological advances), the requirements set for AI are changing as well, resulting in a feedback loop with interactions between society and AI. Another underemphasized aspect in existing literature is the resilience of the society towards AI-enabled changes. Therefore, novel methodologies are required to ensure that the impact of new technologies are assessed from the points of view of efficiency, ethics, and sustainability, prior to launching large-scale AI deployments. In this sense, research aimed at obtaining insight on the reasons for failure of AI systems, introducing combined human–machine analysis tools48, are an essential step towards accountable AI technology, given the large risk associated to such a failure.Although we found more published evidence of AI serving as an enabler than as an inhibitor on the SDGs, there are at least two important aspects that should be considered. First, self-interest can be expected to bias the AI research community and industry towards publishing positive results. Second, discovering detrimental aspects of AI may require longer-term studies and, as mentioned above, there are not many established evaluation methodologies available to do so. Bias towards publishing positive results is particularly apparent in the SDGs corresponding to the Environment group. A good example of this bias is target 14.5 on conserving coastal and marine areas, where machine-learning algorithms can provide optimum solutions given a wide range of parameters regarding the best choice of areas to include in conservation networks49. However, even if the solutions are optimal from a mathematical point of view (given a certain range of selected parameters), additional research would be needed to assess the long-term impact of such algorithms on equity and fairness6, precisely because of the unknown factors that may come into play. Regarding the second point stated above, it is likely that the AI projects with the highest potential of maximizing profit will get funded. Without control, research on AI is expected to be directed towards AI applications where funding and commercial interests are. This may result in increased inequality50. Consequently, there is the risk that AI-based technologies with potential to achieve certain SDGs may not be prioritized, if their expected economic impact is not high. Furthermore, it is essential to promote the development of initiatives to assess the societal, ethical, legal, and environmental implications of new AI technologies.Substantive research and application of AI technologies to SDGs is concerned with the development of better data-mining and machine-learning techniques for the prediction of certain events. This is the case of applications such as forecasting extreme weather conditions or predicting recidivist offender behavior. The expectation with this research is to allow the preparation and response for a wide range of events. However, there is a research gap in real-world applications of such systems, e.g., by governments (as discussed above). Institutions have a number of barriers to the adoption AI systems as part of their decision-making process, including the need of setting up measures for cybersecurity and the need to protect the privacy of citizens and their data. Both aspects have implications on human rights regarding the issues of surveillance, tracking, communication, and data storage, as well as automation of processes without rigorous ethical standards21. Targeting these gaps would be essential to ensure the usability and practicality of AI technologies for governments. This would also be a prerequisite for understanding long-term impacts of AI regarding its potential, while regulating its use to reduce the possible bias that can be inherent to AI6.Furthermore, our research suggests that AI applications are currently biased towards SDG issues that are mainly relevant to those nations where most AI researchers live and work. For instance, many systems applying AI technologies to agriculture, e.g., to automate harvesting or optimize its timing, are located within wealthy nations. Our literature search resulted in only a handful of examples where AI technologies are applied to SDG-related issues in nations without strong AI research. Moreover, if AI technologies are designed and developed for technologically advanced environments, they have the potential to exacerbate problems in less wealthy nations (e.g., when it comes to food production). This finding leads to a substantial concern that developments in AI technologies could increase inequalities both between and within countries, in ways which counteract the overall purpose of the SDGs. We encourage researchers and funders to focus more on designing and developing AI solutions, which respond to localized problems in less wealthy nations and regions. Projects undertaking such work should ensure that solutions are not simply transferred from technology-intensive nations. Instead, they should be developed based on a deep understanding of the respective region or culture to increase the likelihood of adoption and success.Towards sustainable AIThe great wealth that AI-powered technology has the potential to create may go mainly to those already well-off and educated, while job displacement leaves others worse off. Globally, the growing economic importance of AI may result in increased inequalities due to the unevenly distributed educational and computing resources throughout the world. Furthermore, the existing biases in the data used to train AI algorithms may result in the exacerbation of those biases, eventually leading to increased discrimination. Another related problem is the usage of AI to produce computational (commercial, political) propaganda based on big data (also defined as “big nudging”), which is spread through social media by independent AI agents with the goals of manipulating public opinion and producing political polarization51. Despite the fact that current scientific evidence refutes technological determinism of such fake news51, long-term impacts of AI are possible (although unstudied) due to a lack of robust research methods. A change of paradigm is therefore needed to promote cooperation and to limit the possibilities for control of citizen behavior through AI. The concept of Finance 4.0 has been proposed52 as a multi-currency financial system promoting a circular economy, which is aligned with societal goals and values. Informational self-determination (in which the individual takes an active role in how their data are handled by AI systems) would be an essential aspect of such a paradigm52. The data intensiveness of AI applications creates another problem: the need for more and more detailed information to improve AI algorithms, which is in conflict with the need of more transparent handling and protection of personal data53. One area where this conflict is particularly important is healthcare: Panch et al.54 argue that although the vast amount of personal healthcare data could lead to the development of very powerful tools for diagnosis and treatment, the numerous problems associated to data ownership and privacy call for careful policy intervention. This is also an area where more research is needed to assess the possible long-term negative consequences. All the challenges mentioned above culminate in the academic discourse about legal personality of robots55, which may lead to alarming narratives of technological totalitarianism.Many of these aspects result from the interplay between technological developments on one side and requests from individuals, response from governments, as well as environmental resources and dynamics on the other. Figure 5 shows a schematic representation of these dynamics, with emphasis on the role of technology. Based on the evidence discussed above, these interactions are not currently balanced and the advent of AI has exacerbated the process. A wide range of new technologies are being developed very fast, significantly affecting the way individuals live as well as the impacts on the environment, requiring new piloting procedures from governments. The problem is that neither individuals nor governments seem to be able to follow the pace of these technological developments. This fact is illustrated by the lack of appropriate legislation to ensure the long-term viability of these new technologies. We argue that it is essential to reverse this trend. A first step in this direction is to establish adequate policy and legislation frameworks, to help direct the vast potential of AI towards the highest benefit for individuals and the environment, as well as towards the achievement of the SDGs. Regulatory oversight should be preceded by regulatory insight, where policymakers have sufficient understanding of AI challenges to be able to formulate sound policy. Developing such insight is even more urgent than oversight, as policy formulated without understanding is likely to be ineffective at best and counterproductive at worst.Fig. 5: Interaction of AI and society.Schematic representation showing the identified agents and their roles towards the development of AI. Thicker arrows indicate faster change. In this representation, technology affects individuals through technical developments, which change the way people work and interact with each other and with the environment, whereas individuals would interact with technology through new needs to be satisfied. Technology (including technology itself and its developers) affects governments through new developments that need appropriate piloting and testing. Also, technology developers affect government through lobbying and influencing decision makers. Governments provide legislation and standards to technology. The governments affect individuals through policy and legislation, and individuals would require new legislation consistent with the changing circumstances from the governments. The environment interacts with technology by providing the resources needed for technological development and is affected by the environmental impact of technology. Furthermore, the environment is affected either negatively or positively by the needs, impacts, and choices of individuals and governments, which in turn require environmental resources. Finally, the environment is also an underlying layer that provides the “planetary boundaries” to the mentioned interactions.Full size imageAlthough strong and connected institutions (covered by SDG 16) are needed to regulate the future of AI, we find that there is limited understanding of the potential impact of AI on institutions. Examples of the positive impacts include AI algorithms aimed at improving fraud detection56,57 or assessing the possible effects of certain legislation58,59. Another concern is that data-driven approaches for policing may hinder equal access to justice because of algorithm bias, particularly towards minorities60. Consequently, we believe that it is imperative to develop legislation regarding transparency and accountability of AI, as well as to decide the ethical standards to which AI-based technology should be subjected to. This debate is being pushed forward by initiatives such as the IEEE (Institute of Electrical and Electronics Engineers) ethical aligned design60 and the new EU (European Union) ethical guidelines for trustworthy AI61. It is noteworthy that despite the importance of an ethical, responsible, and trustworthy approach to AI development and use, in a sense, this issue is independent of the aims of the article. In other words, one can envision AI applications that improve SDG outcomes while not being fully aligned with AI ethics guidelines. We therefore recommend that AI applications that target SDGs are open and explicit about guiding ethical principles, also by indicating explicitly how they align with the existing guidelines. On the other hand, the lack of interpretability of AI, which is currently one of the challenges of AI research, adds an additional complication to the enforcement of such regulatory actions62. Note that this implies that AI algorithms (which are trained with data consisting of previous regulations and decisions) may act as a “mirror” reflecting biases and unfair policy. This presents an opportunity to possibly identify and correct certain errors in the existing procedures. The friction between the uptake of data-driven AI applications and the need of protecting the privacy and security of the individuals is stark. When not properly regulated, the vast amount of data produced by citizens might potentially be used to influence consumer opinion towards a certain product or political cause51.AI applications that have positive societal welfare implications may not always benefit each individual separately41. This inherent dilemma of collective vs. individual benefit is relevant in the scope of AI applications but is not one that should be solved by the application of AI itself. This has always been an issue affecting humankind and it cannot be solved in a simple way, since such a solution requires participation of all involved stakeholders. The dynamicity of context and the level of abstraction at which human values are described imply that there is not a single ethical theory that holds all the time in all situations63. Consequently, a single set of utilitarian ethical principles with AI would not be recommendable due to the high complexity of our societies52. It is also essential to be aware of the potential complexity in the interaction between human and AI agents, and of the increasing need for ethics-driven legislation and certification mechanisms for AI systems. This is true for all AI applications, but especially those that, if they became uncontrolled, could have even catastrophic effects on humanity, such as autonomous weapons. Regarding the latter, associations of AI and robotics experts are already getting together to call for legislation and limitations of their use64. Furthermore, associations such as the Future of Life Institute are reviewing and collecting policy actions and shared principles around the world to monitor progress towards sustainable-development-friendly AI65. To deal with the ethical dilemmas raised above, it is important that all applications provide openness about the choices and decisions made during design, development, and use, including information about the provenance and governance of the data used for training algorithms, and about whether and how they align with existing AI guidelines. It is therefore important to adopt decentralized AI approaches for a more equitable development of AI66.We are at a critical turning point for the future of AI. A global and science-driven debate to develop shared principles and legislation among nations and cultures is necessary to shape a future in which AI positively contributes to the achievement of all the SDGs. The current choices to develop a sustainable-development-friendly AI by 2030 have the potential to unlock benefits that could go far-beyond the SDGs within our century. All actors in all nations should be represented in this dialogue, to ensure that no one is left behind. On the other hand, postponing or not having such a conversation could result in an unequal and unsustainable AI-fueled future.MethodsIn this section we describe the process employed to obtain the results described in the present study and shown in the Supplementary Data 1. The goal was to answer the question “Is there published evidence of AI acting as an enabler or an inhibitor for this particular target?” for each of the 169 targets within the 17 SDGs. To this end, we conducted a consensus-based expert elicitation process, informed by previous studies on mapping SDGs interlinkages8,9 and following Butler et al.67 and Morgan68. The authors of this study are academics spanning a wide range of disciplines, including engineering, natural and social sciences, and acted as experts for the elicitation process. The authors performed an expert-driven literature search to support the identified connections between AI and the various targets, where the following sources of information were considered as acceptable evidence: published work on real-world applications (given the quality variation depending on the venue, we ensured that the publications considered in the analysis were of sufficient quality); published evidence on controlled/laboratory scenarios (given the quality variation depending on the venue, we ensured that the publications considered in the analysis were of sufficient quality); reports from accredited organizations (for instance: UN or government bodies); and documented commercial-stage applications. On the other hand, the following sources of information were not considered as acceptable evidence: educated conjectures, real-world applications without peer-reviewed research; media, public beliefs or other sources of information.The expert elicitation process was conducted as follows: each of the SDGs was assigned to one or more main contributors, and in some cases to several additional contributors as summarized in the Supplementary Data 1 (here the initials correspond to the author names). The main contributors carried out a first literature search for that SDG and then the additional contributors completed the main analysis. One published study on a synergy or a trade-off between a target and AI was considered enough for mapping the interlinkage. However, for nearly all targets several references are provided. After the analysis of a certain SDG was concluded by the contributors, a reviewer was assigned to evaluate the connections and reasoning presented by the contributors. The reviewer was not part of the first analysis and we tried to assign the roles of the main contributor and reviewer to experts with complementary competences for each of the SDGs. The role of the reviewer was to bring up additional points of view and considerations, while critically assessing the analysis. Then, the main contributors and reviewers iteratively discussed to improve the results presented for each of the SDGs until the analysis for all the SDGs was sufficiently refined.After reaching consensus regarding the assessment shown in the Supplementary Data 1, we analyzed the results by evaluating the number of targets for which AI may act as an enabler or an inhibitor, and calculated the percentage of targets with positive and negative impact of AI for each of the 17 goals, as shown in Fig. 1. In addition, we divided the SDGs into the three following categories: Society, Economy, and Environment, consistent with the classification discussed by Refs. 11,12. The SDGs assigned to each of the categories are shown in Fig. 6 and the individual results from each of these groups can be observed in Figs. 2–4. These figures indicate, for each target within each SDG, whether any published evidence of positive or negative impact was found.Fig. 6: Categorization of the SDGs (https://www.un.org/sustainabledevelopment/) into the Society, Economy, and Environment groups.(The content of this figure has not been reviewed by the United Nations and does not reflect its views).Full size imageTaking into account the types of evidenceIn the methodology described above, a connection between AI and a certain target is established if at least one reference documenting such a link was found. As the analyzed studies rely on very different types of evidence, it is important to classify the references based on the methods employed to support their conclusions. Therefore, all the references in the Supplementary Data 1 include a classification from (A) to (D) according to the following criteria:References using sophisticated tools and data to refer to this particular issue and with the possibility to be generalized are of type (A).Studies based on data to refer to this particular issue, but with limited generalizability, are of type (B).Anecdotal qualitative studies and methods are of type (C) .Purely theoretical or speculative references are of type (D).The various classes were assigned following the same expert elicitation process described above. Then, the contribution of these references towards the linkages is weighted and categories (A), (B), (C), and (D) are assigned relative weights of 1, 0.75, 0.5, and 0.25, respectively. It is noteworthy that, given the vast range of studies on all the SDG areas, the literature search was not exhaustive and, therefore, certain targets are related to more references than others in our study. To avoid any bias associated to the different amounts of references in the various targets, we considered the largest positive and negative weight to establish the connection with each target. Let us consider the following example: for a certain target, one reference of type (B) documents a positive connection and two references of types (A) and (D) document a negative connection with AI. In this case, the potential positive impact of AI on that target will be assessed with 0.75, while the potential negative impact is 1.Limitations of the researchThe presented analysis represents the perspective of the authors. Some literature on how AI might affect certain SDGs could have been missed by the authors or there might not be published evidence yet on such interlinkage. Nevertheless, the employed methods tried to minimize the subjectivity of the assessment. How AI might affect the delivery of each SDG was assessed and reviewed by several authors and a number of studies were reviewed for each interlinkage. Furthermore, as discussed in the Methods section, each interlinkage was discussed among a subset of authors until consensus was reached on its nature.Finally, this study relies on the analysis of the SDGs. The SDGs provide a powerful lens for looking at internationally agreed goals on sustainable development and present a leap forward compared with the Millenium Development Goals in the representation of all spheres of sustainable development, encompassing human rights69, social sustainability, environmental outcomes, and economic development. However, the SDGs are a political compromise and might be limited in the representation of some of the complex dynamics and cross-interactions among targets. Therefore, the SDGs have to be considered in conjunction with previous and current, and other international agreements9. For instance, as pointed out in a recent work by UN Human Rights69, human rights considerations are highly embedded in the SDGs. Nevertheless, the SDGs should be considered as a complement, rather than a replacement, of the United Nations Universal Human Rights Charter70.


Data availability
The authors declare that all the data supporting the findings of this study are available within the paper and its Supplementary Data 1 file.
ReferencesAcemoglu, D. & Restrepo, P. Artificial Intelligence, Automation, and Work. NBER Working Paper No. 24196 (National Bereau of Economic Research, 2018).Bolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V. & Kalai, A. Man is to computer programmer as woman is to homemaker? Debiasing word embeddings. Adv. Neural Inf. Process. Syst. 29, 4349–4357 (2016).
                    Google Scholar 
                Norouzzadeh, M. S. et al. Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning. Proc. Natl Acad. Sci. USA 115, E5716–E5725 (2018).Article 
    CAS 
    
                    Google Scholar 
                Tegmark, M. Life 3.0: Being Human in the Age of Artificial Intelligence (Random House Audio Publishing Group, 2017).Jean, N. et al. Combining satellite imagery and machine learning to predict poverty. Science (80-.) 353, 790–794 (2016).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Courtland, R. Bias detectives: the researchers striving to make algorithms fair. Nature 558, 357–360 (2018).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                UN General Assembly (UNGA). A/RES/70/1Transforming our world: the 2030 Agenda for Sustainable Development. Resolut 25, 1–35 (2015).
                    Google Scholar 
                Fuso Nerini, F. et al. Mapping synergies and trade-offs between energy and the Sustainable Development Goals. Nat. Energy 3, 10–15 https://doi.org/10.1038/s41560-017-0036-5 (2017).Article 
    ADS 
    
                    Google Scholar 
                Fuso Nerini, F. et al. Connecting climate action with other Sustainable Development Goals. Nat. Sustain. 1, 674–680 (2019). https://doi.org/10.1038/s41893-019-0334-y
Article 
    
                    Google Scholar 
                Fuso Nerini, F. et al. Use SDGs to guide climate action. Nature 557, https://doi.org/10.1038/d41586-018-05007-1 (2018).Article 
    CAS 
    
                    Google Scholar 
                United Nations Economic and Social Council. Sustainable Development (United Nations Economic and Social Council, 2019).Stockholm Resilience Centre’s (SRC) contribution to the 2016 Swedish 2030 Agenda HLPF report (Stockholm University, 2017).International Energy Agency. Digitalization & Energy (International Energy Agency, 2017).Fuso Nerini, F. et al. A research and innovation agenda for zero-emission European cities. Sustainability 11, 1692 https://doi.org/10.3390/su11061692 (2019).Article 
    
                    Google Scholar 
                Jones, N. How to stop data centres from gobbling up the world’s electricity. Nature 561, 163–166 (2018).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Truby, J. Decarbonizing Bitcoin: law and policy choices for reducing the energy consumption of Blockchain technologies and digital currencies. Energy Res. Soc. Sci. 44, 399–410 (2018).Article 
    
                    Google Scholar 
                Ahmad Karnama, Ehsan Bitaraf Haghighi, Ricardo Vinuesa, (2019) Organic data centers: A sustainable solution for computing facilities. Results in Engineering 4:100063Article 
    
                    Google Scholar 
                Raissi, M., Perdikaris, P. & Karniadakis, G. E. Physics informed deep learning (part I): data-driven solutions of nonlinear partial differential equations. arXiv:1711.10561 (2017).Nagano, A. Economic growth and automation risks in developing countries due to the transition toward digital modernity. Proc. 11th International Conference on Theory and Practice of Electronic Governance—ICEGOV ’18 (2018). https://doi.org/10.1145/3209415.3209442
Helbing, D. & Pournaras, E. Society: build digital democracy. Nature 527, 33–34 (2015).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Helbing, D. et al. in Towards Digital Enlightenment 73–98 (Springer International Publishing, 2019). https://doi.org/10.1007/978-3-319-90869-4_7

                    Google Scholar 
                Nagler, J., van den Hoven, J. & Helbing, D. in Towards Digital Enlightenment 41–46 (Springer International Publishing, 2019). https://doi.org/10.1007/978-3-319-90869-4_5

                    Google Scholar 
                Wegren, S. K. The “left behind”: smallholders in contemporary Russian agriculture. J. Agrar. Chang. 18, 913–925 (2018).Article 
    
                    Google Scholar 
                NSF - National Science Foundation. Women and Minorities in the S&E Workforce (NSF - National Science Foundation, 2018).Helbing, D. The automation of society is next how to survive the digital revolution; version 1.0 (Createspace, 2015).Cockburn, I., Henderson, R. & Stern, S. The Impact of Artificial Intelligence on Innovation (NBER, 2018). https://doi.org/10.3386/w24449
Seo, Y., Kim, S., Kisi, O. & Singh, V. P. Daily water level forecasting using wavelet decomposition and artificial intelligence techniques. J. Hydrol. 520, 224–243 (2015).Article 
    ADS 
    
                    Google Scholar 
                Adeli, H. & Jiang, X. Intelligent Infrastructure: Neural Networks, Wavelets, and Chaos Theory for Intelligent Transportation Systems and Smart Structures (CRC Press, 2008).Nunes, I. & Jannach, D. A systematic review and taxonomy of explanations in decision support and recommender systems. Use. Model Use. Adapt Interact. 27, 393–444 (2017).Article 
    
                    Google Scholar 
                Bissio, R. Vector of hope, source of fear. Spotlight Sustain. Dev. 77–86 (2018).Brynjolfsson, E. & McAfee, A. The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies (W. W. Norton & Company, 2014).Dobbs, R. et al. Poorer Than Their Parents? Flat or Falling Incomes in Advanced Economies (McKinsey Global Institute, 2016).Francescato, D. Globalization, artificial intelligence, social networks and political polarization: new challenges for community psychologists. Commun. Psychol. Glob. Perspect. 4, 20–41 (2018).
                    Google Scholar 
                Saam, N. J. & Harrer, A. Simulating norms, social inequality, and functional change in artificial societies. J. Artificial Soc.Social Simul. 2 (1999).Dalenberg, D. J. Preventing discrimination in the automated targeting of job advertisements. Comput. Law Secur. Rev. 34, 615–627 (2018).Article 
    
                    Google Scholar 
                World Economic Forum (WEF). Fourth Industrial Revolution for the Earth Series Harnessing Artificial Intelligence for the Earth (World Economic Forum, 2018).Vinuesa, R., Fdez. De Arévalo, L., Luna, M. & Cachafeiro, H. Simulations and experiments of heat loss from a parabolic trough absorber tube over a range of pressures and gas compositions in the vacuum chamber. J. Renew. Sustain. Energy 8 (2016).Keramitsoglou, I., Cartalis, C. & Kiranoudis, C. T. Automatic identification of oil spills on satellite images. Environ. Model. Softw. 21, 640–652 (2006).Article 
    
                    Google Scholar 
                Mohamadi, A., Heidarizadi, Z. & Nourollahi, H. Assessing the desertification trend using neural network classification and object-oriented techniques. J. Fac. Istanb. Univ. 66, 683–690 (2016).
                    Google Scholar 
                Kwok, R. AI empowers conservation biology. Nature 567, 133–134 (2019).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Bonnefon, J.-F., Shariff, A. & Rahwan, I. The social dilemma of autonomous vehicles. Science 352, 1573–1576 (2016).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                De Fauw, J. et al. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat. Med 24, 1342–1350 (2018).Article 
    
                    Google Scholar 
                Russell, S., Dewey, D. & Tegmark, M. Research priorities for robust and beneficial artificial intelligence. AI Mag. 34, 105–114 (2015).Article 
    
                    Google Scholar 
                World Economic Forum (WEF). The New Physics of Financial Services – How Artificial Intelligence is Transforming the Financial Ecosystem (World Economic Forum, 2018).Gandhi, N., Armstrong, L. J. & Nandawadekar, M. Application of data mining techniques for predicting rice crop yield in semi-arid climatic zone of India. 2017 IEEE Technological Innovations in ICT for Agriculture and Rural Development (TIAR) (2017). https://doi.org/10.1109/tiar.2017.8273697
Esteva, A. et al. Corrigendum: dermatologist-level classification of skin cancer with deep neural networks. Nature 546, 686 (2017).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Cao, Y., Li, Y., Coleman, S., Belatreche, A. & McGinnity, T. M. Detecting price manipulation in the financial market. 2014 IEEE Conference on Computational Intelligence for Financial Engineering & Economics (CIFEr) (2014). https://doi.org/10.1109/cifer.2014.6924057
Nushi, B., Kamar, E. & Horvitz, E. Towards accountable AI: hybrid human-machine analyses for characterizing system failure. arXiv:1809.07424 (2018).Beyer, H. L., Dujardin, Y., Watts, M. E. & Possingham, H. P. Solving conservation planning problems with integer linear programming. Ecol. Model. 328, 14–22 (2016).Article 
    
                    Google Scholar 
                Whittaker, M. et al. AI Now Report 2018 (AI Now Institute, 2018).Petit, M. Towards a critique of algorithmic reason. A state-of-the-art review of artificial intelligence, its influence on politics and its regulation. Quad. del CAC 44 (2018).Scholz, R. et al. Unintended side effects of the digital transition: European scientists’ messages from a proposition-based expert round table. Sustainability 10, 2001 (2018).Article 
    
                    Google Scholar 
                Ramirez, E., Brill, J., Maureen, K., Wright, J. D. & McSweeny, T. Data Brokers: A Call for Transparency and Accountability (Federal Trade Commission, 2014).Panch, T., Mattie, H. & Celi, L. A. The “inconvenient truth” about AI in healthcare. npj Digit. Med 2, 77 (2019).Article 
    
                    Google Scholar 
                Solaiman, S. M. Legal personality of robots, corporations, idols and chimpanzees: a quest for legitimacy. Artif. Intell. Law 25, 155–179 (2017).Article 
    
                    Google Scholar 
                West, J. & Bhattacharya, M. Intelligent financial fraud detection: a comprehensive review. Comput. Secur 57, 47–66 (2016).Article 
    
                    Google Scholar 
                Hajek, P. & Henriques, R. Mining corporate annual reports for intelligent detection of financial statement fraud – A comparative study of machine learning methods. Knowl.-Based Syst. 128, 139–152 (2017).Article 
    
                    Google Scholar 
                Perry, W. L., McInnis, B., Price, C. C., Smith, S. C. & Hollywood, J. S. Predictive Policing: The Role of Crime Forecasting in Law Enforcement Operations (RAND Corporation, 2013).Gorr, W. & Neill, D. B. Detecting and preventing emerging epidemics of crime. Adv. Dis. Surveillance 4, 13 (2007).IEEE. Ethically Aligned Design - Version II overview (2018). https://doi.org/10.1109/MCS.2018.2810458
European Commission. Draft Ethics Guidelines for Trustworthy AI (Digital Single Market, 2018).Lipton, Z. C. The mythos of model interpretability. Commun. ACM 61, 36–43 (2018).Article 
    ADS 
    
                    Google Scholar 
                Dignum, V. Responsible Artificial Intelligence (Springer International Publishing, 2019).Future of Life Institute. Open Letter on Autonomous Weapons (Future of Life Institute, 2015).Future of Life Institute. Annual Report 2018. https://futureoflife.org/wp-content/uploads/2019/02/2018-Annual-Report.pdf?x51579
Montes, G. A. & Goertzel, B. Distributed, decentralized, and democratized artificial intelligence. Technol. Forecast. Soc. Change 141, 354–358 (2019).Article 
    
                    Google Scholar 
                Butler, A. J., Thomas, M. K. & Pintar, K. D. M. Systematic review of expert elicitation methods as a tool for source attribution of enteric illness. Foodborne Pathog. Dis. 12, 367–382 (2015).Article 
    
                    Google Scholar 
                Morgan, M. G. Use (and abuse) of expert elicitation in support of decision making for public policy. Proc. Natl Acad. Sci. USA 111, 7176–7184 (2014).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                United Nations Human Rights. Sustainable Development Goals Related Human Rights (United Nations Human Rights, 2016).Draft Committee. Universal Declaration of Human Rights (United Nations, 1948).Download referencesAcknowledgementsR.V. acknowledges funding provided by KTH Sustainability Office. I.L. acknowledges the Swedish Research Council (registration number 2017-05189) and funding through an Early Career Research Fellowship granted by the Jacobs Foundation. M.B. acknowledges Implicit SSF: Swedish Foundation for Strategic Research project RIT15-0046. V.D. acknowledges the support of the Wallenberg AI, Autonomous Systems, and Software Program (WASP) program funded by the Knut and Alice Wallenberg Foundation. S.D. acknowledges funding from the Leibniz Competition (J45/2018). S.L. acknowledges funding from the European Union’s Horizon 2020 Research and Innovation Programme under the Marie Skłodowska–Curie grant agreement number 748625. M.T. was supported by the Ethics and Governance of AI Fund. F.F.N. acknowledges funding from the Formas grant number 2018-01253.Author informationAuthors and AffiliationsLinné FLOW Centre, KTH Mechanics, SE-100 44, Stockholm, SwedenRicardo VinuesaDivision of Robotics, Perception, and Learning, School of EECS, KTH Royal Institute Of Technology, Stockholm, SwedenHossein Azizpour & Iolanda LeiteDivision of Media Technology and Interaction Design, KTH Royal Institute of Technology, Lindstedtsvägen 3, Stockholm, SwedenMadeline BalaamResponsible AI Group, Department of Computing Sciences, Umeå University, SE-90358, Umeå, SwedenVirginia DignumLeibniz-Institute of Freshwater Ecology and Inland Fisheries, Müggelseedamm 310, 12587, Berlin, GermanySami DomischAI Sustainability Center, SE-114 34, Stockholm, SwedenAnna FelländerBasque Centre for Climate Change (BC3), 48940, Leioa, SpainSimone Daniela LanghansDepartment of Zoology, University of Otago, 340 Great King Street, 9016, Dunedin, New ZealandSimone Daniela LanghansCenter for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, Massachusetts, 02139, USAMax TegmarkUnit of Energy Systems Analysis (dESA), KTH Royal Institute of Technology, Brinellvagen, 68SE-1004, Stockholm, SwedenFrancesco Fuso NeriniAuthorsRicardo VinuesaView author publicationsYou can also search for this author in
                        PubMed Google ScholarHossein AzizpourView author publicationsYou can also search for this author in
                        PubMed Google ScholarIolanda LeiteView author publicationsYou can also search for this author in
                        PubMed Google ScholarMadeline BalaamView author publicationsYou can also search for this author in
                        PubMed Google ScholarVirginia DignumView author publicationsYou can also search for this author in
                        PubMed Google ScholarSami DomischView author publicationsYou can also search for this author in
                        PubMed Google ScholarAnna FelländerView author publicationsYou can also search for this author in
                        PubMed Google ScholarSimone Daniela LanghansView author publicationsYou can also search for this author in
                        PubMed Google ScholarMax TegmarkView author publicationsYou can also search for this author in
                        PubMed Google ScholarFrancesco Fuso NeriniView author publicationsYou can also search for this author in
                        PubMed Google ScholarContributionsR.V. and F.F.N. ideated, designed, and wrote the paper; they also coordinated inputs from the other authors, and assessed and reviewed SDG evaluations as for the Supplementary Data 1. H.A. and I.L. supported the design, wrote, and reviewed sections of the paper; they also assessed and reviewed SDG evaluations as for the Supplementary Data 1. M.B., V.D., S.D., A.F. and S.L. wrote and reviewed sections of the paper; they also assessed and reviewed SDG evaluations as for the Supplementary Data 1. M.T. reviewed the paper and acted as final editor.Corresponding authorsCorrespondence to
                Ricardo Vinuesa or Francesco Fuso Nerini.Ethics declarations
Competing interests
The authors declare no competing interests.
Additional informationPeer review information Nature Communications thanks Dirk Helbing and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Supplementary informationDescription of Additional Supplementary FilesSupplementary Data 1Rights and permissions
Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.
Reprints and permissionsAbout this articleCite this articleVinuesa, R., Azizpour, H., Leite, I. et al. The role of artificial intelligence in achieving the Sustainable Development Goals.
                    Nat Commun 11, 233 (2020). https://doi.org/10.1038/s41467-019-14108-yDownload citationReceived: 03 May 2019Accepted: 16 December 2019Published: 13 January 2020DOI: https://doi.org/10.1038/s41467-019-14108-yShare this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        
Subjects

Computational scienceDeveloping worldEnergy efficiency





This article is cited by





                                        Assessing the current landscape of AI and sustainability literature: identifying key trends, addressing gaps and challenges
                                    


Shailesh TripathiNadine BachmannHerbert Jodlbauer

Journal of Big Data (2024)




                                        Navigating the digital world: development of an evidence-based digital literacy program and assessment tool for youth
                                    


M. Claire BuchanJasmin BhawraTarun Reddy Katapally

Smart Learning Environments (2024)




                                        Green and sustainable AI research: an integrated thematic and topic modeling analysis
                                    


Raghu RamanDebidutta PattnaikPrema Nedungadi

Journal of Big Data (2024)




                                        Artificial Intelligence can help Loss and Damage only if it is inclusive and accessible
                                    


Francesca LarosaAdam Wickberg

npj Climate Action (2024)




                                        Rethinking digitalization and climate: don’t predict, mitigate
                                    


Daria GritsenkoJon AaenBent Flyvbjerg

npj Climate Action (2024)





CommentsBy submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vd3d3Lmdvdi51ay9nb3Zlcm5tZW50L25ld3MvcmV2b2x1dGlvbmFyeS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS13YXJzaGlwLWNvbnRyYWN0cy1hbm5vdW5jZWTSAQA?oc=5,Revolutionary Artificial Intelligence warship contracts announced - GOV.UK,2020-01-14,GOV.UK,https://www.gov.uk,"The Defence and Security Accelerator (DASA) has announced the first wave of £4-million funding. 
",N/A,"The Defence and Security Accelerator (DASA) has announced the first wave of £4-million funding. 
",N/A,,http://schema.org,BreadcrumbList,N/A,N/A,N/A,"{'@type': 'WebPage', '@id': 'https://www.gov.uk/government/news/revolutionary-artificial-intelligence-warship-contracts-announced'}",Revolutionary Artificial Intelligence warship contracts announced,2020-01-14T11:09:00+00:00,2020-01-14T11:09:00+00:00,"The Defence and Security Accelerator (DASA) has announced the first wave of £4-million funding. 
","{'@type': 'Organization', 'name': 'GOV.UK', 'url': 'https://www.gov.uk', 'logo': {'@type': 'ImageObject', 'url': 'https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-logo-b15a4d254746d1642b8187217576d1e8fe50b51352d352fda13eee55d3c1c80a.png'}}",['https://assets.publishing.service.gov.uk/media/5e1d9ff1ed915d7c4567a705/s960_Intelligent_Ships960x640.jpg'],"{'@type': 'Organization', 'name': 'Ministry of Defence', 'url': 'https://www.gov.uk/government/organisations/ministry-of-defence'}","[{'@context': 'http://schema.org', '@type': 'Thing', 'sameAs': 'https://www.gov.uk/defence/working-armed-forces'}]",Revolutionary Artificial Intelligence warship contracts announced,"<div class=""govspeak""><p>The funding aims to revolutionise the way warships make decisions and process thousands of strands of intelligence and data by using Artificial Intelligence (<abbr title=""Artificial Intelligence"">A.I.</abbr>).</p>

<p>9 projects will share an initial £1-million to develop technology and innovative solutions to overcome increasing ‘information overload’ faced by crews as part of <abbr title=""Defence and Security Accelerator"">DASA</abbr>’s Intelligent Ship, The Next Generation competition.</p>

<p>Defence Minister James Heappey said:</p>

<blockquote>
  <p class=""last-child"">The astonishing pace at which global threats are evolving requires new approaches and fresh-thinking to the way we develop our ideas and technology. The funding will research pioneering projects into how <abbr title=""Artificial Intelligence"">A.I.</abbr> and automation can support our armed forces in their essential day-to-day work.</p>
</blockquote>

<p>Intelligent Ship is focused on inventive approaches for Human to <abbr title=""Artificial Intelligence"">AI</abbr> and <abbr title=""Artificial Intelligence"">AI</abbr> to <abbr title=""Artificial Intelligence"">AI</abbr> teaming for defence platforms, such as warships, aircraft, and land vehicles in 2040 and beyond.</p>

<p><abbr title=""Defence and Security Accelerator"">DASA</abbr>, on behalf of the Defence Science and Technology Laboratory (<abbr title=""Defence Science and Technology Laboratory"">DSTL</abbr>), is looking at how future defence platforms can be designed and optimised to exploit current and future advances in:</p>

<ul>
  <li>automation</li>
  <li>autonomy</li>
  <li>machine learning</li>
  <li>artificial Intelligence.</li>
</ul>

<p>These key areas of research will look to address the complex and constantly evolving threats to national security.</p>

<p>This work will inform requirements then develop applications essential to the future force in an increasingly complex and <abbr title=""Artificial Intelligence"">A.I.</abbr> driven environment. Although titled Intelligent Ship, a warship is just the prototype demonstrator for this competition. The project will inform development relevant to all defence equipment and military services.</p>

<p>Julia Tagg, technical lead from <abbr title=""Defence Science and Technology Laboratory"">DSTL</abbr>, said:</p>

<blockquote>
  <p>This <abbr title=""Defence and Security Accelerator"">DASA</abbr> competition has the potential to lead the transformation of our defence platforms, leading to a sea change in the relationships between <abbr title=""Artificial Intelligence"">AI</abbr> and human teams. This will ensure UK defence remains an effective, capable force for good in a rapidly changing technological landscape.</p>

  <p class=""last-child"">Crews are already facing information overload with thousands of sources of data, intelligence, and information. By harnessing automation, autonomy, machine learning and artificial intelligence with the real-life skill and experience of our men and women, we can revolutionise the way future fleets are put together and operate to keep the UK safe.</p>
</blockquote>

<p>The competition, currently backed by a total of £4-million over 2 phases, has the potential to transform the way the Royal Navy, British Army and Royal Air Force equipment platforms are designed, work together, operated and manned by the 2040s.</p>

<p>Innovations developed in phase 1 of the competition could later help determine the different platform types, size and role of future platforms as well potentially being adapted and integrated into the existing fleet.</p>

<p><abbr title=""Defence and Security Accelerator"">DASA</abbr> Delivery Manager Adam Moore said:</p>

<blockquote>
  <p><abbr title=""Defence and Security Accelerator"">DASA</abbr> brings together the brightest minds in science, industry and academia to turbocharge innovations to keep the UK, as well as those who protect us, safe from emerging and evolving threats to our way of life.</p>

  <p class=""last-child"">This project will ensure the Royal Navy and all our armed forces stays one step ahead of our adversaries.</p>
</blockquote>

</div>","[{'@type': 'ListItem', 'position': 1, 'item': {'name': 'Home', '@id': 'https://www.gov.uk/'}}, {'@type': 'ListItem', 'position': 2, 'item': {'name': 'Defence and armed forces', '@id': 'https://www.gov.uk/defence-and-armed-forces'}}, {'@type': 'ListItem', 'position': 3, 'item': {'name': 'Armed forces', '@id': 'https://www.gov.uk/defence/working-armed-forces'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9pbmR1c3RyaWVzL2VkdWNhdGlvbi9vdXItaW5zaWdodHMvaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXdpbGwtaW1wYWN0LWstMTItdGVhY2hlcnPSAQA?oc=5,Artificial intelligence in education: How will it impact K-12 teachers - McKinsey,2020-01-14,McKinsey,https://www.mckinsey.com,"New technologies for artificial intelligence in education could help teachers do their jobs better and more efficiently. But to capture the potential, stakeholders need to address four imperatives.",N/A,"New technologies for artificial intelligence in education could help teachers do their jobs better and more efficiently. But to capture the potential, stakeholders need to address four imperatives.","New technologies for artificial intelligence in education could help teachers do their jobs better and more efficiently. But to capture the potential, stakeholders need to address four imperatives.",,https://schema.org,Article,N/A,N/A,N/A,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/industries/education/our-insights/how-artificial-intelligence-will-impact-k-12-teachers'}",,2020-01-14T00:00:00Z,2020-01-14T00:00:00Z,,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",https://www.mckinsey.com/~/media/mckinsey/industries/public%20and%20social%20sector/our%20insights/how%20artificial%20intelligence%20will%20impact%20k%2012%20teachers/ai-boon-5050-1536x1536.jpg,"[{'@type': 'Person', 'name': 'Jake Bryant', 'url': 'https://www.mckinsey.com/our-people/jacob-bryant'}, {'@type': 'Person', 'name': 'Christine Heitz'}, {'@type': 'Person', 'name': 'Saurabh Sanghvi', 'url': 'https://www.mckinsey.com/our-people/saurabh-sanghvi'}, {'@type': 'Person', 'name': 'Dilip Wagle'}]",,,,,https://www.mckinsey.com,2020-01-10T10:19:37Z,How artificial intelligence will impact K–12 teachers,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3LnVjbC5hYy51ay9uZXdzLzIwMjAvamFuL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXVzZWQtcHJlZGljdC0zZC1zdHJ1Y3R1cmUtcHJvdGVpbnPSAQA?oc=5,Artificial intelligence used to predict 3D structure of proteins - University College London,2020-01-16,University College London,https://www.ucl.ac.uk,"A deep learning system can predict the structure of a protein using its genetic sequence more accurately than any previous modelling system, according to a study by researchers at DeepMind and UCL.",N/A,"A deep learning system can predict the structure of a protein using its genetic sequence more accurately than any previous modelling system, according to a study by researchers at DeepMind and UCL.","A deep learning system can predict the structure of a protein using its genetic sequence more accurately than any previous modelling system, according to a study by researchers at DeepMind and UCL.",,,,N/A,N/A,"
Information for

Current students
Staff
Alumni
Business
Donors

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd3d3LndlZm9ydW0ub3JnL2FnZW5kYS8yMDIwLzAxLzgtd2F5cy10by1lbnN1cmUteW91ci1jb21wYW55cy1haS1pcy1ldGhpY2FsL9IBAA?oc=5,8 ways to ensure your company's AI is ethical - World Economic Forum,2020-01-16,World Economic Forum,https://www.weforum.org,"While AI holds plenty of promise, it raises concerns about data misuse and privacy. Here are eight lessons to help firms ensure their AI systems don't become ethically compromised. ","World Economic Forum,WEF,Davos,Klaus Schwab, globalization, globalization4.0, globalization4, globalization four, what does globalization mean?","While AI holds plenty of promise, it raises concerns about data misuse and privacy. Here are eight lessons to help firms ensure their AI systems don't become ethically compromised. ","While AI holds plenty of promise, it raises concerns about data misuse and privacy. Here are eight lessons to help firms ensure their AI systems don't become ethically compromised. ",,,,N/A,N/A,"Stakeholder Capitalism8 ways to ensure your company's AI is ethicalJan 16, 2020A code of ethics?Image: Ali Shah Lakhani on Unsplash.comBarbara CosgroveVice-President; Chief Privacy Officer, WorkdayShare:Our ImpactWhat's the World Economic Forum doing to accelerate action on Stakeholder Capitalism?The Big PictureExplore and monitor how Corporate Governance is affecting economies, industries and global issuesCrowdsource InnovationGet involved with our crowdsourced digital platform to deliver impact at scaleStay up to date:Corporate GovernanceFollowThis article is part of: World Economic Forum Annual MeetingCommitments to ethical AI are only valuable if they are implemented.Sharing best practice will become increasingly important.Here are 8 lessons for companies looking to integrate ethics into their AI.Keeping up with artificial intelligence (AI) and data privacy can be overwhelming. While AI holds plenty of promise and opportunity, there are also concerns about data misuse and personal privacy being at risk. As we evaluate these topics and as the Fourth Industrial Revolution unfolds, questions arise about the promise and peril of AI, and how organizations can better realize its value. Integrating 'ethics' into technology products can feel abstract for engineers and developers. While many technology companies are working independently on ways to do this in concrete and tangible ways, it is imperative that we break out of those silos and share best practices. By working collaboratively to learn from each other, we can raise the bar for the industry as a whole - and a good place to start is focusing on the things that earn trust.Have you read?It's make or break time for artificial intelligence. Here's how we can make it workHow businesses can create an ethical culture in the age of techWe need to reconsider ethical and philosophical issues surrounding our digital identitiesMany companies are releasing high-level principles about their approach to designing and deploying AI products. But principles are only valuable if they are actually implemented. Workday recently published our Commitments to Ethical AI to show how we operationalize principles that build directly on our core values of customer service, integrity and innovation. Based on our experiences, here are eight lessons for technology companies looking to champion those principles across their organization: 1. Define what 'AI ethics' means. This definition needs to be specific and actionable for all relevant stakeholders in the company. At my company, it means our machine-learning (ML) systems reflect our commitment to ethical AI: we put people first; we care about society; we act fairly and respect the law; we are transparent and accountable; we protect data; and we deliver enterprise-ready machine-learning systems. 2. Build ethical AI into the product development and release framework. These cannot be separate processes that create more work and complexity for developers and product teams. Workday has built our principles into the fabric of our product development and created processes that drive continued compliance with them. New ML controls have been incorporated into our formal control framework to serve as additional enforcement of our ML ethics principles. Our development teams examine every ML product through an ethical lens by asking questions about data collection and data minimization, transparency and values. We have a long history of this in the privacy space, including privacy-by-design processes as well as third-party audits against our controls and standards. Workday has embraced a set of ethics-by-design controls for machine learning, and have in place robust review and approval mechanisms for the release of new technologies, as well as any new uses of data. We are committed to ongoing reviews of our processes, and evolving them to incorporate new industry best practices and regulatory guidelines. 3. Create cross-functional groups of experts to guide all decisions on the design, development and deployment of responsible ML and AI. Early on in this journey, Workday established a machine-learning task force comprised of experts drawn from our product and engineering, legal, public policy and privacy, ethics and compliance teams. These groups examine future and existing uses of ML in our products. Bringing these diverse sets of skills and views together to discuss future and existing uses of ML in our products has been really powerful, and has enabled us to identify potential issues early on in the product lifecycle. DiscoverWhat is algorithm bias? Show moreAlgorithm bias, also called machine learning bias, is a phenomenon in which algorithms can act in a discriminatory or prejudiced manner due to misplaced assumptions during the learning phase of their development.Unconscious biases regarding gender, race and social class can make their way into the training data fed by programmers into “machine-learning algorithms”, systems which constantly improve their own performance by including new data into an existing model.These biases can be observed in the algorithm’s output: erroneous reflected assumptions that can result in embarrassing news coverage.Some recent stories about accidental algorithm bias include:A facial recognition algorithm that was more accurate on white faces than darker skin tonesSpeech recognition software that couldn't recognise women's voices as well as men'sSoftware used in the United States to predict future criminals that was wrongly biased against black offendersHave you read?Bias in AI is a real problem. Here’s what we should do about itAI isn’t dangerous, but human bias isAI is convicting criminals and determining jail time, but is it fair?How to Prevent Discriminatory Outcomes in Machine Learning4. Bring customer collaboration into the design, development and deployment of responsible AI. Workday engages our customer advisory councils, drawn from a broad cross-section of our customer base, during our product development lifecycle to gain feedback around our development themes related to AI and ML. And through our early adopter programme, we work closely with a handful of customers who act as design partners to test out new ML models and features through our innovation services.This enables us to understand and address customers’ ideas and concerns around AI and ML early on as we co-develop people-centric ML solutions. 5. Take a lifecycle approach to bias in machine learning. ML tools represent a phenomenal opportunity to help our customers leverage data to enhance human decision-making. With that opportunity comes the responsibility to build enterprise-ready tools that maintain our customers' trust, which is why one of the focal points of our commitments to ethical AI is mitigating harmful bias in ML. We use a 'lifecycle approach', through which we perform various bias assessments and reviews starting from the initial concept for a new product through the post-release phase. Accept our marketing cookies to access this content.These cookies are currently disabled in your browser.Accept cookies6. Be transparent. The ethical use of data for ML requires transparency. Because ML algorithms can be so complex, companies should go above and beyond in explaining what data is being used, how it’s being used, and for what purpose. Explain to customers how your ML technologies work and the benefits they offer, and describe the data content needed to power any ML solutions you offer. Demonstrate accountability in your ML solutions to your customers. 7. Empower your employees to design responsible products. We do this through required ethics training modules, toolkits, seminars, employee onboarding and workshops to ensure employees are trained in how to uphold our AI ethical commitments. For example, a human-centered design-thinking workshop uses different scenarios and personas to help Workday employees understand our commitments to creating ethical ML technologies. 8. Share what you know and learn from others in the industry. We do this through participation in industry groups and peer meetings such as the World Economic Forum Steering Committee for Ethical Design and Deployment of Technology to help develop an ethical framework for the tech industry. In addition, Workday makes it a priority to monitor and contribute to new standards and plans. In the US, we have engaged heavily with lawmakers and agency officials on ethical AI, including developing and participating in a Congressional AI Caucus staff briefing on 'Industry Approaches to Ethical AI', and playing the role of convener between industry and policy-makers in multiple venues. In addition, we provided support for the National Science Foundation’s update to the National Artificial Intelligence Research and Development Strategic Plan and the National Institute of Standards and Technology’s (NIST) development of their report, Artificial Intelligence Standards and Tools Development. We continue to advocate for an expanded role for NIST in the development of AI ethics tools. In Europe, Workday participated in a pilot programme to evaluate the European Union’s High-Level Expert Group’s Ethical Guidelines’s (HLEG) Trustworthy Artificial Intelligence Assessment List. As we navigate this evolving world of ethical AI, it will become more important than ever to share practices and identify what we’ve learned along the way. We are eager to hear from others on what approaches have been effective for scaling and implementation, and we welcome the opportunity to share. In fact, the aim of Workday’s collaboration with the World Economic Forum is to encourage others to join us in sharing their best practices for championing responsible and ethical technology. The pursuit of responsible, ethical artificial intelligence and technology is critical - and is greater than any single company or organization.Together, we should be building goodwill and trust through our actions, allowing us to realize the benefits of these powerful new technologies.Don't miss any update on Corporate GovernanceSign up for free and access the latest publications and insights across various topics.Sign up for freeLicense and RepublishingWorld Economic Forum articles may be republished in accordance with the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License, and in accordance with our Terms of Use.The views expressed in this article are those of the author alone and not the World Economic Forum.Related topics:Stakeholder CapitalismEmerging TechnologiesForum InstitutionalFourth Industrial RevolutionShare:Global AgendaThe Agenda WeeklyA weekly update of the most important issues driving the global agendaSubscribe todayYou can unsubscribe at any time using the link in our emails. For more details, review our privacy policy.More on Stakeholder CapitalismSee allInvesting in innovation will secure vital critical minerals for the energy transition – here's where to startMichel Van Hoey and Jörgen SandströmJune 24, 2024To create a 'sustainomy' businesses must focus on the ecosystem, not just the market""Arm"" Piyachart IsarabhakdeeJune 17, 2024'It's now cheaper to save the world than destroy it': author Akshat Rathi on Climate Capitalism Robin Pomeroy and Sophia AkramApril 10, 2024How family business could lead solutions to today's sustainability challengesFrederick Tsao ChavalitMarch 27, 2024EU governments back human rights and environmental due diligence law for supply chainsKimberley Botwright and Spencer FeingoldMarch 27, 2024How true strategic foresight can help companies survive and thriveAmy WebbJanuary 31, 2024",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS9maWxtLzIwMjAvamFuLzE2L2l0cy1hLXdhci1iZXR3ZWVuLXRlY2hub2xvZ3ktYW5kLWEtZG9ua2V5LWhvdy1haS1pcy1zaGFraW5nLXVwLWhvbGx5d29vZNIBdWh0dHBzOi8vYW1wLnRoZWd1YXJkaWFuLmNvbS9maWxtLzIwMjAvamFuLzE2L2l0cy1hLXdhci1iZXR3ZWVuLXRlY2hub2xvZ3ktYW5kLWEtZG9ua2V5LWhvdy1haS1pcy1zaGFraW5nLXVwLWhvbGx5d29vZA?oc=5,'It's a war between technology and a donkey' – how AI is shaking up Hollywood - The Guardian,2020-01-16,The Guardian,https://www.theguardian.com,"Hollywood used to run on hunches. Now, data analytics is far more effective than humans at predicting hits and eliminating flops. Is this a brave new world – or the death knell of creativity? <br>",N/A,"Hollywood used to run on hunches. Now, data analytics is far more effective than humans at predicting hits and eliminating flops. Is this a brave new world – or the death knell of creativity?",N/A,,,,Film,N/A," Cinelytics claims its AI, used by Warner Bros, can forecast box office results with 85% accuracy. Composite: Guardian Design TeamView image in fullscreenCinelytics claims its AI, used by Warner Bros, can forecast box office results with 85% accuracy. Composite: Guardian Design TeamMovies This article is more than 4 years old'It's a war between technology and a donkey' – how AI is shaking up HollywoodThis article is more than 4 years oldThe film business used to run on hunches. Now, data analytics is far more effective than humans at predicting hits and eliminating flops. Is this a brave new world – or the death knell of creativity? Steve RoseThu 16 Jan 2020 10.00 ESTLast modified on Thu 16 Jan 2020 11.50 ESTShare164164If Sunspring is anything to go by, artificial intelligence in film-making has some way to go. This short film, made as an entry to Sci-Fi London’s 48-hour film-making competition in 2016, was written entirely by an AI. The director, Oscar Sharp, fed a few hundred sci-fi screenplays into a long short-term memory recurrent neural network (the type of software behind predictive text in a smartphone), then told it to write its own. The result was almost, but not quite, incoherent nonsense, riddled with cryptic nonsequiturs, bizarre turns of phrase and unfathomable stage directions such as “he is standing in the stars and sitting on the floor”. All of which Sharp and his actors filmed with sincere commitment.“In a future with mass unemployment, young people are forced to sell blood,” says a man in a shiny gold jacket. “You should see the boy and shut up. I was the one who was going to be a hundred years old,” replies a woman fiddling with some electronics. The man vomits up an eyeball. A second man says: “Well, I have to go to the skull.” And so forth. An unwitting viewer might be unsure whether they were watching meaningless nonsense or a lost Tarkovsky script.This isn’t how artificial intelligence is changing the movies – yet. But AI is changing the industry in other ways, to a greater extent than is being admitted. In early January, Warner Bros broke cover and announced it had signed up to an AI-driven project management system that would “inform decision-making around content and talent valuation to support release strategies”. In other words, Warners will be using AI to help it decide what movies to make.The system in question was launched last year by Cinelytic, a Los Angeles-based startup. Other clients listed on its website include Sony Pictures, Ingenious Media and STX Entertainment (the studio behind Hustlers and Playmobil: The Movie). Meanwhile, 20th Century Fox has partnered with Google to develop its own AI, named Merlin, which predicts audiences based on analysis of patterns and objects in movie trailers. Other new companies have also entered the AI game in the past few years, including Belgium-based ScriptBook and Israel’s Vault AI.You can see the appeal, especially for a studio like Warner Bros. As well as putting out hits such as Joker and A Star Is Born, it has had its share of box-office flops, such as King Arthur: Legend of the Sword, The Kitchen, Shaft and The Goldfinch. These projects must have looked like hits on paper. How to tell the difference? Traditionally, Hollywood almost prides itself on its own unpredictability, accepting as a given William Goldman’s adage “no one knows anything”. It is an industry that carries out extensive analysis, research and audience testing, but that still relies to a large extent on human intuition and gut instinct. It is also an industry where the majority of films made are never released, and less than half of those that are make their money back.Can the machines do better? Absolutely, says Cinelytic, which claims an accuracy of 85% in its box office forecasting. Cinelytic was founded in 2015 by Tobias Queisser, whose background is in finance and film producing. His co-founder, Dev Sen, is a rocket scientist who developed risk assessment software for Nasa. Cinelytic claims to have crunched data from more than 95,000 movies and 500,000 actors and professionals, but its chief selling point is that it can make forecasts in real time – expressed as percentage probabilities of certain levels of success. With its user-friendly interface, clients can play with the variables and assess the impact on box office right away.Let’s make an action comedy starring Dwayne Johnson, say. It will be huge! But what if Johnson is not available? How would it look if you cast Gerard Butler instead? Not so huge, perhaps, but the budget might also be lower. How would it do if you released it over 1,000 screens, or 3,000? How would it do in Brazil or China? In effect, Cinelytic’s AI treats the movie industry like fantasy football, assigning quantitative scores to individuals, according to factors such as recent or past box-office performance or social media profile.Others take a slightly different approach. ScriptBook’s AI primarily analyses scripts, as opposed to actors or directors. “Most people believe that cast is everything, but we’ve learned that the story has the highest predictive value,” says Nadira Azermai, who founded the company in 2015. It doesn’t take a computer-sized brain to think of a movie that had a stellar cast but still flopped. But a good story will succeed even without stars – and potentially more so with them, she says.Within six minutes, ScriptBook’s AI reads a script and assigns it more than 400 parameters. “Anything that is information: emotion analysis, the journey for the protagonist and antagonist, whether the film will cater to a wide audience or niche audience, whether it follows a traditional three-act structure, whether the action happens in the most important places.” As more information becomes available, such as the cast, the prediction becomes more accurate, but if the computer says no to begin with, no additional information will change it to a yes.ScriptBook’s success rates are comparable to those of Cinelytic: 83% to 86%, Azermai claims, whereas human decision-making is successful 27% to 31% of the time. In a retroactive study of Sony’s output between 2015 and 2017, for example, it successfully identified 22 out of its 32 releases that lost money. It could have saved the company a fortune. It has achieved similar levels of accuracy with movies before they were released, even predicting the success of unconventional outliers such as Get Out, La La Land and A Quiet Place. Azermai is not yet at liberty to reveal which companies ScriptBook has been working with, but she applauds Warners’ announcement that it is working with Cinelytic. “It is an important message, because the majority of companies are still treating AI as a dirty little secret.”One of the factors driving the AI revolution is undoubtedly Netflix, which, by its spectacular ascent over the past decade, has awakened the entertainment industry to the awesome power of data. Netflix has valued its “recommendations” algorithms (which suggest to viewers what to watch next) at $1bn (£760m) a year in terms of keeping subscribers engaged. The company is notoriously secretive about its methods, but it is safe to assume it is tracking viewers’ every move: what they watch, how long they watch it, what time of day it is, what they watch next, how many hits a new show receives in its first day, and so on. Because Netflix also streams other people’s content, it is even better informed when it comes to producing its own. The studio’s staggering output (Netflix put out 700 original TV shows and 80 features in 2018) would not be possible without AI assistance. As a result of Netflix’s success, tech companies such as Apple and Amazon are getting into content creation and giving the old-school studios a run for their money.“All of a sudden you have this conservative, traditional industry versus companies who are believers in data,” says Azermai. “There is a war on content, but one party is using the latest technology and the other is riding a donkey.”The AI revolution will clearly benefit film-makers, but what is in it for us viewers? One potential drawback is that AI eliminates not only financial risk but creative risk, too. The fear is, if you fed in a vaguely challenging or experimental or atypical project into the machine – say Mulholland Drive or Under the Skin – the algorithm would discourage you from taking the gamble. Why not do a Dwayne Johnson action comedy instead?Added to which, the data these algorithms are processing are actually human beings, who are inherently erratic, fallible and unpredictable. Your asset might go into rehab, get divorced or decide to go off and make shoes for a year. In 1996 Robert Downey Jr was arrested driving his Porsche naked through Los Angeles throwing imaginary rats out of the window. What algorithm would have recommended casting him as Iron Man?“Already we’re seeing that we’re getting more and more remakes and sequels because that’s safe, rather than something that’s out of the box,” says Tabitha Goldstaub, a tech entrepreneur and commentator who specialises in artificial intelligence. Her work has raised deeper concerns about AI. Far from being a dispassionate tool, it often reflects the biases and prejudices of its creators, she says. “A lot of people think it’s maths so it can’t be biased, whereas in fact it’s completely the opposite way around: it’s maths, and therefore it’s data, and whatever data you feed a machine will have bias in it. The world is biased, and so these machines exacerbate our own biases.”She points to the fact that no women have been nominated for best director at this year’s Oscars, and only five women have ever been nominated. The AI might well conclude that if you want to make an Oscar-winning movie, don’t hire a female director. “You can’t help but think: do you really want to leave these people in charge of creating an algorithm that predicts the next hits? It’s quite scary.”But there are signs that AI could help reduce bias. The producer Todd Garner cited an example on his Producer’s Guide podcast recently. Garner’s company produced the Marlon Wayans comedies White Chicks and Little Man, and did very well out of them. But when it took a new Wayans project to traditional studios and financiers, nobody bit, he says. “Because there was no way, they thought, that this movie would play internationally … so it’s a purely domestic play [a US-only release]. Netflix came in and scooped it up immediately, gave us a lot more money to make the movie and the movie was huge for their site. Because Netflix had hosted White Chicks and other Wayans movies on their site, they knew that Marlon Wayans has a worldwide audience. If you don’t have that data, your instinct is, well, African American movies don’t play overseas, period.”Now that AI is here, there is also the question of how much further it will infiltrate film-making. Screenwriting, for example. Things have moved on since Sunspring in 2016. Last year, Kevin Macdonald directed a one-minute advert for Lexus entirely written by an AI – that had been trained on 15 years’ worth of luxury ads.As well as analytical tools, ScriptBook is developing a screenwriting AI, which it has given the dystopian sci-fi thriller name of Deepstory. “It really is a co-creator,” says Azermai, reassuringly. “We envision a next-generation writers’ room where whenever they don’t know where to head to for the next scene, they would have Deepstory create it. The engine takes into account everything that you’ve written, and it will deliver you the next scene, or the next 10 pages, or write it to the end.” Azermai admits Deepstory still has much to learn. “The consistency in writing stays for another 10 pages and then the AI becomes a bit crazy – sometimes it kills the protagonist for some reason – but it’s improving. Within five years we’ll have scripts written by AI that you would think are better than human writing.”The movies themselves have trained us to be suspicious of AIs. They make terrible substitute children (Spielberg’s AI), and even worse romantic partners (Spike Jonze’s Her). They often decide humans are expendable and take over (Kubrick’s 2001) or they enslave us in some futuristic dystopia (Terminator, The Matrix). Could it be that by embracing AI, Hollywood is unwittingly building an equivalent of the Terminator movies’ Skynet? Or, in a slightly less apocalyptic scenario, are we looking at a future where movies are personally tailored to individual viewers? Might we be approaching a sort of Turing test for machine-written fiction? Maybe we have passed it already and we just don’t know it yet. Sounds like a plot for a great, metatextual Hollywood conspiracy thriller. If we got Dwayne Johnson it could be a smash. Let’s crunch some numbers!Explore more on these topicsFilmFilm industryArtificial intelligence (AI)ComputingfeaturesShareReuse this contentMost viewedRFK Jr apologises after leaked phone call in which Trump seems to offer dealNight owls’ cognitive function ‘superior’ to early risers, study suggestsJack Black puts Tenacious D ‘on hold’ after bandmate’s Trump shooting commentTenacious D Australian tour date postponed after comment about Trump shootingNever doubt the instincts of Donald Trump, who just appointed ‘never Trump guy’ as his running mateMarina Hyde",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd2Fyb250aGVyb2Nrcy5jb20vMjAyMC8wMS90aGUtYWktbGl0ZXJhY3ktZ2FwLWhvYmJsaW5nLWFtZXJpY2FuLW9mZmljaWFsZG9tL9IBAA?oc=5,The AI Literacy Gap Hobbling American Officialdom - War On The Rocks,2020-01-14,War On The Rocks,https://warontherocks.com,"This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric",N/A,"This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric",N/A,,https://schema.org,,N/A,N/A,N/A,,,,,,,,,,,,,,,,"[{'@type': 'WebSite', '@id': 'https://warontherocks.com/#website', 'url': 'https://warontherocks.com/', 'name': 'War on the Rocks', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://warontherocks.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://warontherocks.com/2020/01/the-ai-literacy-gap-hobbling-american-officialdom/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://warontherocks.com/wp-content/uploads/2020/01/Horowitz.jpg', 'width': 1330, 'height': 850}, {'@type': 'WebPage', '@id': 'https://warontherocks.com/2020/01/the-ai-literacy-gap-hobbling-american-officialdom/#webpage', 'url': 'https://warontherocks.com/2020/01/the-ai-literacy-gap-hobbling-american-officialdom/', 'name': 'The AI Literacy Gap Hobbling American Officialdom - War on the Rocks', 'isPartOf': {'@id': 'https://warontherocks.com/#website'}, 'primaryImageOfPage': {'@id': 'https://warontherocks.com/2020/01/the-ai-literacy-gap-hobbling-american-officialdom/#primaryimage'}, 'datePublished': '2020-01-14T08:55:46+00:00', 'dateModified': '2021-12-28T21:56:02+00:00', 'author': {'@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8'}, 'description': 'This article was submitted in response to the\xa0call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://warontherocks.com/2020/01/the-ai-literacy-gap-hobbling-american-officialdom/']}]}, {'@type': ['Person'], '@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8', 'name': 'Shane Mason', 'image': {'@type': 'ImageObject', '@id': 'https://warontherocks.com/#personlogo', 'inLanguage': 'en-US', 'url': 'https://secure.gravatar.com/avatar/83a68cf34a391d145ac9f37117795a86?s=96&d=identicon&r=g', 'caption': 'Shane Mason'}}]",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vaW5zaWdodHMub21uaWEtaGVhbHRoLmNvbS9sYWJvcmF0b3J5L2VmZmVjdC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jbGluaWNhbC1sYWJvcmF0b3J50gEA?oc=5,Effect of Artificial Intelligence in the Clinical Laboratory - Omnia Health Insights,2020-01-16,Omnia Health Insights,https://insights.omnia-health.com,Chemistry and Haematology departments have been the earliest to adapt robotics and algorithms into its workflow.,N/A,Chemistry and Haematology departments have been the earliest to adapt robotics and algorithms into its workflow. ,N/A,,https://schema.org,BreadcrumbList,N/A,N/A,"



Patient-centric innovations drive new era of healthcare consumerism 

Jul 15, 2024 


",,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://insights.omnia-health.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'Laboratory', 'item': 'https://insights.omnia-health.com/taxonomy/term/14'}, {'@type': 'ListItem', 'position': 3, 'name': 'Effect of Artificial Intelligence in the Clinical Laboratory'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihwFodHRwczovL3d3dy5uZXd5b3JrZXIuY29tL2J1c2luZXNzL2N1cnJlbmN5L2NvdWxkLW5ldy1yZXNlYXJjaC1vbi1haS1hbmQtd2hpdGUtY29sbGFyLWpvYnMtZmluYWxseS1icmluZy1hYm91dC1hLXN0cm9uZy1wb2xpY3ktcmVzcG9uc2XSAQA?oc=5,Could New Research on A.I. and White-Collar Jobs Finally Bring About a Strong Policy Response? - The New Yorker,2020-01-14,The New Yorker,https://www.newyorker.com,"Sheelah Kolhatkar writes about the findings of a new Brookings Institution study, which determined that certain higher-wage occupations might be more deeply intertwined with A.I. technology in the future than previously thought.","['currency', 'artificial intelligence', 'a.i.', 'technology', 'business', 'web']","Artificial intelligence may end up assisting human workers rather than doing their jobs for them. Either way, the uncertainty is likely to cause alarm.","Artificial intelligence may end up assisting human workers rather than doing their jobs for them. Either way, the uncertainty is likely to cause alarm.",,https://schema.org/,BreadcrumbList,tags,N/A,"CurrencyCould New Research on A.I. and White-Collar Jobs Finally Bring About a Strong Policy Response?By Sheelah KolhatkarJanuary 14, 2020People with bachelor’s degrees might be more exposed to the effects of new technologies than other educational groups, as well as those with higher incomes.Photograph from AlamySave this storySave this storySave this storySave this storyThe encroachment of automation and robotics into the workplace has forced us to rethink the way that certain jobs are done, and it has produced anxiety about whether there will be enough jobs in the future for the human workers who need them. So far, much of the attention has focussed on blue-collar work, as factory assembly lines and warehouses have adopted automated processes more quickly and visibly than other industries. Automation on a factory floor evokes a simple image: robotic arms assembling parts into Tesla cars; mobile robots driving pallets of goods through Amazon distribution centers. In either scenario, the impact on human workers is easy to see. What is harder to visualize is how similar technology might find its way into the aspects of human labor that are invisible and not as easily routinized, such as complex decision-making, strategic planning, and creative thought.Until recently, the consensus among researchers seemed to be that workers with higher levels of education would be less affected by automation than those lower down on the economic hierarchy. Now, though, new research suggests that higher-educated, white-collar workers may be facing significant disruption, as well. In a study published in November by the Brookings Institution, researchers found that certain higher-wage occupations might be more deeply intertwined with A.I. technology in the future than previously thought. “The big takeaway is that manufacturing professions and occupations will be heavily affected,” one of the study’s co-authors, Mark Muro, told me recently. “But so will white-collar jobs—managerial and office activity.” Muro, a senior fellow at Brookings’ Metropolitan Policy Program, who specializes in economic development and technology and who wears spectacles that lend him a bookish air, noted that whether these jobs are likely to be replaced by A.I. or simply changed by it is still unclear; in some cases, A.I. may end up assisting human workers rather than doing their jobs for them. Either way, the uncertainty is likely to cause alarm in some circles.One of the challenges of studying the effects of artificial intelligence on white-collar employment is that the integration of algorithms into office work happens slowly, and often imperceptibly. As a starting point, Muro and his co-authors tried to narrow their task by focussing on machine learning, a form of A.I. that uses algorithms to analyze huge amounts of data, find patterns, and then use those patterns to make predictions. “When most people talk about A.I., they’re talking, in many respects, about this,” Muro said. “When they talk about the radiologists reading a scan enhanced by A.I., they’re talking about machine learning.”Video From The New YorkerSurfing on Kelly Slater’s Machine-Made WaveAfter they defined what they were looking for, another challenge presented itself: how to figure out what new kinds of machine-learning applications were likely to be introduced in the coming years. For this, the researchers employed a method developed by Michael Webb, a graduate student in the economics department at Stanford University, who created an algorithm to analyze A.I. patents that had been filed and cross-reference them with tasks performed in various jobs. Webb examined a pool of approximately sixteen thousand patents that contained verb-object pairs such as “diagnose disease” and “predict prognosis,” which correlated with descriptions of occupations used by the Department of Labor. “Patents are a reflection of the things that inventors think are going to be important innovations that will make money in the future,” Webb told me. “The reason you patent something is that you think you could make some money off of this innovation, and you want the right to create that product and not have other people do it instead.”As a way of testing the effectiveness of this research method, Webb looked back at the previous thirty years or so of patents in software and industrial robotics, to see if the predictions about employment and wage decline one would have found then had panned out. They had: software patents often referred to “recording,” “storing,” and “producing information,” while robot-related patents talked about “cleaning,” “moving,” “welding,” and “assembling.” The words correlated most strongly with the tasks of packers and packagers, hoist and winch operators, machine operators, and those who worked in warehouses—for example, people driving forklifts. “It turns out that the jobs that were highly exposed to those technologies experienced declines in employment and in wages over the next thirty years,” Webb said. That, to him, suggested that software and industrial robots were replacing human labor in those fields (although there were other forces in effect, as well, such as the offshoring of factories).Webb then analyzed A.I. patent filings and found them using verbs such as “recognize,” “detect,” “control,” “determine,” and “classify,” and nouns like “patterns,” “images,” and “abnormalities.” The jobs that appear to face intrusion by these newer patents are different from the more manual jobs that were affected by industrial robots: intelligent machines may, for example, take on more tasks currently conducted by physicians, such as detecting cancer, making prognoses, and interpreting the results of retinal scans, as well as those of office workers that involve making determinations based on data, such as detecting fraud or investigating insurance claims. People with bachelor’s degrees might be more exposed to the effects of the new technologies than other educational groups, as might those with higher incomes. The findings suggest that nurses, doctors, managers, accountants, financial advisers, computer programmers, and salespeople might see significant shifts in their work. Occupations that require high levels of interpersonal skill seem most insulated. (Notably, jobs at the very top of the earning scale, such as C.E.O., are not shown to be deeply changed.)When I asked Muro what he thought the implications of his research might be, he told me about a tweet that someone had written in response to the paper’s findings. The author had expressed concern that his work might “muddy the water about the underemployed and vulnerable,” Muro said, by taking attention away from the truck drivers and factory workers who are already being displaced from their jobs, often with less of a financial cushion to fall back on. “There’s no doubt the white-collar part of the story involves some of the most capable, resilient workers in the economy,” Muro said. “For someone in the eightieth percentile of income, they’re probably well trained by, and are being invested in by, their employers.” That kind of investment, Muro added, “doesn’t flow to those at the lower end.” But he noted that the danger of automation coming for white-collar jobs might help make the issue more real for those in charge of policy decisions. “I think maybe this widens the scope of concern,” he said. “This suggests that it isn’t just somebody else’s problem, namely, a black or brown worker in a factory. . . . We’re all going to be contending with tremendous flux and change in the labor market and our work.”","{'@type': 'WebPage', '@id': 'https://www.newyorker.com/business/currency/could-new-research-on-ai-and-white-collar-jobs-finally-bring-about-a-strong-policy-response'}",,2020-01-14T06:00:00.000-05:00,2020-01-14T06:00:00.000-05:00,,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'The New Yorker', 'logo': {'@type': 'ImageObject', 'url': 'https://www.newyorker.com/verso/static/the-new-yorker/assets/social-image-hub.jpg', 'width': '500px', 'height': '117px'}, 'url': 'https://www.newyorker.com'}","['https://media.newyorker.com/photos/5e14fa7d4b71b300081b1eeb/16:9/w_2560,h_1440,c_limit/Kolhatkar-AIandthewhitecollarjobs.jpg', 'https://media.newyorker.com/photos/5e14fa7d4b71b300081b1eeb/4:3/w_1898,h_1423,c_limit/Kolhatkar-AIandthewhitecollarjobs.jpg', 'https://media.newyorker.com/photos/5e14fa7d4b71b300081b1eeb/1:1/w_1641,h_1641,c_limit/Kolhatkar-AIandthewhitecollarjobs.jpg']","[{'@type': 'Person', 'name': 'Sheelah Kolhatkar', 'sameAs': 'https://www.newyorker.com/contributors/sheelah-kolhatkar'}]",,,"Until recently, the consensus among researchers seemed to be that workers with higher levels of education would be less affected by automation than those lower down on the economic hierarchy. Now, though, new research suggests that higher-educated, white-collar workers may be facing significant disruption, as well. In a study published in November by the Brookings Institution, researchers found that certain higher-wage occupations might be more deeply intertwined with A.I. technology in the future than previously thought. “The big takeaway is that manufacturing professions and occupations will be heavily affected,” one of the study’s co-authors, Mark Muro, told me recently. “But so will white-collar jobs—managerial and office activity.” Muro, a senior fellow at Brookings’ Metropolitan Policy Program, who specializes in economic development and technology and who wears spectacles that lend him a bookish air, noted that whether these jobs are likely to be replaced by A.I. or simply changed by it is still unclear; in some cases, A.I. may end up assisting human workers rather than doing their jobs for them. Either way, the uncertainty is likely to cause alarm in some circles.
One of the challenges of studying the effects of artificial intelligence on white-collar employment is that the integration of algorithms into office work happens slowly, and often imperceptibly. As a starting point, Muro and his co-authors tried to narrow their task by focussing on machine learning, a form of A.I. that uses algorithms to analyze huge amounts of data, find patterns, and then use those patterns to make predictions. “When most people talk about A.I., they’re talking, in many respects, about this,” Muro said. “When they talk about the radiologists reading a scan enhanced by A.I., they’re talking about machine learning.”
After they defined what they were looking for, another challenge presented itself: how to figure out what new kinds of machine-learning applications were likely to be introduced in the coming years. For this, the researchers employed a method developed by Michael Webb, a graduate student in the economics department at Stanford University, who created an algorithm to analyze A.I. patents that had been filed and cross-reference them with tasks performed in various jobs. Webb examined a pool of approximately sixteen thousand patents that contained verb-object pairs such as “diagnose disease” and “predict prognosis,” which correlated with descriptions of occupations used by the Department of Labor. “Patents are a reflection of the things that inventors think are going to be important innovations that will make money in the future,” Webb told me. “The reason you patent something is that you think you could make some money off of this innovation, and you want the right to create that product and not have other people do it instead.”
As a way of testing the effectiveness of this research method, Webb looked back at the previous thirty years or so of patents in software and industrial robotics, to see if the predictions about employment and wage decline one would have found then had panned out. They had: software patents often referred to “recording,” “storing,” and “producing information,” while robot-related patents talked about “cleaning,” “moving,” “welding,” and “assembling.” The words correlated most strongly with the tasks of packers and packagers, hoist and winch operators, machine operators, and those who worked in warehouses—for example, people driving forklifts. “It turns out that the jobs that were highly exposed to those technologies experienced declines in employment and in wages over the next thirty years,” Webb said. That, to him, suggested that software and industrial robots were replacing human labor in those fields (although there were other forces in effect, as well, such as the offshoring of factories).
Webb then analyzed A.I. patent filings and found them using verbs such as “recognize,” “detect,” “control,” “determine,” and “classify,” and nouns like “patterns,” “images,” and “abnormalities.” The jobs that appear to face intrusion by these newer patents are different from the more manual jobs that were affected by industrial robots: intelligent machines may, for example, take on more tasks currently conducted by physicians, such as detecting cancer, making prognoses, and interpreting the results of retinal scans, as well as those of office workers that involve making determinations based on data, such as detecting fraud or investigating insurance claims. People with bachelor’s degrees might be more exposed to the effects of the new technologies than other educational groups, as might those with higher incomes. The findings suggest that nurses, doctors, managers, accountants, financial advisers, computer programmers, and salespeople might see significant shifts in their work. Occupations that require high levels of interpersonal skill seem most insulated. (Notably, jobs at the very top of the earning scale, such as C.E.O., are not shown to be deeply changed.)
When I asked Muro what he thought the implications of his research might be, he told me about a tweet that someone had written in response to the paper’s findings. The author had expressed concern that his work might “muddy the water about the underemployed and vulnerable,” Muro said, by taking attention away from the truck drivers and factory workers who are already being displaced from their jobs, often with less of a financial cushion to fall back on. “There’s no doubt the white-collar part of the story involves some of the most capable, resilient workers in the economy,” Muro said. “For someone in the eightieth percentile of income, they’re probably well trained by, and are being invested in by, their employers.” That kind of investment, Muro added, “doesn’t flow to those at the lower end.” But he noted that the danger of automation coming for white-collar jobs might help make the issue more real for those in charge of policy decisions. “I think maybe this widens the scope of concern,” he said. “This suggests that it isn’t just somebody else’s problem, namely, a black or brown worker in a factory. . . . We’re all going to be contending with tremendous flux and change in the labor market and our work.”","[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.newyorker.com/business'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.newyorker.com/tag/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Could New Research on A.I. and White-Collar Jobs Finally Bring About a Strong Policy Response?'}]",https://www.newyorker.com/business/currency/could-new-research-on-ai-and-white-collar-jobs-finally-bring-about-a-strong-policy-response,,,,,currency,Could New Research on A.I. and White-Collar Jobs Finally Bring About a Strong Policy Response?,"https://media.newyorker.com/photos/5e14fa7d4b71b300081b1eeb/1:1/w_1641,h_1641,c_limit/Kolhatkar-AIandthewhitecollarjobs.jpg","{'@type': 'CreativeWork', 'name': 'The New Yorker'}",True,"Sheelah Kolhatkar writes about the findings of a new Brookings Institution study, which determined that certain higher-wage occupations might be more deeply intertwined with A.I. technology in the future than previously thought.",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vdGhlaGlsbC5jb20vb3Bpbmlvbi9oZWFsdGhjYXJlLzQ3ODY1MS1kYW5nZXJzLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLW1lZGljaW5lL9IBYWh0dHBzOi8vdGhlaGlsbC5jb20vb3Bpbmlvbi9oZWFsdGhjYXJlLzQ3ODY1MS1kYW5nZXJzLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLW1lZGljaW5lL2FtcC8?oc=5,Dangers of artificial intelligence in medicine - The Hill,2020-01-16,The Hill,https://thehill.com,Health-care is an industry in need of AI assistance due to a shortage of doctors and physician burnout.,N/A,Health-care is an industry in need of AI assistance due to a shortage of doctors and physician burnout.,Health-care is an industry in need of AI assistance due to a shortage of doctors and physician burnout.,,https://schema.org,NewsArticle,N/A,N/A,"




Opinion>Healthcare

			The views expressed by contributors are their own and not the view of The Hill		

		Dangers of artificial intelligence in medicine	


			by Enid Montague, opinion contributor - 01/16/20 6:00 PM ET






Facebook





Share







Post



 
		





...


More





			by Enid Montague, opinion contributor - 01/16/20 6:00 PM ET











Facebook





Share







Post



 
		





...


More







Share
✕







Twitter




Twitter







Facebook





Facebook







LinkedIn




						LinkedIn					







Whatsapp







						Whatsapp					







Email




						Email					














Getty Images









Two of the most significant predictions for the new decade are that AI will become more pervasive, and the U.S. health-care system will need to evolve. AI can augment and improve the health-care system to serve more patients with fewer doctors. 
However, health innovators need to be careful to design a system that enhances doctors’ capabilities, rather than replace them with technology and also to avoid reproducing human biases.
A recent study published in Nature (in collaboration with Google) reports that Google AI detects breast cancer better than human doctors. Babylon Health, the AI-based mobile primary care system implemented in the United Kingdom in 2013, is coming to the U.S. 
Health-care is an industry in need of AI assistance due to a shortage of doctors and physician burnout. 
Doctors in the U.S. are experiencing a burnout crisis. Nearly 45 percent of physicians report burnout, and the physician suicide rate is twice that of the general population. Research shows physicians experience burnout because of a poorly designed health care system that isn’t intended to protect them or their patients. 
Physician burnout has been linked to increased medical errors, unprofessional behavior, early retirement, depression, and racial bias. 
In 2019 the Journal of the American Medical Association published a study of 3,392 second-year resident physicians who self-identified as non-Black and found that symptoms of burnout were associated with explicit and implicit racial biases. 
A study from the Mayo clinic reported poorly designed electronic health records as a contributor to physician burnout. 
Another major contributor to burnout is a shortage of physicians compared to the increased number and needs of patients that require care. The Association of American Medical Colleges predicts a shortage of 21,100 and 55,200 primary care physicians by 2032. 
While a possible solution, AI systems can also cause problems. Increased medical error is a real potential consequence of poorly designed AI in medicine. 
Medical error is the third leading cause of death in the U.S., attesting to both the need for improving the system but also the fragility of the system and consequences of poor design. 
Eliminating the empathetic relationship is another potential consequence of poorly designed and integrated AI. Health care is built on a human-human link. 
Humans desire and benefit from the problem-solving that comes from conversations. In clinics with electronic health records, physicians spend about 27 percent of their time on patient care and 52 percent time in the exam room interacting with the patient. 
 
Replacing humans with technology inappropriately could lead to complacency from physicians and reduced engagement from patients.
AI could lead to new inequities and biases. Recent studies have shown that Black people are less likely to get proper treatment for lung cancer and adequate treatment for pain because of false beliefs about differences between Blacks and whites. 
While some may conclude that AI would remove the biases that minorities receive by focusing on objective data, new research identifies inequities in AI systems. 
A study published in Science in 2019 found that an algorithm used in U.S. hospitals systematically discriminated against Black patients by allocating less care to them.
Babylon’s AI-based chatbot sparked concerns as the chatbots’ safety has been reported; Babylon refutes these claims. 
Many of the disruptive aspects of the AI system are unique to the National Health Service, which assigns patients to practitioners. With new funding and support, Babylon will enter the U.S. market. Health safety advocates need to be available to advocate for the unique needs of patients in the American health-care system. 
For AI systems to work without harm, a greater understanding of what clinicians do and their current biases is needed. The goal of designing systems that preserves what clinicians do best without the risk of complacency is critical. 
Both tech companies and health leadership are primarily comprised of white male staff that may not be trained to think about bias comprehensively. Diversifying the workforce of companies building AI systems and those innovating the health-care system is needed. 
A recent report found that people of color and women are underrepresented in the AI field, as about 80 percent of AI professors are men, and people of color are only a fraction of staff at major tech companies. 
Diversifying the pipeline of researchers is essential; equally important is building inclusive workplaces and communities that allow under-represented minority researchers to thrive. 
Yes, well-designed AI in health-care systems can transform the health and well-being of members of society by allowing healthcare professionals to provide better quality care to more people and restoring balance to the people who dedicate their lives to providing care. 
But the danger is that AI systems that pit humans against algorithms will likely introduce new biases and errors into the U.S. health-care system that will not only exacerbate health disparities but also make health care more dangerous for everyone. 
Enid Montague, Ph.D. is an expert on human-centered automation in medicine, Associate Professor of Computing at DePaul University, Adjunct Associate Professor of General Internal Medicine at Northwestern University, and a Public Voices Fellow through The OpEd Project.




Tags 

		Artificial intelligence		

		Electronic health record		

		Health		

		Health equity		

		health system		

		Medical error		

		Physicians		

		Primary care physician		



Copyright 2024 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.






Facebook





Share







Post



 
		





...


More







Share
✕







Twitter




Twitter







Facebook





Facebook







LinkedIn




						LinkedIn					







Whatsapp







						Whatsapp					







Email




						Email					







SPONSORED CONTENTPrivacy PolicyPrivacy PolicyAmazon's Worst Nightmare: Thousands Canceling Prime for This Clever HackOnline Shopping Tools | SponsoredSponsoredUndoThis Dad Decimated 10,000 Bed Bugs From His Kid's Bed After Pushing 1 ButtonHaloClean UV Sanitizer | SponsoredSponsoredUndoThese New Shoes Are Leaving Neuropathy Experts BaffledBarestep | SponsoredSponsoredUndoAmazon's Worst Nightmare: Millions Cancelling Prime (It's Unbelievable)Online Shopping Tools | SponsoredSponsoredUndoHere’s The Average Cost Of Gutter Guards For Smaller HomesHomeBuddy | SponsoredSponsoredLearn MoreUndoThis New AC Cooler Cools the Room In SecondsSherum | SponsoredSponsoredLearn MoreUndoHere's What a New Roof Should Cost You In 2024Homebuddy | SponsoredSponsoredLearn MoreUndoVirginia Launches New Coverage for Cars Used Less Than 50 Miles/DayCar Insurance Discount | SponsoredSponsoredRead MoreUndo2 Cards Charging 0% Interest Until Nearly 2026CompareCredit | SponsoredSponsoredUndo7 Wealth Tips Once Your Portfolio Reaches $1 MillionFisher Investments | SponsoredSponsoredLearn MoreUndoPlace an Ice Cube on a Burger When Grilling, Here's WhyLifeHackGuru | SponsoredSponsoredUndoScientists: If You Have Bed Bugs, Try This Trick TonightHaloClean UV Sanitizer | SponsoredSponsoredUndoOnly Needs a Super-Light Touch to Instantly Cut Even the Toughest Toenail.Toenail Clipper | SponsoredSponsoredLearn MoreUndoVirginia: Big Changes Near Chantilly Leaves Drivers FumingPenny Pincher | SponsoredSponsoredRead MoreUndoHere's What a New Roof Should Cost You In 2023HomeBuddy | SponsoredSponsoredLearn MoreUndoHere's The Average Price Of Gutter Protection For Houses In The USHomeBuddy | SponsoredSponsoredLearn MoreUndoHow Long Will $1M Last in Retirement?SmartAsset | SponsoredSponsoredLearn MoreUndo








				More Healthcare News			



							See All						












				Opinion			




			The medical community must stop gaslighting COVID vaccine victims like me 			








				by Shaun Barcavage, opinion contributor 			


						2 days ago		





					Opinion				


				 / 
			

									2 days ago							













				Healthcare			




			The real reason drug costs are so high in America 			








				by Paul Alexander, opinion contributor  			


						2 days ago		





					Healthcare				


				 / 
			

									2 days ago							













				Healthcare			




			Gender-distressed youth deserve the truth about the science			








				by Lisa Selin Davis, opinion contributor			


						5 days ago		





					Healthcare				


				 / 
			

									5 days ago							













				Healthcare			




			Why has Medicare’s Innovation Center failed?			








				by Chris Pope, opinion contributor			


						5 days ago		





					Healthcare				


				 / 
			

									5 days ago							








				See All			




 







		Video/Hill.TV	



					See all Hill.TV				



					See all Video				












				Rising			



			Rising: July 16, 2024		







				by TheHill.com			


						07/16/24 1:15 PM ET		





					Rising				


				 / 
			

									7 mins ago							













				Rising			




			Rising: July 15, 2024			








				by TheHill.com			


						1 day ago		





					Rising				


				 / 
			

									1 day ago							













				Rising			




			Rising: July 12, 2024			








				by TheHill.com			


						3 days ago		





					Rising				


				 / 
			

									4 days ago							








			See all Hill.TV		



			See all Video		




 







				Top Stories			



							See All						












				Court Battles			




			Menendez convicted over bribery, foreign agent charges			








				by Ella Lee 


						19 mins ago		





					Court Battles				


				 / 
			

									19 mins ago							








				See All			








  







		Most Popular	



					Trump follows Biden remarks with 2-word post				



					Former US attorney: Cannon’s dismissal ‘blessing in disguise’ for Jack ...				



					5 notable moments from Biden’s interview with NBC’s Lester Holt				



					Van Jones: Amber Rose RNC speech ‘most dangerous’ for Democrats				



					Axelrod: Vance’s post on Trump rally shooting ‘ought to disqualify him’ 				



					Menendez convicted over bribery, foreign agent charges				



					Kinzinger says JD Vance’s response to shooting should ‘disqualify’ him ...				



					Trump leading Biden in all 7 major swing states: Polling				



					Former federal prosecutor: Cannon dismissal of Trump documents case 'simply ...				



					RFK Jr. apologizes after call with Trump was leaked				



					Here are the 10 states with the poorest quality of life				



					Jack Black cancels Tenacious D tour after partner’s Trump shooting joke				



					Secret Service faces fresh scrutiny over Trump assassination attempt				



					4 things to know about the Houston power crisis				



					Only an ‘October Surprise’ can swing the presidential election				



					Bet on Nancy Pelosi to show Joe Biden the door				



					Scaramucci: Vance ‘first obvious error’ of Trump campaign since winning ...				



					50 Cent ‘will not be attending’ convention after viral Trump rally reaction				



		Load more	






  










  


","{'@type': 'WebPage', '@id': 'https://thehill.com/opinion/healthcare/478651-dangers-of-artificial-intelligence-in-medicine/'}",The Hill,2020-01-16T23:00:11+00:00,2020-01-16T23:00:02+00:00,,"{'@type': 'Organization', 'name': 'The Hill'}","{'@type': 'ImageObject', 'url': 'https://thehill.com/wp-content/uploads/sites/2/2018/08/artificialintelligence_82118getty.jpg'}","[{'@type': 'Person', 'name': 'Enid Montague, opinion contributor', 'url': ''}]",,,,,https://thehill.com/opinion/healthcare/478651-dangers-of-artificial-intelligence-in-medicine/,,,,,Healthcare,Dangers of artificial intelligence in medicine,,,,,"{'@type': 'SearchAction', 'target': 'https://thehill.com/search/{search_term_string}/', 'query-input': 'required name=search_term_string'}","['Healthcare', 'Opinion']",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiiwFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Fsb256b21hcnRpbmV6LzIwMjAvMDEvMTYvYWktdG8tZGF0YS1wcml2YWN5LWhvdy1oaXJpbmctdG9vbHMtYW5kLXRyZW5kcy13aWxsLWRyaXZlLXdvcmtwbGFjZS1jaGFuZ2VzLWluLTIwMjAv0gEA?oc=5,AI To Data Privacy: How Hiring Tools And Trends Will Drive Workplace Changes In 2020 - Forbes,2020-01-16,Forbes,https://www.forbes.com,Tremendous shifts in the workplace are driving significant changes in recruiting and hiring as employers attempt to find qualified candidates in today’s highly competitive labor market.  Here’s what employers must keep in mind in 2020.,"AI,Artificial Intelligence,Data Privacy,Gig Economy,Gig Worker,CCPA,Biometrics,Recruiting Trends,Recruiting,2020,HireRight,Forbes",Tremendous shifts in the workplace are driving significant changes in recruiting and hiring as employers attempt to find qualified candidates in today’s highly competitive labor market.  Here’s what employers must keep in mind in 2020.,Tremendous shifts in the workplace are driving significant changes in recruiting and hiring as employers attempt to find qualified candidates in today’s highly competitive labor market.  Here’s what employers must keep in mind in 2020.,,http://schema.org,BreadcrumbList,Careers,N/A,"More From ForbesJul 16, 2024,12:00pm EDT5 Strategies For Overcoming Procrastination In Summer TimeJul 16, 2024,12:00pm EDTHow To Use Writing As A Tool To Grow Your Personal BrandJul 16, 2024,12:00pm EDT10 Ways To Build Career Resilience And Handle Whatever Comes Your WayJul 16, 2024,12:00pm EDTNew Study Reveals The Toll NDAs Impose On Harassment And Discrimination VictimsJul 16, 2024,12:00pm EDTHow To Avoid Leadership Hubris: Your Long-Term Success Is At StakeJul 16, 2024,11:00am EDT5 Things You DO NOT Want To Say In Your Next Job InterviewJul 16, 2024,06:00am EDTHow To Find Freelance Writing Jobs In 2024Edit StoryForbesLeadershipCareersEditors' PickAI To Data Privacy: How Hiring Tools And Trends Will Drive Workplace Changes In 2020Alonzo MartinezSenior ContributorOpinions expressed by Forbes Contributors are their own.I provide a concise analysis of legal issues affecting employers.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itJan 16, 2020,12:00pm ESTUpdated Jan 16, 2020, 02:23pm ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinDignitaries address artificial intelligence learning and data.  Photo: Annette Riedl/dpa (Photo by ... [+] Annette Riedl/picture alliance via Getty Images)dpa/picture alliance via Getty Images
Tremendous shifts in the workplace are driving significant changes in recruiting and hiring as employers attempt to find qualified candidates in today’s highly competitive labor market.

For example, employers are more often turning to technology to reduce time-to-hire and build applicant-friendly hiring practices. According to HireRight’s 2019 “Employment Screening Benchmark Report,” 32% of employers have deployed mobile-friendly applications and screening processes to make it easier for candidates.


At the same time, with today’s ongoing labor shortage, companies are looking for new ways to find talent, including hiring more non-traditional employees such as contract, temporary, and contingent workers. 

But these new processes and policies raise critical legal questions and are triggering new laws to protect workers and guide employers. Here’s what employers must keep in mind in 2020.

Artificial Intelligence and Biometrics
PROMOTED
According to HireRight’s Benchmark Report, 25% of human resources professionals believe artificial intelligence (AI) holds big benefits for recruiting in the future.
Already, many deploy AI tools to manage recruitment. Video interview platforms on the market, for example, use AI to evaluate a job seeker’s facial expressions and how they answer questions during a recorded interview. The tools then recommend the best applicants to move forward for consideration.
But not everybody is cheering these solutions. Because of the way the tools are built, critics believe AI could make employment discrimination worse, reflecting “institutional and systemic biases,” according to a report from Upturn, a public advocacy research group.
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report Says
And lawmakers are starting to take notice. In 2019, Illinois lawmakers passed the Artificial Intelligence Video Interview Act, which took effect on January 1. If employers use AI to evaluate applicant-submitted videos, they must alert candidates that AI may be used, give them information about how the technology works and get their consent.









CxO
US


CEO: C-suite news, analysis, and advice for top decision makers right to your inbox.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the CEO newsletter!


                More Newsletters
            


You’re all set! Enjoy the CEO newsletter!

                More Newsletters
            



Federal legislators also are wading into the debate. The Algorithmic Accountability Act of 2019 was introduced in April and, if approved, would govern how AI and related tools are used. California lawmakers are taking a different tack. The California Assembly Concurrent Resolution No. 125 encourages the use of AI to eliminate bias and discrimination in hiring. Both measures could be up for debate in 2020, along with other proposals that may pop up across the country. 


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
Meanwhile, as employers collect scads of information about job applicants and employees, they also could run afoul of laws that control the use of biometric data, which includes fingerprints and scans of facial features that are commonly used in AI. Illinois is again a leader here with its Biometric Information Privacy Act, which guides the collection and use of such data. Texas and Washington also have biometrics laws. More states are expected to jump on the “biometric bandwagon,” according to The National Law Review.
That means that in 2020, employers must not only track new AI and biometrics laws but be careful as they implement AI solutions and build alternatives for job seekers who opt-out.
Data Privacy
Just as employers must be cautious with biometric information, they also must pay more attention to other personal data they collect as states begin to roll out data privacy laws
The new California Consumer Privacy Act covers companies with gross annual revenues of more than $25 million; who buy, receive or sell personal information of 50,000 or more consumers, households or devices; or who earn 50% or more of their annual revenue from selling consumers’ personal information.
Starting this month, these employers must provide privacy notices to employees about the information they gather and maintain reasonable security measures to protect it, among other requirements.
In New York, employers soon must comply with the Stop Hacks and Improve Electronic Data Security Act, or SHIELD Act, which requires companies that employ New York residents to take steps to safeguard employees’ private information. It takes effect on March 21, 2020.
And it’s likely this is just the beginning for data privacy in the United States. In 2019, New York lawmakers debated a proposed New York Privacy Act, which is similar to California’s law. In 2020 and beyond, more lawmakers will bring data privacy measures to the table.
Worker Classification
The gig economy is expected only to continue to grow in 2020 as employers look to independent contractors to find the qualified talent they need. One survey by BCG Henderson Institute, in partnership with Harvard Business School’s Managing the Future of Work initiative, found that about 40% of corporate executives believe that freelancers will take up a bigger share of their company’s workforce through 2023.
But some state lawmakers are cracking down on companies that are increasingly relying on freelancers to do the work instead of hiring salaried employees, who typically can take advantage of benefits such as workers’ compensation, health insurance, and paid time off.
Effective January 1, California’s Assembly Bill 5 outlines guidelines for employers to follow to determine if a worker should be classified as an employee or an independent contractor. Independent contractors, according to the law, must be free from any control or direction of the employer; complete work that is “outside the usual course” of the employer’s business; and take part in an “independently established trade, occupation, or business.”
Lawmakers in New Jersey and New York are debating similar laws. In 2020, it’s likely we’ll see more states consider worker classification regulations.
Other new laws affecting recruitment and hiring are likely to come down the pike in 2020, covering marijuana accommodations, criminal records checks, and pay equity. And that means that as the new decade opens, employers must be mindful of not only the latest tools and trends in hiring but the newest compliance requirements too.
Follow me on LinkedIn. Check out my website. Alonzo MartinezFollowingFollowI am Associate General Counsel at HireRight, the world's largest provider of background check services. I am responsible for monitoring and... Read MoreEditorial StandardsPrintReprints & PermissionsThe video player is currently playing an ad. You can skip the ad in 5 sec with a mouse or keyboard
1/100:11Boston Dynamics Founder On The Need For AI And Hardware In Robotics Research





Skip Ad
 
Continue watchingBoston Dynamics Founder On The Need For AI And Hardware In Robotics Researchafter the adVisit Advertiser websiteGO TO PAGEPause (SPACE)",,AI To Data Privacy: How Hiring Tools And Trends Will Drive Workplace Changes In 2020,2020-01-16T12:00:00-05:00,2020-01-16T14:23:02-05:00,,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/1193887587/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Alonzo Martinez', 'url': 'https://www.forbes.com/sites/alonzomartinez/', 'description': ""I am Associate General Counsel at HireRight, the world's largest provider of background check services. I am responsible for monitoring and advising on key litigation, legislation, and regulatory developments that affect employment. As social causes such as fair chance hiring, pay equity, marijuana legalization, privacy, and the #MeToo movement evolve, employers are subject to constantly changing compliance obligations. My mission is to help organizations easily understand these complex issues by hosting webinars supported by white papers, infographics, eBooks, blogs and other materials to help ensure organizations are kept current with actionable information. I am a member of the Professional Background Screening Association, Association of Corporate Counsel, and Colorado Bar Association Employment Law Division."", 'sameAs': ['https://www.linkedin.com/in/alonzo-martinez-80a40a90/', 'https://www.hireright.com/resource-library']}",,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Leadership', 'item': 'https://www.forbes.com/leadership/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Careers', 'item': 'https://www.forbes.com/careers/'}]",https://www.forbes.com/sites/alonzomartinez/2020/01/16/ai-to-data-privacy-how-hiring-tools-and-trends-will-drive-workplace-changes-in-2020/,,,,,Careers,AI To Data Privacy: How Hiring Tools And Trends Will Drive Workplace Changes In 2020,,,False,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvYXV0b21hdGlvbi1hbmQtbGFib3ItbWFya2V0LWluc3RpdHV0aW9ucy_SAQA?oc=5,Automation and labor market institutions | Brookings - Brookings Institution,2020-01-14,Brookings Institution,https://www.brookings.edu,"Marcus Casey summarizes the key findings from the papers presented at the December 12, 2019, conference on “Automation, Labor Market Institutions, and the Middle Class.”",N/A,"Marcus Casey summarizes the key findings from the papers presented at the December 12, 2019, conference on “Automation, Labor Market Institutions, and the Middle Class.”",N/A,,https://schema.org,,N/A,N/A,"

 Back to Janesville 









                        Back to Janesville 
",,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/automation-and-labor-market-institutions/', 'url': 'https://www.brookings.edu/articles/automation-and-labor-market-institutions/', 'name': 'Automation and labor market institutions | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/automation-and-labor-market-institutions/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/automation-and-labor-market-institutions/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2020/01/shutterstock_1087923140.jpg?quality=75', 'datePublished': '2020-01-14T14:35:48+00:00', 'dateModified': '2022-03-09T04:43:09+00:00', 'description': 'Marcus Casey summarizes the key findings from the papers presented at the December 12, 2019, conference on “Automation, Labor Market Institutions, and the Middle Class.”', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/automation-and-labor-market-institutions/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/automation-and-labor-market-institutions/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/automation-and-labor-market-institutions/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2020/01/shutterstock_1087923140.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2020/01/shutterstock_1087923140.jpg?quality=75', 'width': 7999, 'height': 4000, 'caption': ''}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/automation-and-labor-market-institutions/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Automation and labor market institutions'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vYmVjb21pbmdodW1hbi5haS9yZXZpZXdzLW9uLXRvcC1haS1mcmVlLWNvdXJzZXMtdGhhdC1pdmUtdGFrZW4tNzBlNTA3MjQ4ZjY00gEA?oc=5,Reviews on top AI free courses that I've taken - Becoming Human: Artificial Intelligence Magazine,2020-01-13,Becoming Human: Artificial Intelligence Magazine,https://becominghuman.ai,Last year I’ve decided to get past the artificial intelligence buzzwords from the media articles and really have a clue about the subject. The more research I made the more I got intrigued and…,N/A,Last year I’ve decided to get past the artificial intelligence buzzwords from the media articles and really have a clue about the subject.,Last year I’ve decided to get past the artificial intelligence buzzwords from the media articles and really have a clue about the subject.,,http://schema.org,NewsArticle,N/A,N/A,"Reviews on top AI free courses that I’ve takenAlin Rauta·FollowPublished inBecoming Human: Artificial Intelligence Magazine·6 min read·Jan 13, 20201071ListenShareLast year I’ve decided to get past the artificial intelligence buzzwords from the media articles and really have a clue about the subject.The more research I made the more I got intrigued and interested in AI. It baffled me how much AI will impact our lives and I realised this is the field I want to be in.So, I began searching for learning resources and immersed myself into all kinds of AI related material. This was a normal thing to do since I taught myself how to code and I figured that I can also teach myself at least the basic of AI.After a few months of taking courses, I will give you my opinion on the most useful free courses I have taken, the ones I’m in progress of finishing and as a bonus the ones I intend to take in the future.Courses I’ve takenIntro to Artificial IntelligenceAbout the courseIt’s a classic on AI and it happened to be the first course I’ve ever taken on the subject. It’s a comprehensive course that gives you just the right amount of information about all the branches and sub-branches that AI is made of.Trending AI Articles:1. Making a Simple Neural Network2. Google will beat Apple at its own game with superior AI3. The AI Job Wars: Episode I4. Artificial Intelligence ConferenceAbout the teachersThe course is taught by two of the greatest advocates of AI:Sebastian Thrun: a former associate professor at Stanford University, co-founder of Udacity, led the team that won the 2005 DARPA Grand Challenge and co-developed Street View at Google.Peter Norvig: a director of research at Google and co-author of the leading college text in the field — Artificial Intelligence: A modern ApproachConclusionI can’t recommend it enough. It’s definitely a must.Elements of AIAbout the courseThis is a text based course and the aspect I loved the most about it was the fact that it makes you ponder about the role artificial intelligence is going to have in your life. I like the structure of the course and how quickly you can check if you really understood something by taking a quiz.About the teachersIt’s created by Reaktor and the University of Helsinki. It’s part of an initiative that wants to encourage as broad a group of people as possible to learn about AI. The goal is to make the course available in all EU languages.ConclusionIt’s a quick and engaging course to take to get the very basics on AI.Neural Networks and Deep LearningAbout the courseThis one is a bit more advanced in terms of knowledge you gain after its completion and it’s part of a series of courses on deep learning. I like the fact that it’s not getting too technical and you can easily get to understand more advanced nuances tools that are being used in AI, more exactly — deep learning.About the teachersThe course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.ConclusionIt’s the kind of course you need to take if you’re serious about learning AI.Improving Deep Neural NetworksAbout the courseThis is more of a sequel of the previous course and the purpose is to get your knowledge of deep learning one step further. This is where the magic happens in deep learning because it’s more of an empirical process (trial and error) and you need to get a deeper (yeah, that’s a pun) understanding before you know what parameters to tweak.About the teachersThe course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.ConclusionYou really need to take this course if you already had taken the previous one.Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep LearningAbout the courseTensorFlow is an open source platform for machine learning and this course is about teaching you how to use TensorFlow in your AI applications. As a coder I really enjoyed this course because it has less theory and more practice into it.About the teachersThe course is taught by Laurence Moroney who is an AI advocate at Google and also part of the TensorFlow team. For me, he is one of the best teachers I’ve ever seen.ConclusionIt’s a friendly course for beginners and with lots of hands-on activities.In ProgressConvolutional Neural NetworksAbout the courseThis course touches the concept of computer vision and builds on the knowledge acquired in the previous two courses from the series. I can’t wait to finish it and get more understanding of the computer vision field.About the teachersThe course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.Convolutional Neural Networks in TensorFlowAbout the courseThis is a sequel of Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning course that I’ve already taken and things get even more practical in terms of coding which makes it highly appealing for coders.About the teachersThe course is taught by Laurence Moroney who is an AI advocate at Google and also part of the TensorFlow team. For me, he is one of the best teachers I’ve ever seen.Machine LearningAbout the courseThis is probably the reference course on Machine Learning. It’s by far the longest and the most technical one from all the courses I’ve taken. I believe it’s worth the effort of finishing the course if you are serious about getting a job in AI.About the teachersThe course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.Courses I intend to take (BONUS)Learn AI With An AIThis seems really interesting and it’s the next one on my list.Introduction to Computer VisionThis course is a great companion for the Intro to Artificial Intelligence course and I hope it will broaden my knowledge on computer vision.Machine Learning Crash CourseThis one puts more emphasis on the technical side and it’s a good fit after you dabbled with TensorFlow.Intro to Data ScienceOne of the most host jobs in the world right now is the Data Scientist, so I think it’s really useful to have an idea about the field, which intersects with AI.I hope these reviews will be useful for you and I can’t wait to hear your feedback or the experiences you had with other AI courses.If you liked this article and want to see more of these, then follow me on twitter.P.S. I’m an indie maker and I’m writing a book on the basics of AI. If you want to support me and you’re interested in AI, then you can pre-order my book at a discount here (you won’t get charged until I finish the book): https://gumroad.com/l/SXpw/sideprojectDon’t forget to give us your 👏 !",https://becominghuman.ai/reviews-on-top-ai-free-courses-that-ive-taken-70e507248f64,Reviews on top AI free courses that I’ve taken - Becoming Human: Artificial Intelligence Magazine,2020-01-13T15:04:01.700Z,2021-12-13T06:01:35.985Z,,"{'@type': 'Organization', 'name': 'Becoming Human: Artificial Intelligence Magazine', 'url': 'becominghuman.ai', 'logo': {'@type': 'ImageObject', 'width': 146, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:292/1*1fYpRTTpKQNa0zuEPe3itg.png'}}",['https://miro.medium.com/v2/resize:fit:1200/1*rrdn9aNBOceWrJh70ODUJQ.jpeg'],"{'@type': 'Person', 'name': 'Alin Rauta', 'url': 'https://becominghuman.ai/@RautaAlin'}",,,,,https://becominghuman.ai/reviews-on-top-ai-free-courses-that-ive-taken-70e507248f64,2020-01-13T15:04:01.700Z,,,,,Reviews on top AI free courses that I’ve taken - Becoming Human: Artificial Intelligence Magazine,,,,,,,70e507248f64,['Alin Rauta'],,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS93aHktbGVhcm4tZGF0YS1zY2llbmNlLWluLTIwMjAtZDNmNTQxMjNiMmU00gEA?oc=5,Why learn Data Science in 2020?. Why now? Can I really build a career in… | by James Thorn - Towards Data Science,2020-01-16,Towards Data Science,https://towardsdatascience.com,"Data Science. Big Data. Machine Learning. Artificial Intelligence. These are all powerful pairs of words. Let's see with real studies, numbers, and images why you should consider learning about any…",N/A,Why now? Can I really build a career in this field?,Why now? Can I really build a career in this field?,,http://schema.org,NewsArticle,N/A,N/A,"Member-only storyWhy learn Data Science in 2020?Why now? Can I really build a career in this field?James Thorn·FollowPublished inTowards Data Science·6 min read·Jan 16, 20201081ListenShareImage from Unsplash.comData Science. Big Data. Machine Learning. Artificial Intelligence. These are all powerful pairs of words. Let's see with real studies, numbers, and images why you should consider learning about any of them.Why learn Data Science or Machine Learning?Data Science has been defined as ‘The Sexiest Job of the 21st Century’ by Harvard Business Review. Glassdoor, a world-known website for job seeking, ranked Data Science as the best job in America for 2019. Bloomberg regards Data Scientists as the new Superheroes.Data Scientists, Machine Learning Engineers, Data Engineers; all of these titles have two things in common: they are some of the most attractive professions at the moment, and they all imply dealing with Data.- The demand -These are roles whose demand has greatly increased in the recent years, and most likely will only continue to do so, like shown in the following figure.Increase in the demand for Data Scientists in the recent years. Source top. Source bottom.",https://towardsdatascience.com/why-learn-data-science-in-2020-d3f54123b2e4,Why learn Data Science in 2020? - Towards Data Science,2020-01-16T15:03:37.033Z,2021-12-13T05:59:39.916Z,,"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",['https://miro.medium.com/v2/resize:fit:1200/1*7zKjE0bIN7pzZaU_y5558Q.jpeg'],"{'@type': 'Person', 'name': 'James Thorn', 'url': 'https://james-thorn.medium.com'}",,,,,https://towardsdatascience.com/why-learn-data-science-in-2020-d3f54123b2e4,2020-01-16T15:03:37.033Z,,,,,Why learn Data Science in 2020? - Towards Data Science,,,False,,,,d3f54123b2e4,['James Thorn'],"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3LmphcGFudGltZXMuY28uanAvbmV3cy8yMDIwLzAxLzE0L2FzaWEtcGFjaWZpYy9zb2NpYWwtaXNzdWVzLWFzaWEtcGFjaWZpYy9zb3V0aC1rb3JlYXMtYWktaGlyaW5nLWJvdHMv0gEA?oc=5,'Smile with your eyes': How to beat South Korea's AI hiring bots and land a job - The Japan Times,2020-01-14,The Japan Times,https://www.japantimes.co.jp,"In cram school-obsessed South Korea, students fork out for classes in everything from K-pop auditions to real estate deals. Now, as top Korean firms roll out artificial intelligence in hiring, job seekers want to learn how to beat the bots.","tech,privacy,Jobs,South Korea,facial recognition,AI","In cram school-obsessed South Korea, students fork out for classes in everything from K-pop auditions to real estate deals. Now, as top Korean firms roll out artificial intelligence in hiring, job seekers want to learn how to beat the bots.","In cram school-obsessed South Korea, students fork out for classes in everything from K-pop auditions to real estate deals. Now, as top Korean firms roll out artificial intelligence in hiring, job seekers want to learn how to beat the bots.",,https://schema.org,NewsArticle,ASIA PACIFIC,N/A,N/A,"{'@type': 'WebPage', '@id': 'https://www.japantimes.co.jp/news/2020/01/14/asia-pacific/social-issues-asia-pacific/south-koreas-ai-hiring-bots/'}",,1970-01-01T09:00:00+09:00,2020-01-14T07:10:57+09:00,,"{'@type': 'Organization', 'name': 'The Japan Times', 'url': 'https://www.japantimes.co.jp/', 'sameAs': ['https://twitter.com/japantimes', 'https://www.facebook.com/thejapantimes', 'https://www.instagram.com/thejapantimes/?hl=en', 'https://www.linkedin.com/company/the-japan-times'], 'logo': {'@type': 'ImageObject', 'url': '/theme_japantimes/images/logo.svg', 'width': 270, 'height': 57}}","{'@type': 'ImageObject', 'url': 'https://www.japantimes.co.jp/uploads/imported_images/uploads/2020/01/f-facerecog-a-20200115.jpg'}","[{'@type': 'Person', 'name': 'Sangmi Cha'}]",,,"SEOUL - In cram school-obsessed South Korea, students fork out for classes in everything from K-pop auditions to real estate deals. Now, as top Korean firms roll out artificial intelligence in hiring, job seekers want to learn how to beat the bots.From his basement office in downtown Gangnam, career consultant Park Seong-jung is among those in a growing business of offering lessons on how to handle recruitment screening by computers instead of people. Video interviews using facial recognition technology to analyze character are key, according to Park.'Don't force a smile with your lips,' he told students looking for work in a recent session, one of many he said he has conducted for hundreds of people. 'Smile with your eyes.'",,https://www.japantimes.co.jp/news/2020/01/14/asia-pacific/social-issues-asia-pacific/south-koreas-ai-hiring-bots/,1970-01-01T09:00:00+09:00,,,,ASIA PACIFIC,'Smile with your eyes': How to beat South Korea's AI hiring bots and land a job,https://www.japantimes.co.jp/uploads/imported_images/uploads/2020/01/f-facerecog-a-20200115.jpg,,,,,,,,,en,"{'@type': 'Organization', 'name': 'The Japan Times', 'url': 'https://www.japantimes.co.jp/'}",,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vd3d3LmNubi5jb20vMjAyMC8wMS8xNS90ZWNoL2FpLWpvYi1pbnRlcnZpZXcvaW5kZXguaHRtbNIBQ2h0dHBzOi8vYW1wLmNubi5jb20vY25uLzIwMjAvMDEvMTUvdGVjaC9haS1qb2ItaW50ZXJ2aWV3L2luZGV4Lmh0bWw?oc=5,There's a new obstacle to landing a job after college: Getting approved by AI - CNN,2020-01-15,CNN,https://www.cnn.com,"College career centers used to prepare students for job interviews by helping them learn how to dress appropriately or write a standout cover letter. These days, they’re also trying to brace students for a stark new reality: They may be vetted for jobs in part by artificial intelligence.","artificial intelligence, business and industry sectors, business, economy and trade, computer science and information technology, education, education systems and institutions, employment interviews, employment search, higher education, hiring, human resources and personnel management, labor and employment, students and student life, technology, college students, demographic groups, population and demographics, society, apprenticeships and internships, workers and professionals","College career centers used to prepare students for job interviews by helping them learn how to dress appropriately or write a standout cover letter. These days, they’re also trying to brace students for a stark new reality: They may be vetted for jobs in part by artificial intelligence.","College career centers used to prepare students for job interviews by helping them learn how to dress appropriately or write a standout cover letter. These days, they’re also trying to brace students for a stark new reality: They may be vetted for jobs in part by artificial intelligence.",,https://schema.org,NewsArticle,N/A,N/A,"






















Video Ad Feedback



How AI is changing the way we work
                


                                01:11
                            
 - Source:
                CNN Business
    








Artificial Intelligence
16 videos














Video Ad Feedback



Long before ChatGPT, these online chat bots were already talking to humans
                




                                01:53
                            
Now playing
 - Source:
                CNN














Video Ad Feedback



How AI is changing the way we work
                




                                01:11
                            
Now playing
 - Source:
                CNN Business
    














Video Ad Feedback



CNN tried an AI flirt app. It was shockingly pervy
                




                                03:19
                            
Now playing
 - Source:
                CNN Business















Video Ad Feedback



CNN reporter calls his parents using AI voice. Watch what happens next
                




                                05:47
                            
Now playing
 - Source:
                CNN Business















Video Ad Feedback



These 'news anchors' are created by AI and they're spreading misinformation in Venezuela
                




                                03:29
                            
Now playing
 - Source:
                CNN Business















Video Ad Feedback



Tech expert weighs in on viral AI-generated photo of the Pope
                




                                03:28
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Hear why this teacher says schools should embrace ChatGPT, not ban it
                




                                01:29
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



See what it's like to use Bing's new AI search feature
                




                                02:09
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Scott Galloway on the 'scarier part' of AI tools like ChatGPT
                




                                02:07
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Dovrat: ChatGPT will change the way we do business
                




                                03:11
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Journalist says he had a creepy encounter with new tech that left him unable to sleep
                




                                03:28
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



He loves artificial intelligence. Hear why he is issuing a warning about ChatGPT
                




                                04:38
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Eric Schmidt: AI is not ready to make profound decisions
                




                                04:49
                            
Now playing
 - Source:
                CNNBusiness
    














Video Ad Feedback



Expert warns new AI chatbot could lead to 'nightmare scenario'
                




                                02:52
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



Chinese companies are hiring AI-employees
                




                                05:14
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



He's sold over 50m records and now he's using AI to create music
                




                                02:51
                            
Now playing
 - Source:
                CNN Business















Video Ad Feedback



Long before ChatGPT, these online chat bots were already talking to humans
                




                                01:53
                            
Now playing
 - Source:
                CNN















Video Ad Feedback



How AI is changing the way we work
                




                                01:11
                            
Now playing
 - Source:
                CNN Business
    




See More Videos


















San Francisco
CNN
         — 
    


            College career centers used to prepare students for job interviews by helping them learn how to dress appropriately or write a standout cover letter. These days, they’re also trying to brace students for a stark new reality: They may be vetted for jobs in part by artificial intelligence.
    

            At schools such as Duke University, Purdue University, and the University of North Carolina at Charlotte, career counselors are now working to find out which companies use AI and also speaking candidly with students about what, if anything, they can do to win over the algorithms. This shift in preparations comes as more businesses interested in filling internships and entry-level positions that may see a glut of applicants turn to outside companies such as HireVue to help them quickly conduct vast numbers of video interviews.
    











Photo Illustration: Aakanksha Aggarwal/ Shutterstock




Related article
AI software defines people as male or female. That's a problem




            With HireVue, businesses can pose pre-determined questions — often recorded by a hiring manager — that candidates answer on camera through a laptop or smartphone. Increasingly, those videos are then pored over by algorithms analyzing details such as words and grammar, facial expressions and the tonality of the job applicant’s voice, trying to determine what kinds of attributes a person may have. Based on this analysis, the algorithms will conclude whether the candidate is tenacious, resilient, or good at working on a team, for instance.
    

            Much has been written about the potential of AI to replace human jobs in the future, but the use of services like HireVue highlights a different concern: that AI can act as a gatekeeper for the jobs of today. Companies may not be ready to outsource vetting candidates for C-Suite and executive positions to algorithms, but the stakes are lower for entry-level roles and internships. That means some of today’s college students are effectively the guinea pigs for a largely unproven mechanism for evaluating applicants. 
    

            To make matters more complicated, there is little in the way of regulations or industry standards surrounding disclosure of technology usage -— though Illinois, for example, changed that with a recently-enacted law. So interviewees may not know when (or how) AI is analyzing their interview, and when it isn’t. That creates a sense of uncertainty for those trying to guide college students and new graduates through the interview process, and for the job seekers themselves.
    



        What worries me about AI is AI can’t tell the heart of a person and the drive a person has.
    

            Matthew French, assistant director for employer relations at UNC Charlotte
        


            “It’s kind of the wild, wild west right now of interviewing,” said Matthew French, assistant director for employer relations at UNC Charlotte’s university career center.
    




Ad Feedback












IAN BERRY/CNN



            Sarah Ali, a Duke undergraduate student, has gone through about eight HireVue interviews with various companies for jobs and internships in fields like tech and marketing. Except for the first interview, which helped her snag a marketing internship, none of them led to a job. Even now, she’s unsure what role, if any, AI played in the process — a possibility she only contemplated after speaking with friends about it following the first one.
    

            Even though she landed the internship after that first interview, Ali said she would have done a lot of things differently had she known for sure AI was involved. She might have used key words or phrases that would be picked up by AI and also kept direct eye contact with the camera.
    

            “Once I understood the AI interview process, I definitely started thinking about it as a game and how I could optimize for certain qualities or gestures,” Ali said.
    






Sarah Ali, a Duke University undergraduate student, said she now thinks of the AI interview process as a ""game.""

Teresa O'Reilly



        Why some companies turn to AI in interviews 


            HireVue may be the most well-known video interview company with nearly 800 companies as clients (including CNN, which does not use its AI features). It is used to interview about 1 million people every 90 days, according to HireVue CEO Kevin Parker.
    

            “We’ll interview probably a million college kids this year,” Parker told CNN Business.
    
Enter your email to subscribe to the CNN Five Things Newsletter.close dialogYou give us five minutes, we’ll give you five things you must know for the day.Please enter aboveSign me upBy subscribing you agree to ourprivacy policy.Success! Thanks for Subscribing Get a daily roundup of the top stories you may have missed, unique to your interests. Create your free CNN account to sign-upGet my recommended storiesclose dialog
            Parker said the Utah-based company began using AI in 2014 as a way to help companies sort through video interviews. He won’t say how many clients use AI assessments today, beyond noting that it’s a “smaller subset” of the companies it works with. HireVue highlights several of them on its website, including multiple Fortune 500 companies, such as Unilever.
    




Ad Feedback





            As with other companies like Yobs and Talview that offer AI-based assessments of video interviews, HireVue believes it can be helpful for ushering a massive number of people through the interview process quickly and reviewing them in a fair, consistent way. 
    






A mockup of a report that a company would receive after AI is used to assess a job candidate's HireVue interview, showing how the person compared to others who were interviewed and an average recommendation for the candidate. In this example, the candidate also completed a coding task and answered multiple-choice questions.

HireVue



            Parker said its algorithms consider things such as word usage, pronouns and facial expressions to determine how likely a job candidate is to possess a specific attribute a client is looking for in a certain job, such as empathy or willingness to learn. 
    

            These AI assessments are often used for filling entry-level jobs because candidates don’t have a lot of work history. The goal, according to Parker, is that the AI can act as a way to evaluate abilities and talent.
    

            After an AI assessment is performed on an interview – video interviews can take roughly 20 to 25 minutes –  the client gets a report scoring the candidate on the attributes deemed key to the job. This, Parker said, gives the company offering the job an almost standardized-test-score view of the candidate, showing what they’re good at and how they stand relative to other candidates. A report can also be generated for the job candidate to give them feedback, but it’s up to the employer to share that.
    

            “We recommend that customers do it and I think it’s great feedback for the candidate, but it’s customer specific,” Parker said. It’s unclear how many companies do applicants the courtesy of taking this step.
    






Stephen Roach, a career services consultant at Purdue's Center for Career Opportunities, sometimes takes an almost dismissive approach when coaching students on dealing with AI. ""They can't know how that platform's going to judge them,"" he said.

Xinrui Xu



        “We don’t know what it’s looking for”


            For Meredith McCook, assistant director at the Duke career center, the rise of this kind of interview — via video, and possibly with AI in the background analyzing that video — has meant some changes to how she works with students. She’s often talking to students about the new ways technology may be part of the interview process, and coaching them to practice by doing things such as turning on their laptop’s video camera and spending time talking to it. Duke offers students online video interview practice sessions, too.
    




Ad Feedback





            “With AI, we don’t know what it’s looking for,” McCook said. But in case AI is analyzing the interview, she suggests students raise their laptop to be eye level with the camera so it appears they’re maintaining eye contact, even though there isn’t a human on the other side of the lens.
    

            At UNC Charlotte, French is trying to help students become more informed about when AI is being used. This year, he said, the school will be asking employers it partners with whether they use AI for their virtual interviews in hopes of getting some data on how widespread the practice is. 
    

            He remains troubled about the use of AI in the recruitment process, though. “Everyone makes snap judgments on students, on applicants, when first meeting them,” he said. “But what worries me about AI is AI can’t tell the heart of a person and the drive a person has.”
    






Meredith McCook, assistant director at the Duke career center, admits that she and her peers don't even know what AI is looking for when screening students. 

Rob Ferrell



            Others like Stephen Roach, a career services consultant at Purdue’s center for career opportunities, sometimes take an almost dismissive approach when coaching students on dealing with a potential AI assessment. For example, he may tell them not to worry about it, since it’s outside their control.
    

            “If it is looking at their facial expressions or tone of voice, it might just be them being who they are,” he said. “They can’t know how that platform’s going to judge them.”
    

            These career counselors might soon have more tools to help students crack the black box. Interview prep platform Big Interview, which is used by more than 500 colleges and universities including Purdue and UNC Charlotte, is building its own AI system for scoring mock video interviews and giving would-be interviewees feedback. Big Interview cofounder and chief coach Pamela Skillings said the feedback will include details such as how quickly the person speaks and how much confident or negative language they use. The company plans to roll it out next month.
    

            The impetus for developing the tool, Skillings said, is from seeing people getting screened out after doing video interviews and feeling like they “deserve to know how they’re coming across.” 
    






College students and career counselors are still trying to figure out how to deal with the new role that AI plays in job interviews

EQRoy/Shutterstock



        But does it even work?


            Regardless of how clued in candidates are to when and how AI evaluates their interviews, plenty of people encountering this kind of interview technology — from college career counselors to AI scholars to technology rights activists — are unconvinced it can really work.
    

            “When you start saying, ‘We’ll use things like cadence and facial animation and things of that nature,’ I’m really skeptical that there’s real validity there,” said Aaron Rieke, a managing director at technology rights nonprofit Upturn.
    

            There are also concerns about how well AI can apply to the interview process. Arvind Narayanan, an associate professor of computer science at Princeton, said that while AI can be helpful at, say, identifying whether a photo contains a cat or a dog, it’s much harder to automate things such as predicting future social outcomes — like who will succeed at a job.
    

            He’s particularly doubtful of companies claiming they can analyze facial expressions in order to assess a person’s suitability for a job. (HireVue’s AI assessments can include this, Parker said, but he stressed that it’s used “very, very little”.)
    



        “Once I understood the AI interview process, I definitely started thinking about it as a game and how I could optimize for certain qualities or gestures.”
    

            Sarah Ali, a Duke undergraduate student
        


            One group, the Electronic Privacy Information Center, or EPIC, has gone as far as asking the Federal Trade Commission to investigate HireVue for what it calls “unfair and deceptive trade practices” related to its use of AI — particularly “secret, unproven algorithms” — in the interview process.
    

            HireVue said in a statement that it believes the complaint is without merit. “We uphold the highest levels of rigor and ethics as we work every day to increase fairness and objectivity in the hiring process,” the company said.
    

        Coming face-to-face with artificial intelligence


            To get a sense for what it’s actually like to be knowingly graded by a computer, I recently tried out a simulator that’s available online from Los Angeles-based startup Yobs, which uses AI to help a range of companies.
    

            The interview started with a familiar question: Name your biggest strengths and weaknesses. In the back of my mind, however, I wondered what an algorithm would make of my answer, complete with nervous pauses and frowns.
    






After completing a mock video interview via Yobs, CNN Business' Rachel Metz received an AI assessment scoring her personality traits, including extraversion and agreeableness.

FROM YOBS



            As I stared into my laptop camera, talking to nobody about myself and why I should be a potential employee at the faux Your Dream Company, I couldn’t help but feel a lot more anxious than I ever recall feeling during a phone or in-person interview.
    

            After answering the warm-up question about my strengths and weaknesss, which I was allowed to watch and redo as many times as I wanted, I recorded an ersatz interview where I had to talk about topics such as a time I faced a challenge with a team. Yobs gave me 30 seconds to prepare an answer to each of the questions, and each answer needed to be one to three minutes long. Without a human on the other side of my desk, I struggled to speak for even 40 seconds straight.
    

            The AI assessment of my performance arrived in my inbox soon after. It included computer-generated scores of the so-called Big Five personality traits — including openness and conscientiousness, where I scored highly, and neuroticism where, to my surprise, I scored low. The report also rated me on what are often known as “soft” or interpersonal skills: According to Yobs, my answers indicated a tendency to be cooperative, humble, and analytical, but less likely to be assertive or empathetic.
    

            To score these traits and skills, Yobs cofounder and CEO Raphael Danilo said the company’s AI assessment analyzes what interviewees say and how they say it — a method that sounds similar to HireVue’s. If a video is poor quality or the speaker has an unclear voice, he said, a trained human reviewer (who’s been given guidelines by psychologists working for Yobs on how to measure the same things the AI system is assessing) will look it over. 
    

            Danilo acknowledges that using AI to look over interviews is challenging; he’s not, for instance, comfortable letting it completely automate the hiring process at this point. But he’s convinced it can help employers find good employees quickly.
    

            If you’re looking at 100,000 applications for 500 spots, for instance, “you can’t talk to everybody,” he said. “You can’t take everyone out to lunch. So you have to use signals.”
    






","{'@type': 'WebPage', '@context': 'https://schema.org', 'url': 'https://www.cnn.com/2020/01/15/tech/ai-job-interview/index.html', 'dateModified': '2020-01-15T22:11:11Z', 'inLanguage': 'en', 'additionalType': 'article_fullwidth', 'publisher': {'@type': 'NewsMediaOrganization', 'name': 'CNN', 'logo': 'https://media.cnn.com/api/v1/images/stellar/prod/cnnlogo.png?q=w_60,h_61', 'foundingDate': '1980-06-01', 'url': 'https://www.cnn.com', 'sameAs': ['https://www.facebook.com/cnn/', 'https://twitter.com/CNN', 'https://www.instagram.com/cnn/', 'https://www.youtube.com/cnn']}, 'name': 'There’s a new obstacle to landing a job after college: Getting approved by AI', 'headline': 'There’s a new obstacle to landing a job after college: Getting approved by AI', 'description': 'College career centers used to prepare students for job interviews by helping them learn how to dress appropriately or write a standout cover letter. These days, they’re also trying to brace students for a stark new reality: They may be vetted for jobs in part by artificial intelligence.', 'datePublished': '2020-01-15T15:20:06Z'}",,2020-01-15T15:20:06Z,2020-01-15T22:11:11Z,,"{'@type': 'NewsMediaOrganization', 'name': 'CNN', 'logo': 'https://media.cnn.com/api/v1/images/stellar/prod/cnnlogo.png?q=w_60,h_61', 'foundingDate': '1980-06-01', 'url': 'https://www.cnn.com', 'sameAs': ['https://www.facebook.com/cnn/', 'https://twitter.com/CNN', 'https://www.instagram.com/cnn/', 'https://www.youtube.com/cnn']}","[{'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/200114183709-ai-students-job-interviews.jpg?q=w_1600,h_900,x_0,y_0,c_fill', 'sourceOrganization': {'@type': 'Organization', 'name': 'CNN'}, 'width': '1600', 'height': '900', 'creditText': 'IAN BERRY/CNN', 'dateCreated': '2020-01-14T23:38:09Z', 'dateModified': '2020-01-14T23:38:09Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/200114183709-ai-students-job-interviews.jpg?q=w_1600,h_900,x_0,y_0,c_fill', 'sourceOrganization': {'@type': 'Organization', 'name': 'CNN'}, 'width': '1600', 'height': '900', 'creditText': 'IAN BERRY/CNN', 'dateCreated': '2020-01-14T23:38:09Z', 'dateModified': '2020-01-14T23:38:09Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/200114084951-sarah-ali-duke-university-student.jpg?q=w_2448,h_1836,x_0,y_0,c_fill', 'caption': 'Sarah Ali, a Duke University undergraduate student, said she now thinks of the AI interview process as a ""game.""', 'sourceOrganization': {'@type': 'Organization', 'name': 'Sarah Ali'}, 'width': '2448', 'height': '1836', 'creditText': ""Teresa O'Reilly"", 'dateCreated': '2020-01-14T13:51:35Z', 'dateModified': '2020-01-14T13:51:35Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/200113134718-hirevue-mockup.jpg?q=w_2848,h_1602,x_0,y_0,c_fill', 'caption': ""A mockup of a report that a company would receive after AI is used to assess a job candidate's HireVue interview, showing how the person compared to others who were interviewed and an average recommendation for the candidate. In this example, the candidate also completed a coding task and answered multiple-choice questions."", 'sourceOrganization': {'@type': 'Organization', 'name': 'HireVue'}, 'width': '2848', 'height': '1602', 'creditText': 'HireVue', 'dateCreated': '2020-01-13T18:48:38Z', 'dateModified': '2020-01-14T00:02:29Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/200113125744-stephen-roach-purdue.jpg?q=w_3000,h_3000,x_0,y_0,c_fill', 'caption': 'Stephen Roach, a career services consultant at Purdue\'s Center for Career Opportunities, sometimes takes an almost dismissive approach when coaching students on dealing with AI. ""They can\'t know how that platform\'s going to judge them,"" he said.', 'sourceOrganization': {'@type': 'Organization', 'name': 'Stephen Roach'}, 'width': '3000', 'height': '3000', 'creditText': 'Xinrui Xu', 'dateCreated': '2020-01-13T17:59:31Z', 'dateModified': '2020-01-14T13:55:48Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/200113125600-02-meredith-mccook-duke-university.jpg?q=w_3000,h_2003,x_0,y_0,c_fill', 'caption': ""Meredith McCook, assistant director at the Duke career center, admits that she and her peers don't even know what AI is looking for when screening students. "", 'sourceOrganization': {'@type': 'Organization', 'name': 'Courtesy'}, 'width': '3000', 'height': '2003', 'creditText': 'Rob Ferrell', 'dateCreated': '2020-01-13T17:57:51Z', 'dateModified': '2020-01-14T13:13:08Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/200110171335-duke-university-campus-stock.jpg?q=w_3000,h_2000,x_0,y_0,c_fill', 'caption': 'College students and career counselors are still trying to figure out how to deal with the new role that AI plays in job interviews', 'sourceOrganization': {'@type': 'Organization', 'name': 'Shutterstock'}, 'width': '3000', 'height': '2000', 'creditText': 'EQRoy/Shutterstock', 'dateCreated': '2020-01-10T22:15:40Z', 'dateModified': '2020-01-10T22:15:40Z'}, {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/200110164008-20200110-ai-job-interview-a.jpg?q=w_1600,h_900,x_0,y_0,c_fill', 'caption': ""After completing a mock video interview via Yobs, CNN Business' Rachel Metz received an AI assessment scoring her personality traits, including extraversion and agreeableness."", 'sourceOrganization': {'@type': 'Organization', 'name': 'FROM YOBS'}, 'width': '1600', 'height': '900', 'creditText': 'FROM YOBS', 'dateCreated': '2020-01-10T21:41:06Z', 'dateModified': '2020-01-10T21:41:05Z'}]","[{'@type': 'Person', 'name': 'Rachel Metz', 'url': 'https://www.cnn.com/profiles/rachel-metz'}]",,,"College career centers used to prepare students for job interviews by helping them learn how to dress appropriately or write a standout cover letter. These days, they’re also trying to brace students for a stark new reality: They may be vetted for jobs in part by artificial intelligence. At schools such as Duke University, Purdue University, and the University of North Carolina at Charlotte, career counselors are now working to find out which companies use AI and also speaking candidly with students about what, if anything, they can do to win over the algorithms. This shift in preparations comes as more businesses interested in filling internships and entry-level positions that may see a glut of applicants turn to outside companies such as HireVue to help them quickly conduct vast numbers of video interviews. With HireVue, businesses can pose pre-determined questions — often recorded by a hiring manager — that candidates answer on camera through a laptop or smartphone. Increasingly, those videos are then pored over by algorithms analyzing details such as words and grammar, facial expressions and the tonality of the job applicant’s voice, trying to determine what kinds of attributes a person may have. Based on this analysis, the algorithms will conclude whether the candidate is tenacious, resilient, or good at working on a team, for instance. Much has been written about the potential of AI to replace human jobs in the future, but the use of services like HireVue highlights a different concern: that AI can act as a gatekeeper for the jobs of today. Companies may not be ready to outsource vetting candidates for C-Suite and executive positions to algorithms, but the stakes are lower for entry-level roles and internships. That means some of today’s college students are effectively the guinea pigs for a largely unproven mechanism for evaluating applicants.  To make matters more complicated, there is little in the way of regulations or industry standards surrounding disclosure of technology usage -— though Illinois, for example, changed that with a recently-enacted law. So interviewees may not know when (or how) AI is analyzing their interview, and when it isn’t. That creates a sense of uncertainty for those trying to guide college students and new graduates through the interview process, and for the job seekers themselves. “It’s kind of the wild, wild west right now of interviewing,” said Matthew French, assistant director for employer relations at UNC Charlotte’s university career center. Sarah Ali, a Duke undergraduate student, has gone through about eight HireVue interviews with various companies for jobs and internships in fields like tech and marketing. Except for the first interview, which helped her snag a marketing internship, none of them led to a job. Even now, she’s unsure what role, if any, AI played in the process — a possibility she only contemplated after speaking with friends about it following the first one. Even though she landed the internship after that first interview, Ali said she would have done a lot of things differently had she known for sure AI was involved. She might have used key words or phrases that would be picked up by AI and also kept direct eye contact with the camera. “Once I understood the AI interview process, I definitely started thinking about it as a game and how I could optimize for certain qualities or gestures,” Ali said.  Why some companies turn to AI in interviews  HireVue may be the most well-known video interview company with nearly 800 companies as clients (including CNN, which does not use its AI features). It is used to interview about 1 million people every 90 days, according to HireVue CEO Kevin Parker. “We’ll interview probably a million college kids this year,” Parker told CNN Business. Parker said the Utah-based company began using AI in 2014 as a way to help companies sort through video interviews. He won’t say how many clients use AI assessments today, beyond noting that it’s a “smaller subset” of the companies it works with. HireVue highlights several of them on its website, including multiple Fortune 500 companies, such as Unilever. As with other companies like Yobs and Talview that offer AI-based assessments of video interviews, HireVue believes it can be helpful for ushering a massive number of people through the interview process quickly and reviewing them in a fair, consistent way.  Parker said its algorithms consider things such as word usage, pronouns and facial expressions to determine how likely a job candidate is to possess a specific attribute a client is looking for in a certain job, such as empathy or willingness to learn.  These AI assessments are often used for filling entry-level jobs because candidates don’t have a lot of work history. The goal, according to Parker, is that the AI can act as a way to evaluate abilities and talent. After an AI assessment is performed on an interview – video interviews can take roughly 20 to 25 minutes –  the client gets a report scoring the candidate on the attributes deemed key to the job. This, Parker said, gives the company offering the job an almost standardized-test-score view of the candidate, showing what they’re good at and how they stand relative to other candidates. A report can also be generated for the job candidate to give them feedback, but it’s up to the employer to share that. “We recommend that customers do it and I think it’s great feedback for the candidate, but it’s customer specific,” Parker said. It’s unclear how many companies do applicants the courtesy of taking this step.  “We don’t know what it’s looking for” For Meredith McCook, assistant director at the Duke career center, the rise of this kind of interview — via video, and possibly with AI in the background analyzing that video — has meant some changes to how she works with students. She’s often talking to students about the new ways technology may be part of the interview process, and coaching them to practice by doing things such as turning on their laptop’s video camera and spending time talking to it. Duke offers students online video interview practice sessions, too. “With AI, we don’t know what it’s looking for,” McCook said. But in case AI is analyzing the interview, she suggests students raise their laptop to be eye level with the camera so it appears they’re maintaining eye contact, even though there isn’t a human on the other side of the lens. At UNC Charlotte, French is trying to help students become more informed about when AI is being used. This year, he said, the school will be asking employers it partners with whether they use AI for their virtual interviews in hopes of getting some data on how widespread the practice is.  He remains troubled about the use of AI in the recruitment process, though. “Everyone makes snap judgments on students, on applicants, when first meeting them,” he said. “But what worries me about AI is AI can’t tell the heart of a person and the drive a person has.” Others like Stephen Roach, a career services consultant at Purdue’s center for career opportunities, sometimes take an almost dismissive approach when coaching students on dealing with a potential AI assessment. For example, he may tell them not to worry about it, since it’s outside their control. “If it is looking at their facial expressions or tone of voice, it might just be them being who they are,” he said. “They can’t know how that platform’s going to judge them.” These career counselors might soon have more tools to help students crack the black box. Interview prep platform Big Interview, which is used by more than 500 colleges and universities including Purdue and UNC Charlotte, is building its own AI system for scoring mock video interviews and giving would-be interviewees feedback. Big Interview cofounder and chief coach Pamela Skillings said the feedback will include details such as how quickly the person speaks and how much confident or negative language they use. The company plans to roll it out next month. The impetus for developing the tool, Skillings said, is from seeing people getting screened out after doing video interviews and feeling like they “deserve to know how they’re coming across.”   But does it even work? Regardless of how clued in candidates are to when and how AI evaluates their interviews, plenty of people encountering this kind of interview technology — from college career counselors to AI scholars to technology rights activists — are unconvinced it can really work. “When you start saying, ‘We’ll use things like cadence and facial animation and things of that nature,’ I’m really skeptical that there’s real validity there,” said Aaron Rieke, a managing director at technology rights nonprofit Upturn. There are also concerns about how well AI can apply to the interview process. Arvind Narayanan, an associate professor of computer science at Princeton, said that while AI can be helpful at, say, identifying whether a photo contains a cat or a dog, it’s much harder to automate things such as predicting future social outcomes — like who will succeed at a job. He’s particularly doubtful of companies claiming they can analyze facial expressions in order to assess a person’s suitability for a job. (HireVue’s AI assessments can include this, Parker said, but he stressed that it’s used “very, very little”.) One group, the Electronic Privacy Information Center, or EPIC, has gone as far as asking the Federal Trade Commission to investigate HireVue for what it calls “unfair and deceptive trade practices” related to its use of AI — particularly “secret, unproven algorithms” — in the interview process. HireVue said in a statement that it believes the complaint is without merit. “We uphold the highest levels of rigor and ethics as we work every day to increase fairness and objectivity in the hiring process,” the company said. Coming face-to-face with artificial intelligence To get a sense for what it’s actually like to be knowingly graded by a computer, I recently tried out a simulator that’s available online from Los Angeles-based startup Yobs, which uses AI to help a range of companies. The interview started with a familiar question: Name your biggest strengths and weaknesses. In the back of my mind, however, I wondered what an algorithm would make of my answer, complete with nervous pauses and frowns. As I stared into my laptop camera, talking to nobody about myself and why I should be a potential employee at the faux Your Dream Company, I couldn’t help but feel a lot more anxious than I ever recall feeling during a phone or in-person interview. After answering the warm-up question about my strengths and weaknesss, which I was allowed to watch and redo as many times as I wanted, I recorded an ersatz interview where I had to talk about topics such as a time I faced a challenge with a team. Yobs gave me 30 seconds to prepare an answer to each of the questions, and each answer needed to be one to three minutes long. Without a human on the other side of my desk, I struggled to speak for even 40 seconds straight. The AI assessment of my performance arrived in my inbox soon after. It included computer-generated scores of the so-called Big Five personality traits — including openness and conscientiousness, where I scored highly, and neuroticism where, to my surprise, I scored low. The report also rated me on what are often known as “soft” or interpersonal skills: According to Yobs, my answers indicated a tendency to be cooperative, humble, and analytical, but less likely to be assertive or empathetic. To score these traits and skills, Yobs cofounder and CEO Raphael Danilo said the company’s AI assessment analyzes what interviewees say and how they say it — a method that sounds similar to HireVue’s. If a video is poor quality or the speaker has an unclear voice, he said, a trained human reviewer (who’s been given guidelines by psychologists working for Yobs on how to measure the same things the AI system is assessing) will look it over.  Danilo acknowledges that using AI to look over interviews is challenging; he’s not, for instance, comfortable letting it completely automate the hiring process at this point. But he’s convinced it can help employers find good employees quickly. If you’re looking at 100,000 applications for 500 spots, for instance, “you can’t talk to everybody,” he said. “You can’t take everyone out to lunch. So you have to use signals.”",,,,,,,"['business', 'tech']",There’s a new obstacle to landing a job after college: Getting approved by AI,"https://media.cnn.com/api/v1/images/stellar/prod/200114183709-ai-students-job-interviews.jpg?q=w_1600,h_900,x_0,y_0,c_fill",,False,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article__content'}",en,,P0Y0M0DT0H9M8S,2057.0,"[{'@context': 'https://schema.org', '@type': 'VideoObject', 'dateModified': '2019-08-24T14:03:57Z', 'uploadDate': '2019-05-01T13:21:50Z', 'embedUrl': 'https://fave.api.cnn.io/v1/fav/?video=business/2019/05/01/artificial-intelligence-changing-work-orig.cnn-business&stellarUri=archive.cms.cnn.com/_components/video-resource/instances/h_6fe67f94109b7aea0f837afe9e3c3da9@published&stellarUdk=rn06132f&customer=cnn&edition=domestic&env=prod', 'duration': 'PT00H01M11S', 'inLanguage': 'en', 'name': 'How AI is changing the way we work', 'headline': 'How AI is changing the way we work', 'description': 'Artificial intelligence has the potential to revolutionize many parts of business, from marketing to supply chain. The number of companies using AI is still relatively low, but early adopters will have the most to gain. ', 'thumbnail': {'@type': 'ImageObject', 'contentUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/181211153659-artificial-intelligence.jpg?q=w_1600,h_900,x_0,y_0,c_fill', 'sourceOrganization': {'@type': 'Organization', 'name': 'Getty'}, 'width': '1600', 'height': '900', 'creditText': 'Getty Images/Westend61', 'dateCreated': '2018-12-11T20:37:58Z', 'dateModified': '2018-12-11T20:37:58Z'}, 'thumbnailUrl': 'https://media.cnn.com/api/v1/images/stellar/prod/181211153659-artificial-intelligence.jpg?q=w_1600,h_900,x_0,y_0,c_fill', 'mainEntityOfPage': 'https://www.cnn.com/videos/business/2019/05/01/artificial-intelligence-changing-work-orig.cnn-business'}]",,,,,,
https://news.google.com/rss/articles/CBMiUGh0dHBzOi8vd3d3LmNvcnBvcmF0ZWNvbXBsaWFuY2VpbnNpZ2h0cy5jb20vZXRoaWNhbC11c2UtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,"Ethical AI is Built On Transparency, Accountability and Trust - Corporate Compliance Insights",2020-01-16,Corporate Compliance Insights,https://www.corporatecomplianceinsights.com,Are we ready for the rise of artificial intelligence? Dr. Steven Mintz explores the principles governing the ethical use of AI.,N/A,"AI systems based on machine learning can be used to audit financial data efficiently and look for financial fraud, but","AI systems based on machine learning can be used to audit financial data efficiently and look for financial fraud, but",,http://schema.org,BreadcrumbList,Ethics,N/A,"





What Dramatic UK Election Results Might Mean for Compliance

by Jonathan Armstrong July 16, 2024

New Labour government likely to look more closely at bribery, corruption and AI, among other areas


","{'@type': 'WebPage', '@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/'}","Ethical AI is Built On Transparency, Accountability and Trust",2020-01-16 06:00:36America/Chicago,2020-01-15 23:08:30America/Chicago,,"{'@type': 'Organization', 'name': '', 'url': 'https://www.corporatecomplianceinsights.com', 'logo': {'@type': 'ImageObject', 'url': ''}, 'sameAs': ['https://www.facebook.com/CorporateComplianceInsights/', 'https://twitter.com/cci_compliance', 'https://www.linkedin.com/company/corporate-compliance-insights', 'https://feedly.com/i/subscription/feed%2Fhttp%3A%2F%2Ffeeds.feedburner.com%2FCorporateComplianceInsights']}","{'@type': 'ImageObject', 'url': 'https://www.corporatecomplianceinsights.com/wp-content/uploads/2020/01/AI-human.jpg', 'width': 1000, 'height': 500}","{'@type': 'Person', 'name': 'Steven Mintz', 'url': 'https://www.corporatecomplianceinsights.com/author/steven-mintz/'}",,,"<div class=""intro-text"">

<em>AI systems based on machine learning can be used to audit financial data efficiently and look for financial fraud, but ethical risks exist if the data is biased. Dr. Steven Mintz explores the principles governing the ethical use of AI.</em>

</div>
Ethics are important, whether in our personal or professional lives. Most people believe that ethical behavior encompasses standards such as honesty, fairness, integrity, responsibility and accountability. These norms of behavior, along with transparency, underlie ethical systems of artificial intelligence (AI). Ethical AI is the foundation upon which trust in the system is built. About one-third of executives in a Deloitte survey named ethical risks as one of the top three concerns related to <a href=""https://www2.deloitte.com/content/dam/insights/us/articles/4780_State-of-AI-in-the-enterprise/DI_State-of-AI-in-the-enterprise-2nd-ed.pdf"" target=""_blank"" rel=""noopener noreferrer"">AI.</a>

AI systems pose a diverse set of ethical risks, including how the data is collected and processed. It can be challenging to understand how the system works and the validity of the conclusions reached from the analysis of data. These systems have been referred to as “black boxes,” or a system of automated decision-making often based on <a href=""https://www.corporatecomplianceinsights.com/tag/machine-learning/"" target=""_blank"" rel=""noopener noreferrer"">machine learning</a> from big data.
<h2>Ethics and AI</h2>
<a href=""https://advisory.kpmg.us/content/dam/advisory/en/pdfs/2019/kpmg-ethical%20-ai-five-guiding-pillars.pdf"" target=""_blank"" rel=""noopener noreferrer"">KPMG identified</a> five principles of ethics and AI:
<ul>
 	<li><strong>Transforming the workplace</strong>: Massive change in roles and tasks that define work, along with the rise of powerful analytic and automated decision-making, will cause job displacement and the need for retraining.</li>
 	<li><strong>Establishing oversight and governance</strong>: New regulations will establish guidelines for the ethical use of AI and protect the well-being of the public.</li>
 	<li><strong>Aligning cybersecurity and ethical AI</strong>: Autonomous algorithms give rise to <a href=""https://www.corporatecomplianceinsights.com/category/cybersecurity/"" target=""_blank"" rel=""noopener noreferrer"">cybersecurity</a> risks and adversarial attacks that can contaminate algorithms by tampering with the data. KPMG reported in its 2019 CEO Outlook that 72 percent of U.S. CEOs agree that strong cybersecurity is critical to engender trust with their key stakeholders, compared with 15 percent in 2018.</li>
 	<li><strong>Mitigating bias</strong>: Understanding the workings of sophisticated, autonomous algorithms is essential to take steps to eliminate unfair bias over time as they continue to evolve.</li>
 	<li><strong>Increasing transparency</strong>: Universal standards for fairness and trust should inform overall management policies for the ethical use of AI.</li>
</ul>
<h2>Ethical Risks</h2>
AI can improve human decision-making, but it has its limits. The possibility exists that bias in algorithms can create an ethical risk that brings into question the reliability of the data produced by the system. Bias can be accounted for through explainability of the data, reproducibility in testing for consistent results and auditability.

Other ethical risks include a lack of transparency, erosion of privacy, poor accountability and workforce displacement and transitions. The existence of such risks affects whether AI systems should be trusted. To build trust through transparency, organizations should clearly explain what data they collect, how it is used and how the results affect customers.
<h2>Ethics and Accountability</h2>
The “Algorithmic Accountability Act of 2019” was introduced in the U.S. House of Representatives on April 10, 2019 and referred to the House Committee on Energy and Commerce. The bill requires an assessment of the risks posed by automated decision systems to the privacy or security of personal information of consumers and the risks that the systems may result in or contribute to inaccurate, unfair, biased or discriminatory decisions impacting consumers.

Governance and accountability issues relate to who creates the ethics standards for AI, who governs the AI system and data, who maintains the internal controls over the data and who is accountable when unethical practices are identified. The internal auditors have an important role to play in this regard. They should assess risk, determine compliance with regulations and report their findings directly to the audit committee of the board of directors.
<h2>Auditing AI Data</h2>
Auditing is the function of examining data to determine whether it is accurate and reliable and the system used to generate it is operating as intended. Data that is biased will produce biased results. For example, a financial institution that grants mortgage loans to white applicants in much larger numbers than minorities may be biased. Assuming the data was biased, machine-learning AI systems would unintentionally reproduce these results over time.

AI auditing works well for a leasing firm with hundreds of lease contracts given the need to verify that each one has been properly recorded either as an asset with future value or expense for the period. AI systems can help to quickly analyze complex contracts to make that determination, but the accounting standards must be accurately inputted so the system knows what to look for.
<h2>Fraud Detection</h2>
The biggest value of using AI in auditing is to detect <a href=""https://www.corporatecomplianceinsights.com/category/fraud/"" target=""_blank"" rel=""noopener noreferrer"">fraud</a>, the idea being to identify and catch anomalies. For example, a reimbursable expense submitted by an employee should be examined by tying it to a restaurant receipt. What if the receipt for $100 is not based on food ordered but instead is a gift certificate for a friend or family member? The exact amount of the receipt may raise a red flag in an AI-driven, machine learning system where all data is examined, unlike a more traditional data processing system that uses sampled data.

Companies lose an estimated 5 percent of their revenue annually as a result of occupational fraud, according to the 2018 ACFE Report to the Nations. It turns out, the risk of occupational fraud is much higher than many managers and leaders realize. Each case results in a median loss of $130,000; with cases lasting a median of 16 months, fraud is something organizations of all sizes must take care to detect and <a href=""https://www.acfe.com/report-to-the-nations/2018/"" target=""_blank"" rel=""noopener noreferrer"">deter</a>. AI systems can analyze large amounts of data quickly and thoroughly to determine whether assets have been misappropriated.

AI systems can also have predictive value through machine learning and identifying high-risk areas and events. It can devise an accounting fraud prediction model that more accurately calculates the probability of future material misstatements in financial statements and to improve the quality of audits.

Using AI to examine all of the financial data and determine whether financial fraud exists provides a big advantage over previous systems. It affords a higher level of assurance and reduces the risk of fraud.
<h2>Corporate Governance</h2>
Corporate governance is essential to develop and enforce policies, procedures and standards in AI systems. Chief ethics and compliance officers have an important role to play, including identifying ethical risks, managing those risks and ensuring compliance with standards.

Governance structures and processes should be implemented to manage and monitor the organization’s AI activities. The goal is to promote transparency and accountability while ensuring compliance with regulations and that ethical standards are met.

A research study by Genesys found that more than one-half of those surveyed say their companies do not currently have a written policy on the ethical use of AI, although 21 percent expressed a definite concern that their companies could use AI in an ethical manner. The survey included 1,103 employers and 4,207 employees regarding the current and future effects of AI on their workplaces. The 5,310 participants were drawn from six countries: the U.S., Germany, the U.K., Japan, Australia and New Zealand. Additional results <a href=""https://www.genesys.com/en-gb/company/newsroom/announcements/new-workplace-survey-finds-nearly-80-of-employers-arent-worried-about-unethical-use-of-ai-but-maybe-they-should-be."">include</a>:
<ul>
 	<li>28 percent of employers are apprehensive their companies could face future liability for an unforeseen use of AI.</li>
 	<li>23 percent say there is currently a written corporate policy on the ethical use of AI.</li>
 	<li>40 percent of employers without a written AI ethics policy believe their companies should have one.</li>
 	<li>54 percent of employees believe their companies should have one.</li>
</ul>
<h2>Conclusions</h2>
The ethical use of AI should be addressed by all organizations to build trust into the system and satisfy the needs of stakeholders for accurate and reliable information. A better understanding of machine learning would go a long way to achieve this result.

Professional judgment is still necessary in AI to decide on the value of the information produced by the system and its uses in looking for material misstatements and financial fraud. In this regard, the acronym GIGO (“garbage in, garbage out”) may be appropriate. Unless the data is reliably provided and processed, AI will produce results that are inaccurate, incomplete or incoherent, and machine learning would be compromised with respect to ethical AI.","[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.corporatecomplianceinsights.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'Ethics', 'item': 'https://www.corporatecomplianceinsights.com/category/ethics/'}]",https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/,2020-01-16 06:00:36America/Chicago,,"[{'@type': 'Article', '@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/#article', 'isPartOf': {'@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/'}, 'author': {'name': 'Steven Mintz', '@id': 'https://www.corporatecomplianceinsights.com/#/schema/person/24e8213dd9d04174c964412f2004550a'}, 'headline': 'Ethical AI is Built On Transparency, Accountability and Trust', 'datePublished': '2020-01-16T12:00:36+00:00', 'dateModified': '2020-01-15T23:08:30+00:00', 'mainEntityOfPage': {'@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/'}, 'wordCount': 1330, 'publisher': {'@id': 'https://www.corporatecomplianceinsights.com/#organization'}, 'image': {'@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.corporatecomplianceinsights.com/wp-content/uploads/2020/01/AI-human.jpg', 'keywords': ['Artificial Intelligence (AI)', 'Machine Learning'], 'articleSection': ['Ethics', 'Featured'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/', 'url': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/', 'name': 'Ethical AI is Built On Transparency, Accountability and Trust | Corporate Compliance Insights', 'isPartOf': {'@id': 'https://www.corporatecomplianceinsights.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.corporatecomplianceinsights.com/wp-content/uploads/2020/01/AI-human.jpg', 'datePublished': '2020-01-16T12:00:36+00:00', 'dateModified': '2020-01-15T23:08:30+00:00', 'description': 'Are we ready for the rise of artificial intelligence? Dr. Steven Mintz explores the principles governing the ethical use of AI.', 'breadcrumb': {'@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/#primaryimage', 'url': 'https://www.corporatecomplianceinsights.com/wp-content/uploads/2020/01/AI-human.jpg', 'contentUrl': 'https://www.corporatecomplianceinsights.com/wp-content/uploads/2020/01/AI-human.jpg', 'width': 1000, 'height': 500, 'caption': 'robot hand touching human hand through screen interface'}, {'@type': 'BreadcrumbList', '@id': 'https://www.corporatecomplianceinsights.com/ethical-use-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.corporatecomplianceinsights.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Ethical AI is Built On Transparency, Accountability and Trust'}]}, {'@type': 'WebSite', '@id': 'https://www.corporatecomplianceinsights.com/#website', 'url': 'https://www.corporatecomplianceinsights.com/', 'name': 'Corporate Compliance Insights', 'description': 'The Web&#039;s Premier News Source for Compliance, Ethics &amp; Risk', 'publisher': {'@id': 'https://www.corporatecomplianceinsights.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.corporatecomplianceinsights.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.corporatecomplianceinsights.com/#organization', 'name': 'Corporate Compliance Insights', 'url': 'https://www.corporatecomplianceinsights.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.corporatecomplianceinsights.com/#/schema/logo/image/', 'url': 'https://www.corporatecomplianceinsights.com/wp-content/uploads/2019/03/CCI.800xpng-e1551630142759.png', 'contentUrl': 'https://www.corporatecomplianceinsights.com/wp-content/uploads/2019/03/CCI.800xpng-e1551630142759.png', 'width': 250, 'height': 167, 'caption': 'Corporate Compliance Insights'}, 'image': {'@id': 'https://www.corporatecomplianceinsights.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/CorporateComplianceInsights/', 'https://x.com/cci_compliance']}, {'@type': 'Person', '@id': 'https://www.corporatecomplianceinsights.com/#/schema/person/24e8213dd9d04174c964412f2004550a', 'name': 'Steven Mintz', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.corporatecomplianceinsights.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/be90443b365d4969738b1d2e2a052b3b?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/be90443b365d4969738b1d2e2a052b3b?s=96&d=mm&r=g', 'caption': 'Steven Mintz'}, 'description': 'Dr. Steven Mintz is a professor emeritus from Cal Poly San Luis Obispo. He has published a textbook on accounting ethics, “Ethical Obligations and Decision Making in Accounting: Text and Cases,” and is the recipient of the Accounting Exemplar Award given out by the Public Interest Section of the American Accounting Association. Steven blogs under the pseudonym Ethics Sage. His Workplace Ethics Advice blog was named as one of the 30 Exceptional CSR Blogs. He has also published a book, ""Beyond Happiness and Meaning: Transforming Your Life Through Ethical Behavior."" His website is: https://www.stevenmintzethics.com/. You can follow him on social media at: https://www.facebook.com/StevenMintzEthics.', 'url': 'https://www.corporatecomplianceinsights.com/author/steven-mintz/'}]",,"['Ethics', 'Featured']","Ethical AI is Built On Transparency, Accountability and Trust",,,,,"{'@type': 'SearchAction', 'target': 'https://www.corporatecomplianceinsights.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,https://www.corporatecomplianceinsights.com/#website,"{'@type': 'ImageObject', 'url': ''}","['https://www.facebook.com/CorporateComplianceInsights/', 'https://twitter.com/cci_compliance', 'https://www.linkedin.com/company/corporate-compliance-insights', 'https://feedly.com/i/subscription/feed%2Fhttp%3A%2F%2Ffeeds.feedburner.com%2FCorporateComplianceInsights']","Ethical AI is Built On Transparency, Accountability and Trust",2020-01-16 06:00:36,2020-01-15 23:08:30
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vd3d3LmhlYWx0aGNhcmVpdG5ld3MuY29tL25ld3MvYWktdGVsZWhlYWx0aC1jb3VsZC1oZWxwLWFkZHJlc3MtaG9zcGl0YWwtd29ya2ZvcmNlLWNoYWxsZW5nZXPSAQA?oc=5,"AI, telehealth could help address hospital workforce challenges - Healthcare IT News",2020-01-14,Healthcare IT News,https://www.healthcareitnews.com,A new American Hospital Association report on workforce strategic planning trends says technology is well-positioned to help health systems combat professional staffing shortages.,N/A,A new American Hospital Association report on workforce strategic planning trends says technology is well-positioned to help health systems combat professional staffing shortages.,A new American Hospital Association report on workforce strategic planning trends says technology is well-positioned to help health systems combat professional staffing shortages.,,,,N/A,N/A,"
HIMSS24 EUROPEAN HEALTH CONFERENCE & EXHIBITIONBetter patient outcomes and stronger workforces are a team project. At HIMSS24 Europe, we’ve built a programme to arm you and your peers with the insights you need to transform health systems back at home.May 29-31, 2024 | RomeLearn More ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3LnJlZ2plcmluZ2VuLm5vL2VuL2Rva3VtZW50ZXIvbmFzam9uYWwtc3RyYXRlZ2ktZm9yLWt1bnN0aWctaW50ZWxsaWdlbnMvaWQyNjg1NTk0Lz9jaD0x0gEA?oc=5,The National Strategy for Artificial Intelligence - regjeringen.no - Regjeringen.no,2020-01-15,Regjeringen.no,https://www.regjeringen.no,"artificial intelligence, AI, strategy, national, Norwegian","artificial intelligence, AI, strategy, national, Norwegian","artificial intelligence, AI, strategy, national, Norwegian","artificial intelligence, AI, strategy, national, Norwegian",,https://schema.org,BreadcrumbList,N/A,N/A,N/A,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': '/en/id4/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': '/en/find-document/id2000006/', 'name': 'Documents'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': '/en/dokumenter/nasjonal-strategi-for-kunstig-intelligens/id2685594/', 'name': 'The National Strategy for Artificial Intelligence'}}]",https://www.regjeringen.no//,,,,,,,,,,,"{'@type': 'SearchAction', 'target': 'https://www.regjeringen.no/no/sok/id86008/?term={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mb3Itcmlzay1yZWR1Y3Rpb24taW4tYmFua2luZy1jdXJyZW50LXVzZXMtNzk5NDQ1YTRhMTUy0gEA?oc=5,Artificial Intelligence for Risk Reduction in Banking: Current Uses - Towards Data Science,2020-01-16,Towards Data Science,https://towardsdatascience.com,"Banks are investing in artificial intelligence for risk reduction, namely fraud detection, compliance and cybersecurity. These are applications of anomaly detection.",N/A,"How banks use AI for fraud detection, compliance and cybersecurity","How banks use AI for fraud detection, compliance and cybersecurity",,http://schema.org,NewsArticle,N/A,N/A,"Member-only storyArtificial Intelligence for Risk Reduction in Banking: Current UsesHow banks use AI for fraud detection, compliance and cybersecurityRaj Shroff·FollowPublished inTowards Data Science·8 min read·Jan 16, 20203351ListenSharePhoto by Christine Roy on UnsplashBanks are investing heavily in artificial intelligence for risk reduction, namely fraud detection, compliance and cybersecurity. In machine learning terms, these are applications of anomaly detection techniques.We will look at how three banks — HSBC, JPMorgan and Danske Bank use AI to combat fraud, comply with anti-money laundering (AML) regulation, and shield against cyber threats. We then look at specific machine learning techniques used for anomaly detection. Finally, we consider key takeaways for banking executives tasked with implementing AI-based risk reduction tools.Banks Prioritize Risk ReductionChatbots and customer-facing AI projects receive plenty of hype. Banks frequently publish press releases trumpeting their latest and greatest chatbots. However, press releases are brand building exercises and don’t necessarily indicate actual AI investment or development.Banks’ crucial AI investments in anomaly detection receive little publicity, even if this is where the money is going. Research suggests that of the $3 billion raised by AI vendors in the banking space, over 50% was raised by…",https://towardsdatascience.com/artificial-intelligence-for-risk-reduction-in-banking-current-uses-799445a4a152,Artificial Intelligence for Risk Reduction in Banking | Towards Data Science,2020-01-16T14:15:40.919Z,2021-12-13T06:04:47.268Z,,"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",['https://miro.medium.com/v2/resize:fit:1200/1*ePDpghS4CYCw_ytV1ur-Dw.jpeg'],"{'@type': 'Person', 'name': 'Raj Shroff', 'url': 'https://towardsdatascience.com/@raj.r.shroff'}",,,,,https://towardsdatascience.com/artificial-intelligence-for-risk-reduction-in-banking-current-uses-799445a4a152,2020-01-16T14:15:40.919Z,,,,,Artificial Intelligence for Risk Reduction in Banking | Towards Data Science,,,False,,,,799445a4a152,['Raj Shroff'],"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOGh0dHBzOi8vd3d3LnNsdHJpYi5jb20vbmV3cy8yMDIwLzAxLzE1L3V0YWgtcG9saWNlLWxvb2sv0gEA?oc=5,Utah police look to artificial intelligence for assistance - Salt Lake Tribune,2020-01-14,Salt Lake Tribune,https://www.sltrib.com,Provo • A Utah city police department is considering a partnership with an artificial intelligence company in an effort to help the law enforcement agency work more efficiently.,,Provo • A Utah city police department is considering a partnership with an artificial intelligence company in an effort to help the law enforcement agency work more efficiently.,Provo • A Utah city police department is considering a partnership with an artificial intelligence company in an effort to help the law enforcement agency work more efficiently.,,https://schema.org,NewsArticle,N/A,N/A,"Shredding paper. Folding laundry. Utahns with disabilities work segregated, repetitive jobs — and the DOJ may sue over it.",,,2020-01-15T00:20:58.431Z,2020-01-15T00:20:58.403Z,,"{'@type': 'Organization', 'name': 'The Salt Lake Tribune'}",[''],,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://sltrib.com/news'}]",https://www.sltrib.com,,,,,,Utah police look to artificial intelligence for assistance ,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Salt Lake Tribune', 'productID': 'sltrib.com:showcase'}",True,,,,,,,,,,,,,https://local.sltrib.com/marketing/tribune_T.png,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,article:section,article:summary,article text,@context,@graph,@type,image,url,dateCreated,datePublished,dateModified,headline,name,identifier,author,creator,publisher,mainEntityOfPage,isAccessibleForFree,hasPart,itemListElement,thumbnailUrl,articleBody,isPartOf,articleSection,alternativeHeadline
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LnRoZW5ld2Vjb25vbXkuY29tL3RlY2hub2xvZ3kvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYmVnaW5zLXRvLXNob3ctc2lnbnMtb2YtaHVtYW4tbGlrZS1jcmVhdGl2aXR50gEA?oc=5,Artificial intelligence begins to show signs of human-like creativity - The New Economy,2020-06-01,The New Economy,https://www.theneweconomy.com,"Artificial intelligence begins to show signs of human-like creativity | Artificial intelligence has developed significantly in recent years, but displaying creativity to rival that of humankind is proving challenging. However, progress has recently been made",N/A,"Artificial intelligence has developed significantly in recent years, but displaying creativity to rival that of humankind is proving challenging. However, progress has recently been made","Artificial intelligence has developed significantly in recent years, but displaying creativity to rival that of humankind is proving challenging. However, progress has recently been made",N/A,N/A,"

Technology


 
More in Technology



Mastering the art of data: the skills that will get you noticed
It’s almost a decade since a much-shared Harvard Business Review article declared data scientist the sexiest job of the 21st century. But is working with data still as novel or as exciting as it was then?


The rise of digital currencies in the emerging world
As of September 7, 2021, El Salvador will officially recognise Bitcoin as legal currency. This is a remarkable move, and one that will likely stimulate a huge amount of economic growth as Salvadoreans leapfrog from a largely cash-based society straight to a system characterised by the frictionless, finger-snap efficiency of digital currency.


Trump’s plans to ban Chinese app WeChat blocked
A federal judge has temporarily blocked President Donald Trump’s executive order to ban WeChat over concerns the ban would threaten users’ first amendment rights


Oracle returns to growth
The software maker’s quarterly revenue exceeded analysts’ expectations, as remote working drove greater demand for its cloud-computing services 




Artificial intelligence begins to show signs of human-like creativity Artificial intelligence has developed significantly in recent years, but displaying creativity to rival that of humankind is proving challenging. However, progress has recently been made




									
								By Barclay Ballard | Monday, June 1st, 2020


FacebookTwitterLinkedin



Professional Go player Ke Jie played against DeepMind's AI program AlphaGo in 2016. The program won by displaying human-like creativity when it made a new and unexpected move that went beyond the data on which it was trained

“It was nine seventeen in the morning, and the house was heavy.” Thus begins the 2018 novel 1 the Road. Not a bad opening sentence – certainly no worse than many others that have been committed to posterity. The main difference, however, is that this particular sentence has no author – not in the conventional sense of the word, anyway.
This is because 1 the Road was written entirely by artificial intelligence (AI). Its prose was conjured up by a long short-term memory recurrent neural network, which took input – or inspiration, if you prefer – from surveillance cameras and other sensors mounted on a truck travelling from New York to New Orleans. The end result was an AI-penned version of Jack Kerouac’s On the Road.
This new novel is just one example of AI being used for creative endeavours. Those employed in jobs that are deemed ‘low skill’ have long known that automation poses a threat to their livelihood, but musicians, artists and writers have largely assumed that a machine could never replicate their work. Perhaps this confidence was misplaced.

Musicians, artists and writers have largely assumed that a machine could never replicate their work. Perhaps this confidence was misplaced

Not so smart
Every year since 2015, AI has featured as part of Gartner’s top 10 strategic technology trends in one form or another. The technology and the huge impact that it could have on the business world has long been appreciated, but sifting through the hype is difficult. Science fiction has conjured up images of AI that range from benevolent robot housekeepers to apocalyptic supercomputers. Clearly, the technology is not quite at this stage yet.
Nevertheless, AI is no longer something that needs to be discussed in the future tense – it is already here. When customers have an issue with a product or service, their first port of call is often the website of the respective business. Once there, they might join an online chat to help resolve their problem. Increasingly, this dialogue will be between the customer and a chatbot or virtual assistant. They may have a friendly-looking avatar and surprisingly human-like responses, but they are in fact nothing more than multiple lines of code.
In the manufacturing sector, companies like BMW, Airbus and LG are using AI to deliver greater levels of efficiency, safety and reliability on the factory floor. In the home, meanwhile, developments in AI mean that vacuum cleaners can scan rooms for size and obstacles, determine the most efficient cleaning route and then get to work – all without any human input.
These are all impressive feats – ones that would have been scarcely believable just a few decades ago. However, whether they truly represent AI is debatable. In the aforementioned examples, what is termed AI only works within clearly defined parameters: a robot designed to manufacture car parts cannot employ its skills to help put bikes together, and autonomous vacuum cleaners are powerless when confronted by a humble set of stairs.
Artificial general intelligence refers to a machine that can apply knowledge and skills within different contexts – in short, one that can learn by itself and work out problems like a human
“At present, many examples of AI still represent what has been called ‘narrow AI’, working only within clearly defined parameters,” said Arthur I Miller, author of The Artist in the Machine: The World of AI-Powered Creativity. “There is, however, research being done on developing multipurpose machines. DeepMind in London is working on a version of [computer program] AlphaZero, which started out playing games, to work on medical research – specifically, to look into protein folding, the process whereby an embryo begins to generate organs by folding protein chains.”
Self-driving cars, digital personal assistants like Alexa and even automated spam filters fall within what can be termed ‘narrow AI’. Conversely, artificial general intelligence (AGI) refers to a machine that can apply knowledge and skills within different contexts – in short, one that can learn by itself and work out problems like a human. But even as artificial intelligence improves, the number of applications that can be classified as AGI remain few and far between.
Getting creative
One major stumbling block that must be overcome before a machine can claim to possess AGI is the issue of creativity. Humans find it easy to reach beyond the limits of their own knowledge and create something new – it might not be any good (however ‘good’ may be determined), but all of us can write poetry, draw, decorate and cook. These are creative processes, even if we don’t consciously appreciate them as such. Machines, on the other hand, largely do as they’re told.
Increasingly, though, machines are showing their creative side. As well as novels like 1 the Road, an AI bot named Benjamin wrote a short science fiction film called Sunspring in 2016, which was subsequently acted out and played during the SCI-FI-LONDON film festival. It remains available on YouTube.
Journalists, too, have reasons to be concerned. A number of media outlets including Forbes, The Washington Post and Reuters use machine learning tools to help them produce content. Bloomberg uses a computer system known as Cyborg to instantly turn financial reports into mini articles; according to the New York Times, it is now responsible for around a third of all the content produced by Bloomberg News.

Sceptics would say the written word is among the easier creative fields to mimic – after all, it does have clear grammatical rules to follow and there is an almost limitless vault of content for machines to learn from. But AI creativity has extended into other media as well. “Other examples of AI creativity include AlphaGo, an artificial neural network created at DeepMind, which defeated a top-flight Go master in 2016,” Miller told The New Economy. “It did so by making a totally new and unexpected move which went beyond the data on which it was trained – an amazing display of creativity.”
Sony, meanwhile, has used a machine learning platform called Flow Machines to create a song in the style of the Beatles, while in 2019, Warner Music Group signed a deal with an app called Endel for the distribution of 600 algorithm-created tracks to put on streaming services. Similarly, Google’s Deep Dream Generator has been used to create otherworldly pieces of art, some of which have fetched thousands of dollars at auction. The buyers evidently thought the creativity on show was worth paying for.
Machines have even shown an aptitude for thinking on their feet, something previously thought beyond them. Last year, IBM’s Project Debater took on Harish Natarajan, a 2016 World Debating Championship finalist, in a debate over whether preschools should receive government subsidies. Although Natarajan won, IBM’s AI system made a number of convincing arguments, created its own rebuttals to Natarajan’s points and formulated a closing argument.
All work and no play
No discussion of AI would be complete without some consideration of the apocalyptic future that it is destined to bring about – according to some, anyway. Such fears seem hyperbolic at the moment, but that is because there is not much reason to suspect a customer service chatbot is going to take over the world. However, as AI develops further – as it starts to display creativity and emotions – concerns become more justifiable. If AI can do everything better than we can, what is the point of humans even existing?

This replacement fear often manifests itself through the prism of job losses. However, Miller believes a creative machine may be able to collaborate with humans more effectively, rather than replace them: “AIs have hugely more information in their memories than humans and can deal with it in ways beyond our powers. They can therefore work with humans to develop new products, which might not be found without their help.”
Still, there is no doubt that creative AI poses a new threat to the workforce. According to a 2018 report by PwC, as many as 30 percent of existing jobs could face automation by the mid-2030s. However, not all industries and job roles would be affected equally.
“Industries follow different paths of automation over time, and data-driven industries… may be most automatable in the short term,” the report read. “In contrast, relatively low automatability sectors such as human health, social work and education have more focus on social skills, empathy and creativity, which are more difficult to directly replace by a machine, even allowing for potential technological advances over the next 10 to 20 years.”
As the ability of AI solutions to work creatively improves, however, even the jobs once considered safe from automation may find themselves at risk. It will likely take a long time before writers, musicians, chefs and artists are replaced, but they should no longer think it impossible. For employers and patrons, the appeal is obvious: AI will never miss a deadline, complain about having to alter its work or ask for more money.
Finding inspiration
The scientific progress that has enabled machines to display elements of human creativity is astounding – so much so that the scientists behind it are themselves not entirely sure what is involved. Developments are generally focused on neural networks – these were involved in the writing of 1 the Road, the development of Google’s AlphaGo, and were used to craft Project Debater’s arguments.
“Artificial neural networks are loosely inspired by the way the brain is wired,” Miller explained. “They are made up of layers of artificial neurons and, like the human brain, require data in order to respond to what they see and hear. They can learn without being specifically programmed to do so. Deep neural networks have many layers of neurons.”

Job automation in numbers:
$15trn
Potential boost to global GDP from AI by 2030
20%
of jobs are at risk of automation by the early 2020s
30%
of jobs are at risk of automation by the mid-2030s
44%
of workers with low education risk automation by the mid-2030s
Source: PwC

Although often compared with one another, the human brain and a traditional computer actually operate in contrasting ways. In a computer, transistors are connected to one another in relatively simple arrangements, or chains. Conversely, in the brain, neurons are interconnected with each other in complex, densely packed layers. This makes computers great for storing huge amounts of information and retrieving it in set, pre-programmed ways. But the brain, while it may take a long time to learn complex information, can reorganise and repurpose it into something new – in other words, it can behave creatively.
In an effort to mimic this creativity, computer scientists have been working on artificial neural networks (ANNs) inspired by the brain. They perform tasks by learning from examples without being given task-specific rules. This approach has shown particular success in pattern recognition, facial recognition, translating between languages and speech recognition.
Importantly, however, there is no physical difference between an ANN and a more traditional computer. Machines built on ANNs still have transistors connected in much the same way as a standard consumer PC, but will be running software that mimics the connections seen in a human brain.
But despite the fact that ANNs are designed by programmers, just like any other piece of computing software, how they work is not always understood. AI suffers from what is known as the ‘black box’ problem: while we have clear visibility of the inputs and outputs of any such system, we cannot see how the algorithms take the former and come up with the latter. How exactly did Google’s AlphaGo platform come up with the playing moves it chose? Why does 1 the Road start the way it does and not with any number of other grammatically correct sentences? We cannot see inside the black box to answer these questions, which means a lot of AI’s achievements stem from guesswork.
Everyone’s a critic
There are many who will say that the examples of creativity that machines have displayed so far are still operating within fixed parameters. When a computer crafts a song, it may be impossible for a human to determine in advance exactly what it will sound like, but there are unlikely to be any other surprises. The machine is only creating music because it has been told to do so – this seems a long way from the spark of inspiration felt by the likes of Mozart or McCartney.
“Machines have shown glimmers of creativity, but we will not be able to say that they are truly creative until they have developed emotions, volition and consciousness and actually desire to create,” Miller said. “They will also need to be able to assess their work. One day, however, machines will certainly be truly creative. There is no reason why only humans can be called creative. Many people who deny that machines will ever be creative do so out of fear of dystopian worlds that are more sci-fi than reality.”
To determine whether machines will ever truly reach this standard, a definition of creativity will need to be agreed upon. This in itself seems like an impossible undertaking. Art is subjective, and whether a machine can be called an artist is likely to remain so as well – at least, until the point when (or if) AI starts to recreate a wider range of human characteristics.

While we have clear visibility of the inputs and outputs of any AI system, we cannot see how the algorithms take the former and come up with the latter

But ultimately, whether a machine is being truly creative may not matter outside of philosophical debates. The artistic results that computers will be able to produce, whether in the fields of music, art or literature, are only going to get better and better. If audiences approve of the output, will many people care whether art is produced by a troubled genius or lines of software code?
That is a question for another day. For now, neurologists will continue studying the mysteries of the human brain and computer scientists will continue in their efforts to recreate them in software form. Even if true creativity has not been achieved yet, we can still marvel at the dream-like scenes created by Google’s Deep Dream Generator, enjoy software-crafted songs and grow frustrated in our efforts to beat a computer at chess.
The pace at which AI is developing is impressive regardless of its shortcomings. And it is easy to see where these remain most pronounced: a machine does not yet seem able to tell whether what it has produced is any good, or, indeed, have any concept at all of what it has created.
“The table is black to be seen, the bus crossed in a corner,” begins another section of 1 the Road. “Part of a white line of stairs and a street light was standing in the street, and it was a deep parking lot.” Gibberish? Perhaps – or maybe the avant-garde musings of a literary genius. After all, the opening of James Joyce’s Finnegans Wake is arguably even less coherent, starting mid-sentence: “riverrun, past Eve and Adam’s, from swerve of shore to bend of bay, brings us by a commodius vicus of recirculation back to Howth Castle and Environs.”
Art will always be open to interpretation, discussion, praise and ridicule. No one can say precisely what creative works will be produced in the future, but it’s looking increasingly likely that they will be made by both man and machine.

                                Related topics: AlphaGo, Artificial Intelligence, creativity, job automation 



Post navigation
How crises transform the manufacturing sectorWill COVID-19 finally usher in the age of the cryptocurrency?
 







Supplements






































",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiJWh0dHBzOi8vY3NldC5nZW9yZ2V0b3duLmVkdS9nbG9zc2FyeS_SAQA?oc=5,Glossary - Center for Security and Emerging Technology,2020-06-04,Center for Security and Emerging Technology,https://cset.georgetown.edu,"Place to find CSET's publications, reports, and people",N/A,"Here we define four key terms related to CSET’s work: artificial intelligence, machine learning, deep learning, and neural networks. Below, we suggest other glossaries that define related terms. For more information about some popular types of models — generative AI, large language models, and foundation models — see our blog post explaining how these categories […]",N/A,N/A,N/A,N/A,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://cset.georgetown.edu/glossary/', 'url': 'https://cset.georgetown.edu/glossary/', 'name': 'Glossary | Center for Security and Emerging Technology', 'isPartOf': {'@id': 'https://cset.georgetown.edu/#website'}, 'datePublished': '2019-12-11T22:17:27+00:00', 'dateModified': '2023-05-12T14:25:41+00:00', 'breadcrumb': {'@id': 'https://cset.georgetown.edu/glossary/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://cset.georgetown.edu/glossary/']}]}, {'@type': 'BreadcrumbList', '@id': 'https://cset.georgetown.edu/glossary/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://cset.georgetown.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Glossary'}]}, {'@type': 'WebSite', '@id': 'https://cset.georgetown.edu/#website', 'url': 'https://cset.georgetown.edu/', 'name': 'Center for Security and Emerging Technology', 'description': 'Place to find CSET&#039;s publications, reports, and people', 'publisher': {'@id': 'https://cset.georgetown.edu/#organization'}, 'alternateName': 'CSET', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://cset.georgetown.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://cset.georgetown.edu/#organization', 'name': 'CSET', 'url': 'https://cset.georgetown.edu/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://cset.georgetown.edu/#/schema/logo/image/', 'url': 'https://cset.georgetown.edu/wp-content/uploads/CSET_Logo_Icon_only_PMS293.png', 'contentUrl': 'https://cset.georgetown.edu/wp-content/uploads/CSET_Logo_Icon_only_PMS293.png', 'width': 192, 'height': 198, 'caption': 'CSET'}, 'image': {'@id': 'https://cset.georgetown.edu/#/schema/logo/image/'}, 'sameAs': ['https://www.linkedin.com/company/georgetown-cset/', 'https://www.youtube.com/channel/UCC0d3h9rVlfBouk0WoKE1FQ', 'https://www.threads.net/@csetgeorgetown', 'https://bsky.app/profile/cset.bsky.social', 'https://twitter.com/CSETGeorgetown']}]",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vc3Npci5vcmcvYXJ0aWNsZXMvZW50cnkvdGhlX3Byb2JsZW1fd2l0aF9jb3ZpZF8xOV9hcnRpZmljaWFsX2ludGVsbGlnZW5jZV9zb2x1dGlvbnNfYW5kX2hvd190b19maXhfdGhlbdIBAA?oc=5,The Problem With COVID-19 Artificial Intelligence Solutions and How to Fix Them - Stanford Social Innovation Review,2020-06-05,Stanford Social Innovation Review,https://ssir.org,N/A,N/A,How nonprofit and business leaders can equitably and responsibly use AI systems in the fight against COVID-19.,How nonprofit and business leaders can equitably and responsibly use AI systems in the fight against COVID-19.,N/A,N/A,"


Technology

The Problem With COVID-19 Artificial Intelligence Solutions and How to Fix Them 
How nonprofit and business leaders can equitably and responsibly use AI systems in the fight against COVID-19.



Cite


share


comment


print


order reprints


related stories





By Genevieve Smith & Ishita Rustagi

Jun. 5, 2020









(Photo by Engin Akyurt/Unsplash)

Private and public entities around the world, particularly in the health care and governance sectors, are developing and deploying a range of artificial intelligence (AI) systems in emergency response to COVID-19. Some of these systems work to track and predict its spread; others support medical response or help maintain social control. Indeed, AI systems can reduce strain on overwhelmed health care systems; help save lives by quickly diagnosing patients, and assessing health declines or progress; and limit the virus’s spread.
But there’s a problem: The algorithms driving these systems are human creations, and as such, they are subject to biases that can deepen societal inequities and pose risks to businesses and society more broadly. In this article, we look at data on the pandemic, share two recent applications of AI, and suggest a number of ways nonprofit and business leaders can help ensure that they develop, manage, and use transformative AI equitably and responsibly.






Rethinking Social Change in the Face of Coronavirus 


In this series, SSIR will present insight from social change leaders around the globe to help organizations face the systemic, operational, and strategic challenges related to COVID-19 that will test the limits of their capabilities.

 FOLLOW THIS SERIES


You'll get email alerts when there is new content in this series.








SIGN UP





The Problem With COVID-19 Data
Using techinical frameworks, such as machine learning, AI systems use algorithms to make inferences from data about people. This includes demographic attributes, preferences, and likely future behaviors. To effectively serve a range of populations, AI systems must learn to make associations based on massive amounts of data that accurately reflect information across identities. However, the data they rely on is often rife with social and cultural biases. Data might not exist for certain populations, may exist but be poor quality for certain groups, and/or reflect inequities in society. As a result, algorithms can make inaccurate predictions and perpetuate social stereotypes and biases.
Unfortunately, much of the data about COVID-19 that the US Center for Disease Control and Prevention (CDC) and others are collecting and tracking is incomplete and biased. COVID-19 infection rates, for example, have been subject to a “vast undercount,” by a factor of 50 or more. Medical data is reflecting only a subset of the population—in many cases, the affluent, white communities who have ready access to limited tests and expensive medical procedures. But there are other important data gaps too:

Data on risk and mortality is not sufficiently disaggregated by sex, race, or ethnicity. The CDC didn’t release a race and sex breakdown of COVID-19 cases and deaths until early April, and even then, it only pulled from parts of 14 states. Today, many states have data that shares cases and mortality by race, but gender is still limited, and there is no available sex-disaggregated mortality data.
Data for racial and ethnic groups is incomplete, and terms and labels are inconsistent. Infection and mortality data released by the CDC, while still infrequent and incomplete, paints a bleak picture around how COVID-19 disproportionately kills certain racial and ethnic groups. Alarming rates among black Americans are rooted in longstanding economic and health care inequalities, and the ambiguous racial/ethnic categorization of existing data further obscures disparities.
COVID-19 data tracking systems aren’t capturing data on immigrants and other marginalized populations. Immigrants are one of many communities of color hard-hit by COVID-19. Many are filling service positions in essential businesses that require them to interact with a large number of people daily, and are already at increased risk of complications or death from COVID-19 due to high rates of underlying chronic illnesses. Despite this, many are not getting tested for fear of getting deported. Sufficient data for transgender and non-binary individuals does not exist either—most state health officials are not collecting data on whether patients identify as LGBTQ—and transgender individuals are at greater risk given economic and social vulnerabilities. This lack of data on the most vulnerable isn’t just a problem in the United States—it’s often even greater in poorer countries.

AI for COVID-19 Medical Response
Some of the AI systems created to support COVID-19 medical response help diagnose and detect COVID-19 through basic online screening or analyzing chest images. Others, such as the forthcoming version of eCART, can help predict COVID-specific outcomes and inform clinical decisions. This is particularly useful for medical volunteers without pulmonary training, who must assess patients’ conditions and decide who needs help first. AI tech may also prove helpful in the search for a COVID-19 vaccine and other therapies. 
However, the data gaps we mentioned earlier have major implications for medical AI systems and AI-enhanced vaccine trials. People react differently to viruses, vaccines, and treatments, as previous outbreaks like SARS and Ebola have illustrated. Data available on COVID-19 outside the United States, for example, shows that men and women face different fatality rates, and a recent research paper found that women patients admitted to the Wuhan Union Hospital had higher levels of COVID-19 antibodies than men. Given systemic inequities that worsen health outcomes for certain racial and ethnic groups, it’s equally important to understand COVID-19 health outcomes for different identities, as well as the intersectional implications.
Algorithms that don’t account for existing inequities risk making inaccurate predictions—or worse. In 2019, a study found that the widely used Optum algorithm, which used health-care spending as a proxy to measure need, was biased against black Americans. It didn’t account for discrimination or lack of access, both of which lead to lower spending on health care by black Americans. Amid the COVID-19 crisis, AI systems that inform limited-resource allocations (such as who to put on a ventilator) must be careful not to inadvertently prioritize certain identities over others. While developers aim to make algorithms race-blind by excluding race as a metric, this can ignore or hide— rather than prevent—discrimination. For example, algorithms that inform clinical decisions may use proxies such as preexisting conditions. Diabetes is a preexisting condition linked to higher rates of COVID-19, and it has a higher incidence for black Americans. If an algorithm uses preexisting conditions but is blind to race, it can result in disproportionately prioritizing white Americans over black Americans.
While some firms adhere to rigorous testing—conducting large validation studies prior to releasing products, for example—not all firms are thorough. Further, the decision-making processes of most AI algorithms are not transparent. This opens the door to inaccurate or discriminatory predictions for certain demographics, and thus poses immense risks to the individuals and practitioners using them.
AI for COVID-19 Social Control
Another recent application of AI is contact tracing, or tracking people who have come into contact with the virus to help contain it. By tracking user information such as health and location, and using AI-powered facial recognition, these tools can enforce social distancing and inform citizens of contact with positive cases. In China, users are assigned a coronavirus score, which impacts their access to public transportation, work, and school. And US government officials have begun raising the possibility of mass surveillance, collecting “anonymized, aggregate” user location data from tech giants like Facebook and Google to map the spread of COVID-19.
But surveillance tools have ethical implications—again, particularly for marginalized populations. Using AI to decide who leaves their home could lead to a form of COVID-19 redlining, subjecting certain communities to greater enforcements. This calls to mind another AI model that results in higher surveillance of poor communities of color: predictive policing. In the United States, risk-assessment algorithms use criminal history information, but don’t take into account deep-rooted racial bias in the policing system, that black Americans are arrested more often for smaller crimes and that neighborhoods with high concentration of black Americans are more heavily patrolled. Black Americans end up overrepresented in the data, which then links to racially biased policing outcomes. Similarly, communities impacted by proposed surveillance systems would likely be poorer communities of color harder hit by COVID-19 for a variety of reasons linked to historical inequities and discrimination.
It is not clear how or how long government agencies or other entities will use these types of AI tools. In China, tracking could stick around after the crisis, allowing Beijing authorities to monitor religious minorities, political dissidents, and other marginalized communities with a history of being over-surveilled. And although data collection in the United States will initially be anonymized and aggregated, there’s potential for misuse and de-anonymization in the future.
Five Things Nonprofit and Business Leaders Can Do
Various AI systems are proving incredibly valuable to tackling the pandemic, and others hold immense promise. But leaders must take care to develop, manage, and use this technology responsibly and equitably; the risks of discrimination and deepening inequality are simply unacceptable. Here are five actions to take now:
1. Demand transparency and explanation of the AI system. First and foremost, leaders need to hold themselves accountable. Particularly with AI systems targeting medical response, it’s important that decision makers understand which groups are represented in the datasets and what the quality of that data is across different groups. Tools such as Datasheets for Datasets are useful for tracking information on dataset creators; the composition, sampling, and labeling process; and intended uses. Leaders whose organizations develop AI systems should also ask questions like: Whose opinions, priorities, and expertise are included in development, and whose are left out?
2. Join and promote multidisciplinary ethics working groups or councils to inform response to COVID-19. This is already happening in Germany and can provide useful insights into how to respond to COVID-19, including using AI. Working groups are a way to bring together social scientists, philosophers, community leaders, and technical teams to discuss potential bias concerns and fairness tradeoffs, as well as solutions.
3. Build partnerships to fill health-data gaps in ways that protect and empower local communities. Nonprofits and universities are especially well-positioned to work with disenfranchised communities and form community research partnerships. In San Francisco, for example, a coalition of citywide Latinx organizations partnered with UCSF to form a COVID-19 task force. The coalition launched a project that tested nearly 3,000 residents in predominantly Latinx neighborhoods to better understand how the virus spreads. The task force and its local volunteers integrated concerns of community members and provided extensive support services to people who tested positive.
4. Advance research and innovation while emphasizing diversity and inclusion. Only a handful of tech companies and elite university labs develop most large-scale AI systems, and developers tend to be white, affluent, technically oriented, and male. Given that AI isn’t neutral and that technologies are a product of the context in which they are created, these systems often fail to meet the needs of different communities. Research initiatives like the recently launched Digital Transformation Institute, a collaborative effort to bring together tech companies and US research universities to fight COVID-19, must emphasize inclusion and justice (alongside innovation and efficiency), and prioritize multi-disciplinary and diverse teams. They can and should take advantage of tools like an AI Fairness Checklist in designing solutions.
5. Resist the urge to prioritize efficiency at the cost of justice and equity. Leaders should rise to the challenge of not compromising justice and equity. In some cases, the question is not how best to develop or deploy an AI system, but whether the AI system should be built or used at all.
As the pandemic continues to severely impact individuals, communities, and economies, nonprofit and business leaders must respond quickly—but not at the cost of heightening discrimination and inequality in the communities hardest hit by the pandemic. AI can help us improve medical response and minimize the spread of COVID-19, but using it wisely requires equity-fluent leadership and a long-term view. As Prashant Warier, CEO and co-founder of the AI company Qure.ai, put it, “Once people start using our algorithms, they never stop.”

Support SSIR’s coverage of cross-sector solutions to global challenges. 
Help us further the reach of innovative ideas. Donate today.

Read more stories by Genevieve Smith & Ishita Rustagi.
 

 



Genevieve Smith is the associate director at the Center for Equity, Gender and Leadership (EGAL) at the UC Berkeley Haas School of Business. For over a decade, she has conducted research and worked to advance gender equity and women's economic empowerment. She is the lead author of EGAL’s forthcoming playbook on mitigating bias in AI.
Ishita Rustagi is the business strategies and operations analyst at the Center for Equity, Gender and Leadership (EGAL) at the UC Berkeley Haas School of Business, where she supports the development of resources, tools, and thought leadership to advance diversity, equity, and inclusion. She is the co-author of EGAL’s playbook on mitigating bias in AI.
 

DOI: 10.48558/neme-4m86

",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vd3d3LnNjaWVuY2Uub3JnL2NvbnRlbnQvYXJ0aWNsZS9leWUtcm9ib3QtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZHJhbWF0aWNhbGx5LWltcHJvdmVzLWFjY3VyYWN5LWNsYXNzaWMtZXllLWV4YW3SAQA?oc=5,"Eye, robot: Artificial intelligence dramatically improves accuracy of classic eye exam - Science",2020-06-03,Science,https://www.science.org,N/A,N/A,But critics caution the online test isn’t quite ready for prime time,But critics caution the online test isn’t quite ready for prime time,N/A,N/A,"


The classic eye exam may be about to get an upgrade. Researchers have developed an online vision test—fueled by artificial intelligence (AI)—that produces much more accurate diagnoses than the sheet of capital letters we've been staring at since the 19th century. If perfected, the test could also help patients with eye diseases track their vision at home. ""It's an intriguing idea"" that reveals just how antiquated the classic eye test is, says Laura Green, an ophthalmologist at the Krieger Eye Institute. Green was not involved with the work, but she studies ways to use technology to improve access to health care. The classic eye exam, known as the Snellen chart, has been around since 1862. The farther down the sheet a person can read, the better their vision. The test is quick and easy to administer, but it has problems, says Chris Piech, a computer scientist at Stanford University. Patients start to guess at letters when they become blurry, he says, which means they can get different scores each time they take the test.

SIGN UP FOR THE SCIENCEADVISER NEWSLETTER
The latest news, commentary, and research, free to your inbox daily
Sign up


Piech is no stranger to the Snellen test. At age 10, doctors diagnosed him with chronic uveitis, an inflammatory eye disease. ""I was sitting through all these tests and it was pretty obvious to me that it was terribly inaccurate,"" he says. He wanted to find a way to remove human error from the Snellen exam, while improving its accuracy. So Piech and his colleagues developed an online test. Users first calibrate their screen size by adjusting a box on a web page to the size of a credit card. After entering the distance they are from the screen, the test displays an ""E"" in one of four orientations. Based on the answer, the algorithm then uses statistics to make a prediction for a vision score, similar to how AIs make a playlist based on your favorite artists, or what ads to show based on what you clicked on earlier. As the test goes on, the algorithm is able to make a more accurate prediction about the score. The test asks 20 questions per eye and takes a couple minutes to complete. When the researchers ran their ""Stanford acuity test"" (StAT) through 1000 computer simulations mimicking real patients, the diagnostic reduced error by 74% compared with the Snellen test, the team reports this month in the Proceedings of the AAAI Conference on Artificial Intelligence. The simulations work by starting with a known acuity score and factors in the types of mistakes a human might make. It then virtually ""takes"" the different eye tests in order to compare how accurate they are. The team used this instead of actual patients because it starts with the ""true"" acuity—something unknown in a human.Advertisement You can take StAT yourself at myeyes.ai, although Piech cautions that the test isn't meant to replace doctor visits just yet. ""It's definitely helpful,"" says Mark Blecher, an ophthalmologist in Philadelphia who's written opinion articles comparing various eye tests before. Online eye tests aren't really new, but Blecher commended the clever use of AI in boosting accuracy. Blecher says for the next step it would be important to consider the circumstances in which the user takes the test. Things like room lighting or screen brightness could affect the scores, he says. Whether the StAT test will actually replace the Snellen chart is up for debate. Blecher says getting all eye care professionals to agree on a new standard would be ""daunting at best"" because the status quo can be hard to overcome. Green is more optimistic. ""I think that it would very quickly get adopted by over 80% of ophthalmology practices,"" she says. ""We really are desperate to have some good way of doing this.""


",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vd3d3LmtkbnVnZ2V0cy5jb20vMjAyMC8wNi9haS1zeXN0ZW1zLW5lZWQtaHVtYW4taW50ZXJ2ZW50aW9uLmh0bWzSAQA?oc=5,Why Do AI Systems Need Human Intervention to Work Well? - KDnuggets,2020-06-05,KDnuggets,https://www.kdnuggets.com,"All is not well with artificial intelligence-based systems during the coronavirus pandemic. No, the virus does not impact AI – however, it does impact humans, without whom AI and ML systems cannot function properly. Surprised?",N/A,"All is not well with artificial intelligence-based systems during the coronavirus pandemic. No, the virus does not impact AI – however, it does impact humans, without whom AI and ML systems cannot function properly. Surprised?","All is not well with artificial intelligence-based systems during the coronavirus pandemic. No, the virus does not impact AI – however, it does impact humans, without whom AI and ML systems cannot function properly. Surprised?",2020 Jun Opinions,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9hLWJlZ2lubmVyLWZyaWVuZGx5LWV4cGxhbmF0aW9uLW9mLWhvdy1uZXVyYWwtbmV0d29ya3Mtd29yay01NTA2NGRiNjBkZjTSAQA?oc=5,A Beginner-Friendly Explanation of How Neural Networks Work - Towards Data Science,2020-06-02,Towards Data Science,https://towardsdatascience.com,"A few weeks ago, when I started to learn about neural networks, I found that the quality of introductory information for such a complex topic didn’t exist. I frequently read that neural networks are…",N/A,Understanding Neural Network Fundamentals for Five-Year-Olds,Understanding Neural Network Fundamentals for Five-Year-Olds,N/A,N/A,"Member-only storyA Beginner-Friendly Explanation of How Neural Networks WorkUnderstanding Neural Network Fundamentals for Five-Year-OldsTerence Shin, MSc, MBA·FollowPublished inTowards Data Science·6 min read·Jun 2, 20201891ListenShareImage by Ahmed Gad from PixabayTable of ContentPrefaceArtificial Intelligence, Machine Learning, and Neural NetworksThe Mechanics of a Basic Neural NetworkTypes of Neural NetworksNeural Network ApplicationsPrefaceA few weeks ago, when I started to learn about neural networks, I found that the quality of introductory information for such a complex topic didn’t exist. I frequently read that neural networks are algorithms that mimic the brain or have a brain-like structure, which didn’t really help me at all. Therefore, this article aims to teach the fundamentals of a neural network in a manner that is digestible for anyone, especially those that are new to machine learning.Artificial Intelligence, Machine Learning, and Neural NetworksBefore understanding what neural networks are, we need to take a few steps back and understand what artificial intelligence and machine learning are.Artificial Intelligence and Machine Learning",http://schema.org,,NewsArticle,['https://miro.medium.com/v2/resize:fit:1200/1*TVOzKardxUSe1rHUImbk3Q.png'],https://towardsdatascience.com/a-beginner-friendly-explanation-of-how-neural-networks-work-55064db60df4,2020-06-02T18:24:35.629Z,2020-06-02T18:24:35.629Z,2021-12-14T18:11:36.247Z,A Beginner-Friendly Explanation of How Neural Networks Work,A Beginner-Friendly Explanation of How Neural Networks Work,55064db60df4,"{'@type': 'Person', 'name': 'Terence Shin, MSc, MBA', 'url': 'https://terenceshin.medium.com'}","['Terence Shin, MSc, MBA']","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",https://towardsdatascience.com/a-beginner-friendly-explanation-of-how-neural-networks-work-55064db60df4,False,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vd3d3LmJhcmFuZGJlbmNoLmNvbS9jb2x1bW5zL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFuZC1sZWdhbC1wcm9mZXNzaW9uLWFuLWludGVsbGlnZW50LXdheS1haGVhZNIBc2h0dHBzOi8vd3d3LmJhcmFuZGJlbmNoLmNvbS9hbXAvc3RvcnkvY29sdW1ucy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hbmQtbGVnYWwtcHJvZmVzc2lvbi1hbi1pbnRlbGxpZ2VudC13YXktYWhlYWQ?oc=5,Artificial Intelligence and the Legal Profession: An 'intelligent' way ahead? - Bar & Bench - Indian Legal News,2020-06-03,Bar & Bench - Indian Legal News,https://www.barandbench.com,,"Artifical Intelligence,AI and Law firms","The advent of technology-driven economy and globalisation has brought along with itself several boons and banes, with the whole world becoming virtually closer.","The advent of technology-driven economy and globalisation has brought along with itself several boons and banes, with the whole world becoming virtually closer.",N/A,N/A,N/A,http://schema.org,,NewsArticle,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/barandbench/import/2016/05/AI.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",https://www.barandbench.com/columns/artificial-intelligence-and-legal-profession-an-intelligent-way-ahead,2020-06-03T10:17:48Z,2020-06-03T10:17:48Z,2020-06-03T10:17:48Z,Artificial Intelligence and the Legal Profession: An 'intelligent' way ahead?,Artificial Intelligence and the Legal Profession: An 'intelligent' way ahead?,,"[{'@type': 'Person', 'givenName': 'Ananth Kini', 'name': 'Ananth Kini', 'url': 'https://www.barandbench.com/author/ananth-kini'}]",,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Bar and Bench - Indian Legal news', 'url': 'https://www.barandbench.com', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'barandbench', 'contentUrl': 'https://gumlet.assettype.com/barandbench/2019-12/7a743b15-5d5d-44d7-96c2-13616780ed95/brand_2x.png', 'url': 'https://gumlet.assettype.com/barandbench/2019-12/7a743b15-5d5d-44d7-96c2-13616780ed95/brand_2x.png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://twitter.com/barandbench', 'https://www.youtube.com/barandbench', 'https://www.facebook.com/barandbench', 'https://www.linkedin.com/company/bar-&-bench', 'https://www.instagram.com/barandbench'], 'id': 'https://www.barandbench.com'}","{'@type': 'WebPage', '@id': 'https://www.barandbench.com/columns/artificial-intelligence-and-legal-profession-an-intelligent-way-ahead'}",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.barandbench.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'Columns', 'item': 'https://www.barandbench.com/columns'}, {'@type': 'ListItem', 'position': 3, 'name': ""Artificial Intelligence and the Legal Profession: An 'intelligent' way ahead?"", 'item': 'https://www.barandbench.com/columns/artificial-intelligence-and-legal-profession-an-intelligent-way-ahead'}]",https://media.assettype.com/barandbench/import/2016/05/AI.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"The advent of technology-driven economy and globalisation has brought along with itself several boons and banes, with the whole world becoming virtually closer. Among all these developments around the world, the one area that has perhaps grabbed the most eye-balls is Artificial Intelligence (AI)..Use of AI: A double-edged sword.AI, like any other innovation, has its own advantages and drawbacks. On the positive side, AI can help us get our work done with more efficiency and effectiveness along with being cost effective and time saving. But on negative side, it can literally usurp the employment of millions of people worldwide, irrespective of their job profile. In this regard, one can refer to McKinsey Global Institute’s study which has predicted that anywhere between 40 million and 160 million women worldwide may need transition of occupations by 2030. Although an increased reliance on automation may result in higher demands for jobs related to robotics science, engineering etc, the number of people rendered unemployed due to automation is highly disproportionate than those who would be employed..Further, the NITI Aayog in its report titled ‘National Strategy on Artificial Intelligence’, has exhaustively discussed the challenges, focus areas and global development of AI. It has stated therein that concerns of privacy of data, an unattractive Intellectual Property regime, low intensity of AI research, and low awareness for adopting AI in business processes, will be some of major impediments in successful deployment of AI in India..Use of AI in the legal system.The use of AI in the legal system is still in its nascent stage, but is slowly being adopted by several countries, law firms and judiciaries alike. It provides cost effective solutions to lawyers by pointing out the legal infirmities in judgments, providing assistance in drafting contractual documents, due diligence, legal analytics etc. Similarly, AI can act as catalyst in lessening the burden of the judiciary, especially in those cases that involve menial offences, leaving the complex cases to be decided by human judges..AI Ross, developed by IBM, has been adopted many law firms worldwide, particularly in the USA and is primarily used to vet legal contracts, conduct legal research, and briefly summarize case laws etc. Likewise, Linklaters LLP, a multinational law firm, is also developing an AI programme, Nakhoda, with the objective of providing effective contract management and structured legal data..The Treasury Board Secretariat of Canada has formulated directives on the use of automated decision-making. These state that the decisions made by the AI should be in consonance with basic tenets of fairness, transparency and legal principles..Amongst all these aforesaid developments in the AI related field, several core issues have emerged such as:a) What is the legal personality of AI? Can it be accorded the status of a ‘person’ or ‘citizen’?b) Who would be responsible if any loss occurs due to the negligence of an AI? Will the principle of absolute or vicarious liability apply in such a scenario? In the latter case, what punishment can be attributed to an artificial personality?c) How far can AI be used in the legal profession?d) Whether a person who avails the services of AI can be termed as a ‘Consumer’ under the Consumer Protection Act, 1986 etc..Much like its potential, the legal issues surrounding AI also seem to be endless. Though AI may seem to be attractive at first blush, it is fraught with many dangers that have been highlighted by several eminent scientists like Stephen Hawking, who said, ""…The primitive forms of artificial intelligence we already have proved very useful. But I fear the development of full artificial intelligence could spell the end of the human race. Once humans develop artificial intelligence, it would take off on its own, and re-design itself at an ever increasing rate. Humans, who are limited by slow biological evolution, couldn't compete and would be superseded."".Recent developments in the Indian legal profession.The growth of AI in the Indian legal field has been subdued. According to a study, only about 4% of lawyers in India make use of AI for their work. Cyril Amarchand Mangaldas is perhaps the first law firm in India to adopt AI which is primarily used to analyse and improvise contractual and other legal documents..I, Lawbot? Cyril Amarchand first Indian law firm to adopt artificial intelligence.The impact of AI on the legal profession and its consequent viability has aptly been described by former Chief Justice of India Dipak Misra while addressing a conference. He said,""...the future of any new-age technology lies in the regulations that govern them. Artificial Intelligence (AI) promises a high growth potential in a number of sectors… AI needs a strong legal framework around it to explore maximum benefits. AI today is growing multifold and we still do not know all the advantages or pitfalls…India has the right talent and technological resources. With a powerful legal directive, the country can set many milestones with a strong command over AI…But India currently does not have specific regulations that govern AI…"".Similarly, current CJI SA Bobde also spoke on similar lines and has advocated for greater use of AI in the legal system, especially in the field of docket management and decision making. At an the event organised by the Supreme Court Bar Association (SCBA), he opined,“…We must increasingly focus on harnessing IT and IT enabled services (ITES) for providing more efficient and cost-effective access to and delivery of justice. This must also include undertaking serious study concerning future of Artificial Intelligence in law, especially how Artificial Intelligence can assist in judicial decision making. I believe exploring this interface would be immensely beneficial for many reasons. For instance, it would allow us to streamline courts caseloads through enabling better court management. This would be a low hanging fruit. On the other end of the spectrum, it will allow us to shift the judicial time from routine-simple-straightforward matters (e.g. cases which are non-rivalrous) and apply them to more complex-intricate matters that require more human attention and involvement...Therefore, in India identification of such matters and developing relevant technology ought to be our next focus."".Justice DY Chandrachud has also spoken on similar lines, In an interview, he said, ""The idea of Artificial Intelligence is not to supplant the human brain or the human mind or the presence of judges but to provide a facilitative tool to judges to reassess the processes which they follow, to reassess the work which they do and to ensure that their outcome are more predictable and consistent and ultimately provide wider access to justice to the common citizens."".However, in developing countries like India, the usage of AI may not be regularized because of reluctance to adapt to this new change. There is also an apprehension that AI may cause serious ramifications in a labour surplus economy like India, with majority of people being uneducated and poverty stricken.In this context, Justice Dominique Hascher, judge at the Supreme Court of France, has rightly said that, ""Each nation today aims to become a global leader in Artificial Intelligence. Hence, countries such as the US, the UK, China and Germany are increasing investments to leverage this technology. However, private technology companies are acing the field…India’s approach towards AI strategy has to be balanced for both local needs and the greater good. A strong regulatory system around this can ensure long-term benefits and growth..The author is an advocate currently working in AUA Legal LLP, and practicing before the Delhi High Court and subordinate courts in the capital. He can be reached at advananthkini@gmail.com for any suggestions/comments.","{'@type': 'WebPage', 'url': 'https://www.barandbench.com/columns/artificial-intelligence-and-legal-profession-an-intelligent-way-ahead', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/barandbench/import/2016/05/AI.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",Columns,
https://news.google.com/rss/articles/CBMiS2h0dHBzOi8vdHJpYnVuZS5jb20ucGsvc3RvcnkvMjIzNDg4OS9mdXR1cmUtd2FyZmFyZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZdIBUWh0dHBzOi8vdHJpYnVuZS5jb20ucGsvc3RvcnkvMjIzNDg4OS9mdXR1cmUtd2FyZmFyZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZT9hbXA9MQ?oc=5,The future of warfare and Artificial Intelligence - The Express Tribune,2020-06-04,The Express Tribune,https://tribune.com.pk,The greatest impact of AI on warfare may be social since autonomous  AI driven machines increasingly replace humans ,"Consumer Electronics Show, Artificial intellegence","The greatest impact of AI on warfare may be social since autonomous, AI-driven machines increasingly replace humans","The greatest impact of AI on warfare may be social since autonomous, AI-driven machines increasingly replace humans",Opinion,N/A,N/A,https://schema.org,,NewsArticle,"{'@type': 'ImageObject', 'url': 'https://tribune-reloaded.s3.amazonaws.com/media/images/2234889-inamulhaquenew-1591212102/2234889-inamulhaquenew-1591212102.jpg', 'height': '640', 'width': '480'}",,,2020-06-04T05:35:03+05:00,2020-06-04T05:35:03+05:00,The future of warfare and Artificial Intelligence,,,"{'@type': 'Person', 'name': 'Inam Ul Haque', 'url': 'https://tribune.com.pk/author/7491/inam-ul-haque'}",,"{'@type': 'Organization', 'name': 'The Express Tribune', 'logo': {'@type': 'ImageObject', 'url': 'https://i.tribune.com.pk/media/images/logos/tribune-logo.webp', 'height': '62', 'width': '250'}}","{'@type': 'WebPage', '@id': 'https://tribune.com.pk/story/2234889/future-warfare-artificial-intelligence'}",,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vYW5hbHl0aWNzaW5kaWFtYWcuY29tL2dvdnQtbGF1bmNoZXMtYWktd2Vic2l0ZS1ob3ctd2lsbC1pdC1oZWxwLWluZGlhcy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbmR1c3RyeS_SAQA?oc=5,Govt Launches AI Website: How Will It Help India's Artificial Intelligence Industry? - AIM,2020-06-02,AIM,https://analyticsindiamag.com,N/A,N/A,N/A,N/A,N/A,N/A,"










				NVIDIA Blackwell Solidify Leadership, AMD & Intel to Gain Ground With MI300X & Gaudi3			



			Shyam Nandan Upadhyay		

			25/06/2024		


",,,,,,,,,,,,,,,,,,,,,,,

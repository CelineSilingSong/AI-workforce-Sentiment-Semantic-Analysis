URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,mainEntityOfPage,headline,image,datePublished,dateModified,article:section,article:summary,article text,url,author,publisher,articleSection,name,isAccessibleForFree,itemListElement,dateCreated,isPartOf,mentions,hasPart,address,diversityPolicy,email,legalName,leiCode,telephone,logo,brand,articleBody,creator,thumbnailUrl,@graph,identifier,isBasedOn,alternativeHeadline,@id,contactPoint,sameAs,genre,inLanguage,locationCreated,publishingPrinciples,caption,speakable,wordCount,articleMeta
https://news.google.com/rss/articles/CBMijwFodHRwczovL3d3dy5wcm5ld3N3aXJlLmNvbS9uZXdzLXJlbGVhc2VzLzcwLW9mLXVzLWVtcGxveWVlcy1ob2xkLXBvc2l0aXZlLXZpZXctb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tdGhlLXdvcmtwbGFjZS10b2RheS0zMDA4ODIxMjUuaHRtbNIBAA?oc=5,70% of U.S. Employees Hold Positive View of Artificial Intelligence in the Workplace Today - PR Newswire,2019-07-10,PR Newswire,https://www.prnewswire.com,"/PRNewswire/ -- Despite recent doom-and-gloom anecdotal reporting, a nationwide survey of 1,001 workers in the United States (U.S.) finds that 70% have an...",Genesys,"/PRNewswire/ -- Despite recent doom-and-gloom anecdotal reporting, a nationwide survey of 1,001 workers in the United States (U.S.) finds that 70% have an...","/PRNewswire/ -- Despite recent doom-and-gloom anecdotal reporting, a nationwide survey of 1,001 workers in the United States (U.S.) finds that 70% have an...",https://schema.org,NewsArticle,{'@id': 'https://www.prnewswire.com/news-releases/70-of-us-employees-hold-positive-view-of-artificial-intelligence-in-the-workplace-today-300882125.html'},70% of U.S. Employees Hold Positive View of Artificial Intelligence in the Workplace Today,"['https://mma.prnewswire.com/media/944880/Genesys_AI_Survey.jpg?p=facebook', 'https://mma.prnewswire.com/media/408485/Geneys_RGB_Logo.jpg?p=facebook']",2019-07-10T08:00:00-04:00,2019-07-10T08:00:00-04:00,N/A,N/A,"






70% of U.S. Employees Hold Positive View of Artificial Intelligence in the Workplace Today

Genesys survey results challenge common assumptions about AI job displacement fears

















News provided by

Genesys



Jul 10, 2019, 08:00 ET



Share this article









 














 









Share toX





 








Share this article


















Share toX


















SAN FRANCISCO, July 10, 2019 /PRNewswire/ -- Despite recent doom-and-gloom anecdotal reporting, a nationwide survey of 1,001 workers in the United States (U.S.) finds that 70% have an upbeat attitude toward new workplace technologies involving artificial intelligence (AI), such as chatbots, robots and augmented reality. Only 5% say they dislike new technology for putting their jobs at risk today. In fact, 32% of U.S. respondents feel AI will have a positive impact on their job in the next five years, increasing from 26% today. Just 19% of those surveyed express fear that AI/bots could swallow their jobs within the next decade.


Continue Reading

















Genesys survey finds the majority of U.S. employees have a favorable view of artificial intelligence (AI) at work.







These findings stem from new research by Genesys® (www.genesys.com), the global leader in omnichannel customer experience and contact center solutions, into the attitudes of employed Americans regarding the rising adoption of AI in the workplace. Genesys conducted an identical survey in six countries — the U.S., Germany, the United Kingdom, Japan, Australia, and New Zealand — for a total of 4,207 participants.

The picture isn't all rosy, however. While 75% of Americans surveyed say they are ""rarely"" or ""never"" threatened by new technology at work, one quarter do feel unsettled by it. Happily, only 4% ""always"" feel threatened. This is fairly similar to respondents in Germany, the U.K., Australia, and New Zealand, but in Japan that figure jumps to 12%.
Is AI a Friend or Future ""Frenemy""?While 52% of U.S. workers surveyed say AI has not yet affected their jobs, that number falls to 29% when asked about a five-year timeframe, with expectations for an increase in both positive and negative effects. Part of the reason for the low percentage of AI's current impact? It's not as ubiquitous in the workplace as many people would believe. Among U.S. respondents, 68% say they are not yet using tools that leverage AI; surprisingly, there is not a noteworthy difference between large and small companies. Survey results also shed light on AI's influence on employee social interaction, ethics and upskilling, with worker attitudes varying according to age, company size, job status and job function. The overall impression? Employees have a generally positive view of technology now, but are less certain if technology enabled with AI will be their friendly co-worker in the future, or a ""frenemy.""""The survey findings substantiate a long-held Genesys belief that a blended approach to AI is best in customer contact centers as well as the workplace in general,"" said Merijn te Booij, chief marketing officer for Genesys. ""Some jobs will evolve as human work combines with the capabilities of AI. The key for organizations adopting this intelligent technology is to help employees understand its potential to make their jobs more fulfilling by taking the mundane, easily automated tasks off their plates. This opens the door for more employees to apply skills AI just can't replace – like creativity, leadership and empathy.""Considering 27% of Americans say they simply cannot predict the impact of AI on their jobs five years down the road, and only half feel they have the skills to compete effectively, it's increasingly important for companies to closely monitor the pace of AI adoption and employee training programs to address it.A few additional U.S. findings related to overall attitudes toward AI include:
Two-thirds (66%) of the U.S. cohort say technology makes them more efficient in their jobs. This response is exactly the same across the three age ranges surveyed. 
8% of U.S. employees say they dislike new workplace technology such as AI and bots because it takes away their easy tasks. 
More part-time U.S. employees (25%) fear AI will take their jobs within 10 years than do full-time workers (18%). 
Surprisingly, exactly twice as many (26%) of the U.S. employees in the youngest cohort (ages 18-38) fear replacement by AI within the next decade as do their over-55 co-workers (13%). 
Nearly 70% of U.S. employees trust their employers to use AI in an ethical way.
Genesys will release additional insights from the survey in the coming weeks, with key findings related to specific demographic groups.Survey Methodology and ParticipantsWithin the U.S., a total of 1,001 adults completed the online survey in April. Respondents were evenly divided into three age ranges: 18-38, 39-54, 55-73, with women accounting for 65% and men 35%; less than 1% did not categorize by gender.Approximately 80% of those surveyed have full-time employee status with the remaining 20% working part-time. Respondents came from seven categories of company sizes, with a total of 42% employed in companies of fewer than 250 employees. While U.S. survey respondents work in a wide variety of industries, 77% fell into one of 11 functional job categories: Administrative, Assembly Line/Manufacturing, Customer Service/Retail, Doctor/Nurse/Caregiver, Education/Training, Finance/Accounting, Food Service, Human Resources, Marketing/Inside Sales, Media, and Driver/Transportation Provider. The remaining 23% fell into an ""Other"" job category.ATTENTION: For a copy of the full survey data, please contact the Genesys media relations team at genesys@sterlingpr.com.About GenesysGenesys® powers more than 25 billion of the world's best customer experiences each year. Our success comes from connecting employee and customer conversations on any channel. Every day, 11,000 companies in more than 100 countries trust our #1 customer experience platform to drive great business outcomes and create lasting relationships. Combining the best of technology and human ingenuity, we build solutions that mirror natural communication and work the way you think. Our industry-leading solutions foster true omnichannel engagement because they perform equally well across channels, on-premise and in the cloud. Experience communication as it should be: fluid, instinctive and profoundly empowering. Visit genesys.com on Twitter, Facebook, YouTube, LinkedIn and the Genesys blog.©2019 Genesys Telecommunications Laboratories, Inc. All rights reserved. Genesys and the Genesys logo are trademarks and/or registered trademarks of Genesys. All other company names and logos may be registered trademarks or trademarks of their respective companies. Contacts:Shaunna MorganSr. Public Relations ManagerGenesysshaunna.morgan@genesys.com+1 317-493-4241Adriana SaldañaSterling Communicationsgenesys@sterlingpr.com+1 408-395-5500SOURCE Genesys Related Links http://www.genesys.com







×
Modal title




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMikQFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Jlcm5hcmRtYXJyLzIwMTkvMDcvMDgvbWFuLXZzLW1hY2hpbmUtdGhlLTYtZ3JlYXRlc3QtYWktY2hhbGxlbmdlcy10by1zaG93Y2FzZS10aGUtcG93ZXItb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,Man Vs. Machine: The 6 Greatest AI Challenges To Showcase The Power Of Artificial Intelligence - Forbes,2019-07-08,Forbes,https://www.forbes.com,One of the ways to see just how far AI has come is to look at the history of when AI-powered machines battled humans in tasks and games that had previously been assumed to be the domain of humans. Here we pulled together the highlights of the history of challenges between man and AI.,,One of the ways to see just how far AI has come is to look at the history of when AI-powered machines battled humans in tasks and games that had previously been assumed to be the domain of humans. Here we pulled together the highlights of the history of challenges between man and AI.,One of the ways to see just how far AI has come is to look at the history of when AI-powered machines battled humans in tasks and games that had previously been assumed to be the domain of humans. Here we pulled together the highlights of the history of challenges between man and AI.,http://schema.org,BreadcrumbList,,Man Vs. Machine: The 6 Greatest AI Challenges To Showcase The Power Of Artificial Intelligence,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2019/07/AdobeStock_152392992-1200x800.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",2019-07-08T00:20:00-04:00,2019-07-08T00:20:28-04:00,Enterprise & Cloud,N/A,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryInnovationEnterprise TechMan Vs. Machine: The 6 Greatest AI Challenges To Showcase The Power Of Artificial IntelligenceBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowJul 8, 2019,12:20am EDTUpdated Jul 8, 2019, 12:20am EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinAs artificial intelligence (AI) research and development continues to strengthen, there have been some incredibly intriguing projects where machines battled man in tasks that were once thought the realm of humans. While not all were 100% successful, AI researchers and technology companies learned a lot about how to continue forward momentum as well as what a future might look like when machines and humans work alongside one another. Here are some of the highlights from when artificial intelligence battled humans.








Man Vs. Machine: The 6 Greatest AI Challenges To Showcase The Power Of Artificial Intelligence
Adobe Stock






World Champion chess player Garry Kasparov competed against artificial intelligence twice. In the first chess match-up between machine (IBM Deep Blue) and man (Kasparov) in 1996 Kasparov won. The next year, Deep Blue was victorious. When Deep Blue won, many talked that it was a sign that artificial intelligence was catching up to human intelligence and it inspired a documentary film called The Man vs. The Machine. Shortly after losing, Kasparov went on record to state he thought the IBM team had cheated; however, in an interview in 2016, Kasparov said he had analyzed the match and retracted his previous conclusion and cheating accusation.
In 2011, IBM Watson took on Ken Jennings and Brad Rutter, two of the most successful contestants of the game show Jeopardy who had collectively won $5 million during their reigns as Jeopardy champions. Watson won! To prepare for the competition, Watson played 100 games against past winners. The computer was the size of a room, was named after IBM’s founder Thomas J. Watson and required a powerful and noisy cooling system to keep its servers from overheating. Deep Blue and Watson were products that came from IBM’s Grand Challenge initiatives that pit man against machines. Since Jeopardy has a unique format where contestants provide the answers to the “clues” they are given, Watson first had to learn how to untangle the language to determine what was being asked even before it could do the work to figure out how to respond—a significant feat for natural language processing that resulted in IBM developing DeepQA, a software structure to do just that.
PROMOTED
Could artificial intelligence play Atari games better than humans? DeepMind Technologies took on this challenge, and in 2013 it applied its deep learning model to seven Atari 2600 games. This endeavor had to overcome the challenge of reinforcement learning to control agents directly from vision and speech inputs. The breakthroughs in computer vision and speech recognition allowed the innovators at DeepMind Technologies to develop a convolutional neural network for reinforcement learning to enable a machine to master several Atari games using only raw pixels as input and in a few games have better results than humans.

Next up in our review of man versus machine is the achievements of AlphaGo, a machine that is able to learn for itself what knowledge is. The supercomputer was able to learn 3,000 years of human knowledge in a mere 40 days prompting some to claim it was “one of the greatest advances ever in artificial intelligence.” The system had already learned how to beat the world champion of Go, an ancient board game that was once thought to be impossible for a machine to decipher. The film about the experience is now available on Netflix.  AlphaGo's success, when not being constrained by human knowledge, presents the possibility of the system being used to solve some of the world's most challenging problems such as in healthcare or energy or environmental concerns.
In another test of artificial intelligence capabilities, DeepMind sought out a more complex game for artificial intelligence to battle that required the use of different features of intelligence that are necessary to solve scientific and real-world problems. They found the next challenge in StarCraft II, a real-time strategy game created by Blizzard Entertainment that features multi-layered gameplay. AlphaStar was the first artificial intelligence to defeat professional players of the game by using its deep neural network that was trained from raw game data by reinforcement and supervised learning.
Project Debater, a project from IBM, tackles another area of expertise for artificial intelligence—debating humans on complex topics. This skill involves dissecting your opponent’s arguments and finding ways to appeal to their emotions (or the audience’s emotions)—something that would seem like a uniquely human ability to do. Even though Miss Project Debater lost when it faced off against one of the world’s leading debate champions, it was still an impressive display of artificial intelligence capabilities. To succeed at a debate, AI needs to rely on facts and logic, be able to make sense of an opponent’s line of reasoning and to navigate human language fully which has been one of the most challenging feats of all for AI to master. While not 100% successful, Project Debater gave a good glimpse of what’s possible in the future where machines can augment human intelligence in powerful ways.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",https://www.forbes.com/sites/bernardmarr/2019/07/08/man-vs-machine-the-6-greatest-ai-challenges-to-showcase-the-power-of-artificial-intelligence/,"{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Enterprise & Cloud,Man Vs. Machine: The 6 Greatest AI Challenges To Showcase The Power Of Artificial Intelligence,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vbWl0c2xvYW4ubWl0LmVkdS9pZGVhcy1tYWRlLXRvLW1hdHRlci9ldGhpY3MtYW5kLWF1dG9tYXRpb24td2hhdC10by1kby13aGVuLXdvcmtlcnMtYXJlLWRpc3BsYWNlZNIBAA?oc=5,Ethics and automation: What to do when workers are displaced - MIT Sloan News,2019-07-08,MIT Sloan News,https://mitsloan.mit.edu,"Automation and AI can create good jobs, benefit workers, improve productivity, and grow the economy. Here’s how to roll them out right.",N/A,"Automation and AI can create good jobs, benefit workers, improve productivity, and grow the economy. Here’s how to roll them out right.","Automation and AI can create good jobs, benefit workers, improve productivity, and grow the economy. Here’s how to roll them out right.",,,,,,,,N/A,N/A,"
 










recent




1 hour ago
Making generative AI work in the enterprise: New from MIT SMR




23 hours ago
How to tap AI’s potential while avoiding its pitfalls 




Jul 10, 2024
Banks’ climate pledges don’t add up to change, research finds


















Credit: iStock / PhonlamaiPhoto















Ideas Made to Matter


                        Artificial Intelligence


Ethics and automation: What to do when workers are displaced

By
 Tracy Mayor


Jul 8, 2019






Why It Matters		



Digital technologies are transforming the nature of human labor, enriching some workers, but leaving others behind. What’s the ethical approach?



















Share













































































facebook
X
linkedin
email
print

open share links
close share links

As companies embrace automation and artificial intelligence, some jobs will be created or enhanced, but many more are likely to go away. What obligation do organizations have to displaced workers in such situations? Is there an ethical way for business leaders to usher their workforces through digital disruption?
Researchers wrestled with those questions recently at MIT Technology Review’s EmTech Next conference. Their conclusion: Company leaders need to better understand the negative repercussions of the technologies they adopt and commit to building systems that drive economic growth and social cohesion.
Pramod Khargonekar, vice chancellor for research at University of California, Irvine, and Meera Sampath, associate vice chancellor for research at the State University of New York, presented findings from their paper, “Socially Responsible Automation: A Framework for Shaping the Future.”



Work smart with our Thinking Forward newsletterInsights from MIT experts, delivered every Tuesday morning.
Email Address









Leave this field blank





The research makes the case that “humans will and should remain critical and central to the workplace of the future, controlling, complementing and augmenting the strengths of technological solutions.” In this scenario, automation, artificial intelligence, and related technologies are tools that should be used to enrich human lives and livelihoods.  (Watch Khargonekar and Sampath's presentation here.)
Aspirational, yes, but how do we get there?
Khargonekar and Sampath explained the four levels of what they call the pyramid of progress:
Level 0: Cost-focused automation. At the lowest level of the pyramid, technology is used solely to gain economic benefits by reducing human labor. These cost-based programs are not only not socially conscious or human-centric, the researchers said, they often fail to deliver and can even be detrimental to business interests.
Level 1: Performance-driven automation. This approach is more cognizant of the role that humans play in the loop. Processes and systems are reengineered to take advantage of automation while still using human skills and capabilities to fill in technological shortfalls.
In Amazon’s warehouses, for example, employees perform tasks that require dexterity and flexibility, such as picking and packing goods, while robots take on routine heavy-lifting tasks like transporting loaded bins.
While such systems move beyond cost efficiencies, they typically are still driven by business metrics that don’t take into account larger implications of the workforce, nor the societal costs and benefits of automation.
Level 2: Worker-centered automation. At this level, the business goal is not just performance optimization, but worker development and enrichment. In these systems, the goal of automation is not to sideline people or replace them with machines, but to encourage new forms of human-machine interaction that augment human capabilities.
On Toyota’s manufacturing lines, workers manually produce goods at first, innovating and simplifying processes as they go, with machines taking over only after the process has been perfected.
While such approaches are workforce-empowering, strategies and choices are still viewed from the point of view of the organization, rather than in the context of a broader business-society ecosystem, the researchers write.
Level 3: Socially responsible automation. At the top of the pyramid, automation is deployed to produce more and better jobs for humans, driving economic growth while also promoting societal well-being. Attaining such a lofty goal requires “explicit, active interventions,” the authors write — that is, business leaders must commit to proactively identifying new revenue streams and job-enabling growth as they roll out and refine automation.
One example is Baltimore-based Marlin Steel, once known as the “king of bagel baskets.” Small business manufacturing is a segment where workers are particularly hard hit when automation is introduced, but Marlin Steel was able to buck that trend, Sampath explained.
Faced with declining demand for its products and rising competition, the company invested in robotics and automation, reengineered its production processes, enhanced its product line with highly engineered custom products, and expanded its client base — all by equipping its employees with the skills and training they needed to operate in its new, technology-driven workplace.
Giving workers a say — even in their own layoffs
If that’s the vision of socially responsible automation, the reality is less rosy, Khargonekar and Sampath conceded — at least in the short term.
When a moderator asked if most companies weren’t “stuck at the bottom row of the pyramid,” Sampath replied, “I really would say so. Today, industry focuses predominantly at the bottom-most level, cost savings, or perhaps the one level after that, which is performance-focused. So predominantly, we are still at the very bottom.”
That means that automation is likely to lead to layoffs; but even then, there’s a right way and wrong way to handle the process.
Susan Winterberg, a fellow in the Technology and Public Purpose Project at the Harvard Kennedy School’s Belfer Center for Science and International Affairs, cited her case study about Nokia Corp., written with Harvard Business School professor Susan Sucher. (Watch Winterberg's presentation here.)
The Finnish telecommunications giant had a tough time in recent years navigating the consumer electronics marketplace. In 2008, Nokia made the decision to close a mobile assembly plant in Bochum, Germany, despite having just posted record profit for the year. Gates to the factory were locked, and workers arriving for the day were redirected to a local arena where they were told their plant was not cost-effective and their jobs were moving overseas.
An ensuing round of public protests and boycott campaigns cost Nokia money, lost it customers, and damaged its brand worldwide, Winterberg said. Which is why the company took a different tack in 2011 when competition from the iPhone and Android forced it to restructure its mobile phone division.
The decision was made to close down eight research and development centers and two assembly plants and downsize five other assembly and manufacturing plants worldwide. In total, 1,800 people were scheduled to lose their jobs across 13 countries.
This time, Winterberg said, the company pledged to:
Accept its responsibility as a driver of local economies.
Take an active role in supporting employees, notifying workers months in advance of closures and involving impacted employees in the design and operation of support programs.
Communicate openly with all stakeholders, including employees, unions, governments, and local entities, even when Nokia itself did not yet have all the answers.
As part of its Nokia Bridge program, employees could find another job at Nokia, take advantage of training opportunities to learn a new skill, or apply for grants to pursue a different career path entirely. The firm set up career fairs for employees, even inviting their competitors in local markets.
Additionally, Nokia created an incubator program that helped employees leverage intellectual property it no longer needed into new business ventures — a move that helped not just individual workers, but spurred growth and innovation in the local economies it was exiting. Along the same lines, the company found buyers for its closing plants, so employment options would remain stable in affected communities.
The upshot was more than simple good will, Winterberg said. Throughout the process, the company was able to maintain its factory scorecards and employee engagement scores, which typically fall during restructuring, and to continue completing R&D projects in the pipeline, ensuring the future health of the firm.
Most relevant to the idea of ethics and automation is that organizations adopted a stewardship mindset, Winterberg said. They acknowledge that they’re employers, they’re contributors to their communities, and that they play an important role in their customers' lives.
Read next: The lure of 'so-so technology,' and how to avoid it









































For more info
Tracy Mayor
Senior Associate Director, Editorial

(617) 253-0065


tmayor@mit.edu






Related Articles












Ideas Made to Matter

Making generative AI work in the enterprise: New from MIT SMR












Ideas Made to Matter

How to tap AI’s potential while avoiding its pitfalls 












Ideas Made to Matter

How can we preserve human ability in the age of machines?



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LmJsb29tYmVyZy5jb20vbmV3cy9hcnRpY2xlcy8yMDE5LTA3LTA5L2FtZXJpY2Fucy1zdXJ2ZXllZC1zZWUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYXMtam9icy1raWxsZXLSAQA?oc=5,Americans Surveyed See Artificial Intelligence as Jobs Killer - Bloomberg,2019-07-09,Bloomberg,https://www.bloomberg.com,"While more Americans see businesses moving jobs abroad as a greater economic threat than artificial intelligence, the majority of workers expect that AI will also be a jobs killer.","Artificial Intelligence,Jobs,Education,Environment,Government,Career,Well Spent,Future of Work,Personal Finance,Technology,markets,technology,economics,economics","While more Americans see businesses moving jobs abroad as a greater economic threat than artificial intelligence, the majority of workers expect that AI will also be a jobs killer.","While more Americans see businesses moving jobs abroad as a greater economic threat than artificial intelligence, the majority of workers expect that AI will also be a jobs killer.",http://schema.org,NewsMediaOrganization,https://www.bloomberg.com/news/articles/2019-07-09/americans-surveyed-see-artificial-intelligence-as-jobs-killer,Americans Surveyed See Artificial Intelligence as Jobs Killer,"['https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i8d49QsVKE.E/v0/1200x674.jpg', 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iLcQTe5q48yE/v1/-1x-1.jpg', 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/social-default.cc6ae30e.jpg']",2019-07-09T13:36:22.895Z,2019-07-09T13:36:22.895Z,N/A,N/A,"MarketsEconomicsAmericans Surveyed See Artificial Intelligence as Jobs KillerFacebookTwitterLinkedInEmailLinkGiftExpand    Photographer: Akos Stiller/BloombergFacebookTwitterLinkedInEmailLinkGiftGift this articleHave a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MOREFacebookTwitterLinkedInEmailLinkGiftBy Shelly HaganJuly 9, 2019 at 9:36 AM EDTBookmarkSaveLock This article is for subscribers only.While more Americans see businesses moving jobs abroad as a greater economic threat than artificial intelligence, the majority of workers expect that AI will also be a jobs killer.As companies ramp up hiring to develop AI, workers agree they need retraining for today’s in-demand skills. At the same time, global workers -- particularly Americans -- say going back to school is no longer a feasible option, according to a survey by Northeastern University and Gallup.Have a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MORE",https://www.bloomberg.com,"[{'@type': 'Person', 'name': 'Shelly Hagan'}]","{'@type': 'Organization', 'name': 'Bloomberg', 'url': 'https://www.bloomberg.com', 'logo': {'@type': 'ImageObject', 'url': 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/bloomberg-logo-amp.bae0aa0a.png', 'width': 262, 'height': 60}}",,Bloomberg,False,,2019-07-09T13:36:22.895Z,"{'@type': ['CreativeWork', 'Product'], 'name': 'Bloomberg', 'productID': 'bloomberg.com:basic'}","[{'@type': 'CollectionPage', 'name': 'Markets', 'url': 'https://www.bloomberg.com/markets'}]","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}","{'@type': 'PostalAddress', 'addressCountry': 'USA', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10022', 'streetAddress': '731 Lexington Avenue'}",https://www.bloomberg.com/diversity-inclusion,inquiry1@bloomberg.net,Bloomberg Finance L.P.,5493001KJTIIGC8Y1R12,(212) 318-2000,https://www.bloomberg.com/logo-bloomberg.svg,"[{'@type': 'Brand', 'name': 'Bloomberg markets', 'url': 'https://www.bloomberg.com/markets'}, {'@type': 'Brand', 'name': 'Bloomberg technology', 'url': 'https://www.bloomberg.com/technology'}, {'@type': 'Brand', 'name': 'Bloomberg pursuits', 'url': 'https://www.bloomberg.com/pursuits'}, {'@type': 'Brand', 'name': 'Bloomberg politics', 'url': 'https://www.bloomberg.com/politics'}, {'@type': 'Brand', 'name': 'Bloomberg opinion', 'url': 'https://www.bloomberg.com/opinion', 'logo': 'https://www.bloomberg.com/logo-bloomberg_opinion.svg'}, {'@type': 'Brand', 'name': 'Bloomberg businessweek', 'url': 'https://www.bloomberg.com/businessweek', 'logo': 'https://www.bloomberg.com/logo-bloomberg_businessweek.svg'}, {'@type': 'Brand', 'name': 'Bloomberg green', 'url': 'https://www.bloomberg.com/green'}, {'@type': 'Brand', 'name': 'Bloomberg equality', 'url': 'https://www.bloomberg.com/equality'}, {'@type': 'Brand', 'name': 'Bloomberg citylab', 'url': 'https://www.bloomberg.com/citylab'}, {'@type': 'Brand', 'name': 'Bloomberg crypto', 'url': 'https://www.bloomberg.com/crypto'}, {'@type': 'Brand', 'name': 'Bloomberg industries', 'url': 'https://www.bloomberg.com/industries'}, {'@type': 'Brand', 'name': 'Bloomberg economics', 'url': 'https://www.bloomberg.com/economics'}, {'@type': 'Brand', 'name': 'Bloomberg ai', 'url': 'https://www.bloomberg.com/ai'}, {'@type': 'Brand', 'name': 'Bloomberg wealth', 'url': 'https://www.bloomberg.com/wealth'}]",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3LmR3LmNvbS9lbi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hcmUtbWFjaGluZXMtdGFraW5nLW92ZXIvYS00OTUxMjU5NtIBUWh0dHBzOi8vYW1wLmR3LmNvbS9lbi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hcmUtbWFjaGluZXMtdGFraW5nLW92ZXIvYS00OTUxMjU5Ng?oc=5,Artificial intelligence: Are machines taking over? - DW (English),2019-07-10,DW (English),https://www.dw.com,"Artificial intelligence expert Toby Walsh is convinced that machines will be as smart as human beings within just 50 years. He spoke to DW about the benefits, and ways to prevent the worst consequences.",N/A,"Artificial intelligence expert Toby Walsh is convinced that machines will be as smart as human beings within just 50 years. He spoke to DW about the benefits, and ways to prevent the worst consequences.","Artificial intelligence expert Toby Walsh is convinced that machines will be as smart as human beings within just 50 years. He spoke to DW about the benefits, and ways to prevent the worst consequences.",https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.dw.com/en/artificial-intelligence-are-machines-taking-over/a-49512596'}",Artificial intelligence: Are machines taking over? ,"['https://static.dw.com/image/46169980_804.jpg', 'https://static.dw.com/image/46169980_604.jpg']",2019-07-10T07:52:50.241Z,2019-07-10T10:32:46.25Z,N/A,N/A,"CultureArtificial intelligence: Are machines taking over? Stefan Dege als07/10/2019July 10, 2019Artificial intelligence expert Toby Walsh is convinced that machines will be as smart as human beings within just 50 years. He spoke to DW about the benefits, and ways to prevent the worst consequences.https://p.dw.com/p/3LkUGCopy linkImage: picture-alliance/dpa/K. WeiAdvertisementIn 2062: The World AI Made, Toby Walsh renders a dystopic vision of our technology-driven future. Published in 2018, the Australian writer who is also one of the world's leading scientists in the field of artificial intelligence, chose the year 2062 because his daughter would have been as old that year as he was when he wrote the book. 
Walsh makes clear how AI will change our lives, our work, but also have effects on politics and society in general. He also sets out to answer important questions: Will robots develop consciousness? Will we end up becoming machines ourselves? And how will we wage wars in the future?
The author and researcher was recently in Germany to speak at ""Recalculating the Route,"" a cultural symposium themed around the future held at the Goethe Institute in Weimar in June. DW talked further with Walsh about his visions for the future.
Read more: Artificial intelligence: The EU's 7 steps for trusty AI
DW: People have long been scared of machines. Is there a growing justification for this fear in 2019? 
Toby Walsh: There's a deep psychological fear in our psyche that goes back millennia, one in which people think that machines might actually take over. Actually, I think the things we should be fearful of are actually not the intelligent machines, but the stupidity of machines. And that we'll be giving responsibility to machines that don't have the appropriate intelligence.
Certainly machines have no consciousness, no sentience, no desires of their own. Machines do only what we tell them to do; they're not going to suddenly wake up and decide to take over the planet.
The problem with machines is is that they do exactly what we tell them to do. And sometimes we haven't thought carefully through what we're telling them to do. 

Part of the intention of my book is to prompt people not to be so worried about these sorts of Terminator scenarios in which machines rise up and take over the world. However, they should realize that it's actually much more insidious that we are already handing over decisions to machines that might be biased, might be racist or sexist, and all these sorts of things that we've been trying to get out of a society for the last hundred years.
How might AI actually serve to improve our future? 
To live in the world in a more sustainable way, we have to embrace technology. If we think of all the challenges facing the world, the only hope we have to deal with all these stresses is what we've done for the last hundred years, which is to embrace technology.
Read more: Can AI create real art?
People forget that since the Industrial Revolution, in a wealthy country like Germany, life expectancy has nearly doubled — because of the fact that we have used technologies. We have used science to live healthier lives, to understand disease and to invent things like penicillin that have allowed us to live much longer. 
Politics have completely failed us, so our only hope now is to deal with things like climate change by looking for technical fixes.
Toby Walsh says artificial intelligence can bring great benefits, but also pitfalls   Image: DW/S. Dege
Do you think AI will become our new God?
I think the risk is that we won't be gods ourselves. There'll be an underclass of people who are unemployed and unemployable because the machines are doing all the work and the wealth is owned by a very few small number of individuals who are the owners of the robots. So, we'll be far from God. We'll be living a very low-quality life. At the end of the day, technology is to be used for us.
And it will hopefully amplify our humanity. After all, it's all those very human things — our empathy, our social intelligence, our emotional intelligence, our creativity — that machines don't have today.
Read more: Resistance to killer robots growing
And it's not clear if they ever will have those things. We are ultimately going to appreciate things that are touched or made by the human hand. We pay much more for handcrafted breads and homemade beer — and all those things that only humans make — than for the mass-produced things the machines make.
A woman looks at a work of art created by an algorithm in 2018. It was produced by a French collective ""Obvious,"" which produces art using artificial intelligence.Image: Getty Images/AFP/T.A. Clary
What should we do now to better control the way we utilize machines in the future?
People need to be better educated about the risks. We need regulation; we need governments. We're discovering that we have to properly regulate the tech sector, just like we regulated big oil and big pharma and big tobacco. All of those companies had to be regulated so that they worked for the public good.
Europe is leading the way. The General Data Protection Regulation is a beginning, an example of how to get appropriate privacy, and to get the tech companies behaving with our data more appropriately. And the interesting thing is, my friends and colleagues working in the tech sector will tell you in private they need to be regulated.

So we live in interesting times?
Yes, very interesting times. But equally, it's amazing that the biggest changes in our lives have been in the past 30 years. We've had the internet only in the last 30 years. We've only had smartphones for a dozen years. Hard to imagine we could live now without these.
They've both been a great convenience in our lives. And that's why we have to think more carefully about technology and how it can help us to tackle those wicked problems like climate change and rising inequality and the global refugee problem. Technologies can help us do that.
Toby Walsh is Professor of Artificial Intelligence at the University of New South Wales, Australia. He leads a research group focusing on algorithmic decision theory. In 2018, he was a visiting professor at the Institute of Software Engineering and Computer Science at the Technical University of Berlin.
Do you really want AI in your life?To view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 video02:14
Send us your feedbackYour feedbackAdvertisement",,"[{'@type': 'Person', 'name': 'Stefan Dege'}]","{'@type': 'Organization', 'name': 'Deutsche Welle', 'logo': {'@type': 'ImageObject', 'url': 'https://dw.com/images/icons/favicon-180x180.png', 'width': '180', 'height': '180'}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmJ1c2luZXNzaW5zdXJhbmNlLmNvbS9hcnRpY2xlLzIwMTkwNzA5L05FV1MwNi85MTIzMjk0ODMvQUktZHJpdmVuLWhpcmluZy1jb3VsZC1zcGFyay1lbXBsb3ltZW50LWxpdGlnYXRpb27SAQA?oc=5,AI-driven hiring could spark employment litigation - Business Insurance,2019-07-09,Business Insurance,https://www.businessinsurance.com,Companies using artificial intelligence technologies in the recruitment and hiring process may face employment practices claims if other states follow Illinois in trying to restrict the use of artificial intelligence in video interviews.,N/A,Companies using artificial intelligence technologies in the recruitment and hiring process may face employment practices claims if other states follow Illinois in trying to restrict the use of artificial intelligence in video interviews.,Companies using artificial intelligence technologies in the recruitment and hiring process may face employment practices claims if other states follow Illinois in trying to restrict the use of artificial intelligence in video interviews.,,,,,,,,N/A,N/A,"





Risk Management

AI-driven hiring could spark employment litigation



Claire Wilkinson


July 09, 2019



Reprints



Share

Facebook
LinkedIn
Google +
Twitter


Emerging Risks
Employment Practices
General liability
Technology
More +
Less -









Companies using artificial intelligence technologies in the recruitment and hiring process may face employment practices claims if other states follow Illinois in trying to restrict the use of artificial intelligence in video interviews.
The Artificial Intelligence Video Interview Act passed by the Illinois General Assembly on May 29 and sent to Gov. J.B. Pritzker is considered first-of-its-kind legislation but could be adopted by other states with strong employee and job applicant protections, experts say.
The Illinois governor has 60 calendar days to sign a law or veto it — doing nothing means the bill becomes state law after the 60 days. The Governor’s office was not immediately available to respond to a request for comment.
The law is an “important first step” in legislating how artificial intelligence should be used in the employment context, said Gary Clark, Chicago-based chair of the labor and employment group for Quarles & Brady LLP.
“The failure to fully investigate and understand the use of artificial intelligence technology whether in this context or others could expose employers to huge legal liability if they just jump right in and start using it,” said Mr. Clark.
“Any time you are using artificial intelligence in the human resources or recruiting or employment function, you need to do a deep dive into how it’s being used and to fully evaluate what risks may result from how it’s being used with regard to video interviews,” he said.
While the Illinois statute requires employers to notify applicants before an interview that artificial intelligence may be used and explain how the technology works, it “doesn’t have a whole lot of teeth” in its current form, said John Litchfield, senior counsel at Foley & Lardner LLP in Chicago.
“It’s hard to know if rules will be developed by a state agency like the Department of Labor to enforce the law and, if they are developed, what type of penalties or issues may arise as a result for employers and for companies developing the software,” he said.
The Illinois law is considered the first of its kind, but other states may follow its lead, which could trigger an increase in employment practices liability insurance claims and force companies to increase their focus on managing these risks, experts say.
“There will be other states that will come on board, mainly the employment-sophisticated states like California, New York, Massachusetts, New Jersey — states that have strict regulations over how employers can treat employees and applicants,” Mr. Litchfield said.
While in its current form there are no penalties or fines attached to the Illinois act, it is “definitely something to watch for in case there are amendments,” said Sheryl Falk, Houston-based partner and co-lead of the global privacy and data security task force at Winston & Strawn LLP.
Citing another ground-breaking law, the Illinois Biometric Information Act passed in 2008, Ms. Falk said “the keen difference is that the Illinois (biometrics) law provides a private right of action, so a consumer can sue the employer if the employer has not complied with the law.”
“Any time there’s a new law on the books that’s setting up best practices and required standards, this raises liability. It’s even more critical for companies to be clear and accurate about how they are using this data,” said Ms. Falk, who is also a member of the technical advisory board of Utah-based HireVue Inc., a software firm that uses artificial intelligence in its video interviewing platform.
The Illinois artificial intelligence statute incorporates elements from the ethical frameworks that many companies already operate under, such as concepts of notice and transparency, she said.
Employers also must obtain consent from applicants before the interview and only share the videos with those whose expertise is necessary to evaluate the applicant’s fitness for a position, she said.
Similar to the Illinois Biometric Information Act, assuming a private right of action is granted under the law, there is a potential for claims alleging that the employer failed to adhere to the specific notice requirements of the Artificial Intelligence Video Interview Act, said Talene Carter, New York-based national employment practices liability product leader for FINEX North America at Willis Towers Watson PLC.
“Those types of claims could trigger employment practices liability coverage as invasion of privacy, as misrepresentation,” Ms. Carter said.
However, the act could also spur an increase in other, more traditional employment practice violations, experts say.
These types of issues relate to whether employers are screening applicants out based on their gender, race or disability at a higher rate than people that don’t fall within those protected categories, said Mr. Litchfield.
“It’s important for employers and software developers creating this technology to keep in mind the traditional, everyday bread-and-butter labor and employment issues that exist regardless of whether an interview is taking place by a machine or robot or a human-to-human interaction,” he said.
If the artificial intelligence technology that evaluates a candidate’s suitability for a job based on certain characteristics such as speech patterns or body language is found to discriminate against people with disabilities, that could violate the Americans with Disabilities Act, said Mr. Clark.
“Similarly, if the characteristics or speech patterns this technology looks for tend to discriminate against a specific race, gender, national origin or sexual orientation, that could have huge risks as it could violate Title VII,” he said, referring to the Civil Rights Act of 1964.
There are different ways coverage under an employment practices liability insurance policy could be triggered, said Ms. Carter.
“There’s a potential for discrimination claims, there’s a potential for failure to hire, there’s the potential for unintentional discriminatory impact,” she said.
For example, there’s no reference in the statute to what happens if an individual did not consent to the use of artificial intelligence, she said. In this scenario, if an employer removes an applicant from consideration, “there might be a potential claim there,” Ms. Carter said.
State Rep. Jaime Andrade Jr., D-Chicago, a sponsor of the legislation, said the purpose of the act is not to “set up landmines for companies so that people can sue.”
“It is about being fair and transparent,” he said.
Kevin Parker, chief executive officer of HireVue Inc., said the company is “broadly supportive of the intentions and goals of the act in terms of candidate privacy and transparency.”
“There’s always been an abundance of caution for companies broadly to make sure there’s no adverse impact associated with any part of the hiring process. That has always extended to how they think about how they use video interviewing generally and how they use artificial intelligence to support their interviewing efforts,” Mr. Parker said.
HireVue does a “significant amount” of analysis before interviewing anyone to ensure “there is no adverse impact, or we eliminate it if we find it,” he said.
“We do a lot of testing with gender differences, age differences, ethnic differences … We can look at every group as they go through the model and see where the adverse impact might arise and eliminate that from the analysis going forward,” he said.
In the meantime, both employers and insurers should be looking at their employment practices liability insurance policies to check their coverage for “artificial intelligence-type liability in the employment context,” said Mr. Litchfield.
“Everyone should be looking at this and analyzing the risks,” he said.
From the insurers’ perspective, if a private right of action is added to the statute and an influx of claims follows, markets may start to narrow coverage for invasion of privacy employment practices liability violations, said Ms. Carter.
“There’s a potential that as we start to see more use of artificial intelligence in the employment context and if we see more states enacting similar statutes, that we may see some changes in the underwriting of employment practices liability policies,” she said.



Read Next



Illinois high court takes on biometrics privacy case

                                                The Illinois Supreme Court is set to decide whether plaintiffs can successfully sue firms for violating the Illinois Biometric Information Act for allegedly failing to properly notify people about their policies even if no actual harm is claimed.
                                            





 Related Stories 



 Illinois high court takes on biometrics privacy case



Readers Poll




Your response has been saved successfully.


Please select one option.

Most Read in Risk Management


 1. 2024 Brokers Profiles: World's 10 Largest Insurance Brokers


 2. Axa XL names three new CUOs


 3. Marsh unit to buy Horton


 4. Chubb makes more executive moves


 5. Top insurance brokers, No. 3: Arthur J. Gallagher & Co.


 6. Research & Rankings: BI Top 100


Sign up for Daily Briefing, the free email newsletter from Business Insurance.

*First Name:*Last Name:*Email Address:*Company Name:*Industry:Select...Accounting FirmActuarial/Appraisal FirmAd Agency/PR/Marketing CompanyAgricultureAssociationBank/Financial InstitutionBusiness Service FirmsCaptive ManagementClaims/Third Party Administrator/AdjusterConstructionConsulting FirmEducational Institute/College/UniversityGovernmentHealth Care ProviderInsurance Agency/BrokerageInsurance/Reinsurance CompanyLaw FirmManaging General Agent (MGA)Manufacturing/UtilitiesReal EstateReligious/Non Profit OrganizationRetail, Restaurant, HospitalityService Provider (Outside Counsel, TPA, Etc.)Technology ProvidersTransportation/Communications/Electric/GasUnionWholesale TradeOther*Job Function:Select...Accountant/FinanceActuaryAdministrative/AssistantAdvertiser/Marketer/PR ProfessionalAgent (Resale)Agent (Wholesale)Analyst - Business/ResearchAppraiserAttorney/General CounselCaptive ManagerClaimsComplianceCustomer ServiceCyber SecurityDiversity/InclusionEducator/ProfessorExecutive/LeadershipHuman Resources/BenefitsInsurance AgentInsurance BrokerIT ProfessionalRecruiterRisk ManagementSafety/SecuritySales (Not Agent/Broker)Service Provider (TPA, Consultant, Outside Counsel)StudentUnderwriterWorkers CompOther (specify)Submit














X

            Sign up now for free access to this article and much more.
        

            If you are already registered with Business Insurance, click here to Login


Please tell us a bit more about yourself in order to continue


First Name



Last Name



Email

Invalid email address.


Company Name



Job Function

--Select--
Accountant/Finance
Advertiser/Marketer/PR Professional
Agent (Resale)
Agent (Wholesale)
Attorney/General Counsel
Broker
Chief Technology/Information Officer
Claims 
CSuite/Executive Management
Human Resources/Benefits
Risk Manager
Sales
Service Provider (TPA, Consultant, Outside Counsel)
Student

Required


Type of Business

--Select--
Agriculture/Forestry/Fishing
Construction
Finance, Banking & Real Estate Services
Government/Education/NonProfit
Hospitality
Insurance
Manufacturing/Utilities
Services
Technology
Transportation/Communications/Electric/Gas
Wholesale/Retail Trade

Required








X




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3LmxhdGltZXMuY29tL2VudGVydGFpbm1lbnQvYXJ0cy9sYS1ldC1jbS13YXluZS1tY2dyZWdvci1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1wcmVtaWVyZS0yMDE5MDcxMC1zdG9yeS5odG1s0gEA?oc=5,Can artificial intelligence become a choreographer? Wayne McGregor brings AI to L.A. - Los Angeles Times,2019-07-10,Los Angeles Times,https://www.latimes.com,"Premiering Friday at the Music Center, ""Living Archive: An AI Performance Experiment"" was created in collaboration with Google Arts & Culture. ",N/A,"From his early years choreographing in the 1990s, Wayne McGregor has been fascinated by the intersection of dance with science and technology. ","From his early years choreographing in the 1990s, Wayne McGregor has been fascinated by the intersection of dance with science and technology. ",http://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.latimes.com/entertainment/arts/la-et-cm-wayne-mcgregor-artificial-intelligence-premiere-20190710-story.html'}",Can artificial intelligence become a choreographer? Wayne McGregor brings AI to L.A.,"[{'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 836, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/d4f9d01/2147483647/strip/false/crop/2047x1151+0+0/resize/1486x836!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F29%2F50%2F3de5bf75690dcaefa97273a89e74%2Fla-1562181113-qdjq3v5ix3-snap-image', 'width': 1486}, {'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 675, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/65c6fe8/2147483647/strip/false/crop/2046x1151+0+0/resize/1200x675!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F29%2F50%2F3de5bf75690dcaefa97273a89e74%2Fla-1562181113-qdjq3v5ix3-snap-image', 'width': 1200}]",2019-07-10T14:00:01.000Z,2019-07-16T16:56:43.390Z,Entertainment & Arts,N/A,"    By Makeda Easter   July 10, 2019 7 AM PT      Share       Share via Close extra sharing options    Email     Facebook    X    LinkedIn    Threads    Reddit    WhatsApp    Copy Link URLCopied!   Print        From his early years choreographing in the 1990s, Wayne McGregor has been fascinated by the intersection of dance with science and technology.The British choreographer based his 2008 work “Entity” for his ensemble Company Wayne McGregor, on collaborative research with psychologists, neuroscientists and software engineers. McGregor tapped into a full sequence of his own genetic code for 2017’s “Autobiography” and he has choreographed with drones — spherical orbs programmed by an algorithm — for an installation featuring his company and members of the Royal Ballet where he’s the resident choreographer.For one of his latest works, McGregor collaborated with Google Arts & Culture to develop an artificial intelligence-powered tool that creates original dance movement. The work, “Living Archive: An AI Performance Experiment,” makes its world premiere Friday at the Music Center’s Dorothy Chandler Pavilion. Advertisement   It’s part of “Adès & McGregor: A Dance Collaboration” featuring composer-conductor Thomas Adès, the L.A. Phil, England’s Royal Ballet and Company Wayne McGregor.McGregor choreographed the three works on the program, including 2010’s “Outlier” a collaborative performance with the Royal Ballet and Company Wayne McGregor, and the world premiere of “The Dante Project (Inferno),” enacted by the Royal Ballet and inspired by the poet’s 14th century epic work, the “Divine Comedy.”Review: Royal Ballet comes to L.A. for the first time in years with ‘Mayerling’ »   But the structure of the AI-assisted work is more nebulous.Set to Adès’ “In Seven Days,” a 2008 piece for piano and orchestra based on the biblical creation myth, the deliberately untitled work is “a philosophical meditation on how a dance is made,” McGregor said by phone. It explores questions like: what does it mean to choreograph? And can interesting choreography be made with help from artificial intelligence?“That’s why I called it a performance experiment,” McGregor said. “We’re going to see how that plays out on stage.”             ×        Advertisement    Creating an artificial intelligence system that could not only understand McGregor’s movement vocabulary but also create new choreography based on his style, was a two-year process.McGregor teamed up with Google engineers and creative technologists to train the algorithm, called “Living Archive,” using thousands of hours of video from the choreographer’s previous works over 25 years. It was a way of “activating the archives” and “hijacking its past,” McGregor said.The technology also learned the distinct way each of McGregor’s 10 company dancers moved. Cameras captured dancers’ solos, detecting the forms of their individual poses, and then it provided suggestions for the next choreographic sequences, displaying them — in the form of constellation-like stick-figure avatars — on a screen in real time.McGregor compared the tool to predictive text, a technology that suggests words while typing on a phone. This choreographic catalyst is more sophisticated though, he said. ”It takes the essence of what that dancer is doing — the shape, the position, the dynamic, the articulation of that body. Then it uses that information to develop the next potential phrase.”Presented with options for possible sequences of movement, the dancer could then either use the phrase, interpret it in their own way or use it to inspire improvisation. “It’s a real recursive process between the dancer and the AI system,” the choreographer said.McGregor gravitated toward less obvious choreographic choices from the tool — “the unusualness, the things that you don’t recognize,” he said. “We’re looking for surprise, we’re looking for the body misbehaving, we’re looking for errors, we’re looking for anomalies.”The AI collaboration was like adding another dancer to his company, McGregor said. “It’s exploiting opportunities in the data you can never see yourself.”The work is part of the long tradition of modern and contemporary choreographers turning to technology to create.Throughout his 70-year career, Merce Cunningham embraced technology, using the software DanceForms as a choreographic tool in the 1990s. In 2005, Trisha Brown developed a 30-minute work using an artist-designed, artificial intelligence program that responded instantly to dancers’ movements with animated graphics. And this year, Bill T. Jones partnered with Google’s Creative Lab to experiment with the company’s PoseNet program, a machine-learning model that can recognize the positioning of human figures in real time.For some, the thought of artificial intelligence creating a dance work conjures a dystopian future where machines have replaced human artists. But McGregor didn’t seem too worried.“It’s not a question about whether or not the AI is creative,” he said. “Because firstly, creative people have made it and [the tool] is creating really interesting solutions to physical problems.”In a time where choreographers are planning how to carry out their life’s work long after they’re gone, McGregor envisioned a future where a machine could still carry on the legacy of his work 100 years from now.“But is there a moment where the dances that the AI system makes are more interesting than the dances the humans make?” McGregor wondered. “I don’t know yet. But there is a very interesting potential.”======Adès & McGregor: A Dance CollaborationWhen: 7:30 p.m. Friday-SaturdayTickets: $34-$138Where: Dorothy Chandler Pavilion, 135 N. Grand Avenue, L.A.Info: www.musiccenter.orgmakeda.easter@latimes.com@makedaeaster   More to Read               Opinion: What’s behind the AI boom? Exploited humans   July 12, 2024                NBCUniversal’s Donna Langley on AI: ‘We’ve got to get the ethics of it right’   June 21, 2024                Opinion: As AI is embraced, what happens to the artists whose work was stolen to build it?   June 18, 2024         ",https://www.latimes.com/entertainment/arts/la-et-cm-wayne-mcgregor-artificial-intelligence-premiere-20190710-story.html,"[{'@context': 'http://schema.org', '@type': 'Person', 'description': 'Makeda Easter is a former arts reporter at the Los Angeles Times.', 'name': 'Makeda Easter', 'url': 'https://www.latimes.com/people/makeda-easter'}]","{'@type': 'Organization', 'name': 'Los Angeles Times', 'logo': {'@type': 'ImageObject', 'url': 'https://ca-times.brightspotcdn.com/dims4/default/954b438/2147483647/strip/false/crop/382x60+0+0/resize/382x60!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fde%2F5f%2F46c2d05b430cbc6e775301df1062%2Flogo-full-black.png', 'width': 382, 'height': 60}}",Entertainment & Arts,Can artificial intelligence become a choreographer? Wayne McGregor brings AI to L.A. - Los Angeles Times,False,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Los Angeles Times', 'productID': 'lanews:all-access'}",,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}",,,,,,,,,"From his early years choreographing in the 1990s, Wayne McGregor has been fascinated by the intersection of dance with science and technology. The British choreographer based his 2008 work “Entity” for his ensemble Company Wayne McGregor, on collaborative research with psychologists, neuroscientists and software engineers. McGregor tapped into a full sequence of his own genetic code for 2017’s “Autobiography” and he has choreographed with drones — spherical orbs programmed by an algorithm — for an installation featuring his company and members of the Royal Ballet where he’s the resident choreographer. For one of his latest works, McGregor collaborated with Google Arts & Culture to develop an artificial intelligence-powered tool that creates original dance movement. The work, “Living Archive: An AI Performance Experiment,” makes its world premiere Friday at the Music Center’s Dorothy Chandler Pavilion. It’s part of “Adès & McGregor: A Dance Collaboration” featuring composer-conductor Thomas Adès, the L.A. Phil, England’s Royal Ballet and Company Wayne McGregor. McGregor choreographed the three works on the program, including 2010’s “Outlier” a collaborative performance with the Royal Ballet and Company Wayne McGregor, and the world premiere of “The Dante Project (Inferno),” enacted by the Royal Ballet and inspired by the poet’s 14th century epic work, the “Divine Comedy.” Review: Royal Ballet comes to L.A. for the first time in years with ‘Mayerling’ » But the structure of the AI-assisted work is more nebulous. Set to Adès’ “In Seven Days,” a 2008 piece for piano and orchestra based on the biblical creation myth, the deliberately untitled work is “a philosophical meditation on how a dance is made,” McGregor said by phone. It explores questions like: what does it mean to choreograph? And can interesting choreography be made with help from artificial intelligence? “That’s why I called it a performance experiment,” McGregor said. “We’re going to see how that plays out on stage.” Creating an artificial intelligence system that could not only understand McGregor’s movement vocabulary but also create new choreography based on his style, was a two-year process. McGregor teamed up with Google engineers and creative technologists to train the algorithm, called “Living Archive,” using thousands of hours of video from the choreographer’s previous works over 25 years. It was a way of “activating the archives” and “hijacking its past,” McGregor said. The technology also learned the distinct way each of McGregor’s 10 company dancers moved. Cameras captured dancers’ solos, detecting the forms of their individual poses, and then it provided suggestions for the next choreographic sequences, displaying them — in the form of constellation-like stick-figure avatars — on a screen in real time. McGregor compared the tool to predictive text, a technology that suggests words while typing on a phone. This choreographic catalyst is more sophisticated though, he said. ”It takes the essence of what that dancer is doing — the shape, the position, the dynamic, the articulation of that body. Then it uses that information to develop the next potential phrase.” Presented with options for possible sequences of movement, the dancer could then either use the phrase, interpret it in their own way or use it to inspire improvisation. “It’s a real recursive process between the dancer and the AI system,” the choreographer said. McGregor gravitated toward less obvious choreographic choices from the tool — “the unusualness, the things that you don’t recognize,” he said. “We’re looking for surprise, we’re looking for the body misbehaving, we’re looking for errors, we’re looking for anomalies.” The AI collaboration was like adding another dancer to his company, McGregor said. ""It's exploiting opportunities in the data you can never see yourself.” The work is part of the long tradition of modern and contemporary choreographers turning to technology to create. Throughout his 70-year career, Merce Cunningham embraced technology, using the software DanceForms as a choreographic tool in the 1990s. In 2005, Trisha Brown developed a 30-minute work using an artist-designed, artificial intelligence program that responded instantly to dancers’ movements with animated graphics. And this year, Bill T. Jones partnered with Google’s Creative Lab to experiment with the company’s PoseNet program, a machine-learning model that can recognize the positioning of human figures in real time. For some, the thought of artificial intelligence creating a dance work conjures a dystopian future where machines have replaced human artists. But McGregor didn’t seem too worried. “It's not a question about whether or not the AI is creative,” he said. “Because firstly, creative people have made it and [the tool] is creating really interesting solutions to physical problems.” In a time where choreographers are planning how to carry out their life’s work long after they’re gone, McGregor envisioned a future where a machine could still carry on the legacy of his work 100 years from now. “But is there a moment where the dances that the AI system makes are more interesting than the dances the humans make?” McGregor wondered. “I don't know yet. But there is a very interesting potential.” ====== Adès & McGregor: A Dance Collaboration When: 7:30 p.m. Friday-Saturday Tickets: $34-$138 Where: Dorothy Chandler Pavilion, 135 N. Grand Avenue, L.A. Info: www.musiccenter.org makeda.easter@latimes.com @makedaeaster",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LmJlbmVmaXRuZXdzLmNvbS9uZXdzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWlzLWNoYW5naW5nLXRoZS1wZXJmb3JtYW5jZS1yZXZpZXfSAQA?oc=5,artificial intelligence is changing the performance review - Employee Benefit News,2019-07-10,Employee Benefit News,https://www.benefitnews.com,"Technology is expected to help bosses find ways to better coach and assess their workforce in the present, rather than focus on the past.","['Evaluation and coaching', 'HR Technology', 'HR analytics', 'Workforce management', 'Workplace management', 'Employee engagement', 'Employee retention', 'Employee communications', 'Gated']","Technology is expected to help bosses find ways to better coach and assess their workforce in the present, rather than focus on the past.","Technology is expected to help bosses find ways to better coach and assess their workforce in the present, rather than focus on the past.",http://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.benefitnews.com/news/artificial-intelligence-is-changing-the-performance-review'}",AI is changing the annual performance review,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://arizent.brightspotcdn.com/bf/be/bb2fd85b48b4af6e56ffc83e8e63/hr-tech-appreciation.4.4.19.png'}",2019-07-10T15:10:19.236Z,2019-07-11T12:34:00.102Z,N/A,N/A,"   Evaluation and coaching    AI is changing the annual performance review      By     Caroline Hroncich       CloseText                    About Caroline       twitter     chroncich1             July 10, 2019, 11:10 a.m. EDT  2 Min Read       Facebook   Twitter   LinkedIn   Email       Performance management is going digital — and it may be changing the role of the manager. As more employers invest in artificial intelligence, the technology is expected to play a larger role in helping employers assess their workers, according to a report from Mercer. With the help of technology, the consulting firm predicts that the manager role will shift from gauging past performance to more of a coach, that guides workers future success.   “We believe that AI, by scraping communication platforms such as text, emails and calendars, will help identify those colleagues and customers that are most connected to an employee,” says Lori Holsinger, global performance management study leader at Mercer. “Based on those touch points, it will encourage those most connected to provide coaching to the employee – in person, video chat, or online — based on the employee’s preference. We believe that this approach will increase feedback that will encourage employees and coaching in person.”See also: Turning to tech, Mars revamps employee coaching benefit  HR technology is already starting to play a role in performance management and coaching. For example, tools including Bravely and BetterUp are mobile apps that provide personalized coaching to workers. The fast casual restaurant Dig Inn and M&M’s manufacturer Mars both offer coaching tech to employees. Mars selected the digital tool BetterUp, because it wanted something that would be able to reach its global workforce.     







 Americans are looking to be paid an ""emotional wage"", but what is it?
            




That paycheck you receive every two weeks is the main reason you go to work, right? Well, for many American workers, it is only one part of their wider...








Partner Insights from
Amply


Partner Insights from
Amply








   “We believe you should have a one Mars experience,” Summer Davies, global senior manager of leadership at Mars told Employee Benefit News in May. “[That] means if you work at Mars in Topeka, you should have the same access to growth development and support, as if you work in Guangzhou, China or Cape Town, South Africa.”But the number of employers actually implementing new technology remains small and some are struggling to find the return on investment. Even though there was a 19% increase in the use of performance management vendor technology in the last six years — and 25% of employers integrated that tech into other people management platforms — the use of talent analytics has not increased. Less than 15% of employers have actually adopted new tools, Mercer found. See also: Dig Inn invests in employee coaching benefitIf employers do decide to use technology to boost their review process, Holsinger says it should be used as a supplement to in-person coaching. Tech can provide valuable information on growing an employee’s career, exploring career paths and understanding what a day-in-the life can be for critical jobs, she adds. “This technology needs to be supplemented with personalized career coaching by someone who invests in the employee’s career and helps them reach their short- and long-term career goals,” she says. “This will be the new role of the traditional manager.”       Caroline Hroncich   Former senior editor, SourceMedia             twitter         ",https://www.benefitnews.com/news/artificial-intelligence-is-changing-the-performance-review,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'SourceMedia', 'articleSection': 'Author', 'description': 'Caroline Hroncich is a former senior editor of Employee Benefit News and Employee Benefit Adviser.', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://arizent.brightspotcdn.com/5c/77/12ea72fc400eb023e4b3f0532a5f/5ap5li6f-400x400.jpg'}, 'jobTitle': 'Former senior editor', 'name': 'Caroline Hroncich', 'url': 'https://www.benefitnews.com/author/caroline-hroncich'}]","{'sameAs': [], 'name': 'Employee Benefit News', 'foundingDate': '', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'height': '40px', 'url': 'https://arizent.brightspotcdn.com/c2/04/7dcda7264a978d15e051f6c829c1/employeebenefitnews-brand-logo-color-no-padding.svg', '@context': 'http://schema.org'}}",Article,,,,2019-07-10T15:10:19.236Z,,,,,,,,,,,,,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'SourceMedia', 'articleSection': 'Author', 'description': 'Caroline Hroncich is a former senior editor of Employee Benefit News and Employee Benefit Adviser.', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://arizent.brightspotcdn.com/5c/77/12ea72fc400eb023e4b3f0532a5f/5ap5li6f-400x400.jpg'}, 'jobTitle': 'Former senior editor', 'name': 'Caroline Hroncich', 'url': 'https://www.benefitnews.com/author/caroline-hroncich'}]",https://arizent.brightspotcdn.com/bf/be/bb2fd85b48b4af6e56ffc83e8e63/hr-tech-appreciation.4.4.19.png,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vd3d3LmFhbWMub3JnL25ld3Mvd2lsbC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yZXBsYWNlLWRvY3RvcnPSAQA?oc=5,Will artificial intelligence replace doctors? - AAMC,2019-07-09,AAMC,https://www.aamc.org,Several new studies have shown that computers can outperform doctors in cancer screenings and disease diagnoses.,N/A,Several new studies have shown that computers can outperform doctors in cancer screenings and disease diagnoses.,Several new studies have shown that computers can outperform doctors in cancer screenings and disease diagnoses.,https://schema.org,,,,,,,N/A,N/A,"






            AAMCNews
          Will artificial intelligence replace doctors?Several new studies have shown that computers can outperform doctors in cancer screenings and disease diagnoses. What does that mean for newly trained radiologists and pathologists?





























By 
Ken Budd, 
Special to AAMCNews


July 9, 2019

















“Do you think we’re gonna be replaced?”
A young Johns Hopkins University fellow recently asked that question while chatting with Elliot Fishman, MD, about artificial intelligence (AI). The two men were on the opposite ends of the career spectrum: Fishman has been a professor of radiology and oncology at Johns Hopkins Medicine since 1980; the fellow was preparing for his first job as a radiologist.
“I said, ‘Well, I think it’s going to change what we do, but the good news is, at least you’re not a pathologist,’” Fishman recalls. “And he goes, ‘My wife is just graduating and she’s a pathologist.’ So I said, ‘Put away as much money as you can really fast.’”
Fishman laughs when he tells the story, but he understands the concern. Over the past few years, many AI proponents and medical professionals have branded radiology and pathology as dinosaur professions, doomed for extinction. In 2016, a New England Journal of Medicine article predicted that “machine learning will displace much of the work of radiologists and anatomical pathologists,” adding that “it will soon exceed human accuracy.” That same year, Geoffrey Hinton, PhD, a professor emeritus at the University of Toronto who also designs machine learning algorithms for Google (and who received the Association for Computing Machinery’s A.M. Turing Award, often called the Nobel Prize of computing, in 2019), declared, “We should stop training radiologists now.""
The reason for the predictions? AI’s tantalizing power to identify patterns and anomalies and to examine “pathologies that look certain ways,” says Fishman, who is among the enthusiasts: He’s studying the use of AI for early detection of pancreatic cancer.
“The hope is that if we could pick up early tumors that are missed, we would have better outcomes,” he says.
An array of studies have offered glimpses of AI’s enormous potential. In a study published by Nature Medicine in May 2019, a Google algorithm outperformed six radiologists to determine if patients had lung cancer. The algorithm, which was developed using 42,000 patient scans from a National Institutes of Health clinical trial, detected 5% more cancers than its human counterparts and reduced false positives by 11%. False positives are a particular problem with lung cancer: A study in JAMA Internal Medicine of 2,100 patients found a false positive rate of 97.5%.
Furthermore, AI performed comparably to breast screening radiologists in a study in the March 2019 Journal of the National Cancer Institute. At Stanford University, computer scientists developed an algorithm for diagnosing skin cancer, using a database of nearly 130,000 skin disease images. In diagnostic tests, the algorithm’s success rate was almost identical to that of 21 dermatologists, according to a study published in Nature in 2017. In another skin cancer study, AI surpassed the performance of 58 international dermatologists. The algorithm not only missed fewer melanomas, but it was less likely to misdiagnose benign moles as malignant, the European Society for Medical Oncology found.

“Machine intelligence presents us with an opportunity to significantly improve the delivery of health care, particularly in high-disease or low-resource settings.”
Sameer Antani, PhD
PhD National Library of Medicine

The possibilities extend beyond cancer. Recent studies have shown how AI can detect rare hereditary diseases in children, genetic diseases in infants, cholesterol-raising genetic diseases, and neurodegenerative diseases, as well as predict the cognitive decline that leads to Alzheimer’s disease. A variety of companies are offering FDA-approved AI products, such as iCAD’s ProFound AI for digital breast tomosynthesis. Israeli-based Aidoc has received three FDA approvals for AI products, the latest occurring in June 2019 for triage of cervical spine fractures. In 2018, the FDA approved Imagen’s OsteoDetect, an AI algorithm that helps detect wrist fractures.
So when will AI become an everyday tool for diagnosis? It might not happen as fast as people think, Fishman believes, but it’s definitely coming.
“If you think it’s just some passing fancy, you’re making a mistake,” he says. “In radiology and pathology, it’s going to affect everything you do.”
The upsides of AI
AI has huge potential but it’s still in its infancy as a diagnostic tool. “There are a lot of rapid advances being made and a rush for monetizing them,” says Sameer Antani, PhD, acting branch chief for the National Library of Medicine’s Communications Engineering Branch and Computer Science Branch, who leads a research team on AI in such areas as cervical cancer screening and rare diseases. Initially, AI will be most effective for dealing with specific problems. “A program that does the whole CT of the abdomen is going to take a while,” says Fishman. “There are so many organs and there’s so much variability. But for specific tests that examine individual organs — the liver, the kidneys, the pancreas, the lungs, the heart — I think that’s where AI is going to be strong. And it’s happening.”
AI could be particularly beneficial in places with limited access to health care. “Machine intelligence presents us with an opportunity to significantly improve the delivery of health care, particularly in high-disease or low-resource settings,” says Antani. Consider a study published in March 2019 by the American Academy of Ophthalmology, which found that a Google algorithm improved doctors’ ability to accurately diagnose diabetic retinopathy. The algorithm has been tested in India, which is the type of country that could benefit from AI screenings, since it suffers from a shortage of doctors and ophthalmologists. At Stanford, researchers believe their skin cancer algorithm could work on a smartphone, allowing people to screen themselves.
AI could also help reduce radiology’s 30% error rate. “Our goal is to be perfect, but that’s unreasonable. People are busier than ever, they’re reading more studies, they’re working harder — errors increase with faster speed,” says Fishman. And algorithms can handle a larger workload than humans. The Google skin cancer program looked at about 130,000 images. A dermatologist looks at about 12,000 in his or her lifetime, Fishman notes.
“Computers can look at cases 24/7 and they can keep learning,” he says. “It has the opportunity to be the best helper you could ever imagine.”
Data bias and lost jobs
For all of its upsides, scientists such as the late Stephen Hawking have warned that artificial intelligence could destroy mankind. At Harvard Medical School’s 2019 Precision Medicine conference, Harvard Law School professor Jonathan Zittrain compared AI to asbestos: “It turns out that it’s all over the place, even though at no point did you explicitly install it, and it has possibly some latent bad effects that you might regret later, after it’s already too hard to get it all out.” He also noted that AI can be tricked, according to a story from Stat, citing a Google algorithm that correctly identified a tabby cat. When some pixels were changed, the algorithm thought the kitty was — no joke — guacamole.
The newness of AI applications presents a challenge for regulatory agencies to measure and validate its performance in medical diagnostics, Antani says. In April 2019, the FDA announced plans to develop regulations focusing on medical AI products that adapt based on new data.
Another issue is the data itself. The promise of AI depends on “the availability, quality, and completeness of training data and design of the AI framework/algorithm,” says Antani. Factors that affect data strength include social, geographic, or economic biases, as well as simply acquiring data. Computer scientists are developing AI architectures that produce compelling results with less data, Antani says, but “while these are exciting technological advances, they still do not address the shortcomings.”
Efforts to improve data diversity include Count Me In, a cancer project involving more than 6,000 patients so far. Count Me In collects medical information — from tumor samples to blood and saliva — and compiles it in databases for researchers. Launched in 2018, Count Me In is a collaboration between the Broad Institute of Massachusetts Institute of Technology and Harvard, the Biden Cancer Initiative, the Dana Farber Cancer Institute, and the Emerson Collective (founded by Laurene Powell Jobs, the widow of Apple co-founder Steve Jobs). Its efforts include the Metastatic Breast Cancer Project, which has received tumor samples and medical information from over 4,800 patients.
Count Me In is not only providing its data to researchers for free, but it’s collecting it from across the United States. “If you’re at Hopkins, or you’re at Mass General, your population is Boston or Baltimore. There could be some baked in biases in your population, for good or bad,” says Fishman. “So you need wide data and this is a way of potentially collecting data that’s unbiased.”

“I’m not exactly worried that they’re going to put us out of business right away. Way back when, pathologists looked at every pap smear. Now a machine looks at them and once in a while it kicks something out. Things change.”
Elliott Fishman, MD
Johns Hopkins Medicine

But does better data simply hasten the loss of jobs for health care professionals? Will radiologists and pathologists be replaced by smartphone apps or a medical voice assistant? AI has the potential not only to be more accurate, but to work faster than humans.
“I’m not exactly worried that they’re going to put us out of business right away,” says Fishman. “Way back when, pathologists looked at every pap smear. Now a machine looks at them and once in a while it kicks something out. Things change.”
That change, while potentially profound, does not mean that radiologists and pathologists are destined for the unemployment line. Experts also predicted the demise of radiologists when MRI machines were introduced, wrote Curtis P. Langlotz, professor of radiology at the Stanford University Medical Center, in a May 2019 editorial for the journal Radiology. “Radiologists are being trained to recognize AI’s shortcomings and capitalize on its strengths,” he wrote, adding that most comparisons between algorithms and radiologists are too simplistic. “An AI algorithm that diagnoses common chest conditions at the level of a subspecialty thoracic radiologist is a major step forward, an incredible asset to underserved regions, and could serve as a valued assistant for a subspecialty radiologist.” But radiologists are also trained to detect less-common diseases such as rheumatoid arthritis and sickle cell disease. “AI is impressive in identifying horses,” he wrote, “but is a long way from recognizing zebras.”
How will the job change? Over the next 5 to 10 years, the most successful radiologists and pathologists will be those “who are well equipped and eager to participate in data management and integrated diagnoses,” says Frank J. Rybicki, MD, PhD, vice chair of operations and quality with the University of Cincinnati Department of Radiology and medical director of Imagia Cybernetics Inc. When an algorithm produces unexpected results, radiologists will need to understand why. Fishman believes this will lead to a deeper role in patient care — which is one reason why he’s more excited than threatened.
“If you ask me who will benefit from AI, it’s the patients,” says Fishman. “That’s why I’m so excited. Better care for our patients. What can be better than that?”
















Ken  Budd, Special to AAMCNews


















SHARE:
Topic:
                Medical Education
        
                Health Care
        
                Medical Profession & Practice
        
                Research & Technology
        
                Innovation
        





",,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', 'headline': 'Will artificial intelligence replace doctors?', 'description': 'Several new studies have shown that computers can outperform doctors in cancer screenings and disease diagnoses.', 'image': {'@type': 'ImageObject', 'url': 'https://www.aamc.org/sites/default/files/artificial-intelligence-replace-doctors-medical-doctors-viewing-scan-922708164_0.jpg'}, 'datePublished': '2019-07-08T15:01:18-0400', 'dateModified': '2022-06-29T06:33:41-0400', 'author': {'@type': 'Person', 'name': 'Ken Budd'}, 'publisher': {'@type': 'Organization', 'name': 'AAMC', 'logo': {'@type': 'ImageObject', 'url': 'https://www.aamc.org/themes/custom/hippocrates/images/AAMC-Color-Logo.jpg'}}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.aamc.org/news/will-artificial-intelligence-replace-doctors'}}]",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9ob3ctYWktY2FuLWJlLW9uZS1vZi10aGUtZGlzcnVwdGl2ZS10ZWNobm9sb2d5LWluLWhpc3RvcnktMWRjM2Y3ZDM4Y2Zh0gEA?oc=5,How AI Can be One of the Disruptive technology in history. - Towards Data Science,2019-07-08,Towards Data Science,https://towardsdatascience.com,Artificial Intelligence is making a quick transition from future technology to one that surrounds us in our daily lives. From taking perfect pictures to predicting what we can say next in an email…,N/A,Artificial Intelligence is making a quick transition from future technology to one that surrounds us in our daily lives. From taking…,Artificial Intelligence is making a quick transition from future technology to one that surrounds us in our daily lives. From taking…,http://schema.org,NewsArticle,https://towardsdatascience.com/how-ai-can-be-one-of-the-disruptive-technology-in-history-1dc3f7d38cfa,How AI Can be One of the Disruptive technology in history.,['https://miro.medium.com/v2/resize:fit:1200/0*FYE94Fb6ase8AhJo.jpg'],2019-07-08T13:24:20.163Z,2021-12-10T19:28:51.579Z,N/A,N/A,"How AI Can be One of the Disruptive technology in history.Herman Morgan·FollowPublished inTowards Data Science·5 min read·Jul 8, 20197ListenShareArtificial Intelligence is making a quick transition from future technology to one that surrounds us in our daily lives. From taking perfect pictures to predicting what we can say next in an email, artificial intelligence is being incorporated into the products and services we use every day to transform our lives for better but how can this emerging technology affect our future work?Of all the technologies that are driving digital transformation in the enterprise, often the people out AI as the most disruptive among all. There arises no question to how AI is in the process of disrupting people’s day-to-day jobs because of the sophisticated automation.Courtesy-FreepikAI is putting people out of work whether it is shifting the work for more productive tasks because automation takes the grunt work. Such discussions are clearly important as they miss out the larger transformative story. After all, the digital transformation takes place at every organizational and industry level.Unexpressed Economic Impact?There are various attempts to make a prediction that results in the overall level of employment at a national or global level where the shortage of skills and surplus are fluctuating in the coming times. In general practice, the employment outlook can be shaped by the combination of the Fourth Industrial Revolution, where the decisions of powerful corporations and investors require current and predicted future industries which is likely an unpredictable number of economic cycles.Additionally, here the diverse economic factors can make up complex challenges to predict with any certainty what are the likely progress of job creation and displacement over the upcoming years. Most of the forecasters, analysts, developers, scientists, technology providers, and economists are debating whether they can evolve or accelerate the learning capability of AI and its potential impact on society. To this, the most intelligent approach will be to start preparing for a range of solutions.Is AI Emerging New Societal Structures?In present times, many in society are unaware of how AI can alter key social structures. For instance, if the legal system can be administered and enforced by AI, does that indicate that we have reached the ideals of fair objectivity? Or on the other side, would that define the new order with the inherent and unintended bias of its creators? If AI is really replacing the humans then how will humans work for the living? How would people spend their newfound permanent leisure hours?For a wider range of society, what actually impacts the large-scale redundancies across all means of professions as a result of the pervasiveness by AI? All these can just be a few topics where we the application of AI has direct and unintended consequences that challenge our current assumptions and work model which needs to get addressed in the not so near future. These challenges need an inclusive, experimental and proactive responses in order to see the impacts of change and ensure that no segment of society lags behind.What are the new Challenges for Business?With multiple technologies in the recent past, businesses are having the luxury to know that they can wait until they are ready to pursue with AI. For many organizations, this can be relatively safe in the assumption that being late to market does not necessarily mean their demise. Moreover, predominant short-term results drive focus and this culture has led to many ignoring artificial intelligence.courtesy-FreepikIn the end, those at the top of huge organizations are rarely excited about any technology and this can lead to a struggle for appreciating the true disruptive potential of AI. The exponential speed of the AI developments indicates that more the business becomes data-centric, greater the imperative to start investing time for better understanding and analyzing the technology. If we look from the top down, we need to appreciate how AI is advancing and differs from previous disruptive advancements and grasping its capability to enable new and unimaginable ideas and business models. We need to understand the true potential of AI to unlock value form the vast arrays of data within our businesses. Also, we need to become more conscious about the long-term societal impact and the broader rule of business in society.Businesses need to think much more strategically about the wider societal ramifications of operational decisions call it corporate social responsibility or enlightened self-interest. There arise multiple questions like where will the money come if organizations begin to rely on favor of automation? How we can assure the right balance between humans and machines so that technology serves the people? In clear terms, there is a deep desire in business today to implement human capability and free up the time for our best talent with the application of AI.Moreover, the evidence suggests a vast majority of AI projects that are backed by a business case prediction on reducing operational costs in the form of humans. Some are raising high concerns that such a narrow pursuit of cost efficiency with the help of automation can limit our capacity to respond to problems and change customer needs. Still, humans are the best option when it comes to adapting to new developments when we learn about emerging industries and pursue new opportunities innovating to stay ahead in this fast-changing competitive world. Business leaders weigh up the benefits of near-term cost-savings for taking humanity out of the businesses by commoditizing our offerings against the risk of automation.How will the IT industry use AI for future?The ability of smart machines to underestimate human workers is definitely a valid threat but it is not intense until and unless a tech worker feels enlightened about AI. One of the prominent ways to ensure that AI serves humanity is to keep it more beneficial and exploit the benefits by rejecting the aspects which threaten the greater good.Such massive transformation can be a startling development yet somehow it rings true to the previous technological breakthroughs like the internet which has led to entirely new economic systems and business models creating the entire IT professions. Keep Learning!Author Bio:HP Morgan is a Tech Analyst at Tatvasoft.com.au, It is Software Development Service provider in Australia. He is having seven years of experience in a Technological domain. He loves to travel to Spontaneous places.",https://towardsdatascience.com/how-ai-can-be-one-of-the-disruptive-technology-in-history-1dc3f7d38cfa,"{'@type': 'Person', 'name': 'Herman Morgan', 'url': 'https://towardsdatascience.com/@mhermanmorgan'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",,How AI Can be One of the Disruptive technology in history.,,,2019-07-08T13:24:20.163Z,,,,,,,,,,,,,['Herman Morgan'],,,1dc3f7d38cfa,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1mYXNoaW9uLWRlc2lnbi_SAQA?oc=5,AI's Latest Job? Designing Cool T-Shirts - WIRED,2019-07-11,WIRED,https://www.wired.com,That attractive design on your T-shirt wasn't made by some hipster artist. It was produced by a neural network.,"['gear', 'trends', 'ai hub', 'small company', 'startup', 'consumer services', 'images', 'neural network', 'fashion', 'artificial intelligence', 'neural networks', 'web']",That attractive design on your T-shirt wasn't made by some hipster artist. It was produced by a neural network.,That attractive design on your T-shirt wasn't made by some hipster artist. It was produced by a neural network.,https://schema.org/,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://www.wired.com/story/artificial-intelligence-in-fashion-design/'}",AI's Latest Job? Designing Cool T-Shirts,"['https://media.wired.com/photos/5d266a1d68b4f10008a41c84/16:9/w_2400,h_1350,c_limit/gear%20-%20feature%20art%20-%20ai%20fashion.jpg', 'https://media.wired.com/photos/5d266a1d68b4f10008a41c84/4:3/w_2400,h_1800,c_limit/gear%20-%20feature%20art%20-%20ai%20fashion.jpg', 'https://media.wired.com/photos/5d266a1d68b4f10008a41c84/1:1/w_1800,h_1800,c_limit/gear%20-%20feature%20art%20-%20ai%20fashion.jpg']",2019-07-11T07:00:00.000-04:00,2019-07-11T07:00:00.000-04:00,tags,N/A,"Arielle PardesGearJul 11, 2019 7:00 AMAI's Latest Job? Designing Cool T-ShirtsThat attractive design on your T-shirt wasn't made by some hipster artist. It was produced by a neural network.Play/Pause ButtonPauseCasey Chin; Cross & FreckleSave this storySaveSave this storySaveThe AI Database →End UserSmall companyStartupSectorConsumer servicesSource DataImagesTechnologyNeural NetworkThe T-shirts sold by Cross & Freckle, a New York–based fashion upstart, don't look revolutionary at first glance. They come in black or white, they're cut for a unisex fit, and they sell for $25. Each of them has a little design embroidered into the cotton that references staples of New York City life: pigeons, dollar pizza slices, subway rats.Sarah McBride, the brand’s cofounder, likens the T-shirts to ""the New York City summer uniform."" But McBride didn't actually design the shirts. Neither did anyone else. They were designed instead by a neural network, which crunched doodle data from millions of people and spit out the original art that makes up the embroidery.Cross & Freckle isn't the first company to use AI to generate art—people have been doing that for years. But this project offers a glimpse into the nascent world of AI-generated fashion, where designers use machine-learning models to remix and riff on old designs. Cross & Freckle doesn't just use AI to create its designs; it also got the brand's name and logo from a neural net, called the Hipster Business Name Generator and used an AI text generator to create the mumbo-jumbo marketing copy on the company's website. It's a new model for a brand that relies entirely on AI.Code ModeThe embroidered designs look like something a child might have scribbled with a crayon, or something an adult might have drawn with a computer mouse on Microsoft Paint. That's actually not far off: The graphics came out of a variational autoencoder trained on data from Google Creative Lab's game Quick, Draw, which has collected over a million doodles from people around the world. Quick, Draw works like Pictionary: Draw a giraffe or a light bulb or a slice of pizza, and the computer guesses what it is. In aggregate, the drawings make up what Google calls the ""world's largest doodling data set.""Trending NowNotifications Are Stressing Us OutPaul Blankley, who handles Cross & Freckle's technical side, created the autoencoder and fed it doodles of pigeons, rats, pizza, and dogs from Google's data set. ""There are hundreds of thousands of drawings for each of the different categories, from countries all over the world,"" he says. ""So you get this cool mix of what does the world think it means to be a doodle of a pigeon, or a doodle of a piece of pizza."" The autoencoder riffed on those drawings, creating its own original designs.""What’s great with generative AI is that it will churn out a bunch of different options so you can choose what might be the best version of a puppy or pizza slice for a T-shirt, or which hipster name is the most random but still real-sounding,"" says McBride. ""So there was still an element of human selection and curation involved.""The fashion industry already relies on artificial intelligence to fine-tune various parts of clothes-making, from managing inventory to predicting trends to offering recommen­dations to customers. “Virtual stylists” help people find their ideal size when shopping online, and data-driven recommenda­tion engines help surface things that fit into someone’s personal style. Brands big and small are searching for ways to incorporate machine prowess into the process. Just last week, Amazon introduced StyleSnap, a tool that uses com­puter vision to find items of clothing similar to the styles in a photograph—the latest push to get people buying clothes on Amazon.Robot RunwayBut AI also offers new opportunities for designers who are looking not just to forecast the trends, but to create original designs. Glitch, a company created by a pair of MIT graduates, sells dresses designed by deep-learning software. And last year, just in time for New York Fashion Week, artist Robbie Barrat designed an entire collection for the fashion house Balenciaga using a neural net. The program scraped images from Balenciaga's lookbooks, catalogs, and runway shows, then remixed them to create original styles. The resulting images are strange; the models’ faces, in parti­cular, smear into each other in the AI-generated photos. But the designs themselves are cool and push the boundaries of fashion in interesting ways.One image shows a runway model sporting a three-component coat made of black satin and bright pink fur. Another reimagines a windbreaker in the shape of a classic button-down. They’re weird, but so is high fashion—and you could imagine many of these looks appearing on a real Balenciaga runway.Advertisement""The most interesting aspect of using AI to generate media is that it allows us to create shapes that have never been created before, while also giving us a look into an AI’s interpretation of what a dog, pizza slice, pigeon, and subway rat should look like,"" says McBride. ""The AI becomes our cocreator.""With the help of AI, designers shift into a role that's more curatorial and maybe even more creative. Whether we choose to wear those creations is up to us.More Great WIRED StoriesThe second coming of the robot petThe infrastructure mess causing countless web outagesThe cypherpunks tapping bitcoin via ham radioDisney's new Lion King is the VR-fueled future of cinemaYouTube's “shitty robot” queen made a Tesla pickup truck📱 Torn between the latest phones? Never fear—check out our iPhone buying guide and favorite Android phones📩 Hungry for even more deep dives on your next favorite topic? Sign up for the Backchannel newsletterMost PopularGearHow to Properly Archive Your Digital FilesBy Justin Pot, WIREDGearThe 21 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDGearHow to Get a Real ID License Before the DeadlineBy Reece RogersGearPS5 vs PS5 Slim: What’s the Difference, and Which One Should You Get?By Eric Ravenscraft, WIRED",https://www.wired.com/story/artificial-intelligence-in-fashion-design/,"[{'@type': 'Person', 'name': 'Arielle Pardes', 'sameAs': 'https://www.wired.com/author/arielle-pardes/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",gear,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Gear', 'item': 'https://www.wired.com/gear/'}, {'@type': 'ListItem', 'position': 2, 'name': 'fashion', 'item': 'https://www.wired.com/tag/fashion/'}, {'@type': 'ListItem', 'position': 3, 'name': ""AI's Latest Job? Designing Cool T-Shirts""}]",,"{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,,,,,,,,"Sarah McBride, the brand’s cofounder, likens the T-shirts to ""the New York City summer uniform."" But McBride didn't actually design the shirts. Neither did anyone else. They were designed instead by a neural network, which crunched doodle data from millions of people and spit out the original art that makes up the embroidery.
Cross & Freckle isn't the first company to use AI to generate art—people have been doing that for years. But this project offers a glimpse into the nascent world of AI-generated fashion, where designers use machine-learning models to remix and riff on old designs. Cross & Freckle doesn't just use AI to create its designs; it also got the brand's name and logo from a neural net, called the Hipster Business Name Generator and used an AI text generator to create the mumbo-jumbo marketing copy on the company's website. It's a new model for a brand that relies entirely on AI.
Code Mode
The embroidered designs look like something a child might have scribbled with a crayon, or something an adult might have drawn with a computer mouse on Microsoft Paint. That's actually not far off: The graphics came out of a variational autoencoder trained on data from Google Creative Lab's game Quick, Draw, which has collected over a million doodles from people around the world. Quick, Draw works like Pictionary: Draw a giraffe or a light bulb or a slice of pizza, and the computer guesses what it is. In aggregate, the drawings make up what Google calls the ""world's largest doodling data set.""
Paul Blankley, who handles Cross & Freckle's technical side, created the autoencoder and fed it doodles of pigeons, rats, pizza, and dogs from Google's data set. ""There are hundreds of thousands of drawings for each of the different categories, from countries all over the world,"" he says. ""So you get this cool mix of what does the world think it means to be a doodle of a pigeon, or a doodle of a piece of pizza."" The autoencoder riffed on those drawings, creating its own original designs.
""What’s great with generative AI is that it will churn out a bunch of different options so you can choose what might be the best version of a puppy or pizza slice for a T-shirt, or which hipster name is the most random but still real-sounding,"" says McBride. ""So there was still an element of human selection and curation involved.""
The fashion industry already relies on artificial intelligence to fine-tune various parts of clothes-making, from managing inventory to predicting trends to offering recommen­dations to customers. “Virtual stylists” help people find their ideal size when shopping online, and data-driven recommenda­tion engines help surface things that fit into someone’s personal style. Brands big and small are searching for ways to incorporate machine prowess into the process. Just last week, Amazon introduced StyleSnap, a tool that uses com­puter vision to find items of clothing similar to the styles in a photograph—the latest push to get people buying clothes on Amazon.
Robot Runway
But AI also offers new opportunities for designers who are looking not just to forecast the trends, but to create original designs. Glitch, a company created by a pair of MIT graduates, sells dresses designed by deep-learning software. And last year, just in time for New York Fashion Week, artist Robbie Barrat designed an entire collection for the fashion house Balenciaga using a neural net. The program scraped images from Balenciaga's lookbooks, catalogs, and runway shows, then remixed them to create original styles. The resulting images are strange; the models’ faces, in parti­cular, smear into each other in the AI-generated photos. But the designs themselves are cool and push the boundaries of fashion in interesting ways.
One image shows a runway model sporting a three-component coat made of black satin and bright pink fur. Another reimagines a windbreaker in the shape of a classic button-down. They’re weird, but so is high fashion—and you could imagine many of these looks appearing on a real Balenciaga runway.
""The most interesting aspect of using AI to generate media is that it allows us to create shapes that have never been created before, while also giving us a look into an AI’s interpretation of what a dog, pizza slice, pigeon, and subway rat should look like,"" says McBride. ""The AI becomes our cocreator.""
With the help of AI, designers shift into a role that's more curatorial and maybe even more creative. Whether we choose to wear those creations is up to us.

More Great WIRED Stories

The second coming of the robot pet
The infrastructure mess causing countless web outages
The cypherpunks tapping bitcoin via ham radio
Disney's new Lion King is the VR-fueled future of cinema
YouTube's “shitty robot” queen made a Tesla pickup truck
📱 Torn between the latest phones? Never fear—check out our iPhone buying guide and favorite Android phones
📩 Hungry for even more deep dives on your next favorite topic? Sign up for the Backchannel newsletter",,"https://media.wired.com/photos/5d266a1d68b4f10008a41c84/1:1/w_1800,h_1800,c_limit/gear%20-%20feature%20art%20-%20ai%20fashion.jpg",,,,That attractive design on your T-shirt wasn't made by some hipster artist. It was produced by a neural network.,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LnNjbXAuY29tL21hZ2F6aW5lcy9zdHlsZS90ZWNoLWRlc2lnbi9hcnRpY2xlLzMwMTczODcvd291bGQteW91LXBheS11czQzMjUwMC1ibHVycnktcGFpbnRpbmctY3JlYXRlZC1hadIBcmh0dHBzOi8vYW1wLnNjbXAuY29tL21hZ2F6aW5lcy9zdHlsZS90ZWNoLWRlc2lnbi9hcnRpY2xlLzMwMTczODcvd291bGQteW91LXBheS11czQzMjUwMC1ibHVycnktcGFpbnRpbmctY3JlYXRlZC1haQ?oc=5,"Would you pay US$432,500 for this blurry painting made by an AI algorithm? - Style",2019-07-08,Style,https://www.scmp.com,", a blurry portrait of an aristocratic gentleman in a dark frock coat and white collar made the news when it was sold at Christie’s New York for US$432,500 ((HK$3.39 million) last October.","South China Morning Post, News, Opinion, China, Hong Kong, World, US, Asia, Business, Economy, Technology, Lifestyle, Sport","The portrait, ‘Edmond de Belamy’ – produced by three students – captured public imagination at auction last year, but some artists argue ‘it’s not art’.",N/A,https://schema.org,ImageObject,https://www.scmp.com/magazines/style/tech-design/article/3017387/would-you-pay-us432500-blurry-painting-created-ai,"Would you pay US$432,500 for this blurry painting created by an AI algorithm?","{'@type': 'ImageObject', 'height': {'@type': 'QuantitativeValue', 'value': 3179}, 'url': 'https://cdn.i-scmp.com/sites/default/files/d8/images/methode/2019/07/08/27b82a24-9303-11e9-a6c8-8445313d8ede_image_hires_105824.JPG', 'width': {'@type': 'QuantitativeValue', 'value': 3200}}",2019-07-08T10:00:10+08:00,2019-07-22T12:35:57+08:00,Magazines,N/A,"AdvertisementAdvertisementAdvertisementTech & DesignWould you pay US$432,500 for this blurry painting created by an AI algorithm?STORYVictoria BurrowsJul 8 , 2019“Edmond de Belamy” a work of art created by artificial intelligence, which was sold at auction for US$432,500. Photo: Christie’s/APEdmond de Belamy, a blurry portrait of an aristocratic gentleman in a dark frock coat and white collar made the news when it was sold at Christie’s New York for US$432,500 ((HK$3.39 million) last October.It was not the price that attracted attention – the sum is a mere sniff in the direction of the record-breaking US$91 million spent on Jeff Koon’s stainless steel rabbit inspired by a child’s inflatable toy – the highest price ever paid for work by a living artist.What caused the commotion was that instead of an artist’s signature, there was an algorithm – the work was generated by artificial intelligence (AI).READ FULL ARTICLEAppImages generated using AI technology in Google’s pattern-finding software DeepDream have been circulating since 2015, but they have generally been appreciated for their science rather than art.The guys behind this stunt are not even artists, but [members of] a very talented start-up, who knew how – with an initially false narrative, the right keywords and some good contacts – to cash in on the hypeGerman artist Mario KlingemannThe Christie’s sale, however, was the first time one of the big players in the global art market shone a spotlight on the brave new world that challenges the boundaries of machine learning and creativity: AI art.Like many other AI works, Edmond de Belamy was created using GAN – a generative adversarial network. Obvious, an arts collective comprising a trio of 25-year-old French students, fed AI with an algorithm and a data set of 15,000 portraits painted between the 14th and 20th centuries.Advertisement“Edmond de Belamy” a work of art created by artificial intelligence, which was sold at auction for US$432,500. Photo: Christie’s/APThe algorithm is made up of two parts: the generator, which makes a new image based on the set; and the discriminator, which, Turing test-style, aims to tell the difference between a human-made image and one created by the generator.The generator learns from its mistakes; when the discriminator is fooled into thinking that a new image is a real-life portrait, the result is something along the lines of Edmond de Belamy.People are interested in AI art because it looks like what we know as art, but this is not art, this is just reproduction, just imitation. If a human was to make this art now, we would say it was bad art, so why is it interesting if a machine makes it?Maurice Benayoun, professor, School of Creative Media, City University of Hong KongAdvertisementThe auction went on to capture public imagination, but not everyone was impressed, particularly other artists working within the field, who criticised the sale.“The guys behind this stunt are not even artists, but a very talented start-up, who knew how – with an initially false narrative, the right keywords and some good contacts – to cash in on the hype,” German artist Mario Klingemann, one of the first creative coders to experiment with AI and art, says.“I was disappointed that a marketing ploy as obvious as this actually worked.”Klingemann’s own artwork, Memories of Passersby I, uses neural networks – what he calls “neurography” – to generate an infinite stream of imaginary portraits that are projected onto a two-screen installation.AdvertisementGerman artist Mario Klingemann’s Memories of Passersby I, which is created using neural networks. Photo: Courtesy of OnkaosOther versions followed. Memories of Passersby I was sold in March by Sotheby’s London for a much cooler US$51,000 with fees.Robbie Barratt, a 19-year-old pioneer of GAN art, whose algorithms shared online via open-source licence were tweaked by Obvious for its project, has also reacted to the sale, describing Belamy as neither interesting nor original.GANs are, by their nature, derivative: they don’t create, they generate.AdvertisementNow a cornerstone of contemporary machine learning, GANs were first designed by researcher Ian Goodfellow in 2014.Unlike the repetitious results produced by DeepDream, GANs can be trained to produce new and different images. But the images are still emulative and this, many agree, excludes them from serious consideration as art.Untitled 1, a neurography image created by German artist Mario Klingemann – one of the first creative coders to experiment with artificial intelligence and art.“People are interested in AI art because it looks like what we know as art, but this is not art, this is just reproduction, just imitation,” Maurice Benayoun, a professor at School of Creative Media, City University of Hong Kong, says.Advertisement“If a human was to make this art now, we would say it was bad art, so why is it interesting if a machine makes it?”Art is about ideas; whether an artist uses a paint brush or AI, these are tools to communicate ideas. So while GANs themselves may not produce what many would consider as art, in the hands of an artist, they could indeed be used to speak of the world beyond the image.“I’m not a painter,” says Klingemann. “My way of expression is through code. From my perspective, code allows me to translate what is in my head out into the world better than anything I could ever accomplish with my hands and physical tools.“For me, personally, there is no question that what I and other serious artists in this field are creating with AI is art – and many curators, collectors and critics seem to agree.”AdvertisementOne of German artist Mario Klingemann’s interactive installations.Klingemann is creatively involved throughout the art-making process, from the initial concept for a work, through selecting and modifying neural architectures, finding and curating data to train the models, combining various models and embedding them in other algorithms and, finally, choreographing and curating their output.“AI in its current state is surprising, unpredictable and can be very inspiring but it’s still me who plays the creative role in this relationship,” he says.I’m not a painter. My way of expression is through code [which] allows me to translate what is in my head out into the world better than anything I could ever accomplish with my hands and physical toolsMario KlingemannA professor at Rutgers University in the United States has complicated the debate, however.Ahmed Elgammal believes that AICAN – think GAN 2.0 – puts creativity firmly in the capabilities of machine intelligence.“GAN tries to emulate images, but art must make something new. So we developed our creative adversarial network,” says Elgammal, a professor of computer science and director at Rutgers’ Art and Artificial Intelligence Laboratory, which created a program called AICAN (Artificial Intelligence Creative Adversarial Network).Elgammal fed the program with images from across five centuries, from the Renaissance to the present day, all grouped into categories by aesthetic, so that it could learn the concept of style.Like in GAN, AICAN was tasked with learning the aesthetics of existing works of art, but it was not allowed to closely emulate styles. This effectively gave the machine two opposing forces: follow the aesthetics, don’t repeat styles.Much of AICAN’s art is abstract; Elgammal suggests this is perhaps because the algorithm has grasped that if it wants to make something novel, it cannot go back and produce figurative works as existed before the 20th century.The AICAN artwork Divided Sunshine (2018), a pigment print on rag paper, is a field of blue over a hazy strip of white, reminiscent of the sky. A thick streak of deep red runs vertically down the centre of the image, alongside a thinner, incomplete strip, also red.It was exhibited at SCOPE Miami Beach and The Arts+ in Frankfurt last year.“The definition of creativity is a long and ongoing debate,” Elgammal says. “Immanuel Kant’s definition of the 18th century is based on two qualities: something has to be novel, and it has to have influence, like Pablo Picasso’s Les Demoiselles d’Avignon [1907], which sparked the cubist movement. This definition helped inspire AICAN.”“But the division of art and science – aesthetics as subjective and science as objective – can also be traced back to Kant, and I don’t believe this is true. I established this lab because I believe looking at art will advance AI. Intelligence is not just used in driving a car or playing chess, it is involved in listening to music, comprehending literature and enjoying art. If we want to build a machine that is intelligent, we need to step into this territory of creativity.”Elgammal has conducted tests with viewers, flesh-and-blood discriminators, to assess reactions to human-generated and machine-generated works. He says there is very little difference, and that, in fact, some people are more inspired by the art that is done by machine.Does this suggest AICAN works should be considered art? Not if your definition of art is that it should speak of the wider world or provide an emotional response to it. For the time being, AI art remains in the realm of science fiction.  The painting Divided Sunshine (2018), which was created using artificial intelligence. Photo: AICAN.io For me, personally, there is no question that what I and other serious artists in this field are creating with AI is art … it’s still me who plays the creative role in this relationship … and many curators, collectors and critics seem to agreeMario Klingemann This is not what art is aboutFrench artist Maurice Benayoun’s Brain Factory at Microwave FestivalMany see the extravagant US$432,500 paid last year for the world’s first AI art at auction as indicative of the art market in general.Klingemann, who describes Edmond de Belamy as “mediocre and unrepresentative”, says the sale “tells you more about the art market than about art”.Like Klingemann, Benayoun is frustrated with the fetishisation of art. A market in which an unnamed buyer spends US$91 million on Koons’ stainless steel sculpture of a rabbit is one that inspires incredulity.“The art market is important, of course, but who is inspired by this rabbit?” asks Benayoun, who has been described as France’s most cutting-edge artist.The art market is important, of course, but who is inspired by this rabbit? The technique of making a rabbit of steel or imitations of paintings made of bits … This is not what art is aboutMaurice Benayoun“The technique of making a rabbit of steel or imitations of paintings made of bits … This is not what art is about.“When someone invests US$91 million, I hope they will invest US$92 million in artist Piero Manzoni’s 1960s work Artist’s Shit – literally his own excrement in a can. This is a better artwork, was done long before, and it’s organic.“I hope whoever bought the rabbit will go bankrupt very soon as there are so many more relevant ways to spend this money. Art is supposed to help us understand the world and perhaps change it a little. Art is giving shape to ideas.”Benayoun is literally giving shape to ideas through a blockchain-based art project called Value of Va lues (VoV).In an attempt to find the real, economic value of human values through EEG (electroencephalography), an interactive art installation titled Brain Factory allows the audience to give a shape to abstract concepts through Brain-Computer Interaction (BCI), and then converts the resulting forms into physical objects.I hope whoever bought [Jeff Koons’] rabbit will go bankrupt very soon as there are so many more relevant ways to spend this money. Art is supposed to help us understand the world and perhaps change it a little. Art is giving shape to ideasMaurice BenayounSo anyone sitting in the artist’s chair can, merely by thinking of an abstract concept like justice, power or peace, can “design” them in 3D model form.The neuro-designed shapes are entered onto the blockchain and can be converted into cryptocurrency, giving a monetary value to the art. If thousands of the shapes are bartered or sold, all tracked in real time, this gives metaphorical insight into the relative value of human values and the workings of the art market.Yet projects such as VoV, and the fact that AI is able to create infinite variations around a concept or style, showing that the idea of a single perfect work is merely a dream, may be no match for the way in which the single artefact, the unique object, is revered today in an almost cultish fashion.“Art is a belief system, like a religion in which rationality has no place, so I doubt that the notion of art objects as fetishes that have arbitrary high values will go away any time soon,” Klingemann says.Want more stories like this? Sign up here. Follow STYLE on Facebook, Instagram and TwitterAdvertisementArt+ FOLLOWThe portrait, ‘Edmond de Belamy’ – produced by three students – captured public imagination at auction last year, but some artists argue ‘it’s not art’TAGSArtArtificial intelligenceTechnologyChina technologyStart-upsRoboticsVictoria Burrows+ FOLLOWA former senior commissioning editor at the South China Morning Post and restaurant critic for the Wall Street Journal Asia, Victoria writes about food, wine, and whisky for the BBC, Travel + Leisure, Nat Geo, Vogue India and more./ READ MORE /Inside the late Malcolm Forbes’ US$19.9 million New York homeReview | Did Denim Unspun get us some great custom-fit jeans?Review | Are the Powerbeats Pro better than the Apple AirPods?",https://cdn.i-scmp.com/sites/default/files/d8/images/methode/2019/07/03/cf90c960-9ca2-11e9-baa5-dd214ed0de8f_image_hires_171706.jpeg,"{'@type': 'Person', 'name': 'Victoria Burrows', 'sameAs': 'https://www.scmp.com/author/victoria-burrows'}","{'@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'height': {'@type': 'QuantitativeValue', 'value': 512}, 'url': 'https://assets-v2.i-scmp.com/production/icons/scmp-icon-512x512.png', 'width': {'@type': 'QuantitativeValue', 'value': 512}}, 'name': 'South China Morning Post'}",Tech &amp; Design,South China Morning Post,True,"[{'@type': 'ListItem', 'item': {'@id': 'https://www.scmp.com/magazines', 'name': 'Magazines'}, 'position': 1}, {'@type': 'ListItem', 'item': {'@id': 'https://www.scmp.com/magazines/style', 'name': 'Style'}, 'position': 2}, {'@type': 'ListItem', 'item': {'@id': 'https://www.scmp.com/magazines/style/tech-design', 'name': 'Tech &amp; Design'}, 'position': 3}]",2019-07-05T14:05:45+08:00,"{'@type': ['CreativeWork', 'Product'], 'name': 'SCMP Digital', 'productID': 'www.scmp.com:digital'}",,,"19/F Tower One, Times Square, 1 Matheson Street, Causeway Bay, Hong Kong",,,,,+852-2680-8888,https://assets-v2.i-scmp.com/production/icons/scmp-icon-512x512.png,,"Edmond de Belamy, a blurry portrait of an aristocratic gentleman in a dark frock coat and white collar made the news when it was sold at Christie’s New York for US$432,500 ((HK$3.39 million) last October.
It was not the price that attracted attention – the sum is a mere sniff in the direction of the record-breaking US$91 million spent on Jeff Koon’s stainless steel rabbit inspired by a child’s inflatable toy – the highest price ever paid for work by a living artist.
What caused the commotion was that instead of an artist’s signature, there was an algorithm – the work was generated by artificial intelligence (AI).
Images generated using AI technology in Google’s pattern-finding software DeepDream have been circulating since 2015, but they have generally been appreciated for their science rather than art.
The guys behind this stunt are not even artists, but [members of] a very talented start-up, who knew how – with an initially false narrative, the right keywords and some good contacts – to cash in on the hype
German artist Mario Klingemann
The Christie’s sale, however, was the first time one of the big players in the global art market shone a spotlight on the brave new world that challenges the boundaries of machine learning and creativity: AI art.
Like many other AI works, Edmond de Belamy was created using GAN – a generative adversarial network. Obvious, an arts collective comprising a trio of 25-year-old French students, fed AI with an algorithm and a data set of 15,000 portraits painted between the 14th and 20th centuries.

The algorithm is made up of two parts: the generator, which makes a new image based on the set; and the discriminator, which, Turing test-style, aims to tell the difference between a human-made image and one created by the generator.
The generator learns from its mistakes; when the discriminator is fooled into thinking that a new image is a real-life portrait, the result is something along the lines of Edmond de Belamy.
People are interested in AI art because it looks like what we know as art, but this is not art, this is just reproduction, just imitation. If a human was to make this art now, we would say it was bad art, so why is it interesting if a machine makes it?
Maurice Benayoun, professor, School of Creative Media, City University of Hong Kong
The auction went on to capture public imagination, but not everyone was impressed, particularly other artists working within the field, who criticised the sale.
STYLE Edit: Why Ermenegildo Zegna’s exhibition showcases a pile of rags among gorgeous artworks
“The guys behind this stunt are not even artists, but a very talented start-up, who knew how – with an initially false narrative, the right keywords and some good contacts – to cash in on the hype,” German artist Mario Klingemann, one of the first creative coders to experiment with AI and art, says.
“I was disappointed that a marketing ploy as obvious as this actually worked.”
Klingemann’s own artwork, Memories of Passersby I, uses neural networks – what he calls “neurography” – to generate an infinite stream of imaginary portraits that are projected onto a two-screen installation.

Other versions followed. Memories of Passersby I was sold in March by Sotheby’s London for a much cooler US$51,000 with fees.
Robbie Barratt, a 19-year-old pioneer of GAN art, whose algorithms shared online via open-source licence were tweaked by Obvious for its project, has also reacted to the sale, describing Belamy as neither interesting nor original.
Self-rolling suitcases, companion robots and roll-up TVs rule at CES 2019 – with a little help from AI
GANs are, by their nature, derivative: they don’t create, they generate.
Now a cornerstone of contemporary machine learning, GANs were first designed by researcher Ian Goodfellow in 2014.
Unlike the repetitious results produced by DeepDream, GANs can be trained to produce new and different images. But the images are still emulative and this, many agree, excludes them from serious consideration as art.

“People are interested in AI art because it looks like what we know as art, but this is not art, this is just reproduction, just imitation,” Maurice Benayoun, a professor at School of Creative Media, City University of Hong Kong, says.
“If a human was to make this art now, we would say it was bad art, so why is it interesting if a machine makes it?”
Art is about ideas; whether an artist uses a paint brush or AI, these are tools to communicate ideas. So while GANs themselves may not produce what many would consider as art, in the hands of an artist, they could indeed be used to speak of the world beyond the image.
“I’m not a painter,” says Klingemann. “My way of expression is through code. From my perspective, code allows me to translate what is in my head out into the world better than anything I could ever accomplish with my hands and physical tools.
8 high-profile galleries to check out at Art Basel Hong Kong 2018
“For me, personally, there is no question that what I and other serious artists in this field are creating with AI is art – and many curators, collectors and critics seem to agree.”

Klingemann is creatively involved throughout the art-making process, from the initial concept for a work, through selecting and modifying neural architectures, finding and curating data to train the models, combining various models and embedding them in other algorithms and, finally, choreographing and curating their output.
“AI in its current state is surprising, unpredictable and can be very inspiring but it’s still me who plays the creative role in this relationship,” he says.
I’m not a painter. My way of expression is through code [which] allows me to translate what is in my head out into the world better than anything I could ever accomplish with my hands and physical tools
Mario Klingemann
A professor at Rutgers University in the United States has complicated the debate, however.
Ahmed Elgammal believes that AICAN – think GAN 2.0 – puts creativity firmly in the capabilities of machine intelligence.
“GAN tries to emulate images, but art must make something new. So we developed our creative adversarial network,” says Elgammal, a professor of computer science and director at Rutgers’ Art and Artificial Intelligence Laboratory, which created a program called AICAN (Artificial Intelligence Creative Adversarial Network).
Elgammal fed the program with images from across five centuries, from the Renaissance to the present day, all grouped into categories by aesthetic, so that it could learn the concept of style.
Like in GAN, AICAN was tasked with learning the aesthetics of existing works of art, but it was not allowed to closely emulate styles. This effectively gave the machine two opposing forces: follow the aesthetics, don’t repeat styles.
Much of AICAN’s art is abstract; Elgammal suggests this is perhaps because the algorithm has grasped that if it wants to make something novel, it cannot go back and produce figurative works as existed before the 20th century.
The AICAN artwork Divided Sunshine (2018), a pigment print on rag paper, is a field of blue over a hazy strip of white, reminiscent of the sky. A thick streak of deep red runs vertically down the centre of the image, alongside a thinner, incomplete strip, also red.
It was exhibited at SCOPE Miami Beach and The Arts+ in Frankfurt last year.
“The definition of creativity is a long and ongoing debate,” Elgammal says. “Immanuel Kant’s definition of the 18th century is based on two qualities: something has to be novel, and it has to have influence, like Pablo Picasso’s Les Demoiselles d’Avignon [1907], which sparked the cubist movement. This definition helped inspire AICAN.”
“But the division of art and science – aesthetics as subjective and science as objective – can also be traced back to Kant, and I don’t believe this is true. I established this lab because I believe looking at art will advance AI. Intelligence is not just used in driving a car or playing chess, it is involved in listening to music, comprehending literature and enjoying art. If we want to build a machine that is intelligent, we need to step into this territory of creativity.”
Elgammal has conducted tests with viewers, flesh-and-blood discriminators, to assess reactions to human-generated and machine-generated works. He says there is very little difference, and that, in fact, some people are more inspired by the art that is done by machine.
Does this suggest AICAN works should be considered art? Not if your definition of art is that it should speak of the wider world or provide an emotional response to it. For the time being, AI art remains in the realm of science fiction.
 
Art Basel 2018: How many ways can a Lady Dior bag be recreated?
 

 
For me, personally, there is no question that what I and other serious artists in this field are creating with AI is art … it’s still me who plays the creative role in this relationship … and many curators, collectors and critics seem to agree
Mario Klingemann
11 Instagrammable displays at Art Basel Hong Kong 2018
 
This is not what art is about

Many see the extravagant US$432,500 paid last year for the world’s first AI art at auction as indicative of the art market in general.
Klingemann, who describes Edmond de Belamy as “mediocre and unrepresentative”, says the sale “tells you more about the art market than about art”.
Like Klingemann, Benayoun is frustrated with the fetishisation of art. A market in which an unnamed buyer spends US$91 million on Koons’ stainless steel sculpture of a rabbit is one that inspires incredulity.
“The art market is important, of course, but who is inspired by this rabbit?” asks Benayoun, who has been described as France’s most cutting-edge artist.
The art market is important, of course, but who is inspired by this rabbit? The technique of making a rabbit of steel or imitations of paintings made of bits … This is not what art is about
Maurice Benayoun
“The technique of making a rabbit of steel or imitations of paintings made of bits … This is not what art is about.
“When someone invests US$91 million, I hope they will invest US$92 million in artist Piero Manzoni’s 1960s work Artist’s Shit – literally his own excrement in a can. This is a better artwork, was done long before, and it’s organic.
“I hope whoever bought the rabbit will go bankrupt very soon as there are so many more relevant ways to spend this money. Art is supposed to help us understand the world and perhaps change it a little. Art is giving shape to ideas.”
Blocktails are the new cocktails: how blockchain tech is pushing new frontiers in the F&amp;B world
Benayoun is literally giving shape to ideas through a blockchain-based art project called Value of Va lues (VoV).
In an attempt to find the real, economic value of human values through EEG (electroencephalography), an interactive art installation titled Brain Factory allows the audience to give a shape to abstract concepts through Brain-Computer Interaction (BCI), and then converts the resulting forms into physical objects.
I hope whoever bought [Jeff Koons’] rabbit will go bankrupt very soon as there are so many more relevant ways to spend this money. Art is supposed to help us understand the world and perhaps change it a little. Art is giving shape to ideas
Maurice Benayoun
So anyone sitting in the artist’s chair can, merely by thinking of an abstract concept like justice, power or peace, can “design” them in 3D model form.
The neuro-designed shapes are entered onto the blockchain and can be converted into cryptocurrency, giving a monetary value to the art. If thousands of the shapes are bartered or sold, all tracked in real time, this gives metaphorical insight into the relative value of human values and the workings of the art market.
You can now own British singer George Michael&apos;s artworks – here&apos;s how
Yet projects such as VoV, and the fact that AI is able to create infinite variations around a concept or style, showing that the idea of a single perfect work is merely a dream, may be no match for the way in which the single artefact, the unique object, is revered today in an almost cultish fashion.
“Art is a belief system, like a religion in which rationality has no place, so I doubt that the notion of art objects as fetishes that have arbitrary high values will go away any time soon,” Klingemann says.
Want more stories like this? Sign up here. Follow STYLE on Facebook, Instagram and Twitter
",,,,,,"Would you pay US$432,500 for this blurry painting made by an AI algorithm?",https://www.scmp.com/magazines/style/tech-design/article/3017387/would-you-pay-us432500-blurry-painting-created-ai,"{'@type': 'ContactPoint', 'contactType': 'customer support', 'telephone': '+852-2680-8888'}","['https://www.facebook.com/southchinamorningpost/', 'https://twitter.com/SCMPNews', 'https://www.youtube.com/southchinamorningpost', 'https://www.linkedin.com/company/south-china-morning-post', 'https://www.instagram.com/scmpnews', 'https://plus.google.com/b/109548181662196012156/+SouthChinaMorningPostSCMP']",Magazines,en-GB,"{'@type': 'Place', 'name': 'Hong Kong'}",https://www.scmp.com/policies-and-standards,French artist Maurice Benayoun’s Brain Factory at Microwave Festival,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LnBzdS5lZHUvbmV3cy9yZXNlYXJjaC9zdG9yeS91c2luZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1kZXRlY3QtZGlzY3JpbWluYXRpb24v0gEA?oc=5,Using artificial intelligence to detect discrimination - Penn State University,2019-07-11,Penn State University,https://www.psu.edu, A new artificial intelligence tool for detecting unfair discrimination — such as on the basis of race or gender — has been created by researchers at Penn State and Columbia University.  ,N/A,A new artificial intelligence tool for detecting unfair discrimination — such as on the basis of race or gender — has been created by researchers at Penn State and Columbia University.,N/A,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'undefined/research/story/using-artificial-intelligence-detect-discrimination'}",Using artificial intelligence to detect discrimination,https://sc-api.psu.edu/s3/files/styles/4_3_2000w/public/AI%20discrimination%20GettyImages%20fatido.jpg?h=4d18bf5b&itok=l5Tcu9lu,,,N/A,N/A,Advocate Penn State,,"[{'@type': 'Person', 'name': 'Sara LaJeunesse', 'url': ''}]","{'@type': 'Organization', 'name': '\u200bPenn State News', 'logo': {'@type': 'ImageObject', 'url': 'https://www.psu.edu/components/img/psu-mark-footer.png', 'width': 164, 'height': 52}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3LnNhYW5pY2huZXdzLmNvbS9uZXdzL2FyZS1yb2JvdHMtY29taW5nLWZvci15b3VyLWpvYnMtbWF5YmUtbWF5YmUtbm90LXJlcG9ydC0yNzMxMDTSAQA?oc=5,Are robots coming for your jobs? This think tank says no - Saanich News,2019-07-10,Saanich News,https://www.saanichnews.com,"Artificial intelligence, robots, won’t necessarily displace workers",N/A,"Artificial intelligence, robots, won’t necessarily displace workers",N/A,http://schema.org,NewsArticle,https://www.saanichnews.com/news/are-robots-coming-for-your-jobs-maybe-maybe-not-report-273104,Are robots coming for your jobs? This think tank says no,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://www.bpmcdn.com/f/files/saanich/import/2019-07/17622640_web1_190408-RDA-M-190409-RDA-artificial-intelligence.jpg', 'width': '1200', 'height': '800', 'description': 'FILE - This Monday, Aug. 1, 2016 file photo shows the humanoid robot “Alter” on display at the National Museum of Emerging Science and Innovation in Tokyo. Understanding humor may be one of the last things that separates humans from ever smarter machines, computer scientists and linguists say. (AP Photo/Koji Sasahara)'}",2019-07-09T17:00:00Z,2019-07-10T21:16:35Z,News,N/A,N/A,https://www.saanichnews.com/news/are-robots-coming-for-your-jobs-maybe-maybe-not-report-273104,Katya Slepian,"{'@context': 'http://schema.org', '@type': 'NewsMediaOrganization', 'name': 'Saanich News', 'url': 'https://www.saanichnews.com', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://www.bpmcdn.com/files/ui/bpm/SNE_onw.png', 'width': '194', 'height': '32'}, 'address': {'@type': 'PostalAddress', 'addressLocality': 'Saanich', 'addressRegion': 'BC', 'postalCode': None, 'streetAddress': None}, 'sameAs': ['https://x.com/saanichnews']}",News,Saanich News,False,,2019-07-09T17:00:00Z,"{'@type': ['CreativeWork', 'Product'], 'name': 'Saanich News', 'productID': 'saanichnews.com:showcase'}",,,"{'@type': 'PostalAddress', 'addressLocality': 'Saanich', 'addressRegion': 'BC', 'postalCode': None, 'streetAddress': None}",,,,,,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://www.bpmcdn.com/files/ui/bpm/SNE_onw.png', 'width': '194', 'height': '32'}",,,,,,,,,,,['https://x.com/saanichnews'],,,,,,"{'@type': 'SpeakableSpecification', 'cssSelector': 'details-title, details-intro'}",294.0,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3LmFlaS5vcmcvZXZlbnRzL3JvYm90LXByb29mLWhpZ2hlci1lZHVjYXRpb24taW4tdGhlLWFnZS1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,Robot-proof: Higher Education in the Age of Artificial Intelligence - American Enterprise Institute,2019-07-10,American Enterprise Institute,https://www.aei.org,N/A,N/A,Join AEI for a discussion on the key recommendations from Dr. Aoun’s book and the implications for the future of higher education and human capital development.,N/A,https://schema.org,,,,,,,N/A,N/A,"



                    Event                


 




                                    Wednesday, July 10, 2019 | 10:30 AM to 11:45 AM ET                                



Robot-proof: Higher Education in the Age of Artificial Intelligence


With 



                            AEI, Auditorium
1789 Massachusetts Avenue NW 
Washington, DC 20036                        

                            Contact Information
                            For more information, please contact Caleb Seibert at caleb.seibert@aei.org, 202.828.6027.








Event Summary
On July 10, AEI hosted Northeastern University President Joseph E. Aoun to discuss his recent book, “Robot-Proof: Higher Education in the Age of Artificial Intelligence” (MIT Press, 2017), with AEI’s Brent Orrell and Stan Veuger.
Dr. Aoun introduced the concepts outlined in his book by calling attention to the widespread concern that artificial intelligence (AI) will destroy more jobs than it will create. In the discussion that followed, he demonstrated that while education providers will have to adjust, AI cannot automate out the workforce, as many jobs require human thought and connection. He emphasized that the key to responding to the challenges new technology is bringing to education and the workforce is to focus career training on the humanics and lifelong learning.
Dr. Aoun’s remarks were followed by a panel discussion with Mr. Orrell and Dr. Veuger, who emphasized the complexity of predicting the effects of automation on labor and highlighted strategies for retraining the workforce. Audience members also asked a series of questions, relating Dr. Aoun’s recommendations to the financial burden of higher education and to the value of liberal arts degrees in training the next generation in the humanics. The event concluded with Dr. Aoun highlighting the need for colleges and universities to incorporate experiential and lifelong learning, in which students connect theory learned in the classroom to practice outside of the classroom, into curriculums.
— Clare O’Connor
Event Description
Today, nearly every conversation about the future of work and the modern economy is dominated by the specter of robotics and intelligent machines. In his new book, “Robot-Proof: Higher Education in the Age of Artificial Intelligence” (MIT Press, 2017), Northeastern University President Joseph E. Aoun confronts the need for colleges and universities to meet the challenge — and opportunity — presented by smart machines. His blueprint features three primary components: a new curriculum for the artificial intelligence age, the case for experiential learning, and a call for higher education to place lifelong learning at the heart of the educational enterprise.
Join AEI for a discussion on the key recommendations from Dr. Aoun’s book and the implications for the future of higher education and human capital development.
Join the conversation on social media with @AEI on Twitter and Facebook.
If you are unable to attend, we welcome you to watch the event live on this page. Full video will be posted within 24 hours.



Agenda
10:15 AM
Registration
10:30 AM
Welcome:
Brent Orrell, AEI
10:35 AM
Opening remarks:
Joseph E. Aoun, Northeastern University
10:50 AM
Panel discussion
Panelists:
Joseph E. Aoun, Northeastern University
Stan Veuger, AEI
Moderator:
Brent Orrell, AEI
11:30 AM
Q&A
11:45 AM
Adjournment







",,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.aei.org/events/robot-proof-higher-education-in-the-age-of-artificial-intelligence/', 'url': 'https://www.aei.org/events/robot-proof-higher-education-in-the-age-of-artificial-intelligence/', 'name': 'Robot-proof: Higher Education in the Age of Artificial Intelligence | American Enterprise Institute - AEI', 'isPartOf': {'@id': 'https://www.aei.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.aei.org/events/robot-proof-higher-education-in-the-age-of-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://www.aei.org/events/robot-proof-higher-education-in-the-age-of-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.aei.org/wp-content/uploads/2019/06/robot_proof_artificial_intelligence_800x469.png', 'datePublished': '2019-06-14T11:43:10+00:00', 'dateModified': '2022-05-25T20:48:47+00:00', 'breadcrumb': {'@id': 'https://www.aei.org/events/robot-proof-higher-education-in-the-age-of-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.aei.org/events/robot-proof-higher-education-in-the-age-of-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.aei.org/events/robot-proof-higher-education-in-the-age-of-artificial-intelligence/#primaryimage', 'url': 'https://www.aei.org/wp-content/uploads/2019/06/robot_proof_artificial_intelligence_800x469.png', 'contentUrl': 'https://www.aei.org/wp-content/uploads/2019/06/robot_proof_artificial_intelligence_800x469.png', 'width': 800, 'height': 469, 'caption': '@tampatra via Twenty20'}, {'@type': 'BreadcrumbList', '@id': 'https://www.aei.org/events/robot-proof-higher-education-in-the-age-of-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.aei.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Robot-proof: Higher Education in the Age of Artificial Intelligence'}]}, {'@type': 'WebSite', '@id': 'https://www.aei.org/#website', 'url': 'https://www.aei.org/', 'name': 'American Enterprise Institute - AEI', 'description': 'The American Enterprise Institute, AEI, is a nonpartisan public policy research institute with a community of scholars and supporters committed to expanding liberty, increasing individual opportunity and strengthening free enterprise.', 'publisher': {'@id': 'https://www.aei.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.aei.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.aei.org/#organization', 'name': 'American Enterprise Institute - AEI', 'url': 'https://www.aei.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.aei.org/#/schema/logo/image/', 'url': 'https://www.aei.org/wp-content/uploads/2022/08/logo.svg', 'contentUrl': 'https://www.aei.org/wp-content/uploads/2022/08/logo.svg', 'width': 145, 'height': 74, 'caption': 'American Enterprise Institute - AEI'}, 'image': {'@id': 'https://www.aei.org/#/schema/logo/image/'}}]",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigAFodHRwczovL3d3dy5kb3dudG9lYXJ0aC5vcmcuaW4vYmxvZy9zY2llbmNlLXRlY2hub2xvZ3kvaXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZXhjbHVkaW5nLWluZGlhbi13b21lbi1zbWFydHBob25lLXVzZXJzLS02NTU2MNIBAA?oc=5,Is Artificial Intelligence excluding Indian women smartphone users? - Down To Earth Magazine,2019-07-10,Down To Earth Magazine,https://www.downtoearth.org.in,,"Science & Technology,Smartphones,Women","An artificial intelligence (AI)-powered revolution is underway, and it fits in the palm of our hands. AI is changing the way we experience technology, and nowhe","An artificial intelligence (AI)-powered revolution is underway, and it fits in the palm of our hands. AI is changing the way we experience technology, and nowhe",http://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.downtoearth.org.in/science-technology/is-artificial-intelligence-excluding-indian-women-smartphone-users--65560'}",Is Artificial Intelligence excluding Indian women smartphone users?,"{'@type': 'ImageObject', 'url': 'https://gumlet.assettype.com/down-to-earth/import/library/large/2019-07-10/0.52274000_1562757426_sj.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",2019-07-10T04:34:44Z,2019-07-11T01:11:15Z,N/A,N/A,N/A,https://www.downtoearth.org.in/science-technology/is-artificial-intelligence-excluding-indian-women-smartphone-users--65560,"[{'@type': 'Person', 'givenName': 'Esha Rao', 'name': 'Esha Rao', 'url': 'https://www.downtoearth.org.in/author/esha-rao'}, {'@type': 'Person', 'givenName': 'Vineet Bhandari', 'name': 'Vineet Bhandari', 'url': 'https://www.downtoearth.org.in/author/vineet-bhandari'}, {'@type': 'Person', 'givenName': 'Dayoung Lee', 'name': 'Dayoung Lee', 'url': 'https://www.downtoearth.org.in/author/dayoung-lee'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Down To Earth', 'url': 'https://www.downtoearth.org.in', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'downtoearth', 'contentUrl': 'https://thumbor-stg.assettype.com/downtoearth/2024-03/6387df98-00ed-4b50-b1fb-ae54adbb9dce/DTE_English.png', 'url': 'https://thumbor-stg.assettype.com/downtoearth/2024-03/6387df98-00ed-4b50-b1fb-ae54adbb9dce/DTE_English.png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.facebook.com/down2earthindia', 'https://twitter.com/down2earthindia', 'https://www.youtube.com/channel/UCIB_MLJZL0T_s5OUuqhmbVA', 'https://www.instagram.com/dtemagazine/'], 'id': 'https://www.downtoearth.org.in'}",Science & Technology,Is Artificial Intelligence excluding Indian women smartphone users?,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.downtoearth.org.in'}, {'@type': 'ListItem', 'position': 2, 'name': 'Science & Technology', 'item': 'https://www.downtoearth.org.in/science-technology'}, {'@type': 'ListItem', 'position': 3, 'name': 'Is Artificial Intelligence excluding Indian women smartphone users?', 'item': 'https://www.downtoearth.org.in/science-technology/is-artificial-intelligence-excluding-indian-women-smartphone-users--65560'}]",2019-07-10T04:34:44Z,"{'@type': 'WebPage', 'url': 'https://www.downtoearth.org.in/science-technology/is-artificial-intelligence-excluding-indian-women-smartphone-users--65560', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://gumlet.assettype.com/down-to-earth/import/library/large/2019-07-10/0.52274000_1562757426_sj.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,,"An artificial intelligence (AI)-powered revolution is underway, and it fits in the palm of our hands. AI is changing the way we experience technology, and nowhere is its value as easily apparent as through our smartphones..It learns our preferences to personalise our news feeds and music playlists. It lets us upload photos that are Instagram-worthy and unlocks phones through facial recognition. It recognises and deciphers our voice and powers our digital assistants..Voice-enabled search is an increasingly preferred mode of vernacular web browsing, with 28 per cent of search queries in India being conducted by voice and Hindi search queries increasing by 400 per cent year on year (Indian consumers say big hello to voice-based devices, Tech Trend, Business Standard, 2019). This is increasingly true for the first-time users who find voice-based input more intuitive than typing on the phone..However, AI raises new challenges for the 40 million (More than a quarter of India’s population will be smartphone users this year, eMarketer, 2018) first-time smartphone users being added each year, especially women (Smartphone users in India 2018: 16% YoY Growth is the highest in the world, DazeInfo, 2018)..Lata, who resides in Chhattisgarh and uses her husband’s smartphone to watch the Mahabharat on a regional infotainment app, struggled to find maternal and child health content that was available on the same app — “I am not able to find videos on my child’s health on this application. I did not know it was there. I will use it now”. Why does AI fail to personalise content for her, thus limiting her ability meet her aspirations?.In its simplest form, AI uses an algorithm to monitor the user’s engagement with digital content, learning every time the user chooses to Like, Share, Play, and Skip. This information is leveraged to predict the relevance of future content, with higher usage resulting in better personalisation..Such usage-based algorithms are biased in favour of those who are active smartphone users. Where the system trips up, unfortunately, is on the fact that women are not active smartphone users on average..Like Lata, a large segment of women access smartphones that belong to a male family member, typically the father, the husband or the son. Our work in Chhattisgarh, where the government distributed 3.5 million smartphones to women, suggests that they tend to be the least active on these smartphones..As first-time users, often on ‘borrowed’ smartphones, women are a less likely to carry out even basics tasks on a mobile phone. For example, the gender gap for making / receiving calls and sending an SMS is approximately 20 per cent and 50 per cent percentage points, respectively (Wide gender gap in mobile phone access is hurting India’s women, IndiaSpend, 2018). .In such a context, AI is simply unable to learn about her likes and dislikes. Content is curated for frequent phone users such as children and men in the household..As such, women must scroll through a long list of articles and videos to discover what is relevant for them, reducing the efficacy of their time using the smartphone. AI, by the very nature of how it works, is leaving first time women users behind. .This is far from saying that AI is the root cause of the kind of digital inequality we see today. AI is a technological tool that is built to be neutral in a world that is built to be unequal..Patriarchal societal and cultural norms cause women to face restrictive environments, in which their needs are often de-prioritised over the needs of the child, or the family. It is a social ill that outdates digital technology by several centuries, and its effects cannot be willed away any time soon despite our best efforts..Other factors such as women’s lack of digital literacy and limited access to information channels compound the situation. Knowing that we cannot solve for gender inequality right away, the least we can do is ensure that advances in technology do not widen the inequality..An AI that works for women.A good starting point would be to work with solution providers who are willing to use a gender lens. We worked with one such provider to re-design an infotainment app using a human-centered design process to place a woman’s contexts and realities, and her needs and aspirations at the center of the design process. .We visited rural districts in Chhattisgarh and conducted HCD research through in-depth interviews, intercepts, group discussions, and observations. Using these research methods, the team tested prototypes for the digital solutions and co-designed specific User Interface/User Experience features with the women..Our interactions with Lata and over 80 other women revealed that traditional solutions — such as user profiles — don’t work for them. First-time users simply ignored the profiles as they were unfamiliar with the concept..Even those who understood the concept, raised privacy concerns as they did not want the profiles to become a way for the male members to inspect their usage. Passwords were hard to remember and only increased suspicion..Our work suggested a preference for non-dynamic navigable content categories — movies, songs, health and agriculture among others on the landing page. We discovered that they sought relevant content but within these categories..The convenience of this is analogous to being able to look up the right aisle in a super market to pick up the stuff you need rather than going through another frequent member’s shopping list. Pressed for time, and often struggling to use new services, women need AI that works for them..The next phase of growth in smartphone usage will come from women users. And they are increasingly overcoming social barriers and aspire to leverage smartphones to access government schemes, apply for scholarships for their children, improve their vocational skills, and find jobs among other things..Making the effort to create solutions that take a gender lens to solution design, can aid digital inclusion for women. It is time that we saw that new technology does not repeat the biases of outdated values..Esha Rao is an associate consultant while Vineet Bhandari is a senior project manager at Dalberg. Dayoung Lee is an associate partner based in Mumbai and a co-lead of the Education to Employment Practice",,https://gumlet.assettype.com/down-to-earth/import/library/large/2019-07-10/0.52274000_1562757426_sj.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy5maWVyY2VoZWFsdGhjYXJlLmNvbS90ZWNoL3Byb3ZpZGVuY2Utc3Qtam9zZXBoLWhlYWx0aC1taWNyb3NvZnQtZm9ybS1zdHJhdGVnaWMtYWxsaWFuY2UtdG8tbGV2ZXJhZ2UtY2xvdWQtYWktdGVjaG5vbG9nedIBAA?oc=5,"Providence St. Joseph Health, Microsoft form strategic alliance to leverage cloud, AI technology - Fierce healthcare",2019-07-08,Fierce healthcare,https://www.fiercehealthcare.com,Providence St.,"Administrative costs,Artificial Intelligence,Clinical Decision Support,Cloud Computing,Data,Data Analytics,Interoperability,FHIR,Microsoft,Providence St. Joseph,Fierce Healthcare Homepage,Hospitals,Finance,AI and Machine Learning,Health Tech",Providence St. | Providence St. Joseph Health has formed a multiyear strategic alliance with tech giant Microsoft to modernize its health IT infrastructure across its entire system and leverage cloud and artificial intelligence technologies to improve health outcomes and reduce the total cost of care.,Providence St. | Providence St. Joseph Health has formed a multiyear strategic alliance with tech giant Microsoft to modernize its health IT infrastructure across its entire system and leverage cloud and artificial intelligence technologies to improve health outcomes and reduce the total cost of care.,https://schema.org/,,,,,,,"Fierce Healthcare Homepage,Hospitals,Finance,AI and Machine Learning",N/A,"

































Fierce Pharma


Fierce Biotech


Fierce Healthcare


Fierce Life Sciences Events






Advertise


About Us








 

 


























 










Providers



Hospitals


Practices


Retail




Health Tech



AI and Machine Learning


Digital Health


Telehealth




Payers


Regulatory


Finance


Special Reports


Fierce 50



Special Report


Awards Gala








Resources



Webinars


Fierce Events


Industry Events


Podcasts


Survey


Whitepapers



 Events 

Subscribe
















 




Subscribe





























Providers



Hospitals


Practices


Retail




Health Tech



AI and Machine Learning


Digital Health


Telehealth




Payers


Regulatory


Finance


Special Reports


Fierce 50



Special Report


Awards Gala








Resources



Webinars


Fierce Events


Industry Events


Podcasts


Survey


Whitepapers



 Events 

Subscribe










Fierce Pharma


Fierce Biotech


Fierce Healthcare


Fierce Life Sciences Events






Advertise


About Us








 

 













































Health Tech




Providence St. Joseph Health, Microsoft form strategic alliance to leverage cloud, AI technology





By 
Heather Landi





Jul 8, 2019 12:32pm




Administrative costs
Artificial Intelligence
Clinical Decision Support
Cloud Computing














The health system plans to deploy next-generation solutions and emerging technologies from Microsoft at a hospital facility in Seattle, in Microsoft’s backyard. (Providence St. Joseph Health)
Providence St. Joseph Health has formed a multiyear strategic alliance with tech giant Microsoft to modernize its health IT infrastructure across its entire system and leverage cloud and artificial intelligence technologies to improve health outcomes and reduce the total cost of care.The two organizations will work together to modernize Providence St. Joseph Health's IT infrastructure, particularly around informatics as well as its business infrastructure, Rod Hochman, M.D., president and CEO of Providence St. Joseph Health, told FierceHealthcare. ""All of us recognize that healthcare has been slow to this modernization and other industries have moved ahead at a more rapid rate,"" he said. The 51-hospital health system serves 10 million patients a year across seven states and operates more than 900 clinics. The Renton, Washington-based health system is in Microsoft's backyard, Hochman said, opening an opportunity to collaborate and transform the care experience.The health system plans to deploy next-generation solutions and emerging technologies from Microsoft and its partners at a hospital facility in Seattle, Washington, near Microsoft’s Redmond headquarters. A specific facility site has not yet been announced. The goal will be to scale these innovations across the entire Providence St. Joseph Health system to bring innovative and necessary solutions to more communities.""This is the most comprehensive partnership between a technology company and a health system,"" Hochman said.Satya Nadella, CEO of Microsoft, said in a statement that the goal of the partnership is to accelerate Providence St. Joseph Health’s digital transformation and to ""build new innovations together that are designed to improve health care delivery and outcomes.""RELATED: Providence St. Joseph Health launches business offering PBM service, population health expertiseThe two organizations will develop a portfolio of integrated solutions designed to improve care delivery by combining technologies from Microsoft with Providence St. Joseph Health’s data and clinical expertise. The alliance will accelerate the healthcare industry’s adoption of the cloud and enable data-driven clinical and operational decision-making by leveraging Microsoft Azure, and industry interoperability standards like FHIR, to integrate siloed data sources in a cloud environment that enables security and compliance, the organizations said.“At Microsoft, we believe that engaging a range of partners across the health care ecosystem will be required to improve the value of care that is provided,” Peter Lee, Ph.D., corporate vice president at Microsoft Healthcare, said in a statement. “With Providence St. Joseph Health, we believe we can work together to address many of the most difficult problems that affect the health care industry by combining Microsoft’s research, cloud, and productivity capabilities with Providence St. Joseph Health’s clinical expertise.” Hochman said there are several key elements to the strategic alliance which will develop over the next five years: ""The first is to heavily support our clinicians in making them more productive and to develop collaboration tools to make clinicians more effective, beyond what can do with their electronic health records.""RELATED: Providence St. Joseph Health acquires Epic IT solutions consultant Bluetree As part of the strategic alliance, Providence St. Joseph Health will use Microsoft Azure as its preferred cloud platform and standardize productivity and collaboration tools for its 119,000 caregivers on Microsoft 365. Health system doctors and nurses will use Microsoft Teams for more secure communication and collaboration, the organizations said.The health system plans to work with Microsoft to modernize its revenue cycle IT platform to become more efficient and reduce administrative costs. Providence St. Joseph Health will also transition out of eight data centers to a more flexible, secure cloud environment and harness cloud computing and analytics, Hochman said.The IT modernization will also improve the care experience for consumers, Hochman said: ""Consumers want their experience in healthcare to be a little bit more integrated, to say the least. This work will enable doctors, clinicians and nurses to have as much information at the point of care as possible.""By working with Microsoft to leverage AI, the health system will be able to tackle ""low-hanging fruit,"" Hochman noted: ""We think AI is going to be tremendously helpful, particularly in clinical decision making, orthopedics, the neurosciences, and cancer, and being able to combine research and AI to accelerate it.""The strategic alliance with Microsoft also ties into the health system's focus on nonclinical projects within its business. In February, Providence St. Joseph Health launched Ayin Health Solutions, a population health company, to offer expertise to help payers, providers, employers and government entities with the shift to value-based care. RELATED: HIMSS19: Providence St. Joseph Health acquires revenue cycle management blockchain startupIt also recently announced plans to acquire Bluetree, an Epic consulting and strategy company that helps healthcare providers maximize their return on their electronic health record investment. The health system also owns Engage, which has grown to become one of the largest Meditech solution companies in the United States, according to the health system.The health system acquired Seattle-based Lumedic, a revenue cycle management company based on blockchain technology, with the aim of streamlining data sharing and improving claims processing.Mike Butler, PSJH's president of strategy and operations, told Xconomy that the Bluetree deal is part of the health system's plan to create a billion-dollar company from its nonclinical projects. The health system expects the company to produce 20% EBITDA by 2023. Annual revenue so far is $44 million for Engage and $15 million for the Community Connect business, according to the Xconomy article.""We’ve recognized in our own organization that besides providing direct healthcare it's important for healthcare organizations our size to also be a service organization,"" Hochman said. ""The things that come out of the Microsoft partnership to facilitate clinical and business operations for our health system could be exportable to other health systems to improve the administrative back office as well as clinical tools and AI to transform healthcare.""

Administrative costs
Artificial Intelligence
Clinical Decision Support
Cloud Computing
Data
Data Analytics
Interoperability
FHIR
Microsoft
Providence St. Joseph
Hospitals
Finance
AI and Machine Learning
Health Tech












Related ContentUnitedHealth reaffirms guidance as it posts $4.2B in Q2 profitJul 16, 2024 07:34amNo Surprises Act audit finds inaccurate calculations by Aetna of TexasJul 15, 2024 05:10pmFTC probing DaVita, Fresenius Medical Care's noncompetes for dialysis clinic medical directorsJul 15, 2024 04:00pmChicago safety-net hospital's former CFO charged in $15M embezzlement schemeJul 15, 2024 04:00pm







See more articles










 



 

 








Connect



The Team


Advertise




Join Us



Newsletters


Resources


RSS Feeds


Editorial Advisory Council




Our Brands



Fierce Pharma


Fierce Biotech


Fierce Healthcare




Our Events



Life Sciences Events

















©2024 Questex LLC All rights reserved.
Terms of use
Privacy Policy
Privacy Settings











",,,,,,,,,,,,,,,,,,,,,,,"{'@type': 'NewsArticle', 'headline': 'Providence St. Joseph Health, Microsoft form strategic alliance', 'articleSection': None, 'keywords': 'Health Tech', 'description': 'Providence St. Joseph Health has formed a multiyear strategic alliance with Microsoft.', 'datePublished': '2019-07-08T16:32:25', 'isAccessibleForFree': True, 'dateModified': '1648105029', 'author': [[{'@type': 'Person', 'name': 'Heather Landi', 'url': 'https://www.fiercehealthcare.com/person/heather-landi'}]], 'publisher': {'@type': 'Organization', 'name': 'FierceHealthcare', 'url': 'https://www.fiercehealthcare.com'}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.fiercehealthcare.com/tech/providence-st-joseph-health-microsoft-form-strategic-alliance-to-leverage-cloud-ai-technology'}, 'image': 'https://qtxasset.com/quartz/qcloud5/media/image/fiercehealthcare/1562600860/PSJH-Main-Entrance-Renton.jpg/PSJH-Main-Entrance-Renton.jpg?VersionId=C9kc7EJg9_yeI.G9hn.qEmY27SdVd8aK'}",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vZGFpbHloaXZlLmNvbS92YW5jb3V2ZXIvZnVqaXRzdS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS10ZWNobm9sb2d5LXZhbmNvdXZlci1vZmZpY2UtMjAxOdIBAA?oc=5,Fujitsu's new global AI headquarters office opens in Vancouver | Venture - Daily Hive,2019-07-10,Daily Hive,https://dailyhive.com,Adding to the city&#39;s reputation as an AI leader. ,"Fujitsu,Vancouver Tech,News,Venture,Tech",Tokyo-based multinational company Fujitsu recently opened its global artificial intelligence head office at One Bentall Centre in downtown Vancouver.,Tokyo-based multinational company Fujitsu recently opened its global artificial intelligence head office at One Bentall Centre in downtown Vancouver.,http://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': '/vancouver/fujitsu-artificial-intelligence-technology-vancouver-office-2019'}",Fujitsu&#39;s new global AI headquarters office opens in Vancouver,https://images.dailyhive.com/20190710002640/fujitsu.jpg,2019-07-10T12:17:21.970Z,2019-07-24T16:04:44.972Z,N/A,N/A,"NewsVentureTechFujitsu's new global AI headquarters office opens in VancouverKenneth Chan|Jul 10 2019, 8:17 amFujitsu logo on a building. (Shutterstock)New and growing computing powers generated by artificial intelligence (AI), developed right here in Vancouver, could help solve the world’s most pressing problems.ADVERTISEMENT
In recent years, the city has developed a global reputation for having one of the world’s largest clusters of forefront AI companies — and now, it can add Fujitsu to the list.
See alsoThis recycling robot at YVR Airport uses artificial intelligence to sort your recyclablesThis is what Vancouver can do to attract more corporate head officesCity of Vancouver needs to focus more on growing the economy, says chief plannerBC's Carbon Engineering gets $25 million from federal governmentTransLink services to be used as an innovative testing ground for tech startups
The Tokyo-based multinational company recently opened its global AI headquarters office at One Bentall Centre in downtown Vancouver. It is a relatively lean operation right now, but by the end of the year its workforce could nearly triple, with continued growth expected over the coming years, matching the exponential growth of market demand for AI-based solutions.ADVERTISEMENT
According to Dean Prelazzi, vice-president and head of business development and marketing for Fujitsu Inteligence Technology (FIT), Vancouver is a highly strategic location for the company.
“[There is] tremendous innovation, a big ecosystem, lots of opportunities to work in collaboration with a variety of organizations and companies, and the startup ecosystem is particularly rich and diverse,” Prelazzi told Daily Hive.
He further emphasized Vancouver’s importance to FIT: “We are committed to being here.”
Local universities, namely the University of British Columbia and Simon Fraser University, provide the local ecosystem with an immense research environment. This is coupled with the industry-level research-and-development outputs and capacities of local giants in quantum computing and data science, specifically TRIUMF, D-Wave Systems, and 1QBit, which is closely associated with Fujitsu.ADVERTISEMENT
Vancouver also has close connections with Asia, especially Fujitsu’s homebase in Japan, and Silicon Valley, and it is also important for FIT to establish a presence in North America, given that is the largest market in the world for AI “by a long shot.”
Government policies on the federal level are also helping catalyze the country’s global leadership in AI. In 2017, Canada became the first country in the world to establish a strategy for developing AI, and this was paired with $125 million in public funding spanning a period of five years.
“As a result of this strategy, Canada is at the forefront globally of leading this cerebral thinking of AI and its impact on society,” he said.ADVERTISEMENT
While Japanese AI in popular media may be more commonly associated with the development of robotics, FIT’s mandate is more grounded in optimizing and commercialization calculations of high-variable problems that were previously beyond the capacity of conventional computing.
This is also about being proactive, before technological developments on computing hit the wall on the limits of Moore’s Law.
FIT’s work in Vancouver centres around its quantum-inspired digital annealer, which combines the power and speed of quantum computing using everyday physical equipment.
“We’re at a point at the development of our society, with respect to getting to the ceiling of computational power, that we need more power if we are going to solve the largest problems in the world… if we are going to solve climate change and cure the diseases of the world and push the limits of drug discovery,” continued Prelazzi.ADVERTISEMENT
He pointed to FIT’s ongoing work with European shipping company Konsberg, which uses the company’s technology’s to analyze weather data to determine the best and most efficient open ocean routes for its cargo ships.
By using AI to optimize vessel fuel usage, it is estimated each cargo ship could save up to $1 million per year in marine fuel costs, and in the process also reduce the level of high sulfur emissions.
In other transportation analysis work for the Japan Post Service, the optimization of route combinations, truck types, and mail and cargo led to an 8% reduction in the number of postal vehicles, 30% reduction in driving time, and 7% reduction in costs.
More recently, FIT began working with the City of Montreal to improve its services and mobility through smart city applications.ADVERTISEMENT
There is immense potential for its AI to be used to optimize manufacturing, particularly the monotonous tasks of production line robots, and even in-store retail. Applications of AI in stores can increase customer engagement and improve self check-out systems, with new AI-powered methods that reduce increasingly apparent fraud problems at the honour system-based kiosks.
In the financial sector, AI is already being used to model the potential direction of stock markets, analyze signatures, help detect fraudulent patterns, and improve security.
And AI in healthcare could go as far as assisting with biopsy diagnostics, helping healthcare practitioners reveal hidden correlations, identify previous care patterns, and create data that previously was not available.
“We’re still challenged in pushing the upper limits of where we need quantum to be in order for it to be integrated as a mainstream operation to solve large problems in production,” said Prelazzi.ADVERTISEMENT
“This digital technology alleviates those challenges and allows companies today to start taking advantage of solving real, very large problems.”
Fujitsu employs 140,000 people globally, and it also has offices in Toronto and Montreal. Founded in 1935, the Fortune 500 company is the world’s second oldest information technology company — just after IBM and ahead of Hewlett Packard.
See alsoThis recycling robot at YVR Airport uses artificial intelligence to sort your recyclablesThis is what Vancouver can do to attract more corporate head officesCity of Vancouver needs to focus more on growing the economy, says chief plannerBC's Carbon Engineering gets $25 million from federal governmentTransLink services to be used as an innovative testing ground for tech startups

Kenneth Chan+ FOLLOWFollow Channels and Categories+ News+ Venture+ Tech",/vancouver/fujitsu-artificial-intelligence-technology-vancouver-office-2019,"[{'@type': 'Person', 'name': 'Kenneth Chan', 'url': '/author/kenneth-chan'}]","{'@type': 'Organization', 'name': 'Daily Hive', 'logo': {'@type': 'ImageObject', 'url': 'https://dailyhive.com/assets/dh_logo-1c9f2e28157849bf2b7979ae64dfa02ab41c99175f9a2cc9a0d5dec96aaea1f8.png'}}","['News', 'Venture', 'Tech']",,,,2019-07-10T12:17:21.970Z,,,,,,,,,,,,,,,,956258,,,,,,,,,,,,,vancouver

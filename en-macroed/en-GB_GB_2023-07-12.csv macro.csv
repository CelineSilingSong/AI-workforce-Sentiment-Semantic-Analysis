URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,itemListElement,@type,author,datePublished,headline,publisher,image,article:section,article:summary,article text,dateModified,@graph,url,articleSection,name,isAccessibleForFree,articleBody,isBasedOn,thumbnailUrl,isPartOf,alternativeHeadline,mainEntityOfPage,logo,sameAs,contactPoint,dateCreated,mentions,hasPart,address,diversityPolicy,email,legalName,leiCode,telephone,brand,inLanguage,comment,commentCount,copyrightHolder,sourceOrganization,copyrightYear,@id,ethicsPolicy,masthead,foundingDate,location,potentialAction,target,genre,about,discussionURL,isFamilyFriendly,person,publishingPrinciples,timeRequired,wordCount,creator,speakable
https://news.google.com/rss/articles/CBMihgFodHRwczovL3d3dy5kZWxvaXR0ZS5jb20vdWsvZW4vYWJvdXQvcHJlc3Mtcm9vbS9tb3JlLXRoYW4tZm91ci1taWxsaW9uLXBlb3BsZS1pbi10aGUtdWstaGF2ZS11c2VkLWdlbmVyYXRpdmUtYWktZm9yLXdvcmstZGVsb2l0dGUuaHRtbNIBAA?oc=5,More than four million people in the UK have used Generative AI for work - Deloitte - Deloitte,2023-07-12,Deloitte,https://www.deloitte.com,"The majority of people in the UK (52%) have heard of Generative AI, and more than a quarter (26%) have used it, according to new findings from Deloitte’s 2023 Digital Consumer Trends research, based on a survey of 4,150 UK adults aged 16-75.",N/A,"The majority of people in the UK (52%) have heard of Generative AI, and more than a quarter (26%) have used it, according to new findings from Deloitte’s 2023 Digital Consumer Trends research, based on a survey of 4,150 UK adults aged 16-75.","The majority of people in the UK (52%) have heard of Generative AI, and more than a quarter (26%) have used it, according to new findings from Deloitte’s 2023 Digital Consumer Trends research, based on a survey of 4,150 UK adults aged 16-75.",https://schema.org/,"[{'item': {'@id': '', 'name': 'Who we are'}, 'position': 1, '@type': 'ListItem'}, {'item': {'@id': '/uk/en/about/press-room.html', 'name': 'Press room'}, 'position': 2, '@type': 'ListItem'}]",Article,[],2023-07-12T00:00:00.0Z,More than four million people in the UK have used Generative AI for work - Deloitte | Deloitte UK,"{'@type': 'Organization', 'name': 'Deloitte', 'logo': {'@type': 'ImageObject', 'url': 'https://www.deloitte.com/content/dam/modern/logo/deloitte-print.png'}}","['https://assets.deloitte.com/is/image/deloitte/deloitte-uk-generative-ai-3:660-x-660?$Responsive$&fmt=webp&fit=stretch,1&dpr=off', 'https://assets.deloitte.com/is/image/deloitte/deloitte-uk-generative-ai-3:800-x-600?$Responsive$&fmt=webp&fit=stretch,1&dpr=off', 'https://assets.deloitte.com/is/image/deloitte/deloitte-uk-generative-ai-3:1200-x-675?$Responsive$&fmt=webp&fit=stretch,1&dpr=off']",N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vd3d3Lmdvb2R3aW5sYXcuY29tL2VuL2luc2lnaHRzL3B1YmxpY2F0aW9ucy8yMDIzLzA3L2luc2lnaHRzLXRlY2hub2xvZ3ktYWltbC1lbXBsb3llcnMtZ2VuZXJhdGl2ZS1haS1hdC13b3Jr0gEA?oc=5,What Employers Need to Know About Use of Generative AI at Work | Insights & Resources | Goodwin - Goodwin Procter,2023-07-13,Goodwin Procter,https://www.goodwinlaw.com,What Employers Need to Know About Use of Generative AI at Work,What Employers Need to Know About Use of Generative AI at Work,What Employers Need to Know About Use of Generative AI at Work,What Employers Need to Know About Use of Generative AI at Work,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vd3d3LmJiYy5jb20vd29ya2xpZmUvYXJ0aWNsZS8yMDIzMDQxOS1jaGF0Z3B0LWhvdy1nZW5lcmF0aXZlLWFpLWNvdWxkLWNoYW5nZS1oaXJpbmctYXMtd2Uta25vdy1pdNIBAA?oc=5,The big ways AI is changing hiring - BBC.com,2023-07-13,BBC.com,https://www.bbc.com,Candidates are already using tools such as ChatGPT to write cover letters and CVs. But it’s just a small piece of how AI is transforming hiring processes.,N/A,Candidates are already using tools such as ChatGPT to write cover letters and CVs. But it’s just a small piece of how AI is transforming hiring processes.,Candidates are already using tools such as ChatGPT to write cover letters and CVs. But it’s just a small piece of how AI is transforming hiring processes.,https://schema.org,,NewsArticle,"{'@type': 'Person', 'name': 'Alex Christian', 'url': ''}",2023-04-24T15:18:08.000Z,The big ways AI is changing hiring,"{'@type': 'Organization', 'name': 'BBC'}",['https://ychef.files.bbci.co.uk/1280x720/p0fhn46s.jpg'],N/A,N/A,"ChatGPT: How generative AI could change hiring as we know it13 July 2023ShareAlex ChristianFeatures correspondentShareCandidates are already using tools such as ChatGPT to write cover letters and CVs. But it’s just a small piece of how AI is transforming hiring processes.Since November 2022, AI chatbot ChatGPT has enabled anyone with internet access to generate anything in the written form: think intricate essays and code, succinct memos or poetry. Even with basic prompts, ChatGPT can complete complex, written tasks in moments, and work as a creative tool to quickly produce efficient content.“I’ve had students use ChatGPT to write appeals for parking tickets,” says Vince Miller, reader in sociology and cultural studies at the University of Kent, UK. “But in general, the technology allows people who may not necessarily possess the best writing skills to suddenly have them.”Jobseekers are among those reporting such benefits. Leveraging a dataset containing 570 billion individual words, OpenAI’s ChatGPT can compose convincing cover letters on demand, or synthesise a few career details into a competent, bullet-pointed CV. Want to send an email to a hiring manager? Prompt the chatbot, then copy and paste the AI-generated text straight into the message.But hiring managers aren’t oblivious: they understand candidates are already leaning on generative AI to assist them, and may well do so even more as the technology grows in sophistication. This could create a shift in job applications as we know them, moving recruiters away from the traditional modes of evaluating candidates.Not all recruiters report the use of generative AI as a hiring red flag – or even a worrying development at all.Getty ImagesAI could create a shift in job applications as we know them, moving recruiters away from the traditional modes of evaluating candidates (Credit: Getty Images)Adam Nicoll, group marketing director at recruitment and job-consulting firm Randstad, based in Luton, UK, says time-poor hiring managers may be unlikely to distinguish between a cover letter written by a candidate and one generated by AI. “The language generated by ChatGPT reads clean, if formulaic. Compared to most cover letter writing, there are no idiosyncrasies; there are no red flags, but no personality,” he says.Despite this, he says he wouldn’t necessarily consider this cheating the hiring process. “It’s helping those who aren’t the best at writing and editing in producing a neat summary of career highlights. It’s the digitised version of asking a friend to review your CV.”Nicoll says that recruiters have already been relying less on traditional modes of evaluating candidates, anyway. “The cover letter has been on its way out for years: hiring managers skim read a resume for less than 10 seconds, let alone read a 200-word personal statement. At best, the cover letter is a box-ticking exercise that accompanies the CV – it’s virtually obsolete.”Instead, Nicoll says recruiters increasingly prefer viewing a candidate’s social media and LinkedIn profile to understand their personality instead. And as more candidates use generative AI to compose their written materials, he adds the importance of these application elements is becoming even more irrelevant. “If anyone can artificially enhance their pitching email to a hiring manager, then it becomes redundant,” says University of Kent’s Miller. As more candidates use generative AI to compose their written materials, the importance of these application elements is becoming even more irrelevantExperts say standard hiring processes may change as a result.For instance, since generative AI can create pre-interview presentations, employers may introduce harder assessments in response. “The onus is to test and evaluate what the machines can’t do,” says Miller. “While generative AI can arrange data in an interesting way, it’s not particularly creative – it can only work with what already exists. So, that could mean assessments demanding more creative and abstract thought from the candidate.”Additionally, there could be a greater emphasis on scrutinising candidates in face-to-face settings, says Brooke Weddle, partner at consulting firm McKinsey & Company, based in Washington, DC. “As opposed to cover letters, which typically convey little information critical to the actual hiring decision, employers look hard at cultural fit and soft skills during the interview process.” Furthermore, some recruiters are already embracing new AI tools on their side of the job hiring process. For instance, some large corporations are leveraging AI in the recruitment process to test job seekers’ qualities through skill- and personality assessments, which use data-driven behavioural insights to match candidates against vacancies and reveal their soft skills. These kinds of emerging platforms that give recruiters more data on candidates stand to change the job-application process, too, especially as “we move from degree certifications to skills-based hiring”, says Weddle. And this may be just the beginning of big changes to come.How we workFeatures",2023-07-13T13:52:44.282Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3LmFkcC5jb20vc3BhcmsvYXJ0aWNsZXMvMjAyMy8wNy9nZW5lcmF0aXZlLWFpLWF0LXdvcmstYWRkcmVzc2luZy15b3VyLXRvcC1jb25jZXJucy5hc3B40gEA?oc=5,Generative AI at Work: Addressing Your Top Concerns - ADP,2023-07-12,ADP,https://www.adp.com,There are valid concerns about using generative AI at work. But it's helpful to consider how it can empower our human potential.,generative ai at work,There are valid concerns about using generative AI at work. But it's helpful to consider how it can empower our human potential.,There are valid concerns about using generative AI at work. But it's helpful to consider how it can empower our human potential.,,,,,,,,,N/A,N/A,"

Trends
Generative AI at Work: Addressing Your Top Concerns
Part of a series  |  Generative AI Insights



Brett Daniel





 
Share Spark Article on LinkedIn        


 
Share Spark Article on Facebook        


 
Share Spark Article on Twitter        


 
Share Spark Article via Email        

Print Spark Article 






There are valid concerns about using generative AI at work. But it's helpful to consider how it can empower our human potential.
Generative artificial intelligence (AI) is changing how we work.
According to a Fishbowl by Glassdoor survey, by late January 2023, 43 percent of professionals were using AI tools such as ChatGPT, a popular generative AI technology, for work-related tasks. Fifty-seven percent of employees who've used ChatGPT at work report that it boosts their productivity, according to a TalentLMS survey. From an HR standpoint, the market for generative AI is expected to be worth over $1.5 billion by 2032.
It's not hard to understand why generative AI is having an impact. Some of today's most popular generative AI tools are free, user-friendly and easy to access. Any HR practitioner or employee with an internet connection can use them to complete tasks, be more creative and satiate their curiosity. But along with the productivity and educational benefits generative AI offers, concerns have arisen, especially in the workplace.


Recommended for You

risk
Summer Dress Codes: Employers' Rights and Responsibilities


Before we dive in, let's define our terms.
What is generative AI?
According to the United States Government Accountability Office (GAO), generative AI creates content, including text, images, audio or video, when prompted by a user. Generative AI tools generate responses using algorithms often trained on open-source information, such as text and images from the internet. These systems are not cognitive and do not possess human judgment.
""Generative AI is the next phase in data, AI and machine learning coming together,"" says Jack Berkowitz, chief data officer, ADP. ""It's based on this model that can predict the next word. It almost feels like magic.""
For today's employees and HR practitioners, this means getting used to having generative AI as a coworker.
Generative AI as a coworker
You might be wondering: What's it like having generative AI as a coworker? You may know the answer if you've used generative AI at work. Still, for those who don't know, it's like having a knowledgeable and articulate personal assistant, albeit one who might say dubious and offensive things.
""It's like the coworker who knows a lot, who you're pretty sure is smarter than you are, but who also tends to get really unfocused and has the potential to say things that might be a bit off — so you need to keep watch,"" says Helena Almeida, vice president, managing counsel, ADP. ""You have to make sure you're using it in the right way, but it's a great help.""
Empowering human potential
There are valid concerns about generative AI and its impact on the workplace and labor market. But it's also helpful to consider how generative AI can empower human potential at work today.
For example, generative AI can help HR practitioners and employees be more creative.
""We all have ways that we think about issues and problems. Generative AI has the potential to help us break through our own thinking about things and open up creativity around how we solve problems at work,"" Almeida says.
It can also help all employees, HR practitioners included, realize their potential and do more.
""Lots of people talk about the risks,"" says Jason Albert, global chief privacy officer, ADP. ""It has risks, but its ability to help people succeed and achieve more, that's what I'm really excited about.""
In other words, generative AI is a technology created by people that can ultimately be designed for people.
""Our role at ADP is to help companies flourish and help their employees flourish,"" Albert says. ""That's where this goes over time: making the technology better for people.""
Bias in AI remains a workplace problem
According to the U.S. Equal Employment Opportunity Commission (EEOC), it is illegal to discriminate against an applicant or employee because of their race, color, religion, sex (including gender identity, sexual orientation and pregnancy), national origin, age (40 or older), disability or genetic information. These requirements aren't newsworthy, and many business leaders, HR practitioners and employees understand them. What remains newsworthy, however, is AI's potential to perpetuate — or mitigate — discrimination in hiring and employment decisions.
Bottom line: Discrimination is illegal, regardless of whether a human or system discriminates.
""There are concerns that if AI 'sees' that the last five successful candidates were white men, then it will 'learn' that a successful candidate is a white man,"" Almeida says. ""The advantage we have at ADP when we're talking about an AI algorithm is that we have data scientists focused on what data is going into the algorithms that are going to evaluate candidates. How do we monitor the algorithms to make sure the AI's not learning what we don't want it to learn? There are always steps being taken to make sure this bias doesn't seep in. When we're talking about AI, we have advantages that help us be better and make better decisions about bias.""
AI's potential for reducing workplace bias
While AI may lead to discriminatory outcomes, it may also help reduce them.
""Not only can we focus on AI from a data input, quality and monitoring standpoint, but AI can also help drive down bias because it can take the information and check for these things in a way that is harder to do for humans because we're fallible,"" Albert says.
AI can even help with discriminatory practices like pay inequity.
""Already behind the scenes of what makes ADP's pay equity technology work is a lot of AI,"" Berkowitz says. ""Instead of having to go and trundle through a bunch of information, you get simple questions and answers. AI is lifting our learnings about pay equity to make them more understandable.""
Despite AI's efficiency and benefits, monitoring for discriminatory practices should remain the responsibility of a human.
""Whether in recruiting or anything else, the person should always be in control. The locus of control should be the person, not the AI,"" Berkowitz says. ""AI's an advisor, but still, it's your decision. It's up to you to decide how you want to take its recommendation and use it. Being focused on that partnership is the essential point. We don't want to take control away from the person.""
How will generative AI change the workplace?
Generative AI has already changed the workplace. It helps HR practitioners and employees be smarter, more productive and more creative every day. But its evolution isn't finished. For example, it will get better at assisting HR practitioners and employees with tasks.
""We're going to see it go in a couple of interesting paths next,"" Albert says. ""There will be these levels of automation associated with it that none of us can really anticipate today, this notion of not only recommending a trip but booking that trip, of notifying your hotel that you're going to be late, of rebooking your rental car, of booking a dinner at an airport. These types of things will happen automatically. I'm excited about that.""
Personalization will also increase.
""When you use one of these models, they're stunning, but they're also generic,"" Albert says. There's this area of prompt engineering where you write a long request, but you get what you want. There's going to be growth in this area. The answers you get will be more specific to you. It's the personalization that will really take charge here.""
Generative AI at work: Guardrails, transparency
As AI evolves, new opportunities arise, but so does the potential for unintended consequences. These new tools must be used in a way that is ethical, secure and compliant. Organizations are already developing guidelines to ensure interactions with generative AI tools are done with security and privacy guardrails in place.
""With new technologies like generative AI, people aren't going to use it if they don't trust it,"" Almeida says. ""Making sure that the product is compliant will give people the trust they need to feel comfortable using the product. All of that is education. Part of that trust will come from educating people on all the steps companies are taking to protect their data and to make sure the AI is working as it should.""
The immediate solution? Enlist the help of a trusted partner.
""It's important to work with a vendor that enables you to meet your compliance obligations in this area,"" Berkowitz says. ""At ADP, we've added a human loop into our process, which means a human is ensuring high data quality and checking the output the AI generates.""
ADP has also adopted rigorous principles and processes to govern its use of generative AI and AI in general.
Find out what we're doing

Tags

Diversity and Inclusion 
Trends and Innovation 
HCM Technology 
Artificial Intelligence 
Discrimination 
Employee Engagement and Productivity 


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMijQFodHRwczovL3d3dy50aGVndWFyZGlhbi5jb20vdGVjaG5vbG9neS8yMDIzL2p1bC8xNC9tb3JlLXRoYW4tcXVhcnRlci1vZi1hZHVsdHMtaGF2ZS11c2VkLWdlbmVyYXRpdmUtYWktYXJ0aWZpY2FsLWludGVsbGlnZW5jZS1zdXJ2ZXktc3VnZ2VzdHPSAY0BaHR0cHM6Ly9hbXAudGhlZ3VhcmRpYW4uY29tL3RlY2hub2xvZ3kvMjAyMy9qdWwvMTQvbW9yZS10aGFuLXF1YXJ0ZXItb2YtYWR1bHRzLWhhdmUtdXNlZC1nZW5lcmF0aXZlLWFpLWFydGlmaWNhbC1pbnRlbGxpZ2VuY2Utc3VydmV5LXN1Z2dlc3Rz?oc=5,"More than a quarter of UK adults have used generative AI, survey suggests - The Guardian",2023-07-13,The Guardian,https://www.theguardian.com,"Adoption rate of latest AI systems exceeds that of voice-assisted smart speakers, with one in 10 using them at least once a day",N/A,"Adoption rate of latest AI systems exceeds that of voice-assisted smart speakers, with one in 10 using them at least once a day",N/A,,,,,,,,,Technology,N/A," Generative AI has gripped the public imagination since the launch of ChatGPT in November because of its human-seeming responses. Photograph: Ascannio/AlamyView image in fullscreenGenerative AI has gripped the public imagination since the launch of ChatGPT in November because of its human-seeming responses. Photograph: Ascannio/AlamyArtificial intelligence (AI) This article is more than 1 year oldMore than a quarter of UK adults have used generative AI, survey suggestsThis article is more than 1 year oldAdoption rate of latest AI systems exceeds that of voice-assisted smart speakers, with one in 10 using them at least once a dayDan Milmo Global technology editorThu 13 Jul 2023 19.01 EDTLast modified on Thu 13 Jul 2023 19.05 EDTShareMore than a quarter of UK adults have used generative artificial intelligence such as chatbots, according to survey showing that 4 million people have also used it for work.Generative AI, which refers to AI tools that produce convincing text or images in response to human prompts, has gripped the public imagination since the launch of ChatGPT in November.The rate of adoption of the latest generation of AI systems exceeds that of voice-assisted speakers such as Amazon’s Alexa, according to accounting group Deloitte, which published the survey.Deloitte said 26% of 16- to 75-year-olds have used a generative AI tool, representing about 13 million people, with one in 10 of those respondents using it at least once a day.“It took five years for voice-assisted speakers to achieve the same adoption levels. It is incredibly rare for any emerging technology to achieve these levels of adoption and frequency of usage so rapidly,” said Paul Lee, a Deloitte partner.The Deloitte survey of 4,150 UK adults found that just over half of the population had heard of generative AI, with around one in 10 respondents – the equivalent of approximately four million people – using it for work.ChatGPT became a sensation due to its ability to generate human-seeming responses to a range of queries in different styles, producing articles, essays, jokes, poetry and job applications in response to text prompts.It has been followed by Microsoft’s Bing chatbot, which is based on the same system as ChatGPT, Google’s Bard chatbot and, this week, Claude 2 from US firm Anthropic.Image generators have also taken off, exemplified by a realistic-looking picture of Pope Francis in a puffer jacket, produced by US startup Midjourney.However the ability of such systems to mass produce convincing text, image and even voice at scale has led to warnings that they could become tools for creating large-scale disinformation campaigns.The Deloitte survey found that of those who had used generative AI, more than four out of 10 believe it always produces factually correct answers. One of the biggest flaws in generative AI systems so far is that they are prone to producing glaring factual errors.“Generative AI technology is, however, still relatively nascent, with user interfaces, regulatory environment, legal status and accuracy still a work in progress,” said Lee.Explore more on these topicsArtificial intelligence (AI)ChatbotsChatGPTComputingnewsShareReuse this contentMost viewed‘A wise investment’: Trump’s $6,000 gift to Kamala Harris comes back to bite himLiveNancy Pelosi endorses Kamala Harris for Democratic nomination as support for vice-president grows – livePilot, 26, dies as her plane crashes after skydiving flight over Niagara FallsBen Jennings on Joe Biden endorsing Kamala Harris – cartoonYou’ve heard of nepo babies, but what about nepo dogs? The rise of the Very Important Pooch",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3Lm94Zm9yZGVjb25vbWljcy5jb20vcmVzb3VyY2UvZW50ZXJwcmlzZS1nZW5lcmF0aXZlLWFpLXN0YXRlLW9mLXRoZS1tYXJrZXQv0gEA?oc=5,Enterprise generative AI: State of the market - Oxford Economics,2023-07-12,Oxford Economics,https://www.oxfordeconomics.com,Executives know they need generative AI—but there’s a gap between awareness and the ability to deliver value at scale.,N/A,Executives know they need generative AI—but there’s a gap between awareness and the ability to deliver value at scale.,N/A,https://schema.org,,,,,,,,N/A,N/A,"



Share: 


  


  


  


  


  



",,"[{'@type': 'Article', '@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/#article', 'isPartOf': {'@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/'}, 'author': {'name': 'Kimberly Cabello', '@id': 'https://www.oxfordeconomics.com/#/schema/person/bbd86dccc4c00619f28b6203b11ade17'}, 'headline': 'Enterprise generative AI: State of the market', 'datePublished': '2023-07-12T17:33:18+00:00', 'dateModified': '2023-10-17T18:30:31+00:00', 'mainEntityOfPage': {'@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/'}, 'wordCount': 152, 'publisher': {'@id': 'https://www.oxfordeconomics.com/#organization'}, 'image': {'@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/#primaryimage'}, 'thumbnailUrl': 'https://www.oxfordeconomics.com/wp-content/uploads/2023/07/AI-planning.png', 'keywords': ['AI', 'Artificial Intelligence', 'Future of work', 'Global', 'IBM', 'Strategy and leadership', 'Technology', 'Thought Leadership'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/', 'url': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/', 'name': 'Enterprise generative AI: State of the market | Oxford Economics', 'isPartOf': {'@id': 'https://www.oxfordeconomics.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/#primaryimage'}, 'image': {'@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/#primaryimage'}, 'thumbnailUrl': 'https://www.oxfordeconomics.com/wp-content/uploads/2023/07/AI-planning.png', 'datePublished': '2023-07-12T17:33:18+00:00', 'dateModified': '2023-10-17T18:30:31+00:00', 'description': 'Executives know they need generative AI—but there’s a gap between awareness and the ability to deliver value at scale.', 'breadcrumb': {'@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/#primaryimage', 'url': 'https://www.oxfordeconomics.com/wp-content/uploads/2023/07/AI-planning.png', 'contentUrl': 'https://www.oxfordeconomics.com/wp-content/uploads/2023/07/AI-planning.png', 'width': 1000, 'height': 700}, {'@type': 'BreadcrumbList', '@id': 'https://www.oxfordeconomics.com/resource/enterprise-generative-ai-state-of-the-market/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.oxfordeconomics.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Resource Hub', 'item': 'https://www.oxfordeconomics.com/resource-hub/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise generative AI: State of the market'}]}, {'@type': 'WebSite', '@id': 'https://www.oxfordeconomics.com/#website', 'url': 'https://www.oxfordeconomics.com/', 'name': 'Oxford Economics', 'description': '', 'publisher': {'@id': 'https://www.oxfordeconomics.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.oxfordeconomics.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.oxfordeconomics.com/#organization', 'name': 'Oxford Economics', 'url': 'https://www.oxfordeconomics.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.oxfordeconomics.com/#/schema/logo/image/', 'url': 'https://www.oxfordeconomics.com/wp-content/uploads/2021/11/oxford-economics-logo.png', 'contentUrl': 'https://www.oxfordeconomics.com/wp-content/uploads/2021/11/oxford-economics-logo.png', 'width': 1205, 'height': 272, 'caption': 'Oxford Economics'}, 'image': {'@id': 'https://www.oxfordeconomics.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.oxfordeconomics.com/#/schema/person/bbd86dccc4c00619f28b6203b11ade17', 'name': 'Kimberly Cabello', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.oxfordeconomics.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/d7bbb3fb90ecfb825fb25a4f4745f509?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/d7bbb3fb90ecfb825fb25a4f4745f509?s=96&d=mm&r=g', 'caption': 'Kimberly Cabello'}, 'sameAs': ['spatel@oxfordeconomics.com'], 'url': 'https://www.oxfordeconomics.com/resource/author/kcabellooxfordeconomics-com/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vd3d3LmluZm93b3JsZC5jb20vYXJ0aWNsZS8zNzAyNjUwL3RoZS1uZXctaGlnaC1wYXlpbmctam9icy1pbi1nZW5lcmF0aXZlLWFpLmh0bWzSAVxodHRwczovL3d3dy5pbmZvd29ybGQuY29tL2FydGljbGUvMzcwMjY1MC90aGUtbmV3LWhpZ2gtcGF5aW5nLWpvYnMtaW4tZ2VuZXJhdGl2ZS1haS5hbXAuaHRtbA?oc=5,The new high-paying jobs in generative AI - InfoWorld,2023-07-14,InfoWorld,https://www.infoworld.com,"The push to adopt generative AI in the cloud will lead to new roles and needed skills, and enterprises will likely pay top dollar. ",N/A,"The push to adopt generative AI in the cloud will lead to new roles and needed skills, and enterprises will likely pay top dollar. ","The push to adopt generative AI in the cloud will lead to new roles and needed skills, and enterprises will likely pay top dollar. ",,,,,,,,,N/A,N/A,"










		The push to adopt generative AI in the cloud will lead to new roles and needed skills, and enterprises will likely pay top dollar. 	




 
Credit: gustavofrazao / Getty








I predicted that cloud providers would see a rise in demand for their services in 2024, given the push to use generative AI and the amount of resources (and money) this technology takes to operate. Now mainstream publications are also making this call, and we can all agree that generative AI will grow, and thus cloud computing will too. Simple math.
Like any change in a market, some will take advantage of the new opportunities, and some will be left behind. Recently, I’ve been getting many questions about what the workforce supporting cloud-powered generative AI will look like. More importantly, how can you take personal advantage?
Let’s explore some new roles that will likely emerge and how you can position yourself to serve in them.











 
 
 
AI cloud architect
Professionals specializing in designing and optimizing cloud architectures to support generative AI workloads will be in huge demand. How do I know? We don’t have enough cloud architects as is, and the mistakes occurring because of the lack of knowledge are starting to take their toll.
More Videos0 seconds of 9 minutes, 8 secondsVolume 0%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledShortcuts Open/Close/ or ?Play/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


Next UpConcurrency and parallelism in Python, explained09:11SettingsOffAutomated Captions - en-USFont ColorWhiteFont Opacity100%Font Size100%Font FamilyArialCharacter EdgeNoneBackground ColorBlackBackground Opacity50%Window ColorBlackWindow Opacity0%ResetWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%200%175%150%125%100%75%50%ArialCourierGeorgiaImpactLucida ConsoleTahomaTimes New RomanTrebuchet MSVerdanaNoneRaisedDepressedUniformDrop ShadowWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%WhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%







Live00:0009:0809:08 

Companies will need trained, experienced cloud architects who understand how AI systems work and play well with existing cloud-based systems. If you’re interested, you’ll need training on how a cloud operates and the specific techniques that generative AI services use, such as data, knowledge models, APIs, and other forms of integration, plus how to ensure the scalability, security, and performance of AI systems.
AI data engineer
AI and data experts manage and preprocess large data sets used to train generative AI models. Most people understand that AI systems depend on high-quality, accurate data. AI data engineers ensure data quality, implement pipelines, and optimize data storage and retrieval. Their focus is more on data operations, but understanding how AI systems work, including training data, is essential. 











 
 
 
This position will require an excellent working knowledge of databases, data integration, and how AI systems ingest data for training. This role also needs to understand data curation, quality, security, and governance. I suspect that most AI data engineers will come from the data operations side of things, not the AI side.
AI model curator
These individuals curate and select the most relevant and effective generative AI models for specific applications. They need to deeply understand the AI landscape and stay updated on the latest advancements, including the most helpful third-party tools and how models can be streamlined.
Again, this is more focused on operations. However, it requires specialized operations skills that most current ops team members won’t have. These people will likely come from the data ops side, but deep AI experience is essential. 











 
 
 
AI ethicist
Yes, this is a thing. With generative AI’s potential ethical implications, AI ethicists are crucial in ensuring responsible AI usage. Duties will include assessing and mitigating biases, privacy concerns, and potential societal impacts of these new generative AI systems in the cloud.
This position could come from many different areas. They could be primarily nontechnical roles. I suspect that many will have a business ethics background, but understanding technology will be a vital component of this role, even if that is not understood now.
AI trainer
Not to be confused with those who train people about AI, these professionals specialize in fine-tuning and optimizing generative AI models. Specifically, they work with data scientists and domain experts to prepare models for specific tasks and improve their performance and accuracy.











 
 
 
AI business strategist
Think AI-focused CTO or professional who can bridge the gap between technical AI capabilities and business goals. Their role will be identifying opportunities for generative AI deployment, developing strategies, and managing AI projects to drive business outcomes.
Most of these people will come from IT leadership roles with some technical background. They may have been project leaders or worked for the CIO at some point. They will need an eclectic mix of skills to be successful. 
I suspect that I’m missing a few other roles that will be important, but they will likely be derivatives of the ones listed here. If any of these would be a good career move, then set up your training to head in that direction. Also, position yourself with existing or new jobs so you can move into these roles when they become available. Given that demand will outpace supply, these jobs will pay well, at least for the first few years.











 
 
 
 















 
Related content

 


analysis

Messy data is holding enterprises back from AI
Until CIOs are ready to confront data that is siloed, redundant, or can’t be traced through the business process, generative AI will not pay off. 

				By David Linthicum				


Jul 19, 2024

5 mins 


Generative AI
Data Quality
Artificial Intelligence






analysis

Learning cloud cost management the hard way
After all these years, we still haven’t implemented enough finops, automation, and governance to stop wasting money in the cloud. 

				By David Linthicum				


Jul 16, 2024

5 mins 


Cloud Management
Data Governance
IT Skills






analysis

Generative AI won’t fix cloud migration
You’ve probably heard how generative AI will solve all cloud migration problems. It’s not that simple. Generative AI could actually make it harder and more costly.  

				By David Linthicum				


Jul 12, 2024

5 mins 


Generative AI
Artificial Intelligence
Cloud Computing






analysis

All the brilliance of AI on minimalist platforms
Buy all the processing and storage you can or go with a minimum viable platform? AI developers and designers are dividing into two camps. 

				By David Linthicum				


Jul 09, 2024

5 mins 


Generative AI
Cloud Architecture
Artificial Intelligence






Resources


Videos



















",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvbG91aXNtb3NjYS8yMDIzLzA3LzEyL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXBvd2Vycy1hLW5ldy1lcmEtaW4tY29uc3RydWN0aW9uL9IBAA?oc=5,Artificial Intelligence Powers A New Era In Construction - Forbes,2023-07-12,Forbes,https://www.forbes.com,"Exploring the transformative role of Artificial Intelligence in reshaping construction processes, from enhancing operational efficiency to improving on-site safety.","Artificial Intelligence,construction industry","Exploring the transformative role of Artificial Intelligence in reshaping construction processes, from enhancing operational efficiency to improving on-site safety.","Exploring the transformative role of Artificial Intelligence in reshaping construction processes, from enhancing operational efficiency to improving on-site safety.",http://schema.org,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Small Business', 'item': 'https://www.forbes.com/small-business/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Small Business Strategy', 'item': 'https://www.forbes.com/small-business-strategy/'}]",BreadcrumbList,"{'@type': 'Person', 'name': 'Louis Mosca', 'url': 'https://www.forbes.com/sites/louismosca/', 'description': ""I help business owners become business leaders. Throughout my twenty-plus year career with American Management Services, I've had the privilege of helping thousands of independent business owners develop and implement a formal plan designed to grow their business, maximize profits, and create functional organizations. Before joining American Management Services, I was a certified public accountant, held positions at W.R. Grace and Sony of America, and was the owner of several small businesses."", 'sameAs': ['https://www.linkedin.com/company/american-management-services-inc', 'https://www.twitter.com/@MoscaSmallBiz', 'https://www.amserv.com/', '706150402749547']}",2023-07-12T14:05:42-04:00,Artificial Intelligence Powers A New Era In Construction,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/64aeea4ea7246c2a9be9bcff/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",Small Business Strategy,N/A,"More From ForbesJul 22, 2024,01:51pm EDTIs Empathy Important In Leadership? 7 Reasons To Embrace This TraitJul 21, 2024,07:00am EDTBusiness Tech Roundup: Auto Dealership Software Platform Pays $25M RansomJul 19, 2024,10:37am EDTW-2 Changes For 2024: Three Things Businesses Owners Should KnowJul 18, 2024,01:51pm EDTHow To Raise Consumer Packaged Goods (CPG) FundingJul 16, 2024,05:32pm EDTThe Three Biggest Mistakes Prospective Business Buyers MakeJul 16, 2024,01:52pm EDTUncertainty Clouds The FutureJul 14, 2024,07:00am EDTBusiness Tech Roundup:  Is Microsoft Copilot Worth The Money?Edit StoryForbesSmall BusinessSmall Business StrategyArtificial Intelligence Powers A New Era In ConstructionLouis MoscaContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got it0Jul 12, 2023,02:05pm EDTShare to FacebookShare to TwitterShare to LinkedinArtificial Intelligence is quickly becoming an integral tool in various industries. But have you ever thought about how it can reshape construction? Regardless of the type of business, proprietors are always seeking strategies for operations improvement and efficiency enhancement. And with construction, the use cases are intriguing.

One could understandably presume that the methods for rebar laying or concrete pouring are limited. That's where AI enters the picture, adding a high-tech touch to the traditionally hands-on field.


What is AI?
Many people’s idea of what is AI comes from film and television, especially in recent years. AI, in its current form, is a computer that can perform complex tasks. It understands natural language, recognizes patterns, problem-solving, and decision-making.

An artificial intelligence system can learn from data sets to make predictions or find conclusions without human intervention.

One of the most common applications of AI is found on your phone. Voice-activated assistants like Siri and Google understand benign requests and deliver results (within a reasonable degree of scope).
PROMOTEDAn android working with a construction worker on a jobsitevaleriygoncharukphoto

What About the Construction Industry?
MORE FROMFORBES ADVISORBest Travel Insurance CompaniesByAmy DaniseEditorBest Covid-19 Travel Insurance PlansByAmy DaniseEditor
Theoretically, AI can be used in the pre-construction phases. Through the application of historical data analysis, AI, which is trained on extensive past datasets, can examine data meticulously to make well-informed decisions. For instance, the data it can sort through are project type, downtime averages, scope of work, delivery methods, and more.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Picture a giant virtual brain pouring over decades of data to predict the best strategies to complete projects, or estimate project manhours.
Artificial intelligence not only pertains to intelligent decision-making but also involves strategic planning. It can help construction companies to optimize the use of resources, manage timelines, and overall achieve better efficiency.


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
Parsing Through Building Codes
The world of building codes and permits can be a minefield.
With AI, parsing through building codes becomes as easy as pie. It can quickly identify relevant codes, saving companies from potential legal hassles and ensuring every construction job is up to code.
Remember the headaches you had the last time you went through the building permit process? Well, AI can help streamline this, making it more efficient and less of a hassle.
Project Lifecycle
Every construction project goes through several stages. Artificial intelligence can provide assistance in every aspect, largely due to the capabilities of neural networks.
‘A neural network is a computing model inspired by the brain's structure, used for machine learning tasks.’ – Explained by ChatGPT
AI can use neural networks to classify the progress of different sub-projects. It’s like having a virtual project manager keeping tabs on everything.
This means it can spot potential issues early on. Instead of reacting to problems, you'll be able to prevent them. Now, that's what we call a game-changer!
Ensuring On-Site Safety with AI
Perhaps, the most important way AI can help in construction is by improving safety.
Through photo recognition, AI can detect safety hazards, such as workers not wearing protective gear or hazardous working conditions. AI can be trained on how jobs are supposed to be performed to point out flaws in activities.
AI can look at the work area and past data to guess project risks. This can help you avoid risky situations.
With lots of building data, AI can use simulations to suggest ways to make structures and designs better for things like energy use and air quality.
Now What?
AI is growing quickly. It's tough to find an expert who can help with your ideas, especially an affordable construction AI expert.
While AI is already bringing significant benefits, it's not without challenges. Other issues include data privacy, technology cost, and the need for significant cultural shifts within construction companies.
Despite these challenges, the potential of AI in construction is immense. As technology continues to evolve, we can only imagine how much more it could reshape the industry.
We think the AI evolution opens the doors for huge potential and opportunity.
Follow me on Twitter or LinkedIn. Check out my website. Louis MoscaFollowingFollowI help business owners become business leaders. Throughout my twenty-plus year career with American Management... Read MoreEditorial StandardsPrintReprints & Permissions
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEJoin The ConversationComments 0One Community. Many Voices. Create a free account to share your thoughts. Read our community guidelines  here.Forbes Community GuidelinesOur community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.In order to do so, please follow the posting rules in our site's Terms of Service.  We've summarized some of those key rules below. Simply put, keep it civil.Your post will be rejected if we notice that it seems to contain:False or intentionally out-of-context or misleading informationSpamInsults, profanity, incoherent, obscene or inflammatory language or threats of any kindAttacks on the identity of other commenters or the article's authorContent that otherwise violates our site's terms.User accounts will be blocked if we notice or believe that users are engaged in:Continuous attempts to re-post comments that have been previously moderated/rejectedRacist, sexist, homophobic or other discriminatory commentsAttempts or tactics that put the site security at riskActions that otherwise violate our site's terms.So, how can you be a power user?Stay on topic and share your insightsFeel free to be clear and thoughtful to get your point across‘Like’ or ‘Dislike’ to show your point of view.Protect your community.Use the report tool to alert us when someone breaks the rules.Thanks for reading our community guidelines.  Please read the full list of posting rules found in our site's Terms of Service.",2023-10-05T13:06:53-04:00,,https://www.forbes.com/sites/louismosca/2023/07/12/artificial-intelligence-powers-a-new-era-in-construction/,Small Business Strategy,Artificial Intelligence Powers A New Era In Construction,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd3d3LnZveC5jb20vdW5leHBsYWluYWJsZS8yMDIzLzcvMTUvMjM3OTM4NDAvY2hhdC1ncHQtYWktc2NpZW5jZS1teXN0ZXJ5LXVuZXhwbGFpbmFibGUtcG9kY2FzdNIBAA?oc=5,How do AI systems like ChatGPT work? There’s a lot scientists don’t know. - Vox.com,2023-07-15,Vox.com,https://www.vox.com," “We built it, we trained it, but we don’t know what it’s doing.”",N/A," “We built it, we trained it, but we don’t know what it’s doing.”",N/A,,,,,,,,,N/A,N/A,"Podcasts /UnexplainableEven the scientists who build AI can’t tell you how it works “We built it, we trained it, but we don’t know what it’s doing.”by  Noam HassenfeldJul 15, 2023, 7:00 AM EDTFacebookLinkArtificial intelligence systems like ChatGPT might disrupt or revolutionize many industries. But that doesn’t mean we understand what they’re doing. Frank Rumpenhorst/Picture Alliance via Getty ImagesNoam Hassenfeld is the host and senior producer of Unexplainable, Vox’s science podcast about everything we don’t know. He co-created the show and also composes the music.Artificial intelligence systems like ChatGPT can do a wide range of impressive things: they can write passable essays, they can ace the bar exam, they’ve even been used for scientific research. But ask an AI researcher how it does all this, and they shrug. “If we open up ChatGPT or a system like it and look inside, you just see millions of numbers flipping around a few hundred times a second,” says AI scientist Sam Bowman. “And we just have no idea what any of it means.”Bowman is a professor at NYU, where he runs an AI research lab, and he’s a researcher at Anthropic, an AI research company. He’s spent years building systems like ChatGPT, assessing what they can do, and studying how they work. He explains that ChatGPT runs on something called an artificial neural network, which is a type of AI modeled on the human brain. Instead of having a bunch of rules explicitly coded in like a traditional computer program, this kind of AI learns to detect and predict patterns over time. But Bowman says that because systems like this essentially teach themselves, it’s difficult to explain precisely how they work or what they’ll do. Which can lead to unpredictable and even risky scenarios as these programs become more ubiquitous.I spoke with Bowman on Unexplainable, Vox’s podcast that explores scientific mysteries, unanswered questions, and all the things we learn by diving into the unknown. The conversation is included in a new two-part series on AI: The Black Box.This conversation has been edited for length and clarity.Noam HassenfeldHow do systems like ChatGPT work? How do engineers actually train them?Sam BowmanSo the main way that systems like ChatGPT are trained is by basically doing autocomplete. We’ll feed these systems sort of long text from the web. We’ll just have them read through a Wikipedia article word by word. And after it’s seen each word, we’re going to ask it to guess what word is gonna come next. It’s doing this with probability. It’s saying, “It’s a 20 percent chance it’s ‘the,’ 20 percent chance it’s ‘of.’” And then because we know what word actually comes next, we can tell it if it got it right. This takes months, millions of dollars worth of computer time, and then you get a really fancy autocomplete tool. But you want to refine it to act more like the thing that you’re actually trying to build, act like a sort of helpful virtual assistant.There are a few different ways people do this, but the main one is reinforcement learning. The basic idea behind this is you have some sort of test users chat with the system and essentially upvote or downvote responses. Sort of similarly to how you might tell the model, “All right, make this word more likely because it’s the real next word,” with reinforcement learning, you say, “All right, make this entire response more likely because the user liked it, and make this entire response less likely because the user didn’t like it.”Noam HassenfeldSo let’s get into some of the unknowns here. You wrote a paper all about things we don’t know when it comes to systems like ChatGPT. What’s the biggest thing that stands out to you?Sam BowmanSo there’s two connected big concerning unknowns. The first is that we don’t really know what they’re doing in any deep sense. If we open up ChatGPT or a system like it and look inside, you just see millions of numbers flipping around a few hundred times a second, and we just have no idea what any of it means. With only the tiniest of exceptions, we can’t look inside these things and say, “Oh, here’s what concepts it’s using, here’s what kind of rules of reasoning it’s using. Here’s what it does and doesn’t know in any deep way.” We just don’t understand what’s going on here. We built it, we trained it, but we don’t know what it’s doing.Noam HassenfeldVery big unknown.Sam BowmanYes. The other big unknown that’s connected to this is we don’t know how to steer these things or control them in any reliable way. We can kind of nudge them to do more of what we want, but the only way we can tell if our nudges worked is by just putting these systems out in the world and seeing what they do. We’re really just kind of steering these things almost completely through trial and error.Noam HassenfeldCan you explain what you mean by “we don’t know what it’s doing”? Do we know what normal programs are doing?Sam BowmanI think the key distinction is that with normal programs, with Microsoft Word, with Deep Blue [IBM’s chess playing software], there’s a pretty simple explanation of what it’s doing. We can say, “Okay, this bit of the code inside Deep Blue is computing seven [chess] moves out into the future. If we had played this sequence of moves, what do we think the other player would play?” We can tell these stories at most a few sentences long about just what every little bit of computation is doing. With these neural networks [e.g., the type of AI ChatGPT uses], there’s no concise explanation. There’s no explanation in terms of things like checkers moves or strategy or what we think the other player is going to do. All we can really say is just there are a bunch of little numbers and sometimes they go up and sometimes they go down. And all of them together seem to do something involving language. We don’t have the concepts that map onto these neurons to really be able to say anything interesting about how they behave.Noam HassenfeldHow is it possible that we don’t know how something works and how to steer it if we built it?Sam BowmanI think the important piece here is that we really didn’t build it in any deep sense. We built the computers, but then we just gave the faintest outline of a blueprint and kind of let these systems develop on their own. I think an analogy here might be that we’re trying to grow a decorative topiary, a decorative hedge that we’re trying to shape. We plant the seed and we know what shape we want and we can sort of take some clippers and clip it into that shape. But that doesn’t mean we understand anything about the biology of that tree. We just kind of started the process, let it go, and try to nudge it around a little bit at the end.Noam HassenfeldIs this what you were talking about in your paper when you wrote that when a lab starts training a new system like ChatGPT they’re basically investing in a mystery box?Sam BowmanYeah, so if you build a little version of one of these things, it’s just learning text statistics. It’s just learning that ‘the’ might come before a noun and a period might come before a capital letter. Then as they get bigger, they start learning to rhyme or learning to program or learning to write a passable high school essay. And none of that was designed in — you’re running just the same code to get all these different levels of behavior. You’re just running it longer on more computers with more data. So basically when a lab decides to invest tens or hundreds of millions of dollars in building one of these neural networks, they don’t know at that point what it’s gonna be able to do. They can reasonably guess it’s gonna be able to do more things than the previous one. But they’ve just got to wait and see. We’ve got some ability to predict some facts about these models as they get bigger, but not these really important questions about what they can do. This is just very strange. It means that these companies can’t really have product roadmaps. They can’t really say, “All right, next year we’re gonna be able to do this. Then the year after we’re gonna be able to do that.” And it also plays into some of the concerns about these systems. That sometimes the skill that emerges in one of these models will be something you really don’t want. The paper describing GPT-4 talks about how when they first trained it, it could do a decent job of walking a layperson through building a biological weapons lab. And they definitely did not want to deploy that as a product. They built it by accident. And then they had to spend months and months figuring out how to clean it up, how to nudge the neural network around so that it would not actually do that when they deployed it in the real world.Noam HassenfeldSo I’ve heard of the field of interpretability. Which is the science of figuring out how AI works. What does that research look like, and has it produced anything?Sam BowmanInterpretability is this goal of being able to look inside our systems and say pretty clearly with pretty high confidence what they’re doing, why they’re doing it. Just kind of how they’re set up being able to explain clearly what’s happening inside of a system. I think it’s analogous to biology for organisms or neuroscience for human minds. But there are two different things people might mean when they talk about interpretability.One of them is this goal of just trying to sort of figure out the right way to look at what’s happening inside of something like ChatGPT figuring out how to kind of look at all these numbers and find interesting ways of mapping out what they might mean, so that eventually we could just look at a system and say something about it. The other avenue of research is something like interpretability by design. Trying to build systems where by design, every piece of the system means something that we can understand.But both of these have turned out in practice to be extremely, extremely hard. And I think we’re not making critically fast progress on either of them, unfortunately.Noam HassenfeldWhat makes interpretability so hard?Sam BowmanInterpretability is hard for the same reason that cognitive science is hard. If we ask questions about the human brain, we very often don’t have good answers. We can’t look at how a person thinks and explain their reasoning by looking at the firings of the neurons.And it’s perhaps even worse for these neural networks because we don’t even have the little bits of intuition that we’ve gotten from humans. We don’t really even know what we’re looking for. Another piece of this is just that the numbers get really big here. There are hundreds of billions of connections in these neural networks. So even if you can find a way that if you stare at a piece of the network for a few hours, we would need every single person on Earth to be staring at this network to really get through all of the work of explaining it.Noam HassenfeldAnd because there’s so much we don’t know about these systems, I imagine the spectrum of positive and negative possibilities is pretty wide.Sam BowmanYeah, I think that’s right. I think the story here really is about the unknowns. We’ve got something that’s not really meaningfully regulated, that is more or less useful for a huge range of valuable tasks, we’ve got increasingly clear evidence that this technology is improving very quickly in directions that seem like they’re aimed at some very, very important stuff and potentially destabilizing to a lot of important institutions. But we don’t know how fast it’s moving. We don’t know why it’s working when it’s working. We don’t have any good ideas yet about how to either technically control it or institutionally control it. And if we have no idea what next year’s systems are gonna do, and if next year we have no idea what the systems the year after that are gonna do. It seems very plausible to me that that’s going to be the defining story of the next decade or so. How we come to a better understanding of this and how we navigate it.You’ve read 1 article in the last monthHere at Vox, we believe in helping everyone understand our complicated world, so that we can all help to shape it. Our mission is to create clear, accessible journalism to empower understanding and action.If you share our vision, please consider supporting our work by becoming a Vox Member. Your support ensures Vox a stable, independent source of funding to underpin our journalism. If you are not ready to become a Member, even small contributions are meaningful in supporting a sustainable model for journalism.Thank you for being part of our community.Swati SharmaVox Editor-in-ChiefMembershipMonthlyAnnualOne-time$5/month$10/month$25/month$50/monthOther$50/year$100/year$150/year$200/yearOther$20$50$100$250OtherJoin for $5/monthWe accept credit card, Apple Pay, and Google Pay. You can also contribute viaMost PopularDoes Kamala Harris give Democrats a better chance to win?Biden just quit the race and endorsed Kamala Harris. What happens now?Who could be Kamala Harris’s VP? The potential list, briefly explained.Why is everyone talking about Kamala Harris and coconut trees?Project 2025: The myths and the facts
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEToday, ExplainedUnderstand the world with a daily explainer plus the most compelling stories of the day.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vd3d3LmNpby5jb20vYXJ0aWNsZS82NDU0MjUvc2hvdWxkLXlvdS1idWlsZC1vci1idXktZ2VuZXJhdGl2ZS1haS5odG1s0gFNaHR0cHM6Ly93d3cuY2lvLmNvbS9hcnRpY2xlLzY0NTQyNS9zaG91bGQteW91LWJ1aWxkLW9yLWJ1eS1nZW5lcmF0aXZlLWFpLmh0bWw?oc=5,Should you build or buy generative AI? - CIO,2023-07-14,CIO,https://www.cio.com,"You can adopt generative AI by taking, shaping or making the models you need. But the more you build, the more resources are needed, and even systems you buy will need building work.",N/A,"You can adopt generative AI by taking, shaping or making the models you need. But the more you build, the more resources are needed, and even systems you buy will need building work.","You can adopt generative AI by taking, shaping or making the models you need. But the more you build, the more resources are needed, and even systems you buy will need building work.",,,,,,,,,N/A,N/A,"










		You can adopt generative AI by taking, shaping or making the models you need. But the more you build, the more resources are needed, and even systems you buy will need building work.	




 
Credit: PeopleImages / Getty Images








Whether it’s text, images, video or, more likely, a combination of multiple models and services, taking advantage of generative AI is a ‘when, not if’ question for organizations.
Since the release of ChatGPT last November, interest in generative AI has skyrocketed. It’s already showing up in the top 20 shadow IT SaaS apps tracked by Productiv for business users and developers alike. But many organizations are limiting use of public tools while they set policies to source and use generative AI models. CIOs want to take advantage of this but on their terms—and their own data.
As so often happens with new technologies, the question is whether to build or buy. For generative AI, that’s complicated by the many options for refining and customising the services you can buy, and the work required to make a bought or built system into a useful, reliable, and responsible part of your organization’s workflow. Organizations don’t want to fall behind the competition, but they also want to avoid embarrassments like going to court, only to discover the legal precedent cited is made up by a large language model (LLM) prone to generating a plausible rather than factual answer.
 
 
 













 
 

From taking to making
Rather than a rigid distinction between building and buying such complex technology, Eric Lamarre, the senior partner leading McKinsey Digital in North America, suggests thinking in terms of taking, shaping and—in a very few cases—making generative AI models.

More Videos0 seconds of 59 minutes, 43 secondsVolume 0%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledShortcuts Open/Close/ or ?Play/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


Next UpCIO Leadership Live Kathy Kay56:23SettingsOffAutomated Captions - en-USFont ColorWhiteFont Opacity100%Font Size100%Font FamilyArialCharacter EdgeNoneBackground ColorBlackBackground Opacity50%Window ColorBlackWindow Opacity0%ResetWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%200%175%150%125%100%75%50%ArialCourierGeorgiaImpactLucida ConsoleTahomaTimes New RomanTrebuchet MSVerdanaNoneRaisedDepressedUniformDrop ShadowWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%WhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%







Live00:0059:4359:43 

“As a ‘taker,’ you consume generative AI through either an API, like ChatGPT, or through another application, like GitHub Copilot, for software acceleration when you do coding,” he says. Finished apps that include generative AI may not offer much competitive differentiation, and answers they produce won’t always be perfect. But you want to adopt them to avoid competitive disadvantage, especially as they often arrive as new features in applications that staff already know how to use. “Every company will be doing that,” he adds. “In the shaper model, you’re leveraging existing foundational models, off the shelf, but retraining them with your own data.”
That reduces the ‘hallucination’ problem and gets you more accurate and relevant results.
 
 
 













 
 

“Contact center applications are very specific to the kind of products that the company makes, the kind of services it offers, and the kind of problems that have been surfacing,” he says. A general LLM won’t be calibrated for that, but you can recalibrate it—a process known as fine-tuning—to your own data. Fine-tuning applies to both hosted cloud LLMs and open source LLM models you run yourself, so this level of ‘shaping’ doesn’t commit you to one approach.
McKinsey tried to speed up writing evaluations by feeding transcripts of evaluation interviews to an LLM. But without fine-tuning or grounding it in the organization’s data, it was a complete failure, according to Lamarre. “The LLM didn’t have any context about the different roles, what kind of work we do, or how we evaluate people,” he says.
Generative AI models like ChatGPT and GPT4 with a plugin model let you augment the LLM by connecting it to APIs that retrieve real-time information or business data from other systems, add other types of computation, or even take action like open a ticket or make a booking. That includes curated data, like a legal database, in the same way you might add a commercial weather prediction service to a more traditional machine learning (ML) model for generating routes or predicting shipping times rather than build your own weather model from scratch.
 
 
 













 
 

Shaping will involve more than simply building an LLM into your own applications and processes, and organizations will need more sophisticated capabilities, Lamarre warned. “To get good output, you need to create a data environment that can be consumed by the model,” he says. “You need to have data engineering skills, and be able to recalibrate these models, so you probably need machine learning capabilities on your staff, and you need to be good at prompt engineering. So how do I coach my people to ask the right questions to get the best output?”






Explore related questions


What are the key benefits of using generative AI in business?When will generative AI become a mainstream technology in organizations?Who should be responsible for implementing generative AI in a company?Will building a custom generative AI model provide a competitive advantage?Does using public generative AI tools pose a risk to business data?





Ask




He cautioned CIOs against ‘shiny object syndrome’ with generative AI, especially if they haven’t already built up expertise in ML. “The reality that’s going to hit home in the next six to 12 months is generative AI is just as difficult as ‘traditional’ AI,” he says.
But with those skills, shaping generative AI systems created from existing models and services will deliver applications most likely to offer competitive differentiation. However, making will be even more challenging and, most likely, rare, Lamarre predicts.
 
 
 













 
 

Buy in or lose out
For smaller organizations like The Contingent, a non-profit supporting vulnerable children, families, and young professionals, even with 10 of its 60 staff working in technology and data research, building their own generative AI seems daunting to consider, according to CIO Peter Kim.
There’s a crisis in child welfare with support needs outpacing capacity, and he’s interested in how generative AI can help profile audiences, evaluate messaging around the continuum of opportunities for volunteering, match applicants with internships, and even reduce the time it takes to recruit new staff.
That will start with using the Copilot features Microsoft is introducing in many products, including in Cloud for Nonprofit. “It would seem almost foolish to pass this up, because it’s just going to become part of the norm,” he says. “If you’re not using it, you’re going to get left behind.”
 
 
 













 
 

But Kim also plans to customize some of the generative AI services available. He expects it to be particularly helpful for coding the many connectors the non-profit has to build for the disparate, often antiquated, systems government and private agencies use, and writing data queries. In addition, he hopes to understand nuances of geographical and demographic data, and extract insights from historical data and compare it to live data to identify patterns and opportunities to move quickly.
Rather than devote resources to replicate generative AI capabilities already available, that time and effort will go to automating existing manual processes and exploring new possibilities. “We’re not imagining utilizing AI to do the same things just because that’s the way we’ve always done it,” he says. “With this new superpower, how should we develop or refine refactoring these business processes?”
Buying rather than building will make it easier to take advantage of new capabilities as they arrive, he suggests. “I think one of the success of organizations in being able to utilize the tools that are becoming more readily available will lie in the ability to adapt and review.”
 
 
 













 
 

In a larger organization, using commercially available LLMs that come with development tools and integrations will allow multiple departments to experiment with different approaches, discover where generative AI can be useful, and get experience with how to use it effectively. Even organizations with significant technology expertise like Airbnb and Deutsche Telekom are choosing to fine-tune LLMs like ChatGPT rather than build their own.
“You take the large language model, and then you can bring it within your four walls and build that domain piece you need for your particular company and industry,” National Grid group CIDO Adriana Karaboutis says. “You really have to take what’s already there. You’re going to be five years out here doing a moonshot while your competitors layer on top of everything that’s already available.”
Panasonic’s B2B Connect unit used the Azure OpenAI Service to build its ConnectAI assistant for internal use by its legal and accounting teams, as well as HR and IT, and the reasoning was similar, says Hiroki Mukaino, senior manager for IT & digital strategy. “We thought it would be technically difficult and costly for ordinary companies like us that haven’t made a huge investment in generative AI to build such services on our own,” he says.
 
 
 













 
 

Increasing employee productivity is a high priority and rather than spend time creating the LLM, Mukaino wanted to start building it into tools designed for their business workflow. “By using Azure OpenAI Service, we were able to create an AI assistant much faster than build an AI in-house, so we were able to spend our time on improving usability.”

He also views the ability to further shape the generative AI options with plugins as a good way to customize it to Panasonic’s needs, calling plugins important functions to compensate for the shortcomings of the current ChatGPT.
Fine-tuning cloud LLMs by using vector embeddings from your data is already in private preview in Azure Cognitive Search for the Azure OpenAI Service.
 
 
 













 
 

“While you can power your own copilot using any internal data, which immediately improves the accuracy and decreases the hallucination, when you add vector support, it’s more efficient retrieving accurate information quickly,” Microsoft AI platform corporate VP John Montgomery says. That creates a vector index for the data source—whether that’s documents in an on-premises file share or a SQL cloud database—and an API endpoint to consume in your application.
Panasonic is using this with both structured and unstructured data to power the ConnectAI assistant. Similarly, professional services provider EY is chaining multiple data sources together to build chat agents, which Montgomery calls a constellation of models, some of which might be open source models. “Information about how many pairs of eyeglasses the company health plan covers would be in an unstructured document, and checking the pairs claimed for and how much money is left in that benefit would be a structured query,” he says.
Use and protect data
Companies taking the shaper approach, Lamarre says, want the data environment to be completely contained within their four walls, and the model to be brought to their data, not the reverse. While whatever you type into the consumer versions of generative AI tools is used to train the models that drive them (the usual trade-off for free services), Google, Microsoft and OpenAI all say commercial customer data isn’t used to train the models.
 
 
 













 
 

For example, you can run Azure OpenAI over your own data without fine-tuning, and even if you choose to fine-tune on your organization’s data, that customization, like the data, stays inside your Microsoft tenant and isn’t applied back to the core foundation model. “The data usage policy and content filtering capabilities were major factors in our decision to proceed,” Mukaino says. 
Although the copyright and intellectual property aspects of generative AI remain largely untested by the courts, users of commercial models own the inputs and outputs of their models. Customers with particularly sensitive information, like government users, may even be able to turn off logging to avoid the slightest risk of data leakage through a log that captures something about a query.
Whether you buy or build the LLM, organizations will need to think more about document privacy, authorization and governance, as well as data protection. Legal and compliance teams already need to be involved in uses of ML, but generative AI is pushing the legal and compliance areas of a company even further, says Lamarre.
 
 
 













 
 

Unlike supervised learning on batches of data, an LLM will be used daily on new documents and data, so you need to be sure data is available only to users who are supposed to have access. If different regulations and compliance models apply to different areas of your business, you won’t want them to get the same results.
Source and verify
Adding internal data to a generative AI tool Lamarre describes as ‘a copilot for consultants,’ which can be calibrated to use public or McKinsey data, produced good answers, but the company was still concerned they might be fabricated. “We can’t be in the business of being wrong,” he says. To avoid that, it cites the internal reference an answer is based on, and the consultant using it is responsible to check for accuracy.

But employees already have that responsibility when doing research online, Karaboutis points out. “You need intellectual curiosity and a healthy level of skepticism as these language models continue to learn and build up,” she says. As a learning exercise for the senior leadership group, her team crated a deepfake video of her with a generated voice reading AI-generated text.
 
 
 













 
 

Apparently credible internal data can be wrong or just out of date, too, she cautioned. “How often do you have policy documents that haven’t been removed from the intranet or the version control isn’t there, and then an LLM finds them and starts saying ‘our maternity policy is this in the UK, and it’s this in the US.’ We need to look at the attribution but also make sure we clean up our data,” she says. 
Responsibly adopting generative AI mirrors lessons learned with low code, like knowing what data and applications are connecting into these services: it’s about enhancing workflow, accelerating things people already do, and unlocking new capabilities, with the scale of automation, but still having human experts in the loop.
Shapers can differentiate
“We believe generative AI is beneficial because it has a much wider range of use and flexibility in response than conventional tools and service, so it’s more about how you utilize the tool to create competitive advantage rather than just the fact of using it,” Mukaino says.
 
 
 













 
 

Reinventing customer support, retail, manufacturing, logistics, or industry specific workloads like wealth management with generative AI will take a lot of work, as will setting usage policies and monitoring the impact of the technology on workflows and outcomes. Budgeting for those resources and timescales are essential, too. It comes down to can you build and rebuild faster than competitors that are buying in models and tools that let them create applications straight away, and let more people in their organization experiment with what generative AI can do?

General LLMs from OpenAI, and the more specialized LLMs built on top of their work like GitHub Copilot, improve as large numbers of people use them: the accuracy of code generated by GitHub Copilot has become significantly more accurate since it was introduced last year. You could spend half a million dollars and get a model that only matches the previous generation of commercial models, and while benchmarking isn’t always a reliable guide, these continue to show better results on benchmarks than open source models.
Be prepared to revisit decisions about building or buying as the technology evolves, Lamarre warns. “The question comes down to, ‘How much can I competitively differentiate if I build versus if I buy,’ and I think that boundary is going to change over time,” he says.
If you’ve invested a lot of time and resources in building your own generative models, it’s important to benchmark not just how they contribute to your organization but how they compare to the commercially available models your competition could adopt today, paying 10 to 15 cents for around a page of generated text, not what they had access to when you started your project.
 
 
 













 
 

Major investments
“The build conversation is going to be reserved for people who probably already have a lot of expertise in building and designing large language models,” Montgomery says, noting that Meta builds its LLMs on Azure, while Anthropic, Cohere, and Midjourney use Google Cloud infrastructure to train their LLMs.
Some organizations do have the resources and competencies for this, and those that need a more specialized LLM for a domain may make the significant investments required to exceed the already reasonable performance of general models like GPT4.
Training your own version of an open source LLM will need extremely large data sets: while you can acquire these from somewhere like Hugging Face, you’re still relying on someone else having curated them. Plus you’ll still need data pipelines to clean, deduplicate, preprocess, and tokenize the data, as well as significant infrastructure for training, supervised fine-tuning, evaluation, and deployment, as well as the deep expertise to make the right choices for every step.
There are multiple collections with hundreds of pre-trained LLMs and other foundation models you can start with. Some are general, others more targeted. Generative AI startup Docugami, for instance, began training its own LLM five years ago, specifically to generate the XML semantic model for business documents, marking up elements like tables, lists and paragraphs rather than the phrases and sentences most LLMs work with. Based on that experience, Docugami CEO Jean Paoli suggests that specialized LLMs are going to outperform bigger or more expensive LLMs created for another purpose.
“In the last two months, people have started to understand that LLMs, open source or not, could have different characteristics, that you can even have smaller ones that work better for specific scenarios,” he says. But he adds most organizations won’t create their own LLM and maybe not even their own version of an LLM.
Only a few companies will own large language models calibrated on the scale of the knowledge and purpose of the internet, adds Lamarre. “I think the ones that you calibrate within your four walls will be much smaller in size,” he says.
If they do decide to go down that route, CIOs will need to think about what kind of LLM best suits their scenarios, and with so many to choose from, a tool like Aviary can help. Consider the provenance of the model and the data it was trained on. These are similar questions that organizations have learned to ask about open source projects and components, Montgomery points out. “All the learnings that came from the open source revolution are happening in AI, and they’re happening much quicker.”
IDC’s AI Infrastructure View benchmark shows that getting the AI stack right is one of the most important decisions organizations should take, with inadequate systems the most common reason AI projects fail. It took more than 4,000 NVIDIA A100 GPUs to train Microsoft’s Megatron-Turing NLG 530B model. While there are tools to make training more efficient, they still require significant expertise—and the costs of even fine-tuning are high enough that you need strong AI engineering skills to keep costs down.
Docugami’s Paoli expects most organizations will buy a generative AI model rather than build, whether that means adopting an open source model or paying for a commercial service. “The building is going to be more about putting together things that already exist.” That includes using these emerging stacks to significantly simplify assembling a solution from a mix of open source and commercial options.
So whether you buy or build the underlying AI, the tools adopted or created with generative AI should be treated as products, with all the usual user training and acceptance testing to make sure they can be used effectively. And be realistic about what they can deliver, Paoli warns. 
“CIOs need to understand they’re not going to buy one LLM that’s going to change everything or do a digital transformation for them,” he says.

















 
Related content

 


brandpost

							Sponsored by Skillable						

From skills to performance: How hands-on learning is preparing IT teams for digital transformations
Digital transformation, upgrading IT security, AI, and business collaboration are among the top priorities that CEOs have identified for their IT leadership, and they all have something in common: The need for appropriately skilled workers. 

				By Maro Eremyan				


Jul 22, 2024

8 mins 


Digital Transformation






news

CrowdStrike incident has CIOs rethinking their cloud strategies
CIOs are looking at ways to avoid single points of failure and are re-evaluating their cloud strategies to prevent any 'blue screen of death' incidents. 

				By Gyana Swain				


Jul 22, 2024

7 mins 


Business Continuity
Cloud Computing






brandpost

							Sponsored by Avaya						

Data security and privacy: The foundation of customer trust
Striking the balance between enhanced customer engagement, robust data security measures, and upholding customer privacy: Exploring innovations, challenges, and regulatory landscapes in the pursuit of seamless, trustworthy experiences. 

				By  Chris Hill, Chief Information Security Officer, and Niklas Potthoff, Global Data Privacy Officer, Avaya				


Jul 22, 2024

7 mins 


Data Management






brandpost

							Sponsored by Ultrium LTO						

LTO technology: One of the most enduring – and most effective – ways to protect your data from cybercrime
Linear Tape-Open (LTO) not only reads and writes data faster than disk, but also creates an airgap that is impassable for cybercriminals. 

				By Jeff Miller				


Jul 22, 2024

3 mins 


Security






PODCASTS


VIDEOS


RESOURCES


EVENTS













 
SUBSCRIBE TO OUR NEWSLETTER			

				From our editors straight to your inbox			

			Get started by entering your email address below.		


 



Please enter a valid email address




Subscribe









",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LnpkbmV0LmNvbS9hcnRpY2xlL21vc3Qtd29ya2Vycy13YW50LXRvLXVzZS1nZW5lcmF0aXZlLWFpLXRvLWFkdmFuY2UtdGhlaXItY2FyZWVycy1idXQtZG9udC1rbm93LWhvdy_SAQA?oc=5,Most workers want to use generative AI to advance their careers but don't know how - ZDNet,2023-07-13,ZDNet,https://www.zdnet.com,Generative AI can provide valuable assistance -- if you know how to use it.,N/A,Generative AI can provide valuable assistance -- if you know how to use it.,Generative AI can provide valuable assistance -- if you know how to use it.,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3Lmpkc3VwcmEuY29tL2xlZ2FsbmV3cy9nZW5lcmF0aXZlLWFpLWluLXRoZS13b3JrcGxhY2UtcHJvY2VlZC00MzE3ODMxL9IBAA?oc=5,Generative AI in the Workplace: Proceed with Caution - JD Supra,2023-07-13,JD Supra,https://www.jdsupra.com,"The pace of innovation is astounding—jarring, really. Sure, “Artificial Intelligence” has been a topic of public conversation for decades. Many of us remember when Deep Blue beat Garry...",N/A,"The pace of innovation is astounding—jarring, really. Sure, “Artificial Intelligence” has been a topic of public conversation for decades. Many of us...","The pace of innovation is astounding—jarring, really. Sure, “Artificial Intelligence” has been a topic of public conversation for decades. Many of us remember when Deep Blue beat Garry Kasparov...",,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQGh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9ob3ctdG8tdXNlLWFpLXRvb2xzLXByb3RlY3QtcHJpdmFjeS_SAQA?oc=5,How to Use Generative AI Tools While Still Protecting Your Privacy - WIRED,2023-07-16,WIRED,https://www.wired.com,Here's how to take some control of your data while using artificial intelligence tools and apps.,"['gear', 'how to and advice', 'artificial intelligence', 'privacy', 'chatgpt', 'google', 'microsoft', 'openai', 'textaboveleftsmall', 'comments-enabled', 'digital_syndication']",Here's how to take some control of your data while using artificial intelligence tools and apps.,Here's how to take some control of your data while using artificial intelligence tools and apps.,https://schema.org/,"[{'@type': 'ListItem', 'position': 1, 'name': 'Gear', 'item': 'https://www.wired.com/gear/'}, {'@type': 'ListItem', 'position': 2, 'name': 'artificial intelligence', 'item': 'https://www.wired.com/tag/artificial-intelligence/'}, {'@type': 'ListItem', 'position': 3, 'name': 'How to Use Generative AI Tools While Still Protecting Your Privacy'}]",BreadcrumbList,"[{'@type': 'Person', 'name': 'David Nield', 'sameAs': 'https://www.wired.com/author/david-nield/'}]",2023-07-16T07:00:00.000-04:00,"How to Use Generative AI Tools While Still Protecting Your Privacy

","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}","['https://media.wired.com/photos/64b1ded4daed59ebbf460c89/16:9/w_2400,h_1350,c_limit/How-to-Use-Generative-AI-Tools-While-Still-Protecting-Your-Privacy-Security-GettyImages-1486016254.jpg', 'https://media.wired.com/photos/64b1ded4daed59ebbf460c89/4:3/w_2132,h_1599,c_limit/How-to-Use-Generative-AI-Tools-While-Still-Protecting-Your-Privacy-Security-GettyImages-1486016254.jpg', 'https://media.wired.com/photos/64b1ded4daed59ebbf460c89/1:1/w_1600,h_1600,c_limit/How-to-Use-Generative-AI-Tools-While-Still-Protecting-Your-Privacy-Security-GettyImages-1486016254.jpg']",tags,N/A,"David NieldGearJul 16, 2023 7:00 AMHow to Use Generative AI Tools While Still Protecting Your PrivacyHere's how to take some control of your data while using artificial intelligence tools and apps.Photograph: akinbostanci/Getty ImagesSave this storySaveSave this storySaveThe explosion of consumer-facing tools that offer generative AI has created plenty of debate: These tools promise to transform the ways in which we live and work while also raising fundamental questions about how we can adapt to a world in which they're extensively used for just about anything.As with any new technology riding a wave of initial popularity and interest, it pays to be careful in the way you use these AI generators and bots—in particular, in how much privacy and security you're giving up in return for being able to use them.AdChoicesADVERTISEMENTIt's worth putting some guardrails in place right at the start of your journey with these tools, or indeed deciding not to deal with them at all, based on how your data is collected and processed. Here's what you need to look out for and the ways in which you can get some control back.Always Check the Privacy Policy Before UseMake sure AI tools are honest about how data is used.
OpenAI via David NieldChecking the terms and conditions of apps before using them is a chore but worth the effort—you want to know what you're agreeing to. As is the norm everywhere from social media to travel planning, using an app often means giving the company behind it the rights to everything you put in, and sometimes everything they can learn about you and then some.Featured VideoChatGPT Answers the Web's Most Searched QuestionsThe OpenAI privacy policy, for example, can be found here—and there's more here on data collection. By default, anything you talk to ChatGPT about could be used to help its underlying large language model (LLM) “learn about language and how to understand and respond to it,” although personal information is not used “to build profiles about people, to contact them, to advertise to them, to try to sell them anything, or to sell the information itself.”Personal information may also be used to improve OpenAI's services and to develop new programs and services. In short, it has access to everything you do on DALL-E or ChatGPT, and you're trusting OpenAI not to do anything shady with it (and to effectively protect its servers against hacking attempts).It's a similar story with Google's privacy policy, which you can find here. There are some extra notes here for Google Bard: The information you input into the chatbot will be collected ""to provide, improve, and develop Google products and services and machine learning technologies.” As with any data Google gets off you, Bard data may be used to personalize the ads you see.Watch What You ShareIt's maybe not a great idea to upload your own face for the AI treatment.
OpenAI via David NieldEssentially, anything you input into or produce with an AI tool is likely to be used to further refine the AI and then to be used as the developer sees fit. With that in mind—and the constant threat of a data breach that can never be fully ruled out—it pays to be largely circumspect with what you enter into these engines.Most PopularGearCMF's Phone 1 Is Better Than Any $199 Smartphone Should Ever BeBy Julian ChokkattuGearDyson Has New Headphones That Don’t Cover Your Mouth This TimeBy Boone AshworthGearBreathe Easy—We Found the Best Air PurifiersBy Lisa Wood ShapiroGearThe Best Mesh Wi-Fi RoutersBy Simon HillWhen it comes to the tools that produce AI-enhanced versions of your face, for example—which seem to continue to increase in number—we wouldn't recommend using them unless you're happy with the possibility of seeing AI-generated visages like your own show up in other people's creations.AdvertisementAs far as text goes, steer completely clear of any personal, private, or sensitive information: We've already seen portions of chat histories leaked out due to a bug. As tempting as it might be to get ChatGPT to summarize your company's quarterly financial results or write a letter with your address and bank details in it, this is information that's best left out of these generative AI engines—not least because, as Microsoft admits, some AI prompts are manually reviewed by staff to check for inappropriate behavior.To be fair this is something that the AI developers caution against. ""Don’t include confidential or sensitive information in your Bard conversations,"" warns Google, while OpenAI encourages users ""not to share any sensitive content"" that could find it's way out to the wider web through the shared links feature. If you don't want it to ever in public or be used in an AI output, keep it to yourself.Change the SettingsGoogle Bard data can be auto-deleted, if required.
Google via David NieldYou've decided you're OK with the privacy policy, you're making sure you're not oversharing—the final step is to explore the privacy and security controls you get inside your AI tools of choice. The good news is that most companies make these controls relatively visible and easy to operate.Google Bard follows the lead of other Google products like Gmail or Google Maps: You can choose to have the data you give it automatically erased after a set period of time, or manually delete the data yourself, or let Google keep it indefinitely. To find the controls for Bard, head here and make your choice.Like Google, Microsoft rolls its AI data management options in with the security and privacy settings for the rest of its products. Head here to find the privacy options for everything you do with Microsoft products, then click Search history to review (and if necessary delete) anything you've chatted with Bing AI about.When it comes to ChatGPT on the web, click your email address (bottom left), then choose Settings and Data controls. You can stop ChatGPT from using your conversations to train its models here, but you'll lose access to the chat history feature at the same time. Conversations can also be wiped from the record by clicking the trash can icon next to them on the main screen individually, or by clicking your email address and Clear conversations and Confirm clear conversations to delete them all.Enter your email to get the Wired newsletterclose dialogRecommended NewsletterGadget LabThe latest news, expert guides, and in-depth reviews from WIRED's Gear team. Delivered on Tuesdays and Thursdays.Twice WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterGadget LabThe latest news, expert guides, and in-depth reviews from WIRED's Gear team. Delivered on Tuesdays and Thursdays.Twice WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialog",2023-07-16T07:00:00.000-04:00,,https://www.wired.com/story/how-to-use-ai-tools-protect-privacy/,gear,,True,"As with any new technology riding a wave of initial popularity and interest, it pays to be careful in the way you use these AI generators and bots—in particular, in how much privacy and security you're giving up in return for being able to use them.
It's worth putting some guardrails in place right at the start of your journey with these tools, or indeed deciding not to deal with them at all, based on how your data is collected and processed. Here's what you need to look out for and the ways in which you can get some control back.
Always Check the Privacy Policy Before Use
Checking the terms and conditions of apps before using them is a chore but worth the effort—you want to know what you're agreeing to. As is the norm everywhere from social media to travel planning, using an app often means giving the company behind it the rights to everything you put in, and sometimes everything they can learn about you and then some.
The OpenAI privacy policy, for example, can be found here—and there's more here on data collection. By default, anything you talk to ChatGPT about could be used to help its underlying large language model (LLM) “learn about language and how to understand and respond to it,” although personal information is not used “to build profiles about people, to contact them, to advertise to them, to try to sell them anything, or to sell the information itself.”
Personal information may also be used to improve OpenAI's services and to develop new programs and services. In short, it has access to everything you do on DALL-E or ChatGPT, and you're trusting OpenAI not to do anything shady with it (and to effectively protect its servers against hacking attempts).
It's a similar story with Google's privacy policy, which you can find here. There are some extra notes here for Google Bard: The information you input into the chatbot will be collected ""to provide, improve, and develop Google products and services and machine learning technologies.” As with any data Google gets off you, Bard data may be used to personalize the ads you see.
Watch What You Share
Essentially, anything you input into or produce with an AI tool is likely to be used to further refine the AI and then to be used as the developer sees fit. With that in mind—and the constant threat of a data breach that can never be fully ruled out—it pays to be largely circumspect with what you enter into these engines.
When it comes to the tools that produce AI-enhanced versions of your face, for example—which seem to continue to increase in number—we wouldn't recommend using them unless you're happy with the possibility of seeing AI-generated visages like your own show up in other people's creations.
As far as text goes, steer completely clear of any personal, private, or sensitive information: We've already seen portions of chat histories leaked out due to a bug. As tempting as it might be to get ChatGPT to summarize your company's quarterly financial results or write a letter with your address and bank details in it, this is information that's best left out of these generative AI engines—not least because, as Microsoft admits, some AI prompts are manually reviewed by staff to check for inappropriate behavior.
To be fair this is something that the AI developers caution against. ""Don’t include confidential or sensitive information in your Bard conversations,"" warns Google, while OpenAI encourages users ""not to share any sensitive content"" that could find it's way out to the wider web through the shared links feature. If you don't want it to ever in public or be used in an AI output, keep it to yourself.
Change the Settings
You've decided you're OK with the privacy policy, you're making sure you're not oversharing—the final step is to explore the privacy and security controls you get inside your AI tools of choice. The good news is that most companies make these controls relatively visible and easy to operate.
Google Bard follows the lead of other Google products like Gmail or Google Maps: You can choose to have the data you give it automatically erased after a set period of time, or manually delete the data yourself, or let Google keep it indefinitely. To find the controls for Bard, head here and make your choice.
Like Google, Microsoft rolls its AI data management options in with the security and privacy settings for the rest of its products. Head here to find the privacy options for everything you do with Microsoft products, then click Search history to review (and if necessary delete) anything you've chatted with Bing AI about.
When it comes to ChatGPT on the web, click your email address (bottom left), then choose Settings and Data controls. You can stop ChatGPT from using your conversations to train its models here, but you'll lose access to the chat history feature at the same time. Conversations can also be wiped from the record by clicking the trash can icon next to them on the main screen individually, or by clicking your email address and Clear conversations and Confirm clear conversations to delete them all.",,"https://media.wired.com/photos/64b1ded4daed59ebbf460c89/2:3/w_1066,h_1599,c_limit/How-to-Use-Generative-AI-Tools-While-Still-Protecting-Your-Privacy-Security-GettyImages-1486016254.jpg","{'@type': 'CreativeWork', 'name': 'WIRED'}",Here's how to take some control of your data while using artificial intelligence tools and apps.,"{'@type': 'WebPage', '@id': 'https://www.wired.com/story/how-to-use-ai-tools-protect-privacy/'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vYmRhaWx5LmNvLnVrL2FydGljbGVzLzIwMjMvMDcvMTMvaGVyZS1hcmUtdGhlLTUtbGVnYWwtam9icy10aGF0LXdpbGwtYmUtY3JlYXRlZC1hcy1hLXJlc3VsdC1vZi1nZW5lcmF0aXZlLWFp0gEA?oc=5,Here are the 5 legal jobs that will be created as a result of generative AI - Bdaily News,2023-07-13,Bdaily News,https://bdaily.co.uk,Bdaily UK | Business News,N/A,"By Dawid Robert Kotur, Founder and CEO of Curvestone AI
Generative AI such as Chat GPT is rapidly changing the way…
| Law | London | Employment | Innovation | Science and Technology |",N/A,http://schema.org,,Organization,"{'@type': 'Person', 'name': 'Curvestone AI'}",2023-07-13T12:21:49+00:00,Here are the 5 legal jobs that will be created as a result of generative AI,"{'@type': 'Organization', 'name': 'Bdaily', 'logo': {'@type': 'ImageObject', 'url': 'https://bdaily.co.uk/assets/img/bdaily-icon.png', 'width': '400', 'height': '400'}}","{'@type': 'ImageObject', 'url': 'https://bdaily.co.uk/images/uploads/lOzB0kgAiH9XTUGiVhHe3JJRRLtwzdLnXlujKMG2.jpeg?w=1200&h=630&fm=jpg&fit=crop-50-50&s=689ebd99f8e1dccf20471c7e31791b9b', 'width': '1200', 'height': '630'}",N/A,N/A,"









                Image Source:
                Pixabay






Published by

        Member
    
 Curvestone AI
 on
13 Jul 2023






LinkedIn







Facebook







Twitter









Member Article

Here are the 5 legal jobs that will be created as a result of generative AI

By Dawid Robert Kotur, Founder and CEO of Curvestone AI
Generative AI such as Chat GPT is rapidly changing the way we work, live, and interact with technology. While the media has shed light - sometimes overdramatically - on many of the challenges this transition comes with, I wanted to tackle one in particular: the idea that AI will replace many human jobs. I have worked in the broader field of AI for almost a decade and have first hand experience of how it is likely to impact the jobs market. While I’m not denying that the wide-ranging use of Generative AI will remove the need for some jobs - particularly in the legal market - I wanted to share my insight into the new job and upskilling opportunities AI is also going to create in that market in parallel.
Here are five of the jobs I foresee being created in the next ten years:
Legal Prompt Engineers
Legal Prompt Engineers will be responsible for developing and maintaining the AI algorithms that power chat bots and virtual assistants. They will work closely with data scientists and software engineers to ensure that these AI systems are efficient, accurate, and user-friendly. They will also work with lawyers and technical specialists to make sure that lawyers interact with Generative AI in a way that performs best and gives an output that a lawyer can use as part of their service to the client.
Legal AI Ethical Officers
With the increasing use of AI in various industries, especially legal, ethical concerns have risen. Legal AI Ethical Officers will be responsible for ensuring that AI systems are developed and used in an ethical and responsible manner. They will work closely with AI developers and business leaders to identify potential ethical issues and develop strategies to address them. It won’t be surprising if at some point all medium to large sized companies will have at least one of those people ensuring a compliant and ethical use of Generative AI.
Legal Bias Anthropologists
Bias Anthropologists will be experts in identifying and addressing biases in AI systems. They will work with data scientists and AI developers to identify potential biases in the data used to train AI systems and develop strategies to mitigate these biases. These people will be absolutely crucial in the legal sector where the use of Generative AI is growing exponentially - making sure, for instance, that the algorithms being used by the sector do not discriminate against certain groups or individuals.
Legal Generative AI Operators
Generative AI Operators will be responsible for operating AI systems that can generate legal documents, such as contracts and patents. They will work closely with legal professionals to ensure that these documents are accurate and legally binding. They will do this much faster and to a better standard than human lawyers can today. If done well, in a lot of places, paralegal can and should be upskilled to transition into such a role.
Legal AI Product Managers
AI Product Managers will be responsible for developing and managing Generative AI products and services. They will closely work with AI developers, business leaders, and customers to identify market opportunities and develop AI products that meet customer needs. It will be the Legal AI Product Managers who will ideally have both technical and legal training to help the industry transform. Most law firms will have many of those people hired directly in their teams, acting as the linchpins between lawyers and technical departments. I have met people who do this kind of work already, just without the title. They are usually technically-minded lawyers who see the industry progressing beyond the status quo and want to take innovation as an opportunity to diversify their skill set.
Despite what a lot of people think, Generative AI will not replace lawyers. Law firms that do not embrace technology early might see a lot of their business go elsewhere simply because of the enormous time and money losses associated with NOT using AI. But even knowing that, the transition will be slow, as the legal industry is based on relationships and trust. It will take a lot for clients of law firms to move to other more innovative providers just because of the price.
As legal services become cheaper due to leveraging Generative AI, however, we might actually see real job growth in the legal sector as more people will be able to afford legal services and therefore drive more demand for those services. The jobs created to fulfill that demand will probably be different to what we see on the market today, but it is also likely that soon universities will adjust their curriculum to incorporate how to use Generative AI in law, so everything is more or less moving in sync.
What’s certain is that a new generation of AI-enabled legal professionals is coming.


                        This was posted in Bdaily's Members' News section
                                                    by
                            
                                Curvestone AI
                            .
                                            






Explore these topics

#Law
#London
#Employment
#Innovation
#Science and Technology






Enjoy the read? Get Bdaily delivered.


Sign up to receive our popular morning London email for free.  




Name 



Email 



Opt in to another list



Bdaily National



Bdaily North East



Bdaily Yorkshire



Marketing *







I agree to receive a daily email and understand I can unsubscribe at any time.





Subscribe
 * Occasional offers & updates from selected Bdaily partners







Our Partners

















",2023-07-13T12:30:32+00:00,,https://bdaily.co.uk,,,,,,,,,"{'@type': 'WebPage', '@id': 'https://bdaily.co.uk/articles/2023/07/13/here-are-the-5-legal-jobs-that-will-be-created-as-a-result-of-generative-ai'}",https://bdaily.co.uk/assets/img/bdaily.png,"['http://facebook.com/bdailynetwork', 'https://twitter.com/Bdaily', 'https://www.linkedin.com/company/bdaily']","[{'@type': 'ContactPoint', 'telephone': '+448453882022', 'contactType': 'sales', 'availableLanguage': 'English'}, {'@type': 'ContactPoint', 'telephone': '+441912236791', 'contactType': 'customer support', 'availableLanguage': 'English'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3LmRhcmtyZWFkaW5nLmNvbS92dWxuZXJhYmlsaXRpZXMtdGhyZWF0cy9ob3ctdG8tcHV0LWdlbmVyYXRpdmUtYWktdG8td29yay1pbi15b3VyLXNlY3VyaXR5LW9wZXJhdGlvbnMtY2VudGVy0gEA?oc=5,How to Put Generative AI to Work in Your Security Operations Center - Dark Reading,2023-07-12,Dark Reading,https://www.darkreading.com,Generative AI is the cybersecurity resource that never sleeps. Here are some of the ways security-focused generative AI can benefit different members of the SOC team.,N/A,Generative AI is the cybersecurity resource that never sleeps. Here are some of the ways security-focused generative AI can benefit different members of the SOC team.,N/A,https://schema.org,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.darkreading.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'Vulnerabilities & Threats', 'item': 'https://www.darkreading.com/vulnerabilities-threats'}]",BreadcrumbList,"[{'@type': 'Person', 'name': 'A.N. Ananth', 'image': 'https://eu-images.contentstack.com/v3/assets/blt6d90778a997de1cd/bltabb931b9fa779bec/64f179586f5509c5e32bcf60/Ananth_hi_res.jpg', 'url': 'https://www.darkreading.com/author/a-n-ananth'}]",2023-07-12T17:00:00.000Z,How to Put Generative AI to Work in Your Security Operations Center,"{'@type': ['NewsMediaOrganization', 'Organization', 'OnlineBusiness'], 'identifier': 'https://www.darkreading.com', 'name': 'Dark Reading', 'url': 'https://www.darkreading.com', 'sameAs': ['https://twitter.com/DarkReading', 'https://www.linkedin.com/company/dark-reading/', 'https://www.facebook.com/darkreadingcom/', 'https://www.youtube.com/@DarkReadingOfficialYT', 'https://news.google.com/publications/CAAqBwgKMKmknwswtq63Aw'], 'foundingDate': '2006', 'description': 'To challenge community members to think about security by providing strong, even unconventional points of view, backed by hard-nosed reporting, hands-on experience, and the professional knowledge that comes only with years of work in the information security industry.', 'logo': {'@type': 'ImageObject', 'url': 'https://www.darkreading.com/build/_assets/DarkReading-EAU2PZUE.svg', 'width': {'@type': 'QuantitativeValue', 'value': 1008}, 'height': {'@type': 'QuantitativeValue', 'value': 112}}}","{'@type': 'ImageObject', 'url': 'https://eu-images.contentstack.com/v3/assets/blt6d90778a997de1cd/blta95cc0a3b1a755ee/64f14f2c705b0e4e3f4ca539/AI-phonlamaiphoto-AdobeStock_177359950.jpeg', 'caption': '', 'creditText': 'Source: Phonlamaiphoto via Adobe Stock'}",N/A,N/A,N/A,2023-12-08T12:01:49.095Z,,,,,,,,,,,https://www.darkreading.com/vulnerabilities-threats/how-to-put-generative-ai-to-work-in-your-security-operations-center,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiO2h0dHBzOi8vYmxvZ3MubnZpZGlhLmNvbS9ibG9nL2dlbmVyYXRpdmUtYWktZm9yLWluZHVzdHJpZXMv0gEA?oc=5,AI-Fueled Productivity: Generative AI Opens New Era of Efficiency Across Industries - NVIDIA Blog,2023-07-13,NVIDIA Blog,https://blogs.nvidia.com,N/A,N/A,"A watershed moment on Nov. 22, 2022, was mostly virtual, yet it shook the foundations of nearly every industry on the planet. On that day, OpenAI released ChatGPT, the most advanced artificial intelligence chatbot ever developed. This set off demand for generative AI applications that help businesses become more efficient, from providing consumers with answers  Read Article",N/A,https://schema.org,,,,,,,,N/A,N/A,"



AI-Fueled Productivity: Generative AI Opens New Era of Efficiency Across Industries

July 13, 2023 by Cliff Edwards 










					Share			


 
 
 
 
Email0 


  A watershed moment on Nov. 22, 2022, was mostly virtual, yet it shook the foundations of nearly every industry on the planet.
On that day, OpenAI released ChatGPT, the most advanced artificial intelligence chatbot ever developed. This set off demand for generative AI applications that help businesses become more efficient, from providing consumers with answers to their questions to accelerating the work of researchers as they seek scientific breakthroughs, and much, much more.
Businesses that previously dabbled in AI are now rushing to adopt and deploy the latest applications. Generative AI — the ability of algorithms to create new text, images, sounds, animations, 3D models and even computer code — is moving at warp speed, transforming the way people work and play.
By employing large language models (LLMs) to handle queries, the technology can dramatically reduce the time people devote to manual tasks like searching for and compiling information.
The stakes are high. AI could contribute more than $15 trillion to the global economy by 2030, according to PwC. And the impact of AI adoption could be greater than the inventions of the internet, mobile broadband and the smartphone — combined.
The engine driving generative AI is accelerated computing. It uses GPUs, DPUs and networking along with CPUs to accelerate applications across science, analytics, engineering, as well as consumer and enterprise use cases.
Early adopters across industries — from drug discovery, financial services, retail and telecommunications to energy, higher education and the public sector — are combining accelerated computing with generative AI to transform business operations, service offerings and productivity.
Click to view the infographic: Generating the Next Wave of AI Transformation
Generative AI for Drug Discovery
Today, radiologists use AI to detect abnormalities in medical images, doctors use it to scan electronic health records to uncover patient insights, and researchers use it to accelerate the discovery of novel drugs.
Traditional drug discovery is a resource-intensive process that can require the synthesis of over 5,000 chemical compounds and yields an average success rate of just 10%. And it takes more than a decade for most new drug candidates to reach the market.
Researchers are now using generative AI models to read a protein’s amino acid sequence and accurately predict the structure of target proteins in seconds, rather than weeks or months.
Using NVIDIA BioNeMo models, Amgen, a global leader in biotechnology, has slashed the time it takes to customize models for molecule screening and optimization from three months to just a few weeks. This type of trainable foundation model enables scientists to create variants for research into specific diseases, allowing them to develop target treatments for rare conditions.
Whether predicting protein structures or securely training algorithms on large real-world and synthetic datasets, generative AI and accelerated computing are opening new areas of research that can help mitigate the spread of disease, enable personalized medical treatments and boost patient survival rates.
Generative AI for Financial Services
According to a recent NVIDIA survey, the top AI use cases in the financial services industry are customer services and deep analytics, where natural language processing and LLMs are used to better respond to customer inquiries and uncover investment insights. Another common application is in recommender systems that power personalized banking experiences, marketing optimization and investment guidance.
Advanced AI applications have the potential to help the industry better prevent fraud and transform every aspect of banking, from portfolio planning and risk management to compliance and automation.
Eighty percent of business-relevant information is in an unstructured format — primarily text — which makes it a prime candidate for generative AI. Bloomberg News produces 5,000 stories a day related to the financial and investment community. These stories represent a vast trove of unstructured market data that can be used to make timely investment decisions.
NVIDIA, Deutsche Bank, Bloomberg and others are creating LLMs trained on domain-specific and proprietary data to power finance applications.
Financial Transformers, or “FinFormers,” can learn context and understand the meaning of unstructured financial data. They can power Q&A chatbots, summarize and translate financial texts, provide early warning signs of counterparty risk, quickly retrieve data and identify data-quality issues.
These generative AI tools rely on frameworks that can integrate proprietary data into model training and fine-tuning, integrate data curation to prevent bias and use guardrails to keep conversations finance-specific.
Expect fintech startups and large international banks to expand their use of LLMs and generative AI to develop sophisticated virtual assistants to serve internal and external stakeholders, create hyper-personalized customer content, automate document summarization to reduce manual work, and analyze terabytes of public and private data to generate investment insights.
Generative AI for Retail
With 60% of all shopping journeys starting online and consumers more connected and knowledgeable than ever, AI has become a vital tool to help retailers match shifting expectations and differentiate from a rising tide of competition.
Retailers are using AI to improve customer experiences, power dynamic pricing, create customer segmentation, design personalized recommendations and perform visual search.
Generative AI can support customers and employees at every step through the buyer journey.
With AI models trained on specific brand and product data, they can generate robust product descriptions that improve search engine optimization rankings and help shoppers find the exact product they’re looking for. For example, generative AI can use metatags containing product attributes to generate more comprehensive product descriptions that include various terms like “low sugar” or “gluten free.”
AI virtual assistants can check enterprise resource planning systems and generate customer service messages to inform shoppers about which items are available and when orders will ship, and even assist customers with order change requests.
Fashable, a member of NVIDIA Inception’s global network of technology startups, is using generative AI to create virtual clothing designs, eliminating the need for physical fabric during product development. With the models trained on both proprietary and market data, this reduces the environmental impact of fashion design and helps retailers design clothes according to current market trends and tastes.
Expect retailers to use AI to capture and retain customer attention, deliver superior shopping experiences, and drive revenue by matching shoppers with the right products at the right time.
Generative AI for Telecommunications
In an NVIDIA survey covering the telecommunications industry, 95% of respondents reported that they were engaged with AI, while two-thirds believed that AI would be important to their company’s future success.
Whether improving customer service, streamlining network operations and design, supporting field technicians or creating new monetization opportunities, generative AI has the potential to reinvent the telecom industry.
Telcos can train diagnostic AI models with proprietary data on network equipment and services, performance, ticket issues, site surveys and more. These models can accelerate troubleshooting of technical performance issues, recommend network designs, check network configurations for compliance, predict equipment failures, and identify and respond to security threats.
Generative AI applications on handheld devices can support field technicians by scanning equipment and generating virtual tutorials to guide them through repairs. Virtual guides can then be enhanced with augmented reality, enabling technicians to analyze equipment in a 3D immersive environment or call on a remote expert for support.
New revenue opportunities will also open for telcos. With large edge infrastructure and access to vast datasets, telcos around the world are now offering generative AI as a service to enterprise and government customers.
As generative AI advances, expect telecommunications providers to use the technology to optimize network performance, improve customer support, detect security intrusions and enhance maintenance operations.
Generative AI for Energy
In the energy industry, AI is powering predictive maintenance and asset optimization, smart grid management, renewable energy forecasting, grid security and more.
To meet growing data needs across aging infrastructure and new government compliance regulations, energy operators are looking to generative AI.
In the U.S., electric utility companies spend billions of dollars every year to inspect, maintain and upgrade power generation and transmission infrastructure.
Until recently, using vision AI to support inspection required algorithms to be trained on thousands of manually collected and tagged photos of grid assets, with training data constantly updated for new components. Now, generative AI can do the heavy lifting.
With a small set of image training data, algorithms can generate thousands of physically accurate images to train computer vision models that help field technicians identify grid equipment corrosion, breakage, obstructions and even detect wildfires. This type of proactive maintenance enhances grid reliability and resiliency by reducing downtime, while diminishing the need to dispatch teams to the field.
Generative AI can also reduce the need for manual research and analysis. According to McKinsey, employees spend up to 1.8 hours per day searching for information — nearly 20% of the work week. To increase productivity, energy companies can train LLMs on proprietary data, including meeting notes, SAP records, emails, field best practices and public data such as standard material data sheets.
With this type of knowledge repository connected to an AI chatbot, engineers and data scientists can get instant answers to highly technical questions. For example, a maintenance engineer troubleshooting pitch control issues on a turbine’s hydraulic system could ask a bot: “How should I adjust the hydraulic pressure or flow to rectify pitch control issues on a model turbine from company X?” A properly trained model would deliver specific instructions to the user, who wouldn’t have to look through a bulky manual to find answers.
With AI applications for new system design, customer service and automation, expect generative AI to enhance safety and energy efficiency, as well as reduce operational expenses in the energy industry.
Generative AI for Higher Education and Research
From intelligent tutoring systems to automated essay grading, AI has been employed in education for decades. As universities use AI to improve teacher and student experiences, they’re increasingly dedicating resources to build AI-focused research initiatives.
For example, researchers at the University of Florida have access to one of the world’s fastest supercomputers in academia. They’ve used it to develop GatorTron — a natural language processing model that enables computers to read and interpret medical language in clinical notes that are stored in electronic health records. With a model that understands medical context, AI developers can create numerous medical applications, such as speech-to-text apps that support doctors with automated medical charting.
In Europe, an industry-university collaboration involving the Technical University of Munich is demonstrating that LLMs trained on genomics data can generalize across a plethora of genomic tasks, unlike previous approaches that required specialized models. The genomics LLM is expected to help scientists understand the dynamics of how DNA is translated into RNA and proteins, unlocking new clinical applications that will benefit drug discovery and health.
To conduct this type of groundbreaking research and attract the most motivated students and qualified academic professionals, higher education institutes should consider a whole-university approach to pool budget, plan AI initiatives, and distribute AI resources and benefits across disciplines.
Generative AI for the Public Sector
Today, the biggest opportunity for AI in the public sector is helping public servants to perform their jobs more efficiently and save resources.
The U.S. federal government employs over 2 million civilian employees — two-thirds of whom work in professional and administrative jobs.
These administrative roles often involve time-consuming manual tasks, including drafting, editing and summarizing documents, updating databases, recording expenditures for auditing and compliance, and responding to citizen inquiries.
To control costs and bring greater efficiency to routine job functions, government agencies can use generative AI.
Generative AI’s ability to summarize documents has great potential to boost the productivity of policymakers and staffers, civil servants, procurement officers and contractors. Consider a 756-page report recently released by the National Security Commission on Artificial Intelligence. With reports and legislation often spanning hundreds of pages of dense academic or legal text, AI-powered summaries generated in seconds can quickly break down complex content into plain language, saving the human resources otherwise needed to complete the task.
AI virtual assistants and chatbots powered by LLMs can instantly deliver relevant information to people online, taking the burden off of overstretched staff who work phone banks at agencies like the Treasury Department, IRS and DMV.
With simple text inputs, AI content generation can help public servants create and distribute publications, email correspondence, reports, press releases and public service announcements.
The analytical capabilities of AI can also help process documents to speed the delivery of vital services provided by organizations like Medicare, Medicaid, Veterans Affairs, USPS and the State Department.
Generative AI could be a pivotal tool to help government bodies work within budget constraints, deliver government services more quickly and achieve positive public sentiment.
Generative AI for Media and Entertainment
A typical film must generate more than 2x its production budget in box office revenues to be profitable. And with lofty production costs, even major movies like Indiana Jones and the Dial of Destiny, The Flash and Shazam! Fury of the Gods struggled to turn a profit.
Media and entertainment companies must optimize and accelerate production pipelines to stay competitive. Deloitte research showed that 72% of M&E leaders believe AI will be crucial over the next five years.
In media and entertainment, AI can assist artists, developers and business decision-makers.
For content creation, generative AI can help artists and developers reduce the time needed for concept art, previsualization, and creating environments with 3D content placement, crowds, and set dressing. This will free up artists’ time to achieve the most ideal shots and sequences.
By using LLMs to power voice generation and audio- or text-generated animation, studios and broadcasters can create personalized, immersive experiences with existing characters and sports heroes. Sports legends can interact with fans, superheros can talk about their comic series and droids can become augmented reality assistants. These experiences can create greater customer engagement and new revenue streams.
To reduce distribution costs, streaming services and live broadcasters can use generative AI and data analytics to monitor and visualize quality of service, predict when and where to preload content, mitigate piracy, recommend content and more. Ad content or product placement can also be inserted dynamically into content at the point of consumption, improving relevance for both consumers and advertisers.
Whether reducing content costs, creating new revenue streams or optimizing user experiences, generative AI has emerged as a key tool to help the media and entertainment industry reinvent itself while delighting audiences with new forms of entertainment.
Generative AI – A Key Ingredient for Business Success 
Across every field, organizations are transforming employee productivity, improving products and delivering higher-quality services with generative AI.
To put generative AI into practice, businesses need expansive amounts of data, deep AI expertise and sufficient compute power to deploy and maintain models quickly. Enterprises can fast-track adoption with the NeMo generative AI framework, part of NVIDIA AI Enterprise software, running on DGX Cloud. NVIDIA’s pretrained foundation models offer a simplified approach to building and running customized generative AI solutions for unique business use cases.
Learn more about powerful generative AI tools to help your business increase productivity, automate tasks, and unlock new opportunities for employees and customers. 


Categories: Deep Learning | Generative AITags: Artificial Intelligence | DGX Cloud | Education | Energy | Financial Services | Healthcare and Life Sciences | Industrial and Manufacturing | Media and Entertainment | Public Sector | Retail | Telecommunications 


 




All NVIDIA News 







Decoding How AI-Powered Upscaling on NVIDIA RTX Improves Video Quality 













Meet the Designer Creating Spaces Where NVIDIANs Do Their Life’s Work 













Next-Gen Video Editing: Wondershare Filmora Adds NVIDIA RTX Video HDR Support, RTX-Accelerated AI Features 













Jensen Huang, Mark Zuckerberg to Discuss Future of Graphics and Virtual Worlds at SIGGRAPH 2024 













Mile-High AI: NVIDIA Research to Present Advancements in Simulation and Gen AI at SIGGRAPH 





 Stay up to date on the latest enterprise news.Thank you for subscribing.* Professional Email AddressSubscribe NowUnsubscribe at any time. Read the NVIDIA Privacy Policy.


",,"[{'@type': 'WebPage', '@id': 'https://blogs.nvidia.com/blog/generative-ai-for-industries/', 'url': 'https://blogs.nvidia.com/blog/generative-ai-for-industries/', 'name': 'Generative AI Opens New Era of Efficiency Across Industries | NVIDIA Blog', 'isPartOf': {'@id': 'https://blogs.nvidia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://blogs.nvidia.com/blog/generative-ai-for-industries/#primaryimage'}, 'image': {'@id': 'https://blogs.nvidia.com/blog/generative-ai-for-industries/#primaryimage'}, 'thumbnailUrl': 'https://blogs.nvidia.com/wp-content/uploads/2023/07/industries-gen-ai.jpg', 'datePublished': '2023-07-13T15:00:09+00:00', 'dateModified': '2024-05-23T15:46:59+00:00', 'author': {'@id': 'https://blogs.nvidia.com/#/schema/person/a25e83e2d50ce6a9e76f7e9267a7188e'}, 'breadcrumb': {'@id': 'https://blogs.nvidia.com/blog/generative-ai-for-industries/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://blogs.nvidia.com/blog/generative-ai-for-industries/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://blogs.nvidia.com/blog/generative-ai-for-industries/#primaryimage', 'url': 'https://blogs.nvidia.com/wp-content/uploads/2023/07/industries-gen-ai.jpg', 'contentUrl': 'https://blogs.nvidia.com/wp-content/uploads/2023/07/industries-gen-ai.jpg', 'width': 1920, 'height': 1080}, {'@type': 'BreadcrumbList', '@id': 'https://blogs.nvidia.com/blog/generative-ai-for-industries/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://blogs.nvidia.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'AI-Fueled Productivity: Generative AI Opens New Era of Efficiency Across Industries'}]}, {'@type': 'WebSite', '@id': 'https://blogs.nvidia.com/#website', 'url': 'https://blogs.nvidia.com/', 'name': 'NVIDIA Blog', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://blogs.nvidia.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://blogs.nvidia.com/#/schema/person/a25e83e2d50ce6a9e76f7e9267a7188e', 'name': 'Cliff Edwards', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://blogs.nvidia.com/#/schema/person/image/37a771060713decd5a465e5fc6e9a8b3', 'url': 'https://blogs.nvidia.com/wp-content/uploads/2020/12/Cliff-Edwards-96x96.jpg', 'contentUrl': 'https://blogs.nvidia.com/wp-content/uploads/2020/12/Cliff-Edwards-96x96.jpg', 'caption': 'Cliff Edwards'}, 'description': 'Cliff Edwards is part of the Enterprise Communications team at NVIDIA, covering thought leadership PR, as well as AI advances in retail and telco. A graduate of Northwestern University, he spent more than two decades as a journalist for the Associated Press, BusinessWeek and Bloomberg Businessweek, covering the intersection of communications and computing.', 'url': 'https://blogs.nvidia.com/blog/author/cliffedwards/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LmJsb29tYmVyZy5jb20vbmV3cy9hcnRpY2xlcy8yMDIzLTA3LTE3L2FpLWNhbi13cml0ZS1idXQtaXMtaXQtYW55LWdvb2QtYXQtcGlja2luZy1zdG9ja3MtcXVpY2t0YWtl0gEA?oc=5,Is Artificial Intelligence Any Good at Stock Picking? All About AI in Finance - Bloomberg,2023-07-16,Bloomberg,https://www.bloomberg.com,Financial firms are racing to integrate artificial intelligence into as many of their operations as they can. But investors continue to struggle to harness the technology to the business’s central goal: predicting price movements in a way that boosts profits. It’s a challenge that’s proving far tougher than enlisting computer algorithms to summarize research reports. Even those sure that AI will one day revolutionize stock-picking think getting there will come through a long series of small twea,"Artificial Intelligence,Stocks,Central Bankers,JPMORGAN CHASE & CO,Investing,Wall Street,Customer Service,Mutual Funds,Bonds,Jason Hsu,markets,technology,quicktake",Financial firms are racing to integrate artificial intelligence into as many of their operations as they can. But investors continue to struggle to harness the technology to the business’s central goal: predicting price movements in a way that boosts profits. It’s a challenge that’s proving far tougher than enlisting computer algorithms to summarize research reports. Even those sure that AI will one day revolutionize stock-picking think getting there will come through a long series of small twea,Financial firms are racing to integrate artificial intelligence into as many of their operations as they can. But investors continue to struggle to harness the technology to the business’s central goal: predicting price movements in a way that boosts profits. It’s a challenge that’s proving far tougher than enlisting computer algorithms to summarize research reports. Even those sure that AI will one day revolutionize stock-picking think getting there will come through a long series of small twea,http://schema.org,,NewsMediaOrganization,"[{'@type': 'Person', 'name': 'Justina Lee'}]",2023-07-17T06:30:00.002Z,Is Artificial Intelligence Any Good at Stock Picking? All About AI in Finance,"{'@type': 'Organization', 'name': 'Bloomberg', 'url': 'https://www.bloomberg.com', 'logo': {'@type': 'ImageObject', 'url': 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/bloomberg-logo-amp.bae0aa0a.png', 'width': 262, 'height': 60}}","['https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ikZKLsSJ6kaU/v1/1200x800.jpg', 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/social-default.cc6ae30e.jpg']",N/A,N/A,"MarketsQuicktakeAI Can Write, But Is It Any Good at Picking Stocks?FacebookTwitterLinkedInEmailLinkGiftFacebookTwitterLinkedInEmailLinkGiftGift this articleHave a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MOREFacebookTwitterLinkedInEmailLinkGiftBy Justina LeeJuly 17, 2023 at 2:30 AM EDTUpdated on  November 15, 2023 at 6:00 AM ESTBookmarkSaveLock This article is for subscribers only.Financial firms are racing to integrate artificial intelligence into as many of their operations as they can. But investors continue to struggle to harness the technology to the business’s central goal: predicting price movements in a way that boosts profits. It’s a challenge that’s proving far tougher than enlisting computer algorithms to summarize research reports. Even those sure that AI will one day revolutionize stock-picking think getting there will come through a long series of small tweaks and might initially produce a modest edge, though on Wall Street even a modest edge can mint billions.In all sorts of roles, including customer service and making trade execution more efficient. JPMorgan Chase Inc. says that it sees more than 300 use cases for AI across its operations. In terms of boosting investment returns, hopes largely rest on machine learning, the subfield of AI where computers are trained on massive amounts of data to perform particular tasks. Machine learning encompasses both generative AI — the content-creating power behind ChatGPT — and predictive AI, which uses past results to forecast future outcomes. All of this builds on so-called quantitative, or quant, investing, a decades-old approach in which money managers have used computers to crunch piles of numbers to develop formulas for picking securities.Have a confidential tip for our reporters? Get in TouchBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MORE",2023-11-15T11:00:00.000Z,,https://www.bloomberg.com,,Bloomberg,False,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Bloomberg', 'productID': 'bloomberg.com:basic'}",,https://www.bloomberg.com/news/articles/2023-07-17/ai-can-write-but-is-it-any-good-at-picking-stocks-quicktake,https://www.bloomberg.com/logo-bloomberg.svg,,,2023-07-17T06:30:00.002Z,"[{'@type': 'CollectionPage', 'name': 'Markets', 'url': 'https://www.bloomberg.com/markets'}]","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}","{'@type': 'PostalAddress', 'addressCountry': 'USA', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10022', 'streetAddress': '731 Lexington Avenue'}",https://www.bloomberg.com/diversity-inclusion,inquiry1@bloomberg.net,Bloomberg Finance L.P.,5493001KJTIIGC8Y1R12,(212) 318-2000,"[{'@type': 'Brand', 'name': 'Bloomberg markets', 'url': 'https://www.bloomberg.com/markets'}, {'@type': 'Brand', 'name': 'Bloomberg technology', 'url': 'https://www.bloomberg.com/technology'}, {'@type': 'Brand', 'name': 'Bloomberg pursuits', 'url': 'https://www.bloomberg.com/pursuits'}, {'@type': 'Brand', 'name': 'Bloomberg politics', 'url': 'https://www.bloomberg.com/politics'}, {'@type': 'Brand', 'name': 'Bloomberg opinion', 'url': 'https://www.bloomberg.com/opinion', 'logo': 'https://www.bloomberg.com/logo-bloomberg_opinion.svg'}, {'@type': 'Brand', 'name': 'Bloomberg businessweek', 'url': 'https://www.bloomberg.com/businessweek', 'logo': 'https://www.bloomberg.com/logo-bloomberg_businessweek.svg'}, {'@type': 'Brand', 'name': 'Bloomberg green', 'url': 'https://www.bloomberg.com/green'}, {'@type': 'Brand', 'name': 'Bloomberg equality', 'url': 'https://www.bloomberg.com/equality'}, {'@type': 'Brand', 'name': 'Bloomberg citylab', 'url': 'https://www.bloomberg.com/citylab'}, {'@type': 'Brand', 'name': 'Bloomberg crypto', 'url': 'https://www.bloomberg.com/crypto'}, {'@type': 'Brand', 'name': 'Bloomberg industries', 'url': 'https://www.bloomberg.com/industries'}, {'@type': 'Brand', 'name': 'Bloomberg economics', 'url': 'https://www.bloomberg.com/economics'}, {'@type': 'Brand', 'name': 'Bloomberg ai', 'url': 'https://www.bloomberg.com/ai'}, {'@type': 'Brand', 'name': 'Bloomberg wealth', 'url': 'https://www.bloomberg.com/wealth'}]",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vd3d3LmluZm9zZWN1cml0eS1tYWdhemluZS5jb20vbmV3cy9ldGhpY2FsLWhhY2tlcnMtZ2VuZXJhdGl2ZS1haS_SAQA?oc=5,Ethical Hackers Reveal How They Use Generative AI - Infosecurity Magazine,2023-07-12,Infosecurity Magazine,https://www.infosecurity-magazine.com,"Bugcrowd’s report finds that many ethical hackers are utilizing generative AI in their work, but 72% argue it will never replace human creativity",N/A,"Bugcrowd’s report finds that many ethical hackers are utilizing generative AI in their work, but 72% argue it will never replace human creativity","Bugcrowd’s report finds that many ethical hackers are utilizing generative AI in their work, but 72% argue it will never replace human creativity",https://schema.org,,NewsArticle,"{'@type': 'Person', 'name': 'James Coker', 'url': 'https://www.infosecurity-magazine.com/profile/james-coker/', 'familyName': 'Coker', 'givenName': 'James'}",2023-07-12T16:00:00+00:00,Ethical Hackers Reveal How They Use Generative AI,"{'@type': 'Organization', 'name': 'Infosecurity Magazine', 'sameAs': ['https://www.facebook.com/pages/Infosecurity-Magazine/210560332330063', 'https://x.com/InfosecurityMag', 'https://www.linkedin.com/company/infosecurity-magazine/'], 'url': 'https://www.infosecurity-magazine.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://www.infosecurity-magazine.com/_common/img/logo.png'}}","{'@type': 'ImageObject', 'url': 'https://assets.infosecurity-magazine.com/webpage/og/0118a111-92cb-4a32-b1fb-e8232ce960ef.jpg'}",N/A,N/A,N/A,2024-07-11T03:30:13.17+00:00,,https://www.infosecurity-magazine.com/news/ethical-hackers-generative-ai/,,Ethical Hackers Reveal How They Use Generative AI,,"Bugcrowd’s report finds that many ethical hackers are utilizing generative AI in their work, but 72% argue it will never replace human creativity",,,,,https://www.infosecurity-magazine.com/news/ethical-hackers-generative-ai/,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvam9lbWNrZW5kcmljay8yMDIzLzA3LzEzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW9wZW5zLXRocmVlLW5ldy1yb3V0ZXMtdG8tY2FyZWVyLWFkdmFuY2VtZW50L9IBAA?oc=5,Artificial Intelligence Opens Three New Routes To Career Advancement - Forbes,2023-07-13,Forbes,https://www.forbes.com,These are the ways today’s managers and professionals need to meet the challenges and opportunities of artificial intelligence head-on.,"AI,Artificial Intelligence Opens Three New Routes To Career Advancement,Artificial intelligence,career advancement",These are the ways today’s managers and professionals need to meet the challenges and opportunities of artificial intelligence head-on.,These are the ways today’s managers and professionals need to meet the challenges and opportunities of artificial intelligence head-on.,http://schema.org,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",BreadcrumbList,"{'@type': 'Person', 'name': 'Joe McKendrick', 'url': 'https://www.forbes.com/sites/joemckendrick/', 'description': 'I am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the 2023 AI Summit in New York, as well as the 2021 and 2022 Summits. I regularly contribute to Harvard Business Review on AI topics. My column on service orientation appears on CNET, covering topics shaping business and technology careers. I am also a co-author of the SOA Manifesto, which outlines the values and guiding principles of service orientation in business and IT. Much of my research work is in conjunction with Forbes Insights and Unisphere Research/ Information Today, Inc., covering topics such as artificial intelligence, cloud computing, digital transformation, and big data analytics. In a previous life, I served as communications and research manager of the Administrative Management Society (AMS), an international professional association dedicated to advancing knowledge within the IT and business management fields. I am a graduate of Temple University.', 'sameAs': ['https://www.twitter.com/joemckendrick', 'Joe McKendrick']}",2023-07-13T11:21:12-04:00,Artificial Intelligence Opens Three New Routes To Career Advancement,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/64066e2004e88f37218619bd/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",Enterprise Tech,N/A,"Edit StoryInnovationEnterprise TechArtificial Intelligence Opens Three New Routes To Career AdvancementJoe McKendrickSenior ContributorOpinions expressed by Forbes Contributors are their own.I track how technology innovations move markets and careersFollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itJul 13, 2023,11:21am EDTShare to FacebookShare to TwitterShare to LinkedinCareer advancement in the age of Ai: be creative, be awaregetty
Artificial intelligence is recasting career advancement opportunities in new and interesting ways. For technology professionals, it means getting more analytical. For business leaders, it means getting more creative.


There are three types of impacts AI will have on executive career opportunities:




AI may promise (or threaten) to reduce workforce sizes, but, at the same time, it is creating a huge demand for skilled professionals to design, build, maintain, and train AI models and associated data.
AI may assume many decision-making roles, but the organizations and individuals that will succeed are those who can apply AI to new business situations, create new markets, disrupt existing markets, and put the unprecedented insights that AI is capable of delivering the work for organizations and then world.
AI-infused organizations may be so highly automated they need few employees. But the cost of entry will be so low that small, nimble, entrepreneurial organizations that find new ways to deliver services via AI will flourish.



“Since new-age opportunities will be in the areas of machine learning, natural language processing, robotics, and artificial intelligence, technical professionals will need to redirect their careers towards data analysis and programming,” remarks Dharmesh Mistry, vice president and head of the technology market unit at Capgemini Americas. “At the same time, business-oriented professionals should redirect themselves towards creative problem-solving and critical thinking, which are areas where AI is yet to make significant advances.”
PROMOTED
History may be repeating itself ‘in that the jobs that will be lost due to these tech breakthroughs will be more than made up for by tech-forward roles, functions, and even entire departments that will exist in the coming years that don’t exist today,” says Adam Samples, president of staffing for Atrium. “Society will evolve. It already has. And the emerging generations are already showing clear signs of little to no interest in certain labor roles, food services and retail roles, and transactional administrative support roles. Employers are showing signs of no longer wanting to incur the cost and risk of employing people in these categories.”
In high demand will be “’bilingual’ leaders who can speak to both technical and business stakeholders,” says Bjorn Austraat, senior vice president and head of AI Acceleration at Truist: Such leaders and professionals need to be “fluent in ‘data science-ese’ and ‘executive-ese.’ An over-reliance on purely technical skills can lead to disjointed science experiments without a clear business return and an excessive focus on business outcomes — especially early on in sometimes lengthy data science and model ops lifecycles — can squelch disruptive innovation.”
MORE FROMFORBES ADVISORBest Travel Insurance CompaniesByAmy DaniseEditorBest Covid-19 Travel Insurance PlansByAmy DaniseEditor
What skillsets should executives and professionals emphasize as they move up the career ladder in the age of AI? The managerial or professional skills that will matter in the near future will include the following:









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            





Understand the basics of AI: “While executives don't need to understand the intricacies or the inner working of any AI programs that they are trying to embark on, they need to understand the basics,” says Andy Thurai, vice president and principal analyst with Constellation Research. For example, he outlines, “what capabilities does AI programs they are considering have? This will help them think about business use cases that they can solve and come up with ideas on how to solve some pain points and which areas they can use AI.”
Ramp up your critical thinking: In the age of AI, managers need to be adept at “analyzing information and evaluating arguments to make informed decisions,” Mistry says. “This skill is becoming more important as the amount of information available in the digital age increases. It has become a massive asset to be able to filter out relevant information from a sea of data. Moreover, although new forms of AI, such as ChatGPT, can generate answers quickly based on prompts, it often generates incorrect or outright false statements – hallucinations —and critical thinking will be required to parse the true from the false.”
Understand that AI is taking up the heavy lifting for low-level tasks: “Between AI and robotics, many of the mundane tasks — and quite frankly workplace functions that the modern generations find undesirable — have been and will continue to be automated into obscurity,” says Samples. “Transactional accounting, repeatable administrative support tasks, and legal support functions are just a few of many examples. I believe we will see the modern employment landscape transition from a balanced transactional and strategic workplace to a workplace that places more emphasis on strategic aspects.”
Focus on bringing out more of your creativity: “With automation taking over many routine and repetitive tasks, creativity will be an essential skill for managers to differentiate themselves in the job market,” says Mistry. “Moreover, AI can only build based on what it has been trained on, and therefore, can never truly be creative and generate truly novel ideas.”
Estimate the payback and measure the results: AI is no different than any other technology that has entered the business landscape, in that it needs to deliver tangible business gains. Ask if “AI can solve this specific problem better than the way it is done currently,” says Thurai. “Evaluate efficiency, cost, and skills needed. After all implementing and maintaining AI is not going to be easy. It must be proven worthy. Return on investment and total cost of ownership must be justified before it can be approved. This will also allow executives to invite the right solution to demonstrate their capabilities rather than just trying ChatGPT for everything.”


Not on this list, at least from a business professionals’ perspective, is a need for extremely deep technical knowledge of AI or any of its variations. ”Non-technical business professionals are not expected to know how to build or deploy AI apps,” says Mistry. “However, it is essential for these professionals to understand the fundamentals of AI, the potential applications of AI, the knowledge of how to build a business case around AI, and a basic understanding of the technicalities involved.”
Follow me on Twitter. Joe McKendrickFollowingFollowI am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the... Read MoreEditorial StandardsPrintReprints & Permissions",2023-10-05T13:20:17-04:00,,https://www.forbes.com/sites/joemckendrick/2023/07/13/artificial-intelligence-opens-three-new-routes-to-career-advancement/,Enterprise Tech,Artificial Intelligence Opens Three New Routes To Career Advancement,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LnpkbmV0LmNvbS9hcnRpY2xlL3RoaXMtaXMtaG93LWdlbmVyYXRpdmUtYWktd2lsbC1jaGFuZ2UtdGhlLWdpZy1lY29ub215LWZvci10aGUtYmV0dGVyL9IBAA?oc=5,This is how generative AI will change the gig economy for the better - ZDNet,2023-07-15,ZDNet,https://www.zdnet.com,"Generative AI is transforming the way we work, but fears that it will destroy the economy are overblown.",N/A,"Generative AI is transforming the way we work, but fears that it will destroy the economy are overblown.","Generative AI is transforming the way we work, but fears that it will destroy the economy are overblown.",,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vYWNjZWxlcmF0aW9uZWNvbm9teS5jb20vYWkvaG93LXRvLXVuZGVyc3RhbmQtbWFuYWdlLXRva2VuLWJhc2VkLXByaWNpbmctb2YtZ2VuZXJhdGl2ZS1haS1sYXJnZS1sYW5ndWFnZS1tb2RlbC1jb3N0cy_SAQA?oc=5,"How To Understand, Manage Token-Based Pricing of Generative AI Large Language Models - Acceleration Economy",2023-07-12,Acceleration Economy,https://accelerationeconomy.com,"For businesses to minimize the costs of language models, they must understand token-based pricing and evaluate multiple providers.",N/A,"For businesses to minimize the costs of language models, they must understand token-based pricing and compare providers such as OpenAI and Anthropic.","For businesses to minimize the costs of language models, they must understand token-based pricing and compare providers such as OpenAI and Anthropic.",http://schema.org,,Article,"{'@type': 'Person', 'name': 'Toni Witt'}",2023-07-12T07:00:00-04:00,"How To Understand, Manage Token-Based Pricing of Generative AI Large Language Models","{'@type': 'Organization', 'name': 'Acceleration Economy', 'sameAs': 'https://accelerationeconomy.com', 'logo': {'@type': 'ImageObject', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2024/03/AE-cloud-wars-logo.png'}}","{'@type': 'ImageObject', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2023/06/Token-Based-Pricing-of-Language-Models.jpg', 'width': 1200, 'height': 675}",N/A,N/A,"    Share    Facebook    Twitter    LinkedIn    Email        The Acceleration Economy practitioner analyst team recently has received feedback from buyers that they have confusion regarding the token-based pricing schema of language models. In this analysis, I lay out a brief overview of that schema so that you can make more informed decisions in an age where large language models (LLMs) are becoming ubiquitous and necessary elements of products or operations. Ultimately, base-level models, whether LLMs like GPT-4 or image generators like DALL-E-2, are priced by computational consumption, just like most cloud services. The biggest difference is the unit of measurement. Before diving into prices there are a few key terms to know:      Tokens are basic units of text or code that LLMs use to process and generate language. These can be individual characters, parts of words, words, or parts of sentences. These tokens are then assigned numbers which, in turn, are put into a vector that becomes the actual input to the first neural network of the LLM. How the tokens look depends on your tokenization scheme. As a rule of thumb, however, 1,000 tokens is about 750 words in English.Tokenization is the act of splitting larger input or output texts into smaller units for LLMs to ‘digest.’ OpenAI and Azure OpenAI use a tokenization scheme called ‘Byte-Pair Encoding’ that merges the most frequently occurring pairs of characters or bytes into a single token.A prompt is the text instruction you give to a model.Completion means the response of the model. With any generative AI model, there is always a tradeoff between computational load and performance. Best-in-class models like GPT-4 are extremely powerful but require much more computation than simple models. This is, in part, due to the different tokenization schemes.  Which companies are the most important vendors in AI and hyperautomation? Check out the Acceleration Economy AI/Hyperautomation Top 10 Shortlist.  Case Study: Breaking Down Anthropic’s LLM Pricing The prices of different models vary greatly. Below is a screenshot from Anthropic, a competitor of OpenAI: Source: https://www.anthropic.com/product In this example, Anthropic has two different LLMs, Claude Instant and Claude-v1. Their price differs by nearly 10 times, which underscores the point that you need to be very selective about where each model is applied. The best way to see if a model meets your needs is to try it in a test environment first. In the table, you also see a column for ‘Context Window.’ This indicates how long your prompt can be, measured in tokens. 100,000 tokens equate to about 75,000 words, which is equivalent to a full-length novel. ChatGPT and GPT-3.5 have a context of only a few thousand tokens, a ceiling you will quickly bump into if you copy and paste long texts into the prompting bar. One version of GPT-4, called gpt-4-32k, supports up to 32,768 tokens. This is very high for a model that also has great performance — a combination that makes GPT-4 one of the most expensive options. You will also notice that Anthropic charges per Prompt and per Completion. This means for every interaction with an LLM, you will be charged for the length of the input you give as well as the length of the output. This is because computation must be done to convert your natural language input into a vector format that an LLM can understand, then run the input through the neural network itself to receive an output.  This double charge is very common across LLM providers, and it’s worth noting that the Prompt charge is always less than the Completion charge. This is because more computation goes into completion than in preparing the prompt for completion. Case Study: Microsoft OpenAI Service Pricing Breakdown With Microsoft’s OpenAI Services, you can use OpenAI’s models, including DALL-E and the GPT-n series, right within Azure. Note: ChatGPT and ChatGPT Plus have very different pricing structures; the numbers in this section are for direct API calls. You will also notice a table for standard vs fine-tuned models. Fine-tuned models are custom-trained models, in which you influence the model’s behavior by training it with your own dataset. Fine-tuned models are priced by hour deployed as well as by tokens: Source: https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/ All in all, the pricing structure of Azure OpenAI Services is very similar to the rest of the Azure services. Before its partnership with OpenAI, Microsoft also started offering its Cognitive Language Services — things like sentiment analysis, summarization, and more — which are priced in chunks of 1,000 characters and model training priced by the hour. Other cognitive services like computer vision are priced by ‘transaction’ which is, in almost all cases, the same as an API call. Another enterprise-friendly LLM provider to check out is Cohere, which recently announced a partnership with Oracle. For its text generation tool, Cohere charges $15 for 1 million tokens. For reference, the model behind ChatGPT, gpt-35-turbo, costs around $2 for 1 million tokens. However, Cohere has more offerings around enterprise security, flexibility, and privacy that might justify this cost. Guidebook: The Ethical & Workforce Impacts of Generative AI Cost Minimization You can do a number of things to minimize the cost you incur from LLM providers: Use cost management tools like Microsoft Cost ManagementChoose the right model. Unfortunately, this requires some trial and error, which is worth doing before putting a model into production and incurring high costs for performance that isn’t needed for your use case. Again, costs vary greatly. Gpt-35-turbo is 10 times less expensive than GPT-4, and (in most cases) just as good.Reduce the prompt length. Providers will charge based on the length of your prompt and the output.Limit maximum response length in your prompt itself.Consolidate prompts by combining information with questions and requests, in order to reduce the prompt length and number of outputs required.Consider using prompt management software or token cost tracking software. Final Thoughts This analysis should increase clarity around LLM pricing. The field of generative AI is still very new, and pricing is bound to change in the future. The main point to emphasize is the need to get hands-on with different models and different providers before jumping into production, to not only select the right model to minimize the cost but also to understand how your business will be charged for your unique use case. Different providers also have different strengths. OpenAI’s partnership with Microsoft brings it right into Azure. Anthropic places more value on AI safety and ethics. Cohere’s products are designed for the enterprise. It also seems like a new AI startup is coming out every day. All in all, it’s important for companies considering building AI products or embedding AI into their offering to look at multiple providers — including startups — to better manage cost but also make sure organizational values are aligned with your provider.  For more insights, visit the ai ecosystem channel          Artificial Intelligence featured natural language processing ",2023-07-12T06:46:09-04:00,"[{'@type': 'Article', '@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/#article', 'isPartOf': {'@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/'}, 'author': {'name': 'Toni Witt', '@id': 'https://accelerationeconomy.com/#/schema/person/4ffd402f98e6123fad6b86e0bb4bae4e'}, 'headline': 'How To Understand, Manage Token-Based Pricing of Generative AI Large Language Models', 'datePublished': '2023-07-12T11:00:00+00:00', 'dateModified': '2023-07-12T10:46:09+00:00', 'mainEntityOfPage': {'@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/'}, 'wordCount': 1123, 'publisher': {'@id': 'https://accelerationeconomy.com/#organization'}, 'image': {'@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/#primaryimage'}, 'thumbnailUrl': 'https://accelerationeconomy.com/wp-content/uploads/2023/06/Token-Based-Pricing-of-Language-Models.jpg', 'keywords': ['Artificial Intelligence', 'featured', 'natural language processing'], 'articleSection': ['AI Ecosystem', 'Digital Business', 'Generative AI'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/', 'url': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/', 'name': 'How To Understand, Manage Token-Based Pricing of Generative AI Large Language Models', 'isPartOf': {'@id': 'https://accelerationeconomy.com/#website'}, 'primaryImageOfPage': {'@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/#primaryimage'}, 'image': {'@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/#primaryimage'}, 'thumbnailUrl': 'https://accelerationeconomy.com/wp-content/uploads/2023/06/Token-Based-Pricing-of-Language-Models.jpg', 'datePublished': '2023-07-12T11:00:00+00:00', 'dateModified': '2023-07-12T10:46:09+00:00', 'description': 'For businesses to minimize the costs of language models, they must understand token-based pricing and evaluate multiple providers.', 'breadcrumb': {'@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/#primaryimage', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2023/06/Token-Based-Pricing-of-Language-Models.jpg', 'contentUrl': 'https://accelerationeconomy.com/wp-content/uploads/2023/06/Token-Based-Pricing-of-Language-Models.jpg', 'width': 1200, 'height': 675, 'caption': 'Token-Based Pricing of Language Models'}, {'@type': 'BreadcrumbList', '@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://accelerationeconomy.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How To Understand, Manage Token-Based Pricing of Generative AI Large Language Models'}]}, {'@type': 'WebSite', '@id': 'https://accelerationeconomy.com/#website', 'url': 'https://accelerationeconomy.com/', 'name': 'Acceleration Economy', 'description': 'Acceleration Economy', 'publisher': {'@id': 'https://accelerationeconomy.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://accelerationeconomy.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://accelerationeconomy.com/#organization', 'name': 'Acceleration Economy', 'url': 'https://accelerationeconomy.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://accelerationeconomy.com/#/schema/logo/image/', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2023/03/AE-Practitioner-Analysts-Retina.png', 'contentUrl': 'https://accelerationeconomy.com/wp-content/uploads/2023/03/AE-Practitioner-Analysts-Retina.png', 'width': 350, 'height': 112, 'caption': 'Acceleration Economy'}, 'image': {'@id': 'https://accelerationeconomy.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://accelerationeconomy.com/#/schema/person/4ffd402f98e6123fad6b86e0bb4bae4e', 'name': 'Toni Witt', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://accelerationeconomy.com/#/schema/person/image/', 'url': 'https://accelerationeconomy.com/wp-content/uploads/2022/11/Toni-Witt-150x150.png', 'contentUrl': 'https://accelerationeconomy.com/wp-content/uploads/2022/11/Toni-Witt-150x150.png', 'caption': 'Toni Witt'}, 'description': 'Besides keeping up with the latest in AI and corporate innovation, Toni Witt co-founded Sweet, a startup redefining hospitality through zero-fee payments infrastructure. He also runs a nonprofit community of young entrepreneurs, influencers, and change-makers called GENESIS.', 'sameAs': ['https://verysweet.co/', 'https://www.linkedin.com/in/toni-witt-135123213/'], 'url': 'https://accelerationeconomy.com/author/toni-witt/'}]",https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/,,,,,,,,,"{'@type': 'WebPage', '@id': 'https://accelerationeconomy.com/ai/how-to-understand-manage-token-based-pricing-of-generative-ai-large-language-model-costs/'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihQFodHRwczovL3d3dy50ZWxlY29tcmV2aWV3YXNpYS5jb20vbmV3cy9mZWF0dXJlZC1hcnRpY2xlcy8zNDQxLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLWFzaWEtY2FuLWFpLXRocmVhdGVuLWpvYnMtaW4tYXNlYW4tY291bnRyaWVz0gEA?oc=5,Artificial Intelligence in Asia: Can AI Threaten Jobs in ASEAN Countri - Telecom Review Asia,2023-07-14,Telecom Review Asia,https://www.telecomreviewasia.com,"Artificial intelligence (AI) can facilitate the abilities of machines, digital computers or computer-controlled robots to perform different tasks","Asia, ASEAN, AI, artificial intelligence, job layoff","Artificial intelligence (AI) can facilitate the abilities of machines, digital computers or computer-controlled robots to perform different tasks","Artificial intelligence (AI) can facilitate the abilities of machines, digital computers or computer-controlled robots to perform different tasks that have traditionally required human intelligence. A",,,,,,,,,N/A,N/A,"






				Artificial Intelligence in Asia: Can AI Threaten Jobs in ASEAN Countries?





													Details							




					14 July 2023          





















Previous Article
Telcos in Q1 2023: 5G Deployments Continued to Increase CAPEX for Leading Performers





Next Article
Unleashing the Future: Endless Possibilities With 5G Advanced







Tools


 Print 
 Email 




Typography




Smaller
Small
Medium
Big
Bigger






Default
Helvetica
Segoe
Georgia
Times




 Reading Mode




Share This






Artificial intelligence (AI) can facilitate the abilities of machines, digital computers or computer-controlled robots to perform different tasks that have traditionally required human intelligence. AI allows machines to represent or improve the capabilities of human minds. It can also include natural language processing, speech recognition, machine learning, robotics, deep learning, expert systems and more.


The attention around AI has accelerated as many business owners, entrepreneurs and technology experts have welcomed and embraced the technology. AI enables an organization to function effectively and accurately with little to no actual human supervision. The technology is currently being used in certain businesses to automate tasks such as customer service work, lead generation, quality control, content writing and fraud detection.
Many believe that AI can perform many assignments more proficiently than humans. When it comes to repetitive tasks, AI tools often finish jobs quickly and with fewer errors. Due to the extensive data sets it can process, AI can also provide insights to enterprises regarding operations or functions they might not have been aware of.
According to a Statista survey conducted in 2020 regarding the use of artificial intelligence technology in businesses in Asia Pacific, 62% of respondents said that in 2019, AI was most actively used in IT management in their respective businesses. Further, 11%, the lowest, said that AI technology was being used for legal and compliance purposes in their businesses.
Will AI Cause Job Layoffs in Asia?
A previous study titled ""Technology and the Future of ASEAN Jobs,"" conducted by Cisco and Oxford Economics, examined the effects of AI on workers in the Association of Southeast Asian Nations (ASEAN) six largest economies.
""Over the next decade, innovations in digital technology will present vast opportunities to ASEAN economies to boost their productivity and prosperity. The more widespread adoption of existing technologies, coupled with advances in the use of artificial intelligence (AI) through software, hardware and robotics, has the potential to transform business capabilities,"" the study explained.
""As a youthful region (half the 630 million inhabitants are aged under 30) with an internationally competitive manufacturing sector and innovative enterprises, ASEAN is poised to take advantage. However, digital transformation will also mean that many of the region's workers face considerable upheaval.""
The research model concluded that, by 2028, 28 million fewer workers across these economies will be required to provide the same level of output as today. ""This constitutes substantial productivity gains from more widespread technology adoption, which will drive growth and create new demands for workers.""
The study also noted that the overall job landscape will look different. For about 6.6 million workers across the ASEAN-6 region, the new technology scenario will render their job roles redundant. To be specific, the agriculture sector will be the primary source of these redundancies. Overall, the research found that there will be 5.7 million net fewer FTE workers in the agriculture sector by 2028 across the six economies.
Current Global Job Reductions 
Online marketplace Carousell announced that it was reducing its team to about 10% of its headcount — approximately 110 positions. In November, Indonesia’s GoTo Group — a merger between ride-hailing giant Gojek and e-commerce marketplace Tokopedia — cut a total of 1,300 jobs, or about 12% of its headcount. Both companies stated challenging macroeconomic conditions as the reason for such reductions.
According to Crunchbase data, the launch of ChatGPT on the last day of November punctuated what was, at the time, the largest layoff month of 2022. As an aside, funding for AI startups constituted almost 10% of global startup funding.
In May 2023, United States-based employers confirmed 80,089 job cuts, a 20% increase from the 66,995 just one month prior. This May figure also stands at 287% higher than the 20,712 cuts announced in the same month of 2022, according to the global firm Challenger, Gray & Christmas, Inc.
Google's parent company, Alphabet, also caused a stir after cutting approximately 12,000 people from its workforce. The CEO of Google and Alphabet, Sundar Pichai, emailed Google employees regarding the layoff, saying that he took ""full responsibility"" for the decisions.
""I am confident about the huge opportunity in front of us thanks to the strength of our mission, the value of our products and services, and our early investments in AI. To fully capture it, we'll need to make tough choices. So, we've undertaken a rigorous review across product areas and functions to ensure that our people and roles are aligned with our highest priorities as a company. The roles we're eliminating reflect the outcome of that review,"" he explained.
AI is continuously evolving, and its new uses are being discovered every day. Many are firmly convinced that AI can be used to solve many of the world's most pressing problems. From curing diseases to creating efficient transportation systems and providing better access to the internet and education, the potential of AI is immense. This technology has the capability to revolutionize many aspects of society as well as create all-new industries that can provide solutions for various industry problems. How this will affect the traditional employment landscape is yet to be fully seen.











Share

Save


Whatsapp




						Asia					



						ASEAN					



						artificial intelligence					



						AI					



						job layoff					










Previous Article
Telcos in Q1 2023: 5G Deployments Continued to Increase CAPEX for Leading Performers





Next Article
Unleashing the Future: Endless Possibilities With 5G Advanced




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy5ldXJvbmV3cy5jb20vbmV4dC8yMDIzLzA3LzEzL2hpZ2hseS1za2lsbGVkLW9jY3VwYXRpb25zLXN1Y2gtYXMtbWVkaWNpbmUtbGF3LWFuZC1maW5hbmNlLW1heS1iZS1hdC1yaXNrLW9mLWFpLWF1dG9tYXRpb9IBAA?oc=5,"Highly skilled occupations such as medicine, law and finance 'may be at risk of automation from AI' - Euronews",2023-07-13,Euronews,https://www.euronews.com,The OECD has recently announced that 27 per cent of jobs in major countries rely on skills that could be easily automated amid the AI revolution.,"Technology,AI,job loss,Artificial intelligence,ChatGPT,New technologies",The OECD has recently announced that 27 per cent of jobs in major countries rely on skills that could be easily automated amid the AI revolution.,The OECD has recently announced that 27 per cent of jobs in major countries rely on skills that could be easily automated amid the AI revolution.,https://schema.org,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.euronews.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Next', 'item': 'https://www.euronews.com/next'}, {'@type': 'ListItem', 'position': 3, 'name': 'Tech&#x20;News', 'item': 'https://www.euronews.com/next/tech-news'}, {'@type': 'ListItem', 'position': 4, 'name': ""Google's AI chatbot Bard expands to Europe to take on ChatGPT""}]",BreadcrumbList,,,,,,N/A,N/A,"
                Now playing
                
              Next
          
                          Europe News
                        
                                                    
                              Borrell accuses Orbán of disloyalty, joins boycott against presidency
                          ",,"[{'@type': 'NewsArticle', 'mainEntityOfPage': {'@type': 'Webpage', 'url': 'https://www.euronews.com/next/2023/07/13/highly-skilled-occupations-such-as-medicine-law-and-finance-may-be-at-risk-of-ai-automatio'}, 'headline': 'Highly skilled occupations such as medicine, law and finance ‘may be at risk of automation from AI’', 'description': 'The OECD has recently announced that 27 per cent of jobs in major countries rely on skills that could be easily automated amid the AI revolution.', 'articleBody': 'A major report into artificial intelligence (AI) and employment has found 27 per cent of jobs could be at high risk of automation amid the AI revolution. The Organisation for Economic Co-operation and Development’s (OECD) report also suggests it is highly skilled occupations that could be more at risk. “While firms’ adoption of AI is still relatively low, rapid progress including with generative AI (e.g. ChatGPT), falling costs and the increasing availability of workers with AI skills suggest that OECD countries may be on the brink of an AI revolution,” the organisation’s  2023 Employment Outlook  said. The OECD is a 38-member bloc that includes mostly wealthy countries such as the UK, Japan, Germany, the US, Australia and Canada. According to the OECD, AI is expected to have the most impact on highly skilled jobs in fields such as medicine, law and finance, which may lead to major disruptions in the job market. “Occupations in finance, medicine and legal activities which often require many years of education, and whose core functions rely on accumulated experience to reach decisions, may suddenly find themselves at risk of automation from AI,”  said  the OECD. A survey, which was conducted back in 2022 by the OECD, covered different reactions from workers amidst AI emergence in the job market. The survey included 5,300 workers in 2,000 companies in the fields of manufacturing and finance within seven of the 38 OECD countries. The results showed that three out of five of the workers fear that they could lose their job to AI over the next 10 years. Interestingly, despite the fear of job displacement, the survey also indicates that 63 per cent of workers who have integrated AI into their daily tasks reported increased satisfaction and enjoyment in their jobs. Additionally, a majority of workers using AI reported improved job performance along with a positive impact on their mental health. However, the Paris-based organisation emphasised that “urgent action” is needed to prepare for the emergence of AI in the workplace. “These rapid developments, combined with the falling costs of producing and adopting these new technologies, suggest that OECD economies may be on the cusp of an AI revolution which could fundamentally change the workplace,” the OECD said. The OECD also highlighted the importance of closely monitoring data regarding AI implementation in the workplace and gaining a better understanding of how it is expected to change, create, or eliminate jobs. ', 'dateCreated': '2023-07-13 13:19:48 +02:00', 'dateModified': '2023-07-24 12:23:40 +02:00', 'datePublished': '2023-07-13 13:32:27 +02:00', 'image': {'@type': 'ImageObject', 'url': 'https://static.euronews.com/articles/stories/07/74/91/10/1440x810_cmsv2_c2daf780-733c-58d2-8008-af28186d60ed-7749110.jpg', 'width': '1440px', 'height': '810px', 'caption': 'AI revolution: More than a quarter of jobs at high risk, says OECD', 'thumbnail': 'https://static.euronews.com/articles/stories/07/74/91/10/385x202_cmsv2_c2daf780-733c-58d2-8008-af28186d60ed-7749110.jpg', 'publisher': {'@type': 'Organization', 'name': 'euronews', 'url': 'https://static.euronews.com/website/images/euronews-logo-main-blue-403x60.png'}}, 'author': {'@type': 'Person', 'name': 'Imane El Atillah', 'url': 'el-atillah', 'sameAs': 'https://twitter.com/euronews'}, 'publisher': {'@type': 'Organization', 'name': 'Euronews', 'legalName': 'Euronews', 'url': 'https://www.euronews.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://static.euronews.com/website/images/euronews-logo-main-blue-403x60.png', 'width': '403px', 'height': '60px'}, 'sameAs': ['https://www.facebook.com/euronews', 'https://twitter.com/euronews', 'https://flipboard.com/@euronews', 'https://www.instagram.com/euronews.tv/', 'https://www.linkedin.com/company/euronews']}, 'isAccessibleForFree': 'False', 'hasPart': {'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.poool-content'}, 'speakable': {'@type': 'SpeakableSpecification', 'xPath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""], 'url': 'https://www.euronews.com/next/2023/07/13/highly-skilled-occupations-such-as-medicine-law-and-finance-may-be-at-risk-of-ai-automatio'}}, {'@type': 'WebSite', 'name': 'Euronews.com', 'url': 'https://www.euronews.com/', 'potentialAction': {'@type': 'SearchAction', 'target': 'https://www.euronews.com/search?query={search_term_string}', 'query-input': 'required name=search_term_string'}, 'sameAs': ['https://www.facebook.com/euronews', 'https://twitter.com/euronews', 'https://flipboard.com/@euronews', 'https://www.instagram.com/euronews.tv/', 'https://www.linkedin.com/company/euronews']}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS90ZWNobm9sb2d5LzIwMjMvMDcvMTYvYWktcHJvZ3JhbXMtdHJhaW5pbmctbGF3c3VpdHMtZmFpci11c2Uv0gEA?oc=5,"AI learned from social media, books and more. Now it faces lawsuits. - The Washington Post",2023-07-16,The Washington Post,https://www.washingtonpost.com,"Authors, artists and publishers are suing tech companies that used copyrighted works to train their artificial intelligence programs.",N/A,"Authors, artists and publishers are suing tech companies that used copyrighted works to train their artificial intelligence programs.","Authors, artists and publishers are suing tech companies that used copyrighted works to train their artificial intelligence programs.",https://schema.org,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}]",BreadcrumbList,"{'@type': 'Person', 'name': 'Gerrit De Vynck', 'url': 'https://www.washingtonpost.com/people/gerrit-de-vynck/'}",2023-07-16T11:00:39.126Z,AI learned from their work. Now they want compensation.,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/2TDRCCUGARDHFXMZLG2WEJ35GY_size-normalized.JPG&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/2TDRCCUGARDHFXMZLG2WEJ35GY_size-normalized.JPG&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/2TDRCCUGARDHFXMZLG2WEJ35GY_size-normalized.JPG&w=800&h=600', 'height': 800, 'width': 600}]",Technology,N/A,"Witnesses are sworn in at a Senate subcommittee hearing on issues of artificial intelligence, intellectual property and copyright in Washington on Wednesday. (Shuran Huang for The Washington Post) By  Gerrit De VynckJuly 16, 2023 at 7:00 a.m. EDTSAN FRANCISCO — An increasingly vocal group of artists, writers and filmmakers are arguing that artificial intelligence tools like chatbots ChatGPT and Bard were illegally trained on their work without permission or compensation — posing a major legal threat to the companies pushing the tech out to millions of people around the world.Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeOpenAI’s ChatGPT and image-generator Dall-E, as well as Google’s Bard and Stability AI’s Stable Diffusion, were all trained on billions of news articles, books, images, videos and blog posts scraped from the internet, much of which is copyrighted.This past week, comedian Sarah Silverman filed a lawsuit against OpenAI and Facebook parent company Meta, alleging they used a pirated copy of her book in training data because the companies’ chatbots can summarize her book accurately. Novelists Mona Awad and Paul Tremblay filed a similar lawsuit against OpenAI. And more than 5,000 authors, including Jodi Picoult, Margaret Atwood and Viet Thanh Nguyen, have signed a petition asking tech companies to get consent from and give credit and compensation to writers whose books were used in training data.AdvertisementStory continues below advertisementTwo class-action lawsuits were filed against OpenAI and Google, both alleging the companies violated the rights of millions of internet users by using their social media comments to train conversational AIs. And the Federal Trade Commission opened an investigation into whether OpenAI violated consumer rights with its data practices.💻Follow TechnologyFollowMeanwhile, Congress held the second of two hearings focusing on AI and copyright Wednesday, hearing from representatives of the music industry, Photoshop maker Adobe, Stability AI and concept artist and illustrator Karla Ortiz.GET CAUGHT UPStories to keep you informedPreviousNextAppeals court blocks Biden’s student loan repayment planSparkleSummary is AI-generated, newsroom-reviewed.The Persian Gulf is enduring life-threatening heat indexes above 140 degreesSparkleSummary is AI-generated, newsroom-reviewed.Paul Hollywood is right: Don’t refrigerate breadSparkleSummary is AI-generated, newsroom-reviewed.Bob Newhart, who went from standup comedy to sitcom star, dies at 94SparkleSummary is AI-generated, newsroom-reviewed.Social anxiety can be limiting. There are ways to get relief.SparkleSummary is AI-generated, newsroom-reviewed.“These AI companies use our work as training data and raw materials for their AI models without consent, credit, or compensation,” Ortiz, who has worked on movies such as “Black Panther” and “Guardians of the Galaxy” said in prepared remarks. “No other tool solely relies on the works of others to generate imagery. Not Photoshop, not 3D, not the camera, nothing comes close to this technology.”AdvertisementStory continues below advertisementThe wave of lawsuits, high-profile complaints and proposed regulation could pose the biggest barrier yet to the adoption of “generative” AI tools, which have gripped the tech world since OpenAI launched ChatGPT to the public late last year and spurred executives from Microsoft, Google and other tech giants to declare the tech is the most important innovation since the advent of the mobile phone.Scrolling through social media can be addictive in similar ways to cocaine or alcohol. And it’s contributing to a growing mental health crisis among youths. (Video: Luis  Velarde, Brian Monroe/The Washington Post)Artists say the livelihoods of millions of creative workers are at stake, especially because AI tools are already being used to replace some human-made work. Mass scraping of art, writing and movies from the web for AI training is a practice creators say they never considered or consented to.But in public appearances and in responses to lawsuits, the AI companies have argued that the use of copyrighted works to train AI falls under fair use — a concept in copyright law that creates an exception if the material is changed in a “transformative” way.“The AI models are basically learning from all of the information that’s out there. It’s akin to a student going and reading books in a library and then learning how to write and read,” Kent Walker, Google’s president of global affairs, said in an interview Friday. “At the same time you have to make sure that you’re not reproducing other people’s works and doing things that would be violations of copyright.”The movement of creators asking for more consent over how their copyrighted content is used is part of a larger movement as AI shifts long-standing ground rules and norms for the internet. For years, websites have been happy to have Google and other tech giants scrape their data for the purpose of helping them show up in search results or access digital advertising networks, both of which helped them make money or get in front of new customers.AdvertisementStory continues below advertisementThere are some precedents that could work in the tech companies’ favor, like a 1992 U.S. Appeals Court ruling that allowed companies to reverse engineer other firms’ software code to design competing products, said Andres Sawicki, a law professor at the University of Miami who studies intellectual property. But many people say there’s an intuitive unfairness to huge, wealthy companies using the work of creators to make new moneymaking tools without compensating anyone.“The generative AI question is really hard,” he said.The battle over who will benefit from AI is already getting contentious.In Hollywood, AI has become a flash point for writers and actors who have recently gone on strike. Studio executives want to preserve the right to use AI to come up with ideas, write scripts and even replicate the voices and images of actors. Workers see AI as an existential threat to their livelihoods.AdvertisementStory continues below advertisementThe content creators are finding allies among major social media companies, which have also seen the comments and discussions on their sites scraped and used to teach AI bots how human conversation works.On Friday, Twitter owner Elon Musk said the website was contending with companies and organizations “illegally” scraping his site constantly, to the point where he decided to limit the number of tweets individual accounts could look at in an attempt to stop the mass scraping.“We had multiple entities trying to scrape every tweet ever made,” Musk said.Other social networks, including Reddit, have tried to stop content from their sites from being collected as well, by beginning to charge millions of dollars to use their application programing interfaces or APIs — the technical gateways through which other apps and computer programs interact with social networks.AdvertisementStory continues below advertisementSome companies are being proactive in signing deals with AI companies to license their content for a fee. On Thursday, the Associated Press agreed to license its archive of news stories going back to 1985 to OpenAI. The news organization will get access to OpenAI’s tech to experiment with using it in its own work as part of the deal.A June statement released by Digital Content Next, a trade group that includes the New York Times and The Washington Post among other online publishers, said that the use of copyrighted news articles in AI training data would “likely be found to go far beyond the scope of fair use as set forth in the copyright act.”“Creative professionals around the world use ChatGPT as a part of their creative process, and we have actively sought their feedback on our tools from day one,” said Niko Felix, a spokesman for OpenAI. “ChatGPT is trained on licensed content, publicly available content, and content created by human AI trainers and users.”AdvertisementStory continues below advertisementSpokespeople for Facebook and Microsoft declined to comment. A spokesperson for Stability AI did not return a request for comment.“We’ve been clear for years that we use data from public sources — like information published to the open web and public data sets — to train the AI models behind services like Google Translate,” said Google General Counsel Halimah DeLaine Prado. “American law supports using public information to create new beneficial uses, and we look forward to refuting these baseless claims.”Fair use is a strong defense for AI companies, because most outputs from AI models do not explicitly resemble the work of specific humans, Sawicki, the copyright law professor, said. But if creators suing the AI companies can show enough examples of AI outputs that are very similar to their own works, they will have a solid argument that their copyright is being violated, he said.AdvertisementStory continues below advertisementCompanies could avoid that by building filters into their bots to make sure they don’t spit out anything that is too similar to an existing piece of art, Sawicki said. YouTube, for example, already uses technology to detect when copyrighted works are uploaded to its site and automatically take it down. In theory, AI companies could build algorithms that could spot outputs that are highly similar to existing art, music or writing.The computer science techniques that enable modern-day “generative” AI have been theorized for decades, but it wasn’t until Big Tech companies such as Google, Facebook and Microsoft combined their massive data centers of powerful computers with the huge amounts of data they had collected from the open internet that the bots began to show impressive capabilities.By crunching through billions of sentences and captioned images, the companies have created “large language models” able to predict what the logical thing to say or draw in response to any prompt is, based on their understanding of all the writing and images they’ve ingested.AdvertisementStory continues below advertisementIn the future, AI companies will use more curated and controlled data sets to train their AI models, and the practice of throwing heaps of unfiltered data scraped from the open internet will be looked back on as “archaic,” said Margaret Mitchell, chief ethics scientist at AI start-up Hugging Face. Beyond the copyright problems, using open web data also introduces potential biases into the chatbots.“It’s such a silly approach and an unscientific approach, not to mention an approach that hits on people’s rights,” Mitchell said. “The whole system of data collection needs to change, and it’s unfortunate that it needs to change via lawsuits, but that is often how tech operates.”Mitchell said she wouldn’t be surprised if OpenAI has to delete one of its models completely by the end of the year because of lawsuits or new regulation.OpenAI, Google and Microsoft do not release information on what data they use to train their models, saying that it could allow bad actors to replicate their work and use the AIs for malicious purposes.A Post analysis of an older version of OpenAI’s main language-learning model showed that the company had used data from news sites, Wikipedia and a notorious database of pirated books that has since been seized by the Department of Justice.Not knowing what exactly goes into the models makes it even harder for artists and writers to get compensation for their work, Ortiz, the illustrator, said during the Senate hearing.“We need to ensure there’s clear transparency,” Ortiz said. “That is one of the starting foundations for artists and other individuals to be able to gain consent, credit and compensation.”Share394 CommentsArtificial-IntelligenceHAND CURATEDThese four searches show how Google is changing with AI and shoppingMay 14, 2024These four searches show how Google is changing with AI and shoppingMay 14, 2024How the authoritarian Middle East became the capital of Silicon ValleyMay 14, 2024How the authoritarian Middle East became the capital of Silicon ValleyMay 14, 2024Web publishers brace for carnage as Google adds AI answersMay 13, 2024Web publishers brace for carnage as Google adds AI answersMay 13, 2024View 3 more storiesNewsletterAs news breaksTech News AlertsBreaking news email alerts on technology and the tech industry.Sign upSubscribe to comment and get the full experience. Choose your plan →",2023-07-17T14:46:56.626Z,,,,,False,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}","AI learned from social media, books and more. Now it faces lawsuits.",https://www.washingtonpost.com/technology/2023/07/16/ai-programs-training-lawsuits-fair-use/,,,,,,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vdGhlY29udmVyc2F0aW9uLmNvbS9haS1zY2FtLWNhbGxzLWltaXRhdGluZy1mYW1pbGlhci12b2ljZXMtYXJlLWEtZ3Jvd2luZy1wcm9ibGVtLWhlcmVzLWhvdy10aGV5LXdvcmstMjA4MjIx0gEA?oc=5,AI scam calls imitating familiar voices are a growing problem – here's how they work - The Conversation,2023-07-12,The Conversation,https://theconversation.com,AI can generate a synthetic voice that sounds just like a loved one.,N/A,AI can generate a synthetic voice that sounds just like a loved one.,N/A,,,,,,,,,N/A,N/A,"






Antonio Guillem/Shutterstock









            AI scam calls imitating familiar voices are a growing problem – here’s how they work
          




Published: July 12, 2023 10:54am EDT












Oli Buckley, University of East Anglia



Author





        Oli Buckley
      


      Associate Professor of Cyber Security, University of East Anglia
    





Disclosure statement
Oli Buckley does not work for, consult, own shares in or receive funding from any company or organization that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment.


Partners

University of East Anglia provides funding as a member of The Conversation UK.
View all partners

We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)


 Facebook496


 LinkedIn


 WhatsApp


 Messenger

 Print


Scam calls using AI to mimic voices of people you might know are being used to exploit unsuspecting members of the public. These calls use what’s known as generative AI, which refers to systems capable of creating text, images or any other media such as video, based on prompts from a user. 
Deepfakes have gained notoriety over the last few years with a number of high-profile incidents, such as actress Emma Watson’s likeness being used in a series of suggestive adverts that appeared on Facebook and Instagram. 
There was also the widely shared – and debunked – video from 2022 in which Ukrainian president Volodymyr Zelensky appeared to tell Ukranians to “lay down arms”.
Now, the technology to create an audio deepfake, a realistic copy of a person’s voice, is becoming increasingly common. To create a realistic copy of someone’s voice you need data to train the algorithm. This means having lots of audio recordings of your intended target’s voice. The more examples of the person’s voice that you can feed into the algorithms, the better and more convincing the eventual copy will be.
Many of us already share details of our daily lives on the internet. This means the audio data required to create a realistic copy of a voice could be readily available on social media. But what happens once a copy is out there? What is the worst that can happen? A deepfake algorithm could enable anyone in possession of the data to make “you” say whatever they want. In practice, this can be as simple as writing out some text and getting the computer to say it out loud in what sounds like your voice.
Major challenges
This capability risks increasing the prevalence of audio misinformation and disinformation. It can be used to try to influence international or national public opinion, as seen with the “videos” of Zelensky.
But the ubiquity and availability of these technologies poses significant challenges at a local level too – particularly in the growing trend of “AI scam calls”. Many people will have received a scam or phishing call that tells us, for example, that our computer has been compromised and we must immediately log in, potentially giving the caller access to our data.



Real versus deepfake voices can be distinguished from their spectrogram, or voiceprint.
Brastock/Shutterstock


It is often very easy to spot that this is a hoax, especially when the caller is making requests that someone from a legitimate organisation would not. However, now imagine that the voice on the other end of the phone is not just a stranger, but sounds exactly like a friend or loved one. This injects a whole new level of complexity, and panic, for the unlucky recipient.
A recent story reported by CNN highlights an incident where a mother received a call from an unknown number. When she answered the phone, it was her daughter. The daughter had allegedly been kidnapped and was phoning her mother to pass on a ransom demand. 
In fact, the girl was safe and sound. The scammers had made a deepfake of her voice. This is not an isolated incident, with variations of the scam including a supposed car accident, where the victim calls their family for money to help them out after a crash.
Old trick using new tech
This is not a new scam in itself, the term “virtual kidnapping scam” has been around for several years. It can take many forms but a common approach is to trick victims into paying a ransom to free a loved one they believe is being threatened. 
The scammer tries to establish unquestioning compliance, in order to get the victim to pay a quick ransom before the deception is discovered. However, the dawn of powerful and available AI technologies has upped the ante significantly – and made things more personal. It is one thing to hang up on an anonymous caller, but it takes real confidence in your judgement to hang up on a call from someone sounding just like your child or partner. 
There is software that can used to identify deepfakes, and will create a visual representation of the audio called a spectrogram. When you are listening to the call it might seem impossible to tell it apart from the real person, but voices can be distinguished when spectrograms are analysed side-by-side. At least one group has offered detection software for download, though such solutions may still require some technical knowledge to use. 
Most people will not be able to generate spectrograms so what can you do when you are not certain what you are hearing is the real thing? As with any other form of media you might come across: be sceptical. 
If you receive a call from a loved one out of the blue and they ask you for money or make requests that seem out of character, call them back or send them a text to confirm you really are talking to them. 
As the capabilities of AI expand, the lines between reality and fiction will increasingly blur. And it is not likely that we will be able to put the technology back in the box. This means that people will need to become more cautious.





Artificial intelligence (AI)


Social media


Misinformation


Disinformation


Deepfakes


Social media disinformation


deepfake videos


Audio deepfakes


Deepfake detection


Give me perspective


Voice deepfakes









",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPGh0dHBzOi8vd3d3LmF1dG9kZXNrLmNvbS9ibG9ncy9jb25zdHJ1Y3Rpb24vYWktY29uc3RydWN0aW9uL9IBAA?oc=5,The Rise of AI in Construction - Autodesk Redshift,2023-07-12,Autodesk Redshift,https://www.autodesk.com,"AI and machine learning in construction open up some exciting possibilities within our industry for the future, beginning now.",N/A,"AI and machine learning in construction open up some exciting possibilities within our industry for the future, beginning now.",N/A,https://schema.org,,,,,,,,N/A,N/A,N/A,,"[{'@type': 'Article', '@id': 'https://www.autodesk.com/blogs/construction/ai-construction/#article', 'isPartOf': {'@id': 'https://www.autodesk.com/blogs/construction/ai-construction/'}, 'author': {'name': 'Grace Ellis', '@id': 'https://www.autodesk.com/blogs/construction/#/schema/person/1f6f5f62bdfd0e6e4e7b1f3ef1c6b654'}, 'headline': 'The Rise of AI in Construction\xa0\xa0', 'datePublished': '2023-07-12T14:00:06+00:00', 'dateModified': '2024-04-29T18:39:26+00:00', 'mainEntityOfPage': {'@id': 'https://www.autodesk.com/blogs/construction/ai-construction/'}, 'wordCount': 2724, 'commentCount': 0, 'publisher': {'@id': 'https://www.autodesk.com/blogs/construction/#organization'}, 'image': {'@id': 'https://www.autodesk.com/blogs/construction/ai-construction/#primaryimage'}, 'thumbnailUrl': 'https://www.autodesk.com/blogs/construction/wp-content/uploads/2022/01/ai-and-machine-learning-in-construction.jpg', 'keywords': ['construction industry', 'construction management', 'construction technology'], 'articleSection': ['Connected Construction'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.autodesk.com/blogs/construction/ai-construction/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.autodesk.com/blogs/construction/ai-construction/', 'url': 'https://www.autodesk.com/blogs/construction/ai-construction/', 'name': 'The Rise of AI in Construction\xa0\xa0', 'isPartOf': {'@id': 'https://www.autodesk.com/blogs/construction/#website'}, 'primaryImageOfPage': {'@id': 'https://www.autodesk.com/blogs/construction/ai-construction/#primaryimage'}, 'image': {'@id': 'https://www.autodesk.com/blogs/construction/ai-construction/#primaryimage'}, 'thumbnailUrl': 'https://www.autodesk.com/blogs/construction/wp-content/uploads/2022/01/ai-and-machine-learning-in-construction.jpg', 'datePublished': '2023-07-12T14:00:06+00:00', 'dateModified': '2024-04-29T18:39:26+00:00', 'description': 'AI and machine learning in construction open up some exciting possibilities within our industry for the future, beginning now.', 'breadcrumb': {'@id': 'https://www.autodesk.com/blogs/construction/ai-construction/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.autodesk.com/blogs/construction/ai-construction/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.autodesk.com/blogs/construction/ai-construction/#primaryimage', 'url': 'https://www.autodesk.com/blogs/construction/wp-content/uploads/2022/01/ai-and-machine-learning-in-construction.jpg', 'contentUrl': 'https://www.autodesk.com/blogs/construction/wp-content/uploads/2022/01/ai-and-machine-learning-in-construction.jpg', 'width': 1920, 'height': 1080, 'caption': 'ai and machine learning in construction'}, {'@type': 'BreadcrumbList', '@id': 'https://www.autodesk.com/blogs/construction/ai-construction/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.autodesk.com/blogs/construction/'}, {'@type': 'ListItem', 'position': 2, 'name': 'The Rise of AI in Construction\xa0\xa0'}]}, {'@type': 'WebSite', '@id': 'https://www.autodesk.com/blogs/construction/#website', 'url': 'https://www.autodesk.com/blogs/construction/', 'name': 'Digital Builder', 'description': '', 'publisher': {'@id': 'https://www.autodesk.com/blogs/construction/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.autodesk.com/blogs/construction/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.autodesk.com/blogs/construction/#organization', 'name': 'Autodesk Construction Services', 'url': 'https://www.autodesk.com/blogs/construction/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.autodesk.com/blogs/construction/#/schema/logo/image/', 'url': 'https://www.autodesk.com/blogs/construction/wp-content/uploads/2019/10/ACC-logo@2x.png', 'contentUrl': 'https://www.autodesk.com/blogs/construction/wp-content/uploads/2019/10/ACC-logo@2x.png', 'width': 1002, 'height': 94, 'caption': 'Autodesk Construction Services'}, 'image': {'@id': 'https://www.autodesk.com/blogs/construction/#/schema/logo/image/'}, 'sameAs': ['https://facebook.com/autodeskconstructioncloud', 'https://x.com/adsk_construct', 'https://instagram.com/autodeskconstructioncloud', 'https://www.linkedin.com/company/autodesk-construction-solutions', 'https://bit.ly/ACC-YT']}, {'@type': 'Person', '@id': 'https://www.autodesk.com/blogs/construction/#/schema/person/1f6f5f62bdfd0e6e4e7b1f3ef1c6b654', 'name': 'Grace Ellis', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.autodesk.com/blogs/construction/#/schema/person/image/', 'url': 'https://www.autodesk.com/blogs/construction/wp-content/uploads/2019/11/222C699F-5282-4648-A202-BAC1CD6BC896.jpg', 'contentUrl': 'https://www.autodesk.com/blogs/construction/wp-content/uploads/2019/11/222C699F-5282-4648-A202-BAC1CD6BC896.jpg', 'caption': 'Grace Ellis'}, 'description': 'As Manager of Content Marketing Strategy at Autodesk and Editor in Chief of the Digital Builder Blog, Grace has nearly 15 years of experience creating world-class content for technology firms. She has been working within the construction technology space for the last 6+ years and is passionate about empowering industry professionals with cutting-edge tools and leading strategies that improve the quality of their jobs and lives.', 'sameAs': ['https://www.linkedin.com/in/graceandreellis/'], 'url': 'https://www.autodesk.com/blogs/construction/author/grace/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjMvMDcvMTUvdGVjaG5vbG9neS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1tb2RlbHMtY2hhdC1kYXRhLmh0bWzSAQA?oc=5,'Not for Machines to Harvest': Data Revolts Break Out Against A.I. - The New York Times,2023-07-15,The New York Times,https://www.nytimes.com,"Fed up with A.I. companies consuming online content without consent, fan fiction writers, actors, social media companies and news organizations are among those rebelling.",N/A,"Fed up with A.I. companies consuming online content without consent, fan fiction writers, actors, social media companies and news organizations are among those rebelling.","Fed up with A.I. companies consuming online content without consent, fan fiction writers, actors, social media companies and news organizations are among those rebelling.",https://schema.org,,NewsMediaOrganization,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/sheera-frenkel', 'name': 'Sheera Frenkel'}, {'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/stuart-a-thompson', 'name': 'Stuart A. Thompson'}]",2023-07-15T09:01:06.000Z,Data Revolts Break Out Against A.I.,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/07/12/multimedia/AIREVOLT-kit-zchf/AIREVOLT-kit-zchf-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2023/07/12/multimedia/AIREVOLT-kit-zchf/AIREVOLT-kit-zchf-videoSixteenByNineJumbo1600.jpg', 'caption': 'Kit Loffstadt, who has been writing fan fiction online for many years, stopped posting her stories in May because of concerns over A.I. models.', 'creditText': 'Mary Turner for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/07/12/multimedia/AIREVOLT-kit-zchf/AIREVOLT-kit-zchf-superJumbo.jpg', 'height': 1363, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2023/07/12/multimedia/AIREVOLT-kit-zchf/AIREVOLT-kit-zchf-superJumbo.jpg', 'caption': 'Kit Loffstadt, who has been writing fan fiction online for many years, stopped posting her stories in May because of concerns over A.I. models.', 'creditText': 'Mary Turner for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/07/12/multimedia/AIREVOLT-kit-zchf/AIREVOLT-kit-zchf-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2023/07/12/multimedia/AIREVOLT-kit-zchf/AIREVOLT-kit-zchf-mediumSquareAt3X.jpg', 'caption': 'Kit Loffstadt, who has been writing fan fiction online for many years, stopped posting her stories in May because of concerns over A.I. models.', 'creditText': 'Mary Turner for The New York Times'}]",Technology,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENT‘Not for Machines to Harvest’: Data Revolts Break Out Against A.I.Fed up with A.I. companies consuming online content without consent, fan fiction writers, actors, social media companies and news organizations are among those rebelling.Share full article250Read in appKit Loffstadt, who has been writing fan fiction online for many years, stopped posting her stories in May because of concerns over A.I. models.Credit...Mary Turner for The New York TimesBy Sheera Frenkel and Stuart A. ThompsonSheera Frenkel and Stuart Thompson report on online misinformation and digital data.July 15, 2023For more than 20 years, Kit Loffstadt has written fan fiction exploring alternate universes for “Star Wars” heroes and “Buffy the Vampire Slayer” villains, sharing her stories free online.But in May, Ms. Loffstadt stopped posting her creations after she learned that a data company had copied her stories and fed them into the artificial intelligence technology underlying ChatGPT, the viral chatbot. Dismayed, she hid her writing behind a locked account.Ms. Loffstadt also helped organize an act of rebellion last month against A.I. systems. Along with dozens of other fan fiction writers, she published a flood of irreverent stories online to overwhelm and confuse the data-collection services that feed writers’ work into A.I. technology.“We each have to do whatever we can to show them the output of our creativity is not for machines to harvest as they like,” said Ms. Loffstadt, a 42-year-old voice actor from South Yorkshire in Britain.AdvertisementSKIP ADVERTISEMENTFan fiction writers are just one group now staging revolts against A.I. systems as a fever over the technology has gripped Silicon Valley and the world. In recent months, social media companies such as Reddit and Twitter, news organizations including The New York Times and NBC News, authors such as Paul Tremblay and the actress Sarah Silverman have all taken a position against A.I. sucking up their data without permission.Their protests have taken different forms. Writers and artists are locking their files to protect their work or are boycotting certain websites that publish A.I.-generated content, while companies like Reddit want to charge for access to their data. At least 10 lawsuits have been filed this year against A.I. companies, accusing them of training their systems on artists’ creative work without consent. This past week, Ms. Silverman and the authors Christopher Golden and Richard Kadrey sued OpenAI, the maker of ChatGPT, and others over A.I.’s use of their work.ImageThe actress Sarah Silverman is among the creative professionals who have sued A.I. companies over copyright infringement.Credit...Mark Sommerfeld for The New York TimesAt the heart of the rebellions is a newfound understanding that online information — stories, artwork, news articles, message board posts and photos — may have significant untapped value.The new wave of A.I. — known as “generative A.I.” for the text, images and other content it generates — is built atop complex systems such as large language models, which are capable of producing humanlike prose. These models are trained on hoards of all kinds of data so they can answer people’s questions, mimic writing styles or churn out comedy and poetry.AdvertisementSKIP ADVERTISEMENTThat has set off a hunt by tech companies for even more data to feed their A.I. systems. Google, Meta and OpenAI have essentially used information from all over the internet, including large databases of fan fiction, troves of news articles and collections of books, much of which was available free online. In tech industry parlance, this was known as “scraping” the internet.More In TechnologyWhen Tech Fails, It Is Usually With a Whimper Instead of a Bang July 20, 2024An Algorithm Told Police She Was Safe. Then Her Husband Killed Her. July 18, 2024More Gas Cars and Trucks, Fewer E.V.s as Automakers Change Plans July 18, 2024OpenAI’s GPT-3, an A.I. system released in 2020, spans 500 billion “tokens,” each representing parts of words found mostly online. Some A.I. models span more than one trillion tokens.The practice of scraping the internet is longstanding and was largely disclosed by the companies and nonprofit organizations that did it. But it was not well understood or seen as especially problematic by the companies that owned the data. That changed after ChatGPT debuted in November and the public learned more about underlying A.I. models that powered the chatbots.“What’s happening here is a fundamental realignment of the value of data,” said Brandon Duderstadt, the founder and chief executive of Nomic, an A.I. company. “Previously, the thought was that you got value from data by making it open to everyone and running ads. Now, the thought is that you lock your data up, because you can extract much more value when you use it as an input to your A.I.”The data protests may have little effect in the long run. Deep-pocketed tech giants like Google and Microsoft already sit on mountains of proprietary information and have the resources to license more. But as the era of easy-to-scrape content comes to a close, smaller A.I. upstarts and nonprofits that had hoped to compete with the big firms might not be able to obtain enough content to train their systems.AdvertisementSKIP ADVERTISEMENTIn a statement, OpenAI said ChatGPT was trained on “licensed content, publicly available content and content created by human A.I. trainers.” It added, “We respect the rights of creators and authors, and look forward to continuing to work with them to protect their interests.”Google said in a statement that it was involved in talks on how publishers could manage their content in the future. “We believe everyone benefits from a vibrant content ecosystem,” the company said. Microsoft did not respond to a request for comment.The data revolts erupted last year after ChatGPT became a worldwide phenomenon. In November, a group of programmers filed a proposed class action lawsuit against Microsoft and OpenAI, claiming the companies had violated their copyright after their code was used to train an A.I.-powered programming assistant.In January, Getty Images, which provides stock photos and videos, sued Stability A.I., an A.I. company that creates images out of text descriptions, claiming the start-up had used copyrighted photos to train its systems.Then in June, Clarkson, a law firm in Los Angeles, filed a 151-page proposed class action suit against OpenAI and Microsoft, describing how OpenAI had gathered data from minors and said web scraping violated copyright law and constituted “theft.” On Tuesday, the firm filed a similar suit against Google.AdvertisementSKIP ADVERTISEMENT“The data rebellion that we’re seeing across the country is society’s way of pushing back against this idea that Big Tech is simply entitled to take any and all information from any source whatsoever, and make it their own,” said Ryan Clarkson, the founder of Clarkson.ImageThe lawyers Ryan Clarkson, Tim Giordano, Tracey Cowan and Yana Hart of Clarkson Law Firm in Los Angeles.Credit...Maggie Shannon for The New York TimesEric Goldman, a professor at Santa Clara University School of Law, said the lawsuit’s arguments were expansive and unlikely to be accepted by the court. But the wave of litigation is just beginning, he said, with a “second and third wave” coming that would define A.I.’s future.Larger companies are also pushing back against A.I. scrapers. In April, Reddit said it wanted to charge for access to its application programming interface, or A.P.I., the method through which third parties can download and analyze the social network’s vast database of person-to-person conversations.AdvertisementSKIP ADVERTISEMENTSteve Huffman, Reddit’s chief executive, said at the time that his company didn’t “need to give all of that value to some of the largest companies in the world for free.”ImageSteve Huffman, the founder and chief executive of Reddit.Credit...Amy Lombard for The New York TimesThat same month, Stack Overflow, a question-and-answer site for computer programmers, said it would also ask A.I. companies to pay for data. The site has nearly 60 million questions and answers. Its move was earlier reported by Wired.News organizations are also resisting A.I. systems. In an internal memo about the use of generative A.I. in June, The Times said A.I. companies should “respect our intellectual property.” A Times spokesman declined to elaborate.For individual artists and writers, fighting back against A.I. systems has meant rethinking where they publish.Nicholas Kole, 35, an illustrator in Vancouver, British Columbia, was alarmed by how his distinct art style could be replicated by an A.I. system and suspected the technology had scraped his work. He plans to keep posting his creations to Instagram, Twitter and other social media sites to attract clients, but he has stopped publishing on sites like ArtStation that post A.I.-generated content alongside human-generated content.AdvertisementSKIP ADVERTISEMENT“It just feels like wanton theft from me and other artists,” Mr. Kole said. “It puts a pit of existential dread in my stomach.”At Archive of Our Own, a fan fiction database with more than 11 million stories, writers have increasingly pressured the site to ban data-scraping and A.I.-generated stories.In May, when some Twitter accounts shared examples of ChatGPT mimicking the style of popular fan fiction posted on Archive of Our Own, dozens of writers rose up in arms. They blocked their stories and wrote subversive content to mislead the A.I. scrapers. They also pushed Archive of Our Own’s leaders to stop allowing A.I.-generated content.Betsy Rosenblatt, who provides legal advice to Archive of Our Own and is a professor at University of Tulsa College of Law, said the site had a policy of “maximum inclusivity” and did not want to be in the position of discerning which stories were written with A.I.For Ms. Loffstadt, the fan fiction writer, the fight against A.I. came as she was writing a story about “Horizon Zero Dawn,” a video game where humans fight A.I.-powered robots in a postapocalyptic world. In the game, she said, some of the robots were good and others were bad.AdvertisementSKIP ADVERTISEMENTBut in the real world, she said, “thanks to hubris and corporate greed, they are being twisted to do bad things.”Sheera Frenkel is a prize-winning technology reporter based in San Francisco. In 2021, she and Cecilia Kang published “An Ugly Truth: Inside Facebook's Battle for Domination.” More about Sheera FrenkelStuart A. Thompson is a reporter on the Technology desk covering online information flows. More about Stuart A. ThompsonA version of this article appears in print on July 16, 2023, Section A, Page 1 of the New York edition with the headline: Creators Lead Data Rebellion To Protest A.I.. Order Reprints | Today’s Paper | SubscribeSee more on: OpenAI, Microsoft CorporationRead 250 CommentsShare full article250Read in appAdvertisementSKIP ADVERTISEMENTComments 250‘Not for Machines to Harvest’: Data Revolts Break Out Against A.I.Skip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Enjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",2023-07-15T09:01:06.000Z,,https://www.nytimes.com/,,The New York Times,False,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",‘Not for Machines to Harvest’: Data Revolts Break Out Against A.I.,https://www.nytimes.com/2023/07/15/technology/artificial-intelligence-models-chat-data.html,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://en.wikipedia.org/wiki/The_New_York_Times,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",,https://www.nytco.com/company/diversity-and-inclusion/,,,,,,en,{'@id': '#commentsContainer'},250.0,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024,https://www.nytimes.com/#publisher,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMjMvc3R1ZHktZmluZHMtY2hhdGdwdC1ib29zdHMtd29ya2VyLXByb2R1Y3Rpdml0eS13cml0aW5nLTA3MTTSAQA?oc=5,Study finds ChatGPT boosts worker productivity for some writing tasks - MIT News,2023-07-14,MIT News,https://news.mit.edu,A new MIT study highlights the potential of generative AI for certain types of writing assignments in the workplace.,"Shakked Noy, Whitney Zhang, ChatGPT’s impact on productivity, work and ChatGPT, ChatGPT’s economic impact, MIT economics",A new MIT study highlights the potential of generative AI for certain types of writing assignments in the workplace.,N/A,,,,,,,,,N/A,N/A,"


A new report by MIT researchers highlights the potential of generative AI to help workers with certain writing assignments.




Zach Winn
|
MIT News Office


 Publication Date:
 July 14, 2023





Press Inquiries

  Press Contact:



      
            Abby        

            Abazorius        

  

      Email:
     abbya@mit.edu


      Phone:
              617-253-2709      
  

      
            MIT News Office        

  


 Media Download



 


          ↓ Download Image



 Caption:
        
              Access to the assistive chatbot ChatGPT decreased the time it took workers to complete the tasks by 40 percent, and output quality rose by 18 percent.      
 Credits:
        
              Image: iStock      





*Terms of Use:

    Images for download on the MIT News office website are made available to non-commercial entities, press and the general public under a 
    Creative Commons Attribution Non-Commercial No Derivatives license.
    You may not alter the images provided, other than to crop them to size. A credit line must be used when reproducing images; if one is not provided 
    below, credit the images to ""MIT."" 
  







 Close














 Caption:
          Access to the assistive chatbot ChatGPT decreased the time it took workers to complete the tasks by 40 percent, and output quality rose by 18 percent.      
          

 Credits:
          Image: iStock      
          

















Previous image
Next image






















Amid a huge amount of hype around generative AI, a new study from researchers at MIT sheds light on the technology’s impact on work, finding that it increased productivity for workers assigned tasks like writing cover letters, delicate emails, and cost-benefit analyses.
The tasks in the study weren’t quite replicas of real work: They didn’t require precise factual accuracy or context about things like a company’s goals or a customer’s preferences. Still, a number of the study’s participants said the assignments were similar to things they’d written in their real jobs — and the benefits were substantial. Access to the assistive chatbot ChatGPT decreased the time it took workers to complete the tasks by 40 percent, and output quality, as measured by independent evaluators, rose by 18 percent.
The researchers hope the study, which appears today in open-access form in the journal Science, helps people understand the impact that AI tools like ChatGPT can have on the workforce.
“What we can say for sure is generative AI is going to have a big effect on white collar work,” says Shakked Noy, a PhD student in MIT’s Department of Economics, who co-authored the paper with fellow PhD student Whitney Zhang ’21. “I think what our study shows is that this kind of technology has important applications in white collar work. It’s a useful technology. But it’s still too early to tell if it will be good or bad, or how exactly it’s going to cause society to adjust.”
Simulating work for chatbots
For centuries, people have worried that new technological advancements would lead to mass automation and job loss. But new technologies also create new jobs, and when they increase worker productivity, they can have a net positive effect on the economy.
“Productivity is front of mind for economists when thinking of new technological developments,” Noy says. “The classical view in economics is that the most important thing that technological advancement does is raise productivity, in the sense of letting us produce economic output more efficiently.”
To study generative AI’s effect on worker productivity, the researchers gave 453 college-educated marketers, grant writers, consultants, data analysts, human resource professionals, and managers two writing tasks specific to their occupation. The 20- to 30-minute tasks included writing cover letters for grant applications, emails about organizational restructuring, and plans for analyses helping a company decide which customers to send push notifications to based on given customer data. Experienced professionals in the same occupations as each participant evaluated each submission as if they were encountering it in a work setting. Evaluators did not know which submissions were created with the help of ChatGPT.
Half of participants were given access to the chatbot ChatGPT-3.5, developed by the company OpenAI, for the second assignment. Those users finished tasks 11 minutes faster than the control group, while their average quality evaluations increased by 18 percent.
The data also showed that performance inequality between workers decreased, meaning workers who received a lower grade in the first task benefitted more from using ChatGPT for the second task.
The researchers say the tasks were broadly representative of assignments such professionals see in their real jobs, but they noted a number of limitations. Because they were using anonymous participants, the researchers couldn’t require contextual knowledge about a specific company or customer. They also had to give explicit instructions for each assignment, whereas real-world tasks may be more open-ended. Additionally, the researchers didn’t think it was feasible to hire fact-checkers to evaluate the accuracy of the outputs. Accuracy is a major problem for today’s generative AI technologies.
The researchers said those limitations could lessen ChatGPT’s productivity-boosting potential in the real world. Still, they believe the results show the technology’s promise — an idea supported by another of the study’s findings: Workers exposed to ChatGPT during the experiment were twice as likely to report using it in their real job two weeks after the experiment.
“The experiment demonstrates that it does bring significant speed benefits, even if those speed benefits are lesser in the real world because you need to spend time fact-checking and writing the prompts,” Noy says.
Taking the macro view
The study offered a close-up look at the impact that tools like ChatGPT can have on certain writing tasks. But extrapolating that impact out to understand generative AI’s effect on the economy is more difficult. That’s what the researchers hope to work on next.
“There are so many other factors that are going to affect wages, employment, and shifts across sectors that would require pieces of evidence that aren’t in our paper,” Zhang says. “But the magnitude of time saved and quality increases are very large in our paper, so it does seem like this is pretty revolutionary, at least for certain types of work.”
Both researchers agree that, even if it’s accepted that ChatGPT will increase many workers’ productivity, much work remains to be done to figure out how society should respond to generative AI’s proliferation.
“The policy needed to adjust to these technologies can be very different depending on what future research finds,” Zhang says. “If we think this will boost wages for lower-paid workers, that’s a very different implication than if it’s going to increase wage inequality by boosting the wages of already high earners. I think there’s a lot of downstream economic and political effects that are important to pin down.”
The study was supported by an Emergent Ventures grant, the Mercatus Center, George Mason University, a George and Obie Shultz Fund grant, the MIT Department of Economics, and a National Science Foundation Graduate Research Fellowship Grant.








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print









Paper






Paper: “Experimental evidence on the productivity effects of generative artificial intelligence”








Press Mentions


The HillThe Hill reporter Tobias Burns spotlights the efforts of a number of MIT researchers to better understand the impact of generative AI on productivity in the workforce. One research study “looked as cases where AI helped improved productivity and worker experience specifically in outsourced settings, such as call centers,” explains Burns. Another research study explored the impact of AI programs, such as ChatGPT, among employees. 










Full story via The Hill →
ForbesResearchers from MIT have found that using generative AI chatbots can improve the speed and quality of simple writing tasks, but often lack factual accuracy, reports Richard Nieva for Forbes. “When we first started playing with ChatGPT, it was clear that it was a new breakthrough unlike anything we've seen before,” says graduate student Shakked Noy. “And it was pretty clear that it was going to have some kind of labor market impact.”











Full story via Forbes →















Previous item
Next item



















Related Links

Department of EconomicsSchool of Humanities, Arts, and Social Sciences






Related Topics

Graduate, postdoctoral
Artificial intelligence
Machine learning
Algorithms
Human-computer interaction
Economics
Technology and society
Policy
School of Humanities Arts and Social Sciences
Labor and jobs
Research



Related Articles











Researchers teach an AI to write better chart captions













If art is how we express our humanity, where does AI fit in?













3 Questions: Jacob Andreas on large language models 

















Previous item
Next item
















",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd3d3LnB3Yy5jb20vdXMvZW4vdGVjaC1lZmZlY3QvYWktYW5hbHl0aWNzL2dlbmVyYXRpdmUtYWktdHJhbnNmb3JtYXRpb24tZm9yLXlvdXItYnVzaW5lc3MuaHRtbNIBAA?oc=5,Generative AI transformation for your business - PwC,2023-07-13,PwC,https://www.pwc.com,"Discover generative AI’s potential for digital transformation in company operations, workforce, cloud and data modernization, business reinvention.",,"Discover generative AI’s potential for digital transformation in company operations, workforce, cloud and data modernization, business reinvention.",N/A,http://schema.org,,Thing,,,,,https://www.pwc.com/us/en/tech-effect/content/images/flagship/ai/generativeai-article-hero/gen-ai-business.png,N/A,N/A,"
 Discover more generative AI insights   Generative AI is here Explore how it can reinvent the way we work, accelerate innovation and drive trusted outcomes. Learn more",,,,,Generative AI transformation for your business: PwC ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMilAFodHRwczovL3d3dy5sYXRpbWVzLmNvbS9idXNpbmVzcy9zdG9yeS8yMDIzLTA3LTEzL2NvbHVtbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jaGF0Ym90cy1hcmUtc3ByZWFkaW5nLWZhc3QtYnV0LWh5cGUtYWJvdXQtdGhlbS1pcy1zcHJlYWRpbmctZmFzdGVy0gEA?oc=5,Hiltzik: AI hype is as old as AI itself - Los Angeles Times,2023-07-13,Los Angeles Times,https://www.latimes.com,Will artificial intelligence make jobs obsolete and lead to humankind's extinction? Not on your life,N/A,Will artificial intelligence make jobs obsolete and lead to humankind's extinction? Not on your life,Will artificial intelligence make jobs obsolete and lead to humankind's extinction? Not on your life,http://schema.org,,NewsArticle,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Los Angeles Times', 'description': 'Pulitzer Prize-winning journalist Michael Hiltzik has written for the Los Angeles Times for more than 40 years. ', 'email': 'michael.hiltzik@latimes.com', 'jobTitle': 'Business Columnist', 'name': 'Michael Hiltzik', 'url': 'https://www.latimes.com/people/michael-hiltzik'}]",2023-07-13T12:00:36.644Z,Hiltzik: AI hype is as old as AI itself,"{'@type': 'Organization', 'name': 'Los Angeles Times', 'logo': {'@type': 'ImageObject', 'url': 'https://ca-times.brightspotcdn.com/dims4/default/954b438/2147483647/strip/false/crop/382x60+0+0/resize/382x60!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fde%2F5f%2F46c2d05b430cbc6e775301df1062%2Flogo-full-black.png', 'width': 382, 'height': 60}}","[{'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 991, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/86501f6/2147483647/strip/false/crop/6720x4480+0+0/resize/1486x991!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F69%2Ff9%2F9c8ad23e4785adec762058f585bb%2F1290944-et-ct-wga-strike-jlc-006.jpg', 'width': 1486}, {'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 675, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/a8624f4/2147483647/strip/false/crop/6720x3780+0+350/resize/1200x675!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F69%2Ff9%2F9c8ad23e4785adec762058f585bb%2F1290944-et-ct-wga-strike-jlc-006.jpg', 'width': 1200}]",Business,N/A,"       Writers Guild of America members on the picket line expressed their fears that work would be taken over by AI chatbots. (Jay L. Clendenin / Los Angeles Times)       By Michael HiltzikBusiness Columnist    July 13, 2023 5 AM PT      Share       Share via Close extra sharing options    Email     Facebook    X    LinkedIn    Threads    Reddit    WhatsApp    Copy Link URLCopied!   Print        Those of us who have spent the last few decades reporting on technology have seen fads and fashions rise and fall on investment bubbles.In the late 1990s it was dot-com companies, more recently crypto, blockchain, NFTs, driverless cars, the “metaverse.” All have had their day in the sun amid promises they would change the world, or at least banking and finance, the arts, transportation, society at large. To date, those promises are spectacularly unfulfilled.That brings us to artificial intelligence chatbots.  In from three to eight years we will have a machine with the general intelligence of an average human being.... In a few months, it will be at genius level and a few months after that its powers will be incalculable.  — AI pioneer Marvin Minsky — in 1970   Advertisement    Since last October, when I raised a red flag about hype in the artificial intelligence field, investor enthusiasm has only grown exponentially (as have public fears). Wall Street and venture investors are pouring billions of dollars into AI startups — Microsoft alone made a $10-billion investment in OpenAI, the firm that produced the ChatGPT bot.     Newsletter  Get the latest from Michael Hiltzik  Commentary on economics and more from a Pulitzer Prize winner.  Enter email address      Sign Me Up     You may occasionally receive promotional content from the Los Angeles Times.      Companies scratching for capital have learned that they need only claim an AI connection to bring investors to their doors, much as startups typed “dot-com” onto their business plans a couple of decades ago. Nvidia Corp. has acquired a trillion-dollar market value on the strength of a chip it makes that’s deemed crucial for the data-crunching required by AI chatbots.AI promoters are giddy about their products’ capabilities (and potential profits).Here’s venture capitalist Marc Andreessen: Among the boons in “our new era of AI,” he wrote recently, “every child will have an AI tutor that is infinitely patient, infinitely compassionate, infinitely knowledgeable, infinitely helpful”; every person “an AI assistant/coach/mentor/trainer/advisor/therapist”; every scientist “an AI assistant/collaborator/partner”; every political leader the same superintelligent aide.        Business   Column: The artificial intelligence field is infected with hype. Here’s how not to get duped  AI sounds great, but it has never lived up to its promise. Don’t fall for the baloney.Oct. 7, 2022  There isn’t much to be said about this prediction, other than that it’s endearing in its childlike naivete, given that in today’s world we still can’t get broadband internet connections, which originated in the 1990s, to millions of Americans. Would it surprise you to know that Andreessen’s venture firm has sunk investments into more than 40 AI-related companies? Me neither. Advertisement    Andreessen also wrote: “Anything that people do with their natural intelligence today can be done much better with AI.” That’s provably untrue. Examples of AI confounding its users’ expectations have been piling up on almost a weekly basis. Among the most famous instances is that of a New York lawyer who filed a brief in a federal court lawsuit citing or quoting dozens of fictitious suits generated by ChatGPT. When the judge ordered the lawyer to verify the citations, he asked ChatGPT if they were for real, which is a bit like asking a young mother if her baby is the most adorable baby ever. The bot said, sure they are, another “hallucination.” In the end, the lawyer and his associates were fined $5,000 and ordered to write abject letters of apology to the opposing parties and all the judges the bot had falsely identified with the fake cases. He also lost the lawsuit.Reports of other similar fiascos abound. An eating disorder association replaced the humans staffing its helpline with a chatbot, possibly as a union-busting move — but then had to take the bot offline because, Vice reported, it was encouraging callers to undertake “unhealthy eating habits.” A Texas professor flunked an entire class because ChatGPT had claimed to be the author of their papers. The university administration exonerated almost all the students after they proved the bot was wrong; someone even submitted the professor’s PhD dissertation to the bot, which claimed to have written that, too.    Technology and the Internet   Birth of a Thinking Machine  For 17 years, a team has been trying to develop the most sophisticated artificial intelligence system ever. This summer, the public will be able to see its work.June 21, 2001  Claims made for the abilities or perils of AI chatbots have often turned out to be mistaken or chimerical. A team of MIT researchers purported to discover that ChatGPT could ace the school’s math and computer science curricula with “a perfect solve rate” on the subject tests; their finding was debunked by a group of MIT students. (The original paper has been retracted.) An eye-opening report that an AI program in an Air Force simulation “killed” its human operator to pursue its programmed goals (HAL-style) turned out to be fictitious.So it’s useful to take a close look at what AI chatbots can and can’t do. We can start with the terminology. For these programs, “artificial intelligence” is a misnomer. They’re not intelligent in anything like the sense that humans and animals are intelligent; they’re just designed to seem intelligent to an outsider unaware of the electronic processes going on inside. Indeed, using the very term distorts our perception of what they’re doing.That problem was noticed by Joseph Weizenbaum, the designer of the pioneering chatbot ELIZA, which replicated the responses of a psychotherapist so convincingly that even test subjects who knew they were conversing with a machine thought it displayed emotions and empathy. “What I had not realized,” Weizenbaum wrote in 1976, “is that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people.” Weizenbaum warned that the “reckless anthropomorphization of the computer” — that is, treating it as some sort of thinking companion — had produced a “simpleminded view ... of intelligence.”Even the most advanced computers had no ability to acquire information other than by being “spoon-fed,” Weizenbaum wrote. That’s true of today’s chatbots, which acquire their data by “scraping” text found on the web; it’s just that their capacity to gorge on data is so much greater now, thanks to exponential improvements in computing power, than it was in 1976. The chatbots attracting so much interest today are what AI researchers call “generative” AI — which uses statistical rules to answer queries by extrapolating from data they’ve previously acquired. At its heart, says Australian technologist David Gerard, ChatGPT is “a stupendously scaled-up autocomplete,” like a word-processing program predicting the end of a word or sentence you’ve started typing. The program “just spews out word combinations based on vast quantities of training text.”        Business   Column: This artificial intelligence chatbot turns out to be a plagiarist — and an idiot  The tech site CNET brought in an artificial intelligence bot to write financial articles, but the product turned out to be worthless and even unethical. Jan. 25, 2023  The professional enthusiasm for these programs — predictions that they’ve moved us a step closer to true artificial intelligence, or that they’re capable of learning, or that they harbor the potential to destroy the human race — may seem unprecedented. But it’s not. The same cocksure predictions — what Weizenbaum called “grandiose fantasies” — have been part of the AI world since its inception. In 1970, Marvin Minsky of MIT, one of the godfathers of AI, told Time magazine that “In from three to eight years we will have a machine with the general intelligence of an average human being ... a machine that will be able to read Shakespeare, grease a car, play office politics, tell a joke, and have a fight. ... In a few months, it will be at genius level and a few months after that its powers will be incalculable.”Minsky and his contemporaries ultimately had to recognize that the programs that seemed to show limitless potential were adept only within narrow confines. That’s still true. ChatGPT can turn out doggerel poetry or freshman and sophomore essays, pass tests on some technical subjects, write press releases, compile legal filings with a veneer of professionalism. But these are all generic classes of writing; samples turned out by humans in these categories often have a vacuous, robotic quality. Asked to produce something truly original or creative, chatbots fail or, as those hapless lawyers discovered, fabricate. (When Charlie Brooker, creator of the TV series “Black Mirror,” asked ChatGPT to write an episode, the product was of a quality he described with an unprintable epithet.)That may give pause to businesses hoping to hire chatbots to cut their human payrolls. When they discover that they may have to employ workers to vet chat output to avoid attracting customer wrath or even lawsuits, they may not be so eager to give bots even routine responsibilities, much less mission-critical assignments. In turn, that may hint at the destiny of the current investment frenzy. “The optimistic AI spring of the 1960s and early 1970s,” writes Melanie Mitchell of the Santa Fe Institute, gave way to the “AI winter” in which government funding and popular enthusiasm collapsed. Another boom, this time over “expert systems,” materialized in the early 1980s but had faded by the end of the decade. (“When I received my PhD in 1990, I was advised not to use the term ‘artificial intelligence’ on my job applications,” Mitchell writes.) Every decade seemed to have its boom and bust.Is AI genuinely threatening? Even the terrifying warnings issued about the perils of the technology and the need for regulation look like promotional campaigns in disguise. Their ulterior motive, writes Ryan Calo of the University of Washington, is to “focus the public’s attention on a far-fetched scenario that doesn’t require much change to their business models” and to convince the public that AI is uniquely powerful (if deployed responsibly). Interestingly, Sam Altman, CEO of OpenAI, has lobbied the European Union not to “overregulate” his business. EU regulations, as it happens, would focus on near-term issues related to job losses, privacy infringements and copyright violations. Some of those concerns are motivations of the writers’ and actors’ strikes going on now in Hollywood — the union members are properly concerned that they may lose work to AI bots exploited by cheapskate producers and studio heads who think audiences are too dumb to know the difference between human and robotic creativity.What’s scarcely acknowledged by today’s AI entrepreneurs, like their predecessors, is how hard it will be to jump from the current class of chatbots to genuine machine intelligence. The image of human intelligence as the product merely of the hundred trillion neural connections in the human brain — a number unfathomable by the human brain — leads some AI researchers to assume that once their programs reach that scale, their machines will become conscious. It’s the last hard problems in achieving intelligence, much less consciousness, that may be insurmountable: Human researchers haven’t even agreed on a definition of intelligence and have failed to identify the seat of consciousness. Is there a reasonable role in our lives for chatbots? The answer is yes, if they’re viewed as tools to augment learning, not for cheating; teachers are worried about identifying chat-generated assignments, but in time they’ll use the same techniques they have to identify plagiarism — comparing the product to what they know of their student’s capabilities and rejecting those that look too, too polished (or have identifiable errors). ChatGPT can help students, writers, lawyers and doctors organize large quantities of information or data to help get ideas straight or produce creative insights. It can be useful in the same way that smart teachers advise students to use other web resources with obvious limitations, such as Wikipedia: They can be the first place one consults in preparing an assignment, but they better not be the last.     Latest from Michael Hiltzik         Column: Who elected Elon Musk our arbiter of social norms?           Column: Why hugely profitable corporations won’t spend enough to keep hackers from stealing your private info           Column: The Trump shooting and the glorification of guns          More to Read               Opinion: What’s behind the AI boom? Exploited humans   July 12, 2024                AI is learning from what you said on Reddit, Stack Overflow or Facebook. Are you OK with that?   July 8, 2024                ChatGPT’s new voice mode is giving ‘Her’ vibes   May 14, 2024         ",2023-10-09T22:15:17.769Z,,https://www.latimes.com/business/story/2023-07-13/column-artificial-intelligence-chatbots-are-spreading-fast-but-hype-about-them-is-spreading-faster,Business,Hiltzik: AI hype is as old as AI itself - Los Angeles Times,False,"Those of us who have spent the last few decades reporting on technology have seen fads and fashions rise and fall on investment bubbles. In the late 1990s it was dot-com companies, more recently crypto, blockchain, NFTs, driverless cars, the ""metaverse."" All have had their day in the sun amid promises they would change the world, or at least banking and finance, the arts, transportation, society at large. To date, those promises are spectacularly unfulfilled. That brings us to artificial intelligence chatbots. Since last October, when I raised a red flag about hype in the artificial intelligence field, investor enthusiasm has only grown exponentially (as have public fears). Wall Street and venture investors are pouring billions of dollars into AI startups — Microsoft alone made a $10-billion investment in OpenAI, the firm that produced the ChatGPT bot. Companies scratching for capital have learned that they need only claim an AI connection to bring investors to their doors, much as startups typed ""dot-com"" onto their business plans a couple of decades ago. Nvidia Corp. has acquired a trillion-dollar market value on the strength of a chip it makes that's deemed crucial for the data-crunching required by AI chatbots. AI promoters are giddy about their products' capabilities (and potential profits). Here's venture capitalist Marc Andreessen: Among the boons in ""our new era of AI,"" he wrote recently, ""every child will have an AI tutor that is infinitely patient, infinitely compassionate, infinitely knowledgeable, infinitely helpful""; every person ""an AI assistant/coach/mentor/trainer/advisor/therapist""; every scientist ""an AI assistant/collaborator/partner""; every political leader the same superintelligent aide. There isn't much to be said about this prediction, other than that it's endearing in its childlike naivete, given that in today's world we still can't get broadband internet connections, which originated in the 1990s, to millions of Americans. Would it surprise you to know that Andreessen's venture firm has sunk investments into more than 40 AI-related companies? Me neither. Andreessen also wrote: ""Anything that people do with their natural intelligence today can be done much better with AI."" That's provably untrue. Examples of AI confounding its users' expectations have been piling up on almost a weekly basis. Among the most famous instances is that of a New York lawyer who filed a brief in a federal court lawsuit citing or quoting dozens of fictitious suits generated by ChatGPT. When the judge ordered the lawyer to verify the citations, he asked ChatGPT if they were for real, which is a bit like asking a young mother if her baby is the most adorable baby ever. The bot said, sure they are, another ""hallucination."" In the end, the lawyer and his associates were fined $5,000 and ordered to write abject letters of apology to the opposing parties and all the judges the bot had falsely identified with the fake cases. He also lost the lawsuit. Reports of other similar fiascos abound. An eating disorder association replaced the humans staffing its helpline with a chatbot, possibly as a union-busting move — but then had to take the bot offline because, Vice reported, it was encouraging callers to undertake ""unhealthy eating habits."" A Texas professor flunked an entire class because ChatGPT had claimed to be the author of their papers. The university administration exonerated almost all the students after they proved the bot was wrong; someone even submitted the professor's PhD dissertation to the bot, which claimed to have written that, too. Claims made for the abilities or perils of AI chatbots have often turned out to be mistaken or chimerical. A team of MIT researchers purported to discover that ChatGPT could ace the school's math and computer science curricula with ""a perfect solve rate"" on the subject tests; their finding was debunked by a group of MIT students. (The original paper has been retracted.) An eye-opening report that an AI program in an Air Force simulation ""killed"" its human operator to pursue its programmed goals (HAL-style) turned out to be fictitious. So it's useful to take a close look at what AI chatbots can and can't do. We can start with the terminology. For these programs, ""artificial intelligence"" is a misnomer. They're not intelligent in anything like the sense that humans and animals are intelligent; they're just designed to seem intelligent to an outsider unaware of the electronic processes going on inside. Indeed, using the very term distorts our perception of what they're doing. That problem was noticed by Joseph Weizenbaum, the designer of the pioneering chatbot ELIZA, which replicated the responses of a psychotherapist so convincingly that even test subjects who knew they were conversing with a machine thought it displayed emotions and empathy. ""What I had not realized,” Weizenbaum wrote in 1976, “is that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people.” Weizenbaum warned that the ""reckless anthropomorphization of the computer"" — that is, treating it as some sort of thinking companion — had produced a ""simpleminded view ... of intelligence."" Even the most advanced computers had no ability to acquire information other than by being ""spoon-fed,"" Weizenbaum wrote. That's true of today's chatbots, which acquire their data by ""scraping"" text found on the web; it's just that their capacity to gorge on data is so much greater now, thanks to exponential improvements in computing power, than it was in 1976. The chatbots attracting so much interest today are what AI researchers call ""generative"" AI — which uses statistical rules to answer queries by extrapolating from data they've previously acquired. At its heart, says Australian technologist David Gerard, ChatGPT is ""a stupendously scaled-up autocomplete,"" like a word-processing program predicting the end of a word or sentence you've started typing. The program ""just spews out word combinations based on vast quantities of training text."" The professional enthusiasm for these programs — predictions that they've moved us a step closer to true artificial intelligence, or that they're capable of learning, or that they harbor the potential to destroy the human race — may seem unprecedented. But it's not. The same cocksure predictions — what Weizenbaum called ""grandiose fantasies"" — have been part of the AI world since its inception. In 1970, Marvin Minsky of MIT, one of the godfathers of AI, told Time magazine that ""In from three to eight years we will have a machine with the general intelligence of an average human being ... a machine that will be able to read Shakespeare, grease a car, play office politics, tell a joke, and have a fight. ... In a few months, it will be at genius level and a few months after that its powers will be incalculable.” Minsky and his contemporaries ultimately had to recognize that the programs that seemed to show limitless potential were adept only within narrow confines. That's still true. ChatGPT can turn out doggerel poetry or freshman and sophomore essays, pass tests on some technical subjects, write press releases, compile legal filings with a veneer of professionalism. But these are all generic classes of writing; samples turned out by humans in these categories often have a vacuous, robotic quality. Asked to produce something truly original or creative, chatbots fail or, as those hapless lawyers discovered, fabricate. (When Charlie Brooker, creator of the TV series ""Black Mirror,"" asked ChatGPT to write an episode, the product was of a quality he described with an unprintable epithet.) That may give pause to businesses hoping to hire chatbots to cut their human payrolls. When they discover that they may have to employ workers to vet chat output to avoid attracting customer wrath or even lawsuits, they may not be so eager to give bots even routine responsibilities, much less mission-critical assignments. In turn, that may hint at the destiny of the current investment frenzy. ""The optimistic AI spring of the 1960s and early 1970s,"" writes Melanie Mitchell of the Santa Fe Institute, gave way to the ""AI winter"" in which government funding and popular enthusiasm collapsed. Another boom, this time over ""expert systems,"" materialized in the early 1980s but had faded by the end of the decade. (""When I received my PhD in 1990, I was advised not to use the term 'artificial intelligence' on my job applications,"" Mitchell writes.) Every decade seemed to have its boom and bust. Is AI genuinely threatening? Even the terrifying warnings issued about the perils of the technology and the need for regulation look like promotional campaigns in disguise. Their ulterior motive, writes Ryan Calo of the University of Washington, is to ""focus the public’s attention on a far-fetched scenario that doesn’t require much change to their business models"" and to convince the public that AI is uniquely powerful (if deployed responsibly). Interestingly, Sam Altman, CEO of OpenAI, has lobbied the European Union not to ""overregulate"" his business. EU regulations, as it happens, would focus on near-term issues related to job losses, privacy infringements and copyright violations. Some of those concerns are motivations of the writers' and actors' strikes going on now in Hollywood — the union members are properly concerned that they may lose work to AI bots exploited by cheapskate producers and studio heads who think audiences are too dumb to know the difference between human and robotic creativity. What's scarcely acknowledged by today's AI entrepreneurs, like their predecessors, is how hard it will be to jump from the current class of chatbots to genuine machine intelligence. The image of human intelligence as the product merely of the hundred trillion neural connections in the human brain — a number unfathomable by the human brain — leads some AI researchers to assume that once their programs reach that scale, their machines will become conscious. It's the last hard problems in achieving intelligence, much less consciousness, that may be insurmountable: Human researchers haven't even agreed on a definition of intelligence and have failed to identify the seat of consciousness. Is there a reasonable role in our lives for chatbots? The answer is yes, if they're viewed as tools to augment learning, not for cheating; teachers are worried about identifying chat-generated assignments, but in time they'll use the same techniques they have to identify plagiarism — comparing the product to what they know of their student's capabilities and rejecting those that look too, too polished (or have identifiable errors). ChatGPT can help students, writers, lawyers and doctors organize large quantities of information or data to help get ideas straight or produce creative insights. It can be useful in the same way that smart teachers advise students to use other web resources with obvious limitations, such as Wikipedia: They can be the first place one consults in preparing an assignment, but they better not be the last.",,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Los Angeles Times', 'productID': 'lanews:all-access'}",,"{'@type': 'WebPage', '@id': 'https://www.latimes.com/business/story/2023-07-13/column-artificial-intelligence-chatbots-are-spreading-fast-but-hype-about-them-is-spreading-faster'}",,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vY2lvLmVjb25vbWljdGltZXMuaW5kaWF0aW1lcy5jb20vbmV3cy9uZXh0LWdlbi10ZWNobm9sb2dpZXMvaW1wYWN0LW9mLWdlbmVyYXRpdmUtYWktb24tZ2VuLXotbGVhZGVyc2hpcC8xMDE3NzcwNDXSAX1odHRwczovL2Npby5lY29ub21pY3RpbWVzLmluZGlhdGltZXMuY29tL2FtcC9uZXdzL25leHQtZ2VuLXRlY2hub2xvZ2llcy9pbXBhY3Qtb2YtZ2VuZXJhdGl2ZS1haS1vbi1nZW4tei1sZWFkZXJzaGlwLzEwMTc3NzA0NQ?oc=5,Impact of generative AI on Gen Z leadership - ETCIO,2023-07-15,ETCIO,https://cio.economictimes.indiatimes.com,ETCIO An initiative of The Economic Times,"['Next-Gen Technologies', 'Gen Z', 'Manavjeet Singh', 'Teamlease', 'Sumit Sabharwal', 'Clxns', 'Aayush Ghosh Choudhury', 'Generative Ai', 'Ai']","Being digital native, Gen Z happens to be more tech-savvy than its prior generations. Now that they have the mighty generative AI tools at their disposal, will it be able to expedite the Gen Z takeover?","Being digital native, Gen Z happens to be more tech-savvy than its prior generations. Now that they have the mighty generative AI tools at their disposal, will it be able to expedite the Gen Z takeover?",http://schema.org,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://cio.economictimes.indiatimes.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://cio.economictimes.indiatimes.com/news', 'name': 'News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://cio.economictimes.indiatimes.com/news/next-gen-technologies', 'name': 'Next-Gen Technologies'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://cio.economictimes.indiatimes.com/news/next-gen-technologies/impact-of-generative-ai-on-gen-z-leadership/101777045', 'name': 'Impact of generative AI on Gen Z leadership'}}]",WebSite,"[{'@type': 'Person', 'name': 'Soma Tah', 'url': 'https://cio.economictimes.indiatimes.com/author/479259712/soma-tah'}, {'@type': 'Thing', 'name': 'ET CIO', 'url': 'https://cio.economictimes.indiatimes.com'}]",2023-07-15T12:54:58+05:30,Impact of generative AI on Gen Z leadership,"{'@type': 'NewsMediaOrganization', 'name': 'ETCIO', 'logo': {'@type': 'ImageObject', 'url': 'https://img.etb2bimg.com/files/cp/upload-1679564648-et-cio-light-theme.png', 'width': 600, 'height': 60}}","[{'@type': 'ImageObject', 'url': 'https://etimg.etb2bimg.com/thumb/msid-101777045,width-1200,height-900,resizemode-4/.jpg', 'width': 1200, 'height': 900}]",N/A,N/A,N/A,2023-07-15T13:19:49+05:30,,https://cio.economictimes.indiatimes.com,Next-Gen Technologies,ETCIO,,"Generative AI is poised to revolutionize the business landscape, with Gen Z leaders at the forefront of harnessing its transformative power.Many organizations are still grappling to figure out the most effective ways to apply generative AI into their day-to-day business operations. Interestingly, however, when it comes to the real usage of the technology, it has been found that Gen Z workers are generally more at ease putting generative AI tools to work than the other age groups in the workforce. Gen Z has also proactively learnt how to use this tool to enhance their own outputs. For example, resourceful Gen Z students at schools and colleges have already offloaded their homework onto generative AI. In all likelihood, they would be carrying over the same expectations into the workplace also, when they enter the workforce and with the recent release of OpenAI&rsquo;s GPT-4, the transition will happen way faster than we anticipated. &ldquo;Gen Z was born in the middle of a technology revolution, and are well positioned to find use cases that help do regular things 10x faster,&rdquo; points out Aayush Ghosh Choudhury, Co-founder &amp; CEO, Scrut Automation. &ldquo;The Gen Z workforce is digital-native, mobile-first, and more tech-savvy than the previous generations. It wants to focus on value added work instead of spending time on repetitive and non-productive tasks that generative AI can easily perform. They expect the employers to provide the latest technology products, tools, and hardware to perform their jobs efficiently,&rdquo; explains Sumit Sabharwal, CEO of TeamLease HRtech. In such a scenario, availing the most advanced generative AI tool can be a small step towards improving retention, he believes. Now, GPT-4 is definitely the best version as users can feed it images along with text. This capability will enable the users to feed more nuanced prompts to the system, which was not possible with text-only support. It&rsquo;ll be even better for the Gen Z workforce as it is strong at multimedia communication. &ldquo;I have seen my design and marketing team use GPT-3 and how excited they are with GPT-4. The glee in their eyes is real,&rdquo; says Manavjeet Singh, MD &amp; CEO of CLXNS, an AI-based debt collection platform. As generative AI technology continues to advance further, it is likely to play an increasingly important role in the business landscape, empowering businesses of all types and sizes to operate more efficiently and effectively. Businesses run by Gen Z leaders stand to gain considerably from this evolution and insane productivity boost.Manoj Shastrula, Founder&#8297; and CEO of SaaS startup Socly.io says, ""The appeal of generative AI lies in its adaptability- it can be tailored to satisfy the unique requirements of various industries. For instance, generative AI is being used in retail to develop simulated try-on experiences, and in healthcare, AI is facilitating the development of customized treatment plans and new drugs. Generative AI is also revolutionizing how companies operate, and as Gen Z leaders adopt this technology, we can anticipate increased innovation, growth, and positive effects in the future.&rdquo;With their innate digital fluency and natural affinity for technology, Gen Z leaders are poised to lead the charge in leveraging generative AI for unparalleled business success. &ldquo;Given that Gen Z leaders are digital natives, they are likely to be at the forefront of harnessing generative AI to drive business success,&rdquo; says Rikant Pittie, Co-founder, EaseMyTrip. Also, generative AI has revolutionized the way people function, as demonstrated by ChatGPT. Organizations equipped with advanced tools like GPT-4 can attract and retain the tech-savvy Gen Z workforce by offering them cutting-edge technology to take progressive steps, he believes.But all is not hunky-dory here. There is a lurking challenge too. CLXNS&rsquo; Manavjeet Singh says, &ldquo;For Gen Z leaders this brings out a different challenge &ndash; the growth in impostors and fake experts and how could one differentiate between a real expert and fake one? Similar to how Instagram filters enable users to present themselves as significantly more attractive than they are in reality, GPT3 and GPT4 will enable many employees to sound significantly brighter. Many impostors will be drawn to this and Gen Z leaders will need to develop their ability to distinguish the wheat from the chaff. But besides these issues, overall the workforce will become more efficient and more productive in day to day tasks.&rdquo; However, there are some difficulties with generative AI acceptance, cautions Shastrula. &ldquo;Business leaders must make sure AI-powered systems are moral, open, and responsible,&rdquo; he concludes.",,,,,"{'@type': 'WebPage', '@id': 'https://cio.economictimes.indiatimes.com/news/next-gen-technologies/impact-of-generative-ai-on-gen-z-leadership/101777045'}","{'@type': 'ImageObject', 'url': 'https://img.etb2bimg.com/files/cp/upload-1679564648-et-cio-light-theme.png', 'width': 600, 'height': 60}",,,,,,,,contactus@etcio.com,,,,,,,,,,,,,,,"{'@type': 'Place', 'address': 'Times Internet Limited (Times Center), FC - 6, Sector 16 A, Film City, Noida - 201301 Uttar Pradesh, India'}","{'@type': 'SearchAction', 'target': 'https://cio.economictimes.indiatimes.com/search/{query}', 'query-input': 'required name=query'}",,,,,,,,,,,
https://news.google.com/rss/articles/CBMilQFodHRwczovL3RpbWVzb2ZpbmRpYS5pbmRpYXRpbWVzLmNvbS9nYWRnZXRzLW5ld3Mvd2h5LWdvb2dsZXMtaHVtYW4taW50ZWxsaWdlbmNlLWlzLWNvbXBsYWluaW5nLW92ZXItYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYXJ0aWNsZXNob3cvMTAxNjk5NjQyLmNtc9IBmQFodHRwczovL3RpbWVzb2ZpbmRpYS5pbmRpYXRpbWVzLmNvbS9nYWRnZXRzLW5ld3Mvd2h5LWdvb2dsZXMtaHVtYW4taW50ZWxsaWdlbmNlLWlzLWNvbXBsYWluaW5nLW92ZXItYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYW1wX2FydGljbGVzaG93LzEwMTY5OTY0Mi5jbXM?oc=5,Why Google’s ‘human intelligence’ is complaining over artificial intelligence - The Times of India,2023-07-12,The Times of India,https://timesofindia.indiatimes.com,"The workload of human contract workers behind Google's Bard chatbot, responsible for maintaining data quality and removing traces of bias, has increas","OpenAI,Google AI chatbot,Google,Bard,appen,AI chatbots,Accenture","The workload of human contract workers behind Google's Bard chatbot, responsible for maintaining data quality and removing traces of bias, has increas","The workload of human contract workers behind Google's Bard chatbot, responsible for maintaining data quality and removing traces of bias, has increas",http://schema.org/,,ViewAction,"{'@type': 'Person', 'name': 'Abhinav Kaustubh', 'url': 'https://timesofindia.indiatimes.com/toireporter/author-Abhinav-Kaustubh-479257654.cms'}",2023-07-12T17:19:00+05:30,Why Google’s ‘human intelligence’ is complaining over artificial intelligence,"{'@type': 'Organization', 'name': 'Times Of India', 'url': 'https://timesofindia.indiatimes.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://static.toiimg.com/photo/msid-92877370/92877370.jpg', 'width': 600, 'height': 60}}","{'@type': 'ImageObject', 'url': 'https://static.toiimg.com/thumb/resizemode-4,width-1280,height-720,msid-101699924/101699924.jpg', 'width': 1280, 'height': 720}",N/A,N/A,N/A,2023-07-12T18:25:00+05:30,,https://timesofindia.indiatimes.com/gadgets-news/why-googles-human-intelligence-is-complaining-over-artificial-intelligence/articleshow/101699642.cms,,Why Google’s ‘human intelligence’ is complaining over artificial intelligence,,"Google’s Bard chatbot is quite prompt in answering your queries. But do you know, despite all the artificial intelligence at work, the Bard is highly dependent on humans, and they are overworked, underpaid, and frustrated?There are a group of contract workers who work behind the scenes to support generative AI. If you think it is all AI, then you are wrong, human intelligence is as important as artificial intelligence as they are the ones who make sure the chatbot spits out accurate and reliable answers.Amidst Google's AI race with OpenAI, the ones to suffer are these contract workers. The workload of these workers has increased in size and complexity.Take the case of Bard. It offers prompt responses to a variety of questions. Whether you are asking for help in your mathematics assignment or making it write a whole new book, it can do it all. Nevertheless, the chatbot and the companies depend on human reviewers to improve the quality of these responses and maintain consistency. These individuals evaluate the answers, provide feedback on errors, and remove traces of partiality.Those working on the Bard are from companies such as Appen and Accenture. Despite working under strict time constraints with minimal training and earning as little as $14 an hour, these contractors have expressed concerns about the standard of their work and worry about facing the consequences of speaking up, reports Bloomberg. These staffers have been working since January on AI-related tasks to prepare for the public release of Google's AI products.According to six current Google contract workers, their job has become increasingly challenging. Even without specialised knowledge, these workers are responsible for evaluating responses on a variety of topics, including medication dosages and state regulations. They must follow complex instructions and complete tasks with tight deadlines, some as short as three minutes. One of the contractors said the current situation is causing fear, stress, and uncertainty among people, resulting in underpaid work and a lack of cohesiveness. The contractor believes that this culture of apprehension is not helpful in achieving the desired quality and teamwork from everyone.Contractors working for Google have expressed concerns about their working conditions, both privately and publicly. They claim that the conditions affect the quality of content that users see. In May, a contract worker for Appen wrote a letter to Congress, stating that the speed at which they are required to review content could make Bard a ""faulty"" and ""dangerous"" product.The workers claimed that their work was evaluated through automated means that were difficult to understand. They could not communicate directly with Google and only provided feedback through a ""comments"" section for each task. Additionally, workers had to work quickly as they were flagged by an AI system that urged them to work faster.According to the workers, they have come across disturbing content such as bestiality, war footage, child pornography, and hate speech as part of their job evaluating the quality of Google's offerings. Some workers at Accenture said they were temporarily assigned to review inappropriate and offensive prompts. However, after one worker filed an HR complaint, the project was suddenly stopped for the US team. Nevertheless, teams at other locations are still continuing this practice.Accenture employees were also asked to provide creative responses to prompts for Google's AI chatbot, Bard. They were given tasks such as writing a Shakespearean-style poem about dragons or debugging code. Sources familiar with the situation revealed this information anonymously.Last month, six contract workers at Appen who trained Google's new AI chatbot claimed they were unjustly fired for speaking out about low pay and unreasonable deadlines. The employer, Appen, is accused of illegally firing the workers for organizing. Despite advocating for better pay and working conditions for almost a year, they were terminated just two weeks after warning Congress about potential danger from the chatbot, Bard. Appen cited ""business conditions"" as the reason for termination and has not commented further.In a statement, Google said the company is not the employer of any of the workers in question. Instead, the suppliers are responsible for setting the working conditions, such as pay, benefits, hours, tasks assigned, and employment changes.",,"https://static.toiimg.com/thumb/msid-101699924,width-1280,height-720,imgsize-8164,resizemode-6,overlay-toi_sw,pt-32,y_pad-40/photo.jpg",,,https://timesofindia.indiatimes.com/gadgets-news/why-googles-human-intelligence-is-complaining-over-artificial-intelligence/articleshow/101699642.cms,,,,,,,,,,,,,,en,,,,,,,,,,,,"{'type': 'EntryPoint', 'urlTemplate': 'android-app://com.toi.reader.activities/toi.index.deeplink/t/a/101699642'}",,,,,,,,,,
https://news.google.com/rss/articles/CBMiwQFodHRwczovL2hyLmVjb25vbWljdGltZXMuaW5kaWF0aW1lcy5jb20vbmV3cy93b3JrcGxhY2UtNC0wL2xlYXJuaW5nLWFuZC1kZXZlbG9wbWVudC90aGlzLWlzLWhvdy1jb21wYW5pZXMtYXJlLXByZXBhcmluZy10aGVpci1lbXBsb3llZXMtZm9yLXRoZS1mdXR1cmUtb2Ytd29yay1lbmFibGVkLWJ5LWdlbmVyYXRpdmUtYWkvMTAxNzE4NzA20gHFAWh0dHBzOi8vaHIuZWNvbm9taWN0aW1lcy5pbmRpYXRpbWVzLmNvbS9hbXAvbmV3cy93b3JrcGxhY2UtNC0wL2xlYXJuaW5nLWFuZC1kZXZlbG9wbWVudC90aGlzLWlzLWhvdy1jb21wYW5pZXMtYXJlLXByZXBhcmluZy10aGVpci1lbXBsb3llZXMtZm9yLXRoZS1mdXR1cmUtb2Ytd29yay1lbmFibGVkLWJ5LWdlbmVyYXRpdmUtYWkvMTAxNzE4NzA2?oc=5,This is how companies are preparing their employees for the future of work enabled by Generative AI - ETHRWorld.com,2023-07-13,ETHRWorld.com,https://hr.economictimes.indiatimes.com,ETHRWorld An initiative of The Economic Times,"['Learning And Development', 'Generative AI', 'Genpact', 'Piyush Mehta', 'Naganagouda S J', 'Large Language Models', 'Machine Learning', 'Natural Language Processing', 'Tally Solutions', 'Artificial Intelligence']","Generative AI: To keep up with the accelerated pace of innovation, companies are encouraging their employees to continuously learn and develop the next set of skills needed to not only thrive and adapt to the changing workplace landscape, but build career resilience for the future.","Generative AI: To keep up with the accelerated pace of innovation, companies are encouraging their employees to continuously learn and develop the next set of skills needed to not only thrive and adapt to the changing workplace landscape, but build career resilience for the future.",http://schema.org,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://hr.economictimes.indiatimes.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://hr.economictimes.indiatimes.com/news', 'name': 'News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://hr.economictimes.indiatimes.com/news/workplace-4-0/learning-and-development/this-is-how-companies-are-preparing-their-employees-for-the-future-of-work-enabled-by-generative-ai/101718706', 'name': 'This is how companies are preparing their employees for the future of work enabled by Generative AI'}}]",WebSite,"[{'@type': 'Person', 'name': 'Swastik Sarkar', 'url': 'https://hr.economictimes.indiatimes.com/author/479259335/swastik-sarkar'}, {'@type': 'Thing', 'name': 'ETHRWorld', 'url': 'https://hr.economictimes.indiatimes.com'}]",2023-07-13T11:40:27+05:30,This is how companies are preparing their employees for the future of work enabled by Generative AI,"{'@type': 'NewsMediaOrganization', 'name': 'ETHRWorld', 'logo': {'@type': 'ImageObject', 'url': 'https://img.etb2bimg.com/files/cp/upload-1679564249-et-hr-light-theme.png', 'width': 600, 'height': 60}}","[{'@type': 'ImageObject', 'url': 'https://etimg.etb2bimg.com/thumb/msid-101718706,width-1200,height-900,resizemode-4/.jpg', 'width': 1200, 'height': 900}]",N/A,N/A,N/A,2023-07-13T11:40:29+05:30,,https://hr.economictimes.indiatimes.com,Learning And Development,ETHRWorld,,"According to a study by the IMF, 85 million jobs would be displaced by 2025, as a direct consequence of the tug of war between machine and human.Recently, a company onboarded a &lsquo;Bot&rsquo; as an employee to meet the future demand of the workplace. This is an indication that the skills gap will be bridged by AI-based automation tools over time unless employers and their team members are not upskilling and reskilling themselves with time.Google and Microsoft already use language models to improve the accuracy of their search engines and the natural language processing (NLP) cloud services they sell.According to a study by the IMF, 85 million jobs would be displaced by 2025, as a direct consequence of the tug of war between machine and human. The same report also states that the AI model holds the potential to generate 97 million &lsquo;future jobs&rsquo; within the same time period.LinkedIn's &lsquo;Most In-Demand Skills for 2023&rsquo; report also reveals that global talent shortages have reached a 16-year high, as 75 per cent of employers can&rsquo;t find the talent they need with the right blend of technical and soft skills.To keep up with this accelerated pace of innovation, businesses are also encouraging employees to continuously learn and enable them to develop the next set of skills needed to not only thrive and adapt to the changing workplace landscape, but also build career resilience for the future.To learn more about how companies are planning to upskill their workforce in the era of generative AI, ETHRWorld interacted with HR leaders across industries.Impact of generative AI tools on industryThe AI technology enables organisations to accelerate speed to market, personalise customer experience, enhance employee experience, attract top talent, improve operational efficiencies and automate processes.&ldquo;Using generative AI, enterprise leaders can unlock new levels of productivity and value creation opportunities both internally and externally, driving greater innovation and agility while gaining a competitive edge,&rdquo; said Piyush Mehta, CHRO, Genpact.Tally Solutions plans to incorporate these AI tools into its products while preserving a healthy ratio of automation to human knowledge.&ldquo;Enterprise Resource Planning (ERP) systems like Tally have been severely impacted by generative AI techniques used in the commercial software markets. We are aware of the challenges such as data security and algorithmic biases,&rdquo; said Naganagouda S J, Chief People Officer, Tally Solutions.While generative AI tools offer various benefits and opportunities, their intervention also raises concerns. Ethical considerations such as bias, privacy and the impact on employment needs to be addressed to ensure responsible and beneficial use of these technologies across industries.  Wipro to spend $1 bn to train entire staff in AIThe spending, over the next three years, also involves bringing 30,000 employees from cloud, data analytics, consulting and engineering teams together to embed the technology into all internal operations and solutions offered to clients.See More DetailsBuilding a resilient future workforce through AITo cope with the changing workplace requirements, Genpact has launched Generative Artificial Intelligence (AI) training for its 1,15,000 global workforce, including HR professionals.To help its employees prepare for the future AI-driven world, the company recently launched generative AI skill on Genome. It acts as a gateway for the employees to master Large Language Models (LLMs) like ChatGPT through compelling use cases and practical applications, benefits and potential of this next wave of AI.Genpact launched this training programme in June 2023. Within a month it has trained about 10,000 people and an additional 19,000 people are actively learning this new skill, according to Mehta.Besides this, the company has launched a data literacy initiative, called DataBridge, that allows its employees to become data proficient by learning data science techniques &ndash; these are foundational skills needed to harness new technologies, including generative AI.Genpact&rsquo;s Machine Learning (ML) Incubator is a hybrid learning programme that drives contextualised learning to data science aspirants alongside their regular workflow. The programme enables the employees to develop critical AI/ML skills needed today, including data science, data engineering and augmented intelligence advisory.&ldquo;The rise of modern generative AI-powered workplaces will drive a new S-curve of value creation, where the ability to use data and AI-driven insights to empower and engage people will define winners from losers,&rdquo; said Mehta.Tally Solutions, in order to meet the needs of the changing workplace landscape and build a future-resilient workforce, has implemented various strategies such as future-oriented skill development programmes, embracing technology such as AI and automation to increase productivity and efficiency of the employees.The company has a specific plan for the HR department in the domain of automation. It has created a special strategy that concentrates on the following to meet the demands of HR professionals:Training on the use of AI in HR procedures, including tools for hiring employees and data-driven analyticsThe development of HR-specific expertise in fields like workforce analytics and employee engagementStressing the importance of data-driven HR strategy and offering training on data analysis softwareFacilitating networking and co-operation possibilities at conferences and forums for the sectorThe company has also introduced comprehensive AI technology training courses, collaborative learning systems and hackathons for specialised AI education and accreditation for its employees.Generative AI and its potentials in the HR spaceGenerative AI can be used in HR to process employee engagement and retention data from surveys, conversations, emails and other employee communication sources.This can provide speedy insights into employee sentiment, career growth aspirations, and organisational expectations, which can be used to enhance talent management practices and improve overall experience of employees within the company.&ldquo;At Genpact, we recently launched AI Guru, a digital subject matter expert powered by generative AI, to support our employees in their learning journeys on Genome and answer their questions instantly,&rdquo; said Mehta.According to Naganagouda of Tally Solutions, Generative AI technology has the potential to revolutionise HR practices, optimising efficiency, decision-making and employee experience. &ldquo;This ensures that our HR practices are aligned with the evolving landscape of AI technologies and support the overall success of our organisation and our workforce,&rdquo; he said.Read alsoPahle Khushi, Phir Khushahali: A mantra to create positive workplace cultureThis is how Cimpress India&rsquo;s flexible workplace policy is creating an inclusive workplaceRespect: A Japanese company&rsquo;s mantra to build long term employee relationshipThis is how R&amp;R strategy is helping Bridgestone India to build an efficient workforce",,,,,"{'@type': 'WebPage', '@id': 'https://hr.economictimes.indiatimes.com/news/workplace-4-0/learning-and-development/this-is-how-companies-are-preparing-their-employees-for-the-future-of-work-enabled-by-generative-ai/101718706'}","{'@type': 'ImageObject', 'url': 'https://img.etb2bimg.com/files/cp/upload-1679564249-et-hr-light-theme.png', 'width': 600, 'height': 60}",,,,,,,,contactus@ethrworld.com,,,,,,,,,,,,,,,"{'@type': 'Place', 'address': 'Times Internet Limited (Times Center), FC - 6, Sector 16 A, Film City, Noida - 201301 Uttar Pradesh, India'}","{'@type': 'SearchAction', 'target': 'https://hr.economictimes.indiatimes.com/search/{query}', 'query-input': 'required name=query'}",,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmJ1c2luZXNzaW5zdXJhbmNlLmNvbS9hcnRpY2xlLzIwMjMwNzEyL05FV1MwNi85MTIzNTg0MjEvQXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcG9zZXMtcmlzay10by1IUi1wcmFjdGljZXPSAQA?oc=5,Artificial intelligence poses risk to HR practices - Business Insurance,2023-07-12,Business Insurance,https://www.businessinsurance.com,"Artificial intelligence can be a valuable tool for employers in functions such as hiring, but it also poses significant risks of inadvertent discrimination, experts warn.",N/A,"Artificial intelligence can be a valuable tool for employers in functions such as hiring, but it also poses significant risks of inadvertent discrimination, experts warn.","Artificial intelligence can be a valuable tool for employers in functions such as hiring, but it also poses significant risks of inadvertent discrimination, experts warn.",,,,,,,,,N/A,N/A,"





Risk Management

Artificial intelligence poses risk to HR practices



 Judy Greenwald


July 12, 2023



Reprints



Share

Facebook
LinkedIn
Google +
Twitter


Current Issue
Cyber Risks
Emerging Risks
Technology
Marsh & McLennan
Coverage Disputes
D&O
Regulation
Aon
USI Insurance Services
Agents & Brokers
E&O
More +
Less -









Artificial intelligence can be a valuable tool for employers in functions such as hiring, but it also poses significant risks of inadvertent discrimination, experts warn.
The use of generative AI tools — including ChatGPT — which learn patterns and relationships from massive amounts of data, has exploded to more than 100 million users, according to a report released in June by the U.S. Government Accountability Office. 
In the employment context, AI is most likely to be used in hiring but is expected to play a greater role in related functions, including layoffs, promotions and succession planning.
“It’s quicker to have an AI source review all (job candidates’) resumes and sort them than pre-interview candidates. It makes the process quicker” and involves fewer human resources staff, said Mary Anne Mullin, New York-based senior vice president at QBE Insurance Group Ltd.
But it still requires some human oversight, experts say. The issue has attracted the attention of Congress and federal regulators as well as some state and local legislative bodies (see related story below). 
Its use will increase as the technology becomes more sophisticated, said Joni Mason, New York-based senior vice president and national executive and professional risk solutions practice leader for USI Insurance Services Inc. 
Employers “want to make sure that their algorithm doesn’t discriminate against different groups,” said Scott M. Nelson, a partner with Hunton Andrews Kurth LLP in Houston. 
He said a general, if simplistic, rule of thumb is the “4/5 rule,” under which a selection practice is considered to have a disparate impact if the selection rate for a certain group is less than 80% that of the group with the highest rate.
In a putative class-action lawsuit filed in U.S. District Court in Oakland, California, in February, Derek L. Mobley blamed Pleasanton, California-based Workday Inc.’s AI systems and screening tools for his failure to find employment despite applying for at least 100 positions since 2018. 
Mr. Mobley charged that the tools administered by Workday and used by employers rely upon “subjective practices” that have had a disparate impact on applicants who are African-American, older than 40, and/or disabled.
There will be more lawsuits, experts say. 
“Wrongful employment decisions and, in particular, claims around discrimination are in the offing,” said Kelly Thoerig, Marsh LLC’s New York-based U.S. employment practices liability product leader.
She said that while there has not been a notable volume of AI-related employment claims to date, “the framework is there” for a creative plaintiffs bar.
Observers say employers will generally be held responsible for any perceived discrimination. 
“It’s incumbent upon these companies to not just rely on the vendor that supplies the AI program,” Ms. Mullin said.
“It’s going to come down to having a very diverse and strong set of data,” said David Derigiotis, Detroit-based chief insurance officer for insurtech Embroker. “It has to be tested and tested and must be reported and the results found to be satisfactory before live production,” he said. 
Employment practices liability policies will likely provide coverage if there is litigation, observers say.
“What insureds might want to look at is what kind of computer-related exclusions could be on the policy, and they need to talk with their broker to make sure that any wrongful claim that arises from AI is covered under the definition of wrongful employment, including claims and settlements,” Ms. Mullin said.
Technology errors and omissions coverage may also come into play, Mr. Derigiotis said.
“We have seen some questions around employers’ utilization of AI and AI-related technologies come up with more regularity” during underwriting, but generally speaking ‘’it hasn’t created any outsize problems,” Ms. Thoerig said.

Lawmakers, regulators set rules on using Ai as a recruitment tool 
Artificial intelligence’s use in employment decisions has drawn the attention of federal, state and local regulators and legislators.
This includes:

The Equal Employment Opportunity Commission in May issued guidance on how to avoid discrimination under Title VII of the Civil Rights Act of 1964 when using AI.
During a June 13 hearing on AI, U.S. Democratic Sen. Jon Ossoff, of Georgia, chairman of the Senate Subcommittee on Human Rights & the Law, said AI’s potential impact on work could include fundamental shifts in recruitment, candidate screening and hiring.
A New York City law, Local Law 144, which took effect July 5, requires employers and employment agencies that use AI to conduct a bias audit within one year of its use, make information about the audit publicly available, and provide employees or job candidates with certain notices about its use.
Illinois’ Artificial Intelligence Video Interview Act, which became effective Jan. 1, 2020, regulates AI’s use in job applicant video interviews.
Maryland’s Facial Recognition Services Law, which became effective Oct. 1, 2020, prohibits employers from using facial recognition technology during pre-employment job interviews without the applicant’s consent. 

In addition, the European Union has passed draft rules governing AI’s use for functions including making hiring decisions. No comparable U.S. federal legislation is imminent.
Europe is taking a more unified approach than the United States, said Ernest Paskey, Washington-based partner and head of assessment solutions, North America, for Aon PLC. 
AI-related uses have also been the focus of many state legislatures (see chart). 


Some of the proposed legislation pinpoints hiring, while other measures are framed more broadly, addressing issues such as housing or credit, said Michael Fetzer, Brunswick, Georgia-based associate partner, global science and analytics, for Aon.





Readers Poll




Your response has been saved successfully.


Please select one option.

Most Read in Risk Management


 1. Chubb makes more executive moves


 2. Marsh unit to buy Horton


 3. AIG names Chicago region managing director


 4. Travelers says further rate increases possible


 5. Chubb makes several executive appointments


 6. Judge dismisses some of Marsh unit’s counterclaims against former exec


Sign up for Daily Briefing, the free email newsletter from Business Insurance.

*First Name:*Last Name:*Email Address:*Company Name:*Industry:Select...Accounting FirmActuarial/Appraisal FirmAd Agency/PR/Marketing CompanyAgricultureAssociationBank/Financial InstitutionBusiness Service FirmsCaptive ManagementClaims/Third Party Administrator/AdjusterConstructionConsulting FirmEducational Institute/College/UniversityGovernmentHealth Care ProviderInsurance Agency/BrokerageInsurance/Reinsurance CompanyLaw FirmManaging General Agent (MGA)Manufacturing/UtilitiesReal EstateReligious/Non Profit OrganizationRetail, Restaurant, HospitalityService Provider (Outside Counsel, TPA, Etc.)Technology ProvidersTransportation/Communications/Electric/GasUnionWholesale TradeOther*Job Function:Select...Accountant/FinanceActuaryAdministrative/AssistantAdvertiser/Marketer/PR ProfessionalAgent (Resale)Agent (Wholesale)Analyst - Business/ResearchAppraiserAttorney/General CounselCaptive ManagerClaimsComplianceCustomer ServiceCyber SecurityDiversity/InclusionEducator/ProfessorExecutive/LeadershipHuman Resources/BenefitsInsurance AgentInsurance BrokerIT ProfessionalRecruiterRisk ManagementSafety/SecuritySales (Not Agent/Broker)Service Provider (TPA, Consultant, Outside Counsel)StudentUnderwriterWorkers CompOther (specify)Submit














X

            Sign up now for free access to this article and much more.
        

            If you are already registered with Business Insurance, click here to Login


Please tell us a bit more about yourself in order to continue


First Name



Last Name



Email

Invalid email address.


Company Name



Job Function

--Select--
Accountant/Finance
Advertiser/Marketer/PR Professional
Agent (Resale)
Agent (Wholesale)
Attorney/General Counsel
Broker
Chief Technology/Information Officer
Claims 
CSuite/Executive Management
Human Resources/Benefits
Risk Manager
Sales
Service Provider (TPA, Consultant, Outside Counsel)
Student

Required


Type of Business

--Select--
Agriculture/Forestry/Fishing
Construction
Finance, Banking & Real Estate Services
Government/Education/NonProfit
Hospitality
Insurance
Manufacturing/Utilities
Services
Technology
Transportation/Communications/Electric/Gas
Wholesale/Retail Trade

Required








X




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmZhc3Rjb21wYW55LmNvbS85MDkyMTY3OS83LXJlZC1mbGFncy10aGF0LWluZGljYXRlLXNvbWVvbmUtdXNlZC1nZW5lcmF0aXZlLWFpLW9uLXRoZWlyLXJlc3VtZS_SAQA?oc=5,7 red flags that indicate someone used generative AI on their résumé - Fast Company,2023-07-12,Fast Company,https://www.fastcompany.com,AI tools that help potential hires appear more skilled than they may actually be make recruiters' jobs harder than ever.,N/A,AI tools that help potential hires appear more skilled than they may actually be make recruiters' jobs harder than ever.,A list of red flags and strategies to mitigate mis-hires.,https://schema.org,,,,,,,,N/A,N/A,"The many steps recruiters have to take to properly assess candidates have always been fairly difficult to navigate. And with more tools popping up every day that help potential hires appear more skilled than they may actually be, it’s tougher than ever.At this point in time, talent acquisition professionals are well aware that a large quantity of people are using generative AI tools like ChatGPT for résumés, but not all of them know how to combat the increased volume of unqualified applicants. This article will provide the lay of the land and upsides of AI assistance as well as a list of red flags to look out for and strategies to mitigate mis-hires.Job seekers are likely using AIRecently, COMPUTERWORLD surveyed 2,153 job seekers about their experience using ChatGPT in their job search. A resounding 88% of them said they are either somewhat or highly likely to use it for their future application materials.We can’t blame modern job seekers for using the new technology. After all, 78% of those surveyed earned an interview after taking advantage of it and 59% were hired!The survey also uncovered the fact that four out of 10 interviewers were unable to identify candidates that had used it. However, the surveyed job seekers did state that 35% of them didn’t get the job because their interviewer was aware of their usage.The landscape is a bit confusing.Is ChatGPT a detractor from quality application materials? Are certain job seekers simply using it incorrectly? Are some recruiters discounting its abilities?There are positives to this new innovation, but the technology is tempered by laziness in some applicants and prejudice in some talent acquisition professionals.Let’s dive in deeper.The upsideChatGPT can generate a solid start for candidates as long as they provide the correct prompt. Candidates need to know what they require of the AI, provide what it needs to be successful at the task (such as their résumé, goals and the role they are applying for). Essentially, candidates can execute their application process faster if they spend time working out the right prompt and if they tailor the output afterward.In addition to providing a head start with proper prompt usage, ChatGPT might allow English as a second language (ESL) candidates to more clearly present their value proposition to recruiters. It can be difficult for people whose first language isn’t English to fine tune a résumé, but that doesn’t mean they are any less qualified.Finally, ChatGPT can pair up a candidate’s skills with the requirements in a job description and then candidates can modify the output from there. That is, in our minds, the best use case for the new technology.Red flagsSo with the upsides in mind, let’s examine how to identify a poorly executed ChatGPT résumé.advertisementFirst off, if the résumé directly mirrors the asks in the job description without personality, it has probably been generated (badly) using ChatGPT.Second, if the résumé you receive showcases a completely different style of writing than the other application materials, ChatGPT (or another similar tool) is likely at play.Third, if you start seeing résumés come through that seem oddly familiar, for example, two nearly identical résumés, they are likely from ChatGPT, and, quite frankly, lying is afoot. Speaking of lies, when ChatGPT is unable to find a point of reference, it can fabricate “facts” fairly convincingly. Inaccurate or false information is par for the course and should be on your radar.Fourth, ChatGPT was trained on information prior to 2021, so if you are sourcing for a role that is newer, “ChatGPT may not fully understand the context and nuance of [the required] work experience, achievements and career goals.”Some other red flags to look out for are generic phrasing, strange formatting , and repetitive language.Identification strategiesThe fact is, if executed well, it can be pretty difficult to flag all applicants who have utilized generative AI technology (and it’s not always productive to do so). But if you want to make sure you are getting a quality candidate, here are some strategies you can employ.Ask personal, experience-based questions as a part of your application process.Try to learn whether they have the practice experience or potential to solve the problems you need help with by posing questions designed with that specific candidate in mind.Lean heavily into reference checks.Don’t disregard the power of praise. Contact all the references on their list but also consider the testimonials on their LinkedIn profile when you are doing your vetting.Pay close attention to the skills section.Are their skills identical to the job description with little deviation? That could be a desperate ploy to earn the job and a major indicator of applicants who are faking it.Implement phone screens.Screening through a phone call can be a great tool to see whether you’re speaking with a real-deal candidate. Ask them some introductory questions and see how they respond. The truth will reveal itself most times.Observe their in-person or email presentation.If you bring in a candidate for an interview or if you contact the candidate via email, take note of potential discrepancies between their résumé writing style and presentation. The difference can be quite stark.Cross-check what they have written versus how they are positioned on LinkedIn and other platforms.Again, different writing styles and inconsistently represented qualifications are major indications of falsification in applications. Take the time to compare materials if you want the full picture.Consider including other options (ideally something proprietary to your company) beyond résumés and cover letters in your application process to guarantee human involvement and potential fit. Practical exercises can help you further assess that a candidate can do the work they say they can do. For analytical roles, this could take the form of solving a problem using sample data, or for creative roles, you might ask a candidate to create something that showcases a relevant skill.This article originally appeared on Beacon Hill Staffing’s blog and is reprinted with permission. Apply to the Most Innovative Companies Awards  and be recognized as an organization driving the world forward through innovation. Don’t miss the super-early rate deadline on Friday, July 26!",,"[{'@type': 'Article', '@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/#article', 'isPartOf': {'@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/'}, 'author': [{'@type': 'Person', '@id': 'https://www.fastcompany.com/user/beacon-hill-staffing#/schema/person/7806689d934e610d660caf5536fea0b2', 'name': 'Beacon Hill Staffing', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/beacon-hill-staffing#/schema/person/image/e4f1065015514efdc8625f27d3a75781', 'url': 'https://secure.gravatar.com/avatar/8cd8cc85b2c8687041504325bfc27279?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8cd8cc85b2c8687041504325bfc27279?s=96&d=mm&r=g', 'caption': 'Beacon Hill Staffing'}, 'url': 'https://www.fastcompany.com/user/beacon-hill-staffing', 'description': ''}], 'headline': '7 red flags that indicate someone used generative AI on their résumé', 'datePublished': '2023-07-12T09:30:00+00:00', 'dateModified': '2023-07-11T19:54:45+00:00', 'mainEntityOfPage': {'@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/'}, 'wordCount': 1066, 'publisher': {'@id': 'https://www.fastcompany.com/#organization'}, 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume#primaryimage', 'url': 'https://images.fastcompany.com/image/upload/wp-cms/uploads/2023/07/p-1-90921679-7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume.jpg', 'contentUrl': 'https://images.fastcompany.com/image/upload/wp-cms/uploads/2023/07/p-1-90921679-7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume.jpg', 'caption': '7 red flags that indicate someone used generative AI on their résumé'}, 'thumbnailUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2023/07/p-1-90921679-7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume.jpg', 'keywords': ['Workplace Evolution'], 'articleSection': ['Work Life'], 'inLanguage': 'en-US', 'copyrightYear': '2023', 'copyrightHolder': {'@id': 'https://cms.mansueto.com/#organization'}, 'isAccessibleForFree': False, 'articleBody': 'The many steps recruiters have to take to properly assess candidates have always been fairly difficult to navigate. And with more tools popping up every day that help potential hires appear more skilled than they may actually be, it\'s tougher than ever.\n\n\n\nAt this point in time, talent acquisition professionals are well aware that a large quantity of people are using generative AI tools like ChatGPT for résumés, but not all of them know how to combat the increased volume of unqualified applicants. This article will provide the lay of the land and upsides of AI assistance as well as a list of red flags to look out for and strategies to mitigate mis-hires.\n\n\n\nJob seekers are likely using AI\n\n\n\nRecently,&nbsp;COMPUTERWORLD surveyed 2,153 job seekers&nbsp;about their experience using ChatGPT in their job search. A resounding&nbsp;88%&nbsp;of them said they are either somewhat or highly likely to use it for their future application materials.\n\n\n\nWe can\'t blame modern job seekers for using the new technology. After all,&nbsp;78%&nbsp;of those surveyed earned an interview after taking advantage of it and&nbsp;59%&nbsp;were hired!\n\n\n\nThe survey also uncovered the fact that&nbsp;four out of 10&nbsp;interviewers were unable to identify candidates that had used it. However, the surveyed job seekers did state that&nbsp;35%&nbsp;of them didn’t get the job because their interviewer was aware of their usage.\n\n\n\nThe landscape is a bit confusing.\n\n\n\nIs ChatGPT a detractor from quality application materials? Are certain job seekers simply using it incorrectly? Are some recruiters discounting its abilities?\n\n\n\nThere are positives to this new innovation, but the technology is tempered by laziness in some applicants and prejudice in some talent acquisition professionals.\n\n\n\nLet\'s dive in deeper.\n\n\n\nThe upside\n\n\n\nChatGPT can generate a solid start for candidates as long as they provide the correct prompt. Candidates need to&nbsp;know what they require of the AI, provide what it needs to be successful at the task&nbsp;(such as their résumé, goals and the role they are applying for). Essentially, candidates can execute their application process faster if they spend time working out the right prompt and if they tailor the output afterward.\n\n\n\nIn addition to providing a head start with proper prompt usage, ChatGPT might allow English as a second language (ESL) candidates to more clearly present their value proposition to recruiters. It can be difficult for people whose first language isn\'t English to fine tune a résumé, but that doesn\'t mean they are any less qualified.\n\n\n\nFinally, ChatGPT can&nbsp;pair up a candidate\'s skills with the requirements in a job description&nbsp;and then candidates can modify the output from there. That is, in our minds, the best use case for the new technology.\n\n\n\nRed flags\n\n\n\nSo with the upsides in mind, let\'s examine how to identify a poorly executed ChatGPT résumé.\n\n\n\nFirst off, if the résumé directly mirrors the asks in the job description without personality, it has probably been generated (badly) using ChatGPT.\n\n\n\nSecond, if the résumé you receive showcases a completely different style of writing than the other application materials, ChatGPT (or another similar tool) is likely at play.\n\n\n\nThird, if you start seeing résumés come through that seem oddly familiar, for example, two nearly identical résumés, they are likely from ChatGPT, and, quite frankly, lying is afoot. Speaking of lies, when ChatGPT is unable to find a point of reference, it can fabricate ""facts"" fairly convincingly.&nbsp;Inaccurate or false information&nbsp;is par for the course and should be on your radar.\n\n\n\nFourth, ChatGPT was trained on information prior to 2021, so if you are sourcing for a role that is newer,&nbsp;""ChatGPT may not fully understand the context and nuance of [the required] work experience, achievements and career goals.""\n\n\n\nSome other red flags to look out for are&nbsp;generic&nbsp;phrasing, strange&nbsp;formatting&nbsp;, and&nbsp;repetitive language.\n\n\n\nIdentification strategies\n\n\n\nThe fact is, if executed well, it can be pretty difficult to flag all applicants who have utilized generative AI technology (and it\'s not always productive to do so). But if you want to make sure you are getting a quality candidate, here are some strategies you can employ.\n\n\n\nAsk personal, experience-based questions as a part of your application process.Try to learn whether they have the practice experience or potential to solve the problems you need help with by posing questions designed with that specific candidate in mind.Lean heavily into reference checks.Don\'t disregard the power of praise. Contact all the references on their list but also consider the testimonials on their LinkedIn profile when you are doing your vetting.Pay close attention to the skills section.Are their skills identical to the job description with little deviation? That could be a desperate ploy to earn the job and a major indicator of applicants who are faking it.Implement phone screens.Screening through a phone call can be a great tool to see whether you\'re speaking with a real-deal candidate. Ask them some introductory questions and see how they respond. The truth will reveal itself most times.Observe their in-person or email presentation.If you bring in a candidate for an interview or if you contact the candidate via email, take note of potential discrepancies between their résumé writing style and presentation. The difference can be quite stark.Cross-check what they have written versus how they are positioned on LinkedIn and other platforms.Again, different writing styles and inconsistently represented qualifications are major indications of falsification in applications. Take the time to compare materials if you want the full picture.Consider including other options (ideally something proprietary to your company) beyond résumés and cover letters in your application process to guarantee human involvement and potential fit. Practical exercises can help you further assess that a candidate can do the work they say they can do. For analytical roles, this could take the form of solving a problem using sample data, or for creative roles, you might ask a candidate to create something that showcases a relevant skill.\n\n\n\nThis article originally appeared on Beacon Hill Staffing\'s blog and is reprinted with permission.'}, {'@type': 'WebPage', '@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/', 'url': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/', 'name': 'Red flags that show someone used generative AI on their resume', 'isPartOf': {'@id': 'https://www.fastcompany.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/#primaryimage'}, 'image': {'@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/#primaryimage'}, 'thumbnailUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2023/07/p-1-90921679-7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume.jpg', 'datePublished': '2023-07-12T09:30:00+00:00', 'dateModified': '2023-07-11T19:54:45+00:00', 'description': ""AI tools that help potential hires appear more skilled than they may actually be make recruiters' jobs harder than ever."", 'breadcrumb': {'@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/']}], 'author': [{'@type': 'Person', '@id': 'https://www.fastcompany.com/user/beacon-hill-staffing#/schema/person/7806689d934e610d660caf5536fea0b2', 'name': 'Beacon Hill Staffing', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/beacon-hill-staffing#/schema/person/image/e4f1065015514efdc8625f27d3a75781', 'url': 'https://secure.gravatar.com/avatar/8cd8cc85b2c8687041504325bfc27279?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8cd8cc85b2c8687041504325bfc27279?s=96&d=mm&r=g', 'caption': 'Beacon Hill Staffing'}, 'url': 'https://www.fastcompany.com/user/beacon-hill-staffing', 'description': ''}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/#primaryimage', 'url': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2023/07/p-1-90921679-7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume.jpg', 'contentUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2023/07/p-1-90921679-7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume.jpg', 'width': 2480, 'height': 1395, 'caption': '[Photos: Viktoriia Oleinichenko/Getty images; Dean Ricciardi/Unsplash]'}, {'@type': 'BreadcrumbList', '@id': 'https://www.fastcompany.com/90921679/7-red-flags-that-indicate-someone-used-generative-ai-on-their-resume/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.fastcompany.com'}, {'@type': 'ListItem', 'position': 2, 'name': '7 red flags that indicate someone used generative AI on their résumé'}]}, {'@type': 'WebSite', '@id': 'https://www.fastcompany.com/#website', 'url': 'https://www.fastcompany.com/', 'name': 'Fast Company', 'description': '', 'publisher': {'@id': 'https://www.fastcompany.com/#organization'}, 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.fastcompany.com/#organization', 'name': 'Fast Company', 'url': 'https://www.fastcompany.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/#/schema/logo/image/', 'url': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms-2/2024/03/fc_logo.png', 'contentUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms-2/2024/03/fc_logo.png', 'width': 696, 'height': 696, 'caption': 'Fast Company'}, 'image': {'@id': 'https://www.fastcompany.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/FastCompany/', 'https://x.com/FastCompany', 'https://fastcompany.social/@fastcompany', 'https://www.linkedin.com/company/fast-company/']}, {'@type': 'Person', '@id': 'https://www.fastcompany.com/user/beacon-hill-staffing#/schema/person/7806689d934e610d660caf5536fea0b2', 'name': 'Beacon Hill Staffing', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/beacon-hill-staffing#/schema/person/image/e4f1065015514efdc8625f27d3a75781', 'url': 'https://secure.gravatar.com/avatar/8cd8cc85b2c8687041504325bfc27279?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8cd8cc85b2c8687041504325bfc27279?s=96&d=mm&r=g', 'caption': 'Beacon Hill Staffing'}, 'url': 'https://www.fastcompany.com/user/beacon-hill-staffing', 'description': ''}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vd3d3LmVkd2Vlay5vcmcvdGVjaG5vbG9neS93aGF0LWVkdWNhdG9ycy1rbm93LWFib3V0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLTMtY2hhcnRzLzIwMjMvMDfSAQA?oc=5,"What Educators Know About Artificial Intelligence, in 3 Charts - Education Week",2023-07-14,Education Week,https://www.edweek.org,Most educators say they have not received any professional development on artificial intelligence. ,"Classroom Technology,Technology,Artificial Intelligence,Research",Most educators say they have not received any professional development on artificial intelligence.,Most educators say they have not received any professional development on artificial intelligence.,http://schema.org,,NewsArticle,Arianna Prothero,"July 14, 2023","What Educators Know About Artificial Intelligence, in 3 Charts","{'@type': 'Organization', 'name': 'Education Week', 'url': 'https://www.edweek.org', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/14/75/99f6320f4351a3fc7387b9e52280/ari-prothero-blue-updated.jpg'}}","{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/28/09/efd019a94baab80b743f64afd2de/ai-tools-train-1502238107.jpg'}","Technology, Classroom Technology",N/A,N/A,"November 16, 2023",,https://www.edweek.org/technology/what-educators-know-about-artificial-intelligence-in-3-charts/2023/07,,,,,,https://epe.brightspotcdn.com/28/09/efd019a94baab80b743f64afd2de/ai-tools-train-1502238107.jpg,,"What Educators Know About Artificial Intelligence, in 3 Charts,What Educators Know About Artificial Intelligence, in 3 Charts","{'@type': 'WebPage', '@id': 'https://www.edweek.org/technology/what-educators-know-about-artificial-intelligence-in-3-charts/2023/07'}",,,,,,,,,,,,,,en-US,,,,,2023,,,,,,,,News,"Classroom Technology,Technology,Artificial Intelligence,Research",https://www.edweek.org/technology/what-educators-know-about-artificial-intelligence-in-3-charts/2023/07#comments,true,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Education Week', 'description': 'Arianna Prothero covers technology, student well-being, and the intersection of the two for Education Week.', 'email': 'aprothero@educationweek.org', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/14/75/99f6320f4351a3fc7387b9e52280/ari-prothero-blue-updated.jpg'}, 'jobTitle': 'Assistant Editor', 'name': 'Arianna Prothero', 'url': 'https://www.edweek.org/by/arianna-prothero'}]",https://www.edweek.org/about,P1M,380,,
https://news.google.com/rss/articles/CBMijAFodHRwczovL2ZlZGVyYWxuZXdzbmV0d29yay5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvMjAyMy8wNy9uc2Etd29ya2luZy1vbi1uZXctYWktcm9hZG1hcC1hcy1pbnRlbC1hZ2VuY2llcy1ncmFwcGxlLXdpdGgtcmVjZW50LWFkdmFuY2VzL9IBAA?oc=5,NSA working on new AI 'roadmap' as intel agencies grapple with recent advances - Federal News Network,2023-07-14,Federal News Network,https://federalnewsnetwork.com,"The intelligence community is grappling, like many industries and society at large, with rapid advances in large language models and generative artificial intelligence over the past nine months","['central intelligence agency', 'chatgpt', 'defense intelligence agency', 'george barnes', 'national security agency', 'office of the director of national intelligence']","The intelligence community is grappling, like many industries and society at large, with rapid advances in large language models and generative artificial intelligence over the past nine months","The intelligence community is grappling, like many industries and society at large, with rapid advances in large language models and generative artificial intelligence over the past nine months",http://schema.org,,NewsArticle,"[{'@type': 'Person', 'name': 'Justin Doubleday'}]",2023-07-14T22:17:50Z,NSA working on new AI ‘roadmap’ as intel agencies grapple with recent advances,"{'@type': 'Organization', 'name': 'Federal News Network', 'logo': {'@type': 'ImageObject', 'url': 'https://federalnewsnetwork.com/wp-content/themes/wfed/assets/img/icons/logo.png'}}","{'@type': 'ImageObject', 'url': 'https://federalnewsnetwork.com/wp-content/uploads/2022/08/GettyImages-1345658982-1880x1058.jpg', 'width': 1880, 'height': 1058}",N/A,N/A,"







OPM takes first step to identify what federal employees need to know to work with AI


Artificial Intelligence
Read more

",2023-07-17T11:40:58Z,"[{'@type': 'BreadcrumbList', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://federalnewsnetwork.com/#listItem', 'position': 1, 'name': 'Home', 'item': 'https://federalnewsnetwork.com/', 'nextItem': 'https://federalnewsnetwork.com/artificial-intelligence/2023/#listItem'}, {'@type': 'ListItem', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/#listItem', 'position': 2, 'name': '2023', 'item': 'https://federalnewsnetwork.com/artificial-intelligence/2023/', 'nextItem': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/#listItem', 'previousItem': 'https://federalnewsnetwork.com/#listItem'}, {'@type': 'ListItem', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/#listItem', 'position': 3, 'name': 'July', 'item': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/', 'nextItem': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#listItem', 'previousItem': 'https://federalnewsnetwork.com/artificial-intelligence/2023/#listItem'}, {'@type': 'ListItem', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#listItem', 'position': 4, 'name': 'NSA working on new AI ‘roadmap’ as intel agencies grapple with recent advances', 'previousItem': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/#listItem'}]}, {'@type': 'NewsArticle', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#newsarticle', 'name': 'NSA working on new AI ‘roadmap’ as intel agencies grapple with recent advances', 'headline': 'NSA working on new AI ‘roadmap’ as intel agencies grapple with recent advances', 'author': {'@id': 'https://federalnewsnetwork.com/author/jdoubledayfederalnewsnetwork-com/#author'}, 'publisher': {'@id': 'https://federalnewsnetwork.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://federalnewsnetwork.com/wp-content/uploads/2022/08/GettyImages-1345658982-e1683568374410.jpg', 'width': 1841, 'height': 1241}, 'datePublished': '2023-07-14T22:17:50-04:00', 'dateModified': '2023-07-17T11:40:58-04:00', 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#webpage'}, 'isPartOf': {'@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#webpage'}, 'articleSection': 'All News, Artificial Intelligence, Intelligence Community, Technology, Central Intelligence Agency, ChatGPT, Defense Intelligence Agency, George Barnes, National Security Agency, Office of the Director of National Intelligence, justin-doubleday', 'dateline': 'Published on July 14, 2023.'}, {'@type': 'Organization', '@id': 'https://federalnewsnetwork.com/#organization', 'name': 'Federal News Network', 'url': 'https://federalnewsnetwork.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://federalnewsnetwork.com/wp-content/themes/wfed/assets/img/media_kit/JPG/fnn-logo-hor-small.jpg', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#organizationLogo'}, 'image': {'@id': 'https://federalnewsnetwork.com/#organizationLogo'}, 'sameAs': ['https://twitter.com/FederalNewsNet', 'https://www.instagram.com/federalnewsnet/', 'https://www.youtube.com/@federalnewsnetwork', 'https://www.linkedin.com/company/federal-news-network', 'https://en.wikipedia.org/wiki/WFED'], 'contactPoint': {'@type': 'ContactPoint', 'telephone': '+12028955086', 'contactType': 'Newsroom'}}, {'@type': 'Person', '@id': 'https://federalnewsnetwork.com/author/jdoubledayfederalnewsnetwork-com/#author', 'url': 'https://federalnewsnetwork.com/author/jdoubledayfederalnewsnetwork-com/', 'name': 'Justin Doubleday'}, {'@type': 'WebPage', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#webpage', 'url': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/', 'name': 'NSA working on new AI ‘roadmap’ as intel agencies grapple with recent advances', 'description': 'The intelligence community is grappling, like many industries and society at large, with rapid advances in large language models and generative artificial intelligence over the past nine months', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://federalnewsnetwork.com/#website'}, 'breadcrumb': {'@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#breadcrumblist'}, 'author': {'@id': 'https://federalnewsnetwork.com/author/jdoubledayfederalnewsnetwork-com/#author'}, 'creator': {'@id': 'https://federalnewsnetwork.com/author/jdoubledayfederalnewsnetwork-com/#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://federalnewsnetwork.com/wp-content/uploads/2022/08/GettyImages-1345658982-e1683568374410.jpg', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#mainImage', 'width': 1841, 'height': 1241}, 'primaryImageOfPage': {'@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/#mainImage'}, 'datePublished': '2023-07-14T22:17:50-04:00', 'dateModified': '2023-07-17T11:40:58-04:00'}, {'@type': 'WebSite', '@id': 'https://federalnewsnetwork.com/#website', 'url': 'https://federalnewsnetwork.com/', 'name': 'Federal News Network', 'alternateName': 'WFED', 'description': 'Helping feds meet their mission.', 'inLanguage': 'en-US', 'publisher': {'@id': 'https://federalnewsnetwork.com/#organization'}}]",https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/,Artificial Intelligence,,,,,https://federalnewsnetwork.com/wp-content/uploads/2022/08/GettyImages-1345658982-e1683568374410-150x150.jpg,,,"{'@type': 'WebPage', '@id': 'https://federalnewsnetwork.com/artificial-intelligence/2023/07/nsa-working-on-new-ai-roadmap-as-intel-agencies-grapple-with-recent-advances/'}",,,,2023-07-14T22:17:50Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,['Justin Doubleday'],"{'@type': 'SpeakableSpecification', 'cssSelector': ['.schema-title', '.schema-summary']}"
https://news.google.com/rss/articles/CBMijAFodHRwczovL3d3dy5zbWguY29tLmF1L3BvbGl0aWNzL2ZlZGVyYWwvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVzaGFwaW5nLXRoZS1qb2JzLW1hcmtldC1pbi1hdXN0cmFsaWEtcy1iaWdnZXN0LWNpdGllcy0yMDIzMDcxMi1wNWRubzIuaHRtbNIBjAFodHRwczovL2FtcC5zbWguY29tLmF1L3BvbGl0aWNzL2ZlZGVyYWwvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVzaGFwaW5nLXRoZS1qb2JzLW1hcmtldC1pbi1hdXN0cmFsaWEtcy1iaWdnZXN0LWNpdGllcy0yMDIzMDcxMi1wNWRubzIuaHRtbA?oc=5,Artificial intelligence reshaping the jobs market in Australia’s biggest cities - Sydney Morning Herald,2023-07-16,Sydney Morning Herald,https://www.smh.com.au,"There were 756 jobs ads across Australia that referenced AI skills in 2012. By 2021, there were 20,505.",,"There were 756 jobs ads across Australia that referenced AI skills in 2012. By 2021, there were 20,505.","There were 756 jobs ads across Australia that referenced AI skills in 2012. By 2021, there were 20,505.",http://schema.org,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.smh.com.au/politics', 'name': 'Politics'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.smh.com.au/politics/federal', 'name': 'Federal'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.smh.com.au/topic/artificial-intelligence-5ui', 'name': 'AI'}}]",BreadcrumbList,"{'@type': 'Person', 'name': 'Anthony Galloway'}",2023-07-15T19:00:00+00:00,Artificial intelligence reshaping the jobs market in Australia’s biggest cities,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'height': '628', 'url': 'https://www.smh.com.au/smh.png', 'width': '1200'}, 'name': 'The Sydney Morning Herald'}","{'@type': 'ImageObject', 'height': 450, 'url': 'https://static.ffx.io/images/$zoom_0.5176%2C$multiply_0.7554%2C$ratio_1.777778%2C$width_1059%2C$x_0%2C$y_0/t_crop_custom/q_86%2Cf_auto/0084a62f0074ad1b6af8dd2b904e153ebca2f77f', 'width': 800}",Federal,N/A,"ExclusivePoliticsFederalAIThis was published 1 year agoArtificial intelligence reshaping the jobs market in Australia’s biggest citiesBy Anthony Galloway July 16, 2023 — 5.00amSaveLog in, register or subscribe to save articles for later.Save articles for laterAdd articles to your saved list and come back to them any time.Got itShareNormal text sizeLarger text sizeVery large text size7View all commentsAdvertisement Labour markets in NSW and Victoria are among the first to show signs of being reshaped by artificial intelligence, accounting for the vast majority of new jobs using the emerging technology in Australia.As the federal government considers how to regulate the technology, Australia’s first AI human capital index showed the country’s two biggest states accounted for 76 per cent of new AI jobs, despite having 57 per cent of the overall workforce.There were 756 jobs ads across Australia that referenced AI skills in 2012. By 2021, there were 20,505.Credit: Stephen KiprillisAmid the rapid acceleration of AI applications such as ChatGPT, the federal government last month outlined plans to regulate the use of the technology.The new research by economics advisory firm Mandala Partners showed private sector investment in AI was growing, with banks, consultancies and accounting firms leading the way. The federal government, Commonwealth Bank, Deloitte, Amazon and Macquarie Bank were employing the most workers with skills in the technology.But the study revealed a gap between different states and industries in the development of the technology.NSW, Victoria and the ACT were outperforming on the development of the technology, while Queensland and WA were below expected baselines.NSW accounted for 49 per cent of AI jobs and Victoria had 27 per cent, while Queensland and WA each had 8 per cent of AI-related workers.The study measured job advertisements over the past decade to identify which industries and organisations were seeking skills in artificial intelligence, and compared the results with overall labour force figures for each state.AdvertisementRelated ArticleOpinionAIAnother robo-debt disaster’s inevitable if we give AI too much autonomyRachael FalkCEO of the Cyber Security Cooperative Research CentreMandala Partners managing partner Amit Singh said investment in AI needed to be encouraged across the country so that the productivity gains and benefits from the technology are more evenly spread.“This is not just a technology for people in Sydney and Melbourne,” he said. “It is also for farmers, doctors, miners, teachers in regional Australia. It’s for all of us.”The research also showed large firms were competing for AI talent with the Commonwealth public service.The federal government posted at least 2728 AI job advertisements over the past seven years, followed by the Commonwealth Bank on 1739, Deloitte on 1287, Amazon on 1077, Macquarie Bank on 983, and the NSW government on 867.As AI has moved from theory to practice, investment had moved from universities to the private sector in Australia, the research found.In 2012, there were 756 jobs advertised referencing AI skills, while in 2021 there were 20,505.A decade ago, investment was dominated by universities and sectors like financial services and mining. But then over the next five years, professional services and technology firms ramped up their investment to provide AI services to their clients.Over the past year, firms in other industries like logistics and manufacturing had begun to invest in AI capabilities.The professional services industry now has the most AI jobs, followed by financial services, education and then IT and media.The research also highlighted a sharp downturn in AI jobs being advertised during last year’s tech layoffs, but that had since been reversed.“It’s clear that more and more roles need AI skills,” Singh said.“This is not new, it’s been happening for 10 years. But what is new is that after the tech downturn, the AI skills trend is accelerating again.”Related ArticleExclusiveAILabor to take first steps in writing AI rule bookThe government has begun consultations with industry and AI experts as it formulates a new policy for regulating the technology.A spokesman for Industry and Science Minister, Ed Husic, said the government wanted to see the benefits of AI maximised while mitigating risks.“The government is in the midst of consultations with industry and other stakeholders about the appropriate regulation of AI to this end,” the spokesman said.“Further steps will be outlined when submissions have been considered.”Opposition science spokesman Paul Fletcher said the new study showed there was strong demand for people with AI skills across the economy.Related ArticleExplainerRobots‘Die as a human or live forever as a cyborg’: Will robots rule the world?“Of course we need to be alive to potential risks and whether our regulatory frameworks need updating,” he said.“But the bigger challenge when it comes to AI is making sure that Australia does not fall behind globally in this competitive field.“Australia produces fewer than 200 PhDs a year in AI; we need to build the number of skilled AI professionals.”Cut through the noise of federal politics with news, views and expert analysis from Jacqueline Maley. Subscribers can sign up to our weekly Inside Politics newsletter here.SaveLog in, register or subscribe to save articles for later.ShareLicense this articleAIEmploymentJobsFuture technologyAnthony Galloway is political correspondent for The Sun-Herald and The Sunday Age.Connect via email.7View all commentsMost Viewed in PoliticsStates pump up ‘key technology’ to get households off gasEmbattled Liverpool council backs costly legal challenge to administration order‘It’s a delusion’: Kelty hits back at Coalition call to deregister CFMEULiverpool Council to take Minns government to court over looming suspensionA quarter of a million shortfall: Housing target unlikely to be metThe forgotten tax adding billions to the country’s insurance premiums



SMH RECOMMENDS








World
New details revealed about Trump bullet wound
Former US president Donald Trump underwent CT scans for the bullet wound he sustained in last weekend’s assassination attempt, but did not require stitches.










World
Endorsements, donations come rolling in for Kamala Harris
And after warning Biden that he would lose to Trump, former House Speaker Nancy Pelosi - one of the most influential Democrats in the country - gave her unequivocal backing to his 59-year-old deputy.










SMH
The ‘deep animus’ behind the beef between ABC boss and a radio legend
ABC chair Kim Williams says he hasn’t spoken to broadcaster Phillip Adams in 35 years and is puzzled by the animosity the former Late Night Live host has for him.



 







Promoted











Fisher Investments
7 Wealth Tips Once Your Portfolio Reaches $1 Million










Sleep Apnea News
Doctor: Sleep Apnea Treatment Without CPAP (It's Genius)












 

Barefoot Vitality
Neurologists Amazed: Barefoot Shoes are The Best Thing You Can Do in 2024



 







 











Online Shopping Tools
Amazon's Worst Nightmare: Thousands Canceling Prime for This Clever










financewallet.org
District Of Columbia Launches New Policy For Cars Used Less Than 50 Miles/Day










WG Men
Top Doctor Reveals the Root Cause of ED in Men Over 50










Online Shopping Tools
Former Flight Attendant Shows How To Fly Business Class For Up To 50% Off










Sunrise Village
If You Need To Kill Time On Your Computer, This Addictive Game Is A Must.










AHF
How Men Born Before 1960 Can Build Muscle (Try Tonight)










MetalRoofNation.com
Don't Overpay For Your New Roof In 2024










Home Value Calculator - Sponsored Links
Unbelievable: Calculator Shows The Value Of Your House Instantly (Take a Look)










Popular Searches|Search Ads
The New EX90 SUV Will Leave You Speechless (See Prices)



 




From our partnersLoading 3rd party ad contentLoading 3rd party ad contentLoading 3rd party ad contentLoading 3rd party ad contentAdvertisement",2023-07-15T19:00:00+00:00,,,,,True,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Sydney Morning Herald', 'productID': 'smh.com.au:webonly'}",,"{'@id': 'https://www.smh.com.au/politics/federal/artificial-intelligence-reshaping-the-jobs-market-in-australia-s-biggest-cities-20230712-p5dno2.html', '@type': 'WebPage'}",,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vdHJhZGVicmFpbnMuaW4vdG9wLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXN0b2Nrcy1pbi1pbmRpYS_SAQA?oc=5,Top Artificial Intelligence Stocks in 2023 - Best AI Stocks in India - Trade Brains,2023-07-15,Trade Brains,https://tradebrains.in,"In this article, we focus on the Top Artificial intelligence Stocks in India, stock market that provides opportunities in this field. Keep..",N/A,"In this article, we focus on Top Artificial intelligence Stocks in Indian stock market that provides opportunities in this field. Keep reading to find out more. ","In this article, we focus on Top Artificial intelligence Stocks in Indian stock market that provides opportunities in this field. Keep reading to find out more. ",https://schema.org,,,,,,,,N/A,N/A,"

Top Artificial Intelligence Stocks in 2023 – Best AI Stocks in India
 by Trade Brains | Jul 15, 2023  | Portfolio, Stocks | 11 comments


      

Top Artificial Intelligence Stocks in India: The world is changing at an unprecedented speed. A decade one would think twice before watching an online high-resolution video, today we have self-driving electric cars entering the Indian markets and human intelligence-like machines and robots doing our work. This has also opened new opportunities for investors to jump in early into these prospects. 


In this article, we focus on Top Artificial Intelligence Stocks in India stock market that provides opportunities in this field. Keep reading to find out more.  







YouTube ChannelError loading media4 Best New-Age Investment Options in 2024 _ High Returns and Low Risks _ Trade BrainsunstickShare this videoCopyPausePlay00:00% Buffered0PreviousPausePlayNextLive00:00 / 10:58UnmuteMuteSettingsExit fullscreenFullscreenCopy video urlPlay / PauseMute / UnmuteReport a problemLanguageBackDefaultEnglishEspañolУкраїнськаРусскийShareBackFacebookTwitterLinkedinEmailVidverto Player








Table of Contents

AI Stocks in IndiaTop Artificial Intelligence Stocks #1. Tata ElxsiTop Artificial Intelligence Stocks #2. AffleTop Artificial Intelligence Stocks #3. Kellton Tech SolutionsTop Artificial Intelligence Stocks #4. OracleTop Artificial Intelligence Stocks #5. Happiest MindsTop Artificial Intelligence Stocks #6. Persistent SystemsTop Artificial Intelligence Stocks #7. CyientTop Artificial Intelligence Stocks #8. BoschList Of Best AI Stocks in IndiaIs AI a good stock to buy?In Closing 
AI Stocks in India

Artificial Intelligence refers to the simulation of human intelligence by machines, especially computer systems. These allow tasks earlier required manpower to be performed in lesser time and with greater accuracy. 
AI stocks are not only a great investment for the future but also could be a game-changer for the Indian economy. It is expected that AI has the potential to make up 15% of India’s current gross value in 2035 or $957 billion. Following are some of the top companies working on AI in the Indian stock market. Note: If you want to learn Candlesticks and Chart Trading from Scratch, here’s the best book available on Amazon! Get the book now!

Top Artificial Intelligence Stocks #1. Tata Elxsi

Tata Elxsi was founded in 1989 to develop and promote applications of electronics, embedded systems, and software. Today Tata Elxsi is one of the worlds leading providers of design and technology services in various industries. These include automotive, broadcasting, communication, healthcare and transportation. 



The company, part of the Tata Group is listed in the stock market and performs in the large-cap range. When it comes to AI the company has had success in various fields like self-driving cars, video analytics solutions etc. 
The company also works on other technology-related aspects like IoT (Internet of Things), cloud, and smart mobility. In the previous year, Tate Elxsi won the NASSCOM Engineering & Innovation Excellence Awards 2021 for Engineering Service Providers for all product groups. 
Financially the company has performed well. Tata Elxsi has had a compounded sales growth of 15% for the last 5 years. 
QUICK READ – Best Battery Sector Stocks in India – Overview and Market Share



Top Artificial Intelligence Stocks #2. Affle

Founded in 2006, Affle is a global technology company. The company is mainly focused on providing end-to-end solutions for app marketing. 
Here Affle delivers consumer acquisitions, engagements, and transactions through relevant mobile advertising. Their AI uses behavioural signals, marketing attribution, and transactional data from users to predict one’s interests. This allows them to direct ads as per these preferences enriching users’ ad content. 
Affle also provides enterprises with end-to-end solutions to help them engage with mobile users. They currently have 20 patents with 6 granted in the US related to digital advertising, fraud detection and voice-based intelligence.



The company has 14 patents filed in the US, India and Singapore related to innovative futuristic use cases   
Top Artificial Intelligence Stocks #3. Kellton Tech Solutions

Founded in 1993 and based in Hyderabad, Kellton Tech Solutions is an information technology and outsourcing company. 
The company provides services for digital transformation, digital connected enterprise, SAP, outsourced product development, and digital commerce and marketing.



They are focused on using AI to solve challenges that would otherwise take a lot of human intellect. The company does this by automating complex tasks helping businesses get more out of machines. 
Top Artificial Intelligence Stocks #4. Oracle

Oracle helps companies use prebuilt artificial intelligence, and data-driven cloud applications to automate operations resulting in saved time and cost and improved customer experience due to accelerated processes. 
Its AI applications can be used across various fields. These include optimising cash flows, automating receivables and payables, and procurement & inventory for finance teams. 
In sales, their applications help agents convert sales by helping them recognize opportunities with the highest probability. These applications are also extended to HR helping them improve employee engagement and prospective candidate quality. 
Their cloud applications help speed up automation and reduce human errors. 
Top Artificial Intelligence Stocks #5. Happiest Minds

Founded in 2011, Happiest Minds is an IT consulting and services company. The company offers its clients various services which include artificial intelligence, cloud, internet of things(IoT), blockchain robotics/drones, virtual/augmented reality, etc. 
The company uses artificial intelligence for language processing, image analytics, video analytics, and emerging technologies like AR and VR. In addition to this, the company also helps businesses implement robotic smacking use of AI resulting in saved time and cost. 
The company was listed on the stock exchange in September 2020.
Top Artificial Intelligence Stocks #6. Persistent Systems

Founded in 1993 and based in Pune, Persistent Systems offers its clients secure and scalable mobile networking capability. 
The company uses modern Wave Relay MANET technology for this purpose. The company uses AI to help companies improve and scale their operations, prioritize cases and design platform architecture. 
Financially the company has performed well too. It has achieved a compounded sales growth of 15% for the last five years.
Top Artificial Intelligence Stocks #7. Cyient

Founded in 1991, Cyient is an engineering, outsourcing and technology solutions company. They provide AI tools and assist companies to achieve their respective goals. 
Based in Hyderabad the company was also among the top 30 outsourcing companies in the world. Financially the company has achieved a compounded sales growth of 10%. 
Since 2000, the company has made 11 acquisitions and 3 investments further aiding its growth. 
ALSO READ 

Best Chemical Stocks in India 2023 – List of Fundamentally Strong Stocks

Top Artificial Intelligence Stocks #8. Bosch

Bosch has its arms in several fields. The company started the Bosch Center for Artificial Intelligence (BCAI) in 2017 to develop AI-related products and services. 
It also produces research that produces differentiation in all of its arms. The company uses AI and machine learning in vehicle diagnostics, predictive maintenance, large scale simulations etc. 

List Of Best AI Stocks in India



StockMarket Cap in CrROENet Profit Margin




Tata Elxsi47,046 40.97 24.01


Affle14,348 2819.85%


Kellton Tech Solutions794.64 15.748.36%


Oracle34,191 25.35 31.7%


Happiest Minds14,368 30.84 16.1%


Persistent Systems39,532 26.3611.03%


Cyient16,438 15.8 8.55


Bosch56,267 13.149.54




Is AI a good stock to buy?
Presently, AI as a revenue segment earns lesser income than the other larger divisions for tech companies in India. So investors hoping to enter a tech company in the hope of an AI boom must take this into account. Unlike in the US, there is not any listed stock in India that earns a majority of its revenues from an AI product.
Thus, at this point in time, investors should take a holistic approach to investing in companies instead of being solely focused on their AI capabilities.
In Closing 
The current technological swing towards AI has attracted several companies to invest in the technology. This also has resulted in investors wanting a piece of the action. Investing in the right Artificial Intelligence stocks will be extremely fruitful in the long term.



That’s all for this post on Top Artificial Intelligence Stocks in India, let us know which AI stock you find the most attractive in the comments below. Happy Investing!
By utilizing the stock screener, stock heatmap, portfolio backtesting, and stock compare tool on the Trade Brains portal, investors gain access to comprehensive tools that enable them to identify the best stocks also get updated with stock market news, and make well-informed investment decisions.

Start Your Stock Market Journey Today!
Want to learn Stock Market trading and Investing? Make sure to check out exclusive Stock Market courses by FinGrad, the learning initiative by Trade Brains. You can enroll in FREE courses and webinars available on FinGrad today and get ahead in your trading career. Join now!!

Promoted Content
Crohn's Disease - Usual Symptoms (Click Here To Take A Look)Search AdsRumors About Baron Go From Bad To WorseInspiredotWashington Seniors Can Get $45k Life Insurance at No CostHyundai's New Santa Fe Suv Is Turning Heads (See Prices)HyundaiBarron Trump's Ex Just Dropped This Bombshell!Radar MediaNew 2024 Hyundai Palisade Is Just Sheer Perfection - See PricesSearch AdsPsoriatic Arthritis Warning Symptoms (Don't Ignore Them)Search AdsEarly Signs And Symptoms Of Alzheimer Seniors Should Look Out ForSearch AdsCan Dental Implants Be Paid For By Medicare? Click To SeeSearch AdsThe Multi-Utility Spatula Every Griller Needs. See It In Action!Online SolutionsRam 1500 For Seniors May Take You By Surprise. (See Prices)Search AdsThe Next Wave Of Hearing Aids: Prices In 2024 Will Astonish YouSearch AdsWashington: New Two Bedroom Senior Apartments 250/month Are Stunning!Search AdsWashington: Singles On The Hunt For Genuine ConnectionsDream SinglesJill Biden Thought No One Saw, But She Was Caught On CameraBuzz Day

 







 

Sarasij Majumder 
					on July 27, 2021 at 4:59 pm				



wELL SELECTED
Reply 






 

Anand 
					on January 12, 2022 at 5:08 am				



Which is better  AI stock
Reply 






 

DC AGNIHOTRI 
					on January 21, 2022 at 2:44 pm				



Happiest Mind
Reply 






 

GangadharaRao Gundlapalli 
					on January 29, 2023 at 8:52 pm				



Which company is best for reality sector in small caps
Reply 








 

DC AGNIHOTRI 
					on January 27, 2022 at 10:32 am				



Happiest Mind
Reply 






 

Ranjit Bhowmick 
					on January 30, 2022 at 10:49 am				



Hehe
Reply 








 

Deepak Sen 
					on February 12, 2022 at 12:33 pm				



I think Tata alexey is good from all of these artificial intelligence stocks. Happiest ming also good and may be these all tech Giants will sonner come into the metaverse because it will be a hot topic in future.
It’s my own perspective! Maybe something think different.
Reply 






 

abdul mateen 
					on July 26, 2023 at 2:09 pm				



well said dear. Its your perspective,.
Reply 








 

Deepak Ravi 
					on August 13, 2022 at 9:52 am				



its a good information for indian to invest in future technology.
Reply 






 

Abhilash 
					on October 12, 2022 at 7:54 pm				



is it worth investing in Cyient compared to others listed here?
Happiest minds is still the best one ? please help
Reply 






 

Abhilash 
					on October 12, 2022 at 7:54 pm				



is it worth investing in Cyient compared to others listed here?
Happiest minds is still the best one ?
Reply 





Submit a Comment Cancel replyYour email address will not be published. Required fields are marked *Comment * Name * 
Email * 
Website 
 

 
 
",,"[{'@type': 'WebPage', '@id': 'https://tradebrains.in/top-artificial-intelligence-stocks-in-india/', 'url': 'https://tradebrains.in/top-artificial-intelligence-stocks-in-india/', 'name': 'Top Artificial Intelligence Stocks in 2023 - Best AI Stocks in India', 'isPartOf': {'@id': 'https://tradebrains.in/#website'}, 'primaryImageOfPage': {'@id': 'https://tradebrains.in/top-artificial-intelligence-stocks-in-india/#primaryimage'}, 'image': {'@id': 'https://tradebrains.in/top-artificial-intelligence-stocks-in-india/#primaryimage'}, 'thumbnailUrl': 'https://tradebrains.in/wp-content/uploads/2022/01/Artificial-Intelligence-Stocks-in-India-cover.jpg', 'datePublished': '2023-07-15T12:30:00+00:00', 'dateModified': '2024-05-20T08:26:05+00:00', 'author': {'@id': 'https://tradebrains.in/#/schema/person/3b02446adebf02714e122d0fc165355d'}, 'description': 'In this article, we focus on the Top Artificial intelligence Stocks in India, stock market that provides opportunities in this field. Keep..', 'breadcrumb': {'@id': 'https://tradebrains.in/top-artificial-intelligence-stocks-in-india/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://tradebrains.in/top-artificial-intelligence-stocks-in-india/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://tradebrains.in/top-artificial-intelligence-stocks-in-india/#primaryimage', 'url': 'https://tradebrains.in/wp-content/uploads/2022/01/Artificial-Intelligence-Stocks-in-India-cover.jpg', 'contentUrl': 'https://tradebrains.in/wp-content/uploads/2022/01/Artificial-Intelligence-Stocks-in-India-cover.jpg', 'width': 1280, 'height': 854, 'caption': 'Artificial Intelligence Stocks in India cover image'}, {'@type': 'BreadcrumbList', '@id': 'https://tradebrains.in/top-artificial-intelligence-stocks-in-india/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://tradebrains.in/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Blog', 'item': 'https://tradebrains.in/blog/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top Artificial Intelligence Stocks in 2023 &#8211; Best AI Stocks in India'}]}, {'@type': 'WebSite', '@id': 'https://tradebrains.in/#website', 'url': 'https://tradebrains.in/', 'name': 'Trade Brains', 'description': 'Simplified Investing for Everyone', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://tradebrains.in/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://tradebrains.in/#/schema/person/3b02446adebf02714e122d0fc165355d', 'name': 'Trade Brains', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://tradebrains.in/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/f15a3daecbeb76ce772c76781c718cd7?s=96&d=wavatar&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/f15a3daecbeb76ce772c76781c718cd7?s=96&d=wavatar&r=g', 'caption': 'Trade Brains'}, 'sameAs': ['kritesh.abhishek'], 'url': 'https://tradebrains.in/author/trade-brains/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,headline,image,datePublished,dateModified,author,article:section,article:summary,article text,mainEntityOfPage,alternativeHeadline,isPartOf,publisher,isAccessibleForFree,hasPart,itemListElement,url,articleSection,name,thumbnailUrl,commentCount,aggregateRating,comment,@graph,articleBody,dateCreated
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3Lm1hc3RlcmNhcmQuY29tL25ld3MvcGVyc3BlY3RpdmVzLzIwMjAvYWktYW5kLXRoZS1mdXR1cmUtb2Ytd29yay10aHJlZS13YXlzLXRvLW5hdmlnYXRlLWRpc3J1cHRpb24v0gEA?oc=5,AI and the future of work: Three ways to navigate disruption - Mastercard,2020-12-26,Mastercard,https://www.mastercard.com,Artificial intelligence could radically transform the way we work. Mastercard leaders share insights into avoiding unintended consequences and ensuring a smarter future for us all.,N/A,Artificial intelligence could radically transform the way we work. Mastercard leaders share insights into avoiding unintended consequences and ensuring a smarter future for us all.,Artificial intelligence could radically transform the way we work. Mastercard leaders share insights into avoiding unintended consequences and ensuring a smarter future for us all.,https://schema.org,NewsArticle,AI and the future of work: Three ways to navigate disruption,['https://www.mastercard.com/news/media/yb2biksn/ai-still-3.jpg'],0001-01-01T00:00:00,0001-01-01T00:00:00,"[{'@type': 'Organization', 'name': 'Mastercard', 'url': 'https://www.mastercard.com'}]",N/A,N/A,"

AI and the future of work: Three ways to navigate disruption



The enormous potential of artificial intelligence could radically transform the way we work. In fact, the World Economic Forum‚Äôs just-released Future of Jobs Report 2020 says that within five years, the amount of time spent on tasks at work by humans and machines will be equal. The possibilities for disruption are real, but Mastercard leaders say we can avoid unintended consequences of innovation and ensure that AI can augment and empower humans workers, ensuring a smarter future for all.







The data provided in this video is part of a comprehensive study Mastercard commissioned with Kantar Group to explore the disruptive potential of AI.

",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS90ZWNobm9sb2d5LzIwMjAvMTIvMjMvZ29vZ2xlLXRpbW5pdC1nZWJydS1haS1ldGhpY3Mv0gEA?oc=5,Timnit Gebru was critical of Google‚Äôs approach to ethical AI - The Washington Post,2020-12-23,The Washington Post,https://www.washingtonpost.com,The abrupt firing of one of the most high-profile Black women in AI shows that Google is pushing back on the kind of scrutiny that it claims to welcome.,timnit gebru,The abrupt firing of one of the most high-profile Black women in AI shows that Google is pushing back on the kind of scrutiny that it claims to welcome.,The abrupt firing of one of the most high-profile Black women in AI shows that Google is pushing back on the kind of scrutiny that it claims to welcome.,https://schema.org,BreadcrumbList,Google hired Timnit Gebru to be an outspoken critic of unethical AI. Then she was fired for it. ,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/TQLFY3SD4MI6XLBKHLAPFOGO5M.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/TQLFY3SD4MI6XLBKHLAPFOGO5M.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/TQLFY3SD4MI6XLBKHLAPFOGO5M.jpg&w=800&h=600', 'height': 800, 'width': 600}]",2020-12-23T19:15:17.064Z,2020-12-30T17:09:18.348Z,"{'@type': 'Person', 'name': 'Nitasha Tiku', 'url': 'https://www.washingtonpost.com/people/nitasha-tiku/'}",Technology,N/A,"Google AI research scientist Timnit Gebru speaks on Sept. 7, 2018, at TechCrunch Disrupt SF 2018 at the Moscone Center in San Francisco. (Kimberly White/Getty Images/TechCrunch) By  Nitasha TikuDecember 23, 2020 at 2:15 p.m. ESTTwo months ago, Google promoted Timnit Gebru, co-lead of a group focused on ethical artificial intelligence, after she earned a high score on her annual employee appraisal. Gebru is one of the most high-profile Black women in her field and a powerful voice in the new field of ethical AI, which seeks to identify issues around bias, fairness, and responsibility.Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeIn his peer review of Gebru, Jeff Dean, the head of Google Artificial Intelligence, left only one comment when asked what she could do to have a greater impact, according to documents viewed by The Washington Post: Ensure that her team helps make a promising new software tool for processing human language ‚Äúconsistent with our AI Principles.‚ÄùIn an email thanking Dean for his review, Gebru let him know that her team was already working on a paper about the ethical risks around the same language models, which are essential to understanding the complexity of language in search queries. On Oct. 20, Dean wrote that he wanted to see a draft, adding, ‚Äúdefinitely not my area of expertise, but would definitely learn from reading it.‚ÄùAdvertisementStory continues below advertisementSix weeks later, Google fired Gebru while she was on vacation.üíªFollow TechnologyFollow‚ÄúI can‚Äôt imagine anybody else who would be safer than me,‚Äù Gebru, 37, said. ‚ÄúI was super visible. I‚Äôm well known in the research community, but also the regulatory space. I have a lot of grass-roots support ‚Äî and this is what happened.‚ÄùGoogle‚Äôs star AI ethics researcher, one of a few Black women in the field, says she was fired for a critical emailIn an internal memo that he later posted online explaining Gebru‚Äôs departure, Dean told employees that the paper ‚Äúdidn‚Äôt meet our bar for publication‚Äù and ‚Äúignored too much relevant research‚Äù on recent positive improvements to the technology. Gebru‚Äôs superiors had insisted that she and the other Google co-authors either retract the paper or remove their names. Employees in Google Research, the department that houses the ethical AI team, say authors who make claims about the benefits of large language models have not received the same scrutiny during the approval process as those who highlight the shortcomings.AdvertisementStory continues below advertisementHer abrupt firing shows that Google is pushing back on the kind of scrutiny that it claims to welcome, according to interviews with Gebru, current Google employees, and emails and documents viewed by The Post.GET CAUGHT UPStories to keep you informedPreviousNextThe Republicans are here. For Milwaukee, that‚Äôs complicated.SparkleSummary is AI-generated, newsroom-reviewed.Amazon Prime Day causes workplace injuries, Senate probe findsSparkleSummary is AI-generated, newsroom-reviewed.Why melting ice sheets are making our days longer SparkleSummary is AI-generated, newsroom-reviewed.Housing, once the ticket to wealth in China, is now draining fortunesSparkleSummary is AI-generated, newsroom-reviewed.Make your job less painful, at least physicallySparkleSummary is AI-generated, newsroom-reviewed.It raises doubts about Silicon Valley‚Äôs ability to self-police, especially when it comes to advanced technology that is largely unregulated and being deployed in the real world despite demonstrable bias toward marginalized groups. Already, AI systems shape decision-making in law enforcement, employment opportunity and access to health care worldwide.That made Gebru‚Äôs perspective essential in a field that is predominantly White, Asian and male. Women made up only 15 percent of the AI research staff at Facebook and 10 percent at Google, according to a 2018 report in Wired magazine. At Google, Black women make up 1.6 percent of the workforce.AdvertisementStory continues below advertisementAlthough Google publicly celebrated Gebru‚Äôs work identifying problems with AI, it disenfranchised the work internally by keeping it hierarchically distinct from other AI initiatives, not heeding the group‚Äôs advice, and not creating an incentive structure to put in practice the ethical findings, Gebru and other employees said.Google declined to comment, but noted that in addition to the dozen or so staff members on Gebru‚Äôs team, 200 employees are focused on responsible AI.Google has said that it did not fire Gebru, but accepted her ‚Äúresignation,‚Äù citing her request to explain who at Google demanded that the paper be retracted, according to Dean‚Äôs memo. The company also blamed an email Gebru wrote to an employee resource group for women and allies at Google working in AI as inappropriate for a manager. The message warned the group that pushing for diversity was no use until Google leadership took accountability.Federal study confirms racial bias of many facial-recognition systems, casts doubt on their expanding useRumman Chowdhury, a former global lead for responsible AI at Accenture and chief executive of Parity, a start-up that helps companies figure out how to audit algorithms, said there is a fundamental lack of respect within the industry for work on AI ethics compared with equivalent roles in other industries, such as model risk managers in quantitative hedge funds or threat analysts in cybersecurity.AdvertisementStory continues below advertisement‚ÄúIt‚Äôs being framed as the AI optimists and the people really building the stuff [versus] the rest of us negative Nellies, raining on their parade,‚Äù Chowdhury said. ‚ÄúYou can‚Äôt help but notice, it‚Äôs like the boys will make the toys and then the girls will have to clean up.‚ÄùGoogle, which for decades evangelized an office culture that embraced employee dissent, has fired outspoken workers in recent years and shut down forums for exchange and questioning.Nearly 3,000 Google employees and more than 4,000 academics, engineers and industry colleagues have signed a petition calling Gebru‚Äôs termination an act of retaliation by Google. Last week, nine Democratic lawmakers, including Sens. Elizabeth Warren (Mass.) and Cory Booker (N.J.) and Rep. Yvette D. Clarke (N.Y.), sponsor of the Algorithmic Accountability Act, a bill that would require companies to audit and correct race and gender bias in its algorithms, sent a letter to Google chief executive Sundar Pichai asking the company to affirm its commitment to research freedom and diversity.Google CEO, in leaked video, says company is ‚Äògenuinely struggling‚Äô with employee trustLike any good researcher, Gebru is comfortable in the gray areas. And she has been using her ouster as an opportunity to shed light on the black box of algorithmic accountability inside Google ‚Äî annotating the company‚Äôs claims with contradictory data, drawing connections to larger systemic issues, and illuminating the way internal AI ethics efforts can break down without oversight or a change in incentives to corporate practices and power structures.AdvertisementStory continues below advertisementBig Tech dominates AI research around advancements in machine learning, image recognition, language translation ‚Äî poaching talent from top universities, sponsoring conferences and publishing influential papers. In response to concerns about the way those technologies could be abused or compound bias, the industry ramped up funding and promotion of AI ethics initiatives, beginning around 2016.Tech giants have made similar investments in shaping policy debate around antitrust and online privacy, as a way to ward off lawmakers. Pichai invoked Google‚Äôs AI principles in an interview in 2018 with The Post, arguing for self-regulation around AI.Google created its Ethical AI group in 2018 as an outgrowth of an employee-led push to prioritize fairness in the company‚Äôs machine learning applications. Margaret Mitchell, Gebru‚Äôs co-lead, pitched the idea of a team of researchers investigating the long-term effects of AI and translating those findings into action to mitigate harm and risk.AdvertisementStory continues below advertisementThe same year, Pichai released a broadly worded set of principles governing Google‚Äôs AI work after thousands of employees protested the company‚Äôs contract with the Pentagon to analyze surveillance imagery from drones. But Google, which requires privacy and security tests before any product launch, has not mandated an equivalent process for vetting AI ethics, employees say.Google CEO Sundar Pichai: Fears about artificial intelligence are ‚Äòvery legitimate,‚Äô he says in Post interviewGebru, whose family‚Äôs ethnic origins are in Eritrea, was born and raised in Ethiopia and came to Massachusetts as 16-year-old after receiving political asylum from the war between the two African countries. She began her career as an electrical engineer at Apple and received her PhD from the Stanford Artificial Intelligence Lab, studying computer vision under renowned computer scientist Fei-Fei Li, a former Google executive and now co-director of Stanford‚Äôs Human-Centered AI Institute, which receives funding from Google.Gebru did her postdoctoral research at Microsoft Research as part of a group focused on accountability and ethics in AI. There, she and Joy Buolamwini, then a masters student at MIT Media Lab, co-wrote a groundbreaking 2018 study that found that commercial facial recognition tools sold by companies such as IBM and Microsoft were 99 percent accurate at identifying White males, but only 35 percent effective with Black women.AdvertisementStory continues below advertisementIn June, IBM, Microsoft and Amazon announced that they would stop selling the software to law enforcement, which Dean credited to Gebru‚Äôs work. She also co-founded Black in AI, a nonprofit organization that increased the number Black attendees at the largest annual AI conference.Compare Google search engine results over nearly two decades and a trend emerges: Results are filled with advertising and non-Google results are lower down. (Video: The Washington Post)Gebru said that in 2018, Google recruited her with the promise of total academic freedom. She was unconvinced, but the company was opening its first artificial intelligence lab on the African continent in Accra, the capital of Ghana, and she wanted to be involved. When she joined Google, Gebru said, she was the first Black female researcher in the company. (When she left, there were still only a handful of Black women working in research, out of hundreds.)Gebru said she was also drawn to working with Mitchell. Both women prioritized foresight and building practical solutions to prevent AI risk, whereas the operating mind-set in tech is biased toward benefits and ‚Äúrapid hindsight,‚Äù in response to harm, Mitchell said.AdvertisementStory continues below advertisementGebru‚Äôs approach to ethical AI was shaped by her experiences. Hardware, for instance, came with datasheets that documented whether components were safe to use in certain situations. ‚ÄúWhen you look at this field as a whole, that doesn‚Äôt exist,‚Äù said Gebru, an electrical engineer. ‚ÄúIt‚Äôs just super behind in terms of documentation and standards of safety.‚ÄùShe also leaned on her industry experience when collaborating with other teams. Engineers live on a product cycle, consumed with putting out fires and fixing bugs. A vague requirement to ‚Äúmake things fair‚Äù would only cause more work and frustration, she thought. So she tried to build institutional structures and documentation tools for ‚Äúwhen people want to do the right thing.‚ÄùDespite their expertise, the Ethical AI group fought to be taken seriously and included in Google‚Äôs other AI efforts, employees said.Within the company, Gebru and her former colleagues said, there is little transparency or accountability regarding how decisions around AI ethics or diversity initiatives get made. Work on AI principles, for instance, falls under Kent Walker, the senior vice president of global affairs, whose vast purview includes lobbying, public policy and legal work. Walker also runs an internal ethics board of top executives, including Dean, called the Advanced Technology Review Council, which is responsible for yes or no decisions when issues escalate, Gebru said. The Ethical AI team had to fight to be consulted on Walker‚Äôs initiatives, she said.‚ÄúHere‚Äôs the guy tasked with covering Google‚Äôs a--, lobbying and also ‚Ä¶ working on AI principles,‚Äù Gebru said. ‚ÄúShouldn‚Äôt you have a different entity that pushes back a little bit internally ‚Äî some sort of push and pull?‚Äù What‚Äôs more, members of Walker‚Äôs council are predominantly vice presidents or higher, constricting diversity, Gebru said.Amazon, Facebook and Google turn to deep network of political allies to battle back antitrust probesIn her conversations with product teams, such as a group working on fairness in Machine Learning Infrastructure, Gebru said she kept getting questions about what tools and features they could build to protect against the ethical risks involved with large language models. Google had credited it with the biggest breakthrough in improving search results in the past five years. The models can process words in relation to the other words that come before and after them, which is useful for understanding the intent behind conversational search queries.But despite the increasing use of these models, there was limited research investigating groups that might be negatively impacted. Gebru says she wanted to help develop those safeguards, one of the reasons she agreed to collaborate with the research paper proposed by Emily M. Bender, a linguist at the University of Washington.Mitchell, who developed the idea of model cards, like nutrition labels for machine learning models, described the paper as ‚Äúdue diligence.‚Äù Her model card idea is being adopted more widely across the industry, and engineers needed to know how to fill out the section on harm.Gebru said her biggest contribution to both her team and the paper has been identifying researchers who study directly-affected communities.That diversity was reflected in the authors of the paper, including Mark Diaz, a Black and Latino Google researcher whose previous work looked at how platforms leave out the elderly, who talk about ageism in blog posts, but don‚Äôt share as much on sites such as Twitter. For the paper, he identified the possibility that large data sets from the Internet, particularly if they are from a single moment in time, will not reflect cultural shifts from social movements, such as the #MeToo movement or Black Lives Matter, which seek to shift power through changes in language.The paper identified four overarching categories of harm, according to a recent draft viewed by The Post. It delved into the environmental effect of the computing power, the inscrutability of massive data sets used to train these models, the opportunity costs of the ‚Äúhype‚Äù around claims that these models can understand language, as opposed to identifying patterns, and the danger that the real-sounding text generated by such models could be used to spread misinformation.Because Google depends on large language models, Gebru and Mitchell expected that the company might push back against certain sections or attempt to water down their findings. So they looped in PR & Policy representatives in mid-September, with plenty of time before the deadline for changes at the end of January 2021.Before making a pre-publication draft available online, Gebru first wanted to vet the paper with a variety of experts, including those who have built large language models. She asked for feedback from two top people at OpenAI, an AI research lab co-founded by Elon Musk, in addition to her manager at Google, and about 30 others. They suggested additions or revisions, Gebru said. ‚ÄúI really wanted to send it to people who would disagree with our view and be defensive,‚Äù Gebru said.Given all their upfront effort, Gebru was baffled when she received a notification for a meeting with Google Research Vice President Megan Kacholia at 4.30 p.m. on the Thursday before Thanksgiving.At the meeting, Kacholia informed Gebru and her co-authors that Google wanted the paper retracted.On Thanksgiving, a week after the meeting, Gebru composed a six-page email to Kacholia and Dean outlining how disrespectful and oddly secretive the process had been.‚ÄúSpecific individuals should not be empowered to unilaterally shut down work in such a disrespectful manner,‚Äù she wrote, adding that researchers from underrepresented groups were mistreated.Mitchell, who is White, said she shared Gebru‚Äôs concerns but did not receive the same treatment from the company. ‚ÄúGoogle is very hierarchical, and it‚Äôs been a battle to have any sort of recognition,‚Äù she said. ‚ÄúWe tried to explain that Timnit, and to a lesser extent me, are respected voices publicly, but we could not communicate upwards.‚Äù‚ÄúHow can you still ask why there aren‚Äôt Black women in this industry?‚Äù Gebru said.Gebru said she found out this week that the paper was accepted to the Conference on Fairness, Accountability and Transparency, as part of its anonymous review process. ‚ÄúIt‚Äôs sad, the scientific community respects us a lot more than anybody inside Google,‚Äù she said.America‚Äôs Racial Reckoning: What you need to knowFull coverage: Race & ReckoningDemographic changes: How the racial makeup of where you live has changed since 1990Newsletter: Subscribe to About US to read the latest on race and identityGeorge Floyd‚Äôs America: Examining systemic racism through the lens of his lifeResources: Understanding racism and inequality in AmericaShare661 CommentsNewsletterAs news breaksTech News AlertsBreaking news email alerts on technology and the tech industry.Sign upSubscribe to comment and get the full experience. Choose your plan ‚Üí",https://www.washingtonpost.com/technology/2020/12/23/google-timnit-gebru-ai-ethics/,Timnit Gebru was critical of Google‚Äôs approach to ethical AI,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}","{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}",False,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}","[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}]",,,,,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3LmRpY2UuY29tL2NhcmVlci1hZHZpY2UvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWxsLWp1c3QtY29zdGx5LWh5cGXSAQA?oc=5,Artificial Intelligence (A.I.): Is It All Just Costly Hype? - Dice Insights,2020-12-24,Dice Insights,https://www.dice.com,"Is artificial intelligence (and by extension, machine learning) capable of powering a sustainable business? Or is it all just expensive hype?",N/A,"Is artificial intelligence (and by extension, machine learning) capable of powering a sustainable business? Or is it all just expensive hype?",N/A,https://schema.org/,Article,Artificial Intelligence (A.I.): Is It All Just Costly Hype?,"{'@type': 'ImageObject', 'url': 'https://www.dice.com/binaries/large/content/gallery/dice/insights/2018/04/shutterstock_510170158-2.jpg', 'width': 1200, 'height': 681}",2020-12-24T12:00:00Z,,"{'@type': 'Person', 'name': 'Nick Kolakowski', 'url': 'https://www.dice.com/about/authors/nick-kolakowski'}",Insights,N/A,"
Artificial Intelligence (A.I.): Is It All Just Costly Hype?

                by
                    
                    Nick Kolakowski
                    
Dec 24, 2020
                6 min read
            


Earlier this year, two partners at prominent venture-capital firm Andreessen Horowitz published an interesting blog post about artificial intelligence (A.I.). Specifically, is A.I. (and by extension, machine learning) capable of powering a sustainable business? Or is the tech industry infatuated with a technology that‚Äôs just a lot of empty hype?  
It‚Äôs a worthy question as we close out 2020, considering how much money and resources companies are pouring into all things A.I.-related (often despite budget cutbacks related to the COVID-19 pandemic). Martin Casado and Matt Bornstein, the partners in question, conclude that A.I. is indeed viable‚Äîbut that A.I.-centric businesses can‚Äôt operate like traditional software firms.  
Specifically, A.I. companies have ‚Äúlower gross margins‚Äù (due to the need for lots of expensive and talented humans, as well as infrastructure expenses), ‚Äúscaling challenges‚Äù (due to edge cases), and ‚Äúweaker defensive moats‚Äù (because of more A.I. tools and apps becoming commoditized, among other issues).  
‚ÄúTraining¬†a single A.I. model can cost hundreds of thousands of dollars (or¬†more) in¬†compute¬†resources,‚Äù they wrote. ‚ÄúWhile it‚Äôs tempting to treat this as a one-time cost, retraining is increasingly recognized as an ongoing cost, since the data that feeds AI models tends to change over time (a phenomenon known as ‚Äòdata drift‚Äô).‚Äù  
If the A.I. model is training on something storage-intensive like video, things get even worse. Add on top of that the cost of humans to design and wrangle the models, and you can see how any hoped-for profits from an A.I. project could quickly evaporate.  
Humans in the Artificial Intelligence Loop  
The entire Andreessen Horowitz posting is worth reading, especially if you‚Äôre debating whether to jump aboard an artificial intelligence startup. Amidst all the discussions of cloud-infrastructure costs and model complexity, though, one thing stands out: the overwhelming presence of human beings within A.I. systems that are supposedly becoming more and more automated.  
It‚Äôs not just a question of employing people who can build and continually maintain models. ‚ÄúFor many tasks, especially those requiring greater cognitive reasoning, humans are often plugged into A.I. systems in real time,‚Äù the posting added. ‚ÄúSocial media companies, for example, employ thousands of human reviewers to augment A.I.-based moderation systems. Many autonomous vehicle systems include remote human operators, and most A.I.-based medical devices interface with physicians as joint decision makers.‚Äù  
And there‚Äôs no end in sight to intervention: ‚ÄúMany problems‚Äîlike self-driving cars‚Äîare too complex to be fully automated with current-generation A.I. techniques. Issues of safety, fairness, and trust also demand meaningful human oversight‚Äîa fact likely to be enshrined in A.I. regulations currently under development in the¬†US,¬†EU, and elsewhere.‚Äù  
We‚Äôve seen these sorts of issues cropping up already among companies with artificial intelligence products. A few years ago, for example, Google rolled out Duplex, its automated voice assistant, which it predicted would revolutionize the process of making reservations and dealing with customer service. However, journalists quickly demonstrated there were relatively straightforward ways to ‚Äústump‚Äù Duplex. As of mid-2019, 25 percent of Google Duplex calls were supposedly made by human operators as opposed to an A.I.¬†¬†¬†  
Now consider all the A.I.-centric (or ‚ÄúA.I. hopeful,‚Äù for those still trying to develop an application) businesses that don‚Äôt have Google‚Äôs talent or resources. The dream of building an artificial intelligence model that‚Äôs fully capable of performing its assigned task without any sort of human intervention‚Äîwell, that‚Äôs likely years away.  
Andreessen Horowitz isn‚Äôt the first firm to warn about this issue. In 2019, Arvind Krishna, IBM‚Äôs senior vice president of cloud and cognitive software, warned that A.I. initiatives could implode once companies realize how much effort is truly necessary to prep the related data. ‚ÄúYou run out of patience along the way, because you spend your first year just collecting and cleansing the data,‚Äù¬†he told the audience at The Wall Street Journal‚Äôs Future of Everything Festival,¬†according to the newspaper.  
In a 2018 blog posting, A.I. researcher Filip Piekniewski listed all the ways in which the¬†artificial intelligence¬†hype wasn‚Äôt matching with reality, including¬†a lack of progress in Google‚Äôs DeepMind. Two years later, it‚Äôs clear that A.I. is still grinding forward as a discipline, consuming lots of cash and talent as companies hope for incremental advances.  
But at least artificial intelligence researchers are still making lots of cash. And, despite these challenges, keep in mind that automation is still a long-term risk to many professions.   
  
Ultimately, A.I. and machine learning technologies that help companies handle customer personalization and communication, data analytics and processing, and a host of other applications will continue to grow, even if it takes longer than expected to achieve seamless automation. An IDC report found three-quarters of commercial enterprise applications could lean on A.I. by next year alone, while an Analytics Insight report projects more than 20 million available jobs in¬†artificial intelligence¬†by 2023.¬†  
Whether you're a manager or a software developer, in other words, prepare for A.I. (even weaker A.I.) to change how you work. Make sure to review the 10 jobs that could be radically impacted by these technologies sooner than you think.  



   Sign Up Today
  
Want more great insights?¬†Create a Dice profile today to receive the weekly Dice Advisor newsletter, packed with everything you need to boost your career in tech. Register now

  
  
","{'@type': 'WebPage', '@id': 'https://www.dice.com/career-advice/artificial-intelligence-all-just-costly-hype'}",,,"{'@type': 'Organization', 'name': 'Dice', 'url': 'https://www.dice.com', 'logo': 'https://www.dice.com/binaries/content/gallery/dice/icons/dice-logo.svg', 'sameAs': ['https://www.linkedin.com/company/dice', 'https://www.facebook.com/dice', 'https://twitter.com/Dicedotcom', 'https://www.instagram.com/dicedotcom', 'https://www.youtube.com/Dice', 'https://www.facebook.com/DiceforEmployers', 'https://twitter.com/Dice4Employers']}",,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMisgFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL3Rob21hc2JyZXdzdGVyLzIwMjAvMTIvMjIvZ29vZ2xlLXByb21pc2VkLW5vdC10by11c2UtaXRzLWFpLWluLXdlYXBvbnMtc28td2h5LWlzLWFscGhhYmV0LWludmVzdGluZy1pbi1haS1zYXRlbGxpdGUtc3RhcnR1cHMtd2l0aC1taWxpdGFyeS1jb250cmFjdHMv0gEA?oc=5,"Google Promised Not To Use Its AI In Weapons, So Why Is It Investing In Startups Straight Out Of 'Star Wars'? - Forbes",2020-12-22,Forbes,https://www.forbes.com,"Google‚Äôs CEO Sundar Pichai promised to no longer use his company‚Äôs artificial intelligence expertise to develop weapons. But that hasn‚Äôt stopped Google‚Äôs parent company, Alphabet, where Pichai is also CEO, from investing in a couple of companies that are getting into the business of war.","Google,GV,Alphabet,satellites,surveillance,planet,orbital insight,sundar pichai,dod,defense,military,intelligence agencies,national geospatial-intelligence agency,national reconnaissance office,datahub","Google‚Äôs CEO Sundar Pichai promised to no longer use his company‚Äôs artificial intelligence expertise to develop weapons. But that hasn‚Äôt stopped Google‚Äôs parent company, Alphabet, where Pichai is also CEO, from investing in a couple of companies that are getting into the business of war.","Google‚Äôs CEO Sundar Pichai promised to no longer use his company‚Äôs artificial intelligence expertise to develop weapons. But that hasn‚Äôt stopped Google‚Äôs parent company, Alphabet, where Pichai is also CEO, from investing in a couple of companies that are getting into the business of war.",http://schema.org/,Comment,"Google Promised Not To Use Its AI In Weapons, So Why Is It Investing In Startups Straight Out Of ‚ÄòStar Wars‚Äô?","{'@context': 'http://schema.org/', '@type': 'ImageObject', 'url': 'https://images.spot.im/v1/production/tmfydjz5dovzlpanutm8', 'width': '1600', 'height': '900'}",2020-12-22T06:30:00-05:00,2020-12-22T09:58:42-05:00,"{'@type': 'Person', 'name': 'Thomas Brewster', 'url': 'https://www.forbes.com/sites/thomasbrewster/', 'description': ""I'm a senior writer for Forbes, covering security, surveillance and privacy. I'm also the editor of The Wiretap newsletter, which has exclusive stories on real-world surveillance and all the biggest cybersecurity stories of the week. It goes out every Monday and you can sign up here: https://www.forbes.com/newsletter/thewiretap I‚Äôve been breaking news and writing features on these topics for major publications since 2010. As a freelancer, I worked for The Guardian, Vice, Wired and the BBC, amongst many others. Tip me on Signal at +1 929-512-7964."", 'sameAs': ['https://www.twitter.com/iblametom', 'https://www.forbes.com/sites/thomasbrewster/']}",Cybersecurity,N/A,"ForbesInnovationCybersecurityEdit StoryDaily CoverGoogle Promised Not To Use Its AI In Weapons, So Why Is It Investing In Startups Straight Out Of ‚ÄòStar Wars‚Äô? Illustration by Max-O-Matic for Forbes. Photos: Eric Piermoint/AFP/Getty Images, Monika Skolimowska/Getty ImagesThomas BrewsterForbes StaffSenior writer at Forbes covering cybercrime, privacy and surveillance.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got it0Dec 22, 2020,06:30am ESTUpdated Dec 22, 2020, 09:58am ESTMore than two years ago, Google‚Äôs CEO Sundar Pichai promised to no longer use his company‚Äôs artificial intelligence expertise to develop weapons. But that hasn‚Äôt stopped Google‚Äôs parent company, Alphabet, where Pichai is also CEO, from investing in a couple of companies that are getting into the business of war.

In June 2018, Google CEO Sundar Pichai made a sweeping promise. In a blog entitled ‚ÄòAI at Google: our principles,‚Äô Pichai said Google would not develop artificial intelligence for ‚Äúweapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.‚Äù

Pichai‚Äôs pledge hadn‚Äôt come out of the blue: earlier that year, employees protested the company‚Äôs participation in Project Maven, a Department of Defense (DOD) initiative worth a reported potential $250 million a year - and $15 million over 18 months to Google - to use AI to identify buildings and other targets ‚Äúof interest‚Äù to the military from drone footage. Insiders at the Mountain View-based giant fumed. More than three thousand signed a letter to Pichai, writing, ‚ÄúWe believe that Google should not be in the business of war.‚Äù Google eventually let the contract lapse.

Sundar Pichai, CEO of Google and Alphabet, has been having to put out another fire of late, after the departure of AI researcher Timnit Gebru. In a letter to staff he wrote that it was ""a painful but important reminder of the progress we still need to make."" CHRISTIAN PEACOCK FOR FORBES
Pichai may have promised Google AI wouldn‚Äôt harm people, but he said nothing about Google‚Äôs parent company Alphabet. In late 2019, Pichai became CEO of Alphabet while still retaining his job as CEO of Google ‚Äì and through investments by Google and its venture capital wing, GV (formerly Google Ventures), Alphabet is still very much in the business of war.

GV positions itself as an ‚Äúindependent, return-driven fund‚Äù with $5 billion under management. But the Mountain View, Calif.-based firm was spun out of Google back in 2009 and it‚Äôs all Alphabet money. As it says on its website, ‚ÄúGV is the venture capital arm of Alphabet,‚Äù and Alphabet is the firm‚Äôs ‚Äúsole limited partner.‚Äù (GV and Pichai declined repeated requests for comment on this story.)

Both Google and GV have minority stakes in companies supplying military surveillance tools. In 2016 GV acquired a stake in Palo Alto-based Orbital Insight and in 2017 Google took equity in Planet, headquartered in San Francisco. Together, in the last three years, the two firms have won at least $30.5 million in Defense Department contracts, alongside deals with space intelligence agencies, for projects that could be said to ‚Äúdirectly facilitate injury.‚Äù
Orbital is a software company founded by former Google Books director James Crawford. Its AI sifts through masses of satellite images, drone footage and aggregated smartphone location data from 800 million devices across the world with the goal of telling customers what‚Äôs physically changed on Earth and why it matters. The uses are myriad. Orbital could, for instance, track North Korean nuclear sites or the Taliban building training camps. But it also has peaceful uses like monitoring deforestation in the Amazon and mapping watersheds or sprawling urban slums. It gets its satellite footage from a range of providers, including Planet, its Google-portfolio sibling.
Planet, which was founded by NASA engineers, has 150 imaging satellites in orbit, claiming they make up the world‚Äôs largest constellation of Earth-imaging satellites. Planet‚Äôs big sell is the ability to quickly and cheaply send up small satellites into space. It has Doves - about the size of a loaf of bread - and Skysat satellites - about the size of a minifridge. Both are capable of beaming high-quality imagery back to earth. The startup was valued at nearly $1.8 billion after a 2018 funding round, according to PitchBook data. Google acquired 16% of the company, after selling its satellite imaging subsidiary Terra Bella to Planet in 2017, which has now diluted to 13%.
Both companies work with the U.S. military and various intelligence agencies. Planet has contracts with space intel agencies, including the National Reconnaissance Office and the National Geospatial-Intelligence Agency, a DOD combat support agency. Orbital bid for work on that controversial Project Maven, according to two former employees.
Government contracting records show that between February 2017 and July 2020 Orbital was given $10 million to develop AI technology for a Defense Department program called Datahub. The Datahub would take satellite imagery and ‚Äútrack enemy patterns of life 24/7, all weather and day/night across large areas of responsibility at machine speed,‚Äù according to Pentagon budget documents. The resulting intelligence would be used to speed up a DoD tactical approach known as Find-Fix-Finish-Exploit-Analyze (F3EA), whereby a target is found, tracked, captured or killed, interrogated and then an analysis done to determine future opportunities. Intelligence derived from Datahub would also be used to automate the Defense Department‚Äôs weapons deployment ‚Äúfor timely precision strikes.‚Äù
The investments threaten to be problematic for Google and Alphabet ‚Äì even when done at arm‚Äôs remove through its ‚Äúindependent‚Äù venture capital wing. Google has repeatedly stumbled trying to live up to the expectations of its idealistic workforce. There was Project Maven and there was Project Dragonfly in 2017, when Google planned a search tool that came with built-in Chinese censorship. Then there were internal protests over contracts with the immigration agencies helping enact the Trump administration‚Äôs policies in 2019. Just this December, the exit of Google researcher Timnit Gebru, who was investigating potential racial bias in AI, led to a public fracas. Gebru claimed she‚Äôd been fired for posting frustrations about the retraction of one of her papers. More than 2,500 Google employees have signed a petition demanding their employer be transparent about Gebru‚Äôs termination.
A Google spokesperson said: ‚ÄúWhen we do our due diligence before any investment, we work with entrepreneurs to understand their tech, business plans and team, and, where appropriate, look for consistency with the AI Principles we announced in 2018.‚Äù

GV has been involved in every Orbital fundraising round since the satellite imagery company was founded in 2013. GV participated in a $9 million Series A round in 2015 and then in 2016 led a $15 million equity investment as part of the Series B. It has invested in all four of Orbital‚Äôs raises, the most recent being a $50 million Series D in November 2019. In all, Orbital has raised $130 million, most recently at a valuation of $480 million, according to PitchBook data. Forbes estimates GV has a stake of roughly 13% in the startup, which Forbes named as a Next Billion-Dollar startup in 2017. Sequoia is the largest outside stakeholder at over 20%, according to a source familiar with the investments.
From early on, Orbital has worked on humanitarian projects. With the World Bank it tries to quantify poverty by counting new buildings, roads and agricultural land in less-developed countries. It kept tabs on the world‚Äôs forests with the World Resources Institute. And as recently as last year its AI was monitoring the expansion of China‚Äôs ‚Äúre-education‚Äù camps in the Xinjiang region.
But the big money in the geospatial game resides in government coffers and in addition to its altruistic work, Orbital has forged numerous ties with U.S. intelligence and military agencies. In-Q-Tel, the CIA‚Äôs investment arm, provided $5 million of financing (via a warrant) in 2015. Shortly after a handful of In-Q-Tel employees moved over to Orbital and the fund‚Äôs managing partner George Hoyem became a board observer, according to Crunchbase. Among Orbital‚Äôs advisors for federal government business is Robert Cardillo, former director of the National Geospatial-Intelligence Agency. And in late 2019, it signed a deal with Booz Allen Hamilton, the Beltway consultancy with deep ties to the intelligence community, to supply its tools at speed via Booz‚Äôs Modzy, a kind of app store for government AI services.
Not everyone inside Orbital was happy about its ties to the military. Orbital‚Äôs own ethics pledge states, ‚ÄúWe do not develop or condone any intent to harm humanity, the environment, and/or society.‚Äù According to one former senior staffer, Orbital said its tech wouldn‚Äôt be applied to things like ‚Äúbomb targeting,‚Äù but ‚Äúonce you identify‚Ä¶a building, [the government] is gonna do whatever they want with it.‚Äù Though they didn‚Äôt have issues with the ethics of working with the military, they felt it ‚Äúsilly to make up these fake rules‚Ä¶ just call it what it is.‚Äù The ex-employee added that the company went from ‚Äúsaving chimpanzees in Indonesia‚Äù to ‚Äúfinding targets in Afghanistan.‚Äù
A former software engineer added that the defense work was ‚Äúa big problem because there's a lot of money in doing things that some people might consider unethical.‚Äù The ex-staffer said that in Silicon Valley it‚Äôs ‚Äúhard to attract employees here to a company that's going to be... dependent on the U.S. military.‚Äù They acknowledged that the business had tried to steer clear of ‚Äúthe bad stuff, but if you‚Äôve borrowed $120 million from other people, you're kind of pressured to deliver on it.‚Äù
Orbital declined to provide any executives for an interview. A spokesperson for Orbital said ‚Äúa few employees... expressed concern over government work,‚Äù but added that the company has an ethics board, led by founder Crawford, that reviews each contract. When a government wanted to fly drones past ships and use Orbital for facial recognition, for instance, Orbital declined to do the work, as it doesn‚Äôt track individuals. The spokesperson added that it had ‚Äúsuccessfully completed‚Äù its work on the Datahub program, but declined to offer more detail or comment on any possible breaches of its own ethics stance.
Regarding its overall Pentagon work, the spokesperson added: ""Orbital Insight's work with the U.S. Department of Defense helps the agency zoom in on the physical world and monitor global activity so they can avoid surprises and proactively address critical situations. Precise change detection and an accurate picture of what's happening on the ground are essential for keeping our country safe and secure with effective security responses and communication.""
Orbital may no longer work on Datahub (former senior employees say the company lost the contract), but the startup continues to actively seek out government work. Official records show that since 2018, Orbital has spent $300,000 on Congressional lobbying, talking to lawmakers about the uses of geospatial AI. And in July 2020, it signed its biggest publicly-known government contract to date: a $22 million deal with Customs and Border Protection (CBP), details of which were obtained by Jack Poulson, an ex-Stanford math professor who used to work at Google until he resigned over the Chinese search engine plans, and now runs big tech research outfit Tech Inquiry. The contract documents, obtained via a Freedom of Information Act (FOIA) request, indicate that CBP is using Orbital tools to analyze data coming from drones, surveillance balloons and satellites that monitor radio frequency signals. According to contract records, Orbital‚Äôs border work will mix classic ‚Äúgeospatial surveillance‚Äù with search and rescue aid, the latter covered by a separate $3 million contract. An Orbital spokesperson said it was a research and development project with CBP looking ‚Äúto prevent loss of life for people stranded along the southern border and provide officers with more situational awareness in remote areas.‚Äù A CBP spokesperson said the ‚Äúprimary‚Äù use case was for search and rescue.


Planet has raised even more money than Orbital, above $400 million since it was founded in 2010. Its Doves satellites, which catch rides into orbit on the backs of launches from the likes of SpaceX and Rocket Lab, monitor Earth‚Äôs entire landmass and large chunks of its oceans, including coastal parts of the South China Sea and the Persian Gulf, every day.
Like Orbital, Planet‚Äôs business is a mix of humanitarian, private market and government contracting. Amongst its government projects are $20 million in National Geospatial-Intelligence Agency satellite imagery contracts. In the last three years, it‚Äôs completed a mix of studies and pilots with the Navy, the Air Force and the Army, looking at how best to use its satellite imagery across land and sea, in contracts worth more than $15 million.
Planet is hoping to significantly expand its collaboration with U.S. intelligence in the coming years, by bidding on the lucrative EnhancedView contract. Managed by the National Reconnaissance Office, EnhancedView contractors provide the U.S. government with commercial satellite imagery. For the last ten years the bulk of the EnhancedView money has gone to satellite and geospatial intelligence provider Maxar Technologies, which makes $300 million a year from the deal. Currently Planet‚Äôs constellation of Skysats and Doves is being tested to see how they compare with Maxar‚Äôs satellites. ‚ÄúWe believe we will be able to offer an excellent level of performance and service to the U.S. government,‚Äù the Planet spokesperson added.
Will Marshall is one of three NASA scientists that founded Planet. It started out as Planet Labs, but changed to Planet, whilst its government-focused business is Planet Federal, based in Washington D.C. ERIC PIERMOINT/AFP/GETTY IMAGES

As with Orbital, three former senior employees say there was some internal turmoil at Planet over its work with the military, claiming a small number of staff left as a result. ‚ÄúInitially, they were very altruistic. They were launching satellites for the benefit of everybody in the world,‚Äù said one former staffer. ¬†‚ÄúThen they discovered that actually, the only people that really want to pay the big money for satellite data is governments.‚Äù Another ex-employee said they thought Planet was against doing intelligence work but the pivot was a ‚Äúturn off‚Äù and one reason they left.¬†
Planet‚Äôs spokesperson said there was no such shift, that its first customers were with military and intelligence agencies, and it has ‚Äúno internal record of any employee ever leaving Planet because of our work with governments.‚Äù It pointed Forbes to the company‚Äôs ethics code in which it says: ‚ÄúOur partners may not use our products to further actions that sponsor harm, abuse, aggression, violence, or other violations of human rights.‚Äù The company also has an Ethics Committee that ‚Äúreviews potential or existing customer engagements for ethical issues‚Äù and it has nixed potential private and public sector contracts because of moral concerns. Planet declined to provide any information on what those contracts were.
A former Planet employee focused on government work said that the company was walking ‚Äúa fine line.‚Äù ‚ÄúWhat their [ethics] statement says and then what the government does with the thing that they sell them is not really in their prerogative to control,‚Äù they added.
All these tricky ethical quandaries haven‚Äôt stopped Pichai‚Äôs Alphabet companies from investing further in the geospatial market. GV is also backing a less-proven moonshot, participating in $40 million and $35 million rounds in 2018 and 2020 for SpinLaunch. The startup has a novel idea for getting satellites into orbit, using what amounts to a giant, spinning arm that hammer-throws satellites into space. Thanks to Alphabet‚Äôs money and a 2019 $2.5 million contract with the DoD‚Äôs Defense Innovation Unit Small Responsive Launch program, SpinLaunch‚Äôs as-yet unproven tech could soon be responsible for helping the Pentagon deploy even more military spy satellites to monitor the planet.
When Pichai laid out his company‚Äôs AI principles, he took on a utilitarian tone in describing their protean limits. ‚ÄúWhere there is a material risk of harm, we will proceed only where we believe that the benefits substantially outweigh the risks, and will incorporate appropriate safety constraints,‚Äù he wrote. But it‚Äôs not within Google‚Äôs remit to apply those unspecified constraints on the companies in which it invests or their militaristic customers.
Follow me on¬†Twitter.¬†Check out¬†my¬†website.¬†Send me a secure¬†tip.¬†Thomas BrewsterFollowingFollowI'm a senior writer for Forbes, covering security, surveillance and privacy. I'm also the editor of The Wiretap newsletter, which has exclusive stories on real-world surveillance and all the biggest cybersecurity...¬†Read MoreEditorial StandardsPrintReprints & PermissionsJoin The ConversationComments¬†0One Community. Many Voices.¬†Create a free account to share your thoughts.¬†Read our community guidelines¬† here.Forbes Community GuidelinesOur community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.In order to do so, please follow the posting rules in our site's¬†Terms of Service.¬† We've summarized some of those key rules below. Simply put, keep it civil.Your post will be rejected if we notice that it seems to contain:False or intentionally out-of-context or misleading informationSpamInsults, profanity, incoherent, obscene or inflammatory language or threats of any kindAttacks on the identity of other commenters or the article's authorContent that otherwise violates our site's¬†terms.User accounts will be blocked if we notice or believe that users are engaged in:Continuous attempts to re-post comments that have been previously moderated/rejectedRacist, sexist, homophobic or other discriminatory commentsAttempts or tactics that put the site security at riskActions that otherwise violate our site's¬†terms.So, how can you be a power user?Stay on topic and share your insightsFeel free to be clear and thoughtful to get your point across‚ÄòLike‚Äô or ‚ÄòDislike‚Äô to show your point of view.Protect your community.Use the report tool to alert us when someone breaks the rules.Thanks for reading our community guidelines.  Please read the full list of posting rules found in our site's¬†Terms of Service.",,,,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",False,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Cybersecurity', 'item': 'https://www.forbes.com/cybersecurity/'}]",https://www.forbes.com/sites/thomasbrewster/2020/12/22/google-promised-not-to-use-its-ai-in-weapons-so-why-is-alphabet-investing-in-ai-satellite-startups-with-military-contracts/,Cybersecurity,"Google Promised Not To Use Its AI In Weapons, So Why Is It Investing In Startups Straight Out Of ‚ÄòStar Wars‚Äô?",https://images.spot.im/v1/production/tmfydjz5dovzlpanutm8,0.0,"{'@context': 'http://schema.org/', '@type': 'AggregateRating', 'ratingValue': 0, 'reviewCount': 0, 'worstRating': 1, 'bestRating': 5}",[],,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3Lm1pbGl0YXJ5YWVyb3NwYWNlLmNvbS9jb21wdXRlcnMvYXJ0aWNsZS8xNDE4OTQ2OC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1haS1wcm9qZWN0LW1hdmVuLWFybXMtcmFjZdIBAA?oc=5,artificial intelligence (AI) Project Maven arms race - Military & Aerospace Electronics,2020-12-22,Military & Aerospace Electronics,https://www.militaryaerospace.com,AI has already gained a strong foothold in logistics and maintenance in Pentagon thinking and is now making its way to military field commanders.,N/A,AI has already gained a strong foothold in logistics and maintenance in Pentagon thinking and is now making its way to military field commanders.,AI has already gained a strong foothold in logistics and maintenance in Pentagon thinking and is now making its way to military field commanders.,https://schema.org,NewsArticle,Artificial intelligence (AI) becomes the latest arms race as adversaries seek to perfect machine learning,['https://img.militaryaerospace.com/files/base/ebm/mae/image/2020/12/AI_arms_race_22_Dec_2020.5fe21d86dcba9.png?auto=format%2Ccompress&w=320'],2020-12-22,,,N/A,N/A,,"{'@type': 'WebPage', '@id': 'https://www.militaryaerospace.com/computers/article/14189468/artificial-intelligence-ai-project-maven-arms-race'}",,,"{'@type': 'Organization', 'name': 'Military Aerospace', 'logo': {'@type': 'ImageObject', 'url': 'https://img.militaryaerospace.com/files/base/ebm/mae/image/website/logos/1642001379640-mae-logo-2.png', 'width': '', 'height': 35}}",False,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.paywall'}",,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vd3d3LmFzcGlzdHJhdGVnaXN0Lm9yZy5hdS90aGUtZ2VvcG9saXRpY3Mtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,The geopolitics of artificial intelligence | The Strategist - The Strategist,2020-12-24,The Strategist,https://www.aspistrategist.org.au,N/A,N/A,"As artificial intelligence technologies become more powerful and deeply integrated in human systems, countries around the world are struggling to understand the benefits and risks they might pose to national security, prosperity and political stability. ...",N/A,https://schema.org,,,,,,,N/A,N/A,"

The geopolitics of artificial intelligence
24 Dec 2020|Anastasia Kapetas 



SHARE

Share to Facebook







Share to Twitter







Share to LinkedIn







Share to Email







Print This Post
With ImagesWithout Images

 

As artificial intelligence technologies become more powerful and deeply integrated in human systems, countries around the world are struggling to understand the benefits and risks they might pose to national security, prosperity and political stability.
These efforts are still very much a work in progress. Australia is developing a whole-of-government AI action plan, led by the Department of Industry, Science, Energy and Resources. The department released a discussion paper this year and finalised its call for submissions in November.
In line with the department‚Äôs brief, the paper concentrates on the economic potential of AI, while acknowledging the need for a human-centred, ‚Äòresponsible‚Äô AI regime. That reflects a push internationally to conceptualise AI in terms of digital human security and human rights.
But AI technologies also have serious implications for national security and geopolitics, which need to be thoroughly explored in any discussion of what an AI framework for Australia might look like.
In any discussion of AI, it‚Äôs important to note that definitions of the technology are not settled and the applications are vast. But most definitions circle around the idea of machine learning, the ability of a digital technology not just to automate a function, but to learn from interactions with its environment and optimise a function accordingly.
The AI systems that we need to think about in national security terms include surveillance and profiling, the persuasive AI that pervades digital social networks, predictive algorithms and autonomous systems. It is also important to think about the control of the entire AI supply chain, from the human source of the datasets that AI technologies need to learn from, to research and development and technology transfers, and the effects of AI systems on societies.
But the AI geopolitical picture is now a contested tangle of state rivalry, multinational monopoly growth and public anxiety.
That AI is deeply embedded in the discourse of geopolitical competition is well established. The belief that AI will be the key to military, economic and ideological dominance has found voice in a proliferation of grand AI mission statements by the US, China, Russia and other players.
Whether an AI advantage will deliver pre-eminent power to any one nation is arguable. National control over AI technology still remains elusive in a world of globalised R&D collaboration and supply chains and transnational digital technology companies.
But the perception, at least, has driven intense national economic competition over establishment of global AI-powered monopolies in almost every sector‚Äîenergy, infrastructure, health, online gaming, telecommunications, news, social media and entertainment‚Äîand the enormous data-harvesting power that goes with them.
Governments are also racing to develop AI military technologies like autonomous lethal weapons and swarming technology as well as the AI-enhanced surveillance, communications and data-exploitation capabilities they hope will give their military forces the decisional edge on the battlefield.
At the same time, countries are trying to unwind the globalisation of AI technology in order to control R&D collaboration and technology transfers. Individual nations and alliance systems are beginning to champion their own versions of AI norms and technology bases.
In the process, the huge datasets held by governments, corporations and various data brokers have become a strategic asset. They are coveted as the raw fuel needed to train machine-learning algorithms.
Governments have been actively exploring the ways in which these datasets can be weaponised, how they might be used to create cyber weapons targeting critical infrastructure, influence the information systems of another country, build better profiles of its elites for influence targeting and form a clearer picture of the internal dynamics of a political system.
As these uses continue to be experimented with, how datasets are collected and where they are housed is becoming a national security issue. The decision by the US and others to ban Huawei and break up TikTok can be seen at least partially in this context.
But as the competition for the AI edge heats up, the initial excitement and uncritical embrace of this technology has darkened to a mood of profound unease.
Democratic governments are being forced to grapple with the fact that the AI algorithms that run social media platforms operate to maximise user engagement and encourage behavioural change which can then be sold to advertisers. And these learning algorithms have supercharged the possibilities for what some analysts have termed ‚Äòsharp power‚Äô‚Äîthe manipulation of public sentiment through computational propaganda, disinformation and conspiracism by foreign actors and their domestic proxies.
Deep fakes‚Äîsynthetic media created with the help of machine learning‚Äîcan be fun but are becoming another tool in the burgeoning disinformation arsenal. AI-generated disinformation was reportedly used by China to interfere in the Taiwanese presidential election in January, and by partisan operatives to discredit Democratic candidate Joe Biden‚Äôs son Hunter ahead of the US election. ‚Äã
The past year has at times seemed like a laboratory for demonstrating the malignant effects of AI-driven communications platforms on politics. The corrosive effect on credible governance and institutional legitimacy, in the case of the US, has threatened democratic norms, the ability of the government to mount a credible pandemic response and its reputational power abroad.
Further, the increasing AI-enabled convergence of the physical and digital worlds is constantly creating new infrastructure vulnerabilities. The development of 5G ‚Äòsmart cities‚Äô‚Äîthe mass automation of public infrastructure via sensors and learning algorithms‚Äîwill open up even more avenues for surveillance, data weaponisation and criminal cyber activity, and will provide foreign adversaries with further means to reach into societies at the granular level. The recent discovery of a massive cyber intelligence campaign against US security systems, enabled through a US government software contractor, is a reminder of what‚Äôs possible here.
All of this has governments and publics around the world signalling alarm, if not outright panic, about the destructive power of AI platforms. As the year comes to a close, the US has launched anti-trust actions against Google, which will almost certainly survive into a Biden administration. The EU has opened an investigation into anti-competitive conduct by Amazon. This alarm is no longer confined to democratic countries. China is drawing up new anti-trust measures squarely aimed at is own AI behemoths of Alibaba, Tencent and Baidu.
This fight between states and global platforms will be a defining feature of the next decade, as will be the fight for public trust in AI technologies. China‚Äôs pioneering work in deploying state-directed, AI-enhanced surveillance provides an illustration of a chilling totalitarian vision of intimate control of individual citizens through their dependence on integrated digital smart systems.
As citizens feel more and more powerless against the growing use of AI, they will increasingly push both governments and platforms to be more ambitious in designing technologies and enforceable regulatory regimes that are centred on the public interest.
By engaging transparently with the high risk to security, democracy and social cohesion inherent in many AI applications, Australia has the opportunity to develop innovative policy that could help set standards internationally.



Author



Anastasia Kapetas¬†is national security editor at¬†The Strategist. Image: Yuiizaa September/Unsplash.







Tags

artificial intelligence
democracy
future
technology





Share

SHARE

Share to Facebook







Share to Twitter







Share to LinkedIn







Share to Email







Print This Post
With ImagesWithout Images

 





",,,,,,,,,,,,,,,"[{'@type': 'WebSite', '@id': 'https://www.aspistrategist.org.au/#website', 'url': 'https://www.aspistrategist.org.au/', 'name': 'The Strategist', 'description': 'ASPI&#039;s analysis and commentary site', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.aspistrategist.org.au/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-AU'}, {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://www.aspistrategist.org.au/the-geopolitics-of-artificial-intelligence/#primaryimage', 'url': 'https://www.aspistrategist.org.au/wp-content/uploads/2020/12/ai2312.jpg', 'contentUrl': 'https://www.aspistrategist.org.au/wp-content/uploads/2020/12/ai2312.jpg', 'width': 1050, 'height': 700}, {'@type': 'WebPage', '@id': 'https://www.aspistrategist.org.au/the-geopolitics-of-artificial-intelligence/', 'url': 'https://www.aspistrategist.org.au/the-geopolitics-of-artificial-intelligence/', 'name': 'The geopolitics of artificial intelligence | The Strategist', 'isPartOf': {'@id': 'https://www.aspistrategist.org.au/#website'}, 'primaryImageOfPage': {'@id': 'https://www.aspistrategist.org.au/the-geopolitics-of-artificial-intelligence/#primaryimage'}, 'datePublished': '2020-12-23T19:00:22+00:00', 'dateModified': '2020-12-23T19:21:30+00:00', 'author': {'@id': 'https://www.aspistrategist.org.au/#/schema/person/adff203ce018c24f1cf0f9aa42effc20'}, 'breadcrumb': {'@id': 'https://www.aspistrategist.org.au/the-geopolitics-of-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-AU', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.aspistrategist.org.au/the-geopolitics-of-artificial-intelligence/']}]}, {'@type': 'BreadcrumbList', '@id': 'https://www.aspistrategist.org.au/the-geopolitics-of-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.aspistrategist.org.au/'}, {'@type': 'ListItem', 'position': 2, 'name': 'The geopolitics of artificial intelligence'}]}, {'@type': 'Person', '@id': 'https://www.aspistrategist.org.au/#/schema/person/adff203ce018c24f1cf0f9aa42effc20', 'name': 'Anastasia Kapetas', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://www.aspistrategist.org.au/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/c87f16bf7229713b8822cceea19a57ab?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/c87f16bf7229713b8822cceea19a57ab?s=96&d=mm&r=g', 'caption': 'Anastasia Kapetas'}, 'url': 'https://www.aspistrategist.org.au/author/anastasia-kapetas/'}]",,
https://news.google.com/rss/articles/CBMif2h0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC03LWFtYXppbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYXBwbGljYXRpb25zLXRoYXQtYXJlLXVuZmFtaWxpYXLSAYkBaHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC03LWFtYXppbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYXBwbGljYXRpb25zLXRoYXQtYXJlLXVuZmFtaWxpYXI?oc=5,Top 7 Amazing Artificial Intelligence Applications that Are Unfamiliar - Analytics Insight,2020-12-24,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,AI applications,Amazing AI applications,Unfamiliar AI applications,Top AI applications","There are a lot of extraordinary AI applications that exist on the tech radar but are unfamiliar When people hear the word 'artificial intelligence,' most of us","There are a lot of extraordinary AI applications that exist on the tech radar but are unfamiliar When people hear the word 'artificial intelligence,' most of us",http://schema.org,NewsArticle,Top 7 Amazing Artificial Intelligence Applications that Are Unfamiliar,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Top-7-Amazing-Artificial-Intelligence-Applications-that-Are-Unfamiliar.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",2020-12-24T23:30:15Z,2020-12-24T23:30:15Z,"[{'@type': 'Person', 'givenName': 'Adilin Beatrice', 'name': 'Adilin Beatrice', 'url': 'https://www.analyticsinsight.net/author/adilin-beatrice'}]",N/A,N/A,What is AI and Data Science Engineering? ,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/top-7-amazing-artificial-intelligence-applications-that-are-unfamiliar'}",,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/top-7-amazing-artificial-intelligence-applications-that-are-unfamiliar', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Top-7-Amazing-Artificial-Intelligence-Applications-that-Are-Unfamiliar.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 7 Amazing Artificial Intelligence Applications that Are Unfamiliar', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/top-7-amazing-artificial-intelligence-applications-that-are-unfamiliar'}]",https://www.analyticsinsight.net/artificial-intelligence/top-7-amazing-artificial-intelligence-applications-that-are-unfamiliar,Artificial Intelligence,Top 7 Amazing Artificial Intelligence Applications that Are Unfamiliar,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Top-7-Amazing-Artificial-Intelligence-Applications-that-Are-Unfamiliar.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,"There are a lot of extraordinary AI applications that exist on the tech radar but are unfamiliar.When people hear the word 'artificial intelligence,' most of us are tend to think about the atrocious robot that takes over humankind as¬†portrayed in sci-fi movies. Even though it is possible when¬†AI reaches a certain level of improvement, the current developments in technology are mostly human-friendly. Artificial intelligence refers to the simulation of human intelligence in machines programmed to think like humans and mimic their actions. Generally,¬†AI benefits in significant fields¬†like finance, healthcare, business, and security. Besides, humans can never beat AI in weather prediction, drug discovery, and stock market crashes. We are already¬†employing AI to do many jobs¬†in our daily routine. For example, Netflix and Spotify use AI technology to sort the viewer's preference. A lot of modern home appliances are powered by AI. Henceforth, let us take a moment to think about some extraordinary things that AI is doing today. Analytics Insight brings you a list of AI applications that shows the power of AI..Top 10 AI applications that show how far we have come.AI perfumers.We always had a thought on how AI will react if it can hear, taste, or smell things. Scientists and researchers have been working to improve such features in AI machines. Even though it is a long way to reach that stage, tech companies are taking baby steps to improve relative technologies. IBM research is collaborated with a German Fragrance House Symrise to introduce artificial olfaction sensation in the perfume industry. They analyzed present fragrance chemical formulas to develop a new way of preparing fragrances. The companies used data to sort consumer choices and preferences by studying historical buying options. Later, they used the data to mix several aromatic components to give people a unique fragrance. In 2019, two AI-prepared aromas were released by the company..AI pets.Pet lovers, please take note. AI pets are stealing the market with more love. Generally, children play with cyborg dogs and little robots. It was not a big deal until the real AI pet entered the tech space. AI pets can recognize emotions and respond to your commands. Yes, it is very heartwarming. MOFLIN is an AI pet with emotional capabilities. It evolves like living animals. MOFLIN is designed to learn and constantly grow, using its interactions to determine patterns and evaluate its surroundings from its sensors. The AI pet chooses from an infinite number of mobile and sound pattern combinations to respond and express their feelings..Fortune telling.Thinking AI as a 'fortune teller' might sound funny. But the futuristic technology is bringing breakthrough changes into the modern landscape. AI researchers are working to make technology discover people's feelings and emotions with high precision. Stanford University researchers unveiled an algorithm that scans faces on images to declare a person as gay. The AI algorithm is efficient enough to detect a gay with 81% accuracy in men and 74% accuracy in women. Social media platforms are also using AI to flag unusual behavior among people, leading to suicide. Facebook's AI detected over a hundred cases that needed attention..AI in creativity.We are at the technological evolution where AI is capable of showing its interest in art and creativity. Today, AI is composing music, drawing pictures and much more. An AI-based system called MuseNet can now compose classical music that echoes the classical legends, Bach and Mozart. OpenAI's MuseNet is a Deep Neural Network that can create four-minute musical compositions with different tech instruments and combine Mozart's country styles with the Beatles. An algorithm developed by Tao Xu at Microsoft Research generates art or pictures. It is trained on a database of photographs and descriptions, matching certain words to particular colors, textures, and shapes..AI as the best chef.AI-powered robots are doing the cooking and serving jobs for a long time. Recently, chef robots have invaded the Chinese military to cook food for army men. However, an AI-machine designing the food you crave or suggesting a dish with the left-over ingredients is something to note. IBM's Chef Watson might be the solution home chefs need to overcome a pantry with only a few ingredients that couldn't possibly go together or welcome inspiration to professional chefs who want to evolve their menu through cognitive cooking and take advantage of seasonal ingredients..Revolutionising recruiting.We are familiar with how AI is invading every sector and transforming them for good. But we always thought that we are superior to AI in every way. Currently, AI can benefit the resume filtering process, which can be time-consuming and tedious. Even though there are minor issues like AI recruitment facing discrimination problems, the technology is updating its functionalities to conquer them. Besides, AI software can design interview questions for potential hires with a focus on the person's professional competency for a particular job without knowing their race, gender, or ethnicity..AI in smart cities.Smart cities are the dream of both governments and people. Many countries worldwide are trying to turn their developing city into a smart city with Internet of Things (IoT) connectivity. According to Omdia, the global smart city AI software market is set to soar to US$4.9 billion in 2025, up from US$673.8 million in 2019. Wireless data communication standards are enabling smart city applications to move into the online realm where they can capitalize on the latest AI innovations..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",2020-12-24T23:30:15Z
https://news.google.com/rss/articles/CBMikQFodHRwczovL2J1c2luZXNzZGF5Lm5nL2NvbXBhbmllcy9hcnRpY2xlL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWV2YW5nZWxpc3Qtb2x1c29sYS1hbXVzYW4taXMtb25lLW9mLWpjaXMtdG9wLW91dHN0YW5kaW5nLXBlcnNvbmFsaXRpZXMtZm9yLTIwMjAv0gEA?oc=5,"Artificial Intelligence evangelist, Olusola Amusan is one of JCI‚Äôs Top outstanding personalities for 2020. - Businessday",2020-12-22,Businessday,https://businessday.ng,N/A,N/A,N/A,N/A,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vY2FuYWRpYW5nZW9ncmFwaGljLmNhL2FydGljbGVzL2NhbmFkaWFuLWNvbXBhbmllcy13aXRoLXJvYm90cy10ZW5kLXRvLWVtcGxveS1tb3JlLWh1bWFuLWVtcGxveWVlcy1yZXBvcnQv0gEA?oc=5,Canadian companies with robots tend to employ more human employees: Report - Canadian Geographic,2020-12-23,Canadian Geographic,https://canadiangeographic.ca,"&nbsp;A Statistics Canada analysis showed that companies that have robots employ 15 per cent more human employees and have fewer managers
",N/A,"¬†A Statistics Canada analysis showed that companies that have robots employ 15 per cent more human employees and have fewer managers
","¬†A Statistics Canada analysis showed that companies that have robots employ 15 per cent more human employees and have fewer managers
",http://schema.org,NewsArticle,Canadian companies with robots tend to employ more human employees: Report,['https://canadiangeographic.ca/wp-content/uploads/2022/02/fitore-f-qks8oq4d_r0-unsplash-1200x900.jpg'],2020-12-23T04:00:00+00:00,2020-12-23T04:00:00+00:00,"[{'@type': 'Person', 'name': 'Leila El Shennawy', 'url': 'https://canadiangeographic.ca/author/leila-el-shennawy/'}]",N/A,N/A,"




History
The untold story of the Hudson‚Äôs Bay Company

A look back at the early years of the¬†350-year-old¬†institution that once claimed a vast portion of the globe




4473 words


18 minutes




","{'@type': 'WebPage', '@id': 'https://canadiangeographic.ca/articles/canadian-companies-with-robots-tend-to-employ-more-human-employees-report/'}",,,"{'@type': 'Organization', 'name': 'Canadian Geographic', 'logo': {'@type': 'ImageObject', 'url': 'https://canadiangeographic.ca/wp-content/themes/child-theme/assets/img/brand-assets/cg-logo.png?=16cd926'}}",,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2hvdy1iZW5lZmljaWFsLWlzLWFpLXRvLXByb2R1Y3Rpdml0edIBZ2h0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9ob3ctYmVuZWZpY2lhbC1pcy1haS10by1wcm9kdWN0aXZpdHk?oc=5,How Beneficial is AI to Productivity? - Analytics Insight,2020-12-26,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,AI and productivity,Technology sectors,Automation,AI improves productivity","Artificial intelligence (AI), which can be applied to automate the system to achieve more productivity and results, brings a significant change in technology se","Artificial intelligence (AI), which can be applied to automate the system to achieve more productivity and results, brings a significant change in technology se",http://schema.org,NewsArticle,How Beneficial is AI to Productivity?,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/AI-and-Productivity.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",2020-12-26T11:53:38Z,2020-12-26T11:53:38Z,"[{'@type': 'Person', 'givenName': 'Monomita Chakraborty', 'name': 'Monomita Chakraborty', 'url': 'https://www.analyticsinsight.net/author/monomita-chakraborty'}]",N/A,N/A,What is AI and Data Science Engineering? ,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/how-beneficial-is-ai-to-productivity'}",,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/how-beneficial-is-ai-to-productivity', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/AI-and-Productivity.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'How Beneficial is AI to Productivity?', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/how-beneficial-is-ai-to-productivity'}]",https://www.analyticsinsight.net/artificial-intelligence/how-beneficial-is-ai-to-productivity,Artificial Intelligence,How Beneficial is AI to Productivity?,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/AI-and-Productivity.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,"Artificial intelligence (AI), which can be applied to automate the system to achieve more productivity and results, brings a significant change in technology sectors. Just from your cell phone to the diagnosis of diseases, AI is now being used in many fields, offering high-performance and precise device operation with quality..AI systems are sufficiently effective to minimize human effort in different fields. Many of them use artificial intelligence to build computer programs that perform various activities on a regular basis in many industries. Applications of artificial intelligence help to get the job done quicker and with accurate outcomes. The key motive behind artificial intelligence is error-free and productive functions. Many industries have begun to use AI technology in recent years to minimize human efforts, and also to produce efficient and faster performance..Artificial intelligence (AI) is, according to the World Economic Forum, already a fact in many sectors, but the application of technology still possesses considerably more potential. The study provides for labor productivity growth in developed countries by up to 40% by 2035, as a result of artificial intelligence influences. Sweden is expected to have a high productivity rise of about 37%. Also predicted to benefit greatly from the impacts of AI are the US (35 percent) and Japan (34 percent). AI will theoretically increase labor productivity in Germany and Austria by approximately 30 percent in the next 15 years..Artificial Intelligence automation is rising efficiently across countries and the numbers look impressive. AI also dominates the field of scientific research apart from applications for corporate setups for productivity improvement..There are many advantages, but there is also a certain amount of risk for any big breakthrough. One of the main threats may be the use of this technology for destruction or other similar practices. If this happens, the very technologies we develop will destroy us in the near future. There are several organizations and scientists who are calling for regulatory oversight of AI implementation and programs to take care of this critical aspect. In order for all countries to be at peace and to experience development in their respective countries, oversight must be at the national and international levels..AI is not a vision for the future, but rather something that is real today and is being integrated into and deployed in a variety of sectors. This includes economics, national security, medical care, criminal law, transport, and smart cities. Many instances exist in which AI already has an impact on the environment and has greatly improved human potential..Artificial Intelligence not only plays a vital role in the growth of business and systems but also at the next level for humans. We can expect much more exciting features and use of AI in the future with the rapid growth of technology and advancement..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",2020-12-26T11:53:38Z

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,@graph,genre,about,copyrightYear,discussionURL,inLanguage,isFamilyFriendly,isPartOf,person,alternativeHeadline,publishingPrinciples,thumbnailUrl,mainEntityOfPage,timeRequired,wordCount,dateCreated,identifier,creator,hasPart,pagination,printEdition
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvdG9tdmFuZGVyYXJrLzIwMjAvMDIvMTIvaG93LXRvLXRlYWNoLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,How To Teach Artificial Intelligence - Forbes,2020-02-12,Forbes,https://www.forbes.com,"Every high school graduate should have an appreciation of how AI is reshaping the economy and the career landscape—and the option of educational pathways that lead to college and meaningful high wage work.  
","AI,artificial intellience,computer science education,K-12,education,careers","Every high school graduate should have an appreciation of how AI is reshaping the economy and the career landscape—and the option of educational pathways that lead to college and meaningful high wage work.  
","Every high school graduate should have an appreciation of how AI is reshaping the economy and the career landscape—and the option of educational pathways that lead to college and meaningful high wage work.  
",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/tomvanderark/2020/02/12/how-to-teach-artificial-intelligence/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5e4280f7298c2a00065f7857/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Tom Vander Ark', 'url': 'https://www.forbes.com/sites/tomvanderark/', 'description': ""I am an advocate for better learning for everyone. As CEO of Getting Smart, I advise schools, districts, networks, foundations and learning organizations on the path forward. I've written or co-authored more than 50 books and papers including Getting Smart, Smart Cities, Smart Parents, Better Together, and The Power of Place. I served as a public school superintendent and the first Executive Director of Education for the Bill & Melinda Gates Foundation. I serve on the boards of nonprofits including Education Board Partners, 4.0 Schools, Digital Learning Institute, eduInnovation and advise One Stone, Teton Science Schools, Whittle School & Studios, and Mastery Transcript Consortium."", 'sameAs': ['https://www.twitter.com/@tvanderark']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",How To Teach Artificial Intelligence,2020-02-12T05:00:00-05:00,2020-02-21T16:58:55-05:00,Education,How To Teach Artificial Intelligence,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Leadership', 'item': 'https://www.forbes.com/leadership/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Education', 'item': 'https://www.forbes.com/education/'}]",Education,N/A,"More From ForbesJul 16, 2024,12:01pm EDTBig Changes Coming To The ACT Test.  Should Students Take It?Jul 16, 2024,06:00am EDT7 Ways Schools Are Stunting Children’s Prospects In An AI WorldJul 15, 2024,07:12pm EDTAt The Heart of Education, An Insoluble ProblemJul 15, 2024,09:05am EDTQuizlet Reports Pace Of AI Adoption Slowing, Becoming More IntentionalJul 15, 2024,07:39am EDTNew Survey Reveals Low Level Of Civics Literacy Among College StudentsJul 15, 2024,06:30am EDTThe College Admissions Taboo: 5 Reasons To Discuss College Transfer With The Class Of 2028Jul 13, 2024,07:35pm EDTWhat Does Project 2025 Actually Plan For Education?Edit StoryForbesLeadershipEducationHow To Teach Artificial IntelligenceTom Vander ArkContributorOpinions expressed by Forbes Contributors are their own.I write about the future of learning, work and human development.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itFeb 12, 2020,05:00am ESTUpdated Feb 21, 2020, 04:58pm ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to Linkedin
Artificial intelligence—code that learns—is likely to be humankind’s most important invention. It’s a 60-year-old idea that took off five years ago when fast chips enabled massive computing and sensors, cameras, and robots fed data-hungry algorithms. 


We’re a couple of years into a new age where machine learning (a functional subset of AI), big data and enabling technologies are transforming every sector. In every sector, there is a big data set behind every question. Every field is computational: healthcare, manufacturing, law, finance and accounting, retail, and real estate. We all work with smart machines—and they are getting smart fast. 

A World Economic Forum report indicated that 89% of U.S.-based companies are planning to adopt user and entity big data analytics by 2022, while more than 70% want to integrate the Internet of Things, explore web and app-enabled markets, and take advantage of machine learning and cloud computing

PROMOTED
Given these important and rapid shifts, it’s a good time to consider what young people need to know about AI and information technology. First, everyone needs to be able to recognize AI and its influence on people and systems, and be proactive as a user and citizen. Second, everyone should have the opportunity to use AI and big data to solve problems. And third, young people interested in computer science as a career should have a pathway for building AI. 

Recognizing AI. AI4K12 is an initiative of leading computer scientists that have identified five big ideas that every student should know about AI:
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report Says


Computers perceive the world using sensors. Examples include speech recognition and computer vision; emerging issues include the nature of intelligence and the limitations of human and computer perception. 
Agents maintain representations of the world and use them for reasoning. Examples include types of algorithms, the work they do and their limitations. 
Computers can learn from data. Examples include types of machine learning—yet there are concerns about issues such as bias in training data.  
Intelligent agents require many types of knowledge to interact naturally with humans. Examples include interacting with digital assistants, chatbots and robots. Emerging issues involve the nature of consciousness and limitations of AI interaction.  
AI applications can impact society in both positive and negative ways. Emerging issues include the use, fairness and transparency of algorithms and likely social impacts.   











CxO
US


CEO: C-suite news, analysis, and advice for top decision makers right to your inbox.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the CEO newsletter!


                More Newsletters
            


You’re all set! Enjoy the CEO newsletter!

                More Newsletters
            



Grade span expectations will be available from the organization this summer. See a visual summary below.AI-focused learning objectives for K-12 schools.AI4K12


1/100:00Forbes Leadership





Skip Ad
 
Continue watchingHow Parents Can Juggle Work And Support Their Child’s Educationafter the adVisit Advertiser websiteGO TO PAGE
The MIT Media Lab developed a middle school AI+Ethics course that hits many of these learning objectives. It was piloted by Montour Public Schools outside of Pittsburgh, Pennsylvania, which has incorporated the three-day course in its media arts class. Montour elementary students also conduct Google AI experiments.
Harvard Professor Xiao-Li Meng suggests starting with cross-curricular conversations about data quality—including where does it come from, what bias might be incorporated, how could we gather more?
Using AI. Beyond recognizing the growing influence of AI, young people benefit from periodic application of smart tools across the curriculum. 
Montour Middle School has a six-week elective course on AI autonomous robotics in collaboration with Carnegie Mellon Professor Dr. David Touretzky (who is also the founder of AI4K12). Students are challenged to learn and use AI technology to solve real problems. The school also offers a 10-day AI music class hosted in collaboration with Amper Music. Additionally, Montour hosted the World Artificial Intelligence Competition for Youth and over 100 middle school students presented their work last year in an AI Grand Showcase. 
Renton Prep (@rentonprep) introduces all students, sixth grade and up, to computer science including AI. Head of School Michelle Zimmerman (@mrzphd) has a book, Teaching AI, that is a great resource for educators and school leaders.
Code.org developed an AI for Oceans tutorial that serves as a useful introduction for intermediate and middle grade students. 
A dozen communities offer summer programs for underrepresented youth through AI4All (@ai4allorg). In these sessions, students learn how to use AI to solve problems they care about while being mentored by top AI practitioners.
FIRST Tech Challenge is an after-school opportunity for middle school students to learn about programming robots. Google offers free resources for computer science clubs. 
Building AI. For high school students interested in AI, data science and more broadly in  computer science, a dedicated pathway or academy is a great option. A recommended course sequence includes: 


9th: Computer Science Discovery (a free introductory course from Code.org) 
10th: AP Computer Science Principles (a free course from Code.org)
11th: Introduction to Data Science (a free class from UCLA used in LAUSD)
12th: college credit Python course (AP CS Java class is an option, but Python is more commonly used in data science and AI) 


Complement the CS curriculum with three years of integrated math (with a stronger emphasis on computation than calculation) and AP (or college credit) statistics.
A new college credit option is the MicroBachelors Program in Computer Science Fundamentals from edX (the three courses are free; the credit costs $500). 
Industry certifications are an increasingly popular supplement to (or even replacement for) college credit courses. AWS Educate offers free cloud computing courses and stackable badges. Google also offers cloud training and certification. 
Microsoft offers many training classes resulting in certificates. They have bundled resources into Imagine Academy, a set of resources used by schools in 135 countries. It supports pathways in computer science, data science, infrastructure, and productivity.
Work experiences and internships are a valuable complement to classroom learning. In Dallas over 75 business partners support the 18 P-TECH academies (which combine high school, community college and work experience).    
Every high school graduate should have an appreciation of how AI is reshaping the economy and the career landscape. They should have the chance to use smart tools to attack challenges they care about. And, if they are interested in a career in AI and data science, they should have pathways that lead to college and meaningful high wage work.  
Follow me on Twitter. Tom Vander ArkFollowingFollowI am an advocate for better learning for everyone. As CEO of Getting Smart, I advise schools, districts, networks, foundations and learning organizations on... Read MoreEditorial StandardsPrintReprints & Permissions
1/100:00Yo Gotti Sheds Light On His Upbringing 





Skip Ad
 
Continue watchingYo Gotti Sheds Light On His Upbringing after the adVisit Advertiser websiteGO TO PAGE",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LnVuaXRldGhldW5pb24ub3JnL25ld3MtZXZlbnRzL25ld3MvMjAyMC9mZWJydWFyeS9yZXBvcnQtb24tcm9ib3RzLWluLXRoZS1wdWJsaWMtc2VjdG9yLWZvcmdldHMtYWJvdXQtdGhlLWh1bWFuc9IBAA?oc=5,Report on robots in the public sector forgets about the humans - Unite the union,2020-02-11,Unite the union,https://www.unitetheunion.org,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vZWRyaS5vcmcvb3VyLXdvcmsvdGhlLWh1bWFuLXJpZ2h0cy1pbXBhY3RzLW9mLW1pZ3JhdGlvbi1jb250cm9sLXRlY2hub2xvZ2llcy_SAQA?oc=5,The human rights impacts of migration control technologies - European Digital Rights (EDRi),2020-02-12,European Digital Rights (EDRi),https://edri.org,N/A,N/A,"This is the first blogpost of a series on our new project which brings to the forefront the lived experiences of people on the move as they are impacted by technologies of migration control. The project, led by our Mozilla Fellow Petra Molnar, highlights the need to regulate the opaque technological experimentation documented in and […]",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,N/A,"[{'@type': 'WebPage', '@id': 'https://edri.org/our-work/the-human-rights-impacts-of-migration-control-technologies/', 'url': 'https://edri.org/our-work/the-human-rights-impacts-of-migration-control-technologies/', 'name': 'The human rights impacts of migration control technologies - European Digital Rights (EDRi)', 'isPartOf': {'@id': 'https://edri.org/#website'}, 'primaryImageOfPage': {'@id': 'https://edri.org/our-work/the-human-rights-impacts-of-migration-control-technologies/#primaryimage'}, 'image': {'@id': 'https://edri.org/our-work/the-human-rights-impacts-of-migration-control-technologies/#primaryimage'}, 'thumbnailUrl': 'https://edri.org/wp-content/uploads/2020/03/AI-migration-01.png', 'datePublished': '2020-02-12T00:00:00+00:00', 'dateModified': '2020-09-29T10:16:23+00:00', 'breadcrumb': {'@id': 'https://edri.org/our-work/the-human-rights-impacts-of-migration-control-technologies/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://edri.org/our-work/the-human-rights-impacts-of-migration-control-technologies/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://edri.org/our-work/the-human-rights-impacts-of-migration-control-technologies/#primaryimage', 'url': 'https://edri.org/wp-content/uploads/2020/03/AI-migration-01.png', 'contentUrl': 'https://edri.org/wp-content/uploads/2020/03/AI-migration-01.png', 'width': 1431, 'height': 485}, {'@type': 'BreadcrumbList', '@id': 'https://edri.org/our-work/the-human-rights-impacts-of-migration-control-technologies/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://edri.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Resources', 'item': 'https://edri.org/our-work/'}, {'@type': 'ListItem', 'position': 3, 'name': 'The human rights impacts of migration control technologies'}]}, {'@type': 'WebSite', '@id': 'https://edri.org/#website', 'url': 'https://edri.org/', 'name': 'European Digital Rights (EDRi)', 'description': 'Protecting digital rights in Europe.', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://edri.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMjAvYnJpbmdpbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY2xhc3Nyb29tLXJlc2VhcmNoLWxhYi1hbmQtYmV5b25kLTAyMTPSAQA?oc=5,"Bringing artificial intelligence into the classroom, research lab, and beyond - MIT News",2020-02-13,MIT News,https://news.mit.edu,"Through the Undergraduate Research Opportunities Program (UROP), MIT students have worked with researchers on projects to improve artificial intelligence literacy and K-12 education, understand face recognition and how the brain forms new memories, and speed up tedious tasks like cataloging new library material. ","Massachusetts Institute of Technology, MIT, MIT Quest for Intelligence, UROP, undergraduate research opportunities program (UROP), artificial intelligence, K-12 education, robots, Jibo, Nicole Thumma, Media Lab, Cynthia Breazeal, Hae Won Park, Nancy Kanwisher, Brain and cognitive sciences, Joanne Yuan, Katharina Dobs, Convolutional Neural Networks, Susumu Tonegawa, Timothy O’Connor, Bridge Project, Peter Hart, Julian Viera, Katherine Gallagher, Neuroscience, libraries, Andrei Dumitrescu, Google Cloud, Library of Congress, Pablo Alejo-Aguirre, Randi Williams, i2 Learning, Gizmo, Dolapo Adedokun, Daniel Adebi, stock market","Through the Undergraduate Research Opportunities Program (UROP), MIT students have worked with researchers on projects to improve artificial intelligence literacy and K-12 education, understand face recognition and how the brain forms new memories, and speed up tedious tasks like cataloging new library material. ",N/A,,,,,,,,,,,,,,N/A,N/A,"


Through the Undergraduate Research Opportunities Program, students work to build AI tools with impact. 




Kim Martineau
|
MIT Quest for Intelligence


 Publication Date:
 February 13, 2020





Press Inquiries

  Press Contact:



      
            Kim         

            Martineau        

  

      Email:
     kimmarti@mit.edu


      Phone:
              617-710-5216      
  

      
            MIT Quest for Intelligence        

  








 Close














 Caption:
          Students participating in MIT Quest for Intelligence-funded UROP projects include: (clockwise from top left) Nicole Thumma, Joanne Yuan, Julian Viera, Andrei Dumitrescu, Pablo Alejo-Aguirre, and Dolapo Adedokun.      
          

 Credits:
          Photo panel: Samantha Smiley      
          

















Previous image
Next image






















Artificial intelligence is reshaping how we live, learn, and work, and this past fall, MIT undergraduates got to explore and build on some of the tools coming out of research labs at MIT. Through the Undergraduate Research Opportunities Program (UROP), students worked with researchers at the MIT Quest for Intelligence and elsewhere on projects to improve AI literacy and K-12 education, understand face recognition and how the brain forms new memories, and speed up tedious tasks like cataloging new library material. Six projects are featured below.
Programming Jibo to forge an emotional bond with kids
Nicole Thumma met her first robot when she was 5, at a museum. “It was incredible that I could have a conversation, even a simple conversation, with this machine,” she says. “It made me think robots are the most complicated manmade thing, which made me want to learn more about them.”
Now a senior at MIT, Thumma spent last fall writing dialogue for the social robot Jibo, the brainchild of MIT Media Lab Associate Professor Cynthia Breazeal. In a UROP project co-advised by Breazeal and researcher Hae Won Park, Thumma scripted mood-appropriate dialogue to help Jibo bond with students while playing learning exercises together.
Because emotions are complicated, Thumma riffed on a set of basic feelings in her dialogue — happy/sad, energized/tired, curious/bored. If Jibo was feeling sad, but energetic and curious, she might program it to say, “I'm feeling blue today, but something that always cheers me up is talking with my friends, so I'm glad I'm playing with you.​” A tired, sad, and bored Jibo might say, with a tilt of its head, “I don't feel very good. It's like my wires are all mixed up today. I think this activity will help me feel better.” 
In these brief interactions, Jibo models its vulnerable side and teaches kids how to express their emotions. At the end of an interaction, kids can give Jibo a virtual token to pick up its mood or energy level. “They can see what impact they have on others,” says Thumma. In all, she wrote 80 lines of dialogue, an experience that led to her to stay on at MIT for an MEng in robotics. The Jibos she helped build are now in kindergarten classrooms in Georgia, offering emotional and intellectual support as they read stories and play word games with their human companions.
Understanding why familiar faces stand out
With a quick glance, the faces of friends and acquaintances jump out from those of strangers. How does the brain do it? Nancy Kanwisher’s lab in the Department of Brain and Cognitive Sciences (BCS) is building computational models to understand the face-recognition process. Two key findings: the brain starts to register the gender and age of a face before recognizing its identity, and that face perception is more robust for familiar faces.
This fall, second-year student Joanne Yuan worked with postdoc Katharina Dobs to understand why this is so. In earlier experiments, subjects were shown multiple photographs of familiar faces of American celebrities and unfamiliar faces of German celebrities while their brain activity was measured with magnetoencephalography. Dobs found that subjects processed age and gender before the celebrities’ identity regardless of whether the face was familiar. But they were much better at unpacking the gender and identity of faces they knew, like Scarlett Johansson, for example. Dobs suggests that the improved gender and identity recognition for familiar faces is due to a feed-forward mechanism rather than top-down retrieval of information from memory. 
Yuan has explored both hypotheses with a type of model, convolutional neural networks (CNNs), now widely used in face-recognition tools. She trained a CNN on the face images and studied its layers to understand its processing steps. She found that the model, like Dobs’ human subjects, appeared to process gender and age before identity, suggesting that both CNNs and the brain are primed for face recognition in similar ways. In another experiment, Yuan trained two CNNs on familiar and unfamiliar faces and found that the CNNs, again like humans, were better at identifying the familiar faces.
Yuan says she enjoyed exploring two fields — machine learning and neuroscience — while gaining an appreciation for the simple act of recognizing faces. “It’s pretty complicated and there’s so much more to learn,” she says.
Exploring memory formation
Protruding from the branching dendrites of brain cells are microscopic nubs that grow and change shape as memories form. Improved imaging techniques have allowed researchers to move closer to these nubs, or spines, deep in the brain to learn more about their role in creating and consolidating memories.
Susumu Tonegawa, the Picower Professor of Biology and Neuroscience, has pioneered a technique for labeling clusters of brain cells, called “engram cells,” that are linked to specific memories in mice. Through conditioning, researchers train a mouse, for example, to recognize an environment. By tracking the evolution of dendritic spines in cells linked to a single memory trace, before and after the learning episode, researchers can estimate where memories may be physically stored. 
But it takes time. Hand-labeling spines in a stack of 100 images can take hours — more, if the researcher needs to consult images from previous days to verify that a spine-like nub really is one, says Timothy O’Connor, a software engineer in BCS helping with the project. With 400 images taken in a typical session, annotating the images can take longer than collecting them, he adds.
O’Connor contacted the Quest Bridge to see if the process could be automated. Last fall, undergraduates Julian Viera and Peter Hart began work with Bridge AI engineer Katherine Gallagher to train a neural network to automatically pick out the spines. Because spines vary widely in shape and size, teaching the computer what to look for is one big challenge facing the team as the work continues. If successful, the tool could be useful to a hundred other labs across the country.
“It’s exciting to work on a project that could have a huge amount of impact,” says Viera. “It’s also cool to be learning something new in computer science and neuroscience.”
Speeding up the archival process
Each year, Distinctive Collections at the MIT Libraries receives a large volume of personal letters, lecture notes, and other materials from donors inside and outside of MIT that tell MIT’s story and document the history of science and technology. Each of these unique items must be organized and described, with a typical box of material taking up to 20 hours to process and make available to users.
To make the work go faster, Andrei Dumitrescu and Efua Akonor, undergraduates at MIT and Wellesley College respectively, are working with Quest Bridge’s Katherine Gallagher to develop an automated system for processing archival material donated to MIT. Their goal: to develop a machine-learning pipeline that can categorize and extract information from scanned images of the records. To accomplish this task, they turned to the U.S. Library of Congress (LOC), which has digitized much of its extensive holdings. 
This past fall, the students pulled images of about 70,000 documents, including correspondence, speeches, lecture notes, photographs, and books housed at the LOC, and trained a classifier to distinguish a letter from, say, a speech. They are now using optical character recognition and a text-analysis tool to extract key details like the date, author, and recipient of a letter, or the date and topic of a lecture. They will soon incorporate object recognition to describe the content of a photograph, and are looking forward to testing their system on the MIT Libraries’ own digitized data.
One highlight of the project was learning to use Google Cloud. “This is the real world, where there are no directions,” says Dumitrescu. “It was fun to figure things out for ourselves.” 
Inspiring the next generation of robot engineers
From smartphones to smart speakers, a growing number of devices live in the background of our daily lives, hoovering up data. What we lose in privacy we gain in time-saving personalized recommendations and services. It’s one of AI’s defining tradeoffs that kids should understand, says third-year student Pablo Alejo-Aguirre. “AI brings us beautiful and elegant solutions, but it also has its limitations and biases,” he says.
Last year, Alejo-Aguirre worked on an AI literacy project co-advised by Cynthia Breazeal and graduate student Randi Williams. In collaboration with the nonprofit i2 Learning, Breazeal’s lab has developed an AI curriculum around a robot named Gizmo that teaches kids how to train their own robot with an Arduino micro-controller and a user interface based on Scratch-X, a drag-and-drop programming language for children. 
To make Gizmo accessible for third-graders, Alejo-Aguirre developed specialized programming blocks that give the robot simple commands like, “turn left for one second,” or “move forward for one second.” He added Bluetooth to control Gizmo remotely and simplified its assembly, replacing screws with acrylic plates that slide and click into place. He also gave kids the choice of rabbit and frog-themed Gizmo faces. “The new design is a lot sleeker and cleaner, and the edges are more kid-friendly,” he says. 
After building and testing several prototypes, Alejo-Aguirre and Williams demoed their creation last summer at a robotics camp. This past fall, Alejo-Aguirre manufactured 100 robots that are now in two schools in Boston and a third in western Massachusetts. “I’m proud of the technical breakthroughs I made through designing, programming, and building the robot, but I’m equally proud of the knowledge that will be shared through this curriculum,” he says.
Predicting stock prices with machine learning
In search of a practical machine-learning application to learn more about the field, sophomores Dolapo Adedokun and Daniel Adebi hit on stock picking. “We all know buy, sell, or hold,” says Adedokun. “We wanted to find an easy challenge that anyone could relate to, and develop a guide for how to use machine learning in that context.”
The two friends approached the Quest Bridge with their own idea for a UROP project after they were turned away by several labs because of their limited programming experience, says Adedokun. Bridge engineer Katherine Gallagher, however, was willing to take on novices. “We’re building machine-learning tools for non-AI specialists,” she says. “I was curious to see how Daniel and Dolapo would approach the problem and reason through the questions they encountered.”
Adebi wanted to learn more about reinforcement learning, the trial-and-error AI technique that has allowed computers to surpass humans at chess, Go, and a growing list of video games. So, he and Adedokun worked with Gallagher to structure an experiment to see how reinforcement learning would fare against another AI technique, supervised learning, in predicting stock prices.
In reinforcement learning, an agent is turned loose in an unstructured environment with one objective: to maximize a specific outcome (in this case, profits) without being told explicitly how to do so. Supervised learning, by contrast, uses labeled data to accomplish a goal, much like a problem set with the correct answers included.
Adedokun and Adebi trained both models on seven years of stock-price data, from 2010-17, for Amazon, Microsoft, and Google. They then compared profits generated by the reinforcement learning model and a trading algorithm based on the supervised model’s price predictions for the following 18 months; they found that their reinforcement learning model produced higher returns.
They developed a Jupyter notebook to share what they learned and explain how they built and tested their models. “It was a valuable exercise for all of us,” says Gallagher. “Daniel and Dolapo got hands-on experience with machine-learning fundamentals, and I got insight into the types of obstacles users with their background might face when trying to use the tools we’re building at the Bridge.”








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print







Related Links

Undergraduate Research Opportunities ProgramQuest for IntelligenceMIT Media LabMIT LibrariesDepartment of Brain and Cognitive SciencesDepartment of Electrical Engineering and Computer ScienceSchool of ScienceSchool of Engineering






Related Topics

Quest for Intelligence
Brain and cognitive sciences
Media Lab
Libraries
School of Engineering
School of Science
Algorithms
Computer science and technology
Machine learning
Undergraduate Research Opportunities Program (UROP)
Students
Undergraduate
Electrical engineering and computer science (EECS)



Related Articles











Developing artificial intelligence tools for all













Exploring the nature of intelligence

















Previous item
Next item
















",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3LmVldGltZXMuY29tL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWdldHMtaXRzLW93bi1zeXN0ZW0tb2YtbnVtYmVycy_SAQA?oc=5,Artificial Intelligence Gets Its Own System of Numbers - EE Times,2020-02-14,EE Times,https://www.eetimes.com,"BF16, the new number format optimized for deep learning, promises power and compute savings with a minimal reduction in prediction accuracy","ee times, electrical engineering, electronic engineering times, electronics, eet, news, analysis, opinion, business, technology, EELife, EELive! electronic design, community, embedded systems, software, education, EE Times University, Designline, learning, eet, part search, tech papers, fundamentals courses, product search, electronic components, video, analog, digital, mixed signal, semiconductors, silicon, software","BF16, the new number format optimized for deep learning, promises power and compute savings with a minimal reduction in prediction accuracy",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"



designLines
AI & Big Data Designline


Artificial Intelligence Gets Its Own System of Numbers

By
Sally Ward-Foxton 
02.14.2020

2



Share Post


Share on Facebook



Share on Twitter














BF16, sometimes called BFloat16 or Brain Float 16, is a new number format optimised for AI/deep learning applications. Invented at Google Brain, it has gained wide adoption in AI accelerators from Google, Intel, Arm and many others.
The idea behind BF16 is to reduce the compute power and energy consumption needed to multiply tensors together by reducing the precision of the numbers. A tensor is a three-dimensional matrix of numbers; multiplication of tensors is the key mathematical operation required for AI calculations.

  As developers realize IoT systems need more intelligence deployed to the edge to overcome latency, performance data privacy/security and bandwidth challenges, we explore the pursuit of that smarter edge: the what, why and where.

Most AI training today uses FP32, 32-bit floating point numbers. While this means the calculations are very accurate, it needs beefy hardware and uses a lot of power. Inference in general uses INT8, 8-bit integer (whole) numbers. While using lower precision number systems like INT8 offers more throughput on the same hardware, and therefore saves power, the results of the calculation (the prediction) are less accurate.


Partner Content
View All
					










SiC Wafer Cutting Speed Up to 100 Times Faster than Dicing 
By Mitsuboshi Diamond Industries  07.08.2024








Revolutionary Solutions for Enhancing the Efficiency of Robotic Arms: YMIN Capacitor Applications
By Shanghai Yongming Electronic Co.,Ltd  07.08.2024








Environmental Protection and Efficiency Combined: YMIN’s Supercapacitors SDS/SLX Series Revolutionize the Electronic Pen Market
By Shanghai Yongming Electronic Co.,Ltd  07.01.2024


SPONSORED: Sensing the environment as with human senses


The idea behind BF16 is to optimize the tradeoff between precision and prediction accuracy in order to increase throughput.
Anatomy of an FP Number
Binary numbers in computing are represented as:
Mantissa x baseexponent where the base is 2.
In FP32, each number is represented by:
1 bit representing the sign (+ or -), followed by an 8-bit exponent, followed by a 23-bit mantissa (total 32 bits).
For BF16, Google Brain proposed reducing precision by truncating the mantissa of an FP32 number to 7 bits.
BF16 numbers are therefore represented by:
1 sign bit, then 8 exponent bits, then 7 mantissa bits (total 16 bits).
Floating point number formats (Image: Google)
These 16-bit numbers offer the increased throughput that Google was after, while preserving the approximate dynamic range (the entire range of numbers that can be represented by this system) of FP32, since the exponent is the same size.
Prediction accuracy for algorithms using BF16 was similar, if not quite as accurate as FP32 (Google have said this is because neural networks are far more sensitive to the size of the exponent than the mantissa). For most applications, this is deemed to be an acceptable trade-off.
Why not use FP16?
The existing FP16 format, popular in mobile graphics applications, is also a 16-bit floating point number format. Why not just use that?
FP16 comprises:
1 sign bit, 5 exponent bits, then 10 mantissa bits (total 16 bits).
With this format, the exponent is smaller than for FP32, so the dynamic range is much reduced. Also, it’s much harder to convert FP32 numbers to FP16 than to BF16 – it’s a lot more work compared to just truncating the mantissa, which is a relatively simple operation.
Another important point is the physical area of silicon required for calculations. Since the physical size of a hardware multiplier increases with the square of the mantissa width, there are significant savings in silicon area gained by switching from FP32 to BF16 (enough to convince Google to use BF16 in its Tensor Processing Unit (TPU) chips). BF16 multipliers are eight times smaller than an FP32 multiplier, and still half the size of an FP16 equivalent.
What other formats are there for DL?
BF16 was not the only new number format proposed for deep learning. Nervana proposed a format called Flexpoint in 2017. The idea was to reduce computational and memory requirements by combining the advantages of point and floating point number systems.
Fixed point numbers use a fixed number of bits to represent an integer (whole number) and a fraction (the part after the decimal point) – in general it is simpler and faster to compute with fixed point numbers compared to the floating point formats described above. However, for a given number of bits, the dynamic range is much smaller for a fixed point number than a floating point number.
Flexpoint numbers shared the same exponent to make tensors easier to multiply (Image: Nervana/NeurIPS)
All the (floating point) numbers in a Flexpoint tensor used the same exponent (not just the same exponent size, the exact same exponent value). This exponent was shared between all the numbers in the tensor – so that communication of the exponent could be amortized across the entire tensor.
Multiplying tensors could then be done as a fixed point operation, since the exponent is the same for each calculation  — this would be simpler than the maths required for floating point numbers. These calculations represent the vast majority of deep learning maths, so the savings would be significant. However, it was complex to manage the exponents, and the dynamic range (the range of numbers that could be represented) was low, because all numbers had the same exponent.
Flexpoint never took off and even Nervana’s own chips ended up using BF16 before their demise.
Articles in this Special Project:
Let’s Talk Edge Intelligence
By Nitin Dahad
What’s the difference between edge AI and endpoint AI, and how much smart should you put into an edge AI device? We talk to various vendors about edge intelligence to see if there is a consensus on the ‘right way’.
 

Adapting the Microcontroller for AI in the Endpoint
by Sally Ward-Foxton
Will Arm continue to dominate going forward? Alternatives are springing up, and with the IoT set to expand, the market is set to expand as well.
 
Putting AI into the Edge is a No-Brainer and Here’s Why
By Duncan Stewart, Jeff Loucks, Deloitte’s Center for Technology, Media and Telecommunications
Adding AI will add only incremental cost to a device, whether it’s a smartphone or an enterprise/industrial application. The market, the economics, and the inherent benefits of edge AI.

Chip Startups for AI in Edge and Endpoint Applications
By Sally Ward-Foxton
Our top ten picks for most promising and/or interesting edge AI chip startups.
 
 
Edge Intelligence Ticks Many Boxes For AI
By Dennis Goldenson, SAR Insight & Consulting
Making the case for edge intelligence: no networks and real-time data.
 
 

Seeing the AI Inference Market with 2020 Vision: Our Top 5 Predictions
By Geoff Tate, Flex Logix
So AI chips optimized for inference, not for graphics, training or DSP, will be the big thing in 2020. Here is one perspective on the top 5 predictions for AI inference.
 
 
Giving IoT a Much Smarter Edge
By Nitin Dahad
As developers realize IoT systems need more intelligence deployed to the edge to overcome latency, performance data privacy/security and bandwidth challenges, we explore the pursuit of that smarter edge: the what, why and where. This is the introduction to the Edge AI Special Project. 



Suggested Reading


Connectivity Solutions Add Intelligence to Factories - EE Times
Open-Source Development Comes to Edge AI/ML Applications - EE Times
Electrical Engineering & Electronics Webinars - EE Times


Subscribe Today!
Get the latest electronics industry news delivered right to your inbox. Sign up for our free eNewsletters.Subscribe 





RELATED TOPICS:
ARTIFICIAL INTELLIGENCE (AI)
Share this:TwitterFacebookLinkedIn 






 


Sally Ward-Foxton 
							
Sally Ward-Foxton covers AI for EETimes.com and EETimes Europe magazine. Sally has spent the last 18 years writing about the electronics industry from London. She has written for Electronic Design, ECN, Electronic Specifier: Design, Components in Electronics, and many more news publications. She holds a Masters' degree in Electrical and Electronic Engineering from the University of Cambridge.   
Follow Sally on LinkedIn












2 comments

Post Comment 






 









												TanjB											
																					 
									
2020-02-18 12:12:56 


BF16 is a quick hack which does sensibly prioritize exponent at the cost of the fraction.  An interesting and perhaps better system is the ""posit"" which compresses fraction more aggressively for large exponents while giving more fraction for ordinary exponents.  It leverages the intuition that models are generally normalized to work in the central range.

Unfortunately, it is not possible to simply chop off some bits to simulate the format and so large scale tests have been limited.  The largest I have read about were weather forecasts where stability and accuracy beat BF16 and approached FP32.  That shows some promise, but more large scale modelling would be needed to really explore the tradeoffs vs. BF16.  It does seem premature to settle on BF16 as the only contender, given how much machinery the world is building for ML.

Posits would be more complex to unpack and pack for computation but in modern machines most of the power is lost in moving the data.  The energy needed to pack and unpack and to do the computations is likely to be minor.



Log in to Reply 








 









												TanjB											
																					 
									
2020-02-18 12:13:56 


Posits are described at posithub.org.



Log in to Reply 






Leave a Reply Cancel reply
				You must Register or
				Login to post a comment. 
This site uses Akismet to reduce spam. Learn how your comment data is processed.





","[{'@type': 'NewsArticle', '@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/#article', 'isPartOf': {'@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/'}, 'author': [{'@id': 'https://www.eetimes.com/#/schema/person/image/cfcaad583f77c25d69bd6325b9f93a4d'}], 'headline': 'Artificial Intelligence Gets Its Own System of Numbers', 'datePublished': '2020-02-14T07:42:38+00:00', 'dateModified': '2020-02-21T07:23:18+00:00', 'mainEntityOfPage': {'@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/'}, 'wordCount': 1136, 'commentCount': 2, 'publisher': {'@id': 'https://www.eetimes.com/#organization'}, 'image': {'@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/#primaryimage'}, 'thumbnailUrl': 'https://www.eetimes.com/wp-content/uploads/2020/02/Binary-Stock-Image-shutterstock_590692604-s.jpg?fit=926%2C927', 'keywords': ['Artificial Intelligence (AI)'], 'articleSection': ['Blog'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/', 'url': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/', 'name': 'Artificial Intelligence Gets Its Own System of Numbers - EE Times', 'isPartOf': {'@id': 'https://www.eetimes.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/#primaryimage'}, 'image': {'@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/#primaryimage'}, 'thumbnailUrl': 'https://www.eetimes.com/wp-content/uploads/2020/02/Binary-Stock-Image-shutterstock_590692604-s.jpg?fit=926%2C927', 'datePublished': '2020-02-14T07:42:38+00:00', 'dateModified': '2020-02-21T07:23:18+00:00', 'description': 'BF16, the new number format optimized for deep learning, promises power and compute savings with a minimal reduction in prediction accuracy', 'breadcrumb': {'@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/#primaryimage', 'url': 'https://www.eetimes.com/wp-content/uploads/2020/02/Binary-Stock-Image-shutterstock_590692604-s.jpg?fit=926%2C927', 'contentUrl': 'https://www.eetimes.com/wp-content/uploads/2020/02/Binary-Stock-Image-shutterstock_590692604-s.jpg?fit=926%2C927', 'width': 926, 'height': 927}, {'@type': 'BreadcrumbList', '@id': 'https://www.eetimes.com/artificial-intelligence-gets-its-own-system-of-numbers/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.eetimes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence Gets Its Own System of Numbers'}]}, {'@type': 'WebSite', '@id': 'https://www.eetimes.com/#website', 'url': 'https://www.eetimes.com/', 'name': 'EE Times', 'description': 'Connecting The Global Electronics Industry', 'publisher': {'@id': 'https://www.eetimes.com/#organization'}, 'alternateName': 'EETimes', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.eetimes.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'NewsMediaOrganization', '@id': 'https://www.eetimes.com/#organization', 'name': 'EE Times', 'alternateName': 'EETimes', 'url': 'https://www.eetimes.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.eetimes.com/#/schema/logo/image/', 'url': 'https://www.eetimes.com/wp-content/uploads/eetimes-logo-e1682516975717.jpg?fit=200%2C198', 'contentUrl': 'https://www.eetimes.com/wp-content/uploads/eetimes-logo-e1682516975717.jpg?fit=200%2C198', 'width': 200, 'height': 198, 'caption': 'EE Times'}, 'image': {'@id': 'https://www.eetimes.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/EETimes', 'https://x.com/eetimes', 'https://www.instagram.com/ee.times', 'https://www.linkedin.com/company/ee-times', 'https://www.youtube.com/channel/UCMMLsicGD2Zazw6xtPELWqg', 'https://en.wikipedia.org/wiki/EE_Times']}, {'@type': 'Person', '@id': 'https://www.eetimes.com/#/schema/person/image/cfcaad583f77c25d69bd6325b9f93a4d', 'name': 'Sally Ward-Foxton', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.eetimes.com/#/schema/person/image/376cbd075120ce5418bbcd0d5ba1c146', 'url': 'https://www.eetimes.com/wp-content/uploads/Sally-Ward_Foxton_low-res-6-e1678729120589.jpg?resize=150%2C150', 'contentUrl': 'https://www.eetimes.com/wp-content/uploads/Sally-Ward_Foxton_low-res-6-e1678729120589.jpg?resize=150%2C150', 'width': 150, 'height': 150, 'caption': 'Sally Ward-Foxton'}, 'description': ""Sally Ward-Foxton covers AI for EETimes.com and EETimes Europe magazine. Sally has spent the last 18 years writing about the electronics industry from London. She has written for Electronic Design, ECN, Electronic Specifier: Design, Components in Electronics, and many more news publications. She holds a Masters' degree in Electrical and Electronic Engineering from the University of Cambridge.\u202f\u202f"", 'url': 'https://www.eetimes.com/author/sally-ward-foxton/'}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd2Fyb250aGVyb2Nrcy5jb20vMjAyMC8wMi90aGUtYWJjcy1vZi1haS1lbmFibGVkLWludGVsbGlnZW5jZS1hbmFseXNpcy_SAQA?oc=5,The ABCs of AI-Enabled Intelligence Analysis - War On The Rocks,2020-02-14,War On The Rocks,https://warontherocks.com,Editor’s Note: This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial,N/A,Editor’s Note: This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial,N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,N/A,"[{'@type': 'WebSite', '@id': 'https://warontherocks.com/#website', 'url': 'https://warontherocks.com/', 'name': 'War on the Rocks', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://warontherocks.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://warontherocks.com/2020/02/the-abcs-of-ai-enabled-intelligence-analysis/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://warontherocks.com/wp-content/uploads/2020/02/Iain.jpg', 'width': 1330, 'height': 850}, {'@type': 'WebPage', '@id': 'https://warontherocks.com/2020/02/the-abcs-of-ai-enabled-intelligence-analysis/#webpage', 'url': 'https://warontherocks.com/2020/02/the-abcs-of-ai-enabled-intelligence-analysis/', 'name': 'The ABCs of AI-Enabled Intelligence Analysis - War on the Rocks', 'isPartOf': {'@id': 'https://warontherocks.com/#website'}, 'primaryImageOfPage': {'@id': 'https://warontherocks.com/2020/02/the-abcs-of-ai-enabled-intelligence-analysis/#primaryimage'}, 'datePublished': '2020-02-14T08:45:23+00:00', 'dateModified': '2020-02-14T02:11:57+00:00', 'author': {'@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8'}, 'description': 'Editor’s Note: This article was submitted in response to the\xa0call for ideas issued by the co-chairs of the National Security Commission on Artificial', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://warontherocks.com/2020/02/the-abcs-of-ai-enabled-intelligence-analysis/']}]}, {'@type': ['Person'], '@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8', 'name': 'Shane Mason', 'image': {'@type': 'ImageObject', '@id': 'https://warontherocks.com/#personlogo', 'inLanguage': 'en-US', 'url': 'https://secure.gravatar.com/avatar/83a68cf34a391d145ac9f37117795a86?s=96&d=identicon&r=g', 'caption': 'Shane Mason'}}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vZW5naW5lZXJpbmcucHJpbmNldG9uLmVkdS9uZXdzLzIwMjAvMDIvMTIvcmVzZWFyY2hlcnMtZGV2aXNlLWFwcHJvYWNoLXJlZHVjZS1iaWFzZXMtY29tcHV0ZXItdmlzaW9uLWRhdGEtc2V0c9IBAA?oc=5,Researchers devise approach to reduce biases in computer vision data sets - Princeton Engineering - Engineering at Princeton University,2020-02-12,Engineering at Princeton University,https://engineering.princeton.edu,"Addressing problems of bias in artificial intelligence, computer scientists from Princeton and Stanford University have developed methods to obtain fairer data sets containing images of people.",N/A,"Addressing problems of bias in artificial intelligence, computer scientists from Princeton and Stanford University have developed methods to obtain fairer data sets containing images of people.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

Researchers devise approach to reduce biases in computer vision data sets 
 By Molly Sharlach
 February 12, 2020

Addressing problems of bias in artificial intelligence, computer scientists from Princeton and Stanford University have developed methods to obtain fairer data sets containing images of people. The researchers propose improvements to ImageNet, a database of more than 14 million images that has played a key role in advancing computer vision over the past decade.

Addressing problems of bias in artificial intelligence, computer scientists from Princeton and Stanford University have proposed improvements to ImageNet, a database of more than 14 million images. The researchers developed a tool that allows users to specify and retrieve image sets of people that are balanced by age, gender expression or skin color. The above animation is a conceptual representation of the tool. GIF by Ryan Rizzuto
ImageNet, which includes images of objects and landscapes as well as people, serves as a source of training data for researchers creating machine learning algorithms that classify images or recognize elements within them. ImageNet’s unprecedented scale necessitated automated image collection and crowdsourced image annotation. While the database’s person categories have rarely been used by the research community, the ImageNet team has been working to address biases and other concerns about images featuring people that are unintended consequences of ImageNet’s construction.
“Computer vision now works really well, which means it’s being deployed all over the place in all kinds of contexts,” said co-author Olga Russakovsky, an assistant professor of computer science at Princeton. “This means that now is the time for talking about what kind of impact it’s having on the world and thinking about these kinds of fairness issues.”
In a new paper, the ImageNet team systematically identified non-visual concepts and offensive categories, such as racial and sexual characterizations, among ImageNet’s person categories and proposed removing them from the database. The researchers also designed a tool that allows users to specify and retrieve image sets of people that are balanced by age, gender expression or skin color – with the goal of facilitating algorithms that more fairly classify people’s faces and activities in images. The researchers presented their work on Jan. 30 at the Association for Computing Machinery’s Conference on Fairness, Accountability and Transparency in Barcelona, Spain.
“There is very much a need for researchers and labs with core technical expertise in this to engage in these kinds of conversations,” said Russakovsky. “Given the reality that we need to collect the data at scale, given the reality that it’s going to be done with crowdsourcing because that’s the most efficient and well-established pipeline, how do we do that in a way that’s fairer – that doesn’t fall into these kinds of prior pitfalls? The core message of this paper is around constructive solutions.”
A group of computer scientists at Princeton and Stanford launched ImageNet in 2009 as a resource for academic researchers and educators. Leading the effort was Princeton alumna and faculty member Fei-Fei Li, now a professor of computer science at Stanford. To encourage researchers to build better computer vision algorithms using ImageNet, the team also created the ImageNet Large Scale Visual Recognition Challenge. The challenge focused largely on object recognition using 1,000 image categories, only three of which featured people.
Some of the fairness issues in ImageNet stem from the pipeline used to build the database. Its image categories came from WordNet, an older database of English words used for natural language processing research. ImageNet’s creators adopted the nouns in WordNet – some of which, although they are clearly defined verbal terms, do not translate well to a visual vocabulary. For example, terms that describe a person’s religion or geographic origin might retrieve only the most distinctive image search results, potentially leading to algorithms that perpetuate stereotypes.
A recent art project called ImageNet Roulette brought increased attention to these concerns. The project, released in September 2019 as part of an art exhibition on image recognition systems, used images of people from ImageNet to train an artificial intelligence model that classified people in words based on a submitted image. Users could upload an image of themselves and retrieve a label based on this model. Many of the classifications were offensive or simply off-base.
The central innovation that allowed ImageNet’s creators to amass such a large database of labeled images was the use of crowdsourcing – specifically, the Amazon Mechanical Turk (MTurk) platform, through which workers were paid to verify candidate images. This approach, while transformative, was imperfect, leading to some biases and inappropriate categorizations.
“When you ask people to verify images by selecting the correct ones from a large set of candidates, people feel pressured to select some images and those images tend to be the ones with distinctive or stereotypical features,” said lead author Kaiyu Yang, a graduate student in computer science.
In the study, Yang and colleagues first filtered out potentially offensive or sensitive person categories from ImageNet. They defined offensive categories as those containing profanity or racial or gender slurs; sensitive categories included, for example, the classification of people based on sexual orientation or religion. To annotate the categories, they recruited 12 graduate students from diverse backgrounds, instructing them to err on the side of labeling a category as sensitive if they were unsure. This eliminated 1,593 categories – about 54% of the 2,932 person categories in ImageNet.
The researchers then turned to MTurk workers to rate the “imageability” of the remaining safe categories on a scale of 1 to 5. Keeping categories with an imageability rating of 4 or higher resulted in only 158 categories classified as both safe and imageable. Even this highly filtered set of categories contained more than 133,000 images – a wealth of examples for training computer vision algorithms.
Within these 158 categories, the researchers studied the demographic representation of people in the images in order to assess the level of bias in ImageNet and devise an approach to create fairer data sets. ImageNet’s content comes from image search engines such as Flickr, and search engines in general have been shown to produce results that overrepresent males, light-skinned people, and adults between the ages of 18 and 40.
“People have found that the distributions of demographics in image search results are highly biased, and this is why the distribution in ImageNet is also biased,” said Yang. “In this paper we tried to understand how biased it is, and also to propose a method to balance the distribution.”
Of the attributes protected under U.S. anti-discrimination laws, the researchers considered the three attributes that are imageable: skin color, gender expression and age. MTurk workers were asked to annotate each attribute of each person in an image. They classified skin color as light, medium or dark; and age as child (under 18), adult 18–40, adult 40–65 or adult over 65. Gender classifications included male, female and unsure – a way to include people with diverse gender expressions, as well as annotate images in which gender could not be perceived from visual clues (such as many images of babies or scuba divers).
An analysis of the annotations showed that, similar to search results, ImageNet’s content reflects considerable bias. People annotated as dark-skinned, females, and adults over 40 were underrepresented across most categories.
Although the annotation process included quality controls and required annotators to reach consensus, out of concern for the potential harm of mis-annotations, the researchers opted not to release demographic annotations for individual images. Instead, they designed a web-interface tool that allows users to obtain a set of images that are demographically balanced in a way the user specifies. For example, the full collection of images in the category “programmer” may include about 90% males and 10% females, while in the United States about 20% of computer programmers are female. A researcher could use the new tool to retrieve a set of programmer images representing 80% males and 20% females – or an even split, depending on the researcher’s purpose.
“We do not want to say what is the correct way to balance the demographics, because it’s not a very straightforward issue,” said Yang. “The distribution could be different in different parts of the world – the distribution of skin colors in the U.S. is different than in countries in Asia, for example. So we leave that question to our user, and we just provide a tool to retrieve a balanced subset of the images.”
The ImageNet team is currently working on technical updates to its hardware and database, in addition to implementing the filtering of the person categories and the rebalancing tool developed in this research. ImageNet will soon be re-released with these updates, and with a call for feedback from the computer vision research community.
Princeton Ph.D. student Klint Qinami and Assistant Professor of Computer Science Jia Deng co-authored the paper along with Yang, Li and Russakovsky. The research was supported by the National Science Foundation.

","[{'@type': 'NewsArticle', '@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets#article', 'isPartOf': {'@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets'}, 'author': {'name': 'Molly Sharlach', '@id': 'https://engineering.princeton.edu/#/schema/person/52ec80252a04f1b9403f44ce9905a4b7'}, 'headline': 'Researchers devise approach to reduce biases in computer vision data sets', 'datePublished': '2020-02-12T00:00:00+00:00', 'dateModified': '2024-05-30T15:09:37+00:00', 'mainEntityOfPage': {'@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets'}, 'wordCount': 11, 'publisher': {'@id': 'https://engineering.princeton.edu/#organization'}, 'image': {'@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets#primaryimage'}, 'thumbnailUrl': 'https://engineering.princeton.edu/wp-content/uploads/2021/09/russakovsky_imagenet_project.gif', 'inLanguage': 'en-US', 'copyrightYear': '2020', 'copyrightHolder': {'@id': 'https://engineering.princeton.edu/#organization'}}, {'@type': 'WebPage', '@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets', 'url': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets', 'name': 'Researchers devise approach to reduce biases in computer vision data sets - Princeton Engineering', 'isPartOf': {'@id': 'https://engineering.princeton.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets#primaryimage'}, 'image': {'@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets#primaryimage'}, 'thumbnailUrl': 'https://engineering.princeton.edu/wp-content/uploads/2021/09/russakovsky_imagenet_project.gif', 'datePublished': '2020-02-12T00:00:00+00:00', 'dateModified': '2024-05-30T15:09:37+00:00', 'description': 'Addressing problems of bias in artificial intelligence, computer scientists from Princeton and Stanford University have developed methods to obtain fairer data sets containing images of people.', 'breadcrumb': {'@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets#primaryimage', 'url': 'https://engineering.princeton.edu/wp-content/uploads/2021/09/russakovsky_imagenet_project.gif', 'contentUrl': 'https://engineering.princeton.edu/wp-content/uploads/2021/09/russakovsky_imagenet_project.gif', 'width': 800, 'height': 450, 'caption': 'Addressing problems of bias in artificial intelligence, computer scientists from Princeton and Stanford University have proposed improvements to ImageNet, a database of more than 14 million images. The researchers developed a tool that allows users to specify and retrieve image sets of people that are balanced by age, gender expression or skin color. The above animation is a conceptual representation of the tool. GIF by Ryan Rizzuto'}, {'@type': 'BreadcrumbList', '@id': 'https://engineering.princeton.edu/news/2020/02/12/researchers-devise-approach-reduce-biases-computer-vision-data-sets#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://engineering.princeton.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'News', 'item': 'https://engineering.princeton.edu/news'}, {'@type': 'ListItem', 'position': 3, 'name': 'Researchers devise approach to reduce biases in computer vision data sets'}]}, {'@type': 'WebSite', '@id': 'https://engineering.princeton.edu/#website', 'url': 'https://engineering.princeton.edu/', 'name': 'Princeton Engineering', 'description': '', 'publisher': {'@id': 'https://engineering.princeton.edu/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://engineering.princeton.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://engineering.princeton.edu/#organization', 'name': 'Princeton Engineering | Princeton University', 'url': 'https://engineering.princeton.edu/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://engineering.princeton.edu/#/schema/logo/image/', 'url': 'https://engineering.princeton.edu/wp-content/uploads/2021/11/engineering-school.jpeg', 'contentUrl': 'https://engineering.princeton.edu/wp-content/uploads/2021/11/engineering-school.jpeg', 'width': 1600, 'height': 900, 'caption': 'Princeton Engineering | Princeton University'}, 'image': {'@id': 'https://engineering.princeton.edu/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/princetonengineering/', 'https://x.com/EPrinceton', 'https://www.instagram.com/eprinceton/', 'https://www.linkedin.com/school/princetonengineering/', 'https://www.youtube.com/user/princetonengineering', 'https://en.m.wikipedia.org/wiki/Princeton_University_School_of_Engineering_and_Applied_Science']}, {'@type': 'Person', '@id': 'https://engineering.princeton.edu/#/schema/person/52ec80252a04f1b9403f44ce9905a4b7', 'name': 'Molly Sharlach'}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmVkd2Vlay5vcmcvdGVjaG5vbG9neS90aHJlZS1yZWFzb25zLXRvLWJlLXNrZXB0aWNhbC1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1zY2hvb2xzLzIwMjAvMDLSAQA?oc=5,Three Reasons to Be Skeptical of Artificial Intelligence in Schools - Education Week,2020-02-12,Education Week,https://www.edweek.org,"Having a strong teacher in the classroom is more important than having good technology, a University of Michigan professor argues. ","Future of Work,Technology,Artificial Intelligence","Having a strong teacher in the classroom is more important than having good technology, a University of Michigan professor argues.","Having a strong teacher in the classroom is more important than having good technology, a University of Michigan professor argues.",http://schema.org,NewsArticle,https://www.edweek.org/technology/three-reasons-to-be-skeptical-of-artificial-intelligence-in-schools/2020/02,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/81/3f/36f2ca87beb82fd8bfeda0557cd9/robot-blog-copyright-getty.jpg'}",Alyson Klein,"{'@type': 'Organization', 'name': 'Education Week', 'url': 'https://www.edweek.org', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/23/7a/33b323164fe78d35aa293a63f251/alyson-klein-jb.jpg'}}",Three Reasons to Be Skeptical of Artificial Intelligence in Schools,"February 12, 2020","November 18, 2020",,,,,"Technology, Future of Work",N/A,N/A,,News,"Future of Work,Technology,Artificial Intelligence",2020,https://www.edweek.org/technology/three-reasons-to-be-skeptical-of-artificial-intelligence-in-schools/2020/02#comments,en-US,true,https://www.edweek.org/technology/digital-education,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Education Week', 'description': 'Alyson Klein is an assistant editor for Education Week.', 'email': 'aklein@educationweek.org', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/23/7a/33b323164fe78d35aa293a63f251/alyson-klein-jb.jpg'}, 'jobTitle': 'Assistant Editor', 'name': 'Alyson Klein', 'url': 'https://www.edweek.org/by/alyson-klein'}]","Three Reasons to Be Skeptical of Artificial Intelligence in Schools,Three Reasons to Be Skeptical of Artificial Intelligence in Schools",https://www.edweek.org/about,https://epe.brightspotcdn.com/81/3f/36f2ca87beb82fd8bfeda0557cd9/robot-blog-copyright-getty.jpg,"{'@type': 'WebPage', '@id': 'https://www.edweek.org/technology/three-reasons-to-be-skeptical-of-artificial-intelligence-in-schools/2020/02'}",P2M,555,,,,,,
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vaHJtYXNpYS5jb20vaG93LWNvdW50cmllcy1hcmUtdXNpbmctYWktdG8tdHJhY2stZW1wbG95bWVudC_SAQA?oc=5,How countries are using AI to track employment | HRM Asia - HRM Asia,2020-02-12,HRM Asia,https://hrmasia.com,,N/A,"Artificial Intelligence is used not only by businesses, but governments to match jobs, analyse employment trends and even track illegal hiring.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

How countries are using AI to track employment

        Artificial Intelligence is used not only by businesses, but governments to match jobs, analyse employment trends and even track illegal hiring.    


        By: Daniel Teo | February 12, 2020
            

Topics: Asia-Pacific | Digital Transformation | HR Technology | News | Recruitment   


 
Artificial Intelligence (AI) is a powerful technology that has transformed many businesses and jobs. And with the amount of data in the employment industry, organisations and even governments are beginning to make use of the technology to match jobs and even track illegal hiring.
And with the employment market and trends going through constant changes with the rise of the gig economy and freelancers, there’s an increasing need to utilise technology to keep pace with the changes.
Let’s take a look at how some countries are utilizing AI to do so.
1) Recommend jobs
Estonia is leading the way in using AI for recruitment and employment. The government is making use of algorithm to profile candidates and “give a recommendation of where you could go next”, the country’s Chief Data Officer Ott Velsberg told GovInsider. “We could, in theory, give a heads up to you and say that you should perhaps choose another one,” he said. It can also predict what kind of jobs are in danger of redundancy. He also added that around 72% of candidates who joined new jobs through the AI system were still employed six months later, compared to 58% of those advised by officials.
2) Monitor fraud and illegal hires
Besides using AI to match jobs, governments are also using the technology to detect and track illegal hires. Singapore is using data to track the risk of employees and employers trying to break labour laws.
“Using advanced data science and machine learning on large, diverse sets of employment, business and transactional data, MOM developed agile analytics models to detect patterns and emerging risks for which early interventions in policy and regulations could be implemented,” a Ministry of Manpower (MOM) spokesperson told GovInsider.
“With tighter controls, more people would try to circumvent the system. With better use of data, MOM has achieved significantly higher detection rates and greater enforcement presence in a resource lean manner. For one exercise, we saved about 20,000 man-hours but covered 650 more cases,” the Ministry added.
3) International migration and future skills
Another way that AI can be used is to analyse migration and skills trends. One example is how the United Nations Development Programme’s Regional Innovation Centre for Asia Pacific has used publicly available LinkedIn data to identify labour migration patterns to and from Thailand.
It analysed data in Thailand and found out that Thailand attracted most people to jobs in international affairs, renewables, and sports while defence, space and maritime lost the most jobs to employees migrating out of Thailand.
Between 2015 and 2018, the biggest changes in labour migration came to and from Thailand were in the US, France and Myanmar. The LinkedIn data also showed that soft skills like time management, problem solving, negotiation and leadership are on the rise in Thailand.
ShareTweetShare

 




 
","[{'@type': 'WebPage', '@id': 'https://hrmasia.com/how-countries-are-using-ai-to-track-employment/', 'url': 'https://hrmasia.com/how-countries-are-using-ai-to-track-employment/', 'name': 'How countries are using AI to track employment | HRM Asia', 'isPartOf': {'@id': 'https://hrmasia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://hrmasia.com/how-countries-are-using-ai-to-track-employment/#primaryimage'}, 'image': {'@id': 'https://hrmasia.com/how-countries-are-using-ai-to-track-employment/#primaryimage'}, 'thumbnailUrl': 'https://hrmasia.com/wp-content/uploads/2020/02/54444686_l.jpg', 'datePublished': '2020-02-11T22:00:09+00:00', 'dateModified': '2020-02-11T10:17:35+00:00', 'author': {'@id': 'https://hrmasia.com/#/schema/person/1de41fb4b6aaf36c7cdeb59bf2e7bf2e'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://hrmasia.com/how-countries-are-using-ai-to-track-employment/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrmasia.com/how-countries-are-using-ai-to-track-employment/#primaryimage', 'url': 'https://hrmasia.com/wp-content/uploads/2020/02/54444686_l.jpg', 'contentUrl': 'https://hrmasia.com/wp-content/uploads/2020/02/54444686_l.jpg', 'width': 7470, 'height': 4418, 'caption': 'people, profession, qualification, employment and success concept - happy businessman over group of professional workers over city background'}, {'@type': 'WebSite', '@id': 'https://hrmasia.com/#website', 'url': 'https://hrmasia.com/', 'name': 'HRM Asia', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://hrmasia.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://hrmasia.com/#/schema/person/1de41fb4b6aaf36c7cdeb59bf2e7bf2e', 'name': 'Daniel Teo', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrmasia.com/#/schema/person/image/', 'url': 'https://hrmasia.com/wp-content/uploads/2019/12/daniel-teo-150x150.jpg', 'contentUrl': 'https://hrmasia.com/wp-content/uploads/2019/12/daniel-teo-150x150.jpg', 'caption': 'Daniel Teo'}, 'url': 'https://hrmasia.com/author/daniel/'}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3LmZpZXJjZWJpb3RlY2guY29tL21lZHRlY2gvbWVkdHJvbmljLXRvLWJvbHN0ZXItaXRzLWFpLWFuZC1zdXJnaWNhbC1yb2JvdGljcy13b3JrLWRpZ2l0YWwtc3VyZ2VyeS1hY3F1aXNpdGlvbtIBAA?oc=5,"Medtronic to bolster its AI, surgical robotics work with Digital Surgery acquisition - Fierce Biotech",2020-02-13,Fierce Biotech,https://www.fiercebiotech.com,Medtronic is looking to augment not only its work in robotic surgery but efforts across all of its procedural offerings through the,"Artificial Intelligence,mergers and acquisitions,robotic surgery,Robotics,Digital Surgery,Medtronic,Fierce Biotech Homepage,AI and Machine Learning,MedTech",Medtronic is looking to augment not only its work in robotic surgery but efforts across all of its procedural offerings through the,Medtronic is looking to augment not only its work in robotic surgery but efforts across all of its procedural offerings through the,https://schema.org/,,,,,,,,,,,,,"Fierce Biotech Homepage,AI and Machine Learning",N/A,"

































Fierce Pharma


Fierce Biotech


Fierce Healthcare


Fierce Life Sciences Events






Advertise


About Us








 

 


























 










Biotech



Cell & Gene Therapy


Clinical Data


Venture Capital


Deals




Research


Medtech



Devices


Diagnostics


AI and Machine Learning




CRO


Special Reports


Trending Topics



Diabetes




Fierce 50



Special Report


Awards Gala








Resources



Fierce Events


Industry Events


Webinars


Podcasts


Whitepapers


Survey



 Events 

Subscribe
















 




Subscribe





























Biotech



Cell & Gene Therapy


Clinical Data


Venture Capital


Deals




Research


Medtech



Devices


Diagnostics


AI and Machine Learning




CRO


Special Reports


Trending Topics



Diabetes




Fierce 50



Special Report


Awards Gala








Resources



Fierce Events


Industry Events


Webinars


Podcasts


Whitepapers


Survey



 Events 

Subscribe










Fierce Pharma


Fierce Biotech


Fierce Healthcare


Fierce Life Sciences Events






Advertise


About Us








 

 













































MedTech




Medtronic to bolster its AI, surgical robotics work with Digital Surgery acquisition





By 
Conor Hale





Feb 13, 2020 7:00am




Artificial Intelligence
mergers and acquisitions
robotic surgery
Robotics














To Medtronic, Digital Surgery offers not just new products to sell but also capabilities that could boost its in-house development projects. (Pixabay)
Medtronic is looking to augment not only its work in robotic surgery but efforts across all of its procedural offerings through the acquisition of Digital Surgery, London-based maker of data analytics, artificial intelligence and training programs for the operating room.This includes integrating and bundling the company’s AI and surgical video education platforms with the medtech giant’s various hardware endeavors—plus co-developed digital solutions for its upcoming, modular soft-tissue surgery robot named Hugo.The plan is for Digital Surgery to retain its current leadership and headquarters in the U.K., though it will operate under the robotics arm of Medtronic’s Minimally Invasive Therapies Group, which said it aims to invest and expand the workforce of the company. The financial terms of the deal have not been disclosed. RELATED: Medtronic takes its new surgery robot out for a spin with investor debutLast year, Medtronic CEO Omar Ishrak laid out his intentions to develop and apply computer-guided surgery and planning tools to multiple medical specialties, including bringing robotics to bear on “virtually every area” the company has a procedural presence.As a part of that mandate, its robotics division has been focused on developing four main technology vectors that touch Medtronic’s work across open surgery, laparoscopic and robotic procedures. They include visualization and navigation, instrumentation and implants, data and analytics, and the robotics platforms themselves.“And as we have been approaching the commercialization of our robotics platform, we've been, in parallel, focused on investing in and developing products, road maps and capabilities in those vectors,” said Megan Rosengarten, vice president and general manager of Medtronic’s surgical robotics business.RELATED: Medtronic reveals past Karl Storz vision team-up ahead of robotic surgery unveiling“For that data and analytics vector, we've been looking for quite a while and actively exploring partners in that space,” Rosengarten told FierceMedTech in an interview, describing how Digital Surgery checked a lot of boxes for the company—offering not just new products to sell, but also capabilities that could act as an in-house booster to help accelerate Medtronic’s other development projects.The deal includes Digital Surgery’s education app, Touch Surgery, with its on-demand library of hundreds of videos and procedure simulations for training surgeons and students outside the OR. The company also provides a HIPAA-certified surgical video sharing platform, which uses AI to automatically recognize and blur out images that could be used to identify patients or staff. This allows surgeons to annotate and edit videos for post-procedure team assessments, institutional training or use at conferences.“Products that assisted with the collection, storage and analysis of surgical video were specific things that we were looking for,” as well as capabilities that could be leveraged internally, such as image processing and algorithm development, Rosengarten said. Additionally, the ability to track procedure times and standardize procedures could help reduce variability as well as cost. “We’re really looking forward to learning a lot from Medtronic, as well as having access to their scale and expertise,” said Touch Surgery co-founder and CEO Jean Nehme, a surgeon himself. “We’re going to be able to work with a team who are global in surgery, and take the technology that we’ve been building to more patients.”RELATED: Digital Surgery partners with U.K. hospitals to bring GPS-style directions to the operating roomThe deal’s announcement comes the same week as robotics mainstay Intuitive Surgical’s move to acquire Orpheus Medical, an Israeli company that provides clinical video capture and archiving plus imaging documentation solutions. Its system records video from scope cameras and external monitors, including from Intuitive’s da Vinci system. “I went into this thinking we were either going to find components and products that we would commercialize and integrate into our robotic platform, or I was going to find some of these core data analytics and AI capabilities, or I was going to find a platform, a digital ecosystem and some existing assets around video and images,” Rosengarten said. “And that’s kind of the beauty—I don't want to oversell it, but the beauty of this Digital Surgery deal is that we got some elements of all of those things.”“The plans on this are to continue to grow and commercialize the products that exist within Digital Surgery today, in both laparoscopic and robotic surgery,” she added. “And they also bolster the data science capabilities that we have within the surgical robotics group—and will help develop the road map of solutions we have planned for the software that will be rolling out on our Hugo platform.”The Hugo surgical system was unveiled in a practice demonstration for investors last September, where it was used to perform a prostate procedure on a cadaver. At the time, Medtronic said it plans to secure a CE mark and 510(k) clearances for the platform, featuring up to four independent, cart-mounted robotic arms, within just two years—with the ultimate goal of offering per-procedure costs comparable to manual laparoscopy.

Artificial Intelligence
mergers and acquisitions
robotic surgery
Robotics
Digital Surgery
Medtronic
AI and Machine Learning
MedTech












Related ContentCardio-focused Cardurion closes hearty $260M series B to challenge statin-dominated status quoJul 17, 2024 07:00amSionna salvages AbbVie assets, teeing up dual combo assault on cystic fibrosisJul 16, 2024 10:00amScorpion snaps up $150M in series C funds to widen clinical plans for cancer pipelineJul 16, 2024 09:40amSotio taps Biocytogen to create bispecific ADCs in $326M dealJul 16, 2024 09:05am







See more articles










 



 

 








Connect



The Team


Advertise




Join Us



Newsletters


Resources


RSS Feeds




Our Brands



Fierce Pharma


Fierce Biotech


Fierce Healthcare




Our Events



Life Sciences Events

















©2024 Questex LLC All rights reserved.
Terms of use
Privacy Policy
Privacy Settings











","{'@type': 'NewsArticle', 'headline': 'Medtronic bolsters AI, robotics work with Digital Surgery buy', 'articleSection': None, 'keywords': 'MedTech', 'description': 'With the acquisition of Digital Surgery, Medtronic is looking to augment its work in robotic surgery as well as efforts across all its offerings.', 'datePublished': '2020-02-13T12:00:00', 'isAccessibleForFree': True, 'dateModified': '1648104147', 'author': [[{'@type': 'Person', 'name': 'Conor Hale', 'url': 'https://www.fiercebiotech.com/person/conor-hale-0'}]], 'publisher': {'@type': 'Organization', 'name': 'FierceBiotech', 'url': 'https://www.fiercebiotech.com'}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.fiercebiotech.com/medtech/medtronic-to-bolster-its-ai-and-surgical-robotics-work-digital-surgery-acquisition'}, 'image': 'https://qtxasset.com/quartz/qcloud5/media/image/fiercebiotech/1581561210/doctor-650534_1280.jpg/doctor-650534_1280.jpg?VersionId=UlgjKyhYrtn_1iChXXugE2chj045oeVS'}",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LmdlZWt3aXJlLmNvbS8yMDIwL2FpMi10aHJvd3MtY2hhbGxlbmdlLXJvYm90aWMtc2NhdmVuZ2VyLWh1bnQtc2V0LXZpcnR1YWwtcmVhbC1yb29tcy_SAQA?oc=5,AI2 throws down the challenge for robotic scavenger hunt in virtual and real rooms - GeekWire,2020-02-11,GeekWire,https://www.geekwire.com,"Computer vision and navigation have improved by leaps and bounds, thanks to artificial intelligence, but how well do the computer models work in the real world?",N/A,"Computer vision and navigation have improved by leaps and bounds, thanks to artificial intelligence, but how well do the computer models work in the real world?",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"


AI2 throws down the challenge for robotic scavenger hunt in virtual and real rooms
by Alan Boyle on February 11, 2020 at 6:00 amFebruary 10, 2020 at 11:05 pm




 Share  26
 Tweet
 Share
 Reddit
 Email




Subscribe to GeekWire Newsletters today!






 
 

BOT or NOT? This special series explores the evolving relationship between humans and machines, examining the ways that robots, artificial intelligence and automation are impacting our work and lives.






The RoboTHOR 2020 Challenge will test how well computer models for visual identification and navigation translate into real-world robotic performance. (AI2 Illustration / Winson Han)
Computer vision and navigation have improved by leaps and bounds, thanks to artificial intelligence, but how well do the computer models work in the real world?
That’s the challenge that Seattle’s Allen Institute for Artificial Intelligence is setting for AI researchers over the next few months, with geek fame and glory as the prize.
AI2’s RoboTHOR Challenge, which kicks off today, capitalizes on years of work that’s been done to train AI agents in synthetic environments.
Ani Kembhavi, a research scientist at AI2, says RoboTHOR focuses on the next step. “If you can train a deep-learning, computer vision model to do something in an embodied environment … how well would this model work when deployed in an actual robot?” he told GeekWire.
That’s a crucial step for putting such models to work, in applications ranging from self-driving cars to robotic caregivers. But testing the models in actual robots, or cars, is expensive. “A lot of the research in this important topic can only be done by an organization with a lot of funding,” Kembhavi said.
He said AI2’s RoboTHOR Challenge aims to “democratize” the development of computer models that translate more easily to the real world, in line with the nonprofit institute’s mission to advance the state of artificial intelligence for the common good.

The challenge sets up a virtual world with 89 different apartments in it. Inside each simulated apartment is a collection of everyday objects — including, say, chairs and a table, a sofa and a lamp, even a computer manual.
AI2 will make the simulation software and training data for 75 of the apartments available to all comers via the RoboTHOR website. (For what it’s worth, “THOR” stands for The House Of inteRactions.)
“We provide all the help that you need to start training the model,” Kembhavi said.
The computer models will be judged on how well they’re able to navigate to an object of a specified category from an arbitrary location. For example, if the model is given the category “apple,” it will have to identify the apple in the room, plot a course to get close to the apple and then signal that it’s been found. Think of it as a virtual scavenger hunt.
The real trick is to see how well the model does when it’s uploaded into a real robot, conducting a scavenger hunt in a real apartment. For that phase of the challenge, AI2 has set up a room that can be quickly configured to look like any of the apartments in the repertoire.
The left half of this image shows a simulated apartment room set up for the RoboTHOR Challenge. The right half shows a real room that reflects the exact layout of the simulation. (AI2 Images)
Teams will be able to test their models on 14 apartment scenarios, using LoCoBot, a robot that was developed specifically for these kinds of experiments.
Roozbeh Mottaghi, a senior research scientist at AI2 who’s also a computer science professor at the University of Washington, said LoCoBot was selected because it has all the sensors and mobility needed for the challenge. It’s also relatively cheap, with a price tag in the range of $5,000.
Organizers of the challenge have designed the environment so that teams can construct their own real-world RoboTHOR rooms if they want, using IKEA furniture and standard objects to spread around the room. The cost of replicating the RoboTHOR room in all its incarnations would be roughly $10,000.
The top-scoring teams will be invited to demonstrate their models in a RoboTHOR room that’ll be set up for an Embodied AI workshop at the Conference on Computer Vision and Pattern Recognition, scheduled June 14-15 in Seattle.
Winners will also be able to exercise their bragging rights in the research papers and presentations that will no doubt come out of the RoboTHOR Challenge.
“Those are the prizes,” Kembhavi joked.
Check out this video to see LoCoBot at work in a different type of experiment:



Message from the UnderwriterPutting AI-driven insights, productivity tools,
and security in the hands of businesses

We’re all experiencing a real-time revolution with the rise of generative AI. The opportunity is huge—but it requires a new approach to cloud computing. Organizations are already leveraging Google Cloud’s AI capabilities to unlock data, lower costs, embrace hybrid work, and protect against threats.
Learn how they’re succeeding at Transform with Google Cloud.
Learn more about underwritten and sponsored content on GeekWire.
More Bot or NotHow clean tech companies can take advantage of AI — without draining energy from the planetAI has trouble identifying sarcasm from Seattle satirical news site The Needling‘We know something big is happening’: Tech vets encourage experimentation, education with AIGeekWire contributing editor Alan Boyle is an award-winning science writer and veteran space reporter. Formerly of NBCNews.com, he is the author of ""The Case for Pluto: How a Little Planet Made a Big Difference."" Follow him via CosmicLog.com, on Twitter @b0yle, and on Facebook and MeWe. Reach him via email at alan@geekwire.com. 
 Share  26
 Tweet
 Share
 Reddit
 Email




Previous StoryJudge expected to rule in favor of T-Mobile-Sprint merger, paving way for historic wireless combination 

Next StoryAI-powered ‘Otterbot’ chatbot helps students navigate choppy waters of financial aid applications 

 Filed Under: Bot or Not • Science  Tagged With: AI2 • Allen Institute for Artificial Intelligence • computer vision • Navigation • RoboTHOR Challenge • Robotics








GeekWire Newsletters

Subscribe to GeekWire's free newsletters to catch every headline




Email address

Subscribe







GeekWire Daily - Top headlines daily
                                    




GeekWire Weekly - Most-read stories of the week, delivered Sunday
                                    




Breaking News Alerts - Important news as it happens
                                    




GeekWire Startups - News, analysis, insights from the Pacific Northwest startup ecosystem, delivered Friday
                                    




GeekWire Mid-week Update — Most-read stories so far this week, delivered Wednesday
                                    




GeekWire Local Deals — Special offers for Pacific Northwest area readers
                                    







Send Us a Tip
Have a scoop that you'd like GeekWire to cover? Let us know.

Send Us a Tip








","[{'@type': 'NewsArticle', '@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/#article', 'isPartOf': {'@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/'}, 'author': [{'@id': 'https://www.geekwire.com/#/schema/person/9641ab4b8b61dd1b5a6d0ebc6236d5ab'}], 'headline': 'AI2 throws down the challenge for robotic scavenger hunt in virtual and real rooms', 'datePublished': '2020-02-11T14:00:12+00:00', 'dateModified': '2020-02-11T07:05:12+00:00', 'mainEntityOfPage': {'@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/'}, 'wordCount': 738, 'commentCount': 0, 'publisher': {'@id': 'https://www.geekwire.com/#organization'}, 'image': {'@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/#primaryimage'}, 'thumbnailUrl': 'https://cdn.geekwire.com/wp-content/uploads/2020/02/200210-robothor2.png', 'keywords': ['AI2', 'Allen Institute for Artificial Intelligence', 'computer vision', 'Navigation', 'RoboTHOR Challenge', 'Robotics'], 'articleSection': ['Bot or Not', 'Science'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/', 'url': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/', 'name': 'AI2 throws down a challenge for robotic scavenger hunt', 'isPartOf': {'@id': 'https://www.geekwire.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/#primaryimage'}, 'image': {'@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/#primaryimage'}, 'thumbnailUrl': 'https://cdn.geekwire.com/wp-content/uploads/2020/02/200210-robothor2.png', 'datePublished': '2020-02-11T14:00:12+00:00', 'dateModified': '2020-02-11T07:05:12+00:00', 'description': 'Computer vision and navigation have improved by leaps and bounds, thanks to artificial intelligence, but how well do the computer models work in the real world?', 'breadcrumb': {'@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/#primaryimage', 'url': 'https://cdn.geekwire.com/wp-content/uploads/2020/02/200210-robothor2.png', 'contentUrl': 'https://cdn.geekwire.com/wp-content/uploads/2020/02/200210-robothor2.png', 'width': 2148, 'height': 1080, 'caption': 'The RoboTHOR 2020 Challenge will test how well computer models for visual identification and navigation translate into real-world performance. (AI2 Illustration / Winson Han)'}, {'@type': 'BreadcrumbList', '@id': 'https://www.geekwire.com/2020/ai2-throws-challenge-robotic-scavenger-hunt-set-virtual-real-rooms/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.geekwire.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Bot or Not', 'item': 'https://www.geekwire.com/bot-or-not/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI2 throws down the challenge for robotic scavenger hunt in virtual and real rooms'}]}, {'@type': 'WebSite', '@id': 'https://www.geekwire.com/#website', 'url': 'https://www.geekwire.com/', 'name': 'GeekWire', 'description': 'Breaking News in Technology &amp; Business', 'publisher': {'@id': 'https://www.geekwire.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.geekwire.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.geekwire.com/#organization', 'name': 'GeekWire', 'url': 'https://www.geekwire.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/#/schema/logo/image/', 'url': 'https://cdn.geekwire.com/wp-content/uploads/2017/10/GeekWire-Logo.png', 'contentUrl': 'https://cdn.geekwire.com/wp-content/uploads/2017/10/GeekWire-Logo.png', 'width': 400, 'height': 400, 'caption': 'GeekWire'}, 'image': {'@id': 'https://www.geekwire.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/geekwire', 'https://x.com/geekwire', 'https://www.instagram.com/geekwire/', 'https://www.youtube.com/geekwire', 'https://www.pinterest.com/geekwire/', 'https://en.wikipedia.org/wiki/GeekWire', 'https://www.linkedin.com/company/geekwire/']}, {'@type': 'Person', '@id': 'https://www.geekwire.com/#/schema/person/9641ab4b8b61dd1b5a6d0ebc6236d5ab', 'name': 'Alan Boyle', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/#/schema/person/image/fe58e4d63645669100f65958faeb8f2f', 'url': 'https://secure.gravatar.com/avatar/8aeeff7d40870308f9c2c5796cd026d0?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8aeeff7d40870308f9c2c5796cd026d0?s=96&d=mm&r=g', 'caption': 'Alan Boyle'}, 'description': 'Alan Boyle is an award-winning science writer and space reporter and GeekWire contributing editor. Formerly of NBCNews.com, he is the author of ""The Case for Pluto: How a Little Planet Made a Big Difference."" Follow him via CosmicLog.com, on Twitter @b0yle,\xa0on Facebook and on MeWe.', 'sameAs': ['https://cosmiclog.com/', 'https://www.facebook.com/alan.boyle', 'https://instagram.com/alanb0yle', 'https://www.linkedin.com/in/alan-boyle-97a874', 'https://x.com/b0yle', 'https://en.wikipedia.org/wiki/Alan_Boyle'], 'url': 'https://www.geekwire.com/author/alanboyle/'}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS90b3AtMjAtZnJlZS1kYXRhLXNjaWVuY2UtbWwtYW5kLWFpLW1vb2NzLW9uLXRoZS1pbnRlcm5ldC00MDM2YmQwYWFjMTLSAQA?oc=5,"Top 20 free Data Science, ML and AI MOOCs on the Internet - Towards Data Science",2020-02-14,Towards Data Science,https://towardsdatascience.com,"best free online courses in data science, machine learning, artificial intelligence in 2020",N/A,"Here is a list of the best online courses on Data Science, Machine Learning, Deep Learning, and Artificial Intelligence","Here is a list of the best online courses on Data Science, Machine Learning, Deep Learning, and Artificial Intelligence",http://schema.org,NewsArticle,https://towardsdatascience.com/top-20-free-data-science-ml-and-ai-moocs-on-the-internet-4036bd0aac12,['https://miro.medium.com/v2/da:true/resize:fit:1200/0*edVfyoCh_rxmJmkn'],"{'@type': 'Person', 'name': 'Benedict Neo', 'url': 'https://benedictxneo.medium.com'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}","Top 20 free Data Science, ML and AI MOOCs on the Internet.",2020-02-14T05:52:40.832Z,2021-12-13T11:55:12.781Z,,"Top 20 free Data Science, ML and AI MOOCs on the Internet.",False,,N/A,N/A,"Member-only storyData Science | Machine Learning | Artificial IntelligenceTop 20 free Data Science, ML and AI MOOCs on the Internet.Here is a list of the best free online courses on Data Science, Machine Learning, Deep Learning, and Artificial Intelligence.Benedict Neo·FollowPublished inTowards Data Science·13 min read·Feb 14, 20203K9ListenSharePhoto by Tianyi Ma on UnsplashFormal education in the 21st century has transformed into a choice instead of a mandatory step in life. With the internet boom and the rise of Massive Open Online Courses (MOOCs), one can opt for learning data science online and avoid the burden of student debt. Statistics show that eLearning enables students to learn 5x more material for every hour of training. The benefits of online learning are limitless — from the cost-cutting aspect to the flexible schedule and environment.The democratization of Data ScienceIt’s the year 2020, and data science is more democratized than ever. This means any individual can do data science with little to no expertise, as long as the proper tools and a substantial amount of data are provided. As data drenched every part of the industry, possessing the skills of data scientists will be imperative, as it engenders a workforce that speaks the language of data.",,,,,,,,,,,,,https://towardsdatascience.com/top-20-free-data-science-ml-and-ai-moocs-on-the-internet-4036bd0aac12,,,2020-02-14T05:52:40.832Z,4036bd0aac12,['Benedict Neo'],"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd2Fyb250aGVyb2Nrcy5jb20vMjAyMC8wMi90aGUtYXJteS1uZWVkcy1mdWxsLXN0YWNrLWRhdGEtc2NpZW50aXN0cy1hbmQtYW5hbHl0aWNzLXRyYW5zbGF0b3JzL9IBAA?oc=5,The Army Needs Full-Stack Data Scientists and Analytics Translators - War On The Rocks,2020-02-14,War On The Rocks,https://warontherocks.com,"This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric",N/A,"This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,N/A,"[{'@type': 'WebSite', '@id': 'https://warontherocks.com/#website', 'url': 'https://warontherocks.com/', 'name': 'War on the Rocks', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://warontherocks.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://warontherocks.com/2020/02/the-army-needs-full-stack-data-scientists-and-analytics-translators/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://warontherocks.com/wp-content/uploads/2020/02/erich.jpg', 'width': 1330, 'height': 850}, {'@type': 'WebPage', '@id': 'https://warontherocks.com/2020/02/the-army-needs-full-stack-data-scientists-and-analytics-translators/#webpage', 'url': 'https://warontherocks.com/2020/02/the-army-needs-full-stack-data-scientists-and-analytics-translators/', 'name': 'The Army Needs Full-Stack Data Scientists and Analytics Translators\xa0 - War on the Rocks', 'isPartOf': {'@id': 'https://warontherocks.com/#website'}, 'primaryImageOfPage': {'@id': 'https://warontherocks.com/2020/02/the-army-needs-full-stack-data-scientists-and-analytics-translators/#primaryimage'}, 'datePublished': '2020-02-14T08:55:48+00:00', 'dateModified': '2020-02-14T02:12:29+00:00', 'author': {'@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8'}, 'description': 'This article was submitted in response to the call for ideas issued by the co-chairs of the National Security Commission on Artificial Intelligence, Eric', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://warontherocks.com/2020/02/the-army-needs-full-stack-data-scientists-and-analytics-translators/']}]}, {'@type': ['Person'], '@id': 'https://warontherocks.com/#/schema/person/5fbc79c9cfff1efb418c5ac579f244e8', 'name': 'Shane Mason', 'image': {'@type': 'ImageObject', '@id': 'https://warontherocks.com/#personlogo', 'inLanguage': 'en-US', 'url': 'https://secure.gravatar.com/avatar/83a68cf34a391d145ac9f37117795a86?s=96&d=identicon&r=g', 'caption': 'Shane Mason'}}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3LmVkd2Vlay5vcmcvdGVjaG5vbG9neS9ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbWlnaHQtc2F2ZS10aW1lLzIwMjAvMDLSAQA?oc=5,How Artificial Intelligence Might Save Time - Education Week,2020-02-11,Education Week,https://www.edweek.org,"Teachers: Could you use an extra 13 hours in your work week, or for your personal life? That might be possible in the future, according to a report published last month by McKinsey &amp; Company.","Classroom Technology,Technology,Classroom Management,Artificial Intelligence,Teachers,Automation","Teachers: Could you use an extra 13 hours in your work week, or for your personal life? That might be possible in the future, according to a report published last month by McKinsey &amp; Company.","Teachers: Could you use an extra 13 hours in your work week, or for your personal life? That might be possible in the future, according to a report published last month by McKinsey &amp; Company.",http://schema.org,NewsArticle,https://www.edweek.org/technology/how-artificial-intelligence-might-save-time/2020/02,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/d9/66/d00a8941cac1daaa54265880b4ec/web-ai-soc-thumb-600x297-38342.jpg'}",Alyson Klein,"{'@type': 'Organization', 'name': 'Education Week', 'url': 'https://www.edweek.org', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/23/7a/33b323164fe78d35aa293a63f251/alyson-klein-jb.jpg'}}",How Artificial Intelligence Might Save Time,"February 11, 2020","January 12, 2021",,,,,"Technology, Classroom Technology",N/A,N/A,,News,"Classroom Technology,Technology,Classroom Management,Artificial Intelligence,Teachers,Automation",2020,https://www.edweek.org/technology/how-artificial-intelligence-might-save-time/2020/02#comments,en-US,true,,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Education Week', 'description': 'Alyson Klein is an assistant editor for Education Week.', 'email': 'aklein@educationweek.org', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/23/7a/33b323164fe78d35aa293a63f251/alyson-klein-jb.jpg'}, 'jobTitle': 'Assistant Editor', 'name': 'Alyson Klein', 'url': 'https://www.edweek.org/by/alyson-klein'}]","How Artificial Intelligence Might Save Time,How Artificial Intelligence Might Save Time,How Artificial Intelligence Might Save Time",https://www.edweek.org/about,https://epe.brightspotcdn.com/d9/66/d00a8941cac1daaa54265880b4ec/web-ai-soc-thumb-600x297-38342.jpg,"{'@type': 'WebPage', '@id': 'https://www.edweek.org/technology/how-artificial-intelligence-might-save-time/2020/02'}",P4M,828,,,,,13,"Education Week, Vol. 39, Issue 21"
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LmdlZWt3aXJlLmNvbS8yMDIwL2JpbGwtZ2F0ZXMtdGhpbmtzLWdlbmUtZWRpdGluZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1zYXZlLXdvcmxkL9IBAA?oc=5,Why Bill Gates thinks gene editing and artificial intelligence could save the world - GeekWire,2020-02-14,GeekWire,https://www.geekwire.com,"Microsoft co-founder Bill Gates has been working to improve the state of global health through his nonprofit foundation for 20 years, and today he told",N/A,"Microsoft co-founder Bill Gates has been working to improve the state of global health through his nonprofit foundation for 20 years, and today he told",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"


Why Bill Gates thinks gene editing and artificial intelligence could save the world
by Alan Boyle on February 14, 2020 at 6:20 pmFebruary 15, 2020 at 2:12 pm




 Share  7.3k
 Tweet
 Share
 Reddit
 Email




Subscribe to GeekWire Newsletters today!






 



Microsoft co-founder Bill Gates makes a point during a Q&A with Margaret Hamburg, board chair for the American Association for the Advancement of Science. (GeekWire Photo / Alan Boyle)
Microsoft co-founder Bill Gates has been working to improve the state of global health through his nonprofit foundation for 20 years, and today he told the nation’s premier scientific gathering that advances in artificial intelligence and gene editing could accelerate those improvements exponentially in the years ahead.
“We have an opportunity with the advance of tools like artificial intelligence and gene-based editing technologies to build this new generation of health solutions so that they are available to everyone on the planet. And I’m very excited about this,” Gates said in Seattle during a keynote address at the annual meeting of the American Association for the Advancement of Science.
Such tools promise to have a dramatic impact on several of the biggest challenges on the agenda for the Bill & Melinda Gates Foundation, created by the tech guru and his wife in 2000.
Also from Bill Gates: Coronavirus impact could be ‘very, very dramatic’
When it comes to fighting malaria and other mosquito-borne diseases, for example, CRISPR-Cas9 and other gene-editing tools are being used to change the insects’ genome to ensure that they can’t pass along the parasites that cause those diseases. The Gates Foundation is investing tens of millions of dollars in technologies to spread those genomic changes rapidly through mosquito populations.
Millions more are being spent to find new ways fighting sickle-cell disease and HIV in humans. Gates said techniques now in development could leapfrog beyond the current state of the art for immunological treatments, which require the costly extraction of cells for genetic engineering, followed by the re-infusion of those modified cells in hopes that they’ll take hold.
For sickle-cell disease, “the vision is to have in-vivo gene editing techniques, that you just do a single injection using vectors that target and edit these blood-forming cells which are down in the bone marrow, with very high efficiency and very few off-target edits,” Gates said. A similar in-vivo therapy could provide a “functional cure” for HIV patients, he said..
Bill Gates shows how the rise of computational power available for artificial intelligence is outpacing Moore’s Law. (GeekWire Photo / Todd Bishop)
The rapid rise of artificial intelligence gives Gates further cause for hope. He noted that that the computational power available for AI applications has been doubling every three and a half months on average, dramatically improving on the two-year doubling rate for chip density that’s described by Moore’s Law.
One project is using AI to look for links between maternal nutrition and infant birth weight. Other projects focus on measuring the balance of different types of microbes in the human gut, using high-throughput gene sequencing. The gut microbiome is thought to play a role in health issues ranging from digestive problems to autoimmune diseases to neurological conditions.
“This is an area that needed these sequencing tools and the high-scale data processing, including AI, to be able to find the patterns,” Gates said. “There’s just too much going on there if you had to do it, say, with paper and pencil to understand the 100 trillion organisms and the large amount of genetic material there. This is a fantastic application for the latest AI technology.”
Similarly, “organs on a chip” could accelerate the pace of biomedical research without putting human experimental subjects at risk.
“In simple terms, the technology allows in-vitro modeling of human organs in a way that mimics how they work in the human body,” Gates said. “There’s some degree of simplification. Most of these systems are single-organ systems. They don’t reproduce everything, but some of the key elements we do see there, including some of the disease states — for example, with the intestine, the liver, the kidney. It lets us understand drug kinetics and drug activity.”
Bill Gates explains how gene-drive technology can cause genetic changes to spread rapidly in mosquito populations. (GeekWire Photo / Todd Bishop)
The Gates Foundation has backed a number of organ-on-a-chip projects over the years, including one experiment that’s using lymph-node organoids to evaluate the safety and efficacy of vaccines. At least one organ-on-a-chip venture based in the Seattle area, Nortis, has gone commercial thanks in part to Gates’ support.
High-tech health research tends to come at a high cost, but Gates argues that these technologies will eventually drive down the cost of biomedical innovation.
He also argues that funding from governments and nonprofits will have to play a role in the world’s poorer countries, where those who need advanced medical technologies “essentially have no voice in the marketplace.”
“If the solution of the rich country doesn’t scale down … then there’s this awful thing where it might never happen,” Gates said during a Q&A with Margaret Hamburg, who chairs the AAAS board of directors.
But if the acceleration of medical technologies does manage to happen around the world, Gates insists that could have repercussions on the world’s other great challenges, including the growing inequality between rich and poor.
“Disease is not only a symptom of inequality,” he said, “but it’s a huge cause.”
Other tidbits from Gates’ talk:

When it comes to agriculture, climate change is making the challenges facing farmers in developing countries even more acute, Gates said. More extreme weather conditions could bring more floods, more droughts and more pests and plant diseases capable of wiping out crops. Gates pointed to efforts at CGIAR to develop more resilient strains of corn, rice and other crops, and at the University of Cambridge to build healthier soil. The Gates Foundation has set up an initiative called Gates Ag One to support such innovations.
Gates said he was concerned about two trends in the distribution of health information. “One is that titillating false information is more engaging than true information,” he said. The flap over the false linkage between vaccines and autism serves as an example of that, he said. “And then there’s this general notion of, hey, if the experts say something, are they somehow biased or naive?” he noted. “This is a fight. Will we go through a cycle where it’s not as acute as it is today? I don’t know. Right at the moment, it doesn’t feel that way.”
Gates said he subscribed to psychologist Steven Pinker’s view that the world is getting better. “Despite that there’s plenty to worry about … we shouldn’t lose sight of the fact that the progress has been absolutely phenomenal,” he said. “Many people are literally ahistorical to think that in a meaningful sense, 20 years ago or 40 years ago, life was better. That’s just not the case. Yes, there are huge problems, but if you’re a woman, if you’re gay, if you were subject to certain diseases, if you lived in developing countries, 40 years ago was dramatically worse than it is today.”

Read Gates’ prepared remarks in a posting to his Gates Notes blog, or watch the video on AAAS’ YouTube channel.


GeekWire contributing editor Alan Boyle is an award-winning science writer and veteran space reporter. Formerly of NBCNews.com, he is the author of ""The Case for Pluto: How a Little Planet Made a Big Difference."" Follow him via CosmicLog.com, on Twitter @b0yle, and on Facebook and MeWe. Reach him via email at alan@geekwire.com. 
 Share  7.3k
 Tweet
 Share
 Reddit
 Email




Previous StoryBill Gates warns that coronavirus impact could be ‘very, very dramatic,’ outlines long-term solutions 

Next StoryStripe closes Seattle office for two days as precaution after learning employee had contact with coronavirus patient 

 Filed Under: Science  Tagged With: AAAS • AI • Artifical intelligence • Bill & Melinda Gates Foundation • Bill and Melinda Gates Foundation • CRISPR • Gates Foundation • Gene editing








GeekWire Newsletters

Subscribe to GeekWire's free newsletters to catch every headline




Email address

Subscribe







GeekWire Daily - Top headlines daily
                                    




GeekWire Weekly - Most-read stories of the week, delivered Sunday
                                    




Breaking News Alerts - Important news as it happens
                                    




GeekWire Startups - News, analysis, insights from the Pacific Northwest startup ecosystem, delivered Friday
                                    




GeekWire Mid-week Update — Most-read stories so far this week, delivered Wednesday
                                    




GeekWire Local Deals — Special offers for Pacific Northwest area readers
                                    







Send Us a Tip
Have a scoop that you'd like GeekWire to cover? Let us know.

Send Us a Tip








","[{'@type': 'NewsArticle', '@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/#article', 'isPartOf': {'@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/'}, 'author': [{'@id': 'https://www.geekwire.com/#/schema/person/9641ab4b8b61dd1b5a6d0ebc6236d5ab'}], 'headline': 'Why Bill Gates thinks gene editing and artificial intelligence could save the world', 'datePublished': '2020-02-15T02:20:40+00:00', 'dateModified': '2020-02-15T22:12:31+00:00', 'mainEntityOfPage': {'@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/'}, 'wordCount': 1225, 'commentCount': 2, 'publisher': {'@id': 'https://www.geekwire.com/#organization'}, 'image': {'@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/#primaryimage'}, 'thumbnailUrl': 'https://cdn.geekwire.com/wp-content/uploads/2020/02/200214-gates1.jpg', 'keywords': ['AAAS', 'AI', 'Artifical intelligence', 'Bill &amp; Melinda Gates Foundation', 'Bill and Melinda Gates Foundation', 'CRISPR', 'Gates Foundation', 'Gene editing'], 'articleSection': ['Science'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/', 'url': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/', 'name': 'Why Bill Gates thinks gene editing and artificial intelligence could save the world &#8211; GeekWire', 'isPartOf': {'@id': 'https://www.geekwire.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/#primaryimage'}, 'image': {'@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/#primaryimage'}, 'thumbnailUrl': 'https://cdn.geekwire.com/wp-content/uploads/2020/02/200214-gates1.jpg', 'datePublished': '2020-02-15T02:20:40+00:00', 'dateModified': '2020-02-15T22:12:31+00:00', 'description': 'Microsoft co-founder Bill Gates has been working to improve the state of global health through his nonprofit foundation for 20 years, and today he told', 'breadcrumb': {'@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/#primaryimage', 'url': 'https://cdn.geekwire.com/wp-content/uploads/2020/02/200214-gates1.jpg', 'contentUrl': 'https://cdn.geekwire.com/wp-content/uploads/2020/02/200214-gates1.jpg', 'width': 2400, 'height': 1600, 'caption': 'Microsoft co-founder Bill Gates makes a point during a Q&A with Margaret Hamburg, board chair for the American Association for the Advancement of Science. (GeekWire Photo / Alan Boyle)'}, {'@type': 'BreadcrumbList', '@id': 'https://www.geekwire.com/2020/bill-gates-thinks-gene-editing-artificial-intelligence-save-world/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.geekwire.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Science', 'item': 'https://www.geekwire.com/science/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Why Bill Gates thinks gene editing and artificial intelligence could save the world'}]}, {'@type': 'WebSite', '@id': 'https://www.geekwire.com/#website', 'url': 'https://www.geekwire.com/', 'name': 'GeekWire', 'description': 'Breaking News in Technology &amp; Business', 'publisher': {'@id': 'https://www.geekwire.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.geekwire.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.geekwire.com/#organization', 'name': 'GeekWire', 'url': 'https://www.geekwire.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/#/schema/logo/image/', 'url': 'https://cdn.geekwire.com/wp-content/uploads/2017/10/GeekWire-Logo.png', 'contentUrl': 'https://cdn.geekwire.com/wp-content/uploads/2017/10/GeekWire-Logo.png', 'width': 400, 'height': 400, 'caption': 'GeekWire'}, 'image': {'@id': 'https://www.geekwire.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/geekwire', 'https://x.com/geekwire', 'https://www.instagram.com/geekwire/', 'https://www.youtube.com/geekwire', 'https://www.pinterest.com/geekwire/', 'https://en.wikipedia.org/wiki/GeekWire', 'https://www.linkedin.com/company/geekwire/']}, {'@type': 'Person', '@id': 'https://www.geekwire.com/#/schema/person/9641ab4b8b61dd1b5a6d0ebc6236d5ab', 'name': 'Alan Boyle', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.geekwire.com/#/schema/person/image/fe58e4d63645669100f65958faeb8f2f', 'url': 'https://secure.gravatar.com/avatar/8aeeff7d40870308f9c2c5796cd026d0?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8aeeff7d40870308f9c2c5796cd026d0?s=96&d=mm&r=g', 'caption': 'Alan Boyle'}, 'description': 'Alan Boyle is an award-winning science writer and space reporter and GeekWire contributing editor. Formerly of NBCNews.com, he is the author of ""The Case for Pluto: How a Little Planet Made a Big Difference."" Follow him via CosmicLog.com, on Twitter @b0yle,\xa0on Facebook and on MeWe.', 'sameAs': ['https://cosmiclog.com/', 'https://www.facebook.com/alan.boyle', 'https://instagram.com/alanb0yle', 'https://www.linkedin.com/in/alan-boyle-97a874', 'https://x.com/b0yle', 'https://en.wikipedia.org/wiki/Alan_Boyle'], 'url': 'https://www.geekwire.com/author/alanboyle/'}]",,,,,,,,,,,,,,,,,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,mainEntityOfPage,dateCreated,isPartOf,mentions,hasPart,address,diversityPolicy,email,legalName,leiCode,telephone,logo,brand,identifier,inLanguage,issn,potentialAction,@id,sameAs,alternativeHeadline,@graph,creator,comment,commentCount,copyrightHolder,sourceOrganization,copyrightYear,ethicsPolicy,masthead,foundingDate
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvam9lbWNrZW5kcmljay8yMDE4LzA4LzE0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXdpbGwtcmVwbGFjZS10YXNrcy1ub3Qtam9icy_SAQA?oc=5,"Artificial Intelligence Will Replace Tasks, Not Jobs - Forbes",2018-08-14,Forbes,https://www.forbes.com,"Executives should be helping to reduce jobs in which AI and machine learning take over boring tasks, while humans spend more time with higher-level tasks.",,"Executives should be helping to reduce jobs in which AI and machine learning take over boring tasks, while humans spend more time with higher-level tasks.","Executives should be helping to reduce jobs in which AI and machine learning take over boring tasks, while humans spend more time with higher-level tasks.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/joemckendrick/2018/08/14/artificial-intelligence-will-replace-tasks-not-jobs/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/joemckendrick/files/2016/08/Asimo-Honda-cropped-250x300.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Joe McKendrick', 'url': 'https://www.forbes.com/sites/joemckendrick/', 'description': 'I am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the 2023 AI Summit in New York, as well as the 2021 and 2022 Summits. I regularly contribute to Harvard Business Review on AI topics. My column on service orientation appears on CNET, covering topics shaping business and technology careers. I am also a co-author of the SOA Manifesto, which outlines the values and guiding principles of service orientation in business and IT. Much of my research work is in conjunction with Forbes Insights and Unisphere Research/ Information Today, Inc., covering topics such as artificial intelligence, cloud computing, digital transformation, and big data analytics. In a previous life, I served as communications and research manager of the Administrative Management Society (AMS), an international professional association dedicated to advancing knowledge within the IT and business management fields. I am a graduate of Temple University.', 'sameAs': ['https://www.twitter.com/joemckendrick', 'Joe McKendrick']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","Artificial Intelligence Will Replace Tasks, Not Jobs",2018-08-14T23:09:00-04:00,2018-08-20T12:12:48-04:00,Tech,"Artificial Intelligence Will Replace Tasks, Not Jobs",True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Tech,N/A,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryInnovationEnterprise TechArtificial Intelligence Will Replace Tasks, Not JobsJoe McKendrickSenior ContributorOpinions expressed by Forbes Contributors are their own.I track how technology innovations move markets and careersFollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itAug 14, 2018,11:09pm EDTUpdated Aug 20, 2018, 12:12pm EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinThere is no shortage of angst when it comes to the impact of AI on jobs. For example, a survey by Pew Research Internet finds Americans are roughly twice as likely to express worry (72%) than enthusiasm (33%) about a future in which robots and computers are capable of doing many jobs that are currently done by humans.








AI, at your service.
Photo: Honda 






However, at least one set of experts believes jobs will be shredded, but not eliminated. Instead of worrying about job losses, executives should be helping to reduce jobs in which AI and machine learning take over boring tasks, while humans spend more time with higher-level tasks.
That's the word from Erik Brynjolfsson and Daniel Rock, with MIT, and Tom Mitchell of Carnegie Mellon University, who points out that the impact of machine learning, the self-programming, self-adjusting core of AI, on jobs. is iffy. ""ML will affect very different parts of the workforce than earlier waves of automation,"" they state in a recent paper.  Instead, automation will occur on a task-by-task basis.
PROMOTED
""Tasks within jobs typically show considerable variability in 'suitability for machine learning' while few -- if any -- jobs can be fully automated using machine learning,"" they continue. ""Machine learning technology can transform many jobs in the economy, but full automation will be less significant than the re-engineering of processes and the reorganization of tasks.""
What jobs are most likely to see tasks handled by AI or machine learning? Oddly enough, funeral directors rank high on the automatable list. Here are the roles Brynjolfsson and his co-authors identify as top candidates for machine learning:

Concierges









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Mechanical drafters Morticians, undertakers, and funeral directors
Credit authorizers
Brokerage clerks

And the jobs least likely to be shredded by AI/machine learning:

Massage therapists
Animal scientists
Archaeologists
Public address system and other announcers
Plasterers and stucco masons

Brynjolfsson and his colleagues say we're having the wrong debate when it comes to AI: instead of pondering how jobs will be wiped out, people need to focus on ""the redesign of jobs and re-engineering of business processes."" While AI and machine learning will be everywhere, the suitability for machine learning of work tasks varies greatly.""  The high and low suitability-for-machine-learning  tasks within a job can be separated and re-bundled.""
Dr. Irving Wladawsky-Berger, former IBM mover and shaker and now one of the most informed observers of the digital economy, provided perspective on the Brynjolfsson report, noting that some of the job activities ""are more susceptible to automation, while others require judgment, social skills and other hard-to-automate human capabilities. But just because some of the activities in a job have been automated, does not imply that the whole job has disappeared."" To the contrary, he continues, ""automating parts of a job will often increase the productivity and quality of workers by complementing their skills with machines and computers, as well as enabling them to focus on those aspects of the job that most need their attention.""
Bracing for job shredding calls for rethinking the various tasks for which employees assume responsibilities. Brynjolfsson and his co-authors warn, however, that arbitrarily bundling machine-learning-enabled and non-ML tasks into a single job is counterproductive. ""Bundling suitability-for-machine-learning and non-SML tasks prevents specialization and locks up potential productivity gains.""
Ultimately, the key to success in this emerging environment is to be able to marshal and capitalize on AI capabilities to deliver more value and service to customers. Employees can play a vital role in identifying opportunities, training models and algorithms, and taking a leadership role in determining if the systems are delivering business value in an ethical way.
Jobs will be enriched and elevated by AI and machine learning, but the best jobs will be those created to employ AI that links customers to the services and products they need.
 Joe McKendrickFollowingFollowI am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LnBvbGl0aWNzaG9tZS5jb20vdGhlaG91c2UvYXJ0aWNsZS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1oZWFsdGhjYXJlLS13aGF0LWRvZXMtdGhlLW5ocy13b3JrZm9yY2UtdGhpbmvSAQA?oc=5,Artificial Intelligence in healthcare – what does the NHS workforce think? - PoliticsHome,2018-08-13,PoliticsHome,https://www.politicshome.com,N/A,N/A,A new survey of NHS staff reveals that while there remains a difference between the level of enthusiasm for AI between senior managers and oth...,"<p>A new survey of NHS staff reveals that while&nbsp;there remains a difference between the level of enthusiasm for AI between senior managers and other respondents of the survey, overall the majority view it as positive.</p>
",,,,,,,,,,,,,,N/A,N/A,"

Artificial Intelligence in healthcare – what does the NHS workforce think?



































                
                    Sophie-Rose Feary
                     | Dods Monitoring




3 min read13 August 2018


A new survey of NHS staff reveals that while there remains a difference between the level of enthusiasm for AI between senior managers and other respondents of the survey, overall the majority view it as positive.


Digital transformation has been the recent focal point in the discussion surrounding healthcare, and with AI at the forefront, continuously popping up as an example of ways the NHS could achieve its aims stated in the Five Year Forward View.
The tech focused Secretary of State for Health and Social Care, Matt Hancock, announced an investment of £400 million in tech transformation and supported AI as providing “huge opportunities to improve patient outcomes and to make life easier for staff.”  The Prime Minister herself has even spoken at length about AIs potential improve health provision in the UK.
However, AI not only provides opportunities to the NHS, it is also draws our attention to the areas where the NHS needs improving. The House of Lords Select Committee report ‘AI in the UK: Ready, willing and able?’ showed that obtaining applicable data from other organisations remains the most significant barrier to adoption of AI and could force the implantation to stand still whilst other changes are made.
This leave us with one question, what does the NHS workforce think?  

Related









Government Announces Compensation For Infected Blood Victims To Start This Year


                By Zoe Crowther


21 May




While the adoption of AI in aiding the NHS to deliver healthcare is a priority of the Department and its Secretary, a survey by Dods Research reveals the NHS workers attitudes to AI and how organisations use it.  

 





The survey had 1,019 respondents including 700 individuals working for NHS Trusts, 47 for clinical commissioning groups, and 31 from NHS England. In terms of roles, approaching 200 respondents were senior managers, heads of services, directors or chief executives and over 300 were clinicians.
The survey revealed a noticeable gap between those that see potential in AI and those that have plans to implement it within their organisations. Over 60% of respondents having no plans for using AI, as opposed to a mere 6% of respondents from each cohort that had been utilising it in their organisations.
Furthermore, it also showed that whilst senior managers were euthanistic about AI, clinicians remained more cautious, noting the issues that could accompany it such as the needs for additional safe guards.
Despite his much-acclaimed appreciation for technology, Hancock’ has acknowledged the gap that will need to be filled before AI can become the star “we will put in place the data standards and support the workforce to adopt change too.” Training will need to be offered to staff to understand the data generated, safe guards will need to be implemented and IT infrastructure will have to be up-to date to ensure the system is secure. 
AI has huge potential for healthcare, as can be seen in the responses to the survey, but progress is still needed to ensure that staff and organisations are using it correctly and to the best of its ability. AI will need to be a much needed helping hand to the NHS workforce, not another issue to add to the NHS’s list of improvements.
***To purchase the full AI in Healthcare report which includes lots of exclusive in-depth insight into public sector sentiment towards applications of machine learning, the type of suppliers that might be considered and the issues that need to be resolved for an AI project – please click here to visit the Dods Shop.***


Related









Government Announces Compensation For Infected Blood Victims To Start This Year


                By Zoe Crowther


21 May




PoliticsHome Newsletters
Get the inside track on what MPs and Peers are talking about. Sign up to The House's morning email for the latest insight and reaction from Parliamentarians, policy-makers and organisations. 

Read the most recent article written by Sophie-Rose Feary - A Diverted Vehicle for Change: the Northern Ireland Executive Bill



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LmJsb29tYmVyZy5jb20vdmlldy9hcnRpY2xlcy8yMDE4LTA4LTE2L3NtYXJ0LW1hY2hpbmVzLXdvbi10LWJlLXJlYWR5LXRvLWRvLWNvbXBsZXgtam9icy1hbnl0aW1lLXNvb27SAQA?oc=5,Smart Machines Won't Be Ready to Do Complex Jobs Anytime Soon - Bloomberg,2018-08-16,Bloomberg,https://www.bloomberg.com,"Some routine jobs might be at risk someday, but work requiring judgment seems safe.","Artificial Intelligence,Jobs,Artificial General Intelligence,ALPHABET INC-CL A,Startups,Economics,Autonomous Vehicle,APPLE INC,AMAZON.COM INC,Investing,view,economics,economics","Some routine jobs might be at risk someday, but work requiring judgment seems safe.","Some routine jobs might be at risk someday, but work requiring judgment seems safe.",http://schema.org,NewsMediaOrganization,https://www.bloomberg.com,"['https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i50qXQRO9oIo/v1/1200x800.jpg', 'https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i50qXQRO9oIo/v1/-1x-1.jpg', 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/social-default.cc6ae30e.jpg']","[{'@type': 'Person', 'name': 'Noah Smith'}]","{'@type': 'Organization', 'name': 'Bloomberg', 'url': 'https://www.bloomberg.com', 'logo': {'@type': 'ImageObject', 'url': 'https:/assets.bwbx.io/s3/lightsaber/_next/static/media/bloomberg-logo-amp.bae0aa0a.png', 'width': 262, 'height': 60}}",Smart Machines Won&apos;t Be Ready to Do Complex Jobs Anytime Soon,2018-08-16T14:00:14.507Z,2018-08-16T14:00:14.501Z,,Bloomberg,False,,N/A,N/A,"OpinionNoah Smith, ColumnistArtificial Intelligence Still Isn’t All That SmartSome routine jobs might be at risk someday, but work requiring judgment seems safe.August 16, 2018 at 10:00 AM EDTBy Noah SmithNoah Smith is a former Bloomberg Opinion columnist. He was an assistant professor of finance at Stony Brook University, and he blogs at Noahpinion.FacebookTwitterLinkedInEmailLinkGiftExpandCan we talk? (That’s probably a silly question.)Photographer: Beata Zawrzel/NurPhoto/Getty ImagesFacebookTwitterLinkedInEmailLinkGiftGift this articleBefore it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MOREFacebookTwitterLinkedInEmailLinkGiftBookmarkSaveLock This article is for subscribers only.In the business world, machine learning often goes by the annoying moniker of “artificial intelligence.” That science-fiction buzzword evokes visions of godlike sentient computers, when in fact, the product is much closer to a statistical regression. Machine learning is about using algorithms to predict things — whether a web-security image contains a cat, what a Google user wants to search for, or whether a self-driving car should brake to avoid a crash. No one yet knows how to give a single computer system the mental flexibility to reason and learn like a human being.But buzzwords or no, the field is hot. AI startups have been getting more and more funding in recent years:Before it’s here, it’s on the Bloomberg TerminalBloomberg Terminal LEARN MORE",https://www.bloomberg.com/view/articles/2018-08-16/smart-machines-won-t-be-ready-to-do-complex-jobs-anytime-soon,2018-08-16T14:00:14.507Z,"{'@type': ['CreativeWork', 'Product'], 'name': 'Bloomberg', 'productID': 'bloomberg.com:basic'}","[{'@type': 'CollectionPage', 'name': 'Opinion', 'url': 'https://www.bloomberg.com/opinion'}, {'@type': 'CollectionPage', 'name': 'Opinions on Technology &amp; Ideas', 'url': 'https://www.bloomberg.com/opinion-technology-and-ideas'}]","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}","{'@type': 'PostalAddress', 'addressCountry': 'USA', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10022', 'streetAddress': '731 Lexington Avenue'}",https://www.bloomberg.com/diversity-inclusion,inquiry1@bloomberg.net,Bloomberg Finance L.P.,5493001KJTIIGC8Y1R12,(212) 318-2000,https://www.bloomberg.com/logo-bloomberg.svg,"[{'@type': 'Brand', 'name': 'Bloomberg markets', 'url': 'https://www.bloomberg.com/markets'}, {'@type': 'Brand', 'name': 'Bloomberg technology', 'url': 'https://www.bloomberg.com/technology'}, {'@type': 'Brand', 'name': 'Bloomberg pursuits', 'url': 'https://www.bloomberg.com/pursuits'}, {'@type': 'Brand', 'name': 'Bloomberg politics', 'url': 'https://www.bloomberg.com/politics'}, {'@type': 'Brand', 'name': 'Bloomberg opinion', 'url': 'https://www.bloomberg.com/opinion', 'logo': 'https://www.bloomberg.com/logo-bloomberg_opinion.svg'}, {'@type': 'Brand', 'name': 'Bloomberg businessweek', 'url': 'https://www.bloomberg.com/businessweek', 'logo': 'https://www.bloomberg.com/logo-bloomberg_businessweek.svg'}, {'@type': 'Brand', 'name': 'Bloomberg green', 'url': 'https://www.bloomberg.com/green'}, {'@type': 'Brand', 'name': 'Bloomberg equality', 'url': 'https://www.bloomberg.com/equality'}, {'@type': 'Brand', 'name': 'Bloomberg citylab', 'url': 'https://www.bloomberg.com/citylab'}, {'@type': 'Brand', 'name': 'Bloomberg crypto', 'url': 'https://www.bloomberg.com/crypto'}, {'@type': 'Brand', 'name': 'Bloomberg industries', 'url': 'https://www.bloomberg.com/industries'}, {'@type': 'Brand', 'name': 'Bloomberg economics', 'url': 'https://www.bloomberg.com/economics'}, {'@type': 'Brand', 'name': 'Bloomberg ai', 'url': 'https://www.bloomberg.com/ai'}, {'@type': 'Brand', 'name': 'Bloomberg wealth', 'url': 'https://www.bloomberg.com/wealth'}]",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LmNocm9uaWNsZS5jb20vYXJ0aWNsZS9ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaXMtY2hhbmdpbmctdGVhY2hpbmcv0gEA?oc=5,How Artificial Intelligence Is Changing Teaching - The Chronicle of Higher Education,2018-08-12,The Chronicle of Higher Education,https://www.chronicle.com,"New technologies promise to make the classroom experience more interactive and personal, but they also raise concerns about ethics and privacy.","['Teaching & Learning', 'Technology', 'Innovation & Transformation']","New technologies promise to make the classroom experience more interactive and personal, but they also raise concerns about ethics and privacy.","New technologies promise to make the classroom experience more interactive and personal, but they also raise concerns about ethics and privacy.",http://schema.org,NewsArticle,,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://chronicle.brightspotcdn.com/43/07/1e1af6c8a06cfe3b9d91c4a33685/9c34ebaca21b003a02ea5e3e18414336.jpg'}","[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'The Chronicle of Higher Education', 'description': 'Beth McMurtrie is a senior writer for The Chronicle of Higher Education, where she focuses on the future of learning and technology’s influence on teaching. In addition to her reported stories, she is a co-author of the weekly Teaching newsletter about what works in and around the classroom. Email her at beth.mcmurtrie@chronicle.com and follow her on LinkedIn.', 'email': 'Beth.McMurtrie@chronicle.com', 'identifier': '0000016f-f6e1-d930-ab7f-f6f7cc390000', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://chronicle.brightspotcdn.com/64/fe/4a6f476c42cb81041c980fc5a9be/mcmurtrie-beth.JPG'}, 'jobTitle': 'Senior Writer', 'name': 'Beth McMurtrie', 'url': 'https://www.chronicle.com/author/beth-mcmurtrie'}]","{'@type': 'Organization', 'name': 'The Chronicle of Higher Education', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://chronicle.brightspotcdn.com/64/fe/4a6f476c42cb81041c980fc5a9be/mcmurtrie-beth.JPG'}}",How Artificial Intelligence Is Changing Teaching,2018-08-12T23:00:00Z,,News,,False,,News,N/A,"


                                        News
                                    




Twitter



LinkedIn



Show more sharing options




Share
Close extra sharing options



Twitter



LinkedIn


 
Facebook



Email



Copy Link URLCopied!


Print







        How Artificial Intelligence Is Changing Teaching
    


By 
Beth McMurtrie



        August 12, 2018
    













Nathan Lindstrom for The Chronicle


Two years ago, Craig Coates, an entomologist at Texas A&M University, was asked to take over a science course plagued by cheating. The previous instructor of the large lecture course, “Insects in Human Society,” had tried to stay one step ahead, but in the class, oriented around online quizzes and tests, students would quickly share new material as soon as it went up. “It became an arms race between pushing out more questions faster and cheating,” recalls Coates, an instructional associate professor who has taught on the campus for nearly 20 years. “It moved everything toward rote learning.”







Don’t have an account? Sign up now.
To continue reading for FREE, please sign up.
A free account provides you access to free articles each month, newsletters, job postings, salary data, and exclusive store discounts.




Sign Up First Name  Last Name  Email  Password Sign Up
Yes, please send me Academe Today, The Chronicle's daily flagship newsletter.



Yes, please send me Academe Today, The Chronicle's daily flagship newsletter. 
By creating a free account, you are agreeing to receive updates and special offers from The Chronicle and our selected partners. Unsubscribe links are provided in every email. View our user agreement and privacy policy. 




To continue reading for FREE, please sign in.
Already have an account?
Sign In

Subscribe today! Try unlimited digital access for as low as $9 a month.
     



Subscribe today! Try unlimited digital access for less than $10 month.
   













Nathan Lindstrom for The Chronicle


 Two years ago, Craig Coates, an entomologist at Texas A&M University, was asked to take over a science course plagued by cheating. The previous instructor of the large lecture course, “Insects in Human Society,” had tried to stay one step ahead, but in the class, oriented around online quizzes and tests, students would quickly share new material as soon as it went up. “It became an arms race between pushing out more questions faster and cheating,” recalls Coates, an instructional associate professor who has taught on the campus for nearly 20 years. “It moved everything toward rote learning.” He wanted to reorient the course toward writing and discussion, convinced that the method would not only reduce cheating but also be a more engaging way to learn. But with 500 students — 200 in person and 300 online — grading would be a challenge. He experimented with one assignment, and it took days for him and three teaching assistants to complete the grading. “It was obviously going to be impossible,” he said, to do it by hand. Peer review was an option, but he and his TAs needed help sorting, assigning, and evaluating submissions. That led him to try a tool that uses algorithms and analytics. The switch was a success: Students enjoyed writing about current research, including keeping an insect blog and debating topics in entomology. The response, Coates says, has been “overwhelmingly positive.” Artificial intelligence is showing up more frequently in college classrooms, particularly at big institutions that are seeking to make large courses more intimate and interactive. A professor at Georgia Tech developed virtual teaching assistants and tutors. Researchers at Carnegie Mellon University are creating conversational agents to promote online discussion. And on a growing number of campuses, professors are using adaptive courseware that adjusts lessons according to students’ understanding and deploying AI-driven tools, like the one Coates used, to promote writing and peer review.


ADVERTISEMENT





  As artificial intelligence enters our daily lives through smart speakers and chatbots, it’s no wonder that academics are exploring its potential in teaching. The technologies in these tools vary, of course. Some focus on sorting information to a help a professor organize and evaluate assignments. Others use automated text analysis to mine students’ writing and fashion relevant prompts. Adaptive courseware is built around the sequencing of lesson plans, selecting content based on regular assessments of what students know. Advanced tools are based on machine learning, a form of AI that learns from user behavior. And many forms of AI draw on research in learning science, cognitive psychology, data science, and computer science. This trend prompts serious questions. When you’ve got artificial intelligence handling work that is normally done by a human, how does that change the role of the professor? And what is the right balance of technology and teacher? Some, like Coates, feel that algorithm-driven technologies can be useful aids in large classes. They automate some of teaching’s routine tasks, so that professors can do what no machine can — challenge and inspire students to gain a deeper understanding of what they’re learning. These technologies, advocates argue, are simply tools in service of creative forms of teaching.


ADVERTISEMENT





 But skeptics worry that if education is increasingly reliant on artificial intelligence and automated responses, it will put technology in the driver’s seat and prompt formulaic approaches to learning. Some of the algorithms used in AI-driven tools are built on large data sets of student work, raising privacy and ethical questions. Turning to technology for solutions, critics say, may also short-circuit conversations about some of the structural challenges to effective teaching and learning. That avoidance of structural issues troubles people like Kevin Gannon, a history professor at Grand View University, in Des Moines, and head of the campus Center for Excellence in Teaching and Learning. “We see a particular problem, whether it’s retention rates for minoritized students or large class sizes and heavy grading loads,” he says, “and our first instinct is to find something new and hot to address the problem rather than focus on the classroom and faculty and students.” Perhaps nowhere are those tensions more apparent than with adaptive courseware, sometimes called intelligent tutoring systems. The programs have grown increasingly popular as an alternative to large classes that emphasize lecture and memorization. They have also given rise to the specter of the robot teacher. With adaptive courseware, students first encounter material outside of class, often through short video lessons and readings. They take quizzes that assess their understanding of the material and, depending on the results, the courseware either advances them to the next lesson or provides supplemental instruction on concepts they don’t yet grasp. Advocates say this lets students study at their own pace and frees up the instructor’s time in class to shore up students’ knowledge or help them apply what they have learned. Adaptive courseware has made the most inroads in introductory STEM courses, particularly math, in which it is easier to sequence content and test understanding of concepts than in, say, a literature class. Administrators at several large public universities, including the University of Central Florida and Georgia State University, have seen positive results with the use of adaptive courseware, which are often accompanied by a rethinking of classroom time, to emphasize active-learning techniques.


ADVERTISEMENT





 







Nathan Lindstrom for The ChronicleCraig Coates, an entomologist at Texas A&M, uses a peer-assessment tool called Peerceptiv to anonymize and distribute student work, allowing each writing assignment to be reviewed by several classmates. 


 Susan Holechek became a convert several years ago as Arizona State University began testing adaptive courseware in a number of introductory courses. The biology instructor teaches a class for nonmajors — who probably wouldn’t be there if they didn’t have to be. “It’s a very, very, very tough crowd,” she says. Holechek tried out a small class that used a combination of adaptive courseware and active learning, while also teaching her conventional 300-student lecture course. For a lesson on DNA, for example, her traditional lecture focused mainly on conveying information, she says. Students in the smaller, pilot section might read the textbook, watch a video, and then take a short quiz the night before class to see how well they understood the material. If they scored poorly on some part of the lesson plan, the courseware would then send them back to review that concept, with new examples or additional information to help them grasp it better. Using adaptive courseware enables Holechek to spend class time on exercises that encourage students to apply concepts that they encountered online. In one exercise, called “Who Kidnapped Sparky” (the university’s mascot), they work with DNA samples to understand their use in forensics. “It allows me to be more creative,” she says.


ADVERTISEMENT





 The adaptive courseware also helps her create opportunities for more points of contact — between her and her students, and her students with the material. A dashboard helps Holechek keep track of how well each student is doing on homework and quizzes, with a cumulative “mastery” rating attached to each. Every Sunday the instructor goes over the collective results from homework reviews to see which concepts her class struggled with. Then she builds a brief Monday-morning lecture around that material. The proportion of students earning a C or better in Holechek’s course rose from 76 to 94 percent in the pilot and has continued to remain strong now that she has switched entirely to adaptive learning. Other experiences with adaptive courseware have been more mixed. A recent study looking at results from across a range of colleges found little to no difference in course grades. This points to a larger challenge with education technology, ed-tech experts say: If instructors expect tech to fix classroom problems but don’t address underlying pedagogical issues, they are likely to see limited results. After stumbling through some early experiments with adaptive learning, Arizona State found that training instructors in active-learning strategies increased the impact of the adaptive courseware they used. The university has also redesigned classrooms to promote collaborative work and offers a starter kit to those new to active learning that includes sample exercises focused on problem solving and critical thinking. The connection between pedagogy and technology is often missing in the debate over AI-driven teaching tools, notes Barbara Means, executive director of learning-science research at Digital Promise Global, an independent nonprofit group that studies digital technologies in education. “We end up talking past each other because people tend to say, ‘Does it work?,’ "" she says. “And it really needs to be a more nuanced question.” In other words, what works for one kind of student in one kind of learning environment with a particular set of educational goals might not work for someone else.


ADVERTISEMENT





 Ryan S. Baker, an associate professor in the Graduate School of Education at the University of Pennsylvania, who does research in this field, goes so far as to call AI a “red herring” in these discussions. “Well-designed activities, on or offline, can promote critical thinking,” he says. AI tools to support these activities are simply “a secondary part of it.” One of the best ways to help students develop their critical-thinking skills is to get them to write. That can be accomplished by writing more — and more often — and reviewing their peers’ writing. This has been a particularly fertile area of exploration for AI in the classroom. Kathleen West tried to encourage her students write more frequently and more meaningfully in her online psychology classes at the University of North Carolina at Charlotte. But she was stymied by clunky technology and large class sizes. Sometimes she would post a discussion question in her learning-management system and no one would answer it. Other times the conversation got so unwieldy it became impossible for her to follow. West, who is a lecturer and academic adviser, began using an AI-driven tool called Packback to support online discussions. Each student is required to post a question relevant to the course once a week and then respond to two other students’ questions. Packback takes care of basic monitoring, like making sure the students are on topic and are asking open-ended questions that encourage discussion. It prompts students to supply answers that are backed up with sources and to write more in depth. And it uses an algorithm to give a ‘curiosity score’ to each post based on those and other measures. Because everyone can see all the scores, some instructors say students often try harder when writing subsequent posts.


ADVERTISEMENT





 West says the tool frees up her time to do more-engaged teaching. That might include joining an online discussion to press a student to elaborate on her ideas or show better evidence of her assertions. An additional benefit of doing more writing, she says, is that students’ writing and critical-thinking skills have improved overall. “Writing on exams has increased exponentially in quality because they’re practicing writing,” she says. “The quality is just night-and-day different.” The tool Coates uses, called Peerceptiv, works by evaluating the reviewer, not the writing itself, says Chris Schunn, a professor of psychology, learning sciences and policy, and intelligent systems at the University of Pittsburgh and the principal investigator behind the program. It helps instructors by anonymizing and distributing student work, allowing each writing assignment to be reviewed by several classmates. Then it monitors and graphs student feedback, including feedback on the reviewers. 







Robin WilliamsCheating had been a problem in “Insects in Human Society,” a large lecture course at Texas A&M. After Craig Coates took over, he integrated more discussion and writing, using an AI tool to help manage the increased flow of work. 


 If a student hands out high ratings to every classmate while others are writing more-nuanced evaluations, his rank as a reviewer will drop. If he gives feedback that other students say is helpful, his score rises. Essentially the AI is looking for outliers, common ground, and dissension in the reviews, Schunn says, then feeds that information back to the professor in the form of a dashboard. If a particular assignment seems to be generating a lot of conflicting peer reviews, that might signal to the instructor that the topic itself is confusing.


ADVERTISEMENT





 “It shifts you from randomly looking at everything,” he says, “to paying attention where work is problematic.” But writing is complicated; it can be resistant to standardized evaluation. Other researchers are using AI to better understand what kind of feedback improves writing and how it might vary by discipline. Valerie Ross, director of the Critical Writing Program at Penn, is working on a project, funded by the National Science Foundation, to build what she calls an “ecological model” in support of good writing. By that she means one not built on generic rules — which is often a criticism of writing tools — but specific to discipline, genre, and classroom environment. To do that, she and her collaborators at the Massachusetts Institute of Technology, the University of South Florida, Dartmouth College, and North Carolina State University are mining writing samples and peer reviews from about 10,0000 students as well as instructor feedback. They will use predictive modeling to identify what seem to be the most useful parts of the process and to answer some big questions: What are valid measures of writing development? Are there particular comments or feedback that lead to improved writing? “Good writing is so socially situated,” she says. “That’s part of the limitations of the AI-big data approach. All those rules are just tools for writers.” But even when it focuses more narrowly on evaluating writing in a specific discipline, artificial intelligence may still be of limited use. At the University of Michigan, concerns about the lack of writing in foundational STEM courses led faculty members to create an automated peer-review system in hopes of changing that dynamic. Created with support from the university and the NSF, the system, called M-Write, has been tested on 8,000 students to date. Similar to Peerceptiv, M-Write anonymizes, sorts, and assigns work by students so that they can review one another’s writing. An integral part of the system, says Anne Ruggles Gere, an English professor who helped create it, is the use of writing fellows. These trained undergraduates act as connectors between students and professor, stepping in, for example, when students get confused by a particular assignment. “They are really the human link that makes the whole system cohere and work well,” says Gere, who heads the university’s Sweetland Center for Writing.


ADVERTISEMENT





 M-Write researchers would like their system to be able to evaluate how well students understand the concepts they’re writing about, but that goal has proved to be elusive, says Ginger Shultz, an assistant professor of chemistry and co-creator of M-Write. She and her colleagues have figured out ways to tailor messages to students based on, say, whether they’ve made substantial revisions in their writing. But evaluating their conceptual learning through AI has proved far harder, in part because it is so specific to a discipline or even a particular course. To analyze short essay answers of a few sentences for conceptual learning, some software uses what’s called a “bag of words” model, in which the program searches to see whether certain types of words are in the text and how often they appear. A question about chemical equilibrium, Shultz says, might prompt answers that include the words “increasing,” “Le Chatelier’s Principle,” or “reactants.” But that approach doesn’t work for essays of one or two pages, which might cover several ideas. “We’ve been poking at this for two years,” she says, “but accuracy isn’t where we want it to be.” Gere, who is also president of the Modern Language Association, sees AI-driven teaching tools as part of a spectrum of technologies increasingly prevalent in higher education, like advising apps and predictive analytics. Because faculty members are becoming more familiar with how technology is being used on campus, she believes they are more willing to experiment with it in the classroom. “There’s a general awareness,” she says, “that this is, in many ways, going to be part of our lives as academics as we move forward.” Kevin Gannon, the Grand View history professor, isn’t sure that AI-driven teaching is a positive trend. He’s no Luddite: he uses technology in his teaching, runs flipped classrooms, and keeps a blog called The Tattooed Professor. But if colleges are dropping thousands of dollars on tech-driven solutions, he argues, that’s money they’re not spending on hiring more faculty members and teaching assistants. If decision makers believe that AI tutors are effective teachers, he asks, why should they increase salaries and budgets? “I worry that this will be the cost-efficient solution to tuition-dependent systems. And we grow further and further away from conversations about, Is this a public good or not, because we have Auto Teach English 101.”


ADVERTISEMENT





 He also worries that AI is creating an even deeper divide among the institutional haves and have-nots. No elite colleges, he says, will ever brag about using AI to automate teaching. Their gold standard will remain small class sizes and close contact with professors. Deborah Beck shares Gannon’s skepticism about the use of automation in the classroom. She teaches an introductory course in classical mythology at the University of Texas at Austin. Her class is large — about 200 students — but she gives weekly writing assignments and reads them all. She sees that as integral to her job. Modeling good writing, thoughtful interaction, and respectful disagreement is part of the teaching process, says Beck, an associate professor in the department of classics. “That’s really hard to outsource to AI.” She also believes that her students value her close attention to their work. They tell her the discussion boards were among the most valuable tools they used. In one assignment, she asks her students to analyze how the characters in a reading talk about the ethical issues surrounding the rape of Lucretia, a foundational story in Roman history. Then she shares with the class why she particularly liked one response, explaining how it was written in a lively manner, gave insights beyond what others had already written, and offered specific examples to support the writer’s argument. Beck wonders how automated writing prompts could be as specific, or work as well for students who may have come to college not really knowing how to study. “They need help in learning how to learn,” she says. “And that’s something we all need to think about. Especially in ed tech.”


ADVERTISEMENT





 As academics experiment with AI in the classroom, privacy experts say more attention needs to be paid to big-picture issues of ethics and efficacy. Technology alters teaching environments in critical ways, yet there is little public scrutiny of those changes, says Elana Zeide, a technology-law expert and fellow at the University of California at Los Angeles’ School of Law. “It’s being adopted without much thoughtfulness or much education of the people using the tools.” One factor is the reliance on algorithms and continuous data collection to make these tools work. Do professors really understand how those tools make their decisions? Probably not, Zeide says, since the algorithms are proprietary. Some tools also control content, determine how learning is measured, and define outcomes, which shifts pedagogical decision-making away from educators toward private, for-profit companies that sell these products, she says. “In contrast to the public and heated debates that accompany textbook choices,” she notes in a recent article, “schools often adopt education technologies ad hoc.” Figuring out which tools might be beneficial, and how they work, is the hard part, of course. Vendors use the language of learning science to describe the benefits of their tools, but their promotional materials can make it difficult to distinguish between broad claims and solid grounding in science and experimentation. Packback, for example, says it uses Bloom’s Taxonomy to prompt higher forms of thinking that shift students away from simple recall and toward analysis and evaluation. The company also claims to help awaken “fearless, relentless curiosity” by encouraging students to ask open-ended questions.


ADVERTISEMENT





 Experts say vendors should show the research that backs up their products and agree to test runs so that instructors can see how well their programs operate. The technologies should also be adaptable to a particular professor’s course design. “Vendors say we literally can’t tell you how the AI is making decisions on any given case, because the whole point is that it is learned and developed with a set of criteria we input at the start,” says Martin Kurzweil, director of the educational-transformation program at Ithaka S+R, a nonprofit group that studies and supports the use of technology in higher education. “I don’t totally buy that.” 







Deanna Dent, ASUNowSusan Holechek (standing), an instructor at Arizona State U., uses adaptive courseware in her introductory biology classes. It allows her to use class time on exercises that reinforce the concepts students are learning. 


 While the ‘intelligence” part of AI in teaching is still limited, experts envision a future in which the technology becomes broadly multifunctional. Artificial assistants could help design textbooks, deliver course content, develop quiz questions, evaluate the answers, monitor online discussions, adjust to students’ learning styles, and advise students on their path through college. Researchers are already making advances on these fronts.


ADVERTISEMENT





 Ryan Baker, of Penn, is one of many researchers studying ways to identify students’ habits and attitudes in hopes of developing courseware that can strengthen study skills through tailored messages and tips. Researchers at Pennsylvania State University are piloting a so-called distractor generator that creates the false answers needed to populate multiple-choice quizzes. They are also using AI and machine learning in a program called BBookX to help professors design textbooks. And at Carnegie Mellon, researchers are experimenting with a technology to promote better discussion among students online. Known as a conversational agent, it aims to spur deeper interactions among students by prompting them to react to classmates’ ideas. Robot tutors aren’t about to replicate the full array of teaching-and-learning behaviors that take place as a matter of course among people anytime soon. But artificial intelligence does raise a provocative question, one no doubt on the minds of educators worried about the decline in public higher-education funding: If administrators are willing to cut corners by paying low wages to adjuncts and giving them heavy courseloads, what’s to stop them from trimming their costs even further by offering students some adaptive courseware and a teaching assistant instead? Institutions inclined that way, says Baker, “are probably going to be willing to accept low-quality solutions.”


ADVERTISEMENT





 He and other educator-advocates say AI can be of real value to learning. Algorithms can reveal patterns of student behavior not immediately noticeable to a professor. Adaptive courseware can nudge students toward effective learning strategies. Tools that can outsource lower-level tasks are worthy of consideration. Just as long as the instructor remains in charge of the classroom. Beth McMurtrie writes about technology’s influence on teaching and the future of learning. Follow her on Twitter @bethmcmurtrie, or email her at beth.mcmurtrie@chronicle.com.



","{'@type': 'WebPage', '@id': 'https://www.chronicle.com/article/how-artificial-intelligence-is-changing-teaching/'}",,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.contentBody'}",,,,,,,,,0000016f-f7bb-d930-ab7f-f7bf601400f9,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vc2xvYW5yZXZpZXcubWl0LmVkdS9hcnRpY2xlL2hvdy1haS1jYW4tYW1wbGlmeS1odW1hbi1jb21wZXRlbmNpZXMv0gEA?oc=5,How AI Can Amplify Human Competencies - MIT Sloan Management Review,2018-08-15,MIT Sloan Management Review,https://sloanreview.mit.edu,"The future of AI looks much like the present, with machines helping humans to do their jobs better, not replacing them.",N/A,"The future of AI looks much like the present, with machines helping humans to do their jobs better, not replacing them.","The future of AI looks much like the present, with machines helping humans to do their jobs better, not replacing them.
",,,,,,,,,,,,,,N/A,N/A,"


Magazine Fall 2018 Issue Frontiers How AI Can Amplify Human Competencies
Advanced systems will continue to help people do their jobs better instead of replacing them.


Ken Goldberg, interviewed by Frieda Klotz

August 15, 2018

Reading Time: 7 min 





Topics


Data, AI, & Machine Learning


Managing Technology


AI & Machine Learning


Automation


Technology Implementation


Technology Innovation Strategy




Frontiers

            An MIT SMR initiative exploring how technology is reshaping the practice of management.        

              
           More in this series
                      




 subscribe-icon

Subscribe
 












Permissions and PDF
 










Share



 Twitter



Facebook







Linkedin










What to Read Next

 Will AI Help or Hurt Sustainability? Yes | Andrew Winston
 Don’t Sacrifice Employee Upskilling for Productivity
 How to Create Slides That Suit Your Superiors: 11 Tips | Nancy Duarte
 Nudge Users to Catch Generative AI Errors













Ken Goldberg, professor and department chair of industrial engineering and operations research at UC Berkeley

Though artificial intelligence systems are already becoming a part of daily life, recent debates about AI and the future of work have gained a sense of urgency. The late Stephen Hawking worried that humans “couldn’t compete, and would be superseded” by machines, while Tesla founder Elon Musk has suggested that competition in AI could lead to World War III. The Economist reported earlier this year that nearly half of the jobs in 32 developed countries surveyed by the Organisation for Economic Co-operation and Development (OECD) were vulnerable to automation, declaring, “a wave of automation anxiety has hit the West.”
Ken Goldberg, professor and department chair of industrial engineering and operations research at UC Berkeley, is pushing back on all of that. Instead of embracing the notion that robots will surpass humans and replace us in the workforce (a concept referred to as “singularity”), he argues for “multiplicity” — a hybrid view of how new technologies and people might work in partnership toward human goals. To an extent, he says, this is how AI is already starting to function.
MIT Sloan Management Review correspondent Frieda Klotz spoke with Goldberg about a future in which AI is a complement, not a threat, to workers. What follows is an edited and condensed version of their conversation.
MIT Sloan Management Review: What areas of robotic technology is your lab currently working on?
Goldberg: We’re developing robot software for tasks as wide-ranging as warehouse order fulfillment, home decluttering and robot-assisted surgery. What’s common to all the work we’re doing is the idea of algorithms and learning for robots, improving our ability to analyze data and examples and then use that to build control policies — or models — for how robots can move.
The area I’ve been working on for 35 years is robot grasping — how to reliably pick up objects. It’s easy for humans, but it’s a problem for robots. Basically, every robot is still a klutz, and that’s a big challenge if you want to develop one that will declutter a home or pack boxes in a warehouse.
Can you talk about your concept of multiplicity?
Goldberg: People keep saying we’re on the verge of a transition, the singularity, when computers will take over. 



Topics


Data, AI, & Machine Learning


Managing Technology


AI & Machine Learning


Automation


Technology Implementation


Technology Innovation Strategy




Frontiers

            An MIT SMR initiative exploring how technology is reshaping the practice of management.        

              
           More in this series
                      



About the Author
Frieda Klotz is a freelance journalist and correspondent for MIT Sloan Management Review. She tweets @friedaklotz.



Tags: 

Artificial Intelligence
Job Security
Robotics



Reprint #: 
60117




More Like This
         MIT SMR Connections | Strategic Shift: Skills-Powered Organizations in the Age of AI                Organizations Face Challenges in Timely Compliance With the EU AI Act                AI Hype and Skepticism: Economist Paul Romer                The Hazards of Putting Ethics on Autopilot     
 


Add a comment Cancel replyYou must sign in to post a comment.First time here? Sign up for a free account: Comment on articles and get access to many more articles. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3LnRoZWF0bGFudGljLmNvbS9oZWFsdGgvYXJjaGl2ZS8yMDE4LzA4L21hY2hpbmUtbGVhcm5pbmctZGVybWF0b2xvZ3ktc2tpbi1jb2xvci81Njc2MTkv0gEA?oc=5,AI-Driven Dermatology Could Leave Dark-Skinned Patients Behind - The Atlantic,2018-08-16,The Atlantic,https://www.theatlantic.com,Machine learning has the potential to save thousands of people from skin cancer each year—while putting others at greater risk.,"skin, darker skin tones, skin cancer, African Americans, machine-learning algorithms, New York City, racial disparities, United States, cancerous skin lesions, particular skin type, International Skin Imaging, people, data sets, Skin Cancer Foundation, nonexistent skin cancers—or, machine-learning software, diverse skin types, Adamson, York City–based dermatologist, potential racial disparities, black people, mortality rate, artificial intelligence, Rosalind Franklin University, white people, five-year survival rate, demographically complete data, trend—including artificial intelligence, accessible data sets, n’t wear sunscreen, convolutional neural networks, highest mortality rate, machine learning, demographic data gaps, efficient doctor visits, diverse study population, primarily fair-skinned populations, skin images, skin issues, Smith, Medical Center Göttingen, machine-learning algorithm, potential clinical consequences, equitable demographic participation, Allan C. Halpern, Adewole Adamson, light skin, Memorial Sloan Kettering, fair skin, highest survival rate",Machine learning has the potential to save thousands of people from skin cancer each year—while putting others at greater risk.,N/A,https://schema.org,NewsArticle,https://www.theatlantic.com/health/archive/2018/08/machine-learning-dermatology-skin-color/567619/,"[{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 720}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 405}, 'url': 'https://cdn.theatlantic.com/thumbor/dxmpo2ACwYcr2dgHkSHCFnLGsMQ=/0x317:5075x3172/720x405/media/img/mt/2018/08/GettyImages_160936345/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'url': 'https://cdn.theatlantic.com/thumbor/GIHucoWTul-rzfKYBD7twjdV_2w=/1333x2:4818x3487/1080x1080/media/img/mt/2018/08/GettyImages_160936345/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1200}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/QZrvzH-E09TIr5EH4hYaMnL__E4=/337x96:4733x3393/1200x900/media/img/mt/2018/08/GettyImages_160936345/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1600}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/CeQ0-5P1LV0pwvMycXToJtpiTLE=/0x317:5075x3172/1600x900/media/img/mt/2018/08/GettyImages_160936345/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 960}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/T9Xf7NFJoq4LbZ8ay4Zs6oCXUFQ=/0x317:5075x3172/960x540/media/img/mt/2018/08/GettyImages_160936345/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/y81tewA6QI2WFT4GL0lnoiOJ1CI=/1333x2:4818x3487/540x540/media/img/mt/2018/08/GettyImages_160936345/original.jpg'}]","[{'@type': 'Person', 'name': 'Angela Lashbrook', 'sameAs': 'https://www.theatlantic.com/author/angela-lashbrook/'}]",{'@id': 'https://www.theatlantic.com/#publisher'},AI-Driven Dermatology Could Leave Dark-Skinned Patients Behind,2018-08-16T18:27:00Z,2018-08-16T20:10:18Z,Health,The Atlantic,False,,Health,N/A,"HealthAI-Driven Dermatology Could Leave Dark-Skinned Patients BehindMachine learning has the potential to save thousands of people from skin cancer each year—while putting others at greater risk.By Angela LashbrookSteve Gschmeissner / GettyAugust 16, 2018ShareSave LaToya Smith was 29 years old when she died from skin cancer. The young doctor had gotten her degree in podiatry from Rosalind Franklin University, in Chicago, just four years prior, and had recently finished a medical mission in Eritrea. But a diagnosis of melanoma in 2010 meant she would work in private practice for only a year before her death.As a black woman, LaToya reflected a stark imbalance in skin-cancer statistics in America. While fair-skinned people are at the highest risk for contracting skin cancer, the mortality rate for African Americans is considerably higher: Their five-year survival rate is 73 percent, compared with 90 percent for white Americans, according to the American Academy of Dermatology.As the rates of melanoma for all Americans continue a 30-year climb, dermatologists have begun exploring new technologies to try to reverse this deadly trend—including artificial intelligence. There’s been a growing hope in the field that using machine-learning algorithms to diagnose skin cancers and other skin issues could make for more efficient doctor visits and increased, reliable diagnoses. The earliest results are promising—but also potentially dangerous for darker-skinned patients.To read this story, Sign in or start a subscription.CloseNever miss a story. Start your subscription.Uncompromising quality. Enduring impact. Your support ensures a bright future for independent journalism.Get StartedAlready have an account? Sign inAngela Lashbrook is a writer based in New York.","{'@type': 'WebPage', '@id': 'https://www.theatlantic.com/health/archive/2018/08/machine-learning-dermatology-skin-color/567619/'}",,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article-content-body'}",,,,,,,"{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'url': 'https://cdn.theatlantic.com/assets/media/files/atlantic-logo--224x224.png'}",,,en-US,1072-7825,"{'@type': 'SearchAction', 'target': 'https://www.theatlantic.com/search/?q={q}', 'query-input': 'required name=q'}",https://www.theatlantic.com/#publisher,"['https://www.facebook.com/TheAtlantic', 'https://twitter.com/theatlantic']",AI-Driven Dermatology Could Leave Dark-Skinned Patients Behind,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOmh0dHBzOi8vaHJtYXNpYS5jb20va2VlcGluZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1odW1hbi_SAQA?oc=5,Putting the human touch on artificial intelligence | HRM Asia - HRM Asia,2018-08-15,HRM Asia,https://hrmasia.com,,N/A,Helen Masters says now is great time for HR leaders to embrace transformation and the benefits it can deliver.,N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

Putting the human touch on artificial intelligence

        Helen Masters says now is great time for HR leaders to embrace transformation and the benefits it can deliver.    


        By: HRM Asia Newsroom | August 15, 2018
         • 3 min read    

Topics: Asia-Pacific | Features | Singapore   


 
 
Helen Masters is Senior Vice President and General Manager for software developer Infor in Asia-Pacific, where she is responsible for the development of the company’s market presence across Australia, New Zealand, Southeast Asia, South Korea, and Greater China.
With the advent of classification methodologies in machine learning and the development of big data analytics, artificial intelligence (AI) is set to transform HR functions significantly. The recently conducted annual Harvey Nash HR Survey found that 63% of HR leaders in the Asia-Pacific region expect automation and AI to impact their organisations over the next five years, while 26% report these technologies are already having an impact today.
The creation of individually-tailored learning and development plans generated by big data processes, and chatbots that are able to recruit applicants are just two examples in which AI has already started to impact HR and talent management.
 
Starting the conversation

Chatbots are already omnipresent in consumers’ lives, and now they are starting to appear in the workplace. Intelligent assistants are being used to simulate human interactions. HR leaders are now using chatbots to recruit job candidates and also respond to internal employee enquiries. Chatbots are usually the first line of contact, followed by the HR personnel for more complex enquiries and conversations.
In addition, chatbots can help in the screening process for recruitment by performing quick background checks, can help in on-boarding, training employees and with annual self-assessments.
 
Predicting employee performance

Machine learning is perhaps the most successful part of AI, at least from an industry point of view. Usage cases include when employers want to know which candidates are the most suitable for open positions, or when there is a group of employees that HR would like to evaluate in terms of likely attrition rates.  Predictive talent analytics and employee flight risk models will revolutionise how HR looks at workforce planning. However, human intervention will still be required at some points to work under a diverse set of scenarios.
 
Modern upskilling
Traditionally, coaching modules have been used by the HR profession to offer upskilling and career development for employees. AI can help successfully plan, organise, and coordinate these training programmes for staff members across all levels.

Digital classrooms are the most common solutions for these training programmes. AI can also help in determining the best timeframe for new courses so as to fit the preferences of all employees individually.
 
Employee engagement
Sentiment analysis techniques have been used to evaluate positive and negative emotions and biases in a wide range of digitally published materials, including tweets and blog posts. There has also been an increase in these techniques in the HR space to better evaluate emotions and engagement levels of employees in particular.

Some AI platforms are also designed to identify employees that may be heading for the exit. The platforms help track employee computer activity and then analyse the data to determine a baseline of regular use. Any significant deviation from the normal baseline will then be flagged to the employer.
In practice, sentiment analysis to measure employee engagement can be quite effective. But what is less talked about are the ways in which biased, or even blatantly incorrect results can be generated through traditional methods only. Therefore, HR management must be careful to establish a consensus on sentiment analysis that is fair and objective. In this way, AI tools clearly support this HR function.
 
A balanced approach

As technologies develop and more data becomes available, AI will continue to impact HR in new and vastly different ways. However, HR managers should take the time to fully understand the advantages and potential considerations to various approaches and build the right set of algorithms and data architecture before solely relying on technology solutions.
Because of the human factor, there is no aspect of HR that is purely black or white. HR managers will need to find the right balance between greater insights through data and AI and maintaining the human insights and judgments that are essential to an effective HR team.
 
HRM Asia is excited to announce the HR Tech Think Tank, a one-day event that will deep-dive into the latest HR Technologies that are enabling faster, better and cheaper solutions to HR practices and people operations.
Held in Singapore on October 19, the HR Tech Think Tank will feature eight technologist-led, interactive workshops on the latest applications for payroll, talent management, and much more.
Head to the HR Tech Think Tank website for more information and to register.
 















This story first appeared in the July-August 2018 edition of HRM Magazine Asia. Check out the rest of the issue here.













 
ShareTweetShare

 




 
",,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://hrmasia.com/keeping-artificial-intelligence-human/', 'url': 'https://hrmasia.com/keeping-artificial-intelligence-human/', 'name': 'Putting the human touch on artificial intelligence | HRM Asia', 'isPartOf': {'@id': 'https://hrmasia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://hrmasia.com/keeping-artificial-intelligence-human/#primaryimage'}, 'image': {'@id': 'https://hrmasia.com/keeping-artificial-intelligence-human/#primaryimage'}, 'thumbnailUrl': 'https://hrmasia.com/wp-content/uploads/2018/08/GettyImages-695671640_EDIT.jpg', 'datePublished': '2018-08-15T15:10:24+00:00', 'dateModified': '2018-09-21T06:26:34+00:00', 'author': {'@id': 'https://hrmasia.com/#/schema/person/b29372701a854890161e0ea362a6b0c6'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://hrmasia.com/keeping-artificial-intelligence-human/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrmasia.com/keeping-artificial-intelligence-human/#primaryimage', 'url': 'https://hrmasia.com/wp-content/uploads/2018/08/GettyImages-695671640_EDIT.jpg', 'contentUrl': 'https://hrmasia.com/wp-content/uploads/2018/08/GettyImages-695671640_EDIT.jpg', 'width': 1628, 'height': 1181}, {'@type': 'WebSite', '@id': 'https://hrmasia.com/#website', 'url': 'https://hrmasia.com/', 'name': 'HRM Asia', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://hrmasia.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://hrmasia.com/#/schema/person/b29372701a854890161e0ea362a6b0c6', 'name': 'HRM Asia Newsroom', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrmasia.com/#/schema/person/image/', 'url': 'https://hrmasia.com/wp-content/uploads/2018/09/HRM_Avatar2-120x120.jpg', 'contentUrl': 'https://hrmasia.com/wp-content/uploads/2018/09/HRM_Avatar2-120x120.jpg', 'caption': 'HRM Asia Newsroom'}, 'url': 'https://hrmasia.com/author/hrmasia/'}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vaHViLnBhY2t0cHViLmNvbS9pYm1zLWRlZXBsb2NrZXItdGhlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXBvd2VyZWQtc25lYWt5LW5ldy1icmVlZC1vZi1tYWx3YXJlL9IBbWh0dHBzOi8vaHViLnBhY2t0cHViLmNvbS9pYm1zLWRlZXBsb2NrZXItdGhlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXBvd2VyZWQtc25lYWt5LW5ldy1icmVlZC1vZi1tYWx3YXJlL2FtcC8?oc=5,IBM’s DeepLocker: The Artificial Intelligence powered sneaky new breed of Malware - Packt Hub,2018-08-13,Packt Hub,https://hub.packtpub.com,"IBM researchers have developed an AI powered, Ultra-Targeted and Evasive malware called ‘DeepLocker’ thus going a level up in the malware game",N/A,"IBM researchers have developed an AI powered, Ultra-Targeted and Evasive malware called ‘DeepLocker’ thus going a level up in the malware game",N/A,http://schema.org,BreadcrumbList,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://hub.packtpub.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://hub.packtpub.com/category/security/', 'name': 'Security'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://hub.packtpub.com/category/security/cybersecurity/', 'name': 'Cybersecurity'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@type': 'WebPage', '@id': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/', 'name': 'IBM’s DeepLocker: The Artificial Intelligence powered sneaky new breed of Malware'}}]",N/A,N/A,"

Home  Security  Cybersecurity  IBM’s DeepLocker: The Artificial Intelligence powered sneaky new breed of Malware


SecurityCybersecurityNews IBM’s DeepLocker: The Artificial Intelligence powered sneaky new breed of Malware

By Melisha Dsouza -   August 13, 2018 - 12:30 pm 5938 0 










3 min readIn the new found age of Artificial Intelligence, where everything and everyone uses Machine Learning concepts to make life easier, the dark side of the same is can be left unexplored. Cybersecurity is gaining a lot of attention these days.The most influential organizations have experienced a downfall because of undetected malware that have managed to evade even the most secure cyber defense mechanisms. The job just got easier for cyber criminals that exploit AI to empower them and launch attacks. Imagine combining AI with cyber attacks!
At last week’s Black Hat USA 2018 conference, IBM researchers presented their newly developed malware “DeepLocker” that is backed up by AI. Weaponized AI seems here to stay.
Read Also: Black Hat USA 2018 conference Highlights for cybersecurity professionals
All you need to know about DeepLocker
Simply put, DeepLocker is a new generation malware which can stealth under the radar and go undetected till its target is reached. It uses an Artificial Intelligence model to identify its target using indicators like facial recognition, geolocation and voice recognition. All of which is easily available on the web these days!
What’s interesting is that the malware can hide its malicious payload in carrier applications- like a video conferencing software, and go undetected by most antivirus and malware scanners until it reaches specific victims. 
Imagine sitting on your computer performing daily tasks. Considering that your profile pictures are available on the internet, your video camera can be manipulated to find a match to your online picture. Once the target (your face) is identified, the malicious payload can be unleashed thanks to your face which serves as a key to unlock the virus. 

This simple  “trigger condition” to unlock the attack is almost impossible to reverse engineer. The malicious payload will only be unlocked if the intended target is reached. It achieves this by using a deep neural network (DNN) AI model.
The simple logic of  “if this, then that” trigger condition used by DeepLocker is transformed into a deep convolutional network of the AI model.
 

DeepLocker – AI-Powered Concealment
  Source: SecurityIntelligence
 
The DeepLocker makes it really difficult for malware analysts to answer the 3 main questions- 

What target is the malware after-  Is it after people’s faces or some other visual clues? 
What specific instance of the target class is the valid trigger condition? 
And what is the ultimate goal of the attack payload?

Now that’s some commendable work done by the IBM researchers. IBM has always strived to make a mark in the field of innovation. DeepLocker comes as no surprise as IBM has the highest number of facial recognition patents granted in 2018.
BlackHat USA 2018 sneak preview
The main aim of the IBM Researchers- Marc Ph. Stoecklin, Jiyong Jang and Dhilung Kirat–  briefing the crowd in the BlackHat USA 2018 conference was,

To raise awareness that AI-powered threats like DeepLocker can be expected very soon
To demonstrate how attackers have the capability to build stealthy malware that can circumvent defenses commonly deployed today and
To provide insights into how to reduce risks and deploy adequate countermeasures.

To demonstrate the efficiency of DeepLocker’s capabilities, they designed and demonstrated a proof of concept. The WannaCry virus was camouflaged in a benign video conferencing application so that it remains undetected by antivirus engines and malware sandboxes. As a triggering condition, an individual was selected, and the AI was trained to launch the malware when certain conditions- including the facial recognition of the target- were met.
The experiment was, undoubtedly, a success.
The DeepLocker is just an experiment by IBM to show how open-source AI tools can be combined with straightforward evasion techniques to build a targeted, evasive and highly effective malware. As the world of cybersecurity is constantly evolving, security professionals will now have to up their game to combat hybrid malware attacks.
Found this article Interesting? Read the Security Intelligence blog to discover more.
Read Next
7 Black Hat USA 2018 conference cybersecurity training highlights
12 common malware types you should know
Social engineering attacks – things to watch out for while online

 

 


TAGSArtificial Intelligence NewsIBM NewsmalwareAI News 




Share
FacebookTwitterLinkedin

 Melisha Dsouza  


LEAVE A REPLY Cancel reply


Please enter your comment!


Please enter your name here



You have entered an incorrect email address!
Please enter your email address here




Save my name, email, and website in this browser for the next time I comment.
 

Δ 






Must Read in Security



 Malware Analysis 
Top 6 Cybersecurity Books from Packt to Accelerate Your Career

Expert Network -  June 28, 2021 - 2:06 pm 0 

With new technology threats, rising international tensions, and state-sponsored cyber-attacks, cybersecurity is more important than ever. In organizations worldwide, there is not only a dire need for cybersecurity... 






Win-KeX Version 2.0 from Kali Linux 
September 18, 2020 - 5:43 pm 







Kali Linux 2020.3 Release (ZSH, Win-Kex, HiDPI & Bluetooth Arsenal) from... 
August 18, 2020 - 6:19 pm 


  

InterviewsArtificial IntelligenceLearn Transformers for Natural Language Processing with Denis RothmanExpert Network - August 31, 2021 - 5:48 am0High PerformanceClean Coding in Python with Mariano AnayaExpert Network - July 27, 2021 - 9:17 am0Artificial IntelligenceBringing AI to the B2B world: Catching up with Sidetrade CTO Mark Sheldon [Interview]Packt Editorial Staff - February 24, 2020 - 11:54 am0InterviewsOn Adobe InDesign 2020, graphic designing industry direction and more: Iman Ahmed, an Adobe Certified Partner and Instructor [Interview]Savia Lobo - January 24, 2020 - 6:00 am0DevOpsIs DevOps experiencing an identity crisis? [Interview]Packt Editorial Staff - January 7, 2020 - 8:32 am0 




",,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://hub.packtpub.com/#organization', 'name': 'Packt', 'url': 'https://hub.packtpub.com/', 'sameAs': ['https://www.facebook.com/PacktPub', 'https://www.linkedin.com/company/packt-publishing/', 'https://www.youtube.com/channel/UC3VydBGBl132baPCLeDspMQ', 'https://twitter.com/PacktPublishing'], 'logo': {'@type': 'ImageObject', '@id': 'https://hub.packtpub.com/#logo', 'inLanguage': 'en-US', 'url': 'https://hub.packtpub.com/wp-content/uploads/2018/03/packt-retina-2.png', 'width': '368', 'height': '180', 'caption': 'Packt'}, 'image': {'@id': 'https://hub.packtpub.com/#logo'}}, {'@type': 'WebSite', '@id': 'https://hub.packtpub.com/#website', 'url': 'https://hub.packtpub.com/', 'name': 'Packt Hub', 'description': 'Tech News, Insights and Tutorials from Packt Publishing', 'publisher': {'@id': 'https://hub.packtpub.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://hub.packtpub.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://hub.packtpub.com/wp-content/uploads/2018/03/Cybercriminal.jpg', 'width': 1820, 'height': 1024, 'caption': 'NetSpectre attack exploits data from CPU memory'}, {'@type': 'WebPage', '@id': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/#webpage', 'url': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/', 'name': 'IBM’s DeepLocker: The Artificial Intelligence powered sneaky new breed of Malware | Packt Hub', 'isPartOf': {'@id': 'https://hub.packtpub.com/#website'}, 'primaryImageOfPage': {'@id': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/#primaryimage'}, 'datePublished': '2018-08-13T16:30:35+00:00', 'dateModified': '2018-09-20T09:16:50+00:00', 'description': 'IBM researchers have developed an AI powered, Ultra-Targeted and Evasive malware called ‘DeepLocker’ thus going a level up in the malware game', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/']}]}, {'@type': ['Article', 'NewsArticle'], '@id': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/#article', 'isPartOf': {'@id': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/#webpage'}, 'author': {'@id': 'https://hub.packtpub.com/#/schema/person/f46b2f696f35a0074704ac714a01570d'}, 'headline': 'IBM’s DeepLocker: The Artificial Intelligence powered sneaky new breed of Malware', 'datePublished': '2018-08-13T16:30:35+00:00', 'dateModified': '2018-09-20T09:16:50+00:00', 'mainEntityOfPage': {'@id': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/#webpage'}, 'commentCount': 0, 'publisher': {'@id': 'https://hub.packtpub.com/#organization'}, 'image': {'@id': 'https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/#primaryimage'}, 'keywords': 'Artificial Intelligence News,IBM News,malware,AI News', 'articleSection': 'Cybersecurity,Security,News', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://hub.packtpub.com/ibms-deeplocker-the-artificial-intelligence-powered-sneaky-new-breed-of-malware/#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://hub.packtpub.com/#organization'}}, {'@type': 'Person', '@id': 'https://hub.packtpub.com/#/schema/person/f46b2f696f35a0074704ac714a01570d', 'name': 'Melisha Dsouza', 'image': {'@type': 'ImageObject', '@id': 'https://hub.packtpub.com/#personlogo', 'inLanguage': 'en-US', 'url': 'https://hub.packtpub.com/wp-content/uploads/2018/08/avatar_user_272_1533559611-96x96.jpg', 'caption': 'Melisha Dsouza'}}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3Lm9wYi5vcmcvbmV3cy9hcnRpY2xlL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvbnNlcnZhdGlvbmlzdHMtcG9ydGxhbmQtd2lsZG1lLXdpbGRib29rL9IBcmh0dHBzOi8vd3d3Lm9wYi5vcmcvbmV3cy9hcnRpY2xlL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvbnNlcnZhdGlvbmlzdHMtcG9ydGxhbmQtd2lsZG1lLXdpbGRib29rLz9vdXRwdXRUeXBlPWFtcA?oc=5,How Conservationists Are Using AI And Big Data To Aid Wildlife - Oregon Public Broadcasting,2018-08-14,Oregon Public Broadcasting,https://www.opb.org,A Portland nonprofit is using artificial intelligence to help give the conservation movement a makeover.,Science & Environment | Environment | Animals | Flora And Fauna | Local | News | Technology,A Portland nonprofit is using artificial intelligence to help give the conservation movement a makeover.,A Portland nonprofit is using artificial intelligence to help give the conservation movement a makeover.,http://schema.org,NewsArticle,,"['https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/ETOQI5VAFJBFJELJAX63DU4TLI.jpg?auth=b268733919de7359ac29de45b513ca7031cccda4dc4c6711b18d0eb34030fa6f&width=1200&height=675&smart=true', 'https://opb-opb-prod.cdn.arcpublishing.com/resizer/v2/ETOQI5VAFJBFJELJAX63DU4TLI.jpg?auth=b268733919de7359ac29de45b513ca7031cccda4dc4c6711b18d0eb34030fa6f&width=1440&height=810&smart=true']","{'@type': 'Person', 'name': 'Joseph Winters'}","{'@type': 'Organization', 'name': 'OPB', 'logo': {'@type': 'ImageObject', 'url': 'https://www.opb.org/pf/resources/images/opb/opb-jsonld.png', 'width': 182, 'height': 60}}",How Conservationists Are Using AI And Big Data To Aid Wildlife,2018-08-14T18:30:00Z,2020-06-02T23:14:34.977Z,,,,,N/A,N/A,"In The NewsBiden remarks on Trump‘The Evergreen’Oregon’s roadsWillamette River trash woesPortland bike countPortland vehicle registrationsTree pestsscience environmentHow Conservationists Are Using AI And Big Data To Aid WildlifeBy Joseph Winters (OPB/EarthFix)Aug. 14, 2018 2:30 p.m.Give Jason Holmberg 10,000 zebra photos and he’ll find the specific individual zebra you’re looking for, no problem.""It could take two minutes,"" he said.THANKS TO OUR SPONSOR:Become a SponsorHolmberg won't personally sort through the photos — it's his software that will. Holmberg is executive director of the nonprofit Wild Me. The Portland-based organization has developed a digital tool called Wildbook that uses artificial intelligence and machine learning to expedite wildlife identification. In tandem with citizen science, Wildbook is able to condense years of human work — like photographing thousands of animals and identifying each by hand — into a matter of weeks.The Portland-based nonprofit Wild Me has developed a tool called Wildbook. It uses artificial intelligence to identify individuals in a species. It can analyze 10,000 photos of zebras to locate a particular individual in two minutes.Courtesy of Wild MeIn research and in daily life, AI is rapidly changing the way things work. With some savvy software engineering, computers can learn to carry out complex, tedious tasks — whether it's detecting cancer cells, operating driverless race cars or analyzing hockey plays. And as Wildbook shows, AI is giving conservation a makeover, too.""It blows human efforts out of the water,"" Holmberg said.For example, in 2016 researchers in Kenya organized a two-day event in which volunteers drove over prescribed regions of the country, taking pictures of all the zebras they could find. The team of over 350 scientists, government officials, park rangers and community members collected more than 40,000 photos in total.""It would be impossible for a research team to take all those photos, let alone analyze them,"" said professor Chuck Stewart, head of the Computer Science department at New York’s Rensselaer Polytechnic Institute.Instead, citizen scientists were enlisted for data collection and Wildbook’s AI algorithms helped researchers identify every zebra in just a few weeks. The Kenyan government even recognized the results of the study as the country’s official zebra census.For each photo submitted to the system, Wildbook scans the image for signs of wildlife, filtering out background data like trees and brush. Then another algorithm steps in to identify not only the animal’s species but its individual identity.""Rather than just 'this is a humpback whale,' it says 'this is Willy the humpback whale,'"" Stewart explained.A whale shark. Big data and AI allow scientists to rapidly comb through thousands of photos and identify individuals using the skin patterning behind the gills and any scars they might have.Photo by Simon J. Pierce. Image provided courtesy of Wild MeWildbook can do this because many animals have unique markings that distinguish them from other members of their species, “like a bar code,” explained Dan Rubenstein, professor of zoology and program director of environmental studies at Princeton.For zebras, it’s their stripes. With whales, it’s the curvature on the edge of their fins. Soon, researchers hope to identify elephants by the shape of their ears, which flicker before they charge, or even primates, which may be identifiable with facial recognition technology.As for the accuracy of these automated IDs? For some projects, ""it gets it right about 99 percent of the time,"" said Rubenstein, who tests the software in his field work on Kenyan zebra populations. He also provides ecology and biology guidance to the Wildbook team.The population data created with Wildbook’s help can be used for much more than a census. At Oregon State University’s Marine Mammal Institute, professor Scott Baker uses the software to understand humpback whale migrations in the North Pacific. Other researchers have used it to learn about risk mitigation behavior in giraffes.But most importantly, Wildbook is a tool for conservation. By encouraging citizen participation and with the speed of AI-driven data processing, Holmberg hopes to quicken the creation and evaluation of conservation strategies.Related: Can 'Moneyball' Fix How The West Manages Wildfire?THANKS TO OUR SPONSOR:Become a SponsorThe arrival of tools like Wildbook comes at time of growing concern for global biodiversity. In March, a United Nations panel released acollection of reportsfinding that plant and animal species in every part of the world were under severe threat. Bysome estimates, as many as 200 species are lost each year. Some have gone so far as to say that we are witnessing Earth’s most devastating extinction event since the end of the dinosaurs, 65 million years ago.Researchers are calling for a collaborative effort to protect biodiversity.“From accountants to IT developers and machine learning experts, all of these are desperately needed to elevate wildlife conservation to the 21st century,” said Wild Me software engineer Drew Blount.This includes citizen scientists, as well. For researchers and AI software developers, smartphone cameras represent data-collection game-changers. And a platform like Wildbook can make submitting data easy and accessible.Partnerships with tech giants can offer conservation-minded nonprofits the resources to grow beyond their limited means. The Rainforest Connection, for example, uses Google's Tensorflow technology to monitor the Amazon Rainforest, listening in for signs of illegal chainsaw activity.A similar opportunity materialized for Wildbook this June when Microsoft announced it would back the nonprofit as part of its AI for Earth program. By providing access to more expansive cloud computing and AI resources, the partnership will help make Wildbook more accessible to researchers and citizen scientists.""It’s gonna be huge,"" said Rubenstein.Before AI for Earth, images submitted to Wildbook had to bounce between imaging software and database software, from algorithm to algorithm, as part of the cataloging process. “That’s not an efficient way to digest hundreds of thousands of images,” Rubenstein explained.But Microsoft’s cloud capabilities will allow data to be compartmentalized. Instead of haphazard organization on isolated computers, data will be stored online.In addition to improving data management, the Wild Me team also plans to use AI for Earth’s support to give Wildbook a facelift. An improved user interface will keep users engaged and eager to continue submitting photos.In the future, Holmberg and his colleagues hope that AI and machine learning will continue to ease human researchers from the burden of tedious tasks. One example is the whale shark YouTube scanner, which scours the web for relevant videos of whale shark sightings.Every 24 hours the software finds videos titled or tagged “whale shark,” downloads them, reads the description, and uses machine learning to identify which individual whale shark (if any) appears in the video. The software can even use geolocation information to disregard videos shot in an aquarium and ask real YouTubers for more information by posting a comment.It sounds like the stuff of the future, but the technology is already being deployed. “It’s what we might call an informatics revolution,” said Baker. He and fellow researchers, conservationists, and citizen scientists are hopeful that by making data more accessible and interpretable, Wildbook can help solve — or at least mitigate — the biodiversity crisis.Correction: Aug. 16, 2018. An earlier version of this story misidentified the location of an Oregon State University professor's humpback whale research. The professor is studying humpback whales in the North Pacific.THANKS TO OUR SPONSOR:Become a SponsorTHANKS TO OUR SPONSOR:Become a SponsorOPB’s First Look newsletterSign up to get important news and culture from around the Northwest, delivered to your inbox six days a week.EmailPlease leave this field blankSign UpTags: Science & Environment, Environment, Animals, Flora And Fauna, Local, News, Technology","{'@type': 'WebPage', '@id': 'https://www.opb.org/news/article/artificial-intelligence-conservationists-portland-wildme-wildbook/'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vd3d3LnN0YXRuZXdzLmNvbS8yMDE4LzA4LzEzL2dvb2dsZS1kZWVwbWluZC1haS1kaWFnbm9zZXMtZXllLWRpc2Vhc2VzL9IBAA?oc=5,"Opening the 'black box,' Google DeepMind AI system diagnoses eye diseases and shows its work - STAT",2018-08-13,STAT,https://www.statnews.com,A Google DeepMind AI system can identify dozens of eye diseases and point out the portions of scans it relies upon to make diagnoses.,"Artificial intelligence,health tech,research,vision","Experts said the level of accuracy is impressive, but the bigger breakthrough is the DeepMind system’s solution to the so-called “black box” problem of artificial intelligence.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"




In the LabOpening the ‘black box,’ Google DeepMind AI system diagnoses eye diseases and shows its work 


 
By Casey Ross Aug. 13, 2018 
Reprints






















































Hyacinth Empinado/STAT














































In eye care, artificial intelligence systems have shown they can match the accuracy of doctors in diagnosing specific diseases. But a new system designed by Google DeepMind and British doctors goes a crucial step further: It can show users how it reached its conclusions.
A study published Monday in Nature Medicine reports that the DeepMind system can identify dozens of diseases and point out the portions of optical coherence tomography scans that it relies upon to make its diagnoses. That’s a crucial factor in validating the safety and efficacy of AI technologies being developed for use in diagnosing or recommending treatments for a broad range of diseases, from cancer to neurological and vision problems.advertisement

The paper states that the system made the right referral recommendation in more than 94 percent of cases based on a review of historic patient scans at Moorfields Eye Hospital in London and performed as good as, or better than, top eye specialists who examined the same scans. Experts said that level of accuracy is impressive on such an open-ended query. But the bigger breakthrough is the system’s solution to the so-called “black box” problem of artificial intelligence, which refers to the inability of such systems to explain their thinking.
The opacity of AI systems is an impediment to their adoption by health providers who want the ability to understand their rationale and training, and ensure recommendations are based on science instead of supposition. In cancer care, for example, IBM’s Watson for Oncology has faced criticism for a lack of clarity surrounding the system’s training and the basis of its treatment recommendations.
“Doctors and patients don’t want just a black box answer, they want to know why,” said Ramesh Raskar, an associate professor at the Massachusetts Institute of Technology who studies computational imaging. “There is a standard of care, and if the AI technique doesn’t follow that standard of care, people are going to be uncomfortable with it, even if it’s the smartest thing in the world.”advertisement






							Related:
						

							IBM’s Watson supercomputer recommended ‘unsafe and incorrect’ cancer treatments, internal documents show						




The new study, conducted by DeepMind researchers and British eye doctors, is the latest of many to describe an advancement in the use of artificial intelligence in medicine. Technology giants such as Apple, Amazon, IBM, and Microsoft are all developing products for use in health care. Drug makers are looking to use AI to speed up the development of new treatments, while hospitals are deploying it to improve the efficiency of scheduling and coordination of care, and also want to use it to help doctors diagnose diseases and recommend treatments more accurately and faster.
Startups and individual doctors are also developing AI-based systems; another paper in Nature Medicine on Monday describes a technology tested by researchers at the Icahn School of Medicine at Mount Sinai in New York that uses a deep neural network to identify evidence of acute neurological events such as strokes in CT scans, which could improve outcomes by speeding up diagnosis and treatment.
Much of the recent research and development in AI has focused on eye care, an area where the heavy use of scans — and a shortage of specialists in some regions — makes it ripe for such technology. In April, the Food and Drug Administration approved the first software that can diagnose diabetic retinopathy, a common eye disease that afflicts patients with diabetes. That product, called IDx-DR, can identify the disease without a clinician’s involvement.
In addition to its transparency, the system involved in the DeepMind Health study stands out because it is not focused on a single condition, but can identify 50 different eye diseases based on its review of imaging data. It analyzes three-dimensional scans, making it capable of processing more data than prior AI systems that relied on two-dimensional images. The study authors also demonstrated their system can achieve a high level of accuracy on multiple types of scanning machines with a limited amount of additional training.
The system employs a novel architecture that uses two neural networks — the first network translates raw ocular CT scans into a tissue map, and the second analyzes the map to identify symptoms of eye disease. A user can watch a video showing the portions of the scan it uses to reach its conclusions as well as the confidence levels it assigns to each possible diagnosis.





							STAT+:
						

							Exclusive analysis of biopharma, health policy, and the life sciences.						




While the performance of this system is promising, it is not going to be used any time soon in hospitals or eliminate the need for human specialists to review scans. The study authors said the system still needs years of refinement and testing, including a randomized controlled trial, before it could be used in clinical care. Even then, it would still require some degree of human oversight.
“The key thing is that we do prospective studies in multiple different locations before we actually let this loose on patients,” said Dr. Pearse Keane, an ophthalmologist at Moorfields Eye Hospital and a co-author of the study. “We all think this technology could be transformative, but we also acknowledge that it’s not magic and we have to apply the same level of rigor to it that we would apply to any intervention.”
The level of evidence needed to deploy AI-based diagnostic or treatment advisers remains a matter of debate and varies widely by the type of product and the company selling it.
The approach of DeepMind and Moorfields contrasts with that of IBM and its clinical partner, Memorial Sloan Kettering Cancer Center of New York. IBM has aggressively marketed and sold its Watson for Oncology system to hospitals across Asia without publishing prospective studies about its impact on the decision-making of doctors or outcomes of patients. It has done so despite criticism from its own oncologists about the lack of evidence and complaints from clients who have cited examples of biased and inaccurate recommendations.
While AI is still largely experimental in medicine, it offers huge potential for changing the delivery of care. Optical CT is one of the most common imaging procedures in the U.S, with more than 5.35 million scans performed on Medicare beneficiaries in 2014. In some areas, a shortage of specialists is making it more difficult to provide accurate diagnosis and timely care for patients facing vision loss.


“We all think this technology could be transformative, but we also acknowledge that it’s not magic and we have to apply the same level of rigor to it that we would apply to any intervention.”

Dr. Pearse Keane, ophthalmologist and study co-author




In the United Kingdom, the shortage of specialists is more severe than it is in the United States. More than 2 million people are living with sight loss in the U.K., a number that is expected to double by 2050, according to the study. That means some patients with serious conditions end up waiting many weeks, or even months, to get treated.
Keane referenced an experience with a patient who was facing a total loss of sight due to macular degeneration, the leading cause of vision loss. She sought an urgent medical appointment when she began experiencing problems with her remaining good eye, but had to wait six weeks to see a specialist.  “Clearly there are huge capacity issues that are faced all around the world,” Keane said. “If it was my mother or a family member of mine, I would want them seen within six days, not six weeks.”
The artificial intelligence system used in the study demonstrated potential for reducing the backlog through automation. In the study, it was tasked with diagnosing 50 different conditions and triaging patients using Moorfields’ referral system. Its accuracy was tested on historic optical CT scans of 997 patients whose scans and files were also examined by eight human experts.





Newsletters
Sign up for Morning Rounds
Your daily dose of news in health and medicine.




Please enter a valid email address.



Privacy Policy










On the most urgent referrals, the computer matched the accuracy of the two top retinal specialists and performed better than two other specialists and four optometrists. Across all cases, it had a slightly lower error rate (5.5 percent) than the top two human specialists (6.7 percent and 6.8 percent) when the human experts were limited to a review of the scan results. Several of the specialists nearly matched the computer’s performance when they were able to review patient notes and other supplemental materials, according to the study.
Dr. John Miller, an ophthalmologist at Massachusetts Eye and Ear hospital who was not involved in the study, said the biggest question facing the system in the study is who will be able to use it — primary care doctors, pharmacists, or specialists.
It could prove useful in all those settings, Miller said, noting that its use at the primary care level could be especially useful by streamlining the referral system to help patients get timely care. “If we can be confident in a system that can identify retinal-specific disease at an early stage, that can prompt an earlier appointment for the patient and potentially save sight,” he said.
Miller added that its use also might save time, money, and worry wasted on incorrect diagnosis — a situation that arises in 10 to 25 percent of the cases he sees at Massachusetts Eye and Ear. “I think it’s going to help us see more of the right types of patients, instead of screening some patients without the suggested disease,” he said. “I view it as augmenting my practice, not threatening it.”










































About the Author						
Reprints


 
Casey Ross

National Technology Correspondent
Casey Ross covers the use of artificial intelligence in medicine and its underlying questions of safety, fairness, and privacy.



				casey.ross@statnews.com			




				@caseymross			

 


Tags
Artificial intelligence
health tech
research
vision 




					STAT encourages you to share your voice. We welcome your commentary, criticism, and expertise on our subscriber-only platform, STAT+ Connect




To submit a correction request, please visit our Contact Us page.

",,,,,,,,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', '@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/#article', 'isPartOf': {'@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/'}, 'author': [{'@id': 'https://www.statnews.com/#/schema/person/fa8817cd12456b3ab3691230045efcd9'}], 'headline': 'Opening the ‘black box,’ Google DeepMind AI system diagnoses eye diseases and shows its work', 'datePublished': '2018-08-13T15:00:47+00:00', 'dateModified': '2023-07-25T01:44:40+00:00', 'mainEntityOfPage': {'@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/'}, 'wordCount': 1606, 'publisher': {'@id': 'https://www.statnews.com/#organization'}, 'image': {'@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/#primaryimage'}, 'thumbnailUrl': 'https://www.statnews.com/wp-content/uploads/2018/08/Eye-scan-still.jpg', 'keywords': ['Artificial intelligence', 'health tech', 'research', 'vision'], 'articleSection': ['Health', 'In the Lab'], 'inLanguage': 'en-US', 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://www.statnews.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/', 'url': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/', 'name': 'Google DeepMind AI system diagnoses eye diseases and shows its work | STAT', 'isPartOf': {'@id': 'https://www.statnews.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/#primaryimage'}, 'image': {'@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/#primaryimage'}, 'thumbnailUrl': 'https://www.statnews.com/wp-content/uploads/2018/08/Eye-scan-still.jpg', 'datePublished': '2018-08-13T15:00:47+00:00', 'dateModified': '2023-07-25T01:44:40+00:00', 'description': 'A Google DeepMind AI system can identify dozens of eye diseases and point out the portions of scans it relies upon to make diagnoses.', 'breadcrumb': {'@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/#primaryimage', 'url': 'https://www.statnews.com/wp-content/uploads/2018/08/Eye-scan-still.jpg', 'contentUrl': 'https://www.statnews.com/wp-content/uploads/2018/08/Eye-scan-still.jpg', 'width': 1920, 'height': 1080, 'caption': 'Still illo for corresponding video loop: 1kNoHdcs'}, {'@type': 'BreadcrumbList', '@id': 'https://www.statnews.com/2018/08/13/google-deepmind-ai-diagnoses-eye-diseases/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.statnews.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Opening the ‘black box,’ Google DeepMind AI system diagnoses eye diseases and shows its work'}]}, {'@type': 'WebSite', '@id': 'https://www.statnews.com/#website', 'url': 'https://www.statnews.com/', 'name': 'STAT', 'description': 'Reporting from the frontiers of health and medicine', 'publisher': {'@id': 'https://www.statnews.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.statnews.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.statnews.com/#organization', 'name': 'STAT', 'url': 'https://www.statnews.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.statnews.com/#/schema/logo/image/', 'url': 'https://www.statnews.com/wp-content/uploads/2016/06/Stat_Logo_150.png', 'contentUrl': 'https://www.statnews.com/wp-content/uploads/2016/06/Stat_Logo_150.png', 'width': 150, 'height': 41, 'caption': 'STAT'}, 'image': {'@id': 'https://www.statnews.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/statnews/', 'https://x.com/statnews', 'https://www.linkedin.com/company/stat-news/', 'https://www.youtube.com/channel/UC89FjSf9AT1O2qw6vxrrxDQ', 'https://www.instagram.com/statnews/']}, {'@type': 'Person', '@id': 'https://www.statnews.com/#/schema/person/fa8817cd12456b3ab3691230045efcd9', 'name': 'Casey Ross', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.statnews.com/#/schema/person/image/307b03a67b9f061111f23c65579d539d', 'url': 'https://www.statnews.com/wp-content/uploads/2021/02/casey-r-profile-1-96x96.png', 'contentUrl': 'https://www.statnews.com/wp-content/uploads/2021/02/casey-r-profile-1-96x96.png', 'caption': 'Casey Ross'}, 'description': ""Casey Ross is a national technology correspondent at STAT. His reporting examines the use of artificial intelligence in medicine and its underlying questions of safety, fairness, and privacy. Before joining STAT in 2016, he wrote for the Cleveland Plain Dealer and the Boston Globe, where he worked on the Spotlight Team in 2014 and was a finalist for the Pulitzer Prize. A Vermont native, he now lives in Ohio with his wife and three children. When he's not with them, he's in his cornfield, cultivating some of the sweetest bi-color in the Midwest."", 'sameAs': ['https://x.com/caseymross'], 'url': 'https://www.statnews.com/staff/casey-ross/'}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mb3ItYXJhYmljLWIyZGMzMTNmMzdmNdIBAA?oc=5,"Artificial Intelligence for Arabic | by Daniel Shapiro, PhD - Towards Data Science",2018-08-16,Towards Data Science,https://towardsdatascience.com,"Google’s DialogFlow has no Arabic support for building chatbots, and standard natural language machine learning frameworks such as spaCy do not contain Arabic support either. Microsoft’s Arabic…",N/A,"Google’s DialogFlow has no Arabic support for building chatbots, and standard natural language machine learning frameworks such as spaCy do…","Google’s DialogFlow has no Arabic support for building chatbots, and standard natural language machine learning frameworks such as spaCy do…",http://schema.org,NewsArticle,https://towardsdatascience.com/artificial-intelligence-for-arabic-b2dc313f37f5,['https://miro.medium.com/v2/resize:fit:1200/1*Wzicfd5pP9F7UvzP5NrAaQ.png'],"{'@type': 'Person', 'name': 'Daniel Shapiro, PhD', 'url': 'https://towardsdatascience.com/@lemaysolutions'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",Artificial Intelligence for Arabic - Towards Data Science,2018-08-16T17:10:45.746Z,2018-08-17T12:28:18.199Z,,Artificial Intelligence for Arabic - Towards Data Science,,,N/A,N/A,"Artificial Intelligence for ArabicDaniel Shapiro, PhD·FollowPublished inTowards Data Science·6 min read·Aug 16, 201866ListenShareGoogle’s DialogFlow has no Arabic support for building chatbots, and standard natural language machine learning frameworks such as spaCy do not contain Arabic support either. Microsoft’s Arabic Toolkit is being discontinued this month (July 2018). Moreover, until recently, even research models using gloVe and word2vec were not easy to obtain. That’s not very helpful. There is generally a lack of available off-the-shelf high quality models for interpreting the Arabic language with artificial intelligence.Google still offers excellent APIs to AI capabilities like neural machine translation, but not the vectors (the AI stuff) used to DO the translation. These language models are important when performing common non-translation text processing tasks such as sentiment analysis, spam filtering, plagiarism detection, and so much more. Moreover, these models are critical for automating enterprise tasks that require natural language understanding as part of a workflow, such as resume processing in Human Resources (HR), document clustering in governmental reports, and document prioritization in financial services. The need for Arabic AI models is quite strong.A very nice starting point for otaining an Arabic word embedding model is AraVec (2017), a model created by Abu Bakr Soliman and his colleagues at the Center for Informatics Science of Nile University, in Giza, Egypt. The following links lead to their article and the related code.bakrianoo/aravecaravec - AraVec is a pre-trained distributed word representation (word embedding) open source project which aims to…github.comAraVec: A set of Arabic Word Embedding Models for use in Arabic NLPAdvancements in neural networks have led to developments in fields like computer vision, speech recognition and natural…www.sciencedirect.comIn the past year or so, some articles on this topic have been published in high quality journals and conferences. Here are some of the most relevant ones:Word embeddings for Arabic sentiment analysis - IEEE Conference PublicationManual feature extraction is a challenging and time consuming task, especially in a Morphologically Rich Language (MRL)…ieeexplore.ieee.orgWord Embeddings and Convolutional Neural Network for Arabic Sentiment Classification - ACL…ACL materials are Copyright © 1963-2018 ACL; other materials are copyrighted by their respective copyright holders…aclanthology.infoThe surprisingly strong demand for AI solutions in the MENA region got us thinking about why there is this gap in the market. Our solution is to fill that gap. We established a joint venture called Stallion.ai to serve the MENA region with B2B artificial intelligence solutions for enterprise clients.Taking this problem head-on, we decided to design an Arabic word embedding model from scratch. We scraped Wikipedia pages and books from the public domain. That’s 14 GB of text. We have been augmenting this dataset with other large sources of text, to gain additional language context and versatility. Rather than delving into the technological details of the work we have been undertaking, consider the practical business reasons for wanting an AI system that understands Arabic text.One interesting project that highlights the need for more Arabic language support is the NOOR programming language.There is an old legal saying, “He who drafts, wins.” I could not track down the attribution and neither could the books who cite it. The idea of this old quote is that drawing up a contract gives the drafter the ability to set the terms of the contract, and they will do it in their own favor. Similarly, it is essential for a business operating in Arabic to apply AI techniques to their original documents, rather than machine translations of these documents. Operating on the borrowed context from another language simply does not work as well as employing a real embedding model built on text from the same language.In science fiction, and in the press, artificial intelligence is like a universal translator. Even in engineering systems like compilers (e.g. GCC), several high-level languages (e.g. Java, C, C++) can be compiled into one universal middle language (GIMPLE) before being emitted into assembly for one of several processor targets. The structure looks like this:How GCC understands (compiles) many language frontends into a single common representation and then emits code for a target architecture.Having a universal representation of language like GIMPLE is excellent because we can apply common useful optimizations to this intermediate (universal) representation of language. In effect, a universal language allows us to understand meaning rather than think about the idiosyncratic nature of just one language. Unfortunately, machine learning does not represent language like compilers do. Computer code is based on rigorous assumptions about formal language theory that we do not assume in natural language like contracts and text messages. Natural language is full of ambiguity. For example, synonyms are not the same across languages. Code, on the other hand, leaves basically no room for ambiguity. Worse yet, the ambiguity in Arabic is not the same as it is in English. This line of thinking tells us that dedicated per-language models will outperform borrowed across-language models that were not trained on the language we care about. However, the situation is even worse, as we will soon see.We just discussed reasons we want to understand Arabic specifically, rather than learning across languages. Now consider that within arabic text there are variations that we need to consider separately.Firstly, there are dialect issues and slang including emoji, but let’s skip over that, and go to the second issue: style heterogeneity. It is well established that different types of text logs contain different semantic information. For example, the corpus of all text from the newspaper Al Hayat does not give us enough information to understand the tweets by Nancy Ajram. Why? Because formal text and informal text are not the same thing. Machine learning works best when trained on text very similar to the text it will be evaluating.There is even a third problem of context. Word embedding models like Aravec are an excellent first step to support at least SOMETHING in Arabic. The next step must be to encode context-specific business terminology and phrases into these models. These are typically out-of-dictionary terms that the off-the-shelf models were not trained on, or existing words that mean something different. Sometimes these words are English or named entities used inside Arabic documents (e.g. “كابل RS232 إلى واجهة RJ45”). Within dictionary words often still need adjusting. For example, the word collision means accident on the road to a road engineer, but a database key problem to a database engineer. These contexts need to be used to adjust the AI solution, and ofen the words involved are not even in the AI model before this adjustment takes place. On a project by project basis these custom modifications are achieved using our word embedding augmentation technology.To summarize the problems we are addressing at Stallion.ai: Businesses that process Arabic language documents needs customized AI solutions that the market has ignored for far too long. We have seen new projects arise as others shut down. We have identified gaps in the market, including the following shortcomings in existing models: dialect support, understanding slang, understanding technical context and out-of-dictionary words, and understanding various kinds of text. We are exploring both industrial and academic opportunities to study and apply this technology.Are you looking for AI help in the MENA region? Say hi to evan@stallion.ai or reach me at daniel@stallion.ai-Danieldaniel@lemay.ai ← Say hi.Lemay.ai1(855)LEMAY-AIOther articles you may enjoy:Artificial Intelligence and Bad DataImage Datasets for Artificial IntelligenceArtificial Intelligence: Get your users to label your data",https://towardsdatascience.com/artificial-intelligence-for-arabic-b2dc313f37f5,2018-08-16T17:10:45.746Z,,,,,,,,,,,,b2dc313f37f5,,,,,,,,"['Daniel Shapiro, PhD']",,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vaGJyLm9yZy93ZWJpbmFyLzIwMTgvMDgvaHVtYW4tcGx1cy1tYWNoaW5lLXJlaW1hZ2luaW5nLXdvcmstaW4tdGhlLWFnZS1vZi1hadIBAA?oc=5,Human Plus Machine: Reimagining Work in the Age of AI - HBR.org Daily,2018-08-16,HBR.org Daily,https://hbr.org,"Featuring H. James Wilson, Managing Director of Information Technology and Business Research at Accenture, and co-author of Human + Machine: Reimagining Work in the Age of Artificial Intelligence",N/A,"Featuring H. James Wilson, Managing Director of Information Technology and Business Research at Accenture, and co-author of Human + Machine: Reimagining Work in the Age of Artificial Intelligence",N/A,https://schema.org,WebSite,https://hbr.org/,,,,,,,,,,,Technology and analytics,N/A,N/A,,,,,,,,,,,,,,,,,"{'@type': 'SearchAction', 'target': 'https://hbr.org/search?term={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vYmVjb21pbmdodW1hbi5haS9kZWVwLWxlYXJuaW5nLWFuLWVsaTUtaW50cm8tdG8tbmV1cmFsLW5ldHdvcmtzLWJhZjdiMDJjMWFlNdIBAA?oc=5,Deep Learning — An ELI5 Intro to Neural Networks - Becoming Human: Artificial Intelligence Magazine,2018-08-16,Becoming Human: Artificial Intelligence Magazine,https://becominghuman.ai,"In this blog post, you’ll learn about neural networks. There’s a lot of hype around artificial intelligence so I thought I’d write this post for individuals who are out of this domain or for those…",N/A,"In this blog post, you’ll learn about neural networks. There’s a lot of hype around artificial intelligence so I thought I’d write this…","In this blog post, you’ll learn about neural networks. There’s a lot of hype around artificial intelligence so I thought I’d write this…",http://schema.org,NewsArticle,https://becominghuman.ai/deep-learning-an-eli5-intro-to-neural-networks-baf7b02c1ae5,['https://miro.medium.com/v2/resize:fit:1200/1*2SWb6CmxzbPZijmevFbe-g.jpeg'],"{'@type': 'Person', 'name': 'Hammad Asad', 'url': 'https://becominghuman.ai/@asad_hammad'}","{'@type': 'Organization', 'name': 'Becoming Human: Artificial Intelligence Magazine', 'url': 'becominghuman.ai', 'logo': {'@type': 'ImageObject', 'width': 146, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:292/1*1fYpRTTpKQNa0zuEPe3itg.png'}}",Deep Learning — An ELI5 Intro to Neural Networks - Becoming Human: Artificial Intelligence Magazine,2018-08-16T11:05:56.297Z,2018-08-20T13:37:52.641Z,,Deep Learning — An ELI5 Intro to Neural Networks - Becoming Human: Artificial Intelligence Magazine,,,N/A,N/A,"Deep Learning — An ELI5 Intro to Neural NetworksHammad Asad·FollowPublished inBecoming Human: Artificial Intelligence Magazine·6 min read·Aug 16, 2018218ListenShareIn this blog post, you’ll learn about neural networks. There’s a lot of hype around artificial intelligence so I thought I’d write this post for individuals who are out of this domain or for those interested in knowing about deep learning.When I first started, I pictured this when people said neural networks:This analogy is accurate. A single neuron will take the output of several neurons in the form of nervous impulses and will decide to fire if it meets a certain threshold.I personally like to think of it as a system of connected water pipes with knobs. The knobs determine how much water will come out of the joined ends. If all the knobs are at the perfect setting, the optimal water will flow out of the system.Now let’s work with an example. Here’s a basic graph that models the acceptance at an university:We use the diagonal line to determine if we got accepted to the university or not. Imagine you got a grade of 4 and you had written 10 tests [coordinates (10,4)]. According to this graph, we’d still be accepted to the university since we’re on the green side. Awesome right?In reality, that would be a low score and would probably result in being declined from the university. This tells us that our line isn’t placed at the best spot or angle. Is a single line even a good option? Maybe, but we can do better here.What other shapes can we draw to perfectly separate our data?How about this?This wouldn’t really be accurate. Plus a circle isn’t a function (2 values of y map to a single x). How do we even optimize its size?Let’s try having two lines intersecting and maybe we can use some math to make them positioned in the best way (don’t worry about the math yet).Trending AI Articles:1. Machines Demonstrate Self-Awareness2. Visual Music & Machine Learning Workshop for Kids3. Part-of-Speech tagging tutorial with the Keras Deep Learning library4. AI & NLP WorkshopNow our data looks more separated. As a student, I can now check if I will be accepted. I can ask myself 3 questions when plotting myself onto this map.Is the point above the horizontal line?Is the point on the right side of the vertical line?Is the answer to question 1 AND 2 a YES?Here’s how it would visually look like:Now, if we look at each question independently, we can model it with a neural network like this:In the image above, you’ll see the AND operation at the end. An AND operation is something we use in the logic world to calculate if two values are both YES. It’ll output a YES only if all values coming in as an input are both a YES. If one or both values are a NO, the AND operation will output a NO.A simplified depiction of the image above is:Notice that we represented the AND operation as a graph.Now we’ve successfully represented our first neural network. There are 3 layers in our network:The input layer — our inputs TEST and GRADE.The hidden layer — our plotting on the graph.The output layer — where the AND operation does its job and outputs a YES or NO.Here’s a simple depiction of our network:This is the simplest version of a neural network. Each node is typically called a neuron or a perceptron. In deep learning, we can have several hidden layers.Here’s a slightly more complex network with 3 inputs (features) and 4 neurons in the hidden layer.Unfortunately, the data in the real world is multidimensional. In our example, we were working with 2 dimensions, the GRADE and TEST. What if we had a 100-dimension input and 4 hidden layers with 100 neurons in each layer? You can start to imagine that our network would start to look very complex.Isn’t it crazy how with a large dataset, a lot of computing power, and a large neural network, we can teach computers to drive cars, understand language and play games?Now things start to get a little more complex:How do you determine which input is more important than the others?How will the neural network pick up on that?In my next post, I’ll breakdown how to make these neural networks learn. These include concepts such as weights, gradient descent and backpropagation. There are also various families of neural networks such as the Convolutional Neural Network (CNN) or Recurrent Neural Networks (RNN). They can be used for computer vision and natural language processing, respectively. They can also be combined to do very crazy stuff! I will also be covering them in future posts :)If you’re curious, this is what part of a CNN and RNN architecture may look like:Convolutional Neural Network (CNN) architecture for Image RecognitionRecurrent Neural Network (RNN) Structure used for SequencesUse-Cases of Architectures & Areas to Hype you up:CNN: Detecting tumors in medical images with higher accuracy than a trained professional.RNN: Making a bot write new chapters of Game of Thrones.Generative Adversarial Network (GANs): Generating new Pokemon using an existing dataset of Pokemon.Deep Reinforcement Learning: Teaching a robot to do surgery or learning to drive from scratch.Autoencoders: Compression, De-noising, Dimensionality ReductionThanks for reading!References:All credits to picture of graphs and neural networks go to Udacity (https://www.udacity.com/)CNN Tesla architecture: http://cs231n.github.io/convolutional-networks/RNN architecture: http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/",https://becominghuman.ai/deep-learning-an-eli5-intro-to-neural-networks-baf7b02c1ae5,2018-08-16T11:05:56.297Z,,,,,,,,,,,,baf7b02c1ae5,,,,,,,,['Hammad Asad'],,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMDgvMTYvdGVjaG5vbG9neS9nb29nbGUtZW1wbG95ZWVzLXByb3Rlc3Qtc2VhcmNoLWNlbnNvcmVkLWNoaW5hLmh0bWzSAQA?oc=5,Google Employees Protest Secret Work on Censored Search Engine for China (Published 2018) - The New York Times,2018-08-16,The New York Times,https://www.nytimes.com,"About 1,400 of the internet company’s employees have signed a letter demanding transparency, saying censored search results raise “urgent moral and ethical issues.”",N/A,"About 1,400 of the internet company’s employees have signed a letter demanding transparency, saying censored search results raise “urgent moral and ethical issues.”","About 1,400 of the internet company’s employees have signed a letter demanding transparency, saying censored search results raise “urgent moral and ethical issues.”",https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/08/16/business/16DRAGONFLY/16DRAGONFLY-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2018/08/16/business/16DRAGONFLY/16DRAGONFLY-videoSixteenByNineJumbo1600.jpg', 'caption': 'Google employees have signed a letter protesting the company’s building of a censored search engine for China.', 'creditText': 'Aly Song/Reuters'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/08/16/business/16DRAGONFLY/16DRAGONFLY-superJumbo.jpg', 'height': 1264, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2018/08/16/business/16DRAGONFLY/16DRAGONFLY-superJumbo.jpg', 'caption': 'Google employees have signed a letter protesting the company’s building of a censored search engine for China.', 'creditText': 'Aly Song/Reuters'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/kate-conger', 'name': 'Kate Conger'}, {'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/daisuke-wakabayashi', 'name': 'Daisuke Wakabayashi'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",Google Employees Protest Secret Work on Censored Search Engine for China,2018-08-16T16:23:21.000Z,2018-08-17T02:36:36.000Z,,The New York Times,False,,Technology,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTGoogle Employees Protest Secret Work on Censored Search Engine for ChinaShare full article186Read in appGoogle employees have signed a letter protesting the company’s building of a censored search engine for China.Credit...Aly Song/ReutersBy Kate Conger and Daisuke WakabayashiAug. 16, 2018阅读简体中文版閱讀繁體中文版Hundreds of Google employees, upset at the company’s decision to secretly build a censored version of its search engine for China, have signed a letter demanding more transparency to understand the ethical consequences of their work.In the letter, which was obtained by The New York Times, employees wrote that the project and Google’s apparent willingness to abide by China’s censorship requirements “raise urgent moral and ethical issues.” They added, “Currently we do not have the information required to make ethically-informed decisions about our work, our projects, and our employment.”The letter is circulating on Google’s internal communication systems and is signed by about 1,400 employees, according to three people familiar with the document, who were not authorized to speak publicly.The internal activism presents another obstacle for Google’s potential return to China eight years after the company publicly withdrew from the country in protest of censorship and government hacking. China has the world’s largest internet audience but has frustrated American tech giants with content restrictions or outright blockages of services including Facebook and Instagram.AdvertisementSKIP ADVERTISEMENTIt is also the latest example of how Google’s outspoken work force has agitated for changes to strategy. In April, the internet company’s employees spoke out against its involvement in a Pentagon program that uses artificial intelligence to improve weaponry. By June, Google had said it would not renew a contract with the Pentagon for A.I. work.Google’s interest in bringing search back to China came to the forefront earlier this month, when reports surfaced that the company was working on a search app that restricts content banned by Beijing. The project, known internally as Dragonfly, was developed largely in secret, prompting outrage among employees who worried they had been unwittingly working on technology that would help China withhold information from its citizens.“We urgently need more transparency, a seat at the table, and a commitment to clear and open processes: Google employees need to know what we’re building,” the letter said.The letter also called on Google to allow employees to participate in ethical reviews of the company’s products, to appoint external representatives to ensure transparency and to publish an ethical assessment of controversial projects. The document referred to the situation as a code yellow, a process used in engineering to address critical problems that impact several teams.AdvertisementSKIP ADVERTISEMENTGoogle declined to comment on the letter. It has said in the past that it will not comment on Dragonfly or “speculation about future plans.”Late on Thursday, employees pressed Google’s chief executive, Sundar Pichai, and other management about Dragonfly at a weekly staff meeting. As of late Wednesday, one of the top questions on an internal software system called Dory, which lets employees vote for the queries that executives should answer at the meeting, asked whether Google had lost its ethical compass, said people who had reviewed the questions. Other questions on Dory asked directly about the Dragonfly project and specific information that may be censored by the Chinese government, such as air pollution data.“If we were to do our mission well, we are to think seriously about how to do more in China,” Mr. Pichai said in the staff meeting, audio of which was obtained by The Times. “That said, we are not close to launching a search product in China.”Mr. Pichai and Sergey Brin, a co-founder of Google, stopped answering questions about Dragonfly after seeing their answers posted on Twitter.ImageGoogle has maintained a significant presence in China even though its flagship services are not accessible in the country.Credit...Aly Song/ReutersThis week’s staff meeting was the first opportunity for Google’s work force to ask executives about Dragonfly, because the meeting was not held last week. The absence of a gathering — the result of a regularly scheduled break in the summer, according to a company spokesman, Rob Shilkin — led to fears among employees that leadership was becoming less transparent following several controversies over Google’s government work.AdvertisementSKIP ADVERTISEMENTGoogle has traditionally been more responsive to employee concerns and more transparent about future projects and inner workings than other major technology companies, inviting questions from workers at its staff meetings and encouraging internal debate.The internal dissent over Dragonfly comes on the heels of the employee protests over Google’s involvement in the Pentagon project to use artificial intelligence. After Google said it would not renew its contract with the Pentagon, it unveiled a series of ethical principles governing its use of A.I.

What you should know. The Times makes a careful decision any time it uses an anonymous source. The information the source supplies must be newsworthy and give readers genuine insight.Learn more about our process.In those principles, Google publicly committed to use A.I. only in “socially beneficial” ways that would not cause harm and promised to develop its capabilities in accordance with human rights law. Some employees have raised concerns that helping China suppress the free flow of information would violate these new principles.In 2010, Google said it had discovered that Chinese hackers had attacked the company’s corporate infrastructure in an attempt to access to the Gmail accounts of human rights activists. The attack, combined with government censorship, propelled Google to pull its search engine from the country.AdvertisementSKIP ADVERTISEMENTThe exit from China was a seminal moment for the company — a symbol of its uncompromising idealism captured by Google’s unofficial motto of “Don’t Be Evil.” At the time, Chinese internet users marked the loss of Google’s search engine by laying flowers at the company’s Beijing offices in what became known as an “illegal flower tribute.” A possible re-entry to China, according to current and former employees, is a sign of a more mature and pragmatic company.Letter From Google EmployeesHundreds of employees at the tech company urged their leadership to be more transparent about its ethics and its use of artificial intelligence.









    1 page, 0.04 MB
  

Google has maintained a significant presence in China even though its flagship services are not accessible in the country. Last year, Google announced plans for a research center in China focused on artificial intelligence. And it has introduced translation and file management apps for the Chinese market. Google now has more than 700 employees in China.Google’s work on Dragonfly is not a guarantee that its search engine will be welcomed back to China. The government would have to approve its return and it has kept American technology firms like Facebook at arm’s length, opting instead to work closely with homegrown internet behemoths.Some employees are in favor of re-entering China, arguing that exiting the country in protest of censorship has done little to pressure Beijing to change its position while it has made Google nonessential among the world’s largest base of internet users.AdvertisementSKIP ADVERTISEMENTWhen Google pulled out of China in 2010, Mr. Brin said it objected to the country’s “totalitarian” policies when it came to censorship, political speech and internet communications. If anything, China has only tightened its controls in the last eight years — leaving the company in a bind for how to justify its return.“You can never satisfy a censor, particularly the ones in China,” said Charles Mok, member of the Hong Kong Legislative Council who advocates and represents the information technology sector and who is affiliated with the territory’s democratic camp.Google is probably facing intense pressure to introduce more of its products in China, Mr. Mok said, but added that the company would lend legitimacy to government censorship if it debuted a censored search product in China.“Then the Chinese government can say, ‘Google is O.K. with it, too,’” he said. Follow Kate Conger and Daisuke Wakabayashi on Twitter: @kateconger and @daiwaka.A version of this article appears in print on Aug. 17, 2018, Section A, Page 1 of the New York edition with the headline: Google Workers Protest Secrecy In China Project. Order Reprints | Today’s Paper | SubscribeSee more on: Alphabet Inc.Read 186 CommentsShare full article186Read in appAdvertisementSKIP ADVERTISEMENTComments 186Google Employees Protest Secret Work on Censored Search Engine for ChinaSkip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Enjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",https://www.nytimes.com/2018/08/16/technology/google-employees-protest-search-censored-china.html,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",,https://www.nytco.com/company/diversity-and-inclusion/,,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",,,,,,https://www.nytimes.com/#publisher,https://en.wikipedia.org/wiki/The_New_York_Times,Google Workers Protest Secrecy In China Project,,,{'@id': '#commentsContainer'},186.0,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3Lml0d29ybGRjYW5hZGEuY29tL2FydGljbGUva2VlcGluZy1ldGhpY3MtaW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvNDA4MDkw0gFcaHR0cHM6Ly93d3cuaXR3b3JsZGNhbmFkYS5jb20vYXJ0aWNsZS9rZWVwaW5nLWV0aGljcy1pbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS80MDgwOTA_YW1wPTE?oc=5,Keeping ethics in artificial intelligence - IT World Canada,2018-08-16,IT World Canada,https://www.itworldcanada.com,"As artificial intelligence (AI) develops and its uses continue to grow, there’s still a discussion to be had around how to use AI in a trustworthy and ethical way. Businesses need to lead the process, creating an honest, global conversation about the benefits of AI not only for the industry but also governments and society",N/A,"As artificial intelligence (AI) develops and its uses continue to grow, there’s still a discussion to be had around how to use AI in a trustworthy and ethical way. Businesses need to lead the process, creating an honest, global conversation about the benefits of AI not only for the industry but also governments and society","As artificial intelligence (AI) develops and its uses continue to grow, there’s still a discussion to be had around how to use AI in a trustworthy and ethical way. Businesses need to lead the process, creating an honest, global conversation about the benefits of AI not only for the industry but also governments and society",https://schema.org,,,,,,,,,,,,,N/A,N/A,"









1116
0


Artificial IntelligenceDigital TransformationManaged Services & Outsourcing
Keeping ethics in artificial intelligence
 Meagan Simpson

August 16, 2018 





FacebookTwitterLinkedinReddItEmailPrint



As artificial intelligence (AI) develops and its uses continue to grow, there’s still a discussion to be had around how to use AI in a trustworthy and ethical way.
Businesses need to lead the process, creating an honest, global conversation about the benefits of AI not only for the industry but also governments and society at large, a Sage Group report on building a competitive yet ethical AI economy has concluded.
“The next challenge will be to move the global conversation away from AI as a threat, or replacement for humans, and towards encouraging businesses to approach AI as a complement to human ingenuity,” the report states.
According to the study that Sage conducted with a group of international business executives and U.K.-based government officials, the key is for industry leaders, businesses and C-suite executives to define ethical principles that will guide AI development.
This discussion comes at a time when the global AI market is hitting its stride, the International Data Corporation (IDC) reports industries are aggressively investing in AI and cognitive systems, and that worldwide spending on these systems will increase by 54 per cent from 2017, reaching $19.1 billion this year.
An example that brings to mind a robot future like that of I, Robot or the Terminator movies, is a report from the Fast Company about an AI-powered “psychopath” named Norman, which was created as an experiment to teach people how AI systems can be as good or bad as the people and the data sets that make them. Fast Company’s article states that “bias can be baked in very easily, and very unintentionally.”
Another example is the ProPublica investigation from 2016 that found the AI systems being used by U.S. judges to help predict the likelihood of criminals to re-offend were biased against African Americans.
Consumers will hold companies responsible for how AI is used and operated, states Sage, and that accountability will lie with C-suite executives; the key is to stay ahead and create ethical practices and tests that go beyond just the creation of technology but also continually evaluate risks and biases in AI machinery.
The British company’s report states that there is a need for businesses and governments to work together to help create a future where interactions with technology are positive and actually help people and improve work, all framed in an environment of understanding and trust. Implementing an ethical framework for your company is a great place to start, a way to create building blocks for the future of AI technology, it finds.
And the Canadian government is starting to recognize that need to address these issues and implement plans in order to keep up with the ever-changing world of AI.
The federal government, as IT World Canada has previously reported, has provided funding to groups such as the Vector Institute for Artificial Intelligence and the Alberta Machine Intelligence Institution in order to help develop a pan-Canadian AI strategy.
The chief intelligence officer (CIO) of the Government of Canada, Alex Benay, has also been a leader in the conversation around the need for ethical AI practices, and argues that the government is currently lacking much-needed regulation.
https://twitter.com/AlexBenay/status/983869169438416901
Benay is also the co-founder of the CIO Strategy Council, a not-for-profit that brings together public and private sector CIOs to discuss digital issues and help set industry standards. In a recent release the Council called itself an emerging leader “committed to spearheading the development of the first-ever globally-recognized standards for the ethical use of both AI and big data.”
The Sage report offers its own idea of what a framework for building ethical AI practices for business and governments would look like. It suggests creating a government framework, ensuring that AI is held accountable, building trust through transparency, and empowering the workforce.
Sage’s framework for ethical AI Source: Sage Group
When it comes to the economy and using these types of technology, the Sage report argues that achieving ethical AI is core to having successful business models and decision making, and that offering education both internally and to society as a whole is necessary. 
“People need to understand how AI works, why it provides the best solution in a given context and why they should welcome assistance from an AI powered platform,” states the report.
Scenarios like the U.S. courts and “Norman” AI that can damage the public’s trust of AI are exactly what parties like Sage, Benay, and CIO Strategy Council are trying to fight by promoting a proactive approach led by leaders in the industry, with support from governments.

TagsAIalex benayartificial intelligenceCIO Strategy Councildigital ethicsethicsSage Plc




Would you recommend this article?0 0 



Share
FacebookTwitterLinkedinReddItEmailPrint



Thanks for taking the time to let us know what you think of this article!
  We'd love to hear your opinion about this or any other story you read in our publication.
 Click this link to send me a note →
 
Jim Love, Chief Content Officer, IT World Canada
	  


Featured Download
Meagan SimpsonMeagan Simpson is a Jr. staff writer for IT World Canada. A graduate of Carleton University’s journalism program, she loves sports, travelling, reading and photography, and when not covering tech news she can be found cuddled up on the couch with her cat and a good book.


 



Previous articleLinkedIn creating new version of Groups featureNext articleHashtag Trending – More Intel processors risk cyber attacks; Walmart website drives sales; Amazon coming to a big screen near you

 


Featured Articles



 

Cybersecurity in 2024: Priorities and challenges for Canadian organizations 
By Derek Manky

As predictions for 2024 point to the continued expansion...

Read more







 

Survey shows generative AI is a top priority for Canadian corporate leaders.
Leaders are devoting significant budget to generative AI for 2024

Canadian corporate...

Read more






Related Tech News



 

AI presents an “extinction level threat” – US Gov’t Report: Hashtag Trending...


Jim Love -  March 12, 2024 







 

RingCentral drills down the opportunities for AI to revamp customer interactions


Ashee Pamma -  March 8, 2024 







 

Only 23 per cent of Canadians have a healthy relationship with work;...


Ashee Pamma -  March 6, 2024 






Tech Jobs

 


Subscribe to our NewsletterOur experienced team of journalists and bloggers bring you engaging in-depth interviews, videos and content targeted to IT professionals and line-of-business executives.



SUBSCRIBE



Tech Companies Hiring Right Now
  ",,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#article', 'name': 'Keeping ethics in artificial intelligence | IT World Canada News', 'headline': 'Keeping ethics in artificial intelligence', 'author': {'@id': 'https://www.itworldcanada.com/author/meagansimpson#author'}, 'publisher': {'@id': 'https://www.itworldcanada.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://i.itworldcanada.com/wp-content/uploads/2018/08/GettyImages-867341648-e1534456940396.jpg', 'width': 618, 'height': 249}, 'datePublished': '2018-08-16T18:11:10-04:00', 'dateModified': '2021-05-29T10:06:38-04:00', 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#webpage'}, 'isPartOf': {'@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#webpage'}, 'articleSection': 'Artificial Intelligence, Digital Transformation, Managed Services &amp; Outsourcing, AI, alex benay, artificial intelligence, CIO Strategy Council, digital ethics, ethics, Sage Plc'}, {'@type': 'BreadcrumbList', '@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://www.itworldcanada.com/#listItem', 'position': 1, 'name': 'Home', 'item': 'https://www.itworldcanada.com/', 'nextItem': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#listItem'}, {'@type': 'ListItem', '@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#listItem', 'position': 2, 'name': 'Keeping ethics in artificial intelligence', 'previousItem': 'https://www.itworldcanada.com/#listItem'}]}, {'@type': 'Organization', '@id': 'https://www.itworldcanada.com/#organization', 'name': 'IT World Canada', 'url': 'https://www.itworldcanada.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://i.itworldcanada.com/wp-content/uploads/2022/03/it-world-logo-300x33-1.png', '@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090/#organizationLogo'}, 'image': {'@id': 'https://www.itworldcanada.com/#organizationLogo'}, 'sameAs': ['https://www.facebook.com/ITWorldCa', 'https://twitter.com/intent/user?screen_name=itworldca', 'https://www.youtube.com/channel/UCvlbuIiCz691utVrZYbYhIA', 'https://www.linkedin.com/company/itworldcanada/']}, {'@type': 'Person', '@id': 'https://www.itworldcanada.com/author/meagansimpson#author', 'url': 'https://www.itworldcanada.com/author/meagansimpson', 'name': 'Meagan Simpson', 'image': {'@type': 'ImageObject', '@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#authorImage', 'url': 'https://www.itworldcanada.com/wp-content/uploads/2022/08/cropped-4123.jpg', 'width': 96, 'height': 96, 'caption': 'Meagan Simpson'}}, {'@type': 'WebPage', '@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#webpage', 'url': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090', 'name': 'Keeping ethics in artificial intelligence | IT World Canada News', 'description': 'As artificial intelligence (AI) develops and its uses continue to grow, there’s still a discussion to be had around how to use AI in a trustworthy and ethical way. Businesses need to lead the process, creating an honest, global conversation about the benefits of AI not only for the industry but also governments and society', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://www.itworldcanada.com/#website'}, 'breadcrumb': {'@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#breadcrumblist'}, 'author': {'@id': 'https://www.itworldcanada.com/author/meagansimpson#author'}, 'creator': {'@id': 'https://www.itworldcanada.com/author/meagansimpson#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://i.itworldcanada.com/wp-content/uploads/2018/08/GettyImages-867341648-e1534456940396.jpg', '@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090/#mainImage', 'width': 618, 'height': 249}, 'primaryImageOfPage': {'@id': 'https://www.itworldcanada.com/article/keeping-ethics-in-artificial-intelligence/408090#mainImage'}, 'datePublished': '2018-08-16T18:11:10-04:00', 'dateModified': '2021-05-29T10:06:38-04:00'}, {'@type': 'WebSite', '@id': 'https://www.itworldcanada.com/#website', 'url': 'https://www.itworldcanada.com/', 'name': 'IT World Canada', 'description': 'Information Technology news on products, services and issues for CIOs, IT managers and network admins', 'inLanguage': 'en-US', 'publisher': {'@id': 'https://www.itworldcanada.com/#organization'}}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vcm9sbGNhbGwuY29tLzIwMTgvMDgvMTYvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbWF5LWhlbHAtbWF0Y2gtdmV0ZXJhbnMtd2l0aC1jaXZpbGlhbi1qb2JzL9IBAA?oc=5,Artificial Intelligence May Help Match Veterans with Civilian Jobs - Roll Call,2018-08-16,Roll Call,https://rollcall.com,N/A,N/A,"One of the problems military veterans have long faced is matching their skills learned in the armed forces to the needs of civilian employers, an issue Congress continues to grapple with in the fiscal 2019 spending bills. Many military jobs translate perfectly into the civilian sector — repairing an Abrams tank is much like repairing […]",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"




        Politics
      




        Artificial Intelligence May Help Match Veterans with Civilian Jobs
      


        Software translates military job codes into relevant info for civilian employers
  




Artificial intelligence could help veterans find jobs in the civilian sector that make the most of their military training. (Spencer Platt/Getty Images file photo)  








By
Charlene Zhang

Posted August 16, 2018 at 10:31am






Facebook







Twitter







Email







Reddit






One of the problems military veterans have long faced is matching their skills learned in the armed forces to the needs of civilian employers, an issue Congress continues to grapple with in the fiscal 2019 spending bills.Many military jobs translate perfectly into the civilian sector — repairing an Abrams tank is much like repairing any heavy piece of machinery, for example — but many combat and leadership skills do not, on the surface, directly transfer.The Department of Veterans Affairs’ Vocational Rehabilitation and Employment Program is at the forefront of helping veterans find the right job after military service. The program’s counselors help assess capabilities of veterans and help men and women veterans find the right job.But the VR&E program, as it is known, is often short of counselors and funding. Federal law requires that there be one counselor for every 125 veterans seeking full-time work. But the program never quite reaches that ratio.VR&E would have to have added 266 new full-time counselors to meet that requirement, but the Veterans Benefits Administration only added 61 full-time workers for 2018, and slashed the budget for estimated overtime for counselors from nearly a million dollars to $500,000 through 2019, leaving more veterans unassisted, according to the American Legion.But now a startup company that uses artificial intelligence may be able to make up some of this gap in matching veterans to the right civilian jobs.SkillMil, a San Francisco-based startup, was founded by a former Navy submarine commander, Noel Gonzalez in 2016, during his time at the Stanford Research Institute. Gonzalez’s company has designed software, driven by artificial intelligence algorithms, that translates the byzantine array of military job codes into an assessment relevant to civilian employers.And then SkillMil seeks to link veterans to civilian jobs that will fit their skills.The software is still in the stage of testing and fixing bugs, but SkillMil has already retained six companies with more than 2500 veterans waiting for help, Gonzalez said.Last year, using SkillMil’s beta version of the software, the company matched 40 percent of a test group to jobs, with an 80 percent satisfaction rate, and lower job turnover than usual, Gonzalez said.Normally, during the first 18 months after veterans leave the military, they have high job turnover and go through three or four companies before they find the right fit and stable employment, Gonzalez said. He traces that to the VA’s dependence on counselors and the relative inaccuracy of human matching.This was a subject that Michael Kratsios, deputy assistant to the president at the White House Office of Science and Technology Policy, talked about at an artificial intelligence summit recently in Washington. Kratsios acknowledged that artificial intelligence raises fears of job losses as machines take over the more routine kinds of work that humans now do.But, he said, artificial intelligence “is not only about displacing workforce, but also about ensuring the right pipeline for more skilled workers, including the matching and training of veterans’ skill sets,” Kratsios said.
Congress takes a look 
Congress has long been interested in new ways to get veterans into full-time stable employment. In the Senate’s version of the 2019 appropriations bill, senators call for the Energy secretary, in consultation with the Defense secretary, to determine which military bases should partner with community colleges, universities and the private sector “to train veterans and members of the Armed Forces transitioning to civilian life to enter the cybersecurity, energy, and artificial intelligence workforces.”Gonzalez said that his experience so far with SkillMil shows that veterans can be placed, not in minimum wage jobs, but in good paying jobs in modern economic sectors such as cybersecurity, supply-chain logistics, aviation, and energy.Artificial intelligence should be able to show the way to more automatic profiling and matching of veterans to appropriate jobs, Gonzalez says.SkillMil has started working with Amazon.com on its Delivery Service Partner program, which encourages veteran entrepreneurs to launch their own truck delivery companies, comprised of between 20 to 40 vans, to help streamline the flow of Amazon’s deliveries in what the company call’s its critical last mile — before it reaches a customer’s doorstep.“The ultimate goal of the partnership is to make sure SkillMil becomes the de facto veteran’s job matching with Amazon,” Gonzalez said. Amazon has set up a $1 million fund to help veterans with startup costs of these local delivery services.Joe Sharpe, the veteran’s employment director at the American Legion, said big tech companies, such as Amazon, are increasingly using targeted employment programs aimed at military veterans.The most recent Department of Labor statistics show that the unemployment rate for calendar year 2017 for veterans serving in the military since September 2001, stood at 4.5 percent, and was slightly higher than the overall national unemployment rate for 2017 of 3.9 percent. Also Watch:Trump Praises McSally, Criticizes the Media at NDAA Signing Event[jwp-video n=”1″]
 



 






Around the Web Here's What New Gutter Guards Should Cost You in 2024LeafFilter PartnerDo Not Eat These 4 Foods Linked to Memory Loss (Avoid)Primal HealthWhy Are Retirees Flocking to Gold?American Hartford GoldWhy Are People Snapping Up This $89 AC Unit?ChillWellOver 60? Don't Accept ED As Normal - Do This InsteadWellness GazeHyundai's New 2024 Palisade Is Turning Heads (Take a Look)Hyundai Palisade



    Recent Stories
  







Florida federal judge tosses out Trump classified documents case








Capitol Lens | Calm before the storm








Convention puts Wisconsin in spotlight, but it’s used to that








Amid tense election, Secret Service working with already boosted budget








Biden condemns attempted Trump assassination, calls for ‘unity’








Trump rushed from stage after gunshots fired at rally








",,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/#article', 'isPartOf': {'@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/'}, 'author': {'name': '', '@id': ''}, 'headline': 'Artificial Intelligence May Help Match Veterans with Civilian Jobs', 'datePublished': '2018-08-16T14:31:52+00:00', 'dateModified': '2019-12-13T14:21:20+00:00', 'mainEntityOfPage': {'@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/'}, 'wordCount': 818, 'publisher': {'@id': 'https://rollcall.com/#organization'}, 'image': {'@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/#primaryimage'}, 'thumbnailUrl': 'https://cdn.media.rollcall.com/author/2018/08/GettyImages-872909136.jpg', 'keywords': ['Appropriations', 'Aviation', 'Budget', 'Cybersecurity', 'Defense', 'Energy', 'Executive Branch', 'House', 'Intelligence', 'Leadership', 'Media', 'Minimum Wage', 'Science', 'Senate', 'Wage', 'Washington', 'White House'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/', 'url': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/', 'name': 'Artificial Intelligence May Help Match Veterans with Civilian Jobs - Roll Call', 'isPartOf': {'@id': 'https://rollcall.com/#website'}, 'primaryImageOfPage': {'@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/#primaryimage'}, 'image': {'@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/#primaryimage'}, 'thumbnailUrl': 'https://cdn.media.rollcall.com/author/2018/08/GettyImages-872909136.jpg', 'datePublished': '2018-08-16T14:31:52+00:00', 'dateModified': '2019-12-13T14:21:20+00:00', 'breadcrumb': {'@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/#primaryimage', 'url': 'https://cdn.media.rollcall.com/author/2018/08/GettyImages-872909136.jpg', 'contentUrl': 'https://cdn.media.rollcall.com/author/2018/08/GettyImages-872909136.jpg', 'caption': 'Artificial intelligence could help\xa0veterans find jobs in the civilian sector that make the most of their military training. (Spencer Platt/Getty Images file photo)'}, {'@type': 'BreadcrumbList', '@id': 'https://rollcall.com/2018/08/16/artificial-intelligence-may-help-match-veterans-with-civilian-jobs/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://rollcall.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence May Help Match Veterans with Civilian Jobs'}]}, {'@type': 'WebSite', '@id': 'https://rollcall.com/#website', 'url': 'https://rollcall.com/', 'name': 'Roll Call', 'description': 'Covering Capitol Hill Since 1955', 'publisher': {'@id': 'https://rollcall.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://rollcall.com/search/{search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://rollcall.com/#organization', 'name': 'Roll Call', 'url': 'https://rollcall.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://rollcall.com/#/schema/logo/image/', 'url': '/app/uploads/2021/02/rollcall-placeholder-image-1.png', 'contentUrl': '/app/uploads/2021/02/rollcall-placeholder-image-1.png', 'width': 1280, 'height': 1024, 'caption': 'Roll Call'}, 'image': {'@id': 'https://rollcall.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/RollCall', 'https://twitter.com/rollcall']}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3LnVuaWZvci5vcmcvbmV3cy9hbGwtbmV3cy91bmlmb3ItbWVtYmVycy1yZWFkeS1mYWNlLXRlY2hub2xvZ2ljYWwtd29ya3BsYWNlLWNoYW5nZXPSAQA?oc=5,members ready to face technological workplace changes | Unifor - Unifor National,2018-08-16,Unifor National,https://www.unifor.org,"Members from across the country were in Halifax on August 15, 2018, to attend the Automation, New Technology and the Future of Work conference...",N/A,"Members from across the country were in Halifax on August 15, 2018, to attend the Automation, New Technology and the Future of Work conference...","Members from across the country were in Halifax on August 15, 2018, to attend the Automation, New Technology and the Future of Work conference...",,,,,,,,,,,,,,N/A,N/A,"


August 16, 2018


ShareFacebookTwitter

 


Members from across the country were in Halifax on August 15, 2018, to attend the Automation, New Technology and the Future of Work conference. As the world of work changes rapidly, new technologies are more frequently introduced in the workplace. Conference delegates came together to discuss, learn and develop a strategy for the future of work that puts workers first. “In a system where profits and productivity are paramount, there will always be a desire for corporations to invest in labour-saving technology,” said Jerry Dias National President. “The Future of Work conference brought members together to craft bargaining and political action strategies to deal with automation, artificial intelligence, and the growth of the digital economy.” Angelo Dicaro, acting Unifor Research Director, kicked off the conference with a presentation on the union's  newly minted research paper The Future of Work is Ours: Confronting risks and seizing opportunities.  The research paper makes it clear that automation, artificial intelligence and other forms of new technology are here to stay and will continue to create challenges that workers will face in workplaces and industries around the world.  The  research paper also discusses possible solutions and strategies to  confront technological changes at work. After the introduction to current issues with automation and technology, participants broke into smaller groups organized by sectors so that tangible, specific strategies and ideas could be developed for workplaces and bargaining. During the report back led by facilitators, certain themes emerged. It was noted that there was significant anxiety in most sectors about job security, but there was also a degree of optimism, especially among skilled trades members. The latter sentiment helped focus the discussion on the fight-back: the role of unions in forcing technological change in order to make work safer and  create new jobs. Collective bargaining was identified as a key tool for worker power in both protecting jobs at individual worksites, but also at leveraging transition for workers into new roles. Regionally and nationally, it was emphasized that Unifor must push for an even stronger social safety net that includes employer or government-sponsored training. Participants discussed the potential that green technology holds for green jobs, and resisting the green-washing (especially in the hospitality industry) that merely reduces work hours. The conference’s final session hosted a panel of experts to offer additional analysis and provide several public policy and tax changes that could protect good jobs and help Canada stay competitive into the future. Guests Sunil Johal, Policy Director, Mowat Centre and Christine Saulnier, Director, Canadian Centre for Policy Alternatives – Nova Scotia had a wide-ranging conversation about areas where Canada’s skilled workforce and value-added is a strength and not a disadvantage. In the evening delegates were treated to a live viewing of the hit CBC Radio show “the debaters” where comics went toe to toe in a battle of laughs debating if work should be replaced by robots. The conference is the first of many steps in Unifor’s development of a long-term plan to put workers’ interests on the forefront of technological changes in our workplaces. 
 




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,headline,alternativeHeadline,image,author,url,datePublished,publisher,articleBody,wordcount,article:section,article:summary,article text,@graph,mainEntityOfPage,dateCreated,dateModified,heading,name,inLanguage,issn,potentialAction,@id,logo,sameAs,isAccessibleForFree,hasPart,articleSection,thumbnailUrl,uploadDate,duration,contentUrl,embedUrl,speakable,creator,itemListElement,isBasedOn,isPartOf,identifier,address,geo,parentOrganization
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmZhcnJlci5jby51ay9uZXdzLWFuZC1pbnNpZ2h0cy9ibG9ncy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi10aGUtd29ya3BsYWNlLWhlbHBmdWwtb3ItaGFybWZ1bC_SAQA?oc=5,Artificial intelligence in the workplace: helpful or harmful? - Farrer & Co,2021-04-27,Farrer & Co,https://www.farrer.co.uk,"The pros and cons of using AI in the workplace have been much debated over recent years – periodically grabbing the headlines, but coming under surprisingly little scrutiny from a regulatory perspective. The benefits for employers have been",,"The pros and cons of using AI in the workplace have been much debated over recent years – periodically grabbing the headlines, but coming under surprisingly little scrutiny from a regulatory perspective. The benefits for employers have been significant, often providing a lifeline for business continuity during the lockdowns of the last year, but what about the impact on the employee? The rise of AI in the workplace has principally been discussed in the context of the gig economy, where workers are no longer directed by a human manager, but by an automated algorithm. Now, with the acceleration in the use of radical new technologies, AI is very much a feature of working life in general. However, while stories of robots replacing workers have (on the whole) not (as yet?) come true, the rise of algorithmic HR and management tools means that it’s the ‘bosses’ whose jobs risk to some extent becoming automated. AI in the workplace today AI technologies are already being used across a broad range of industries, at every stage in the employment cycle. From recruitment to dismissal, their use has significant implications for today’s workplaces - whether that workplace is a bank, an accountancy firm or a university. It is worth defining some of the terms in the context of the functions that AI performs: Algorithmic decision making (ADM) – this is where the AI - be it an algorithm or a software application (an “app”) - takes over the decision making in the employment relationship. That could be to manage a schedule or assign tasks. It might also be used in the recruitment process. For example, in algorithmic hiring, applicants could be asked to upload a video of themselves talking; yet no human being or HR manager will ever watch that video to make the decision as whether to hire them. Likewise, ADM has been used to make “high risk” decisions, such as analysing performance metrics to establish who should be promoted or Think of the scenario where a driver in the gig economy has a rating which goes below 4.5 out of 5 and then, one day, she tries to log on to the app and it no longer works. Machine learning - a machine is made “smart” by allowing the algorithms in the AI system to adapt by learning from correlations it finds in one data input (known as the “training set”) to make predictions relating to another data set. For instance, a hiring system trained on the data of a company’s historical employees might use this data to decide who to hire in the future. Profiling - machines can use “feature selection” to categorise employees by analysing known and inferred personal data about each person. This data, in turn, could be used to make predictions about individuals, such as the risk of them turning up late for work or whether they are likely to move to a competitor. As these functions show, algorithmic management is starting in some areas to replace – or, at the very least, augment - the exercise of a whole range of traditional employment functions. Algorithmic discrimination Where algorithms are used in place of human decision making, it is perhaps unsurprising that they sometimes risk replicating existing biases and inequalities in society. Consequently, unfair rules have been inadvertently hardcoded into AI systems, thereby resulting in discriminatory decisions: In March, Uber’s use of facial identification software in its app was inconsistent and inaccurate when it came to skin colour. This indirectly caused racial discrimination by denying the use of its app by drivers and couriers of non-White ethnicities (and therefore their access to work). Amazon’s hiring algorithm was ultimately scrapped after its machine learning system taught itself that male candidates were preferable. This sex discrimination was brought about by using data relating to Amazon’s top engineers (who were mainly men) as the “training set”. This resulted in CVs being discarded where they included the word “women’s”, (such as “women’s netball team captain”) and by giving low scores to graduates of all-women colleges. But even where the data has been “cleaned”, there are still legal traps which need to be avoided. For instance, one approach which computer scientists favour to avoid such biases, is to run a different algorithm for each subpopulation in a data set. However, this is the equivalent to saying that there should be one machine to score women and another machine to score men (or separate machines to score people of different ethnicities, for example). Computationally, this approach could be an elegant solution. Nevertheless, in employment law terms, the inconsistent application of criteria to people with different protected characteristics would fall foul of the Equality Act. This would make such a technological solution wholly unlawful – and ultimately unhelpful - as a starting point. Technological problems, legal solutions? The paradox of AI is that it expands its control over the workforce, while simultaneously diffusing accountability in the decision-making chain. An HR manager in charge of hiring workers will be subject to anti-discrimination duties in law. But who is held responsible when an AI tool, itself, introduces discrimination into the “hiring and firing” process?    An employee is unlikely to be able to claim for direct discrimination in such circumstances, as it is not possible to show any kind of intent on the part of the AI. As indirect discrimination is the only claim available, this opens up a space for justification for use of the AI. So, in the example of an automated hiring process, an employer might have a defence that its use of ADM is a proportionate means of achieving the legitimate aim (in this case, efficiently dealing with a very high number of applications for a given role). As such, there may be a risk that a claimant will not be able to enforce their right not to be discriminated against, wherever the employer can defer accountability to the AI system. As it currently stands, the law does allow employers to make decisions without human intervention, albeit these are in limited circumstances and require transparency, under the UK General Data Protection Regulation (UK GDPR). The Trade Union Congress (TUC) (in conjunction with Robin Allen QC and Dee Masters of Cloisters Chambers) has argued for changes in the law, in its recently published report on the use of AI at work. This report sets out the TUC’s recommendations for better protection of workers against algorithmic discrimination, including: Re-evaluating existing legal structures, such as the Equality Act, to protect against “discrimination by algorithm”. This would include: “a complete and express reversal of the burden of proof in relation to “high risk” uses of AI or ADM systems, such that the employer must prove from the outset that discrimination has not occurred rather than the conventional burden of proof in discrimination claims where the claimant bears the initial burden.” “Red lines” beyond which the deployment of new technologies should not occur. Specifically, they argue that the use of AI and ADM in high-risk decisions should only be permitted where existing and potential employees and workers themselves can sensibly understand those decisions, be part of the decision-making process and satisfy themselves that the technology is being used in a way which is rational, accurate and non-discriminatory. AI registers to be made mandatory for employers to maintain and update regularly and for these registers to be accessible to employees, workers, and job applicants. Likewise, the government in its (much lambasted) race report, has made its own recommendations for improving the transparency of AI and ADM. This report calls for: Mandating the use of tools, such as Algorithmic Impact Assessments, that help raise fairness risks and detect and mitigate bias before, during, and after any system deployment; Placing a transparency obligation on all public sector organisations that apply algorithms with an impact on significant decisions that affect individuals; and Asking the Equality and Human Rights Commission (EHRC) to issue guidance on the lawfulness of bias mitigation techniques, the collection of data to measure bias, and to clarify how to apply the Equality Act to ADM. Where next for the regulation of AI? So far AI has on the whole been developed and deployed with very little oversight. However, given the rapid rise in its reach and impact, we are starting to see a shift towards calls for greater restrictions and regulation. Perhaps not surprisingly (given its far-reaching approach to privacy in the GDPR), the EU appears to be leading the way on this front, with its recently published Proposal for a Regulation laying down harmonised rules on artificial intelligence. This is described as the first ever legal framework on AI, aimed at harnessing the opportunities and addressing the challenges of AI and positioning the EU to play a leading role globally on the issue. From a work perspective, the EU’s report states that any AI-systems involved in employment, worker management and self-employment (eg in recruitment, evaluation of performance, promotion and termination) should be classified as “high-risk”, and so subject to specific safeguards, “since those systems may appreciably impact future career prospects and livelihoods of these persons”. Proposed obligations include (from a provider point of view) ensuring human oversight of AI systems and focusing on the quality of the data used to teach the AI system, and (from a user point of view) following instructions on the use of AI systems, monitoring the functioning of the system and keeping records. The proposed sanctions for breach are significant, with fines of up to €20 million or 4 per cent of annual worldwide turnover. The rules are still in draft form and subject to a lengthy approvals process, so it is likely to take several years before anything comes into effect. Moreover, now that the UK has left the EU, the proposals will not be binding on the UK as and when they are implemented. Nevertheless, in publishing its proposals, the EU has sent a strong message about its intent to push for tighter extra-territorial oversight on how AI is used and it will be interesting to see how the UK, and indeed the rest of the world, respond. Even if the UK Government does not follow suit in introducing regulations of its own, it is worth noting that UK based entities creating or deploying AI in the EU will still need to follow whatever EU rules eventually come into force.  For more information, see our article on Artificial Intelligence: Analysing the EU’s new Regulation. What this means for employers In the absence of any clear guidance, employers should be live to the potential unintended consequences of any automated AI systems they use. This requires organisations to stay up to date with rapidly changing technological developments and, wherever such AI systems are implemented, to carefully consider how these might impact on fairness, accountability, and transparency in the workplace. The extent to which employers bear legal responsibility for any discriminatory decisions arising from such AI systems is currently unclear; but it is incumbent on employers to inform themselves of such issues. In other words, there is still very much a need to keep the ‘human’ in human resources decision-making. If you require further information about anything covered in this blog, please contact Rachel Lewis, Iman Kouchouk, or your usual contact at the firm on +44 (0)20 3375 7000. This publication is a general summary of the law. It should not replace legal advice tailored to your specific circumstances. © Farrer & Co LLP, April 2021","The pros and cons of using AI in the workplace have been much debated over recent years – periodically grabbing the headlines, but coming under surprisingly little scrutiny from a regulatory perspective. The benefits for employers have been significant, often providing a lifeline for business continuity during the lockdowns of the last year, but what about the impact on the employee? The rise of AI in the workplace has principally been discussed in the context of the gig economy, where workers are no longer directed by a human manager, but by an automated algorithm. Now, with the acceleration in the use of radical new technologies, AI is very much a feature of working life in general. However, while stories of robots replacing workers have (on the whole) not (as yet?) come true, the rise of algorithmic HR and management tools means that it’s the ‘bosses’ whose jobs risk to some extent becoming automated. AI in the workplace today AI technologies are already being used across a broad range of industries, at every stage in the employment cycle. From recruitment to dismissal, their use has significant implications for today’s workplaces - whether that workplace is a bank, an accountancy firm or a university. It is worth defining some of the terms in the context of the functions that AI performs: Algorithmic decision making (ADM) – this is where the AI - be it an algorithm or a software application (an “app”) - takes over the decision making in the employment relationship. That could be to manage a schedule or assign tasks. It might also be used in the recruitment process. For example, in algorithmic hiring, applicants could be asked to upload a video of themselves talking; yet no human being or HR manager will ever watch that video to make the decision as whether to hire them. Likewise, ADM has been used to make “high risk” decisions, such as analysing performance metrics to establish who should be promoted or Think of the scenario where a driver in the gig economy has a rating which goes below 4.5 out of 5 and then, one day, she tries to log on to the app and it no longer works. Machine learning - a machine is made “smart” by allowing the algorithms in the AI system to adapt by learning from correlations it finds in one data input (known as the “training set”) to make predictions relating to another data set. For instance, a hiring system trained on the data of a company’s historical employees might use this data to decide who to hire in the future. Profiling - machines can use “feature selection” to categorise employees by analysing known and inferred personal data about each person. This data, in turn, could be used to make predictions about individuals, such as the risk of them turning up late for work or whether they are likely to move to a competitor. As these functions show, algorithmic management is starting in some areas to replace – or, at the very least, augment - the exercise of a whole range of traditional employment functions. Algorithmic discrimination Where algorithms are used in place of human decision making, it is perhaps unsurprising that they sometimes risk replicating existing biases and inequalities in society. Consequently, unfair rules have been inadvertently hardcoded into AI systems, thereby resulting in discriminatory decisions: In March, Uber’s use of facial identification software in its app was inconsistent and inaccurate when it came to skin colour. This indirectly caused racial discrimination by denying the use of its app by drivers and couriers of non-White ethnicities (and therefore their access to work). Amazon’s hiring algorithm was ultimately scrapped after its machine learning system taught itself that male candidates were preferable. This sex discrimination was brought about by using data relating to Amazon’s top engineers (who were mainly men) as the “training set”. This resulted in CVs being discarded where they included the word “women’s”, (such as “women’s netball team captain”) and by giving low scores to graduates of all-women colleges. But even where the data has been “cleaned”, there are still legal traps which need to be avoided. For instance, one approach which computer scientists favour to avoid such biases, is to run a different algorithm for each subpopulation in a data set. However, this is the equivalent to saying that there should be one machine to score women and another machine to score men (or separate machines to score people of different ethnicities, for example). Computationally, this approach could be an elegant solution. Nevertheless, in employment law terms, the inconsistent application of criteria to people with different protected characteristics would fall foul of the Equality Act. This would make such a technological solution wholly unlawful – and ultimately unhelpful - as a starting point. Technological problems, legal solutions? The paradox of AI is that it expands its control over the workforce, while simultaneously diffusing accountability in the decision-making chain. An HR manager in charge of hiring workers will be subject to anti-discrimination duties in law. But who is held responsible when an AI tool, itself, introduces discrimination into the “hiring and firing” process?    An employee is unlikely to be able to claim for direct discrimination in such circumstances, as it is not possible to show any kind of intent on the part of the AI. As indirect discrimination is the only claim available, this opens up a space for justification for use of the AI. So, in the example of an automated hiring process, an employer might have a defence that its use of ADM is a proportionate means of achieving the legitimate aim (in this case, efficiently dealing with a very high number of applications for a given role). As such, there may be a risk that a claimant will not be able to enforce their right not to be discriminated against, wherever the employer can defer accountability to the AI system. As it currently stands, the law does allow employers to make decisions without human intervention, albeit these are in limited circumstances and require transparency, under the UK General Data Protection Regulation (UK GDPR). The Trade Union Congress (TUC) (in conjunction with Robin Allen QC and Dee Masters of Cloisters Chambers) has argued for changes in the law, in its recently published report on the use of AI at work. This report sets out the TUC’s recommendations for better protection of workers against algorithmic discrimination, including: Re-evaluating existing legal structures, such as the Equality Act, to protect against “discrimination by algorithm”. This would include: “a complete and express reversal of the burden of proof in relation to “high risk” uses of AI or ADM systems, such that the employer must prove from the outset that discrimination has not occurred rather than the conventional burden of proof in discrimination claims where the claimant bears the initial burden.” “Red lines” beyond which the deployment of new technologies should not occur. Specifically, they argue that the use of AI and ADM in high-risk decisions should only be permitted where existing and potential employees and workers themselves can sensibly understand those decisions, be part of the decision-making process and satisfy themselves that the technology is being used in a way which is rational, accurate and non-discriminatory. AI registers to be made mandatory for employers to maintain and update regularly and for these registers to be accessible to employees, workers, and job applicants. Likewise, the government in its (much lambasted) race report, has made its own recommendations for improving the transparency of AI and ADM. This report calls for: Mandating the use of tools, such as Algorithmic Impact Assessments, that help raise fairness risks and detect and mitigate bias before, during, and after any system deployment; Placing a transparency obligation on all public sector organisations that apply algorithms with an impact on significant decisions that affect individuals; and Asking the Equality and Human Rights Commission (EHRC) to issue guidance on the lawfulness of bias mitigation techniques, the collection of data to measure bias, and to clarify how to apply the Equality Act to ADM. Where next for the regulation of AI? So far AI has on the whole been developed and deployed with very little oversight. However, given the rapid rise in its reach and impact, we are starting to see a shift towards calls for greater restrictions and regulation. Perhaps not surprisingly (given its far-reaching approach to privacy in the GDPR), the EU appears to be leading the way on this front, with its recently published Proposal for a Regulation laying down harmonised rules on artificial intelligence. This is described as the first ever legal framework on AI, aimed at harnessing the opportunities and addressing the challenges of AI and positioning the EU to play a leading role globally on the issue. From a work perspective, the EU’s report states that any AI-systems involved in employment, worker management and self-employment (eg in recruitment, evaluation of performance, promotion and termination) should be classified as “high-risk”, and so subject to specific safeguards, “since those systems may appreciably impact future career prospects and livelihoods of these persons”. Proposed obligations include (from a provider point of view) ensuring human oversight of AI systems and focusing on the quality of the data used to teach the AI system, and (from a user point of view) following instructions on the use of AI systems, monitoring the functioning of the system and keeping records. The proposed sanctions for breach are significant, with fines of up to €20 million or 4 per cent of annual worldwide turnover. The rules are still in draft form and subject to a lengthy approvals process, so it is likely to take several years before anything comes into effect. Moreover, now that the UK has left the EU, the proposals will not be binding on the UK as and when they are implemented. Nevertheless, in publishing its proposals, the EU has sent a strong message about its intent to push for tighter extra-territorial oversight on how AI is used and it will be interesting to see how the UK, and indeed the rest of the world, respond. Even if the UK Government does not follow suit in introducing regulations of its own, it is worth noting that UK based entities creating or deploying AI in the EU will still need to follow whatever EU rules eventually come into force.  For more information, see our article on Artificial Intelligence: Analysing the EU’s new Regulation. What this means for employers In the absence of any clear guidance, employers should be live to the potential unintended consequences of any automated AI systems they use. This requires organisations to stay up to date with rapidly changing technological developments and, wherever such AI systems are implemented, to carefully consider how these might impact on fairness, accountability, and transparency in the workplace. The extent to which employers bear legal responsibility for any discriminatory decisions arising from such AI systems is currently unclear; but it is incumbent on employers to inform themselves of such issues. In other words, there is still very much a need to keep the ‘human’ in human resources decision-making. If you require further information about anything covered in this blog, please contact Rachel Lewis, Iman Kouchouk, or your usual contact at the firm on +44 (0)20 3375 7000. This publication is a general summary of the law. It should not replace legal advice tailored to your specific circumstances. © Farrer & Co LLP, April 2021",http://schema.org,Article,Artificial intelligence in the workplace: helpful or harmful?,Artificial intelligence in the workplace: helpful or harmful?,https://www.farrer.co.uk/globalassets/employees-low-res.jpg,"[{'@type': 'Person', 'familyName': 'Lewis', 'givenName': 'Rachel', 'name': 'Rachel Lewis'}, {'@type': 'Person', 'familyName': 'Kouchouk', 'givenName': 'Iman', 'name': 'Iman Kouchouk'}]",https://www.farrer.co.uk/news-and-insights/blogs/artificial-intelligence-in-the-workplace-helpful-or-harmful/,6/30/2021 1:04:00 PM,"{'@type': 'Organization', 'name': 'Farrer & Co', 'url': 'https://www.farrer.co.uk/', 'logo': {'@type': 'ImageObject', 'url': 'https://www.farrer.co.uk/static/images/assets/print-logo.png'}}","The pros and cons of using AI in the workplace have been much debated over recent years – periodically grabbing the headlines, but coming under surprisingly little scrutiny from a regulatory perspective. The benefits for employers have been significant, often providing a lifeline for business continuity during the lockdowns of the last year, but what about the impact on the employee? The rise of AI in the workplace has principally been discussed in the context of the gig economy, where workers are no longer directed by a human manager, but by an automated algorithm. Now, with the acceleration in the use of radical new technologies, AI is very much a feature of working life in general. However, while stories of robots replacing workers have (on the whole) not (as yet?) come true, the rise of algorithmic HR and management tools means that it’s the ‘bosses’ whose jobs risk to some extent becoming automated. AI in the workplace today AI technologies are already being used across a broad range of industries, at every stage in the employment cycle. From recruitment to dismissal, their use has significant implications for today’s workplaces - whether that workplace is a bank, an accountancy firm or a university. It is worth defining some of the terms in the context of the functions that AI performs: Algorithmic decision making (ADM) – this is where the AI - be it an algorithm or a software application (an “app”) - takes over the decision making in the employment relationship. That could be to manage a schedule or assign tasks. It might also be used in the recruitment process. For example, in algorithmic hiring, applicants could be asked to upload a video of themselves talking; yet no human being or HR manager will ever watch that video to make the decision as whether to hire them. Likewise, ADM has been used to make “high risk” decisions, such as analysing performance metrics to establish who should be promoted or Think of the scenario where a driver in the gig economy has a rating which goes below 4.5 out of 5 and then, one day, she tries to log on to the app and it no longer works. Machine learning - a machine is made “smart” by allowing the algorithms in the AI system to adapt by learning from correlations it finds in one data input (known as the “training set”) to make predictions relating to another data set. For instance, a hiring system trained on the data of a company’s historical employees might use this data to decide who to hire in the future. Profiling - machines can use “feature selection” to categorise employees by analysing known and inferred personal data about each person. This data, in turn, could be used to make predictions about individuals, such as the risk of them turning up late for work or whether they are likely to move to a competitor. As these functions show, algorithmic management is starting in some areas to replace – or, at the very least, augment - the exercise of a whole range of traditional employment functions. Algorithmic discrimination Where algorithms are used in place of human decision making, it is perhaps unsurprising that they sometimes risk replicating existing biases and inequalities in society. Consequently, unfair rules have been inadvertently hardcoded into AI systems, thereby resulting in discriminatory decisions: In March, Uber’s use of facial identification software in its app was inconsistent and inaccurate when it came to skin colour. This indirectly caused racial discrimination by denying the use of its app by drivers and couriers of non-White ethnicities (and therefore their access to work). Amazon’s hiring algorithm was ultimately scrapped after its machine learning system taught itself that male candidates were preferable. This sex discrimination was brought about by using data relating to Amazon’s top engineers (who were mainly men) as the “training set”. This resulted in CVs being discarded where they included the word “women’s”, (such as “women’s netball team captain”) and by giving low scores to graduates of all-women colleges. But even where the data has been “cleaned”, there are still legal traps which need to be avoided. For instance, one approach which computer scientists favour to avoid such biases, is to run a different algorithm for each subpopulation in a data set. However, this is the equivalent to saying that there should be one machine to score women and another machine to score men (or separate machines to score people of different ethnicities, for example). Computationally, this approach could be an elegant solution. Nevertheless, in employment law terms, the inconsistent application of criteria to people with different protected characteristics would fall foul of the Equality Act. This would make such a technological solution wholly unlawful – and ultimately unhelpful - as a starting point. Technological problems, legal solutions? The paradox of AI is that it expands its control over the workforce, while simultaneously diffusing accountability in the decision-making chain. An HR manager in charge of hiring workers will be subject to anti-discrimination duties in law. But who is held responsible when an AI tool, itself, introduces discrimination into the “hiring and firing” process? &#160;&#160; An employee is unlikely to be able to claim for direct discrimination in such circumstances, as it is not possible to show any kind of intent on the part of the AI. As indirect discrimination is the only claim available, this opens up a space for justification for use of the AI. So, in the example of an automated hiring process, an employer might have a defence that its use of ADM is a proportionate means of achieving the legitimate aim (in this case, efficiently dealing with a very high number of applications for a given role). As such, there may be a risk that a claimant will not be able to enforce their right not to be discriminated against, wherever the employer can defer accountability to the AI system. As it currently stands, the law does allow employers to make decisions without human intervention, albeit these are in limited circumstances and require transparency, under the UK General&#160;Data Protection Regulation&#160;(UK&#160;GDPR). The Trade Union Congress (TUC) (in conjunction with Robin Allen QC and Dee Masters of Cloisters Chambers) has argued for changes in the law, in its recently published report on the use of AI at work. This report sets out the TUC’s recommendations for better protection of workers against algorithmic discrimination, including: Re-evaluating existing legal structures, such as the Equality Act, to protect against “discrimination by algorithm”. This would include: “a complete and express reversal of the burden of proof in relation to “high risk” uses of AI or ADM systems, such that the employer must prove from the outset that discrimination has not occurred rather than the conventional burden of proof in discrimination claims where the claimant bears the initial burden.” “Red lines” beyond which the deployment of new technologies should not occur. Specifically, they argue that the use of AI and ADM in high-risk decisions should only be permitted where existing and potential employees and workers themselves can sensibly understand those decisions, be part of the decision-making process and satisfy themselves that the technology is being used in a way which is rational, accurate and non-discriminatory. AI registers to be made mandatory for employers to maintain and update regularly and for these registers to be accessible to employees, workers, and job applicants. Likewise, the government in its (much lambasted) race report, has made its own recommendations for improving the transparency of AI and ADM. This report calls for: Mandating the use of tools, such as Algorithmic Impact Assessments, that help raise fairness risks and detect and mitigate bias before, during, and after any system deployment; Placing a transparency obligation on all public sector organisations that apply algorithms with an impact on significant decisions that affect individuals; and Asking the Equality and Human Rights Commission (EHRC) to issue guidance on the lawfulness of bias mitigation techniques, the collection of data to measure bias, and to clarify how to apply the Equality Act to ADM. Where next for the regulation of AI? So far AI has on the whole been developed and deployed with very little oversight. However, given the rapid rise in its reach and impact, we are starting to see a shift towards calls for greater restrictions and regulation. Perhaps not surprisingly (given its far-reaching approach to privacy in the GDPR), the EU appears to be leading the way on this front, with its recently published Proposal for a Regulation laying down harmonised rules on artificial intelligence. This is described as the first ever legal framework on AI, aimed at harnessing the opportunities and addressing the challenges of AI and positioning the EU to play a leading role globally on the issue. From a work perspective, the EU’s report states that any AI-systems involved in employment, worker management and self-employment (eg in recruitment, evaluation of performance, promotion and termination) should be classified as “high-risk”, and so subject to specific safeguards, “since those systems may appreciably impact future career prospects and livelihoods of these persons”. Proposed obligations include (from a provider point of view) ensuring human oversight of AI systems and focusing on the quality of the data used to teach the AI system, and (from a user point of view) following instructions on the use of AI systems, monitoring the functioning of the system and keeping records. The proposed sanctions for breach are significant, with fines of up to €20 million or 4 per cent of annual worldwide turnover. The rules are still in draft form and subject to a lengthy approvals process, so it is likely to take several years before anything comes into effect. Moreover, now that the UK has left the EU, the proposals will not be binding on the UK as and when they are implemented. Nevertheless, in publishing its proposals, the EU has sent a strong message about its intent to push for tighter extra-territorial oversight on how AI is used and it will be interesting to see how the UK, and indeed the rest of the world, respond. Even if the UK Government does not follow suit in introducing regulations of its own, it is worth noting that UK based entities creating or deploying AI in the EU will still need to follow whatever EU rules eventually come into force.&#160; For more information, see our article on Artificial Intelligence: Analysing the EU’s new Regulation. What this means for employers In the absence of any clear guidance, employers should be live to the potential unintended consequences of any automated AI systems they use. This requires organisations to stay up to date with rapidly changing technological developments and, wherever such AI systems are implemented, to carefully consider how these might impact on fairness, accountability, and transparency in the workplace. The extent to which employers bear legal responsibility for any discriminatory decisions arising from such AI systems is currently unclear; but it is incumbent on employers to inform themselves of such issues. In other words, there is still very much a need to keep the ‘human’ in human resources decision-making. If you require further information about anything covered in this blog, please contact&#160;Rachel Lewis, Iman Kouchouk, or your usual contact at the firm on +44 (0)20 3375 7000. This publication is a general summary of the law. It should not replace legal advice tailored to your specific circumstances. &#169; Farrer &amp; Co LLP, April 2021",1911,N/A,N/A,"

Artificial intelligence in the workplace: helpful or harmful?
Blog
30.06.2021        






The pros and cons of using AI in the workplace have been much debated over recent years – periodically grabbing the headlines, but coming under surprisingly little scrutiny from a regulatory perspective. The benefits for employers have been significant, often providing a lifeline for business continuity during the lockdowns of the last year, but what about the impact on the employee?
The rise of AI in the workplace has principally been discussed in the context of the gig economy, where workers are no longer directed by a human manager, but by an automated algorithm. Now, with the acceleration in the use of radical new technologies, AI is very much a feature of working life in general. However, while stories of robots replacing workers have (on the whole) not (as yet?) come true, the rise of algorithmic HR and management tools means that it’s the ‘bosses’ whose jobs risk to some extent becoming automated.
AI in the workplace today
AI technologies are already being used across a broad range of industries, at every stage in the employment cycle. From recruitment to dismissal, their use has significant implications for today’s workplaces - whether that workplace is a bank, an accountancy firm or a university.
It is worth defining some of the terms in the context of the functions that AI performs:

Algorithmic decision making (ADM) – this is where the AI - be it an algorithm or a software application (an “app”) - takes over the decision making in the employment relationship. That could be to manage a schedule or assign tasks. It might also be used in the recruitment process. For example, in algorithmic hiring, applicants could be asked to upload a video of themselves talking; yet no human being or HR manager will ever watch that video to make the decision as whether to hire them. Likewise, ADM has been used to make “high risk” decisions, such as analysing performance metrics to establish who should be promoted or Think of the scenario where a driver in the gig economy has a rating which goes below 4.5 out of 5 and then, one day, she tries to log on to the app and it no longer works.
Machine learning - a machine is made “smart” by allowing the algorithms in the AI system to adapt by learning from correlations it finds in one data input (known as the “training set”) to make predictions relating to another data set. For instance, a hiring system trained on the data of a company’s historical employees might use this data to decide who to hire in the future.
Profiling - machines can use “feature selection” to categorise employees by analysing known and inferred personal data about each person. This data, in turn, could be used to make predictions about individuals, such as the risk of them turning up late for work or whether they are likely to move to a competitor.

As these functions show, algorithmic management is starting in some areas to replace – or, at the very least, augment - the exercise of a whole range of traditional employment functions.
Algorithmic discrimination
Where algorithms are used in place of human decision making, it is perhaps unsurprising that they sometimes risk replicating existing biases and inequalities in society. Consequently, unfair rules have been inadvertently hardcoded into AI systems, thereby resulting in discriminatory decisions:

In March, Uber’s use of facial identification software in its app was inconsistent and inaccurate when it came to skin colour. This indirectly caused racial discrimination by denying the use of its app by drivers and couriers of non-White ethnicities (and therefore their access to work).
Amazon’s hiring algorithm was ultimately scrapped after its machine learning system taught itself that male candidates were preferable. This sex discrimination was brought about by using data relating to Amazon’s top engineers (who were mainly men) as the “training set”. This resulted in CVs being discarded where they included the word “women’s”, (such as “women’s netball team captain”) and by giving low scores to graduates of all-women colleges.

But even where the data has been “cleaned”, there are still legal traps which need to be avoided. For instance, one approach which computer scientists favour to avoid such biases, is to run a different algorithm for each subpopulation in a data set. However, this is the equivalent to saying that there should be one machine to score women and another machine to score men (or separate machines to score people of different ethnicities, for example). Computationally, this approach could be an elegant solution. Nevertheless, in employment law terms, the inconsistent application of criteria to people with different protected characteristics would fall foul of the Equality Act. This would make such a technological solution wholly unlawful – and ultimately unhelpful - as a starting point.
Technological problems, legal solutions?
The paradox of AI is that it expands its control over the workforce, while simultaneously diffusing accountability in the decision-making chain. An HR manager in charge of hiring workers will be subject to anti-discrimination duties in law. But who is held responsible when an AI tool, itself, introduces discrimination into the “hiring and firing” process?   
An employee is unlikely to be able to claim for direct discrimination in such circumstances, as it is not possible to show any kind of intent on the part of the AI. As indirect discrimination is the only claim available, this opens up a space for justification for use of the AI. So, in the example of an automated hiring process, an employer might have a defence that its use of ADM is a proportionate means of achieving the legitimate aim (in this case, efficiently dealing with a very high number of applications for a given role). As such, there may be a risk that a claimant will not be able to enforce their right not to be discriminated against, wherever the employer can defer accountability to the AI system.
As it currently stands, the law does allow employers to make decisions without human intervention, albeit these are in limited circumstances and require transparency, under the UK General Data Protection Regulation (UK GDPR). The Trade Union Congress (TUC) (in conjunction with Robin Allen QC and Dee Masters of Cloisters Chambers) has argued for changes in the law, in its recently published report on the use of AI at work. This report sets out the TUC’s recommendations for better protection of workers against algorithmic discrimination, including:

Re-evaluating existing legal structures, such as the Equality Act, to protect against “discrimination by algorithm”. This would include: “a complete and express reversal of the burden of proof in relation to “high risk” uses of AI or ADM systems, such that the employer must prove from the outset that discrimination has not occurred rather than the conventional burden of proof in discrimination claims where the claimant bears the initial burden.”
“Red lines” beyond which the deployment of new technologies should not occur. Specifically, they argue that the use of AI and ADM in high-risk decisions should only be permitted where existing and potential employees and workers themselves can sensibly understand those decisions, be part of the decision-making process and satisfy themselves that the technology is being used in a way which is rational, accurate and non-discriminatory.
AI registers to be made mandatory for employers to maintain and update regularly and for these registers to be accessible to employees, workers, and job applicants.

Likewise, the government in its (much lambasted) race report, has made its own recommendations for improving the transparency of AI and ADM. This report calls for:

Mandating the use of tools, such as Algorithmic Impact Assessments, that help raise fairness risks and detect and mitigate bias before, during, and after any system deployment;
Placing a transparency obligation on all public sector organisations that apply algorithms with an impact on significant decisions that affect individuals; and
Asking the Equality and Human Rights Commission (EHRC) to issue guidance on the lawfulness of bias mitigation techniques, the collection of data to measure bias, and to clarify how to apply the Equality Act to ADM.

Where next for the regulation of AI?
So far AI has on the whole been developed and deployed with very little oversight. However, given the rapid rise in its reach and impact, we are starting to see a shift towards calls for greater restrictions and regulation. Perhaps not surprisingly (given its far-reaching approach to privacy in the GDPR), the EU appears to be leading the way on this front, with its recently published Proposal for a Regulation laying down harmonised rules on artificial intelligence. This is described as the first ever legal framework on AI, aimed at harnessing the opportunities and addressing the challenges of AI and positioning the EU to play a leading role globally on the issue.
From a work perspective, the EU’s report states that any AI-systems involved in employment, worker management and self-employment (eg in recruitment, evaluation of performance, promotion and termination) should be classified as “high-risk”, and so subject to specific safeguards, “since those systems may appreciably impact future career prospects and livelihoods of these persons”. Proposed obligations include (from a provider point of view) ensuring human oversight of AI systems and focusing on the quality of the data used to teach the AI system, and (from a user point of view) following instructions on the use of AI systems, monitoring the functioning of the system and keeping records. The proposed sanctions for breach are significant, with fines of up to €20 million or 4 per cent of annual worldwide turnover.
The rules are still in draft form and subject to a lengthy approvals process, so it is likely to take several years before anything comes into effect. Moreover, now that the UK has left the EU, the proposals will not be binding on the UK as and when they are implemented. Nevertheless, in publishing its proposals, the EU has sent a strong message about its intent to push for tighter extra-territorial oversight on how AI is used and it will be interesting to see how the UK, and indeed the rest of the world, respond. Even if the UK Government does not follow suit in introducing regulations of its own, it is worth noting that UK based entities creating or deploying AI in the EU will still need to follow whatever EU rules eventually come into force. 
For more information, see our article on Artificial Intelligence: Analysing the EU’s new Regulation.
What this means for employers
In the absence of any clear guidance, employers should be live to the potential unintended consequences of any automated AI systems they use. This requires organisations to stay up to date with rapidly changing technological developments and, wherever such AI systems are implemented, to carefully consider how these might impact on fairness, accountability, and transparency in the workplace.
The extent to which employers bear legal responsibility for any discriminatory decisions arising from such AI systems is currently unclear; but it is incumbent on employers to inform themselves of such issues. In other words, there is still very much a need to keep the ‘human’ in human resources decision-making.
If you require further information about anything covered in this blog, please contact Rachel Lewis, Iman Kouchouk, or your usual contact at the firm on +44 (0)20 3375 7000.This publication is a general summary of the law. It should not replace legal advice tailored to your specific circumstances.© Farrer & Co LLP, April 2021


Want to know more?

                Contact us
            


Share on




Twitter









LinkedIn









Email









Facebook








About the authors

 Rachel Lewis
Partner - Board Member
Rachel has over 20 years’ experience advising a diverse range of clients across the full spectrum of employment law issues. She is well known for her pragmatism, supportiveness and for the commerciality of her approach.
Rachel has over 20 years’ experience advising a diverse range of clients across the full spectrum of employment law issues. She is well known for her pragmatism, supportiveness and for the commerciality of her approach.




Rachel's profile page




Email Rachel




+44 (0)20 3375 7440




 Iman Kouchouk
Associate
Iman is an employment lawyer advising both employers and employees on both contentious and non-contentious employment law issues.
Iman is an employment lawyer advising both employers and employees on both contentious and non-contentious employment law issues.




Iman's profile page




Email Iman




+44 (0)20 3375 7291







Authors

 

Rachel Lewis, Partner - Board Member




Email Rachel




+44 (0)20 3375 7440




 

Iman Kouchouk, Associate




Email Iman




+44 (0)20 3375 7291




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vZWRyaS5vcmcvb3VyLXdvcmsvZXVzLWFpLWxhdy1uZWVkcy1tYWpvci1jaGFuZ2VzLXRvLXByZXZlbnQtZGlzY3JpbWluYXRpb24tYW5kLW1hc3Mtc3VydmVpbGxhbmNlL9IBAA?oc=5,EU’s AI law needs major changes to prevent discrimination and mass surveillance - European Digital Rights (EDRi),2021-04-28,European Digital Rights (EDRi),https://edri.org,"The European Commission has just launched the its proposed regulation on artificial intelligence (AI). As governments andcompanies continue to use AI in ways that lead to discrimination andsurveillance, the proposed law must go much further to protect peopleand their rights. Here’s a deeper analysis from the EDRi network,including some initial recommendations for change.",N/A,"The European Commission has just launched the its proposed regulation on artificial intelligence (AI). As governments andcompanies continue to use AI in ways that lead to discrimination andsurveillance, the proposed law must go much further to protect peopleand their rights. Here’s a deeper analysis from the EDRi network,including some initial recommendations for change.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,N/A,"[{'@type': 'WebPage', '@id': 'https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/', 'url': 'https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/', 'name': 'EU’s AI law needs major changes to prevent discrimination and mass surveillance - European Digital Rights (EDRi)', 'isPartOf': {'@id': 'https://edri.org/#website'}, 'primaryImageOfPage': {'@id': 'https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/#primaryimage'}, 'image': {'@id': 'https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/#primaryimage'}, 'thumbnailUrl': 'https://edri.org/wp-content/uploads/2021/04/AI-PR_Version_2_sharepic.png', 'datePublished': '2021-04-28T12:47:10+00:00', 'dateModified': '2021-05-07T07:24:14+00:00', 'description': 'The European Commission has just launched the its proposed regulation on artificial intelligence (AI). As governments andcompanies continue to use AI in ways that lead to discrimination andsurveillance, the proposed law must go much further to protect peopleand their rights. Here’s a deeper analysis from the EDRi network,including some initial recommendations for change.', 'breadcrumb': {'@id': 'https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/#primaryimage', 'url': 'https://edri.org/wp-content/uploads/2021/04/AI-PR_Version_2_sharepic.png', 'contentUrl': 'https://edri.org/wp-content/uploads/2021/04/AI-PR_Version_2_sharepic.png', 'width': 1200, 'height': 675, 'caption': 'Illustration showing society on a chess board ""supervised"" by oversized ""knights"".'}, {'@type': 'BreadcrumbList', '@id': 'https://edri.org/our-work/eus-ai-law-needs-major-changes-to-prevent-discrimination-and-mass-surveillance/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://edri.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Resources', 'item': 'https://edri.org/our-work/'}, {'@type': 'ListItem', 'position': 3, 'name': 'EU’s AI law needs major changes to prevent discrimination and mass surveillance'}]}, {'@type': 'WebSite', '@id': 'https://edri.org/#website', 'url': 'https://edri.org/', 'name': 'European Digital Rights (EDRi)', 'description': 'Protecting digital rights in Europe.', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://edri.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9pbmR1c3RyaWVzL21ldGFscy1hbmQtbWluaW5nL291ci1pbnNpZ2h0cy9zdWNjZWVkaW5nLWluLXRoZS1haS1zdXBwbHktY2hhaW4tcmV2b2x1dGlvbtIBAA?oc=5,Succeeding in the AI supply-chain revolution - McKinsey,2021-04-30,McKinsey,https://www.mckinsey.com,New technology solutions could be transformative—but only if executives properly prepare their organizations.,N/A,New technology solutions could be transformative—but only if executives properly prepare their organizations.,New technology solutions could be transformative—but only if executives properly prepare their organizations.,https://schema.org,Article,,,https://www.mckinsey.com/~/media/mckinsey/industries/metals%20and%20mining/our%20insights/succeeding%20in%20the%20ai%20supply%20chain%20revolution/suceeding-in-the-ai-1536x1536.jpg,,https://www.mckinsey.com,2021-04-30T00:00:00Z,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,,N/A,N/A,N/A,,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/industries/metals-and-mining/our-insights/succeeding-in-the-ai-supply-chain-revolution'}",2021-04-29T19:04:45Z,2021-04-30T00:00:00Z,Succeeding in the AI supply-chain revolution,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3LnRoZWF0bGFudGljLmNvbS90ZWNobm9sb2d5L2FyY2hpdmUvMjAyMS8wNC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1taXNyZWFkaW5nLWh1bWFuLWVtb3Rpb24vNjE4Njk2L9IBAA?oc=5,Artificial Intelligence Is Misreading Human Emotion - The Atlantic,2021-04-27,The Atlantic,https://www.theatlantic.com,There is no good evidence that facial expressions reveal a person’s feelings. But Big Tech companies want you to believe otherwise.,"Paul Ekman, cards of facial expressions, small number of universal emotions, very early use of a computational metaphor, display of core expressions, Silvan Tomkins, national-security systems, affect recognition, academic work, Technology companies, AI field, such expressions, facial movements, emotional expression, Today affect-recognition tools, person’s face, new theory, use of photography, Charles Darwin’s The Expression, facial recognition, presents.When Ekman, Tomkins’s work, small set of universal emotions, U.S. National Library of Medicine, start-ups, AI emotion-detection tools, young American psychologist, mountainous highlands of Papua New Guinea, neuroscientist Lisa Feldman Barrett, most important role, Ekman’s own words, part of the artificial-intelligence industry, emotional state, Tomkins’s photographs, person’s interior state, Fore people of Okapa, systematic review of the scientific literature, affect-detection systems, facial expression, hand-labeled, biggest tech companies, wider world, particular individual, Western researchers, current technology, deep-learning techniques, AI hiring company HireVue, field of computer vision, facial recognition attempts, Ekman",There is no good evidence that facial expressions reveal a person’s feelings. But Big Tech companies want you to believe otherwise.,N/A,https://schema.org,NewsArticle,Artificial Intelligence Is Misreading Human Emotion,Artificial Intelligence Is Misreading Human Emotion,"[{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'url': 'https://cdn.theatlantic.com/thumbor/yZRA0_fyMYLa5Pbhtu_96QwGK6M=/906x0:1986x1080/1080x1080/media/img/mt/2021/04/1_The_Atlantic_illustration_AI_MASK_Irene_SuosaloStill-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1200}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/Jw4T3Pl0XTz4aXkkkUuyDMXRbow=/249x0:1749x1125/1200x900/media/img/mt/2021/04/1_The_Atlantic_illustration_AI_MASK_Irene_SuosaloStill-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1600}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/FH3DVcfvZVCKSOqZyIhYtqL0HuA=/0x0:2000x1125/1600x900/media/img/mt/2021/04/1_The_Atlantic_illustration_AI_MASK_Irene_SuosaloStill-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 960}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/b8b24mQc6HuKh77mqnlyg30Ak6s=/0x0:2000x1125/960x540/media/img/mt/2021/04/1_The_Atlantic_illustration_AI_MASK_Irene_SuosaloStill-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/xJJ7qA5JcQdMdQCE8xPtItkfUuY=/988x60:1903x975/540x540/media/img/mt/2021/04/1_The_Atlantic_illustration_AI_MASK_Irene_SuosaloStill-1/original.jpg'}]","[{'@type': 'Person', 'name': 'Kate Crawford', 'sameAs': 'https://www.theatlantic.com/author/kate-crawford/'}]",https://www.theatlantic.com/technology/archive/2021/04/artificial-intelligence-misreading-human-emotion/618696/,2021-04-27T16:35:28Z,{'@id': 'https://www.theatlantic.com/#publisher'},,,Technology,N/A,"Irene SuosaloTechnologyArtificial Intelligence Is Misreading Human EmotionThere is no good evidence that facial expressions reveal a person’s feelings. But Big Tech companies want you to believe otherwise.By Kate CrawfordApril 27, 2021ShareSave At a remote outpost in the mountainous highlands of Papua New Guinea, a young American psychologist named Paul Ekman arrived with a collection of flash cards and a new theory. It was 1967, and Ekman had heard that the Fore people of Okapa were so isolated from the wider world that they would be his ideal test subjects.Like Western researchers before him, Ekman had come to Papua New Guinea to extract data from the indigenous community. He was gathering evidence to bolster a controversial hypothesis: that all humans exhibit a small number of universal emotions, or affects, that are innate and the same all over the world. For more than half a century, this claim has remained contentious, disputed among psychologists, anthropologists, and technologists. Nonetheless, it became a seed for a growing market that will be worth an estimated $56 billion by 2024. This is the story of how affect recognition came to be part of the artificial-intelligence industry, and the problems that presents.When Ekman arrived in the tropics of Okapa, he ran experiments to assess how the Fore recognized emotions. Because the Fore had minimal contact with Westerners and mass media, Ekman had theorized that their recognition and display of core expressions would prove that such expressions were universal. His method was simple. He would show them flash cards of facial expressions and see if they described the emotion as he did. In Ekman’s own words, “All I was doing was showing funny pictures.” But Ekman had no training in Fore history, language, culture, or politics. His attempts to conduct his flash-card experiments using translators floundered; he and his subjects were exhausted by the process, which he described as like pulling teeth. Ekman left Papua New Guinea, frustrated by his first attempt at cross-cultural research on emotional expression. But this would be just the beginning.This article is adapted from Crawford’s recent book.Today affect-recognition tools can be found in national-security systems and at airports, in education and hiring start-ups, in software that purports to detect psychiatric illness and policing programs that claim to predict violence. The claim that a person’s interior state can be accurately assessed by analyzing that person’s face is premised on shaky evidence. A 2019 systematic review of the scientific literature on inferring emotions from facial movements, led by the psychologist and neuroscientist Lisa Feldman Barrett, found there is no reliable evidence that you can accurately predict someone’s emotional state in this manner. “It is not possible to confidently infer happiness from a smile, anger from a scowl, or sadness from a frown, as much of current technology tries to do when applying what are mistakenly believed to be the scientific facts,” the study concludes. So why has the idea that there is a small set of universal emotions, readily interpreted from a person’s face, become so accepted in the AI field?To understand that requires tracing the complex history and incentives behind how these ideas developed, long before AI emotion-detection tools were built into the infrastructure of everyday life.The idea of automated affect recognition is as compelling as it is lucrative. Technology companies have captured immense volumes of surface-level imagery of human expressions—including billions of Instagram selfies, Pinterest portraits, TikTok videos, and Flickr photos. Much like facial recognition, affect recognition has become part of the core infrastructure of many platforms, from the biggest tech companies to small start-ups.Whereas facial recognition attempts to identify a particular individual, affect recognition aims to detect and classify emotions by analyzing any face. These systems already influence how people behave and how social institutions operate, despite a lack of substantial scientific evidence that they work. Automated affect-detection systems are now widely deployed, particularly in hiring. The AI hiring company HireVue, which can list Goldman Sachs, Intel, and Unilever among its clients, uses machine learning to infer people’s suitability for a job. In 2014, the company launched its AI system to extract microexpressions, tone of voice, and other variables from video job interviews, which it used to compare job applicants against a company’s top performers. After considerable criticism from scholars and civil-rights groups, it dropped facial analysis in 2021, but kept vocal tone as an assessment criterion. In January 2016, Apple acquired the start-up Emotient, which claimed to have produced software capable of detecting emotions from images of faces. Perhaps the largest of these start-ups is Affectiva, a company based in Boston that emerged from academic work done at MIT.Affectiva has coded a variety of emotion-related applications, primarily using deep-learning techniques. These approaches include detecting distracted and “risky” drivers on roads and measuring consumers’ emotional responses to advertising. The company has built what it calls the world’s largest emotion database, made up of more than 10 million people’s expressions from 87 countries. Its monumental collection of videos was hand-labeled by crowdworkers based primarily in Cairo.Outside the start-up sector, AI giants such as Amazon, Microsoft, and IBM have all designed systems for emotion detection. Microsoft offers perceived emotion detection in its Face API, identifying “anger, contempt, disgust, fear, happiness, neutral, sadness, and surprise,” while Amazon’s Rekognition tool similarly proclaims that it can identify what it characterizes as “all seven emotions” and “measure how these things change over time, such as constructing a timeline of the emotions of an actor.”Emotion-recognition systems share a similar set of blueprints and founding assumptions: that there is a small number of distinct and universal emotional categories, that we involuntarily reveal these emotions on our faces, and that they can be detected by machines. These articles of faith are so accepted in some fields that it can seem strange even to notice them, let alone question them. But if we look at how emotions came to be taxonomized—neatly ordered and labeled—we see that questions lie in wait at every corner.Ekman’s research began with a fortunate encounter with Silvan Tomkins, then an established psychologist at Princeton who had published the first volume of his magnum opus, Affect Imagery Consciousness, in 1962. Tomkins’s work on affect had a huge influence on Ekman, who devoted much of his career to studying its implications. One aspect in particular played an outsize role: the idea that if affects are an innate set of evolutionary responses, they would be universal and thus recognizable across cultures. This desire for universality has an important bearing on why this theory is widely applied in AI emotion-recognition systems today. The theory could be applied everywhere, a simplification of complexity that was easily replicable at scale.In the introduction to Affect Imagery Consciousness, Tomkins framed his theory of biologically based universal affects as one addressing an acute crisis of human sovereignty. He was challenging the development of behaviorism and psychoanalysis, two schools of thought that he believed treated consciousness as a mere by-product that was in service to other forces. He noted that human consciousness had “been challenged and reduced again and again, first by Copernicus”—who displaced man from the center of the universe—“then by Darwin”—whose theory of evolution shattered the idea that humans were created in the image of a Christian God—“and most of all by Freud”—who decentered human consciousness and reason as the driving forces behind our motivations. Tomkins continued, “The paradox of maximal control over nature and minimal control over human nature is in part a derivative of the neglect of the role of consciousness as a control mechanism.” To put it simply, consciousness tells us little about why we feel and act the way we do. This is a crucial claim for all sorts of later applications of affect theory, which stress the inability of humans to recognize both the feeling and the expression of affects. If we as humans are incapable of truly detecting what we are feeling, then perhaps AI systems can do it for us?Tomkins’s theory of affects was his way to address the problem of human motivation. He argued that motivation was governed by two systems: affects and drives. Tomkins proposed that drives tend to be closely associated with immediate biological needs, such as hunger and thirst. They are instrumental; the pain of hunger can be remedied with food. But the primary system governing human motivation and behavior is that of affects, involving positive and negative feelings. Affects, which play the most important role in human motivation, amplify drive signals, but they are much more complex. For example, it is difficult to know the precise causes that lead a baby to cry, expressing the distress-anguish affect.How can we know anything about a system in which the connections between cause and effect, stimulus and response, are so tenuous and uncertain? Tomkins proposed an answer: “The primary affects . . . seem to be innately related in a one-to-one fashion with an organ system which is extraordinarily visible”—namely, the face. He found precedents for this emphasis on facial expression in two works published in the 19th century: Charles Darwin’s The Expression of the Emotions in Man and Animals, from 1872, and an obscure volume by the French neurologist Guillaume-Benjamin-Amand Duchenne de Boulogne from 1862.Tomkins assumed that the facial display of affects was a universal human trait. “Affects,” Tomkins believed, “are sets of muscle, vascular, and glandular responses located in the face and also widely distributed through the body, which generate sensory feedback . . . These organized sets of responses are triggered at subcortical centers where specific ‘programs’ for each distinct affect are stored”—a very early use of a computational metaphor for a human system. But Tomkins acknowledged that the interpretation of affective displays depends on individual, social, and cultural factors. He admitted that there were very different “dialects” of facial language in different societies. Even the forefather of affect research raised the possibility that interpreting facial displays depends on social and cultural context.Given that facial expressions are culturally variable, using them to train machine-learning systems would inevitably mix together all sorts of different contexts, signals, and expectations. The problem for Ekman, and later for the field of computer vision, was how to reconcile these tensions.During the mid-1960s, opportunity knocked at Ekman’s door in the form of a large grant from what is now called the Defense Advanced Research Projects Agency (DARPA), a research arm of the Department of Defense. DARPA’s sizable financial support allowed Ekman to begin his first studies to prove universality in facial expression. In general, these studies followed a design that would be copied in early AI labs. He largely duplicated Tomkins’s methods, even using Tomkins’s photographs to test subjects from Chile, Argentina, Brazil, the United States, and Japan. Subjects were presented with photographs of posed facial expressions, selected by the designers as exemplifying or expressing a particularly “pure” affect, such as fear, surprise, anger, happiness, sadness, and disgust. Subjects were then asked to choose among these affect categories and label the posed image. The analysis measured the degree to which the labels chosen by subjects correlated with those chosen by the designers.From the start, the methodology had problems. Ekman’s forced-choice response format would be later criticized for alerting subjects to the connections that designers had already made between facial expressions and emotions. Further, the fact that these emotions were faked would raise questions about the validity of the results.The idea that interior states can be reliably inferred from external signs has a long history. It stems in part from the history of physiognomy, which was premised on studying a person’s facial features for indications of his character. Aristotle believed that “it is possible to judge men’s character from their physical appearance . . . for it has been assumed that body and soul are affected together.” The Greeks also used physiognomy as an early form of racial classification, applied to “the genus man itself, dividing him into races, in so far as they differ in appearance and in character (for instance Egyptians, Thracians, and Scythians).”Physiognomy in Western culture reached a high point during the 18th and 19th centuries, when it was seen as part of the anatomical sciences. A key figure in this tradition was the Swiss pastor Johann Kaspar Lavater, who wrote Essays on Physiognomy: For the Promotion of Knowledge and the Love of Mankind, originally published in German in 1789. Lavater took the approaches of physiognomy and blended them with the latest scientific knowledge. He believed that bone structure was an underlying connection between physical appearance and character type. If facial expressions were fleeting, skulls seemed to offer a more solid material for physiognomic inferences. Skull measurement was a popular technique in race science, and was used to support nationalism, white supremacy, and xenophobia. This work was infamously elaborated on throughout the 19th century by phrenologists such as Franz Joseph Gall and Johann Gaspar Spurzheim, as well as in scientific criminology through the work of Cesare Lombroso.But it was the French neurologist Duchenne, described by Ekman as a “marvelously gifted observer,” who codified the use of photography and other technical means in the study of human faces. In Mécanisme de la physionomie humaine, Duchenne laid important foundations for both Darwin and Ekman, connecting older ideas from physiognomy and phrenology with more modern investigations into physiology and psychology. He replaced vague assertions about character with a more limited investigation into expression and interior mental and emotional states.Duchenne worked in Paris at the Salpêtrière asylum, which housed up to 5,000 people with a wide range of mental illnesses and neurological conditions. Some would become his subjects for distressing experiments, part of the long tradition of medical and technological experimentation on the most vulnerable, those who cannot refuse. Duchenne, who was little known in the scientific community, decided to develop techniques of electrical shocks to stimulate isolated muscle movements in people’s faces. His aim was to build a more complete anatomical and physiological understanding of the face. Duchenne used these methods to bridge the new psychological science and the much older study of physiognomic signs, or passions. He relied on the latest photographic advancements, such as collodion processing, which allowed for much shorter exposure times, enabling Duchenne to freeze fleeting muscular movements and facial expressions in images.Even at these early stages, the faces were never natural or socially occurring human expressions but simulations produced by the brute application of electricity to the muscles. Regardless, Duchenne believed that the use of photography and other technical systems would transform the squishy business of representation into something objective and evidentiary, more suitable for scientific study. Darwin praised Duchenne’s “magnificent photographs” and included reproductions in his own work.Plates from Mécanisme de la physionomie humaine. (U.S. National Library of Medicine)Ekman would follow Duchenne in placing photography at the center of his experimental practice. He believed that slow-motion photography was essential to his approach, because many facial expressions operate at the limits of human perception. The aim was to find so-called microexpressions—tiny muscle movements in the face.One of Ekman’s ambitious plans in his early research was to codify a system for detecting and analyzing facial expressions. In 1971, he co-published a description of what he called the Facial Affect Scoring Technique (FAST).Relying on posed photographs, the approach used six basic emotional types largely derived from Ekman’s intuitions. But FAST soon ran into problems when other scientists encountered facial expressions not included in its typology. So Ekman decided to ground his next measurement tool in facial musculature, harkening back to Duchenne’s original electroshock studies. Ekman identified roughly 40 distinct muscular contractions on the face and called the basic components of each facial expression an “action unit.” After some testing and validation, Ekman and Wallace Friesen published the Facial Action Coding System (FACS) in 1978; updated editions continue to be widely used.Despite its financial success, FACS was very labor-intensive to use. Ekman wrote that it took 75 to 100 hours to train users in the FACS methodology, and an hour to score a single minute of facial footage. This challenge presented exactly the type of opportunity that the emerging field of computer vision was hungry to take on.As work into the use of computers in affect recognition began to take shape, researchers recognized the need for a collection of standardized images to experiment with. A 1992 National Science Foundation report co-written by Ekman recommended that “a readily accessible, multimedia database shared by the diverse facial research community would be an important resource for the resolution and extension of issues concerning facial understanding.” Within a year, the Department of Defense began funding a program to collect facial photographs. By the end of the decade, machine-learning researchers had started to assemble, label, and make public the data sets that drive much of today’s machine-learning research. Academic labs and companies worked on parallel projects, creating scores of photo databases. For example, researchers in a lab in Sweden created Karolinska Directed Emotional Faces. This database comprises images of individuals portraying posed emotional expressions corresponding to Ekman’s categories. They’ve made their faces into the shapes that accord with six basic emotional states: joy, anger, disgust, sadness, surprise, and fear. When looking at these training sets, it is difficult to not be struck by a sense of pantomime: Incredible surprise! Abundant joy! Paralyzing fear! These subjects are literally making machine-readable emotion.Facial expressions from the Cohn-Kanade data set: joy, anger, disgust, sadness, surprise, and fear. (Courtesy of Jeffrey Cohn)As the field grew in scale and complexity, so did the types of photographs used in affect recognition. Researchers began using the FACS system to label data generated not from posed expressions but rather from spontaneous facial expressions, sometimes gathered outside of laboratory conditions. Ekman’s work had a profound and wide-ranging influence. The New York Times described Ekman as “the world’s most famous face reader,” and Time named him one of the 100 most influential people in the world. He would eventually consult with clients as disparate as the Dalai Lama, the FBI, the CIA, the Secret Service, and the animation studio Pixar, which wanted to create more lifelike renderings of cartoon faces. His ideas became part of popular culture, included in best sellers such as Malcolm Gladwell’s Blink and a television drama, Lie to Me, on which Ekman was a consultant for the lead character’s role, apparently loosely based on him.His business prospered: Ekman sold techniques of deception detection to agencies such as the Transportation Security Administration, which used them to develop the Screening of Passengers by Observation Techniques (SPOT) program. SPOT has been used to monitor air travelers’ facial expressions since the September 11 attacks, in an attempt to “automatically” detect terrorists. The system uses a set of 94 criteria, all of which are allegedly signs of stress, fear, or deception. But looking for these responses means that some groups are immediately disadvantaged. Anyone who is stressed, is uncomfortable under questioning, or has had negative experiences with police and border guards can score higher. This creates its own forms of racial profiling. The SPOT program has been criticized by the Government Accountability Office and civil-liberties groups for its racial bias and lack of scientific methodology. Despite its $900 million price tag, there is no evidence that it has produced clear successes.As Ekman’s fame spread, so did the skepticism of his work, with critiques emerging from a number of fields. An early critic was the cultural anthropologist Margaret Mead, who debated Ekman on the question of the universality of emotions in the late 1960s. Mead was unconvinced by Ekman’s belief in universal, biological determinants of behavior that exist separately from highly conditioned cultural factors.Scientists from different fields joined the chorus over the decades. In more recent years, the psychologists James Russell and José-Miguel Fernández-Dols have shown that the most basic aspects of the science remain uncertain. Perhaps the foremost critic of Ekman’s theory is the historian of science Ruth Leys, who sees a fundamental circularity in Ekman’s method. The posed or simulated photographs he used were assumed to express a set of basic affective states that were, Leys wrote, “already free of cultural influence.” These photographs were then used to elicit labels from different populations to demonstrate the universality of facial expressions. The psychologist and neuroscientist Lisa Feldman Barrett puts it bluntly: “Companies can say whatever they want, but the data are clear. They can detect a scowl, but that’s not the same thing as detecting anger.”More troubling still is that in the field of the study of emotions, researchers have not reached consensus about what an emotion actually is. What emotions are, how they are formulated within us and expressed, what their physiological or neurobiological functions could be, their relation to stimuli—all of this remains stubbornly unsettled. Why, with so many critiques, has the approach of “reading emotions” from a person’s face endured? Since the 1960s, driven by significant Department of Defense funding, multiple systems have been developed that are more and more accurate at measuring facial movements. Ekman’s theory seemed ideal for computer vision because it could be automated at scale. The theory fit what the tools could do.Powerful institutional and corporate investments have been made based on perceived validity of Ekman’s theories and methodologies. Recognizing that emotions are not easily classified, or that they’re not reliably detectable from facial expressions, could undermine an expanding industry. Many machine-learning papers cite Ekman as though these issues are resolved, before directly proceeding into engineering challenges. The more complex issues of context, conditioning, relationality, and culture are often ignored. Ekman himself has said he is concerned about how his ideas are being commercialized, but when he’s written to tech companies asking for evidence that their emotion-recognition programs work, he has received no reply.Instead of trying to build more systems that group expressions into machine-readable categories, we should question the origins of those categories themselves, as well as their social and political consequences. For example, these systems are known to flag the speech affects of women, particularly Black women, differently from those of men. A study conducted at the University of Maryland has shown that some facial recognition software interprets Black faces as having more negative emotions than white faces, specifically registering them as angrier and more contemptuous, even when controlling for their degree of smiling.This is the danger of automating emotion recognition. These tools can take us back to the phrenological past, when spurious claims were used to support existing systems of power. The decades of scientific controversy around inferring emotional states consistently from a person’s face underscores a central point: One-size-fits-all “detection” is not the right approach. Emotions are complicated, and they develop and change in relation to our cultures and histories—all the manifold contexts that live outside the AI frame.But already, job applicants are judged unfairly because their facial expressions or vocal tones don’t match those of other employees. Students are flagged at school because their faces appear angry, and customers are questioned because their facial cues indicate they may be shoplifters. These are the people who will bear the costs of systems that are not just technically imperfect, but based on questionable methodologies. A narrow taxonomy of emotions—grown from Ekman’s initial experiments—is being coded into machine-learning systems as a proxy for the infinite complexity of emotional experience in the world.This article is adapted from Kate Crawford’s recent book, Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence.Kate Crawford is a research professor at USC Annenberg and a senior principal researcher at Microsoft Research. She holds the inaugural Visiting Chair for AI and Justice at the École Normale Supérieure in Paris.",,"{'@type': 'WebPage', '@id': 'https://www.theatlantic.com/technology/archive/2021/04/artificial-intelligence-misreading-human-emotion/618696/'}",,2023-11-13T18:15:32Z,,The Atlantic,en-US,1072-7825,"{'@type': 'SearchAction', 'target': 'https://www.theatlantic.com/search/?q={q}', 'query-input': 'required name=q'}",https://www.theatlantic.com/#publisher,"{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'url': 'https://cdn.theatlantic.com/assets/media/files/atlantic-logo--224x224.png'}","['https://www.facebook.com/TheAtlantic', 'https://twitter.com/theatlantic']",False,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article-content-body'}",Technology,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LnpkbmV0LmNvbS9hcnRpY2xlL2V0aGljcy1vZi1haS10aGUtYmVuZWZpdHMtYW5kLXJpc2tzLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,Ethics of AI: Benefits and risks of artificial intelligence - ZDNet,2021-04-30,ZDNet,https://www.zdnet.com,"Tiernan Ray says AI has always carried the risk of abuses such as bias. The increasing scale of the field, however, in terms of the size of neural network models, the escaping compute budget, and the proliferation of generated content such as fake faces and fake writing, has magnified the ethical issues. Problems can’t simply be engineered-away: at some point, society must re-examine the social contract. Read more: https://zd.net/3xsRj6e",N/A,"The increasing scale of AI -- in terms of the size of neural networks, their energy use, the size of data sets, and the prevalence of the technology in society -- is raising the stakes for major ethical questions.","The increasing scale of AI -- in terms of the size of neural networks, their energy use, the size of data sets, and the prevalence of the technology in society -- is raising the stakes for major ethical questions.",https://schema.org,VideoObject,,,,,,,,,,N/A,N/A,N/A,,,,,,AI’s ethical issues are exacerbated by increasing scale,,,,,,,,,,https://www.zdnet.com/a/img/resize/14b1a6b023d8f4e83b9e30cf8f5c7435ea3ee61e/2021/04/29/c0df2498-b572-4614-ab39-dfa291102684/20210422-tiernan-karen-ai.jpg?auto=webp&fit=crop&height=675&width=1200,2021-04-30T12:00:03.000Z,PT0H5M26S,https://mt-rv-v5.zdnet.com/vr/2021/04/29/1891517507937/20210422_Tiernan_Karen_AI_649757_742.mp4,https://www.zdnet.com/video/share/ais-ethical-issues-are-exacerbated-by-increasing-scale/,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vd3d3LmdvbGZtb250aGx5LmNvbS9nZWFyL2dlYXItYmxvZy9ob3ctYWktaXMtdHJhbnNmb3JtaW5nLWdvbGYtZXF1aXBtZW50LTIyMTQ5MdIBAA?oc=5,How AI Is Transforming Golf Equipment - using artificial intelligence in golf - Golf Monthly,2021-04-26,Golf Monthly,https://www.golfmonthly.com,How AI Is Transforming Golf Equipment - find out how artificial intelligence is being used to design and manufacture golf clubs,N/A,The role of artificial intelligence in golf club design,The role of artificial intelligence in golf club design,https://schema.org,BreadcrumbList,How A.I. Is Transforming Golf Equipment,The role of artificial intelligence in golf club design ,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://cdn.mos.cms.futurecdn.net/d39zjYvYwzjnD4kVwHSn2P.jpg', 'caption': 'How AI Is Transforming Golf Equipment', 'height': '689', 'width': '1225'}","{'@type': 'Person', 'name': 'in partnership with Callaway Golf', 'url': 'https://www.golfmonthly.com/author/in-partnership-with-callaway-golf', 'description': 'Articles created in partnership with Callaway Golf.', 'jobTitle': 'Advertising Partnership', 'email': 'Callawaygolf@fakeemail.com'}",https://www.golfmonthly.com/gear/gear-blog/how-ai-is-transforming-golf-equipment-221491,2021-04-26T08:24:57+00:00,"{'@type': 'Organization', 'name': 'Golf Monthly', 'url': 'https://www.golfmonthly.com', 'logo': {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://cdn.mos.cms.futurecdn.net/flexiimages/qeujzpdn9t1609846280.png', 'caption': 'Golf Monthly logo'}}",,,N/A,N/A,"









Gear


Gear Blog



How A.I. Is Transforming Golf Equipment
The role of artificial intelligence in golf club design 




 



 



 



 




Sign up to Golf Monthly Newsletter
Newsletter






When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works.


















(Image credit: Callaway Golf)






By in partnership with Callaway Golf published 26 April 2021 


Artificial intelligence is changing the way clubs are designed - which is good news for golfers
How A.I. Is Transforming Golf EquipmentEverywhere you look, there's evidence of Artificial Intelligence (A.I.). Computers are becoming increasingly adept at simulating human-like tasks. For example, when you ask Alexa for a weather update ahead of your match, that's A.I. It's clever stuff - and the good news is that it's even being used to help us play better golf.Sponsored LinksSponsored LinksPromoted LinksPromoted LinksCompareCredit2 Cards Charging 0% Interest Until Nearly 2026CompareCreditUndoWe spoke to Dr Alan Hocknell, head of R&D at Callaway, about how and why the company started using A.I., the exciting direction it has taken them and what the future holds.LATEST VIDEOS FROM golfmonthly
Golf Monthly














Why did Callaway start using A.I.?""I was interested in trying to break out of a pattern of thinking too similarly to our competitors, particularly in driver design,"" explained Hocknell.""Take face design, for example. Most faces are thicker in the middle and thinner at the edges, done one way or another, mostly with thin titanium. There was a thread that everybody was edging down the same path and I wanted to have some extra inspiration to think differently.""""We discovered we could take what we had built over the last few years, which is essentially a very accurate simulation capability for the collision between a club and ball, and we could use this large amount of data to try to teach a computer how to think about club design. Perhaps it would come up with some solutions or some design directions that we wouldn't have come up with ourselves?""Get the Golf Monthly NewsletterSubscribe to the Golf Monthly newsletter to stay up to date with all the latest tour news, equipment news, reviews, head-to-heads and buyer’s guides from our team of experienced experts.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.""I think A.I. is this giant ethereal thing that people hear about in all walks of their life, but they don't really know what it is. We're only using the machine learning piece of A.I., but we are doing something a bit unique in turning a lot of A.I. stuff into a physical good."" In the case of Callaway, it is golf clubs that perform better than ever before.""This has led us to hire new staff not from the golf industry that have more specialisation in numerical analysis. We did that on purpose so that they brought that ‘non-golf’ set of thoughts about how to set up the problems correctly for the computer with the type of data that you need to add.""For Callaway's engineers, the aim is to combine these A.I., data-driven design break-throughs with the knowledge they already have about what golfers like to see and feel from their equipment.""If players can see vestiges of their input in the final design, then their desire for that product increases because they have a level of ownership of it,"" Hocknell added.""That feels human whereas A.I. might feel cold and alien because it's generated by a computer, although the computer has been influenced by humans and it's not just like we press a button and the design comes out. But, including people in the feedback loop has genuine impacts on the final design, particularly for Tour players.""Changing The Face Of GolfMany golfers won't concern themselves with what's going on in the clubhead, so long as it's hitting the ball long and straight. However, what makes A.I. so fascinating is how it's transforming the way clubs are being made - and it's playing a significant role in delivering huge performance benefits.Callaway has always been a brand that thinks outside the box, and right from the very beginning it has recognised the importance of investing in R&D. Ever since the days of the Big Bertha, the manufacturer has strived to maximise the amount of ball speed a player can generate.In 2019, it took this to a different level with a new Flash Face, designed by an $8m supercomputer, which used A.I. to cycle through 15,000 face design iterations and over 100 impact simulations.""The computer came back with some face thickness pattern variations that we had never considered before,"" adds Hocknell. ""A lot of the thickness patterns that we were looking at were generally thicker in the middle of the face and thinner at the edges in various forms. But this one came up with a series of thick areas and thin areas.""This illustration shows the ripple design on the back of the Flash Face that promises more ball speed across a larger hitting areaThe 'chosen one' was Epic Flash. Its unique internal mapping consisted of dozens of subtle ripples flowing from heel to toe that worked together to elevate COR in the face's centre region. It was, Hocknell says, an ""aha moment"".Epic Flash won a lot of fans - us included. On that promise of extra ball speed and more distance even on off centre strikes, it delivered. However, Callaway is a brand with a rich heritage in innovation, and it has always looked to push technological boundaries. If A.I. could be used to change the design of club faces, what else could it do?When Callaway upgraded its own supercomputer, we found out just how powerful A.I. could be. It worked its way through thousands more design iterations to deliver a new face for the Mavrik drivers. Flash Face SS20 was thinner than the one used in Epic Flash and, because A.I. had identified an even more powerful design, it needed to be made from a stronger material - an upgraded form of titanium - to withstand the pressure.RELATED: Callaway Mavrik Drivers ReviewUsing A.I. To 'Personalise' ClubsA.I. has played a crucial role in helping golfers to generate extra speed, but it's also taken personalisation to a different level. The Mavrik line-up, released in 2020, includes three distinct head shapes (Standard, Sub Zero and Max), and each head is uniquely optimised for different player types.It wasn't just the driver that benefitted from A.I.'s influence, either. The Mavrik range comprises drivers, fairway woods, hybrids and irons, with each available in three player categories. Here's the crucial part: because each club has a different purpose, it has a different face design. So, each of the heads employs unique A.I.-generated face thickness patterns that vary by model and even by loft to further optimise performance benefits for different types of golfers, hitting different types of shots.For example, with Mavrik's long irons, the faces are crafted for launch and speed, while the mid-irons are shaped for speed and consistency; meanwhile, the short irons are fine-tuned for spin and precision.And just to emphasise how the use of A.I. is spreading into other areas of the design process, it has also helped Callaway engineers redesign the interior of the head, with sound ribs improving the acoustics, something which has delivered better feel, too.RELATED: Callaway Mavrik Irons ReviewNew Epic, More A.I.In the new Epic drivers for 2021, Callaway has used A.I. to influence another of its key speed enhancing technologies - ""Jailbreak"", the structure that joins the crown and sole. With improved stability in the horizontal and torsional direction, the new Speed Frame delivers more ball speed across the face. In fact, in combination with a new Flash Face (SS21) - also the work of A.I. - these are Callaway's fastest ever drivers.""The Jailbreak Speed Frame is a classic example of how A.I. completely changed our thinking,"" Hocknell explains.""The normal design process would be to ask how we could make Jailbreak better. An engineer would say it's very stiff in the vertical direction but it's not so stiff horizontally or torsionally - would stiffness in those extra dimensions help? So we'd go away and build a prototype that was stiffer in those extra dimensions and then test it to see if it worked.""""Instead with A.I., we said to the computer: ""Here's Jailbreak, your design space allows you to change it if you want to with the goal of added ball speed"". A.I. comes back with a design that achieved it. At the end of the day, the computer doesn't know what torsional stiffness is, it just knows math. So it's completely backwards, in a way, we're left to interpret what it has done versus setting out parameters of how the design will change.""The Epic range is comprised of three drivers - Epic Speed, Epic Max and Epic Max LS, whilst there are two fairway wood options. If it's not clear already, there's a model to suit every level of golfer and swing type. And because A.I. has optimised each head for different players, you can also be sure of getting the best possible performance from your Callaway woods.RELATED: Callaway Epic 21 Drivers ReviewWhatever the future holds, A.I. will continue to play a key role in golf club design. It's not a marketing concept - A.I. is affecting the way clubs are designed. Perhaps there will come a time when Callaway's R&D department - there's no danger of the supercomputer replacing the human experts - designs a bespoke face for each of its Tour players depending on their own swing.""There's a whole lot of possibilities out there and we are looking at which ones are most effective for designing the better products we want,"" says Hocknell.""I don't think it's too much of a secret we are using A.I. tools in golf ball design. I can say that in five years time, we'll be thinking differently as an R&D organization and using a different toolset than the one that we've used before.""It feels like this is very much just the beginning. Watch this space.





in partnership with Callaway GolfSocial Links NavigationAdvertising PartnershipArticles created in partnership with Callaway Golf.




CompareCredit2 Cards Charging 0% Interest Until Nearly 2026With no annual fee and no interest until nearly 2026, these cards are helping Americans pay off debt in record time.CompareCredit|SponsoredSponsoredUndoThe One Club Jack Nicklaus Used For 37 Years And All 18 Of His Major VictoriesThe latest incredible stat for Jack Nicklaus reveals he used the same 3-wood for 37 years to include all 18 of his Major championship victoriesGolf MonthlyUndo




































Latest


























'The Golf Game Isn't The Problem, I'm The Problem' - Robert MacIntyre Pinpoints Lightbulb Moments That Sparked Winning Run


Robert MacIntyre has pinpointed the lightbulb moments that helped him eventually win the Scottish Open - and could help him in his bid to double up at The Open


By Paul Higham

Published 2 hours ago
















This Fascinating Scorecard Trend Could Reveal What It Takes To Win The Open Championship...


After looking back through the scorecards of previous Open Championship winners, I discovered an interesting trend that could highlight the route to victory


By Barry Plummer

Published 2 hours ago




















","[{'@type': 'SiteNavigationElement', 'name': 'Amazon Prime Day Golf 2024 - LIVE Updates - Only A Few Hours Remaining!', 'url': 'https://www.golfmonthly.com/news/live/amazon-prime-day-golf-deals-2024-live-updates', '@id': '#trending'}, {'@type': 'SiteNavigationElement', 'name': 'Open Championship Betting Picks', 'url': 'https://www.golfmonthly.com/betting/the-open-championship-betting-2024-expert-tips-and-value-picks', '@id': '#trending'}, {'@type': 'SiteNavigationElement', 'name': 'Tiger Woods Issues Defiant Response To Montgomerie Retirement Comments', 'url': 'https://www.golfmonthly.com/news/tiger-woods-colin-montgomerie-retirement', '@id': '#trending'}, {'@type': 'SiteNavigationElement', 'name': 'Viktor Hovland Reveals Why He Turned Down LIV Golf Move', 'url': 'https://www.golfmonthly.com/news/viktor-hovland-reveals-why-he-turned-down-liv-golf-move', '@id': '#trending'}]",,,2021-04-26T08:24:57+00:00,,How A.I. Is Transforming Golf Equipment,,,,,,,,,Gear Blog,https://cdn.mos.cms.futurecdn.net/d39zjYvYwzjnD4kVwHSn2P-320-80.jpg,,,,,"{'@context': 'https://schema.org', '@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', '/html/head/meta[@name=""description""]/@content']}","{'@type': 'Person', 'name': 'in partnership with Callaway Golf', 'url': 'https://www.golfmonthly.com/author/in-partnership-with-callaway-golf', 'description': 'Articles created in partnership with Callaway Golf.', 'jobTitle': 'Advertising Partnership', 'email': 'Callawaygolf@fakeemail.com'}","[{'@context': 'https://schema.org', '@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.golfmonthly.com/gear', 'name': 'Gear'}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.golfmonthly.com/gear/gear-blog', 'name': 'Gear Blog'}}]",,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vZW50ZXJwcmlzZXJzcHJvamVjdC5jb20vYXJ0aWNsZS8yMDIxLzQvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWktc29sdXRpb25zLTQtcXVlc3Rpb25zLWFza9IBAA?oc=5,Artificial intelligence (AI): 4 questions to ask while choosing solutions - The Enterprisers Project,2021-04-27,The Enterprisers Project,https://enterprisersproject.com,"As AI/ML solutions become more ubiquitous, choose one that will grow with your organization's needs. Consider these key questions",N/A,"As AI/ML solutions become more ubiquitous, choose one that will grow with your organization's needs. Consider these key questions","As AI/ML solutions become more ubiquitous, choose one that will grow with your organization's needs. Consider these key questions",,,,,,,,,,,,N/A,N/A,"
As AI/ML solutions become more ubiquitous, choose one that will grow with your organization's needs. Consider these key questions



          By 

David P. Mariani


April 27, 2021          |
%t min read



















      215 readers like this.  
















Organizations are increasingly using  artificial intelligence (AI) and machine learning (ML) to solve business problems and transform their operations. These technologies are affecting nearly every process across all industries and becoming imperative for competitive edge. 
As AI and ML techniques continue to evolve, so do the requirements of the businesses that use them. When choosing an AI/ML strategy, it is important to ensure that the product roadmaps of your prospective AI/ML vendors align with your business’s future objectives in areas such as AI democratization, augmented analytics in BI, and cloud.
[ Need to speak artificial intelligence? Download our Cheat sheet: AI glossary. ]
Here are a few key questions to consider when choosing an AI/ML strategy and solution:
1. How will your solution save my team time?
There are plenty of  open source tools and solutions out there that you can cobble together to get the job done for little or no cost. If you're going to shell out real money for a data science platform, you need to see tangible ROI. 
Data preparation
Data preparation dominates most data science projects, turning your data scientists into expensive, and often unproductive, data engineers. To counter this, it’s important to choose a platform that makes data acquisition and transformation easy. These data engineering features should be seamlessly integrated into the modeling workflow.
Model selection
Another area ripe for optimization and automation is model selection. The platform should provide access to a variety of models, open source and proprietary, and recommend the best model for the job. 
Feature stores
Feature development is often a time-consuming and error-prone process. Choose a platform that integrates with a variety of ""feature stores,"" like Feast or Uber’s Michelangelo to reduce duplicative work and drive consistency across data science projects and teams. 
[ Want best practices for AI workloads? Get the eBook: Top considerations for building a production-ready AI/ML environment. ]
2. What types of AI use cases work best on your platform?
Typically, there are two main categories of use cases for data science: operational and diagnostic. Most machine learning platform vendors excel at one or the other.
Operational use cases
Let’s start with the operational use case. Developing the best algorithm for displaying the optimal set of products on your homepage is an example of an operational data science use case. In such cases, real-time performance, application and data integration, and CI/CD features are critical. For operational use cases, an expert data scientist or team of data scientists may work for weeks on developing and testing an optimal algorithm. Stability, performance, and accuracy are tantamount to success. These solutions are often long-lived and have a direct impact on a consumer.
Diagnostic use cases
In diagnostic use cases, the requirements are very different. Predicting sales for a particular SKU for an upcoming promotion is an example of a diagnostic use case. In this example, a citizen data scientist would benefit from an AutoML platform to help in model training, selection and visualizing results. These use cases typically involve a single data scientist working over the course of a few days at most. The most important features are automation, agility, and results that are ""good enough."" These use cases are typically one-offs with no customer-facing implications of operational use cases.
Be sure to choose a vendor whose solution best matches your most common use case.
3. How does your platform scale and how does it work in the cloud?
We live in an increasingly cloud-y world, where most of our enterprise data is generated, captured, and stored. 
Cloud-native
It’s essential that your machine learning platform is  cloud-native so you can operate on the data without egress and with elastic scale. However, a cloud-native architecture may not be enough. Many of the public cloud AI/ML solutions operate only in their own cloud, so avoid lock-in by choosing a platform that can work across multiple clouds.
Data platform support

Skip to bottom of list 
More on artificial intelligence

Augmented reality (AR) vs. virtual reality (VR): What’s the difference?
6 misconceptions about AIOps, explained
Cheat sheet: AI glossary
What is AI/ML and why does it matter to your business?
Ebook: Top considerations for building a production-ready AI/ML environment
AI vs. NLP: What are the differences?
What is edge machine learning?




Another major consideration: Where does your data live, and how is it prepared? Choose a data science platform that can operate on a variety of data platforms, including data lakes and data warehouses. Since most of the time in a data science workflow is spent preparing data, the ML platform’s data-wrangling features are critical. This is especially important if your data science team lacks data engineering sophistication, which puts additional pressure on IT to acquire data and thereby limits self-service.
[ Read also: 6 misconceptions about AIOps, explained. ]
4. What level of expertise is required to use your platform?
This question touches on your team’s maturity and skill level when it comes to data integration and machine learning. Are you looking for a solution primarily targeted at the expert data scientist, a citizen data scientist, or both? The answer to this question will determine the style of machine learning platform you can support. 
There’s a clear trend in the market for AI/ML democratization, so choosing a platform that can work for both personas is a good bet.
[ Get exercises and approaches that make disparate teams stronger. Read the digital transformation ebook: Transformation Takes Practice. ]



What to read next



Topics

Enterprise Technology
Artificial Intelligence
Machine Learning







 
David P. Mariani is chief technology officer and founder at AtScale. David is a hands-on technology executive with more than 25 years of experience in delivering Big Data, consumer Internet, internet advertising and hosted services platforms, creating nearly $800M in company exits.More about me






Related content


 

The future of healthcare is in the cloud
 

Cloud computing: 3 business advantages
 

4 ways CIOs are rethinking digital transformation











",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3Lm5ld3lvcmtlci5jb20vY3VsdHVyZS9jdWx0dXJhbC1jb21tZW50L3RoZS1jb21wdXRlcnMtYXJlLWdldHRpbmctYmV0dGVyLWF0LXdyaXRpbmfSAQA?oc=5,"The Computers Are Getting Better at Writing, Thanks to Artificial Intelligence - The New Yorker",2021-04-30,The New Yorker,https://www.newyorker.com,"Steve Marche on Sudowrite, an application that harnesses the artificial-intelligence program GPT-3 to generate text and even mimic the literary style of writers such as Franz Kafka.","['cultural comment', 'annals of technology', 'writing', 'artificial intelligence', 'a.i.', 'technology', 'literature', 'linguistics', 'splitscreenimagerightfullbleed', 'web']","Whatever field you are in, if it uses language, it is about to be transformed.","Whatever field you are in, if it uses language, it is about to be transformed.",https://schema.org/,BreadcrumbList,"The Computers Are Getting Better at Writing, Thanks to Artificial Intelligence","Steve Marche on Sudowrite, an application that harnesses the artificial-intelligence program GPT-3 to generate text and even mimic the literary style of writers such as Franz Kafka.","['https://media.newyorker.com/photos/607742e2871bbfab520aed42/16:9/w_2560,h_1440,c_limit/Marche-AIWriting.jpg', 'https://media.newyorker.com/photos/607742e2871bbfab520aed42/4:3/w_2560,h_1920,c_limit/Marche-AIWriting.jpg', 'https://media.newyorker.com/photos/607742e2871bbfab520aed42/1:1/w_2560,h_2560,c_limit/Marche-AIWriting.jpg']","[{'@type': 'Person', 'name': 'Stephen Marche', 'sameAs': 'https://www.newyorker.com/contributors/stephen-marche'}]",https://www.newyorker.com/culture/cultural-comment/the-computers-are-getting-better-at-writing,2021-04-30T06:00:00.000-04:00,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'The New Yorker', 'logo': {'@type': 'ImageObject', 'url': 'https://www.newyorker.com/verso/static/the-new-yorker/assets/social-image-hub.jpg', 'width': '500px', 'height': '117px'}, 'url': 'https://www.newyorker.com'}","The second section of “The Metamorphosis” continues the story this way:

As soon as Gregor was alone, he began to feel ill. Turning around was an effort. Even breathing was an effort. A thin stream of blood trickled from his flank down his fuzzy belly. He wanted to crawl away from it, but there was no place to go. He lay still on the spot where he had come to rest just in order to get his breath back and to stop the bleeding. “I’m in a bad way,” said Gregor. It had never occurred to him before that he could really become ill. He had seen sick animals—a dove once in a while, which had fallen out of the nestling into the gutter and could not fly any more, or the weak infants of the woman next door who had to be picked up with the tongs and thrown into the dustbin, or the bugs his father used to bring to him when he was still a young boy and which he had liked so much.

Except the second section of “The Metamorphosis” doesn’t begin that way. An artificial-intelligence application called Sudowrite wrote the paragraph above. I inputted the text of the first section of “The Metamorphosis” and then pressed a button called Wormhole. The computer composed the continuation.
Sudowrite uses, as its base, GPT-3, the latest version of a deep-learning neural network that can auto-generate text. The organization that created GPT-3, OpenAI, was founded as a nonprofit with a mission “to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return.” In July of 2019, Microsoft invested a billion dollars, which allowed OpenAI to create a supercomputer with two hundred and eighty-five thousand C.P.U. cores, ten thousand G.P.U.s, and four hundred gigabits per second of network connectivity per server. Microsoft claims that it ranks in the top five supercomputers in the world, processing more than twenty-three thousand teraflops per second. The power of the supercomputer has been transformative. GPT-2, which John Seabrook took for a test drive in 2019, asking it to write an article for The New Yorker, had 1.5 billion parameters. GPT-3 has a hundred and seventy-five billion. (A parameter is a configuration variable required to make a prediction in machine learning.) Brute computational power is why Sudowrite can write like Kafka.
GPT-3 hints at a world in which machines can generate language. The consequences are vertiginous. To spend ten minutes with Sudowrite is to recognize that the undergraduate essay, the basic pedagogical mode of all humanities, will soon be under severe pressure. Take an A paper, change a few words in the first paragraph, push buttons three times, and you have an essay that fits the assignment. Whatever field you are in, if it uses language, it is about to be transformed. The changes that are coming are fundamental to every method of speaking and writing that presently exists.
Amit Gupta is one of the founders of Sudowrite. He left Silicon Valley for a career as a science-fiction writer and found a glorious fusion of the two when GPT-3 appeared. “Other artists have had tools like this for a long time,” he said. “There are really sophisticated tools for visual artists—whether it’s Photoshop or a 3‑D tool, there’s all these things that you can apply. People who are using 3‑D models aren’t using clay. They’re not using the tools of the past. They’re using really advanced tools that automate a lot of the processes. But writing has been stuck in the past. We’re not using paper and pen, but we’re not much better off than that.” Sudowrite accesses GPT-3’s interface and turns it into a legible tool that any writer can use. Currently, Sudowrite is in beta. Gupta imagines the product turning into a resource that writers will pay fifteen to twenty dollars per month to use.
Kafka has a plain style. But Sudowrite is not just for plain styles. In fact, it works better with more distinctive literary styles. In the autumn of 1797, Samuel Taylor Coleridge gave himself an opiate and fell asleep while reading “Purchas’s Pilgrimage.” He woke up after a dream that lasted three hours, in which he believed that he had written between two hundred and three hundred lines. On waking, he began transcribing what he had dreamt.

In Xanadu did Kubla Khan
A stately pleasure-dome decree:
Where Alph, the sacred river, ran
Through caverns measureless to man
Down to a sunless sea.

Unfortunately, Coleridge was interrupted by a “person on business from Porlock,” and, “on his return to his room, found, to his no small surprise and mortification, that though he still retained some vague and dim recollection of the general purport of the vision, yet, with the exception of some eight or ten scattered lines and images, all the rest had passed away like the images on the surface of a stream into which a stone has been cast.” If Coleridge had Sudowrite, he would have typed in what he had and pressed a button.
When I pressed the button asking Sudowrite to continue “Kubla Khan” in an “ominous” style, it generated the following:

The old Moon shook her silver tresses
The new Moon bow’d her golden horns:
While all the stars that round her burn’d,
Bow’d to the ground and based their fires.
    To the one ever-branching cloud
    That blew and drifted—blow and drift;
    To the one moon that alone swung,
    Colossal, glimmering, through the sky;
    I bowed my head and half-believed
A dizzy spell had made me dream.
The tumult ceased, the clouds were torn,
The moon resumed her solemn course,
The stars were faint, the dawn was near,
And faintly from the distant sea
What seemed a misty-white and slender rod,
A phantom-wand, a beam of light,
    It grew and grew to a towering spire,
    A seraph-wand, a sun-bright sail.

I find this beautiful, memorable. If you told me that Coleridge wrote it, I would believe you. The machine even put in the indents.
But what is writing this? Who is writing this? In a sense, Coleridge wrote it. He articulated the pathways of its manufacture. I suppose that I could be the author insofar as I selected the passage and pressed the button. Or, thinking broadly, the author of this passage is the entire corpus of human language processed through GPT-3.
But GPT-3 points to a deeper question: In what way did Coleridge write the original lines of “Kubla Khan”? He himself doubted whether what led him to have the manuscript of “Kubla Khan” in front of him could be called writing. He said he composed it “if that indeed can be called composition in which all the images rose up before him as things, with a parallel production of the correspondent expressions, without any sensation or consciousness of effort.” He considered his own work the vessel of a force outside himself. And this is not an experience unique to him. The oldest poems in the Western tradition, the Iliad and the Odyssey, begin with an invocation to the muse, a plea for a mysterious, unfathomable other to enter the artist, taking over, conjuring language. GPT-3 is a mysterious, unfathomable other, taking over, conjuring language. It is a muse you will be able to access for fifteen to twenty dollars per month.
I wanted to see how another writer would react to Sudowrite. Nathan Englander moved in down the street from me in Toronto, and, during COVID, we’ve been sitting around my back yard in a distanced way, chatting and drinking. He very kindly agreed to an experiment. I took one of my favorites of his stories, “Free Fruit for Young Widows,” about a young boy named Etgar who hears a powerful story of wartime revenge from his father, and put it in Sudowrite. It continued the story this way:

Etgar began having dreams. Not the way people always talk about. Not the way people always say dreams are, like scenes of floating in the sky, or journeys down long spiral staircases into deep caves. Not dreams of falling into a stream or waking lost in the woods. Not the kind of dreams where you see people you missed and can’t remember them. Not like that. Because that is a dream that people talk about, but no one really dreams that way. To the contrary, Etgar’s dreams were more like little flashes—no more than a few seconds each time. With more than that you are already in the world, you are interacting with it, after all, and that’s not me. No, Etgar’s dreams were more like the few seconds before sleep or the few seconds after it, when you too are suspended in between.

At first, I was confused by this continuation from the machine. For one thing, Englander doesn’t write with sentence fragments, but, upon rereading, the content seemed Englander-esque to me. “It’s a shocking and terrifying leap,” he said, when I showed it to him. “Yes, it’s off. But not in the sense that a computer wrote it but in the sense that someone just starting to write fiction wrote it—sloppy but well-meaning. It’s like it has the spark of life to it but just needs to sit down and focus and put the hours in.” Although Englander doesn’t feel the passage is something he would write, he doesn’t hate it, either. “It was like the work of someone aspiring to write,” he said. “Like maybe a well-meaning pre-med student or business student fulfilling a writing requirement because they have to—the work is there, but maybe without some of the hunger. But it definitely feels teachable. I’d totally sit down and have a cup of coffee with the machine. You know, to talk things out.”
Friendliness will not be the typical reaction, I fear. The first reaction to this technology will be dismissal—that the technology isn’t really doing anything much at all, that it isn’t writing, that it’s just a toy. The second reaction will be unease—that the technology is doing too much, that it is writing, that it will replace the human. GPT-3 is a tool. It does not think or feel. It performs instructions in language. The OpenAI people imagine it for “generating news articles, translation, answering questions.” But these are the businessman’s pedantic and vaguely optimistic approaches to the world’s language needs.
For those who choose to use artificial intelligence, it will alter the task of writing. “The writer’s job becomes as an editor almost,” Gupta said. “Your role starts to become deciding what’s good and executing on your taste, not as much the low-level work of pumping out word by word by word. You’re still editing lines and copy and making those words beautiful, but, as you move up in that chain, and you’re executing your taste, you have the potential to do a lot more.” The artist wants to do something with language. The machines will enact it. The intention will be the art, the craft of language an afterthought.
For writers who don’t like writing—which, in my experience, is nearly all of us—Sudowrite may well be a salvation. Just pop in what you have, whatever scraps of notes, and let the machine give you options. There are other, more obvious applications. Sudowrite was relatively effective when I asked it to continue Charles Dickens’s unfinished novel “The Mystery of Edwin Drood.” I assume it will be used by publishers to complete unfinished works like Jane Austen’s “Sanditon” or P. G. Wodehouse’s “Sunset at Blandings.” With a competent technician and an editor-writer you could compose them now, rapidly, with the technology that’s available. There must be a market for a new Austen or Wodehouse. I could do either in a weekend. (Other writers have already tried to write like Austen and Wodehouse, but even excellent examples always feel like contemporary versions of their works. If you used a Wodehouse machine or an Austen machine, it would sound like they sound. The future would not have happened to the algorithm.)
Gupta knows that Sudowrite is only beginning to sense, dimly, the possibilities of GPT-3, never mind the possibilities of artificial intelligence in natural language. GPT-3 is perhaps the Model A of this technology. The above is a small taste of what can be done at a hundred and seventy-five billion parameters. What happens at a trillion? What happens at ten trillion? The human brain has about a hundred trillion parameters. What happens when the technology passes that number? “It’s early days,” Gupta said. “I see a future where it gets super more sophisticated and it helps you realize ideas that you couldn’t realize easily on your own.”
The creative possibilities are exciting and terrifying. Englander didn’t really see the machine as a competitor to himself but almost as a student that he could coax out of weakness. “If it was desperately trying to tell me something about dreams, it would have the juice,” Englander told me. “But this was more like the work of somebody who admires writing but doesn’t need to write. Someone—a living, breathing someone—trying to sound like they think a writer should.”
Already, what GPT-3 shows is that literary style is an algorithm, a complex series of instructions. The reason a passage from Kafka or Coleridge or Englander doesn’t look like math is because the mind isn’t capable of holding a hundred and seventy-five billion parameters at the same time. Very soon, when you read a text you will not be able to assume a person intended or wrote that language. Eventually, this technology will escape the confines of the scientific realm, to those who use language to manipulate and to control, and perhaps even those who use language to express and celebrate.
Meanwhile, there are other avenues of meaning to explore. If you put in the whole of “The Metamorphosis” into Sudowrite, it will compose an extension:

When Mr. Samsa thought about moving house and how they could all pull their way up again, he couldn’t suppress a shiver running down his spine—and this shiver ran down the spine of all three of them, he could see, as if they were collectively possessed and trembling all over with some sort of fever. It was more like a convulsion than a shiver. Then they calmed down, quite exhausted. Mr. Samsa thought: “If we continue like this we’ll soon be having a charwoman in our family. First thing tomorrow I’ll make inquiries about suitable flats”. And then he looked up: the two women were gazing ahead and did not see that he was looking at them. All of a sudden Grete burst out laughing. “What’s that for?”, asked her father. “Well, just because”, replied Grete. And Mr. Samsa did not insist.

But “The Metamorphosis” doesn’t need extension. It’s perfect. It has survived because the core meaning of its story continues to resonate. Gregor is subject to a miracle that is at once a revelation and a catastrophe. The human entity changes once again, in a way that is both magical and degrading.
An earlier version of this post misidentified the name of a function in Sudowrite as well as its proposed cost.",,tags,N/A,"Cultural CommentThe Computers Are Getting Better at WritingWhatever field you are in, if it uses language, it is about to be transformed.By Stephen MarcheApril 30, 2021FacebookXEmailPrintSave StoryIllustration by Charlotte FuSave this storySave this storySave this storySave this storyKafka’s “The Metamorphosis” has a famous opening: “One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.” The rest of the story follows, logically and ludicrously, from that original degrading miracle. Gregor struggles to get out of bed. His mother tells him that it’s time to go to work. His boss, the chief clerk, shows up and demands that he return to the business no matter what shape he’s in. He cannot. Finally, his father, in a fit of furious disgust, tries to beat the vermin-Gregor back into his room. His insect body gets stuck halfway through the door until “his father gave him a hefty shove from behind which released him from where he was held and sent him flying, and heavily bleeding, deep into his room. The door was slammed shut with the stick, then, finally, all was quiet.”The second section of “The Metamorphosis” continues the story this way:AdChoicesAs soon as Gregor was alone, he began to feel ill. Turning around was an effort. Even breathing was an effort. A thin stream of blood trickled from his flank down his fuzzy belly. He wanted to crawl away from it, but there was no place to go. He lay still on the spot where he had come to rest just in order to get his breath back and to stop the bleeding. “I’m in a bad way,” said Gregor. It had never occurred to him before that he could really become ill. He had seen sick animals—a dove once in a while, which had fallen out of the nestling into the gutter and could not fly any more, or the weak infants of the woman next door who had to be picked up with the tongs and thrown into the dustbin, or the bugs his father used to bring to him when he was still a young boy and which he had liked so much.Except the second section of “The Metamorphosis” doesn’t begin that way. An artificial-intelligence application called Sudowrite wrote the paragraph above. I inputted the text of the first section of “The Metamorphosis” and then pressed a button called Wormhole. The computer composed the continuation.Sudowrite uses, as its base, GPT-3, the latest version of a deep-learning neural network that can auto-generate text. The organization that created GPT-3, OpenAI, was founded as a nonprofit with a mission “to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return.” In July of 2019, Microsoft invested a billion dollars, which allowed OpenAI to create a supercomputer with two hundred and eighty-five thousand C.P.U. cores, ten thousand G.P.U.s, and four hundred gigabits per second of network connectivity per server. Microsoft claims that it ranks in the top five supercomputers in the world, processing more than twenty-three thousand teraflops per second. The power of the supercomputer has been transformative. GPT-2, which John Seabrook took for a test drive in 2019, asking it to write an article for The New Yorker, had 1.5 billion parameters. GPT-3 has a hundred and seventy-five billion. (A parameter is a configuration variable required to make a prediction in machine learning.) Brute computational power is why Sudowrite can write like Kafka.GPT-3 hints at a world in which machines can generate language. The consequences are vertiginous. To spend ten minutes with Sudowrite is to recognize that the undergraduate essay, the basic pedagogical mode of all humanities, will soon be under severe pressure. Take an A paper, change a few words in the first paragraph, push buttons three times, and you have an essay that fits the assignment. Whatever field you are in, if it uses language, it is about to be transformed. The changes that are coming are fundamental to every method of speaking and writing that presently exists.Amit Gupta is one of the founders of Sudowrite. He left Silicon Valley for a career as a science-fiction writer and found a glorious fusion of the two when GPT-3 appeared. “Other artists have had tools like this for a long time,” he said. “There are really sophisticated tools for visual artists—whether it’s Photoshop or a 3‑D tool, there’s all these things that you can apply. People who are using 3‑D models aren’t using clay. They’re not using the tools of the past. They’re using really advanced tools that automate a lot of the processes. But writing has been stuck in the past. We’re not using paper and pen, but we’re not much better off than that.” Sudowrite accesses GPT-3’s interface and turns it into a legible tool that any writer can use. Currently, Sudowrite is in beta. Gupta imagines the product turning into a resource that writers will pay fifteen to twenty dollars per month to use.Kafka has a plain style. But Sudowrite is not just for plain styles. In fact, it works better with more distinctive literary styles. In the autumn of 1797, Samuel Taylor Coleridge gave himself an opiate and fell asleep while reading “Purchas’s Pilgrimage.” He woke up after a dream that lasted three hours, in which he believed that he had written between two hundred and three hundred lines. On waking, he began transcribing what he had dreamt.In Xanadu did Kubla KhanA stately pleasure-dome decree:Where Alph, the sacred river, ranThrough caverns measureless to manDown to a sunless sea.Unfortunately, Coleridge was interrupted by a “person on business from Porlock,” and, “on his return to his room, found, to his no small surprise and mortification, that though he still retained some vague and dim recollection of the general purport of the vision, yet, with the exception of some eight or ten scattered lines and images, all the rest had passed away like the images on the surface of a stream into which a stone has been cast.” If Coleridge had Sudowrite, he would have typed in what he had and pressed a button.When I pressed the button asking Sudowrite to continue “Kubla Khan” in an “ominous” style, it generated the following:The old Moon shook her silver tressesThe new Moon bow’d her golden horns:While all the stars that round her burn’d,Bow’d to the ground and based their fires.    To the one ever-branching cloud    That blew and drifted—blow and drift;    To the one moon that alone swung,    Colossal, glimmering, through the sky;    I bowed my head and half-believedA dizzy spell had made me dream.The tumult ceased, the clouds were torn,The moon resumed her solemn course,The stars were faint, the dawn was near,And faintly from the distant seaWhat seemed a misty-white and slender rod,A phantom-wand, a beam of light,    It grew and grew to a towering spire,    A seraph-wand, a sun-bright sail.I find this beautiful, memorable. If you told me that Coleridge wrote it, I would believe you. The machine even put in the indents.But what is writing this? Who is writing this? In a sense, Coleridge wrote it. He articulated the pathways of its manufacture. I suppose that I could be the author insofar as I selected the passage and pressed the button. Or, thinking broadly, the author of this passage is the entire corpus of human language processed through GPT-3.Video From The New YorkerA Trump Speech Written By Artificial IntelligenceBut GPT-3 points to a deeper question: In what way did Coleridge write the original lines of “Kubla Khan”? He himself doubted whether what led him to have the manuscript of “Kubla Khan” in front of him could be called writing. He said he composed it “if that indeed can be called composition in which all the images rose up before him as things, with a parallel production of the correspondent expressions, without any sensation or consciousness of effort.” He considered his own work the vessel of a force outside himself. And this is not an experience unique to him. The oldest poems in the Western tradition, the Iliad and the Odyssey, begin with an invocation to the muse, a plea for a mysterious, unfathomable other to enter the artist, taking over, conjuring language. GPT-3 is a mysterious, unfathomable other, taking over, conjuring language. It is a muse you will be able to access for fifteen to twenty dollars per month.I wanted to see how another writer would react to Sudowrite. Nathan Englander moved in down the street from me in Toronto, and, during COVID, we’ve been sitting around my back yard in a distanced way, chatting and drinking. He very kindly agreed to an experiment. I took one of my favorites of his stories, “Free Fruit for Young Widows,” about a young boy named Etgar who hears a powerful story of wartime revenge from his father, and put it in Sudowrite. It continued the story this way:Etgar began having dreams. Not the way people always talk about. Not the way people always say dreams are, like scenes of floating in the sky, or journeys down long spiral staircases into deep caves. Not dreams of falling into a stream or waking lost in the woods. Not the kind of dreams where you see people you missed and can’t remember them. Not like that. Because that is a dream that people talk about, but no one really dreams that way. To the contrary, Etgar’s dreams were more like little flashes—no more than a few seconds each time. With more than that you are already in the world, you are interacting with it, after all, and that’s not me. No, Etgar’s dreams were more like the few seconds before sleep or the few seconds after it, when you too are suspended in between.At first, I was confused by this continuation from the machine. For one thing, Englander doesn’t write with sentence fragments, but, upon rereading, the content seemed Englander-esque to me. “It’s a shocking and terrifying leap,” he said, when I showed it to him. “Yes, it’s off. But not in the sense that a computer wrote it but in the sense that someone just starting to write fiction wrote it—sloppy but well-meaning. It’s like it has the spark of life to it but just needs to sit down and focus and put the hours in.” Although Englander doesn’t feel the passage is something he would write, he doesn’t hate it, either. “It was like the work of someone aspiring to write,” he said. “Like maybe a well-meaning pre-med student or business student fulfilling a writing requirement because they have to—the work is there, but maybe without some of the hunger. But it definitely feels teachable. I’d totally sit down and have a cup of coffee with the machine. You know, to talk things out.”Friendliness will not be the typical reaction, I fear. The first reaction to this technology will be dismissal—that the technology isn’t really doing anything much at all, that it isn’t writing, that it’s just a toy. The second reaction will be unease—that the technology is doing too much, that it is writing, that it will replace the human. GPT-3 is a tool. It does not think or feel. It performs instructions in language. The OpenAI people imagine it for “generating news articles, translation, answering questions.” But these are the businessman’s pedantic and vaguely optimistic approaches to the world’s language needs.For those who choose to use artificial intelligence, it will alter the task of writing. “The writer’s job becomes as an editor almost,” Gupta said. “Your role starts to become deciding what’s good and executing on your taste, not as much the low-level work of pumping out word by word by word. You’re still editing lines and copy and making those words beautiful, but, as you move up in that chain, and you’re executing your taste, you have the potential to do a lot more.” The artist wants to do something with language. The machines will enact it. The intention will be the art, the craft of language an afterthought.For writers who don’t like writing—which, in my experience, is nearly all of us—Sudowrite may well be a salvation. Just pop in what you have, whatever scraps of notes, and let the machine give you options. There are other, more obvious applications. Sudowrite was relatively effective when I asked it to continue Charles Dickens’s unfinished novel “The Mystery of Edwin Drood.” I assume it will be used by publishers to complete unfinished works like Jane Austen’s “Sanditon” or P. G. Wodehouse’s “Sunset at Blandings.” With a competent technician and an editor-writer you could compose them now, rapidly, with the technology that’s available. There must be a market for a new Austen or Wodehouse. I could do either in a weekend. (Other writers have already tried to write like Austen and Wodehouse, but even excellent examples always feel like contemporary versions of their works. If you used a Wodehouse machine or an Austen machine, it would sound like they sound. The future would not have happened to the algorithm.)Gupta knows that Sudowrite is only beginning to sense, dimly, the possibilities of GPT-3, never mind the possibilities of artificial intelligence in natural language. GPT-3 is perhaps the Model A of this technology. The above is a small taste of what can be done at a hundred and seventy-five billion parameters. What happens at a trillion? What happens at ten trillion? The human brain has about a hundred trillion parameters. What happens when the technology passes that number? “It’s early days,” Gupta said. “I see a future where it gets super more sophisticated and it helps you realize ideas that you couldn’t realize easily on your own.”The creative possibilities are exciting and terrifying. Englander didn’t really see the machine as a competitor to himself but almost as a student that he could coax out of weakness. “If it was desperately trying to tell me something about dreams, it would have the juice,” Englander told me. “But this was more like the work of somebody who admires writing but doesn’t need to write. Someone—a living, breathing someone—trying to sound like they think a writer should.”Already, what GPT-3 shows is that literary style is an algorithm, a complex series of instructions. The reason a passage from Kafka or Coleridge or Englander doesn’t look like math is because the mind isn’t capable of holding a hundred and seventy-five billion parameters at the same time. Very soon, when you read a text you will not be able to assume a person intended or wrote that language. Eventually, this technology will escape the confines of the scientific realm, to those who use language to manipulate and to control, and perhaps even those who use language to express and celebrate.Meanwhile, there are other avenues of meaning to explore. If you put in the whole of “The Metamorphosis” into Sudowrite, it will compose an extension:When Mr. Samsa thought about moving house and how they could all pull their way up again, he couldn’t suppress a shiver running down his spine—and this shiver ran down the spine of all three of them, he could see, as if they were collectively possessed and trembling all over with some sort of fever. It was more like a convulsion than a shiver. Then they calmed down, quite exhausted. Mr. Samsa thought: “If we continue like this we’ll soon be having a charwoman in our family. First thing tomorrow I’ll make inquiries about suitable flats”. And then he looked up: the two women were gazing ahead and did not see that he was looking at them. All of a sudden Grete burst out laughing. “What’s that for?”, asked her father. “Well, just because”, replied Grete. And Mr. Samsa did not insist.But “The Metamorphosis” doesn’t need extension. It’s perfect. It has survived because the core meaning of its story continues to resonate. Gregor is subject to a miracle that is at once a revelation and a catastrophe. The human entity changes once again, in a way that is both magical and degrading.An earlier version of this post misidentified the name of a function in Sudowrite as well as its proposed cost.",,"{'@type': 'WebPage', '@id': 'https://www.newyorker.com/culture/cultural-comment/the-computers-are-getting-better-at-writing'}",,2021-04-30T06:00:00.000-04:00,,,,,,,,,True,,cultural comment,"https://media.newyorker.com/photos/607742e2871bbfab520aed42/1:1/w_2560,h_2560,c_limit/Marche-AIWriting.jpg",,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Culture', 'item': 'https://www.newyorker.com/culture'}, {'@type': 'ListItem', 'position': 2, 'name': 'Writing', 'item': 'https://www.newyorker.com/tag/writing'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Computers Are Getting Better at Writing'}]",,"{'@type': 'CreativeWork', 'name': 'The New Yorker'}",,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vd3d3LnN0YXRuZXdzLmNvbS8yMDIxLzA0LzI2L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFmaWItbWF5by1jbGluaWMv0gEA?oc=5,AI caught a hidden problem in one patient's heart. Can it work for others? - STAT,2021-04-26,STAT,https://www.statnews.com,The AI is performing a task that physicians can't: predicting the risk of atrial fibrillation by analyzing data on hearts beating normally.,"Artificial intelligence,cardiovascular disease,health tech","The more AI begins to look like a miracle for one patient, the more that miracle must be questioned on behalf of all the rest.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"




Health tech 




AI caught a hidden problem in one patient’s heart. Can it work for others? 


 
By Casey Ross April 26, 2021 
Reprints


















































Peter Maercklein poses for a portrait near his home in rural Olmsted County, Minn. An artificial intelligence-enabled tool developed by Mayo Clinic picked up on his atrial fibrillation. 
Joseph Ahlquist for STAT














































Somewhere in Peter Maercklein’s heartbeat was an abnormality no one could find. He survived a stroke 15 years ago, but doctors never saw anything alarming on follow-up electrocardiograms. Then, one day last fall, an artificial intelligence algorithm read his EKGs and spotted something else: a ripple in the calm that indicated an elevated risk of atrial fibrillation.
Specifically, the algorithm, created by physicians at Mayo Clinic, found Maercklein had an 81.49% probability of experiencing A-fib, a quivering or irregular heartbeat that can lead to heart failure and stroke. Just days later, after Maercklein agreed to participate in a research study, a wearable Holter monitor recorded an episode of A-fib while he was walking on a treadmill.advertisement

The finding dramatically altered the course of his care. He was put on a blood thinner and eventually received a pacemaker, interventions that happen too late, or not at all, for hundreds of thousands of people who die every year of untreated heart disease.


STAT+ Exclusive Story
Already have an account? Log in








This article is exclusive to STAT+ subscribers
Unlock this article — and get additional analysis of the technologies disrupting health care — by subscribing to STAT+.
Already have an account? Log in
Already have an account? Log in


Individual plans



Group plans



Monthly
$39
Totals $468 per year
$39/month
Get Started
Totals $468 per year



Starter
$30
for 3 months, then $39/month
$30 for 3 months
Get Started
Then $39/month


Annual
$399
Save 15%
$399/year
Get Started
Save 15%




11+ Users
Custom
Savings start at 25%!
Request A Quote
Request A Quote
Savings start at 25%!



2-10 Users
$300
Annually per user
$300/year
Get Started
$300 Annually per user



View All Plans











						Get unlimited access to award-winning journalism and exclusive events.					
Subscribe


Log In













































About the Author						
Reprints


 
Casey Ross

National Technology Correspondent
Casey Ross covers the use of artificial intelligence in medicine and its underlying questions of safety, fairness, and privacy.



				casey.ross@statnews.com			




				@caseymross			

 


Tags
Artificial intelligence
cardiovascular disease
health tech 




					STAT encourages you to share your voice. We welcome your commentary, criticism, and expertise on our subscriber-only platform, STAT+ Connect




To submit a correction request, please visit our Contact Us page.

","[{'@type': 'NewsArticle', '@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/#article', 'isPartOf': {'@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/'}, 'author': [{'@id': 'https://www.statnews.com/#/schema/person/fa8817cd12456b3ab3691230045efcd9'}], 'headline': 'AI caught a hidden problem in one patient&#8217;s heart. Can it work for others?', 'datePublished': '2021-04-26T08:35:44+00:00', 'dateModified': '2023-07-31T18:47:28+00:00', 'mainEntityOfPage': {'@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/'}, 'wordCount': 2163, 'publisher': {'@id': 'https://www.statnews.com/#organization'}, 'image': {'@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/#primaryimage'}, 'thumbnailUrl': 'https://www.statnews.com/wp-content/uploads/2021/04/042321-PETER-MAERCKLEIN-08812.jpg', 'keywords': ['Artificial intelligence', 'cardiovascular disease', 'health tech'], 'articleSection': ['Health tech'], 'inLanguage': 'en-US', 'isAccessibleForFree': 'False', 'hasPart': {'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.restricted-content-text'}, 'copyrightYear': '2021', 'copyrightHolder': {'@id': 'https://www.statnews.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/', 'url': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/', 'name': ""AI caught a hidden problem in one patient's heart. Can it work for others?"", 'isPartOf': {'@id': 'https://www.statnews.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/#primaryimage'}, 'image': {'@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/#primaryimage'}, 'thumbnailUrl': 'https://www.statnews.com/wp-content/uploads/2021/04/042321-PETER-MAERCKLEIN-08812.jpg', 'datePublished': '2021-04-26T08:35:44+00:00', 'dateModified': '2023-07-31T18:47:28+00:00', 'description': ""The AI is performing a task that physicians can't: predicting the risk of atrial fibrillation by analyzing data on hearts beating normally."", 'breadcrumb': {'@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/#primaryimage', 'url': 'https://www.statnews.com/wp-content/uploads/2021/04/042321-PETER-MAERCKLEIN-08812.jpg', 'contentUrl': 'https://www.statnews.com/wp-content/uploads/2021/04/042321-PETER-MAERCKLEIN-08812.jpg', 'width': 5845, 'height': 3897, 'caption': 'Peter Maercklein poses for a portrait on one of the trails through his property Friday, April 23, 2021, at his home near Eyota, Minn., in rural Olmsted County. While taking part in a research study an artificial intelligence-enabled electrocardiogram picked up on his atrial fibrillation, allowing him to treat it before it caused him heart problems.'}, {'@type': 'BreadcrumbList', '@id': 'https://www.statnews.com/2021/04/26/artificial-intelligence-afib-mayo-clinic/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.statnews.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'AI caught a hidden problem in one patient&#8217;s heart. Can it work for others?'}]}, {'@type': 'WebSite', '@id': 'https://www.statnews.com/#website', 'url': 'https://www.statnews.com/', 'name': 'STAT', 'description': 'Reporting from the frontiers of health and medicine', 'publisher': {'@id': 'https://www.statnews.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.statnews.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.statnews.com/#organization', 'name': 'STAT', 'url': 'https://www.statnews.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.statnews.com/#/schema/logo/image/', 'url': 'https://www.statnews.com/wp-content/uploads/2016/06/Stat_Logo_150.png', 'contentUrl': 'https://www.statnews.com/wp-content/uploads/2016/06/Stat_Logo_150.png', 'width': 150, 'height': 41, 'caption': 'STAT'}, 'image': {'@id': 'https://www.statnews.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/statnews/', 'https://x.com/statnews', 'https://www.linkedin.com/company/stat-news/', 'https://www.youtube.com/channel/UC89FjSf9AT1O2qw6vxrrxDQ', 'https://www.instagram.com/statnews/']}, {'@type': 'Person', '@id': 'https://www.statnews.com/#/schema/person/fa8817cd12456b3ab3691230045efcd9', 'name': 'Casey Ross', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.statnews.com/#/schema/person/image/307b03a67b9f061111f23c65579d539d', 'url': 'https://www.statnews.com/wp-content/uploads/2021/02/casey-r-profile-1-96x96.png', 'contentUrl': 'https://www.statnews.com/wp-content/uploads/2021/02/casey-r-profile-1-96x96.png', 'caption': 'Casey Ross'}, 'description': ""Casey Ross is a national technology correspondent at STAT. His reporting examines the use of artificial intelligence in medicine and its underlying questions of safety, fairness, and privacy. Before joining STAT in 2016, he wrote for the Cleveland Plain Dealer and the Boston Globe, where he worked on the Spotlight Team in 2014 and was a finalist for the Pulitzer Prize. A Vermont native, he now lives in Ohio with his wife and three children. When he's not with them, he's in his cornfield, cultivating some of the sweetest bi-color in the Midwest."", 'sameAs': ['https://x.com/caseymross'], 'url': 'https://www.statnews.com/staff/casey-ross/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiuAFodHRwczovL3d3dy5idXNpbmVzc3dpcmUuY29tL25ld3MvaG9tZS8yMDIxMDQyODAwNTM0Mi9lbi9BdHRhYm90aWNzLVBhcnRuZXJzLVdpdGgtQWx0YU1MLWFuZC1BbWlpLXRvLUJvbHN0ZXItQXJ0aWZpY2lhbC1JbnRlbGxpZ2VuY2UtYW5kLU1hY2hpbmUtTGVhcm5pbmctQ2FwYWJpbGl0aWVzLWZvci1TdXBwbHktQ2hhaW5z0gEA?oc=5,Attabotics Partners With AltaML and Amii to Bolster Artificial Intelligence and Machine Learning Capabilities for Supply ... - Business Wire,2021-04-28,Business Wire,https://www.businesswire.com,Attabotics partners with AltaML and Amii to bolster artificial intelligence and machine learning capabilities for supply chains.,N/A,Attabotics partners with AltaML and Amii to bolster artificial intelligence and machine learning capabilities for supply chains.,Attabotics partners with AltaML and Amii to bolster artificial intelligence and machine learning capabilities for supply chains.,,,,,,,,,,,,N/A,N/A,"




Attabotics Partners With AltaML and Amii to Bolster Artificial Intelligence and Machine Learning Capabilities for Supply Chains




New Collaboration Will Support the Growth of Calgary as an Innovation Hub for Emerging Technologies






April 28, 2021 09:00 AM Eastern Daylight Time



CALGARY, Alberta--(BUSINESS WIRE)--Attabotics, the 3D robotics supply chain company, today announced a partnership with AltaML, a leading Canadian applied artificial intelligence and machine learning company, and the Alberta Machine Intelligence Institute (Amii), one of the world’s preeminent centers of artificial intelligence research and application, to develop capabilities in artificial intelligence (AI) and machine learning (ML) that further optimize efficiency and productivity in Attabotics’ innovative supply chain infrastructure. Together, the three organizations will begin operationalizing the partnership through projects that combine AI technologies with IoT (Internet of Things) infrastructure to achieve more efficient IoT operations, improve human-machine interactions and enhance Attabotics’ data management and capabilities.

“Creating alliances with industry-leading partners is something we’ve put an emphasis on, which is why we’re so grateful to have identified the right partners in AltaML and Amii to help further optimize our platform as we revolutionize the supply chain.”Post this

Requiring 85 percent less space than typical fulfillment warehouses, Attabotics is an entirely new way to store and pick goods in warehouses that is tailor-made to help retailers respond to changing e-commerce demands and empower brands. The company transforms the rows and aisles of a typical warehouse into a single, vertical storage structure that’s modular and scalable, and uses “3D” robots internally to store and retrieve items for box packers on the outside perimeter. Attabotics offers an ideal applied platform to utilize emerging technologies to optimize the supply chain for modern commerce.

Integrating AI technology into the supply chain for transparency, predictive analytics and network optimization is integral as the pandemic has shown that the traditional supply chain doesn’t – and won’t – support modern consumer behavior. Attabotics is building advanced AI/ML capabilities that maximize supply chain system throughput by predictively optimizing fulfillment while minimizing downtime. Attabotics drives these advanced AI models by leveraging IoT data derived from modern cloud based robotic operations. With AltaML and Amii, Attabotics is taking another step toward building out its digitally integrated, distributed network that is optimized for modern commerce.

“We’re excited to work with two world-renowned organizations to build the future of innovation in Canada,” said Scott Gravelle, Attabotics CEO. “Creating alliances with industry-leading partners is something we’ve put an emphasis on, which is why we’re so grateful to have identified the right partners in AltaML and Amii to help further optimize our platform as we revolutionize the supply chain.”

This collaboration draws on the strengths of three Alberta technology leaders to expand the data analytics capabilities for customers. Combining Attabotics’ expertise in warehousing and fulfillment with AltaML’s expertise developing applied AI solutions and Amii’s world-leading research expertise, the collaboration will enable innovation in areas such as maximizing system automation uptime and throughput. This partnership will also support the growth of Calgary and Alberta as an innovation hub and contributes to an ecosystem where technology and innovation continue to thrive.

“AltaML builds and deploys AI-powered software for complex problems, creating new competitive advantage for our partners,” said Nicole Janssen, AltaML co-CEO. “Attabotics has disrupted traditional warehousing, and we are thrilled to work with them, and Amii, to optimize their processes through applied AI. We are already seeing promising results and look forward to many more to come.”

“Amii is thrilled to be part of this one-of-a-kind collaboration bringing together three of Alberta’s leading technology organizations. Together, we’re demonstrating the province’s reputation as a hub for technology and artificial intelligence through the combination of Attabotics’ transformational work in advanced robotics for supply chain, Amii’s leadership and expertise in artificial intelligence research and development and AltaML’s proven record in applying AI to create business impact. This partnership shows the power of public-private partnerships and is further proof of Alberta’s leadership in the research and application of AI,” said Cam Linke, Amii CEO.

About Attabotics

Attabotics is the world’s first 3D robotics supply chain system for modern commerce. Inspired by the framework of ant colonies, Attabotics replaces the rows and aisles of traditional fulfillment centers with a patented storage structure and robotics shuttles that utilize both horizontal and vertical space, reducing a company’s warehouse needs by 85%. By empowering retailers to place fulfillment centers near high-density urban areas, Attabotics helps create jobs and decrease carbon emissions by closing the last-mile delivery gap. Attabotics has been adopted by major brands including luxury department store Nordstrom, and other retailers across apparel, food & beverage, and home goods. Attabotics is based in Calgary, Alberta, Canada, with fulfillment centers across the United States and Canada.

About AltaML

AltaML is an award-winning AI software company driven by a purpose to elevate human potential through applied AI. AltaML works with organizations as an invested partner, bringing its deep AI expertise together with partner domain expertise to create productivity-enhancing solutions to complex problems. AltaML’s customers are primarily enterprise-level organizations undergoing digital transformation and looking for predictive value from their data. In 2020, AltaML was named one of Canada’s Companies-to-Watch in Deloitte’s Technology Fast 50™ awards, was the winner of Start Alberta’s “Most Significant Cross-Community Collaboration of the Year” award for the AltaML Applied AI Lab, and was named a 2020 Responsible AI Award winner by AI Global. AltaML has offices in Edmonton, Calgary and Toronto.

About Amii

One of Canada’s three centres of AI excellence in the Pan-Canadian AI Strategy, Amii (the Alberta Machine Intelligence Institute) is an Alberta-based non-profit institute that supports world-leading research in artificial intelligence and machine learning and translates scientific advancement into industry adoption. Amii grows AI capabilities through advancing leading-edge research, delivering exceptional educational offerings and providing business advice – all with the goal of building in-house AI capabilities. For more information, visit amii.ca.



Contacts

Attabotics 
Jake Tredo
attabotics@moxiegrouppr.com 

AltaML 
Claire Kay
claire@altaml.com 

Amii 
Spencer Murray
spencer.murray@amii.ca 
t: 587-415-6100 ext. 109 c: 780-991-7136




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3Lm1pbGl0YXJ5YWVyb3NwYWNlLmNvbS91bmNyZXdlZC9hcnRpY2xlLzE0MjAyMDQwL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFuZC1tYWNoaW5lLWxlYXJuaW5nLWZvci11bm1hbm5lZC12ZWhpY2xlc9IBAA?oc=5,Artificial intelligence and machine learning for unmanned vehicles - Military & Aerospace Electronics,2021-04-26,Military & Aerospace Electronics,https://www.militaryaerospace.com,"Military experts are developing new enabling technologies to help unmanned aircraft, ground vehicles, submarines, and surface vessels swarm and make decisions without human intervention...",N/A,"Military experts are developing new enabling technologies to help unmanned aircraft, ground vehicles, submarines, and surface vessels swarm and make decisions without human intervention...","Military experts are developing new enabling technologies to help unmanned aircraft, ground vehicles, submarines, and surface vessels swarm and make decisions without human intervention...",https://schema.org,NewsArticle,Artificial intelligence and machine learning for unmanned vehicles,,"['https://img.militaryaerospace.com/files/base/ebm/mae/image/2021/04/2104MAEsr_p01.60831c6ba8727.png?auto=format%2Ccompress&w=320', 'https://img.militaryaerospace.com/files/base/ebm/mae/image/2021/04/2104MAEsr_p02.60831c6b57ede.png?auto=format%2Ccompress&w=320', 'https://img.militaryaerospace.com/files/base/ebm/mae/image/2021/04/2104MAEsr_p03.60831c6a6dbd3.png?auto=format%2Ccompress&w=320', 'https://img.militaryaerospace.com/files/base/ebm/mae/image/2021/04/2104MAEsr_p04.60831c6b12567.png?auto=format%2Ccompress&w=320', 'https://img.militaryaerospace.com/files/base/ebm/mae/image/2021/04/2104MAEsr_p05.60831c6adac07.png?auto=format%2Ccompress&w=320', 'https://img.militaryaerospace.com/files/base/ebm/mae/image/2021/04/2104MAEsr_p06.60831c69ea28a.png?auto=format%2Ccompress&w=320']","[{'@type': 'Person', 'name': 'Jamie Whitney', 'url': 'https://www.militaryaerospace.com/16728552'}]",,2021-04-26,"{'@type': 'Organization', 'name': 'Military Aerospace', 'logo': {'@type': 'ImageObject', 'url': 'https://img.militaryaerospace.com/files/base/ebm/mae/image/website/logos/1642001379640-mae-logo-2.png', 'width': '', 'height': 35}}",,,N/A,N/A,,,"{'@type': 'WebPage', '@id': 'https://www.militaryaerospace.com/uncrewed/article/14202040/artificial-intelligence-and-machine-learning-for-unmanned-vehicles'}",,,,,,,,,,,False,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.paywall'}",,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vd3d3LmZhc3Rjb21wYW55LmNvbS85MDYzMDY1NC9zdGFuZm9yZC1haS1leHBlcnRzLWhlYWx0aGNhcmXSAQA?oc=5,2 Stanford experts say AI won't transform healthcare until the 2030s - Fast Company,2021-04-30,Fast Company,https://www.fastcompany.com,Professors Fei-Fei Li and Andrew Ng are skeptical that we'll see any AI healthcare breakthroughs in the next few years.,N/A,"Is AI going to change healthcare? Yes, but not for a long while.",Professors Fei-Fei Li and Andrew Ng are skeptical that we'll see any AI healthcare breakthroughs in the next few years.,https://schema.org,,,,,,,,,,,N/A,N/A,"Computer scientists have long promised that artificial intelligence could make healthcare work easier for doctors and ultimately better for patients. Around 10 years ago, IBM said its Watson technology would help doctors diagnose and treat patients. But no company has yet come close to delivering on that promise; in fact, according to two leading AI experts, artificial intelligence probably won’t transform healthcare for another decade.“In the tech world, progress tends to happen slowly and then very quickly,” says Andrew Ng, founder of Google Brain, former chief scientist at Baidu, and current adjunct professor at Stanford. “I think we’re still in the progress-is-happening-slowly process in healthcare.”On Thursday, Ng and Fei-Fei Li, codirector of the Stanford Institute for Human-Centered Artificial Intelligence, discussed how they see AI integrating into the healthcare industry at a panel hosted by the institute. Ng said that he doesn’t anticipate major breakthroughs in the next few years. Rather, he hopes to see AI in healthcare “blossom” over the next decade.The Obama administration paved the way for this eventual future by incentivizing healthcare systems to digitize patient health records through the HITECH Act and the Affordable Care Act. But the promise of AI-powered health has not materialized, even though the healthcare industry could certainly use the help. More than 40% of doctors are suffering from burnout, according to a 2021 Medscape survey—and the vast majority of them say they were burned out even before the pandemic. The main agents thrusting them toward exhaustion are bureaucratic tasks, like inputting notes, that often need to be completed in their off time. There are big concerns that pervasive burnout among clinicians could lead to poor outcomes for patients.Some companies, like Nuance AI, which was recently acquired by Microsoft, are developing tools that could potentially write a doctor’s notes for them. But so far, the technology is little more than a transcription service. There are still major hurdles to making technology good enough that it can truly assist doctors in a way that reduces their workload.“We need AI and technology to prove that they make a fundamental human difference to the care, recovery, or the well-being of . . . the patient or to the healthcare worker’s work,” Li said.Healthcare is a high-stakes business. When there are errors in medicine—a missed diagnosis, a wrong medication administered—people can die. Ng says there are multiple barriers to getting artificial intelligence to work inside of healthcare. He says the algorithms need to be better and they need to be tackling the right problems.For instance, when Ng’s researchers test and train their algorithms in Stanford’s hospital using its data and machines, they can prove that the technology is as good as Stanford’s radiologists at spotting various conditions in X-rays. But, he says, there is a gap between this proof of concept and actual in situ use. If a researcher were to take that same algorithm down the street to another hospital where the X-ray technician uses a slightly different imaging protocol, the AI system would perform poorly, because the conditions are not exactly as the ones in which the algorithm was tested.“In contrast, any human radiologist can walk down the street to the other hospital and do just fine,” Ng said.Another problem concerning AI in healthcare is that not all of the necessary data is digitized. Li noted that an important aspect of healthcare that isn’t documented is human behavior, “whether you’re talking about patients living at home with chronic disease and hoping they never have signs of deterioration or you’re talking about doctors carrying out their important procedures, hoping that the protocols are met and there’s no clinical error.”What’s called ambient artificial intelligence, or technology that sits seamlessly in the background of an environment passively collecting data, could play an important role, for instance, in monitoring whether doctors are conducting procedures appropriately. Another possibility: alerting a doctor to a patient in intensive care who’s taken a downturn. But right now, the technology is not there yet.“We need, for example, in radiology, a proven product or proven story that truly has not only helped diagnose patients but also made radiologists work better and collectively moved the needle,” Li said. “We’re inching toward that watershed moment.”Recognize your technological breakthrough by applying to this year’s Next Big Things in Tech Awards! Extended Deadline to Apply: Friday, July 19.","[{'@type': 'Article', '@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare#article', 'isPartOf': {'@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare'}, 'author': [{'@type': 'Person', '@id': 'https://www.fastcompany.com/user/ruth-reader#/schema/person/a5e0ff62be0b08456fc7f1e88812af3d', 'name': 'Ruth Reader', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/ruth-reader#/schema/person/image/2959691ad8a116b68f0ed3f299a69040', 'url': 'https://secure.gravatar.com/avatar/8f9fd4d7ea004ea33654645aefb0129d?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8f9fd4d7ea004ea33654645aefb0129d?s=96&d=mm&r=g', 'caption': 'Ruth Reader'}, 'url': 'https://www.fastcompany.com/user/ruth-reader', 'description': 'Ruth Reader is a writer for <em>Fast Company</em>. She covers the intersection of health and technology.'}], 'headline': '2 Stanford experts say AI won&#8217;t transform healthcare until the 2030s', 'datePublished': '2021-04-30T11:00:04+00:00', 'dateModified': '2021-04-30T00:55:40+00:00', 'mainEntityOfPage': {'@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare'}, 'wordCount': 732, 'publisher': {'@id': 'https://www.fastcompany.com/#organization'}, 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare#primaryimage', 'url': 'https://images.fastcompany.com/image/upload/wp-cms/uploads/2021/04/p-2-in-the-future-of-healthcare-where-does-ai-fit-in.jpg', 'contentUrl': 'https://images.fastcompany.com/image/upload/wp-cms/uploads/2021/04/p-2-in-the-future-of-healthcare-where-does-ai-fit-in.jpg', 'caption': '2 Stanford experts say AI won&#8217;t transform healthcare until the 2030s'}, 'thumbnailUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2021/04/p-2-in-the-future-of-healthcare-where-does-ai-fit-in.jpg', 'keywords': ['ai', 'Andrew Ng', 'fei-fei li', 'health', 'healthcare', 'Stanford'], 'articleSection': ['Tech'], 'inLanguage': 'en-US', 'copyrightYear': '2021', 'copyrightHolder': {'@id': 'https://cms.mansueto.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare', 'url': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare', 'name': ""2 Stanford experts say AI won't transform healthcare until the 2030s - Fast Company"", 'isPartOf': {'@id': 'https://www.fastcompany.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare#primaryimage'}, 'image': {'@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare#primaryimage'}, 'thumbnailUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2021/04/p-2-in-the-future-of-healthcare-where-does-ai-fit-in.jpg', 'datePublished': '2021-04-30T11:00:04+00:00', 'dateModified': '2021-04-30T00:55:40+00:00', 'description': ""Professors Fei-Fei Li and Andrew Ng are skeptical that we'll see any AI healthcare breakthroughs in the next few years."", 'breadcrumb': {'@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare']}], 'author': [{'@type': 'Person', '@id': 'https://www.fastcompany.com/user/ruth-reader#/schema/person/a5e0ff62be0b08456fc7f1e88812af3d', 'name': 'Ruth Reader', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/ruth-reader#/schema/person/image/2959691ad8a116b68f0ed3f299a69040', 'url': 'https://secure.gravatar.com/avatar/8f9fd4d7ea004ea33654645aefb0129d?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8f9fd4d7ea004ea33654645aefb0129d?s=96&d=mm&r=g', 'caption': 'Ruth Reader'}, 'url': 'https://www.fastcompany.com/user/ruth-reader', 'description': 'Ruth Reader is a writer for <em>Fast Company</em>. She covers the intersection of health and technology.'}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare#primaryimage', 'url': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2021/04/p-2-in-the-future-of-healthcare-where-does-ai-fit-in.jpg', 'contentUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2021/04/p-2-in-the-future-of-healthcare-where-does-ai-fit-in.jpg', 'width': 1920, 'height': 1080, 'caption': '[Source photo: Karolina Grabowska/Unsplash]'}, {'@type': 'BreadcrumbList', '@id': 'https://www.fastcompany.com/90630654/stanford-ai-experts-healthcare#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.fastcompany.com'}, {'@type': 'ListItem', 'position': 2, 'name': '2 Stanford experts say AI won&#8217;t transform healthcare until the 2030s'}]}, {'@type': 'WebSite', '@id': 'https://www.fastcompany.com/#website', 'url': 'https://www.fastcompany.com/', 'name': 'Fast Company', 'description': '', 'publisher': {'@id': 'https://www.fastcompany.com/#organization'}, 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.fastcompany.com/#organization', 'name': 'Fast Company', 'url': 'https://www.fastcompany.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/#/schema/logo/image/', 'url': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms-2/2024/03/fc_logo.png', 'contentUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms-2/2024/03/fc_logo.png', 'width': 696, 'height': 696, 'caption': 'Fast Company'}, 'image': {'@id': 'https://www.fastcompany.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/FastCompany/', 'https://x.com/FastCompany', 'https://fastcompany.social/@fastcompany', 'https://www.linkedin.com/company/fast-company/']}, {'@type': 'Person', '@id': 'https://www.fastcompany.com/user/ruth-reader#/schema/person/a5e0ff62be0b08456fc7f1e88812af3d', 'name': 'Ruth Reader', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/ruth-reader#/schema/person/image/2959691ad8a116b68f0ed3f299a69040', 'url': 'https://secure.gravatar.com/avatar/8f9fd4d7ea004ea33654645aefb0129d?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8f9fd4d7ea004ea33654645aefb0129d?s=96&d=mm&r=g', 'caption': 'Ruth Reader'}, 'url': 'https://www.fastcompany.com/user/ruth-reader', 'description': 'Ruth Reader is a writer for <em>Fast Company</em>. She covers the intersection of health and technology.'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vYmxvZ3MuY2hhcG1hbi5lZHUvZ2NpLzIwMjEvMDQvMjYvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLWltcHJvdmVkLWhhcmR3YXJlLWFyY2hpdGVjdHVyZS_SAQA?oc=5,Artificial Intelligence and Improved Hardware Architecture - GCI team aims to redesign the shape of the computer - Chapman University,2021-04-26,Chapman University,https://blogs.chapman.edu,N/A,N/A,"The Grand Challenges Initiative (GCI) is the backbone of the first and second-year experience in the Schmid College of Science and Technology and the Fowler School of Engineering. Although the past year has brought many challenges, GCI teams are continuing to innovate from home. One sophomore team is finding ways to improve computer hardware design",N/A,,,,,,,,,,,,N/A,N/A,"


 




Artificial Intelligence and Improved Hardware Architecture GCI team aims to redesign the shape of the computer
April 26, 2021


The Grand Challenges Initiative (GCI) is the backbone of the first and second-year experience in the Schmid College of Science and Technology and the Fowler School of Engineering. Although the past year has brought many challenges, GCI teams are continuing to innovate from home. One sophomore team is finding ways to improve computer hardware design to accommodate energy-intensive artificial intelligence programs. 
Blake Calvo ’23 (biochemistry and molecular biology), Jack Pauly ’23 (computer science), Ken Baierl ’23 (computer engineering), Patrick Hooverson ’23 (computer science), and Michael Efseaff ’23 (computer science) have always been interested in artificial intelligence. The GCI program gave them the opportunity to explore that interest more in-depth, and the group ultimately decided to focus on hardware aspects of computer design. After finishing literature reviews, the group decided to further narrow their focus to actually redesign the shape of the computer. 
They said, “This worked well for us as all of our group members are adept with computer hardware. Most of our knowledge comes from experience or various YouTube tutorials, but Ken is majoring in computer hardware and that was absolutely a boon for our success. Our group’s current objective stemmed from Michael’s idea to change the structure of the computer itself, opting for an improved design that would maximize the ratio of surface area to used space. This design has since then morphed into what is currently being modeled in the SolidWorks program. Our current objective revolves around finishing the design in this new program and having it fabricated out of high-grade aluminum.” 
All images are taken from an animation depicting an ideal version of their idea modeled and animated by Michael Efseaff ’23.
This image depicts what a single trapezoid may look like, each trapezoid is its own independent computing system, with cooling, power, and is externally covered with a mesh filter grill.
When six trapezoids are brought together it creates a hexagon, the 6 independent computing systems cluster together in order to improve computing power and efficiency. The center is where external cables, like a power cable, would enter and exit.
The cover photo shows the design when six trapezoids are brought together it creates a hexagon, the six independent computing systems cluster together in order to improve computing power and efficiency. The center is where external cables, like a power cable, would enter and exit.
As the group has moved forward with their project, they’ve been surprised to learn how far we are from the type of artificial intelligence seen in science fiction. Despite this, or perhaps because of it, the group continues to feel inspired to address challenges in the current development of AI. They also attribute their enthusiasm for the project to their particular group. Calvo explained, “Having the opportunity to work with a group that is so incredibly smart and motivated to see this project through has not only been exciting but a humbling experience. I look forward to all of my meetings with this group of guys, plus, tackling a challenge without a definite solution has been incredibly stimulating and exciting.” The group is also helped by the support from the GCI program itself. Solidworks, an advanced industry software, is the primary tool the group is using. Funding from GCI lets groups like this one have access to industry tools. 
The group members have expressed that they plan to continue working on this project past the end of their time in GCI. Beyond that, all the group members have diverse career goals, from attending dental school to becoming a high school teacher.
The Team 






				Blake Calvo ’23 (biochemistry and molecular biology)
				




				Jack Pauly ’23 (computer science)
				




				Ken Baierl ’23 (computer engineering)
				




				Michael Efseaff ’23 (computer science)
				




				Patrick Hooverson ’23 (computer science)
				

Blake Calvo’s goal is to enter into dental school and pursue a career in oral and maxillofacial surgery. He is interested in this kind of surgery because it lets him work with patients on a personal level, while also performing surgeries that are complex and challenging. 
Jack Pauly is exploring careers but ultimately would like to combine his major in computer science and programming with his interest in digital design.
Ken Baierl would like to take this project as far as he can, but also wants to directly work on the components of a computer. This GCI team has helped Ken look more into computers and how they can work in different ways using different components. 
Michael Efseaff wants to work in the game industry on either the engineering side or as a product manager. A dream of Michael’s since he was 8 years old has always been to develop a Star Wars game. 
Patrick Hooverson would like to pursue a career in computer science. He also hopes to minor in psychology. As of now, he is thinking he would like to be a high school teacher, teaching math or computer science.




Monroe Roush '21

Browse Related:

Education, Internet, and Technology




 Jotly - Cal Hegstrom, Finley Jackson, Shravan Dhanasekaran, Timothy Pieschala, Owen Glidewell
May 10, 2023




 Financial Literacy Through Stonks - Jack Mazac, Daniel Boudagian, Jason King, Gilberto Arellano, Nikita Dreizin
May 10, 2023




 Ecotasks - An Energy Saving App - Emma Garofalo, Matt Shugarte, Michael Smith, Thomas Kim, Ewan Shen, David Giani
May 10, 2023






Top Keywords:

Grand Challenges Initiative




 Grand Challenges Initiative Showcase 2022 - Congratulations to the 2022 Arthur C. Flint Prize Winner
June 2, 2022




 Welcome New Grand Challenges Initiative Fellows - Meet our newest GCI Fellows!
September 20, 2021




 Study finds hidden conflict in mutually beneficial relationship between legumes and rhizobia - New research from Dr. Kenjiro Quides, a Postdoctoral Teaching and Research Fellow in the Grand Challenges Initiative
April 26, 2021





GCI teams




 Grand Challenges Initiative Showcase 2022 - Congratulations to the 2022 Arthur C. Flint Prize Winner
June 2, 2022




 Tackling the Opioid Crisis - How one GCI team is developing a non-addictive opioid
April 26, 2021





student reseach




 Grand Challenges Initiative Showcase 2022 - Congratulations to the 2022 Arthur C. Flint Prize Winner
June 2, 2022




 Tackling the Opioid Crisis - How one GCI team is developing a non-addictive opioid
April 26, 2021













Share on Twitter





Post to Facebook





 







",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LmdldGFwcC5jb20vcmVzb3VyY2VzL3NjaGVkdWxpbmctb3B0aW1pemF0aW9uLXdpdGgtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,Scheduling Optimization Got You Down? AI for Scheduling is the Way to Go. - GetApp,2021-04-28,GetApp,https://www.getapp.com,Technology such as artificial intelligence is rapidly changing various processes for people working in field services.,N/A,Technology such as artificial intelligence is rapidly changing various processes for people working in field services.,Technology such as artificial intelligence is rapidly changing various processes for people working in field services.,https://schema.org,BreadcrumbList,Scheduling Optimization Got You Down? AI for Scheduling is the Way to Go.,,"{'@type': 'ImageObject', 'url': 'https://images.ctfassets.net/1nw0m35kh5t7/58KMQjblmfg3RNaAiLba2H/54ee021b593926403819c8c07066503d/3-Ways-AI-For-Scheduling-Helps-You-Improve-Field-Services-4-3.jpg'}","[{'@type': 'Person', 'name': 'Ashish Upadhyay', 'url': 'https://www.getapp.com/resources/author/ashish-upadhyay/'}]",https://www.getapp.com/resources/scheduling-optimization-with-artificial-intelligence/,2021-04-28,"{'@type': 'Organization', 'name': 'GetApp', 'logo': {'@type': 'ImageObject', 'url': 'https://images.ctfassets.net/1nw0m35kh5t7/58KMQjblmfg3RNaAiLba2H/54ee021b593926403819c8c07066503d/3-Ways-AI-For-Scheduling-Helps-You-Improve-Field-Services-4-3.jpg'}}",,,N/A,N/A,N/A,,"{'@type': 'WebPage', '@id': 'https://www.getapp.com/resources/scheduling-optimization-with-artificial-intelligence/'}",,2021-10-06,,,,,,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Resources', 'item': 'https://www.getapp.com/resources/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Scheduling Optimization Got You Down? AI for Scheduling is the Way to Go.'}]",,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vaW5kaWFhaS5nb3YuaW4vYXJ0aWNsZS9lbXBhdGhldGljLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Empathetic Artificial Intelligence - INDIAai,2021-04-26,INDIAai,https://indiaai.gov.in,"As much as we want to strongly believe that humans are logical beings and there is nothing more important to logic, we cannot ignore that humans are social creatures. We thrive on empathy. We like to think that we are logical creatures. In truth, our emotions govern a large part of our intelligence.",undefined,"As much as we want to strongly believe that humans are logical beings and there is nothing more important to logic, we cannot ignore that humans are social creatures. We thrive on empathy. We like to think that we are logical creatures. In truth, our emotions govern a large part of our intelligence.","As much as we want to strongly believe that humans are logical beings and there is nothing more important to logic, we cannot ignore that humans are social creatures. We thrive on empathy. We like to think that we are logical creatures. In truth, our emotions govern a large part of our intelligence.",,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vYmVjb21pbmdodW1hbi5haS92YXJpYXRpb25hbC1hdXRvZW5jb2RlcnMtc2ltcGx5LWV4cGxhaW5lZC00NmU2Zjk3OTQ3ZWTSAQA?oc=5,Variational Autoencoders Simply Explained | by Ayan Nair | Becoming Human - Becoming Human: Artificial Intelligence Magazine,2021-04-26,Becoming Human: Artificial Intelligence Magazine,https://becominghuman.ai,"Our ability to draw, write, and innovate is rivalled by no other species. It’s what has allowed us to become as advanced as we are today. But soon, we might not be the only ones with the skill of…",N/A,The idea of creativity is often solely associated with humans.,The idea of creativity is often solely associated with humans.,http://schema.org,NewsArticle,Variational Autoencoders Simply Explained - Becoming Human: Artificial Intelligence Magazine,,['https://miro.medium.com/v2/da:true/resize:fit:1200/0*NfFl6ZOLvm0F-6t7'],"{'@type': 'Person', 'name': 'Ayan Nair', 'url': 'https://ayannair2021.medium.com'}",https://becominghuman.ai/variational-autoencoders-simply-explained-46e6f97947ed,2021-04-26T12:02:39.822Z,"{'@type': 'Organization', 'name': 'Becoming Human: Artificial Intelligence Magazine', 'url': 'becominghuman.ai', 'logo': {'@type': 'ImageObject', 'width': 146, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:292/1*1fYpRTTpKQNa0zuEPe3itg.png'}}",,,N/A,N/A,"Variational Autoencoders Simply ExplainedAyan Nair·FollowPublished inBecoming Human: Artificial Intelligence Magazine·8 min read·Apr 26, 20212291ListenShareArt created by AI! SourceThe idea of creativity is often solely associated with humans.Our ability to draw, write, and innovate is rivalled by no other species. It’s what has allowed us to become as advanced as we are today.But soon, we might not be the only ones with the skill of creativity. Computers are catching up, and they’re catching up fast.Artificial intelligence (AI) has already given computers the ability to play Atari games and write like Shakespeare. They’ve even been able to create their own music and art.Creating art and composing music takes years for many to master. It requires consistent effort and dedication for a human to become skilled at performing such tasks.But computers can learn such skills in hours.It’s remarkable that a computer can learn extremely complex skills in such a short time, but how do they go about doing this? To understand the process, let’s observe how a computer can be taught to create its own handwritten digits.Big Data JobsBehold, the Variational Autoencoder!Imagine conveying the plot of a 500-page fiction novel in ten words. Having to convey so much information in so few words sounds impossible.But computers can perform similar feats relatively easily using variational autoencoders!A variational autoencoder, or a VAE for short, is an AI algorithm with two main purposes — encoding and decoding information. Although it isn’t their primary purpose, they can also generate new information using this encoding and decoding ability (more on this later).When encoding information, the VAE maps large amounts of information to smaller representations. This compressed representation of information is called the latent space of the VAE, as the original information is hidden in this compressed representation.Considering the example of encoding and decoding images of handwritten numbers, the VAE would take in an image of a handwritten number and compress it into a latent space.An example of how an input image would be decoded. The image of the number is 28px x 28px and thus consists of 784 pixels. The VAE can encode all of the information from the 784 pixels in just five numbers. Image created by author.What’s cool about the VAE, though, is its ability to work backwards. It can reconstruct the original input image by observing the latent space. In other words, the VAE decodes the latent space to reconstruct the input.The VAE can recognize the information stored in the latent space and use it to reconstruct the original image. It can thus work backwards. Image created by author.Being able to condense and reconstruct images is super cool, but not easy to do. The VAE has to teach itself how to properly map from an input image to a latent space. Because they’re really good at learning such mappings, we typically train an AI algorithm called a neural network to work as a VAE.A Brief Introduction to Neural NetworksA neural network is really good at identifying patterns from data. It’s typically visualized as a series of interconnected circles called nodes.Sample neural network architecture. SourceEach column of nodes is collectively referred to as a layer. Information usually enters a neural network through the leftmost layer, which is called the input layer.The information then gets passed to the middle layer, or hidden layer. More hidden layers in a neural network allow for the algorithm to learn more complex patterns in the input data.After using the hidden layers to identify these complex patterns, a final output layer returns the neural network’s findings.The way in which the input, output, and hidden layers are arranged is referred to as the neural network’s architecture. Different architectures can allow neural networks to perform different tasks. Because our VAE is created to encode and decode information, it requires a very specific neural network architecture to function.Trending AI Articles:1. Why Corporate AI projects fail?2. How AI Will Power the Next Wave of Healthcare Innovation?3. Machine Learning by Using Regression Model4. Top Data Science Platforms in 2021 Other than KaggleConstructing the VAEThe VAE’s architecture consists of two parts — the encoder and decoder.The encoder is utilized for mapping the input to a latent space, while the decoder maps the latent space back to the original input.Because the decoder is used to reconstruct input information, it’s built as the exact opposite of the encoder. Putting the encoder and decoder together makes the VAE’s signature bowtie-like shape.The architecture of the VAE. The left side layers form the encoder while the right-hand layers are used for the decoder. The latent space rests in between these two parts. SourceHowever, in the VAE, the encoder doesn’t directly map to the latent space. Rather, it first uses the input data to output two quantities called mu (the u symbol) and sigma (the o symbol).Mu and SigmaLet’s say we have two images of the number 7, both of which are fed to the VAE’s encoder. The latent spaces of both of these images should theoretically be similar, as both images contain the number 7.Surprisingly, though, that’s not the case. Visualizing encodings of handwritten number images showcases this phenomenon.The encodings of various images of handwritten digits. Each point represents an encoding of a single image. The color denotes the handwritten number that was in the encoded image. SourceNotice how scattered the encodings of the same numbers are. The points are quite distant from each other.This is bad news for our VAE. The VAE’s encoder should give similar encodings to similar images. By doing this, the VAE’s decoder can more accurately reconstruct the original image from the latent space.If one specific encoding is generated per input image, however, the VAE’s decoder will get overwhelmed. It’s like trying to memorize the exact definitions of a million different words; the decoder cannot possibly learn how to deal with millions of specific encodings — the more general, the better.To ensure that the decoder doesn’t have this problem, the VAE utilizes mu and sigma.Think of mu and sigma as the VAE’s way of creating more general encodings. Utilizing mu and sigma allows for two distinct images of the number 6 to have similar encodings.Two images of the number 6 encoded with mu and sigma. Notice how similar the latent spaces are. With mu and sigma, similar images get similar latent spaces. Image created by author.The generality of the encodings with mu and sigma can be seen when visualizing various latent spaces.The encodings of various images of handwritten numbers. Each dot represents an encoding of a single image. The color denotes what handwritten digit was in the original image. SourceNow, images of the same numbers have encodings that are clustered together. The decoder won’t have to undergo the monumental task of learning how to decode millions of specific encodings.But, unfortunately, the VAE isn’t created with the ability to create a meaningful mu and sigma that can successfully create more general encodings. It can’t even properly decode a latent space. Our VAE needs to train itself to efficiently perform these tasks.Training the VAEEvery AI needs a way to critique itself. This includes our VAE; it cannot improve without knowing how to improve. To understand its mistakes and figure out how to improve itself, an AI uses a mathematical function called the loss function.Thus, our VAE needs a loss function in order to learn how to properly function. It employs a very specific kind of loss function called the reconstruction loss.The original image is encoded into the latent space, which is then decoded to create a reconstructed image. The reconstruction loss measures the difference between the original and reconstructed image. Image created by author.The reconstruction loss measures the difference between an original image and a reconstructed image. A higher reconstruction loss corresponds to a higher lack of quality in the reconstructed image.By aiming to minimize the reconstruction loss, the VAE can understand why its reconstructed images are missing the mark. With this knowledge, the VAE can tweak itself and flawlessly reconstruct input images!Reconstruction loss can be calculated with a formula like the mean squared error, which compares the pixel-for-pixel similarity between the original and reconstructed image. Y corresponds to the input image while ỹ corresponds to the reconstructed image. SourceHowever, the reconstruction loss does not help with learning a better mu and sigma. Improving these quantities requires the use of an additional equation called the Kullback-Leibler Divergence, or KL-Divergence, which is used to learn a mu and sigma that can effectively create more general latent spaces.The formula for the KL-Divergence. Using mu (the u symbol) and sigma (the o symbol), the KL-Divergence can judge the efficacy of the VAE’s current mu and sigma. With the feedback from the KL-Divergence, the VAE tweaks its mu and sigma to get better latent spaces. SourceArmed with the KL-Divergence and the reconstruction loss, the VAE is ready to learn! Here’s what the final training process would look like if we wanted to train a VAE to encode and decode images:The VAE first takes in an input image, which it encodes into a mu and sigma.The mu and sigma are combined to create a latent space.The VAE uses its decoder to reconstruct the input image from the latent space.The reconstruction loss and KL-Divergence are calculated using the reconstructed image, input image, mu, and sigma.Using the reconstruction loss and KL-Divergence values, the VAE slightly tweaks its encoder, decoder, mu, and sigma.This process occurs repeatedly; the VAE encodes and decodes thousands of images, continually improving itself until, eventually, the VAE becomes really good at encoding and decoding images.Generating New Handwritten Numbers With the VAEWhile it may seem that the VAE’s sole purpose is for encoding and decoding data, it can also be used to create new data!Because the VAE is good at decoding general latent spaces, it can actually decode random latent spaces as well. Picking random numbers for a latent space and feeding them to the VAE’s decoder gives some pretty interesting results!An example of the output of a random latent space. Image created by author.The generated image will sometimes be fuzzy or even incomprehensible due to the use of a random latent space. You never know what kind of image the VAE will create!A bunch of different generated images! Some look really clear while others are, well, questionable. Image created by author.With the VAE, computers can begin to create their own handwritten numbers. And this is only the start. VAEs are beginning to express their creativity further, performing feats like creating their own clothes. Computers are becoming increasingly creative, and VAEs are playing a big role in furthering that creativity.Thank you for reading! Be sure to:- Leave a 👏- Check out my implementation of a VAE for creating handwritten digits- Subscribe to my monthly newsletterDon’t forget to give us your 👏 !",,https://becominghuman.ai/variational-autoencoders-simply-explained-46e6f97947ed,2021-04-26T12:02:39.822Z,2022-01-06T23:05:54.587Z,,Variational Autoencoders Simply Explained - Becoming Human: Artificial Intelligence Magazine,,,,,,,,,,,,,,,,['Ayan Nair'],,,,46e6f97947ed,,,
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vcGcuZWR1LnBsL2VuL25ld3MvMjAyMS0wNC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mZW1hbGUtaGFuZHPSAQA?oc=5,Artificial intelligence in female hands | Gdańsk University of Technology - Politechnika Gdańska,2021-04-26,Politechnika Gdańska,https://pg.edu.pl,"Agnieszka Mikołajczyk, a PhD student from the Faculty of Electrical and Control Engineering, conducts research on AI algorithms and their Explainable AI. She is the originator and designer of an application that, if installed on a mobile phone, can diagnose skin nevi in terms of neoplastic changes. ",N/A,"Agnieszka Mikołajczyk, a PhD student from the Faculty of Electrical and Control Engineering, conducts research on AI algorithms and their Explainable AI. She is the originator and designer of an application that, if installed on a mobile phone, can diagnose skin nevi in terms of neoplastic changes. ",N/A,https://schema.org,BreadcrumbList,Artificial intelligence in female hands,,['https://pg.edu.pl/themes/custom/politechnika_gdanska/images/data-types/logo-pl.jpg'],,https://pg.edu.pl/en,2021-04-26 08:26+02:00,,,,N/A,N/A,"








  Date added:
      2021-04-26
  


Artificial intelligence in female hands






 











Agnieszka Mikołajczyk, a PhD student from the Faculty of Electrical and Control Engineering, conducts research on AI algorithms and their Explainable AI. She is the originator and designer of an application that, if installed on a mobile phone, can diagnose skin nevi in terms of neoplastic changes.


Already during her engineering studies, she knew that she wanted to associate her scientific work with social issues. The subject of her engineering thesis was the diagnosis of skin nevi. In this way, an algorithm and an application were created, supported by artificial intelligence, which can be installed on an ordinary computer. The idea turned out to be innovative, and the engineering work was awarded in the ""Innovative Young"" competition organized by the PIAP Industrial Institute for Automation and Measurements.
The artificial intelligence algorithm used in the application was improved by the young researcher during her second-cycle studies - she improved the application and expanded the database, presenting promising results in her master's thesis, which was also awarded in the ""Innovative Youth"" competition and in the competition for the Prof. Romuald Szczęsny’s prize.
During her doctoral studies, Agnieszka Mikołajczyk focused on the so-called ""deep learning"". The aim of this research is the most effective development of neural networks in algorithms. A properly trained network can associate the acquired knowledge and demonstrate the expected results in the analysis of the provided data.
– Initially, I started working on data augmentation methods -says the doctoral student- that is, to put it in simple terms, artificially increasing their quantity. Medical data, which is sensitive data, is always difficult to obtain, especially if we are seeking data from sick patients. Thanks to the photorealistic style transfer method, I obtained 120,000 new photos of skin lesions. Deep learning, which is a subcategory of machine learning, is about creating and training neural networks in such a way that they generate the desired predictions on their own, based on the available data. In this case, on the basis of photos of skin lesions, they were able to recognize whether the nevus was malignant or benign.
However, training the AI algorithm is not easy, as it can take into account such artifacts that humans do not even pay attention to. The key to such training of neural networks is the reliability of the data, undisturbed by any tags that the algorithm may misinterpret. Data bias are the subject of research by the PhD student in a project financed by the Preludium grant from the National Science Center.
Agnieszka Mikołajczyk also eagerly uses her knowledge in other pro-social projects. She works, among others in the non-profit organization Women in Machine Learning & Data Science (WiMLDS)
– The organization aims to support and promote women in the field of artificial intelligence and data science. Together with two friends from WiMLDS, we have created an educational project ""Detect Waste in Pomerania"", which is a response to the problem of environmental pollution.
The aim of the ""Detect Waste in Pomerania"" initiative is to popularize science, the less waste approach, and above all, to educate and support women in their career development in the field of artificial intelligence. Nine participants with experience in Artificial Intelligence and five mentors - experienced machine learning specialists were involved in the project. The project started at the end of October 2020 and ended five months later in March 2021. Its participants are working on creating an artificial intelligence algorithm for the detection of waste (mainly plastic) in the natural environment.
The created algorithm is a pilot solution that in the future may improve, e.g. automating waste recycling, environmental monitoring (automatic search for illegal landfills and automated measurement of the level of environmental pollution), and even minimizing the costs of keeping the city clean.



  122 views






See more



2024-07-15
Almost 455 thousand PLN granted for research on Morse theory




2024-07-11
Gdańsk Tech researchers to develop an innovative technology to remove “forever chemicals” from water and wastewater 




2024-07-09
60 candidates from all over Poland. Talent Scholarships awarded




2024-07-08
NATO at Gdańsk Tech. The University is to become the Alliance's ""Living Lab""




2024-07-08
More than 440 thousand PLN for the university’s internationalization












",,,,2021-04-26 08:36+02:00,,Gdańsk university of technology,,,"{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://pg.edu.pl/search/global?keys={search_term_string}'}, 'query-input': 'required name=search_term_string'}",https://pg.edu.pl,https://pg.edu.pl/themes/custom/politechnika_gdanska/images/data-types/logo-pl.jpg,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': 'https://pg.edu.plhttps://pg.edu.pl/en/news', 'name': 'News'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial intelligence in female hands'}]",,,,"{'@type': 'PostalAddress', 'streetAddress': 'Gabriela Narutowicza 11/12', 'addressLocality': 'Gdańsk', 'addressRegion': 'Pomorskie', 'postalCode': '80-233', 'addressCountry': 'PL'}","{'@type': 'GeoCoordinates', 'latitude': 54.370867, 'longitude': 18.616314290832513}",
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC0xMC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yZXNlYXJjaC1jb21wYW5pZXMtdG8ta25vdy1pbi0yMDIx0gGEAWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS90b3AtMTAtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVzZWFyY2gtY29tcGFuaWVzLXRvLWtub3ctaW4tMjAyMQ?oc=5,Top 10 Artificial Intelligence Research Companies to Know in 2021 - Analytics Insight,2021-04-30,Analytics Insight,https://www.analyticsinsight.net,,"Artificial intelligence,AI companies ,AI applications ,Artificial intelligence technology,AI technology ","The Artificial intelligence culture has taken the world by storm. Famous AI companies namely Google, Apple, Microsoft, etc. work round the clock to discover gro","The Artificial intelligence culture has taken the world by storm. Famous AI companies namely Google, Apple, Microsoft, etc. work round the clock to discover gro",http://schema.org,NewsArticle,Top 10 Artificial Intelligence Research Companies to Know in 2021,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/AI-research-centers.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Disha Ganguli', 'name': 'Disha Ganguli', 'url': 'https://www.analyticsinsight.net/author/disha-ganguli'}]",https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-research-companies-to-know-in-2021,2021-04-30T23:30:03Z,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","The Artificial intelligence culture has taken the world by storm. Famous AI companies namely Google, Apple, Microsoft, etc. work round the clock to discover ground-breaking innovations and prospects that AI has under its wings..AI technology has spearheaded in almost every sector possible. Healthcare and Education sector have benefitted the most from it. AI research, for several reasons, have gained importance over the decades. Laboratories are crowded with scientists and experts who indulge into breakthrough researches..The AI industry has known to have broken strong records in which artificial intelligence start-ups have raised around $33 million in the previous year, 2020. This is reflective of the ongoing nature of the artificial intelligence technology and industry on a whole that refused to succumb to the many consequences of the pandemic..TOP 5 ARTIFICIAL INTELLIGENCE COMPANIES WITH MARKET SHARETOP AI COMPANIES IN THE WORLD CREATING MASSIVE DISRUPTIONTOP 10 AI COMPANIES REDEFINING THE WORLD OF RETAIL.This article talks about 10 most amazing companies are making phenomenal breakthroughs by extensive AI research and weaving new prospects on AI applications. Lay below a list of few:.1. Ascent.Industry- Fintech.Ascent is a Chicago-based company that specialises in automating and managing compliance programs for financial firms. It has its dealings with those financial firms that are supported by cloud technology and artificial intelligence that ensure to keep programs powerful and safe at even times of crises. The cloud solutions of this company are strong enough to deal with real-time problems by devising out real-time solutions..2. Riskified.Industry: E-commerce.Based in New York, Riskified is driven by Artificial intelligence to aid e-commerce sites to filter its authentic customers and reducing rough operations, thereby creating a seamless customer experience. With an intense AI research, Riskified has now evolved to produce scalable solutions for its clients to make instant real-time decisions to keep frauds at bay..3. Cylance.Industry: Cybersecurity.Cylance is a cybersecurity company that understands the needs of incorporating cybersecurity measures in business organisations and sectors as cyber attacks continue to grow. Performing intense research on AI, machine learning, and algorithmic science to understand the nuances of these technologies, the company directs them towards fulfilling ethical purposes and sharpening the performances of cybersecurity tools and technologies..4. Moveworks.Industry: Information and Technology.Moveworks specialises in offering customer service interface. The customer service interface draws the support of artificial intelligence and deep learning to solve IT report issues. Moveworks works for supporting start-ups that often go hay wire in managing logistical functions. The services provided by Moveworks makes sure to curtail strain on IT professionals and carrying out tasks on time..5. Grammarly.Industry- Education, Productivity and Writing.How many of you were aware of the fact that Grammarly too is standing on the shoulders of AI? Grammarly is a software, running with the support of AI. An application indispensable for writers, researchers and the student body, Grammarly helps them with spelling and grammar. With its unique AI integrations, it catches grammatical errors and spellings within seconds after reading the document. Grammarly is striving to enhance its AI tools to increase the productivity of its subscribers..6. Tempus.Industry- Healthcare, Biotech, Big Data.Located in Chicago, Illinois, Tempus is operating vehemently in the healthcare sector. With the backing of artificial intelligence, Tempus works at providing precision medicine, which means that medicines and treatments are customised according to the healthcare needs of an individual. Tempus, in recent days, is focusing on AI research to unearth cancer break throughs..7. Datarobot.Industry- software and big data.Understanding the importance of machine learning and artificial intelligence for business bodies, DataRobot works to deliver best AI and ML services that predict the best possible solutions for challenges by designing innovative models..8. Narrative science.Industry- Big Data.It specialises in creating Natural Language Generation models that translates data into stories that are easy to comprehend as raw data itself is quite complicated. Knowing that storytelling is an art, it creates stories out of data that contain all the insights, help businesses to be prudent in their undertakings..9. Alphasense.Industry- Fintech.Alphasense is a rising fintech company that runs itself on AI powered measures to aid Fortune 500 companies and big business organisations..10. ClariFai.Industry- Software.ClariFai, the platform, specialises in image recognition that helps its clients to make a seamless and effortless experience of their media. It deals with the organisation of images and videos using intelligent technology..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,N/A,N/A,What is AI and Data Science Engineering? ,,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-research-companies-to-know-in-2021'}",2021-04-30T23:30:03Z,2021-04-30T23:30:03Z,,Top 10 Artificial Intelligence Research Companies to Know in 2021,,,,,,,,,Artificial Intelligence,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/AI-research-centers.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 10 Artificial Intelligence Research Companies to Know in 2021', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-research-companies-to-know-in-2021'}]",,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-research-companies-to-know-in-2021', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/AI-research-centers.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3R5cGVzLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXdlYWstc3Ryb25nLWFuZC1zdXBlci1hadIBfGh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS90eXBlcy1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS13ZWFrLXN0cm9uZy1hbmQtc3VwZXItYWk?oc=5,"Types of Artificial Intelligence – Weak, Strong and Super AI - Analytics Insight",2021-04-29,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,artificial intelligence types,future of AI,different types of artificial intelligence,3 types of artificial intelligence",It's crucial to consider the different forms of Artificial Intelligence in order to predict how they'll grow in the future. Artificial intelligence (AI) is alre,It's crucial to consider the different forms of Artificial Intelligence in order to predict how they'll grow in the future. Artificial intelligence (AI) is alre,http://schema.org,NewsArticle,"Types of Artificial Intelligence – Weak, Strong and Super AI",,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-18.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Monomita Chakraborty', 'name': 'Monomita Chakraborty', 'url': 'https://www.analyticsinsight.net/author/monomita-chakraborty'}]",https://www.analyticsinsight.net/artificial-intelligence/types-of-artificial-intelligence-weak-strong-and-super-ai,2021-04-29T03:35:14Z,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","It's crucial to consider the different forms of Artificial Intelligence in order to predict how they'll grow in the future..Artificial intelligence (AI) is already having a huge impact on our lives, making it critical to remain ahead of the game. When AI continues to take on more human-like elements of perception, the forms of artificial intelligence are a way to envision what the future of AI could look like. It's crucial to consider the different forms of AI in order to predict how they'll grow in the future. Keep reading to learn more about the various types of artificial intelligence..TOP 10 ARTIFICIAL INTELLIGENCE RECRUITERS IN INDIA TO KEEP AN EYE ON IN 2021TOP 25 HOTTEST ARTIFICIAL INTELLIGENCE STARTUPS TO WORK IN INDIAARTIFICIAL INTELLIGENCE IN MIGRATION: ITS POSITIVE AND NEGATIVE IMPLICATIONS.Weak AI.The most common type of AI today is weak AI. Weak AI is sweeping the globe, from smartphone apps to the Internet to big data analytics..The name comes from the fact that these artificial intelligence systems are specifically designed to perform one mission. They are also known as 'Narrow AI' because of their limited approach and inability to perform tasks other than those assigned to them. This narrows their intelligence to a single task or group of tasks, enabling for more tweaking and optimization..Strong AI.Artificial general intelligence (AGI), also known as strong AI or deep AI, refers to the idea of a machine with general intelligence that can learn and apply its intelligence to solve every problem. In any given case, AGI can think, comprehend, and behave in a manner that is distinct from that of a person..Strong AI employs a philosophy of mind AI framework, which is defined as the ability to perceive other intelligent entities' desires, feelings, values, and thought processes. Even so, due to recent advances in nanotechnology, Strong AI, which is still in its infancy, holds a lot of promise. Moreover, Strong AI is being considered as a potential application for the development of an artificial neural network that can act as a proper human being..Super AI.As per a report, according to University of Oxford scholar and AI expert Nick Bostrom, when AI becomes much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills, we've achieved Artificial Super Intelligence..Artificial Super Intelligence (ASI) can outperform human intelligence in all areas, including innovation, general intelligence, and problem-solving. Machines would be able to demonstrate knowledge previously only seen in the best of us. This is the kind of AI that many people are concerned about, and the kind of AI that Elon Musk believes will lead to humanity's extinction..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,N/A,N/A,What is AI and Data Science Engineering? ,,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/types-of-artificial-intelligence-weak-strong-and-super-ai'}",2021-04-29T03:35:14Z,2021-04-29T03:35:14Z,,"Types of Artificial Intelligence – Weak, Strong and Super AI",,,,,,,,,Artificial Intelligence,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-18.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Types of Artificial Intelligence – Weak, Strong and Super AI', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/types-of-artificial-intelligence-weak-strong-and-super-ai'}]",,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/types-of-artificial-intelligence-weak-strong-and-super-ai', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-18.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC0yNS1ob3R0ZXN0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXN0YXJ0dXBzLXRvLXdvcmstaW4taW5kaWHSAYMBaHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC0yNS1ob3R0ZXN0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXN0YXJ0dXBzLXRvLXdvcmstaW4taW5kaWE?oc=5,Top 25 Hottest Artificial Intelligence Startups to Work in India - Analytics Insight,2021-04-27,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence startups in India,Artificial Intelligence ,Artificial Intelligence startups ,AI startups in India,artificial intelligence companies",Today all eyes are on India because the number of Artificial Intelligence startups in the country has exploded in recent years. Artificial Intelligence (AI) is ,Today all eyes are on India because the number of Artificial Intelligence startups in the country has exploded in recent years. Artificial Intelligence (AI) is ,http://schema.org,NewsArticle,Top 25 Hottest Artificial Intelligence Startups to Work in India,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-17.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Monomita Chakraborty', 'name': 'Monomita Chakraborty', 'url': 'https://www.analyticsinsight.net/author/monomita-chakraborty'}]",https://www.analyticsinsight.net/artificial-intelligence/top-25-hottest-artificial-intelligence-startups-to-work-in-india,2021-04-27T07:05:33Z,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","Today all eyes are on India because the number of Artificial Intelligence startups in the country has exploded in recent years..Artificial Intelligence (AI) is the latest buzzword that is bringing all of the company's focus to a whole new level across domains. Globally, all eyes are on India because the number of AI startups in the country has exploded in recent years, resulting in fierce competition in the marketplace to give the right technology..A LOOK AT 5 AI STARTUPS EMPOWERING DEFENCE AND SECURITY INDUSTRYTOP 15 GLOBALLY RENOWNED EMOTIONAL ARTIFICIAL INTELLIGENCE STARTUPSHOW CAN STARTUPS GET TO GRIPS WITH AI FOR THE FIRST TIME?.Following are the top 25 hottest artificial intelligence start-ups to work in India:.Intello Labs.Intello Labs has developed a framework for agricultural commodity grading and quality control using artificial intelligence techniques such as computer vision and deep learning. Intello Labs offers a mobile app-based image-based solution that helps add clarity and standardization to quality assessment, lowering value risk and wastage in agriculture supply chains..Discovery AI .Discovery AI is on a quest to use best of breed Artificial Intelligence (AI) and Natural Language Processing (NLP) technologies to help businesses increase sales, cut costs, and boost productivity. Discovery AI is developing an enterprise-ready conversational AI network to boost app adoption and cut down on service calls..Vernacular.ai .Vernacular.ai seeks to increase the efficiency of call center operations by using a voice AI platform to simplify the process of delivering customer service assistance..Doxper .Doxper assists doctors, hospitals, and patients. It enhances the doctor-patient relationship. Doxper aims to make data storage and retrieval simple, as well as automate patient follow-ups and data transcription..HyperVerge.NEA, Milliways Ventures, and Naya Ventures have invested in HyperVerge, Inc., a deep-learning startup based in Silicon Valley. HyperVerge has created patent-pending applications for real-time image and video processing from satellites, surveillance cameras, industrial cameras, and documents..CropIn.CropIn is a self-evolving, intuitive framework that provides future-ready farming solutions to the whole agricultural industry. The firm provides agribusinesses with decision-making tools that ensure accuracy, dependability, and long-term viability..Uniphore .Uniphore is a multinational AI technology conversational company offering the customer service platform driven by AI and automation technologies. The company's mission is to use voice to fill the gap between people and machines..Bash.ai.Businesses can use Bash.ai's chatbot software to handle their employee service portals. The bot analyses employee queries using AI and NLP, then uses rule-based algorithms to extract the most valid response and display it to the employee..Avaamo.Avaamo, a venture-funded enterprise software company, aims to use conversational AI to revolutionist the way we interact, transact, and operate. Avaamo's main product is a framework that integrates AI, machine learning, conversation design, and integration with legacy business workflows..SigTuple .SigTuple creates intelligent screening applications that use AI to analyze visual medical data to assist diagnosis. The company is developing Manthana, an artificial intelligence (AI) platform that will aid in the efficient analysis of visual medical data..LogiNext .LogiNext is a world's leading enterprise SaaS company that optimizes field service and logistics movements leveraging data analytics and machine learning algorithms all over the world..My Ally .My Ally is a groundbreaking B2B SaaS organization that uses artificial intelligence to improve recruitment. Their AI assistant Alex handles scheduling and coordination, allowing the talent team to concentrate on more difficult tasks..Salesken AI .Salesken AI is a group of technologists and training experts who have teamed up to apply the best of AI and data science to sales success. With their conversation AI software that evaluates interactions and provides cues or nudges to sales reps in real-time, allowing them to achieve better results..Teric Soft .Teric Soft provides web development, Android/iOS development, and AI solutions, among other services. Teric AI, for example, provides image annotations and data management, transforming images into high-quality training data..RayReach Technologies Pvt. Ltd..RayReach Technologies focuses on providing AI and Machine Learning (ML) solutions in the fields of Predictive Analytics, Prescriptive, and Automated Prescriptive. Revenue Predictions, Sales Predictions, HR Attrition Models, Service Management cases such as Predicting Major Incidents, Predicting SLA Breaches, and many others are among the models developed by the company..Artivatic Data Labs .Artivatic Data Labs is an end-to-end AI infrastructure framework based on deep-tech, machine learning (ML) technologies and in-depth analogies of genomic science, psychology, and neuroscience. It enables large corporations, entrepreneurs, and developers to create and implement intelligent products and solutions without the need for extensive growth..IN-D .IN-D creates an AI-powered platform for digital operations that are location-agnostic, agile, and low-cost. It encourages document processing using AI-based knowledge extraction for structured and unstructured data, regardless of template..Innefu .Innefu Labs is a company that specializes in IT security solutions for the banking and financial services industries. Its artificial intelligence technology offers biometrics authentication and multi-factor authentication methods, as well as data analysis to anticipate and avoid virtual threats..Attentive AI .Attentive AI creates artificially intelligent systems that process petabytes of geospatial imagery and transform it into useful information. The company provides 2D and 3D vector data derived from satellite, aerial, street, and drone imagery to geospatial technology providers and end users..Expertrons .Expertrons is the world's first AI network with video bots of experts sharing their knowledge securing a dream job, internship, or maybe even a B-school. Potential candidates can be linked to AI-recommended experts and employed as a result of a referral..WotNot .WotNot is a chatbot development platform that allows users to create intelligent, interactive, and customized bots for a business. It aids companies in generating more leads, scaling their funding, and so on..Rubique.Rubique, a fintech company, simplifies complex lending processes and empowers individuals and small businesses by offering quick and easy access to credit through a variety of credit cards and loan items, making finance simple for them..Niki.ai.Niki.ai is a virtual agent that completes end-to-end online transactions in a variety of domains on your behalf. Niki is your one-stop destination for anything from postpaid recharges to hotel reservations..Qure.ai .Qure.ai seeks to make healthcare more available and affordable by using artificial intelligence. Deep learning experience is combined with clinical, science, and regulatory knowledge by the company's core team..Ishitva Robotics Systems .Ishitva Robotics Systems seeks to fix real-world waste problems by developing effective solutions using Industry 4.0 technologies such as Artificial Intelligence, Machine Learning, and the Internet of Things..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,N/A,N/A,What is AI and Data Science Engineering? ,,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/top-25-hottest-artificial-intelligence-startups-to-work-in-india'}",2021-04-27T07:05:33Z,2021-04-27T07:05:33Z,,Top 25 Hottest Artificial Intelligence Startups to Work in India,,,,,,,,,Artificial Intelligence,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-17.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 25 Hottest Artificial Intelligence Startups to Work in India', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/top-25-hottest-artificial-intelligence-startups-to-work-in-india'}]",,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/top-25-hottest-artificial-intelligence-startups-to-work-in-india', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-17.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LmNoZWF0c2hlZXQuY29tL2VudGVydGFpbm1lbnQvdGhlLWNpcmNsZS1hcHAtaXNudC10b3RhbGx5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRlY2hub2xvZ3ktd29ya3MuaHRtbC_SAQA?oc=5,'The Circle' App Isn't Totally Artificial Intelligence; Here's How the Technology Works - Showbiz Cheat Sheet,2021-04-26,Showbiz Cheat Sheet,https://www.cheatsheet.com,,N/A,'The Circle' players use a specially designed app to communicate with one another — find out how the technology really works.,N/A,https://schema.org,VideoObject,&#8216;The Circle&#8217; App Isn&#8217;t Totally Artificial Intelligence; Here&#8217;s How the Technology Works,,,"{'@type': 'Person', 'name': 'Lauren Anderson', 'jobTitle': 'Senior Writer - Streaming', 'url': 'https://www.cheatsheet.com/author/lauren-anderson/'}",https://www.cheatsheet.com/,2021-04-26T09:40:16-0400,"{'@type': 'Organization', 'name': 'Showbiz Cheat Sheet', 'description': 'Binge-worthy entertainment news and celebrity interviews'}",,,N/A,N/A,"

TV‘The Circle’ App Isn’t Totally Artificial Intelligence; Here’s How the Technology WorksFind out how the technology on Netflix's 'The Circle' really works. 

by
Lauren Anderson

Published on April 26, 2021




2 min read



Share: 


Share on Twitter: 




Share on Facebook: 




Share via email: 




Copy link 

Link copied to the clipboard! 




","[{'@type': 'NewsArticle', '@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#article', 'isPartOf': {'@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/'}, 'author': {'name': 'Lauren Anderson', '@id': 'https://www.cheatsheet.com/#/schema/person/08b4b0504a6f75d4549806c8002f17a8'}, 'headline': '&#8216;The Circle&#8217; App Isn&#8217;t Totally Artificial Intelligence; Here&#8217;s How the Technology Works', 'datePublished': '2021-04-26T13:40:16+00:00', 'dateModified': '2021-04-29T23:42:07+00:00', 'mainEntityOfPage': {'@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/'}, 'wordCount': 628, 'publisher': {'@id': 'https://www.cheatsheet.com/#organization'}, 'image': {'@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#primaryimage'}, 'thumbnailUrl': 'https://www.cheatsheet.com/wp-content/uploads/2021/04/The-Circle-Technology-1-1024x576.png', 'keywords': ['Netflix', 'The Circle', 'tv shows'], 'articleSection': ['Entertainment', 'TV'], 'inLanguage': 'en-US', 'copyrightYear': '2021', 'copyrightHolder': {'@id': 'https://www.cheatsheet.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/', 'url': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/', 'name': ""'The Circle' App Isn't Totally Artificial Intelligence; Here's How the Technology Works"", 'isPartOf': {'@id': 'https://www.cheatsheet.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#primaryimage'}, 'image': {'@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#primaryimage'}, 'thumbnailUrl': 'https://www.cheatsheet.com/wp-content/uploads/2021/04/The-Circle-Technology-1-1024x576.png', 'datePublished': '2021-04-26T13:40:16+00:00', 'dateModified': '2021-04-29T23:42:07+00:00', 'description': ""'The Circle' players use a specially designed app to communicate with one another — find out how the technology really works."", 'breadcrumb': {'@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#primaryimage', 'url': 'https://www.cheatsheet.com/wp-content/uploads/2021/04/The-Circle-Technology-1.png', 'contentUrl': 'https://www.cheatsheet.com/wp-content/uploads/2021/04/The-Circle-Technology-1.png', 'width': 1200, 'height': 675, 'caption': ""'The Circle' | Netflix""}, {'@type': 'BreadcrumbList', '@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.cheatsheet.com/'}, {'@type': 'ListItem', 'position': 2, 'name': '&#8216;The Circle&#8217; App Isn&#8217;t Totally Artificial Intelligence; Here&#8217;s How the Technology Works'}]}, {'@type': 'WebSite', '@id': 'https://www.cheatsheet.com/#website', 'url': 'https://www.cheatsheet.com/', 'name': 'Showbiz Cheat Sheet', 'description': 'Binge-worthy entertainment news and celebrity interviews', 'publisher': {'@id': 'https://www.cheatsheet.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.cheatsheet.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.cheatsheet.com/#organization', 'name': 'Showbiz Cheat Sheet', 'url': 'https://www.cheatsheet.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.cheatsheet.com/#/schema/logo/image/', 'url': 'https://www.cheatsheet.com/wp-content/uploads/2019/05/scs-logo.png', 'contentUrl': 'https://www.cheatsheet.com/wp-content/uploads/2019/05/scs-logo.png', 'width': 295, 'height': 76, 'caption': 'Showbiz Cheat Sheet'}, 'image': {'@id': 'https://www.cheatsheet.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/ShowbizCheatsheet', 'https://twitter.com/cheatsheet']}, {'@type': 'Person', '@id': 'https://www.cheatsheet.com/#/schema/person/08b4b0504a6f75d4549806c8002f17a8', 'name': 'Lauren Anderson', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.cheatsheet.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/31ef23415b6d1d9c72ff6b2ac525d87e?s=96&d=https%3A%2F%2Fwww.cheatsheet.com%2Fwp-content%2Fuploads%2F2022%2F12%2FShowbiz-Cheat-Sheet-Logo.jpeg&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/31ef23415b6d1d9c72ff6b2ac525d87e?s=96&d=https%3A%2F%2Fwww.cheatsheet.com%2Fwp-content%2Fuploads%2F2022%2F12%2FShowbiz-Cheat-Sheet-Logo.jpeg&r=g', 'caption': 'Lauren Anderson'}, 'description': ""Lauren Anderson is an expert on all things Jersey Shore and The Office, but she also covers competition shows like Dancing With the Stars and reality TV series like 1000-lb Sisters and\xa0The Kardashians. She also recommends true crime documentaries as well as what to watch on major streaming services. Lauren enjoys being able to write about what she covers as a fan first: She's able to cover topics she cares about in a way that speaks to the audiences that are watching along with her. Lauren is a member of the Society of Professional Journalists and International Association of Professional Writers &amp; Editors. She earned her Bachelor's degree in Entertainment &amp; Arts Management from Drexel University. She began writing about entertainment in 2015 and joined the Showbiz Cheat Sheet team in 2020. She's HubSpot certified in Content Marketing, Inbound Marketing, and Social Media from her digital marketing days, before she got to binge-watch TV full-time. When she's not watching screeners or monitoring SallyAnn Salsano's plans for new reality shows (for posterity, of course), you can find her watching the latest Adam Driver movie or trying a new TikTok recipe. See more from Lauren at Screen Rant, PopSugar, Elite Daily, and her Muck Rack profile."", 'sameAs': ['https://twitter.com/laurennnderson'], 'url': 'https://www.cheatsheet.com/author/lauren-anderson/'}, {'@type': 'ItemList', '@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#itemlist', 'isPartOf': {'@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#article'}, 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'ImageObject', 'caption': ""'The Circle' uses an app that's not totally artificial intelligence"", 'url': 'https://www.cheatsheet.com/wp-content/uploads/2021/04/The-Circle-Technology-1-1024x576.png', '@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/#the-circle-uses-an-app-thats-not-totally-artificial-intelligence'}}]}]","{'@type': 'WebPage', '@id': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/'}",,2021-04-29T19:42:07-0400,,75 Facts about The British Royal Family _ Showbiz Cheat Sheet.mp4,,,"{'@type': 'SeekToAction', 'target': 'https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/?jw_start=%7Bseek_to_second_number%7D', 'startOffset-input': 'required name=seek_to_second_number'}",,https://www.cheatsheet.com/wp-content/themes/wallstcheatsheet-v2/images/logo/showbiz_2x.png?x72806,"['https://twitter.com/cheatsheet', 'https://www.facebook.com/ShowbizCheatSheet/', 'https://www.linkedin.com/company/showbiz-cheat-sheet/', 'https://www.instagram.com/showbizcheatsheet/']",,,,https://cdn.jwplayer.com/v2/media/NVhW23nF/poster.jpg?width=720,2023-08-22T19:43:34.000Z,PT10M38S,https://cdn.jwplayer.com/manifests/NVhW23nF.m3u8?max_resolution=1280,https://www.cheatsheet.com/entertainment/the-circle-app-isnt-totally-artificial-intelligence-technology-works.html/,,,,,,,,,"{'@type': 'Organization', '@id': 'https://www.endgame360.com', 'name': 'Endgame 360'}"
https://news.google.com/rss/articles/CBMihQFodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS90b3AtMTAtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVjcnVpdGVycy1pbi1pbmRpYS10by1rZWVwLWFuLWV5ZS1vbi1pbi0yMDIx0gGPAWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS90b3AtMTAtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVjcnVpdGVycy1pbi1pbmRpYS10by1rZWVwLWFuLWV5ZS1vbi1pbi0yMDIx?oc=5,Top 10 Artificial Intelligence Recruiters in India to Keep an Eye On in 2021 - Analytics Insight,2021-04-28,Analytics Insight,https://www.analyticsinsight.net,,"Artificial intelligence recruiters,Artificial intelligence ,Recruiters in India,Human resource,Recruiting","Analytics insight has listed top AI recruiters from top-notch companies For the past few years, artificial intelligence has become a buzzword in the tech sphere","Analytics insight has listed top AI recruiters from top-notch companies For the past few years, artificial intelligence has become a buzzword in the tech sphere",http://schema.org,NewsArticle,Top 10 Artificial Intelligence Recruiters in India to Keep an Eye On in 2021,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-Recruiters.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Adilin Beatrice', 'name': 'Adilin Beatrice', 'url': 'https://www.analyticsinsight.net/author/adilin-beatrice'}]",https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-recruiters-in-india-to-keep-an-eye-on-in-2021,2021-04-28T05:32:57Z,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","Analytics insight has listed top AI recruiters from top-notch companies.For the past few years, artificial intelligence has become a buzzword in the tech sphere. As more advancements in technology are taking center stage, more companies and people are jumping into the pool of artificial intelligence. Fortunately, the technology sector never disappoints them. With exploding population and high-end experts, India is one of the front-running countries that are striving to streamline artificial intelligence. Because of the country's never-ending efforts, artificial intelligence recruiters and recruiting are also mushrooming. AI recruiters in India, especially, from big companies are seeking talented candidates in machine learning engineering, robotic scientist, data scientist, research analyst, business intelligence developer, etc. Analytics insight has listed the top 10 artificial intelligence recruiters from top-notch companies who could brighten your future..TOP ARTIFICIAL INTELLIGENCE JOBS TO APPLY IN APRIL 2021TOP ARTIFICIAL INTELLIGENCE JOBS TO APPLY IN FEBRUARY 2021A REMARKABLE INCREASE IN ARTIFICIAL INTELLIGENCE JOBS, SHOWS INDEED DATA.Top 10 AI recruiters in India.Nikhil Gowda of Amazon.Position: Lead Recruiter.Nikhil Gowda is the Lead Recruiter at Amazon. He acquired a bachelor's in Human Resources and a Master's in Business Management from Amity University and Amity Global Business School. Based in Bengaluru, Gowda has multiple skills including lead generation, business development, market research, team management, CRM, Key account management, talent acquisition, recruiting, new business development, human resources, benefits negotiation, etc. He started his career at Amazon eight years ago as a Human Resource Recruitment Coordinator. Today, Gowda is handling end-to-end recruitment for the company's consumer organization, Prime Now, and B2B business groups in India. He is engaged in building and maintaining a network of potential candidates through pro-active market research and conducting in-depth interviews of potential candidates..LinkedIn- Nikhil Gowda.Shikha Bakshi of Fractal Analytics.Position: Lead TA Manager: Capacity.Shikha Bakshi is the Lead TA and HC Manager of Fractal Analytics. Located in Delhi, India, Bakshi holds a Masters's degree in Business Administration. She has been working at Fractal Analytics for the past six years. Bakshi held many positions in the company over the years before making her way to the current Lead Manager posting. Earlier, she worked for Mancer Consulting Services and XL Capital. Bakshi is an expert in leadership, BPO, stakeholder management, human resources, staffing services, interviewing, market intelligence, internet recruiting, sourcing, IT recruitment, etc..LinkedIn- Shikha Bakshi.Sujith Raparthi of Deloitte.Position: Talent Acquisition &amp; Campus Hiring at Deloitte India.Sujith Raparthi is working as the Talent Acquisition &amp; Campus Hiring at Deloitte India. He started his career at Deloitte six years back. Before that Raparthi was working as an HR Recruiter at Hayasree Technologies. At Deloitte, he is responsible for leading the development and delivery of resourcing strategies and solutions that support the company's recruitment objectives. Raparthi also encompasses end-to-end process management starting from the campus testing process to candidate onboarding. With many years of experience in the talent acquisition industry, he is familiar with all the best recruitment practices and policies and knows how to effectively apply them in the workplace..LinkedIn- Sujith Raparthi.Abhilash Chipkar of LinkedIn.Position: Technical Recruiter.Abhilash Chipkar is the Technical Recruiter at LinkedIn. With 7+ years of experience in recruitment, Chipkar is greatly motivated to search for talent to make quality connections. He is currently engaging in recruitment services related to Site Reliability Engineering (SRE), software development, platform, and productivity tools engineering, and IT Infrastructure (Network, Systems, Storage, Databases, Cloud, DevOps). Before Joining LinkedIn, Chipkar spent three years at CareerNet Technologies as a Consultant..LinkedIn- Abhilash Chipkar.Archana Kumari of IBM.Position: HR Recruiter at IBM Global Business Process Services.Archana Kumari is the HR Recruiter at IBM Global Business Process Services. In her role, Kumari is responsible for the full recruitment life cycle for a few positions in IT, technical, analytics recruitment, and vendor management. She understands the job requirement and sources the profile from sources like LinkedIn, HeadHonchos, Naukri, etc. as internal sourcing. Kumari also schedules the interviews and rolls out offer letters to selected candidates. She has been working for IBM for the past thirteen years..LinkedIn- Archana Kumari.Priyanka Annie of Accenture.Position: Talent Acquisition at Accenture.Priyanka Annie is working as Talent Acquisition at Accenture. She is an experienced recruiter with a demonstrated history of working in the information technology, consulting, and services industry. Skilled in Microsoft Office, IT recruitment, and human resources, Annie has spent all her working life at Accenture. In her profession, she is responsible to understand and analyze the requirements in different skill set categories. Annie posts job openings of job portals conduct telephonic interviews, understands the applicant's resume, and promotes it for the profile. She acquired a master's in business administration with Human Resources and Services as the focus area..LinkedIn- Priyanka Annie.Nidhi Bajaj of Myntra.Position: Manager- Talent Acquisition.Nidhi Bajaj is working as the Manager of Talent Acquisition at Myntra. She is an experienced talent acquisition professional with a demonstrated history of working in the internet industry. Bajaj is skilled in analytics recruiting, sourcing, screening, and performance management. At her position, she s handling end-to-end lateral hiring requirements across functions for retail and fashion professionals, digital marketers, creative champs, and analytic/strategic experience professionals. Bajaj has previously worked with Jabong and CareerOrbits portals Pvt. Ltd..LinkedIn- Nidhi Bajaj.Fahad Khan of Flipkart.Position: Lead-Talent Acquisition.Fahad Khan works as the Lead-Talent Acquisition at Flipkart. Khan has eight years of experience in human resources. At Flipkart, he is responsible for talent acquisition, induction, performance appraisal, team building, employee bonding, and employee grievances. Khan holds a bachelor's degree in Physics from Wilson College and a master's degree in human resources from Welingkar Institute of Management. Before being employed at Flipkart, he previously held HR and recruitment positions at B.LAB Private Limited, Epicenter Technologies Pvt Ltd, and Nautica Hr Placements..LinkedIn- Fahad Khan.Ritika Mathur of Facebook.Position: Engineering Recruiting.Ritika Mathur is working for Engineering Recruiting at Facebook. At her position, she is hiring top-notch engineering talent from the APAC region for Facebook headquarters in Menlo Park, California. Mathur has hired eighteen solid engineers from India in two quarters. She also has experience of working with Google as AdWords Associate. Mathur acquired a Masters's of Business Administration in Human Resources and Bachelors in Literature..LinkedIn- Ritika Mathur.Renu Sevanthi of Apple.Position: Head of Recruiting.Renu Sevanthi works as the Head of Recruiting at Apple. At his position, Sevanthi is responsible for staffing leadership, team management, hiring strategies, stakeholder management, end-to-end talent acquisition for high-end technology streams, and executive hiring. She also sets up the talent acquisition strategy for Apple India..LinkedIn- Renu Sevanthi.Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,N/A,N/A,What is AI and Data Science Engineering? ,,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-recruiters-in-india-to-keep-an-eye-on-in-2021'}",2021-04-28T05:32:57Z,2021-04-28T05:32:57Z,,Top 10 Artificial Intelligence Recruiters in India to Keep an Eye On in 2021,,,,,,,,,Artificial Intelligence,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-Recruiters.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 10 Artificial Intelligence Recruiters in India to Keep an Eye On in 2021', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-recruiters-in-india-to-keep-an-eye-on-in-2021'}]",,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-recruiters-in-india-to-keep-an-eye-on-in-2021', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/04/Artificial-Intelligence-Recruiters.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vc2JyLmNvbS5zZy9jby13cml0dGVuLXBhcnRuZXIvbW9yZS1uZXdzL3RldGhlcmZpLXdpbnMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYXdhcmQtdGVsZWNvbW11bmljYXRpb25zLXNici10ZWEt0gEA?oc=5,Tetherfi wins Artificial Intelligence Award for Telecommunications at SBR TEA 2021 - Singapore Business Review,2021-04-27,Singapore Business Review,https://sbr.com.sg,"From surviving the pandemic to thriving: A Singapore-based CX Start-up, Tetherfi, enables enterprises to transition to a remote working model; no compromises on security, compliance or collaboration.",N/A,"From surviving the pandemic to thriving: A Singapore-based CX Start-up, Tetherfi, enables enterprises to transition to a remote working model; no compromises on security, compliance or collaboration.","From surviving the pandemic to thriving: A Singapore-based CX Start-up, Tetherfi, enables enterprises to transition to a remote working model; no compromises on security, compliance or collaboration.",https://schema.org,,,,,,,,,,,N/A,N/A,"


More News




Co-Written / Partner


            Staff Reporter 
        
,


                Singapore
            










  
              Published:  
          


3 years ago










            300 views      







            Tetherfi wins Artificial Intelligence Award for Telecommunications at SBR TEA 2021 
        

From surviving the pandemic to thriving: A Singapore-based CX Start-up, Tetherfi, enables enterprises to transition to a remote working model; no compromises on security, compliance or collaboration.When COVID-19 lockdowns forced millions to go virtual and work from home, contact centers were among the worst-hit. Enterprises suddenly needed to find ways to get their agents, supervisors and other business users to work from home. There was tremendous pressure on supervisors to monitor work-from-home agents to ensure maximum compliance and efficiency, remotely.Making this turnaround required profound innovation, particularly creating a unique solution that enabled a work-from-home contact center model just within days. It also needed building robust security and compliance modules without compromising employee experience or privacy norms.It required leadership in technology and on the field understanding of what customers, enterprises, and agents needed—the result: Tetherfi Work from Home (WFH) Solution.Tetherfi developed a unique work from home solution using real-time camera vision, Artificial Intelligence and Machine Learning. The technology was so agile that enterprises could switch to remote working in just a few days using their existing infrastructure. It even allowed businesses to track, alert, reduce risk and improve collaboration without compromising on customer service during these unprecedented times.


            Join Singapore Business Review community
        



Your e-mail address






""Tetherfi Work From Home Solution is a result of years of extensive research at our R&D lab in Singapore"", says Vineeth Nayak, Founder & CEO, Tetherfi. He adds, ""The pandemic has turned into a catalyst for digital transformation in the contact center industry. It is no longer about simply surviving the pandemic; it's about envisioning new business approaches and markets.""Tetherfi wins Artificial Intelligence AwardTetherfi has emerged the winner of the AI - Telecommunications category at this year's SBR Technology Excellence Awards, recognizing its achievement in reimagining the post-COVID-19 return for contact centers. This award is a token of appreciation for streamlining remote work to improve business outcomes, operation efficiency, and employee experience.Tetherfi's Work From Home Solution is powered by TRS (Tetherfi Remote Security) technology. Some of the critical features include:- 2-Factor Face Authentication	- Gadget & Eavesdropping Detection	- Copy Paste Detection	- Liveness & Absence Detection	- Website Blocking	- External Monitor Detection	- Gesture Recognition	- Employee CollaborationWith Tetherfi's technology, agents and supervisors can work from their location of choice to create unified and proactive customer experiences. With AI and ML-led tracking and alerting integrated with the agent device camera, there is a level of security that's unmatched compared to standard WFH setups.Singapore's Leading Enterprise Contact Centre Shifts 20% of Employees to Remote Work:In April 2020, when the Singapore Government mandated the shutdown of all but essential services, the whole population was strongly encouraged to work from home. To ensure business continuity, one of Singapore's leading companies partnered with Tetherfi to adapt and maintain the ""new normal"" of working from home in an efficient, secure and compliant manner.Some of the key milestones achieved by the contact centres adapting Tetherfi solution include:- Transition to a WFH model in less than 10 days	- Instantly shift 20% to 50% of employees to a remote working model	- Zero footprint, minimal additional costs and zero overheads	- No installation on agent desktop or supervisor consoles	- Remote agent activation and supervision	- Real-time actions and emotion detection with face authentication and gamification	- Instant security authentication like alerting unauthorized screen peeps for complianceAbout Tetherfi:Tetherfi delivers rich-media, conversational, Multi-experience (MX) customer engagement for Sales and Service. Tetherfi Multi-Experience (MX) platform powered by Tetherfi SDK / API enables enterprises to chat, touch, video, audio, screen share & co-browse with their customers and prospects anywhere and on any device. All these combined interaction modalities within a single session to resolve issues seamlessly will be vital in providing a competitive & engaging customer experience (CX).Tetherfi has 145+ employees (& growing) spread across its R & D centre - Tetherfi Labs and its other offices spread across Singapore (HQ), the USA, India, Srilanka and other South East Asia countries.For more information, visit https://tetherfi.com or write to us at insidesales@tetherfi.comThe Technology Excellence Awards, presented by Singapore Business Review, was held via studio award presentations and video conferencing sessions throughout the second and third week of April.This year’s nominations were judged by a panel consisting of Daryl Pereira, Head of Cyber at KPMG; Cheang Wai Keat, Partner, Consulting at Ernst & Young Advisory Pte. Ltd.; Henry Tan, Group Chief Executive Officer and Chief Innovation Officer at Nexia TS; Sivakumar Saravan, Senior Partner at Crowe Singapore; Cecil Su, Director, Head of Cybersecurity of BDO Singapore.If you would like to join the 2022 awards and be acclaimed for your company’s exceptional technological innovations, please email Jane Patiag at jane@charltonmediamail.com.

","[{'@type': 'NewsArticle', 'headline': 'Tetherfi wins Artificial Intelligence Award for Telecommunications at SBR TEA 2021', 'name': 'Tetherfi wins Artificial Intelligence Award for Telecommunications at SBR TEA 2021', 'description': '<p><em>From surviving the pandemic to thriving: A Singapore-based CX Start-up, Tetherfi, enables enterprises to transition to a remote working model; no compromises on security, compliance or collaboration.</em></p><p>When COVID-19 lockdowns forced millions to go virtual and work from home, contact centers were among the worst-hit. Enterprises suddenly needed to find ways to get their agents, supervisors and other business users to work from home. There was tremendous pressure on supervisors to monitor work-from-home agents to ensure maximum compliance and efficiency, remotely.</p><p>Making this turnaround required profound innovation, particularly creating a unique solution that enabled a work-from-home contact center model just within days. It also needed building robust security and compliance modules without compromising employee experience or privacy norms.</p><p>It required leadership in technology and on the field understanding of what customers, enterprises, and agents needed—the result: Tetherfi Work from Home (WFH) Solution.</p><p>Tetherfi developed a unique work from home solution using real-time camera vision, Artificial Intelligence and Machine Learning. The technology was so agile that enterprises could switch to remote working in just a few days using their existing infrastructure. It even allowed businesses to track, alert, reduce risk and improve collaboration without compromising on customer service during these unprecedented times.</p><p>""Tetherfi Work From Home Solution is a result of years of extensive research at our R&D lab in Singapore"", says Vineeth Nayak, Founder & CEO, Tetherfi. He adds, ""The pandemic has turned into a catalyst for digital transformation in the contact center industry. It is no longer about simply surviving the pandemic; it\'s about envisioning new business approaches and markets.""</p><p><strong>Tetherfi wins Artificial Intelligence Award</strong></p><p>Tetherfi has emerged the winner of the AI - Telecommunications category at this year\'s SBR Technology Excellence Awards, recognizing its achievement in reimagining the post-COVID-19 return for contact centers. This award is a token of appreciation for streamlining remote work to improve business outcomes, operation efficiency, and employee experience.</p><p>Tetherfi\'s Work From Home Solution is powered by TRS (Tetherfi Remote Security) technology. Some of the critical features include:</p><p>- 2-Factor Face Authentication\t- Gadget & Eavesdropping Detection\t- Copy Paste Detection\t- Liveness & Absence Detection\t- Website Blocking\t- External Monitor Detection\t- Gesture Recognition\t- Employee Collaboration</p><p>With Tetherfi\'s technology, agents and supervisors can work from their location of choice to create unified and proactive customer experiences. With AI and ML-led tracking and alerting integrated with the agent device camera, there is a level of security that\'s unmatched compared to standard WFH setups.</p><p>Singapore\'s Leading Enterprise Contact Centre Shifts 20% of Employees to Remote Work:</p><p>In April 2020, when the Singapore Government mandated the shutdown of all but essential services, the whole population was strongly encouraged to work from home. To ensure business continuity, one of Singapore\'s leading companies partnered with Tetherfi to adapt and maintain the ""new normal"" of working from home in an efficient, secure and compliant manner.</p><p>Some of the key milestones achieved by the contact centres adapting Tetherfi solution include:</p><p>- Transition to a WFH model in less than 10 days\t- Instantly shift 20% to 50% of employees to a remote working model\t- Zero footprint, minimal additional costs and zero overheads\t- No installation on agent desktop or supervisor consoles\t- Remote agent activation and supervision\t- Real-time actions and emotion detection with face authentication and gamification\t- Instant security authentication like alerting unauthorized screen peeps for compliance</p><p>About Tetherfi:</p><p>Tetherfi delivers rich-media, conversational, Multi-experience (MX) customer engagement for Sales and Service. Tetherfi Multi-Experience (MX) platform powered by Tetherfi SDK / API enables enterprises to chat, touch, video, audio, screen share & co-browse with their customers and prospects anywhere and on any device. All these combined interaction modalities within a single session to resolve issues seamlessly will be vital in providing a competitive & engaging customer experience (CX).</p><p>Tetherfi has 145+ employees (& growing) spread across its R & D centre - Tetherfi Labs and its other offices spread across Singapore (HQ), the USA, India, Srilanka and other South East Asia countries.</p><p>For more information, visit <a rel=""nofollow"" href=""https://tetherfi.com"">https://tetherfi.com</a> or write to us at <a rel=""nofollow"" href=""https://mailto:insidesales@tetherfi.com"">insidesales@tetherfi.com</a></p><p><iframe height=""350"" src=""https://player.vimeo.com/video/551363821"" width=""640""></iframe></p><p><em>The Technology Excellence Awards, presented by Singapore Business Review, was held via studio award presentations and video conferencing sessions throughout the second and third week of April.</em></p><p><em>This year’s nominations were judged by a panel consisting of\xa0Daryl Pereira, Head of Cyber at KPMG; Cheang Wai Keat, Partner, Consulting at Ernst & Young Advisory Pte. Ltd.; Henry Tan, Group Chief Executive Officer and Chief Innovation Officer at Nexia TS; Sivakumar Saravan, Senior Partner at Crowe Singapore; Cecil Su, Director, Head of Cybersecurity of BDO Singapore.</em></p><p><em>If you would like to join the 2022 awards and be acclaimed for your company’s exceptional technological innovations, please email Jane Patiag at <a href=""mailto:jane@charltonmediamail.com"">jane@charltonmediamail.com</a>.</em></p>', 'image': {'@type': 'ImageObject', 'url': 'https://assets.charltonmedia.com/s3fs-public/styles/opengraph/public/2021-06/new_project_2_0.jpg?itok=gol2bjkM', 'width': '1200', 'height': '630'}, 'datePublished': '2021-04-27T15:06:59+0800', 'dateModified': '2021-06-03T12:05:56+0800', 'author': {'@type': 'Person', '@id': 'https://sbr.com.sg/co-written-partner/more-news/tetherfi-wins-artificial-intelligence-award-telecommunications-sbr-tea-', 'name': 'Staff Reporter', 'url': 'https://charltonmedia.com/'}, 'publisher': {'@type': 'Organization', '@id': 'Charlton Media Group', 'name': 'Charlton Media Group', 'url': 'https://charltonmedia.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://sbr.com.sg/themes/custom/responsive/img/schema.png', 'width': '600', 'height': '314'}}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,

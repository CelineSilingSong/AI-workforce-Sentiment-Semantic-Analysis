URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,headline,image,thumbnailUrl,author,publisher,dateCreated,datePublished,dateModified,timeRequired,url,mainEntityOfPage,article:section,article:summary,article text,hasPart,copyrightHolder,sourceOrganization,copyrightYear,isAccessibleForFree,isPartOf,name,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,creator,about,articleSection,@graph,address,alternativeHeadline,video,comment,commentCount,inLanguage
https://news.google.com/rss/articles/CBMiRmh0dHBzOi8vd3d3LnJlZGJ1bGwuY29tL2diLWVuL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXVrLW11c2ljLWFydGlzdHPSAQA?oc=5,Artificial Intelligence in music: Meet UK's pioneers - Red Bull,2019-03-06,Red Bull,https://www.redbull.com,AI is both awe-inspiring and unnerving. Will the technology ever replace human musicians?,N/A,AI is both awe-inspiring and unnerving. Will the technology ever replace human musicians?,N/A,https://schema.org,Article,Artificial aesthetics: Meet the UK musicians experimenting with AI,"{'@type': 'ImageObject', 'url': 'https://img.redbull.com/images/c_limit,w_1500,h_1000,f_auto,q_auto/redbullcom/2019/03/06/8af6600e-051f-40ce-8a86-603bb05a7657/yoona', 'author': {'@type': 'Person', 'name': 'auxuman'}, 'thumbnail': {'@type': 'ImageObject', 'url': 'https://img.redbull.com/images/c_limit,w_150,h_100,f_auto,q_auto/redbullcom/2019/03/06/8af6600e-051f-40ce-8a86-603bb05a7657/yoona', 'author': {'@type': 'Person', 'name': 'auxuman'}}}","https://img.redbull.com/images/c_limit,w_150,h_100,f_auto,q_auto/redbullcom/2019/03/06/8af6600e-051f-40ce-8a86-603bb05a7657/yoona","{'@type': 'Person', 'name': 'Francis Blagburn'}","{'@type': 'Organization', 'name': 'Red\xa0Bull', 'logo': {'@type': 'ImageObject', 'url': 'https://www.redbull.com/v3/resources/images/client/header/redbullcom-logo_double-with-text.svg', 'width': {'@type': 'QuantitativeValue', 'value': 240}, 'height': {'@type': 'QuantitativeValue', 'value': 48}}}",2019-03-06T11:58:14.000Z,2019-03-06T11:58:14Z,2023-11-08T05:24:48.652Z,PT9M,https://www.redbull.com/gb-en/artificial-intelligence-uk-music-artists,"{'@type': 'WebPage', 'url': 'https://www.redbull.com/gb-en/artificial-intelligence-uk-music-artists'}",N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiS2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTkvMDMvMDEvYnVzaW5lc3MvZXRoaWNhbC1haS1yZWNvbW1lbmRhdGlvbnMuaHRtbNIBAA?oc=5,Seeking Ground Rules for A.I. - The New York Times,2019-03-01,The New York Times,https://www.nytimes.com,It’s not easy to encourage the ethical use of artificial intelligence. But here are 10 recommendations.,N/A,It’s not easy to encourage the ethical use of artificial intelligence. But here are 10 recommendations.,It’s not easy to encourage the ethical use of artificial intelligence. But here are 10 recommendations.,https://schema.org,NewsMediaOrganization,Seeking Ground Rules for A.I.,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/03/04/business/04Groups1/merlin_151450908_768b58df-4e5c-4228-aa53-90fcc9d7566f-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2019/03/04/business/04Groups1/merlin_151450908_768b58df-4e5c-4228-aa53-90fcc9d7566f-videoSixteenByNineJumbo1600.jpg', 'caption': 'Some academics and technology leaders are worried these systems will eventually lead to mass surveillance or autonomous weapons.', 'creditText': 'John Hersey'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/03/04/business/04Groups1/merlin_151450908_768b58df-4e5c-4228-aa53-90fcc9d7566f-superJumbo.jpg', 'height': 1178, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2019/03/04/business/04Groups1/merlin_151450908_768b58df-4e5c-4228-aa53-90fcc9d7566f-superJumbo.jpg', 'caption': 'Some academics and technology leaders are worried these systems will eventually lead to mass surveillance or autonomous weapons.', 'creditText': 'John Hersey'}]",,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/cade-metz', 'name': 'Cade Metz'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,2019-03-02T01:53:56.000Z,2019-03-02T01:53:56.000Z,,https://www.nytimes.com/,https://www.nytimes.com/2019/03/01/business/ethical-ai-recommendations.html,Business,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTSeeking Ground Rules for A.I.It’s not easy to encourage the ethical use of artificial intelligence. But here are 10 recommendations.Share full articleRead in appSome academics and technology leaders are worried these systems will eventually lead to mass surveillance or autonomous weapons.Credit...John HerseyBy Cade MetzMarch 1, 2019About seven years ago, three researchers at the University of Toronto built a system that could analyze thousands of photos and teach itself to recognize everyday objects, like dogs, cars and flowers.The system was so effective that Google bought the tiny start-up these researchers were only just getting off the ground. And soon, their system sparked a technological revolution. Suddenly, machines could “see” in a way that was not possible in the past.This made it easier for a smartphone app to search your personal photos and find the images you were looking for. It accelerated the progress of driverless cars and other robotics. And it improved the accuracy of facial recognition services, for social networks like Facebook and for the country’s law enforcement agencies.But soon, researchers noticed that these facial recognition services were less accurate when used with women and people of color. Activists raised concerns over how companies were collecting the huge amounts of data needed to train these kinds of systems. Others worried these systems would eventually lead to mass surveillance or autonomous weapons.How should we, as a society, deal with these issues? Many have asked the question. Not everyone can agree on the answers. Google sees things differently from Microsoft. A few thousand Google employees see things differently from Google. The Pentagon has its own vantage point.This week, at the New Work Summit, hosted by The New York Times, conference attendees worked in groups to compile a list of recommendations for building and deploying ethical artificial intelligence. The results are included here.But even the existence of this list sparked controversy. Some attendees, who have spent years studying these issues, questioned whether a group of randomly selected people were the best choice for deciding the future of artificial intelligence.One thing is for sure: The discussion will only continue in the months and years to come.ImageCredit...John HerseyImageCredit...John HerseyAdvertisementSKIP ADVERTISEMENTThe RecommendationsTransparency Companies should be transparent about the design, intention and use of their A.I. technology.Disclosure Companies should clearly disclose to users what data is being collected and how it is being used.Privacy Users should be able to easily opt out of data collection.Diversity A.I. technology should be developed by inherently diverse teams.Bias Companies should strive to avoid bias in A.I. by drawing on diverse data sets.Trust Organizations should have internal processes to self-regulate the misuse of A.I. Have a chief ethics officer, ethics board, etc.Accountability There should be a common set of standards by which companies are held accountable for the use and impact of their A.I. technology.AdvertisementSKIP ADVERTISEMENTCollective governance Companies should work together to self-regulate the industry.Regulation Companies should work with regulators to develop appropriate laws to govern the use of A.I.“Complementarity” Treat A.I. as tool for humans to use, not a replacement for human work.The leaders of the groups: Frida Polli, a founder and chief executive, Pymetrics; Sara Menker, founder and chief executive, Gro Intelligence; Serkan Piantino, founder and chief executive, Spell; Paul Scharre, director, Technology and National Security Program, The Center for a New American Security; Renata Quintini, partner, Lux Capital; Ken Goldberg, William S. Floyd Jr. distinguished chair in engineering, University of California, Berkeley; Danika Laszuk, general manager, Betaworks Camp; Elizabeth Joh, Martin Luther King Jr. Professor of Law, University of California, Davis; Candice Morgan, head of inclusion and diversity, PinterestCade Metz is a technology correspondent, covering artificial intelligence, driverless cars, robotics, virtual reality, and other emerging areas. He previously wrote for Wired magazine.  More about Cade MetzShare full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",The New York Times,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,,
https://news.google.com/rss/articles/CBMimwFodHRwczovL3d3dy5hcnRzeS5uZXQvYXJ0aWNsZS9hcnRzeS1lZGl0b3JpYWwtYXJ0d29yay1jcmVhdGVkLWFpLXNvbGQtNDAtMDAwLXNvdGhlYnlzLWZhaWxpbmctZ2VuZXJhdGUtZmVydm9yLXByb3BlbGxlZC1haS13b3JrLXNlbGwtNDAtdGltZXMtZXN0aW1hdGUteWVhctIBAA?oc=5,"Artificial Intelligence Artwork by Mario Klingemann Sells for £40,000 at Sotheby’s - Artsy",2019-03-06,Artsy,https://www.artsy.net,The work failed to spark the same bidding craze incited at Christie’s last year for a portrait by French collective Obvious.,news,The work failed to spark the same bidding craze incited at Christie’s last year for a portrait by French collective Obvious.,The work failed to spark the same bidding craze incited at Christie’s last year for a portrait by French collective Obvious.,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vZGlnaW5vbWljYS5jb20vYWktd2lsbC1jaGFuZ2Utb3ItZWxpbWluYXRlLTEzMDAwMC1mZWRlcmFsLWpvYnMtb3Zlci10aGUtbmV4dC10d28tZGVjYWRlc9IBZGh0dHBzOi8vZGlnaW5vbWljYS5jb20vYWktd2lsbC1jaGFuZ2Utb3ItZWxpbWluYXRlLTEzMDAwMC1mZWRlcmFsLWpvYnMtb3Zlci10aGUtbmV4dC10d28tZGVjYWRlcz9hbXA?oc=5,"AI will change or eliminate 130,000 federal jobs over the next two decades - diginomica",2019-03-05,diginomica,https://diginomica.com,"AI will play a significant role in helping government agencies to more efficiently provide services, but it will reshape the workforce in ways that are dramatic and largely unforeseen, according to Partnership for Public Service.","['Government', 'IoT robotics and AI']","AI will play a significant role in helping government agencies to more efficiently provide services, but it will reshape the workforce in ways that are dramatic and largely unforeseen, according to Partnership for Public Service.",N/A,https://schema.org,NewsArticle,"AI will change or eliminate 130,000 federal jobs over the next two decades","{'@type': 'ImageObject', 'representativeOfPage': 'True', 'url': 'https://diginomica.com/sites/default/files/images/2017-06/binary-2175285_1280.jpg'}",https://diginomica.com/sites/default/files/images/2017-06/binary-2175285_1280.jpg,"{'@type': 'Person', '@id': '2084', 'name': 'Jerry Bowles', 'url': 'https://diginomica.com/author/jbowles'}","{'@type': 'Organization', '@id': 'https://diginomica.com', 'name': 'diginomica', 'url': 'https://diginomica.com', 'logo': {'@type': 'ImageObject', 'url': 'https://diginomica.com/themes/custom/diginomica_theme/logo.png', 'width': '206', 'height': '45'}}",,2019-03-05T14:06:07-0800,2021-09-10T04:20:32-0700,,https://diginomica.com/ai-will-change-or-eliminate-130000-federal-jobs-over-the-next-two-decades,https://diginomica.com/ai-will-change-or-eliminate-130000-federal-jobs-over-the-next-two-decades,Government,N/A,"

AI will change or eliminate 130,000 federal jobs over the next two decades




Bookmark icon


Read later





By Jerry Bowles





March 5, 2019



Dyslexia mode













Summary: 

AI will play a significant role in helping government agencies to more efficiently provide services, but it will reshape the workforce in ways that are dramatic and largely unforeseen, according to Partnership for Public Service.









Facebook







Linkedin







Reddit







Twitter







Threads







Bluesky







Comment bubble icon










 



The industrialized world’s future may hang on mankind’s ability to answer a single, deeply disturbing question--if thinking machines do most of the work, what do humans do? It is a problem without an obvious solution.
What is known for sure and confirmed by dozens of research studies and real-life experiences is that the widespread adoption of artificial intelligence and machine learning over the next few decades will have a profound and disruptive effect on workers in every industry around the world.
A new report titled “More Than Meets AI: Assessing the Impact of Artificial Intelligence on the Work of Government” from The Partnership for Public Service, a nonpartisan, nonprofit organization that works to revitalize the federal government and the IBM Center for The Business of Government, sees difficult times ahead for government workers as well as AI takes root. From the report:
“AI is sure to change the composition of the federal workforce, creating new jobs related to managing AI systems or requiring critical thinking. Jobs based mainly on tasks that can be automated would likely be phased out, and employees would have to learn new or different skills for other jobs.
“Jobs based mainly on tasks that can be automated will likely be phased out, and employees would have to learn new or different skills for other jobs in order survive.

Just how disruptive will AI be to federal workers?
The analysis found more than 80 different federal occupations for which data shows there is substantial opportunity for job automation. More than 130,000 U.S. federal employees worked in these occupations in fiscal 2017, holding a wide-range of responsibilities from examining taxes and inspecting food to scheduling cargo and operating cranes. Multiply those numbers by the government workforce of major countries around the world and you’re talking about millions of people whose jobs and lives will be greatly disrupted in the coming few decades. According to the report:
Ten or 20 years from now, a federal workday is likely to unfold differently than a workday today. An AI transformation is expected to start with the automation of repetitive tasks, freeing up employees’ time to focus on mission-critical work. In the long term, however, AI will change the nature of jobs and how humans work alongside machines.

The report notes that the changes brought on by AI will not be the first substantial disruption of the federal workforce. In 1985, 19 percent of full-time federal employees held clerical positions. In 2017, they constituted just 4.3 percent in the workforce, according to Office of Personnel Management data. During those years, desktop computers and other technologies automated many clerical tasks, and new employees were hired to deliver programs in newly created agencies such as the Department of Homeland Security.
Based on that experience, whatever changes AI brings will not be immediate but an evolution that will play out over years and decades. Still, the report suggests that leaders and managers should begin preparing their employees now for the inevitable changes to come:
Leaders should communicate with employees early and often about the potential of AI to disrupt and alter their work. Leaders and managers should learn from early adopters of AI, such as the U.S. Coast Guard, NASA and the Department of Health and Human Services.

They should find out the extent to which the workday changed for employees, what types of agency work AI helped these organizations accomplish, which tasks were automated successfully, and what kind of work employees might start doing in place of current, repetitive tasks that AI could perform.

What jobs are likely to be most impacted?
Some agencies are more likely than others to be significantly impacted by AI in the near-term future. The research shows that more than a third of the Treasury Department’s staff (36%) are in occupations that would be affected by technology. The Government Publishing Office (28%) and the Securities and Exchange Commission (22%) also have considerable room to use AI in select occupations.


 



My Take
Like all the industry-friendly studies and optimistic pronouncements you see these days about the impact of AI on lower skilled workers, this one is filled with cheerful prattle about how AI will allow machines to handle routine jobs and allow people to perform more meaningful and interesting work, spend more time working directly with customers, perform other mission-related tasks and even learn new skills related to managing AI systems or requiring critical thinking. Another recommendation of the report:
Federal employees should receive training that emphasizes skills for handling interactions with agency customers with the help of AI. “Social literacy” entails skills such as active listening, communication, critical thinking, negotiation, persuasion, reading comprehension and writing. These skills will become more important as employees are able to spend more time with customers.

At the moment, there is no cross-agency strategy or plan to retrain those workers whose jobs are at risk to AI to provide them with the technical, digital and data literacy they will need to survive. Although it’s not specifically mentioned in the text—I suspect deliberately—there is a chart that shows more than half of the at-risk workers are over 50. This is a predictable and possibly avoidable human tragedy in the making.




Image credit - Image sourced via Pixabay 


Read more on: 

Government
IoT robotics and AI



",,,,,True,,"AI will change or eliminate 130,000 federal jobs over the next two decades",,,,,,,,Jerry Bowles,"['Government', 'IoT robotics and AI']",Government,"{'1': {'@type': 'WebPage', '@id': 'https://diginomica.com/ai-will-change-or-eliminate-130000-federal-jobs-over-the-next-two-decades', 'description': 'AI will play a significant role in helping government agencies to more efficiently provide services, but it will reshape the workforce in ways that are dramatic and largely unforeseen, according to Partnership for Public Service.', 'isAccessibleForFree': 'True'}}",,,,,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vdGhlc3RyYXRlZ3licmlkZ2Uub3JnL3RoZS1icmlkZ2UvMjAxOS8zLzUvZWNvbm9taWNzLXN1cmUtYnV0LWRvbnQtZm9yZ2V0LWV0aGljcy13aXRoLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gF_aHR0cHM6Ly90aGVzdHJhdGVneWJyaWRnZS5vcmcvdGhlLWJyaWRnZS8yMDE5LzMvNS9lY29ub21pY3Mtc3VyZS1idXQtZG9udC1mb3JnZXQtZXRoaWNzLXdpdGgtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2U_Zm9ybWF0PWFtcA?oc=5,"Economics Sure, but Don’t Forget Ethics with Artificial Intelligence - The Strategy Bridge",2019-03-05,The Strategy Bridge,https://thestrategybridge.org,"<p><span style=""font-size:18px"">Welcome to <em>The Bridge</em>, an international journal on policy, strategy, national security, and military affairs. If you’re interested in writing for us, email us at submissions@thestrategybridge.org.</span></p>",N/A,"The widening rift between the Pentagon and Silicon Valley endangers national security in an era when global powers are embracing strategic military-technical competition. As countries race to harness the next potentially offsetting technology, artificial intelligence, the implications of relinquishi","The widening rift between the Pentagon and Silicon Valley endangers national security in an era when global powers are embracing strategic military-technical competition. As countries race to harness the next potentially offsetting technology, artificial intelligence, the implications of relinquishi",http://schema.org,Article,"Economics Sure, but Don’t Forget Ethics with Artificial Intelligence",http://static1.squarespace.com/static/5497331ae4b0148a6141bd47/55ebb046e4b0902fc056869c/5c7aeec7eef1a175eb4e37ba/1673697580345/Project+Image+AI+Image.jpg?format=1500w,,Strategy Bridge,"{'name': 'The Strategy Bridge', 'logo': {'@type': 'ImageObject', 'url': 'https://static1.squarespace.com/static/5497331ae4b0148a6141bd47/t/65356dee7d16a71e9af5e4c0/1716851948458/'}, '@context': 'http://schema.org', '@type': 'Organization'}",,2019-03-05T00:01:00-0500,2023-01-14T06:59:40-0500,,https://thestrategybridge.org/the-bridge/2019/3/5/economics-sure-but-dont-forget-ethics-with-artificial-intelligence,,N/A,N/A,"



Strategy Bridge


March 5, 2019




Economics Sure, but Don’t Forget Ethics with Artificial Intelligence



Strategy Bridge


March 5, 2019







Richard Kuzma and Tom Wester



The widening rift between the Pentagon and Silicon Valley endangers national security in an era when global powers are embracing strategic military-technical competition. As countries race to harness the next potentially offsetting technology, artificial intelligence, the implications of relinquishing their competitive edge could drastically change the landscape of the next conflict. The Pentagon has struggled—and continues to struggle—to make a solid business case for technology vendors to sell their products to the Defense Department. This is made especially urgent by Russia and China’s increasing artificial intelligence capabilities and newly created national strategies. While making the economic case to Silicon Valley is critical, building a lasting relationship will necessitate embracing the ethical questions surrounding the development and employment of artificial intelligence on the battlefield. Ultimately, this requires more soul-searching on the part of both military leaders and technologists.It is hard to overstate the importance of ethics in discussions of artificial intelligence cooperation between the military and private sector. Google chose not to renew a Department of Defense contract with Project Maven—a Defense Department project using artificial intelligence for drone targeting—when thousands of employees protested the company’s involvement. Thousands of artificial intelligence researchers followed their letter by signing a pledge to not build autonomous weapons. Computer science students from Stanford and other top-tier universities, a primary talent pipeline for tech companies, wrote a letter to Google’s chief executive officer saying they would not interview with Google if it did not drop its Maven contract. 





View fullsize







Google Employees Petition Against Project Maven (sUAS News)





However, Google isn’t the only case where working with the military has prompted debate and resulted in modifications to corporate behavior. Microsoft employees wrote an open letter demanding the company not bid on the Pentagon’s new cloud contract or sell augmented reality headsets to the Army, and Amazon employees wrote a letter to Jeff Bezos demanding he not sell facial recognition technology to the U.S. government, saying, “We demand a choice in what we build, and a say in how it is used.” Even at Clarifai, a company heavily involved in Project Maven, the project was said to have “damaged morale, complicated recruitment, and undermined trust within the company.”The Defense Department is beginning to recognize the importance of artificial intelligence and machine learning, and realizes the engine of innovation with regards to artificial intelligence lies almost exclusively in the private sector. As such, the Pentagon needs help from commercial leaders and innovators to stay competitive. This requires courting tech chief executive officers charged principally with increasing shareholder value. More importantly, however, it necessitates working closely with the engineers who develop the technology. As in the military, people are a technology company’s most valuable resource. As such, tech executives should pay as close of attention to their engineers as to their bottom line. Additionally, the Pentagon must not only demonstrate it is an attractive potential customer, but must also show how the handiwork of engineers will help, rather than harm, humanity. In this effort, the Defense Department is making significant progress in marketing itself as a customer as well as creating mechanisms for companies to effectively work with the military; however, it still needs to do more to address the ethical challenges to build a lasting relationship.Making the Business CaseThe Pentagon has made great strides in positioning itself a more viable tech customer. For example, the Defense Innovation Unit has successfully executed contracts with dozens of technology companies not only in Silicon Valley, but across the country. It has lowered barriers to entry by creating the Commercial Solutions Opening, which de-jargons military requirements by publicizing plain-language problem statements on easily accessible websites rather than the sometimes hundreds of pages long requirements documents that can be found on Fed Biz Opps, a labyrinth only defense contractors can understand. Additionally, Other Transaction Authorities, the contracting mechanism used in the Commercial Solutions Opening, are more flexible and operate orders of magnitude faster than traditional defense contracting.These authorities do more to protect vendors’ intellectual property rights and provide non-dilutive capital to companies, making them a great resource for start-ups and amplifying any external (non-Department of Defense) investments.But the Defense Innovation Unit is not the only option. If technology companies aren’t mature enough to sell a commercial product to the military in a short timescale, they still have options. The military offers early-stage research and development funding through Small Business Innovation Research grants and partners with technology accelerators, like Techstars.





View fullsize







Then Secretary of Defense Ash Carter at the Texas Advanced Computing Center and Visualization Lab, March 31, 2016. (SFC Clydell Kinchen/DOD Photo)





Ultimately, the Defense Department is recognizing the danger of its sluggish acquisition system and taking concrete steps to make doing business with the military easier. Cultural change must follow these efforts, but it’s promising the heads of Army, Navy, and Air Force acquisition all have backgrounds in rapid acquisition. Yet, while the Pentagon has made strides in building a better economic case for company executives, it has shown less concrete progress in addressing the ethical concerns of the research and engineering pioneers of artificial intelligence.All About Talent“The real ‘arms race’ in artificial intelligence is not military competition, but the battle for talent.” The Department of Defense Chief Information Officer recently testified before the House Armed Services Committee’s Emerging Threats and Capabilities Subcommittee, saying the Pentagon’s new Joint Artificial Intelligence Center is “all about talent.” The Department of Defense’s Chief Data Officer said, “Finding, borrowing, begging and creating [artificial intelligence] talent is a really big challenge.” The best artificial intelligence talent is in the private sector, so the Department of Defense must go outside the Pentagon to tap into this talent pool.There are only a few thousand artificial intelligence researchers worldwide capable of leading new artificial intelligence projects. Known as 10x programmers, these individuals are capable of doing the work of 10 people. Tech giants like Google, Amazon, and Microsoft spend hundreds of millions of dollars to acquire and retain this talent; after all, it’s the life blood of their organizations. Without it, their products suffer, profits shrink, and business models collapse. In her War on the Rocks article, Rachel Olney notes, “When Google chose not to pursue follow-on work from the Maven contract, it was driven by an employee petition. For a company as large as Google, Maven was a fairly small contract and the public relations fiasco was hardly worth the revenue it would bring.” However, the heart of the economic decision sits atop an ethical decision: should artificial intelligence experts build products for war? If the Pentagon cannot convince engineers to do that, efforts to effectively integrate and capitalize on the novel commercial products they create will prove to be futile.Neither the Commercial Sector, nor the Military is InfallibleSome fear Russia and China will militarize artificial intelligence without the ethical constraints to which the United States military is subject. The Chinese government has already rolled out ethically murky projects such as the new social credit system built on a panopticon of financial surveillance and facial recognition. But the U.S. military operates on a code of ethics, not a code of economics, and recent studies have found Americans hold the most institutional trust in the military; Amazon and Google rank second and third. That said, technologists will not, and should not, take at face value the Pentagon’s assurances the military will use their creations for moral purposes. History is filled with technologists who regretted the end-uses of their creations, from the idea that Alfred Nobel established the Nobel Peace Prize due to his regret over creating dynamite to the inventor of pepper spray, Kamran Loghman, and his regret over its use by police against protesters. The story of the world’s most destructive weapon, the atomic bomb, cannot be told without the regret of its contributors. Upon witnessing detonation of the first nuclear bomb, Robert Oppenheimer, the father of the atomic bomb, once said, ""We [at the Manhattan Project] thought of the legend of Prometheus, of that deep sense of guilt in man's new powers that reflects his recognition of evil, and his long knowledge of it."" Albert Einstein, whose discoveries led to the development of the bomb, penned a letter to President Roosevelt saying, “Had I known that the Germans would not succeed in developing an atomic bomb, I would have done nothing.”By cooperating with tech companies on ethics, the Pentagon does more than better itself by becoming more educated on emerging ethical dilemmas; importantly, it has the chance to positively influence the future of artificial intelligence.This is not to say the commercial sector is infallible. After all, market forces alone have not delivered a consistent alignment of societal values, especially over time. For instance, Facebook did not do enough to prevent ethnic cleansing in Myanmar and paid teenagers to install spyware on their devices. Further, Google is accused of violating European privacy laws in seven countries and planned to launch one censored search engine in China and another in Russia. By cooperating with tech companies on ethics, the Pentagon does more than better itself by becoming more educated on emerging ethical dilemmas; importantly, it has the chance to positively influence the future of artificial intelligence.What The Pentagon Should Focus OnThe Google Maven letter, signed by over 3,100 employees at the company, says, “We cannot outsource the moral responsibility of our technologies to third parties.” This is something both the Pentagon and Silicon Valley can agree on, which is why technologists need to be intimately involved in how their work is deployed and battlefield commanders must understand the risks in using artificial intelligence when making life and death decisions. Both algorithms and the data that feed them are affected by people, who maintain an inherent level of bias, enabling small bugs to have large, unforeseen impacts. For example, some algorithms exhibit systematic bias. Codified discrimination is a key unintended consequence of artificial intelligence. Google’s facial recognition algorithm mis-identified photos of African-American individuals as gorillas, a Flickr algorithm labeled Native-American dancers as “costume,” and Nikon cameras questioned “Did someone blink?” after taking a photo of an Asian-American person’s face. In military systems, bias can have a much higher cost; misidentifying a military-aged male could threaten his life.Even if technologists refuse to develop or sell certain technologies to the military, their hesitations should be held in high esteem, because they can help the military mitigate worst-case-scenarios.  





View fullsize







Newsweek covers from September 12, 1983 (left) and July 18, 1988 (right), on the USS Vincennes incident. (Newsweek/Wikimedia)





Yet, just as the Pentagon seeks the best technologists, it must seek out brilliant  ethicists to address technology deployment problems. Department of Defense Directive 3000.09 on autonomy in weapon systems is a start, but only that. Some suggest allowing people to stay in the loop will suffice. However, even with human involvement artificial intelligence decision making can result in tragedy, as when the USS Vincennes shot down a civilian passenger jet. Deeper conversations are needed on how to find, address, and combat bias in algorithms, ensure proper disclosure of algorithm faults and failures, and consider how artificial intelligence interacts with human rights. All these efforts must be underpinned by public, accountable conversations of how artificial intelligence should be used. Even if technologists refuse to develop or sell certain technologies to the military, their hesitations should be held in high esteem, because they can help the military mitigate worst-case-scenarios. To use the phrasing of computer security expert Bruce Schneier, the Pentagon must ensure it is “doing the right things [morally]” rather than just “doing things right [by the letter of the law].”The Department of Defense Must ActThe Pentagon is moving in the right direction when it comes to pursuing safe and ethical artificial intelligence principles, but has failed to clearly articulate how it will take action. The Joint Artificial Intelligence Center was established with a “strong commitment to military ethics and [artificial intelligence] safety,” and the Defense Innovation Board is creating ethics guidelines and recommendations for artificial intelligence development and implementation, currently holding public listening sessions to hear the concerns of industry, academia, and the public. Furthermore, the recently released unclassified summary of the 2018 Department of Defense Artificial Intelligence Strategy has a section specifically outlining the Department’s desire to serve as a leader “in military ethics and [artificial intelligence] safety.” These commitments and listening sessions are critical to starting an open, direct, and ongoing dialog between technologists and the Pentagon.But dialog means little without concrete action behind it. What remains to be seen is how much the Defense Department is willing to integrate with the engineers, designers, and ethicists working on developing artificial intelligence products for the military. To build upon its artificial intelligence ethics efforts and concretely demonstrate its commitment to responsible and ethical artificial intelligence use, the Pentagon should: Solidify an ongoing dialog in which trusted advisors can be briefed on and give input to ongoing military projects. These experts should have a similar role as Defense Innovation Board experts, but should also have more working-level knowledge of artificial intelligence research and experience deploying artificial intelligence systems at scale. Follow Facebook’s lead: after its privacy issues, it hired three of its biggest critics.Integrate wherever possible. Bring in artificial intelligence talent to help lead projects such as reforming the military's talent management system or helping to streamline health care. Allow technologists to get exposure to the military, and the military to capitalize on the talent of leading edge technologists. Start on non-controversial projects, such as helping to enhance individualized job detailing as well as ongoing efforts in predictive maintenance and humanitarian response. Once successful, the Pentagon should then slowly transition towards efforts with a more apparent military foci, such as imagery analysis and target     classification.Enable military members to capitalize on experiences working in the private sector, specifically with regards to artificial intelligence. Expand existing programs such as the U.S. Navy’s Tours with Industry or the U.S. Air Force’s Education with Industry, and enable highly talented individuals with technical experience to pursue extended artificial intelligence related residencies.Create virtuous circles. The technology community won’t trust the ethics advisor program from the outset. The Department of Defense must use the ethics advisors and enable them to apply the brakes on small-scale, non-controversial projects like back-end business practices (e.g., logistics, maintenance, talent management) at first. Learning to mitigate, identify, acknowledge, and address bias in non-controversial projects will provide lessons learned for doing it in higher-stakes projects. Small successes will build trust and confidence in the process.ConclusionThe proliferation of artificial intelligence will likely continue to increase in pace, largely driven by the commercial sector. While the economics of contracting will play a key role in bringing companies to the table to work with the U.S. Department of Defense, ethics will be critical in ensuring they remain for the long haul. The ethical dialogue is an important one and cannot simply be brushed off as “catchy headlines or impassioned debate.” The United States has a free and open society, where technologists with ethical qualms aren’t forced to cooperate with the government. Russia and China don’t face this constraint. If the U.S. military is serious about maintaining its competitive edge with respect to artificial intelligence, ethics must play a central role in its strategy for working with the private sector.  



Richard Kuzma is a Navy surface warfare officer passionate about how the Defense Department adapts to emerging technologies, particularly artificial intelligence. He is an alum of the Defense Innovation Unit and the Harvard Kennedy School, and he is an affiliate at Harvard’s Technology and Public Purpose Project. Tom Wester is a Navy surface warfare officer. He received a Bachelors in Mathematics from the United States Naval Academy in and a Masters in Management Science and Engineering from Stanford University, where he focused on national security and technology policy. Tom is a plank owner and served as a project manager for the space portfolio at the Defense Innovation Unit. The views expressed here are the authors’ and do not reflect those of the Defense Innovation Unit, the Department of the Navy, the Department of Defense, or the U.S. Government.



Have a response or an idea for your own article? Follow the logo below, and you too can contribute to The Bridge:















﻿Enjoy what you just read? Please help spread the word to new readers by sharing it on social media.



Header Image: Image from DARPA’s Cyber Grand Challenge. (DARPA)





        Tagged: Artificial Intelligence, AI, Ethics, Autonomous Systems, Google, DIUx




2 Likes

Share


",,,,,,,"Economics Sure, but Don’t Forget Ethics with Artificial Intelligence",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPmh0dHBzOi8vYW1lcmljYW5saWJyYXJpZXNtYWdhemluZS5vcmcvMjAxOS8wMy8wMS9leHBsb3JpbmctYWkv0gEA?oc=5,Exploring AI - American Libraries,2019-03-01,American Libraries,https://americanlibrariesmagazine.org,N/A,N/A,"The impact of even this early wave of artificial intelligence (AI)—including voice assistants and machine learning (ML)—is still uncertain in many fields, but it is time to include AI on our professional agenda and in our national conversation. In talking with librarians working in this area, it’s clear that while AI can be useful, it … Continue reading Exploring AI →",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

Exploring AIHow libraries are starting to apply artificial intelligence in their work


			By Loida Garcia-Febo | 		
March 1, 2019




FacebookTwitterEmailPrint
I have recently started to hear more phrases such as, “I don’t have to visit a library; I just ask Alexa [or Siri or Google Assistant] and it tells me everything I need to know. I speak to it all day.”
The impact of even this early wave of artificial intelligence (AI)—including voice assistants and machine learning (ML)—is still uncertain in many fields, but it is time to include AI on our professional agenda and in our national conversation.
In talking with librarians working in this area, it’s clear that while AI can be useful, it also raises
familiar concerns about privacy, intellectual freedom, authority, and access. And there are diversity considerations, as well, including access for people with different linguistic styles or abilities.
Fortunately, librarians are looking at AI from several perspectives. Some are using it to teach
information literacy and critical-thinking skills to help patrons formulate questions for these devices
and learn how to evaluate responses. University of Rhode Island, for example, is housing its collaborative efforts around AI in the library. Cambridge (Mass.) Public Library (CPL) partnered with MIT Libraries and Harvard metaLAB to host the installation “Laughing Room,” in which participants enter an artificially intelligent room that plays a laugh track whenever something is said that the room’s algorithm deems funny. CPL Director Maria McCauley says this helped people to consider the impact of surveillance and AI on their lives. To further engage library users with big issues in science and technology shaping our society, the library will host a public dialogue about humor, culture, and AI with Harvard Law School’s Cyberlaw Clinic this spring.
At MIT, Chris Bourg, director of libraries, is focusing on building a technical infrastructure so its collections are accessible by APIs and therefore can be used by machine-learning algorithms. MIT Libraries is working with AI/ML researchers at the university to analyze various library tasks and workflows that might be enhanced by AI. As Bourg says, it is important for academic libraries to make their collections accessible to AI tools like Alexa so that when someone asks a voice assistant for information, reputable scholarly literature is available. To make this successful, libraries will have to work to ensure scholarly information is openly accessible, not locked behind paywalls.
All this may be a lot of new information to process. But Catherine Nicole Coleman, digital research architect at Stanford Libraries in Palo Alto, California, has a good approach: Last year, Coleman conducted “Library AI Conversations” to help library workers familiarize themselves with the latest research and issues. She also worked mostly with bibliographers, archivists, and catalogers to explore the possibilities of AI for metadata and collection development. Additionally, they are collaborating with computer science faculty and faculty in the humanities and social sciences to explore human–machine collaboration, interaction, and interface.
At ALA, we have resources to help library workers understand AI, these new devices, and the role of libraries. The Center for the Future of Libraries has written about voice-control devices; the January issue of Library Technology Reports explores AI and ML; and many of our conferences—including the Library and Information Technology Association’s forum and the Association of College and Research Libraries national conference—include sessions on AI.
My fellow library workers, the future of libraries will continue to be about the communities we serve. Librarians and library professionals will need to be at the forefront to support communities as these technologies transform our world. Let’s continue the conversation and learn together.


LOIDA GARCIA-FEBO is an international library consultant.
 
Share
FacebookTwitterEmailPrint 

Tagged UnderALA Presidentartificial intelligence 




",,,,,,,,,,,,,,,,,,"[{'@type': 'WebSite', '@id': 'https://americanlibrariesmagazine.org/#website', 'url': 'https://americanlibrariesmagazine.org/', 'name': 'American Libraries Magazine', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://americanlibrariesmagazine.org/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://americanlibrariesmagazine.org/2019/03/01/exploring-ai/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://americanlibrariesmagazine.org/wp-content/uploads/2018/07/garcia-febo-loida-pres.jpg', 'width': 465, 'height': 303, 'caption': 'Loida Garcia-Febo'}, {'@type': 'WebPage', '@id': 'https://americanlibrariesmagazine.org/2019/03/01/exploring-ai/#webpage', 'url': 'https://americanlibrariesmagazine.org/2019/03/01/exploring-ai/', 'name': 'Exploring AI | American Libraries Magazine', 'isPartOf': {'@id': 'https://americanlibrariesmagazine.org/#website'}, 'primaryImageOfPage': {'@id': 'https://americanlibrariesmagazine.org/2019/03/01/exploring-ai/#primaryimage'}, 'datePublished': '2019-03-01T14:32:05+00:00', 'dateModified': '2019-02-21T16:12:55+00:00', 'author': {'@id': 'https://americanlibrariesmagazine.org/#/schema/person/744ada2619fe876a8c80889a4442fab2'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://americanlibrariesmagazine.org/2019/03/01/exploring-ai/']}]}, {'@type': 'Person', '@id': 'https://americanlibrariesmagazine.org/#/schema/person/744ada2619fe876a8c80889a4442fab2', 'name': 'Amy Carlton', 'image': {'@type': 'ImageObject', '@id': 'https://americanlibrariesmagazine.org/#personlogo', 'inLanguage': 'en-US', 'url': 'https://secure.gravatar.com/avatar/9ef885131477545099f778f1a3d223e6?s=96&d=mm&r=g', 'caption': 'Amy Carlton'}}]",,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vbmV3cy5hcnRuZXQuY29tL21hcmtldC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1zb3RoZWJ5cy0xNDgxNTkw0gFQaHR0cHM6Ly9uZXdzLmFydG5ldC5jb20vbWFya2V0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXNvdGhlYnlzLTE0ODE1OTAvYW1wLXBhZ2U?oc=5,"Sotheby’s First Auction of an AI Artwork Fails to Incite a Robo-Frenzy, Fetching a Modest $51,000 - artnet News",2019-03-06,artnet News,https://news.artnet.com,"Mario Klingemann's ""Memories of Passersby I"" fetched $51,000 at Sotheby's London contemporary day sale on March 6.","art artificial intelligence, mario klingemann, sotheby's, AI art auction, christie's, obvious, artnet-news","Mario Klingemann's ""Memories of Passersby I"" fetched $51,000 at Sotheby's London contemporary day sale on March 6.",N/A,https://schema.org,,,,,,,,,,,,,Market,N/A,"





Market

Sotheby’s First Auction of an AI Artwork Fails to Incite a Robo-Frenzy, Fetching a Modest $51,000
After a six-figure sale at Christie's in New York, Mario Klingemann's innovative installation that creates surreal portraits sells for $51,000.





Mario Klingemann, Memories of Passersby I (2018). Image courtesy Sotheby's.










Naomi Rea 
March 6, 2019


 ShareShare This Article




Sotheby’s dipped its toes into the market for artwork created using artificial intelligence this morning in London, selling a work by Mario Klingemann titled Memories of Passersby I. The innovative installation by a pioneer of AI art went for £40,000 ($51,012) with fees. The first auction of an AI work in Europe proved to be something of an anticlimax after Christie’s entered the market last October, selling a work attributed to an algorithm for an unprecedented $432,500 in New York.
Klingemann’s work uses neural networks to generate an infinite stream of imaginary portraits, which are projected onto the two-screen installation. The German artist was among the first creative coders to experiment with artificial intelligence and art. The art movement, which Klingemann calls “neurography,” has grown in profile since the Christie’s sale, and many were watching to see whether the rival auction house would match the hype.
The bidding at Sotheby’s started at a more muted £20,000 (or $26,000) and ended just over a minute later with an online bidder securing the work for £32,000 ($42,000), well below its upper estimate of £40,000 ($51,012) without the buyer’s fee. 
Like Christie’s in New York, Sotheby’s opted to sell Klingemann’s work in a day sale. However, where the algorithm-attributed work at Christie’s counted among the prints and multiples, Klingemann’s installation was among the early lots in the auction house’s contemporary day sale, which included work by Peter Doig and Harold Ancart, and the sale marked Rose Wylie’s auction debut (her work Listening to Miss S sold for $135,501 with fees). Klingemann’s work hit the block 9th among the sale’s 223 lots. Shortly afterwards, a work by Gerhard Richter reached $1,120,989 with fees, and an untitled 1983 work by Keith Haring fetched $1,243,418 with fees.
Sotheby’s describes Klingemann’s work as creating unique portraits in real time, writing in a statement that, for the viewer, “the experience is something like watching an act of endless imagination take place in the mind of a machine—while the human subject matter of its visions adds a further layer of poignancy.”
Klingemann spent around three months creating the work. He trained the neural network that produces the surreal images based on of thousands of portraits from the 17th to 19th centuries. He also taught it to share his own aesthetic leanings using a Tinder-like selection process. In the installation, the computer generates new faces as you watch it, each strange feature morphing into the next, sometimes stuttering as it “thinks” about the next image. The end result is something that Sotheby’s likens to the simultaneously disturbing and appealing “convulsive beauty” of the French writer behind the first Surrealist Manifesto, André Breton.
Another edition of the work is currently on view at the Colección Solo in Madrid. Other examples of Klingemann’s work have been shown at the Ars Electronica Festival, MoMA and the Met in New York. In 2018 he received the Lumen Prize which recognizes artwork created with technology.
Sotheby’s contemporary art specialist Marina Ruiz Colomer presented the piece as a breakthrough when the sale was announced in February. “It is the nature of Contemporary Art to push boundaries,” she said. “AI art is the latest innovation winning its place in art history books, and Klingemann’s work stands on the precipice of an exciting new era in our field.”
Follow Artnet News on Facebook: 

Want to stay ahead of the art world? Subscribe to our newsletter to get the breaking news, eye-opening interviews, and incisive critical takes that drive the conversation forward.








 Share This ArticleShare This Article






 
 
 Naomi Rea
Acting Editor-in-Chief
 




 








            The best of Artnet News in your inbox.
        

            Sign up to our daily newsletter.
        








Please enter a valid email address
Signup failed. Please try again later.



Thank you!
You have successfully subscribed to Artnet News.











 

                Related Articles
            










Auctions




Has the AI-Generated Art Bubble Already Burst? Buyers Greeted Two Newly Offered Works at Sotheby’s With Lackluster Demand


			By
							Caroline Goldstein,
							Nov 15, 2019
						


 









Opinion




A Gallery Has Sold More Than $1 Million in Art Made by an Android, But Collectors Are Buying Into a Sexist Fantasy


			By
							Naomi Rea,
							Jun 6, 2019
						


 









Auctions




A German Fashion Retailer Is Selling More Than 4,000 Artworks to Finance a ‘Digital Transformation’


			By
							Kate Brown,
							Mar 14, 2019
						


 





            The best of Artnet News in your inbox.
        

            Sign up to our daily newsletter.
        








Please enter a valid email address
Signup failed. Please try again later.



Thank you!
You have successfully subscribed to Artnet News.



 




                                More Trending Stories
                            



Up Next
                                                    







                                                            Why the Art World Is Just Waking Up to Sophie von Hellermann’s Dream-Like Visions
                                                        





Art & Exhibitions
                                                    







                                                            There’s More to Rome Than Ancient History. Check Out These Must-See Contemporary Gems
                                                        





Art & Exhibitions
                                                    







                                                            The Story Behind a Rare 19th-Century Portrait of a Person of Color Emerges
                                                        





Artists
                                                    







                                                            ‘The More Repellent You Are, the More Attractive You Become’: George Condo on Contemporary Mythmaking
                                                        









                                                            Up Next
                                                        


                                                                Why the Art World Is Just Waking Up to Sophie von Hellermann’s Dream-Like Visions
                                                            













                                                            Art & Exhibitions
                                                        


                                                                There’s More to Rome Than Ancient History. Check Out These Must-See Contemporary Gems
                                                            













                                                            Art & Exhibitions
                                                        


                                                                The Story Behind a Rare 19th-Century Portrait of a Person of Color Emerges
                                                            













                                                            Artists
                                                        


                                                                ‘The More Repellent You Are, the More Attractive You Become’: George Condo on Contemporary Mythmaking
                                                            











",,,,,,,,,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://news.artnet.com/#organization', 'name': 'Artnet News', 'url': 'https://news.artnet.com/', 'sameAs': [], 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/#/schema/logo/image/', 'url': 'https://news.artnet.com/app/news-upload/2023/02/news-logo-64x64-1.png', 'contentUrl': 'https://news.artnet.com/app/news-upload/2023/02/news-logo-64x64-1.png', 'width': 64, 'height': 64, 'caption': 'Artnet News'}, 'image': {'@id': 'https://news.artnet.com/#/schema/logo/image/'}}, {'@type': 'WebSite', '@id': 'https://news.artnet.com/#website', 'url': 'https://news.artnet.com/', 'name': 'Artnet News', 'description': 'The world’s most-read and best trusted art publication', 'publisher': {'@id': 'https://news.artnet.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.artnet.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#primaryimage', 'url': 'https://news.artnet.com/app/news-upload/2019/02/Memories-of-Passersby-5-e1549626953307.jpg', 'contentUrl': 'https://news.artnet.com/app/news-upload/2019/02/Memories-of-Passersby-5-e1549626953307.jpg', 'width': 1000, 'height': 667, 'caption': ""Mario Klingemann, Memories of Passersby I (2018). Image courtesy Sotheby's.""}, {'@type': 'WebPage', '@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#webpage', 'url': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590', 'name': ""Sotheby's First Auction of an AI Artwork Fails to Incite a Robo-Frenzy, Fetching a Modest $51,000 | Artnet News"", 'isPartOf': {'@id': 'https://news.artnet.com/#website'}, 'primaryImageOfPage': {'@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#primaryimage'}, 'datePublished': '2019-03-06T12:33:20+00:00', 'dateModified': '2019-03-06T15:02:46+00:00', 'description': 'Mario Klingemann\'s ""Memories of Passersby I"" fetched $51,000 at Sotheby\'s London contemporary day sale on March 6.', 'breadcrumb': {'@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.artnet.com/market/artificial-intelligence-sothebys-1481590']}]}, {'@type': 'BreadcrumbList', '@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.artnet.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Sotheby&#8217;s First Auction of an AI Artwork Fails to Incite a Robo-Frenzy, Fetching a Modest $51,000'}]}, {'@type': 'NewsArticle', '@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#article', 'isPartOf': {'@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#webpage'}, 'author': {'@id': 'https://news.artnet.com/#/schema/person/ba743d578bca1480ede0230f5a0e91be'}, 'headline': 'Sotheby&#8217;s First Auction of an AI Artwork Fails to Incite a Robo-Frenzy, Fetching a Modest $51,000', 'datePublished': '2019-03-06T12:33:20+00:00', 'dateModified': '2019-03-06T15:02:46+00:00', 'mainEntityOfPage': {'@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#webpage'}, 'wordCount': 560, 'publisher': {'@id': 'https://news.artnet.com/#organization'}, 'image': {'@id': 'https://news.artnet.com/market/artificial-intelligence-sothebys-1481590#primaryimage'}, 'thumbnailUrl': 'https://news.artnet.com/app/news-upload/2019/02/Memories-of-Passersby-5-e1549626953307.jpg', 'articleSection': 'Market', 'inLanguage': 'en-US', 'isAccessibleForFree': 'True', 'hasPart': {'@type': 'WebPageElement', 'isAccessibleForFree': 'True', 'cssSelector': '.article-body'}, 'alternativeHeadline': 'Sotheby&#8217;s First Auction of an AI Artwork Fails to Incite a Robo-Frenzy, Fetching a Modest $51,000 | Artnet News', 'description': {}, 'keywords': []}, {'@type': 'Person', '@id': 'https://news.artnet.com/#/schema/person/ba743d578bca1480ede0230f5a0e91be', 'name': 'Naomi Rea', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.artnet.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/a36033d037b111ee6cd86f7936667840?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/a36033d037b111ee6cd86f7936667840?s=96&d=mm&r=g', 'caption': 'Naomi Rea'}, 'description': ""Naomi Rea is Artnet News's Acting Editor-in-Chief, where she has worked since 2017. She is based in London, U.K."", 'sameAs': ['https://www.instagram.com/naomikrea/', 'https://twitter.com/naomikrea'], 'url': 'https://news.artnet.com/about/naomi-rea-419'}]",,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vYXNzb2NpYXRpb25zbm93LmNvbS8yMDE5LzAzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFzc29jaWF0aW9uLXRlYW0tcGxhbm5pbmcv0gEA?oc=5,Machine Learning: Optimize Your Team for Artificial Intelligence - Associations Now,2019-03-01,Associations Now,https://associationsnow.com,"Integrating AI into your organization’s daily work isn’t as effortless as flipping a switch, but it's easier if you start with the right framework and the right people.",N/A,"Integrating AI into your organization’s daily work isn’t as effortless as flipping a switch, but it's easier if you start with the right framework and the right people.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"



 


Technology
Machine Learning: Optimize Your Team for Artificial Intelligence
 Integrating artificial intelligence into your organization’s daily work isn’t as effortless as flipping a switch, but it's easier if you start with the right framework and the right people. 

By Ernie Smith
Mar 01, 2019







Share



Share



Share



Sure, technologies like machine learning, natural language processing, and automation could help reshape how your association works and serves its members. But finding the right opportunities, and staffing with those opportunities in mind, is the hard part, especially if there’s resistance within your team. Overcoming these challenges could open up a lot of opportunities to take advantage of artificial intelligence down the line. Here are a few considerations for getting your AI ducks in a row. Forge the Right Internal Team You don’t necessarily need AI experts on your staff, said Amith Nagarajan, chairman of the AI-driven newsletter platform Rasa.io. What does matter is whether those staff members have a “growth mindset,” a degree of curiosity, and focus on continued learning that isn’t defined “by their list of prior job functions and tasks they’ve completed.” 



 

“Associations generally won’t be creating any new AI technology but rather applying it,” said Nagarajan. “They don’t need deep AI skills; they need to have people who can apply the AI, at times with a little boost from outside help when it makes sense.” Peter Fitzsimmons, founder and CEO of Contexture, which specializes in machine learning and natural language processing solutions, agreed that collaboration between internal teams and outside AI experts, when the latter are needed, can produce good results. “Engage with and have good working relationships with those technology experts that do understand AI technology and can provide important perspectives at the right times to the whole senior team,” he said. Find the Right Use Case Nagarajan suggested that the best place to implement AI isn’t at the center of your technology stack, but in “edge-case scenarios” that don’t require integration with existing systems. “The problem is that since changing existing processes has so many issues, you end up spending more time on politics, systems integration, and other things that don’t advance your organization’s ability to learn about AI and its applications in real time,” he said. AI is often a good fit for new projects, Fitzsimmons noted. “Look at the critical areas that up until this point have been either so expensive or too time-consuming or ineffective in impact that you haven’t been able to consider them,” he said. AI shouldn’t be a solution in search of a problem, he added, but rather a technology that “might be able to add value in the right solution for you.” Integrate the Right Way Although associations might not yet need techies with extensive AI skill sets, Fitzsimmons said it’s important that someone in the organization “owns” artificial intelligence. But “owning” AI isn’t the same as being in charge of managing a piece of enterprise software, Nagarajan noted, because it’s less a tool and more a discipline. “AI is not a one-shot deal like implementing an AMS or [learning management system]; you need to think of it as a series of small and rapid experiments with the goal of some successes,” he said. “But constant learning along the way is the overarching goal. If you don’t spend time to learn about these capabilities by testing them out, you will quickly fall behind.”
(MF3d/iStock/Getty Images Plus)





 


By  Ernie Smith




Mail




Ernie Smith is a former senior editor for Associations Now. MORE
Got an article tip for us? Contact us and let us know!







",,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/#article', 'isPartOf': {'@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/'}, 'author': [{'@id': 'https://associationsnow.com/#/schema/person/ffd09f2bdf12416f0eab51d82eaaa9c8'}], 'headline': 'Machine Learning: Optimize Your Team for Artificial Intelligence', 'datePublished': '2019-03-01T18:55:32+00:00', 'dateModified': '2021-11-09T17:13:05+00:00', 'mainEntityOfPage': {'@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/'}, 'wordCount': 573, 'publisher': {'@id': 'https://associationsnow.com/#organization'}, 'image': {'@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/#primaryimage'}, 'thumbnailUrl': 'https://associationsnow.com/wp-content/uploads/2019/02/GettyImages-948285004.jpg', 'articleSection': ['Technology'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/', 'url': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/', 'name': 'Machine Learning: Optimize Your Team for Artificial Intelligence | Associations Now', 'isPartOf': {'@id': 'https://associationsnow.com/#website'}, 'primaryImageOfPage': {'@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/#primaryimage'}, 'image': {'@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/#primaryimage'}, 'thumbnailUrl': 'https://associationsnow.com/wp-content/uploads/2019/02/GettyImages-948285004.jpg', 'datePublished': '2019-03-01T18:55:32+00:00', 'dateModified': '2021-11-09T17:13:05+00:00', 'description': ""Integrating AI into your organization’s daily work isn’t as effortless as flipping a switch, but it's easier if you start with the right framework and the right people."", 'breadcrumb': {'@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/#primaryimage', 'url': 'https://associationsnow.com/wp-content/uploads/2019/02/GettyImages-948285004.jpg', 'contentUrl': 'https://associationsnow.com/wp-content/uploads/2019/02/GettyImages-948285004.jpg', 'width': 1000, 'height': 600}, {'@type': 'BreadcrumbList', '@id': 'https://associationsnow.com/2019/03/artificial-intelligence-association-team-planning/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://associationsnow.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Topics', 'item': 'https://associationsnow.com/topics/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Machine Learning: Optimize Your Team for Artificial Intelligence'}]}, {'@type': 'WebSite', '@id': 'https://associationsnow.com/#website', 'url': 'https://associationsnow.com/', 'name': 'Associations Now', 'description': 'News, insight and analysis for association leaders', 'publisher': {'@id': 'https://associationsnow.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://associationsnow.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://associationsnow.com/#organization', 'name': 'Associations Now', 'url': 'https://associationsnow.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://associationsnow.com/#/schema/logo/image/', 'url': 'https://associationsnow.com/wp-content/uploads/2021/11/an_logo_black_update-768x231-1.png', 'contentUrl': 'https://associationsnow.com/wp-content/uploads/2021/11/an_logo_black_update-768x231-1.png', 'width': 768, 'height': 231, 'caption': 'Associations Now'}, 'image': {'@id': 'https://associationsnow.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://associationsnow.com/#/schema/person/ffd09f2bdf12416f0eab51d82eaaa9c8', 'name': 'Ernie Smith', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://associationsnow.com/#/schema/person/image/0f8c36624136e0242d6ec78aaee91dfd', 'url': 'https://associationsnow.com/wp-content/uploads/2022/01/ernie-e1643336096604.jpg', 'contentUrl': 'https://associationsnow.com/wp-content/uploads/2022/01/ernie-e1643336096604.jpg', 'caption': 'Ernie Smith'}, 'description': 'Ernie Smith is a former senior editor for Associations Now.', 'sameAs': ['https://x.com/ErnieSmithAN'], 'url': 'https://associationsnow.com/author/erniesmith/'}]",,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTkvMDMvMDEvYnVzaW5lc3MvZXRoaWNzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLmh0bWzSAQA?oc=5,Is Ethical A.I. Even Possible? - The New York Times,2019-03-01,The New York Times,https://www.nytimes.com,"Idealism can eventually bow to financial pressure and artificial intelligence companies, big and small, can change course.",N/A,"Idealism can eventually bow to financial pressure and artificial intelligence companies, big and small, can change course.","Idealism can eventually bow to financial pressure and artificial intelligence companies, big and small, can change course.",https://schema.org,NewsMediaOrganization,Is Ethical A.I. Even Possible?,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/03/04/business/04AI-cover-web/merlin_151459872_29742e09-27b4-42b5-871c-95c29f9bae98-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2019/03/04/business/04AI-cover-web/merlin_151459872_29742e09-27b4-42b5-871c-95c29f9bae98-videoSixteenByNineJumbo1600.jpg', 'caption': 'Building ethical artificial intelligence is an enormously complex task. It gets even harder when stakeholders realize that ethics are in the eye of the beholder.', 'creditText': 'John Hersey'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/03/04/business/04AI-cover-web/merlin_151459872_29742e09-27b4-42b5-871c-95c29f9bae98-superJumbo.jpg', 'height': 1393, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2019/03/04/business/04AI-cover-web/merlin_151459872_29742e09-27b4-42b5-871c-95c29f9bae98-superJumbo.jpg', 'caption': 'Building ethical artificial intelligence is an enormously complex task. It gets even harder when stakeholders realize that ethics are in the eye of the beholder.', 'creditText': 'John Hersey'}]",,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/cade-metz', 'name': 'Cade Metz'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,2019-03-01T22:16:13.000Z,2019-03-04T14:23:34.000Z,,https://www.nytimes.com/,https://www.nytimes.com/2019/03/01/business/ethics-artificial-intelligence.html,Business,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTIs Ethical A.I. Even Possible?Share full article33Read in appVideotranscriptBackbars0:00/1:41-0:00transcriptWhat Does the Future Hold for A.I.?Some of the top minds in tech and policy shared their outlooks for artificial intelligence and its applications at The New York Times’s New Work Summit/Leading in the Age of A.I. conference.“Technology and public purpose is the issue of our time.” “Has this been, in a sense, a growing up moment for Snap?” “To say the least.” “There will be a day in the future when this technology will help American soldiers rescue hostages.” “I deserve the right to know that I am not contributing to weapon systems that, as perhaps a non-US citizen, would harm my family.” “The goal is to inject a little bit of empathy and emotional intelligence into our machines and digital experiences.” “Do we think we can design a world that looks different, a world that is food secure, a world that is more sustainable? Yes, we can.” “A society that is designed to pay a large number of people for not working is going to be a very unhappy society.” “These companies have also created like intensely secretive, insular, almost cult-like — “ “Correct.” “ — cultures.” “I’ve actually spent years going into cults to study how they operate. And the parallels are really pretty crazy.” “Yeah, like [inaudible].” “In cults, they call it a love bomb. So when you enter, they basically give you so much love, you feel so welcome and so supported, and it’s like the family you never had that now, you don’t want to leave.” “We can’t have a productive conversation where we talk about the nuance in all this. I think we’ll be in a bad place.” “They know how to teach a machine to do something new. Then the question is, have they been able to apply that in a way that is going to be profitable for them?” “In this new world of technology innovation, we are all immigrants, right? We are not immigrants physically in this new geography. But in this conceptual world, we are immigrants. Let’s take on that mentality.”AD0:14







Advertisement

LIVE
      


00:00









1:41
































Some of the top minds in tech and policy shared their outlooks for artificial intelligence and its applications at The New York Times’s New Work Summit/Leading in the Age of A.I. conference.CreditCredit...Mike Cohen for The New York TimesBy Cade MetzMarch 1, 2019HALF MOON BAY, Calif. — When a news article revealed that Clarifai was working with the Pentagon and some employees questioned the ethics of building artificial intelligence that analyzed video captured by drones, the company said the project would save the lives of civilians and soldiers.“Clarifai’s mission is to accelerate the progress of humanity with continually improving A.I.,” read a blog post from Matt Zeiler, the company’s founder and chief executive, and a prominent A.I. researcher. Later, in a news media interview, Mr. Zeiler announced a new management position that would ensure all company projects were ethically sound.As activists, researchers, and journalists voice concerns over the rise of artificial intelligence, warning against biased, deceptive and malicious applications, the companies building this technology are responding. From tech giants like Google and Microsoft to scrappy A.I. start-ups, many are creating corporate principles meant to ensure their systems are designed and deployed in an ethical way. Some set up ethics officers or review boards to oversee these principles.But tensions continue to rise as some question whether these promises will ultimately be kept. Companies can change course. Idealism can bow to financial pressure. Some activists — and even some companies — are beginning to argue that the only way to ensure ethical practices is through government regulation.AdvertisementSKIP ADVERTISEMENT“We don’t want to see a commercial race to the bottom,” Brad Smith, Microsoft’s president and chief legal officer, said at the New Work Summit in Half Moon Bay, Calif., hosted last week by The New York Times. “Law is needed.”The new ethics position at Clarifai never materialized. As this New York City start-up pushed further into military applications and facial recognition services, some employees grew increasingly concerned their work would end up feeding automated warfare or mass surveillance. In late January, on a company message board, they posted an open letter asking Mr. Zeiler where their work was headed.ImageBuilding ethical artificial intelligence is an enormously complex task. It gets even harder when stakeholders realize that ethics are in the eye of the beholder.Credit...John HerseyA few days later, Mr. Zeiler held a companywide meeting, according to three people who spoke on the condition that they not be identified for fear of retaliation. He explained that internal ethics officers did not suit a small company like Clarifai. And he told the employees that Clarifai technology would one day contribute to autonomous weapons.Clarifai specializes in technology that instantly recognizes objects in photos and video. Policymakers call this a “dual-use technology.” It has everyday commercial applications, like identifying designer handbags on a retail website, as well as military applications, like identifying targets for drones.AdvertisementSKIP ADVERTISEMENTThis and other rapidly advancing forms of artificial intelligence can improve transportation, health care and scientific research. Or they can feed mass surveillance, online phishing attacks and the spread of false news.Discovering a BiasAs companies and governments deploy these A.I. technologies, researchers are also realizing that some systems are woefully biased. Facial recognition services, for instance, can be significantly less accurate when trying to identify women or someone with darker skin. Other systems may include security holes unlike any seen in the past. Researchers have shown that driverless cars can be fooled into seeing things that are not really there.All this means that building ethical artificial intelligence is an enormously complex task. It gets even harder when stakeholders realize that ethics are in the eye of the beholder.As some Microsoft employees protest the company’s military contracts, Mr. Smith said that American tech companies had long supported the military and that they must continue to do so. “The U.S. military is charged with protecting the freedoms of this country,” he told the conference. “We have to stand by the people who are risking their lives.”AdvertisementSKIP ADVERTISEMENTThough some Clarifai employees draw an ethical line at autonomous weapons, others do not. Mr. Zeiler argued that autonomous weapons will ultimately save lives because they would be more accurate than weapons controlled by human operators. “A.I. is an essential tool in helping weapons become more accurate, reducing collateral damage, minimizing civilian casualties and friendly fire incidents,” he said in a statement.Google worked on the same Pentagon project as Clarifai, and after a protest from company employees, the tech giant ultimately ended its involvement. But like Clarifai, as many as 20 other companies have worked on the project without bowing to ethical concerns.After the controversy over its Pentagon work, Google laid down a set of “A.I. principles” meant as a guide for future projects. But even with the corporate rules in place, some employees left the company in protest. The new principles are open to interpretation. And they are overseen by executives who must also protect the company’s financial interests.“You functionally have situations where the foxes are guarding the henhouse,” said Liz Fong-Jones, a former Google employee who left the company late last year.In 2014, when Google acquired DeepMind, perhaps the world’s most important A.I. lab, the company agreed to set up an external review board that would ensure the lab’s research would not be used in military applications or otherwise unethical projects. But five years later, it is still unclear whether this board even exists.AdvertisementSKIP ADVERTISEMENTGoogle, Microsoft, Facebook and other companies have created organizations like the Partnership on A.I. that aim to guide the practices of the entire industry. But these operations are largely toothless.Workers Speak OutThe most significant changes have been driven by employee protests, like the one at Google, and pointed research from academics and other independent experts. After Amazon employees protested the sale of facial recognition services to police departments and various academic studies highlighted the bias that plagues these services, Amazon and Microsoft called for government regulation in this area.“People are recognizing there are issues, and they are recognizing they want to change them,” said Meredith Whittaker, a Google employee and the co-founder of the AI Now Institute, a research institute that examines the social implications of artificial intelligence. But she also told the conference that this change was slow to happen, as the forces of capitalism continued to drive these companies toward greater profits.Image“We don’t want to see a commercial race to the bottom,” Brad Smith, Microsoft’s president and chief legal officer, said at The New York Times’s New Work Summit in California. “Law is needed.”Credit...John HerseyEmployees at Clarifai worry that the same technological tools that drive facial recognition will ultimately lead to autonomous weapons — and that flaws in these tools will open a Pandora’s box of problems. “We in the industry know that technology can be compromised. Hackers hack. Bias is unavoidable,” read the open letter to Mr. Zeiler.AdvertisementSKIP ADVERTISEMENTThousands of A.I. researchers from across the industry have signed a separate open letter saying they will oppose autonomous weapons.The Pentagon has said that artificial intelligence built by the likes of Google and Clarifai has not been used for offensive purposes. And it is now building its own set of ethical principles, realizing it needs the support of industry, which has snapped up most of the world’s top A.I. researchers in recent years.But many policy experts say they believe these principles are unlikely to hold any more influence than those laid down at the big corporations, especially because the Pentagon is motivated to keep pace with China, Russia and other international rivals as they develop similar technology. For that reason, some are calling for international treaties that would bar the use of autonomous weapons.Is Regulation the Answer?In their open letter, the Clarifai employees said they were unsure whether regulation was the answer to the many ethical questions swirling around A.I. technology, arguing that the immediate responsibility rested with the company itself.“Regulation slows progress, and our species needs progress to survive the many threats that face us today,” they wrote, addressing Mr. Zeiler and the rest of the company. “We need to be ethical enough to be trusted to make this technology on our own, and we owe it to the public to define our ethics clearly.”AdvertisementSKIP ADVERTISEMENTBut their letter did not have the desired effect. In the days after Mr. Zeiler explained that Clarifai would most likely contribute to autonomous weapons, the employee who wrote the letter and was originally tapped to serve as an ethics adviser, Liz O’Sullivan, left the company.Researchers and activists like Ms. Whittaker see this as a moment when tech employees can use their power to drive change. But they have also said this must happen outside tech companies as well as within.“We need regulation,” Ms. Whittaker said, before name-dropping Microsoft’s chief legal officer. “Even Brad Smith says we need regulation.”A version of this article appears in print on March 1, 2019, Section F, Page 2 of the New York edition with the headline: Promises to Keep. Order Reprints | Today’s Paper | SubscribeRead 33 CommentsShare full article33Read in appAdvertisementSKIP ADVERTISEMENTComments 33Is Ethical A.I. Even Possible?Skip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Tell us about yourself. Take the survey.","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",The New York Times,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,Promises to Keep,[{'@id': 'https://www.nytimes.com/video/embedded/technology/100000006392039/what-does-the-future-hold-for-ai.html'}],{'@id': '#commentsContainer'},33.0,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmJpempvdXJuYWxzLmNvbS9ob3VzdG9uL25ld3MvMjAxOS8wMy8wNS9odW1hbi1za2lsbHMtbmVlZC10by1zaGFycGVuLXRvLWNvZXhpc3Qtd2l0aC5odG1s0gEA?oc=5,Human skills need to sharpen to coexist with machines - Houston Business Journal - The Business Journals,2019-03-05,The Business Journals,https://www.bizjournals.com,Artificial intelligence will inevitably work alongside humans in organizations.,"Human Resources, Career Workplace",Artificial intelligence will inevitably work alongside humans in organizations.,Artificial intelligence will inevitably work alongside humans in organizations.,https://schema.org,NewsArticle,Human skills need to sharpen to coexist with machines,"[{'@type': 'ImageObject', 'url': 'https://media.bizj.us/view/img/11200449/stephanie-rogers*1200xx2333-2333-0-20.jpg', 'width': 1200, 'height': 1200, 'caption': 'Stephanie Rogers, managing director, talent and organization for Accenture.'}, {'@type': 'ImageObject', 'url': 'https://media.bizj.us/view/img/11200449/stephanie-rogers*1200xx2333-1750-0-20.jpg', 'width': 1200, 'height': 900, 'caption': 'Stephanie Rogers, managing director, talent and organization for Accenture.'}, {'@type': 'ImageObject', 'url': 'https://media.bizj.us/view/img/11200449/stephanie-rogers*1200xx2333-1313-0-141.jpg', 'width': 1200, 'height': 675, 'caption': 'Stephanie Rogers, managing director, talent and organization for Accenture.'}]",,"{'@type': 'Person', 'name': 'Stephanie Rogers and Aleek Datta'}","{'@type': 'NewsMediaOrganization', 'name': 'Houston Business Journal', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.bizjournals.com/static/img/logos/houston-logo.png', 'width': 212, 'height': 48}, 'sameAs': ['http://www.facebook.com/pages/Houston-Business-Journal/160132337568', 'http://www.linkedin.com/company/houston-business-journal', 'https://www.instagram.com/houbizjournal', 'https://twitter.com/HOUBizjournal']}",2019-03-05T14:26:00-05:00,2019-03-05T14:26:00-05:00,,,https://www.bizjournals.com/houston/news/2019/03/05/human-skills-need-to-sharpen-to-coexist-with.html,"{'@type': 'WebPage', '@id': 'https://www.bizjournals.com/houston/news/2019/03/05/human-skills-need-to-sharpen-to-coexist-with.html'}",N/A,N/A,"Artificial intelligence will inevitably work alongside humans in organizations. Welcome! Register now to read your first few articles at no cost.Create a FREE account. Register Already have an account?  Sign in Three in four Houston leaders surveyed said within the next two years artificial intelligence (AI) will work side by side with the humans in their organizations as a co-workers, collaborators and trusted advisers. As we see more human-machine collaboration in the workplace, our jobs will rapidly change and so will the skills required to perform those jobs.In fact, Accenture’s report on future workforce found that from truck drivers to nurses and chemical engineers, complex reasoning, creativity, socio-emotional intelligence and sensory perception are the skills that are rising in importance across almost every single work role.In other words, humans have to get good at what humans do best. CREATE YOUR FREE ACCOUNTBECOME A MEMBERJoin the Houston Business Journal to unlock even more insights!Email Address *Password *Show Zip Code *  Join Now  Sign-in   |   Premium Memberships  By submitting your information you are agreeing to our Privacy Policy and User Agreement. expandAleek Datta is a Houston-based managing director, Accenture Strategy – Energy, specialized in HR and talent strategy.SubmittedTake, for example, finance jobs, which are shifting from reporting the past to evaluating the possibilities of the future. Eighty-six percent of U.S. finance leaders believe the traditional finance talent profile needs to change quickly and dramatically, according to an Accenture report on the future of finance. While much of routine accounting, control and compliance tasks are getting automated, the ability to innovate is among the top desirable skills for new finance executives. And increasingly, success relies on soft skills like the ability to educate through story-telling and collaborative working, besides traditional quantitative analysis.These shifts are happening everywhere. The biggest effect of intelligent technologies in the workplace isn’t automation of jobs; it’s the reconfiguration of all positions, as tasks evolve and worker capabilities are augmented by machines.However, today’s education and training systems are not well equipped to build skills unique to humans. By their nature, those skills are not taught in the classroom but, rather, are acquired through doing (ongoing practice and experience), often over long periods of time. The U.S. stands to lose $975 billion in GDP growth promised by investment in intelligent technologies over the next decade if we fail to overhaul our learning approaches and close the skills gap.To solve for this, we should first look to what neuroscience tells us. Experiential learning, it points out, is particularly effective for adults. On-the-job training, design thinking or using simulation tools turn learners into active participants, leading to faster and deeper learning. Organizations should accelerate apprenticeships and use new technologies, like virtual reality, to make experiential learning more accessible and engaging. Artificial intelligence can be also used to respond to a person’s progress and adapt courses to their needs to make learning more personalized. Additionally, our current education systems do not usually address the needs of an individual learner, and we need a more learner-centered approach and design metrics and incentives that encourage the blending of skills in each person. The demand for more creativity doesn’t necessarily mean we need more ballerinas and sculptors; it means that each of us must be more creative in our daily activities. Government could incentivize universities to create greater blends of skills within each individual, as should organizational training programs. Educators should begin encouraging a better-rounded set of skills from elementary school.Finally, businesses and government need to provide vulnerable learners with access to training and help them participate in the upside of the innovation economy. Less-educated and lower-income workers are not only more likely to be in roles that will be automated, but also often have less access to learning opportunities, compounding their disadvantage. Experiential techniques are especially appropriate to help these people develop new skills for entirely new forms of work. Also critical to success will be offering modular, bite-sized courses that are flexible around the work and life commitments of adults.The disruption of employment caused by new technologies must be matched by disruption of our approach to education and learning. And what’s the role of every worker in all this? Embrace lifelong learning. And continue to hone that human advantage. Stephanie Rogers is a managing director, talent and organization, Accenture. Aleek Datta is a Houston-based managing director, Accenture Strategy – Energy, specialized in HR and talent strategy.","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall-content'}",,,,False,,,,,,,,,,,,,,,,,,,en-US

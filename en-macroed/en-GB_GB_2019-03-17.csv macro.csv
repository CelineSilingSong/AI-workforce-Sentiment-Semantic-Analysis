URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,thumbnailUrl,mainEntityOfPage,@graph,wordCount,pageStart,pageEnd,abstract,copyrightHolder,publication,copyrightYear,alternativeHeadline,issn,hasPart,legalName,logo,telephone,sameAs,address,potentialAction,inLanguage,articleBody,associatedMedia,speakable,isBasedOn,isPartOf,@id,dateCreated
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAxOS8wMy8xOC9qb2Itc2VhcmNoLWluLXRoZS1hZ2Utb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtNS1wcmFjdGljYWwtdGlwcy_SAQA?oc=5,Job Search In The Age Of Artificial Intelligence - 5 Practical Tips - Forbes,2019-03-18,Forbes,https://www.forbes.com,Artificial intelligence is altering how individuals search for a job and how organizations recruit and assess a candidate’s skill-set and credentials for open positions. Here are some practical tips candidates must know in order to get through AI-powered screening in their job search.,,Artificial intelligence is altering how individuals search for a job and how organizations recruit and assess a candidate’s skill-set and credentials for open positions. Here are some practical tips candidates must know in order to get through AI-powered screening in their job search.,Artificial intelligence is altering how individuals search for a job and how organizations recruit and assess a candidate’s skill-set and credentials for open positions. Here are some practical tips candidates must know in order to get through AI-powered screening in their job search.,http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2019/03/18/job-search-in-the-age-of-artificial-intelligence-5-practical-tips/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2019/03/AdobeStock_163911850-1200x800.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Job Search In The Age Of Artificial Intelligence - 5 Practical Tips,2019-03-18T01:23:00-04:00,2019-03-18T01:23:52-04:00,Enterprise & Cloud,Job Search In The Age Of Artificial Intelligence - 5 Practical Tips,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,N/A,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise TechJob Search In The Age Of Artificial Intelligence - 5 Practical TipsBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itMar 18, 2019,01:23am EDTUpdated Mar 18, 2019, 01:23am EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinIf you haven’t searched for a job in recent years, things have changed significantly and will continue to evolve thanks to artificial intelligence (AI). According to a Korn Ferry Global survey, 63% of respondents said AI had altered the way recruiting happens in their organization. Not only do candidates have to get past human gatekeepers when they are searching for a new job, but they also have to pass the screening of artificial intelligence that continues to become more sophisticated. Recruiting and hiring new employees is an expensive endeavor for organizations, so they want to do all that’s possible to find candidates who will make valuable long-term employees for a good return on their recruitment investment.








Job Search In The Age Of Artificial Intelligence
Adobe Stock






Here are a few things candidates and organizations need to keep in mind when AI is part of the job search.
How AI helps in the recruiting process
Just like in other industries, artificial intelligence has the potential to streamline the job search process and take over time-consuming tasks for humans. There are several ways artificial intelligence helps candidates and companies during a job search and throughout the recruiting and hiring process.
PROMOTED
Candidates can use artificial intelligence job-seeking tools to find open positions that match their particular skill-set and discover organizations with the culture they want. This alone can save candidates an incredible amount of effort in an already time-consuming activity. Similarly, AI can conduct candidate outreach much more efficiently for companies so they can find candidates actually suited for the role.

When the CV screening process is automated, it is much more efficient—appreciated by candidates and human resources departments alike. Additionally, since recruiters won’t get bogged down in the CV review process, they have more time to nurture relationships with candidates.
AI-powered chatbots are responsive and quick to support a candidate during the application process. Having a chatbot handle inquiries from candidates is another way artificial intelligence frees up the time for human personnel to handle tasks only they can tackle.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Artificial intelligence helps organizations avoid the inevitable unconscious bias that seeps into the recruiting process when humans are determining which candidates to consider for a position. In addition, it can help companies identify growth opportunities for existing employees, training needs that set employees up for success and future promotions, and matches high-performers currently on staff to new opportunities.
Challenges presented by AI tools in the recruitment process
Candidates need to learn how to adjust their resumes and CVs to get through the artificial intelligence gatekeepers. If they don’t modify their approach, they won’t be matched with jobs and organizations that might be a good fit. They also need to be prepared to succeed if they are asked to an automated interview—where a candidate interacts with AI instead of a human. There are even businesses popping up that will help candidates “beat AI” in order to get a job.
Artificial intelligence allows organizations to scan multiple data points about each candidate. Not only are social media accounts reviewed, but it’s possible to critique multiple factors that make up the digital footprint of a candidate—something that would be impossible if only humans were assigned the task. This brings up interesting privacy questions regarding what information can be used to qualify candidates.
In addition to requiring a lot of data to work effectively, artificial intelligence can also learn human bias if the data set and algorithms they operate from have bias. Also, attitude, work ethic, and other attributes are difficult for a robot to critique but have also been a part of the hiring process.





Practical tips for job-seekers to prepare for AI in the job search

      Use keywords in your CV and cover letter that would be relevant for the position you seek

When you prepare your written materials to apply to a job, match the words you use with the terminology and keywords from the job posting. If they request someone who knows AP, be sure to have AP on your resume and cover letter and not accounts payable.

      Write like a human

Be sure your materials are still readable and grammatically correct. Don't assume that since a bot will be reviewing your materials, you must stuff your CV with keywords to get past their algorithms. If you make it past the bots, humans will still review your CV, and they won't be impressed by your skills if your written communication is barely intelligible.

      Have an online presence

While you must take care to have a respectable online presence, if you don’t have any at all, you might be at a disadvantage. Be sure your LinkedIn profile is up to date and depending on the role you seek, a personal website for your job search might also be helpful.

      Be sure your contact info is public

Make it easy for AI software and recruiters to contact you if they find you online. People can miss out on job opportunities if they have all of their online settings private. You can create an email address just for the job search and set up a Google Voice number that can be forwarded to your phone to take messages.

      Be prepared for digital interviews

Interviews conducted by AI bots won’t just be verifying what you say during the interview, but how you say it. Not only will word choices be assessed, but also facial expressions and body language.  I have recently written about the ways Unilever is now using AI in their recruitment, which will give you more insights.
Artificial intelligence has changed the job search process. In order to compete, candidates must respond to the new reality.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiLmh0dHBzOi8vd3d3LmJiYy5jby51ay9uZXdzL3RlY2hub2xvZ3ktNDc2Mzg5MTbSATJodHRwczovL3d3dy5iYmMuY28udWsvbmV3cy90ZWNobm9sb2d5LTQ3NjM4OTE2LmFtcA?oc=5,Artificial intelligence: Algorithms face scrutiny over potential bias - BBC,2019-03-20,BBC,https://www.bbc.co.uk,Artificial intelligence used in the justice and financial systems is to be investigated.,N/A,Artificial intelligence used in the justice and financial systems is to be investigated.,Artificial intelligence used in the justice and financial systems is to be investigated.,http://schema.org,ReportageNewsArticle,https://www.bbc.com/news/technology-47638916,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_news/950D/production/_105475183_877c69b9-4436-4c49-8d40-2a07d82e36eb.jpg'}","{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'noBylinesPolicy': 'http://www.bbc.co.uk/news/help-41670342#authorexpertise', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}","{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'publishingPrinciples': 'http://www.bbc.co.uk/news/help-41670342', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",Artificial intelligence: Algorithms face scrutiny over potential bias,2019-03-20T16:50:14.000Z,2019-03-20T16:50:14.000Z,,,,,N/A,N/A,"Artificial intelligence: Algorithms face scrutiny over potential bias20 March 2019ShareGetty ImagesMore research into computer algorithms is needed as they could have gender or race biases, the government has warned.It announced independent watchdog the Centre for Data Ethics and Innovation (CDEI) will investigate algorithms used in the justice and financial systems.But services using the artificial intelligence already, such as predictive policing, will continue.Human rights group Liberty said it did not make sense to acknowledge the risk and not halt current programs.""In launching this investigation, the government has acknowledged the real risk of bias when relying on predictive policing programs powered by algorithms. So why are they already being rolled out by police forces across the country?"" asked Hannah Couchman, policy officer at Liberty.""We should all be troubled by the silent expansion of the use of opaque algorithmic tools and the clear impact they have on our fundamental rights.""A spokesman for the Department for Digital, Culture, Media and Sport, which launched the inquiry, told the BBC: ""We know there is potential for bias but that is not the same as admitting that there are flaws in the system already.""Police use of crime prediction tech growsIs artificial intelligence racist? Police to test app that assesses suspectsThe government has not said whether algorithms currently in use are affected by bias issues.But the CDEI will work with the Cabinet Office's Race Disparity Unit to explore the potential for bias in algorithms designed for crime and justice.It will also look at potential bias in algorithms used in finance to make decisions such as whether to grant individuals loans and those used in recruitment, which can screen CVs and influence the shortlisting of candidates.Police toolsCrime prediction software has already been adopted by at least 14 police forces in the UK, according to freedom of information requests by Liberty. They fall into two types - predictive mapping of crime hotspots and risk assessments of individuals to try to work out who is more likely to commit an offence or become a victim of crime.In Durham, the Harm Assessment Risk Tool is being used to assist police officers in deciding whether an individual is eligible for deferred prosecution based on the future risk of offending.And Avon and Somerset Police use a system known as Qlik, a data visualisation system that helps it decide where to put police officers.The force previously told the BBC that it made ""every effort to prevent bias"" with data not including ethnicity, gender or demographics.Bias 'inevitable'Luka Crnkovic-Friis, chief executive of AI start-up Peltarion and co-founder of the Swedish AI Council, told the BBC: ""Because AI is trained by people, it's inevitable that bias will filter through. ""Automation tools are only ever as good as the data fed into them, so when using historical data where there is a strong human bias - such as race, re-offending rates and crime - there certainly is a risk that the results could produce bias and the government is right to take steps to account for this."" AI expert Dave Coplin, chief executive of consultancy The Envisioners, suggested what the CDEI should be investigating.""We need to make sure that the CDEI is as focused on where it [artificial intelligence] is being used in government today as well as the further challenges that tomorrow's usage may bring,"" he told the BBC.Police use of crime prediction tech growsIs artificial intelligence racist?",https://ichef.bbci.co.uk/news/1024/branded_news/950D/production/_105475183_877c69b9-4436-4c49-8d40-2a07d82e36eb.jpg,https://www.bbc.com/news/technology-47638916,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vc2VhbmV3cy5jby51ay9zaGlwcGluZy1uZXdzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFuZC10aGUtc2hpcHBpbmctaW5kdXN0cnkv0gEA?oc=5,Artificial Intelligence and the Shipping Industry - Sea News,2019-03-21,Sea News,https://seanews.co.uk,"AI is the new buzzword in the maritime sector. As the shipping industry is under a big transformation at a global level, Artificial Intelligence is already making things easier by seamlessly integrating new shipping logistics and communication technology to evolve the business model within the shipping industry. Further, with the help of new algorithms, the",N/A,"AI is the new buzzword in the maritime sector. As the shipping industry is under a big transformation at a global level, Artificial Intelligence is already making things easier by seamlessly integrating new shipping logistics and communication technology to evolve the business model within the shipping industry. Further, with the help of new algorithms, the","AI is the new buzzword in the maritime sector. As the shipping industry is under a big transformation at a global level, Artificial Intelligence is already making things easier by seamlessly integrating new shipping logistics and communication technology to evolve the business model within the shipping industry. Further, with the help of new algorithms, the",https://schema.org,BreadcrumbList,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://seanews.co.uk/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://seanews.co.uk/category/shipping-news/', 'name': 'Shipping News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': '', 'name': 'Artificial Intelligence and the Shipping Industry'}}]",N/A,N/A,"




HomeShipping NewsArtificial Intelligence and the Shipping Industry


Shipping News
Artificial Intelligence and the Shipping Industry

By Seanews Editor
March 21, 2019 
0

7771




Share
Linkedin






(Image Courtesy: Intel Newsroom)

AI is the new buzzword in the maritime sector. As the shipping industry is under a big transformation at a global level, Artificial Intelligence is already making things easier by seamlessly integrating new shipping logistics and communication technology to evolve the business model within the shipping industry. Further, with the help of new algorithms, the shipping industry can fully rely on AI for mitigating security risks and reduce the cost of operations to a great extent. Along with that, AI can help the maritime sector to respond to and work in accordance with the new environmental regulations and policies in a better way.
This shipping industry has rapidly sustained pressures over environmental regulations which posed a challenge to fuel on which vessels run. This combined with global cyber threats, have made digitalisation an indispensable alternative for the maritime industry. Shippers are now keen on improvising systems to nurture innovation and find solutions to these concerns.
Amidst changing scenarios in global shipping, Artificial intelligence (AI) has emerged as one of the hot topics. Inspiring and practical use cases are emerging on a daily basis, with organisations planning to adopt AI. However, while most of these technology implementations are in the conceptual stage, what and how much it takes to achieve business value and traction out of AI, depends on the reliance and robustness of products.
Artificial intelligence (AI) can collect and analyse data for the container shipping industry to chalk out plans more accurately. AI is pursued as the digital game changer in a variety of industries, which can render effective support to containerised supply chains with in-time transits and equipment availability.
Mitsui O.S.K. Lines, Ltd. (MOL) announced that the company and its subsidiary MOL Information Systems, have signed a contract with Yokohama National University to conduct a joint study on the analysis and use of Big Data related to ocean shipping. The study aims at developing the capability of data analysis of economics and maritime affairs and forecast the ocean shipping market and bunker prices with greater accuracy.
Besides, ports and terminals are recognising the trend for using Big Data to collaborate with shipping lines, except, little is known on how to do this effectively. Kalmar also released its ‘Kalmar Insight’ tool, which has been designed to help terminals turn Big Data into actionable insight.
The logistics and shipping sector can reap major benefits from AI, as artificial intelligence is most focused on large-scale numbers. These figures are analysed and organised from different sources, shaped and then used as the basis for decision-making, at times with minimum or no human input.
With its harsh working conditions, isolated crew and high economical, ecological and human risks, any technology that is implemented through AI, should have a positive impact to address these issues. Technological advances must be directed to the benefit of seafarers, bringing them more safety and first world care, experts opined.
Shipping industry majors such as, Maersk, Panalpina and Flexport have initiated measures to harness AI, to simulate human intelligence, to address an array or issues surrounding the maritime industry. The issues in focus are, selection of the best alternative port, when the original destination is blocked and better estimation of the arrival time, to ensure seamless preparedness of logistics.
AI is also being tapped to forecast whether a shipper will cancel a booking or its container will get rolled by the carrier, and left on the dock.
Artificial intelligence is set to be a USD 16 billion dollar global market in 5 years and a recent study shows that 84 per cent of companies see the use of AI as ‘essential’ to competitiveness. Most press about AI in maritime has been about Rolls-Royce and their plans to use AI in “future remote and autonomous shipping operations”.
SailRouter (cloud application that helps ship owners to reduce fuel consumption and maintenance costs) and VesselBot (digital chartering marketplace for the bulk maritime industry) are also doing their part to bring shipping into the 21st century – and solve some very complex problems, with their AI powered solutions.
With technological advancements gripping all forms of businesses, sooner or later the maritime industry will have to adjust and introduce technology into its business model. At a juncture when the industry is poised to leap forward with multiple regulations and concerns revolving around safe, effective and economical shipping, the time is ripe for companies to develop and implement AI into their workflow.
Sea News Feature, March 21

TagsSea News FeatureTechnology



Share
Linkedin




Previous articled’Amico International Shipping Records USD 55.1 Million Net Loss in 2018Next articleSteel cut for first short-sea LNG bunker vessel for Eesti Gaas at Damen YiChang shipyard, China

Seanews Editor
RELATED ARTICLES



Sea News  

San Francisco Bay ferry service electrification project announced


July 15, 2024 







Shipping News  

MOL Car Carrier Firmament Ace Joins Port of Nagoya Public Aquarium’s Loggerhead Turtle Migration Research Project


July 11, 2024 







Sea News  

Wind-assisted propulsion technology implemented on vessel that set sail this month


July 10, 2024 








Most Popular



 

Plymouth enjoys financial boost as cruise bookings double 


July 16, 2024 







 

Eco-friendly challenge: 18-year-old skipper’s journey around the UK in an electric boat


July 16, 2024 







 

Highlights from the European Committee meeting in London featuring top maritime industry leaders


July 16, 2024 







 

Innovative ship hull cleaning solution expands to Singapore with 2.51m GBP investment


July 15, 2024 




Load more  ",,,"[{'@type': 'BlogPosting', '@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#blogposting', 'name': 'Artificial Intelligence and the Shipping Industry - Sea News', 'headline': 'Artificial Intelligence and the Shipping Industry', 'author': {'@id': 'https://seanews.co.uk/author/admin-2/#author'}, 'publisher': {'@id': 'https://seanews.co.uk/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/seanews.co.uk/wp-content/uploads/2019/03/Intel-Newsroom.jpg?fit=500%2C243&ssl=1', 'width': 500, 'height': 243, 'caption': '(Image Courtesy: Intel Newsroom)'}, 'datePublished': '2019-03-21T05:11:21+00:00', 'dateModified': '2019-03-21T05:11:29+00:00', 'inLanguage': 'en-GB', 'mainEntityOfPage': {'@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#webpage'}, 'isPartOf': {'@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#webpage'}, 'articleSection': 'Shipping News, Sea News Feature, Technology'}, {'@type': 'BreadcrumbList', '@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://seanews.co.uk/#listItem', 'position': 1, 'name': 'Home', 'item': 'https://seanews.co.uk/', 'nextItem': 'https://seanews.co.uk/category/shipping-news/#listItem'}, {'@type': 'ListItem', '@id': 'https://seanews.co.uk/category/shipping-news/#listItem', 'position': 2, 'name': 'Shipping News', 'item': 'https://seanews.co.uk/category/shipping-news/', 'nextItem': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#listItem', 'previousItem': 'https://seanews.co.uk/#listItem'}, {'@type': 'ListItem', '@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#listItem', 'position': 3, 'name': 'Artificial Intelligence and the Shipping Industry', 'previousItem': 'https://seanews.co.uk/category/shipping-news/#listItem'}]}, {'@type': 'Organization', '@id': 'https://seanews.co.uk/#organization', 'name': 'Sea News', 'description': 'Global Maritime News', 'url': 'https://seanews.co.uk/', 'logo': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/seanews.co.uk/wp-content/uploads/2023/03/SN-New-Logo.png?fit=193%2C123&ssl=1', '@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#organizationLogo', 'width': 193, 'height': 123}, 'image': {'@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#organizationLogo'}, 'sameAs': ['https://www.facebook.com/profile.php?id=100090710941358', 'https://twitter.com/SeaNews11', 'https://www.linkedin.com/company/sea-news123/']}, {'@type': 'Person', '@id': 'https://seanews.co.uk/author/admin-2/#author', 'url': 'https://seanews.co.uk/author/admin-2/', 'name': 'Seanews Editor'}, {'@type': 'WebPage', '@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#webpage', 'url': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/', 'name': 'Artificial Intelligence and the Shipping Industry - Sea News', 'description': 'AI is the new buzzword in the maritime sector. As the shipping industry is under a big transformation at a global level, Artificial Intelligence is already making things easier by seamlessly integrating new shipping logistics and communication technology to evolve the business model within the shipping industry. Further, with the help of new algorithms, the', 'inLanguage': 'en-GB', 'isPartOf': {'@id': 'https://seanews.co.uk/#website'}, 'breadcrumb': {'@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#breadcrumblist'}, 'author': {'@id': 'https://seanews.co.uk/author/admin-2/#author'}, 'creator': {'@id': 'https://seanews.co.uk/author/admin-2/#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/seanews.co.uk/wp-content/uploads/2019/03/Intel-Newsroom.jpg?fit=500%2C243&ssl=1', '@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#mainImage', 'width': 500, 'height': 243, 'caption': '(Image Courtesy: Intel Newsroom)'}, 'primaryImageOfPage': {'@id': 'https://seanews.co.uk/shipping-news/artificial-intelligence-and-the-shipping-industry/#mainImage'}, 'datePublished': '2019-03-21T05:11:21+00:00', 'dateModified': '2019-03-21T05:11:29+00:00'}, {'@type': 'WebSite', '@id': 'https://seanews.co.uk/#website', 'url': 'https://seanews.co.uk/', 'name': 'Sea News', 'description': 'Global Maritime News', 'inLanguage': 'en-GB', 'publisher': {'@id': 'https://seanews.co.uk/#organization'}}]",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiigFodHRwczovL2Jsb2dzLmljcmMub3JnL2xhdy1hbmQtcG9saWN5LzIwMTkvMDMvMjEvbGVnYWwtcmV2aWV3cy13ZWFwb25zLW1lYW5zLW1ldGhvZHMtd2FyZmFyZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS0xNi1lbGVtZW50cy1jb25zaWRlci_SAQA?oc=5,"Legal reviews of weapons, means and methods of warfare involving artificial intelligence: 16 elements to consider ... - Blogs | International Committee of the Red Cross",2019-03-21,Blogs | International Committee of the Red Cross,https://blogs.icrc.org,Artificial intelligence and armed conflict: 16 elements that States might consider as part of their legal reviews involving AI-related techniques or tools,N/A,Artificial intelligence and armed conflict: 16 elements that States might consider as part of their legal reviews involving AI-related techniques or tools,N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

 
Legal reviews of weapons, means and methods of warfare involving artificial intelligence: 16 elements to consider

March 21, 2019, Artificial Intelligence and Armed Conflict / Conduct of Hostilities / Law and Conflict / New Technologies / The most read blog posts in 2019 / Weapons 13 mins read                        
Dustin A. Lewis  Senior Researcher, Harvard Law School Program 




 
What are some of the chief concerns in contemporary debates around legal reviews of weapons, means or methods of warfare involving techniques or tools related to artificial intelligence (AI)? One session of the December 2018 workshop on AI at the frontiers of international law concerning armed conflict focused on this topic. In this post, I outline a few key threshold considerations and briefly enumerate 16 elements that States might consider as part of their legal reviews involving AI-related techniques or tools.
It is imperative, in general, for States to adopt robust verification, testing and monitoring regimes as part of the process to determine and impose limitations and—as warranted—prohibitions in respect of an employment of weapons, means or methods of warfare. Where AI-related techniques or tools are—or might be—involved, the design and implementation of legal review regimes might pose particular kinds and degrees of challenges as well as opportunities. With respect to challenges, for example, in a forthcoming blog post Netta Goussac will highlight several legal and other concerns that might arise in respect of reviews of weapons involving AI, not least the potential to introduce uncertainty and corresponding issues regarding (un)predictably and (un)reliability. Furthermore, today it seems, from my perspective, that sufficient trust among States in this area seems to be lacking, at least among certain States with advanced technological capabilities. Against that background, robust legal reviews may not only contribute to legal compliance, but may also help foster normative stability and augment trust among States.
What do I mean by AI-related techniques and tools?
But first, a word on what I mean by AI-related techniques or tools. My starting point is that there is no generally recognized definition of AI. That said, it might be of value to focus on techniques or tools derived from, or otherwise related to, AI science broadly conceived. My understanding—drawn from the work of such scholars as Barbara J. Grosz—is that AI science pertains in part to the development of computationally based understandings of intelligent behavior, typically through two interrelated steps. One of those steps concerns the determination of cognitive structures and processes and the corresponding design of ways to represent and reason effectively. The other step relates to the development of theories, models, data, equations, algorithms and/or systems that embody that understanding.
So defined, AI systems are typically conceived as incorporating techniques—and leading to the development of tools—that enable systems to ‘reason’ more or less ‘intelligently’ and to ‘act’ more or less ‘autonomously’. The systems might do so by, for example, interpreting natural languages and visual scenes; ‘learning’ (or, perhaps more commonly, training); drawing inferences; and making ‘decisions’ and taking action on those ‘decisions’. The techniques and tools might be rooted in one or more of the following methods: those rooted in logical reasoning broadly conceived, which are sometimes also referred to as ‘symbolic AI’ (as a form of model-based methods); those rooted in probability (also as a form of model-based methods); and/or those rooted in statistical reasoning and data (as a form of data-dependent or data-driven methods).
Existing and purportedly new or emerging primary norms
By way of reminder, under international humanitarian law/law of armed conflict (IHL/LOAC), Article 36 of Additional Protocol I of 1977 provides that
[i]n the study, development, acquisition or adoption of a new weapon, means or method of warfare, a High Contracting Party is under an obligation to determine whether its employment would, in some or all circumstances, be prohibited by this Protocol or by any other rule of international law applicable to the High Contracting Party.
What is the legal nature of these reviews? A determination of lawfulness, or lack thereof, by a State in respect of those treaty provisions is not—at least according to the Rapporteur of those provisions’ drafting Committee (see O.R. XV, p 269, CDDH/215/Rev.1, para 30)—binding internationally. If we assume that that position is accurate, it would seem that the same contention might hold for the customary law counterparts, if any, of those treaty provisions. Instead, these legal review provisions—whether of a treaty or customary nature—might be seen as boiling down to an expectation that the obligation to make such a determination will be performed to ensure that weapons, means or methods of warfare will neither be developed nor adopted without at least a careful examination of their legality.
That contention, in turn, begs the question: what are the applicable primary norms? While there is widespread agreement on several primary norms, the possible development and employment of AI-related techniques or tools in respect of weapons, means or methods of warfare might nevertheless encounter several disagreements concerning aspects of the sources and/or content of some primary norms. Some of those disagreements stretch back decades (if not longer). Others are relatively new. Such differential approaches as to what constitutes lawful and unlawful conduct prevent normative uniformity and legal universality and thereby preclude the establishment of a comprehensive set of agreed primary legal norms against which all weapons, means or methods of warfare must be reviewed. Consider three examples.
Indiscriminate attacks
First, while there is, to my mind, no reasonable disagreement among States that, in general, indiscriminate attacks are prohibited under IHL/LOAC, some key aspects of that basic principle are currently contested. Take direct participation in hostilities as an example. In general, under IHL/LOAC civilians shall enjoy protection against the effects of hostilities. Certain aspects of those protections—including the so-called immunity from direct attack—might be withdrawn with respect to civilians who take a direct part in hostilities. There seems to be extensive support for the customary principle upon which Article 51(3) of AP I is based. (That provision, at least as a matter of treaty law, concerns direct participation of civilians in hostilities in respect of international armed conflicts as defined in that instrument.) Yet, according to the Law of War Manual (December 2016), the Office the General Counsel of the United States Department of Defense has noted that, at least in its view, that treaty provision, as drafted, does not reflect customary international law in all of its precise aspects.
Applicable legal frameworks
Second, with respect to applicable legal frameworks, there is, to my mind, no reasonable disagreement among States that relevant provisions of at least IHL/LOAC must be taken into account in legal reviews of weapons. Meanwhile, some States are considering whether international human rights law (IHRL) provisions must also be taken into account—and, if so, how and to what extent. The United Kingdom, for example, is apparently actively considering this issue. Such an assessment concerning the applicable framework(s) matters in no small part because the content of relevant IHL/LOAC provisions are at least traditionally perceived as tolerating more—indeed, in certain circumstances much more, though never unlimited—death, destruction and other harm in comparison to IHRL provisions.
A primary norm concerning AI-related techniques or tools?
Third, there currently seems to be a pivotal disagreement among certain States whether a new or emerging primary norm concerning AI-related techniques or tools and other relevant technologies can, should and/or must be developed. (According to certain scholars and advocates, such a norm might already be discerned.)
Here is where much of the normative debate currently seems to lie in respect of ‘emerging technologies in the area of lethal autonomous weapons systems’ (to use the term from the title of the relevant Group of Governmental Experts). On one hand, for some States, such a primary norm might be formulated in conceptual terms drawn, for example, from the August 2018 proposal by Austria, Brazil and Chile to establish a mandate for a new binding international instrument. That proposal speaks of ‘ensur[ing] meaningful human control over critical functions in lethal autonomous weapon systems’. On the other hand, certain other States argue that existing IHL/LOAC is sufficient. According to that viewpoint, the ‘modernization’ or ‘adaptation’ of IHL/LOAC in respect of emerging technologies in the area of lethal autonomous weapons systems is not needed.
16 elements or properties of interest or concern
While recognizing the significance of the disagreement on the existence and/or sources—or, at least, on some precise aspects—of certain primary norms identified above, it remains imperative for States to adopt robust legal review regimes. With that in mind, it may be of value to enumerate elements or properties of interest or concern that might be salient for the people responsible for conducting legal reviews of weapons, means or methods of warfare involving AI-related techniques or tools to consider.
A few caveats first. The listing order here is not meant to imply a hierarchy. Some of the elements or properties might overlap substantively and/or procedurally. Others might stand on their own. Inclusion on the list is not meant to represent a contention that international law does or does not already oblige a State to consider that particular element or property as part of a legal review. Nor is the list meant to exhaustively enumerate all possibly relevant considerations—far from it. With those caveats in view, here are 16 non-exhaustive assessments concerning elements or properties of interest or concern that might be considered as part of a legal review:

Legal agency: an assessment concerning the preservation of legal agency of humans—as grounded in international law—in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
 Attributability: an assessment concerning the preservation of the attributability—at least to a State and to an individual, including, as relevant, a commander—of an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
Explainability: an assessment concerning the preservation of the explainability of an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
Reconstructability: an assessment concerning the preservation of the reconstructability—in a nutshell, the capacity to sufficiently piece together the inputs, functions, dependencies and outputs of the computational components adopted, and by whom, in relation to each relevant circumstance of use, encompassing all potential legal consequences thereof—of an employment of weapons, means or methods of warfare involving AI-related techniques or tools both during and after employment (a possible guidepost here might be that such an employment is capable of being subject to juridical scrutiny, including by a judicial organ);
Proxies: an assessment whether the computational components—adopted in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools—may or may not be permitted to function, in whole or in part, as proxies for any legally relevant characteristics;
Human intent and human knowledge: an assessment concerning the preservation of human intent and human knowledge—as they pertain to compliance with international law applicable in relation to armed conflict as regards State responsibility and/or individual (including criminal) responsibility—in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
Normative inversion: an assessment concerning the preclusion of normative inversion—that is, preventing the computational components from operating in a manner that, for example, assumes that every person may prima facie be directly attacked, thereby functionally rejecting, and hence inverting, the general presumption of (protected) civilian status—in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools; 
Value decisions and normative judgments: an assessment concerning the reservation of IHL/LOAC-related value decisions and normative judgments only to humans in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
Ongoing monitoring: an assessment concerning the feasibility or not of the ongoing monitoring of the operation of the computational components adopted in an employment of weapons, means and methods of warfare involving AI-related techniques or tools;
Deactivation and/or additional review: an assessment concerning the feasibility or not of the establishment of deactivation thresholds and/or additional review thresholds in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
Critical safety features: an assessment concerning the prevention of the continued employment of weapons, means or methods of warfare involving AI-related techniques or tools where a critical safety feature has been degraded;
Improvisation: an assessment concerning the establishment of sufficient limitations and—as warranted—prohibitions on possible forms of ‘improvisation’ in relation to an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
Representations: an assessment concerning the representations reflected in the computational components—in short, the configurations of the models and their features—adopted in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
Biases: an assessment concerning the biases capable of arising in relation to the computational components adopted in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools;
Dependencies: an assessment concerning the dependencies within and between the computational components—and the relationships between those dependencies—adopted in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools; and
Predictive maintenance: an assessment concerning the feasibility or not of the establishment of predictive maintenance—that is, measures aimed at anticipating, forewarning and preventing failures, degradation, or damage with a view to avoiding the need for corrective maintenance—in respect of an employment of weapons, means or methods of warfare involving AI-related techniques or tools.

***
This post is part of the AI blog series, stemming from the December 2018 workshop on Artificial Intelligence at the Frontiers of International Law concerning Armed Conflict held at Harvard Law School, co-sponsored by the Harvard Law School Program on International Law and Armed Conflict, the International Committee of the Red Cross Regional Delegation for the United States and Canada and the Stockton Center for International Law, U.S. Naval War College.
Other blog posts in the series include

Intro to series and Expert views on the frontiers of artificial intelligence and conflict
Ashley Deeks, Detaining by algorithm
Lorna McGregor, The need for clear governance frameworks on predictive algorithms in military settings
Tess Bridgeman, The viability of data-reliant predictive systems in armed conflict detention
Suresh Venkatasubramanian, Structural disconnects between algorithmic decision making and the law

Li Qiang and Xie Dan, Legal regulation of AI weapons under international humanitarian law: A Chinese perspective
Netta Goussac, Safety net or tangled web: Legal reviews of AI in weapons and war-fighting

See also

ICRC, Artificial intelligence and machine learning in armed conflict: A human-centred approach, June 6, 2019


DISCLAIMER: Posts and discussion on the Humanitarian Law & Policy blog may not be interpreted as positioning the ICRC in any way, nor does the blog’s content amount to formal policy or doctrine, unless specifically indicated.

 
 

Tags: AI, emerging norms, IHL, indiscriminate attacks, legal review, LOAC, machine learning, weapons review 

Share this article








                                    You may also be interested in:                                





 


Principles under pressure: have humanitarian principles really stood the test of time?


12 mins read
 Artificial Intelligence and Armed Conflict / Conduct of Hostilities / Law and Conflict / New Technologies / The most read blog posts in 2019 / Weapons Olivier Ray 


                Recent conflicts have brought to light the jarring personal dilemmas humanitarian workers confront and provoked ...            






 


Forced to report: mandatory reporting of sexual violence in armed conflict


14 mins read
 Artificial Intelligence and Armed Conflict / Conduct of Hostilities / Law and Conflict / New Technologies / The most read blog posts in 2019 / Weapons Maria Carolina Aissa de Figueredo 


                Over the last decade, the International Committee of the Red Cross (ICRC) and its Red ...            


 



Comments




	    Netta,
	    1 May 2019


Thanks for putting these suggestions forward, Dustin.  Though I fear taking the conversation outside the scope of this series, do you think that these same elements are also relevant for the legal reviews of other ‘newer’ means and methods of warfare, such as cyber capabilities?






	    Damian,
	    1 September 2019


Dustin, thank you for writing such an interesting post of such an important topic. I completely agree that States must develop robust procedures for the legal review regimes. This is especially the case for new technology weapons such as AI-enhanced weapons that challenge existing IHL norms.  Unfortunately few States do (19 according to PREMT ).  Many of your elements or properties of interest or concern fall within a State’s prerogative to determine how it will conduct it internal legal reviews.  A State may regard your elements as issues to be considered in the context of the Martens Clause and develop its own position as to whether they represent an existing international law obligation or require a policy position.  I think such considerations should be made early in the study and development of an AI weapon and effectively be a design specification to ensure that the AI weapon is capable of review.  As such States should be investing now in the legal review of such weapons in parallel to their research into AI weapon capabilities.  The legal review of AI weapons will require an assessment of IHL and international law principles and rules are relevant to the weapon’s use, determining the standard of compliance that the reviewing State will require to pass an Article 36 review and developing a testing methodology that identifies the weapon’s ability to do so in a range of operating environments.  Determining the standard of compliance will be a challenge. For example, if an AI-enhanced weapon makes recommendations to a human operator whether certain persons or objects are lawfully targetable (i.e. because they are combatants or military objectives) what standard of certainty will the human operator be able to accept before acting on a recommendation?  Will the State Article 36 review require a standard equivalent to or superior to a human who does everything feasible to distinguish?  How will the Article 36 review consider AI bias, false assessments and human cognitive issues associated with information display?  Ultimately a weapon review should recommend that a weapon is not aquired or adopted or that its use is restricted if it is unable to satisfy the appropriate review standards.  The weapon review obligation will probably need to extend into the operational life of an AI weapon to address changes to its methods of operation or upgrades to the software that renders it ‘new’ for the purpose of Article 36.  Perhaps legal advisors deployed in compliance with Article 82 of AP1 will conduct in-service weapon reviews.  Thanks again for generating discussion on this important topic.  I think that there is a need for further discussion.






	    Damian,
	    5 September 2019


Netta, a great article.  You highlight many of the challenges for States will need to consider to develop their internal process for the legal review of AI enhanced or autonomous weapons.  In my view, to address the challenges you raise, States will need to rethink their internal processes for the weapon review of AI enhanced or autonomous weapons and develop a raft on policy positions to address these challenges.  From a process perspective,  I agree that legal reviews should commence at the earliest stages of study and development of an AI enhanced or autonomous weapon.  This may even extend to include study and research conducted through State sponsored Defence Industrt study and research (see for example the Australian Defence Science and Technology Groups ‘Trusted Autonomous Systems Defence Cooperative Research Centre’).   States should identify at the earlier stages their legal review requirements (e.g. explainable or recordable recommendations/decisions) and including them in the programming and design specifications of a new capability.  This will require States to identify what aspects of the proposed system or weapon functionality engage its international law and IHL obligations and how those obligations can be translated into code and the AI system trained.  For example, if an AI system makes ‘distinction’ recommendations about persons or objects on the battlefield for a human weapon operator to decide and act upon, the State will need to determine what standard of certainty the system must achieve to make a recommendation.  The State may require a standard equivalent to that of a trained human or seek a higher level of certainty.  All functionality that engages a States international law and IHL obligations will need to be tested to inform the legal review and allow the reviewer to identify limitations in the system or weapon. The testing may occur for the weapon’s normal or expected use in a range of anticipated operating environments designed to identify system limitations.   The legal review may ultimately restrict certain weapon functionality in certain environments or circumstances where it proves unreliable or unable to achieve the required standards set by the reviewing State.  For an AI enhanced weapon capable of machine learning, the legal review process will need to extend into the service life of the weapon to address not only self-learned changes and programming updates but also operational factors (rule of engagement, enemy counter-measures that necessitate a change in the weapons method of warfare), environmental and human factors that are unique to a particular mission.  Even for an AI or autonomous weapon that has passed a legal review a State will need determine how the weapon can be certified for operation in an specific mission or theatre.  I think there is merit in States developing a set of guiding principles for the legal review of AI enhanced or autonomous weapons.  These could include fundamental issues such as IHL apply to the use of AI enhanced or autonomous weapons, and legal reviews are to be conducted at least prior to the deployment.  I look forward to further guidance from the ICRC on the legal review of new technology weapons, including AI enhanced and autonomous weapons.






	    Abdullahi Rogo,
	    1 December 2021


States need faction out ways on how to make policy on Al in line with legal review of weapon treaty.



 

Leave a comment

Click here to cancel reply.



Name *



Email address *                                This is for content moderation. Your email address will not be made public.



Your comment



 











Sign up for the Law & Policy newsletter

Email*Forum Subscriptions ChoicesICRC Business UnitI agree to receive communications from ICRC, as per the data protection policy.*By clicking subscribe below, you consent to allow ICRC to store and process the personal information submitted above to provide you the content requested.


Blog rollIntercross
EJIL: Talk!
Opinio Juris
ICRC Religion and Humanitarian Principles
Humanicontrarian
Just Security
AJIL Unbound
Articles of War
Lawfare
ILA Reporter
Lawfire
ODI Expert comment
Rescue Aid
Alinsani
 

",,,"[{'@type': 'Article', '@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/#article', 'isPartOf': {'@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/'}, 'author': {'name': '', '@id': ''}, 'headline': 'Legal reviews of weapons, means and methods of warfare involving artificial intelligence: 16 elements to consider', 'datePublished': '2019-03-21T09:54:09+00:00', 'dateModified': '2019-12-29T23:29:57+00:00', 'mainEntityOfPage': {'@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/'}, 'wordCount': 2465, 'commentCount': 4, 'publisher': {'@id': 'https://blogs.icrc.org/law-and-policy/#organization'}, 'image': {'@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/#primaryimage'}, 'thumbnailUrl': 'https://blogs.icrc.org/law-and-policy/wp-content/uploads/sites/102/2019/03/Artificial-intelligence.-Mike-MacKenzie.jpg', 'keywords': ['AI', 'emerging norms', 'IHL', 'indiscriminate attacks', 'legal review', 'LOAC', 'machine learning', 'weapons review'], 'articleSection': ['Artificial Intelligence and Armed Conflict', 'Conduct of Hostilities', 'Law and Conflict', 'New Technologies', 'The most read blog posts in 2019', 'Weapons'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/#respond']}]}, {'@type': 'WebPage', '@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/', 'url': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/', 'name': 'Legal reviews of weapons, means and methods of warfare involving artificial intelligence: 16 elements to consider - Humanitarian Law &amp; Policy Blog', 'isPartOf': {'@id': 'https://blogs.icrc.org/law-and-policy/#website'}, 'primaryImageOfPage': {'@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/#primaryimage'}, 'image': {'@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/#primaryimage'}, 'thumbnailUrl': 'https://blogs.icrc.org/law-and-policy/wp-content/uploads/sites/102/2019/03/Artificial-intelligence.-Mike-MacKenzie.jpg', 'datePublished': '2019-03-21T09:54:09+00:00', 'dateModified': '2019-12-29T23:29:57+00:00', 'description': 'Artificial intelligence and armed conflict: 16 elements that States might consider as part of their legal reviews involving AI-related techniques or tools', 'breadcrumb': {'@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/#primaryimage', 'url': 'https://blogs.icrc.org/law-and-policy/wp-content/uploads/sites/102/2019/03/Artificial-intelligence.-Mike-MacKenzie.jpg', 'contentUrl': 'https://blogs.icrc.org/law-and-policy/wp-content/uploads/sites/102/2019/03/Artificial-intelligence.-Mike-MacKenzie.jpg', 'width': 960, 'height': 768, 'caption': 'Artificial intelligence. Mike MacKenzie'}, {'@type': 'BreadcrumbList', '@id': 'https://blogs.icrc.org/law-and-policy/2019/03/21/legal-reviews-weapons-means-methods-warfare-artificial-intelligence-16-elements-consider/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://blogs.icrc.org/law-and-policy/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Legal reviews of weapons, means and methods of warfare involving artificial intelligence: 16 elements to consider'}]}, {'@type': 'WebSite', '@id': 'https://blogs.icrc.org/law-and-policy/#website', 'url': 'https://blogs.icrc.org/law-and-policy/', 'name': 'Humanitarian Law &amp; Policy Blog', 'description': 'An ICRC platform for timely analysis and debate on international humanitarian law (IHL) and the policies that shape humanitarian action for people affected by conflict and violence.', 'publisher': {'@id': 'https://blogs.icrc.org/law-and-policy/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://blogs.icrc.org/law-and-policy/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://blogs.icrc.org/law-and-policy/#organization', 'name': 'International Committee of the Red Cross', 'url': 'https://blogs.icrc.org/law-and-policy/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://blogs.icrc.org/law-and-policy/#/schema/logo/image/', 'url': 'https://blogs.icrc.org/law-and-policy/wp-content/uploads/sites/102/2022/04/icon-128.png', 'contentUrl': 'https://blogs.icrc.org/law-and-policy/wp-content/uploads/sites/102/2022/04/icon-128.png', 'width': 128, 'height': 128, 'caption': 'International Committee of the Red Cross'}, 'image': {'@id': 'https://blogs.icrc.org/law-and-policy/#/schema/logo/image/'}}, {'@type': 'Person', '@id': '', 'url': 'https://blogs.icrc.org/law-and-policy/author/'}]",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vY2VuLmFjcy5vcmcvY2FyZWVycy9kaXZlcnNpdHkvQXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdG9vbHMtYmVuZWZpdC1jaGVtaXN0cy85Ny9pMTHSAQA?oc=5,Artificial intelligence tools could benefit chemists with disabilities. So why aren't they? - Chemical & Engineering News,2019-03-18,Chemical & Engineering News,https://cen.acs.org,"Automation scientists in academia and industry have created devices to make lab work more efficient, but they haven’t yet made accessibility for this small population a priority","computational chemistry, artificial intelligence, disability, automation, robot, access","Automation scientists in academia and industry have created devices to make lab work more efficient, but they haven&#8217;t yet made accessibility for this small population a priority","Automation scientists in academia and industry have created devices to make lab work more efficient, but they haven&#8217;t yet made accessibility for this small population a priority",http://schema.org,Periodical,,"{'@type': 'ImageObject', 'url': 'https://cen.acs.org/content/dam/cen/97/11/09711-feature1-minkaracxd.jpg'}","{'@type': 'Person', 'name': 'Sam Lemonick'}","{'@type': 'Organization', 'name': 'American Chemical Society', 'logo': {'@type': 'ImageObject', 'url': 'https://cen.acs.org/apps/cen-cloud/clientlibs/misc/cen/images/favicon.ico'}}",Artificial intelligence could assist chemists with disabilities,20190318,2019-03-15 16:14:14.822+0000,"Careers,Diversity,Physical Chemistry,Computational Chemistry",,,,N/A,N/A,N/A,,"{'@type': 'WebPage', '@id': 'https://cen.acs.org/careers/diversity/Artificial-intelligence-tools-benefit-chemists/97/i11'}",,,16,18,"<p>Hoby Wedler remembers his years in graduate school as many computational chemists do: long hours writing code, running calculations, and poring over papers. Unlike many computational chemists, however, Wedler had a constant companion while he did those things—an assistant who could do things like describe figures in the article he was reading. Because Wedler is blind, he needed the support to complete his research. Over the past decade or so—at the same time Wedler was working on his PhD—chemists around the world have been thinking about ways they could take repetitive lab work out of scientists’ hands. These new tools include robots that can move around a lab and operate equipment as a human would, as well as automated systems contained entirely within a fume hood to mix reagents. While large-scale automation has been largely the domain of pharmaceutical companies, low-cost robotics and sensors, combined with more sophisticated artificial intelligence</p>",Chemical &amp; Engineering News,Chemical &amp; Engineering News,2019,,0009-2347,"{'@id': 'cen-09711-feature1', '@type': 'PublicationVolume', 'volumeNumber': '97', 'datePublished': '20190318'}",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LmtxZWQub3JnL3NjaWVuY2UvMTkzOTI5My9zdGFuZm9yZC1haW1zLXRvLW1ha2UtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbW9yZS1odW1hbtIBAA?oc=5,Stanford Aims to Make Artificial Intelligence More Human - KQED,2019-03-19,KQED,https://www.kqed.org,"AI has managed to tangle itself in a pile of ethical problems: job disruption, security, racial discrimination. Stanford is betting it can make a better AI by using human values as the lodestar.",N/A,"AI has managed to tangle itself in a pile of ethical problems: job disruption, security, racial discrimination. Stanford is betting it can make a better AI by using human values as the lodestar.","AI has managed to tangle itself in a pile of ethical problems: job disruption, security, racial discrimination. Stanford is betting it can make a better AI by using human values as the lodestar.",http://schema.org,Article,,https://ww2.kqed.org/app/uploads/sites/35/2034/03/Stanford_HAI_1036-1020x681.jpg,"{'@type': 'Person', 'name': 'Katrin Snow', 'jobTitle': 'Senior Editor', 'url': 'https://www.kqed.org/author/katsnow'}",,Stanford Aims to Make Artificial Intelligence More Human,2019-03-19T17:10:37-07:00,2024-01-09T17:06:22-08:00,,,,,N/A,N/A,"Artificial IntelligenceStanford Aims to Make Artificial Intelligence More HumanListenKatrin SnowMar 19, 2019Save ArticleSave ArticleFailed to save articlePlease try againEmailMasters student Welsey Guo and postdoctoral scholar Margot Vulliez work in the Stanford robotics lab of Professor Oussma Khatib. (Drew Kelly/Stanford Institute for Human-Centered Artificial Intelligence)Gov. Gavin Newsom is urging Stanford researchers at the new Institute for Human-Centered Artificial Intelligence to stay true to their name and focus on the impact AI is having on people’s jobs.
‘We want to put philosophers and anthropologists and economists and political scientists in the lab with the technologists, so that ethical values and social scientific frameworks are baked in … to the very development of artificial intelligence.’Rob Reich, StanfordNewsom and Microsoft founder and philanthropist Bill Gates keynoted a symposium yesterday where university officials and scientists announced the formal launch of the institute. Its goal is to address both the peril and promise of AI, with human ethics and values as its lodestar.
Newsom said he was recently at the Port of Long Beach, talking with longshoremen worried that upgrades coming to the port will cost them jobs. He said longshoremen asked him not to implement the upgrades.
‘We’re moving forward–low-carbon green growth goals which are the envy of the rest of the nation,” Newsom said. “Our cap-and-trade program, our goals to reduce greenhouse gas emissions, and that means we’re moving forward with new technologies that are more efficient. The problem with the new technologies that are more efficient–you don’t need any people.’
In recent years, AI has managed to tangle itself in a pile of ethical problems. Facial recognition software doesn’t see faces that aren’t white. Speech recognition wants you to speak the King’s English. Or at least a solid American version of it–no accents. Longshoremen aren’t the only workers fearing job loss; truckers and restaurant workers also feel the hot breath of AI at their backs. And we can’t leave out Russian bots serving up lies to mess with our democracy.
“As technologists, it’s our responsibility to address the failings of our tools,” said Stanford HAI co-director Fei-Fei Li. “But it’s also our responsibility to realize the full extent of their potential.”
For example, she said, what if AI could keep an eye on patients in an emergency room, and alert staff when someone’s condition worsens? Or what if AI could help figure out how children learn, and improve education?
The new institute’s research will focus on enhancing and augmenting human lives across medicine, education and other fields, without replacing humans. KQED’s Brian Watt spoke about the new institute with two of its associate directors, computer science professor James Landay and political science professor Rob Reich. The interview has been edited for length and clarity. Some key points from the interview …
What exactly is AI?
Landay: It’s a fuzzy term, and the definition has moved over the years. I’d say the simplest definition is: the capability of machines to imitate intelligent human behavior.
But that behavior could be as simple as Google Maps telling you which ways to get to work today because there’s different traffic, all the way to maybe making a diagnosis about some very complex cancer situation.
What is the one thing people get wrong about AI?
Landay: Thinking that it’s going to be this hyper-intelligent being that will be so much smarter than people, and therefore eventually take over the world like in some kind of “Terminator” movie. That’s really the biggest misconception we see.
Another thing we hear a lot is that AI will make millions of jobs obsolete. Should we be worried?
Landay: I think job disruption is always a thing to be worried about. Globalization led to some major structural problems for some people and created wealth for others. It’s this unevenness that occurs with these disruptions that we need to pay attention to, and get ahead of, to make sure the people who might be disrupted are learning new skills, so they have a future.
Now, some economists think AI might not even disrupt us, because the real problem over the long period is a lack of growth in the population — that there won’t be enough younger people to support all the older people. And that we may even need machines to help us move forward as a society in health care and other areas.
So it’s not even clear, in an economic sense, that AI will replace everyone’s jobs.
Sponsored
The institute’s work revolves around what you call ‘human-centered AI.’ What does that mean? 
Rob Reich: First, ensuring as best we can that the advancement of artificial intelligence ends up serving the interests of human beings, and not displacing or undermining human interests. The essential thing is to ensure that as machines become more and more intelligent and are capable of carrying out more and more complicated tasks that otherwise would have to be done by human beings, that the role we give to machine intelligence supports the goals of human beings and the values we have in the communities we live in, rather than step-by-step displacing what humans do.
Second, the bet that the institute is making here at Stanford is that the advancement of artificial intelligence will happen in a better way if, instead of just putting technologists and AI scientists in the lab and having them work really hard, we do it in partnership with humanists and social scientists.
So the familiar role of the social scientist or philosopher is that the technologists do their thing and then we study it out in the wild; the economist measures the effects of technology and the disruption it has, or the philosopher tries to worry about the values that are disrupted in some way by technology.
At HAI we want to put philosophers and anthropologists and economists and political scientists in the lab with the technologists, so that ethical values and social scientific frameworks are baked in, to the extent possible, to the very development of artificial intelligence.
What are your top two ethical concerns about AI?
Reich: First, when you’re developing an algorithm and making use of enormous oceans of data, that data typically encodes human decisions of the past. And humans, as we all know, have often been biased and engaged in all kinds of unethical behavior. So algorithms can encode into their predictive judgements those human biases of the past. Bias and discrimination can creep into the various forms of AI decision-making.  
The second big consideration is that AI, like lots of technologies, can be used for good, and it can also be used by human beings for bad ends. We want to call attention to the different ways that AI can be deployed and try to build in social frameworks and technical approaches that make it much more likely that AI is deployed for good rather than for ill.



I think about a car that’s programmed to protect the passenger inside. But if a passenger would have to choose between crashing or hitting a child, the human mind would say to save the child. How does AI sort this out?
Rob Reich: That’s exactly the kind of question that putting philosophers and social scientists and technologists in the lab together is meant to allow discussion about.
There’s research that shows if you ask a human being whether they think the car should optimize for all of human safety, rather than just passenger safety, people say of course it should optimize for all human safety. But if you’re asking, ‘What kind of car would you like to purchase, one that optimizes for all human safety or optimizes for passenger safety?’ they go for passenger safety.
This is what, to me, indicates that engineers have to make these value decisions while they’re developing the technology. And far better that it happens in the open with the full discussion amongst all the various stakeholders–including ordinary citizens–so that we can build toward a bigger social consensus.
Sponsored
",,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3LnBicy5vcmcvd2diaC9ub3ZhL2FydGljbGUvY2FuLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWhlbHAtc2F2ZS10aGUtbmF0dXJhbC13b3JsZC_SAQA?oc=5,Can Artificial Intelligence Help Save the Natural World? | NOVA - PBS,2019-03-20,PBS,https://www.pbs.org,"AI-powered tools are giving conservationists new ways to combat the daunting, ongoing, human-caused problem of mass extinction. It won’t be easy.",N/A,"AI-powered tools are giving conservationists new ways to combat the daunting, ongoing, human-caused problem of mass extinction. It won’t be easy.",N/A,https://schema.org,NewsArticle,,['https://www.pbs.org/wgbh/nova/media/original_images/IMG_8494_2.jpeg'],"{'@type': 'Person', 'name': 'Jackie Snow'}","{'@type': 'Organization', '@id': 'https://www.pbs.org/wgbh/nova#organization', 'name': 'Nova', 'logo': {'@type': 'ImageObject', '@id': 'https://www.pbs.org/wgbh/nova#logo', 'inLanguage': 'en-US', 'url': 'https://www.pbs.org//wgbh/nova/_next/static/images/default_share-88b895d8b4f4caef950e526d0f5842f1.png', 'caption': 'Nova'}}",Artificial Intelligence Could Help Save the Natural World,2019-03-20T20:10:00.000Z,2019-03-20T20:10:00.000Z,,,,,N/A,N/A,"Tech + EngineeringTech & EngineeringCan Artificial Intelligence Help Save the Natural World?AI-powered tools are giving conservationists new ways to combat the daunting, ongoing, human-caused problem of mass extinction. It won’t be easy.ByJackie SnowWednesday, March 20, 2019 NOVA NextNOVA NextAI technology is being developed to help rangers detect poachers, who represent a serious threat to African elephants, like this mother and calf in Ol Pejeta Conservancy, Kenya. Image credit: Allison Mitchell.ShareAfrican elephants, the biggest land animals on earth, are in grave peril: They could be extinct in the next decade. Poachers kill an estimated 55 elephants every day.The challenge of protecting elephants is vast, literally—reserves are sprawling, often remote, and understaffed. AI is starting to fill the gaps by being the eyes and brains behind spotting or predicting where the poachers might be. One of the most recent projects to stop attacks is TrailGuard AI, a system of small cameras with algorithms for image detection and object recognition built in.The name TrailGuard comes from the fact that despite the enormous areas some reserves cover, there are still choke points poachers have to travel through, allowing cameras to be setup up strategically in those places. To be helpful, the cameras have to work autonomously, be low-powered, and send photos in real time.
RelatedEcologists Use Astronomy to Track Endangered SpeciesHow People with Disabilities Are Using AI to Improve Their LivesDoes AI Hold the Key to a New and Improved  “Green Revolution” in Agriculture?The Algorithm Will See You Now: How AI is Helping Doctors Diagnose and Treat Patients
An earlier iteration of the TrailGuard camera didn’t have AI built in and sent back photos that 75 percent of the time had no humans in them. The cameras would be triggered by a cloud moving in front of the sun, swaying grass, or animals going by. These false triggers eat up precious battery life and become a nuisance to the rangers who have to drop what they are doing and look through images. Plus, changing batteries every few weeks puts people in danger and potentially gives away where the cameras are set up.Adding AI that detects whether a person is in the photo reduces the error rate to a fraction of previous attempts—and it improves its accuracy with time. Capturing and sending fewer images means TrailGuard cameras now last up to 18 months without having to swap the batteries out.The AI behind the smart cameras has been used in urban settings for years but hasn’t made an appearance to stop poaching until now. “It’s never been used in national parks where we need it the most,"" says Eric Dinerstein, the Director of Biodiversity and Wildlife at RESOLVE, a conservation nonprofit and a partner on the TrailGuard AI project.For cash-strapped national parks trying to stop well-funded poaching forces that can include anything from machine guns to helicopters, any help is appreciated.“This is a huge advantage for conservation,” says Alex Dehgan, the CEO of Conservation X Labs, a nonprofit looking to end human-driven extinctions with technology.Dehgan, who was not involved in the TrailGuard project, points out that rangers will still be crucial to the conservation efforts, but will now have more information to act on than ever before.“[It’s] going to make us all into the equivalent of superheroes,” he says.The goal is to deploy TrailGuard AI in 100 reserves in Africa by the end of the year, starting in the national parks in the Serengeti and Garamba. Ultimately, there are plans to take the technology to Southeast Asia and South America—and possibly use it to combat issues other than poaching, like illegal logging.“We think it's going to be a game changer,” Dinerstein says.


TrailGuard AI, developed by Intel and conservation nonprofit RESOLVE, is a system of small cameras that can help park rangers identify possible poachers quickly, without human image analysis. Image credit: RESOLVE



Saving the Natural World with Artificial IntelligenceHumanity is making it tough for the rest of the inhabitants on Earth to thrive. Deforestation, poaching, and urban sprawl are just some of the problems we’ve unleashed on our non-homo sapiens neighbors. Those pressures, as well as others like climate change and pollution (which aren’t good for humans either), are contributing to a loss of plant and animal species that scientists argue is nothing less than a massive and human-made sixth extinction event.Conservationists have long turned to technology—such as remote sensors and animal I.D. tags—to learn more about the species they study, bring attention to the worst problems, and inform solutions like protected refuges that can help species return to health. AI and machine learning are the latest technologies at their disposal. And luckily for perennially strapped conservation efforts, better-funded AI research is creating free tools, cheap cloud services, and open source resources that put cutting edge technology within reach for even small nonprofits.The need for large datasets, however, still holds backs many ecological AI projects. Most of the data that does exist for conservation isn’t digitized, is incomplete, or is housed in proprietary databases locked down at universities.Projects like Wild Me are trying to address these problems by aggregating large amounts of data for scientists. Wild Me lets researchers upload photos of the animals they study to an open-source platform, and scrapes large amounts of data from websites like YouTube and Flickr. When safari-goers upload footage of a pack of zebras they saw, for example, Wild Me’s computer vision algorithm spots the zebras and can identify individuals it has seen before, creating a record that lets biologists study the health and habitat of animals in new ways.Another data creation effort is Conservify, a lab dedicated to using technology to democratize data gathering to make an impact on conservation efforts. One way they’re doing that is by building low-cost sensors that can be placed in the wild to gather new data. They are also developing an online platform called FieldKit that will help researchers, students, and weekend naturalists share data.Trying out new technology does come with hazards. Communities aren’t going to be happy with tech that doesn’t work or affects them negatively. It might also disturb wildlife unaccustomed to its presence.“Once you go put it out in the field, that’s where the real risk happens,” says Shah Selbe, Conservify’s CEO and founder.Selbe points to the explosion of poorly-trained drone operators as an example of technology sometimes being put to use before it’s ready. Drones have major potential for conservation research, especially when combined with computer vision algorithms that can swiftly parse hours of footage, but drones need to be used carefully so as not to bother local communities or animals. Fortunately, Selbe says so far he hasn’t seen significant failures with new AI tools. The stakes are high because AI, done right, could open the world up to further exploration and understanding.“In terms of the work that I do, everything has absolutely changed,” he says.
Support Provided ByLearn More
Discovering Endangered Plants Before it’s Too LateIn a fluorescent-lit room lined with gray filing cabinets at the University of Maryland (UMD), a hundred thousand plant specimens are tidily housed in manila folders. The samples in the Norton-Brown Herbarium have been carefully collected for more than a century from across the globe, although the majority are from the mid-Atlantic region. One such sample is Phacelia covillei, a flowering plant with bottle-shaped blue blossoms found in scattered pockets in states like Maryland, North Carolina, Indiana, and Missouri.Due to factors like urban development and climate change, Phacelia covillei is at risk of extinction, according to NatureServe, a ranking system used to denote the relative imperilment of different plant and animal species in North America. It made the list thanks to a new machine learning tool that tries to identify threatened plants before it’s too late to save them.


A new machine learning tool aims to speed up the identification of threatened plants like P. covillei, pictured here from the University of Maryland's Norton-Brown's Herbarium. Image credit: Jackie Snow



It’s a big challenge. The vast majority of plants haven’t been assessed at all: Less than 10 percent of plant species around the world have been checked for the IUCN Red List, the premier directory for global extinction risks that is often used to make conservation decisions. Anahí Espíndola, a professor of evolutionary ecology at UMD who worked on the machine learning tool, wanted to see if she could find ways to zero in on those most in need of classification.Espíndola and her team trained a machine learning algorithm on details known about plants that are already on the IUCN Red List—like their location, range, and physical traits—and used it to assess 150,000 plant species whose vulnerability is currently unknown. Their method found that more than 10 percent of those unassessed plants were at risk.This AI tool could speed up conservation efforts and direct limited resources more effectively than current practices. Geographic bias is one problem: Plants are better studied in the U.S. and Europe because of bigger government and university research budgets. Espíndola says AI can quickly pinpoint the plants most at risk, regardless of where they might be. AI might also prevent another problem that plagues animal conservation: The cutest species get an outsized amount of the attention.“You don’t get that bias [with AI],” she says of our preference for the cute and cuddly. “It tells you where to go first.”Seeing the Forest for the TreesConservation AI isn’t just for remote areas; it could also make cities greener. For example, trees reduce the urban heat island effect, reduce stress in humans, and reduce flooding during storms. Despite all of these benefits, U.S. cities are losing 36 million trees a year, according to a study from the Forest Service.Knowing where the trees are (or aren’t) isn’t as easy as it sounds. Counting from the ground takes years and the results are often incomplete due to difficulties distinguishing trees on private property, or using satellite images that aren’t crisp or detailed enough for the human eye. Geospatial analytics startup Descartes Labs built a machine learning tool that can take one-meter resolution satellite imagery and count individual trees, without getting tricked by non-tree greenery or shadows that might appear to be trees. This would point out areas that are “tree deserts” and, over time, show changing areas that might need renewed attention.Descartes Labs originally developed the tool to predict corn harvests but could see the system being used as a deforestation prevention tool. Eventually, Descartes Labs might create layers of different informational maps that would be useful to people trying to manage land for all sorts of reasons, including conservation efforts.“You can be surprised by what you could see by combining layers,” says Tim Wallace, a geographer at Descartes Labs. “The more we combine, the more powerful it becomes.”Era of AI-Powered ConservationIt’s not just ecologists and startups working on saving the world. Some of the biggest companies in the world like Microsoft, Intel, and Google all have AI for good projects, including some that target conservation issues. Not only is this work potentially good for the planet, but it’s good for business, too. Creating cutting-edge tools and putting money into conservation programs is a great way to recruit top talent that doesn’t want to just work on improving advertising click-through rates. And there is an additional bonus: If technology can work in the field, it should also work in less rugged office and factory settings.“[Conservationists] always set the bar super high,” says Lucas Joppa, Microsoft's Chief Environmental Scientist. “And if you can jump that bar, you passed the bar for many, many, many other use cases by far.”Joppa has experience with clearing those bars with Microsoft’s AI for Earth, a five-year, $50 million initiative to back projects by environmental groups and researchers working on sustainable plans using AI. Joppa, who helps oversee the program, says that there is nothing harder or more important than creating technology that can solve these environmental problems.""People think that the hardest problem is how to route an autonomous car to the closest latte,” he says. “We have other problems we need to tackle.”Of course, there is always the concern that AI could do more harm than good for the environment. Previous industrial revolutions were driven by new technologies that ended up being harmful to the planet, from factories spewing smog to encouraging mining of precious metals for smartphones. This AI revolution, Joppa says, will have to be carefully designed to benefit the planet and not create problems, unanticipated or otherwise, for future generations.“That’s not easy to do,” he says.To learn more about researchers' testing of TrailGuard AI, which could someday help rangers better protect elephants and other endangered species, watch this video:



Receive emails about upcoming NOVA programs and related content, as well as featured reporting about current events through a science lens.Email AddressZip CodeSubscribeShare this articleJackie SnowPosts By This Contributor ",,"{'@type': 'WebPage', '@id': 'https://www.pbs.org/wgbh/nova/article/can-artificial-intelligence-help-save-the-natural-world/'}",,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LnNocm0ub3JnL3RvcGljcy10b29scy9uZXdzL2VtcGxveWVycy1lbWJyYWNlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWhy0gEA?oc=5,Employers Embrace Artificial Intelligence for HR - SHRM,2019-03-21,SHRM,https://www.shrm.org,"​Companies around the world are increasing their HR investments in artificial intelligence (AI) and related technology and, in doing so, trying to catch up with investments made by other business functions.","Global Mindset,Business Acumen,Technology,Viewpoint","​Companies around the world are increasing their HR investments in artificial intelligence (AI) and related technology and, in doing so, trying to catch up with investments made by other business functions.","​Companies around the world are increasing their HR investments in artificial intelligence (AI) and related technology and, in doing so, trying to catch up with investments made by other business functions.",https://schema.org,NewsArticle,https://www.shrm.org/,/content/dam/en/shrm/topics-tools/news/older_worker_t4ynma.jpeg,"{'@type': 'Person', 'name': 'Dinah Wisenberg Brin', 'url': ''}",,Employers Embrace Artificial Intelligence for HR,,2024-01-02T13:58:52.770Z,,SHRM,false,,N/A,N/A,"
 














 




Share












 







Linked In


 
 
Facebook


 
 
Twitter


  

Email



 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus
            convallis sem tellus, vitae egestas felis vestibule ut.  





 

 
Error message details.

 
 




Copy button
 



 


















 



 
 
 
Reuse Permissions
              













Request permission to republish or redistribute SHRM content and materials.
            






 
 

 
Learn More
  

  



 





          Viewpoint

Employers Embrace Artificial Intelligence for HR



March 21, 2019

          | 



          

          
                      Dinah Wisenberg Brin
                             







Share



Bookmark


i
Reuse
                            Permissions


















",,,,,,,,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'false', 'cssSelector': '.content-metering-wrapper'}",Society for Human Resource Management,https://shrm-res.cloudinary.com/image/upload/v1703622970/shrm-logo.png,1-800-283-7476,"['http://twitter.com/SHRM', 'http://www.linkedin.com/company/shrm', 'https://www.facebook.com/SHRMHQ', 'http://www.youtube.com/shrmofficial', 'https://instagram.com/shrmofficial/', 'https://en.wikipedia.org/wiki/Society_for_Human_Resource_Management', 'https://www.wikidata.org/wiki/Q1527909', 'https://www.crunchbase.com/organization/shrm']","{'@type': 'PostalAddress', 'streetAddress': '1800 Duke Street', 'addressLocality': 'Alexandria', 'postalCode': '22314', 'addressCountry': 'United States'}","{'@type': 'SearchAction', 'target': 'https://www.shrm.org/search-results#q={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vdG9kYXkuZHVrZS5lZHUvMjAxOS8wMy90aGVzZS13b3Jrcy1hcnQtd2VyZS1jcmVhdGVkLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,These Works of Art Were Created by Artificial Intelligence | Duke Today - Duke Today,2019-03-18,Duke Today,https://today.duke.edu,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,N/A,N/A,"










































PUBLISHED                                                                                            March 18, 2019 
                                                        IN                    Arts 

These Works of Art Were Created by Artificial Intelligence
Ruby to showcase Duke’s first A.I. art contest, 6 to 8 p.m., Wednesday, March 20











                        A new art contest at Duke isn’t limited to human artists -- the contestants in the 'AI for Art' competition also collaborated with machines. Meet the artists and see their work, 6 to 8 p.m. Wednesday, March 20, Rubenstein Arts Center                       









Share this story




Share this story on facebook



Share this story on twitter



Share this story on reddit



Share this story on linkedin



Get this story's permalink



Print this story







Robin A. Smith
 
@dukeresearch 








The thumbnail in the top right? That’s what Duke campus might look like if it were painted by a Chinese ink master. If you look closely, you can also see a Picasso version of the red bridge in the Gardens, and the Chapel recreated in the style of Van Gogh’s “Starry Night.”
These pieces may seem to be the work of human artists. But for the roughly two dozen entries in the first A.I. art competition at Duke, a big part of the creative process belonged to a machine.
      
Meet the Artists in the ‘A.I. for Art’ Competition 
Reception and viewing from 6 to 8 p.m. on Wednesday, March 20 in the Ruby Lounge at the Rubenstein Arts Center.
2020 Campus Drive, Durham, NC More info

No brushes. No paints. Instead, the contestants used advanced computer algorithms that can sort through thousands of image examples, recognize patterns, and then generate new images of their own with the help of artificial intelligence.
See the results for yourself at a reception from 6 to 8 p.m. on Wednesday, March 20 at the Rubenstein Arts Center, hosted by the +Data Science initiative and the Vice Provost for the Arts.
Some of the entries in the ‘A.I. for art’ contest used artificial intelligence to create a mash-up of the style of one image and the content of another. By Scott Emmons '19 and Myla Swallow '19.
	The contestants used several different approaches in artificial intelligence to make art. Some teams focused on teaching machines to capture a specific style, like Monet's Impressionism or the dreamy surrealism of Dalí, and transfer it to another image.
That technique, called style transfer, is what’s behind a piece called “Bridged Reflections,” by undergraduates Scott Emmons ’19 and Myla Swallow ’19. First they trained the system on thousands of images of everyday objects so it could learn what things like faces and buildings typically look like. Then they gave it two images -- one of the lake at Duke Gardens, and another of Picasso's painting “Les Femmes d'Alger” -- and the algorithm reinterpreted the lake in the style of Picasso’s work.
Duke masters students Jingwen Wang ’20 and Yicheng Deng ’19, of data science and ECE respectively, played with a similar technique to create A.I. art inspired by Chinese brush painting.
The secret behind their entry is a class of algorithms called “generative adversarial networks,” or GANs. To get their algorithm to produce a convincing likeness of a traditional Chinese painting, they fed it 9,000 such paintings -- mostly monochrome images of mist-shrouded mountains and meandering rivers -- that they painstakingly scraped from the web.
Based on these, one side of the GAN generates new images, while the other decides if they are “real” or fakes. The generated images get better and better until the system can’t tell the difference.
A lazuli bunting (top) and a hooded warbler (bottom) as seen through the ‘eyes’ of an image recognition algorithm developed in the lab of Duke professor Cynthia Rudin.Yet another contest entry might look like a cubist remix of “Peterson’s Field Guide to Birds,” but the algorithm works a bit differently.
A team led by Duke computer science and ECE professor Cynthia Rudin used a neural network they developed to analyze thousands of bird photos ranging from pelicans to hummingbirds. Then, given a photo of a mystery bird, the A.I builds a surreal photo collage that shows which parts of the bird are most similar to typical species features it has seen before, remixing and overlaying patches of images together to create its own representation.
Co-creator and computer science Ph.D. student Alina Barnett selected the training data. “My parents are birders,” Barnett says.
The resulting mishmash essentially says: “This isn't just any warbler. It's a hooded warbler, and here are the features -- like its masked head and yellow belly -- that give it away.”
They’re “sort of Frankenbirds,” said co-creator James Hoctor, a masters student in computer science who also collaborated on the project with Ph.D. student Chaofan Chen and undergraduate Oscar Li ‘19.
“It’s what you might come up with if you saw a tern on a safari, and instead of taking a picture of it, you went home and drew a copy of it later from memory. And you’re really bad at drawing,” Hoctor said.
These portraits were produced using artificial intelligence by Duke undergraduate Daniel Zhou ’21.
	Art made by artificial intelligence raises difficult questions. How is human creativity different from what A.I. learns to do? How much of the credit for AI-generated art should go to the human versus the machine?
Swallow says she wrestles with these issues. Sure, the human artist chooses what images to feed the algorithm. But beyond those inputs, Swallow says, we “had almost no control over the output. You never really knew what you were going to get.”
Few of the contestants consider themselves artists per se. “I’m not the most artistically creative person,” said undergraduate Daniel Zhou ‘21, who identifies as a STEM guy. ""But I was curious to see if I could produce aesthetic art through machine learning."" 
STEM geeks are inspired by notions of beauty too, says math and computer science major Emmons. “I don’t paint or draw in my free time. But I study math because I think it’s beautiful.”
One of the benefits of using machine learning to create art is scale. With the touch of a button, Emmons said, he was able to “output 900 different paintings overnight. I wanted to hang them up on my wall.”
Similarly, Zhou used A.I. to churn out hundreds of trippy-looking portraits and landscapes, lined up like the repetitive heads of a Warhol painting.
Emmons says his take-away from the contest is that A.I. is no replacement for human artists, but it could be a way to enhance the creative process. “I think what machine learning and A.I. are doing is providing new tools for people to use.”
The submissions have been judged by faculty from Duke’s Art, Art History & Visual Studies Department, and from the Rhodes Information Initiative at Duke (Rhodes-iiD).
The top three entries will take home a share of $8500, with winners announced at the reception on March 20.
Duke Ph.D. student Zach Monge (psychology and neuroscience) used machine learning to transform forest images into abstract paintings and back.
	 








Share this story




Share this story on facebook



Share this story on twitter



Share this story on reddit



Share this story on linkedin



Get this story's permalink



Print this story





Tagged with 

Data+, Computer Science, Pratt School of Engineering, Mathematics, Statistical Science, students, graduate and professional View all tags

















×
Link to this page


Copy and paste the URL below to share this page.





Select URL









",,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vdml0ZXJiaXNjaG9vbC51c2MuZWR1L25ld3MvMjAxOS8wMy91c2luZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS10by1wcmVkaWN0LXZpb2xlbmNlLWluLW1vdmllcy_SAQA?oc=5,Using Artificial Intelligence to Predict Violence in Movies - USC Viterbi | School of Engineering - USC Viterbi School of Engineering,2019-03-20,USC Viterbi School of Engineering,https://viterbischool.usc.edu,N/A,N/A,"The film industry will soon be able to better predict MPAA ratings for movies, thanks to a new artificial intelligence tool.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

Using Artificial Intelligence to Predict Violence in Movies Greta Harrison | March 20, 2019							
						
The film industry will soon be able to better predict MPAA ratings for movies, thanks to a new artificial intelligence tool. 



A research team at USC’s Viterbi School of Engineering has created a tool to help the film industry track the depiction of violence in the language of scripts.
For many in the film industry, seeing your film landed with an NC-17 rating from the Motion Picture Association of America (MPAA) is the kiss of death. With your film no longer accessible to viewers under 17, you are presented with a choice between limited box-office takings or expensive re-editing, or even reshooting, to meet the requirements of a more palatable R rating.
But what if there were a more accurate way to determine a film’s likely classification at the script stage, before it moves through the expensive process of production and post-production? A research team from the Signal Analysis and Interpretation Lab (SAIL) at USC’s Viterbi School of Engineering is using machine learning to analyze the depiction of violence in the language of scripts. The result is a new tool to assist producers, screenwriters and studios in determining the potential classification of their projects.
Presented at the 2019 Association for the Advancement of Artificial Intelligence (AAAI) Conference, the new AI tool was developed by PhD students Victor Martinez,  Krishna Somandepalli, Karan Singla, Anil Ramakrishna, and their advisor Shrikanth Narayanan, the Niki and Max Nikias Chair in Engineering. This was done in collaboration with Yalda Uhls of Common Sense Media. The study is the first time that natural language processing has been used to identify violent language and content in movie scripts.
The research team built the script tool using machine learning language analysis of popular film scripts.
The AI tool was developed using a dataset of 732 popular film scripts that had been annotated for violent content by Common Sense Media. From this information, the team built a neural network machine learning model where algorithms intersect, work together and learn from input data (that is, the text of the scripts), in order to create an output (i.e., violence ratings for the movie). The AI tool analyzed language in the dialogue of screenplays and found that the semantics and sentiment of the language used was a strong indicator of the rated violent content in the completed films.
Narayanan and his team have been using AI to analyze human-centric data for over 15 years as part of their computational media intelligence research, which focuses on analysis of data related to film and mass media. They regularly work with partners such as The Geena Davis Institute for Gender in Media to analyze data from film and media to determine what it can reveal about representation.
Narayanan said that text analysis has a long history in the creative fields of evaluating content for hate speech, sexist and abusive language, but analyzing violence in film through the language of the script is a more complex task.

“Typically when people were studying violent scenes in media, they look for gun shots, screeching cars or crashes, someone fighting and so on. But language is more subtle. These kinds of algorithms can look at and keep track of context, not only what specific words and word choices mean. We look at it from an overarching point of view,” Narayanan said.
Martinez said that one example of the AI tool’s ability to detect implicit violence that current technology cannot detect was a portion of dialogue from The Bourne Ultimatum (2007):

“I knew it was going to end this way. It was always going to end this way…”

Martinez said that this line was flagged by the AI tool as violent, even though it does not have any explicit language markings for violence.
“In contrast to the way the MPAA rates, our models look at the actual content of the movie, and the context in which dialogue is said, to make a prediction on how violent that movie is,” Martinez said.
Somandepalli said that the research team is now using the tool to analyze how screenplays use violence in depictions of victims and perpetrators, and the demographics of those characters.
Such findings could play an important role in a post #MeToo Hollywood, with concerns about representation of women and perpetuation of negative stereotypes, and a renewed focus on strong female characters with agency.
The team anticipates that eventually this would be a tool that could be integrated into screenwriting software. Most screenwriting programs such as Final Draft or WriterDuet are already able to create reports showing the proportion of character dialogue by gender. This tool would allow content analysis in terms of the nature of violent language used by a character, displaying which characters are the perpetrators and which are the victims.
“Often there may be unconscious patterns and biases present in the script that the writer may not intend, and a tool like this will help raise awareness of that.” Narayanan said.
The study “Violence Rating Prediction from Movie Scripts” is published in the Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence.
 
Published on March 20th, 2019Last updated on May 16th, 2024 
",,,"[{'@type': 'WebPage', '@id': 'https://viterbischool.usc.edu/news/2019/03/using-artificial-intelligence-to-predict-violence-in-movies/', 'url': 'https://viterbischool.usc.edu/news/2019/03/using-artificial-intelligence-to-predict-violence-in-movies/', 'name': 'Using Artificial Intelligence to Predict Violence in Movies - USC Viterbi | School of Engineering', 'isPartOf': {'@id': 'https://viterbischool.usc.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://viterbischool.usc.edu/news/2019/03/using-artificial-intelligence-to-predict-violence-in-movies/#primaryimage'}, 'image': {'@id': 'https://viterbischool.usc.edu/news/2019/03/using-artificial-intelligence-to-predict-violence-in-movies/#primaryimage'}, 'thumbnailUrl': 'https://viterbischool.usc.edu/wp-content/uploads/2019/03/Cinema-unsplash.jpg', 'datePublished': '2019-03-20T17:30:35+00:00', 'dateModified': '2024-05-16T16:45:26+00:00', 'breadcrumb': {'@id': 'https://viterbischool.usc.edu/news/2019/03/using-artificial-intelligence-to-predict-violence-in-movies/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://viterbischool.usc.edu/news/2019/03/using-artificial-intelligence-to-predict-violence-in-movies/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://viterbischool.usc.edu/news/2019/03/using-artificial-intelligence-to-predict-violence-in-movies/#primaryimage', 'url': 'https://viterbischool.usc.edu/wp-content/uploads/2019/03/Cinema-unsplash.jpg', 'contentUrl': 'https://viterbischool.usc.edu/wp-content/uploads/2019/03/Cinema-unsplash.jpg', 'width': '1200', 'height': '600', 'caption': 'A research team at USC’s Viterbi School of Engineering has created a tool to help the film industry track the depiction of violence in the language of scripts.'}, {'@type': 'BreadcrumbList', '@id': 'https://viterbischool.usc.edu/news/2019/03/using-artificial-intelligence-to-predict-violence-in-movies/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://viterbischool.usc.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'News', 'item': 'https://viterbischool.usc.edu/news/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Using Artificial Intelligence to Predict Violence in Movies'}]}, {'@type': 'WebSite', '@id': 'https://viterbischool.usc.edu/#website', 'url': 'https://viterbischool.usc.edu/', 'name': 'USC Viterbi | School of Engineering', 'description': '', 'publisher': {'@id': 'https://viterbischool.usc.edu/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://viterbischool.usc.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://viterbischool.usc.edu/#organization', 'name': 'USC Viterbi | School of Engineering', 'url': 'https://viterbischool.usc.edu/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://viterbischool.usc.edu/#/schema/logo/image/', 'url': 'https://viterbischool.usc.edu/wp-content/uploads/2016/10/USC-Viterbi-Preloader.png', 'contentUrl': 'https://viterbischool.usc.edu/wp-content/uploads/2016/10/USC-Viterbi-Preloader.png', 'width': '500', 'height': '175', 'caption': 'USC Viterbi | School of Engineering'}, 'image': {'@id': 'https://viterbischool.usc.edu/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/USCViterbi/', 'https://x.com/USCViterbi', 'https://www.instagram.com/uscviterbi/', 'https://www.youtube.com/user/USCViterbi/']}]",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMilAFodHRwczovL3d3dy5idXNpbmVzc3RvZGF5LmluL3NwZWNpYWxzL2Jlc3QtY29tcGFuaWVzLXRvLXdvcmstZm9yLTIwMTkvc3RvcnkvaHVtYW4taW50ZWxsaWdlbmNlLWJldHRlci10aGFuLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLTE3NzM0MC0yMDE5LTAzLTE40gEA?oc=5,"Human Intelligence Better Than Artificial Intelligence - BusinessToday - Issue Date: Apr 07, 2019 - Business Today",2019-03-18,Business Today,https://www.businesstoday.in,New technologies will displace jobs but also create jobs,"Business Today, Best Companies to Work For, HR solutions company, PeopleStrong, Indian workforce, employees, PeopleStrong Study Team - Issue Date: Apr 07, 2019","New technologies will displace jobs but also create jobs - Issue Date: Apr 07, 2019","New technologies will displace jobs but also create jobs - Issue Date: Apr 07, 2019",http://schema.org/,WebPage,https://www.businesstoday.in/specials/best-companies-to-work-for-2019/story/human-intelligence-better-than-artificial-intelligence-177340-2019-03-18,"{'@type': 'ImageObject', 'url': 'https://akm-img-a-in.tosshub.com/businesstoday/images/story/201903/human-660_032019061517.jpg?size=1280:720', 'height': '720', 'width': '1280'}","[{'@type': 'Person', 'name': 'Manish Sabharwal'}, {'@type': 'Person', 'name': 'Rituparna Chakraborty'}]","{'@type': 'Organization', 'name': 'Business Today', 'url': 'https://www.businesstoday.in', 'logo': {'@type': 'ImageObject', 'url': 'https://akm-img-a-in.tosshub.com/businesstoday/resource/img/bt-schema-logo.png', 'height': '60', 'width': '600'}}",Human Intelligence Better Than Artificial Intelligence,2019-03-18\T10:34:14+05:30,2019-03-22\T10:54:26+05:30,,Human Intelligence Better Than Artificial Intelligence,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.businesstoday.in', 'name': 'News'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.businesstoday.in/specials', 'name': 'SPECIALS'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.businesstoday.in/specials/best-companies-to-work-for-2019', 'name': 'Best Companies to Work For 2019'}}]",N/A,N/A,N/A,,https://www.businesstoday.in/specials/best-companies-to-work-for-2019/story/human-intelligence-better-than-artificial-intelligence-177340-2019-03-18,,,,,,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}",,,,,,,en_US,"Historians warn against Presentism; a belief that today&#039;s problems are uniquely complex and more difficult than before. Psychologists warn against catastrophising; a belief that problems will likely end up with the worst possible outcome. And scientists warn against anecdotalism; a belief that your experience explains what is happening in the world. Any discussion of Artificial Intelligence (AI) must keep in mind these three warnings.The rate at which AI will affect the job market will only accelerate, impacting the highly trained and poorly educated alike. While recognising the imminent danger of how jobs are likely to be disrupted, we can say that many key jobs are safe from AI because AI still lags humans in fields where niche human qualities like communication, empathy, creativity, strategic thinking, questioning, and dreaming matter. Jobs that can essentially be performed by humans have three key elements: STEM education, creativity, and emotional intelligence.Science, technology, engineering, and mathematics will continue to remain important as the prevalence of robots and automated systems will mean an increased need for engineers, technicians, and managers to build, maintain, and control the quality of the work performed by mechanised labour. A McKinsey report shows that the number of engineering professionals like computer scientists, engineers, IT administrators, IT workers, and tech consultants will increase by 20 million to 50 million globally by 2030. These jobs, however, require staying up-to-date with technology and moving into areas that are not automated by technology. AI-focussed automation will create shifts in IT service requirements in such a way that jobs like research analysts, data entry operators, system engineers and test engineers become obsolete while newer roles such as research scientists, language processing specialists, robotic process automation developers, and man-machine teaming managers emerge.While humans are innately capable of recognizing images, interpreting languages, drawing inferences and differentiating objects, machines require an exhaustive dataset to learn and mimic such skills. These hubs could employ people with primitive computer literacy to generate training material for AI systems. And, of course, the demand for AI professionals will rise as more mundane and repetitive work gets automated. Gartner Research Company estimates that in the next few years, there will be an increase in the number of AI professionals despite some entry-level AI positions being automated.Industries like healthcare, education and hospitality and professions like management need strong communication skills, empathy, and the capacity to inspire or gain a person&#039;s confidence; these jobs require emotional intelligence, which only a human being can give. The medical fraternity can use AI for analytical and administrative aspects of healthcare and make it cost effective for people. Managers with good human interaction skills will continue to have jobs. Managerial work will continue to be carried by humans and AI may be used to manage performance. Teachers will remain relevant in the context of helping students figure out their interests, and providing one-on-one mentorship; AI can be a tool to design curriculum.The book The Globotics Upheaval by Richard Baldwin suggests that AI will disrupt lives more than globalisation, industrialisation and automation did. While he believes that the changes are inevitable, there are adaptive strategies that can be used, employing the skills that no machine can copy; creativity and independent thought. Rituparna Chakraborty is President, Indian Staffing Federation, and Co-founder and Executive VP, Teamlease Services. Manish Sabharwal is Chairman and Co-founder of Teamlease Services","{'@type': 'imageObject', 'url': 'https://akm-img-a-in.tosshub.com/businesstoday/images/story/201903/human-660_032019061517.jpg?size=1280:720', 'caption': 'Rituparna Chakraborty and Manish Sabharwal', 'width': '1200', 'height': '900'}","{'@type': 'SpeakableSpecification', 'cssSelector': ['.headline', '.summary']}",,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9mZWktZmVpLWxpLWFpLWNhcmUtbW9yZS1hYm91dC1odW1hbnMv0gEA?oc=5,Fei-Fei Li Wants AI to Care More About Humans - WIRED,2019-03-20,WIRED,https://www.wired.com,Stanford professor and former Google employee Fei-Fei Li is the force behind the new Institute for Human-Centered Artificial Intelligence.,"['business', 'ai hub', 'human-computer interaction', 'ethics', 'research', 'artificial intelligence', 'machine learning', 'stanford', 'google', 'web']",Stanford professor and former Google employee Fei-Fei Li is the force behind the new Institute for Human-Centered Artificial Intelligence.,Stanford professor and former Google employee Fei-Fei Li is the force behind the new Institute for Human-Centered Artificial Intelligence.,https://schema.org/,BreadcrumbList,https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/,"['https://media.wired.com/photos/5c91290b25da720469976827/16:9/w_5036,h_2833,c_limit/Fei%20Fei%20Li%206.jpg', 'https://media.wired.com/photos/5c91290b25da720469976827/4:3/w_7072,h_5304,c_limit/Fei%20Fei%20Li%206.jpg', 'https://media.wired.com/photos/5c91290b25da720469976827/1:1/w_2905,h_2905,c_limit/Fei%20Fei%20Li%206.jpg']","[{'@type': 'Person', 'name': 'Tom Simonite', 'sameAs': 'https://www.wired.com/author/tom-simonite/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",Fei-Fei Li Wants AI to Care More About Humans,2019-03-20T14:53:09.854-04:00,2019-03-20T14:53:09.854-04:00,business,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.wired.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'artificial intelligence', 'item': 'https://www.wired.com/tag/artificial-intelligence/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Fei-Fei Li Wants AI to Care More About Humans'}]",tags,N/A,"Tom SimoniteBusinessMar 20, 2019 2:53 PMFei-Fei Li Wants AI to Care More About HumansThe Stanford professor and former Google exec is the force behind the new Institute for Human-Centered Artificial Intelligence.Fei-Fei Li helped bring about the recent resurgence of artificial intelligence, but says more effort must be made to make the technology serve human interests.Michelle GroskopfSave this storySaveSave this storySaveThe AI Database →ApplicationHuman-computer interactionEthicsEnd UserResearchFei-Fei Li heard the crackle of a cat’s brain cells a couple of decades ago and has never forgotten it. Researchers had inserted electrodes into the animal’s brain and connected them to a loudspeaker, filling a lab at Princeton with the eerie sound of firing neurons. “They played the symphony of a mammalian visual system,” she told an audience Monday at Stanford, where she is now a professor.The music of the brain helped convince Li to dedicate herself to studying intelligence—a path that led the physics undergraduate to specializing in artificial intelligence, and helping catalyze the recent flourishing of AI technology and use cases like self-driving cars. These days, though, Li is concerned that the technology she helped bring to prominence may not always make the world better.Her Stanford speech marked the opening of the Institute for Human-Centered Artificial Intelligence, or HAI, which will work on topics such as how to ensure algorithms make fair decisions in government or finance, and what new regulations may be required on AI applications. Luminaries from Silicon Valley and beyond—including Henry Kissinger and ex-Yahoo CEO Marissa Meyer—came to hear a day of discussions featuring a roster of academic and industry figures that included Bill Gates on how AI will shape society. Later, Li, a founder and co-director of HAI, told WIRED why AI research needs steering onto a new path.Trending NowWIRED25: Kai-Fu Lee and Fei Fei Li On What's Next for Artificial IntelligenceWIRED: Stanford has one of the world’s longest-running AI labs, and around the world there is more AI R&D than ever before. Why create a new research institute?Fei-Fei Li: AI started as a computer science discipline, but now we are in a new chapter. This technology has the potential to do so many good things, but there are also risks and pitfalls. We have to act and make sure it is human benevolent.At HAI we are making AI an interdisciplinary field of study and education by working with many different thinkers and practitioners: social scientists, political scientists, economists, doctors, and neuroscientists. My aspiration is to come up with thoughtful frontier research as well as potential policy recommendations.If people working on AI technology have to start engaging with such broader questions, will technical progress slow down?I never thought this has anything to do with slowing down. We are asking people to be more imaginative, collaborative, thoughtful, and human-centered. I don't know if these adjectives imply slowing down. We want to broaden the horizon and deliver the positive potential in a more concrete way.Li opened her new institute for human-centered AI with a daylong symposium about how the technology will shape society.
HOLLY HERNANDEZMost PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David Gilbert, WIREDSecurityAT&T Paid a Hacker $370,000 to Delete Stolen Phone RecordsBy Kim Zetter, WIREDYou have said there should be more work on using AI to help workers, not to replace them. What does that look like? At HAI’s launch symposium, one of your collaborators, Serena Yeung, mentioned a project placing depth cameras, which track motion in 3D, in hospital rooms.A patient's mobility in the ICU will have a direct impact on how well he or she recovers. Hospitals have protocols to, say, every one or two hours you have to monitor this, but nurses are overworked. A depth camera can watch patient mobility 24/7. AI can enhance and augment the work of clinicians.I personally have been spending lots of time in ICU with my mom in the past half a year. I cannot imagine replacing nurses and doctors, but I can imagine their work being helped in so many different ways so that they can focus on care.Stanford is located in the heart of Silicon Valley and HAI already has relationships with tech companies including Microsoft and Google. Can you become too close to the tech industry?Bill Gates spoke at the symposium with Amy Jin and Stephanie Tena-Meza, alumni of AI4ALL, a nonprofit Li founded to help make AI experts more diverse.
HOLLY HERNANDEZStanford is Stanford not because we're close to Google, but because of the tremendous amount of independent, world-changing research and education we've done for the past 130 years. No matter how much Silicon Valley companies love us, we wouldn’t have this reputation if we didn’t earn it ourselves. I’m very proud of the amazingly thought-provoking and sometimes controversial work we can do here.I think it’s really important that we engage with different industries so that our researchers understand the challenges and our research becomes useful tools. It’s easy to think industry means tech industry, but in our book industry means manufacturing, agriculture, retail, health care, education, government.You were chief scientist for AI and machine learning at Google’s cloud division until late last year. Then you briefly were listed as an adviser to the company, but recently cut ties. Did that industry experience influence your thinking about how AI could shape society? Leaked emails showed you discussing a Pentagon contract that led to employee protests, and Google announcing guidelines for acceptable uses of AI.LEARN MOREThe WIRED Guide to Artificial IntelligenceThe 20-month sabbatical at Google was extremely illuminating. I was inspired by listening to the pain points and challenges and opportunities that different industries have. It reinforced that there is a big role for AI to play in terms of helping the world in many important issues, but we have to guide it in the most thoughtful and human-centric way. And as an AI scientist, I was proud to contribute to the responsible AI guidelines.If HAI is successful, how will the world be different 10 years from now?Above all, I want to see HAI producing a very diverse workforce of AI practitioners, developers, and leaders. And I hope that we can deploy technologies that help humans live better and healthier and work more safely and productively.I also have really high hopes that AI literacy is more prevalent—starting with journalists but also with policy makers, teachers, civic society. This is not a professor wanting everybody to know how to code; it’s about more people participating in the guidance of AI.Enter your email to get the Wired newsletterclose dialogRecommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialogMore Great WIRED StoriesA tap-to-fly helicopter hints at a flying car futureA read/write metaphor is a flawed way to talk about DNATrump’s casinos couldn’t make Atlantic City great againFacebook can make VR avatars move exactly like youI embraced screen time with my daughter—and I love it👀 Looking for the latest gadgets? Check out our latest buying guides and best deals all year round📩 Want more? Sign up for our daily newsletter and never miss our latest and greatest stories","https://media.wired.com/photos/5c91290b25da720469976827/1:1/w_2905,h_2905,c_limit/Fei%20Fei%20Li%206.jpg","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/fei-fei-li-ai-care-more-about-humans/'}",,,,,,,,,Stanford professor and former Google employee Fei-Fei Li is the force behind the new Institute for Human-Centered Artificial Intelligence.,,,,,,,,,,"The music of the brain helped convince Li to dedicate herself to studying intelligence—a path that led the physics undergraduate to specializing in artificial intelligence, and helping catalyze the recent flourishing of AI technology and use cases like self-driving cars. These days, though, Li is concerned that the technology she helped bring to prominence may not always make the world better.
Her Stanford speech marked the opening of the Institute for Human-Centered Artificial Intelligence, or HAI, which will work on topics such as how to ensure algorithms make fair decisions in government or finance, and what new regulations may be required on AI applications. Luminaries from Silicon Valley and beyond—including Henry Kissinger and ex-Yahoo CEO Marissa Meyer—came to hear a day of discussions featuring a roster of academic and industry figures that included Bill Gates on how AI will shape society. Later, Li, a founder and co-director of HAI, told WIRED why AI research needs steering onto a new path.
WIRED: Stanford has one of the world’s longest-running AI labs, and around the world there is more AI R&D than ever before. Why create a new research institute?
Fei-Fei Li: AI started as a computer science discipline, but now we are in a new chapter. This technology has the potential to do so many good things, but there are also risks and pitfalls. We have to act and make sure it is human benevolent.
At HAI we are making AI an interdisciplinary field of study and education by working with many different thinkers and practitioners: social scientists, political scientists, economists, doctors, and neuroscientists. My aspiration is to come up with thoughtful frontier research as well as potential policy recommendations.
If people working on AI technology have to start engaging with such broader questions, will technical progress slow down?
I never thought this has anything to do with slowing down. We are asking people to be more imaginative, collaborative, thoughtful, and human-centered. I don't know if these adjectives imply slowing down. We want to broaden the horizon and deliver the positive potential in a more concrete way.
You have said there should be more work on using AI to help workers, not to replace them. What does that look like? At HAI’s launch symposium, one of your collaborators, Serena Yeung, mentioned a project placing depth cameras, which track motion in 3D, in hospital rooms.
A patient's mobility in the ICU will have a direct impact on how well he or she recovers. Hospitals have protocols to, say, every one or two hours you have to monitor this, but nurses are overworked. A depth camera can watch patient mobility 24/7. AI can enhance and augment the work of clinicians.
I personally have been spending lots of time in ICU with my mom in the past half a year. I cannot imagine replacing nurses and doctors, but I can imagine their work being helped in so many different ways so that they can focus on care.
Stanford is located in the heart of Silicon Valley and HAI already has relationships with tech companies including Microsoft and Google. Can you become too close to the tech industry?
Stanford is Stanford not because we're close to Google, but because of the tremendous amount of independent, world-changing research and education we've done for the past 130 years. No matter how much Silicon Valley companies love us, we wouldn’t have this reputation if we didn’t earn it ourselves. I’m very proud of the amazingly thought-provoking and sometimes controversial work we can do here.
I think it’s really important that we engage with different industries so that our researchers understand the challenges and our research becomes useful tools. It’s easy to think industry means tech industry, but in our book industry means manufacturing, agriculture, retail, health care, education, government.
You were chief scientist for AI and machine learning at Google’s cloud division until late last year. Then you briefly were listed as an adviser to the company, but recently cut ties. Did that industry experience influence your thinking about how AI could shape society? Leaked emails showed you discussing a Pentagon contract that led to employee protests, and Google announcing guidelines for acceptable uses of AI.
The 20-month sabbatical at Google was extremely illuminating. I was inspired by listening to the pain points and challenges and opportunities that different industries have. It reinforced that there is a big role for AI to play in terms of helping the world in many important issues, but we have to guide it in the most thoughtful and human-centric way. And as an AI scientist, I was proud to contribute to the responsible AI guidelines.
If HAI is successful, how will the world be different 10 years from now?
Above all, I want to see HAI producing a very diverse workforce of AI practitioners, developers, and leaders. And I hope that we can deploy technologies that help humans live better and healthier and work more safely and productively.
I also have really high hopes that AI literacy is more prevalent—starting with journalists but also with policy makers, teachers, civic society. This is not a professor wanting everybody to know how to code; it’s about more people participating in the guidance of AI.

More Great WIRED Stories

A tap-to-fly helicopter hints at a flying car future
A read/write metaphor is a flawed way to talk about DNA
Trump’s casinos couldn’t make Atlantic City great again
Facebook can make VR avatars move exactly like you
I embraced screen time with my daughter—and I love it
👀 Looking for the latest gadgets? Check out our latest buying guides and best deals all year round
📩 Want more? Sign up for our daily newsletter and never miss our latest and greatest stories",,,,"{'@type': 'CreativeWork', 'name': 'WIRED'}",,
https://news.google.com/rss/articles/CBMijQFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL21vbGx5c3ByYXlyZWdlbi8yMDE5LzAzLzIwL3doeS1ub3QtbWUtaG93LWxhdXJhLW1vbnRveWEtaXMtaW5jcmVhc2luZy1yZXByZXNlbnRhdGlvbi1pbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,Why Not Me? How Laura Montoya Is Increasing Representation in Artificial Intelligence - Forbes,2019-03-20,Forbes,https://www.forbes.com,"In 2016, she launched Accel.AI., a California nonprofit devoted to lowering the barriers to entry in engineering artificial intelligence. The organization hosts workshops and study sessions, provides learning resources, and also puts on a “Demystifying AI” symposium.",,"In 2016, she launched Accel.AI., a California nonprofit devoted to lowering the barriers to entry in engineering artificial intelligence. The organization hosts workshops and study sessions, provides learning resources, and also puts on a “Demystifying AI” symposium.","In 2016, she launched Accel.AI., a California nonprofit devoted to lowering the barriers to entry in engineering artificial intelligence. The organization hosts workshops and study sessions, provides learning resources, and also puts on a “Demystifying AI” symposium.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/mollysprayregen/2019/03/20/why-not-me-how-laura-montoya-is-increasing-representation-in-artificial-intelligence/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/mollysprayregen/files/2019/03/LNM_Headshot.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Molly Sprayregen', 'url': 'https://www.forbes.com/sites/mollysprayregen/', 'description': 'I am a freelance writer who specializes in LGBTQ issues', 'sameAs': ['https://www.linkedin.com/in/molly-sprayregen-017a4391/', 'https://www.twitter.com/@MollySpray', 'https://www.mollyspray.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Why Not Me? How Laura Montoya Is Increasing Representation in Artificial Intelligence,2019-03-20T08:44:00-04:00,2019-03-20T08:44:53-04:00,ForbesWomen,Why Not Me? How Laura Montoya Is Increasing Representation in Artificial Intelligence,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Leadership', 'item': 'https://www.forbes.com/leadership/'}, {'@type': 'ListItem', 'position': 3, 'name': 'ForbesWomen', 'item': 'https://www.forbes.com/forbeswomen/'}]",ForbesWomen,N/A,"More From ForbesJul 16, 2024,10:27am EDTFind Your True North: Why A Personal Vision Is Critical To SuccessJul 16, 2024,06:00am EDT7 Tips On How To Become A Self-Made MillionaireJul 16, 2024,05:00am EDTHow To ‘Unlearn Silence’ In The WorkplaceJul 15, 2024,05:48pm EDTHow Parents Can Juggle Work And Support Their Child’s EducationJul 15, 2024,08:00am EDTBusiness Challenges: 5 Tips For Deciding To Persist Or PivotJul 15, 2024,06:00am EDT10 Tips To Double Your Profits Without Increasing SalesJul 14, 2024,06:11pm EDTExperts Reveal How To Support Mental Health On A Weight Loss JourneyEdit StoryForbesLeadershipForbesWomenWhy Not Me? How Laura Montoya Is Increasing Representation in Artificial IntelligenceMolly SprayregenFormer ContributorOpinions expressed by Forbes Contributors are their own.I write about queer women who are changing the worldClick to save this article.You'll be asked to sign into your Forbes account.Got itMar 20, 2019,08:44am EDTUpdated Mar 20, 2019, 08:44am EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







Laura Montoya, Founder of Accel.AI and Latinx in AI Coalition
Vjosana Shkurti





It wasn’t long after Laura Montoya began working in artificial intelligence that she noticed a dire lack of diversity in the field. From boot camps to job opportunities, many AI spaces catered mostly to white men and people with enough educational resources to have earned advanced degrees.

Montoya, who studied biology and physical science at Eastern Michigan University, wanted to change that. “I decided if no one else has created a space for women, other minority groups, or people from non-traditional backgrounds to get into the space, why not me?” she says.
In 2016, she launched Accel.AI, a California nonprofit devoted to lowering the barriers to entry in engineering artificial intelligence. The organization hosts workshops and study sessions, provides learning resources, and also hosts a “Demystifying AI” symposium.
PROMOTED
According to Montoya, it can be difficult for minorities to feel empowered to enter the AI space when there are few public role models to whom they can relate.
Women, people of color, and LGBTQ individuals, she says, are not often given the recognition they deserve for their achievements. Right now, she is working with many universities in Latin America who have been working in AI and machine learning for years. “These researchers are just as highly skilled, just as technical, pure mathematicians,” she says. “They publish regularly, yet they don’t get the same accolades or recognition that people do coming out of well known universities, which is why we are doing the work we’re doing to increase representation and provide that recognition for them.”

Within Accel.AI, Montoya also runs an initiative called the Latinx in AI Coalition, dedicated specifically to increasing Latin American representation in AI. She created the coalition after observing the success of organizations like Black in AI and Women in Machine Learning that are devoted to uplifting specific groups. “I thought, being Latina myself, this is a great opportunity, and again, why not me?”
Montoya explains that her initiatives are crucial for a number of reasons. To start, technology is steadily replacing many lower-skilled jobs, which disproportionately affects minority communities. Displaced workers can find more opportunities in tech if they have access to training and resources.









ForbesWomen
US


ForbesWomen: Get the ForbesWomen newsletter, and supercharge your mission with success stories, tips and more.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the ForbesWomen newsletter!


                More Newsletters
            


You’re all set! Enjoy the ForbesWomen newsletter!

                More Newsletters
            



Additionally, Montoya emphasizes, a lack of representation leads to biased technology. When the technology is created by one group of people, then inevitably, it will only represent that group. She cites examples of facial recognition technology only working on lighter skinned individuals.
“With tech and especially with AI,” she says, “It spreads so quickly and is evolving so rapidly, its effects are greater than anything else we’ve ever seen, and that’s why there is so much more concern.” Montoya remains passionate about tech , but she wants to ensure the advancements make a positive impact on the world.
Along her journey, Montoya has learned the importance of having a strong community by her side. When she launched Accel.AI, she wasn’t focused enough on that aspect. “I always carried the burden of being an entrepreneur independently. I wanted to shoulder all the risk myself.”
Montoya learned, however, that to find long-term success, she needed to surround herself with other leaders who felt as passionate about her mission as she did. “Having those other people that care as much as you do at seeing the organization prosper will make it grow not only for the long term but much faster and in a way that will benefit society,” she says.
As Accel.AI grows, Montoya only plans to get busier. She hopes to use what she’s learned to help launch other organizations with similar missions. She already acts as an advisor to startups in the industry and hopes to ultimately work in both nonprofit and for profit spaces of social impact and emerging technologies. As long as the focus is on using technology to improve society, Montoya wants to be part of it. Because as she seems to ask herself so often, why not her?Follow me on Twitter or LinkedIn. Check out my website. Molly SprayregenI am a freelance writer who specializes in LGBTQ  issuesEditorial StandardsPrintReprints & PermissionsThe video player is currently playing an ad. You can skip the ad in 5 sec with a mouse or keyboard
1/100:09BitGo Cofounder And CEO Explains The Sudden Surge Of Bitcoin Worth





Skip Ad
 
Continue watchingBitGo Cofounder And CEO Explains The Sudden Surge Of Bitcoin Worthafter the adVisit Advertiser websiteGO TO PAGE",,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LmNpby5jb20vYXJ0aWNsZS8yMTk4NDkvcGFsbS1iZWFjaC1jb3VudHktc3BlZWRzLWNvdXJ0LWZpbGluZ3Mtd2l0aC1haS5odG1s0gFWaHR0cHM6Ly93d3cuY2lvLmNvbS9hcnRpY2xlLzIxOTg0OS9wYWxtLWJlYWNoLWNvdW50eS1zcGVlZHMtY291cnQtZmlsaW5ncy13aXRoLWFpLmh0bWw?oc=5,Palm Beach County speeds court filings with AI - CIO,2019-03-18,CIO,https://www.cio.com,"With five robots handling basic docketing processes, the county is enhancing efficiency, converting skeptics and escalating staff to higher-value work — and higher pay.",N/A,"With five robots handling basic docketing processes, the county is enhancing efficiency, converting skeptics and escalating staff to higher-value work — and higher pay.","With five robots handling basic docketing processes, the county is enhancing efficiency, converting skeptics and escalating staff to higher-value work — and higher pay.",,,,,,,,,,,,,,N/A,N/A,"










		With five robots handling basic docketing processes, the county is enhancing efficiency, converting skeptics and escalating staff to higher-value work — and higher pay.	




 









Florida’s Palm Beach County is keeping five recent recruits in the dark to boost productivity: The Lights-Out Court Document Processing project has five “robots” working 24/7 to process some of the thousands of documents the county court receives each week. It’s an example of how artificial intelligence and humans can work alongside one another — and shows how enterprises can enhance manual systems with AI.
Attorneys and other frequent filers at Palm Beach County Court are required to submit documents electronically, using a dedicated portal that’s available 24/7. Altogether, they file about 40,000 court documents a week this way, each of which must be docketed — that is, associated with the correct case, tagged and indexed so that it can be found in the court’s records.

[ Cut through the hype with our practical guide to machine learning in business and find out the10 signs you’re ready for AI — but might not succeed. | | Get the latest insights with our CIO Daily newsletter. ]

It’s a laborious process, one that Sharon R. Bock, clerk and comptroller for Palm Beach County, saw as ripe for automation.











 
 
 
Bock, who oversees around 700 employees and a $70 million budget, is always looking for more efficient ways to perform statutory and constitutional duties. With payroll accounting for 95 percent of her spend, using automation technology to deal with some out-of-hours- filings and help staff do more during regular office hours was an obvious target.
More Videos0 seconds of 56 minutes, 23 secondsVolume 0%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledShortcuts Open/Close/ or ?Play/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


Next UpCIO Leadership Live Jeff Sippel1:00:14SettingsOffAutomated Captions - en-USFont ColorWhiteFont Opacity100%Font Size100%Font FamilyArialCharacter EdgeNoneBackground ColorBlackBackground Opacity50%Window ColorBlackWindow Opacity0%ResetWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%200%175%150%125%100%75%50%ArialCourierGeorgiaImpactLucida ConsoleTahomaTimes New RomanTrebuchet MSVerdanaNoneRaisedDepressedUniformDrop ShadowWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%WhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%







Live00:0056:2356:23 

Narrowing the field
The project, which received a 2019 Digital Edge 50 Award for digital innovation, was undertaken in collaboration with Florida software developer Computing System Innovations (CSI), which supplies the software the county uses to redact court documents. CSI developed a machine-learning system to automate the docketing and to access relevant court filings, says Cindy Guerra, the county’s chief operating officer for courts and official records, and the project’s business sponsor. “We used the same interface, so it was actually very seamless,” she says.
Palm Beach County first identified the teams that would work on the project, and the types of filings the county would entrust to the system. They chose to work with “documents that were very frequently docketed but did not pose a risk if something went wrong,” Guerra says.











 
 
 
They also aimed for documents that would allow the highest quality OCR (optical character recognition). “For that reason, we excluded anything coming from a pro se filer, or self-represented litigant, because those tend to be handwritten, and the OCR quality is not going to be as good,” Guerra says.
Those criteria narrowed the load to seven docket codes, three of which were selected to begin the project: notice of hearing, notice of taking a deposition, and notice of cancellation. None of these documents require further action, such as the court asking the clerk to issue a writ or a summons, nor do they involve money.
Training the new recruits
To train CSI’s machine learning software, the county’s business analysts worked with the employee with the most knowledge of the county’s processes and documents to index 500 to 600 documents of each type, extracting and tagging the relevant information from them.











 
 
 
The county set up five instances of CSI’s automated docketing software on its servers, giving them “human” names, with a hint of robot in each: Arnold Connor, Hal Isaac, Rosie Tober, Walley Bishop and Kitt Robbie. Documents processed by these robots are electronically stamped with their names rather than ‘docketed by a robot.’ Guerra jokes: “We didn’t want to alarm our judges.”






Explore related questions


What are the benefits of using AI in high-volume court document processing?What are the advantages of using robots in court document processing?How does AI-powered court document processing benefit the legal aid community?How does AI-powered court document processing benefit the legal profession?How does AI-powered court document processing benefit the judiciary?





Ask




Once the software was trained, it was time to audit it.
“We don’t audit 100 percent of our humans, but we did audit 100 percent of the machines,” says Guerra. “I was 100 percent skeptical, that’s why we did 100 percent auditing.”  











 
 
 
The documents were presented to auditors in the same way, whether they had been processed by a robot or a human. The audit found that the machine learning system was 98 or 99 percent accurate with its three document codes, much better than humans.
“We were the first instance in using this type of software, so we were very apprehensive, and we didn’t know we could trust it. Now we know,” says Guerra. “Machine learning is more accurate than humans in that, once you teach the machine that it made an error, it will never ever make that error again. When we teach our clerks that they have made an error, sometimes it takes multiple trainings for them to actually get it right.”
After the project went live, Guerra received a call from a supervisor who had spotted a mistake in a docket. “She called up saying, ‘I can’t find the clerk who made this error, I can’t find her in our telephone list, her name is Walley Bishop.’ Well, we had to chuckle!” Guerra says. “It’s so seamless that it just looks like a clerk did it.”











 
 
 
Since the system went live in March 2018, it has been trained to read and process 26 docket codes and now dockets more than one in six electronically filed documents, with the goal of docketing more than one in three by July 2019.
Right now, the five robots are doing the docketing work of eight employees, and there’s capacity available to do the work of 19, says Guerra. To reach that, the robots would have to be retrained to deal with less common or more risky documents.
The impact of shifting to AI
Palm Beach County employees needn’t fear for their jobs, according to Bock. With robots available to do the work that is most repetitive and error-prone for humans, “We have been able to retrain our staff into more ‘thinking’ jobs,” she says. “We have also now raised the level, the career level, the experience level and the technical level of our employees so that we’ve now reclassified them into higher wages.”











 
 
 
That move to higher-paid roles has had the slight downside of eroding some of the cost benefits of increasing capacity through adding robots rather than more staff, says Bock, but “AI in our experience is actually allowing our workforce to move from a minimum wage environment for a certain group of people into not only a living wage but into a technical career that’s transferrable, that is exciting, that is thought-provoking.”
She expects that virtuous circle to continue as staff seize the opportunity to learn something new and see that their greater understanding allows for further innovation and the creation of new applications.
Other would-be adopters of AI shouldn’t expect instant results, though. This is not an off-the-shelf, plug-and-play product, Bock cautions. The project took several years from inception to completion, with CSI and county staff working together a lot of the way. “[Guerra’s] deep distrust as the business sponsor is one of the reasons that we were successful,” she says. “Setting up the auditing team meant that we caught the mistakes and retaught, taught, retaught.”











 
 
 
Looking to the future, Guerra wants to start working with more risky documents, “Those that require further actions, so that the machine can learn to make those further actions whether it’s email someone, prepare a writ or prepare a summons,” she says. Another goal is to have the robots issue receipts for documents submitted with payment.
Meanwhile, Bock hopes that the system, currently dealing only with civil filings, can be extended into the criminal segment.
Visitors from the Federal Bankruptcy Court have come to look at the system, and Bock and Guerra both hope other courts will adopt lights-out document processing too. “As other counties in the state of Florida go online, we benefit from the work that they do,” Bock says.











 
 
 
Bock, a lawyer by training, concludes: “This is the most exciting thing I’ve ever done in the 27 years of my career.”

More on AI and machine learning:

 A practical guide to machine learning in business 
 Reskilling IT for the AI era 
 9 IT projects primed for machine learning 
 The future of ERP is AI 
 5 artificial intelligence trends that will dominate 2018 
 6 secrets of successful chatbot strategies 
 How AI is revolutionizing business productivity 
 Machine learning success stories: An inside look 
 9 machine learning myths 
 10 signs you’re ready for AI — but might not succeed 


















 
Related content

 


feature

The CIO role today: Change agents need only apply
CIOs have earned the right to be agents of change and leaders of business transformation for their organizations. All that’s left is the hard work of capitalizing on it. 

				By Grant Gross				


Jul 16, 2024

8 mins 


CIO
Digital Transformation
Change Management






opinion

Microsoft Recall: Everything IT can get wrong about AI in a single feature
Microsoft Recall may be built with artificial intelligence, but its building lacked judgment and wisdom — two things CIOs and IT teams must impart to get AI right. 

				By Bob Lewis				


Jul 16, 2024

6 mins 


Risk Management
Artificial Intelligence






brandpost

							Sponsored by IDC						

ESG reporting: Carbon in the cloud
Cloud computing emissions carries complexity for companies concerned about their sustainability profiles. While IT organizations don’t need to include public cloud use in their ESG reporting, they may choose to do so. And even if they don&rsquo 

				By Dr. Ron Babin, IDC adjunct research advisor				


Jul 15, 2024

6 mins 


Cloud Computing






brandpost

							Sponsored by Avaya						

Best practices for integrating AI in business: A governance approach
Harness the power of AI today by balancing innovation with ethical governance. 

				By Dr. Cat Wade, Cloud Compliance and Ethics Analyst & Chairperson for the Artificial Intelligence Enablement Committee, Avaya				


Jul 15, 2024

5 mins 


Machine Learning
Artificial Intelligence






PODCASTS


VIDEOS


RESOURCES


EVENTS













 
SUBSCRIBE TO OUR NEWSLETTER			

				From our editors straight to your inbox			

			Get started by entering your email address below.		


 



Please enter a valid email address




Subscribe









",,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOmh0dHBzOi8vd3d3Lm91dHJlYWNoLnBzdS5lZHUvcHJvZ3JhbXMvbml0dGFueS1haS1hbGxpYW5jZS_SAQA?oc=5,Nittany AI Alliance - Penn State News,2019-03-20,Penn State News,https://www.outreach.psu.edu,"The Nittany AI Alliance brings together the Penn State community, technology leaders, innovators, and entrepreneurs through programs that create meaningful engagement opportunities for students focused on new artificial intelligence solutions and services.",N/A,"The Nittany AI Alliance brings together the Penn State community, technology leaders, innovators, and entrepreneurs through programs that create meaningful engagement opportunities for students focused on new artificial intelligence solutions and services.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

Nittany AI Alliance  


﻿

The Nittany AI Alliance is creating programs that bring together the Penn State community, technology leaders, innovators, and entrepreneurs. These programs create meaningful engagement opportunities for students focused on new artificial intelligence solutions, services, and outreach projects with industry partners.
Our Mission
The Nittany AI Alliance provides students with unique opportunities to help prepare them to lead in a world shaped by artificial intelligence. To accomplish its mission, the Alliance provides Penn State students project-based experiences, access to industry-leading AI technology, and curated resources to enable experiential learning opportunities. This work brings together companies seeking strategic AI collaborations, faculty working on innovative AI research, and staff looking to address higher education process pain points through the use of AI.
Student Engagement



The Nittany AI Challenge offers teams of students the chance to compete for grants by developing and presenting AI–based solutions that solve real-world problems. Leading AI companies, which have included Amazon Web Services, Google Cloud, IBM Watson, Microsoft and Oracle, offer free workshops and training resources to help teams better understand and leverage their technologies.
Visit Nittany AI Challenge



The Nittany AI Advance program provides Penn State students hands-on experience that enhances their classroom learning by offering opportunities to work on artificial intelligence–related projects. Selected students will work on semester-long projects that involve creating proofs of concept to demonstrate the potential impact of AI in addressing real-world problems.
Visit Nittany AI Advance


Impact
In 2018, the inaugural EdTech Engage conference brought together more than 135 faculty, staff, students, and company representatives to discuss the impact of AI and machine learning in higher education. The Nittany AI Challenge raised $42,000 through company sponsorships for HackPSU and resulted in 71 submissions. Participation increased from previous years, with 58 faculty/staff and 196 students representing more than 25 majors, 10 campuses, 16 colleges, and 35 academic departments. The Challenge concluded with three teams being chosen to receive funding for further development: LionPlanner; ProFound, A Professor Search Engine; and Aspire.

The Nittany AI Alliance engages Penn State through a variety of programs, events, and projects to foster AI–enabled innovations. In 2018, the Alliance impacted 16 campuses and over 700 faculty, staff, and students, while involving leading AI and technology companies. We will continue to focus on providing students with hands-on experiential learning opportunities through the practical application of AI to solve real-world problems.
—Daren Coudriet, Director and Entrepreneur in Residence


Visit Nittany AI Alliance
 
",,,"[{'@type': 'WebPage', '@id': 'https://www.outreach.psu.edu/programs/nittany-ai-alliance/', 'url': 'https://www.outreach.psu.edu/programs/nittany-ai-alliance/', 'name': 'Nittany AI Alliance - Penn State Outreach', 'isPartOf': {'@id': 'https://www.outreach.psu.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.outreach.psu.edu/programs/nittany-ai-alliance/#primaryimage'}, 'image': {'@id': 'https://www.outreach.psu.edu/programs/nittany-ai-alliance/#primaryimage'}, 'thumbnailUrl': 'https://www.outreach.psu.edu/wp-content/uploads/NAI.jpg', 'datePublished': '2018-09-12T14:12:30+00:00', 'dateModified': '2023-05-12T14:16:34+00:00', 'description': 'The Nittany AI Alliance brings together the Penn State community, technology leaders, innovators, and entrepreneurs through programs that create meaningful engagement opportunities for students focused on new artificial intelligence solutions and services.', 'breadcrumb': {'@id': 'https://www.outreach.psu.edu/programs/nittany-ai-alliance/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.outreach.psu.edu/programs/nittany-ai-alliance/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.outreach.psu.edu/programs/nittany-ai-alliance/#primaryimage', 'url': 'https://www.outreach.psu.edu/wp-content/uploads/NAI.jpg', 'contentUrl': 'https://www.outreach.psu.edu/wp-content/uploads/NAI.jpg', 'width': 900, 'height': 506, 'caption': 'Nittany AI Alliance'}, {'@type': 'BreadcrumbList', '@id': 'https://www.outreach.psu.edu/programs/nittany-ai-alliance/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.outreach.psu.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Outreach Programs', 'item': 'https://www.outreach.psu.edu/programs/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Nittany AI Alliance'}]}, {'@type': 'WebSite', '@id': 'https://www.outreach.psu.edu/#website', 'url': 'https://www.outreach.psu.edu/', 'name': 'Penn State Outreach', 'description': 'Penn State Outreach', 'publisher': {'@id': 'https://www.outreach.psu.edu/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.outreach.psu.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.outreach.psu.edu/#organization', 'name': 'Penn State Outreach', 'url': 'https://www.outreach.psu.edu/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.outreach.psu.edu/#/schema/logo/image/', 'url': 'https://www.outreach.psu.edu/wp-content/uploads/favicon.png', 'contentUrl': 'https://www.outreach.psu.edu/wp-content/uploads/favicon.png', 'width': 512, 'height': 512, 'caption': 'Penn State Outreach'}, 'image': {'@id': 'https://www.outreach.psu.edu/#/schema/logo/image/'}}]",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vZWNoYW5uZWxsaW5lLmNvbS8yMDE5LzAzLzE4L2hvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pcy10cmFuc2Zvcm1pbmctaHVtYW4tcmVzb3VyY2VzL9IBAA?oc=5,How Artificial Intelligence Is Transforming Human Resources - eChannelLine,2019-03-18,eChannelLine,https://echannelline.com,"Human resources, as a field, is always evolving to accommodate the growing and changing needs of companies and individuals.",N/A,"Human resources, as a field, is always evolving to accommodate the growing and changing needs of companies and individuals. ""With","Human resources, as a field, is always evolving to accommodate the growing and changing needs of companies and individuals. ""With",http://schema.org,BreadcrumbList,https://echannelline.com/2019/03/18/how-artificial-intelligence-is-transforming-human-resources/,"{'@type': 'ImageObject', 'url': 'https://echannelline.com/wp-content/uploads/2019/03/rock-n-roll-monkey-681546-unsplash.jpg', 'width': 6000, 'height': 3368}","{'@type': 'Person', 'name': 'Jon Henderson', 'url': 'https://echannelline.com/author/jhenderson/'}","{'@type': 'Organization', 'name': '', 'url': 'https://echannelline.com', 'logo': {'@type': 'ImageObject', 'url': ''}, 'sameAs': ['https://plus.google.com/108064857687674595389', 'https://www.facebook.com/eChannelLine', 'https://twitter.com/robertmcohen']}",How Artificial Intelligence Is Transforming Human Resources,2019-03-18 09:14:40,2023-02-23 08:48:39,['articles'],How Artificial Intelligence Is Transforming Human Resources,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://echannelline.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://echannelline.com/category/articles/', 'name': 'articles'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://echannelline.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://echannelline.com/category/articles/', 'name': 'articles'}}]",articles,N/A,"





3rd Gen AMD Ryzen Release Leak – Intel Vulnerability Exposed

 July 15, 2021

",,"{'@type': 'WebPage', '@id': 'https://echannelline.com/2019/03/18/how-artificial-intelligence-is-transforming-human-resources/'}","[{'@type': '', 'headline': 'How Artificial Intelligence Is Transforming Human Resources - eChannelLine', 'datePublished': '2019-03-18T09:14:40+00:00', 'dateModified': '2023-02-23T08:48:39+00:00', 'author': {'@type': 'Person', 'name': 'Jon Henderson'}, 'description': 'Human resources, as a field, is always evolving to accommodate the growing and changing needs of companies and individuals.', 'name': 'How Artificial Intelligence Is Transforming Human Resources - eChannelLine', '@id': 'https://echannelline.com/2019/03/18/how-artificial-intelligence-is-transforming-human-resources/#richSnippet', 'isPartOf': {'@id': 'https://echannelline.com/2019/03/18/how-artificial-intelligence-is-transforming-human-resources/#webpage'}, 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://echannelline.com/2019/03/18/how-artificial-intelligence-is-transforming-human-resources/#webpage'}}]",,,,,,,,,,,,,,,,"{'@type': 'SearchAction', 'target': 'https://echannelline.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}",,"Human resources, as a field, is always evolving to accommodate the growing and changing needs of companies and individuals.

""With the help of artificial intelligence (AI), many HR tasks can be handled more efficiently to increase employee satisfaction drastically,"" says Joanna who is in <a href=""https://www.therfpsuccesscompany.com"">rfp consulting</a> for The RFP Success Company.

<a href=""http://www.atlanta-business-directory.com"">Many companies</a> have already taken steps to utilize AI in their human resources departments. You may find their experiences inspirational enough to consider making AI an integral part of your company’s human resources operation.
<h2>Artificial Intelligence Makes Recruiting A Breeze.</h2>
With AI technology, online information can be collected from the candidate’s entire online presence, then that information can be used in to rank the candidates you will eventually choose from.

By using this technology in this hiring process, candidates can be ranked based on the desired experience, salary expectations, work history, and skills.
<h2>Using AI to Engage With Candidates</h2>
For candidates applying for a position, it can be disheartening to not receive any type of response or have any sort of interaction with the employer after they apply. Artificial intelligence can use systems like <a href=""https://www.hubspot.com/"">Hubspot</a> to engage the candidate in a way that feels more natural than an automated email.

With AI, the messages and responses a candidate receives can be more personal and unique to the candidate, encouraging a more positive overall experience.
<h2>Onboarding New Hires With AI</h2>
Many organizations are also exploring AI to help new hires acclimate to their new positions. Artificial intelligence can help by answering questions, providing information, and sharing resources to familiarize the employee with the company’s culture, policies, and systems.

Given the magnitude of information new employees are asked to digest in the first few days on the job, AI can provide information and education reinforcement to help employees retain relevant information.
<h2>Chatbots For Employees to Access Information</h2>
Chatbots are a specific type of artificial intelligence technology that can be especially useful for employees. Communicating via text, chatbots can answer standard employee questions. Employees can use chatbots to ask about paid-time-off policies, absences, open enrollment, and more.
<h2>Artificial Intelligence to Automate Administrative Tasks</h2>
Administrative tasks like managing payrolls and compliance and examining performance review information are arguably the most laborious <a href=""https://www.humanresourcesedu.org/hr-specialist/"">HR duties</a>. By assigning these tedious tasks to AI, a significant amount of time and effort can instead be spent on employee training and workplace improvements.

An additional benefit to using AI for payroll and compliance management is the technology’s accuracy. AI can easily handle large pieces of information and can be relied on to perform tasks entirely error-free.
<h2>AI Personal Assistants Designed to Help Businesses</h2>
‘Amy Ingram’ is an AI personal assistant that can effectively perform a variety of tasks. Amy was made by <a href=""https://x.ai"">x.ai</a> and takes the hassle out of scheduling appointments and meetings. Amy is even able to write emails that sound so natural, you would think a human wrote them.

‘Leena AI’ is another AI assistant that can build HR chatbots that are able to answer employee questions. Leena can work with most collaboration apps and saves HR managers from having to dedicate time to inform employees about company policies.

According to <a href=""https://www.personneltoday.com/hr/ten-ways-hr-tech-leaders-can-make-artificial-intelligence/"">Personnel Today</a>, 38% of organizations are already using AI at work, while 62% are expecting to use it in the near future. Given the role that technology already takes in our personal lives, it’s no wonder that it’s beginning to ooze into the workplace. Only time will tell how much of a difference AI makes for human resources and businesses overall.",,,,,https://echannelline.com/#website,2019-03-18 09:14:40
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3Lm1hbHRhdG9kYXkuY29tLm10L2J1c2luZXNzL2J1c2luZXNzX2NvbW1lbnQvOTM3NjQvYXJ0aWZpY2lhbF9pbnRlbGxpZ2VuY2VfaWdub3JlX2F0X3lvdXJfb3duX3Jpc2tfX3BrZl9tYWx0YdIBAA?oc=5,Artificial Intelligence: ignore at your own risk | PKF Malta - MaltaToday,2019-03-21,MaltaToday,https://www.maltatoday.com.mt,Experts predict that it in ten years it will underpin $15.7 trillion of global economic growth. Some fear it will wreck job opportunities and create mass unemployment in certain sectors yet others are less sanguine and think that it simply transforms current jobs and create new ones,N/A,Experts predict that it in ten years it will underpin $15.7 trillion of global economic growth. Some fear it will wreck job opportunities and create mass unemployment in certain sectors yet others are less sanguine and think that it simply transforms current jobs and create new ones,N/A,,,,,,,,,,,,,,N/A,N/A," 

THE advent of Artificial Intelligence is entering the economic stage through the back-door but many feel that it is so powerful that we can only ignore its influence at our own peril. It is no minnow.
Experts predict that it in ten years it will underpin $15.7 trillion of global economic growth. Some fear it will wreck job opportunities and create mass unemployment in certain sectors yet others are less sanguine and think that it simply transforms current jobs and create new ones.
The McKinsey Global Institute reckons that by 2030 up to 375m people, or 14% of the global workforce, could have their jobs automated away. Bosses will need to decide whether they are prepared to offer and pay for retraining, and whether they will give time off for it. Many companies feel sympathetic towards the need for workers to develop new skills, but mass education is the remit of national governments and should not come about at the employer’s expense.
This is debateable, since less advanced countries do not have the resources to train workers to reach the higher technical skills required once the AI revolution becomes mainstream. Technological change always causes disruption, but AI is likely to have a bigger impact than anything since the advent of computers, and its consequences could be far more disruptive. Being both powerful and relatively cheap, it will spread faster than computers did and influence many sectors.
Another important question is how to protect privacy as AI spreads. The internet has already made it possible to track people’s digital behaviour in minute detail. There is little doubt that in the coming years, AI will offer even smarter tools for businesses to monitor consumers behaviours, both online and in the physical world.
This may become a threat to privacy. A corollary of AI is machine learning. One can explain this as autonomous learning capacity which empowers a machine to learn by its own without being explicitly programmed. It is a subset of AI, that provides the underlying system with the ability to automatically learn and improve from experience.
Today, many US firms are competing to provide AI-enhanced tools to companies. As can be expected, millions are invested to develop new technologies and companies that achieve a major breakthrough in artificial intelligence could easily race ahead of rivals and toughen global competition.
More likely, in the years ahead AI might contribute to the rise of monopolies in industries outside the tech sector where there used to be dynamic markets, eventually stifling innovation and consumer choice. The fear is that smart computer programs will eliminate millions of
jobs, condemning a generation to minimum-wage drudgery or enforced idleness. Never mind the robots, fear the software.
But real-life experience has shown otherwise. For example, the arrival of automated teller machines (ATMs) spared bank employees the job of handling out cash and freed them to offer financial advice to customers.
Obviously, some jobs could be made a lot easier by AI. One example is taxi drivers. Some fear that taxi drivers will be replaced by autonomous vehicles. But in future taxis will still be manned particularly when needed in town to manoeuvre around busy streets which is far harder than driving long distances down the motorway. Interesting advances powered by AI are happening across many medical areas.
Other potential uses of AI, is to detect cyberattacks, or coordinate fleets of drones, in hospitals and where many people congregate it is useful for mass surveillance through facial recognition. Furthermore, increased automation gives more physical control to digital systems, which in turn makes cyberattacks even more dangerous.
Regulation is needed to ensure that AI engineers are employing best practices in fighting cybersecurity and limiting the intrusion of cyber thieves especially in banks and sensitive data centres.
The fusion of AI and Blockchain systems will further enlarge the arsenal with tools for fighting cybercrime and make DLT databases tamper proof. To give an example, when any, say transaction, is recorded on blockchain, that transaction is made known throughout the chain connecting users’ to each other.
Therefore, it is not possible to tamper with a blockchain, which is why trust is built into the system rather than guaranteed by a ‘central owner’ of the data. Thus, this powerful technology is silently ushering the fourth industrial revolution. It will allow individuals to regain control of their own data, such as medical health or education
records, and use it in ways that would not have been possible in the past. Blockchain and DLT technology will improve the tracking of intellectual property rights, as well as strengthen the concept of ownership in the digital sphere.
Having discussed briefly the uses of AI, one may ask if and how can tiny Malta ever partake of this success story. The answer is blowing in the wind as it so happens that Prime Minister Joseph Muscat has called for a global framework for regulating research into, and the development of, artificial intelligence technologies when last year he addressed a top conference in Shanghai China.
AI, the internet of things and a best-in-class regulatory framework are now high on the government’s agenda, following the successful introduction of the world’s first comprehensive set of blockchain laws last year.
Castille is smelling the coffee and the penny has dropped to lay the foundations for a digital innovation hub. The fly in the ointment is having superlative technical facilities to train a workforce with the right skills. It is a tall order, since millions are needed to train a workforce proficient in AI.
But it is never too late to start. Government recently announced the funding of a scholarship bourse for post-graduate degrees, as well as hosting a lab to encourage the exploration of emerging technologies.
One looks forward with courage to the next Delta Summit this year sponsored by the government with the hope that it will attract tech-evangelists and AI engineers to help us build a local ecosystem. One augurs this fulfils the vision of the prime minister and hallmarks his legacy at a time when he is rumoured to be contemplating his exit from the political stage. ",,,,,,,,,,,,,,,,,,,,,,,,,,,

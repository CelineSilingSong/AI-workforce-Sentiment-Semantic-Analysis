URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,article:section,article:summary,article text,@context,itemListElement,@type,author,datePublished,headline,publisher,image,@graph,mainEntityOfPage,dateModified,isPartOf,isAccessibleForFree,hasPart,url,inLanguage,alternativeHeadline,copyrightHolder,sourceOrganization,copyrightYear,name,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,speakable,creator,provider,thumbnailUrl,video,uploadDate,duration,contentUrl,embedUrl
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS90ZWNobm9sb2d5LzIwMjEvbm92LzExL2FsZ29yaXRobWljLW1vbml0b3JpbmctbWVudGFsLWhlYWx0aC11ay1lbXBsb3llZXPSAWRodHRwczovL2FtcC50aGVndWFyZGlhbi5jb20vdGVjaG5vbG9neS8yMDIxL25vdi8xMS9hbGdvcml0aG1pYy1tb25pdG9yaW5nLW1lbnRhbC1oZWFsdGgtdWstZW1wbG95ZWVz?oc=5,Algorithmic tracking is ‘damaging mental health’ of UK workers - The Guardian,2021-11-11,The Guardian,https://www.theguardian.com,Report by MPs and peers says monitoring worker performance using AI should be regulated by law,N/A,Report by MPs and peers says monitoring worker performance using AI should be regulated by law,N/A,Technology,N/A," An delivery driver with his van. The report said an ‘accountability for algorithms act’ would ensure that companies evaluate the effect of performance-driven regimes. Photograph: Britpix/AlamyView image in fullscreenAn delivery driver with his van. The report said an ‘accountability for algorithms act’ would ensure that companies evaluate the effect of performance-driven regimes. Photograph: Britpix/AlamyArtificial intelligence (AI) This article is more than 2 years oldAlgorithmic tracking is ‘damaging mental health’ of UK workersThis article is more than 2 years oldReport by MPs and peers says monitoring worker performance using AI should be regulated by lawDan Milmo Global technology editorThu 11 Nov 2021 01.00 ESTLast modified on Thu 11 Nov 2021 15.34 ESTShareMonitoring of workers and setting performance targets through algorithms is damaging employees’ mental health and needs to be controlled by new legislation, according to a group of MPs and peers.An “accountability for algorithms act’” would ensure that companies evaluate the effect of performance-driven regimes such as queue monitoring in supermarkets or deliveries-per-hour guidelines for delivery drivers, said the all-party parliamentary group (APPG) on the future of work.“Pervasive monitoring and target-setting technologies, in particular, are associated with pronounced negative impacts on mental and physical wellbeing as workers experience the extreme pressure of constant, real-time micro-management and automated assessment,” said the APPG members in their report, the New Frontier: Artificial Intelligence at Work.The report recommends bringing in a new algorithms act, which it says would establish “a clear direction to ensure AI puts people first”. It warns that “use of algorithmic surveillance, management and monitoring technologies that undertake new advisory functions, as well as traditional ones, has significantly increased during the pandemic”.Under the act workers would be given the right to be involved in the design and use of algorithm-driven systems, where computers make and execute decisions about fundamental aspects of someone’s work – including in some cases allocation of shifts and pay, or whether they get a job in the first place.The report also recommended that corporations and public sector employers fill out algorithmic impact assessments, aimed at ironing out any problems caused by the systems, and expanding the new umbrella body for digital regulation, the Digital Regulation Cooperation Forum, to introduce certification and guidance for use of AI and algorithms at work.The MPs added that the use of AI and algorithms produced a sense of unfairness and lack of independence among workers, who also aren’t aware of the role of personal information in guiding decisions about how they go about their jobs. Regulation of social media and video platforms will also be included in the online safety bill, which will become law towards the end of next year.David Davis MP, the Conservative chair of the APPG on the future of work, said: “Our inquiry reveals how AI technologies have spread beyond the gig economy to control what, who and how work is done. It is clear that, if not properly regulated, algorithmic systems can have harmful effects on health and prosperity.”Clive Lewis, a Labour member of the APPG, added: “Our report shows why and how government must bring forward robust proposals for AI regulation. There are marked gaps in regulation at an individual and corporate level that are damaging people and communities right across the country.”The APPG inquiry was established after the publication of a report into the role of AI and algorithms in modern work in May this year by the Institute for the Future of Work, a research body, entitled the Amazonian Era. The report focused on retail workers and included testimony from delivery drivers and checkout workers who complained of monitoring systems and target-setting that produced high levels of anxiety.“A lot of professional drivers will sometimes jump a red light or brake too hard because they are under time constraints and often they have to use their mobile while driving,” one supermarket delivery driver said in the report. The IFoW study also included testimony from manufacturing workers who had to log 95% of their activity on shifts, so their working day could be planned more intensively.Explore more on these topicsArtificial intelligence (AI)Employment lawSurveillanceGig economyMental healthWork & careersnewsShareReuse this contentMost viewed‘Some of the most shocking photographs ever taken’ – The Camera Never Lies reviewRepublican convention day three: JD Vance to speak as focus turns to foreign policyJon Stewart on Trump assassination attempt: ‘We dodged a catastrophe’LiveBiden hasn’t done enough to ease age concerns, former top Obama adviser says – liveWho is Usha Vance, the Indian American lawyer married to JD Vance?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmRlbG9pdHRlLmNvbS91ay9lbi9zZXJ2aWNlcy9jb25zdWx0aW5nL2FuYWx5c2lzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXdpdGgtZGFsbGUuaHRtbNIBAA?oc=5,Artificial Intelligence with DALL.E - Deloitte,2021-11-14,Deloitte,https://www.deloitte.com,"A dive into DALL·E, an artificial intelligence program created by OpenAI that generates images based on short text phrases.",N/A,"A dive into DALL·E, an artificial intelligence program created by OpenAI that generates images based on short text phrases.","A dive into DALL·E, an artificial intelligence program created by OpenAI that generates images based on short text phrases.",N/A,N/A,N/A,https://schema.org/,"[{'item': {'@id': '', 'name': 'What we do '}, 'position': 1, '@type': 'ListItem'}, {'item': {'@id': '/uk/en/services.html', 'name': 'Services'}, 'position': 2, '@type': 'ListItem'}, {'item': {'@id': '/uk/en/services/consulting.html', 'name': 'Consulting'}, 'position': 3, '@type': 'ListItem'}]",Article,[],2021-11-14T00:00:00.0Z,Artificial Intelligence with DALL.E | Deloitte UK,"{'@type': 'Organization', 'name': 'Deloitte', 'logo': {'@type': 'ImageObject', 'url': 'https://www.deloitte.com/content/dam/modern/logo/deloitte-print.png'}}","['https://assets.deloitte.com/is/image/deloitte/deloitte-uk-ai-with-dalle-promo:660-x-660?$Responsive$&fmt=webp&fit=stretch,1&dpr=off', 'https://assets.deloitte.com/is/image/deloitte/deloitte-uk-ai-with-dalle-promo:800-x-600?$Responsive$&fmt=webp&fit=stretch,1&dpr=off', 'https://assets.deloitte.com/is/image/deloitte/deloitte-uk-ai-with-dalle-promo:1200-x-675?$Responsive$&fmt=webp&fit=stretch,1&dpr=off']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUGh0dHBzOi8vd3d3LmFwb2xsby1tYWdhemluZS5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYXV0aGVudGljYXRpb24tYXJ0d29ya3Mv0gFWaHR0cHM6Ly93d3cuYXBvbGxvLW1hZ2F6aW5lLmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hdXRoZW50aWNhdGlvbi1hcnR3b3Jrcy8_YW1wPTE?oc=5,Is AI really ready to solve the problems that have had art historians stumped? - Apollo Magazine,2021-11-11,Apollo Magazine,https://www.apollo-magazine.com,It’s still early days for the authentication of artworks by artificial intelligence – and experts will always be needed to interpret the findings,N/A,It’s still early days for the authentication of artworks by artificial intelligence – and experts will always be needed to interpret the findings,It’s still early days for the authentication of artworks by artificial intelligence – and experts will always be needed to interpret the findings,N/A,N/A,"



Comment
Is AI really ready to solve the problems that have had art historians stumped?

Ahmed Elgammal and Adam Finnefrock
11 November 2021


Did Rubens really paint the National Gallery’s Samson and Delilah? 





Share

Twitter
Facebook
LinkedIn
Email




The attribution of the National Gallery’s Samson and Delilah (c. 1609–10) to Peter Paul Rubens has long been debated. When the painting resurfaced on the market in 1929, it was offered as a work by the Dutch Caravaggist Gerrit van Honthorst; the scholar Ludwig Burchard immediately declared it as a Rubens but questions have remained over the style and provenance of the work. Earlier this autumn, several media outlets reported that a Swiss company using artificial intelligence (AI) to assess the authenticity of artworks had calculated a 91.78 per cent probability that Samson and Delilah was not painted by Rubens. The same company also wrote a report on another painting in the National Gallery – A View of Het Steen in the Early Morning (c. 1636) – which stated a 98.76per cent probability that Rubens painted the work. (To our knowledge, the attribution of this painting has not been questioned.) This news, with its highly confident claims and oddly precise probabilities, surprised us as researchers who have been deeply involved in problems around art attribution for many years, specialising in developing AI technology and scientific methods for these questions. While the call for a deattribution of a significant painting at a major museum is ripe for publicity, without an in-depth publication of the AI methods employed in the peer-reviewed literature, it is difficult to take these particular conclusions at face value.
Is AI ready to tell us whether or not Samson and Delilah was painted by Rubens? To address this question, an AI researcher would first create ‘training sets’ that contain many examples of paintings by Rubens in one set, and many examples of works by other artists who might be confused with Rubens in another set. Through well-established algorithms that ‘teach’ the AI to accept paintings similar to the first set and reject paintings in the second set, the AI will learn to differentiate Rubens’s paintings from the others with (ideally) sufficient accuracy to answer attribution questions. However, this process has a number of pitfalls that must be properly understood if they are to be avoided.
One of the problems in identifying the work of Rubens and other Old Masters is their workshop practice. As a successful and sought-after painter, Rubens ran a large workshop where multiple assistants would sometimes work on a single painting. The challenge of definitively attributing such a painting based on an overall AI analysis nonetheless provides a wonderful opportunity to explore an interesting question: how can we identify the ‘hand of the master’ in contrast to the workshop assistants? Usefully, both the hands of the master and of the assistants are in the same painting, so there are none of the differences between paintings that would otherwise be additional factors to complicate the analysis.
Many available pre-built AI methods designed for image recognition are built to analyse and categorise images as similarly to a human observer as possible. Common examples include software for facial recognition or image classification (to identify a cat versus a dog, for example). When an artwork has been misattributed – or worse, created to deceive – the images and features are of course similar to that of an authentic painting. An AI designed merely to mimic human judgement and (mis)interpretation will fall prey to the same mistakes that a forger relies upon. The AI will replicate the viewpoint of the connoisseur, but may not improve upon it. But forgers have created paintings to deceive human eyes and human judgement when viewed in visible light. Under different illumination such as infrared or ultraviolet light, or by using pigment identification, the forgery may become readily apparent. So we must further develop AI methods that focus on more subtle aspects of the work – for example, by characterising individual brush strokes.
Other issues can arise when AI methods key in on irrelevant details that would be promptly disregarded by an art historian. Images provided by museums have been captured with various equipment cameras and scanners. AI can easily detect the irrelevant features introduced from the equipment, such as image compression or lens distortion,  and use them as ‘shortcuts’ instead of discriminating based upon the relevant features, which are more difficult to analyse, such as the brush strokes of the artist. An inappropriate AI method can reject the attribution of a work simply because its image was captured by a particular device or compressed using a particular technique. Two recent examples from the medical imaging field showed that deep learning models in pneumonia and Covid-19 could learn shortcuts based on spurious text on the hospital X-rays or other imaging artefacts instead of the medically relevant factors in the image. For these reasons, the AI must be trained on a set of images that have been collected in consistent and well-documented conditions.
By analysing a work stylistically, AI can complement traditional connoisseurship in an automated fashion and at scale. Nevertheless, machine learning methods should not supplant or hide the problems that bedevil connoisseurship behind an apparently uncontestable result from an AI. Recognising the current early development phase of AI, any conclusions must be drawn with an understanding of the limitations of the training set, and be contextualised and subjected to a ‘reality check’ by incorporating multiple approaches. Such a multi-pronged approach will add to the interpretative power of this tool and teach us more about the artists’ working methods and ultimately attribution. As Jennifer Mass, founder of Scientific Analysis of Fine Art (SAFA), notes, ‘the most robust attribution approach is always one in which a painting is examined with a range of methodologies using experts across multiple disciplines. The approach of a single person or analysis tool acting as a sole arbiter of attribution is outdated.’ We believe AI has great potential for questions of attribution, but only if it is done with sound methods. The AI method must be transparently validated and scientifically peer-reviewed so that collectors and researchers can understand both its capacity and limitations.
Ahmed Elgammal is director of the Art and AI Laboratory at Rutgers University, New Jersey. Adam Finnefrock is vice-president of Scientific Analysis of Fine Art, LLC. 





Unlimited access from just $16 every 3 months
Subscribe to get unlimited and exclusive access to the top art stories, interviews and exhibition reviews.





						SUBSCRIBE
							
								for unlimited access
							





						REGISTER
							
								for more articles
							












 




Share

Twitter
Facebook
LinkedIn
Email


Recommended for you




 

Trevor Paglen trains his sights on the rise of machine vision
What are the implications of using object recognition technology to classify human faces and emotions?






 

AI art is on the rise – but how do we measure its success?
Artworks produced using artificial intelligence have long confounded viewers






 

The late, great landscapes of Rubens, reunited at last
A pair of monumental landscapes painted in his later years offer an unusually personal glimpse of the artist himself





",https://schema.org,,,,,,,,"[{'@type': 'WebSite', '@id': '//www.apollo-magazine.com/#/schema/WebSite', 'url': '//www.apollo-magazine.com/', 'name': 'Apollo Magazine', 'description': 'The International Art Magazine', 'inLanguage': 'en-US', 'potentialAction': {'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': '//www.apollo-magazine.com/search/{search_term_string}/'}, 'query-input': 'required name=search_term_string'}, 'publisher': {'@type': 'Organization', '@id': '//www.apollo-magazine.com/#/schema/Organization', 'name': 'Apollo Magazine', 'url': '//www.apollo-magazine.com/'}}, {'@type': 'WebPage', '@id': '//www.apollo-magazine.com/artificial-intelligence-authentication-artworks/', 'url': '//www.apollo-magazine.com/artificial-intelligence-authentication-artworks/', 'name': 'AI and art history | Apollo Magazine', 'description': 'It’s still early days for the authentication of artworks by artificial intelligence – and experts will always be needed to interpret the findings', 'inLanguage': 'en-US', 'isPartOf': {'@id': '//www.apollo-magazine.com/#/schema/WebSite'}, 'breadcrumb': {'@type': 'BreadcrumbList', '@id': '//www.apollo-magazine.com/#/schema/BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': '//www.apollo-magazine.com/', 'name': 'Apollo Magazine'}, {'@type': 'ListItem', 'position': 2, 'item': '//www.apollo-magazine.com/category/comment/', 'name': 'Category: Comment'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI and art history'}]}, 'potentialAction': {'@type': 'ReadAction', 'target': '//www.apollo-magazine.com/artificial-intelligence-authentication-artworks/'}, 'datePublished': '2021-11-11T17:19:35+01:00', 'dateModified': '2021-11-12T14:21:08+01:00', 'author': {'@type': 'Person', '@id': '//www.apollo-magazine.com/#/schema/Person/92bc966a55b0379d6e2c909859ab3fef', 'name': 'Ahmed Elgammal and Adam Finnefrock'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vbWluZG1hdHRlcnMuYWkvMjAyMS8xMS9ib29rLXJldmlldy1naG9zdC13b3JrLWZsb3BzLWluLWVjb25vbWljLXVuZGVyc3RhbmRpbmcv0gEA?oc=5,Book Review: “Ghost Work” Flops in Economic Understanding - Walter Bradley Center for Natural and Artificial Intelligence,2021-11-15,Walter Bradley Center for Natural and Artificial Intelligence,https://mindmatters.ai,"Overall, the book helps people understand “ghost work,” but seems to have some fundamental misunderstandings about choices, tradeoffs, and economics",N/A,"Overall, the book helps people understand “ghost work,” but seems to have some fundamental misunderstandings about choices, tradeoffs, and economics","Overall, the book helps people understand “ghost work,” but seems to have some fundamental misunderstandings about choices, tradeoffs, and economics",N/A,N/A,"



Jonathan Bartlett

November 15, 2021
7
Artificial Intelligence, Economics


				Book Review: “Ghost Work” Flops in Economic Understanding			
""Ghost workers"" are those unseen workers behind artificial intelligence 

Jonathan Bartlett

November 15, 2021
7
Artificial Intelligence, Economics



Share



Facebook








Twitter





LinkedIn






 Flipboard







 Print









Email







Here at Mind Matters, we have often covered the way that humans are used to supplement Artificial Intelligence. Artificial intelligence has generally been misunderstood as replacing human effort in society, while, in reality, it is usually leveraging it, instead. Whether using humans to find good training data, mining content for intentionality, or even using humans directly within machine learning algorithms, today’s most prominent “AI” systems are actually strange hybrids of humans and computers. As a matter of fact, the market for human supplementation of AI is so large that Amazon has an entire service built around it.
While much of this work is done either for free (oftentimes through games on the Internet) or through traditional paid office work, a growing amount is being done through “microtasks,” through systems such as CloudFlower and Amazon’s Mechanical Turk. These services take tiny jobs that require a human touch (i.e., “what keywords best describe this image”) and pay people small amounts per job to perform the task. Because this is behind the scenes, and oftentimes people don’t even know there is a human there, it is often termed “ghost work.” But who are the workers behind this new class of vocation?
The book Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass attempts to provide a sociological profile for this new kind of work and worker. This book looks into the lives and work of the people on these platforms, what they do on a daily basis, why they do it, and the problems they face. On the whole, the book does a good job of helping people understand this new class of work and why and how it is done, but seems to have some fundamental misunderstandings about choices, tradeoffs, and economics, which make them often misunderstand their own subjects and present “solutions” that would probably be more problematic than the problems they look to solve.
On the good side, this book is the first real book to describe the role of humans in artificial intelligence. Most people assume that artificial intelligence means that humans are being replaced with computers, but this isn’t the case at all. In fact, the authors show that this is a long misunderstood part of technological development, which they call the “last mile paradox.” In nearly every automation from the industrial revolution to the present, there is always some amount of “finishing work” that needs to be done by hand. In the textile industry, this is known as “piece work,” where difficult-to-automate aspects of clothing continue to be done by hand even after the large-scale takeover of industrial machinery. It is called “piece work” because the people that this is outsourced to are paid by the “piece” instead of by the hour. 
In the modern day, computer automation requires what can be essentially described as “algorithmic piece work,” where things that are not adequately handled by algorithms can be doled out to people who work by the job instead of by the hour. Most technology users are wholly ignorant that this works even goes on, and assumes that there is automation, not humans, behind all of the tasks that get performed on computers. How do computers tell if an image is pornographic? How can they tell if a “trending hashtag” is a legitimate phenomenon or some kind of scam or hack? How can you tell if someone who cut their hair differently still matches their photo on file? These are all things that computers do not have the context or programming to handle, but still need to be done on algorithmic platforms. These often get farmed out to systems such as Mechanical Turk for a human to process. The book does a great job describing this process and the people behind it.
The book, however, also aims to correct what the authors perceive as injustices towards the workers. However, most of the time the injustices that the authors perceive are either (a) contradicted by the authors’ own reporting, (b) misunderstanding the choices that lay behind the perceived injustice, or (c) something that has nothing to do with the subject (i.e., “ghost work”), but is simply endemic to being underprivileged.
As an example, the authors seem to think that ghost workers should be given the protections of full-time employees, and indicate that it is problematic that they don’t have the same protections. However, why are there different protections for full-time workers than contractors? The authors note that because these workers are not in offices and can work their own hours they therefore aren’t qualified to consider themselves full-time workers. However, the entire reason for considering protections for employees is that, when you work on-site, your employer is responsible for the conditions of your workspace. That is, whatever safety measures are or aren’t there is entirely in the hands of the employer. Additionally, to the extent that an employer asserts their own authority over your life (requiring specific hours, requiring overtime, etc.) also makes them responsible for how they do so. In the case of ghost work, the employee is working from their own home and they can work at any time, day or night. Thus, the employer exhibits no influence whatsoever on the working conditions of the worker and asserts no authority over the worker’s life. Therefore, there is no moral reason why they should treat the worker as someone over which they have a large amount of responsibility.
Additionally, the authors complained about the tough competition for jobs while simultaneously complaining about how difficult it is to join the workforce, specifying the many hurdles people in underdeveloped countries face. However, making it easier to join actually exacerbates the problem of competition. The authors seem fully ignorant of this basic aspect of markets. 
The authors also seem to be unaware of the conditions required for the very existence of this type of employment. They spend a good amount of time critiquing the anti-fraud measures of the system, while completely ignoring the fact that the Internet is rampant with fraudsters trying to play such systems. If the systems can’t eliminate fraud, and don’t have the flexibility to do so economically, then this entire area of the economy disappears. Like most people today, the authors seem fully unaware that there are preconditions for the existence of certain types of work.
There is one criticism, however, that I found helpful: Companies need to have a better way to appeal automated decisions. This is true everywhere. Companies are looking to automate, which is great. But having a fallback, a way to address grievances (or even communication) by a human in the company that has authority to resolve or escalate issues, is extremely important. I think that whether technology becomes a tool of freedom or oppression may largely hinge on this one question, not just for ghost work, but across all aspects of the economy.
In all, Ghost Work does a good job of helping people understand how the underbelly of our technological systems work as well as the people making it happen. However, its prescriptions for modifying these work arrangements are incoherent and problematic for the very people they want to benefit.



Jonathan BartlettSenior Fellow, Walter Bradley Center for Natural & Artificial IntelligenceJonathan Bartlett is a senior software engineer at McElroy Manufacturing.  Jonathan is part of McElroy's Digital Products group, where he writes software for their next generation of tablet-controlled machines as well as develops mobile applications for customers to better manage their equipment and jobs. He also offers his time as the Director of The Blyth Institute, focusing on the interplay between mathematics, philosophy, engineering, and science. Jonathan is the author of several textbooks and edited volumes which have been used by universities as diverse as Princeton and DeVry.

",https://schema.org,,,,,,,,"[{'@type': 'WebSite', '@id': 'https://mindmatters.ai/#/schema/WebSite', 'url': 'https://mindmatters.ai/', 'name': 'Mind Matters', 'description': 'Natural and Artificial Intelligence News and Analysis', 'inLanguage': 'en-US', 'potentialAction': {'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://mindmatters.ai/search/{search_term_string}/'}, 'query-input': 'required name=search_term_string'}, 'publisher': {'@type': 'Organization', '@id': 'https://mindmatters.ai/#/schema/Organization', 'name': 'Mind Matters', 'url': 'https://mindmatters.ai/', 'logo': {'@type': 'ImageObject', 'url': 'https://mindmatters.ai/wp-content/uploads/sites/2/2018/07/cropped-mm.png', 'contentUrl': 'https://mindmatters.ai/wp-content/uploads/sites/2/2018/07/cropped-mm.png', 'width': 512, 'height': 512}}}, {'@type': 'WebPage', '@id': 'https://mindmatters.ai/2021/11/book-review-ghost-work-flops-in-economic-understanding/', 'url': 'https://mindmatters.ai/2021/11/book-review-ghost-work-flops-in-economic-understanding/', 'name': 'Book Review: &#8220;Ghost Work&#8221; Flops in Economic Understanding', 'description': 'Overall, the book helps people understand &#8220;ghost work,&#8221; but seems to have some fundamental misunderstandings about choices, tradeoffs, and economics', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://mindmatters.ai/#/schema/WebSite'}, 'breadcrumb': {'@type': 'BreadcrumbList', '@id': 'https://mindmatters.ai/#/schema/BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': 'https://mindmatters.ai/', 'name': 'Mind Matters'}, {'@type': 'ListItem', 'position': 2, 'item': 'https://mindmatters.ai/c/economics/', 'name': 'Category: Economics'}, {'@type': 'ListItem', 'position': 3, 'name': 'Book Review: &#8220;Ghost Work&#8221; Flops in Economic Understanding'}]}, 'potentialAction': {'@type': 'ReadAction', 'target': 'https://mindmatters.ai/2021/11/book-review-ghost-work-flops-in-economic-understanding/'}, 'datePublished': '2021-11-15T15:23:49+00:00', 'dateModified': '2023-05-18T21:54:07+00:00', 'author': {'@type': 'Person', '@id': 'https://mindmatters.ai/#/schema/Person/ff0fad7199e63df8a20868f81259a3fc', 'name': 'Jonathan Bartlett'}}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vbmV3cy5zdGFuZm9yZC5lZHUvc3Rvcmllcy8yMDIxLzExL3VzaW5nLWFpLWNyZWF0ZS1iZXR0ZXItdmlydHVhbC1yZWFsaXR5LWV4cGVyaWVuY2Vz0gEA?oc=5,Using AI to create better virtual reality experiences - Stanford University News,2021-11-12,Stanford University News,https://news.stanford.edu,N/A,N/A,"Working at the intersection of hardware and software engineering, researchers are developing new techniques for improving 3D displays for virtual and augmented reality technologies.",N/A,N/A,N/A,"



Virtual and augmented reality headsets are designed to place wearers directly into other environments, worlds and experiences. While the technology is already popular among consumers for its immersive quality, there could be a future where the holographic displays look even more like real life. In their own pursuit of these better displays, the Stanford Computational Imaging Lab has combined their expertise in optics and artificial intelligence. Their most recent advances in this area are detailed in a paper published Nov. 12 in Science Advances and work that will be presented at SIGGRAPH ASIA 2021 in December.
Photograph of a holographic display prototype. (Image credit: Stanford Computational Imaging Lab)
At its core, this research confronts the fact that current augmented and virtual reality displays only show 2D images to each of the viewer’s eyes, instead of 3D – or holographic – images like we see in the real world.“They are not perceptually realistic,” explained Gordon Wetzstein, associate professor of electrical engineering and leader of the Stanford Computational Imaging Lab. Wetzstein and his colleagues are working to come up with solutions to bridge this gap between simulation and reality while creating displays that are more visually appealing and easier on the eyes.The research published in Science Advances details a technique for reducing a speckling distortion often seen in regular laser-based holographic displays, while the SIGGRAPH Asia paper proposes a technique to more realistically represent the physics that would apply to the 3D scene if it existed in the real world.Bridging simulation and realityIn the past decades, image quality for existing holographic displays has been limited. As Wetzstein explains it, researchers have been faced with the challenge of getting a holographic display to look as good as an LCD display.One problem is that it is difficult to control the shape of light waves at the resolution of a hologram. The other major challenge hindering the creation of high-quality holographic displays is overcoming the gap between what is going on in the simulation versus what the same scene would look like in a real environment.Previously, scientists have attempted to create algorithms to address both of these problems. Wetzstein and his colleagues also developed algorithms but did so using neural networks, a form of artificial intelligence that attempts to mimic the way the human brain learns information. They call this “neural holography.”









Watch Video








Video showing how the researchers’ neural holography model compares to current state-of-the-art algorithms when applied to 3D scenes. (Stanford Computational Imaging Lab)






“Artificial intelligence has revolutionized pretty much all aspects of engineering and beyond,” said Wetzstein. “But in this specific area of holographic displays or computer-generated holography, people have only just started to explore AI techniques.”
Yifan Peng, a postdoctoral research fellow in the Stanford Computational Imaging Lab, is using his interdisciplinary background in both optics and computer science to help design the optical engine to go into the holographic displays.
“Only recently, with the emerging machine intelligence innovations, have we had access to the powerful tools and capabilities to make use of the advances in computer technology,” said Peng, who is co-lead author of the Science Advances paper and a co-author of the SIGGRAPH paper.
The neural holographic display that these researchers have created involved training a neural network to mimic the real-world physics of what was happening in the display and achieved real-time images. They then paired this with a “camera-in-the-loop” calibration strategy that provides near-instantaneous feedback to inform adjustments and improvements. By creating an algorithm and calibration technique, which run in real time with the image seen, the researchers were able to create more realistic-looking visuals with better color, contrast and clarity.
The new SIGGRAPH Asia paper highlights the lab’s first application of their neural holography system to 3D scenes. This system produces high-quality, realistic representation of scenes that contain visual depth, even when parts of the scenes are intentionally depicted as far away or out-of-focus.
The Science Advances work uses the same camera-in-the-loop optimization strategy, paired with an artificial intelligence-inspired algorithm, to provide an improved system for holographic displays that use partially coherent light sources – LEDs and SLEDs. These light sources are attractive for their cost, size and energy requirements and they also have the potential to avoid the speckled appearance of images produced by systems that rely on coherent light sources, like lasers. But the same characteristics that help partially coherent source systems avoid speckling tend to result in blurred images with a lack of contrast. By building an algorithm specific to the physics of partially coherent light sources, the researchers have produced the first high-quality and speckle-free holographic 2D and 3D images using LEDs and SLEDs.
Transformative potential
Wetzstein and Peng believe this coupling of emerging artificial intelligence techniques along with virtual and augmented reality will become increasingly ubiquitous in a number of industries in the coming years.
“I’m a big believer in the future of wearable computing systems and AR and VR in general, I think they’re going to have a transformative impact on people’s lives,” said Wetzstein. It might not be for the next few years, he said, but Wetzstein believes that augmented reality is the “big future.”
Though augmented virtual reality is primarily associated with gaming right now, it and augmented reality have potential use in a variety of fields, including medicine. Medical students can use augmented reality for training as well as for overlaying medical data from CT scans and MRIs directly onto the patients.
“These types of technologies are already in use for thousands of surgeries, per year,” said Wetzstein. “We envision that head-worn displays that are smaller, lighter weight and just more visually comfortable are a big part of the future of surgery planning.”
“It is very exciting to see how the computation can improve the display quality with the same hardware setup,” said Jonghyun Kim, a visiting scholar from Nvidia and co-author of both papers. “Better computation can make a better display, which can be a game changer for the display industry.”

Stanford graduate student is co-lead author of both papers Suyeon Choi and Stanford graduate student Manu Gopakumar is co-lead author of the SIGGRAPH paper. This work was funded by Ford, Sony, Intel, the National Science Foundation, the Army Research Office, a Kwanjeong Scholarship, a Korea Government Scholarship and a Stanford Graduate Fellowship.
To read all stories about Stanford science, subscribe to the biweekly Stanford Science Digest.

 
 



Media Contacts Taylor Kubota, Stanford News Service: (650) 724-7707; tkubota@stanford.edu



AuthorAllison GaspariniRelated topicsScience & EngineeringArtificial IntelligenceShare this storyCopy link



Subscribe to Stanford ReportNews, insights and events delivered to your inbox each weekday morning.Sign upStories for youReversing chemotherapy resistance in pancreatic cancerA new AI approach optimizes development of antibody drugsChip-scale titanium-sapphire laser puts powerful technology in reachPopular storiesMichele Rasmussen appointed vice provost for student affairsHow technology is reinventing K-12 educationWhat to know about Gen ZHow the apparel industry could refashion itselfReversing chemotherapy resistance in pancreatic cancer



Read nextView all Read nextScience & EngineeringNew center harnesses AI to advance autonomous exploration of outer spaceNewsScience & EngineeringHigh Impact Technology Fund clears the path to commercializationResearchScience & EngineeringA ‘liquid battery’ advanceResearchScience & EngineeringReversing chemotherapy resistance in pancreatic cancerResearchScience & EngineeringA new AI approach optimizes development of antibody drugsNewsScience & EngineeringChip-scale titanium-sapphire laser puts powerful technology in reachResearchScience & EngineeringNew center harnesses AI to advance autonomous exploration of outer spaceNewsScience & EngineeringHigh Impact Technology Fund clears the path to commercializationResearchScience & EngineeringA ‘liquid battery’ advanceResearchScience & EngineeringReversing chemotherapy resistance in pancreatic cancerResearchScience & EngineeringA new AI approach optimizes development of antibody drugsNewsScience & EngineeringChip-scale titanium-sapphire laser puts powerful technology in reachResearchSlide 1Slide 2Slide 3Slide 4Slide 5Slide 6PreviousNext


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS90ZWNobm9sb2d5LzIwMjEvMTEvMTEvbGF3eWVyLWZhY2lhbC1yZWNvZ25pdGlvbi1tb25pdG9yaW5nL9IBAA?oc=5,Contract lawyers face a growing invasion of surveillance programs that monitor their work - The Washington Post,2021-11-11,The Washington Post,https://www.washingtonpost.com,"Attorneys say the constant workday face scans, mandated by their bosses, are fueling fears of over-surveillance: “I will not subject myself to this indignity and the invasion of my privacy in my own home.""",N/A,"Attorneys say the constant workday face scans, mandated by their bosses, are fueling fears of over-surveillance: “I will not subject myself to this indignity and the invasion of my privacy in my own home.""","Attorneys say the constant workday face scans, mandated by their bosses, are fueling fears of over-surveillance: “I will not subject myself to this indignity and the invasion of my privacy in my own home.""",Technology,N/A,"(Sébastien Thibault for The Washington Post) By  Drew HarwellNovember 11, 2021 at 8:00 a.m. ESTCamille Anidi, an attorney on Long Island, quickly understood the flaws of the facial recognition software her employers demanded she use when working from home. The system often failed to recognize her face or mistook the Bantu knots in her hair as unauthorized recording devices, forcing her to log back in sometimes more than 25 times a day.Share414 CommentsMore top storiesHAND CURATEDNearly 50,000 Facebook users may have been targets of private surveillance, company saysDecember 16, 2021Nearly 50,000 Facebook users may have been targets of private surveillance, company saysDecember 16, 2021A QAnon con: How the viral Wayfair sex trafficking lie hurt real kidsDecember 16, 2021A QAnon con: How the viral Wayfair sex trafficking lie hurt real kidsDecember 16, 2021Trailblazing Black feminist and social critic bell hooks dies at 69December 15, 2021Trailblazing Black feminist and social critic bell hooks dies at 69December 15, 2021View 3 more storiesNewsletterAs news breaksTech News AlertsBreaking news email alerts on technology and the tech industry.Sign up



PAID PROMOTED STORIES
 







Subscribe to comment and get the full experience. Choose your plan →",https://schema.org,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}]",BreadcrumbList,"{'@type': 'Person', 'name': 'Drew Harwell', 'url': 'https://www.washingtonpost.com/people/drew-harwell/'}",2021-11-11T13:00:11.049Z,Contract lawyers face a growing invasion of surveillance programs that monitor their work,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/S2FWQPKD5JG2FNPTG7VW3YY3VQ.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/S2FWQPKD5JG2FNPTG7VW3YY3VQ.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/S2FWQPKD5JG2FNPTG7VW3YY3VQ.jpg&w=800&h=600', 'height': 800, 'width': 600}]",,https://www.washingtonpost.com/technology/2021/11/11/lawyer-facial-recognition-monitoring/,2021-11-12T23:50:55.128Z,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",False,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjEvMTEvMTUvdGVjaG5vbG9neS9nb29nbGUtYWktcGVudGFnb24uaHRtbNIBAA?oc=5,Google Says It Can Compete for Pentagon Contracts Without Violating Principles - The New York Times,2021-11-15,The New York Times,https://www.nytimes.com,The company abandoned work on an earlier military program after employees revolted.,N/A,The company abandoned work on an earlier military program after employees revolted.,The company abandoned work on an earlier military program after employees revolted.,Technology,N/A,"See more headlines from our Daily Business BriefingAdvertisementSKIP ADVERTISEMENTGoogle executives tell employees it can compete for Pentagon contracts without violating its principles.The company abandoned work on an earlier military program after employees revolted.Share full articleRead in appSundar Pichai, the chief executive of Google. “I think we are strongly committed to working with the government in a way that’s consistent with our A.I. principles,” he said. Credit...Jim Wilson/The New York TimesBy Kate Conger and Daisuke WakabayashiNov. 15, 2021Google executives told employees last week in a companywide meeting that it is interested in a Pentagon contract for cloud computing and that working for the military would not necessarily conflict with principles created by the company for how its artificial intelligence technology would be used.Google is pursuing the contract three years after an employee revolt forced the company to abandon work on a Pentagon program that used artificial intelligence and to establish new guidelines against using A.I. for weapons or surveillance.The pursuit potentially sets up another clash between company leaders and employees. Google’s cloud unit prioritized preparation for a bid on a Pentagon contract, The New York Times revealed this month, pulling engineers off other projects to focus on creating a winning proposal.The rush to pursue the contract is a dramatic shift for Google, which said in 2018 that it would not bid on a major cloud computing contract with the Defense Department, known as the Joint Enterprise Defense Infrastructure, or JEDI, because the work would conflict with its A.I. principles.AdvertisementSKIP ADVERTISEMENTThe JEDI cloud computing contract was estimated to be worth $10 billion over 10 years, and was awarded to Microsoft in 2019. But facing legal challenges from Amazon, the Pentagon scrapped the contract in July and announced a new plan to purchase cloud computing technology. The new version of the contract, known as the Joint Warfighting Cloud Capability, will split the work between multiple companies.The segmented nature of the contract allows Google to work on parts of the Pentagon cloud without violating its ban on weapons, Google executives told employees in the videoconference meeting on Thursday, a recording of which was obtained by The Times.The exact scope of the work is still unclear because the government has not submitted a formal request for proposal. While it has not been invited to bid, Google has said it is interested.In a blog post published the same day as the meeting, Thomas Kurian, who oversees the company’s cloud unit, wrote: “If we are invited to be part of the J.W.C.C. contract, we will absolutely bid.”At the meeting, Mr. Kurian said there are many areas where Google’s capabilities and expertise can be applied “with no conflict to Google’s A.I. principles.”AdvertisementSKIP ADVERTISEMENT“We have governance processes that provide guidance and oversight into what A.I. products we will offer and what custom A.I. projects we will and we will not pursue, and we will follow those governance processes,” he said.Mr. Kurian’s remarks, which were reported earlier by CNBC, were made in response to a question from an employee about Google’s interest in the Pentagon contract and The Times’s reporting on it.“We understand that not every Googler will agree with this decision, but we believe Google Cloud should seek to serve the government where it is capable of doing so and where the work meets Google’s A.I. principles and our company’s values,” Mr. Kurian said.Google’s chief executive, Sundar Pichai, echoed his remarks. “I think we are strongly committed to working with the government in a way that’s consistent with our A.I. principles,” Mr. Pichai said.A spokesman for Google declined to comment.Kate Conger is a technology reporter in the San Francisco bureau, where she covers the gig economy and social media. More about Kate CongerDaisuke Wakabayashi covers technology from San Francisco, including Google and other companies. Previously, he spent eight years at The Wall Street Journal, first as a foreign correspondent in Japan and then covering technology in San Francisco. More about Daisuke WakabayashiA version of this article appears in print on Nov. 17, 2021, Section B, Page 3 of the New York edition with the headline: Google Pursues Pentagon Contract Despite Revolt. Order Reprints | Today’s Paper | SubscribeSee more on: Defense Budget, Alphabet Inc.Share full articleRead in appAdvertisementSKIP ADVERTISEMENTTell us about yourself. Take the survey.",https://schema.org,,NewsMediaOrganization,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/kate-conger', 'name': 'Kate Conger'}, {'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/daisuke-wakabayashi', 'name': 'Daisuke Wakabayashi'}]",2021-11-15T23:39:50.000Z,Google Says It Can Compete for Pentagon Contracts Without Violating Principles,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/11/15/multimedia/15google/15google-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2021/11/15/multimedia/15google/15google-videoSixteenByNineJumbo1600.jpg', 'caption': 'Sundar Pichai, the chief executive of Google.\xa0“I think we are strongly committed to working with the government in a way that’s consistent with our A.I. principles,” he said. ', 'creditText': 'Jim Wilson/The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/11/15/multimedia/15google/15google-superJumbo.jpg', 'height': 1365, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2021/11/15/multimedia/15google/15google-superJumbo.jpg', 'caption': 'Sundar Pichai, the chief executive of Google.\xa0“I think we are strongly committed to working with the government in a way that’s consistent with our A.I. principles,” he said. ', 'creditText': 'Jim Wilson/The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/11/15/multimedia/15google/15google-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2021/11/15/multimedia/15google/15google-mediumSquareAt3X.jpg', 'caption': 'Sundar Pichai, the chief executive of Google.\xa0“I think we are strongly committed to working with the government in a way that’s consistent with our A.I. principles,” he said. ', 'creditText': 'Jim Wilson/The New York Times'}]",,https://www.nytimes.com/2021/11/15/technology/google-ai-pentagon.html,2021-11-15T23:49:14.000Z,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",False,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",https://www.nytimes.com/,en,Google executives tell employees it can compete for Pentagon contracts without violating its principles.,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,The New York Times,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LnNpbXBsaWxlYXJuLmNvbS9ob3ctYWktaGFzLWV2b2x2ZWQtYXMtdGhlLW1vc3QtaW1wb3J0YW50LXRvb2wtaW4tYnVzaW5lc3MtYXJ0aWNsZdIBAA?oc=5,How AI has Evolved as the Most Important Tool in Business - Simplilearn,2021-11-11,Simplilearn,https://www.simplilearn.com,"Today, the application of artificial intelligence in business is more than just outperforming humans. Google’s search engine and Amazon are the best examples of AI development. Click here to learn the evolvement of AI in business as an important tool!","application of artificial intelligence in business, benefits of artificial intelligence in business, why is artificial intelligence important to business, examples of artificial intelligence in business, ai in business, artificial intelligence in business, simplilearn, article","Today, the application of artificial intelligence in business is more than just outperforming humans. Google’s search engine and Amazon are the best examples of AI development. Click here to learn the evolvement of AI in business as an important tool!","Today, the application of artificial intelligence in business is more than just outperforming humans. Google’s search engine and Amazon are the best examples of AI development. Click here to learn the evolvement of AI in business as an important tool!",N/A,N/A,"
Just a few years ago nobody would have thought that AI would be a vital part of business today, but businesses around the world are continuing to find new reasons to use it to eliminate day-to-day inefficiencies. This is eliminating any sense of a  level playing field for businesses that aren’t utilizing this technology yet, and creating a growing concern about the overall power AI will have over the future workforce. 
Despite its potential, AI also brings up concerns about job displacement, economic instability, and skills shortages. Despite these concerns over the potential implications of AI, the technology still holds great potential for human empowerment. It also gives us the tools we need to automate redundant tasks, spot patterns in the data we collect and uncover important insights that could improve our lives for the better.
Integrating AI into the Workforce
Voice AI communication isn’t only outperforming humans, but it’s also helping streamline the process so we can get things done before they’re due. These are just a few of the ways AI is being used today. About half of America’s workforce feels their company’s AI deployment is greatly outpacing the accuracy and productivity of comparable human activity. This is something that business leaders are already quite aware of. They also realize AI’s potential ethical and human dilemmas. In fact, 69 percent of C-level executives say their employees are concerned that AI technologies will replace them. To help employees feel more comfortable with using AI, companies need to focus on training employee to develop these skills.
How AI is Transforming Business as We Know It
Live Mint says AI helps with human decision-making. This is because algorithms are growing smarter and computing power is growing. While AI still can’t complete common-sense tasks today, it can process and analyze data faster than the human brain can. It will then provide you with many synthesized courses of action so you can figure out the possible consequences of each action and streamline your decision-making process. When this is merged with human interactions, it’ll help you meet your customers’ needs. 
One of the best examples of this is Google’s search engine. It uses thousands of human ‘raters’ to assess the quality of its AI-driven search results. In this way, you can see how AI leverages self-learning systems (e.g. data mining, pattern recognition, natural language processing) as a key advantage over human intelligence. This is something that you can scale in such a way that your bottom line is drastically improved while errors are greatly decreased. Its longevity, coupled with continuous improvements and its ability to document processes is quite rewarding for all types of businesses today—including healthcare, education, auto, banking, and retail. A great example of this is Amazon. According to Live Mint today, they’re using AI to cut costs and improve their platform—making it superior, intuitive, and smart. All of this happens because AI can analyze customers’ social media feeds so they can improve search results and recommendations.
This is just one example of how AI has effectively helped businesses decode patterns in their customers’ online behavior—to the point that they can now predict the probability of a customer returning a product. This also helps businesses segment customers, based on their data, into groups who share the same attributes. By doing this they can improve customer loyalty since they’re able to offer more personalized, relevant marketing messages. 
Customers are growing reliant on AI when they need to find new businesses to engage with. These businesses then rely on AI to help them offer their customers the services or products and support they need. Employees have also grown more dependent on this technology to get their work done each day. All of this is slowly taking a more central role in today’s business world, so businesses can’t afford to have an AI strategy in place today. When this is designed with the customer in mind, AI solutions can drive customer loyalty, engagement, consumption and satisfaction. It won’t take long before companies start seeing AI’s real potential.
Leaders are also embracing the greater presence of AI. Once it becomes more integrated into their operations, leadership will need to be refined. This includes revising their overall strategy, customer experience, technology, and human capital. Most C-level executives recognize this shift in leadership and are working to build their future business strategy around the opportunities AI technology has made available to them. 
Techemergence claims that about 80 percent of C-level executives are confident that their executive team can adapt their leadership skills as they adopt new AI technologies. Another 70 percent of them strongly agree that AI will benefit employees at all levels throughout their organization. This demonstrates the positive view they’re taking toward AI and the transparency it brings in regards to running an autonomous business. Techemergence claims that 52 percent of CEOs today are afraid that leadership will become less transparent with help from AI and automation.
What All This Means to You
There are some companies that are already experiencing AI’s benefits as it grows more mainstream in today’s business world. Those who aren’t already experimenting with AI are at risk of being left behind. To remain competitive, any business who invests in AI should also invest in their employees. As AI continues to change the business world as we know it, those who embrace training and re-skilling their current employees stand to gain tangible benefits.
Clearly, it’s important for your business to be transparent about AI initiatives and how they’ll both benefit and improve your company. This won’t only help you find new opportunities for your business, but it’ll also head off any potential risks before they turn into major problems or hurt your customers, employees or reputation. You can’t simply train your employees then forget about it though. To be truly successful you must adopt a culture of lifelong learning and encourage your staff to continuously develop new skills. 

",https://schema.org,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.simplilearn.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.simplilearn.com/resources', 'name': 'Resources'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.simplilearn.com/resources/artificial-intelligence-machine-learning', 'name': 'AI & Machine Learning'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://www.simplilearn.com/how-ai-has-evolved-as-the-most-important-tool-in-business-article', 'name': 'How AI has Evolved as the Most Important Tool in Business'}}]",BreadcrumbList,"{'@type': 'Person', 'name': 'Peter Davidson', 'url': 'https://www.simplilearn.com/authors/'}",2018-11-13T12:10:50+05:30,How AI has Evolved as the Most Important Tool in Business,"{'@type': 'Organization', 'name': 'Simplilearn', 'logo': {'@type': 'ImageObject', 'url': 'https://www.simplilearn.com/logo.png', 'width': '200', 'height': '200'}}","{'@type': 'ImageObject', 'url': 'https://www.simplilearn.com/ice9/free_resources_article_thumb/How-AI-has-Evolved-as-the-Most-Important-Tool-in-Business.jpg', 'height': '506', 'width': '900'}",,"{'@type': 'WebPage', '@id': 'https://www.simplilearn.com/how-ai-has-evolved-as-the-most-important-tool-in-business-article'}",2021-11-11T12:15:07+05:30,,,,https://www.simplilearn.com/how-ai-has-evolved-as-the-most-important-tool-in-business-article,,,,,,How AI has Evolved as the Most Important Tool in Business,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}",,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vZmluYW5jZS55YWhvby5jb20vbmV3cy9udmlkaWEtY2VvLWFpLWlzLW1vc3QtcG93ZXJmdWwtdGVjaG5vbG9neS1mb3JjZS10aGUtd29ybGQtaGFzLWtub3duLTE2MTA0ODEyNy5odG1s0gEA?oc=5,Nvidia CEO Huang: AI is 'the most powerful technology force the world has known' - Yahoo Finance,2021-11-12,Yahoo Finance,https://finance.yahoo.com,"Nvidia CEO Jensen Huang says AI is the most powerful technology in the world, and the company is using it to create some impressive new products.","['Nvidia', 'Jensen Huang', 'artificial intelligence']","Nvidia CEO Jensen Huang says AI is the most powerful technology in the world, and the company is using it to create some impressive new products.","Nvidia CEO Jensen Huang says AI is the most powerful technology in the world, and the company is using it to create some impressive new products.",N/A,N/A,"Read full articleYahoo FinanceNvidia CEO Huang: AI is ‘the most powerful technology force the world has known’Daniel Howley·Technology EditorFri, Nov 12, 20213 min readLink Copied26In this article: NVDA
            -6.62% INTC
            +0.35% AMD
            -10.21% Nvidia’s (NVDA) stock price has skyrocketed over the year-to-date, jumping 132% as of Thursday. But CEO Jensen Huang isn’t concerned about share prices overheating. Rather, he sees it as a response to people being excited about the work the chip giant is doing in artificial intelligence.“Artificial intelligence is unquestionably the most powerful technology force the world has ever known,” Huang told Yahoo Finance Live. “We’re always seeking to improve our performance, improve our efficiency, and improve our growth opportunities. And artificial intelligence is understandably the best way for that going forward. And I think people are excited about that.”Earlier in the week, Huang kicked off Nvidia’s GTC 2021 conference with a virtual keynote that featured discussions about the company’s efforts in AI, the metaverse, robotics, and self-driving cars.The most valuable chipmaker in the world with a market cap of $749 billion, Nvidia has gone from functioning solely as a maker of graphics cards for gamers to an AI powerhouse thanks to the processing power of its chips.Its gaming arm still brings in the majority of its revenue, about 47% to its data center business’s 36%, but that gap is shrinking more and more each quarter. And while the company is dead set on continuing to be the top card maker in the world, investors recognize Nvidia’s AI and data center businesses as an important and growing piece of the company’s overall strategy.Part of Nvidia’s secret sauce is the fact that while it builds everything from chips to supercomputers, it also produces the software that its customers use to develop their own artificial intelligence capabilities. In other words, the company is a one-stop shop for its clients’ AI needs.Nvidia showed off an AI-powered toy version of CEO Jensen Huang during its GTC 2021 conference. (Image: Nvidia) (Nvidia)“People are excited about the fact that Nvidia is not a traditional semiconductor company,” Huang said. “We’re rich with software, and we are rich with the ability to open to new markets.”According to the CEO, the software that Nvidia makes is essential for accelerated computing, and without it, the computing model the company pioneered doesn’t work.Nvidia’s AI efforts touch everything from its work on self-driving cars, to training robots, to language models, and its own Omniverse. The company’s metaverse platform, Omniverse is the plumbing Nvidia customers can use to build out their own virtual worlds.Customers can use Omniverse to create so-called “digital twins” that they can work with inside of a virtual environment rather than the real world. An automaker might, for instance, use a digital twin to reconfigure one of its manufacturing plants using Omniverse. That could help it spot potential bottlenecks that it might not have noticed until it already spent millions building out the site in the real world.Story continuesNvidia is currently using its Omniverse software to build out its self-driving car efforts by running virtual cars through digital twins of the real world. That allows the vehicles’ to collect the data the company needs to program cars in the real world, without ever having them touch pavement.“I think people are excited about the technology that we’ve created,” Huang said. “I’m delighted that people see the potential in our company, and I’m looking forward to the future we’ve discussed.”Sign up for Yahoo Finance Tech newsletterMore from DanNvidia CEO: ‘We don’t have any magic bullets’ to deal with chip shortageNvidia is on top of the world, but its rivals are gaining steamNvidia announces deeper push into healthcare industry at GTC 2021Follow Yahoo Finance on Twitter, Facebook, Instagram, Flipboard, LinkedIn, YouTube, and redditGot a tip? Email Daniel Howley at dhowley@yahoofinance.com over via encrypted mail at danielphowley@protonmail.com, and follow him on Twitter at @DanielHowley.View comments (26)",http://schema.org,,NewsArticle,"{'@type': 'Person', 'name': 'Daniel Howley', 'url': 'https://www.yahoo.com/author/daniel-howley/', 'jobTitle': 'Technology Editor'}",2021-11-12T16:10:48.000Z,Nvidia CEO Huang: AI is ‘the most powerful technology force the world has known’,"{'@type': 'Organization', 'name': 'Yahoo Finance', 'logo': {'@type': 'ImageObject', 'url': 'https://s.yimg.com/rz/p/yahoo_finance_en-US_h_p_finance_2.png', 'width': 354, 'height': 50}, 'url': 'https://finance.yahoo.com/'}","{'@type': 'ImageObject', 'url': 'https://s.yimg.com/ny/api/res/1.2/ZdH7G6thPkPra4gIMlVXLQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2021-11/0d0e7580-43d1-11ec-b5f5-0da28ebeced8', 'width': 1200, 'height': 675}",,https://finance.yahoo.com/news/nvidia-ceo-ai-is-most-powerful-technology-force-the-world-has-known-161048127.html,2021-11-12T16:10:48.000Z,,,,,,,,,,,,,,,,,,,"{'@type': 'Person', 'name': 'Daniel Howley', 'url': 'https://www.yahoo.com/author/daniel-howley/', 'jobTitle': 'Technology Editor'}","{'@type': 'Organization', 'name': 'Yahoo Finance', 'url': 'http://finance.yahoo.com/', 'logo': {'@type': 'ImageObject', 'width': 484, 'height': 100, 'url': 'https://s.yimg.com/os/creatr-uploaded-images/2020-12/02246f50-3412-11eb-bfdd-de89f8b3b8b8'}}",https://s.yimg.com/ny/api/res/1.2/ZdH7G6thPkPra4gIMlVXLQ--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2021-11/0d0e7580-43d1-11ec-b5f5-0da28ebeced8,"{'@context': 'https://schema.org', '@type': 'VideoObject', 'name': ""Nvidia CEO: The 'omniverse is closer than people think'"", 'description': ""Nvidia Founder and CEO Jensen Huang joins Yahoo Finance’s Julie Hyman and Tech Editor Dan Howley to discuss the chip shortage, the future of AI, and the omniverse — Nvidia's metaverse."", 'thumbnailUrl': 'https://s.yimg.com/uu/api/res/1.2/GTveKZ84W75uVIZJICyU2A--~B/aD0xMzg7dz0yNDc7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/hd/cp-video-transcode/prod/2021-11/10/618c1b4ccf09e42b015d7214/618c1b4ccf09e42b015d7215_o_U_v2.jpg', 'duration': 'PT20M59S', 'contentUrl': 'https://video.media.yql.yahoo.com/v1/video/sapi/hlsstreams/cec63825-3f8c-3f62-85ad-191f5bb9f9aa.m3u8?site=finance&region=US&lang=en-US&devtype=desktop&src=sapi', 'embedUrl': 'https://finance.yahoo.com/video/nvidia-ceo-omniverse-closer-people-191940210.html?format=embed', 'identifier': 'cec63825-3f8c-3f62-85ad-191f5bb9f9aa'}",,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vd3d3LnpkbmV0LmNvbS9hcnRpY2xlL3RoZS1pdC1za2lsbHMtZ2FwLWlzLWdldHRpbmctd29yc2UtaGVyZS1hcmUtMTAtd2F5cy15b3UtY2FuLWF2b2lkLWEtY3Jpc2lzL9IBAA?oc=5,The IT skills gap is getting worse. Here are 10 ways you can avoid a crisis - ZDNet,2021-11-11,ZDNet,https://www.zdnet.com,"Analytics, automation, AI, digital transformation and other tech trends are changing business needs rapidly, leaving companies and workers grappling with a growing skills gap. In this special feature, ZDNet examines technology's role in helping business leaders build tomorrow's workforce, and employees keep their skills up to date and grow their careers.",N/A,More than two-thirds of digital leaders can't keep pace with change because of a lack of technology talent.,More than two-thirds of digital leaders can't keep pace with change because of a lack of technology talent.,N/A,N/A,N/A,https://schema.org,,VideoObject,,,,,,,,,,,,,,,,,,"Building the digital workforce: Tech skills, trends and strategies for success",,,,,,,,,,,https://www.zdnet.com/a/img/resize/8a51b3338bb5d72c4594d2b37d3392e5f1f8e928/2021/07/28/882145ab-ebc4-41fe-a634-abc184855e6b/20210728-sf-aug.jpg?auto=webp&fit=crop&height=675&width=1200,,2021-08-02T12:10:56.000Z,PT0H6M36S,https://video.zdnet.com/be19d733-732e-4abb-b352-08facdca6a64/20210728_sf_aug_720h3200k.mp4,https://www.zdnet.com/video/share/building-the-digital-workforce-tech-skills-trends-and-strategies-for-success/
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vbmV3cy5udXMuZWR1LnNnL2EtbW9kZWwtb2YtbGlmZWxvbmctbGVhcm5pbmctbnVzLWVxdWlwcy1zdGFmZi13aXRoLWRhdGEtbGl0ZXJhY3ktYW5kLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXNraWxscy_SAQA?oc=5,A model of lifelong learning: NUS equips staff with data literacy and artificial intelligence skills - NUS News,2021-11-15,NUS News,https://news.nus.edu.sg,"The changes brought about by the COVID-19 pandemic are still unfolding but its demand on new skills and ways of working is clear, as organisations seek to survive and thrive in the uncertain times ahead. Many businesses have trimmed back on employee development, but NUS has bucked the trend by putting in huge investment to arm its administrative...","Education,Highlights,National University of Singapore","The changes brought about by the COVID-19 pandemic are still unfolding but its demand on new skills and ways of working is clear, as organisations seek to survive and thrive in the uncertain times ahead. Many businesses have trimmed back on employee development, but NUS has bucked the trend by putting in huge investment to arm its administrative...","The changes brought about by the COVID-19 pandemic are still unfolding but its demand on new skills and ways of working is clear, as organisations seek to survive and thrive in the uncertain times ahead. Many businesses have trimmed back on employee development, but NUS has bucked the trend by putting in huge investment to arm its administrative...",N/A,N/A," 








Share
















15
November
2021

 | 
15:18
Asia/Singapore
EducationHighlightsNational University of Singapore
A model of lifelong learning: NUS equips staff with data literacy and artificial intelligence skills









NN
The Data Literacy Programme (DLP) and Artificial Intelligence Competency Course (AICC) aim to equip staff with pertinent skills for a digital future.






The changes brought about by the COVID-19 pandemic are still unfolding but its demand on new skills and ways of working is clear, as organisations seek to survive and thrive in the uncertain times ahead. Many businesses have trimmed back on employee development, but NUS has bucked the trend by putting in huge investment to arm its administrative staff with skills that are critical for success in the digital future. By launching comprehensive training programmes in data literacy and artificial intelligence since last year, NUS is demonstrating its commitment to prepare staff for the digital future.Using data to derive business insights and drive performance The University has set its sights on arming and upskilling its administrative employees on data literacy and analytics, with the Data Literacy Programme (DLP) conducted over the past year.“The DLP reaffirms the University’s commitment to lifelong learning and the development of our staff, and is our first step to prepare them for the digital future,” said NUS President Professor Tan Eng Chye.“NUS is not only committed to deliver innovative student programmes, we are also committed to ensure our staff are equipped with the relevant skills to stay ahead in these rapidly evolving times, and be ready for new roles in the economy including data analysts and data scientists.”Data is an important resource for all organisations, and is key to deriving meaningful insights to drive business decisions and performance. “All organisations including NUS need to have a higher level of data literacy to unlock these resources to improve our decision efficacy.”Learners give the thumbs upSince its launch in mid-2020, over 2,400 employees have completed or are currently attending the DLP Basic course.The course is being delivered via a blended, hybrid learning approach requiring learners to complete a suite of eLearning sessions, attend 15 hours of hands-on workshops, and complete a group project.Specially designed and helmed by a dedicated group of professors and instructors, including Associate Professor Roger Tan, Associate Professor Carol Anne Hargreaves and Dr Vik Gopal, the DLP is tailored for staff with little to no background in data literacy so that a common ground can be established for staff.Feedback has been positive. The DLP has garnered an 80 per cent programme satisfaction rate, with the majority signaling that they will recommend the course to other colleagues.In addition, many learners wish to pursue higher levels of DLP to deepen their data literacy skillsets – to this end, the DLP will roll out intermediate and advanced levels, to cover data engineering and data visualisation.Learners who have become strong advocates of DLP include Ms Ho Yuen Ping from NUS Enterprise, who expressed her hopes of administrative staff in NUS being equipped in baseline data literacy to make better decisions for the University.“I look forward to the day when all administrative staff have gone through DLP – it means that when we present data for managerial decision-making, everyone will understand and be talking the same language.” Mr Li Xin from the NUS Faculty of Science has experienced the usefulness of the in-person workshops. “Sometimes, what we need is a good starting point and very useful guidance from the teachers so that we can get started. Thereafter, maybe Google is useful. But before that, you really don’t know what you don’t know so it is very difficult.”The University’s efforts to upgrade employees’ skills has led to a greater appreciation for data among employees. Ms Ann Koh Lay Boon from the NUS Office of The President recognises that DLP has led her to appreciate the process of working with data.“My experience doing DLP is very interesting. In fact, I have been encouraging people to go on DLP. Now when I look at a report and the data, I understand how much work has gone into (giving you this kind of information). I get a better idea of how things are done,” she shared.Data-driven projectsDLP presents an invaluable opportunity for learners to collaborate with their colleagues across the University to embark on work-related projects, harnessing data to generate meaningful results.Over 400 projects have been presented with 13 winning projects identified based on the depth of data insights generated, the potential impact on the community, and the application of data storytelling techniques.These projects hold much potential in adding value to the work done in NUS. For instance, a team that worked on data related to the NUS internal bus shuttle system explored the different safety events on the bus routes. With in-depth analysis of the data, their project uncovered hotspots for safety events and the types of dominant safety events such as cornering and braking.Another team investigated the data related to the NUS claims system. The project delved into the claims made by different units in NUS qualitatively and quantitatively, generating interesting insights that have prompted the finance team to provide new services and tighten gaps. This project has helped generate savings for NUS.Unleashing AI-based thinking  Following close on the heels of DLP, NUS also rolled out the Artificial Intelligence Competency Course (AICC) for staff, to train them to create smart systems and applications using modern machine learning and deep learning techniques.Designed by faculty members from NUS School of Computing, including Associate Professor Tan Wee Kek, Dr Lek Hsiang Hui and Dr Akshay Narayan, AICC is a series of courses structured according to three levels of competency – basic, intermediate and advanced. The basic course aims to train learners to be conversant in AI, able to explain what AI is and identify opportunities to apply AI within the University to create positive impact.The intermediate and advanced courses are targeted at interested employees who want to apply AI in their workplace to solve real problems and improve productivity.AICC also adopts a hybrid learning approach with participants attending a weekly three-hour in-person discussion with the instructors, culminating in a group project at the end of five weeks.Just six months into the launch of AICC, the programme has already started to bear fruit with participants proposing various innovative AI projects to improve the productivity of their daily work and create new opportunities for the University. For instance, a team from the NUS School of Design and Environment and NUS Centre for English Language Communication has proposed an AI system to automatically verify the correctness of supporting documents that are submitted for postgraduate admission applications.Staff from the NUS Centre for Remote Imaging, Sensing and Processing (CRISP) have conceptualised an AI system to automate the cloud masking process when analysing satellite images, while a team from the NUS Development Office has put forth the idea of creating an AI application to better engage with alumni and potential donors.Ms Kelly Fong Guan Wen from the NUS Office of Human Resources has found AICC to be helpful in her daily work as well as for her general understanding of the potential of AI.“I believe this will come in handy for all colleagues in time to come and I am very grateful to be part of this learning experience.”Spirit of lifelong learning coded in the NUS DNA  NUS aims for all in the University’s community to embody the spirit of lifelong learning.The University has also established a Skills Transformation Fund account for administrative employees. Employees are empowered to take ownership of their development and utilise the fund to enroll in learning courses that build essential skillsets for their jobs.This will help staff to adapt, transform and innovate to better meet the needs of tomorrow’s challenges.“Learning should be a key differentiator in our value proposition as an employer,” said Prof Tan.  By the NUS Office of Human Resources
 

",https://schema.org,,Article,"{'@type': 'Organization', 'name': 'National University of Singapore'}",2021-11-15T08:18:36+01:00,A model of lifelong learning: NUS equips staff with data literacy and artificial intelligence skills,"{'@type': 'Organization', 'name': 'National University of Singapore', 'logo': {'@type': 'ImageObject', 'url': 'https://content.presspage.com/clients/o_2580.jpg'}}",['https://content.presspage.com/uploads/2580/1920_nn.jpg?10000'],,"{'@type': 'WebPage', '@id': 'https://news.nus.edu.sg/'}",2021-11-15T08:26:59+01:00,,,,,,,,,,,,,,,,,,,,,,,,,,

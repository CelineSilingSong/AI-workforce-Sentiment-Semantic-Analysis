URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,potentialAction,article:section,article:summary,article text,headline,datePublished,dateModified,thumbnailUrl,author,publisher,image,articleBody,mainEntityOfPage,isAccessibleForFree,dateCreated,articleSection,wordCount,creator,itemListElement,name,address,@graph,isPartOf,alternativeHeadline
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vaGJyLm9yZy8yMDIyLzExL2hvdy1nZW5lcmF0aXZlLWFpLWlzLWNoYW5naW5nLWNyZWF0aXZlLXdvcmvSAQA?oc=5,How Generative AI Is Changing Creative Work - HBR.org Daily,2022-11-14,HBR.org Daily,https://hbr.org,"Generative AI models for businesses threaten to upend the world of content creation, with substantial impacts on marketing, software, design, entertainment, and interpersonal communications. These models are able to produce text and images: blog posts, program code, poetry, and artwork. The software uses complex machine learning models to predict the next word based on previous word sequences, or the next image based on words describing previous images. Companies need to understand how these tools work, and how they can add value.",N/A,"Generative AI models for businesses threaten to upend the world of content creation, with substantial impacts on marketing, software, design, entertainment, and interpersonal communications. These models are able to produce text and images: blog posts, program code, poetry, and artwork. The software uses complex machine learning models to predict the next word based on previous word sequences, or the next image based on words describing previous images. Companies need to understand how these tools work, and how they can add value.",N/A,https://schema.org,WebSite,https://hbr.org/,"{'@type': 'SearchAction', 'target': 'https://hbr.org/search?term={search_term_string}', 'query-input': 'required name=search_term_string'}",Business and society,N/A,N/A,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMzQ0NDY4NS9nZW5lcmF0aXZlLWFpLWNvcHlyaWdodC1pbmZyaW5nZW1lbnQtbGVnYWwtZmFpci11c2UtdHJhaW5pbmctZGF0YdIBAA?oc=5,The scary truth about AI copyright is nobody knows what will happen next - The Verge,2022-11-15,The Verge,https://www.theverge.com,"Generative AI models have taken off in 2022. They can generate code, text, art, and more. But there are serious questions about their use of copyrighted data for training. Are these models legal? It’s a difficult question to answer.",N/A,Are text-to-image AI legal? It’s a hard question to answer. ,N/A,http://schema.org/,NewsArticle,https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal-fair-use-training-data,,N/A,N/A,"Artificial IntelligenceThe scary truth about AI copyright is nobody knows what will happen nextThe last year has seen a boom in AI models that create art, music, and code by learning from others’ work. But as these tools become more prominent, unanswered legal questions could shape the future of the field.   By  James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge. Nov 15, 2022, 10:00 AM ESTShare this story16 Comments / 16 New Illustration: Max-o-matic / The Verge Illustration: Max-o-matic / The VergeGenerative AI has had a very good year. Corporations like Microsoft, Adobe, and GitHub are integrating the tech into their products; startups are raising hundreds of millions to compete with them; and the software even has cultural clout, with text-to-image AI models spawning countless memes. But listen in on any industry discussion about generative AI, and you’ll hear, in the background, a question whispered by advocates and critics alike in increasingly concerned tones: is any of this actually legal?The question arises because of the way generative AI systems are trained. Like most machine learning software, they work by identifying and replicating patterns in data. But because these programs are used to generate code, text, music, and art, that data is itself created by humans, scraped from the web and copyright protected in one way or another.For AI researchers in the far-flung misty past (aka the 2010s), this wasn’t much of an issue. At the time, state-of-the-art models were only capable of generating blurry, fingernail-sized black-and-white images of faces. This wasn’t an obvious threat to humans. But in the year 2022, when a lone amateur can use software like Stable Diffusion to copy an artist’s style in a matter of hours or when companies are selling AI-generated prints and social media filters that are explicit knock-offs of living designers, questions of legality and ethics have become much more pressing. Generative AI models are trained on copyright-protected data — is that legal?Take the case of Hollie Mengert, a Disney illustrator who found that her art style had been cloned as an AI experiment by a mechanical engineering student in Canada. The student downloaded 32 of Mengert’s pieces and took a few hours to train a machine learning model that could reproduce her style. As Mengert told technologist Andy Baio, who reported the case: “For me, personally, it feels like someone’s taking work that I’ve done, you know, things that I’ve learned — I’ve been a working artist since I graduated art school in 2011 — and is using it to create art that that [sic] I didn’t consent to and didn’t give permission for.” But is that fair? And can Mengert do anything about it? To answer these questions and understand the legal landscape surrounding generative AI, The Verge spoke to a range of experts, including lawyers, analysts, and employees at AI startups. Some said with confidence that these systems were certainly capable of infringing copyright and could face serious legal challenges in the near future. Others suggested, equally confident, that the opposite was true: that everything currently happening in the field of generative AI is legally above board and any lawsuits are doomed to fail. “I see people on both sides of this extremely confident in their positions, but the reality is nobody knows,” Baio, who’s been following the generative AI scene closely, told The Verge. “And anyone who says they know confidently how this will play out in court is wrong.”Andres Guadamuz, an academic specializing in AI and intellectual property law at the UK’s University of Sussex, suggested that while there were many unknowns, there were also just a few key questions from which the topic’s many uncertainties unfold. First, can you copyright the output of a generative AI model, and if so, who owns it? Second, if you own the copyright to the input used to train an AI, does that give you any legal claim over the model or the content it creates? Once these questions are answered, an even larger one emerges: how do you deal with the fallout of this technology? What kind of legal restraints could — or should — be put in place on data collection? And can there be peace between the people building these systems and those whose data is needed to create them? Let’s take these questions one at a time. Illustration: Max-o-matic / The VergeThe output question: can you copyright what an AI model creates?For the first query, at least, the answer is not too difficult. In the US, there is no copyright protection for works generated solely by a machine. However, it seems that copyright may be possible in cases where the creator can prove there was substantial human input.In September, the US Copyright Office granted a first-of-its-kind registration for a comic book generated with the help of text-to-image AI Midjourney. The comic is a complete work: an 18-page narrative with characters, dialogue, and a traditional comic book layout. And although it’s since been reported that the USCO is reviewing its decision, the comic’s copyright registration hasn’t actually been rescinded yet. It seems that one factor in the review will be the degree of human input involved in making the comic. Kristina Kashtanova, the artist who created the work, told IPWatchdog that she had been asked by the USCO “to provide details of my process to show that there was substantial human involvement in the process of creation of this graphic novel.” (The USCO itself does not comment on specific cases.)According to Guadamuz, this will be an ongoing issue when it comes to granting copyright for works generated with the help of AI. “If you just type ‘cat by van Gogh,’ I don’t think that’s enough to get copyright in the US,” he says. “But if you start experimenting with prompts and produce several images and start fine-tuning your images, start using seeds, and start engineering a little more, I can totally see that being protected by copyright.”Copyrighting an AI model’s output will likely depend on the degree of human involvementWith this rubric in mind, it’s likely that the vast majority of the output of generative AI models cannot be copyright protected. They are generally churned out en masse with just a few keywords used as a prompt. But more involved processes would make for better cases. These might include controversial pieces, like the AI-generated print that won a state art fair competition. In this case, the creator said he spent weeks honing his prompts and manually editing the finished piece, suggesting a relatively high degree of intellectual involvement. Giorgio Franceschelli, a computer scientist who’s written on the problems surrounding AI copyright, says measuring human input will be “especially true” for deciding cases in the EU. And in the UK — the other major jurisdiction of concern for Western AI startups — the law is different yet again. Unusually, the UK is one of only a handful of nations to offer copyright for works generated solely by a computer, but it deems the author to be “the person by whom the arrangements necessary for the creation of the work are undertaken.” Again, there’s room for multiple readings (would this “person” be the model’s developer or its operator?), but it offers precedence for some sort of copyright protection to be granted. Ultimately, though, registering copyright is only a first step, cautions Guadamuz. “The US copyright office is not a court,” he says. “You need registration if you’re going to sue someone for copyright infringement, but it’s going to be a court that decides whether or not that’s legally enforceable.”  Illustration: Max-o-matic / The VergeThe input question: can you use copyright-protected data to train AI models?For most experts, the biggest questions concerning AI and copyright relate to the data used to train these models. Most systems are trained on huge amounts of content scraped from the web; be that text, code, or imagery. The training dataset for Stable Diffusion, for example — one of the biggest and most influential text-to-AI systems — contains billions of images scraped from hundreds of domains; everything from personal blogs hosted on WordPress and Blogspot to art platforms like DeviantArt and stock imagery sites like Shutterstock and Getty Images. Indeed, training datasets for generative AI are so vast that there’s a good chance you’re already in one (there’s even a website where you can check by uploading a picture or searching some text).The justification used by AI researchers, startups, and multibillion-dollar tech companies alike is that using these images is covered (in the US, at least) by fair use doctrine, which aims to encourage the use of copyright-protected work to promote freedom of expression. When deciding if something is fair use, there are a number of considerations, explains Daniel Gervais, a professor at Vanderbilt Law School who specializes in intellectual property law and has written extensively on how this intersects with AI. Two factors, though, have “much, much more prominence,” he says. “What’s the purpose or nature of the use and what’s the impact on the market.” In other words: does the use-case change the nature of the material in some way (usually described as a “transformative” use), and does it threaten the livelihood of the original creator by competing with their works? Training a generative AI on copyright-protected data is likely legal, but you could use that same model in illegal waysConsidering the onus placed on these factors, Gervais says “it is much more likely than not” that training systems on copyrighted data will be covered by fair use. But the same cannot necessarily be said for generating content. In other words: you can train an AI model using other people’s data, but what you do with that model might be infringing. Think of it as the difference between making fake money for a movie and trying to buy a car with it. Consider the same text-to-image AI model deployed in different scenarios. If the model is trained on many millions of images and used to generate novel pictures, it’s extremely unlikely that this constitutes copyright infringement. The training data has been transformed in the process, and the output does not threaten the market for the original art. But, if you fine-tune that model on 100 pictures by a specific artist and generate pictures that match their style, an unhappy artist would have a much stronger case against you. “If you give an AI 10 Stephen King novels and say, ‘Produce a Stephen King novel,’ then you’re directly competing with Stephen King. Would that be fair use? Probably not,” says Gervais.Crucially, though, between these two poles of fair and unfair use, there are countless scenarios in which input, purpose, and output are all balanced differently and could sway any legal ruling one way or another. Ryan Khurana, chief of staff at generative AI company Wombo, says most companies selling these services are aware of these differences. “Intentionally using prompts that draw on copyrighted works to generate an output [...] violates the terms of service of every major player,” he told The Verge over email. But, he adds, “enforcement is difficult,” and companies are more interested in “coming up with ways to prevent using models in copyright violating ways [...] than limiting training data.” This is particularly true for open-source text-to-image models like Stable Diffusion, which can be trained and used with zero oversight or filters. The company might have covered its back, but it could also be facilitating copyright-infringing uses. 
Another variable in judging fair use is whether or not the training data and model have been created by academic researchers and nonprofits. This generally strengthens fair use defenses and startups know this. So, for example, Stability AI, the company that distributes Stable Diffusion, didn’t directly collect the model’s training data or train the models behind the software. Instead, it funded and coordinated this work by academics and the Stable Diffusion model is licensed by a German university. This lets Stability AI turn the model into a commercial service (DreamStudio) while keeping legal distance from its creation.Baio has dubbed this practice “AI data laundering.” He notes that this method has been used before with the creation of facial recognition AI software, and points to the case of MegaFace, a dataset compiled by researchers from the University of Washington by scraping photos from Flickr. “The academic researchers took the data, laundered it, and it was used by commercial companies,” says Baio. Now, he says, this data — including millions of personal pictures — is in the hands of “[facial recognition firm] Clearview AI and law enforcement and the Chinese government.” Such a tried-and-tested laundering process will likely help shield the creators of generative AI models from liability as well.There’s a last twist to all this, though, as Gervais notes that the current interpretation of fair use may actually change in the coming months due to a pending Supreme Court case involving Andy Warhol and Prince. The case involves Warhol’s use of photographs of Prince to create artwork. Was this fair use, or is it copyright infringement? “The Supreme Court doesn’t do fair use very often, so when they do, they usually do something major. I think they’re going to do the same here,” says Gervais. “And to say anything is settled law while waiting for the Supreme Court to change the law is risky.” Illustration: Max-o-matic / The VergeHow can artists and AI companies make peace?Even if the training of generative AI models is found to be covered by fair use, that will hardly solve the field’s problems. It won’t placate the artists angry their work has been used to train commercial models, nor will it necessarily hold true across other generative AI fields, like code and music. With this in mind, the question is: what remedies can be introduced, technical or otherwise, to allow generative AI to flourish while giving credit or compensation to the creators whose work makes the field possible?The most obvious suggestion is to license the data and pay its creators. For some, though, this will kill the industry. Bryan Casey and Mark Lemley, authors of “Fair Learning,” a legal paper that has become the backbone of arguments touting fair use for generative AI, say training datasets are so large that “there is no plausible option simply to license all of the underlying photographs, videos, audio files, or texts for the new use.” Allowing any copyright claim, they argue, is “tantamount to saying, not that copyright owners will get paid, but that the use won’t be permitted at all.” Permitting “fair learning,” as they frame it, not only encourages innovation but allows for the development of better AI systems.Others, though, point out that we’ve already navigated copyright issues of comparable scale and complexity and can do so again. A comparison invoked by several experts The Verge spoke to was the era of music piracy, when file-sharing programs were built on the back of massive copyright infringement and prospered only until there were legal challenges that led to new agreements that respected copyright. “So, in the early 2000s, you had Napster, which everybody loved but was completely illegal. And today, we have things like Spotify and iTunes,” Matthew Butterick, a lawyer currently suing companies for scraping data to train AI models, told The Verge earlier this month. “And how did these systems arise? By companies making licensing deals and bringing in content legitimately. All the stakeholders came to the table and made it work, and the idea that a similar thing can’t happen for AI is, for me, a little catastrophic.”Companies and researchers are already experimenting with ways to compensate creatorsWombo’s Ryan Khurana predicted a similar outcome. “Music has by far the most complex copyright rules because of the different types of licensing, the variety of rights-holders, and the various intermediaries involved,” he told The Verge. “Given the nuances [of the legal questions surrounding AI], I think the entire generative field will evolve into having a licensing regime similar to that of music.”Other alternatives are also being trialled. Shutterstock, for example, says it plans to set up a fund to compensate individuals whose work it’s sold to AI companies to train their models, while DeviantArt has created a metadata tag for images shared on the web that warns AI researchers not to scrape their content. (At least one small social network, Cohost, has already adopted the tag across its site and says if it finds that researchers are scraping its images regardless, it “won’t rule out legal action.”) These approaches, though, have met with mixed responses from artistic communities. Can one-off license fees ever compensate for lost livelihood? And how does a no-scraping tag deployed now help artists whose work has already been used to train commercial AI system? For many creators, it seems the damage has already been done. But AI startups are at least suggesting new approaches for the future. One obvious step forward is for AI researchers to simply create databases where there is no possibility of copyright infringement — either because the material has been properly licensed or because it’s been created for the specific purpose of AI training. One such example is “The Stack” — a dataset for training AI designed to specifically avoid accusations of copyright infringement. It includes only code with the most permissive possible open-source licensing and offers developers an easy  way to remove their data on request. Its creators say their model could be used throughout the industry. “The Stack’s approach can absolutely be adapted to other media,” Yacine Jernite, Machine Learning & Society lead at Hugging Face, which helped create The Stack in collaboration with partner ServiceNow, told The Verge. “It is an important first step in exploring the wide range of mechanisms that exist for consent — mechanisms that work at their best when they take the rules of the platform that the AI training data was extracted from into account.” Jernite says Hugging Face wants to help create a “fundamental shift” in how the creators are treated by AI researchers. But so far, the company’s approach remains a rarity.What happens next?Regardless of where we land on these legal questions, the various actors in the generative AI field are already gearing up for… something. The companies making millions from this tech are entrenching themselves: repeatedly declaring that everything they’re doing is legal (while presumably hoping no one actually challenges this claim). On the other side of no man’s land, copyright holders are staking out their own tentative positions without quite committing themselves to action. Getty Images recently banned AI content because of the potential legal risk to customers (“I don’t think it’s responsible. I think it could be illegal,” CEO Craig Peters told The Verge last month) while music industry trade org RIAA declared that AI-powered music mixers and extractors are infringing members’ copyright (though they didn’t go so far as to launch any actual legal challenges). The first shot in the AI copyright wars has already been fired, though, with the launch last week of a proposed class action lawsuit against Microsoft, GitHub, and OpenAI. The case accuses all three companies of knowingly reproducing open-source code through the AI coding assistant, Copilot, but without the proper licenses. Speaking to The Verge last week, the lawyers behind the suit said it could set a precedent for the entire generative AI field (though other experts disputed this, saying any copyright challenges involving code would likely be separate from those involving content like art and music).“Once someone breaks cover, though, I think the lawsuits are going to start flying left and right.”Guadamuz and Baio, meanwhile, both say they’re surprised there haven’t been more legal challenges yet. “Honestly, I am flabbergasted,” says Guadamuz. “But I think that’s in part because these industries are afraid of being the first one [to sue] and losing a decision. Once someone breaks cover, though, I think the lawsuits are going to start flying left and right.”Baio suggested one difficulty is that many people most affected by this technology — artists  and the like — are simply not in a good position to launch legal challenges. “They don’t have the resources,” he says. “This sort of litigation is very expensive and time-consuming, and you’re only going to do it if you know you’re going to win. This is why I’ve thought for some time that the first lawsuits around AI art will be from stock image sites. They seem poised to lose the most from this technology, they can clearly prove that a large amount of their corpus was used to train these models, and they have the funding to take it to court.”Guadamuz agrees. “Everyone knows how expensive it’s going to be,” he says. “Whoever sues will get a decision in the lower courts, then they will appeal, then they will appeal again, and eventually, it could go all the way to the Supreme Court.”Comments16 Comments / 16 NewFeatured Videos From The VergeSamsung’s new folds, flips, and Apple clones | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge's Nilay Patel, David Pierce, and Alex Cranz discuss the announcements from Samsung's Galaxy Unpacked event, Redbox shutting down, and more tech news from this week.Most PopularMost PopularMicrosoft releases recovery tool to help repair Windows machines hit by CrowdStrike issueTwo new must-have Android appsSuunto’s new headphones finally made me appreciate bone conductionBy endorsing Trump, Elon Musk is gambling with Tesla’s futureNotchNook gives MacBooks their own Dynamic Island Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",The scary truth about AI copyright is nobody knows what will happen next,2022-11-15T15:00:00.000Z,2022-11-15T15:00:00.000Z,https://cdn.vox-cdn.com/thumbor/JRjL_e3IjSINFVnJp-aJu3K4zQY=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24175864/226390_AI_Generated_Art_Copyright_MMatic_001.jpg,"[{'@type': 'Person', 'name': 'James Vincent', 'url': 'https://www.theverge.com/authors/james-vincent'}]","{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}","[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/JRjL_e3IjSINFVnJp-aJu3K4zQY=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24175864/226390_AI_Generated_Art_Copyright_MMatic_001.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/QNWjPuAuPJDNgtghaRUyTQNl98s=/0x0:2040x1360/1400x1050/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24175864/226390_AI_Generated_Art_Copyright_MMatic_001.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/ZsIf-CSHYdiULI8znhgW0FfHZos=/0x0:2040x1360/1400x1400/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24175864/226390_AI_Generated_Art_Copyright_MMatic_001.jpg', 'width': 1400, 'height': 1400}]","Generative AI has had a very good year. Corporations like Microsoft, Adobe, and GitHub are integrating the tech into their products; startups are raising hundreds of millions to compete with them; and the software even has cultural clout, with text-to-image AI models spawning countless memes. But listen in on any industry discussion about generative AI, and you’ll hear, in the background, a question whispered by advocates and critics alike in increasingly concerned tones: is any of this actually legal?

The question arises because of the way generative AI systems are trained. Like most machine learning software, they work by identifying and replicating patterns in data. But because these programs are used to generate code, text, music, and art, that data is itself created by humans, scraped from the web and copyright protected in one way or another.

For AI researchers in the far-flung misty past (aka the 2010s), this wasn’t much of an issue. At the time, state-of-the-art models were only capable of generating blurry, fingernail-sized black-and-white images of faces. This wasn’t an obvious threat to humans. But in the year 2022, when a lone amateur can use software like Stable Diffusion to copy an artist’s style in a matter of hours or when companies are selling AI-generated prints and social media filters that are explicit knock-offs of living designers, questions of legality and ethics have become much more pressing. 

""Generative AI models are trained on copyright-protected data — is that legal?""

Take the case of Hollie Mengert, a Disney illustrator who found that her art style had been cloned as an AI experiment by a mechanical engineering student in Canada. The student downloaded 32 of Mengert’s pieces and took a few hours to train a machine learning model that could reproduce her style. As Mengert told technologist Andy Baio, who reported the case: “For me, personally, it feels like someone’s taking work that I’ve done, you know, things that I’ve learned — I’ve been a working artist since I graduated art school in 2011 — and is using it to create art that that [sic] I didn’t consent to and didn’t give permission for.” 

But is that fair? And can Mengert do anything about it? 

To answer these questions and understand the legal landscape surrounding generative AI, The Verge spoke to a range of experts, including lawyers, analysts, and employees at AI startups. Some said with confidence that these systems were certainly capable of infringing copyright and could face serious legal challenges in the near future. Others suggested, equally confident, that the opposite was true: that everything currently happening in the field of generative AI is legally above board and any lawsuits are doomed to fail. 

“I see people on both sides of this extremely confident in their positions, but the reality is nobody knows,” Baio, who’s been following the generative AI scene closely, told The Verge. “And anyone who says they know confidently how this will play out in court is wrong.”

Andres Guadamuz, an academic specializing in AI and intellectual property law at the UK’s University of Sussex, suggested that while there were many unknowns, there were also just a few key questions from which the topic’s many uncertainties unfold. First, can you copyright the output of a generative AI model, and if so, who owns it? Second, if you own the copyright to the input used to train an AI, does that give you any legal claim over the model or the content it creates? Once these questions are answered, an even larger one emerges: how do you deal with the fallout of this technology? What kind of legal restraints could — or should — be put in place on data collection? And can there be peace between the people building these systems and those whose data is needed to create them? 

Let’s take these questions one at a time.

[Image: https://cdn.vox-cdn.com/thumbor/WCVTFwqBWFVeLMLZJ4KDvm98yVE=/0x0:2040x1530/2040x1530/filters:focal(1020x765:1021x766)/cdn.vox-cdn.com/uploads/chorus_asset/file/24175865/226390_AI_Generated_Art_Copyright_MMatic_002.jpg]

The output question: can you copyright what an AI model creates?

For the first query, at least, the answer is not too difficult. In the US, there is no copyright protection for works generated solely by a machine. However, it seems that copyright may be possible in cases where the creator can prove there was substantial human input.

In September, the US Copyright Office granted a first-of-its-kind registration for a comic book generated with the help of text-to-image AI Midjourney. The comic is a complete work: an 18-page narrative with characters, dialogue, and a traditional comic book layout. And although it’s since been reported that the USCO is reviewing its decision, the comic’s copyright registration hasn’t actually been rescinded yet. It seems that one factor in the review will be the degree of human input involved in making the comic. Kristina Kashtanova, the artist who created the work, told IPWatchdog that she had been asked by the USCO “to provide details of my process to show that there was substantial human involvement in the process of creation of this graphic novel.” (The USCO itself does not comment on specific cases.)

According to Guadamuz, this will be an ongoing issue when it comes to granting copyright for works generated with the help of AI. “If you just type ‘cat by van Gogh,’ I don’t think that’s enough to get copyright in the US,” he says. “But if you start experimenting with prompts and produce several images and start fine-tuning your images, start using seeds, and start engineering a little more, I can totally see that being protected by copyright.”

""Copyrighting an AI model’s output will likely depend on the degree of human involvement""

With this rubric in mind, it’s likely that the vast majority of the output of generative AI models cannot be copyright protected. They are generally churned out en masse with just a few keywords used as a prompt. But more involved processes would make for better cases. These might include controversial pieces, like the AI-generated print that won a state art fair competition. In this case, the creator said he spent weeks honing his prompts and manually editing the finished piece, suggesting a relatively high degree of intellectual involvement. 

Giorgio Franceschelli, a computer scientist who’s written on the problems surrounding AI copyright, says measuring human input will be “especially true” for deciding cases in the EU. And in the UK — the other major jurisdiction of concern for Western AI startups — the law is different yet again. Unusually, the UK is one of only a handful of nations to offer copyright for works generated solely by a computer, but it deems the author to be “the person by whom the arrangements necessary for the creation of the work are undertaken.” Again, there’s room for multiple readings (would this “person” be the model’s developer or its operator?), but it offers precedence for some sort of copyright protection to be granted. 

Ultimately, though, registering copyright is only a first step, cautions Guadamuz. “The US copyright office is not a court,” he says. “You need registration if you’re going to sue someone for copyright infringement, but it’s going to be a court that decides whether or not that’s legally enforceable.” 

[Image: https://cdn.vox-cdn.com/thumbor/Q_4p9miEx1pwQd9Je05IyeWOsQI=/0x0:2040x1530/2040x1530/filters:focal(1020x765:1021x766)/cdn.vox-cdn.com/uploads/chorus_asset/file/24175866/226390_AI_Generated_Art_Copyright_MMatic_003.jpg]

The input question: can you use copyright-protected data to train AI models?

For most experts, the biggest questions concerning AI and copyright relate to the data used to train these models. Most systems are trained on huge amounts of content scraped from the web; be that text, code, or imagery. The training dataset for Stable Diffusion, for example — one of the biggest and most influential text-to-AI systems — contains billions of images scraped from hundreds of domains; everything from personal blogs hosted on WordPress and Blogspot to art platforms like DeviantArt and stock imagery sites like Shutterstock and Getty Images. Indeed, training datasets for generative AI are so vast that there’s a good chance you’re already in one (there’s even a website where you can check by uploading a picture or searching some text).

The justification used by AI researchers, startups, and multibillion-dollar tech companies alike is that using these images is covered (in the US, at least) by fair use doctrine, which aims to encourage the use of copyright-protected work to promote freedom of expression. 

When deciding if something is fair use, there are a number of considerations, explains Daniel Gervais, a professor at Vanderbilt Law School who specializes in intellectual property law and has written extensively on how this intersects with AI. Two factors, though, have “much, much more prominence,” he says. “What’s the purpose or nature of the use and what’s the impact on the market.” In other words: does the use-case change the nature of the material in some way (usually described as a “transformative” use), and does it threaten the livelihood of the original creator by competing with their works? 

""Training a generative AI on copyright-protected data is likely legal, but you could use that same model in illegal ways""

Considering the onus placed on these factors, Gervais says “it is much more likely than not” that training systems on copyrighted data will be covered by fair use. But the same cannot necessarily be said for generating content. In other words: you can train an AI model using other people’s data, but what you do with that model might be infringing. Think of it as the difference between making fake money for a movie and trying to buy a car with it. 

Consider the same text-to-image AI model deployed in different scenarios. If the model is trained on many millions of images and used to generate novel pictures, it’s extremely unlikely that this constitutes copyright infringement. The training data has been transformed in the process, and the output does not threaten the market for the original art. But, if you fine-tune that model on 100 pictures by a specific artist and generate pictures that match their style, an unhappy artist would have a much stronger case against you. 

“If you give an AI 10 Stephen King novels and say, ‘Produce a Stephen King novel,’ then you’re directly competing with Stephen King. Would that be fair use? Probably not,” says Gervais.

Crucially, though, between these two poles of fair and unfair use, there are countless scenarios in which input, purpose, and output are all balanced differently and could sway any legal ruling one way or another. 

Ryan Khurana, chief of staff at generative AI company Wombo, says most companies selling these services are aware of these differences. “Intentionally using prompts that draw on copyrighted works to generate an output [...] violates the terms of service of every major player,” he told The Verge over email. But, he adds, “enforcement is difficult,” and companies are more interested in “coming up with ways to prevent using models in copyright violating ways [...] than limiting training data.” This is particularly true for open-source text-to-image models like Stable Diffusion, which can be trained and used with zero oversight or filters. The company might have covered its back, but it could also be facilitating copyright-infringing uses. 

Another variable in judging fair use is whether or not the training data and model have been created by academic researchers and nonprofits. This generally strengthens fair use defenses and startups know this. So, for example, Stability AI, the company that distributes Stable Diffusion, didn’t directly collect the model’s training data or train the models behind the software. Instead, it funded and coordinated this work by academics and the Stable Diffusion model is licensed by a German university. This lets Stability AI turn the model into a commercial service (DreamStudio) while keeping legal distance from its creation.

Baio has dubbed this practice “AI data laundering.” He notes that this method has been used before with the creation of facial recognition AI software, and points to the case of MegaFace, a dataset compiled by researchers from the University of Washington by scraping photos from Flickr. “The academic researchers took the data, laundered it, and it was used by commercial companies,” says Baio. Now, he says, this data — including millions of personal pictures — is in the hands of “[facial recognition firm] Clearview AI and law enforcement and the Chinese government.” Such a tried-and-tested laundering process will likely help shield the creators of generative AI models from liability as well.

There’s a last twist to all this, though, as Gervais notes that the current interpretation of fair use may actually change in the coming months due to a pending Supreme Court case involving Andy Warhol and Prince. The case involves Warhol’s use of photographs of Prince to create artwork. Was this fair use, or is it copyright infringement? 

“The Supreme Court doesn’t do fair use very often, so when they do, they usually do something major. I think they’re going to do the same here,” says Gervais. “And to say anything is settled law while waiting for the Supreme Court to change the law is risky.”

[Image: https://cdn.vox-cdn.com/thumbor/5RR8fPAWmvhRmBs0P1kMpinPZDQ=/0x0:2040x1530/2040x1530/filters:focal(1020x765:1021x766)/cdn.vox-cdn.com/uploads/chorus_asset/file/24175867/226390_AI_Generated_Art_Copyright_MMatic_004.jpg]

How can artists and AI companies make peace?

Even if the training of generative AI models is found to be covered by fair use, that will hardly solve the field’s problems. It won’t placate the artists angry their work has been used to train commercial models, nor will it necessarily hold true across other generative AI fields, like code and music. With this in mind, the question is: what remedies can be introduced, technical or otherwise, to allow generative AI to flourish while giving credit or compensation to the creators whose work makes the field possible?

The most obvious suggestion is to license the data and pay its creators. For some, though, this will kill the industry. Bryan Casey and Mark Lemley, authors of “Fair Learning,” a legal paper that has become the backbone of arguments touting fair use for generative AI, say training datasets are so large that “there is no plausible option simply to license all of the underlying photographs, videos, audio files, or texts for the new use.” Allowing any copyright claim, they argue, is “tantamount to saying, not that copyright owners will get paid, but that the use won’t be permitted at all.” Permitting “fair learning,” as they frame it, not only encourages innovation but allows for the development of better AI systems.

Others, though, point out that we’ve already navigated copyright issues of comparable scale and complexity and can do so again. A comparison invoked by several experts The Verge spoke to was the era of music piracy, when file-sharing programs were built on the back of massive copyright infringement and prospered only until there were legal challenges that led to new agreements that respected copyright. 

“So, in the early 2000s, you had Napster, which everybody loved but was completely illegal. And today, we have things like Spotify and iTunes,” Matthew Butterick, a lawyer currently suing companies for scraping data to train AI models, told The Verge earlier this month. “And how did these systems arise? By companies making licensing deals and bringing in content legitimately. All the stakeholders came to the table and made it work, and the idea that a similar thing can’t happen for AI is, for me, a little catastrophic.”

""Companies and researchers are already experimenting with ways to compensate creators""

Wombo’s Ryan Khurana predicted a similar outcome. “Music has by far the most complex copyright rules because of the different types of licensing, the variety of rights-holders, and the various intermediaries involved,” he told The Verge. “Given the nuances [of the legal questions surrounding AI], I think the entire generative field will evolve into having a licensing regime similar to that of music.”

Other alternatives are also being trialled. Shutterstock, for example, says it plans to set up a fund to compensate individuals whose work it’s sold to AI companies to train their models, while DeviantArt has created a metadata tag for images shared on the web that warns AI researchers not to scrape their content. (At least one small social network, Cohost, has already adopted the tag across its site and says if it finds that researchers are scraping its images regardless, it “won’t rule out legal action.”) These approaches, though, have met with mixed responses from artistic communities. Can one-off license fees ever compensate for lost livelihood? And how does a no-scraping tag deployed now help artists whose work has already been used to train commercial AI system? 

For many creators, it seems the damage has already been done. But AI startups are at least suggesting new approaches for the future. One obvious step forward is for AI researchers to simply create databases where there is no possibility of copyright infringement — either because the material has been properly licensed or because it’s been created for the specific purpose of AI training. One such example is “The Stack” — a dataset for training AI designed to specifically avoid accusations of copyright infringement. It includes only code with the most permissive possible open-source licensing and offers developers an easy  way to remove their data on request. Its creators say their model could be used throughout the industry. 

“The Stack’s approach can absolutely be adapted to other media,” Yacine Jernite, Machine Learning & Society lead at Hugging Face, which helped create The Stack in collaboration with partner ServiceNow, told The Verge. “It is an important first step in exploring the wide range of mechanisms that exist for consent — mechanisms that work at their best when they take the rules of the platform that the AI training data was extracted from into account.” Jernite says Hugging Face wants to help create a “fundamental shift” in how the creators are treated by AI researchers. But so far, the company’s approach remains a rarity.

What happens next?

Regardless of where we land on these legal questions, the various actors in the generative AI field are already gearing up for… something. The companies making millions from this tech are entrenching themselves: repeatedly declaring that everything they’re doing is legal (while presumably hoping no one actually challenges this claim). On the other side of no man’s land, copyright holders are staking out their own tentative positions without quite committing themselves to action. Getty Images recently banned AI content because of the potential legal risk to customers (“I don’t think it’s responsible. I think it could be illegal,” CEO Craig Peters told The Verge last month) while music industry trade org RIAA declared that AI-powered music mixers and extractors are infringing members’ copyright (though they didn’t go so far as to launch any actual legal challenges). 

The first shot in the AI copyright wars has already been fired, though, with the launch last week of a proposed class action lawsuit against Microsoft, GitHub, and OpenAI. The case accuses all three companies of knowingly reproducing open-source code through the AI coding assistant, Copilot, but without the proper licenses. Speaking to The Verge last week, the lawyers behind the suit said it could set a precedent for the entire generative AI field (though other experts disputed this, saying any copyright challenges involving code would likely be separate from those involving content like art and music).

""“Once someone breaks cover, though, I think the lawsuits are going to start flying left and right.”""

Guadamuz and Baio, meanwhile, both say they’re surprised there haven’t been more legal challenges yet. “Honestly, I am flabbergasted,” says Guadamuz. “But I think that’s in part because these industries are afraid of being the first one [to sue] and losing a decision. Once someone breaks cover, though, I think the lawsuits are going to start flying left and right.”

Baio suggested one difficulty is that many people most affected by this technology — artists  and the like — are simply not in a good position to launch legal challenges. “They don’t have the resources,” he says. “This sort of litigation is very expensive and time-consuming, and you’re only going to do it if you know you’re going to win. This is why I’ve thought for some time that the first lawsuits around AI art will be from stock image sites. They seem poised to lose the most from this technology, they can clearly prove that a large amount of their corpus was used to train these models, and they have the funding to take it to court.”

Guadamuz agrees. “Everyone knows how expensive it’s going to be,” he says. “Whoever sues will get a decision in the lower courts, then they will appeal, then they will appeal again, and eventually, it could go all the way to the Supreme Court.”
",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS90ZWNobm9sb2d5LzIwMjIvbm92LzEyL3doZW4tYWktY2FuLW1ha2UtYXJ0LXdoYXQtZG9lcy1pdC1tZWFuLWZvci1jcmVhdGl2aXR5LWRhbGwtZS1taWRqb3VybmV50gF6aHR0cHM6Ly9hbXAudGhlZ3VhcmRpYW4uY29tL3RlY2hub2xvZ3kvMjAyMi9ub3YvMTIvd2hlbi1haS1jYW4tbWFrZS1hcnQtd2hhdC1kb2VzLWl0LW1lYW4tZm9yLWNyZWF0aXZpdHktZGFsbC1lLW1pZGpvdXJuZXk?oc=5,When AI can make art – what does it mean for creativity? - The Guardian,2022-11-12,The Guardian,https://www.theguardian.com,Image-generators such as Dall-E 2 can produce pictures on any theme you wish for in seconds. Some creatives are alarmed but others are sceptical of the hype,N/A,Image-generators such as Dall-E 2 can produce pictures on any theme you wish for in seconds. Some creatives are alarmed but others are sceptical of the hype,N/A,,,,,Technology,N/A," A sea otter in the style of Girl with a Pearl Earring by Johannes Vermeer, created with Dall-E.View image in fullscreenA sea otter in the style of Girl with a Pearl Earring by Johannes Vermeer, created with Dall-E.The ObserverArtificial intelligence (AI) This article is more than 1 year oldWhen AI can make art – what does it mean for creativity?This article is more than 1 year oldImage-generators such as Dall-E 2 can produce pictures on any theme you wish for in seconds. Some creatives are alarmed but others are sceptical of the hypeLaurie ClarkeSat 12 Nov 2022 11.00 ESTLast modified on Thu 17 Nov 2022 19.45 ESTShare268268When the concept artist and illustrator RJ Palmer first witnessed the fine-tuned photorealism of compositions produced by the AI image generator Dall-E 2, his feeling was one of unease. The tool, released by the AI research company OpenAI, showed a marked improvement on 2021’s Dall-E, and was quickly followed by rivals such as Stable Diffusion and Midjourney. Type in any surreal prompt, from Kermit the frog in the style of Edvard Munch, to Gollum from The Lord of the Rings feasting on a slice of watermelon, and these tools will return a startlingly accurate depiction moments later.The internet revelled in the meme-making opportunities, with a Twitter account documenting “weird Dall-E generations” racking up more than a million followers. Cosmopolitan trumpeted the world’s first AI-generated magazine cover, and technology investors fell over themselves to wave in the new era of “generative AI”. The image-generation capabilities have already spread to video, with the release of Google’s Imagen Video and Meta’s Make-A-Video.But AI’s new artistic prowess wasn’t received so ecstatically by some creatives. “The main concern for me is what this does to the future of not just my industry, but creative human industries in general,” says Palmer.View image in fullscreenIn June, Cosmopolitan published the first AI-generated magazine cover, a collaboration between digital artist Karen X Cheng and OpenAI.By ingesting large datasets in order to analyse patterns and build predictive models, AI has long proved itself superior to humans at some tasks. It’s this number-crunching nous that led an AI to trounce the world Go champion back in 2016, rapidly computing the most advantageous game strategy, and unafraid to execute moves that would have elicited scoffs had they come from a person. But until recently, producing original output, especially creative work, was considered a distinctly human pursuit.Recent improvements in AI have shifted the dial. Not only can AI image generators now transpose written phrases into novel pictures, but strides have been made in AI speech-generation too: large language models such as GPT-3 have reached a level of fluency that convinced at least one recently fired Google researcher of machine sentience. Plug in Bach’s oeuvre, and an AI can improvise music in more or less the same style – with the caveat that it would often be impossible for a human orchestra to actually play.This class of technology is known as generative AI, and it works through a process known as diffusion. Essentially, huge datasets are scraped together to train the AI, and through a technical process the AI is able to devise new content that resembles the training data but isn’t identical. Once it has seen millions of pictures of dogs tagged with the word “dog”, it is able to lay down pixels in the shape of an entirely novel pup that resembles the dataset closely enough that we would have no issue labelling it a dog. It’s not perfect – AI image tools still struggle with rendering hands that look human, body proportions can be off, and they have a habit of producing nonsense writing.AI image tools still struggle with rendering hands that look human, and body proportions can be offWhile internet users have embraced this supercharged creative potential – armed with the correctly refined prompt, even novices can now create arresting digital canvases – some artists have balked at the new technology’s capacity for mimicry. Among the prompts entered into image generators Stable Diffusion and Midjourney, many tag an artist’s name in order to ensure a more aesthetically pleasing style for the resulting image. Something as mundane as a bowl of oranges can become eye-catching if rendered in the style of, say, Picasso. Because the AI has been trained on billions of images, some of which are copyrighted works by living artists, it can generally create a pretty faithful approximation.View image in fullscreen‘Kermit the frog painted by Munch’, created by Floris Groesz with Dall-E software. Photograph: @SirJanosFroglezSome are outraged at what they consider theft of their artistic trademark. Greg Rutkowski, a concept artist and illustrator well known for his golden-light infused epic fantasy scenes, has already been mentioned in hundreds of thousands of prompts used across Midjourney and Stable Diffusion. “It’s been just a month. What about in a year? I probably won’t be able to find my work out there because [the internet] will be flooded with AI art,” Rutkowski told MIT Technology Review. “That’s concerning.”Dall-E 2 is a black box, with OpenAI refusing to release the code or share the data that the tools were trained on. But Stable Diffusion has chosen to open source its code and share details of the database of images used to train its model.Spawning, an artist collective, has built a tool called Have I Been Trained? to help artists discover if their artworks were among the 5.8bn images used to train Stable Diffusion, and to opt in or out of appearing in future training sets. The company behind Stable Diffusion, Stability AI, has said it is open to working with the tool. Of the 1,800 artists that have signed up to use the tool already, Matthew Dryhurst, an academic and member of Spawning says it’s a 60/40 split in favour of opt-out.But the Concept Art Association (CAA) stresses that the damage has already been done this time around, because the tools have already been trained on artists’ work without their consent. “It’s like someone who already robbed you saying, ‘Do you want to opt out of me robbing you?’” says Karla Ortiz, an illustrator, and board member of CAA.Stability AI’s Emad Mostaque says that although the data used to train Stable Diffusion didn’t offer an opt-out option, it “was very much a test model, heavily unoptimised on a snapshot of images on the internet.” He says new models are typically trained on fresh datasets and this is when the company would take artists’ requests into consideration.View image in fullscreenA ‘renaissance painting of a person sitting an office cubicle, typing on a keyboard, stressed’, created by Dall-E.It’s not just artworks: analysis of the training database for Stable Diffusion has revealed it also sucked up private medical photography, photos of members of the public (sometimes alongside their full names), and pornography.Ortiz particularly objects to Stability AI commercialising part of its operation – DreamStudio, which offers customers custom models and enhanced ease of use. “These companies have now set a precedent that you use everyone’s copyrighted and private data without anyone even opting in,” she says. “Then they say: ‘We can’t do anything about it, the genie’s out of the bottle!’”What can be done about this beyond relying on the beneficence of the companies behind these tools is still in question.The CAA cites worrying UK legislation that might allow AI companies even greater freedom to suck up copyrighted creative works to train tools that can then be deployed commercially. In the US, the organisation has met government officials to speak about copyright law, and is currently in talks with Washington lobbyists to discuss how to push back on this as an industry.Beyond copycatting, there’s the even bigger issue pinpointed by Palmer: do these tools put an entire class of creatives at risk? In some cases, AI may be used in place of stock images – the image library Shutterstock recently made a deal with OpenAI to integrate Dall-E into its product. But Palmer argues that artwork such as illustration for articles, books or album covers may soon face competition from AI, undermining a thriving area of commercial art.The owners of AI image generators tend to argue that on the contrary, these tools democratise art. “So much of the world is creatively constipated,” the founder of Stability AI, Emad Mostaque, said at a recent event to celebrate a $101m fundraising round, “and we’re going to make it so that they can poop rainbows.” But if everyone can harness AI to create technically masterful images, what does it say about the essence of creativity?AI can’t handle concepts: collapsing moments in time, memory, thoughts, emotions – all of that is a real human skillAnna Ridler, an artist known for her work with AI, says that despite Dall-E 2 feeling “like magic” the first time you use it, so far she hasn’t felt a spark of inspiration in her experiments with the tool. She prefers working with another kind of AI called generative adversarial networks (GANs). GANs work as an exchange between two networks, one creating new imagery, and the other deciding how well the image meets a specified goal. An artistic GAN might have the goal of creating something that is as different as possible from its training data without leaving the category of what humans would consider visual art.These issues have intensified debate around the extent to which we can credit AI with creativity. According to Marcus du Sautoy, an Oxford University mathematician and author of The Creativity Code: How AI is Learning to Write, Paint and Think, Dall-E and other image generators probably come closest to replicating a kind of “combinational” creativity, because the algorithms are taught to create novel images in the same style as millions of others in the training data. GANs of the kind Ridler works with are closer to “transformational” creativity, he says – creating something in an entirely novel style.View image in fullscreenA Dall-E generated image of “a vintage photo of a corgi on a beach” – showing that the software can also create realistic looking images.Ridler objects to such a formulaic approach to defining creativity. “It flattens it down into thinking of art as interesting wallpaper, rather than something that is trying to express ideas and search for truth,” she says. As a conceptual artist, she is well aware of AI’s shortcomings. “AI can’t handle concepts: collapsing moments in time, memory, thoughts, emotions – all of that is a real human skill, that makes a piece of art rather than something that visually looks pretty.”AI image tools demonstrate some of these deficiencies. While “astronaut riding a horse” will return an accurate rendering, “horse riding an astronaut” will return images that look much the same – indicating that AI doesn’t really grasp the causal relationships between different actors in the world.Dryhurst and Ridler contend the “artist replacement” idea stems from underestimating the artistic process. Dryhurst laments what he sees as the media whipping up alarmist narratives, highlighting a recent New York Times article about an artist who used Midjourney to win the digital category of the Colorado state fair’s annual art competition. Dryhurst points out that a state fair is not exactly a prestigious forum. “They were giving out prizes for canned fruit,” he says. “What annoys me is that there seems to be this kind of thirst to scare artists.”“Art is dead, dude,” said the state fair winner.It is possible that the hype around these tools as disruptive forces outstrips reality. Mostaque says AI image generators are part of what he calls “intelligent media”, which represents a “one trillion dollar” opportunity, citing Disney’s content budget of more than $10bn (£8.7bn), and the entire games industry’s value of more than $170bn. “Every single piece of content from the BBC to Disney will be made interactive by these models,” he says.From ‘Barbies scissoring’ to ‘contorted emotion’: the artists using AIRead moreEmerging applications right now are more prosaic including moodboards for design consulting, storyboards for films, and mock-ups for interior design, and Mark Beccue, an analyst at Omdia’s AI division, is sceptical about the $1tn figure. “What are the killer use cases here?” he says. “It doesn’t make sense. What problem are you solving with this?” An analyst from consulting firm Accenture says the tools could one day be used to create content to train machine learning algorithms, such as in self-driving vehicles, and speed up games creation. Whether it will amount to anything as lucrative as AI image generators and their backers propose remains to be seen.Explore more on these topicsArtificial intelligence (AI)The ObserverComputingIllustrationfeaturesShareReuse this contentMost viewedLiveUS elections: Kamala Harris to make first speech since Biden endorsement as more top Democrats back VP – live updatesFrance Unbowed MP sparks outrage by saying Israeli Olympians not welcome The post-Biden era may be uncertain for the Democrats, but for Trump it will be utterly dismayingSimon TisdallWhat is the Kamala Harris coconut tree meme and why is everyone sharing it?You’ve heard of nepo babies, but what about nepo dogs? The rise of the Very Important Pooch",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vdW5jaGFydGVkdGVycml0b3JpZXMudG9tYXNwdWV5by5jb20vcC9nZW5lcmF0aXZlLWFpLWV2ZXJ5dGhpbmcteW91LW5lZWTSAQA?oc=5,Generative AI: Everything You Need to Know - by Tomas Pueyo - Uncharted Territories,2022-11-15,Uncharted Territories,https://unchartedterritories.tomaspueyo.com,And How to Use it for Your Career and Industry,N/A,And How to Use it for Your Career and Industry,And How to Use it for Your Career and Industry,https://schema.org,NewsArticle,https://unchartedterritories.tomaspueyo.com/p/generative-ai-everything-you-need,,N/A,N/A,"Share this postGenerative AI: Everything You Need to Knowunchartedterritories.tomaspueyo.comCopy linkFacebookEmailNoteOtherDiscover more from Uncharted TerritoriesUnderstand the world of today to prepare for the world of tomorrow: AI, tech; the future of democracy, energy, education, and moreOver 93,000 subscribersSubscribeContinue readingSign in  Generative AI: Everything You Need to KnowAnd How to Use it for Your Career and IndustryTomas PueyoNov 15, 202263Share this postGenerative AI: Everything You Need to Knowunchartedterritories.tomaspueyo.comCopy linkFacebookEmailNoteOther26ShareAI is not tomorrow, it’s today.You better wake up and get on it. If you don’t, others will learn to use AI tools before you, increase their productivity, take your job or your company, and leave you in the dust. Instead, you can quickly get up to speed and bring the future to the present.A few weeks ago, I didn’t know that much about Generative AI. Since then, I’ve spent days studying it. I’ve summarized it all in two articles. This is the first one, to get up to speed quickly. You’ll get:Examples of the latest in Generative AI, so you start forming an idea of what you could do with it.A mental framework for how to think about AI.The most common AI tools today.Buckle up!SubscribeThe Cambrian Explosion of Generative AIThe Crow, an AI movie, won the Cannes festival this year in the category of short films.And this is just the beginning. This movie has the eerie artifacts of early AI, and required a dancer as a baseline, to modify into a crow’s movements. But if it can do this now, what will it do tomorrow?Look at this video:Jon Finger @mrjonfingerAnother Ai filmmaking experiment.
Every pixel you see and voice you hear is generated by AI.
Apps:
Images: @midjourney 
Voices: altered ai
Faces motion: Reface app
Camera movement: PopPic app 9:12 PM ∙ Jul 27, 2022701Likes139RetweetsThese guys took AI-generated images through Midjourney, animated the faces with Reface, panned the camera through PopPic, and altered voices through Altered.ai.Or this one:Runway @runwaymlIntroducing AI Magic Tools

Dozens of creative tools to edit and generate content like never before. New tools added every week.

Available now: runwayml.com 1:06 PM ∙ Oct 12, 20223,630Likes533RetweetsIf this type of stuff gets you excited, scared, and a bit lost, good. By the end of the article, you should only feel excited. For that, let’s jump to the core of Generative AI, the type of AI that generates new things rather than process existing data. How should you think about it?AI has three main components: text, images, and sound. Then, each piece can be further divided and combined. For example, video is a set of linked images, with a combination of two types of sounds, music and speech. TextAt the core of everything is text, because it is the closest to thinking. If you want to chat with an AI, ask it questions, create a relationship with it, or create realistic characters, the core is a text-based AI.ConversationThe most famous is GPT-3, from OpenAI, the most advanced Generative AI company today, also behind other advanced AI models like Whisper and DALL-E (we’ll talk about them in detail). There are also other models, like PaLM and LaMDA1.If you’ve seen people chatting with AIs and getting confused about whether they are alive or not, odds are they were talking with one of the three. Here’s an example that I shared in the August 2022 Updates article:Mr Lemoine, who started advocating for the rights of the AI, was suspended by Google.Here’s one way somebody used GPT-3 to brainstorm business ideas, and then asks it to tell him about possible downsides, to refine the ideas.fabians.eth @fabianstelzerI use GPT-3 daily as a brainstorming scratch pad

an always-on sparring partner to run ideas by

feed it what you're working on, let it spit back insights and objections

say you're thinking about starting an AI media startup:  Austen Allred @AustenEveryone is overestimating how humanlike AI & GPT-3 are.

Think of each prompt as a Google search. GPT-3 synthesizes and rewrites the top pages. Very cool!

But it’s not making decisions or having emotion, it’s simply regurgitating what’s in the data set (books/articles about x). https://t.co/afL1yQnMzL7:54 PM ∙ Aug 22, 2022201Likes22RetweetsA few years ago, there was a frenzy of AI chatbots. They didn’t succeed, because they were dumb. They were dumb, because GPT-3 was not here. Now the AI is getting good enough.You can play with GPT-3 today. It has dozens of use cases, like:Join GPT-3, which I used for the first time last week.Here are some examples of companies working in the space2:Write text for you: emails, ads, articles… Companies doing this include Jasper3,  Copy.ai4, Writer, Writesonic, Peppertype, Hypotenuse, Anyword, Copysmith, Scalenut, Postearly, Lex, Rytr5… Mem6 can write and rewrite text for you. Sudowrite is focused on literature, and helps authors express themselves more poignantly. Summari summarizes text. Explainpaper.com does the same for scientific papers. A godsend. Otter and Fireflies transcribe meetings on top of summarizing them for you. Character.ai created a marketplace for bots. It’s not hard to see where this is going: The future of this is the perfect personal assistant, coach, friend, or partner for every one of us. You might have noticed other interesting use cases in the list I showed above. For example… coding?!CodingIndeed, coding can be seen as just translating between a human language and a machine language. Anything that GPT-3 can do for human language, it can do for coding. You can do all sorts of coding with AI, from auto-completing your code, to asking it to explain a piece of code you don’t understand, all the way to simply generating full pieces of code, like in Replit’s7 Ghostwriter.This is the transform use case. They have great examples of their other use casesWhen the code is complex, the AI isn’t there yet. But a large proportion of code is not that complex. That’s what AI can do better and faster than humans.Here’s an example of AI-enhanced coding by GitHub CoPilot:Apparently, for the developers who’ve enabled it, 40% of their code is written by CoPilot. Imagine the productivity improvements!This doesn’t need to be limited to pure coding. Pull requests can be automated. And any language works, like automating spreadsheet formulas.Shubhro Saha @shubroskiThis weekend I built =GPT3(), a way to run GPT-3 prompts in Google Sheets.

It's incredible how tasks that are hard or impossible to do w/ regular formulas become trivial.

For example: sanitize data, write thank you cards, summarize product reviews, categorize feedback... 5:37 PM ∙ Oct 31, 202221,402Likes2,934RetweetsA more standard use case for text-to-text is translation. Here, the surprising piece is not the concept, but how good it is.Transcription and TranslationIn fact, OpenAI has an AI specifically focused on translation, Whisper, which it released less than two months ago. And it turns out it’s not just good at translation between languages; it’s also amazing at transcription from speech to text. If you think about it, it makes sense, since writing and speech can be seen as just different languages. For those who’ve used it, it’s unbelievable.Harry Ramsay @harry_ramsayOpenAI's Whisper is by far the best transcription software I've ever come across. It's not perfect, but on the highest quality model, it's usually 99+% accurate, and it works even with background noise or fast speakers. The demos are unbelievable.

openai.comIntroducing WhisperWe’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech recognition. Read Paper View Code View Model Card Whisper examples: Reveal Transcript Whisper is an automatic speech recogn…9:00 PM ∙ Nov 10, 2022Go to Whisper to see demos.You know how digital assistants are annoying because they don’t understand what you say? Well, if Whisper works as intended, that problem is in the past. Whisper can understand speech much better than Siri, any other AI you’ve used, or even humans, whether there’s background noise or not, and in many languages, and it can also translate between virtually any language. It’s not open yet, but you can play with it for free as a developer. The options are infinite. Here are some:You can use it as a standard transcript tool.To create a pdf transcript of a youtube video, or automatically add captions.To create subtitles in other languages.To automatically record a meeting, transcribe it with Whisper, and summarize it with GPT-3, so that every meeting can be easily digested by anybody.Do the same for medical conversations, where an AI can suggest ideas for diagnoses in real time Translate conversations in near-real time!This leads us to the second big area of Generative AI after text: speech and sound.SoundWhen translating speech between languages, you have different steps: Converting the sounds into intelligible speech, transcribing into the same language, translating into the other language, and then synthesizing the new words into speech.This means you need to go from sound to text and text to sound. Each of these has its own use cases.SpeechOne of the most famous tools in the text-speech vertical is Descript, which I’ve used recently for the podcasts I’ve recorded. It creates a good transcript of what you said8. But the magic is not from speech to text. It’s the other way around: You can edit the transcript, and it automatically edits the words coming from your mouth! You can rewrite words, and it will say those words for you, in your voice! It can do the same for video apparently, but I didn’t try. Adobe is trying to do something similar for podcasts. Reduct does it for video.Along the lines of text to speech, with Murf AI you can write any text and it will read it for you in different voices, or you can have it clone your voice. Here’s a quick demo I made:Wellsaid also allows you to go from text to speech. What about speech in videos? Creating subtitles is becoming trivial, and many companies already offer it. So the most innovative companies focus on other areas. Papercup automatically dubs videos in other languages. Voicemod and Koe Recast allow streamers to change their voice in real time. I couldn’t use it to clone my voice, but Resemble.ai allowed me to do it. It left me… speechless. It was me! The first time I heard it, for an instant I forgot that it was an AI who had produced it. I thought I had recorded it myself.Coqui.ai is trying to become a full AI audio studio: Turn text into voice, and then direct the voice’s timbre, tempo, tone, enunciation, emotion, pitch, prosody, rate, duration, contour… Why would you record sound in the future, when it’s easier to create it from scratch?The most interesting uses are appearing at the fringes of what’s possible. Podcast.ai took the world by storm when it created an entire podcast episode between Joe Rogan and Steve Jobs9. You’d imagine you can barely listen to these podcasts, but in fact they’re reasonable. The voices and intonations are quite accurate, the people are articulate, the topics are right… It’s far from the real thing, still in the uncanny valley, but it’s shockingly closer than I expected. Give it a few more years, and where is this going to go? Live conversations with any person you might want to talk with.So far, we’ve discussed speech. But there are other sounds that are possible. Most obviously, music. MusicDo you want to add a soundtrack? You can create it from scratch, from text to music! In this link, you can see somebody who created a tool where you put a prompt (like “astronaut riding a horse”), a few tags (like “space, saxophone, travel”), and it creates a pretty good soundtrack for it!AK @_akhaliqMubert-Text-to-Music 🎵🎵🎵

Colab notebooks demonstrating prompt-based music generation via Mubert API

GitHub: github.com/MubertAI/Muber… 8:06 PM ∙ Oct 19, 20224,753Likes1,285RetweetsI created a few samples with Soundraw.io. If they’re truly created with AI, they sound surprisingly good! Better than this. Image-to-music is definitely not there yet.This is still in its infancy, but you can imagine we’re not far away from truly great AI-generated soundtrack music with prompts. Jukebox, from OpenAI, has crazy samples including vocals!Sound EffectsThe same thing is starting with sound effects, with at least a couple of companies. Once this works well, can you imagine how amazing that would be for sound editors? How many millions of sounds do you need to have the perfect one for every single situation? And even if you have an ample library, it might not be the perfect sound to fit every video. Creating it from scratch would be much better.These are some of the principles for speech and text. Now let’s move to another sense: the world of visuals.ImagesText to ImagesThis is the most famous one. If you already know a lot about it, just jump to the next section. For those of you who want a quick summary of where we’re at in image generation, keep reading.An AI won the top prize in a painting competition.​The images that AIs can generate are incredible.Every single one of the pictures below was generated by an AI:It works by giving an AI a text prompt, and the AI creates an image that corresponds to that.The first AI to do this was DALL-E, and its successor, DALL-E 2 (you can access the API). But only a few people could access these. Since then, new, more open models have appeared, like Stable Diffusion and Midjourney. You can try some of these tools for free from your browser, like Midjourney, Craiyon10, Stable Diffusion through the Dream Studio tool, photosonic, or Hugging Face. You can also download DiffusionBee to run Stable Diffusion on your computer for free, no technical knowledge needed. Here’s what Midjourney 3 gave me when I asked it for Roman soldiers harvesting11:After some iterations and a lot of work, I got this:These models improve all the time. For example, I just reran the same prompt in the new version of Midjourney, and got this on my first attempt:Not there yet, but this is on my first attempt, and with no additional work whatsoever. Here are some pictures that people have made, with a bit more work:Midjourney CommunitySometimes it’s hard to find the right prompts for great images. Some tools are emerging to help: Here’s a prompts guide, and the official one for Midjourney. Other tools allow you to look at amazing pictures that others have created and the prompts they used. You can use Lexica, krea.ai, arthub.ai, Playground.ai, or Promptomania12.Or, if it’s too hard, simply use GPT-3 to come up with better prompts!Tools like Stable Diffusion and Midjourney allow you to go from text to image. In a way, what Lexica and Promptomania do is go from images to text. But you can also go from image to image.Image to ImageCompanies like Snapchat have already been using AI to edit pictures on the fly. Plenty other tools have appeared to do that, like:Image Enlarger increases definition to your pictures.Autoenhance enhances them automatically.Remove eliminates backgrounds from images for free.Magic Eraser deletes elements in a picture.PhotoRoom combines both: element deletion and background elimination (and also allows you to blur backgrounds).This tool allows you to create realistic-looking people.You can take pictures of people or things and put them inside different scenes.You can try different hairstyles.You can take pictures and modify them with a prompt.Some companies try to combine several of these tools, like ClipDrop, which allows you to remove backgrounds, persons, and text, upscale pictures, and change the light.Product Hunt 😸 @ProductHuntStill can't get over @clipdropapp's mindblowing tech 🤯 7:00 AM ∙ Nov 2, 202215,444Likes2,395RetweetsOther tools allow you to go from a rough sketch to a higher fidelity one in seconds:Adam Howell @_adamhowellSupport for #stablediffusion init images and sketch-to-image is now live on @accomplice_ai

Upload an image – or sketch directly in Accomplice – type something like “detailed sketch of a red eye on white background, illustration” and in 30 secs you've got production-ready results 4:17 PM ∙ Aug 26, 2022284Likes46RetweetsYou have inpainting and outpainting, where the AI allows you to expand your image, or redo some parts of it.William Buchwalter @wbuchwOutpainting a miniature village with #stablediffusion 4:37 PM ∙ Sep 2, 2022482Likes49RetweetsWilliam Buchwalter @wbuchwCombining @StabilityAI #StableDiffusion generative powers + Human guidance and graphic skills* with tools like @Photoshop in a coherent workflow.

 * Of which I've got about 0 as can be seen below. 1:51 PM ∙ Aug 26, 20223,358Likes967RetweetsYou can also sketch images and get much better ones with a prompt:What you’re doing there is simply nudging the AI in the direction of your image.Or you can iterate with your AI, and add images and inpainting to direct a specific image you might have in mind.AK @_akhaliqstable diffusion img2img web UI + workflow video

github: github.com/hlky/stable-di…
reddit thread: reddit.com/r/StableDiffus… 5:42 PM ∙ Aug 27, 20225,858Likes1,069RetweetsDesignMany of these tools, if slightly adjusted, can be used by designers.You can Create a color palette based on a concept.Come up with icons.Or patterns.Or tiles.Create textures.Add textures to a 3D model.You can also create products from scratch:Antonio Cao @RemitNotPaucityGonna ship a Figma plugin to go from prompts + simple shapes to design ideas using #stablediffusion #aiart 6:00 AM ∙ Aug 24, 20228,323Likes1,453RetweetsOr 3D objects:Ben Poole @poolioHappy to announce DreamFusion, our new method for Text-to-3D!

dreamfusion3d.github.io

We optimize a NeRF from scratch using a pretrained text-to-image diffusion model. No 3D data needed!

Joint work w/ the incredible team of @BenMildenhall @ajayj_ @jon_barron
#dreamfusion 8:01 PM ∙ Sep 29, 20225,859Likes1,557RetweetsSo you can go from text to text, text to image, image to text, image to image… And since videos are just images in a sequence, the obvious next step is video.VideoVideo is the hardest, but it’s also the end goal. And progress there is every bit as exciting. Taking this idea of videos as combinations of images, you can easily create storyboards:SALT @SALT_VERSE🧂is a play-to-create experiment. 

To participate:

▫️ watch 🔊
▫️ vote below
▫️ QT '🧂' for some sort of register 4:04 PM ∙ Jun 16, 2022220Likes21RetweetsYou can isolate backgrounds and change them on the fly.Patrick Esser @pess_r#stablediffusion text-to-image checkpoints are now available for research purposes upon request at github.com/CompVis/stable…

Working on a more permissive release & inpainting checkpoints.

Soon™ coming to @runwayml for text-to-video-editing 12:03 AM ∙ Aug 11, 20224,849Likes1,240RetweetsAlso here.NeRFsOr simply create 3D environments!nerfstudio @nerfstudioteamAnimating focal lengths now enabled in nerfstudio 🔭

Check out this capture from Egypt using nothing but a phone 🐫

#NeRF #nerfacto #AIart #neuralrendering #pyramids #Egypt 5:42 AM ∙ Nov 7, 2022819Likes123RetweetsNeRFs (“Neural Radiance Field) are a type of AI that can take a set of 2D images and create a 3D environment based on them. Then, you can move your camera around that 3D environment. It’s brutal.Karen X. Cheng @karenxcheng1/ Now you can create ""drone"" shots from your phone footage, thanks to NeRF
Collab with @justLV / software @nerfstudioteam / see below for our process
 #NeRF #neuralrendering #artificialintelligence #instantNeRF 3:19 PM ∙ Oct 25, 20226,791Likes1,187RetweetsThis was not created with a drone! It’s just taking pictures with a phone, which then creates the scene!Franc Lucent @franclucent(1/2) Whenever I go to a new city, I always try and look for a botanical garden. They're calming, a great place to think or get some reading done, and usually well maintained. I wasn't sure how this would come out in #NeRF, but stepping into the middle of a greenhouse, the light 7:14 PM ∙ Nov 10, 2022217Likes22RetweetsWhat about creating full-blown universes with AI? Like this one, where an AI created a 3D model of a city, and an AI converted it into Manga-style13?佐藤航陽 🌎 著書「世界2.0 メタバースの歩き方と創り方」 @ka2aki86AIに3Dモデルを自動生成させた後に、空間を漫画風に変換して、さらに色をつけてアニメ風にしてみた。『君の名は』風・ジブリ風・ディズニー風のメタバースとかもAIが自由自在に表現できるようにしていきたい。 2:48 PM ∙ Nov 13, 20221,062Likes257Retweets3D ObjectsYou can also extract objects and create 3D versions of them.nerfstudio @nerfstudioteamv0.1.9 Released 🎉

NeRF -> Point cloud export is now available ☁️

#NeRF #pointcloud #nerfacto 7:09 AM ∙ Nov 11, 2022564Likes86RetweetsOr create them from scratch:Ben Desai @DesignInVrFor all the indecisive creatives out there: 🤯 #ai #dalle2 @kaedim3d #procreate @Procreate @OpenAI 2:04 PM ∙ Aug 12, 2022428Likes62RetweetsYou can try them on:ARthur Bouffard @arthurbfrdI created a photo-realistic AR try-on experience in less than 1 hour using AI & ML

Seeing how easy the process is, here’s a breakdown on how you can make this too🧵 (1/7) 5:10 PM ∙ Nov 13, 20221,790Likes267RetweetsAnd make them come to life:Sergei Galkin @sergeyglkn1/6 
How I transferred a physical toy to the digital world in one hour with AI

-> LumaAI (3D scan)
-> Cinema4D (editing)
-> Mixamo (rigging and animation)
-> MetaSparkStudio (AR) 1:05 PM ∙ Nov 1, 202222,469Likes3,902RetweetsAnd with humans too!HumansI created this video in 10 minutes with an iOS app from a company called Scandy. It gets you one free scan per week. Then you can act something out, and put a character on top of it:Scott Lighthiser @LighthiserScott@StableDiffusion Img2Img x #ebsynth  x @koe_recast  TEST

#stablediffusion #AIart 3:32 AM ∙ Sep 7, 20223,758Likes761RetweetsOr today.And if you already have footage you want to just slightly edit to fit some changes, you can do that. For example for dubbing in other languages. Now the mouth fits the language14.All of this is image to video, or video to video. But there’s also text to video!Every video here was generated based on prompts. To see more of these, go to Imagen Video. That was the Google version. Here’s the Facebook version.Even longer-form video!Sundar Pichai @sundarpichai1/ From today's AI@ event: we announced our Imagen text-to-image model is coming soon to AI Test Kitchen. And for the 1st time, we shared an AI-generated super-resolution video using Phenaki to generate long, coherent videos from text prompts and Imagen Video to increase quality. 6:21 PM ∙ Nov 2, 202210,508Likes1,561RetweetsYou can direct characters and tell them what to do… with text.80 LEVEL @80LevelA group of researchers presented Motion Diffusion Model (MDM), a new diffusion-based generative model capable of generating human motions from text prompts.

Details: 80.lv/articles/mdm-a…
#AI #ArtificialIntelligence #research #animation 8:32 AM ∙ Oct 4, 20221,179Likes257RetweetsWith Hour One, Synesthesia, Rephrase.ai, and Jali, you can write stuff, and a human-looking AI will say it for you.Some companies are trying to put everything in one place. From what I could find, Runway is the one company trying to create the perfect video editing tool, with AI inserted everywhere—the first tweet in this section is from them. You can remove backgrounds, snap images to sounds, reduce noise from images, complete scenes that you never filmed, get video from text prompts… All this help can reduce editing work by 60x.Others like DeepBrain create AI avatars for you, from visuals to voice.This stuff is not science fiction. The Amazon Prime show Peripheral used Midjourney to texturize some actors.TakeawaysSo that’s a review of all the big elements we’re seeing in generative AI: text, images, speech, sounds, video, and all their connections. According to the VC firm Sequoia, this is what it all looks like:And here is Sequoia’s latest summary of companies working in the space.Who do you know that needs to learn about Generative AI? Send them this article.ShareI’m very interested in this, so please send my way any piece that I have missed. And if you know an interesting company in the space, I want to hear about it!Now the question becomes: How will your industry change based on AI? Your job? What new industries are going to appear? In tomorrow’s—premium—article, I’ll explore how different industries will change: writing, illustration, design, scientific research, marketing, sales, videogames, movies, investing… But also, how new industries will finally explode, like personal assistants and talking with the departed. Subscribe to read it!Subscribe1 If you’re accepted, you can use Google LaMDA’s Test Kitchen.2This list will get stale fast. The idea is not to be up to date, but rather give you a glimpse of what’s happening.3It raised $130M from the likes of Coatue and Bessemer at a $1.5B valuation4With investors like Sequoia, Tiger and others.5Some companies started even before this trend and have done a pretty good job. The most typical example is corrections.Grammarly is the most famous company in the space, and is worth $13B.6 In fact it’s a personal assistant, but that use case sounds awfully hard to me to start with. I assume the copy editing is easier and better to start with, which is why I highlight it.7Note: Replit ran a crowdfunding round and I participated. I am a big fan of their project!8Although I’m hearing it’s not as good as Whisper.9They’ve released another episode between Lex Friedman and Richard Feynman since.10 Works less well for me.11The actual prompt was: “two roman soldiers harvesting wheat on a field. A third soldier is riding an idle horse and watching the scene. Two villagers are running away in the distance towards a forest that is far away. Hyperrealistic, 8k, unreal engine”12 There are also prompt guides for DALL-E, DALL-E 2, Stable Diffusion.13Translation: ""After having AI automatically generate a 3D model, I converted the space into a manga style, and then added colors to make it look like an anime. I want to make it possible for AI to freely express things like ""Your Name""-style, Ghibli-style, and Disney-style metaverses.""14After spending 15 years in the US, dubbing looks weird to me. But growing up in Europe, it was the norm. So if you look at this and get weirded out, consider you might have the chance of not usually needing dubbing. Correcting the mouths is amazing for those who don’t have that luck. And although today it’s a bit weird, you can imagine it getting quite good, fast. Subscribe to Uncharted TerritoriesBy Tomas Pueyo · Thousands of paid subscribersUnderstand the world of today to prepare for the world of tomorrow: AI, tech; the future of democracy, energy, education, and moreSubscribe63 Likes63Share this postGenerative AI: Everything You Need to Knowunchartedterritories.tomaspueyo.comCopy linkFacebookEmailNoteOther26Share",Generative AI: Everything You Need to Know,2022-11-15T05:30:53-05:00,2022-11-15T05:30:53-05:00,,"[{'@type': 'Person', 'name': 'Tomas Pueyo', 'url': 'https://substack.com/@tomaspueyo', 'description': 'Understand the biggest problems and how to solve them: AI; automation; GeoHistory; the future of education, healthcare, violence, nation-states, communities, energy, transportation, and more', 'identifier': 'user:5362415', 'sameAs': ['https://twitter.com/tomaspueyo'], 'image': {'@type': 'ImageObject', 'contentUrl': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F32cecf91-f0da-4d20-b82f-c9e8ae5e0d89_1600x1600.png', 'thumbnailUrl': 'https://substackcdn.com/image/fetch/w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F32cecf91-f0da-4d20-b82f-c9e8ae5e0d89_1600x1600.png'}}]","{'@type': 'Organization', 'name': 'Uncharted Territories', 'url': 'https://unchartedterritories.tomaspueyo.com', 'description': 'Understand the world of today to prepare for the world of tomorrow: AI, tech; the future of democracy, energy, education, and more', 'interactionStatistic': {'@type': 'InteractionCounter', 'name': 'Subscribers', 'interactionType': 'https://schema.org/SubscribeAction', 'userInteractionCount': 10000}, 'identifier': 'pub:347533', 'logo': {'@type': 'ImageObject', 'url': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc92decb6-7c5c-4053-bc05-651e5548e9b3_1280x1280.png', 'contentUrl': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc92decb6-7c5c-4053-bc05-651e5548e9b3_1280x1280.png', 'thumbnailUrl': 'https://substackcdn.com/image/fetch/w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc92decb6-7c5c-4053-bc05-651e5548e9b3_1280x1280.png'}, 'image': {'@type': 'ImageObject', 'url': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc92decb6-7c5c-4053-bc05-651e5548e9b3_1280x1280.png', 'contentUrl': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc92decb6-7c5c-4053-bc05-651e5548e9b3_1280x1280.png', 'thumbnailUrl': 'https://substackcdn.com/image/fetch/w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc92decb6-7c5c-4053-bc05-651e5548e9b3_1280x1280.png'}, 'sameAs': ['https://twitter.com/tomaspueyo']}","[{'@type': 'ImageObject', 'url': 'https://substackcdn.com/image/upload/w_1028,c_limit,q_auto:best/kxx9oksq5wwxkt5u9e74'}]",,https://unchartedterritories.tomaspueyo.com/p/generative-ai-everything-you-need,True,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMjIvMTEvMTQvMTA2MzE5Mi93ZXJlLWdldHRpbmctYS1iZXR0ZXItaWRlYS1vZi1haXMtdHJ1ZS1jYXJib24tZm9vdHByaW50L9IBcGh0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMjIvMTEvMTQvMTA2MzE5Mi93ZXJlLWdldHRpbmctYS1iZXR0ZXItaWRlYS1vZi1haXMtdHJ1ZS1jYXJib24tZm9vdHByaW50L2FtcC8?oc=5,We’re getting a better idea of AI’s true carbon footprint - MIT Technology Review,2022-11-14,MIT Technology Review,https://www.technologyreview.com,AI startup Hugging Face has undertaken the tech sector’s first attempt to estimate the broader carbon footprint of a large language model.,,AI startup Hugging Face has undertaken the tech sector’s first attempt to estimate the broader carbon footprint of a large language model.,AI startup Hugging Face has undertaken the tech sector’s first attempt to estimate the broader carbon footprint of a large language model.,http://schema.org,Organization,https://www.technologyreview.com/2022/11/14/1063192/were-getting-a-better-idea-of-ais-true-carbon-footprint/,,N/A,N/A,N/A,We’re getting a better idea of AI’s true carbon footprint,2022-11-14T12:17:13-05:00,2022-11-15T09:27:33-05:00,"https://wp.technologyreview.com/wp-content/uploads/2022/11/nuclear-power-BLOOMa.jpeg?resize=854,569","{'@type': 'Person', 'name': 'Melissa Heikkilä'}","{'@type': 'Organization', 'name': 'MIT Technology Review', 'logo': {'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/themes/mittr/client/src/images/logo.png', 'width': 203, 'height': 100}}","{'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/uploads/2022/11/nuclear-power-BLOOMa.jpeg?resize=854,569', 'height': 569, 'width': 854}",,"{'@type': 'WebPage', '@id': 'https://www.technologyreview.com/2022/11/14/1063192/were-getting-a-better-idea-of-ais-true-carbon-footprint/'}",,2022-11-14T12:17:13-05:00,Artificial intelligence,1157.0,"{'@type': 'Person', 'name': 'Melissa Heikkilä'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Artificial intelligence', 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/topic/artificial-intelligence/'}}, {'@type': 'ListItem', 'position': 2, 'name': 'We’re getting a better idea of AI’s true carbon footprint', 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/2022/11/14/1063192/were-getting-a-better-idea-of-ais-true-carbon-footprint/'}}]",MIT Technology Review,"{'@type': 'PostalAddress', 'addressLocality': 'Cambridge, MA, USA', 'postalCode': '02142', 'streetAddress': '1 Main Street'}",,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3Lm1hcmt0ZWNocG9zdC5jb20vMjAyMi8xMS8xNC9ob3ctZG8tZGFsbCVDMiVCN2UtMi1zdGFibGUtZGlmZnVzaW9uLWFuZC1taWRqb3VybmV5LXdvcmsv0gFmaHR0cHM6Ly93d3cubWFya3RlY2hwb3N0LmNvbS8yMDIyLzExLzE0L2hvdy1kby1kYWxsJUMyJUI3ZS0yLXN0YWJsZS1kaWZmdXNpb24tYW5kLW1pZGpvdXJuZXktd29yay8_YW1w?oc=5,"How Do DALL·E 2, Stable Diffusion, and Midjourney Work? - MarkTechPost",2022-11-14,MarkTechPost,https://www.marktechpost.com,"How Do DALL·E 2, Stable Diffusion, and Midjourney Work? The technology behind DALL·E 2. Comparison between DALL·E 2, Stable Diffusion and Midjourney",N/A,"Over the last few years, many advancements have been made in Artificial Intelligence (AI), and one of the new additions to AI is AI Image Generator. It is a tool capable of converting an input statement into a picture or painting. There are many options for text-to-image AI tools, but the ones that stand out are DALLE 2, Stable Diffusion, and Midjourney. DALL·E 2 DALL·E 2 is an AI program created by OpenAI that creates images from textual descriptions. Using more than 10 billion parameter training versions of the GPT-3 transformer model, it interprets natural language inputs and generates the","Over the last few years, many advancements have been made in Artificial Intelligence (AI), and one of the new additions to AI is AI Image Generator. It is a tool capable of converting an input statement into a picture or painting. There are many options for text-to-image AI tools, but the ones that stand out are DALLE 2, Stable Diffusion, and Midjourney. DALL·E 2 DALL·E 2 is an AI program created by OpenAI that creates images from textual descriptions. Using more than 10 billion parameter training versions of the GPT-3 transformer model, it interprets natural language inputs and generates the",https://schema.org,BreadcrumbList,,,N/A,N/A,"


How Do DALL·E 2, Stable Diffusion, and Midjourney Work?

By Arham Islam -   November 14, 2022 



RedditVoteFlipShareTweet0 Shares
Over the last few years, many advancements have been made in Artificial Intelligence (AI), and one of the new additions to AI is AI Image Generator. It is a tool capable of converting an input statement into a picture or painting. There are many options for text-to-image AI tools, but the ones that stand out are DALLE 2, Stable Diffusion, and Midjourney.
DALL·E 2
DALL·E 2 is an AI program created by OpenAI that creates images from textual descriptions. Using more than 10 billion parameter training versions of the GPT-3 transformer model, it interprets natural language inputs and generates the corresponding image.
  Join the Fastest Growing AI Research Newsletter Read by Researchers from Google + NVIDIA + Meta + Stanford + MIT + Microsoft and many others...


An expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula – created using DALLE 2
Stable Diffusion
Stable Diffusion is a text-to-image model that uses a frozen CLIP ViT-L/14 text encoder to tune the model at text prompts. It separates the imaging process into a “diffusion” process at runtime- it starts with only noise and gradually improves the image until it is entirely free of noise, progressively approaching the provided text description.

A pikachu fine dining with a view to the Eiffel Tower – generated by Stable Diffusion
Midjourney
Midjourney is another AI-powered tool that generates images from user prompts. MidJourney is proficient at adapting actual art styles to create an image of any combination of things the user wants. It excels at creating environments, especially fantasy and sci-fi scenes, with dramatic lighting that looks like rendered concept art from a video game.
  [Synthetic Data Webinar] Learn how Gretel’s synthetic data platform, powered by generative AI, make’s data generation easier than ever before: July 30, 2024 | 9:00 am PT, 12:00 pm ET 


                          Cloud Castle at night, cinematic – created by Midjourney
The technology behind DALL·E 2
DALL·E 2 primarily consists of 2 parts – one to convert the user input into the representation of an image (called Prior) and another to convert this representation into an actual photo (called Decoder).

                    Source: https://www.youtube.com/watch?v=F1X4fHzF4mQ
The text and image embeddings used come from another network called CLIP (Contrastive Language-Image Pre-training), also created by OpenAI. CLIP is a neural network that returns the best caption for an input image. It does the opposite of what DALLE 2 does – text-to-image conversion. The objective of CLIP is to learn the connection between the visual and textual representation of an object.


DALL·E 2’s goal is to train two models. The first is Prior, trained to take text labels and create CLIP image embeddings. The second is the Decoder, which takes the CLIP image embeddings and produces a learned image. After training, the workflow of inference looks like this:

The entered caption is transformed into a CLIP text embedding using a neural network.
Prior reduces the dimensionality of the text embedding using Principal Component Analysis or PCA.
Image embedding is created using the text embedding.
In the decoder step, a diffusion model is used to transform the image embedding into the image.
The image is upscaled from 64×64 to 256×256 and then finally to 1024×1024 using a Convolutional Neural Network.

The technology behind Stable Diffusion
Stable Diffusion is powered by Latent Diffusion Model (LDM), a cutting-edge text-to-image synthesis technique. Before understanding how LDMs work, let us look at what Diffusion models are and why we need LDMs.
Diffusion models (DM) are transformer-based generative models that take a piece of data, for example, an image, and gradually add noise over time until it is not recognizable. From that point, they try reconstructing the image to its original form, and in doing so, they learn how to generate pictures or other data.
The issue with DMs is that the powerful ones often consume hundreds of GPU days, and inference is quite expensive due to sequential evaluations. To enable DM training on limited computational resources without compromising their quality as well as flexibility, DMs are applied in the latent space of powerful pre-trained autoencoders. 
Training a diffusion model on such a representation makes it possible to achieve an optimal point between complexity reduction and detail preservation, significantly improving visual fidelity. Introducing a cross-attention layer to the model architecture turns the diffusion model into a powerful and flexible generator for generally conditioned inputs such as text and bounding boxes, enabling high-resolution convolution-based synthesis.
How does Midjourney work?
Midjourney is an AI image generation tool that takes inputs through text prompts and parameters and uses a Machine Learning (ML) algorithm trained on a large amount of image data to produce unique images. 
Midjourney is currently only accessible via the Discord bot on their official Discord. The user generates the image using the ‘/imagine’ command and enters the command prompt like any other AI art generator tool. The bot then returns a snap.



Comparison between DALL·E 2, Stable Diffusion and Midjourney
DALL·E 2 has been trained on millions of stock images, making its output more sophisticated and perfect for enterprise use. DALL·E 2 produces a much better picture than Midjourney or Stable Diffusion when there are more than two characters.
Midjourney, on the other hand, is a tool best known for its artistic style. Midjourney uses its Discord bot to send as well as receive calls to AI servers, and almost everything happens on Discord. The resulting image rarely looks like a photograph; it seems more like a painting.
Stable Diffusion is an open-source model accessible to everyone. It also has a relatively good understanding of contemporary artistic illustration and can produce highly detailed artwork. However, it needs an interpretation of the complex original prompt. Stable Diffusion is excellent for intricate, creative illustrations but falls short when creating general images such as logos.
The below prompts help to understand the similarities and differences between each model.










Don’t forget to join our Reddit page and discord channel, where we share the latest AI research news, cool AI projects, and more. 
References:

https://medium.com/mlearning-ai/dall-e2-vs-stable-diffusion-same-prompt-different-results-e795c84adc56
https://medium.com/geekculture/what-is-dalle-2-what-to-know-before-trying-the-groundbreaking-ai-e7a585f2edf0
https://stability.ai/blog/stable-diffusion-public-release
https://www.dexerto.com/entertainment/what-is-midjourney-new-ai-image-generator-rivals-dall-e-1864522/
https://medium.com/nightcafe-creator/stable-diffusion-tutorial-how-to-use-stable-diffusion-157785632eb3
https://interestingengineering.com/innovation/stability-ai-uses-latent-diffusion-models-to-allow-users-to-create-art-in-stable-diffusion
https://medium.com/augmented-startups/how-does-dall-e-2-work-e6d492a2667f
https://medium.com/codex/a-quick-look-under-the-hood-of-stable-diffusion-open-source-architecture-2f07fc1e729
https://stepico.com/blog/midjourney-as-an-artificial-intelligence-system/
https://www.dexerto.com/entertainment/what-is-midjourney-new-ai-image-generator-rivals-dall-e-1864522/
https://petapixel.com/2022/08/22/ai-image-generators-compared-side-by-side-reveals-stark-differences/
https://analyticsindiamag.com/stable-diffusion-vs-midjourney-vs-dall-e2/
https://medium.com/mlearning-ai/dall-e-2-vs-midjourney-vs-stable-diffusion-8eb9eb7d20be



 Arham IslamI am a Civil Engineering Graduate (2022) from Jamia Millia Islamia, New Delhi, and  I have a keen interest in Data Science, especially Neural Networks and their application in various areas.Pinterest Researchers Present an Effective Scalable Algorithm to Improve Diffusion Models Using Reinforcement Learning (RL)40+ Cool AI Tools You Should Check Out (December 2023)Meta AI Researchers Open-Source Pearl: A Production-Ready Reinforcement Learning AI Agent LibraryResearchers from the University of Texas Showcase Predicting Implant-Based Reconstruction Complications Using Machine LearningRedditVoteFlipShareTweet0 Shares


 



Previous articleAWS AI Labs Propose A Method That Predicts Bias In Face Recognition Models Using Unlabeled DataNext articleResearchers at the Allen Institute for AI Propose Līla, a Unified Benchmark for Comprehensive Evaluation of the Mathematical Reasoning Abilities of Artificial Intelligence Systems Arham Islam  
",,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.marktechpost.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.marktechpost.com/category/technology/', 'name': 'Technology'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.marktechpost.com/category/technology/ai-shorts/', 'name': 'AI Shorts'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@type': 'WebPage', '@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/', 'name': 'How Do DALL·E 2, Stable Diffusion, and Midjourney Work?'}}]",,,"[{'@type': 'Article', '@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/#article', 'isPartOf': {'@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/'}, 'author': {'name': 'Arham Islam', '@id': 'https://www.marktechpost.com/#/schema/person/10d9f9ca0976fe9b2fc0dd1fe3e78a1d'}, 'headline': 'How Do DALL·E 2, Stable Diffusion, and Midjourney Work?', 'datePublished': '2022-11-15T04:47:43+00:00', 'dateModified': '2022-11-15T04:47:56+00:00', 'mainEntityOfPage': {'@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/'}, 'wordCount': 1049, 'commentCount': 0, 'publisher': {'@id': 'https://www.marktechpost.com/#organization'}, 'image': {'@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/#primaryimage'}, 'thumbnailUrl': 'https://www.marktechpost.com/wp-content/uploads/2022/11/Blog-Banner-2-2.png', 'articleSection': ['AI Shorts', 'AI Tool', 'Artificial Intelligence', 'Editors Pick', 'Staff', 'Tech News', 'Technology'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/#respond']}], 'copyrightYear': '2022', 'copyrightHolder': {'@id': 'https://www.marktechpost.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/', 'url': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/', 'name': 'How Do DALL·E 2, Stable Diffusion, and Midjourney Work? - MarkTechPost', 'isPartOf': {'@id': 'https://www.marktechpost.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/#primaryimage'}, 'image': {'@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/#primaryimage'}, 'thumbnailUrl': 'https://www.marktechpost.com/wp-content/uploads/2022/11/Blog-Banner-2-2.png', 'datePublished': '2022-11-15T04:47:43+00:00', 'dateModified': '2022-11-15T04:47:56+00:00', 'description': 'How Do DALL·E 2, Stable Diffusion, and Midjourney Work? The technology behind DALL·E 2. Comparison between DALL·E 2, Stable Diffusion and Midjourney', 'breadcrumb': {'@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/#primaryimage', 'url': 'https://www.marktechpost.com/wp-content/uploads/2022/11/Blog-Banner-2-2.png', 'contentUrl': 'https://www.marktechpost.com/wp-content/uploads/2022/11/Blog-Banner-2-2.png', 'width': 1920, 'height': 1080}, {'@type': 'BreadcrumbList', '@id': 'https://www.marktechpost.com/2022/11/14/how-do-dall%c2%b7e-2-stable-diffusion-and-midjourney-work/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.marktechpost.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How Do DALL·E 2, Stable Diffusion, and Midjourney Work?'}]}, {'@type': 'WebSite', '@id': 'https://www.marktechpost.com/#website', 'url': 'https://www.marktechpost.com/', 'name': 'MarkTechPost', 'description': 'An Artificial Intelligence News Platform', 'publisher': {'@id': 'https://www.marktechpost.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.marktechpost.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.marktechpost.com/#organization', 'name': 'MarkTechPost Media Inc.', 'url': 'https://www.marktechpost.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.marktechpost.com/#/schema/logo/image/', 'url': 'https://www.marktechpost.com/wp-content/uploads/2022/04/cropped-Favicon-512-x-512-1-1.png', 'contentUrl': 'https://www.marktechpost.com/wp-content/uploads/2022/04/cropped-Favicon-512-x-512-1-1.png', 'width': 512, 'height': 512, 'caption': 'MarkTechPost Media Inc.'}, 'image': {'@id': 'https://www.marktechpost.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/MarkTechPost/', 'https://x.com/Marktechpost', 'https://www.linkedin.com/in/asifrazzaq/']}, {'@type': 'Person', '@id': 'https://www.marktechpost.com/#/schema/person/10d9f9ca0976fe9b2fc0dd1fe3e78a1d', 'name': 'Arham Islam', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.marktechpost.com/#/schema/person/image/', 'url': 'https://www.marktechpost.com/wp-content/uploads/2022/10/Screen-Shot-2022-10-03-at-10.48.33-PM-96x96.png', 'contentUrl': 'https://www.marktechpost.com/wp-content/uploads/2022/10/Screen-Shot-2022-10-03-at-10.48.33-PM-96x96.png', 'caption': 'Arham Islam'}, 'description': 'I am a Civil Engineering Graduate (2022) from Jamia Millia Islamia, New Delhi, and I have a keen interest in Data Science, especially Neural Networks and their application in various areas.', 'url': 'https://www.marktechpost.com/author/arhamislam/'}]",,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3LnNwaWNld29ya3MuY29tL3RlY2gvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvZ3Vlc3QtYXJ0aWNsZS9ob3ctYWktY2FuLWhlbHAtYmF0dGxlLXRoZS1vbmdvaW5nLWxhYm9yLXNob3J0YWdlL9IBeGh0dHBzOi8vd3d3LnNwaWNld29ya3MuY29tL3RlY2gvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvZ3Vlc3QtYXJ0aWNsZS9ob3ctYWktY2FuLWhlbHAtYmF0dGxlLXRoZS1vbmdvaW5nLWxhYm9yLXNob3J0YWdlLw?oc=5,How AI Can Help Battle the Ongoing Labor Shortage - Spiceworks News and Insights,2022-11-15,Spiceworks News and Insights,https://www.spiceworks.com,"Kshitij Dayal, SVP of engineering and operations at Legion, explores how AI can provide support at a time characterized by a labor shortage.",labor shortage,"Kshitij Dayal, SVP of engineering and operations at Legion, explores how AI can provide support at a time characterized by a labor shortage.",N/A,,,,,N/A,N/A,"



























 



Kshitij Dayal



					SVP of Engineering and Operations, Legion				




November 15, 2022




 





The Great Resignation has contributed to the labor shortage that has had an impact on every business – especially those with a large hourly workforce. And as companies look for solutions, including new ways to attract and retain talent, employees continue to re-evaluate their priorities for what they value in their jobs, says Kshitij Dayal, SVP of engineering and operations at Legion.
Large organizations like WalmartOpens a new window  and TargetOpens a new window  are hiking salaries to attract hourly workers. However, with so many companies now offering sign-on bonuses and record pay packages, employers looking to compete in a tight labor market need to find a new way to win over employees. AI-powered workforce management and demand forecasting may be the solution. 
Demand Forecasting with AI-derived Insights
Every brick-and-mortar business experiences periods of peak and low workforce demand. From holidays to weather events, throughout the day, week, and month, many factors influence the ebbs and flows of a business. However, without the right tools to properly predict demand, managers are unable to create optimal labor plans and employee schedules, unsure of how many employees should work on a certain day or at a certain time. Scheduling too many people will lead to overspending on labor, and scheduling too few will ensure missed revenue-generating opportunities, as employees’ productivity may be hindered while trying to meet customer demand. 
For example, a slow day in a restaurant with too many employees creates business losses, while a busy day with too few workers can cause the business to lose out on revenue since they cannot seat and serve as many people due to not having the appropriate number of servers or chefs. In addition, inefficient scheduling practices can create disgruntled and dissatisfied employees as they feel overworked when there are staffing shortages.  
Workforce management platforms that incorporate AI-powered demand forecasting capabilities can help solve these problems. They leverage machine learning algorithms to analyze key data points and demand drivers (e.g., daily weather, local events, etc.), looking for patterns and market trends. Then, predictive analytics models use this information to provide insights into customer behaviors to help determine where demand is likely to come from and what the best employee schedule will be. By harnessing the power of AI for demand forecasting, employers can create highly accurate schedules that enable them to optimize their labor efficiency. In addition, they can more easily match their business needs with employee skills and preferences, which creates a better employee experience.
See More: 4 Ways Emerging Workplace Tech Can Ease Perceived Labor Shortage
Build Schedule Agility into Workforce Management
In today’s highly-competitive labor market, employers also need to offer schedule flexibility, especially since 85% of hourly workersOpens a new window  believe it’s important to have more control over their schedules. However, managers who still use traditional, manual methods of creating work schedules (e.g., spreadsheets or even “pen and paper”) are at risk of building inefficient schedules, as well as wasting time that can be spent on higher-value activities, such as working with customers and providing constructive and positive feedback to their employees. 
AI-powered workforce management solutions can automate the entire scheduling process, enabling managers to easily and efficiently generate schedules that adhere to local labor laws (e.g., meal and rest breaks) while also meeting employee preferences. These intelligent scheduling solutions also allow employees to easily request time off, swap shifts, and even pick up extra shifts – often with a single click in a mobile app – creating a better overall experience for all employees as they are able to define when, how much, and where they want to work. A mobile platform is essential for Millennial and Gen Z workers in particular since they expect every aspect of their life to be online, efficient, and personalized to suit their needs.
An intelligent workforce management platform also allows the company to optimize its workforce by sharing employees across multiple locations. This not only provides the company with additional workers who know the inner workings of company procedures but also gives workers the ability to pick up extra shifts that might not have been previously available to them.
Mitigating Supply Chain Disruption
Even now, more than two years after the pandemic started, supply chain disruptions continue to be a pain point in every industry, as companies catch up to meet the demand for items, causing delays and driving up prices. While the current employment trends aren’t the only cause of the supply chain situation, they have had a significant impact, with industries such as manufacturing, transportation, warehousing, and utilities seeing high quit ratesOpens a new window  last year. Companies are having to do more with fewer resources from both an inventory and employee perspective.  
Smart workforce management solutions can help with supply chain uncertainty by enabling distribution centers to operate more efficiently. For example, through the use of AI and ML, companies can analyze thousands of data points that can impact workforce needs (e.g., delivery days, weather events, etc.) so they can make better, more informed scheduling decisions. In addition, it creates staffing guidance based on demand, labor standards, business policies, and budget constraints to create the optimal labor plan. This allows distribution center operators to formulate long-range staffing plans with fixed and flexible schedules.
Fostering a Positive Work Environment
If there is anything to learn from the Great Resignation, it’s that no company is exempt from the labor shortage and training challenges presented during this time. Instead of sitting around and offering the same benefits and pay that workers no longer see value in, companies have taken this time to reflect on what employees actually want in a job and from an employer, whether that is more recognition, higher pay, or greater schedule flexibility. 
By offering benefits that better align with employees’ wants and needs, organizations are demonstrating that they truly care about their people as more than just a number. This creates a better culture and future-proofs the business, decreasing the chances of employees leaving the company.
Every competitive advantage matters as companies continue to look for new ways to attract and retain hourly employees. AI-powered workforce management is a game-changer, providing employers with an easy way to optimize their labor efficiency while improving their employee experience simultaneously.
How are you preparing to navigate the labor and skills shortage with AI? Tell us on  FacebookOpens a new window , TwitterOpens a new window , and LinkedInOpens a new window .
MORE ON LABOR SHORTAGE: 

How APIs Help Leaders Navigate the Labor Shortage
How Automation Helps Small Businesses Offset Labor Shortage Challenges
4 Ways Pairing Lean Manufacturing with Automation Can Mitigate Labor Shortages 

Image Source: Shutterstock











								                  workforce management										



Share This Article:
 






Kshitij Dayal

				                  SVP of Engineering and Operations, Legion	                          


 opens a new window
 opens a new window 



 opens a new window  opens a new window
  	
					Kshitij Dayal is the Senior Vice President of Engineering and Operations at Legion Technologies. Dayal brings more than 25 years of experience in engineering and is responsible for all technology and operations for the DevOps, data science, user experience (UX), and project management sides of the Legion business. Previously, he was a Senior Vice President of Product Development at Workday where he was responsible for product engineering, data science, and development operations. He was also Vice President of Engineering for Adaptive Insights, which was acquired by Workday, where he conceptualized, designed, and orchestrated the build and rollout of the next-generation elastic hypercube technology.			








								Do you still have questions? Head over to the Spiceworks Community to find answers.
							

Take me to Community





",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMjIvMTEvMTUvMTA2MzIwMi93aHktd2UtbmVlZC10by1kby1hLWJldHRlci1qb2Itb2YtbWVhc3VyaW5nLWFpcy1jYXJib24tZm9vdHByaW50L9IBeWh0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMjIvMTEvMTUvMTA2MzIwMi93aHktd2UtbmVlZC10by1kby1hLWJldHRlci1qb2Itb2YtbWVhc3VyaW5nLWFpcy1jYXJib24tZm9vdHByaW50L2FtcC8?oc=5,Why we need to do a better job of measuring AI’s carbon footprint - MIT Technology Review,2022-11-15,MIT Technology Review,https://www.technologyreview.com,Plus: Inside Alphabet X’s new effort to combat climate change with AI and seagrass.,,Plus: Inside Alphabet X’s new effort to combat climate change with AI and seagrass.,Plus: Inside Alphabet X’s new effort to combat climate change with AI and seagrass.,http://schema.org,Organization,https://www.technologyreview.com/2022/11/15/1063202/why-we-need-to-do-a-better-job-of-measuring-ais-carbon-footprint/,,N/A,N/A,N/A,Why we need to do a better job of measuring AI’s carbon footprint,2022-11-15T07:00:00-05:00,2022-11-14T13:35:10-05:00,"https://wp.technologyreview.com/wp-content/uploads/2022/11/nuclear-power-BLOOMa.jpeg?resize=854,569","{'@type': 'Person', 'name': 'Melissa Heikkilä'}","{'@type': 'Organization', 'name': 'MIT Technology Review', 'logo': {'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/themes/mittr/client/src/images/logo.png', 'width': 203, 'height': 100}}","{'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/uploads/2022/11/nuclear-power-BLOOMa.jpeg?resize=854,569', 'height': 569, 'width': 854}",,"{'@type': 'WebPage', '@id': 'https://www.technologyreview.com/2022/11/15/1063202/why-we-need-to-do-a-better-job-of-measuring-ais-carbon-footprint/'}",,2022-11-15T07:00:00-05:00,Artificial intelligence,1178.0,"{'@type': 'Person', 'name': 'Melissa Heikkilä'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Artificial intelligence', 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/topic/artificial-intelligence/'}}, {'@type': 'ListItem', 'position': 2, 'name': 'Why we need to do a better job of measuring AI’s carbon footprint', 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/2022/11/15/1063202/why-we-need-to-do-a-better-job-of-measuring-ais-carbon-footprint/'}}]",MIT Technology Review,"{'@type': 'PostalAddress', 'addressLocality': 'Cambridge, MA, USA', 'postalCode': '02142', 'streetAddress': '1 Main Street'}",,,
https://news.google.com/rss/articles/CBMinwFodHRwczovL3V3YXRlcmxvby5jYS9hc3NvY2lhdGUtcHJvdm9zdC1jby1vcGVyYXRpdmUtYW5kLWV4cGVyaWVudGlhbC1lZHVjYXRpb24vbmV3cy9hZHZhbmNpbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVzZWFyY2gtdGhyb3VnaC13b3JrLWludGVncmF0ZWQtbGVhcm5pbmfSAQA?oc=5,Advancing artificial intelligence research through work-integrated learning: a partnership between the University of ... - University of Waterloo,2022-11-11,University of Waterloo,https://uwaterloo.ca,The University of Waterloo and Norwegian University of Science and Technology (NTNU) partner to focus on talent development in artificial intelligence (AI),N/A,The University of Waterloo and Norwegian University of Science and Technology (NTNU) partner to focus on talent development in artificial intelligence (AI),N/A,,,,,N/A,N/A,"









    
                
  Friday, November 11, 2022





    
    
    
          


  

      
        Advancing artificial intelligence research through work-integrated learning: a partnership between the University of Waterloo and Norway University of Science and Technology

        
      










The University of Waterloo and Norwegian University of Science and Technology (NTNU) partner to focus on talent development in artificial intelligence (AI) through co-operative education and work-integrated learning (WIL).
Waterloo’s Co-operative and Experiential Education team and Waterloo Artificial Intelligence Institute (Waterloo.AI) are partnering with NTNU on a project titled International Work-Integrated-Learning in Artificial Intelligence (IWIL AI). Diku, the Norwegian Agency for International Cooperation and Quality Enhancement in Higher Education, has a program to support partnerships that strengthen education for a sustainable future called UTFORSK. Diku and UTFORSK awarded funding to the partner project.
Lisa ter Woort (she/her), Co-operative Education’s international account manager and business developer, and Harold Godwin (he/him), managing director of Waterloo.AI, collaborated to create this successful project proposal.







Waterloo is a leader in building the intelligent systems of tomorrow through Waterloo.AI. This project is an investment in developing future-ready talent using our co-operative education model.




Lisa ter Woort (she/her), international account manager and business developer, Co-operative Education









Driving the future of AI research






The four-year project promotes the value of co-op/WIL and its intersection with foundational and applied research. IWIL AI will fund 24 Waterloo co-op students as they undertake AI in Norway at NTNU and at their industry partners.
Twelve masters and PhD students from NTNU will have a 6-12 month applied research internship at Waterloo.AI, its research networks and industry partners. The program planning begins in the winter of 2023.
This exchange intends to grow international mobility pathways between these AI networks. “Through this initiative, the goal is to expand the AI talent pool to yield positive impacts that help improve the quality-of-life for people around the world,” says Godwin. “This research exchange will prove to be invaluable for years to come.”
For ter Woort, this unique project is an exciting testing ground for a bilateral mobility initiative integrating relevant WIL opportunities. The global pandemic drove the need for digital transformation. As a result, there continues to be rapid development in AI.
According to a recent article in Forbes, AI is helping companies develop new business models. For example, organizations can use AI technology to find trends that will attract the most customers. AI can also be used to design and test concepts while checking performance parameters in real time. Various industries are developing new products using the predictive power of AI.
“AI is the future,” says ter Woort. “And Waterloo is on track to provide valuable thought leadership and innovations in AI through associated talent development of our co-op students.”










TO LEARN MORE AND GET INVOLVED
Contact Catherine Balcerzak














Project update:
In the fall 2023 and winter 2024 work terms, eight co-op students worked on AI projects with NTNU, SINTEF Digital and Cognite in Norway as part of the IWIL AI project. Some of the roles students held include front and backend developer for AI-supported learning platforms, software developer in AI research, social robotics programmer (AI) and AI specialist.










Faculty,     

Staff,     

Alumni,     

Employers,     

International 





",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC0xMC1yZWNlc3Npb24tcHJvb2YtYWktY29tcGFuaWVzLXRvLXdvcmstZm9yLWluLTIwMjPSAXpodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hbXAvc3RvcnkvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvdG9wLTEwLXJlY2Vzc2lvbi1wcm9vZi1haS1jb21wYW5pZXMtdG8td29yay1mb3ItaW4tMjAyMw?oc=5,Top 10 Recession-Proof AI Companies to Work for in 2023 - Analytics Insight,2022-11-12,Analytics Insight,https://www.analyticsinsight.net,,"Recession-proof AI companies,Artificial intelligence ,Artificial intelligence-based stock prices ,Tech-based stocks,Recession-proof AI companies to work for","In between the tech-based stocks slumping, these are 10 recession-proof AI companies to work for Artificial intelligence-based stock prices experienced a meteor","In between the tech-based stocks slumping, these are 10 recession-proof AI companies to work for Artificial intelligence-based stock prices experienced a meteor",http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/top-10-recession-proof-ai-companies-to-work-for-in-2023,,N/A,N/A,Future Growth Prospects in the Cryptocurrency Market,Top 10 Recession-Proof AI Companies to Work for in 2023,2022-11-12T03:00:00Z,2022-11-12T03:00:00Z,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2022/11/Top-10-Recession-Proof-AI-Companies-to-Work-for-in-2023.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"[{'@type': 'Person', 'givenName': 'Satavisa Pati', 'name': 'Satavisa Pati', 'url': 'https://www.analyticsinsight.net/author/satavisa-pati'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2022/11/Top-10-Recession-Proof-AI-Companies-to-Work-for-in-2023.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","In between the tech-based stocks slumping, these are 10 recession-proof AI companies to work for.Artificial intelligence-based stock prices experienced a meteoric rise during the pandemic, but since November 2021, their value has plummeted and the industry is headed toward a historic slump, also dubbed a market correction, that could lead to a recession. However, not every stock has the same condition. Here are the top 10 recession-proof AI companies to work for in 2023..World from Space.World from Space is a company focusing on the creation of applications based on Earth Observation (EO) and other data, especially from the Copernicus program. WFS has experience with EO data processing (multispectral, SAR), spatial and temporal data analysis, visualizations, machine learning, and integrations into software platforms or GIS..Satelligence.Satelligence is a global NatureTech company with offices worldwide and its teams combine local knowledge, field trips, AI-powered predictive modeling, and remote sensing to monitor what's happening on the ground..Google.Google is a multinational corporation that specializes in Internet-related services and products. The company's product portfolio includes Google Search, which provides users with access to information online; Knowledge Graph which allows users to search for things, people, or places as well as builds systems recognizing speech and understanding natural language.SkillLab.SkillLab develops an application that helps job seekers to search for jobs, showcase their knowledge and find career paths as per their skills..OpenAI.OpenAI is an AI research and deployment company that aims to ensure that artificial intelligence benefits all of humanity. OpenAI's mission is to ensure that artificial intelligence which is a highly autonomous system that outperforms humans at the most economically valuable work—benefits all of humanity..Spotify.Spotify is a commercial music streaming service that provides restricted digital content from a range of record labels and artists. Users can browse through the interface by artist, album, genre, playlist, record label, and direct searches. It also enables individuals to create, share, and edit playlists with other users. If users want recommendations, they can integrate their system with Last. FM, is an application that provides music recommendations based on listening history. The radio feature installed in Spotify creates random playlists for its users that are related to preferred artists..Airbnb.Airbnb is an online community marketplace for people to list, discover, and book accommodations through mobile phones or the internet. The company connects travelers seeking authentic experiences with hosts offering unique, inspiring spaces. Whether the available space is a castle for a night, a sailboat for a week, or an apartment for a month, Airbnb is the easiest way for people to showcase these distinctive spaces to an audience of millions. By facilitating bookings and financial transactions, Airbnb makes the process of listing or booking a space effortless and efficient..Uber.Uber develops, markets, and operates a ride-sharing mobile application that allows consumers to submit a trip request. Its smartphone application connects drivers with people who need a ride. Its application enables users to arrange and schedule transportation and/or logistics services with third-party providers. They take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 600 cities around the world. It also provides Windows Phone App, iPhone App, Blackberry App, and Android App. Uber serves customers in North, Central, and South America as well as Europe, the Middle East, Africa, and the Asia Pacific..Walmart.Walmart is a multinational retail corporation that operates several chains of discount departments and warehouse stores. The company's segments include Walmart U.S., Walmart International, and Sam's Club. The Walmart U.S. segment is a mass merchandiser of consumer products operating under the Walmart or Wal-Mart brands. It also offers digitalservices such as Vudu and InstaWatch..Comcast.Comcast is a media and technology company that connects millions of people to the moments and experiences that matter most. Comcast Cable is one of the nation's largest video, high-speed internet, and phone providers to residential customers under the XFINITY brand, and also provides these services to businesses. It also provides wireless and security and automation services to residential customers under the XFINITY brand..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.","{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-recession-proof-ai-companies-to-work-for-in-2023'}",,2022-11-12T03:00:00Z,Artificial Intelligence,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 10 Recession-Proof AI Companies to Work for in 2023', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-recession-proof-ai-companies-to-work-for-in-2023'}]",Top 10 Recession-Proof AI Companies to Work for in 2023,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-recession-proof-ai-companies-to-work-for-in-2023', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2022/11/Top-10-Recession-Proof-AI-Companies-to-Work-for-in-2023.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vbmV3ZXJhbGl2ZS5uYS9wb3N0cy9vcGluaW9uLWhvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jb3VsZC1lbXBvd2VyLXNtZXMtaW4tYWZyaWNh0gEA?oc=5,Opinion - How Artificial Intelligence could empower SMEs in Africa - New Era,2022-11-15,New Era,https://neweralive.na,"Artificial Intelligence (AI) is a major driver of the fourth industrial revolution (4IR), concerned with creating machines that mimic human-like intelligence.",N/A,"Artificial Intelligence (AI) is a major driver of the fourth industrial revolution (4IR), concerned with creating machines that mimic human-like intelligence.","Artificial Intelligence (AI) is a major driver of the fourth industrial revolution (4IR), concerned with creating machines that mimic human-like intelligence.",https://schema.org,,,,N/A,N/A,"
National2022-11-152022-11-15By Staff ReporterLameck Mbangula Amugongo
Artificial Intelligence (AI) is a major driver of the fourth industrial revolution (4IR), concerned with creating machines that mimic human-like intelligence. Today, AI is creating tremendous possibilities for creation and invention, most recently being AlphaFold, which can accurately predict 3D models of protein structure and will accelerate our understanding of biology. AI is an enabler of innovation and wealth creation. However, AI is not spread evenly. This article outlines how small, and medium enterprises (SMEs) in Africa, including Namibia, can benefit from the power of AI.
In a recent Ted Talk, Andrew Ng compared the rise of AI to the rise of literacy, whereby many years ago, people thought that not everyone needed to learn how to read and write. The people mostly depended on the high priests and monks to read the Holy Scriptures. However, literacy brought about a much better and richer society, allowing people to express their thoughts or ideas in written form. Similarly, the same can be said about AI. Today, AI is being shaped by a few highly skilled engineers. These engineers are the high priests, priestesses and monks that develop and maintain AI systems that tell us how to live and work.
The majority of these skilled engineers “The high priests, priestesses and monks” of AI work for big tech companies and many of us have only access to the AI they build such as Siri, Alexa and other applications we use to manage our health. Thus far, it is the big technology companies that are milking the benefits of AI, because AI systems require a lot of data and are expensive to build. 
It is the large tech companies with the money and the millions of users, enabling big tech companies to create one-size-fits-all AI systems. For example, the algorithm that recommends what to watch on Netflix or Ads you will like on Facebook. For big tech companies, the use of one-size-fits-all AI can generate massive amounts of revenue. However, outside the big tech sector, this approach to AI will not work. For example, in the SME sector, there is hardly any project on AI because SMEs do not have 100 million customers. Thus, it does not make economic sense for SMEs to invest in AI. 
Whenever I visit my grandmother in Endola, I always watch my grandmother with admiration as she bakes and sells her vetkoek. By selling vetkoek, she is generating data. If she had access to AI, she could leverage data to spot demand patterns to identify days of the week when the vetkoek sells well. AI can improve decision-making of SMEs, for example, if the vetkoek” sells well on a Friday afternoon, she may not need to wake up early on Friday. Rather she can use insights from data to determine the amount of vetkoek to make on a given day. Thus, maximising profits. 
I know, AI requires large datasets, and large datasets can help improve the performance of AI. Contrary to the massive dataset, fine-tuning AI can work fine with modest data, such as data gathered by a single SME shop or vendor. The biggest problem is not the data, however, the small shop owned by my grandmother can never justify the cost of building an AI solution.
In Namibia, we have many SME vendors like my grandmother who sell vetkoek and collectively they serve thousands of customers. Yet every SME vendor is different, they serve different customers and record sales differently. So, no one-size-fits-all AI solution will work for all of them. Hence the need to build custom AI solutions for each business.
Typically, to build an AI solution, one needs to know how to code and understand complex mathematics (linear algebra and statistics). Even though I am a strong advocate of people learning how to code, I know that not everyone has the time to learn to code. New low-code AI-development platforms have been developed to enable people without coding skills to build AI algorithms that matter to them. Instead of writing 1000s lines of code, you provide data and fine-tune pre-trained models with custom data. Like how pen and paper were instrumental to widespread literacy. I think low-code AI-development platforms can help make AI accessible to all.
For example, an inspector of a start-up can use AI to detect defects in leather shoes by taking pictures of the shoes, and upload them on the low-code AI development platform. After they label the data to show the AI what tear, shear or discolouring on leather shoes look like. The labelled data is used to teach the AI what defects in leather shoes look like. After the AI learns this data, it might learn better to identify tears but not discolouring. The inspector can add more data showing discolouring to help the AI learn that better. Using low-code AI-development platforms, an inspector will be able to train their own custom AI in a few days.
Likewise, low-code AI-development platforms can empower a baker to use AI to check the quality of the cakes or a farmer to check the quality of vegetables or a carpenter to check the quality of the timber they are using. Platforms like this might need a few years to become easier for my grandmother to use. 
Nevertheless, some of these platforms are useful to someone tech-savvy with a bit of training. Therefore, instead of relying on “The high priests, priestesses and monks” to write AI systems for everyone, we can empower store managers, accountants and some SME owners to build their own AI systems to facilitate decision-making, improve marketing, improve sales and streamline business operations among other benefits.
No doubt coding is the new literacy and understanding AI is the next frontier of literacy that we all need. A wider understanding of AI systems has the potential to empower more people and could be Africa’s last chance for sustainable and inclusive growth.
*Lameck Mbangula Amugongo is a post-doctoral researcher at the Institute for Ethics in Artificial Intelligence (Technical University of Munich). He holds a PhD in Cancer Science from the University of Manchester. The views expressed are his own.
",,,,,,,,,,,,,,,,,,"[{'@type': 'BlogPosting', '@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#blogposting', 'name': 'Opinion – How Artificial Intelligence could empower SMEs in Africa - New Era', 'headline': 'Opinion &#8211;  How Artificial Intelligence could empower SMEs in Africa', 'author': {'@id': 'https://neweralive.na/author/staff-reporter/#author'}, 'publisher': {'@id': 'https://neweralive.na/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://neweralive.na/wp-content/uploads/2024/06/lameck.gif', 'width': 500, 'height': 328}, 'datePublished': '2022-11-15T11:44:00+02:00', 'dateModified': '2022-11-15T11:44:00+02:00', 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#webpage'}, 'isPartOf': {'@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#webpage'}, 'articleSection': 'National'}, {'@type': 'BreadcrumbList', '@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://neweralive.na/#listItem', 'position': 1, 'name': 'Home', 'item': 'https://neweralive.na/', 'nextItem': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#listItem'}, {'@type': 'ListItem', '@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#listItem', 'position': 2, 'name': 'Opinion -  How Artificial Intelligence could empower SMEs in Africa', 'previousItem': 'https://neweralive.na/#listItem'}]}, {'@type': 'Organization', '@id': 'https://neweralive.na/#organization', 'name': 'New Era Demo', 'url': 'https://neweralive.na/'}, {'@type': 'Person', '@id': 'https://neweralive.na/author/staff-reporter/#author', 'url': 'https://neweralive.na/author/staff-reporter/', 'name': 'Staff Reporter', 'image': {'@type': 'ImageObject', '@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#authorImage', 'url': 'https://secure.gravatar.com/avatar/0b2da715c78fc58a3fc5db7c7baa23e2?s=96&d=mm&r=g', 'width': 96, 'height': 96, 'caption': 'Staff Reporter'}}, {'@type': 'WebPage', '@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#webpage', 'url': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/', 'name': 'Opinion – How Artificial Intelligence could empower SMEs in Africa - New Era', 'description': 'Artificial Intelligence (AI) is a major driver of the fourth industrial revolution (4IR), concerned with creating machines that mimic human-like intelligence.', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://neweralive.na/#website'}, 'breadcrumb': {'@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#breadcrumblist'}, 'author': {'@id': 'https://neweralive.na/author/staff-reporter/#author'}, 'creator': {'@id': 'https://neweralive.na/author/staff-reporter/#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://neweralive.na/wp-content/uploads/2024/06/lameck.gif', '@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#mainImage', 'width': 500, 'height': 328}, 'primaryImageOfPage': {'@id': 'https://neweralive.na/opinion-how-artificial-intelligence-could-empower-smes-in-africa/#mainImage'}, 'datePublished': '2022-11-15T11:44:00+02:00', 'dateModified': '2022-11-15T11:44:00+02:00'}, {'@type': 'WebSite', '@id': 'https://neweralive.na/#website', 'url': 'https://neweralive.na/', 'name': 'New Era Demo', 'inLanguage': 'en-US', 'publisher': {'@id': 'https://neweralive.na/#organization'}}]",,

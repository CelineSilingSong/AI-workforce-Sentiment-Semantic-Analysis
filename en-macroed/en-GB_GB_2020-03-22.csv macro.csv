URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@graph,@type,itemListElement,article:section,article:summary,article text,headline,image,datePublished,author,publisher,dateModified,mainEntityOfPage,name,url,genre,wordcount,hasPart,isAccessibleForFree,isPartOf,thumbnailUrl,articleBody,dateCreated,articleSection,alternativeHeadline,copyrightHolder,copyrightYear,inLanguage,wordCount
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd3d3Lm9wZW5hY2Nlc3Nnb3Zlcm5tZW50Lm9yZy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi10aGUtd29ya3BsYWNlLzg0MjA4L9IBAA?oc=5,Making sure artificial intelligence in the workplace benefits people - Open Access Government,2020-03-24,Open Access Government,https://www.openaccessgovernment.org,Franca Salis-Madinier highlights for us the importance of ensuring that artificial intelligence in the workplace benefits people,N/A,"Franca Salis-Madinier from the European Economic and Social Committee and French Democratic Confederation of Labour – Professionals and Managers, highlights for us the importance of ensuring that artificial intelligence in the workplace benefits people","Franca Salis-Madinier from the European Economic and Social Committee and French Democratic Confederation of Labour – Professionals and Managers, highlights for us the importance of ensuring that artificial intelligence in the workplace benefits people",https://schema.org,"[{'@type': 'Article', '@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/#article', 'isPartOf': {'@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/'}, 'author': {'name': 'Nick Wilde', '@id': 'https://www.openaccessgovernment.org/#/schema/person/a98ee42ee29b4e190150fa990221b32b'}, 'headline': 'Making sure artificial intelligence in the workplace benefits people', 'datePublished': '2020-03-24T14:34:02+00:00', 'dateModified': '2020-03-24T14:34:02+00:00', 'mainEntityOfPage': {'@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/'}, 'wordCount': 900, 'commentCount': 0, 'publisher': {'@id': 'https://www.openaccessgovernment.org/#organization'}, 'image': {'@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/#primaryimage'}, 'thumbnailUrl': 'https://www.openaccessgovernment.org/wp-content/uploads/2020/03/Franca-Salis-Madinier-©-Thekaikoro.jpg', 'keywords': ['Artificial Intelligence', 'OAG 026 - April 2020', 'Technological Innovations', 'Workplace Culture'], 'articleSection': ['Technology News'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/#respond']}], 'copyrightYear': '2020', 'copyrightHolder': {'@id': 'https://www.openaccessgovernment.org/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/', 'url': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/', 'name': 'Making sure artificial intelligence in the workplace benefits people', 'isPartOf': {'@id': 'https://www.openaccessgovernment.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/#primaryimage'}, 'image': {'@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/#primaryimage'}, 'thumbnailUrl': 'https://www.openaccessgovernment.org/wp-content/uploads/2020/03/Franca-Salis-Madinier-©-Thekaikoro.jpg', 'datePublished': '2020-03-24T14:34:02+00:00', 'dateModified': '2020-03-24T14:34:02+00:00', 'description': 'Franca Salis-Madinier highlights for us the importance of ensuring that artificial intelligence in the workplace benefits people', 'breadcrumb': {'@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/#primaryimage', 'url': 'https://www.openaccessgovernment.org/wp-content/uploads/2020/03/Franca-Salis-Madinier-©-Thekaikoro.jpg', 'contentUrl': 'https://www.openaccessgovernment.org/wp-content/uploads/2020/03/Franca-Salis-Madinier-©-Thekaikoro.jpg', 'width': 2000, 'height': 1125, 'caption': '© Thekaikoro'}, {'@type': 'BreadcrumbList', '@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.openaccessgovernment.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Making sure artificial intelligence in the workplace benefits people'}]}, {'@type': 'WebSite', '@id': 'https://www.openaccessgovernment.org/#website', 'url': 'https://www.openaccessgovernment.org/', 'name': 'Open Access Government', 'description': 'Government | Health &amp; Social Care | Research', 'publisher': {'@id': 'https://www.openaccessgovernment.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.openaccessgovernment.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://www.openaccessgovernment.org/#organization', 'name': 'Open Access Government', 'url': 'https://www.openaccessgovernment.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.openaccessgovernment.org/#/schema/logo/image/', 'url': 'https://www.openaccessgovernment.org/wp-content/uploads/2022/01/oag-logo-yoast-seo-organisation-1920-1080-001.jpg', 'contentUrl': 'https://www.openaccessgovernment.org/wp-content/uploads/2022/01/oag-logo-yoast-seo-organisation-1920-1080-001.jpg', 'width': 1920, 'height': 1080, 'caption': 'Open Access Government'}, 'image': {'@id': 'https://www.openaccessgovernment.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/OpenAccessGovernment/', 'https://x.com/Adjacent_Gov', 'https://www.linkedin.com/company/open-access-government/']}, {'@type': 'Person', '@id': 'https://www.openaccessgovernment.org/#/schema/person/a98ee42ee29b4e190150fa990221b32b', 'name': 'Nick Wilde', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.openaccessgovernment.org/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/4a7d05a9dd420a8aec3e65a4e9c90fa4?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/4a7d05a9dd420a8aec3e65a4e9c90fa4?s=96&d=mm&r=g', 'caption': 'Nick Wilde'}}]",BreadcrumbList,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.openaccessgovernment.org/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.openaccessgovernment.org/category/open-access-news/', 'name': 'Open Access News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.openaccessgovernment.org/category/open-access-news/technology-news/', 'name': 'Technology News'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@type': 'WebPage', '@id': 'https://www.openaccessgovernment.org/artificial-intelligence-in-the-workplace/84208/', 'name': 'Making sure artificial intelligence in the workplace benefits people'}}]",N/A,N/A,"






Home  Open Access News  Technology News  Making sure artificial intelligence in the workplace benefits people

Open Access NewsTechnology News Making sure artificial intelligence in the workplace benefits people

March 24, 2020 









Franca Salis-Madinier from the European Economic and Social Committee and French Democratic Confederation of Labour – Professionals and Managers, highlights for us the importance of ensuring that artificial intelligence in the workplace benefits people
Surely nobody would deny that digital and artificial intelligence (AI) systems are now playing a massive part in our daily reality and bringing benefits to everyone’s life. New opportunities for business, for progress in healthcare, for safety in transport and energy, and for combating climate change are presented. At the same time, could anyone fail to see the abuses and the dangerous and perverse uses of these same systems that undermine fundamental values such as dignity, the right not to be discriminated against and the right to privacy?
For Europe’s civil society, which has issued numerous opinions on AI through the European Economic and Social Committee(1), AI is not an end in itself, but a tool that – albeit also entailing risks – can bring about radical change for the better. If it is to benefit as many people as possible, politicians need to steer, govern and regulate it.
Aware of these challenges, in April 2019 the European Commission (EC) published its “Ethics Guidelines for Trustworthy AI”(2), setting out seven core principles. More recently, the EC published a White Paper on Artificial Intelligence, in which(3) it propounded the need to regulate “high-risk” AI – the kind that could encroach on people’s rights. These kinds of AI must be tested and authorised before reaching the Single Market, as is the case with medicines and cosmetics.
Introducing AI in the workplace
We are concentrating here on the questions posed by AI systems when introduced into the workplace. For our purposes, we will consider AI as digital technology used to create systems capable of autonomously reproducing human cognitive functions: voice and facial recognition, grasping data, a form of understanding and adaptation (problem-solving, automatic reasoning and learning).
The use of AI in workplaces poses a number of challenges. In the relationship between the intelligent machine and the worker, the guiding principle behind decisions must be that the technology does not subjugate the human being, but is – on the contrary – the source of work for the human that is emancipating, creative and fulfilling.
For this, a number of conditions need to be met:

Humans in the driving seat: human beings must have the last word and the final decision over the technology.
The principle of transparency and the right to an explanation of any decision taken by the technology, in particular, in the human resources (HR) area of recruitment and assessment.
The right to have privacy respected – through the protection of personal data and workers’ informed consent regarding the quality of the data collected, itsownership and use.
The right to safeguard health and safety at work, which is threatened by the unrestricted monitoring made possible by the technologies used.
The right not to be discriminated against.
The right to benefit, whatever the kind of work, from social protection worthy of the name.

Examples of the use of harmful AI
In health and safety at work, the introduction of AI-based work management systems raises questions about workers’ rights and safety. From Amazon warehouses to Uber cars and Deliveroo riders, power and surveillance are in the hands of employers and this is particularly detrimental to low wage earners (many of whom have a migrant background). This is because productivity targets are set that undermine health and safety and bring about psychological stress and because algorithm-driven, unpredictable wage cuts are made that undermine the economic stability of these workers.
The issue of platform regulation and the recognition of rights for these bogus self-employed workers is at the top of Europe’s agenda.
The European Agency for Health and Safety at Work, OSHA, warns of the use of AI in HR practices and refers to some 600 companies, some of them operating in Europe (such as Unilever and Nokia), that use the HireVue app to recruit on the basis of video interviews which analyse candidates’ facial expressions.
Some recommendations:
Regarding data: the principle of protection of rights and freedoms in relation to data processing must be guaranteed and the GDPR (General Data Protection Regulation) must be regularly reviewed and adapted.
The use of facial recognition for decisions that have an impact on people’s lives and access to opportunities must be prohibited and should stop using these applications.
Workers must have the right, through their trade unions, to challenge the use of AI systems that jeopardise their right to physical and mental health and safety and to collectively negotiate safe, fair and reliable labour standards.
Regarding non-discrimination and diversity: the AI industry is surprisingly homogeneous, largely due to its treatment of women, people of colour and gender minorities. To start to tackle this problem, more information would need to be shared publicly on wage levels, levels of discrimination and recruitment practices. Inequalities in pay and opportunities must be ended and managers given real incentives to create, promote and safeguard inclusive workplaces.
Regarding social protection: the EU must guarantee access to social protection for all workers, employees and the – real or bogus – self-employed. Health and safety, social protection, diversity, non-discrimination, respect of privacy and dignity at work, are priorities to be pursued in line with the European Pillar of Social Rights.
References
(1) EESC opinions
(2) European ethical guidelines
(3) White paper AI




Facebook



Twitter



LinkedIn



Print



 


Contributor Details



















Franca Salis-MadinierNational SecretaryFrench Democratic Confederation of Labour – professionals and managersPhone: +32 (0)2 546 90 11https://www.eesc.europa.eu  














Editor's Recommended Articles







 


Must Read >>

			European Commission works on ethics of AI use        	






 


Must Read >>

			Shaping Europe’s digital future with artificial intelligence        	






 


Must Read >>

			Blockchain, internet of things and artificial intelligence to change work and processes        	






 


Must Read >>

			How can artificial intelligence help in HR and recruitment?        	






 


Must Read >>

			Can artificial intelligence solve our societal issues?        	








TAGSArtificial IntelligenceOAG 026 - April 2020Technological InnovationsWorkplace Culture 
Nick Wilde  
RELATED ARTICLESMORE FROM AUTHOR




 

Hydrogen-powered flights: A greener sky by 2045 

 



 

SMS tech’s operational mana software for the NHS 

 



 

Faster and more sustainable communications systems 

 




 

GPT consult: Leading the way as authorising engineers 

 



 

3D-printed material paves the way for advanced soft robotics and wearable devices 

 



 

Its time to stop being confused about cyber security 

  


LEAVE A REPLY Cancel reply


Please enter your comment!


Please enter your name here



You have entered an incorrect email address!
Please enter your email address here




Save my name, email, and website in this browser for the next time I comment.
 

Δ 
 






Related Academic Articles




How do we prepare our youth for a world of big... 
June 27, 2024 


 




Confronting digital ageism: Towards a better aging future 
June 27, 2024 


 




Wrestling with the deepfakes: Detection and beyond 
June 3, 2024 


  



Follow Open Access Government





















 
 









 
 
",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vZW50ZXJwcmlzZXJzcHJvamVjdC5jb20vYXJ0aWNsZS8yMDIwLzMvYWktdnMtYXV0b21hdGlvbi02LXdheXMtc3BvdC1mYWtlLWFp0gEA?oc=5,AI vs. automation: 6 ways to spot fake AI - The Enterprisers Project,2020-03-26,The Enterprisers Project,https://enterprisersproject.com,"Is that really artificial intelligence - or just automation, being described as AI? Let's explore the difference - and six possible signs of AI washing.",N/A,"Is that really artificial intelligence - or just automation, being described as AI? Let's explore the difference - and six possible signs of AI washing.","Is that really artificial intelligence - or just automation, being described as AI? Let's explore the difference - and six possible signs of AI washing.",,,,,N/A,N/A,"
Is that really artificial intelligence - or just automation, being described as AI? Let's explore the difference - and six possible signs of AI washing



          By 

Stephanie Overby


March 26, 2020          |
%t min read



















      356 readers like this.  

















Seems like everybody’s an artificial intelligence (AI) provider these days. The global enterprise AI market, which garnered $4.68 billion in revenues in 2018, is expected to generate $53.06 billion by 2026, according to a report by Allied Market Research. So it’s little wonder that seemingly every enterprise technology vendor wants to grab a piece of the AI pie.
But not all AI solutions are what they seem. “AI washing” – the practice of touting a technology solution as AI when it may be no more than simple automation or a new marketing spin for an existing application – is a real phenomenon, industry analysts say. “Very few, in my opinion, are using strong AI,” says Wayne Butterfield, director of cognitive automation and innovation at ISG. “What we need to be mindful of is that AI covers over 200 different disciplines, so it’s not uncommon to be using a branch of AI in a tool. Some advanced analytics may now be classed as AI, even a small amount of machine learning. This means that you can be creative as a vendor.”
The explosive growth in the velocity, volume, and variety of data being produced by today’s enterprise, along with increasing computing power and the accessibility of new tools, means more IT organizations are considering or deploying AI solutions to solve business problems. However, as always, it’s important to push back on hype and dig into what a new technology actually has to offer before signing on the dotted line.
[ Get our quick-scan primer on 10 key artificial intelligence terms for IT and business leaders: Cheat sheet: AI glossary. ]
What’s the difference between AI and automation?
There is a clear difference between AI (in its various forms, like machine learning, deep learning, or natural language processing) and non-AI automation - both in how they work and what types of outcomes they can produce.
AI uses models and algorithms to autonomously find patterns in the data to provide insights and prescriptions.
“In general, AI relies on models and algorithms to autonomously find patterns in the data (‘inputs’) to provide insights, predictions, and prescriptions (‘outputs’) that could have significant business impact,” says JP Baritugo, director at business transformation and outsourcing consultancy Pace Harmon.
Automation use cases are predominantly task-oriented.
“In contrast, automation is traditionally used for processes where the input data is structured, the rules are defined with manageable exceptions, and interactions with multiple systems are required. Automation use cases are predominantly task-oriented versus a true end-to-end process view.”
An automation solution, for example, might be used to transfer data from emails into an ERP system, execute bulk data uploads and changes, or provision IT assets and resources for a new employee.
AI, by contrast, has broader applications in the business. It can cluster like data to drive business insights, classify data to determine if a customer is a churn risk, or provide predictions or recommendations such as the “next best action” based on a customer’s profile or behavior.
[ How does this work - and what's next? Read also: How big data and AI work together. ]
“Generally speaking, automation is applied to rote processes, and AI is ‘smart’ because the applications are trained to improve,” Baritugo says.
Telling the difference can still be hard. “The reality is that it is somewhat difficult to identify even for the relatively well-trained eye, since many of the systems present as black boxes that take in a certain input and present an output, regardless of whether AI is involved or not,” says Anil Vijayan, vice president at Everest Group. Making the environment even more confusing, some of today’s robotic process automation (RPA) providers now integrate cognitive capabilities into their offerings.
[ What’s next in AI? Read 10 AI trends to watch in 2020. ]
6 signs something might not really be AI:
“A good rule of thumb to pressure-test if a solution is truly using AI is to ask how it’s typically deployed and used,” advises Baritugo. Here are some red flags that may indicate you’re dealing with an AI wanna-be:
1. The product requires minimal data for training
If you’re told that you don’t need much normalized data for model training or the data requirement is downplayed, take note. “AI-based solutions generally require a fair bit of data to perform at a desired level of accuracy,” says Vijayan. “It would be useful to consider the sources of data available for the system to learn as well.”
Basic machine learning models require thousands of examples to train on; deep learning demands hundreds of thousands or millions. So a lack of data requirements is a warning sign to beware.
2. The ""AI"" needs business rules in order to work
""If this, then that"" is a telltale sign of a non-AI automation solution.
“If this, then that” is a telltale sign of a non-AI automation solution: “This is the opposite of how AI should work,” Baritugo says.
While AI might be used for automation, rules-based tasks are usually executed by “dumber” systems like RPA, says Vijayan
3. There is a notable lack of case studies
Many companies are touting their AI chops but may be early on in integrating cognitive capabilities into their tools. Use cases are one of the best ways to find out if a product actually leverages AI today. Look for details about data, training models, and outcomes that go beyond increased efficiency or cost savings.
4. The solution does not get better over time
The more data an AI model is exposed to, the better it should perform.
“When vetting a solution for AI-capabilities, it would be useful to ask how the system learns,” Vijayan says. The more data an AI model is exposed to, the better it should perform. If the provider can’t acceptably demonstrate examples of how the solution is deployed in other customers and how the tool has learned and improved over time, Baritugo explains, it’s probably not an AI solution.
5. The vendor's staff is light on AI talent
“If a provider or vendor claims to be delivering AI-based solutions without relying on third-party vendors, it would be instructive to look at their talent model,” says Vijayan. “Developing complex AI-based solutions [requires] ML engineers, data scientists with specialized ML skill sets, and so on.”
6. There's no clarity about how the AI works



MORE ON AI




How to explain AI in plain English
AI vs. machine learning: What's the difference?
AI pilot projects: How to choose wisely





The provider should be able to articulate, at least at a high level, the models or algorithms used to power their solution, says Baritugo. “‘What form of AI are you using?’ and ‘What is it doing?’ are the questions I usually start with,” says Butterfield. “When the answer isn’t clear, or the usage isn’t actually useful, it’s often a sign of AI washing.”
[ How can automation free up more staff time for innovation? Get the free eBook: Managing IT with Automation. ] 







Topics

Enterprise Technology
Artificial Intelligence
Automation







 
Stephanie Overby is an award-winning reporter and editor with more than twenty years of professional journalism experience. For the last decade, her work has focused on the intersection of business and technology. She lives in Boston, Mass.
More about me






Related content


 

The future of healthcare is in the cloud
 

Cloud computing: 3 business advantages
 

4 ways CIOs are rethinking digital transformation











",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQGh0dHBzOi8vdGR3aS5vcmcvYXJ0aWNsZXMvMjAyMC8wMy8yMy9hZHYtYWxsLWZ1dHVyZS1vZi13b3JrLmFzcHjSAQA?oc=5,The Future of Work - TDWI,2020-03-23,TDWI,https://tdwi.org,Artificial intelligence is on the horizon and is set to change the way we work. Who will be affected and what skills can you develop to insulate yourself?,"AI, job security, skills, augmented intelligence, automation",Artificial intelligence is on the horizon and is set to change the way we work. Who will be affected and what skills can you develop to insulate yourself?,N/A,https://schema.org,"[{'@type': 'WebSite', 'name': 'Transforming Data With Intelligence', 'alternateName': 'TDWI', 'url': 'https://tdwi.org'}, {'@type': 'WebPage', 'name': 'Transforming Data With Intelligence', 'alternateName': 'TDWI', 'url': 'https://tdwi.org'}, {'@type': 'Organization', 'name': 'Transforming Data With Intelligence', 'alternateName': 'TDWI', 'url': 'https://tdwi.org', 'sameAs': ['https://www.linkedin.com/company-beta/220146/', 'https://twitter.com/TDWI', 'https://www.facebook.com/TDWI.allthingsdata', 'https://www.youtube.com/user/TDWI1995', 'https://www.instagram.com/tdwilive/']}]",WebSite,,N/A,N/A,,The Future of Work,"{'@type': 'imageObject', 'url': 'https://tdwi.org/-/media/TDWI/TDWI/BITW/AI17.jpg'}","March 23, 202007/17/202407/22/202407/24/2024","{'@type': 'Person', 'name': 'Troy Hiltbrand'}","{'@type': 'Organization', 'name': 'TDWI', 'logo': {'@type': 'imageObject', 'url': 'https://tdwi.org/design/TDWI/tdwi/2017/img/footerTDWI.jpg'}}","March 23, 202007/17/202407/22/202407/24/2024","{'@type': 'WebPage', '@id': 'https://tdwi.org/upside'}",Transforming Data With Intelligence,https://tdwi.org,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vZW1lcmouY29tL2FpLXNlY3Rvci1vdmVydmlld3MvdG9wLTUtaG9zcGl0YWxzLXVzaW5nLW1hY2hpbmUtbGVhcm5pbmcv0gEA?oc=5,How America's 5 Top Hospitals are Using Machine Learning Today - Emerj,2020-03-24,Emerj,https://emerj.com,"In this article we uncover the machine learning applications are currently in use at top hospitals such as Massachusetts General, Johns Hopki...",,"In this article we uncover the machine learning applications are currently in use at top hospitals such as Massachusetts General, Johns Hopki...",N/A,https://schema.org,,Article,,N/A,N/A," Business intelligence and analyticsHealthcareCustomer service How America’s 5 Top Hospitals are Using Machine Learning Today Kumba SennaarLast updated on March 24, 2020  Last updated on March 24, 2020, published by Kumba Sennaar Kumba is an AI Analyst at Emerj, covering financial services and healthcare AI trends. She has performed research through the National Institutes of Health (NIH), is an honors graduate of Rensselaer Polytechnic Institute and a Master’s candidate in Biotechnology at Johns Hopkins University. Share to: LinkedIn Twitter Facebook Email  Despite the massive venture investments going into healthcare AI applications, there’s little evidence of hospitals using machine learning in real-world applications. We decided that this topic is worth covering in depth since any changes to the healthcare system directly impact business leaders in multiple facets such as employee insurance coverage or hospital administration policies. Industry analysts estimate that the AI health market is poised to reach $6.6 billion by 2021 and by 2026 can potentially save the U.S. healthcare economy $150 billion in annual savings. However, no sources have taken a comprehensive look at machine learning applications at America’s leading hospitals.  In this article we set out to answer questions that business leaders are asking today: What types of machine learning applications are currently in use and which are in the works at top hospitals such as Massachusetts General Hospital and Johns Hopkins Hospital? Are there any common trends among their innovation efforts – and how could these trends affect the future of healthcare? How much has been invested in machine learning and emerging tech innovation across leading hospitals? This article aims to present a succinct picture of the implementation of machine learning by the five leading hospitals in the U.S. based on the 2016-2017 U.S. News and World Report Best Hospitals Honor Roll rankings. (While a respected industry source, we acknowledge that the Honor Roll ranking methodology may not fully represent the complexities of every hospital, we’re simply using the ranking as a means to finding a representative set of high-performing hospitals). Through facts and figures we aim to provide pertinent insights for business leaders and professionals interested in how these top five US hospitals are being impacted by AI.Before presenting the applications at each of the top five hospitals, we’ll take a look at some common themes that emerged from our research in this sector. Machine learning in Hospitals – Insights Up Front Judging by the current machine learning initiatives of the top five US hospitals, the most popular hospital AI applications appear to be: Predictive analytics – The ability to monitor patients and prevent patient emergencies before they occur, by analyzing data for key indicators (see Cleveland Clinic’s partnership with Microsoft and Johns Hopkins’ partnership with GE below) Chatbots – Automating physician inquiries and routing physicians to the proper specialist, (see UCLA’s “Virtual Interventional Radiologist (VIR)” case below) Predictive health trackers – The ability to monitor patients health status using real-time data collection (see Mayo Clinic’s investment in AliveCor) In the full article below, we’ll explore the AI applications of each hospital individually. It’s important to note that most of the applications of AI at major hospitals are relatively new, and few of them have distinct results on their the improvements or efficiencies that these technologies allowed for. We tried our best to exclude AI use-cases that seemed more like PR stunts than actual genuine applications and initiatives.  In either case, you’ll see in the article below that we’re very clear about which applications have traction, and which have no results to speak of thus far. We’ll begin with the #1 ranked report in the Best Hospitals Honor Roll, the Mayo Clinic. Mayo Clinic  In January 2017, Mayo Clinic’s Center for Individualized Medicine teamed up with Tempus, a health tech startup focused on developing personalized cancer care using a machine learning platform. The partnership involves Tempus conducting “molecular sequencing and analysis for 1,000 Mayo Clinic patients participating in studies relating to immunotherapy” for a number of cancer types including “lung cancer, melanoma, bladder cancer, breast cancer and lymphoma.”  While currently in the R&D phase, the initial goal is to use the results of these analyses to help inform more customized treatment options for Mayo’s cancer patients. Mayo joins a small consortium of healthcare organizations in partnerships with Tempus including University of Michigan, University of Pennsylvania and Rush University Medical Center. “The holy grail that we’re looking for, and that Tempus is actively trying to build, is a library of data big enough that these patterns become a therapeutic, meaning you can start to say, ‘People that have this particular mutation shouldn’t take this drug, people that have this particular mutation should take this drug’” -Eric Lefkofsky, Tempus Co-Founder and CEO Tapping into the estimated $13.8 billion DNA sequencing product market, the startup apparently follows two compensation models depending on client type: Tempus charges hospital systems directly for their services and in the case of individuals or patients, the costs are billed to the insurance provider. Tempus CEO, Eric Lefkofsky is also co-founder of eCommerce giant Groupon and a handful of tech companies with analytics software leanings including Uptake Technologies and Mediaocean. According to the CDC, cancer is rivaled only by heart disease which is the leading cause of death in the U.S. and in March 2017, Mayo Clinic in conjunction with medical device maker Omron Healthcare made a $30 million Series D investment in heart health startup AliveCor.   Kardio Pro, designed by AliveCor, is an AI-powered platform designed for clinicians “to monitor patients for the early detection of atrial fibrillation, the most common cardiac arrhythmia that leads to a five times greater risk of stroke.” Kardia Mobile, AliveCor’s flagship product, is a mobile-enabled EKG. Results of the Kardio Pro investment have yet to be reported. Cleveland Clinic In September 2016, Microsoft announced a collaboration with Cleveland Clinic to help the medical center “identify potential at-risk patients under ICU care.” Researchers used Cortana, Microsoft’s AI digital assistant, to tap into predictive and advanced analytics.  Used by 126 million Windows 10 users each month, Cortana is part of Microsoft’s Intelligent Cloud segment which increased by 6 percent or $1.3 billion in revenue according to the company’s 2016 annual report.   Cortana is integrated into Cleveland Clinic’s eHospital system, a type of command center first launched in 2014 that currently monitors “100 beds in six ICUs” from 7pm to 7am. While improved patient outcomes have been reported by William Morris, MD, Associate CIO, specific improvement measures have not been released.  The Microsoft-Cleveland Clinic partnership is focused on identifying patients at high risk for cardiac arrest. Vasopressors are a medication administered to patients in the event of a cardiac arrest. While part of a “pulseless sudden cardiac arrest management protocol,” vasopressors also raise blood pressure. Researchers aim to predict whether or not a patient will require vasopressors. Data collected from monitored ICUs is stored in Microsoft’s Azure SQL Database, a cloud-based database designed for app developers. Data collection points such as patient vitals and lab data are also fed into the system. A computer model is built from the data that integrates machine learning for predictive analysis. A simple visual representation of Microsoft’s applications at work at Cleveland Clinic, taken from the Microsoft’s Technet Blog Massachusetts General Hospital Currently in the early stages of its AI strategy, in April 2016 NVIDIA announced its affiliation with the Massachusetts General Hospital Clinical Data Science Center as a “founding technology partner.” The Center aims to serve as a hub for AI applications in healthcare for the “detection, diagnosis, treatment and management of diseases.”  Officially presented at the 2016 GPU Technology Conference, NVIDIA DGX-1 is described by the company as a “deep learning supercomputer” and was installed at Mass General (readers unfamiliar with GPU technology may be interested in our NVIDIA executive interview titled “What is a GPU?“). The NVIDIA DGX-1 reportedly costs $129,000. With a hospital database comprised of “10 billion medical images” the server will be initially trained on this data for applications in radiology and pathology. The Center aims to later expand to electronic health records (EHRs) and genomics. If NVIDIA DGX-1 delivers on its promises it could mitigate some of the challenges currently facing the field:  “If we can somehow seamlessly capture the relevant data in a highly structured, thorough, repetitive, granular method, we remove that burden from the physician. The physician is happier, we save the patient money and we get the kind of data we need to do the game-changing AI work.” -Will Jack, Co-founder and CEO of Remedy Health  Johns Hopkins Hospital  In March 2016, Johns Hopkins Hospital announced the launch of a hospital command center that uses predictive analytics to support a more efficient operational flow. The hospital teamed up with GE Healthcare Partners to design the Judy Reitz Capacity Command Center which receives “500 messages per minute” and integrates data from “14 different Johns Hopkins IT systems” across 22 high-resolution, touch-screen enabled computer monitors.  A team of 24 command center staff is able to identify and mitigate risk, “prioritize activity for the benefit of all patients, and trigger interventions to accelerate patient flow.” Since the launch of the command center Johns Hopkins reports a 60 percent improvement in the ability to admit patients “with complex medical conditions” from the surrounding region and country at large.  The hospital also reports faster ambulance dispatches, 30 percent faster bed assignments in the emergency department, and a 21 percent increase in patient discharges before noon among other improvements.   Johns Hopkins leaders recently convened in April 2017 for a two day discussion on how to leverage big data and AI in the area of Precision Medicine. Industry analysts estimate the global Precision Medicine market value at $173 billion by 2024 (see our full article on AI applications in medicine for more use-cases in medicine and pharma). While specific details have not been released, a talk on “how artificial intelligence and deep learning are informing patient diagnosis and management” was presented by three speakers including a VP for IBM Watson Health Group, Shahram Ebadollahi, and Sachi Saria, PhD, Assistant Professor of Computer Science.  Saria’s research on machine learning applications to improve patient diagnoses and outcomes was recently presented at the 11th Annual Machine Learning Symposium at the New York Academy of Sciences. UCLA Medical Center In March 2017 in Washington, D.C., UCLA researchers Dr. Edward Lee and Dr. Kevin Seals presented the research behind the design of their Virtual Interventional Radiologist (VIR) at the Society of Interventional Radiology’s annual conference. Essentially a chatbot, the VIR  “automatically communicates with referring clinicians and quickly provides evidence-based answers to frequently asked questions.”  Currently in testing mode, this first VIR prototype is being used by a small team of UCLA health professionals which includes “hospitalists, radiation oncologists and interventional radiologists” (readers with a deeper interest in cancer treatments may want to read our full article about deep learning applications for oncology). The AI-driven application provides the referring physician with the ability to communicate information to the patient such as an overview of an interventional radiology treatment or next steps in a treatment plan, all in real-time.  VIR was built on a foundation of over 2,000 example data points designed to mirror questions that commonly come up during a consultation with an interventional radiologist. Responses are not limited to text in format and may include “websites, infographics, and custom programs.”  The research team integrated VIR with natural language processing ability using the IBM Watson AI system. In the tradition of  customer service chatbots across industries, if VIR cannot provide an adequate response to a particular inquiry the chatbot provides the referring clinician with contact information for a human interventional radiologist.    With increased use the researchers aim to expand the functionality of the application, for “general physicians interfacing with other specialists, such as cardiologists and neurosurgeons.” In March 2016, UCLA university-based researchers, were published in Nature Scientific Reports with a study combining a special microscope with a deep learning computer program “to identify cancer cells with over 95 percent accuracy.”  Photo (see Photonic time stretch microscope): http://newsroom.ucla.edu/releases/microscope-uses-artificial-intelligence-to-find-cancer-cells-more-efficiently The photonic time stretch microscope, invented by Barham Jalali, the research team’s lead scientist, produces high resolution images and is capable of analyzing 36 million images per second. Deep learning is then used to “distinguish cancer cells from healthy white blood cells.” Blood based-diagnostics are a growing sector and an increasingly competitive space as discussed in a recent Emerj interview with the founder of a leading firm investing in early-stage tech startups: “…Looking at DNA, RNA, proteins, all kinds of biomarker information to diagnose someone as early as possible is definitely a very active area…for example if you look at Grail, the very large spinout from Illumina, they’re very well-funded and they’re trying to use DNA and other information from the blood to be able to detect cancer early.” – Shelley Zhuang, Founder and Managing Partner, Eleven Two Capital Concluding Thoughts on Machine Learning at the Top 5 Hospitals It’s important to note that healthcare machine learning applications (unlike other applications in – say – detecting credit card fraud or optimizing marketing campaigns) struggle with unique constraints. Treating patients is a more delicate procedure than testing an eCommerce up-sell, and with regulatory compliance and a multitude of complex stakeholder relationships (doctors to use the technology, hospital execs to buy it, patients to hopefully benefit from it), we must be somewhat sympathetic with these top hospitals for not having tangible results from AI applications in such a touchy and new field. Our interview with health-tech investor Dr. Steve Gullans covered the unique challenges of hospital AI applications in greater depth. Steve mentioned the overt fear that many specialist physicians feel around AI tools, and the other psychological factors that will likely make hospital adoption slow. When asked how hospitals and healthcare facilities might get around these barriers (assuming the technology will in fact better the lives of patients), he expressed his opinion on where adoptions opportunities may exist: “It is tough, but there’s always a few beachheads that are going to pay off; there are some applications right now where physicians don’t enjoy a particular kind of call or one where having some assistance can actually be a big benefit to everyone involved…I think what you’re going to see is very specific populations within a particular setting, such as calling a stroke in the ER as bleeding or non-bleeding, where there’s a life and death decision that’s very binary…” – Dr. Steve Gullans, Excel Venture Management It’s also important to note that we should remain skeptical of technology applications until quantifiable results can be verified. As in nearly all other AI-infused industries, machine learning in healthcare is resulting in plenty of “technology signaling” (the hyped-up touting of “AI” for the sake of garnering attention and press, and not actually for improving an organizations results). Our Case Study section features real industery use-cases of AI in greater depth – such as this example of Luminoso’s natural language processing work for GlaxoSmithKline It’s mutually advantageous for an AI vendor like NVIDIA or Microsoft to grant a “new and super-fancy” AI technology to a top hospital, and grant the hospital the title of “founding technology partner.” These kinds of events are nearly guaranteed to get press and (probably) reflect favorably upon both parties – whether or not the AI application ever drives results for either the hospital (efficiencies) or patients (better health outcomes). We certainly didn’t compose this article to insult the efforts of any of the hospitals or vendors involved, but we as analysts must remain skeptical until results can be determined. Our aim is to inform business readers (like yourself) of the applications and implications of AI, and we always prefer projects with recorded results rather than “initiatives.” That being said, it’s important for business leaders to understand the common trends of such developments to get a sense of the “pulse” of an industry, and we hope to have done just that in this article. One of the reasons we insist that vendor companies list a client company and quantifiable result in our Emerj AI case studies is because – as with any emerging technology – AI is often used as a signal for the “cutting edge,” a tool for hype and not function. We’re of the belief that some of the hospital AI applications highlighted in this article will in fact make their way to real and ubiquitous use (particularly those which we highlighted in our “insights upfront” section at the beginning of this article). Just when fruitful applications will become commonplace – time will tell. Image credit: Static1 Related Posts Machine Learning in Surgical Robotics - 4 Applications That MatterThe application of robotics in surgery has steadily grown since it began in the 1980s.… Machine Learning in the Asian Pharmaceutical Sector - Current ApplicationsMcKinsey estimated that embarking on digital transformation to restructure value chains and drive R&D innovation… Machine Learning in Orthopedics - Current ApplicationsThere are few companies claiming to offer artificial intelligence solutions to orthopedics companies. We found… Machine Learning for Dermatology - 5 Current ApplicationsDermatology is defined as a branch of medicine primarily focused on the evaluation and treatment… Machine Learning in Radiology - Current ApplicationsIt should come as no surprise that AI has found its way into radiology in… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",How America&#8217;s 5 Top Hospitals are Using Machine Learning Today,https://emerj.com/wp-content/uploads/2018/04/how-americas-5-top-hospitals-are-using-machine-learning-today-690x255.jpg,2017-06-26,Kumba Sennaar,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",2020-03-24,https://emerj.com/ai-sector-overviews/top-5-hospitals-using-machine-learning,,,AI Sector Overviews,2701,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LnRlY2h0YXJnZXQuY29tL2hlYWx0aHRlY2hhbmFseXRpY3MvZmVhdHVyZS9Ib3ctTWFjaGluZS1MZWFybmluZy1pcy1UcmFuc2Zvcm1pbmctQ2xpbmljYWwtRGVjaXNpb24tU3VwcG9ydC1Ub29sc9IBAA?oc=5,How Machine Learning is Transforming Clinical Decision Support Tools - TechTarget,2020-03-26,TechTarget,https://www.techtarget.com,"With the right data, integration methods, and personnel in place, machine learning has the potential to advance clinical decision support and help providers deliver optimal care.",N/A,"Organizations that have access to accurate data, comprehensive integration methods, and skilled personnel can use machine learning to advance clinical decision support systems.","Organizations that have access to accurate data, comprehensive integration methods, and skilled personnel can use machine learning to advance clinical decision support systems.",https://schema.org,,Article,,N/A,N/A,"


Getty Images/
Getty Images/





Feature


How Machine Learning is Transforming Clinical Decision Support Tools


With the right data, integration methods, and personnel in place, machine learning has the potential to advance clinical decision support and help providers deliver optimal care.





Share this item with your network:














































By


Jessica Kent


Published: 26 Mar 2020


 
In the era of value-based healthcare, digital innovation, and big data, clinical decision support systems have become vital for organizations seeking to improve care delivery.







Clinical decision support (CDS) tools have the ability to analyze large volumes of data and suggest next steps for treatment, flagging potential problems and enhancing care team efficiency. 
While these systems can add significant value to the healthcare industry, CDS technologies have also come with substantial challenges. Poorly implemented CDS tools that generate unnecessary alerts often result in alarm fatigue and clinician burnout, trends that can threaten patient safety and lead to worse outcomes.
“Clinical decision support tools have been around for a number of years, but many of them have been somewhat standalone solutions and not well-integrated into the clinical point of care devices that people are using,” Katherine Andriole, director of research strategy and operations at the MGH & BWH Center for Clinical Data Science (CCDS), told HealthITAnalytics.
Vendors, researchers, and developers have worked to overcome these issues, aiming to design solutions that are intuitive, informative, and efficient. At the core of many of these improved CDS tools are technologies that have long occupied the minds of healthcare tech enthusiasts: artificial intelligence and machine learning.

“Clinical decision support tools have been around for a number of years, but many of them have been somewhat standalone solutions and not well-integrated into the clinical point of care devices that people are using.""

“A lot of these mathematical techniques have been around for a long time, but the reason that we're seeing them come to fore now is that things have gone digital,” said Andriole, who is also an associate professor of Radiology at Harvard Medical School, Brigham and Women’s Hospital. 
“We used to do radiology on film. Now we have imaging digitally. We used to have a patient chart that was paper in a folder, now charts are electronic. We have computing that is much faster than what we had, say, 20 years ago, when training machine learning models was very computationally intensive.”
Even with all these advancements, however, the industry still struggles with several foundational problems. Limited data access, a lack of provider education and training, and poor technology integration are all obstacles that many organizations have yet to overcome. 
Applying machine learning and other analytics tools to CDS systems will require stakeholders to address these challenges, leading to more informed decision-making and better patient care.

Improving data quality to build quality algorithms
Machine learning and CDS tools are most effective when they are trained on data that is accurate, clean, and complete. After all, an algorithm’s output is only as good as its input, and in the high-stakes industry of healthcare, the input has to be pretty precise. 



Mark Sendak, Population Health and Data Science Lead, DukeHealth


However, as most healthcare professionals know, medical information isn’t always stored in a standardized way. Data inaccuracies and missing information are all too common, meaning organizations have a lot of work to do before they can even start to develop CDS algorithms. 
“You hear a lot about data quality. As the saying goes, garbage in, garbage out,” said Mark Sendak, MD, population health and data science lead at the Duke Institute for Health Innovation. 
“Electronic health records and the data within them are not necessarily designed for downstream use in algorithms. The user interfaces and databases are designed with other purposes in mind, so there's a lot we have to do to curate and transform data from its raw format into something that we can use in machine learning algorithms.”
Sendak and his team recently developed a machine learning model to predict adult patients’ risk of in-hospital mortality. Before building the tool, the group spent time gathering data and identifying which settings within which hospitals had better or worse mortality rates. While collecting information, researchers discovered that they were missing come crucial data points.
“People often say that mortality is a ‘hard outcome,’ which is something that you can measure and see clearly. What was a little bit surprising was that we don't actually have complete death data, especially for patients who are discharged from the hospital, and this is true of many institutions,” Sendak noted.
“If someone is deceased or becomes deceased within a healthcare facility that we operate, we tend to have very accurate, comprehensive mortality data. But if someone is discharged and that person dies – whether it's one week or 10 years after being discharged – and they don't die in a healthcare facility, there are a lot of gaps in mortality data.”

“Electronic health records and the data within them are not necessarily designed for downstream use in algorithms.""

These data gaps are a major barrier in the machine learning development process, Andriole stated. 
“One of the biggest challenges in training algorithms for machine learning is gaining access to large amounts of data,” she said. “Because there can be security and privacy issues with patient information, not everyone has a great supply of data they can use to train these models.”
In Sendak’s case, he and his team were able to collaborate with local organizations to fill in the mortality data gaps, with great results.
“We worked with our state health department to get data through the vital statistics office, which you can do as a research institution for different uses, and we were able to get state-level data,” he said. 
“The results showed that the model performed on par with state-of-the-art methods. Our goal is that maybe this model will be able to identify patients who have a gap in care, and then we would recommend that these patients have a goals of care conversation during the admission.”



Ronald Summers, MD, NIH Clinical Center


For other organizations, freely accessible datasets may be a viable resource for developing comprehensive CDS tools. Ronald Summers, MD, PhD, senior investigator of the Imaging Biomarkers and Computer-Aided Diagnostics Laboratory at the NIH Clinical Center, recently conducted a study in which his team aimed to extract information from CT scans that providers could use to gain further insights into patient health.
Researchers used publicly available data to train a deep learning model and found that the model was able to accurately identify and analyze certain biomarkers on CT scans, providing clinicians with more actionable decision-making information.
“We had to use manual assessment for the validation of each of the biomarkers, so that meant somebody had to sit down and either trace the edges of livers on CT scans or trace muscles, which is time-consuming and tedious,” Summers explained. 
“To speed up this process, we used anonymized public data sets of traced organs, and we taught a deep learning algorithm how to find our particular biomarkers of interest on the CT scans.”
As more health systems seek to leverage AI and other analytics technologies to improve their CDS capabilities, public datasets like these will help accelerate the process of algorithm development.
“Academic institutions are talking about whether we can partner and create datasets that people can use to train their models. Because we know that contributing more labeled and preprocessed data will help move the field forward,” Andriole said.


Leveraging AI to develop workflow-friendly tools   
Most of the hype that surrounds machine learning in CDS is caused by expectations of advanced, hyper-intelligent tools that can flawlessly detect tumors, lesions, or any other signs of illness.
Numerous studies have demonstrated the ability of AI and other analytics tools to predict kidney disease, identify breast cancer, and accurately forecast leukemia remission rates.
Although it’s easy to get swept up in the excitement about the potential of machine learning in healthcare, organizations should take a more pragmatic stance, Summers said.
“Researchers will continue to identify areas where these tools could be clinically beneficial, but the provider community needs to think about how the information developed by these AI systems can be put into practice in a way that improves care,” he stated.
In reality, most organizations are aiming to use machine learning for more mundane CDS tasks – at least for right now. 
“A lot of people are focused on using AI for diagnostic clinical decision support, where the model would provide additional information to clinicians to help them make their decision,” Andriole said.
“But it’s the workflow and administrative kinds of models – the ones that help with things like patient scheduling or predicting patient no-shows – that are already making an impact. At the center, we focus on a number of things that are not necessarily difficult diagnostic problems, but they are things that might improve the workflow in some way.”



Katherine Andriole, PhD, Center for Clinical Data Science


For example, researchers at CCDS have developed a machine learning algorithm that can detect motion when a patient is undergoing an MRI scan. If a patient moves too much during a scan, the image may be unusable, resulting in a patient having to return to their provider to get another one.
“Our imaging artifact detection tool allows us to fix the problem while the patient is still with us and still in the scanner. We can just go ahead and re-scan them rather than go through the process and cost of having them come back in because their imaging wasn’t adequate,” Andriole explained.
“We're going to see some of these decision support or value-added tools put into the scanners, as well as some of the tools that we use at the point of care and in radiology.”
For Sendak, tools that will optimize providers’ day-to-day job functions are top of mind. Understanding how information moves through the system is critical for improving care decisions, he emphasized.
“In our own system, it's always about workflow. Who is the right person to share this information with, and when? At what time, and what are they going to do with it?” Sendak said.
“We try to think through the associated actions and decisions that people need to make. We ask, ‘Okay, are all patients identified by the model and reviewed by a clinician confirmed to have a goals of care conversation?’”
Including humans in the CDS design and implementation process is also essential for success, he noted. Organizations that rely only on advanced solutions to resolve major CDS pain points probably won’t see the best results.
“There's lots of unhelpful, annoying clinical decision support. Machine learning itself will not solve the problems that clinical decision support already has, but it can make certain parts of clinical decision support more effective,” said Sendak.
“In almost all of our projects, we have a human in the loop. These are clinical decision support systems. They're not driving clinical decisions, and models are wrong sometimes.”


Bigger teams, broader skillsets, better decisions 
When building an algorithm that will help support clinical care decisions, it’s necessary to include individuals from all sectors of the healthcare industry. These tools will impact nearly everyone involved in the care delivery process, from providers and staff to patients themselves. Having a team that trusts these models will increase the chance that these algorithms will improve patient care.
“If an AI technique works well, it doesn't necessarily mean that it will move from the bench to the bedside. There are a lot of factors that affect whether these techniques become available for clinical use. There are different people with different viewpoints and interests, and the process of making these tools available often requires skills outside those of the technology developers,” Summers said.
Collaborating on the best ways to integrate CDS tools with care practices will ensure clinicians can do their jobs successfully.
“Developing machine learning for CDS is a team sport,” said Andriole. 
“You need machine learning experts. You need clinicians. You need to understand the clinical use case. We need to understand oftentimes when a model fails, a clinician can look and understand why. We really feel that having clinicians work alongside data scientists is one way we're going to see advancement in this field.”
Going forward, healthcare organizations also may need to expand their pool of employees to include tech experts, Sendak added.
“You don't typically think of health systems hiring teams of data scientists and data engineers. But the institutions that are leading the way in AI do have those jobs and those functions. It’s not just a technology investment, it’s an investment in people, skills, and capabilities,” he said.

“If an AI technique works well, it doesn't necessarily mean that it will move from the bench to the bedside.""

Education and training will also play a key role, Andriole said.
“When new tools come along, we have to educate people on how to use them and how to assess the outputs. We don’t want clinicians to just blindly accept recommendations, but to analyze them and say, ‘Yeah, okay, this is what this means. I understand enough about how this works,’” she said.
“It's not enough knowledge to build a model on their own, but they’ll understand enough to be able to use the tool.”
In the past, AI adoption in healthcare has been met with some degree of resistance by providers, partly due to valid concerns over the ethical implications of using these tools to deliver care.
However, recent research suggests that the tides may be changing. A global survey from Philips showed that 79 percent of healthcare professionals under 40 are confident that digital health technologies can achieve better patient outcomes, while 74 percent believe these tools will improve the patient experience.
As machine learning and clinical decision support continue to evolve, the next generation of providers will likely be well-equipped to understand and apply these tools in regular care delivery.
“People are very interested in learning about how they can use these methods to solve clinical problems,” Andriole said. “And it’s not just computer scientists and data scientists who are interested, but also a lot of our clinical trainees.” 
In the not-so-distant future, machine learning and AI-fueled CDS tools just may become the healthcare industry’s standard.
“We may be able to start automating healthcare in the same ways that other industries have been automated,” Andriole concluded.


Next Steps
Understanding the Basics of Clinical Decision Support SystemsTurning Healthcare Big Data into Actionable Clinical Intelligence





Dig Deeper on Artificial intelligence in healthcare



GAO Appoints New Members to Health IT Advisory Committee




By: Hannah Nelson




Clinicians May Be Unprepared for Widespread CDS Algorithm Integration




By: Shania Kennedy




Clinical Decision Support Tools Did Not Reduce CVD Disparities





Intermountain Develops FHIR-Based Platform for Clinical Decision Support




By: Hannah Nelson







Sponsored News


Hybrid Cloud, Consumption-Based IT: Empowering Transformation in Healthcare ...
–HPE


Driving Digital Transformation in Healthcare
–Dell Technologies


Flexible IT: When Performance and Security Can’t Be Compromised
–Dell Technologies

See More





Related Content


How Clinical Decision Support Adherence Leads to ...
– Healthtech Analytics


Understanding the Basics of Clinical Decision Support...
– Healthtech Analytics


Responsible AI Deployment in Healthcare Requires ...
– Healthtech Analytics








",How Machine Learning is Transforming Clinical Decision Support Tools,https://cdn.ttgtmedia.com/rms/onlineimages/machine_learning_g1307219089.jpg,2020-03-26T08:05Z,"[{'name': 'Jessica Kent', '@type': 'Person'}]","{'name': 'TechTarget', 'logo': {'url': 'https://cdn.ttgtmedia.com/rms/amp/amp_teal_logo_115_60.png', 'height': 60, 'width': 115, '@type': 'ImageObject'}, '@type': 'Organization'}",,"{'@type': 'WebPage', '@id': 'https://www.techtarget.com/healthtechanalytics/feature/How-Machine-Learning-is-Transforming-Clinical-Decision-Support-Tools'}",How Machine Learning is Transforming Clinical Decision Support Tools,,,,"{'cssSelector': '.paywall', '@type': 'WebPageElement', 'isAccessibleForFree': False}",False,,,,,,,,,,
https://news.google.com/rss/articles/CBMiL2h0dHBzOi8vd3d3LmV1cmVrYWxlcnQub3JnL25ld3MtcmVsZWFzZXMvNjc5MzQx0gEA?oc=5,Artificial intelligence for very young brains - EurekAlert,2020-03-26,EurekAlert,https://www.eurekalert.org,N/A,N/A,Montreal's CHU Sainte-Justine children's hospital and the ÉTS engineering school pool their expertise to develop an innovative new technology for the segmentation of neonatal brain images.,Montreal's CHU Sainte-Justine children's hospital and the ÉTS engineering school pool their expertise to develop an innovative new technology for the segmentation of neonatal brain images.,,,,,N/A,N/A,"



                                    News Release 
                                                                     26-Mar-2020
                    


                Artificial intelligence for very young brains
            
Peer-Reviewed Publication
University of Montreal



















image: Example of segmentation produced by the tool which separates the structures in cerebrospinal fluid (red), grey matter (blue) and white matter (yellow) from MRI images T2 (middle column) and T1 (right column).
view more 
Credit: CHU Sainte-Justine



Canadian scientists have developed an innovative new technique that uses artificial intelligence to better define the different sections of the brain in newborns during a magnetic resonance imaging (MRI) exam. 
The results of this study -- a collaboration between researchers at Montreal's CHU Sainte-Justine children's hospital and the ÉTS engineering school -- are published today in Frontiers in Neuroscience.
""This is one of the first times that artificial intelligence has been used to better define the different parts of a newborn's brain on an MRI: namely the grey matter, white matter and cerebrospinal fluid,"" said Dr. Gregory A. Lodygensky, a neonatologist at CHU Sainte-Justine and professor at Université de Montréal.
""Until today, the tools available were complex, often intermingled and difficult to access,"" he added.
In collaboration with Professor Jose Dolz, an expert in medical image analysis and machine learning at ÉTS, the researchers were able to adapt the tools to the specificities of the neonatal setting and then validate them.
This new technique allows babies' brains to be examined quickly, accurately and reliably. Scientists see it as a major asset for supporting research that not only addresses brain development in neonatal care, but also the effectiveness of neuroprotective strategies.
In evaluating a range of tools available in artificial intelligence, CHU Sainte-Justine researchers found that these tools had limitations, particularly with respect to pediatric research. Today's neuroimaging analysis programs are primarily designed to work on ""adult"" MRIs. The cerebral immaturity of newborns, with an inversion of the contrasts between grey matter and white matter, complicates such analyses.
Inspired by Dolz's most recent work, the researchers proposed an artificial neural network that learns how to efficiently combine information from several MRI sequences. This methodology made it possible to better define the different parts of the brain in the newborn automatically and to establish a new benchmark for this problem.
""We've decided not only to share the results of our study on open source, but also the computer code, so that brain researchers everywhere can take advantage of it, all of which benefits patients,"" said Dolz.
CHU Sainte-Justine is one of the most important players in the Canadian Neonatal Brain Platform and also has one of the largest neonatal units in Canada specializing in neurodevelopment. As part of the platform, research teams are implementing projects like this one with the aim of improving the long-term health of those newborns who are most vulnerable to brain injury.
""In studies to assess the positive and negative impact of different therapies on the maturation of babies' brains, we need to have the ability to quantify brain structures with certainty and reliability,"" Lodygensky said. ""By offering the scientific community the fruits of all our discoveries, we are helping them, while generating an extraordinary benefit for at-risk newborns.""
He added: ""We now want to democratize this tool so that it becomes the benchmark for the study of brain structure in newborns around the world. To this end, we are continuing to work on its generalizability -- that is, its use on MRI data acquired in different hospitals.""
###
About this study
""Using deep convolutional neural networks for neonatal brain image segmentation"" was published March 26, 2020 in Frontiers in Neuroscience. The first author is Yang Ding, PhD, under the direction of Gregory A. Lodygensky. The primary authors are Gregory A. Lodygensky, MD, Clinical Associate Professor in the Department of Pediatrics at Université de Montréal and Clinician-Researcher at CHU Sainte-Justine, and Jose Dolz, PhD, Assistant Professor in the Department of Software Engineering and Information Technology at the École de technologie supérieure (ÉTS). The study was supported by the Brain Canada Foundation.
About the CHU Sainte-Justine Research Center
The CHU Sainte-Justine Research Center is a leading mother-child research institution affiliated with Université de Montréal. It brings together more than 210 research investigators, including over 110 clinician-scientists, as well as 450 graduate and postgraduate students focused on finding innovative prevention means, faster and less invasive treatments, as well as personalized approaches to medicine. The Center is part of CHU Sainte-Justine, which is the
largest mother-child center in Canada. For more information, go to research.chusj.org.
About ÉTS
ÉTS is one of the ten constituents of the University of Québec network. It trains engineers and researchers recognized for their practical and innovative approach, the development of new technologies and their ability to transfer their knowledge to private enterprise. CSRankings places ÉTS in the vanguard of the artificial vision branch of artificial intelligence: it ranks first in Québec and sixth in Canada for scientific publications in this domain. For more information, visit: etsmtl.ca.






Journal
Frontiers in Neuroscience


DOI
10.3389/fnins.2020.00207 





Disclaimer: AAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert system.











",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vd3d3LmZpZXJjZWVsZWN0cm9uaWNzLmNvbS9zZW5zb3JzL2FpLW1lZXRzLWZhcm1lci1oZWxwaW5nLW1ha2UtZWFjaC1wbGFudC1jb3VudNIBAA?oc=5,"AI meets the farmer, helping make each plant count - FierceElectronics",2020-03-26,FierceElectronics,https://www.fierceelectronics.com,Agriculture is not one of the first markets people connect with fledgling technologies such as artificial intelligence (AI).,"agriculture,artificial intelligence,machine learning,Sensor Applications,Sensors At Work,John Deere,Fierce Electronics Homepage,Electronics,IoT & Wireless,Sensors","Agriculture is not one of the first markets people connect with fledgling technologies such as artificial intelligence (AI). | Agriculture is not one of the first markets people connect with fledgling technologies such as artificial intelligence (AI). But for agricultural and construction equipment manufacturer John Deere, AI is already starting to help farmers improve crop yield and maintain better control of daily farm tasks.","Agriculture is not one of the first markets people connect with fledgling technologies such as artificial intelligence (AI). | Agriculture is not one of the first markets people connect with fledgling technologies such as artificial intelligence (AI). But for agricultural and construction equipment manufacturer John Deere, AI is already starting to help farmers improve crop yield and maintain better control of daily farm tasks.",https://schema.org/,"{'@type': 'NewsArticle', 'headline': 'AI meets the farmer, helping make each plant count', 'articleSection': None, 'keywords': 'Sensors', 'description': 'John Deere is using AI with its farm machinery to help farmers improve crop yield and maintain better field quality.', 'datePublished': '2020-03-26T18:18:22', 'isAccessibleForFree': True, 'dateModified': '1712371191', 'author': [[{'@type': 'Person', 'name': 'Spencer Chin', 'url': 'https://www.fierceelectronics.com/person/spencer-chin'}]], 'publisher': {'@type': 'Organization', 'name': 'Fierce Electronics', 'url': 'https://www.fierceelectronics.com'}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.fierceelectronics.com/sensors/ai-meets-farmer-helping-make-each-plant-count'}, 'image': 'https://qtxasset.com/quartz/qcloud4/media/image/fierceelectronics/1585254912/see_and_spray.png/see_and_spray.png?VersionId=ekdGBiC.ez2hePABM4cX4uxgoVWdQ4bt'}",,,"Fierce Electronics Homepage,Electronics,IoT & Wireless",N/A,"

































Fierce Network


Fierce Electronics


Sensors Converge


Electronics Events






Advertise


About Us








 

 


























 










Electronics


IoT & Wireless


Sensors


Embedded


AutoTech






Resources



Industry Events


Whitepapers


Webinars


Survey



 Events 

Subscribe
















 




Subscribe





























Electronics


IoT & Wireless


Sensors


Embedded


AutoTech






Resources



Industry Events


Whitepapers


Webinars


Survey



 Events 

Subscribe










Fierce Network


Fierce Electronics


Sensors Converge


Electronics Events






Advertise


About Us








 

 


















Brought to you by:










































Sensors




AI meets the farmer, helping make each plant count





By 
Spencer Chin





Mar 26, 2020 2:18pm




agriculture
artificial intelligence
machine learning
Sensor Applications














John Deere used technology acquired by Blue River Technology to develop a weed control system that precisely dispenses herbicides to reduce pesticide use and improve environmental quality. (Blue River Technology)
Agriculture is not one of the first markets people connect with fledgling technologies such as artificial intelligence (AI). But for agricultural and construction equipment manufacturer John Deere, AI is already starting to help farmers improve crop yield and maintain better control of daily farm tasks.In a phone interview with FierceElectronics earlier this week, Sona Raziabeegum, Strategy Lead, Digital Solutions for John Deere Intelligent Solutions Group, said AI is being adopted as part of high technology solutions the company is implementing for agricultural facilities which must deal with variables such as bad weather, poor soil conditions and the constraints of a short growing season.“There is not a lot of do-over in agriculture,” said Raziabeegum. “We want to convey the message that there is a lot of great technology in agriculture solving real problems. It is not technology looking for a solution.”RELATED: Ethylene-detecting sensor could help prevent food wasteRaziabeegum gave the example of an application where machine learning was used to “train” vision cameras mounted on farm equipment to recognize bad wheat as it is being harvested into a grain bin. A neural mask processes this vision data and instructs the machine to separate the bad grain.In addition, Raziabeegum noted that the neural mask is programmed to spot any debris that may get into the grain bin, which would also adversely affect grain quality.The benefits are better quality of grain and a reduced need for skilled labor. “You’re doing this in real time. Farmers operate on thin margins and are open to the technology’s benefits on their yield and crop quality.”In another application, Raziabeegum said a herbicide sprayer system, called See and Spray, employed vision cameras with a neural net that helps precisely identify where the herbicide should be sprayed. The technology is currently being demonstrated in Mississippi for a cotton field and in a midwestern location for corn, she noted.“We believe the technology in this application can reduce herbicide use by as much as 90%, which helps achieve the goal of using less chemicals in farming.”Because AI has not been used in agriculture previously, Raziabeegum said John Deere invested a lot of time and effort learning to apply the technology in a new use case. It is a different set of parameters than say, automotive, which Raziabeegum said agriculture is often compared to.“In agriculture, it is not just traveling from point A to point B. Once you get there, you need to perform a complicated task. Also, because [of] the unpredictability of agriculture, your AI models have to be a lot more sophisticated in order to apply to crops.”Because agriculture is largely an outdoor application, there’s no enclosed, central onsite facility where one can implement a server and a communications network. Edge computing, with processing onboard the machines doing the work, becomes vitally important.“Connectivity not a given,” Raziabeegum explained. “About 95% of computing on the edge needs inference in real time. Our edge network architecture had to be custom designed.”Because John Deere is largely an equipment manufacturer, it had to acquire some its expertise in AI and machine learning from outside the company. The firm did just that in 2017, when it acquired Blue River Technology, a company specializing in applying machine learning to agriculture, based in Sunnyvale, California. Blue River developed the See and Spray integrated computer vision and machine learning technology for herbicide spraying that John Deere is now implementing.According to Raziabeegum, the average size of the farm John Deere is supporting is 5,000 acres. But she emphasized the company is able to scale technology solutions for facilities that are smaller as well.For the future, Raziabeegum foresees expanding the use of AI and machine learning to develop complete, detailed plant growing and maintenance plans. She also expects AI to be leveraged more for construction applications.

agriculture
artificial intelligence
machine learning
Sensor Applications
Sensors At Work
John Deere
Electronics
IoT & Wireless
Sensors









Educational ResourcesFrom prototype to production with Qube and ParticleFrom 10 seconds to 1 with Field Intell and Particle30 billion liters of water saved with Alert LabsFrom 10 seconds to 1 with Field Intell and ParticleFrom prototype to production with Qube and Particle30 billion liters of water saved with Alert Labs


Related ContentWi-Fi HaLow moves forward after completing WBA field trialsJul 15, 2024 12:22pmSamsung speeds production of AI chips, making use of new GAA techJul 15, 2024 11:08amDell now shipping PowerEdge with AMD MI300X acceleratorsJul 14, 2024 01:15pmMicrochip eyes skrocketing market for spaceflight computingJul 12, 2024 04:16pm







See more articles










 



 

 








Connect



The Team


Advertise




Join Us



Newsletters


Resources


RSS Feeds




Our Brands



Fierce Wireless


Fierce Telecom


StreamTV Insider


Fierce Electronics




Our Events



Electronics


Entertainment


Wireless & Telecom

















©2024 Questex LLC All rights reserved.
Terms of use
Privacy Policy
Privacy Settings











",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMilwFodHRwczovL3d3dy5taWNyb3NvZnQuY29tL2VuLXVzL3Jlc2VhcmNoL3ZpZGVvL2Rlc2lnbmluZy1jb21wdXRlci12aXNpb24tYWxnb3JpdGhtcy10by1kZXNjcmliZS10aGUtdmlzdWFsLXdvcmxkLXRvLXBlb3BsZS13aG8tYXJlLWJsaW5kLW9yLWxvdy12aXNpb24v0gEA?oc=5,Designing Computer Vision Algorithms to Describe the Visual World to People Who Are Blind or Low Vision - Microsoft,2020-03-26,Microsoft,https://www.microsoft.com,N/A,N/A,"A common goal in computer vision research is to build machines that can replicate the human vision system (for example, detect an object or scene category, describe an object or scene, or locate an object). A natural grand challenge for the artificial intelligence community is to design such technology to assist people who are blind […]",N/A,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://www.microsoft.com/en-us/research/video/designing-computer-vision-algorithms-to-describe-the-visual-world-to-people-who-are-blind-or-low-vision/', 'url': 'https://www.microsoft.com/en-us/research/video/designing-computer-vision-algorithms-to-describe-the-visual-world-to-people-who-are-blind-or-low-vision/', 'name': 'Designing Computer Vision Algorithms to Describe the Visual World to People Who Are Blind or Low Vision - Microsoft Research', 'isPartOf': {'@id': 'https://www.microsoft.com/en-us/research/#website'}, 'primaryImageOfPage': {'@id': 'https://www.microsoft.com/en-us/research/video/designing-computer-vision-algorithms-to-describe-the-visual-world-to-people-who-are-blind-or-low-vision/#primaryimage'}, 'image': {'@id': 'https://www.microsoft.com/en-us/research/video/designing-computer-vision-algorithms-to-describe-the-visual-world-to-people-who-are-blind-or-low-vision/#primaryimage'}, 'thumbnailUrl': 'https://www.microsoft.com/en-us/research/uploads/prod/2021/05/3pmrV8aVCes.jpg', 'datePublished': '2020-03-27T02:30:05+00:00', 'dateModified': '2021-05-27T02:38:33+00:00', 'breadcrumb': {'@id': 'https://www.microsoft.com/en-us/research/video/designing-computer-vision-algorithms-to-describe-the-visual-world-to-people-who-are-blind-or-low-vision/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.microsoft.com/en-us/research/video/designing-computer-vision-algorithms-to-describe-the-visual-world-to-people-who-are-blind-or-low-vision/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.microsoft.com/en-us/research/video/designing-computer-vision-algorithms-to-describe-the-visual-world-to-people-who-are-blind-or-low-vision/#primaryimage', 'url': 'https://www.microsoft.com/en-us/research/uploads/prod/2021/05/3pmrV8aVCes.jpg', 'contentUrl': 'https://www.microsoft.com/en-us/research/uploads/prod/2021/05/3pmrV8aVCes.jpg', 'width': 1280, 'height': 720}, {'@type': 'BreadcrumbList', '@id': 'https://www.microsoft.com/en-us/research/video/designing-computer-vision-algorithms-to-describe-the-visual-world-to-people-who-are-blind-or-low-vision/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.microsoft.com/en-us/research/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Designing Computer Vision Algorithms to Describe the Visual World to People Who Are Blind or Low Vision'}]}, {'@type': 'WebSite', '@id': 'https://www.microsoft.com/en-us/research/#website', 'url': 'https://www.microsoft.com/en-us/research/', 'name': 'Microsoft Research', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.microsoft.com/en-us/research/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,N/A,N/A,"



Designing Computer Vision Algorithms to Describe the Visual World to People Who Are Blind or Low Vision







A common goal in computer vision research is to build machines that can replicate the human vision system (for example, detect an object or scene category, describe an object or scene, or locate an object). A natural grand challenge for the artificial intelligence community is to design such technology to assist people who are blind to overcome their real daily visual challenges.
In this webinar with Dr. Danna Gurari, Assistant Professor in the School of Information at the University of Texas at Austin, and Dr. Ed Cutrell, Senior Principal Researcher in the Microsoft Research Ability Group, learn how computer vision researchers are working to create vision systems adapted to the needs of those who use them. By creating new dataset challenges, the researchers aim to empower the artificial intelligence community to work on real use cases.
To encourage the larger artificial intelligence community to collaborate on developing methods for assistive technology, we introduce the first dataset challenges with data that originates from people who are blind. Our data comes from over 11,000 people in real-world scenarios who were seeking to learn about the physical world around them. More broadly, this dataset serves as a great catalyst for uncovering hard artificial intelligence challenges that must be addressed to create more robust systems across many contexts and scenarios.
Together, we’ll explore:

Creating tools for people who are blind or have low vision that match their needs and complement their capabilities
Key challenges of teaching computers how to automatically describe pictures taken by people who are blind or low vision
Several potential solutions to make computers more accurately address the needs of people who are blind or low vision

Resource list:

2021 VizWiz Grand Challenge Workshop (opens in new tab)
Image Accessibility (opens in new tab) (Project page)
Ability (opens in new tab) (Research group)
Project Tokyo (opens in new tab)
AI and Accessibility: A Discussion of Ethical Considerations (opens in new tab) (Publication)
“Person, Shoes, Tree. Is the Person Naked?” What People with Vision Impairments Want in Image Descriptions (opens in new tab) (Publication)
Inclusive design for all, or ICT4D and 4U! with Dr. Ed Cutrell (opens in new tab) (Podcast)
AI for Accessibility Grants (opens in new tab)
Ed Cutrell (opens in new tab) (Researcher profile)
Danna Gurari (opens in new tab) (Researcher profile)

*This on-demand webinar features a previously recorded Q&A session and open captioning.
This webinar originally aired on March 26, 2020
Explore more Microsoft Research webinars: https://aka.ms/msrwebinars (opens in new tab)
Opens in a new tab




Date:


				March 26, 2020			



Speakers:
Danna Gurari, Ed Cutrell


Affiliation:
School of Information at University of Texas at Austin, Microsoft Research








			Speakers		






 



									Ed Cutrell								


								Sr. Principal Research Manager							









		Related Links	



Research Area



									Algorithms								



									Graphics and multimedia								



									Hardware and devices								



									Human-computer interaction								



									Search and information retrieval								



									Social sciences								



									Technology for emerging markets								




Research Lab



									Microsoft Research Lab - Redmond								




Group



									Ability								




Project



									Project Tokyo								



									Image Accessibility								




Publication



									AI and Accessibility: A Discussion of Ethical Considerations								



									""Person, Shoes, Tree. Is the Person Naked?"" What People with Vision Impairments Want in Image Descriptions								









		Watch Next	






 




								Microsoft Research India - who we are.							


							September 15, 2023						

Speakers: 


												Kalika Bali,											

												Sriram Rajamani,											

												Venkat Padmanabhan											

, et. al.









",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvdGhlLXJvYm90cy1hcmUtcmVhZHktYXMtdGhlLWNvdmlkLTE5LXJlY2Vzc2lvbi1zcHJlYWRzL9IBAA?oc=5,The robots are ready as the COVID-19 recession spreads | Brookings - Brookings Institution,2020-03-24,Brookings Institution,https://www.brookings.edu,Any coronavirus-related recession is likely to bring about a spike in labor-replacing automation.,N/A,Any coronavirus-related recession is likely to bring about a spike in labor-replacing automation.,N/A,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/the-robots-are-ready-as-the-covid-19-recession-spreads/', 'url': 'https://www.brookings.edu/articles/the-robots-are-ready-as-the-covid-19-recession-spreads/', 'name': 'The robots are ready as the COVID-19 recession spreads | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/the-robots-are-ready-as-the-covid-19-recession-spreads/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/the-robots-are-ready-as-the-covid-19-recession-spreads/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2020/03/2020-03-11T182140Z_1790027195_RC2UHF92OP6R_RTRMADP_3_HEALTH-CORONAVIRUS-NEW-YORK-WESTCHESTER.jpg?quality=75', 'datePublished': '2020-03-24T18:27:54+00:00', 'dateModified': '2022-03-09T04:51:00+00:00', 'description': 'Any coronavirus-related recession is likely to bring about a spike in labor-replacing automation.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/the-robots-are-ready-as-the-covid-19-recession-spreads/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/the-robots-are-ready-as-the-covid-19-recession-spreads/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/the-robots-are-ready-as-the-covid-19-recession-spreads/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2020/03/2020-03-11T182140Z_1790027195_RC2UHF92OP6R_RTRMADP_3_HEALTH-CORONAVIRUS-NEW-YORK-WESTCHESTER.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2020/03/2020-03-11T182140Z_1790027195_RC2UHF92OP6R_RTRMADP_3_HEALTH-CORONAVIRUS-NEW-YORK-WESTCHESTER.jpg?quality=75', 'width': 2321, 'height': 1547, 'caption': 'A worker looks out from a near empty restaurant on North Avenue during the coronavirus outbreak in New Rochelle, New York, U.S., March 11, 2020. REUTERS/Mike Segar'}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/the-robots-are-ready-as-the-covid-19-recession-spreads/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'The robots are ready as the COVID-19 recession spreads'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,N/A,N/A,"

 Back to Janesville 









                        Back to Janesville 
",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS90ZWNobm9sb2d5LzIwMjAvMDMvMjMvZmFjZWJvb2stbW9kZXJhdG9ycy1jb3JvbmF2aXJ1cy_SAQA?oc=5,Facebook sent home thousands of human moderators due to the coronavirus. Now the algorithms are in charge - The Washington Post,2020-03-24,The Washington Post,https://www.washingtonpost.com,"Facebook, YouTube and Twitter’s content moderators were sent home due to the coronavirus, forcing the companies to rely more on algorithms to police content in the interim.","facebook, content moderation, content reviewers, automation, artificial intelligence, Mark zuckerberg, algorithms","Facebook, YouTube and Twitter’s content moderators were sent home due to the coronavirus, forcing the companies to rely more on algorithms to police content in the interim.","Facebook, YouTube and Twitter’s content moderators were sent home due to the coronavirus, forcing the companies to rely more on algorithms to police content in the interim.",https://schema.org,,BreadcrumbList,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}]",Technology,N/A,"The social networking giant sent its content moderators home and will rely more on algorithms in the interim (The Washington Post illustration; iStock)ShareComment on this storyComment72Add to your saved storiesSaveSAN FRANCISCO — Early this month, most Facebook employees packed up and readied to work from home as the novel coronavirus spread around the world. Despite a company-wide mandate, however, the social networking giant had not figured out how to conduct its most sensitive work remotely: removing pornography, terrorism, hate speech and other unwanted content from across its site.Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeThe people who do that sensitive work — nearly 15,000 contractors at 20 sites globally — continued to come to the office until last Monday, when public pressure, internal protests and quarantine measures around the world pushed Facebook to make a drastic move to shutter its moderation offices.But Facebook’s decision to place that army of moderators on paid leave paves the way for another challenge, forcing the company to police disinformation, medical hoaxes, Russian trolls and the general ugliness of the Internet without them.As misinformation about the novel coronavirus continues to spread, here are some important tips to keep in mind when consuming news about the outbreak. (Video: The Washington Post)Facebook, Google and Twitter scramble to stop misinformation about coronavirusWhile Facebook, YouTube, Twitter and other companies have long touted artificial intelligence and algorithms as the future of policing problematic content, they’ve more recently acknowledged that humans are the most important line of defense. Those contractors, who are paid a fraction of what full-time workers earn, spend hours a day reviewing material flagged as illegal or disturbing, removing posts that cross the line and often suffering psychological harm from the exposure.AdvertisementStory continues below advertisementStill, chief executive Mark Zuckerberg said on a media call Wednesday that Facebook will be forced during the pandemic to rely more heavily on artificial intelligence software to make those judgment calls. The company also will train full-time employees to devote “extra attention” to highly sensitive content, such as any involving suicide, child exploitation and terrorism. Users should expect more mistakes while Facebook triages the process, he said, in part because a fraction of the humans will be involved and because software makes more blunt decisions than humans.💻Follow TechnologyFollowZuckerberg acknowledged the decision could result in “false positives,” including removal of content that should not be taken down.It will “create a trade-off against some other types of content that may not have as imminent physical risks for people.“ Still, he hopes to train more people as quickly as possible because he was “personally quite worried that the isolation from people being at home could potentially lead to more depression or mental health issues, and we want to make sure that we are ahead of that in supporting our community.”AdvertisementStory continues below advertisementZuckerberg’s admission reflects the complex choices and trade-offs Silicon Valley giants are making in the face of a mounting global health crisis. The companies can protect workers and comply with local stay home orders. But that choice could jeopardize the safety of the billions of users around the world, many of whom are quarantined at home, on the Internet all day and exposed to more potentially disturbing material than before.YouTube also announced temporary plans last week to rely more heavily on automated systems to reduce the number of people in the office, something the company warned could prompt a slower appeals process for video content creators and more unreviewed content barred from search or its homepage. The same day, Twitter said it would do the same. Because the automated systems may cause mistakes, it won’t permanently suspend accounts during this time. It’s also triaging to prioritize policing potentially more harmful violations.Facebook, YouTube, Twitter and other social media companies have faced significant past challenges to policing content, from the live video posted during the Christ Church, New Zealand, shooting to disinformation campaigns by Russian trolls during the 2016 presidential election. The decision to send workers home comes during a presidential election year when foreign and domestic users are actively trying to shape public debate using disinformation that might be spotted only by a human eye.AdvertisementStory continues below advertisementThat pressure is heightened as disinformation regarding the novel coronavirus surges. On Facebook-owned WhatsApp, chat groups are spreading unverified information about flights, hotels and schools in connection with the virus, as well as misinformation about potential government crackdowns and how the disease is spreading. On Facebook, a fake letter circulated about an outbreak in Los Angeles, and there were pervasive posts about fake cures and falsehoods that the U.S. government created coronavirus.It’s not just social media: Some consumers are getting fake texts to their phones warning of a nationwide lockdown.White House asks Silicon Valley for help to combat coronavirus, track its spread and stop misinformationFollowing the 2016 presidential election, Facebook in particular hired thousands of third-party moderators in the Philippines, India, Dublin and the United States to police the site and shore up its reputation. The moderators, who work for outsourcing companies like Accenture and Cognizant, are contractors and typically receive less pay and fewer benefits than actual employees.AdvertisementStory continues below advertisementThe decision to send the humans home and rely more on technology to police the sites concerned some researchers.“They haven’t made enough leaps and bounds in artificial intelligence to take away the best tool we have: human intelligence to do the discernment,” said Mary Gray, senior principal researcher at Microsoft Research and co-author of “Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass.”“This is a mess.”Millions of tweets peddled conspiracy theories about coronavirus in other countries, an unpublished U.S. report says“We’re focused on keeping people safe and informed while making sure they can share information and connect with one another during this crisis,"" said Facebook spokesman Drew Pusateri. ""But as we said in a recent update on our content review, we anticipate that some mistakes will occur as we adjust to a modified workforce with a heavier reliance on automation.”AdvertisementStory continues below advertisementFacebook is making the change in large part because it considers the work too sensitive for third party moderators to do from home because, among other reasons, it involves reviewing people’s private Facebook accounts. The company also acknowledges it is a traumatic job and workers would receive less support at home. Typically, moderators work in call centers where every movement, from breaks to keystrokes to judgments over content, is heavily managed and monitored.The company says that may change as the coronavirus emergency evolves.Content moderators at YouTube, Facebook and Twitter see the worst of the web — and suffer silentlyFacebook offered more clarity on its plans in a company blog post late Thursday. When users report content for violating policy, they will see a message explaining there are fewer reviews and Facebook is prioritizing content that poses the greatest potential harm.AdvertisementStory continues below advertisement“This means some reports will not be reviewed as quickly as they used to be and we will not get to some reports at all,” according to the blog post. Reducing the workforce also will alter the appeals process for users who believe their content was removed in error. People can still report they disagree with Facebook’s decision.We’ll ”monitor that feedback to improve our accuracy, but we likely won’t review content a second time,” the company said.Roughly 95 percent of posts involving adult nudity, terrorism, child exploitation, suicide and self-harm that the company ultimately takes down are flagged by algorithms before Facebook users have a chance to report them, according to the company’s latest community standards enforcement report. (The company does not attempt to estimate the total number of problematic posts that appear on the platform, only whether the content that was taken down was reported.)AdvertisementStory continues below advertisementBut for more nuanced categories of speech, the company’s systems often are less effective. Artificial intelligence catches only 16 percent of posts involving bullying and harassment on Facebook, resulting in more than 80 percent of posts reported to the company. Artificial intelligence catches about 80 percent of hate speech.Those numbers have led company officials to realize human judgment still is necessary to monitor more sensitive areas of speech, such as racism and political disinformation.“I think there will always be people” making judgment calls over content, Zuckerberg said in a Washington Post interview last year.Silicon Valley’s two-tiered system for white-collar workers is under pressure as coronavirus spreadsAlready there are signs of potential problems. Early last week, legitimate articles with accurate information about the virus were being removed from Facebook. Zuckerberg said it was caused by a bug in the company’s spam detection system that was unrelated to its triaging of content moderation during the pandemic. “The system is fixed, those posts are back up, and hopefully we won’t have that issue again anytime soon,” he said on the media call last week.AdvertisementStory continues below advertisementAs Facebook moves to a more technology-driven response to policing content, it will prove a major test for the industry, said Jeff Kosseff, a cybersecurity professor and author of “The 26 Words That Created the Internet.”“It will tell us a lot about the state of automated moderation,” Kosseff said. “We don’t really know what exactly tech companies are doing and how effective it is,” although they have been more transparent.UCLA professor Sarah T. Roberts, author of “Behind the Screen: Content Moderation in the Shadows of Social Media,” said Facebook’s hand may have been forced. In Manila, the Filipino capital where Facebook indirectly employs thousands of content moderators, the government enacted a citywide quarantine.Regardless of Facebook’s motivation, Roberts said the experience will reveal how much human reviewers impact our collective well-being and experience of the Internet. It may even shift the Silicon Valley ideology that places a primacy on problem-solving through engineering.“We actually might not be able to code our way out of coronavirus,” she said.Coronavirus: What you need to knowSummer covid uptick: If you’re hearing about more people testing positive or getting sick, it’s no surprise, because data shows another covid wave forming. Nearly two-thirds of infections are caused by KP variants dubbed FLiRT, according to data from the Centers for Disease Control and Prevention as of June 22.Combined covid-flu vaccine: A combined coronavirus-influenza vaccine may be on the horizon after Moderna’s shot produced a higher immune response in older adults than separate vaccines for those viruses administered together. Moderna officials say the earliest that the combined vaccine could hit the market is fall 2025, pending regulatory approval.Covid isolation guidelines: Americans who test positive for the coronavirus no longer need to routinely stay home from work and school for five days under new guidance planned by the CDC. The change has raised concerns among medically vulnerable people.Share72 CommentsNewsletterAs news breaksTech News AlertsBreaking news email alerts on technology and the tech industry.Sign upSubscribe to comment and get the full experience. Choose your plan →",Facebook sent home thousands of human moderators due to the coronavirus. Now the algorithms are in charge,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/AKL52PAY3BH6VDJKTGMCSD4VFI.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/AKL52PAY3BH6VDJKTGMCSD4VFI.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/AKL52PAY3BH6VDJKTGMCSD4VFI.jpg&w=800&h=600', 'height': 800, 'width': 600}]",2020-03-23T17:41:06.351Z,"[{'@type': 'Person', 'name': 'Elizabeth Dwoskin', 'url': 'https://www.washingtonpost.com/people/elizabeth-dwoskin/'}, {'@type': 'Person', 'name': 'Nitasha Tiku', 'url': 'https://www.washingtonpost.com/people/nitasha-tiku/'}]","{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}",2020-07-23T01:02:32.127Z,https://www.washingtonpost.com/technology/2020/03/23/facebook-moderators-coronavirus/,,,,,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vZm9ydHVuZS5jb20vMjAyMC8wMy8yNi9iZXN0LXBsYWNlcy10by13b3JrLWFpLWJ1c2luZXNzLW5hdnktZmVkZXJhbC1jcmVkaXQtdW5pb24v0gEA?oc=5,"How one of America's best places to work is navigating an uncertain, high-tech future - Fortune",2020-03-26,Fortune,https://fortune.com,"As computers take on basic tasks, Navy Credit Federal Union is making sure its employees feel like an active and valuable part of the company.","best places to work, great places to work, best places to get a job, navy credit federal union, artificial intelligence, great places to work in finance, best financial services companies, Great Place to Work, financial services and insurance companies, American Express, Baird, Pinnacle Financial Partners, Veterans United Home Loans, ai, artificial intelligence, ai in business, business ai","As computers take on basic tasks, Navy Credit Federal Union is making sure its employees feel like an active and valuable part of the company.","As computers take on basic tasks, Navy Credit Federal Union is making sure its employees feel like an active and valuable part of the company.",,,,,N/A,N/A,"Finance - ScamsU.S. slaps Mexican accountants with sanctions for timeshare scams funneling money to one of the world’s most notorious drug cartelsBYFatima Hussein and The Associated PressJuly 16, 2024",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vaW5kaWFhaS5nb3YuaW4vYXJ0aWNsZS9yZXNraWxsaW5nLXdvbWVuLWluLWFpLWVtcG93ZXJpbmctdGhlaXItcmUtZW50cnktdG8tdGhlLXdvcmtmb3JjZdIBAA?oc=5,Reskilling women in AI: Empowering their re-entry to the workforce - INDIAai,2020-03-23,INDIAai,https://indiaai.gov.in,"To bridge the gap, Indian Institute of Technology (IIT), Madras, has started a new course – Career Back 2 Women (CB2Women) – through its Digital Skills Academy.",,"To bridge the gap, Indian Institute of Technology (IIT), Madras, has started a new course – Career Back 2 Women (CB2Women) – through its Digital Skills Academy.","To bridge the gap, Indian Institute of Technology (IIT), Madras, has started a new course – Career Back 2 Women (CB2Women) – through its Digital Skills Academy.",,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiggFodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9leHBlcnRzLW9waW5pb24tYWktY2FuLWVtcG93ZXItZG9jdG9ycy1idXQtY2FudC1yZXBsYWNlLXRoZW0tYW55dGltZS1zb29u0gGMAWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9leHBlcnRzLW9waW5pb24tYWktY2FuLWVtcG93ZXItZG9jdG9ycy1idXQtY2FudC1yZXBsYWNlLXRoZW0tYW55dGltZS1zb29u?oc=5,Experts’ Opinion: AI Can Empower Doctors But Can’t Replace Them Anytime Soon - Analytics Insight,2020-03-24,Analytics Insight,https://www.analyticsinsight.net,,"AI,Doctors,Healthcare,COVID-19,Robotics",The outbreak of coronavirus pandemic has somehow set the stage for artificial intelligence (AI) solutions to come into limelight across the healthcare sector. T,The outbreak of coronavirus pandemic has somehow set the stage for artificial intelligence (AI) solutions to come into limelight across the healthcare sector. T,http://schema.org,,NewsArticle,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Experts’ Opinion: AI Can Empower Doctors But Can’t Replace Them Anytime Soon', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/experts-opinion-ai-can-empower-doctors-but-cant-replace-them-anytime-soon'}]",N/A,N/A,"Ready for iOS 18? Here's How to Install the Public Beta
",Experts’ Opinion: AI Can Empower Doctors But Can’t Replace Them Anytime Soon,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/03/doc.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",2020-03-24T06:31:14Z,"[{'@type': 'Person', 'givenName': 'Smriti Srivastava', 'name': 'Smriti Srivastava', 'url': 'https://www.analyticsinsight.net/author/smriti-srivastava'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.linkedin.com/company/analytics-insight/', 'https://www.facebook.com/analyticsinsight.net', 'https://twitter.com/analyticsinme', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen'], 'id': 'https://www.analyticsinsight.net'}",2020-03-24T06:31:14Z,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/experts-opinion-ai-can-empower-doctors-but-cant-replace-them-anytime-soon'}",Experts’ Opinion: AI Can Empower Doctors But Can’t Replace Them Anytime Soon,https://www.analyticsinsight.net/artificial-intelligence/experts-opinion-ai-can-empower-doctors-but-cant-replace-them-anytime-soon,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/experts-opinion-ai-can-empower-doctors-but-cant-replace-them-anytime-soon', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/03/doc.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/03/doc.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"The outbreak of coronavirus pandemic has somehow set the stage for artificial intelligence (AI) solutions to come into limelight across the healthcare sector. Their services in the crisis have simplified the work for many healthcare professionals including doctors. Where doctors are selflessly working 15-18 hours in hospitals, AI-enabled technologies are assisting their line of work with great efficiency to cure patients. For example, a team headquartered at Boston Children's Hospital is implementing machine learning to scour through social posts, news reports, data from official public health channels and information supplied by doctors for warning signs that the virus is taking hold in locations outside of China. Besides, AI coupled with robotics capabilities is working as a mechanical healthcare provider for those suffering from COVID-19 symptoms. However, due to such productivity and enhanced features, many fear that AI could replace doctors..Undeniably, AI has done marvels in the healthcare sector. From radiology to disease detection to drug discovery, the technology has implied that it is poised to stay relevant in the industry with further advancements. However, the advancements do not certainly mean replacing the jobs of medical practitioners. Many experts have agreed that AI is not coming for their jobs, as the world is moving towards a collaborative ecosystem where humans and machines can work in harmony, they believe that the technology may quintessentially assist doctors more proficiently in upcoming years. Some even believe that, even if AI climbs up the ladder of utmost sophistication, it can never match human intelligence and human-level critical/creative thinking..Let's explore what experts have to say about it..Matthew Sappern, CEO at PeriGen.&quot;I think it does things that are really imperative that are not necessarily what nurses can do,&quot; he said. &quot;These tools are not so great where reasoning and empathy are required. You teach them to do something, and they will do it over and over and over again, period. They're good tools to provide perspective, but it's all about the provider or nurse who's making sense of that information.&quot;.He has implied several times that artificial intelligence can aid nurses to focus excessively on the actual job of nursing and abstracts things. According to Mathew, AI possesses the power to enhance the confidence of healthcare professionals while reporting them with exact figures eliminating the vagaries..Dr. John Showalter, Chief Product Officer at Jvion.Dr. John is extremely dismissive of the claims that medical jobs are in jeopardy. According to him, the hype is scary but the reality is not..&quot;There are great benefits that do amazing things for patients. When you come in and improve the scoring for falls, for example, and you understand what needs to be done to prevent falls, that's ready for prime time today.&quot;.&quot;There absolutely places where AI is ready to go today, and then there's a whole bunch of AI hype that's really scary, so sorting out the AI that's ready to help patients and the hype can be really difficult for leadership.&quot;.Eldon Richards, Chief Technology Officer at Recondo Technologies.According to Eldon, AI is now addressing a lot of repetitive tasks that a human might do today..&quot;In reviewing the ethics of a decision, or complex data or one-off decision, AI is not good at those today. AI is very far off when it comes to those capabilities. The mundane, routine things we do, like typing in a word processor, AI is simplifying those things for us, so now we're shifting our focus from these simple tasks to things that require a little more training. I certainly do not see unemployment going up.&quot;.Mary Sun, AI Researcher at First Derm and Medical Student at Mount Sinai Medical Center.&quot;People see it as a job replacement thing and I think that's a pretty flawed way to look at it. In many other industries, like when I was in commercial tech, it's viewed much more as an augmentation, and piece of mind, and double-checking and making sure that you're involving patterns that one doctor cannot possibly see.&quot;.&quot;As one doctor, you can't possibly see a million patients across your lifetime. But medicine, at least diagnosis, is all in the pattern recognition. So I think it's going to be very exciting when we find ways to augment our diagnoses and make them a lot more robust.&quot;.Carlo Perez, CEO of Swift Medical.&quot;What we feel is the doctor will transition into someone who understands how to wield data science, who understands how to use these tools. Hopefully, someone will not need to truly understand AI but will understand their relationship to it. Which is, 'I can utilize these tools, I understand these tools, and I understand how to utilize them in partnership to make better decisions.'&quot;.Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",2020-03-24T06:31:14Z,Artificial Intelligence,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vZW1lcmouY29tL2FpLXNlY3Rvci1vdmVydmlld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcHJvZ3Jlc3NpdmUv0gEA?oc=5,Artificial Intelligence at Progressive - Snapshot and Flo Chatbot - Emerj,2020-03-24,Emerj,https://emerj.com,Discover how Progressive uses artificial intelligence to run its popular Snapshot program and allow customers to interact with a Flo chatbot.,,Discover how Progressive uses artificial intelligence to run its popular Snapshot program and allow customers to interact with a Flo chatbot.,N/A,https://schema.org,,Article,,N/A,N/A," Business intelligence and analyticsFinanceCustomer service Artificial Intelligence at Progressive – Snapshot and Flo Chatbot Niccolo MejiaLast updated on March 24, 2020  Last updated on March 24, 2020, published by Niccolo Mejia Niccolo is a content writer and Junior Analyst at Emerj, developing both web content and helping with quantitative research. He holds a bachelor's degree in Writing, Literature, and Publishing from Emerson College. Share to: LinkedIn Twitter Facebook Email  Progressive is one of the largest auto insurers in the US. The company has been experimenting with AI since the middle of the 2010s, with customer-facing applications that update insurance premiums based on driving habits and answer questions in a chat window. In this article, we discuss both of these AI use-cases. More specifically: Snapshot: Progressive’s Snapshot program, which seems to use predictive analytics to adjust a customer’s premiums based on their driving behavior. Flo Chatbot: The company’s customer service chatbot, which could help customers with purchasing a policy or filing a claim. Emerj’s AI Opportunity Landscape research in insurance shows that Progressive’s Snapshot program follows a trend in which auto insurers use predictive analytics applications to determine how risky a customer or insurance applicant is: Approximately 21.6% of AI products in insurance are applications of this type. In contrast, although several of the largest insurance companies in the US have experimented with chatbots, the insurance industry hasn’t prioritized chatbots the way the retail industry has, as chatbots make up only 8% of the AI products in insurance. We begin our exploration of Progressive’s AI initiatives with their AI-enabled Snapshot program for usage based insurance:  Snapshot: Usage-Based Insurance Progressive claims to use a predictive analytics application that uses driving data collected from their clients to offer usage-based insurance (UBI). This means that Progressive could price their customers’ insurance policies based on how well they drive. The program, called Snapshot, requires customer to install a device into their car’s diagnostics port or download an app to their mobile phone. As the customer drives, the device or app records information about the driver’s behavior and feeds it into a predictive analytics algorithm. The algorithm seemingly offers employees at Progressive a recommendation on whether to increase or decrease the customer’s premium payments after the initial 6 month period during which they have the Snapshot device or app installed. The algorithm purportedly factors for: How often a customer drives and for how long at a time. This is one of the most common factors within “pay-as-you-drive” programs like these. How often a customer speeds. Regular speeding may signal that the driver is a greater risk. How forcefully a customer brakes, which could signal that the customer is not braking soon enough. How sharp the customer’s turns are, which, again, may signal that the customer needs to break sooner. Progressive’s Snapshot program is the result of work with AI vendor H2O.ai. Below is a video that explains this work and how AI makes Snapshot possible:  H2O.ai claims that Progressive’s underwriters were able to create and analyze new risk models faster after adopting the vendor’s AI platform. Flo Chatbot Progressive’s Flo Chatbot, which emulates its mascot, courtesy of Katie Stuhldreher. Progressive also worked with Microsoft Azure to create a natural language processing-enabled chatbot that emulates its popular mascot character, Flo. The Flo chatbot is a virtual assistant for customer service that customers could access through the company’s Facebook messenger account. It also references some of the commercials that Flo appears in and purportedly uses Progressive’s knowledge base to identify answers to customer service questions.  The Flo chatbot can purportedly help customers: File a claim Get an auto insurance quote Change premium payment due dates Answer basic questions about auto insurance, such as “What is a deductible?” The company may also be able to leverage social media responses as data to improve the chatbot’s conversational capabilities. For example, some customers may not know about the chatbot and leave their question as a comment on a Facebook post. Progressive could use these comments as a means of further training the chatbot. Emerj for Insurance Leaders Insurance leaders use AI Opportunity Landscapes to discover what their competitors are doing with AI. This gives them the information they need to keep up with top players in their industry, direct their efforts toward high ROI AI projects, and avoid AI applications that lack any evidence of widespread adoption. Now more than ever, it’s important for insurance leaders to make wise decisions about where to spend their budget. Emerj can help. Learn more about our research services.   Header Image Credit: Motor1.com Related Posts How Insurance Leaders Can Prepare for Artificial Intelligence TodayThere is a consensus among industry experts (both from our own insurance AI secondary research,… Artificial Intelligence-Based Fraud Detection in InsuranceIn recent years, the demand for greater cybersecurity has risen even among the everyday citizen.… Artificial Intelligence for Digitizing Claims Processing - A Brief OverviewMany large insurers are finding ways to digitize parts of their business process in preparation… Artificial Intelligence in Insurance - Three Trends That MatterArtificial intelligence is likely to affect the entire landscape of insurance as we know it. Change… Artificial Intelligence at Wells Fargo - A Brief OverviewWells Fargo has begun a number of AI initiatives, some they've created in-house and some… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",Artificial Intelligence at Progressive &#8211; Snapshot and Flo Chatbot,https://emerj.com/wp-content/uploads/2020/03/progressive-photo-690x327.jpg,2020-03-24,Niccolo Mejia,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",2020-03-24,https://emerj.com/ai-sector-overviews/artificial-intelligence-progressive,,,AI Sector Overviews,704,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMijAFodHRwczovL3d3dy5uZXdzMjQuY29tL2NpdHlwcmVzcy9idXNpbmVzcy93aW5uaW5nLXdvbWVuLWRpbmVvLWxpb21hcy1iaWctcGxhbnMtZm9yLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLXRoZS13b3JsZC1vZi1tZWRpY2luZS0yMDIwMDMyNtIBAA?oc=5,Winning Women | Dineo Lioma's big plans for artificial intelligence in the world of medicine | City Press - News24,2020-03-26,News24,https://www.news24.com,"Engineer, biotech innovator and businessperson Dineo Lioma plans to use artificial intelligence in the world of medicine, which might help to prevent the spread of tuberculosis and even viruses such as Covid-19 in the future.",covid-19,"Engineer, biotech innovator and businessperson Dineo Lioma plans to use artificial intelligence in the world of medicine, which might help to prevent the spread of tuberculosis and even viruses such as Covid-19 in the future.",N/A,https://schema.org,,NewsArticle,"[{'@type': 'ListItem', 'item': {'@type': 'WebPage', '@id': 'https://www.news24.com/\ncitypress\n/\n', 'name': 'citypress'}, 'position': 1}, {'@type': 'ListItem', 'item': {'@type': 'WebPage', '@id': 'https://www.news24.com/\ncitypress\n/\nbusiness\n/\n', 'name': 'business'}, 'position': 2}]",N/A,N/A,N/A,Winning Women | Dineo Lioma’s big plans for artificial intelligence in the world of medicine,"{'@type': 'ImageObject', 'url': 'https://cdn.24.co.za/files/Cms/General/d/8283/feb26b3b66e64b6bb56930a713ae961c.jpg'}",2020-03-26T19:30:20.39+00:00,"{'@type': 'Person', 'name': 'Sue Grant-Marshall'}","{'@type': 'Organization', '@id': 'https://www.news24.com', 'name': 'Citypress', 'sameAs': ['https://www.facebook.com/citypress.co.za', 'https://twitter.com/city_press', 'https://www.instagram.com/city_press'], 'url': 'https://www.news24.com', 'logo': {'@type': 'ImageObject', 'url': 'https://www.news24.com/images/tenants/citypress/Logo.svg'}}",2020-09-01T15:38:55.52+00:00,"{'@type': 'WebPage', '@id': 'https://www.news24.com/citypress/business/winning-women-dineo-liomas-big-plans-for-artificial-intelligence-in-the-world-of-medicine-20200326', 'isPartOf': {'@type': 'WebSite', '@id': 'https://www.news24.com', 'name': 'Citypress', 'description': 'Winning Women | Dineo Lioma’s big plans for artificial intelligence in the world of medicine', 'url': 'https://www.news24.com', 'publisher': {'@type': 'Organization', '@id': 'https://www.news24.com', 'name': 'Citypress', 'sameAs': ['https://www.facebook.com/citypress.co.za', 'https://twitter.com/city_press', 'https://www.instagram.com/city_press'], 'url': 'https://www.news24.com', 'logo': {'@type': 'ImageObject', 'url': 'https://www.news24.com/images/tenants/citypress/Logo.svg'}}}, 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://cdn.24.co.za/files/Cms/General/d/8283/feb26b3b66e64b6bb56930a713ae961c.jpg'}}",,,,,"{'cssSelector': '.article-locked', '@type': 'WebPageElement', 'isAccessibleForFree': False}",False,"{'@type': 'WebPage', '@id': 'https://www.news24.com/citypress/business/winning-women-dineo-liomas-big-plans-for-artificial-intelligence-in-the-world-of-medicine-20200326', 'isPartOf': {'@type': 'WebSite', '@id': 'https://www.news24.com', 'name': 'Citypress', 'description': 'Winning Women | Dineo Lioma’s big plans for artificial intelligence in the world of medicine', 'url': 'https://www.news24.com', 'publisher': {'@type': 'Organization', '@id': 'https://www.news24.com', 'name': 'Citypress', 'sameAs': ['https://www.facebook.com/citypress.co.za', 'https://twitter.com/city_press', 'https://www.instagram.com/city_press'], 'url': 'https://www.news24.com', 'logo': {'@type': 'ImageObject', 'url': 'https://www.news24.com/images/tenants/citypress/Logo.svg'}}}, 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://cdn.24.co.za/files/Cms/General/d/8283/feb26b3b66e64b6bb56930a713ae961c.jpg'}}",https://cdn.24.co.za/files/Cms/General/d/6855/1677dd7e0f804ccaa116a4f5803cd8fd.jpg,,,,,"{'@type': 'Organization', 'name': 'Citypress'}",2020.0,en-US,14873.0
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3Lm1lZGlhdXBkYXRlLmNvLnphL21lZGlhLzE0ODI1Ny8xMC1mYXFzLWFuc3dlcmVkLWFib3V0LXRoZS1mb3VydGgtaW5kdXN0cmlhbC1yZXZvbHV0aW9u0gEA?oc=5,10 FAQs answered about the Fourth Industrial Revolution - Media Update,2020-03-26,Media Update,https://www.mediaupdate.co.za,"The Fourth Industrial Revolution (4IR) is a term people often hear, but are not quite sure what it means. On top of that, there is also a lot of debate regarding whether or not South Africa is ready for this revolution. Let`s find out.","Fourth Industrial Revolution, 4IR, FAQs about 4IR","The Fourth Industrial Revolution (4IR) is a term people often hear, but are not quite sure what it means. On top of that, there is also a lot of debate regarding whether or not South Africa is ready for this revolution. Let`s find out.","The Fourth Industrial Revolution (4IR) is a term people often hear, but are not quite sure what it means. On top of that, there is also a lot of debate regarding whether or not South Africa is ready for this revolution. Let`s find out.",http://schema.org,,NewsArticle,,N/A,N/A,N/A,10 FAQs answered about the Fourth Industrial Revolution,"{'@type': 'ImageObject', 'url': 'https://dash.mediaupdate.co.za/story/image/148257/148257_t.jpg?v=638567568365145052', 'height': 737, 'width': 1311}",2020-03-26T13:00:00,"{'@type': 'Person', 'name': 'Media Update'}","{'@type': 'Organization', 'name': 'Media Update', 'url': 'https://www.mediaupdate.co.za', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mediaupdate.co.za/img/logo60.jpg', 'width': 60, 'height': 60}, 'sameAs': ['http://facebook.com/mediaupdate', 'http://twitter.com/MediaUpdate', 'http://www.linkedin.com/company/media-update']}",2020-03-26T13:00:00,"{'@type': 'WebPage', '@id': 'https://www.mediaupdate.co.za/media/148257/10-faqs-answered-about-the-fourth-industrial-revolution'}",,,,,,,,,,,,,,,,

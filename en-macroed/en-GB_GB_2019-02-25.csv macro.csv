URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,articleBody,isBasedOn,thumbnailUrl,isPartOf,alternativeHeadline,mainEntityOfPage,uploadDate,contentUrl,@graph,dateCreated,copyrightYear,sourceOrganization,copyrightHolder,creator,@id,duration,logo,sameAs
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvY29nbml0aXZld29ybGQvMjAxOS8wMi8yNS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1oeXBlLWlzLXJlYWwv0gEA?oc=5,Artificial Intelligence Hype Is Real - Forbes,2019-02-25,Forbes,https://www.forbes.com,"The story of Artificial Intelligence hype has a considerable business history in 2019. AI is increasingly being absorbed into just about every business sector. Once an investment in the future, it is now an optimization of machine learning in the present.",,"The story of Artificial Intelligence hype has a considerable business history in 2019. AI is increasingly being absorbed into just about every business sector. Once an investment in the future, it is now an optimization of machine learning in the present.","The story of Artificial Intelligence hype has a considerable business history in 2019. AI is increasingly being absorbed into just about every business sector. Once an investment in the future, it is now an optimization of machine learning in the present.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/cognitiveworld/2019/02/25/artificial-intelligence-hype-is-real/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/cognitiveworld/files/2019/02/Depositphotos_83472010_l-2015-1200x1023.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Michael Spencer', 'url': 'https://www.forbes.com/sites/cognitiveworld/people/michaelspencer1/', 'description': 'Michael Spencer is a prolific futurist referred to as the original business insider with over 800 articles on LinkedIn and writing daily on Medium, where he is a top writer in 20+ tags. He is a content consultant for startups involved in robotics, AI, blockchain and IoT. Michael is founder and editor of FutureSin, a Medium publication that explores aspects of technology and society related to artificial intelligence, China, transhumanism and the future of work. Based in Montreal, a significant academic hub for AI, he enjoys writing about actual business trends related to AI.', 'sameAs': ['https://www.linkedin.com/in/michaelkspencer/', 'https://www.twitter.com/https://twitter.com/Mike_K_Spencer', 'https://medium.com/@Michael_Spencer']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Artificial Intelligence Hype Is Real,2019-02-25T08:21:00-05:00,2019-02-25T08:22:28-05:00,AI & Big Data,Artificial Intelligence Hype Is Real,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI & Big Data,N/A,"More From ForbesJun 17, 2024,04:42am EDTProtecting Human Rights In The Age Of Intelligent MachinesApr 24, 2024,05:00am EDTWhat AI Can Tell Us About OzempicFeb 22, 2024,03:42am ESTUnlocking The Power Of Social Data For Clinical Trial DesignJan 25, 2024,04:55am ESTCPG Product Innovation Should Be A Science, Not An ArtAug 7, 2023,08:57am EDTListening Before We Talk: Why Social Data Is Key To Successful NPD In 2023Mar 28, 2023,10:07am EDTHow Technology Is Empowering CPGs To Do More With LessFeb 21, 2023,05:24am ESTAre Humans And Collaboration Still At The Heart Of Innovation?Edit StoryForbesInnovationAIArtificial Intelligence Hype Is RealMichael SpencerContributorCOGNITIVE WORLDContributor GroupOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itFeb 25, 2019,08:21am ESTUpdated Feb 25, 2019, 08:22am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin








 The story of Artificial Intelligence hype has a considerable business history in 2019. AI is increasingly being absorbed into just about every business sector. Once an investment in the future, it is now an optimization of machine learning in the present. What was once a buzzword for an unspecified time carries with it now the hype of the future that is quickly becoming very much the here and now.
 Many people don’t know the extent to which Artificial Intelligence is changing the workforce and how it has been an integral part of the history of R&D at companies such as Microsoft. In fact, quite incredibly in 2019 it’s Microsoft that leads the AI patent race. 









PROMOTED

There have been over 154,000 AI patents filed worldwide since 2010 
The survey from IFI Claims Patent Services shows a strong uptick in the patent category covering AI, machine learning and neural networks.
Between 2013 and 2018, the category grew by 34% annually.










DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



 Yet tech companies such as Microsoft and Google are also sounding the alarm on the potential dangers of AI in an era of deep fakes, facial recognition software with biases and many other applications with potential dangers. As of November last year, Microsoft though had filed 697 AI patents identified as important due to their ‘significant competitive advantage’. Out of the top 30 companies listed in the research, Microsoft filed 20% of all patents and is ranked number 1.  Microsoft’s approach to AI is rigorous and has a long history. 







Microsoft technical fellow Doug Burger with an AI-optimized Project Brainwave accelerator used in... [+] the company’s Azure data centers.
Microsoft


 Microsoft shows the AI Hype is Real  To seek the origins of Microsoft’s interest in artificial intelligence, we have to go back to when Bill Gates founded Microsoft’s research arm in 1991. It’s clear that AI was an area of investigation from the start that’s fast tracked the world we know today. Think about that for a moment, that’s nearly three decades ago. Indeed from the start, Microsoft Research (MSR for short) hired more than its fair share of computing’s most visionary, accomplished experts and academic talent in the domain. Yet in the last few years up to the present of 2019, AI-based marketing patents are the fastest growing global category, reaching a Compound Annual Growth Rate (CAGR) of 29.3% between 2010 and 2018. Machine learning dominates the AI patent landscape today, leading all categories of AI patents including deep learning and neural networks and Microsoft is among the leaders in the Cloud, cybersecurity and AI-based digital security patents. We are just five years into Satya Nadella’s tenure as Microsoft CEO and he has decidedly pivoted the company towards AI and the Cloud. Incredibly, today more than 1,000 computer scientists are in MSR’s employ, as well as at its Redmond headquarters in addition to such global locations such as Boston, Montreal, Beijing, Bangalore and beyond. You might say that the decade ahead, the 2020s, is the era when artificial intelligence will grow up and while to be sure Hollywood renditions of AI are extreme exaggerations of technology far beyond what we are capable of today, there’s a looming promise of AI’s impact on the global economy for years to come. Essentially AI is attributed to add 1.2% to annual GDP growth over the next decade. That’s an astounding figure, and one that proves that the hype might be justified.  Michael SpencerFollowingFollowMichael Spencer is a prolific futurist referred to as the original business insider with over 800 articles on LinkedIn and writing daily on Medium, where he is... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9udmlkaWEtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZ3B1L9IBAA?oc=5,Nvidia's got a cunning plan to keep powering the AI revolution - WIRED,2019-02-27,WIRED,https://www.wired.com,Nvidia’s artificial intelligence journey started with cats. Now it's heading to the kitchen,"['business', 'ai hub', 'artificial intelligence', '_wired-uk-migrated', 'web']",Nvidia’s artificial intelligence journey started with cats. Now it's heading to the kitchen,Nvidia’s artificial intelligence journey started with cats. Now it's heading to the kitchen,https://schema.org/,BreadcrumbList,https://www.wired.com/story/nvidia-artificial-intelligence-gpu/,"['https://media.wired.com/photos/65e71448eb38a5964ff8a327/16:9/w_4000,h_2250,c_limit/gettyimages-1078648858.jpg', 'https://media.wired.com/photos/65e71448eb38a5964ff8a327/4:3/w_3556,h_2667,c_limit/gettyimages-1078648858.jpg', 'https://media.wired.com/photos/65e71448eb38a5964ff8a327/1:1/w_2667,h_2667,c_limit/gettyimages-1078648858.jpg']","[{'@type': 'Person', 'name': 'Sam Shead', 'sameAs': 'https://www.wired.com/author/sam-shead/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",Nvidia's got a cunning plan to keep powering the AI revolution,2019-02-27T01:00:00.000-05:00,2019-02-27T01:00:00.000-05:00,business,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.wired.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'artificial intelligence', 'item': 'https://www.wired.com/tag/artificial-intelligence/'}, {'@type': 'ListItem', 'position': 3, 'name': ""Nvidia's got a cunning plan to keep powering the AI revolution""}]",tags,N/A,"Sam SheadBusinessFeb 27, 2019 1:00 AMNvidia's got a cunning plan to keep powering the AI revolutionNvidia’s artificial intelligence journey started with cats. Now it's heading to the kitchenSave this storySaveSave this storySaveJen-Hsun Huang, CEO and president of Nvidia, speaks during the company’s keynote event at the 2019 Consumer Electronics Show in Las VegasDavid Paul Morris/Bloomberg/Getty ImagesInside Nvidia’s 13,000 square foot AI robotics research lab in Seattle, a small team of researchers is hard at work building the company’s artificial intelligence-powered future. Next to a kitchen worktop, a robotic arm lifts a tin of Spam and puts it in a drawer. The arm has also learned how to clean the dining table and, if you ask nicely, it can help you cook a meal. This, right here, is the first tentative step in Nvidia’s ambitious artificial intelligence master plan.Opened at the start of the year, the lab currently employs 28 people, with capacity for 50 research scientists, faculty advisors, and interns when operating at full-tilt. Led by renowned roboticist Dieter Fox, senior director of robotics research at Nvidia and a professor at the University of Washington, the lab is aiming to develop the next generation of robots that can safely work alongside humans, possibly transforming industries like manufacturing, logistics, and healthcare in the process. It’s one of the many grand challenges for artificial intelligence – a sci-fi vision of robots that aren’t just good at very specific tasks, but capable of behaving as if almost human.AdvertisementBut the robot is also a somewhat elaborate muscle flexing exercise. It’s an eye-catching demonstration of what Nvidia’s hardware and software can do today and could do in the future – and a bid by the company to stay one step ahead of an increasingly speedy competition.Trending NowMoistCr1TiKaL Answers The Web's Most Searched QuestionsOptimising graphics processing unit, or GPUs, for AI back in 2005 must go down as one of the smartest business decisions in technology hardware history. But now it’s on top, and faced with increasing competition, consolidating that position will be one of the toughest tests in Nvidia’s 25-year history.Nvidia’s latest lab has been kitted out with equipment and real life environments that robots are expected to encounter in the real world. The first of these scenarios is a humble kitchen. The robot assistant integrates AI and deep learning techniques to detect and track objects, understand the relative positions of doors and drawers, and open and close them to access specific items. “In the past, robotics research has focused on small, independent projects rather than fully integrated systems,” Fox says. “We’re bringing together a collaborative, interdisciplinary team of experts in robot control and perception, computer vision, human-robot interaction, and deep learning.”The team in Seattle is being assisted by around 60 researchers spread across Nvidia’s other research hubs in Santa Clara, Eastern Massachusetts, Toronto and Tel Aviv. The multidisciplinary approach has a fiendishly difficult goal: Nvidia is trying to show that its artificial intelligence hardware and software can transform robots from what they are today – very accurate positioning machines that dumbly follow regimented instructions – into dynamic and flexible machines that can safely work alongside humans.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David Gilbert, WIREDSecurityAT&T Paid a Hacker $370,000 to Delete Stolen Phone RecordsBy Kim Zetter, WIREDSamim Wagner, an AI researcher for Google in Berlin, believes one of the main reasons Nvidia is carrying out its own research is to help it build better AI hardware that it can then sell on to others. “In order to build feasible and competitive hardware for machine learning, Nvidia is strategically forced to do high quality machine learning research,” he says. “The company’s traditional connections with the games and entertainment industries provide it with a focus-point for its machine learning research, which is key for success.” Which helps explain the robot – and a host of other oddball experiments taking place in Nvidia’s research laboratories.“Now that we have deep learning it’s possible to make robots interact with their environment,” says Bill Dally, Nvidia’s chief scientist and senior vice president of research, in reference to the robot kitchen helper. “Now that we can build perceptual systems, we can build robots that don’t count on the car being in the exact same spot each time.”As with Nvidia’s experiments with robotics, deep learning has enabled AI systems to tackle problems that were previously impossible. Through its trial-and-error technique, breakthroughs have been made in virtual assistants, computer vision, language translation, chatbots and facial recognition. And, as with so much in artificial intelligence, such breakthroughs rely heavily on clever little GPUs.Nvidia’s AI journey started at Joanie’s Cafe in Palo Alto, California, in 2010. “We got into AI after a breakfast meeting I had with Andrew Ng,” says Dally. At that breakfast, Ng, a well known AI researcher who was working with Google Brain at the time, explained how Google was training AI systems to recognise photos of cats with the help of 16,000 central processing units, or CPUs. After pointing out next to no one has 16,000 CPUs at their disposal, Dally laid down a challenge. “I bet we could do this with way fewer GPUs,” he said to Ng.Shortly after the encounter, Dally asked Nvidia researcher Bryan Catanzaro to team up with Ng and do just that. “We achieved roughly the same performance with 48 GPUs that they had done with 16,000 CPUs,” says Dally. “At the time it was really clear to me that this was going to transform everything.”From a bet about recognising cats, Nvidia’s AI business has exploded. The company doesn’t disclose exactly how much it is currently investing into the field, but filings reveal it spent a total of $1.8 billion (£1.4b) on all research in the last financial year. Key areas of investment were gaming, AI and automotive. The effectiveness of its GPUs for artificial intelligence projects has created a  scramble amongst Nvidia’s competitors, with Intel, Google and even Facebook investing huge sums of money to try and catch up.In July 2018, Google announced it was developing its own AI chips for on-device machine learning. Google’s bet is on a new kind of chip: a tensor processing unit designed specifically for neural network machine learning. And a separate, equally important tussle is also unfolding. As well as hardware, Nvidia’s code library is also going up against rival frameworks such as Google Tensorflow or Facebook PyTorch. Think of it as deep learning as a service. And, against all the odds, Nvidia is still holding its own.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David Gilbert, WIREDSecurityAT&T Paid a Hacker $370,000 to Delete Stolen Phone RecordsBy Kim Zetter, WIREDThe reason? As the cat challenge showed, GPUs are brilliant at handling AI tasks. That’s because GPUs are better than CPUs at running the parallel computing problems associated with AI, where many calculations are carried out simultaneously. Parallel computing is particularly prevalent in neural networks because they are designed to work in a similar way to animal brains, which can do many tasks at the same time, or in parallel. Eventually, Nvidia wants to be the one building the artificial brains inside every phone, computer, robot and autonomous car.Led by CEO Jen-Hsun Huang, the company effectively preempted the AI boom back in 2005 when it created software that allowed its GPUs to process the millions of minuscule computations that would eventually be required by modern AI. Its GPUs are now in data centres around the world, powering AI tasks for thousands of businesses. Between 2014 and 2018, the company was boosted by a 524 per cent increase in revenue for its data centre-optimised chips.“We’re the supplier to the whole world,” says Dally. “Everyone’s training their deep neural networks on Nvidia GPUs,” he continues, adding that the company’s T4 chip is widely used for inference tasks. Facebook and Google use Nvidia’s platform to power the AI features on their platforms. Almost all the driverless car companies are using Nvidia technology. The company has also signed deals with Tencent, Alibaba, and Baidu.As with the robot in the kitchen, Nvidia’s other AI experiments appear similarly eclectic and oddball. It’s built a creative neural network, known as a generative adversarial network, or GAN, that’s scarily good at creating hyper-realistic images of human faces. In a paper released in December 2018, the company showed just how clear its GAN faces are compared to GAN faces from four years ago.Faces aren’t the only thing that Nvidia’s GANs can create, or fake. Nvidia has also developed a translation network that can turn photos taken in winter into beautiful summery scenes. Got a rainy photo of your wedding you want brightening up? Nvidia’s AI can make it look just like the sun was shining all along. And it doesn’t stop there. Nvidia showed off the world’s first video game demo to use AI-generated graphics at the end of last year. The demo was a driving simulator that was built by combining AI-generated visuals with a standard video game engine.Read more: Inside Finland’s plan to become an artificial intelligence powerhouseBut there have been bumps in the road. And they hint at a rougher ride to come. At the start of the year, Nvidia was forced to cut its fourth quarter revenue forecast by $500 million in a move that saw its stock tumble nearly 18 per cent. The cryptocurrency crash that rumbled through much of 2018 was extremely painful for Nvidia’s bottom line, costing it an estimated $23 billion in market value. But it was also a blessing – albeit an expensive one.For the time being, the adaptability of Nvidia’s GPUs give it an edge over its rivals: they’re integral to data centres, self-driving cars, research labs, cryptocurrency mining rigs – you name it, there’s a GPU in it. But that could soon change. And that’s where Nvidia’s research labs come into play.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David Gilbert, WIREDSecurityAT&T Paid a Hacker $370,000 to Delete Stolen Phone RecordsBy Kim Zetter, WIRED“There’s a slew of new AI hardware startups,” says Stephen Merity, an AI research consultant and the founder of a startup in stealth mode. “They may well be a threat but it’s a huge open question. I can’t imagine any of those startups hitting mass scale early on.”One such startup is UK-based Graphcore, which is now valued at over $1 billion (£760,000) thanks to funding from the likes of BMW, Sequoia, and the founder of Google-owned DeepMind. Graphcore claims its intelligence processing units, which are yet to go into mass production, are 100 times faster than any existing systems. For Nvidia, that could create a financial headache bigger than the cryptocrash.“I don’t know what the end state of the AI hardware ecosystem looks like,” says deep learning researcher Stephen Merity. “If the end state is the same hardware on both sides, Nvidia has an advantage. If it fragments into ‘hardware you use for training’ and ‘hardware you use in the real world’ then Graphcore and other similar startups may do very well.”Updated 28.02.19, 11:10 GMT: Nvidia’s research lab in Massachusetts is in the east of the state, not the west.This article was originally published by WIRED UKEnter your email to get the Wired newsletterclose dialogRecommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialog","Opened at the start of the year, the lab currently employs 28 people, with capacity for 50 research scientists, faculty advisors, and interns when operating at full-tilt. Led by renowned roboticist Dieter Fox, senior director of robotics research at Nvidia and a professor at the University of Washington, the lab is aiming to develop the next generation of robots that can safely work alongside humans, possibly transforming industries like manufacturing, logistics, and healthcare in the process. It’s one of the many grand challenges for artificial intelligence – a sci-fi vision of robots that aren’t just good at very specific tasks, but capable of behaving as if almost human.
But the robot is also a somewhat elaborate muscle flexing exercise. It’s an eye-catching demonstration of what Nvidia’s hardware and software can do today and could do in the future – and a bid by the company to stay one step ahead of an increasingly speedy competition.
Optimising graphics processing unit, or GPUs, for AI back in 2005 must go down as one of the smartest business decisions in technology hardware history. But now it’s on top, and faced with increasing competition, consolidating that position will be one of the toughest tests in Nvidia’s 25-year history.
Nvidia’s latest lab has been kitted out with equipment and real life environments that robots are expected to encounter in the real world. The first of these scenarios is a humble kitchen. The robot assistant integrates AI and deep learning techniques to detect and track objects, understand the relative positions of doors and drawers, and open and close them to access specific items. “In the past, robotics research has focused on small, independent projects rather than fully integrated systems,” Fox says. “We’re bringing together a collaborative, interdisciplinary team of experts in robot control and perception, computer vision, human-robot interaction, and deep learning.”
The team in Seattle is being assisted by around 60 researchers spread across Nvidia’s other research hubs in Santa Clara, Eastern Massachusetts, Toronto and Tel Aviv. The multidisciplinary approach has a fiendishly difficult goal: Nvidia is trying to show that its artificial intelligence hardware and software can transform robots from what they are today – very accurate positioning machines that dumbly follow regimented instructions – into dynamic and flexible machines that can safely work alongside humans.
Samim Wagner, an AI researcher for Google in Berlin, believes one of the main reasons Nvidia is carrying out its own research is to help it build better AI hardware that it can then sell on to others. “In order to build feasible and competitive hardware for machine learning, Nvidia is strategically forced to do high quality machine learning research,” he says. “The company’s traditional connections with the games and entertainment industries provide it with a focus-point for its machine learning research, which is key for success.” Which helps explain the robot – and a host of other oddball experiments taking place in Nvidia’s research laboratories.
“Now that we have deep learning it’s possible to make robots interact with their environment,” says Bill Dally, Nvidia’s chief scientist and senior vice president of research, in reference to the robot kitchen helper. “Now that we can build perceptual systems, we can build robots that don’t count on the car being in the exact same spot each time.”
As with Nvidia’s experiments with robotics, deep learning has enabled AI systems to tackle problems that were previously impossible. Through its trial-and-error technique, breakthroughs have been made in virtual assistants, computer vision, language translation, chatbots and facial recognition. And, as with so much in artificial intelligence, such breakthroughs rely heavily on clever little GPUs.
Nvidia’s AI journey started at Joanie’s Cafe in Palo Alto, California, in 2010. “We got into AI after a breakfast meeting I had with Andrew Ng,” says Dally. At that breakfast, Ng, a well known AI researcher who was working with Google Brain at the time, explained how Google was training AI systems to recognise photos of cats with the help of 16,000 central processing units, or CPUs. After pointing out next to no one has 16,000 CPUs at their disposal, Dally laid down a challenge. “I bet we could do this with way fewer GPUs,” he said to Ng.
Shortly after the encounter, Dally asked Nvidia researcher Bryan Catanzaro to team up with Ng and do just that. “We achieved roughly the same performance with 48 GPUs that they had done with 16,000 CPUs,” says Dally. “At the time it was really clear to me that this was going to transform everything.”
From a bet about recognising cats, Nvidia’s AI business has exploded. The company doesn’t disclose exactly how much it is currently investing into the field, but filings reveal it spent a total of $1.8 billion (£1.4b) on all research in the last financial year. Key areas of investment were gaming, AI and automotive. The effectiveness of its GPUs for artificial intelligence projects has created a  scramble amongst Nvidia’s competitors, with Intel, Google and even Facebook investing huge sums of money to try and catch up.
In July 2018, Google announced it was developing its own AI chips for on-device machine learning. Google’s bet is on a new kind of chip: a tensor processing unit designed specifically for neural network machine learning. And a separate, equally important tussle is also unfolding. As well as hardware, Nvidia’s code library is also going up against rival frameworks such as Google Tensorflow or Facebook PyTorch. Think of it as deep learning as a service. And, against all the odds, Nvidia is still holding its own.
The reason? As the cat challenge showed, GPUs are brilliant at handling AI tasks. That’s because GPUs are better than CPUs at running the parallel computing problems associated with AI, where many calculations are carried out simultaneously. Parallel computing is particularly prevalent in neural networks because they are designed to work in a similar way to animal brains, which can do many tasks at the same time, or in parallel. Eventually, Nvidia wants to be the one building the artificial brains inside every phone, computer, robot and autonomous car.
Led by CEO Jen-Hsun Huang, the company effectively preempted the AI boom back in 2005 when it created software that allowed its GPUs to process the millions of minuscule computations that would eventually be required by modern AI. Its GPUs are now in data centres around the world, powering AI tasks for thousands of businesses. Between 2014 and 2018, the company was boosted by a 524 per cent increase in revenue for its data centre-optimised chips.
“We’re the supplier to the whole world,” says Dally. “Everyone’s training their deep neural networks on Nvidia GPUs,” he continues, adding that the company’s T4 chip is widely used for inference tasks. Facebook and Google use Nvidia’s platform to power the AI features on their platforms. Almost all the driverless car companies are using Nvidia technology. The company has also signed deals with Tencent, Alibaba, and Baidu.
As with the robot in the kitchen, Nvidia’s other AI experiments appear similarly eclectic and oddball. It’s built a creative neural network, known as a generative adversarial network, or GAN, that’s scarily good at creating hyper-realistic images of human faces. In a paper released in December 2018, the company showed just how clear its GAN faces are compared to GAN faces from four years ago.
Faces aren’t the only thing that Nvidia’s GANs can create, or fake. Nvidia has also developed a translation network that can turn photos taken in winter into beautiful summery scenes. Got a rainy photo of your wedding you want brightening up? Nvidia’s AI can make it look just like the sun was shining all along. And it doesn’t stop there. Nvidia showed off the world’s first video game demo to use AI-generated graphics at the end of last year. The demo was a driving simulator that was built by combining AI-generated visuals with a standard video game engine.
Read more: Inside Finland’s plan to become an artificial intelligence powerhouse
But there have been bumps in the road. And they hint at a rougher ride to come. At the start of the year, Nvidia was forced to cut its fourth quarter revenue forecast by $500 million in a move that saw its stock tumble nearly 18 per cent. The cryptocurrency crash that rumbled through much of 2018 was extremely painful for Nvidia’s bottom line, costing it an estimated $23 billion in market value. But it was also a blessing – albeit an expensive one.
For the time being, the adaptability of Nvidia’s GPUs give it an edge over its rivals: they’re integral to data centres, self-driving cars, research labs, cryptocurrency mining rigs – you name it, there’s a GPU in it. But that could soon change. And that’s where Nvidia’s research labs come into play.
“There’s a slew of new AI hardware startups,” says Stephen Merity, an AI research consultant and the founder of a startup in stealth mode. “They may well be a threat but it’s a huge open question. I can’t imagine any of those startups hitting mass scale early on.”
One such startup is UK-based Graphcore, which is now valued at over $1 billion (£760,000) thanks to funding from the likes of BMW, Sequoia, and the founder of Google-owned DeepMind. Graphcore claims its intelligence processing units, which are yet to go into mass production, are 100 times faster than any existing systems. For Nvidia, that could create a financial headache bigger than the cryptocrash.
“I don’t know what the end state of the AI hardware ecosystem looks like,” says deep learning researcher Stephen Merity. “If the end state is the same hardware on both sides, Nvidia has an advantage. If it fragments into ‘hardware you use for training’ and ‘hardware you use in the real world’ then Graphcore and other similar startups may do very well.”
Updated 28.02.19, 11:10 GMT: Nvidia’s research lab in Massachusetts is in the east of the state, not the west.
This article was originally published by WIRED UK",,"https://media.wired.com/photos/65e71448eb38a5964ff8a327/2:3/w_1778,h_2667,c_limit/gettyimages-1078648858.jpg","{'@type': 'CreativeWork', 'name': 'WIRED'}",Nvidia’s artificial intelligence journey started with cats. Now it's heading to the kitchen,"{'@type': 'WebPage', '@id': 'https://www.wired.com/story/nvidia-artificial-intelligence-gpu/'}",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3Lm5ld3lvcmtlci5jb20vbWFnYXppbmUvMjAxOS8wMy8wNC9hcmUtcm9ib3RzLWNvbXBldGluZy1mb3IteW91ci1qb2LSAQA?oc=5,Are Robots Competing for Your Job? - The New Yorker,2019-02-25,The New Yorker,https://www.newyorker.com,"Probably, but don’t count yourself out, Jill Lepore writes.","['annals of technology', 'robots', 'artificial intelligence (a.i.)', 'automation', 'jobs', 'books', 'magazine']","Probably, but don’t count yourself out.","Probably, but don’t count yourself out.",https://schema.org/,BreadcrumbList,https://www.newyorker.com/magazine/2019/03/04/are-robots-competing-for-your-job,"['https://media.newyorker.com/photos/5c6f02d13a3ac62cebaaf5fd/16:9/w_2115,h_1189,c_limit/190304_r33801.jpg', 'https://media.newyorker.com/photos/5c6f02d13a3ac62cebaaf5fd/4:3/w_2112,h_1584,c_limit/190304_r33801.jpg', 'https://media.newyorker.com/photos/5c6f02d13a3ac62cebaaf5fd/1:1/w_2114,h_2114,c_limit/190304_r33801.jpg']","[{'@type': 'Person', 'name': 'Jill Lepore', 'sameAs': 'https://www.newyorker.com/contributors/jill-lepore'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'The New Yorker', 'logo': {'@type': 'ImageObject', 'url': 'https://www.newyorker.com/verso/static/the-new-yorker/assets/social-image-hub.jpg', 'width': '500px', 'height': '117px'}, 'url': 'https://www.newyorker.com'}",Are Robots Competing for Your Job?,2019-02-25T05:00:00.000-05:00,2019-02-25T05:00:00.000-05:00,annals of technology,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Magazine', 'item': 'https://www.newyorker.com/magazine'}, {'@type': 'ListItem', 'position': 2, 'name': 'Robots', 'item': 'https://www.newyorker.com/tag/robots'}, {'@type': 'ListItem', 'position': 3, 'name': 'Are Robots Competing for Your Job?'}]",tags,N/A,"Annals of TechnologyAre Robots Competing for Your Job?Probably, but don’t count yourself out.By Jill LeporeFebruary 25, 2019Doomsayers insist that this time the employment apocalypse is really nigh.Illustration by Christoph NiemannSave this storySave this storySave this storySave this storyThe robots are coming. Hide the WD-40. Lock up your nine-volt batteries. Build a booby trap out of giant magnets; dig a moat as deep as a grave. “Ever since a study by the University of Oxford predicted that 47 percent of U.S. jobs are at risk of being replaced by robots and artificial intelligence over the next fifteen to twenty years, I haven’t been able to stop thinking about the future of work,” Andrés Oppenheimer writes, in “The Robots Are Coming: The Future of Jobs in the Age of Automation” (Vintage). No one is safe. Chapter 4: “They’re Coming for Bankers!” Chapter 5: “They’re Coming for Lawyers!” They’re attacking hospitals: “They’re Coming for Doctors!” They’re headed to Hollywood: “They’re Coming for Entertainers!” I gather they have not yet come for the manufacturers of exclamation points.The old robots were blue-collar workers, burly and clunky, the machines that rusted the Rust Belt. But, according to the economist Richard Baldwin, in “The Globotics Upheaval: Globalization, Robotics, and the Future of Work” (Oxford), the new ones are “white-collar robots,” knowledge workers and quinoa-and-oat-milk globalists, the machines that will bankrupt Brooklyn. Mainly, they’re algorithms. Except when they’re immigrants. Baldwin calls that kind “remote intelligence,” or R.I.: they’re not exactly robots but, somehow, they fall into the same category. They’re people from other countries who can steal your job without ever really crossing the border: they just hop over, by way of the Internet and apps like Upwork, undocumented, invisible, ethereal. Between artificial intelligence and remote intelligence, Baldwin warns, “this international talent tidal wave is coming straight for the good, stable jobs that have been the foundation of middle-class prosperity in the US and Europe, and other high-wage economies.” Change your Wi-Fi password. Clear your browser history. Ask H.R. about early retirement. The globots are coming.How can you know if you’re about to get replaced by an invading algorithm or an augmented immigrant? “If your job can be easily explained, it can be automated,” Anders Sandberg, of Oxford’s Future of Humanity Institute, tells Oppenheimer. “If it can’t, it won’t.” (Rotten luck for people whose job description is “Predict the future.”) Baldwin offers three-part advice: (1) avoid competing with A.I. and R.I.; (2) build skills in things that only humans can do, in person; and (3) “realize that humanity is an edge not a handicap.” What all this means is hard to say, especially if you’ve never before considered being human to be a handicap. As for the future of humanity, Oppenheimer offers another cockamamie rule of three: “Society will be divided into three general groups. The first will be members of the elites, who will be able to adapt to the ever-changing technological landscape and who will earn the most money, followed by a second group made up primarily of those who provide personalized services to the elite, including personal trainers, Zumba class instructors, meditation gurus, piano teachers, and personal chefs, and finally a third group of those who will be mostly unemployed and may be receiving a universal basic income as compensation for being the victims of technological unemployment.”Readers of Douglas Adams will recognize this sort of hooey from “The Hitchhiker’s Guide to the Galaxy.” Long ago, in a galaxy not at all far away, the people of the planet Golgafrincham were divided into three groups: A, “all the brilliant leaders, the scientists, the great artists, you know, all the achievers”; B, “hairdressers, tired TV producers, insurance salesmen, personnel officers, security guards, public relations executives, management consultants” (the group that everyone else considers to be “a bunch of useless idiots”); and, C, “all the people who did the actual work, who made things and did things.” The B people, told they must lead an expedition to colonize another planet, rocket away in a starship, having been led to believe that their planet is doomed. “Apparently it was going to crash into the sun or something,” the B ship’s captain tells Arthur Dent, vaguely wondering why the other ships never followed. “Or maybe it was that the moon was going to crash into us. Something of the kind. Absolutely terrifying prospect whatever it was.” Dent inquires, “And they made sure they sent you lot off first, did they?”This time, notwithstanding Elon Musk’s ambition to colonize Mars, no one’s trying to persuade the B people to board a spaceship, because the B people—the hairdressers and the Zumba-class instructors, the meditation gurus and the personal trainers—are supposed to stick around to cater to the A people. No, this time it’s the C people, the people who make and do things—things that can now be made and done faster and cheaper by robots—who are being flushed down the cosmic toilet. The historian and sometime futurist Yuval Noah Harari has a name for the C people: he calls them the “useless class.” Some futurists suggest that, in our Asimov-y future, these sort of people might wind up spending their empty days playing video games. Otherwise, they’ll wage a revolution, an eventuality that the self-proclaimed “cognitive elite”—the A people, who believe themselves to be cleverer than the cleverest robots—intend to wait out in fortified lairs. (Peter Thiel owns nearly five hundred acres of land in New Zealand, complete with its own water supply.) More popular is the proposal to pay the C people for doing nothing, in order to avert the revolution. “It’s going to be necessary,” Musk said during a summit in Dubai two years ago, joining a small herd of other billionaires, including Mark Zuckerberg, of Facebook, and Stewart Butterfield, of Slack, who endorse universal basic income. It’s either that or build a wall.Fear of a robot invasion is the obverse of fear of an immigrant invasion, a partisan coin: heads, you’re worried about robots; tails, you’re worried about immigrants. There’s just the one coin. Both fears have to do with jobs, whose loss produces suffering, want, and despair, and whose future scarcity represents a terrifying prospect. Misery likes a scapegoat: heads, blame machines; tails, foreigners. But is the present alarm warranted? Panic is not evidence of danger; it’s evidence of panic. Stoking fear of invading robots and of invading immigrants has been going on for a long time, and the predictions of disaster have, generally, been bananas. Oh, but this time it’s different, the robotomizers insist.This thesis has been rolling around like a marble in the bowl of a lot of people’s brains for a while now, and many of those marbles were handed out by Martin Ford, in his 2015 book, “Rise of the Robots: Technology and the Threat of a Jobless Future.” In the book, and in an essay in “Confronting Dystopia: The New Technological Revolution and the Future of Work” (Cornell), Ford acknowledges that all other earlier robot-invasion panics were unfounded. In the nineteenth century, people who worked on farms lost their jobs when agricultural processes were mechanized, but they eventually earned more money working in factories. In the twentieth century, automation of industrial production led to warnings about “unprecedented economic and social disorder.” Instead, displaced factory workers moved into service jobs. Machines eliminate jobs; rising productivity creates new jobs.“Given this long record of false alarms, contemporary economists are generally dismissive of arguments that technological progress might lead to unemployment as well as falling wages and soaring income inequality,” Ford admits. After all, “history shows that the economy has consistently adjusted to advancing technology by creating new employment opportunities and that these new jobs often require more skills and pay higher wages.”That was then. The reason that things will be different this time, Ford argues, has to do with the changing pace of change. The transformation from an agricultural to an industrial economy was linear; the current acceleration is exponential. The first followed Newton’s law; the second follows Moore’s. The employment apocalypse, when it comes, will happen so fast that workers won’t have time to adjust by shifting to new employment sectors, and, even if they did have time to adjust, there would be no new employment sectors to go to, because robots will be able to do just about everything.It is quite possible that this thesis is correct; it is not possible to know that it is correct. Ford, an advocate of universal basic income, is neither a historian nor an economist. He is a futurist, a modern-day shaman, with an M.B.A. Everybody thinks about the future; futurists do it for a living. Policymakers make plans; futurists read omens. The robots-are-coming omen-reading borrows as much from the conventions of science fiction as from those of historical analysis. It uses “robot” as a shorthand for everything from steam-powered looms to electricity-driven industrial assemblers and artificial intelligence, and thus has the twin effects of compressing time and conflating one thing with another. It indulges in the supposition that work is something the wealthy hand out to the poor, from feudalism to capitalism, instead of something people do, for reasons that include a search for order, meaning, and purpose. It leaves out of its accounting the largest source of labor in the United States before the Civil War, people held in bondage, and fails to consider how the rise of wage labor left women’s work uncompensated. And it ignores the brutal truth that, in American history, panic about technological change is almost always tangled up with panic about immigration. Nineteenth-century populists, those farmers left behind by the industrial revolution, wanted railroad companies to be taxed, but they also wanted to bar African-Americans and Asian immigrants from full citizenship. They raged against the machine; they fought for the color line.Futurists foretell inevitable outcomes by conjuring up inevitable pasts. People who are in the business of selling predictions need to present the past as predictable—the ground truth, the test case. Machines are more predictable than people, and in histories written by futurists the machines just keep coming; depicting their march as unstoppable certifies the futurists’ predictions. But machines don’t just keep coming. They are funded, invented, built, sold, bought, and used by people who could just as easily not fund, invent, build, sell, buy, and use them. Machines don’t drive history; people do. History is not a smart car.Video From The New YorkerHow the Coronavirus Is Widening Economic InequalityIn “Temp: How American Work, American Business, and the American Dream Became Temporary” (Viking), the historian Louis Hyman argues that in the course of the past century management consultants, taking the wheel, reinvented work by making employers more like machines, turning work into the kind of thing that robots could do long before there were any robots able to do it. His story begins in the nineteen-twenties, with the rise of management consulting, and takes a turn in the fifties, with the first major wave of automation, a word coined in 1948. “Machines should be used instead of people whenever possible,” a staffer for the National Office Managers Association advised in 1952. To compete, workers had to become as flexible as machines: able to work on a task basis; ineligible for unions; free at night; willing to work any shift; requiring no health care or other benefits, not so much as a day off at Christmas; easy to hire; and easier to fire.“The rise of computers and the rise of temps went hand in hand,” Hyman writes. By 1958, Elmer Winter had founded Manpower, Inc., and companies all over the country had come to rely on the services of management consultants to trim their employment costs. Hyman argues, “Beginning in the midst of the postwar boom in the 1950s, American jobs were slowly remade from top to bottom: consultants supplanted executives at the top, temps replaced office workers in the middle, and day laborers pushed out union workers at the bottom. On every step of the ladder, work would become more insecure as it became more flexible.”Gradually, Hyman says, “the key features of the postwar corporation—stable workforce, retained earnings, and minimized risk—became liabilities rather than assets.” Beginning in the nineteen-seventies, Harvard Business School’s Michael Porter introduced the logic underlying outsourcing. By the nineteen-eighties, corporations had to get “lean.” (I worked for Porter in those days, as a Manpower temp.) By the nineteen-nineties, they needed to “downsize.” If businesses exist not to make things and employ people but instead to maximize profits for investors, labor can be done by temps, by poorly paid workers in other countries, or by robots, whichever is cheapest.The robots, though, were mainly for show. In the nineteen-eighties, Apple called its headquarters the Robot Factory. “To understand the electronics industry is simple: every time someone says ‘robot,’ simply picture a woman of color,” Hyman advises. One in five electronics companies used no automation at all, and the rest used very little. Seagate’s disk drives were assembled by women in Singapore. Hewlett-Packard hired so many temporary workers that it started its own temp agency. The most important technology in the electronics industry, as Hyman points out, was the fingernail.“Normally, I’d say we can do this the easy way or the hard way, but, honestly, we have time for both. Our 2 P.M. cancelled.”Copy link to cartoonCopyLinkLink copiedShopShopOpen cartoon galleryOpen GalleryIn the nineteen-eighties, the sociologist Patricia Fernandez-Kelly conducted a study of the electronics and garment industries in Southern California. More than seventy per cent of the labor force was women of color, and more than seventy per cent of those women were Hispanic. In San Diego, Fernandez-Kelly interviewed a woman she called Fermina Calero (a pseudonym, to protect her from deportation). Calero was born in Mexico. In 1980, when she was twenty-one, she began working in Tijuana, soldering filaments of metal for sixty-five cents an hour. In 1983, Calero crossed into the United States, illegally, to work at Kaypro, the maker of the Kaypro II, a personal computer that briefly rivalled the Apple II. In the nineteen-sixties and seventies, Andrew Kay, the company’s founder, had hired management consultants to help him reimagine his labor force. In the eighties, when people speaking English responded to the company’s newspaper Help Wanted ads, they were told that there were no openings; when people speaking Spanish called, they were invited to apply. By the time Calero started working for Kaypro, its workforce consisted of seven hundred people, nearly all undocumented Mexican immigrants. The company’s general manager said, “They are reliable; they work hard; they don’t make trouble.” At Kaypro, Calero earned nearly five dollars an hour. When the Immigration and Naturalization Service raided the factory, she hid in a supply closet. She was not a robot.In 1984, the year that Calero hid in a closet at Kaypro, computer scientists at the annual meeting of the American Association for Artificial Intelligence began warning about the coming of an “A.I. winter”: artificial intelligence had been overhyped by a credulous press and overfunded by incautious investors, and, given these wild and wide-eyed expectations, it had underdelivered. The hype was about to die down, and the funding to dry up. The A.I. winter lasted for years.Skeptics of the current robots-are-coming argument predict the arrival of another A.I. winter. “We have not moved a byte forward in understanding human intelligence,” Zia Chishti wrote in the Financial Times last fall. “We have much faster computers, thanks to Moore’s law, but the underlying algorithms are mostly identical to those that powered machines 40 years ago.” That goes back to the time of the Kaypro.A lot has changed in those forty years, not least in the availability of enormous sets of data that artificial intelligences can use to study and learn. Still, the economist Robert J. Gordon is unconvinced that the robots are coming. In his 2016 book, “The Rise and Fall of American Growth,” he argued that a century of economic expansion that began in 1870—driven by human-condition changing developments like electricity, a public water supply, and the interstate-highway system—ended in 1970, and that, since then, inventions have been merely incremental. The telephone was patented in 1876. It changed people’s lives, and contributed to a huge rise in productivity. The cell phone, Gordon argues, just isn’t that different from a telephone. In a 2016 essay, “Why Robots Will Not Decimate Human Jobs,” Gordon points out that the uses to which smartphones get put are “not a part of the market economy that creates jobs and pays wages.” Robots have altered manufacturing, he concedes, but he doesn’t think that they’ve altered the economy, or that they’re about to. “I play a game called ‘find the robot,’ ” he writes. “In my daily strolls in and out of supermarkets, restaurants, doctor and dentist offices, my nearby hospital, offices in my own university, and the vast amount of employment involving elementary and secondary teachers, personal trainers, and old age caretakers, I have yet to find a robot.”Still, even if the hype about robots is mostly unwarranted, the worry about jobs is real. If the latest jobs numbers look good, the longer-term trends look bad, especially for Americans without a high-school diploma, or less, a population whose real wages have been falling for decades. In a downward compression of the labor market, these jobs have been taken not so much by robots as by college graduates: as much as forty per cent of college graduates are currently working at jobs that do not require a college degree, Ellen Ruppel Shell reports, in “The Job: Work and Its Future in a Time of Radical Change” (Currency). Four out of every five children born in the United States in 1950 went on to earn more than their parents. For children born in 1980, that ratio had fallen to one in two. Lately, it’s down to one in three. Estimates range from the cautious to the entirely hysterical, but one reasonable study predicts that, by 2050, one in four working-age American men will be unemployed, having been replaced by some form of automation. Most imminently threatened are the millions of people who work as drivers of cars and trucks, scheduled to be replaced by fleets of self-driving vehicles beginning as early as next year.Economic inequality produces political instability and partisan death matches. Everyone worries about jobs, but people who worry about robots and people who worry about immigrants propose very different solutions. Either way, much writing in this field is, essentially, fantasy. In “The Globotics Upheaval,” Baldwin predicts that the march of the robots will have four stages: transformation, upheaval, backlash, and resolution. The resolution will involve what he calls “shelterism.” Once white-collar workers realize that their jobs are on the line, too, they’ll find ways to protect themselves by “sheltering” certain activities, things that only humans can do. He explains, “This will mean that our work lives will be filled with far more caring, sharing, understanding, creating, empathizing, innovating, and managing people who are actually in the same room. This is a logical inevitability—everything else will be done by globots.” The catch is that, historically, caring, sharing, understanding, and empathizing with people who are in the same room as you has been the work of women, and is therefore either unpaid, and not recognized as work, or paid very badly. Childcare, elementary-school teaching, nursing, geriatric care, and social work will not suddenly become high-paying, high-prestige professions simply because everything else is done by robots. If that were going to happen, it would already be happening, because we already know that these jobs require beings who are human. Instead, something darker is going on, mirrored in the feminizing of robots, from the male robots of the nineteen-sixties and seventies—Hal, R2-D2, C-3PO, and Mr. Robinson’s robot on “Lost in Space”—to the fembots and sexbots of “Her” and “Ex Machina,” and, not least, the sexy and slavish Alexa. Female workers aren’t being paid more for being human; instead, robots are selling better when they’re female.The economist Oren Cass, the author of “The Once and Future Worker: A Vision for the Renewal of Work in America” (Encounter), much of which originally appeared in National Review, is fed up with the robot hysteria. “Technological innovation and automation have always been integral to our economic progress, and in a well-functioning labor market, they should produce gains for all types of workers,” he insists. He has no patience with advocates of universal basic income, either. “We have reached a point where the rich think paying everyone else to go away represents compassionate thinking,” he writes.Like Hyman, Cass blames mid-twentieth-century economic thinkers for the current malaise, though he blames different thinkers. In the middle decades of the twentieth century, he argues, economic policymakers abandoned workers and the health of the labor market in favor of a commitment to over-all economic growth, with redistribution as an adjustment and consumerism as its objective. That required quantifying prosperity, hence the G.D.P., a measure that Cass, along with other writers, finds to be disastrous, not least because it values consumers above producers. Cass sees universal basic income as the end-stage scenario of every other redistribution program, whose justification is that the poor will be fine without work as long as they can buy things. Here he mocks the advocates of the current economic arrangement, who are prone to note that the poor are not actually starving, “and so many people have iPhones!”Reporters are suckers for the hype, Cass maintains, pointing out that after a 2017 study by the National Bureau of Economic Research suggested that, in the next hundred years, robots might eliminate as many manufacturing jobs as were lost in 2001 (presumably, a tolerable loss), the Times ran a story with the headline “Evidence That Robots Are Winning the Race for American Jobs,” while the Washington Post titled its story “We’re So Unprepared for the Robot Apocalypse.” Cass offers a careful criticism of the robots-are-stealing-our-jobs theory. He cites four of its errors. It overestimates twenty-first-century innovations and underestimates the innovations of earlier centuries. It miscalculates the pace of change. It assumes that automation will not create new sectors. (3-D printing might replace a lot of manufacturing workers, but it could also create a lot of new small businesses.) And it fails to appreciate the complexity of many of the jobs it thinks robots can do. The 2013 Oxford study that kept Andrés Oppenheimer up at night Cass finds to be mostly silly. Its authors, Carl Frey and Michael Osborne, rated seven hundred and two occupations from least “computerizable” to most. Highly vulnerable are school-bus drivers, and, while a self-driving school bus does not seem technically too far off, Cass points out, few parents can imagine putting their kids on a bus without a grownup to make sure they don’t bash one another the whole way to school.Cass’s own policy proposals center, very reasonably, on the importance of work and family, but he fails to demonstrate how his proposals—lowering environmental regulations and establishing academic tracking in high schools—will achieve his objectives. And though “The Once and Future Worker” offers a rousing call for an honest reckoning with American economic policy, it also indulges in its own sleight of hand. “The story goes that ‘automation’ or the ‘knowledge economy,’ not bad public policy, is to blame,” Cass writes. “Historically, economists and policy makers have led the effort to explain that technological innovation is good for workers throughout the economy, even as its ‘creative destruction’ causes dislocation for some. So why, suddenly, are they so eager to throw robots and programmers under the bus?” One answer might be that, given the current state of American political polarization, it’s either throw the robots under the bus or throw the immigrants. Cass, not surprisingly, advocates restricting immigration.Donald Trump ran for President on a promise to create twenty-five million new jobs during the next decade. “My economic plan rejects the cynicism that says our labor force will keep declining, that our jobs will keep leaving, and that our economy can never grow as it did once before,” he said in September, 2016. Many economists mocked his plan, which included protecting American jobs by imposing tariffs on imports. The Economist announced a new political fault line, not between left and right but between open and closed: “Welcome immigrants or keep them out? Open up to foreign trade or protect domestic industries? Embrace cultural change, or resist it?” Barack Obama was an opener. Openers tend to talk about robots. “The next wave of economic dislocation won’t come from overseas,” Obama said in his farewell address, in January, 2017, days before Trump’s Inauguration. “It will come from the relentless pace of automation that makes many good, middle-class jobs obsolete.”Trump is a closer. Closers tend to talk about immigrants. Trump has tweeted the word “jobs” nearly six hundred times, but not once has he tweeted the words “robot,” “robots,” or “automation.” “We’re going to fight for every last American job,” he promised from the floor of a Boeing plant in South Carolina, weeks after taking office. “I don’t want companies leaving our country,” the new President said. “There will be a very substantial penalty to be paid when they fire their people and move to another country, make the products, and think that they are going to sell it back over what will soon be a very, very strong border.” That June, Boeing laid off nearly two hundred employees from the South Carolina plant, as part of a forty-per-cent reduction in its production of 777s. In 2017, the company laid off nearly six thousand workers.Trump’s Administration mocks fears of a robot invasion. Closers usually do. “I’m not worried at all,” Secretary of the Treasury Steve Mnuchin said two years ago. Nevertheless, some think tankers suggested that Trump’s election was “secretly about automation.” And a study published last summer in the Oxford Review of Economic Policy—whose lead author, Carl Frey, is the same guy who made the list of the seven hundred and two most computerizable jobs—argues that the robot caravan got Trump elected. Measuring the density of robots and comparing them with election returns, Frey and his colleagues found that “electoral districts that became more exposed to automation during the years running up to the election were more likely to vote for Trump.” Indulging in a counterfactual, they suggest that a less steeply rising increase in exposure to robots would have tipped both Pennsylvania and Wisconsin toward voting for Hillary Clinton. According to this line of thinking, Twitter bots and fake Facebook news didn’t elect Donald Trump, but robots really might have. Or maybe it was all the talk about the wall.Heads, the robots are coming! Accept the inevitability of near-universal unemployment! Tails, the Mexicans are coming! Close the borders! So far, the only other choice, aside from helplessly watching the rise of extremism, is to mint a new coin. Heat a forge. Smelt a blank. Engrave two dies. Put your blank in between them. Strike the whole thing with a hammer. Anyone can do it. ♦","The old robots were blue-collar workers, burly and clunky, the machines that rusted the Rust Belt. But, according to the economist Richard Baldwin, in “The Globotics Upheaval: Globalization, Robotics, and the Future of Work” (Oxford), the new ones are “white-collar robots,” knowledge workers and quinoa-and-oat-milk globalists, the machines that will bankrupt Brooklyn. Mainly, they’re algorithms. Except when they’re immigrants. Baldwin calls that kind “remote intelligence,” or R.I.: they’re not exactly robots but, somehow, they fall into the same category. They’re people from other countries who can steal your job without ever really crossing the border: they just hop over, by way of the Internet and apps like Upwork, undocumented, invisible, ethereal. Between artificial intelligence and remote intelligence, Baldwin warns, “this international talent tidal wave is coming straight for the good, stable jobs that have been the foundation of middle-class prosperity in the US and Europe, and other high-wage economies.” Change your Wi-Fi password. Clear your browser history. Ask H.R. about early retirement. The globots are coming.
How can you know if you’re about to get replaced by an invading algorithm or an augmented immigrant? “If your job can be easily explained, it can be automated,” Anders Sandberg, of Oxford’s Future of Humanity Institute, tells Oppenheimer. “If it can’t, it won’t.” (Rotten luck for people whose job description is “Predict the future.”) Baldwin offers three-part advice: (1) avoid competing with A.I. and R.I.; (2) build skills in things that only humans can do, in person; and (3) “realize that humanity is an edge not a handicap.” What all this means is hard to say, especially if you’ve never before considered being human to be a handicap. As for the future of humanity, Oppenheimer offers another cockamamie rule of three: “Society will be divided into three general groups. The first will be members of the elites, who will be able to adapt to the ever-changing technological landscape and who will earn the most money, followed by a second group made up primarily of those who provide personalized services to the elite, including personal trainers, Zumba class instructors, meditation gurus, piano teachers, and personal chefs, and finally a third group of those who will be mostly unemployed and may be receiving a universal basic income as compensation for being the victims of technological unemployment.”
Readers of Douglas Adams will recognize this sort of hooey from “The Hitchhiker’s Guide to the Galaxy.” Long ago, in a galaxy not at all far away, the people of the planet Golgafrincham were divided into three groups: A, “all the brilliant leaders, the scientists, the great artists, you know, all the achievers”; B, “hairdressers, tired TV producers, insurance salesmen, personnel officers, security guards, public relations executives, management consultants” (the group that everyone else considers to be “a bunch of useless idiots”); and, C, “all the people who did the actual work, who made things and did things.” The B people, told they must lead an expedition to colonize another planet, rocket away in a starship, having been led to believe that their planet is doomed. “Apparently it was going to crash into the sun or something,” the B ship’s captain tells Arthur Dent, vaguely wondering why the other ships never followed. “Or maybe it was that the moon was going to crash into us. Something of the kind. Absolutely terrifying prospect whatever it was.” Dent inquires, “And they made sure they sent you lot off first, did they?”
This time, notwithstanding Elon Musk’s ambition to colonize Mars, no one’s trying to persuade the B people to board a spaceship, because the B people—the hairdressers and the Zumba-class instructors, the meditation gurus and the personal trainers—are supposed to stick around to cater to the A people. No, this time it’s the C people, the people who make and do things—things that can now be made and done faster and cheaper by robots—who are being flushed down the cosmic toilet. The historian and sometime futurist Yuval Noah Harari has a name for the C people: he calls them the “useless class.” Some futurists suggest that, in our Asimov-y future, these sort of people might wind up spending their empty days playing video games. Otherwise, they’ll wage a revolution, an eventuality that the self-proclaimed “cognitive elite”—the A people, who believe themselves to be cleverer than the cleverest robots—intend to wait out in fortified lairs. (Peter Thiel owns nearly five hundred acres of land in New Zealand, complete with its own water supply.) More popular is the proposal to pay the C people for doing nothing, in order to avert the revolution. “It’s going to be necessary,” Musk said during a summit in Dubai two years ago, joining a small herd of other billionaires, including Mark Zuckerberg, of Facebook, and Stewart Butterfield, of Slack, who endorse universal basic income. It’s either that or build a wall.
This thesis has been rolling around like a marble in the bowl of a lot of people’s brains for a while now, and many of those marbles were handed out by Martin Ford, in his 2015 book, “Rise of the Robots: Technology and the Threat of a Jobless Future.” In the book, and in an essay in “Confronting Dystopia: The New Technological Revolution and the Future of Work” (Cornell), Ford acknowledges that all other earlier robot-invasion panics were unfounded. In the nineteenth century, people who worked on farms lost their jobs when agricultural processes were mechanized, but they eventually earned more money working in factories. In the twentieth century, automation of industrial production led to warnings about “unprecedented economic and social disorder.” Instead, displaced factory workers moved into service jobs. Machines eliminate jobs; rising productivity creates new jobs.
“Given this long record of false alarms, contemporary economists are generally dismissive of arguments that technological progress might lead to unemployment as well as falling wages and soaring income inequality,” Ford admits. After all, “history shows that the economy has consistently adjusted to advancing technology by creating new employment opportunities and that these new jobs often require more skills and pay higher wages.”
That was then. The reason that things will be different this time, Ford argues, has to do with the changing pace of change. The transformation from an agricultural to an industrial economy was linear; the current acceleration is exponential. The first followed Newton’s law; the second follows Moore’s. The employment apocalypse, when it comes, will happen so fast that workers won’t have time to adjust by shifting to new employment sectors, and, even if they did have time to adjust, there would be no new employment sectors to go to, because robots will be able to do just about everything.
It is quite possible that this thesis is correct; it is not possible to know that it is correct. Ford, an advocate of universal basic income, is neither a historian nor an economist. He is a futurist, a modern-day shaman, with an M.B.A. Everybody thinks about the future; futurists do it for a living. Policymakers make plans; futurists read omens. The robots-are-coming omen-reading borrows as much from the conventions of science fiction as from those of historical analysis. It uses “robot” as a shorthand for everything from steam-powered looms to electricity-driven industrial assemblers and artificial intelligence, and thus has the twin effects of compressing time and conflating one thing with another. It indulges in the supposition that work is something the wealthy hand out to the poor, from feudalism to capitalism, instead of something people do, for reasons that include a search for order, meaning, and purpose. It leaves out of its accounting the largest source of labor in the United States before the Civil War, people held in bondage, and fails to consider how the rise of wage labor left women’s work uncompensated. And it ignores the brutal truth that, in American history, panic about technological change is almost always tangled up with panic about immigration. Nineteenth-century populists, those farmers left behind by the industrial revolution, wanted railroad companies to be taxed, but they also wanted to bar African-Americans and Asian immigrants from full citizenship. They raged against the machine; they fought for the color line.
In “Temp: How American Work, American Business, and the American Dream Became Temporary” (Viking), the historian Louis Hyman argues that in the course of the past century management consultants, taking the wheel, reinvented work by making employers more like machines, turning work into the kind of thing that robots could do long before there were any robots able to do it. His story begins in the nineteen-twenties, with the rise of management consulting, and takes a turn in the fifties, with the first major wave of automation, a word coined in 1948. “Machines should be used instead of people whenever possible,” a staffer for the National Office Managers Association advised in 1952. To compete, workers had to become as flexible as machines: able to work on a task basis; ineligible for unions; free at night; willing to work any shift; requiring no health care or other benefits, not so much as a day off at Christmas; easy to hire; and easier to fire.
“The rise of computers and the rise of temps went hand in hand,” Hyman writes. By 1958, Elmer Winter had founded Manpower, Inc., and companies all over the country had come to rely on the services of management consultants to trim their employment costs. Hyman argues, “Beginning in the midst of the postwar boom in the 1950s, American jobs were slowly remade from top to bottom: consultants supplanted executives at the top, temps replaced office workers in the middle, and day laborers pushed out union workers at the bottom. On every step of the ladder, work would become more insecure as it became more flexible.”
Gradually, Hyman says, “the key features of the postwar corporation—stable workforce, retained earnings, and minimized risk—became liabilities rather than assets.” Beginning in the nineteen-seventies, Harvard Business School’s Michael Porter introduced the logic underlying outsourcing. By the nineteen-eighties, corporations had to get “lean.” (I worked for Porter in those days, as a Manpower temp.) By the nineteen-nineties, they needed to “downsize.” If businesses exist not to make things and employ people but instead to maximize profits for investors, labor can be done by temps, by poorly paid workers in other countries, or by robots, whichever is cheapest.
The robots, though, were mainly for show. In the nineteen-eighties, Apple called its headquarters the Robot Factory. “To understand the electronics industry is simple: every time someone says ‘robot,’ simply picture a woman of color,” Hyman advises. One in five electronics companies used no automation at all, and the rest used very little. Seagate’s disk drives were assembled by women in Singapore. Hewlett-Packard hired so many temporary workers that it started its own temp agency. The most important technology in the electronics industry, as Hyman points out, was the fingernail.
In the nineteen-eighties, the sociologist Patricia Fernandez-Kelly conducted a study of the electronics and garment industries in Southern California. More than seventy per cent of the labor force was women of color, and more than seventy per cent of those women were Hispanic. In San Diego, Fernandez-Kelly interviewed a woman she called Fermina Calero (a pseudonym, to protect her from deportation). Calero was born in Mexico. In 1980, when she was twenty-one, she began working in Tijuana, soldering filaments of metal for sixty-five cents an hour. In 1983, Calero crossed into the United States, illegally, to work at Kaypro, the maker of the Kaypro II, a personal computer that briefly rivalled the Apple II. In the nineteen-sixties and seventies, Andrew Kay, the company’s founder, had hired management consultants to help him reimagine his labor force. In the eighties, when people speaking English responded to the company’s newspaper Help Wanted ads, they were told that there were no openings; when people speaking Spanish called, they were invited to apply. By the time Calero started working for Kaypro, its workforce consisted of seven hundred people, nearly all undocumented Mexican immigrants. The company’s general manager said, “They are reliable; they work hard; they don’t make trouble.” At Kaypro, Calero earned nearly five dollars an hour. When the Immigration and Naturalization Service raided the factory, she hid in a supply closet. She was not a robot.
Skeptics of the current robots-are-coming argument predict the arrival of another A.I. winter. “We have not moved a byte forward in understanding human intelligence,” Zia Chishti wrote in the Financial Times last fall. “We have much faster computers, thanks to Moore’s law, but the underlying algorithms are mostly identical to those that powered machines 40 years ago.” That goes back to the time of the Kaypro.
A lot has changed in those forty years, not least in the availability of enormous sets of data that artificial intelligences can use to study and learn. Still, the economist Robert J. Gordon is unconvinced that the robots are coming. In his 2016 book, “The Rise and Fall of American Growth,” he argued that a century of economic expansion that began in 1870—driven by human-condition changing developments like electricity, a public water supply, and the interstate-highway system—ended in 1970, and that, since then, inventions have been merely incremental. The telephone was patented in 1876. It changed people’s lives, and contributed to a huge rise in productivity. The cell phone, Gordon argues, just isn’t that different from a telephone. In a 2016 essay, “Why Robots Will Not Decimate Human Jobs,” Gordon points out that the uses to which smartphones get put are “not a part of the market economy that creates jobs and pays wages.” Robots have altered manufacturing, he concedes, but he doesn’t think that they’ve altered the economy, or that they’re about to. “I play a game called ‘find the robot,’ ” he writes. “In my daily strolls in and out of supermarkets, restaurants, doctor and dentist offices, my nearby hospital, offices in my own university, and the vast amount of employment involving elementary and secondary teachers, personal trainers, and old age caretakers, I have yet to find a robot.”
Economic inequality produces political instability and partisan death matches. Everyone worries about jobs, but people who worry about robots and people who worry about immigrants propose very different solutions. Either way, much writing in this field is, essentially, fantasy. In “The Globotics Upheaval,” Baldwin predicts that the march of the robots will have four stages: transformation, upheaval, backlash, and resolution. The resolution will involve what he calls “shelterism.” Once white-collar workers realize that their jobs are on the line, too, they’ll find ways to protect themselves by “sheltering” certain activities, things that only humans can do. He explains, “This will mean that our work lives will be filled with far more caring, sharing, understanding, creating, empathizing, innovating, and managing people who are actually in the same room. This is a logical inevitability—everything else will be done by globots.” The catch is that, historically, caring, sharing, understanding, and empathizing with people who are in the same room as you has been the work of women, and is therefore either unpaid, and not recognized as work, or paid very badly. Childcare, elementary-school teaching, nursing, geriatric care, and social work will not suddenly become high-paying, high-prestige professions simply because everything else is done by robots. If that were going to happen, it would already be happening, because we already know that these jobs require beings who are human. Instead, something darker is going on, mirrored in the feminizing of robots, from the male robots of the nineteen-sixties and seventies—Hal, R2-D2, C-3PO, and Mr. Robinson’s robot on “Lost in Space”—to the fembots and sexbots of “Her” and “Ex Machina,” and, not least, the sexy and slavish Alexa. Female workers aren’t being paid more for being human; instead, robots are selling better when they’re female.
The economist Oren Cass, the author of “The Once and Future Worker: A Vision for the Renewal of Work in America” (Encounter), much of which originally appeared in National Review, is fed up with the robot hysteria. “Technological innovation and automation have always been integral to our economic progress, and in a well-functioning labor market, they should produce gains for all types of workers,” he insists. He has no patience with advocates of universal basic income, either. “We have reached a point where the rich think paying everyone else to go away represents compassionate thinking,” he writes.
Like Hyman, Cass blames mid-twentieth-century economic thinkers for the current malaise, though he blames different thinkers. In the middle decades of the twentieth century, he argues, economic policymakers abandoned workers and the health of the labor market in favor of a commitment to over-all economic growth, with redistribution as an adjustment and consumerism as its objective. That required quantifying prosperity, hence the G.D.P., a measure that Cass, along with other writers, finds to be disastrous, not least because it values consumers above producers. Cass sees universal basic income as the end-stage scenario of every other redistribution program, whose justification is that the poor will be fine without work as long as they can buy things. Here he mocks the advocates of the current economic arrangement, who are prone to note that the poor are not actually starving, “and so many people have iPhones!”
Reporters are suckers for the hype, Cass maintains, pointing out that after a 2017 study by the National Bureau of Economic Research suggested that, in the next hundred years, robots might eliminate as many manufacturing jobs as were lost in 2001 (presumably, a tolerable loss), the Times ran a story with the headline “Evidence That Robots Are Winning the Race for American Jobs,” while the Washington Post titled its story “We’re So Unprepared for the Robot Apocalypse.” Cass offers a careful criticism of the robots-are-stealing-our-jobs theory. He cites four of its errors. It overestimates twenty-first-century innovations and underestimates the innovations of earlier centuries. It miscalculates the pace of change. It assumes that automation will not create new sectors. (3-D printing might replace a lot of manufacturing workers, but it could also create a lot of new small businesses.) And it fails to appreciate the complexity of many of the jobs it thinks robots can do. The 2013 Oxford study that kept Andrés Oppenheimer up at night Cass finds to be mostly silly. Its authors, Carl Frey and Michael Osborne, rated seven hundred and two occupations from least “computerizable” to most. Highly vulnerable are school-bus drivers, and, while a self-driving school bus does not seem technically too far off, Cass points out, few parents can imagine putting their kids on a bus without a grownup to make sure they don’t bash one another the whole way to school.
Cass’s own policy proposals center, very reasonably, on the importance of work and family, but he fails to demonstrate how his proposals—lowering environmental regulations and establishing academic tracking in high schools—will achieve his objectives. And though “The Once and Future Worker” offers a rousing call for an honest reckoning with American economic policy, it also indulges in its own sleight of hand. “The story goes that ‘automation’ or the ‘knowledge economy,’ not bad public policy, is to blame,” Cass writes. “Historically, economists and policy makers have led the effort to explain that technological innovation is good for workers throughout the economy, even as its ‘creative destruction’ causes dislocation for some. So why, suddenly, are they so eager to throw robots and programmers under the bus?” One answer might be that, given the current state of American political polarization, it’s either throw the robots under the bus or throw the immigrants. Cass, not surprisingly, advocates restricting immigration.
Trump is a closer. Closers tend to talk about immigrants. Trump has tweeted the word “jobs” nearly six hundred times, but not once has he tweeted the words “robot,” “robots,” or “automation.” “We’re going to fight for every last American job,” he promised from the floor of a Boeing plant in South Carolina, weeks after taking office. “I don’t want companies leaving our country,” the new President said. “There will be a very substantial penalty to be paid when they fire their people and move to another country, make the products, and think that they are going to sell it back over what will soon be a very, very strong border.” That June, Boeing laid off nearly two hundred employees from the South Carolina plant, as part of a forty-per-cent reduction in its production of 777s. In 2017, the company laid off nearly six thousand workers.
Trump’s Administration mocks fears of a robot invasion. Closers usually do. “I’m not worried at all,” Secretary of the Treasury Steve Mnuchin said two years ago. Nevertheless, some think tankers suggested that Trump’s election was “secretly about automation.” And a study published last summer in the Oxford Review of Economic Policy—whose lead author, Carl Frey, is the same guy who made the list of the seven hundred and two most computerizable jobs—argues that the robot caravan got Trump elected. Measuring the density of robots and comparing them with election returns, Frey and his colleagues found that “electoral districts that became more exposed to automation during the years running up to the election were more likely to vote for Trump.” Indulging in a counterfactual, they suggest that a less steeply rising increase in exposure to robots would have tipped both Pennsylvania and Wisconsin toward voting for Hillary Clinton. According to this line of thinking, Twitter bots and fake Facebook news didn’t elect Donald Trump, but robots really might have. Or maybe it was all the talk about the wall.
Heads, the robots are coming! Accept the inevitability of near-universal unemployment! Tails, the Mexicans are coming! Close the borders! So far, the only other choice, aside from helplessly watching the rise of extremism, is to mint a new coin. Heat a forge. Smelt a blank. Engrave two dies. Put your blank in between them. Strike the whole thing with a hammer. Anyone can do it. ♦",https://www.newyorker.com/magazine/2019/03/04/are-robots-competing-for-your-job,"https://media.newyorker.com/photos/5c6f02d13a3ac62cebaaf5fd/1:1/w_2114,h_2114,c_limit/190304_r33801.jpg","{'@type': 'CreativeWork', 'name': 'The New Yorker'}","Probably, but don’t count yourself out, Jill Lepore writes.","{'@type': 'WebPage', '@id': 'https://www.newyorker.com/magazine/2019/03/04/are-robots-competing-for-your-job'}",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vaWRyYy1jcmRpLmNhL2VuL3Jlc2VhcmNoLWluLWFjdGlvbi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1kZXZlbG9wbWVudNIBAA?oc=5,Artificial intelligence for development | IDRC - International Development Research Centre,2019-02-27,International Development Research Centre,https://idrc-crdi.ca,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,N/A,N/A,"







Home




Artificial intelligence for development




 




  
Twitter

  
Facebook

  
LinkedIn

   
Email


Print













   
Email

  
Facebook

  
LinkedIn


Print

  
Twitter




Close








February 27, 2019



 

MARIUS MASALAR



 




Balancing AI’s potential



We can already see the potential for artificial intelligence (AI) in international development: the seemingly endless possibilities to enhance productivity and innovation across healthcare, agriculture, education, transportation, and governance.
Yet it is also becoming abundantly clear that AI could have negative repercussions as well, particularly in countries with weaker institutional capacity and legal protections. AI has the potential to threaten democratic processes, employment, human rights and — because of the weaponization of AI tools — privacy, policing, and defense.
Apart from these potential benefits and threats, the transformative potential of AI for both good and harm will be magnified in the Global South, where existing gender and socio-economic inequalities could either be tempered or exacerbated.



Artificial Intelligence in the Global South



Given the opportunities and potential consequences of new automation and mechanization techniques and advanced analysis through machine learning and neural networks, IDRC is investing in applied research across a number of domains to advance the public good with the use of artificial intelligence for development (AI4D).
These activities aim to:

Improve policy and regulation to promote inclusive and human rights-based AI
	Responsive institutions and good governance have a crucial role to play in mitigating the potential harms of AI, such as job losses, while ensuring that AI systems deliver innovation and impact.
Spur AI applications for public interest
	Research and innovation networks will foster collaborative and cross-disciplinary spaces for experts to design context-specific AI solutions across a broad range of sectors.
Foster AI infrastructure and skills in the Global South
	It is crucial to support building blocks for the successful dissemination of AI, such as releasing public and private sector data, capacity building, and supporting ethical and fair systems that support the public good.




What does AI4D look like in practice?



IDRC-supported research is ensuring that the benefits of AI are used to advance development, reduce social inequality, and foster greater gender parity.
These activities aim to:



Provide a comprehensive overview of AI’s potential and benefits for the developing world








 






IDRC’s white paper, Artificial intelligence and human development, offers a detailed analysis of AI’s potential impact in the Global South and proposes a proactive research agenda to address the challenges AI poses in the developing world.







Establish AI research networks across the Global South




Media

 

IDRC





A recent mapping of AI talents, actors, and knowledge hot spots in the Global South illustrates the extent to which universities, start-ups, and other stakeholders already engage with AI across Africa.
Through a series of consultations and workshops, IDRC is working with partners to build networks of AI researchers and innovators in Latin America, Africa, and Asia. A critical focus of these consultations is how AI can contribute to achieving the UN’s Sustainable Development Goals. In turn, these consultations will form the basis of networks of excellence to advance and implement the AI4D program.



Fund leading-edge research



Where will AI lead and who will it benefit? IDRC is supporting research that seeks to improve our understanding of how AI will impact human development.







 






New AI research network in sub-Saharan Africa


The launch of a network of excellence will improve our understanding of the ways AI will impact human development.











 






Harnessing big data to meet the SDGs


The big data for development network is using AI to measure progress on the Sustainable Development Goals.











 






Open and collaborative innovation to scale gender equality, youth employment, and inclusion


The Open Africa Innovation Research Network (OpenAIR) is exploring how Africa’s high-tech hubs facilitate the adaptation and adoption of AI to inform government priorities.











 






Canada first to adopt strategy for artificial intelligence


In this UNESCO blog post, Naser Faruqui (IDRC), Elissa Strome (CIFAR) and Remi Quirion (Province of Quebec) explain why Canada became the first country in the world in 2017 to announce a national strategy for artificial intelligence.











 






Excitement, concern, and hope for artificial intelligence in the Global South


Artificial intelligence is a double-edged sword, observes IDRC’s Matthew Smith — its benefits and pitfalls need to be balanced.






















",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDE5LzIvMjcvMTgyNDI3MjQvZmFjZWJvb2stbW9kZXJhdGlvbi1haS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1wbGF0Zm9ybXPSAQA?oc=5,AI won't relieve the misery of Facebook's human moderators - The Verge,2019-02-27,The Verge,https://www.theverge.com,"Google is known for being one of the best places to work. But for the many content moderators working for Google and YouTube, the job is traumatic. And even the best workplace conditions don’t make up for the fact that many moderators suffer long term psychological consequences of doing this job. The Verge traveled to Washington, DC and Austin, TX to speak to a former full time google moderator and to current YouTube contract moderators to see how their experiences compare. 

Following his investigations on Facebook, The Verge’s Casey Newton reports on the working conditions and side effects of scrubbing the internet of “violent extremism” content at Google and YouTube. You can read the full exclusive here: http://bit.ly/2PqraAV

You can find Casey's story about the working conditions of Facebook moderators in Phoenix, AZ here: http://bit.ly/2IqQHqb

Subscribe: http://goo.gl/G5RXGs
Like The Verge on Facebook: https://goo.gl/2P1aGc
Follow on Twitter: https://goo.gl/XTWX61
Follow on Instagram: https://goo.gl/7ZeLvX

Why'd You Push That Button Podcast: https://pod.link/1295289748
The Vergecast Podcast: https://pod.link/430333725
More about our podcasts: https://www.theverge.com/podcasts

Read More: http://www.theverge.com
Community guidelines: http://bit.ly/2D0hlAv
Wallpapers from The Verge: https://bit.ly/2xQXYJr

Subscribe to Verge Science on YouTube, a new home base for our explorations into the future of science: http://bit.ly/2FqJZMl",N/A,Artificial intelligence can’t solve content moderation,N/A,http://schema.org/,VideoObject,https://www.theverge.com/2019/2/27/18242724/facebook-moderation-ai-artificial-intelligence-platforms,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/GbmBwnlATh5O0INgNs_jEBS_1DM=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/10105619/acasto_180123_1777_0002_v3.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/FzFmB5PLhLEi__6Tem8KZd_9fDo=/0x0:2040x1360/1400x1050/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/10105619/acasto_180123_1777_0002_v3.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/nZIogKgqUivKDFmneiPKB5nttyw=/0x0:2040x1360/1400x1400/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/10105619/acasto_180123_1777_0002_v3.jpg', 'width': 1400, 'height': 1400}]","[{'@type': 'Person', 'name': 'James Vincent', 'url': 'https://www.theverge.com/authors/james-vincent'}]","{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",AI won’t relieve the misery of Facebook’s human moderators,2019-02-27T17:41:35.000Z,2019-02-27T17:41:35.000Z,,Google and YouTube moderators speak out,,,N/A,N/A,"Tech/Artificial Intelligence/FacebookAI won’t relieve the misery of Facebook’s human moderatorsAI won’t relieve the misery of Facebook’s human moderators / The problem of online content moderation can’t be solved with artificial intelligence, say expertsBy  James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge. Feb 27, 2019, 12:41 PM ESTShare this story0 Comments / 0 New Illustration by Alex Castro / The VergeNo matter what companies say, AI is not going to solve the problem of content moderation online. It’s a promise we’ve heard many times before, particularly from Facebook CEO Mark Zuckerberg, but experts say the technology is just not there — and, in fact, may never be. Most social networks keep unwanted content off their platforms using a combination of automated filtering and human moderators. As The Verge revealed in a recent investigation, human moderators often work in highly stressful conditions. Employees have to click through hundreds of items of flagged content every day — everything from murder to sexual abuse — and then decide whether or not it violates a platform’s rules, often working on tightly-controlled schedules and without adequate training or support. When presented with the misery their platforms are creating (as well as other moderation-adjacent problems, like perceived bias) companies often say more technology is the solution. During his hearings in front of congress last year, for example, Zuckerberg cited artificial intelligence more than 30 times as the answer to this and other issues. “AI is Zuckerberg’s MacGuffin,” James Grimmelmann, a law professor at Cornell Tech, told The Washington Post at the time. “It won’t solve Facebook’s problems, but it will solve Zuckerberg’s: getting someone else to take responsibility.”So what is AI doing for Facebook and other platforms right now, and why can’t it do more? The problem of automating human cultureRight now, automated systems using AI and machine learning are certainly doing quite a bit to help with moderation. They act as triage systems, for example, pushing suspect content to human moderators, and are able to weed out some unwanted stuff on their own. But the way they do so is relatively simple. Either by using visual recognition to identify a broad category of content (like “human nudity” or “guns”), which is prone to mistakes; or by matching content to an index of banned items, which requires humans to create said index in the first place. The latter approach is used to get rid of the most obvious infringing material; things like propaganda videos from terrorist organizations, child abuse material, and copyrighted content. In each case, content is identified by humans and “hashed,” meaning it’s turned into a unique string of numbers that’s quicker to process. The technology is broadly reliable, but it can still lead to problems. YouTube’s ContentID system, for example, has flagged uploads like white noise and bird song as copyright infringement in the past. AI systems are being trained to parse new sorts of images, like memes.  Image: FacebookThings become much trickier when the content itself can’t be easily classified even by humans. This can include content that algorithms certainly recognize, but that has many shades of meaning (like nudity — does breast-feeding count?) or that are very context-dependent, like harassment, fake news, misinformation, and so on. None of these categories have simple definitions, and for each of them there are edge-cases with no objective status, examples where someone’s background, personal ethos, or simply their mood on any given day might make the difference between one definition and another. We’re asking AI to understand the complexities of human cultureThe problem with trying to get machines to understand this sort of content, says Robyn Caplan, an affiliate researcher at the nonprofit Data & Society, is that it is essentially asking them to understand human culture — a phenomenon too fluid and subtle to be described in simple, machine-readable rules. “[This content] tends to involve context that is specific to the speaker,” Caplan tells The Verge. “That means things like power dynamics, race relations, political dynamics, economic dynamics.” Since these platforms operate globally, varying cultural norms need to be taken into account too, she says, as well as different legal regimes. One way to know whether content will be difficult to classify, says Eric Goldman, a professor of law at Santa Clara University, is to ask whether or not understanding it requires “extrinsic information” — that is, information outside the image, video, audio, or text. “For example, filters are not good at figuring out hate speech, parody, or news reporting of controversial events because so much of the determination depends on cultural context and other extrinsic information,” Goldman tells The Verge. “Similarly, filters aren’t good at determining when a content republication is fair use under US copyright law because the determination depends on extrinsic information such as market dynamics, the original source material, and the uploader’s other activities.”How far can we push AI systems? But AI as a field is moving very swiftly. So will future algorithms be able to reliably classify this sort of content in the future? Goldman and Caplan are skeptical.AI will get better at understanding context, says Goldman, but it’s not evident that AI will soon be able to do so better than a human. “AI will not replace [...] human reviewers for the foreseeable future,” he says.Caplan agrees, and points out that as long as humans argue about how to classify this sort of material, what chance do machines have? “There is just no easy solution,” she says. ”We’re going to keep seeing problems.”It’s worth noting, though, that AI isn’t completely hopeless. Advances in deep learning recently have greatly increased the speed and competency with which computers classify information in images, video, and text. Arun Gandhi, who works for NanoNets, a company that sells AI moderation tools to online businesses, says this shouldn’t be discounted. “A lot of the focus is on how traumatic or disturbing the job of content moderator is, which is absolutely fair,” Gandhi tells The Verge. “But it also takes away the fact that we are making progress with some of these problems.”Progress has been made, but it’s not clear how far it can goMachine learning systems need a large number of examples to learn what offending content looks like, explains Gandhi, which means those systems will improve in years to come as training datasets get bigger. He notes that some of the systems currently in place would look impossibly fast and accurate even a few years ago. “I’m confident, given the improvements we’ve made in the last five, six years, that at some point we’ll be able to completely automate moderation,” says Gandhi. Others would disagree, though, noting that AI systems have yet to master not only political and cultural context (which is changing month to month, as well as country to country) but also basic human concepts like sarcasm and irony. Throw in the various ways in which AI systems can be fooled by simple hacks, and a complete AI solution looks unlikely.Sandra Wachter, a lawyer and research fellow at the Oxford Internet Institute, says there are also legal reasons why humans will need to be kept in the loop for content moderation.“In Europe we have a data protection framework [GDPR] that allows people to contest certain decisions made by algorithms. It also says transparency in decision making is important [and] that you have a right to know what’s happening to your data,” Wachter tells The Verge. But algorithms can’t explain why they make certain decisions, she says, which makes these systems opaque and could lead to tech companies getting sued.RelatedThe secret lives of Facebook moderators in AmericaWachter says that complaints relating to GDPR have already been lodged, and that more cases are likely to follow. “When there are higher rights at stake, like the right to privacy and to freedom of speech, [...] it’s important that we have some sort of recourse,” she says. “When you have to make a judgement call that impacts other people’s freedom you have to have a human in the loop that can scrutinize the algorithm and explain these things.”“A challenge no other media system has ever had to face.”As Caplan notes, what tech companies can do — with their huge profit margins and duty of care to those they employee — is improve working conditions for human moderators. “At the very bare minimum we need to have better labor standards,” she says. As Casey Newton noted in his report, while companies like Facebook do make some effort to properly reward human moderators, giving them health benefits and above-average wages, it’s often outweighed by relentless drive to better accuracy and more decisions. Caplan says that pressure on tech companies to solve the problem of content automation could also be contributing to this state of affairs. “That’s when you get issues where workers are held to impossible standards of accuracy,” she says. The need to come up with a fix as soon as possible plays into Silicon Valley’s often-maligned “move fast and break things” attitude. And while this can be a great way to think when launching an app, it’s a terrible mindset for a company managing the subtleties of global speech.“And we’re saying now maybe we should use machines to deal with this problem,” says Caplan, “but that will lead to a whole new set of issues.” It’s also worth remembering that this is a new and unique problem. Never before have platforms as huge and information-dense as Facebook and YouTube existed. These are places where anyone, anywhere in the world, any time, can upload and share whatever content they like. Managing this vast and ever-changing semi-public realm is “a challenge no other media system has ever had to face,” says Caplan. What we do know is that the status quo is not working. The humans tasked with cleaning up the internet’s mess are miserable, and the humans creating that mess aren’t much better off. Artificial intelligence doesn’t have enough smarts to deal with the problem, and human intelligence is stretched coming up with solutions. Something’s gotta give. Comments0 Comments / 0 NewFeatured Videos From The VergeThe ups and downs of being a political TikToker
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEVitus “V” Spehar is the face behind Under the Desk News, a TikTok channel with 3.1 million subscribers. In our new series, Full Frame: Creators, The Verge's Becca Farsace spent the day with V to learn more about the trials and tribulations of having an online political presence in 2024.Most PopularMost PopularIt’s never been easier for the cops to break into your phoneThe FBI says it has ‘gained access’ to the Trump rally shooter’s phoneGoogle is reportedly planning its biggest startup acquisition everThe Google Pixel 9 just leaked againFBI is working to break into the phone of the Trump rally shooterVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From","No matter what companies say, AI is not going to solve the problem of content moderation online. It’s a promise we’ve heard many times before, particularly from Facebook CEO Mark Zuckerberg, but experts say the technology is just not there — and, in fact, may never be. 

Most social networks keep unwanted content off their platforms using a combination of automated filtering and human moderators. As The Verge revealed in a recent investigation, human moderators often work in highly stressful conditions. Employees have to click through hundreds of items of flagged content every day — everything from murder to sexual abuse — and then decide whether or not it violates a platform’s rules, often working on tightly-controlled schedules and without adequate training or support. 

When presented with the misery their platforms are creating (as well as other moderation-adjacent problems, like perceived bias) companies often say more technology is the solution. During his hearings in front of congress last year, for example, Zuckerberg cited artificial intelligence more than 30 times as the answer to this and other issues. 

“AI is Zuckerberg’s MacGuffin,” James Grimmelmann, a law professor at Cornell Tech, told The Washington Post at the time. “It won’t solve Facebook’s problems, but it will solve Zuckerberg’s: getting someone else to take responsibility.”

So what is AI doing for Facebook and other platforms right now, and why can’t it do more? 

The problem of automating human culture

Right now, automated systems using AI and machine learning are certainly doing quite a bit to help with moderation. They act as triage systems, for example, pushing suspect content to human moderators, and are able to weed out some unwanted stuff on their own. 

But the way they do so is relatively simple. Either by using visual recognition to identify a broad category of content (like “human nudity” or “guns”), which is prone to mistakes; or by matching content to an index of banned items, which requires humans to create said index in the first place. 

The latter approach is used to get rid of the most obvious infringing material; things like propaganda videos from terrorist organizations, child abuse material, and copyrighted content. In each case, content is identified by humans and “hashed,” meaning it’s turned into a unique string of numbers that’s quicker to process. The technology is broadly reliable, but it can still lead to problems. YouTube’s ContentID system, for example, has flagged uploads like white noise and bird song as copyright infringement in the past. 

[Image: AI systems are being trained to parse new sorts of images, like memes. https://cdn.vox-cdn.com/thumbor/6EzVAHsboiM2IipmlKXSeHlHOps=/0x0:2000x1125/2000x1125/filters:focal(1000x563:1001x564)/cdn.vox-cdn.com/uploads/chorus_asset/file/12895655/CodeBlog_penguinG5.png]

Things become much trickier when the content itself can’t be easily classified even by humans. This can include content that algorithms certainly recognize, but that has many shades of meaning (like nudity — does breast-feeding count?) or that are very context-dependent, like harassment, fake news, misinformation, and so on. None of these categories have simple definitions, and for each of them there are edge-cases with no objective status, examples where someone’s background, personal ethos, or simply their mood on any given day might make the difference between one definition and another. 

""We’re asking AI to understand the complexities of human culture""

The problem with trying to get machines to understand this sort of content, says Robyn Caplan, an affiliate researcher at the nonprofit Data & Society, is that it is essentially asking them to understand human culture — a phenomenon too fluid and subtle to be described in simple, machine-readable rules. 

“[This content] tends to involve context that is specific to the speaker,” Caplan tells The Verge. “That means things like power dynamics, race relations, political dynamics, economic dynamics.” Since these platforms operate globally, varying cultural norms need to be taken into account too, she says, as well as different legal regimes. 

One way to know whether content will be difficult to classify, says Eric Goldman, a professor of law at Santa Clara University, is to ask whether or not understanding it requires “extrinsic information” — that is, information outside the image, video, audio, or text. 

“For example, filters are not good at figuring out hate speech, parody, or news reporting of controversial events because so much of the determination depends on cultural context and other extrinsic information,” Goldman tells The Verge. “Similarly, filters aren’t good at determining when a content republication is fair use under US copyright law because the determination depends on extrinsic information such as market dynamics, the original source material, and the uploader’s other activities.”

How far can we push AI systems? 

But AI as a field is moving very swiftly. So will future algorithms be able to reliably classify this sort of content in the future? Goldman and Caplan are skeptical.

AI will get better at understanding context, says Goldman, but it’s not evident that AI will soon be able to do so better than a human. “AI will not replace [...] human reviewers for the foreseeable future,” he says.

Caplan agrees, and points out that as long as humans argue about how to classify this sort of material, what chance do machines have? “There is just no easy solution,” she says. ”We’re going to keep seeing problems.”

It’s worth noting, though, that AI isn’t completely hopeless. Advances in deep learning recently have greatly increased the speed and competency with which computers classify information in images, video, and text. Arun Gandhi, who works for NanoNets, a company that sells AI moderation tools to online businesses, says this shouldn’t be discounted. 

“A lot of the focus is on how traumatic or disturbing the job of content moderator is, which is absolutely fair,” Gandhi tells The Verge. “But it also takes away the fact that we are making progress with some of these problems.”

""Progress has been made, but it’s not clear how far it can go""

Machine learning systems need a large number of examples to learn what offending content looks like, explains Gandhi, which means those systems will improve in years to come as training datasets get bigger. He notes that some of the systems currently in place would look impossibly fast and accurate even a few years ago. “I’m confident, given the improvements we’ve made in the last five, six years, that at some point we’ll be able to completely automate moderation,” says Gandhi. 

Others would disagree, though, noting that AI systems have yet to master not only political and cultural context (which is changing month to month, as well as country to country) but also basic human concepts like sarcasm and irony. Throw in the various ways in which AI systems can be fooled by simple hacks, and a complete AI solution looks unlikely.

Sandra Wachter, a lawyer and research fellow at the Oxford Internet Institute, says there are also legal reasons why humans will need to be kept in the loop for content moderation.

“In Europe we have a data protection framework [GDPR] that allows people to contest certain decisions made by algorithms. It also says transparency in decision making is important [and] that you have a right to know what’s happening to your data,” Wachter tells The Verge. But algorithms can’t explain why they make certain decisions, she says, which makes these systems opaque and could lead to tech companies getting sued.

Wachter says that complaints relating to GDPR have already been lodged, and that more cases are likely to follow. “When there are higher rights at stake, like the right to privacy and to freedom of speech, [...] it’s important that we have some sort of recourse,” she says. “When you have to make a judgement call that impacts other people’s freedom you have to have a human in the loop that can scrutinize the algorithm and explain these things.”

“A challenge no other media system has ever had to face.”

As Caplan notes, what tech companies can do — with their huge profit margins and duty of care to those they employee — is improve working conditions for human moderators. “At the very bare minimum we need to have better labor standards,” she says. As Casey Newton noted in his report, while companies like Facebook do make some effort to properly reward human moderators, giving them health benefits and above-average wages, it’s often outweighed by relentless drive to better accuracy and more decisions. 

Caplan says that pressure on tech companies to solve the problem of content automation could also be contributing to this state of affairs. “That’s when you get issues where workers are held to impossible standards of accuracy,” she says. The need to come up with a fix as soon as possible plays into Silicon Valley’s often-maligned “move fast and break things” attitude. And while this can be a great way to think when launching an app, it’s a terrible mindset for a company managing the subtleties of global speech.

“And we’re saying now maybe we should use machines to deal with this problem,” says Caplan, “but that will lead to a whole new set of issues.” 

It’s also worth remembering that this is a new and unique problem. Never before have platforms as huge and information-dense as Facebook and YouTube existed. These are places where anyone, anywhere in the world, any time, can upload and share whatever content they like. Managing this vast and ever-changing semi-public realm is “a challenge no other media system has ever had to face,” says Caplan. 

What we do know is that the status quo is not working. The humans tasked with cleaning up the internet’s mess are miserable, and the humans creating that mess aren’t much better off. Artificial intelligence doesn’t have enough smarts to deal with the problem, and human intelligence is stretched coming up with solutions. Something’s gotta give. 

[Video: The Terror Queue: Google and YouTube moderators speak out]
",,https://volume-assets.voxmedia.com/production/4c88c2015bb5260507f41c82b9b3636a/VRG_ILLO_3808_Thumbnail__1_.jpg,,,,2019-12-16T16:26:38Z,https://volume-assets.voxmedia.com/production/6d7302280df048b4cfa937594615eadc/Google_Mods_17.mp4,,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvYXV0b21hdGlvbi1hbmQtYWktd2lsbC1kaXNydXB0LXRoZS1hbWVyaWNhbi1sYWJvci1mb3JjZS1oZXJlcy1ob3ctd2UtY2FuLXByb3RlY3Qtd29ya2Vycy_SAQA?oc=5,Automation and AI will disrupt the American labor force. Here's how we can protect workers | Brookings - Brookings Institution,2019-02-25,Brookings Institution,https://www.brookings.edu,"In order to protect workers, policymakers at all levels must step in with new investments to mitigate the impacts of automation.",N/A,"In order to protect workers, policymakers at all levels must step in with new investments to mitigate the impacts of automation.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

 Back to Janesville 









                        Back to Janesville 
",,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/automation-and-ai-will-disrupt-the-american-labor-force-heres-how-we-can-protect-workers/', 'url': 'https://www.brookings.edu/articles/automation-and-ai-will-disrupt-the-american-labor-force-heres-how-we-can-protect-workers/', 'name': 'Automation and AI will disrupt the American labor force. Here’s how we can protect workers | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/automation-and-ai-will-disrupt-the-american-labor-force-heres-how-we-can-protect-workers/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/automation-and-ai-will-disrupt-the-american-labor-force-heres-how-we-can-protect-workers/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2019/02/20190225_metro_Maxim-Muro-Automation_disruption.jpg?quality=75', 'datePublished': '2019-02-25T21:55:26+00:00', 'dateModified': '2022-03-09T04:14:27+00:00', 'description': 'In order to protect workers, policymakers at all levels must step in with new investments to mitigate the impacts of automation.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/automation-and-ai-will-disrupt-the-american-labor-force-heres-how-we-can-protect-workers/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/automation-and-ai-will-disrupt-the-american-labor-force-heres-how-we-can-protect-workers/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/automation-and-ai-will-disrupt-the-american-labor-force-heres-how-we-can-protect-workers/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2019/02/20190225_metro_Maxim-Muro-Automation_disruption.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2019/02/20190225_metro_Maxim-Muro-Automation_disruption.jpg?quality=75', 'width': 3154, 'height': 2106, 'caption': 'Automation'}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/automation-and-ai-will-disrupt-the-american-labor-force-heres-how-we-can-protect-workers/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Automation and AI will disrupt the American labor force. Here’s how we can protect workers'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vc3BsYXNoMjQ3LmNvbS9tYXJpdGltZS1hdXRvbWF0aW9uLXdpbGwtbm90LXNwYXJlLXNlYWZhcmVycy_SAQA?oc=5,Maritime automation will not spare seafarers - Splash247 - Splash 247,2019-02-25,Splash 247,https://splash247.com,"Humans have a tenuous relationship with automation. On balance, we love it. It has made our lives easier. Freed up time for leisure. Freed up time for thinking … about more automation. Progressively,","Editor's Picks,Seafarers","Humans have a tenuous relationship with automation. On balance, we love it. It has made our lives easier. Freed up time for leisure. Freed up time for thinking … about more automation. Progressively, we have made automation cleverer. First, we armed it with simple decision trees, then with supervised reasoning, until we arrived at self-learning …",N/A,http://schema.org,NewsArticle,https://splash247.com/maritime-automation-will-not-spare-seafarers/,"{'@type': 'ImageObject', 'url': 'https://splash247.com/wp-content/uploads/2015/02/Bridge-view-navigation-ecdis-e1600067913350.jpg', 'width': 1200, 'height': 497}","{'@type': 'Person', 'name': 'Kris Kosmala', 'url': 'https://splash247.com/author/krisk/'}","{'@id': '#Publisher', '@type': 'Organization', 'name': 'Splash247', 'logo': {'@type': 'ImageObject', 'url': 'https://splash247.com/wp-content/uploads/2020/06/Splash-Logos_Blue-high-res-RETINA.png'}, 'sameAs': ['https://www.facebook.com/Splash247', 'http://www.twitter.com/splash_247', 'https://www.linkedin.com/company/splash247', 'https://www.youtube.com/channel/UC5XR182FIe9fUuD6lvD1C1g', 'https://apps.apple.com/au/app/splash-maritime-offshore-news/id1671187581', 'https://play.google.com/store/apps/details?id=com.Splash247.android&hl=en&gl=US']}",Maritime automation will not spare seafarers,2019-02-25T14:33:23+08:00,2020-06-20T11:33:46+08:00,"Contributions,Operations,Tech",Maritime automation will not spare seafarers,,,N/A,N/A,"


ContributionsOperationsTech

			Maritime automation will not spare seafarers		




Kris KosmalaFebruary 25, 20192 7 4 minutes read  



 Kongsberg
						


Humans have a tenuous relationship with automation. On balance, we love it. It has made our lives easier. Freed up time for leisure. Freed up time for thinking … about more automation. Progressively, we have made automation cleverer. First, we armed it with simple decision trees, then with supervised reasoning, until we arrived at self-learning mathematical algorithms. Along the way, automation equipped with artificial intelligence allowed us to eliminate human efforts all around.
To put it in perspective, we started with replacing elevator operators with buttons and self-locking doors. We arrived at autonomous cars making better driving decisions than humans themselves. In the process, we also depopulated, among others, factory floors, bank branches, public services offices, and airport service areas.
Are you thinking that a more specialised human workforce is going to be immune? An artificial intelligence program developed in China combs through test results, health records and even handwritten notes, to consistently match or outperform primary care pediatricians. Welcome to the “depopulated” doctor’s office.
Industrial manufacturing led the way, deploying robotics and artificial intelligence on the factory floors to automate labour-intensive, repetitive processes and task processes, then moved on to back-office processes such as purchasing, invoicing, collections, and customer service. Predictive analytics were put to work to improve demand forecasting, increase asset utilisation, and more economically maintain diverse pieces of equipment. In all cases, AI-based technology showed itself to learn and improve in a way similar to humans, but with virtually unlimited capacity for processing and retaining data.
Transportation is not immune from the automation trend and displacement of humans with some form of automation, often augmented by artificial intelligence. Back offices of transportation companies came first. Contract optimisation took out contract administrators, pricing optimisation reduced the number of pricing analysts, allocation optimisation reduced the need for tradelane analysts, and talking bots displaced humans in customer service centers. Recent news of OpenAI writing convincing news stories (watch out, Splash!) and works of fiction is only a step away from digitising it into speech, thus opening the way to displace humans in already downscaled sales offices.
The front lines of transportation have not been immune from those changes, although here the causes were different. Trucking has been hit most severely, as numbers of retiring drivers far exceed numbers of new candidates to take their places. Added weight of regulations affecting drivers’ employment, like that seen in countries of European Union pushed many drivers back to their home countries, unintentionally triggering a driver supply crisis earlier than predicted.
Train drivers and train operations staff will follow. Rail operators are watching full train automation spearheaded by Rio Tinto, a mining company in Australia. Using driverless trains, robotic operators, cameras, lasers, and tracking sensors, the company is able to manage their mine-to-port supply chain remotely, while improving the overall safety of their rail operations. Their competitor, BHP Billiton is on the cusp of designing and enabling a fully automated mine. With humans taken out of the equation, the mine can be designed more efficiently, as human safety procedures are removed, and dangerous operations like blasting can continue without need to wait, while humans are being removed from the dangerzones.
Maritime not immune
However you look at automation, its introduction has always led to less need for human workers. Companies jumping on the full automation bandwagon claim that their displaced employees can be re-trained and reassigned to more attractive jobs overseeing the new technology. So far, not one of those companies managed to prove that point. They always end up with less employees in the end.
Maritime transportation is not immune from all those automation trends. On the terminal quays, gangs of 25 workers have been downsized to 8-10. In terminals where gang sizes are still about 15, you will see half of the gang workers milling about. On the ships, technology is reducing human activities from the engine room all the way up to the bridge. Yes, things are still breaking down and they call for a safe pair of human hands and human brainpower, but the overall need for the sizes of crews of old is diminishing. Larger ships don’t require larger crews and modern ships replacing older ships size for size allow for smaller crews. Ignore the hype of fully autonomous vessels cutting the need for human crews to zero. That’s a fantasy. The reality of the staffed ships of today tells a sufficiently worrying story for the future of human employment.
Thus, it is surprising to find a report taking a contrarian position. Researchers at the World Maritime University came to conclusions that are hard to believe. They reference studies showing that jobs lost due to automation were replaced by more jobs created in areas of increasing demand for the products manufactured by automated production lines, or to translate, for every one job lost on the production line, companies hired more than one person in sales and marketing.
They then neatly extrapolated this research into the world of maritime, or specifically into the seafaring workforce. Under all tested scenarios, their simulations showed only growth in the demand for seafarers between 2020 and 2040. Inexplicably, some of their scenarios showed that seafarers’ numbers will almost double from the approximately 1.6m employed today. These simulations didn’t concern themselves with any other factors other than automation. Believing this would require automation technology progress to stop at current levels and produce no new employment-reducing innovations for the next 20 years. Arrested human ingenuity does not feature in my thinking, does it feature in yours?
I am interested in hearing your thoughts on the subject of automation replacing maritime jobs. Can the maritime industry defy the trend of automation reducing need for human workers?





 TagsEditor's Picks Seafarers







Kris KosmalaFebruary 25, 20192 7 4 minutes read 







 Facebook


 X


 LinkedIn


 Tumblr


 Pinterest


 Reddit


 VKontakte


 Messenger


 Messenger


 WhatsApp


 Telegram


 Share via Email


 Print
 

","Humans have a tenuous relationship with automation. On balance, we love it. It has made our lives easier. Freed up time for leisure. Freed up time for thinking … about more automation. Progressively, we have made automation cleverer. First, we armed it with simple decision trees, then with supervised reasoning, until we arrived at self-learning mathematical algorithms. Along the way, automation equipped with artificial intelligence allowed us to eliminate human efforts all around.

To put it in perspective, we started with replacing elevator operators with buttons and self-locking doors. We arrived at autonomous cars making better driving decisions than humans themselves. In the process, we also depopulated, among others, factory floors, bank branches, public services offices, and airport service areas.

Are you thinking that a more specialised human workforce is going to be immune? An artificial intelligence program developed in China combs through test results, health records and even handwritten notes, to consistently match or outperform primary care pediatricians. Welcome to the “depopulated” doctor’s office.

Industrial manufacturing led the way, deploying robotics and artificial intelligence on the factory floors to automate labour-intensive, repetitive processes and task processes, then moved on to back-office processes such as purchasing, invoicing, collections, and customer service. Predictive analytics were put to work to improve demand forecasting, increase asset utilisation, and more economically maintain diverse pieces of equipment. In all cases, AI-based technology showed itself to learn and improve in a way similar to humans, but with virtually unlimited capacity for processing and retaining data.

Transportation is not immune from the automation trend and displacement of humans with some form of automation, often augmented by artificial intelligence. Back offices of transportation companies came first. Contract optimisation took out contract administrators, pricing optimisation reduced the number of pricing analysts, allocation optimisation reduced the need for tradelane analysts, and talking bots displaced humans in customer service centers. Recent news of OpenAI writing convincing news stories (watch out, Splash!) and works of fiction is only a step away from digitising it into speech, thus opening the way to displace humans in already downscaled sales offices.

The front lines of transportation have not been immune from those changes, although here the causes were different. Trucking has been hit most severely, as numbers of retiring drivers far exceed numbers of new candidates to take their places. Added weight of regulations affecting drivers’ employment, like that seen in countries of European Union pushed many drivers back to their home countries, unintentionally triggering a driver supply crisis earlier than predicted.

Train drivers and train operations staff will follow. Rail operators are watching full train automation spearheaded by Rio Tinto, a mining company in Australia. Using driverless trains, robotic operators, cameras, lasers, and tracking sensors, the company is able to manage their mine-to-port supply chain remotely, while improving the overall safety of their rail operations. Their competitor, BHP Billiton is on the cusp of designing and enabling a fully automated mine. With humans taken out of the equation, the mine can be designed more efficiently, as human safety procedures are removed, and dangerous operations like blasting can continue without need to wait, while humans are being removed from the dangerzones.

Maritime not immune

However you look at automation, its introduction has always led to less need for human workers. Companies jumping on the full automation bandwagon claim that their displaced employees can be re-trained and reassigned to more attractive jobs overseeing the new technology. So far, not one of those companies managed to prove that point. They always end up with less employees in the end.

Maritime transportation is not immune from all those automation trends. On the terminal quays, gangs of 25 workers have been downsized to 8-10. In terminals where gang sizes are still about 15, you will see half of the gang workers milling about. On the ships, technology is reducing human activities from the engine room all the way up to the bridge. Yes, things are still breaking down and they call for a safe pair of human hands and human brainpower, but the overall need for the sizes of crews of old is diminishing. Larger ships don’t require larger crews and modern ships replacing older ships size for size allow for smaller crews. Ignore the hype of fully autonomous vessels cutting the need for human crews to zero. That’s a fantasy. The reality of the staffed ships of today tells a sufficiently worrying story for the future of human employment.

Thus, it is surprising to find a report taking a contrarian position. Researchers at the World Maritime University came to conclusions that are hard to believe. They reference studies showing that jobs lost due to automation were replaced by more jobs created in areas of increasing demand for the products manufactured by automated production lines, or to translate, for every one job lost on the production line, companies hired more than one person in sales and marketing.

They then neatly extrapolated this research into the world of maritime, or specifically into the seafaring workforce. Under all tested scenarios, their simulations showed only growth in the demand for seafarers between 2020 and 2040. Inexplicably, some of their scenarios showed that seafarers’ numbers will almost double from the approximately 1.6m employed today. These simulations didn’t concern themselves with any other factors other than automation. Believing this would require automation technology progress to stop at current levels and produce no new employment-reducing innovations for the next 20 years. Arrested human ingenuity does not feature in my thinking, does it feature in yours?

I am interested in hearing your thoughts on the subject of automation replacing maritime jobs. Can the maritime industry defy the trend of automation reducing need for human workers?",,,,,"{'@type': 'WebPage', '@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/'}",,,"[{'@type': 'Article', '@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/#article', 'isPartOf': {'@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/'}, 'author': {'name': 'Kris Kosmala', '@id': 'https://splash247.com/#/schema/person/9e95aa4f9aae74351ec453a898050427'}, 'headline': 'Maritime automation will not spare seafarers', 'datePublished': '2019-02-25T06:33:23+00:00', 'dateModified': '2020-06-20T11:33:46+00:00', 'mainEntityOfPage': {'@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/'}, 'wordCount': 953, 'commentCount': 2, 'publisher': {'@id': 'https://splash247.com/#organization'}, 'image': {'@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/#primaryimage'}, 'thumbnailUrl': 'https://splash247.com/wp-content/uploads/2015/02/Bridge-view-navigation-ecdis-e1600067913350.jpg', 'keywords': [""Editor's Picks"", 'Seafarers'], 'articleSection': ['Contributions', 'Operations', 'Tech'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://splash247.com/maritime-automation-will-not-spare-seafarers/#respond']}]}, {'@type': 'WebPage', '@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/', 'url': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/', 'name': 'Maritime automation will not spare seafarers - Splash247', 'isPartOf': {'@id': 'https://splash247.com/#website'}, 'primaryImageOfPage': {'@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/#primaryimage'}, 'image': {'@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/#primaryimage'}, 'thumbnailUrl': 'https://splash247.com/wp-content/uploads/2015/02/Bridge-view-navigation-ecdis-e1600067913350.jpg', 'datePublished': '2019-02-25T06:33:23+00:00', 'dateModified': '2020-06-20T11:33:46+00:00', 'breadcrumb': {'@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://splash247.com/maritime-automation-will-not-spare-seafarers/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/#primaryimage', 'url': 'https://splash247.com/wp-content/uploads/2015/02/Bridge-view-navigation-ecdis-e1600067913350.jpg', 'contentUrl': 'https://splash247.com/wp-content/uploads/2015/02/Bridge-view-navigation-ecdis-e1600067913350.jpg', 'width': 756, 'height': 497, 'caption': 'Kongsberg'}, {'@type': 'BreadcrumbList', '@id': 'https://splash247.com/maritime-automation-will-not-spare-seafarers/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://splash247.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Maritime automation will not spare seafarers'}]}, {'@type': 'WebSite', '@id': 'https://splash247.com/#website', 'url': 'https://splash247.com/', 'name': 'Splash247', 'description': 'Global Maritime and Shipping News', 'publisher': {'@id': 'https://splash247.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://splash247.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://splash247.com/#organization', 'name': 'Splash 24/7 - Maritime and Offshore News', 'url': 'https://splash247.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://splash247.com/#/schema/logo/image/', 'url': 'https://splash247.com/wp-content/uploads/2015/01/Splash-247-Logo-square.png', 'contentUrl': 'https://splash247.com/wp-content/uploads/2015/01/Splash-247-Logo-square.png', 'width': 184, 'height': 184, 'caption': 'Splash 24/7 - Maritime and Offshore News'}, 'image': {'@id': 'https://splash247.com/#/schema/logo/image/'}, 'sameAs': ['http://www.facebook.com/Splash247', 'https://x.com/splash_247', 'http://www.linkedin.com/groups/Splash-Maritime-Offshore-News-4559472']}, {'@type': 'Person', '@id': 'https://splash247.com/#/schema/person/9e95aa4f9aae74351ec453a898050427', 'name': 'Kris Kosmala', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://splash247.com/#/schema/person/image/', 'url': 'https://splash247.com/wp-content/uploads/2015/01/Kris-Kosmala-96x96.png', 'contentUrl': 'https://splash247.com/wp-content/uploads/2015/01/Kris-Kosmala-96x96.png', 'caption': 'Kris Kosmala'}, 'description': 'Kris Kosmala is a partner at Click &amp; Connect where he advises companies trying to leverage digitalization to change their business competitive position.', 'sameAs': ['https://www.linkedin.com/in/kriskosmala', 'https://x.com/http://www.twitter.com/sureIQ'], 'url': 'https://splash247.com/author/krisk/'}]",2019-02-25T14:33:23+08:00,2019,{'@id': '#Publisher'},{'@id': '#Publisher'},,,,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LmFydGRlcGVuZGVuY2UuY29tL2FydGljbGVzL21hcmlvLWtsaW5nZW1hbm4taW5zdHJ1bWVudHMtb2YtY3JlYXRpb24tb3ItY2FuLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXJlcGxhY2UtaHVtYW4v0gEA?oc=5,Mario Klingemann: Instruments of Creation or Can Artificial Intelligence Replace Human? - ArtDependence,2019-02-26,ArtDependence,https://www.artdependence.com,"Mario Klingemann (Munich, Germany) is an artist who uses algorithms and artificial intelligence to create and investigate systems. He is particularly interested in human perception of art and creativity, researching methods in which machines can augment or emulate these processes.",N/A,"Mario Klingemann (Munich, Germany) is an artist who uses algorithms and artificial intelligence to create and investigate systems. He is particularly interested in human perception of art and creativity, researching methods in which machines can augment or emulate these processes.","Mario Klingemann (Munich, Germany) is an artist who uses algorithms and artificial intelligence to create and investigate systems. He is particularly interested in human perception of art and creativity, researching methods in which machines can augment or emulate these processes.",,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvY29nbml0aXZld29ybGQvMjAxOS8wMi8yNS90cm91YmxpbmctdHJlbmRzLXRvd2FyZHMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZ292ZXJuYW5jZS_SAQA?oc=5,Troubling Trends Towards Artificial Intelligence Governance - Forbes,2019-02-25,Forbes,https://www.forbes.com,"Even if we define ethical and privacy guidelines -- because the security risks of AI are mostly unknown--unless we make the unknowns known, and understand their origin, drafting effective AI regulations is impossible.",,"Even if we define ethical and privacy guidelines -- because the security risks of AI are mostly unknown--unless we make the unknowns known, and understand their origin, drafting effective AI regulations is impossible.","Even if we define ethical and privacy guidelines -- because the security risks of AI are mostly unknown--unless we make the unknowns known, and understand their origin, drafting effective AI regulations is impossible.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/cognitiveworld/2019/02/25/troubling-trends-towards-artificial-intelligence-governance/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/cognitiveworld/files/2019/02/RobotWithLawScales-F-1200x800.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Jayshree Pandya', 'url': 'https://www.forbes.com/sites/cognitiveworld/people/jayshreepandya/', 'description': 'Jayshree Pandya (née Bhatt), Ph.D., the founder and chief executive officer of Risk Group LLC is working passionately to define a new security centric operating system for humanity. Her efforts towards building a strategic security risk intelligence platform are to equip the global strategic security community with the tools and culture to collectively imagine the strategic security risks to our future and to define and design a new security centric operating system for the future of humanity.', 'sameAs': ['https://www.linkedin.com/in/drjayshreepandya/', 'https://www.riskgroupllc.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Troubling Trends Towards Artificial Intelligence Governance,2019-02-25T18:53:00-05:00,2019-04-17T13:29:40-04:00,AI & Big Data,Troubling Trends Towards Artificial Intelligence Governance,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI & Big Data,N/A,"More From ForbesJun 17, 2024,04:42am EDTProtecting Human Rights In The Age Of Intelligent MachinesApr 24, 2024,05:00am EDTWhat AI Can Tell Us About OzempicFeb 22, 2024,03:42am ESTUnlocking The Power Of Social Data For Clinical Trial DesignJan 25, 2024,04:55am ESTCPG Product Innovation Should Be A Science, Not An ArtAug 7, 2023,08:57am EDTListening Before We Talk: Why Social Data Is Key To Successful NPD In 2023Mar 28, 2023,10:07am EDTHow Technology Is Empowering CPGs To Do More With LessFeb 21, 2023,05:24am ESTAre Humans And Collaboration Still At The Heart Of Innovation?Edit StoryForbesInnovationAITroubling Trends Towards Artificial Intelligence GovernanceJayshree PandyaFormer ContributorCOGNITIVE WORLDContributor GroupOpinions expressed by Forbes Contributors are their own.Click to save this article.You'll be asked to sign into your Forbes account.Got itFeb 25, 2019,06:53pm ESTUpdated Apr 17, 2019, 01:29pm EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin








Introduction

This is an age of artificial intelligence (AI) driven automation and autonomous machines. The increasing ubiquity and rapidly expanding the potential of self-improving, self-replicating, autonomous intelligent machines has spurred massive automation driven transformation of human ecosystems in cyberspace, geospace and space (CGS). As seen across nations, there is already a growing trend towards increasingly entrusting complex decision processes to these rapidly evolving AI systems. From granting parole to diagnosing diseases, college admissions to job interviews, managing trades to granting credits, autonomous vehicles to autonomous weapons, the rapidly evolving AI systems are increasingly being adopted by individuals and entities across nations: its government, industries, organizations, and academia (NGIOA).

Individually and collectively, the promise and perils of these evolving AI systems are raising serious concerns for the accuracy, fairness, transparency, trust, ethics, privacy and security of the future of humanity -- prompting calls for regulation of artificial intelligence design, development, and deployment.
While the fear of any disruptive technology, technological transformation, and its associated changes giving rise to calls for the governments to regulate new technologies in a responsible manner are nothing new, regulating a technology like artificial intelligence is an entirely different kind of challenge. This is because while AI can be transparent, transformative, democratized,  and easily distributed, it also touches every sector of the global economy and can even put the security of the entire future of humanity at risk. There is no doubt that artificial intelligence has the potential to be misused or that it can behave in unpredictable and harmful ways towards humanity—so much so that the entire human civilization could be at risk.
PROMOTED
While there has been some -- much-needed -- focus on the role of ethics, privacy and morals in this debate, security, which is equally significant, is often completely ignored. That brings us to an important question: Are ethics and privacy guidelines enough to regulate AI? We need to not only make AI transparent, accountable and fair, but we need to also create a focus on its security risks.

Security Risks
As seen across nations, security risks are largely ignored in the AI regulation debate. It needs to be understood that any AI system: be it a robot, a program running on a single computer, a program running on networked computers, or any other set of components that hosts an AI, carries with it security risks.
So, what are these security risks and vulnerabilities? It starts with the initial design and development. If the initial design and development allow or encourages the AI to alter its objectives based on its exposure and learning, those alterations will likely occur in accordance with the dictates of the initial design. Now, the AI will one day become self-improving and will also start changing its own code, and, at some point, it may change the hardware as well and could self-replicate. So, when we evaluate all these possible scenarios, at some point, humans will likely lose control of the code or any instructions that were embedded in the code. That brings us to an important question: How will we regulate AI when humans will likely lose control of its development and deployment cycle?









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



As we evaluate the security risks originating from disruptive and dangerous technology over the years, each technology required substantial infrastructure investments. That made the regulatory process fairly simple and easy: just follow the large amounts of investments to know who is building what. However, the information age and technologies like artificial intelligence have fundamentally shaken the foundation of regulatory principles and control. This is mainly because determining the who, where and what of artificial intelligence security risks is impossible because anyone from anywhere with a reasonably current personal computer (or even a smartphone or any smart device) and an internet connection can now contribute to the development of artificial intelligence projects/initiatives. Moreover, the same security vulnerabilities of cyberspace also translate to any AI system as both the software and hardware are vulnerable to security breaches.
Moreover, the sheer number of individuals and entities across nations that may participate in the design, development, and deployment of any AI system’s components will make it difficult to identify the responsibility and accountability of the entire system if anything goes wrong.
Now, with many of the artificial intelligence development projects going open source and with the rise in the number of open-source machine learning libraries, anyone from anywhere can make any modification to such libraries or to the code—and there is just no way to know who made those changes and what would be its security impact in a timely manner. So, the question is when individuals and entities participating in any AI collaborative project from anywhere in the world, how can security risks be identified and proactively managed from a regulatory perspective? 
There is also a common belief that in order to develop AI systems that have the power to cause existential threats to humanity, it would require greater computational power and will be easy to track. However, with the rise in the development of neuromorphic chips, computational power is soon going to be a non-issue—taking away this tracking capability of large use of computing power.
There is also another issue of who is evaluating security risks? Because irrespective of the stage of design, development or deployment of artificial intelligence, do the researchers/designers/developers have the necessary expertise to make broad security risk assessments? That brings us to an important question: What kind of expertise is required to evaluate the security risks of algorithms or any AI systems? Would someone qualify to evaluate these security risks purely based on their background in computer science, cyber-security, or hardware—or we need someone with an entirely different kind of skill set?
Acknowledging this emerging reality, Risk Group initiated the much-needed discussion on Regulating Artificial Intelligence with Dr. Subhajit Basu on Risk Roundup.
Disclosure: Risk Group LLC is my company
 
 




Risk Group discusses Regulating Artificial Intelligence with Dr. Subhajit Basu, an Associate Professor in Information Technology Law (Cyberlaw), Chair: BILETA, Editor: IRLCT, School of Law, the University of Leeds based in the UK.
Complex Challenges in Regulating Artificial Intelligence
Even if we agree on what intelligence is, what artificial intelligence is, or what consciousness is, it seems that from a regulatory standpoint, some of the most problematic features of regulating AI are:

Lack of nomenclature and identity for algorithms
The security risks emerging from the AI code itself
The nature of the self-improvement of the software and hardware
And the interconnected and integrated security risks emerging due to the democratization and decentralization of AI research and development (R&D)

So, to begin with, how can we come up with an identity and nomenclature system for algorithms? How can nations effectively regulate the democratized development of AI? Moreover, how can nations effectively regulate AI development when the development work can be globally distributed, and nations cannot agree on the global standards for regulation?
This is very important because the individuals working on any single component of an AI system might be located in different nations. Moreover, most of the AI development is happening in private entities, and the entire cycle of those AI development systems are proprietary property and kept secret.
Evaluating the Regulatory Frameworks
Regulatory frameworks are traditionally made possible by legal scholarship. It seems that the traditional methods of regulation — such as research and development oversight and product licensing -- seem particularly unsuitable to manage the security risks associated with artificial intelligence and intelligent autonomous machines.
As seen across nations, there are many AI guidelines emerging. There is also a framework proposal emerging for AI regulation that is based on differential tort liability. And, the centerpiece of the proposed regulatory framework seems to be an AI certification process, along with a proposal for manufacturers and operators of AI systems to get certified (where certified AI systems will be able to enjoy limited tort liability while those of uncertified AI systems would face strict liability). It is important to evaluate this proposed regulatory approach of legal liability from a security perspective. If an AI system harms a person, who will be held liable?
Traditionally for most technologies, liability falls on the manufacturer, but with AI development, how will it be known who has designed the algorithm? It could be anyone from any part of the world. And as we see algorithms have no name or identity. Moreover, when intelligent machines become autonomous, it will further make it much more complex for all the stakeholders to be able to foresee emerging security risks proactively. That brings us to an important question: under all these complex scenarios, will the tort liability focus for regulating artificial intelligence ever work?
Tort-based liability systems will be of no use when, for example, any autonomous system decides that humans are now enemies. Whether systems are certified or not, it will make no difference in whether we are managing the security risks emerging from them in a timely manner. When the future of humanity is at risk, what difference will it make in whether there is a way to get compensation for humans. And who will give compensation, autonomous systems? Machines?
What Next?
Perhaps, it is time to begin a discussion on why the security risks emerging from technologies like artificial intelligence need to be at the heart of any regulation or governance framework that is being defined and developed. Because, unless we identify the security risks and understand their origin, it is next to impossible to regulate technologies like AI in a proactive and responsible manner.
Does this mean we are doomed, and nothing can be done? Of course not! Let us put our collective intelligence to begin a broader conversation across nations on how to proactively identify the security risks emerging from artificial intelligence systems and how to regulate them effectively for the future of humanity. Because while we may not know everything, each one of us knows something, and together we can come up with an effective way to regulate AI. Time is now to give identity to each algorithm emerging from across nations! Time is now to define a security risk governance framework for artificial intelligence!
About the Author
Jayshree Pandya (née Bhatt), Founder and CEO of Risk Group LLC, is a scientist, a visionary, an expert in disruptive technologies and a globally recognized thought leader and influencer. She is actively engaged in driving the global discussions on existing and emerging technologies, technology transformation and nation preparedness.
Her work focuses on the impact of existing and emerging technological innovations on nations, national preparedness and the survival, security, and sustainability of humanity. Her research in this context evaluates the evolution of intelligence in all forms, researches strategic security risks emerging from disruptive innovations, reviews the diminishing capacities of the risk management infrastructure, points out the changing role of decision makers, defines dynamic decision-making approaches with machine intelligence, integrates all components of a nation: governments, industries, organizations and academia (NGIOA) and defines strategic security risks so that nations can improve the state of risk-resilience across cyberspace, geospace and space (CGS). As nations make a move from centralization towards decentralization, the re-defining and re-designing of systems at all levels evaluated in Dr. Pandya’s comprehensive research scholarship includes artificial intelligence, machine learning, deep learning, internet of things, blockchain, cryptocurrency, quantum computing, virtual reality, synthetic biology, big data analytics, drones, nanosatellites, biotechnology, nanotechnology, gene editing and much more. Her research is much needed for the survival and security of humanity today and in the coming tomorrow.
NEVER MISS ANY OF JAYSHREE’S POST
Simply join here for a weekly update from JayshreeFollow me on LinkedIn. Check out my website. Jayshree PandyaJayshree Pandya (née Bhatt), Ph.D., the founder and chief executive officer of Risk Group LLC is working passionately to define a new security centric... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vbmV3cy5zdGFuZm9yZC5lZHUvc3Rvcmllcy8yMDE5LzAyL2FuY2llbnQtbXl0aHMtcmV2ZWFsLWVhcmx5LWZhbnRhc2llcy1hcnRpZmljaWFsLWxpZmXSAQA?oc=5,Ancient myths reveal early fantasies about artificial life - Stanford University News,2019-02-28,Stanford University News,https://news.stanford.edu,N/A,N/A,"In her latest research, Stanford classics scholar Adrienne Mayor highlights ancient Greek myths that contained ideas about creating artificial, lifelike creatures.",N/A,,,,,,,,,,,,,,N/A,N/A,"



Thousands of years before machine learning and self-driving cars became reality, the tales of giant bronze robot Talos, artificial woman Pandora and their creator god, Hephaestus, filled the imaginations of people in ancient Greece.


A Greek vase painting, dating to about 450 B.C., depicts the death of Talos. Stanford’s Adrienne Mayor examined the myth of Talos and others in her latest research. (Image credit: Wikimedia Commons / Forzaruvo94)
Historians usually trace the idea of automata to the Middle Ages, when the first self-moving devices were invented, but the concept of artificial, lifelike creatures dates to the myths and legends from at least about 2,700 years ago, said Adrienne Mayor, a research scholar in the Department of Classics in the School of Humanities and Sciences. These ancient myths are the subject of Mayor’s latest book, Gods and Robots: Myths, Machines, and Ancient Dreams of Technology.“Our ability to imagine artificial intelligence goes back to the ancient times,” said Mayor, who is also a 2018-19 fellow at the Center for Advanced Study in the Behavioral Sciences at Stanford. “Long before technological advances made self-moving devices possible, ideas about creating artificial life and robots were explored in ancient myths.”Mayor, a historian of science, said that the earliest themes of artificial intelligence, robots and self-moving objects appear in the work of ancient Greek poets Hesiod and Homer, who were alive somewhere between 750 and 650 B.C.The story of Talos, first mentioned around 700 B.C. by Hesiod, offers one of the earliest conceptions of a robot, Mayor said.The myth describes Talos as a giant bronze man built by Hephaestus, the Greek god of invention and blacksmithing. Talos was commissioned by Zeus, the king of Greek gods, to protect the island of Crete from invaders. He marched around the island three times every day and hurled boulders at approaching enemy ships.
Adrienne Mayor (Image credit: Josiah Ober)
At his core, the giant had a tube running from his head to one of his feet that carried a mysterious life source of the gods the Greeks called ichor. Another ancient text, Argonautica, which dates to the third century B.C., describes how sorceress Medea defeated Talos by removing a bolt at his ankle and letting the ichor fluid flow out, Mayor said.The myth of Pandora, first described in Hesiod’s Theogony, is another example of a mythical artificial being, Mayor said. Although much later versions of the story portray Pandora as an innocent woman who unknowingly opened a box of evil, Mayor said Hesiod’s original described Pandora as an artificial, evil woman built by Hephaestus and sent to Earth on the orders of Zeus to punish humans for discovering fire.“It could be argued that Pandora was a kind of AI agent,” Mayor said. “Her only mission was to infiltrate the human world and release her jar of miseries.”In addition to creating Talos and Pandora, mythical Hephaestus made other self-moving objects, including a set of automated servants, who looked like women but were made of gold, Mayor said. According to Homer’s recounting of the myth, Hephaestus gave these artificial women the gods’ knowledge. Mayor argues that they could be considered an ancient mythical version of artificial intelligence.The ancient myths that Mayor examined in her research grapple with the moral implications of Hephaestus’ creations.“Not one of those myths has a good ending once the artificial beings are sent to Earth,” Mayor said. “It’s almost as if the myths say that it’s great to have these artificial things up in heaven used by the gods. But once they interact with humans, we get chaos and destruction.”Mayor said the myths underscore humanity’s fascination with creating artificial life.“People have an impulse to imagine things that aren’t possible yet,” Mayor said. “There is a timeless link between imagination and science.”


Media Contacts Alex Shashkevich, Stanford News Service: (650) 497-4419, ashashkevich@stanford.edu



AuthorAlex ShashkevichCampus unitStanford School of Humanities & SciencesRelated topicsArts & HumanitiesScience & EngineeringCommunity & CultureArtificial IntelligenceShare this storyCopy link



Subscribe to Stanford ReportNews, insights and events delivered to your inbox each weekday morning.Sign upStories for you80,000-plus characters, one keyboardAsian American research center launchesLectures explore data’s place in the humanitiesPopular storiesMichele Rasmussen appointed vice provost for student affairsHow technology is reinventing K-12 educationWhat to know about Gen ZHow the apparel industry could refashion itselfA new approach to the growing problem of water affordability



Read nextView all Read nextArts & HumanitiesStanford’s winter quarter guest artistsNewsArts & Humanities‘Residual Governance’ dives into South Africa’s mining industryResearchArts & HumanitiesMeet Stanford’s 2023 fall quarter guest artistsNewsArts & Humanities80,000-plus characters, one keyboardBookArts & HumanitiesAsian American research center launchesNewsArts & HumanitiesLectures explore data’s place in the humanitiesAnalysis & InsightsArts & HumanitiesStanford’s winter quarter guest artistsNewsArts & Humanities‘Residual Governance’ dives into South Africa’s mining industryResearchArts & HumanitiesMeet Stanford’s 2023 fall quarter guest artistsNewsArts & Humanities80,000-plus characters, one keyboardBookArts & HumanitiesAsian American research center launchesNewsArts & HumanitiesLectures explore data’s place in the humanitiesAnalysis & InsightsSlide 1Slide 2Slide 3Slide 4Slide 5Slide 6PreviousNext


",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy5qdGEub3JnLzIwMTkvMDIvMjUvaXNyYWVsL2lzcmFlbGktaW5zdGl0dXRlLWludmVzdHMtMTAwLW1pbGxpb24taW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdG8tc29sdmUtcmVhbC13b3JsZC1wcm9ibGVtc9IBAA?oc=5,Israeli institute invests $100 million in artificial intelligence to solve real-world problems - JTA News - Jewish Telegraphic Agency,2019-02-25,JTA News - Jewish Telegraphic Agency,https://www.jta.org,N/A,['sponsored'],One scientist is using the octopus as a model for methods of diagnosis and treatment of disorders like Parkinson’s disease.,N/A,https://schema.org,NewsArticle,http://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems,"{'@type': 'ImageObject', 'url': 'https://www.jta.org/wp-content/uploads/2019/02/2-25-19-artificial-intelligence.jpg'}","[{'@type': 'Person', 'name': 'Larry Luxner'}]","{'@type': 'Organization', 'name': 'Jewish Telegraphic Agency', 'logo': 'https://live-jta.pantheonsite.io/wp-content/uploads/2018/12/cropped-homeicon-square@2x-1.png'}",Israeli institute invests $100 million in artificial intelligence to solve real-world problems,2019-02-25T16:31:28Z,2019-02-25T16:42:40Z,Health,,,,N/A,N/A,"



					Sponsored				
Israel

Israeli institute invests $100 million in artificial intelligence to solve real-world problems


By							

									Larry Luxner								




February 25, 2019
11:31 am







 

							Machine learning is being applied to an ever-widening variety of fields, including biology and chemistry, and is becoming increasingly crucial to Israel's high-tech success. (Sean Gallup/Getty Images)						





Advertisement








REHOVOT, Israel — For years, Israeli scientist Tamar Flash has been fascinated with the octopus, and the unusual way the invertebrate’s eight arms propel it effortlessly through the water.
Her interest is no mere hobby. A renowned professor who does research in artificial intelligence at the Weizmann Institute of Science in Rehovot, Flash is using the octopus as a model for methods of diagnosis and treatment of disorders from Parkinson’s disease to autism.
“My major interest is the brain’s representation of movement, or the principles underlying the organization, control and perception of movement by humans,” Flash said. “The octopus has no bones. It’s totally soft. It’s just made of muscles.”
Modeling the movement of the octopus, she said, also may help scientists develop “soft” robots for rehabilitation clinics, search-and-rescue operations and even nursing homes.


“The first generation of robots were made of steel,” Flash said. “But if we want robots to help handicapped people, we had better make them from soft materials that can come in contact with humans without injuring them.”
Flash works at the Weizmann Institute’s new Artificial Intelligence Center for Scientific Exploration, a $100 million initiative. Hers is one of several projects at the center that seek to apply AI principles to real-life problems.
One of the world’s foremost multidisciplinary research institutions, Weizmann is investing heavily in the burgeoning field of AI. Its expertise in computer vision, machine learning and robotics — as well as a culture that encourages collaborations across disciplines — makes AI a natural fit.
More than half a dozen scientists from across the institute do AI-related research at the new center, which was launched about a year ago. The center’s director is Shimon Ullman, a world leader in computer vision who was awarded the 2015 Israel Prize in mathematics and computer science research.
Tamar Flash is a scientist at the Weizmann Institute’s new Artificial Intelligence Center for Scientific Exploration researching ways to develop “soft” robots modeled on the octopus to help patients in rehabilitation clinics, search-and-rescue operations and nursing homes. (Larry Luxner)
“The techniques coming out of AI — and, more broadly, machine learning — are becoming important in almost all disciplines,” Ullman said. “They can really help scientists deal with huge sets of data in chemistry, in physics and in biology. This will also be very helpful for Israel’s high-tech industry.”
Shai Bagon, an expert in video and image processing, is one of two Robin Chemers Neustein Artificial Intelligence Fellows recruited to work at the center.
“Each one of us has a different perspective,” Bagon said of his fellow researchers. “Some are more theoretical in their inclination, others are more practical. We want to see if by establishing this center we can somehow enable collaborations in fundamental research that wouldn’t have happened otherwise.”
While it’s not yet clear where the work will lead, Bagon said, his team’s mission is to conduct basic research on AI and machine learning.
“We are not told what to investigate,” he said. “Rather it’s all driven by the curiosity and ingenuity of the researchers themselves.”
The Weizmann Institute’s focus on curiosity-driven research rather than on profit or commercial success grants its scientists an unusual level of freedom to pursue their own ideas and investigations.
For example, Flash has been working in the field of human locomotion and robotics since the early 1980s. She studied at the Harvard-MIT Division of Health Sciences and Technology and has a doctorate in medical physics. Over the years, Flash’s work has been funded by the U.S. Navy and the Pentagon’s Defense Advanced Research Projects Agency, and more recently by the European Union.
“We need a basic understanding of what it means to have intelligence,” she said. “There’s a lot of hype now about artificial intelligence, but if we want to bring the AI revolution to the real world, we need robotics. When we move, to us it seems so simple. But it’s not simple at all.”
To help Flash and her colleagues, the center employs powerful Nvidia DGX-1 computers and servers that can crunch numbers in hours rather than weeks or months. However, maintaining and upgrading the equipment is costly, according to Bagon.
The center’s establishment is meant to help Israel become a world leader in underexplored areas of AI. Funding is a challenge, especially given that government agencies and multinationals in the United States, Europe and China invest billions of dollars annually in AI efforts. For this reason, philanthropic support for the center is a major priority for the Weizmann Institute, as well as the American Committee for the Weizmann Institute, which raises funds in the United States for the institute.
“It’s true we can’t compete with China’s budget, or the resources Google has. But we can make some fundamental, deep insight into this subject,” Bagon said. “Whereas companies like Facebook and Google are very much driven by business, we have the luxury of asking questions that other people don’t have the patience or the attention span to ask. We don’t even know these questions yet — let alone the answers to them.”
Prominent mathematician Boaz Nadler is also part of the team at the new AI center. His current research focuses on large data sets and their theoretical and practical applications — specifically how to find outliers and remove “noise” when fusing information from varying sources.
“Crowdsourcing is when you give a series of tasks to many different people and they all give you their answers,” he said. “You don’t know how accurate or inaccurate they are, yet you’d like to combine them and get an answer that’s even more accurate.”
Dramatically increased computing power is driving the AI revolution, much the same way the early 20th century saw a revolution in physics and the 1950s was defined by the computer revolution, Nadler said.
“Israel is known as the ‘Startup Nation,’ and many new startups today are based on machine learning and AI,” Nadler said. “This institute would like to put Weizmann at the forefront of academic research, but it will also help to train people who would then have the skills to go into industry. This is key for the continued success of Israeli companies.”
Share this:TwitterFacebookWhatsAppEmail



This article was sponsored by and produced in partnership with the American Committee for the Weizmann Institute of Science, which develops philanthropic support for the Weizmann Institute of Science in Rehovot, Israel, one of the world’s premier scientific research institutions. This article was produced by JTA’s native content team.


								More from American Committee for the Weizmann Institute of Science							
















Advertisement










",,,https://www.jta.org/wp-content/uploads/2019/02/2-25-19-artificial-intelligence-156x87.jpg,,,"{'@type': 'WebPage', '@id': 'http://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems'}",,,"[{'@type': 'NewsArticle', '@id': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems#article', 'isPartOf': {'@id': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems'}, 'author': [{'@id': 'https://www.jta.org/#/schema/person/image/47b3b9975dca1204042190249b4d8f71'}], 'headline': 'Israeli institute invests $100 million in artificial intelligence to solve real-world problems', 'datePublished': '2019-02-25T16:31:28+00:00', 'dateModified': '2019-02-25T16:42:40+00:00', 'mainEntityOfPage': {'@id': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems'}, 'wordCount': 1064, 'publisher': {'@id': 'https://www.jta.org/#organization'}, 'image': {'@id': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems#primaryimage'}, 'thumbnailUrl': 'https://www.jta.org/wp-content/uploads/2019/02/2-25-19-artificial-intelligence.jpg', 'keywords': ['Sponsored'], 'articleSection': ['Health', 'Israel'], 'inLanguage': 'en-US', 'copyrightYear': '2019', 'copyrightHolder': {'@id': 'https://www.jta.org/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems', 'url': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems', 'name': 'Israeli institute invests $100 million in artificial intelligence to solve real-world problems - Jewish Telegraphic Agency', 'isPartOf': {'@id': 'https://www.jta.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems#primaryimage'}, 'image': {'@id': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems#primaryimage'}, 'thumbnailUrl': 'https://www.jta.org/wp-content/uploads/2019/02/2-25-19-artificial-intelligence.jpg', 'datePublished': '2019-02-25T16:31:28+00:00', 'dateModified': '2019-02-25T16:42:40+00:00', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.jta.org/2019/02/25/israel/israeli-institute-invests-100-million-in-artificial-intelligence-to-solve-real-world-problems#primaryimage', 'url': 'https://www.jta.org/wp-content/uploads/2019/02/2-25-19-artificial-intelligence.jpg', 'contentUrl': 'https://www.jta.org/wp-content/uploads/2019/02/2-25-19-artificial-intelligence.jpg', 'width': 2160, 'height': 1200, 'caption': ""Machine learning is being applied to an ever-widening variety of fields, including biology and chemistry, and is becoming increasingly crucial to Israel's high-tech success. (Sean Gallup/Getty Images)""}, {'@type': 'WebSite', '@id': 'https://www.jta.org/#website', 'url': 'https://www.jta.org/', 'name': 'Jewish Telegraphic Agency', 'description': 'The Global Jewish News Source', 'publisher': {'@id': 'https://www.jta.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.jta.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': ['Organization', 'NewsMediaOrganization'], '@id': 'https://www.jta.org/#organization', 'name': 'Jewish Telegraphic Agency', 'url': 'https://www.jta.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.jta.org/#/schema/logo/image/', 'url': 'https://www.jta.org/wp-content/uploads/2018/12/jta-long-logo-bw.jpg', 'contentUrl': 'https://www.jta.org/wp-content/uploads/2018/12/jta-long-logo-bw.jpg', 'width': 600, 'height': 315, 'caption': 'Jewish Telegraphic Agency'}, 'image': {'@id': 'https://www.jta.org/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.jta.org/#/schema/person/image/47b3b9975dca1204042190249b4d8f71', 'name': 'Larry Luxner', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.jta.org/#/schema/person/image/23494c9101089ad44ae88ce9d2f56aac', 'url': 'https://secure.gravatar.com/avatar/?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/?s=96&d=mm&r=g', 'caption': 'Larry Luxner'}, 'url': 'https://www.jta.org/author/larry-luxner'}]",2019-02-25T16:31:28Z,,,,['Larry Luxner'],,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vYmxvZ3Mub3JhY2xlLmNvbS9jeC9wb3N0LzEwLXF1b3Rlcy1hYm91dC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mcm9tLXRoZS1leHBlcnRz0gEA?oc=5,10 Quotes About Artificial Intelligence from the Experts - Oracle,2019-02-25,Oracle,https://blogs.oracle.com,AI has taken off in inspiring new directions. Here are 10 of the most thought-provoking quotes about artificial intelligence from experts in the field.,"Ask the Experts,Customer Experience Technology",AI has taken off in inspiring new directions. Here are 10 of the most thought-provoking quotes about artificial intelligence from experts in the field.,AI has taken off in inspiring new directions. Here are 10 of the most thought-provoking quotes about artificial intelligence from experts in the field.,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vdGhlY29udmVyc2F0aW9uLmNvbS9jaGluYS1pcy1jYXRjaGluZy11cC10by10aGUtdXMtb24tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVzZWFyY2gtMTEyMTE50gEA?oc=5,China is catching up to the US on artificial intelligence research - The Conversation,2019-02-27,The Conversation,https://theconversation.com,A recent executive order from President Trump won’t do much to help the US stay ahead of Chinese innovation and investment in AI.,N/A,A recent executive order from President Trump won’t do much to help the US stay ahead of Chinese innovation and investment in AI.,N/A,,,,,,,,,,,,,,N/A,N/A,"






        The U.S. may be ahead for now, but not by much.
        onime/Shutterstock.com









            China is catching up to the US on artificial intelligence research
          




Published: February 27, 2019 6:41am EST












Thomas H. Davenport, Babson College



Author





        Thomas H. Davenport
      


      Professor of Information Technology and Management, Babson College
    





Disclosure statement
MIT Press provides funding as a member of The Conversation US.


Partners
View all partners

We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)33


 Facebook290


 LinkedIn


 WhatsApp


 Messenger

 Print


Researchers, companies and countries around the world are racing to explore – and exploit – the possibilities of artificial intelligence technology. China is working on an extremely aggressive multi-billion-dollar plan for government investment into AI research and applications. The U.S. government has been slower to act. 
The Obama administration issued a report on AI near the end of its term. Since then, little has happened – until a Feb. 11 executive order from President Donald Trump encouraging the country to do more with AI.
The executive order has several parts, including directing federal agencies to invest in AI and train workers “in AI-relevant skills,” making federal data and computing resources available to AI researchers and telling the National Institute of Standards and Technology to create standards for AI systems that are reliable and work well together. These are all good ideas, but they lack funding and bureaucratic structure. So after researching how large organizations use AI for the past five years, in my view the executive order alone is not likely to transform the American approach to AI. 
Government spending
China is doing far more than talking about AI. In 2017, the country’s national government announced it wanted to make the country and its industries world leaders in AI technologies by 2030. The government’s latest venture capital fund is expected to invest more than US$30 billion in AI and related technologies within state-owned firms, and that fund joins even larger state-funded VC funds.
One Chinese state alone has said it will devote $5 billion to developing AI technologies and businesses. The city of Beijing has committed $2 billion to developing an AI-focused industrial park. A major port, Tianjin, plans to invest $16 billion in its local AI industry.



The Chinese military is developing ways to control robots with brain signals.
Reuters/China Stringer Network


These government programs will support ambitious major projects, startups and academic research in AI. The national effort also includes using AI in China’s defense and intelligence industries; the country’s leaders are not reluctant to use AI for social and political control. For example, both AI-driven facial recognition, even to catch jaywalkers, and “social credit” – an AI-driven credit score that factors in social behaviors – are already in use.
U.S. investment plans, mostly in the defense industry, are dwarfed by the Chinese effort. DARPA, the Defense Department’s research arm, has sponsored AI research and competitions for many years, and has a $2 billion fund called “AI Next” to help develop the next wave of AI technologies in universities and companies. It’s not yet clear how much real progress its efforts have made. 
Private sector contributions
The U.S. has a strong private sector effort in this technology. There are, for instance, many more AI firms in the U.S. than in China. 
American investment appears strong, too. In 2015, for example, the combined research and development spending at the U.S.-headquartered companies Google, Apple, Facebook, IBM, Microsoft and Amazon was $54 billion. Much of that spending went toward AI research, but some of the work actually happened in China and elsewhere outside the U.S. That work has been used to personalize ads, improve search results, recognize and label faces and generally make products smarter.
In China, the private sector is much more closely tied to government plans than in the U.S. The Chinese government has asked four large AI-oriented firms in China – Baidu, Tencent, Alibaba and iFlytek – to develop AI hardware and software systems to handle autonomous driving and language processing, so other companies could build on those skills.
China may have also surpassed the American historic advantage in venture capital investments. In 2018, U.S. AI startups received $9.3 billion in venture funding – a record amount, but the number of deals was down from 2017. However, one report from China suggests that in the first half of 2018, Chinese venture investments – many of which involved AI – were higher than in the U.S. Data from 2017 suggest that Chinese AI firms received more venture funding than U.S. companies, although the American funding went to many more firms.

Beyond investment money
There are other factors than investment that determine a country’s long-term competitiveness on AI. Talent is an important one. The U.S. had an historical edge in this regard, with strong technical universities, many technology sector employers and relatively open immigration policies. 
A recent analysis of LinkedIn data suggests that the U.S. has far more AI engineers than China does. But China is closing the gap rapidly, with a variety of education and training programs beginning as early as elementary school. The Trump administration’s restrictions on immigration are encouraging some of the world’s best AI researchers to stay home, rather than come to the U.S.
Another element in long-term AI success is how particular regions build mutually reinforcing communities of companies, university ecosystems and government agencies. Silicon Valley is the world leader in this regard, and China doesn’t have anything to match it yet. Both the U.S. and China could learn from efforts in Canada, such as the work by the Montreal Institute for Learning Algorithms, which has offered companies access to facilities, venture capital and university research partnerships to accelerate AI development in that city.



Surveillance cameras are common in China, collecting data on residents.
Reuters/Thomas Peter


A final key element in AI progress is data: The more data a country’s companies have, the better able they are to develop capable AI systems. Chinese online firms have massive amounts of consumer data on which to train machine learning algorithms. Because of its very large number of inhabitants, the population’s heavy use of digital services and its lax regulatory environment, China clearly beats the U.S. on data.
I still think the U.S. has the edge over China in AI capabilities at the moment. However, as much as I would like the U.S. to win this race over the long run, if I were a betting man I would bet on China. As I describe in my new book “The AI Advantage,” China is executing its strategy for AI, and the U.S. is still wrestling to create one. China is also reaping the benefits of having a determined government, an inexhaustible pot of money, a growing cadre of smart researchers and a large, digital-hungry population. 
Perhaps if the leadership of the U.S. government devoted as much attention and investment to AI as it does to its other strong priorities, the U.S. could maintain its lead in the field. That seems unlikely over the next couple of years, however.




Thomas H. Davenport is the author of:
The AI Advantage: How to Put the Artificial Intelligence Revolution to Work
MIT Press provides funding as a member of The Conversation US.








Artificial intelligence (AI)


China


venture capital


Donald Trump


China Economy


Executive Orders


MIT Press









",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3Lm5iY25ld3MuY29tL25ld3MvYWxsL3JlZGRpdC1jby1mb3VuZGVyLWFsZXhpcy1vaGFuaWFuLXBhcmVudGFsLWxlYXZlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWh1c3RsZS1uOTc2NjEx0gEraHR0cHM6Ly93d3cubmJjbmV3cy5jb20vbmV3cy9hbXAvbmNuYTk3NjYxMQ?oc=5,"Reddit co-founder Alexis Ohanian on parental leave, artificial intelligence and 'hustle porn' - NBC News",2019-02-27,NBC News,https://www.nbcnews.com,"Alexis Ohanian, internet entrepreneur, new dad and husband of tennis superstar Serena Williams, joins TODAY with an announcement regarding his crusade for paid paternity leave. Plus, he dishes on his secret pancake recipe and his daughter’s doll, Qai Qai.",N/A,"In an interview, Ohanian spoke about a variety of topics including his commitment to expanding policies to help new dads.","In an interview, Ohanian spoke about a variety of topics including his commitment to expanding policies to help new dads.",http://schema.org,VideoObject,https://www.today.com/video/alexis-ohanian-talks-about-his-push-for-paid-paternity-leave-1444727875880,,,"{'@type': 'NewsMediaOrganization', 'name': 'NBC News', 'logo': {'@type': 'ImageObject', 'url': 'https://media-cldnry.s-nbcnews.com/image/upload/h_60/v1696280688/newsgroup-logos/nbcnews/logo/primary-black-424x45.png'}, 'sameAs': ['https://twitter.com/nbcnews', 'https://www.pinterest.com/nbcnews/', 'https://www.facebook.com/NBCNews/', 'https://www.instagram.com/nbcnews/', 'https://www.youtube.com/nbcnews', 'https://www.snapchat.com/p/8bb879c7-45c0-499c-bb3c-7a3d0e229301/2193844248074240', 'https://www.tiktok.com/@nbcnews?lang=en']}",,,,,Alexis Ohanian talks about his push for paid paternity leave,,,N/A,N/A,"Tech & MediaReddit co-founder Alexis Ohanian on parental leave, artificial intelligence and 'hustle porn'In an interview, Ohanian spoke about a variety of topics including his commitment to expanding policies to help new dads.Alexis Ohanian, co-founder and executive chairman of Reddit.Jerod Harris / Getty Images for PTTOW! filePrintSaveCreate your free profile or log in to save this articleFeb. 27, 2019, 8:19 AM EST / Updated Feb. 27, 2019, 1:14 PM ESTBy Claire AtkinsonReddit co-founder and new dad Alexis Ohanian sees your Instagram posts bragging about how hard you work.“It goes without saying if you want to be an entrepreneur, if you want to be successful at your career, you have to work hard,” Ohanian said during a recent Q&A. “The problem is when people misconstrue the act of flexing on social, or showing off on social as a kind of work. Bragging about self destructive behavior over the long term is stupid. Worse that it’s dangerous.”Ohanian speaks from experience. He co-founded Reddit in 2005, and the website has since become one of the most-visited destinations on the internet ahead of Twitter and Yahoo, according to website analytics service Alexa.Ohanian, a known but low-key figure in the technology industry for years, is now better known to the general public as the husband of tennis superstar Serena Williams and dad to Alexis Olympia, who turned one in September. He is currently a managing partner at the venture capital firm Initialized Capital.0 seconds of 6 minutes, 42 secondsVolume 90%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledPlay/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


SettingsOffEnglishFont ColorWhiteFont Opacity100%Font Size100%Font FamilyArialCharacter EdgeNoneBackground ColorBlackBackground Opacity50%Window ColorBlackWindow Opacity0%ResetWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%200%175%150%125%100%75%50%ArialCourierGeorgiaImpactLucida ConsoleTahomaTimes New RomanTrebuchet MSVerdanaNoneRaisedDepressedUniformDrop ShadowWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%WhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%







Live00:0006:4206:42 We apologize, this video has expired.Alexis Ohanian talks about his push for paid paternity leave06:43In an interview, Ohanian spoke about what it’s like to be a father and why he decided to become a brand partner and spokesperson for Unilever-owned Dove Men+Care to bring attention to parental leave. Ohanian also touched on why it might be hard to discern the truth on the internet in times to come, why “hustle porn” is wrong, and why rest is critical to good performance. This interview has been edited for brevity.Q: Why are you supporting paid paternity leave?A: I’ve been a proud taker of parental leave, and at the time I really just wanted to get the word out as a means of encouraging other men to take advantage. Very few men have access to paid leave policy in this country.Dove has built a brand around supporting dads. So when they said they wanted to support paid parental leave in particular, I got excited. They, to their credit, have launched a $1 million commitment for dads to take their time off during this important time.Q: Did you take off?A: We had 16 weeks at [Reddit], and as the founder I wanted to set the bar by taking full advantage of it, and I’m back to work. This is a life-changing event, and what more employers are realizing is that their people are not going to perform at their best unless they know the home front is secure and taken care of, and that’s what this offers. Tech is one industry. It is overall pretty advanced on the leave policy and still not enough is done. For so many Americans, there isn’t even an opportunity for paid leave, so this is all a step in the right direction.We can start to turn the tide and actually get a real win here. This country needs something with bipartisan support to rally around, and so far whether it’s the president’s State of the Union, Ivanka Trump has spoken out about it, and a number of Democratic and Republican senators and representatives have talked about this being an issue they want to solve.Q: You talked about “Hustle Porn” and working very hard in tech culture. Can you talk about the feedback you’ve got on it?A: I have had a really resounding response from people who have appreciated the fact that this is a really unhealthy farce. It goes without saying if you want to be an entrepreneur, if you want to be successful at your career, you have to work hard. The problem is — and I dubbed it “hustle porn” — the problem is when people misconstrue the act of flexing on social or showing off on social as a kind of work. Bragging about self destructive behavior over the long term is stupid. Worse that, it’s dangerous.RecommendedNewsNewsABC's George Stephanopoulos appears to say of Biden: 'I don't think he can serve four more years'ConsumerConsumerParamount merger sparks concern among movie theater ownersBeing a high performer in whatever career you have requires a tremendous amount of physical and mental stress at work, and every human has a breaking point. You look at the people who are succeeding in our society, I would argue it is sport. What you’ll find is every single one of them has an important value placed on rest, has an important value placed on taking time away, because that recovery time is as important or more important than the actual work you are putting in.I feel like there’s a ripple effect now, because it is dangerous when so many people are sacrificing themselves, physically and mentally, to the point where it is not just hurting them, it is also hurting their businesses. The dialogue around it is changing. People are seeing everything now from therapy to executive coaching become less stigmatized and, more importantly, embraced. We backed a company, Torch, that is building a software solution for executive coaching within companies and making it as easy as possible to get access to, and it continues to change the discussion.Q: Misinformation on the internet is a big topic right now. Do you have thoughts on what the tech companies are doing to combat it?A: Right now, we have a really important opportunity for media literacy, for education, that still isn’t part of any curriculum. We are at a point in the next few years where it will actually be very hard because of artificial intelligence software. It will be very hard to discern truth, and you’ve probably seen a few of these videos.You’ve seen the one with President Obama. They did the voiceover and had him saying some funny stuff. Technology is going to be one of the biggest challenges here. Because what we’re seeing is more and more advanced mechanisms to potentially create artificial content using artificial intelligence, and I think this is going to need to come back to heightened media literacy among all of us. But it will be a major issue for us to have to deal with in the next 10 years in society.Q: You’re an investor in tech companies. Can you name a few companies that you’re interested in?A: To the point about artificial intelligence, I do think we’re at a turning point now with the technology where automatable jobs are routine work, work that software could do better, cheaper and faster. We’re at a turning point where artificial intelligence is going to be able to do a lot of this work. It’s going to be imperative that people are investing in skills that are non-routine skills — everything from being an engineer to being a barber. The non-routine skills will continue to be valuable. They are the jobs that artificial intelligence won’t be able to do. Elon Musk will disagree with me, but I don’t see that being anywhere in the foreseeable future.We’ve been backing self-driving car companies like Voyage, which are helping retirement communities, people who have little mobility, helping them with a self-driving taxi service. This is a great example of how we can make people’s lives better and safer. We’re seeing Standard Cognition, which is going to compete head-to-head with Amazon Go, letting people do self check-out.This is going to be rolled out in the next decade and we’re going to see a huge shift as a result because a lot of labor is going to be affected. Overall, it will make people’s lives better. It’s why those non-routine skills are imperative to learn. I’m also looking to try to invest in companies that will scale opportunities for those people, from engineering or any kind of creative pursuits.Like I said, being a welder or a barber, those are the skills that are going to continue to have value in the new economy, and that I don’t think artificial intelligence will touch.Claire AtkinsonClaire Atkinson is the former senior media editor for NBC News.",,,"['https://media-cldnry.s-nbcnews.com/image/upload/t_fit-1500w,f_auto,q_auto:best/MSNBC/Components/Video/201902/new-reddit-founder-tease-today-190219.jpg']",,,,2019-02-19T14:45:50.000Z,http://link.theplatform.com/s/rksNhC/zPbfTUo51Vl_?format=redirect,,,,,,,https://www.today.com/video/alexis-ohanian-talks-about-his-push-for-paid-paternity-leave-1444727875880,PT6M43S,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vdWguZWR1L25ld3MtZXZlbnRzL3N0b3JpZXMvMjAxOS9mZWJydWFyeS0yMDE5LzAyMjUyMDE5LXJvYm90LWhvc3BpdGFsaXR5LnBocNIBAA?oc=5,"Robots and Artificial Intelligence Present Challenges, Opportunities for Hospitality Industry - University of Houston",2019-02-25,University of Houston,https://uh.edu,"Friendly and generous human-to-human interaction is at the core of good hospitality whether at a hotel, restaurant or club. However, what will the hospitality industry look and feel like when human workers are replaced by machines? ",N/A,"Friendly and generous human-to-human interaction is at the core of good hospitality whether at a hotel, restaurant or club. However, what will the hospitality industry look and feel like when human workers are replaced by machines? ",N/A,,,,,,,,,,,,,,N/A,N/A,"

Robots and Artificial Intelligence Present Challenges, Opportunities for Hospitality IndustryUniversity of Houston Study Offers Glimpse into Robot Revolution 
By Chris Stipes 713-743-8186February 25, 2019


John Bowen, Hilton College professorCristian Morosan, Hilton College associate professorFriendly and generous human-to-human interaction is at the core of good hospitality whether at a hotel, restaurant or club. However, what will the hospitality industry look and feel like when human workers are replaced by machines?
It’s already happening around the world, from robots staffing hotel front desks to machines capable of grilling hamburgers. Experts predict that robots will make up 25 percent of the hospitality workforce by 2030, presenting challenges and opportunities for an industry historically slow to adopt new technology.
University of Houston Hilton College of Hotel and Restaurant Management professors John Bowen and Cristian Morosan recently published one of the first studies to discuss the major disruption robots will cause in the hospitality industry. The study in the journal Worldwide Hospitality and Tourism Themes examines how service delivery systems need to be redesigned to maximize the benefits of robots, while still maintaining authentic customer service.
“The hospitality industry has high turnover in a lot of entry level jobs. Robots are good at doing repetitive tasks like food prep, cleaning and even delivery,” said Bowen. “We’re already seeing some large hotels replace front desk personnel with automated kiosks. Machines will be taking over these positions, which could produce a more error-free product.”
Worldwide labor shortages play a role in the demand for robots, along with the need to communicate with an increasing number of international travelers, according to the study, “Beware hospitality industry; the robots are coming.” Robotic hotel check-in systems will be able to respond to countless languages and react to cultural differences and expectations. Several Las Vegas hotels already use robots to deliver amenities and food directly to a guest’s room.
New systems will need to integrate seamlessly with the service environment while being attractive and easy to use for consumers of all ages. The researchers predict companies that embrace artificial intelligence and robotics will have a competitive advantage.
“It’s a way for hotels to become more efficient and cut down check-in wait times for guests, “ said Bowen. “Ultimately it will lead to a better guest experience and create customer value.”
How to use customer data has long been a challenge for the travel industry. By developing systems that learn from consumer behavior, companies can present products or services tailored to guest preferences. If a hotel guest ordered a particular red wine during a previous visit, for example, they can be offered the same wine as one of their choices subsequent visits.
However, the researchers warn that guest information needs to be used discreetly and securely. A customer may not be traveling with the same companion as on a previous trip, for example.
“Customers bring a lot of data into the hospitality service experience, including credit card and ID info, and also through their mobile device. If companies can determine behavioral data, such as what you’re purchasing and when, they can take this info and learn from it to enhance the customer experience,” said Morosan, who specializes in information technology adoption. 
The study also predicts robots will save the customer time and money by offering services that previously were cost prohibitive.
“Autonomous cars, a type of robot, will pick up guests at the airport. If they have not checked into the hotel, the car can check them in and set up their smartphone to use as a key. Based on the customer information available on the guest, the car can make suggestions regarding restaurants near the hotel. It will be able to ask questions, and based on the responses, the car can make reservations for the guest,” according to the study. “As they head toward the hotel, the guest may see a large stadium on the other side of the river and ask about it. The car can recognize the building and then provide information on the stadium. The robot serves as an airport pick-up, front desk clerk, concierge, and tour guide.”
Hospitality as we know it will be redefined during the robot revolution, and while some companies will thrive, others could be put out of business if they don’t find the right blend of hospitality and technology.
“We have to combine high tech with high touch. I don’t think the hospitality aspect will ever go away, no matter how many robots are used. We just need to find the right combination between artificial intelligence and human touch,” said Morosan. “For example, four and five start hotels will still preserve the human touch in the front of the house, while using AI and machines in the back of the house to better serve the guest.”
 


Categories:
                People, Research
",,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LmZlZGVyYWx0aW1lcy5jb20vaXQtbmV0d29ya3MvMjAxOS8wMi8yOC9haS10by1jaGFuZ2UtdGhlLWZlZGVyYWwtd29ya2ZvcmNlLW92ZXIteWVhcnMtYW5kLWRlY2FkZXMv0gEA?oc=5,AI to change the federal workforce 'over years and decades' - Federal Times,2019-02-28,Federal Times,https://www.federaltimes.com,"Thousands of federal employees are likely to see their work impacted by artificial intelligence over the next few decades, according to a new report.","['will-i-lose-my-job-because-of-ai', 'how-will-aritficial-intelligence-impact-my-job', 'artificial-intelligence-federal-workforce', 'are-federal-agencies-using-artificial-intelligence', 'will-I-lose-my-job-because-of-AI', 'how-will-aritficial-intelligence-impact-my-job', 'artificial-intelligence-federal-workforce', 'are-federal-agencies-using-artificial-intelligence', 'circulated-federal-times']","Thousands of federal employees are likely to see their work impacted by artificial intelligence over the next few decades, according to a new report.",N/A,http://schema.org,NewsArticle,https://www.federaltimes.com/it-networks/2019/02/28/ai-to-change-the-federal-workforce-over-years-and-decades/,"{'url': 'https://www.federaltimes.com/resizer/FWkpUbiSy2Kl8Sen7R0EH1HCYrk=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/DB53NL25MRGZJESFT37AUUQESQ.jpg', '@type': 'ImageObject'}","[{'@type': 'Person', 'name': 'Jessie Bur'}]","{'@type': 'Organization', 'name': 'Federal Times', 'url': 'https://www.federaltimes.com/', 'logo': {'@type': 'ImageObject', 'url': '/resources/img/federal-logo-white.png?d=124'}}",AI to change the federal workforce ‘over years and decades’,2019-02-28T15:02:36.280Z,2022-08-18T01:13:31.442Z,IT & Networks,Federal Times,,,IT & Networks,N/A,"Thousands of federal employees are likely to see their jobs and work requirements change as artificial intelligence is adopted at their agencies, according to a Partnership for Public Service and IBM Center for the Business of Government report released Feb. 28.“AI is expected to revolutionize how government works. For one, AI could enable federal employees to focus on core responsibilities related to their agencies’ missions and spend fewer hours on administrative duties. They are likely to have more time to deliver services, interact with customers and perform other mission-related tasks. Should AI become pervasive in federal agencies, employees will need to enhance their digital and data literacy and learn how best to use the technology to work with citizens effectively,” the report said.“AI is sure to change the composition of the federal workforce, creating new jobs related to managing AI systems or requiring critical thinking. Jobs based mainly on tasks that can be automated would likely be phased out, and employees would have to learn new or different skills for other jobs.”The report estimates that approximately 130,000 federal employees will be directly impacted by the rise of AI, with some agencies seeing over a quarter of their workforce impacted.Experts interviewed for the report disagreed on whether those changes would take place over decades or years, but the recent past has provided examples of how such work disruptions play out.“The changes brought on by AI would not be the first substantial disruption of the federal workforce. In 1985, 19 percent of full-time federal employees held clerical positions. In 2017, they constituted just 4.3 percent in the workforce, according to Office of Personnel Management data,” the report said.“During those years, desktop computers and other technologies automated many clerical tasks, and new employees were hired to deliver programs in newly created agencies such as the Department of Homeland Security. Whatever changes AI brings will not be immediate but an evolution that will play out over years and decades.”Employees in their 50s are the most likely to see near-term impacts on their work from AI, according to the report, while employees in their 20s will see the lowest impact.But “impacted” by AI does not necessarily mean that a job will disappear entirely, as such automated systems can often take care of dull and repetitious tasks, while freeing up employee time for more valuable pursuits.“These are the so-called mundane tasks that almost no public employee wants to do,” said Kevin Desouza, a professor of business, technology and strategy at Queensland University of Technology in Australia, in the report.Employees will, however, likely have to work on becoming more digitally literate to interface better with new AI systems.“Everybody will be a bit of a data scientist in the future. It doesn’t matter if you are an HR person, an IT person or a business person,” said Dorothy Aronson, chief information officer at the National Science Foundation, in the report.Federal leaders and personnel offices should therefore begin to prepare and train their workforces today for the changes AI will likely bring in the future, the report recommended.The Office of Management and Budget should see AI in the context of a cross-agency priority goal and work with the General Services Administration to develop a team like U.S. Digital Service to focus on AI, according to the report, and the Office of Personnel Management should establish an AI occupational series.“Leaders should communicate with employees early and often about the potential of AI to disrupt and alter their work. Leaders and managers should learn from early adopters of AI, such as the U.S. Coast Guard, NASA and the Department of Health and Human Services,” the report said.“They should find out the extent to which the workday changed for employees, what types of agency work AI helped these organizations accomplish, which tasks were automated successfully, and what kind of work employees might start doing in place of current, repetitious tasks that AI could perform.”About  Jessie BurJessie Bur covers federal IT and management.Share:In Other NewsAsk Kevin: Which FEHB national plans offer Medicare Advantage plans?Here's what retirees can do to learn more about Medicare Advantage plans offered by FEHB plans.Ask Reg: The process for counting active duty time toward retirementA reader asks what documents are needed to prove the time acquired while in the armed forces.OpinionOveruse of National Guard threatens to undermine preparednessNontraditional missions run the risk of diverting resources that could be dedicated to training and preparedness, the authors say.Defense Health Agency nurses face recruiting freeze, threats to payThe agency has held town halls informing employees that it’s suspending a regrade of existing GS-13 nursing positions.Government power in US is a swirl of checks and balancesArticle II of the Constitution said executive power would be vested in the president but didn't specify what those powers specifically were.Load More",,https://www.federaltimes.com/it-networks/2019/02/28/ai-to-change-the-federal-workforce-over-years-and-decades/,,,,"{'type': 'WebPage', '@id': 'https://www.federaltimes.com/it-networks/2019/02/28/ai-to-change-the-federal-workforce-over-years-and-decades/'}",,,,,,,,,https://www.federaltimes.com/#publisher,,/resources/img/federal-logo-white.png,"['https://www.facebook.com/https://www.facebook.com/FederalTimes', 'https://twitter.com/federaltimes']"
https://news.google.com/rss/articles/CBMiggFodHRwczovL3d3dy5ncmFwaGljLmNvbS5naC9uZXdzL2dlbmVyYWwtbmV3cy9naGFuYW5ld3MtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWktbmFycm93aW5nLXRoZS1nYXAtYmV0d2Vlbi1odW1hbi1hbmQtbWFjaGluZS5odG1s0gEA?oc=5,"Artificial intelligence (AI), narrowing the gap between human and machine - Graphic Online",2019-02-27,Graphic Online,https://www.graphic.com.gh,I may not keep my job in the near future when automation becomes the norm.,N/A,I may not keep my job in the near future when automation becomes the norm.,I may not keep my job in the near future when automation becomes the norm.,https://schema.org,Article,https://www.graphic.com.gh/,"{'@type': 'ImageObject', 'url': 'https://www.graphic.com.gh/images/2019/feb/27/artificialghana-news.jpg'}","{'@type': 'Person', 'name': 'Bridget Aazore Yuora', 'url': 'https://www.graphic.com.gh/news/general-news/ghananews-artificial-intelligence-ai-narrowing-the-gap-between-human-and-machine.html'}","{'@type': 'Organization', 'name': 'Graphic Online', 'logo': {'@type': 'ImageObject', 'url': 'https://www.graphic.com.gh/images/2018/feb/onlinelogo.png'}}","Artificial intelligence (AI), narrowing the gap between human and machine",2019-02-27T14:48:21+00:00,2019-02-27T14:48:47+00:00,,Graphic Online,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Ghana News', 'item': 'https://www.graphic.com.gh/news.html'}, {'@type': 'ListItem', 'position': 2, 'name': 'General News', 'item': 'https://www.graphic.com.gh/news/general-news.html'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial intelligence (AI), narrowing the gap between human and machine', 'item': 'https://www.graphic.com.gh/news/general-news/ghananews-artificial-intelligence-ai-narrowing-the-gap-between-human-and-machine.html'}]",N/A,N/A,Elon Musk plans to donate $45 million monthly to back Donald Trump's reelection campaign,,,,,,"{'@type': 'WebPage', '@id': 'https://www.graphic.com.gh/news/general-news/ghananews-artificial-intelligence-ai-narrowing-the-gap-between-human-and-machine.html'}",,,,2019-02-27T14:43:03+00:00,,,,,,,,"['https://web.facebook.com/dailygraphicghana/', 'https://twitter.com/Graphicgh', 'https://www.youtube.com/channel/UCfwY1WBJRCOP17Gpa-6l4rA']"
https://news.google.com/rss/articles/CBMiiQFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2NvZ25pdGl2ZXdvcmxkLzIwMTkvMDIvMjcvcmVpbWFnaW5pbmctc3RyYXRlZ2ljLW1hbmFnZW1lbnQtdGhlb3JpZXMtYW5kLW1vZGVscy13aXRoLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,Reimagining Strategic Management Theories And Models With Artificial Intelligence - Forbes,2019-02-27,Forbes,https://www.forbes.com,"The advent of Artificial Intelligence in the corporate world is disrupting existing business processes and changing the way organizations are run. AI is fast becoming a cornerstone of how businesses manage their bottom line, while opening new revenue streams that could provide a boost to...",,"The advent of Artificial Intelligence in the corporate world is disrupting existing business processes and changing the way organizations are run. AI is fast becoming a cornerstone of how businesses manage their bottom line, while opening new revenue streams that could provide a boost to...","The advent of Artificial Intelligence in the corporate world is disrupting existing business processes and changing the way organizations are run. AI is fast becoming a cornerstone of how businesses manage their bottom line, while opening new revenue streams that could provide a boost to...",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/cognitiveworld/2019/02/27/reimagining-strategic-management-theories-and-models-with-artificial-intelligence/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/cognitiveworld/files/2019/02/GearsHologramManManipulating-F-1200x611.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Sameer Dhanrajani', 'url': 'https://www.forbes.com/sites/cognitiveworld/people/sameerdhanrajani/', 'description': ""Sameer is Chief Executive Officer at AIQRATE. A bespoke global AI advisory and consulting firm. Sameer is a globally recognized AI advisor, business builder, evangelist and thought leader known for his deep knowledge and strategic consulting approaches in the AI space. Sameer has consulted with several Fortune 500 global enterprises, Indian corporations, GCCs startups, SMBs, VC/PE firms, and academic institutions in driving AI-led strategic transformation and innovation strategies. He has a rich and proven background of experience in building and scaling AI businesses and practices, securing large AI engagements and deals and creating significant client impact. Sameer is a renowned author, columnist, blogger and is a four-time Tedx speaker. He is author of the best selling book – AI and Analytics: acclerating business decisions, published by Wiley; writes regularly for Forbes, YourStory, Telengana Today, Businessworld and is a prolific blogger with trendsetting, topical coverage on AI strategy and the consulting spectrum. Known for his passion for Artificial Intelligence, Sameer has a huge following on social media and is a well recognized keynote expert, moderator and speaker at several global industry forums and conferences. Sameer has been frequently quoted across business media and news publications and is a recipient of multiple awards and recognitions. Sameer is also associated as an AI advisor on AI policy matters with leading business associations, industry consortia and state governments and is instrumental in leading the effort for positioning India as a premier destination in AI. He is a well-known contributor in the academia space. He is a trusted advisor with leading academic institutions, active with startups and SMBs and advices them on AI led interventions. A fast tracker professional with 20 years of different genres of industry experience, Sameer has donned various leadership roles in consulting, GCCs, bell weather technology organizations and boutique firms to help deliver transformative and innovative AI advisory offerings and consulting offerings to several CXOs and senior leaders. Previously, Sameer was Chief Strategy Officer at Fractal Analytics and was responsible for curating strategic planning roadmaps, driving strategic investments, M&A, incubating new AI capabilities and geographies, marketing & branding and led high-priority growth initiatives to enable Fractal clients on AI-led transformation of their businesses. In his previous assignment, Sameer was Global Business Leader at Cognizant analytics and data sciences business unit at Cognizant Technology Solutions. Under his leadership , Cognizant Analytics became a leading market player in the analytics market space with 3400 analytics professionals serving 180 global clients and executed 3000 plus consulting projects and engagements. As an accomplished professional, Sameer provided the pivotal strategic direction and execution led insights to galvanize Cognizant Analytics run better & run different. Prior to Cognizant, Sameer was the Country Head at Fidelity National Financial and pioneered India's first Global Capability Center (GCC) to be based on a non-linear growth model with platform-based value propositions and developed Fidelity India into a hub of customer delight, delivery innovation, and operational dexterity. Before Fidelity, he worked as Vice President, Analytics at Genpact."", 'sameAs': ['https://www.linkedin.com/in/sameerdhanrajani/', 'https://www.twitter.com/https://twitter.com/DhanrajaniS', 'https://sameerdhanrajani.wordpress.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Reimagining Strategic Management Theories And Models With Artificial Intelligence,2019-02-27T01:01:00-05:00,2019-02-27T01:01:54-05:00,AI & Big Data,Reimagining Strategic Management Theories And Models With Artificial Intelligence,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI & Big Data,N/A,"More From ForbesJun 17, 2024,04:42am EDTProtecting Human Rights In The Age Of Intelligent MachinesApr 24, 2024,05:00am EDTWhat AI Can Tell Us About OzempicFeb 22, 2024,03:42am ESTUnlocking The Power Of Social Data For Clinical Trial DesignJan 25, 2024,04:55am ESTCPG Product Innovation Should Be A Science, Not An ArtAug 7, 2023,08:57am EDTListening Before We Talk: Why Social Data Is Key To Successful NPD In 2023Mar 28, 2023,10:07am EDTHow Technology Is Empowering CPGs To Do More With LessFeb 21, 2023,05:24am ESTAre Humans And Collaboration Still At The Heart Of Innovation?Edit StoryForbesInnovationAIReimagining Strategic Management Theories And Models With Artificial IntelligenceSameer DhanrajaniContributorCOGNITIVE WORLDContributor GroupOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itFeb 27, 2019,01:01am ESTUpdated Feb 27, 2019, 01:01am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin









The advent of Artificial Intelligence in the corporate world is disrupting existing business processes and changing the way organizations are run. AI is fast becoming a cornerstone of how businesses manage their bottom line, while opening new revenue streams that could provide a boost to their toplines as well. Given the scale of its impact, there is no doubt that AI will also have a severe impact on the science that governs how organizations are run today.

I am obviously referring to incumbent management theories and models that govern modern organizational management. In classic terms, management theories are frameworks of wisdom which guide the decisions made by organizational leaders that have survived phenomenally well over the period of the modern enterprise. Sure, there have been reasons to fine-tune each one to the realities of each era and industry, but the core construct has been omnipresent through the years.
With AI’s entry into the mainstream of business, management theories may need to be re-evaluated and tweaked appropriately. While the core construct remains powerfully relevant, an injection of the new-age reality of AI will help managers and business leaders apply them in a more contemporary manner on a few theories and models that are being redefined by AI.
PROMOTED
Porter’s Five Forces
The theory of the Five Competitive Forces put forth by Michael Porter in 1979 is one of the marquee and evergreen theories in management thought schools. Michael Porter suggests that organizations looking for an understanding of their competitor environment need to consider the impact from five perspectives and work on reducing the risks associated: 1) Threat of new entrants, 2) Threat of Substitutes, 3) Bargaining Power of Customers, 4) Bargaining Power of Suppliers and 5) Intra-industry Rivalry. The construct of this theory is that when businesses need to evaluate the competitiveness (or for that matter, the probability of success) in a business or an industry, they need to keep in consideration these five levers that determine an industry’s attractiveness.

With AI now entering the fray, it is time to reimagine our understanding of Porter’s theory. Specifically, when it comes to the threat of new entrants. Over the years, AI has levelled the playing field as a secret sauce, moving even the most established incumbents from their positions in traditional industries. One must look at how AI is fuelling Amazon’s massive growth – which has hugely disrupted the traditional retail industry. Amazon uses AI in a variety of ways – from identifying the next likely purchase to piloting drone-based deliveries. It was no surprise when Amazon’s announcement last year that it will be entering the healthcare industry led to a tumble in the share price of traditional healthcare companies. AI puts enterprises in a pole position and organizations that harness its’ power correctly stand to gain huge ground over those that do not.
Elton Mayo’s Human Relations Theory
Elton Mayo’s landmark research in the field of organizational productivity comes from his studies in the 1920s at Hawthorne plants in Chicago. In seeking to answer questions around how to improve human productivity, he and his assistants tried tinkering with multiple variables that might have an impact on the quality of the labour force’s work – such as light, duration of breaks and duration of working hours. After all these variables proved inconclusive on how to uplift worker productivity, Mayo finally hit upon his hypothesis i.e. giving attention to employees is what truly resulted in improved performances. Giving your workers a voice in the decision-making process, an experience of greater freedom and autonomy and considering the inherent social needs of people – is the most critical lever in the productivity puzzle.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Enter Artificial Intelligence. With AI taking away much of the scud work involved in managing the varied bureaucracies inherent in organizations, leaders will find a lot more time in managing the performance of its most valued asset – human talent. By simplifying routine and repetitive processes for leadership and the people, we can afford to pay much more attention to the well-being of our human talent, celebrate successes and course-correct flagging performances – with the much-needed human(e) touch.
Total Quality Management (TQM)
Many models and theories surround the overall framework for TQM (Total Quality Management) – a science that owes much of its early evolution to manufacturing techniques originating in Japan. At its very essence, TQM is the science that governs the quality in the manufacturing process. It relates to the adherence of manufactured products with agreed specifications, evolved keeping in mind the needs of the end user. TQM bridges multiple concepts – from customer centricity, lowering the waste in manufacturing processes with a view to increasing the overall quality of the manufacturing output.
The theories surrounding this domain may also be due for a revamp. TQM has long been a data-driven process – relying heavily on a post-mortem understanding of evidence-based decision-making and process improvement. With AI in the picture, organizations can improve predictions around off-specified products earlier, leading to a quantum leap in manufacturing quality. AI is also helping improve the forecasting process, thus reducing the waste created through unused, unsold inventory. Similarly, AI will reduce the overhead associated with identifying anomalous manufacturing conditions and provision for predictive machine maintenance as well to keep up the quality standards in manufacturing activity.
The Future of Organizational Management
The defining case for AI to changing existing models and theories of management boils down to the need for creating a blended workforce comprising both humans and machines. Management science today is largely rooted in building more efficient and agile organizations for humans. In the future, humans and AI will work side-by-side to achieve shared organizational goals. This means that AI will help remove a lot of administrative work that often throttles the productivity of leaders – and allow them to direct their energies towards more complex, judgement driven work that requires them to think creatively. Intelligent machines will soon be considered by the workforce to be ‘colleagues’ and the evolution of management thought needs to account for policies and systems that make the most out of this hybrid workforce.
In conclusion, infusing AI will make business more human centric.  Ironic as it may sound, putting AI in charge of the day-to-day, routinized activities will lead to more time for compassionate interactions between humans and unleash human creativity in a huge way. New management theories and models that emerge in the future will hence need to account for the impact of AI – and help organizations and their leaders understand how to navigate this new normal in business.Sameer DhanrajaniFollowingFollowSameer is Chief Executive Officer at AIQRATE. A bespoke global AI advisory and consulting firm.Sameer is a globally recognized AI advisor, business... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,

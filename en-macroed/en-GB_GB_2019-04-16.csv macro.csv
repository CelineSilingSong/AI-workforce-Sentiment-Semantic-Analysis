URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,publisher,datePublished,dateModified,headline,image,thumbnailUrl,mainEntityOfPage,author,article:section,article:summary,article text,articleBody,articleSection,genre,isAccessibleForFree,hasPart,@id,name,logo,sameAs,ContactPoint,parentOrganization,potentialAction,uploadDate,contentUrl,embedUrl,duration,associatedMedia,alternativeHeadline,foundingDate,actionableFeedbackPolicy,correctionsPolicy,ethicsPolicy,Masthead,missionCoveragePrioritiesPolicy,ownershipFundingInfo,unnamedSourcesPolicy,publishingPrinciples,itemListElement,dateCreated,identifier,creator,@graph,speakable,isPartOf,audio
https://news.google.com/rss/articles/CBMiLGh0dHBzOi8vd3d3LmJiYy5jby51ay9uZXdzL2J1c2luZXNzLTQ3ODUyNTg50gEwaHR0cHM6Ly93d3cuYmJjLmNvLnVrL25ld3MvYnVzaW5lc3MtNDc4NTI1ODkuYW1w?oc=5,Will AI kill developing world growth? - BBC,2019-04-18,BBC,https://www.bbc.co.uk,"Automation could wipe out many jobs in developing countries, says globalisation expert Ian Goldin.",N/A,"Automation could wipe out many jobs in developing countries, says globalisation expert Ian Goldin.","Automation could wipe out many jobs in developing countries, says globalisation expert Ian Goldin.",http://schema.org,ReportageNewsArticle,https://www.bbc.com/news/business-47852589,"{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'publishingPrinciples': 'http://www.bbc.co.uk/news/help-41670342', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",2019-04-17T23:08:04.000Z,2019-04-17T23:08:04.000Z,Will AI kill developing world growth?,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_news/12887/production/_106411957_gettyimages-1132636819.jpg'}",https://ichef.bbci.co.uk/news/1024/branded_news/12887/production/_106411957_gettyimages-1132636819.jpg,https://www.bbc.com/news/business-47852589,"{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'noBylinesPolicy': 'http://www.bbc.co.uk/news/help-41670342#authorexpertise', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",N/A,N/A,"Will AI kill developing world growth?17 April 2019ShareGetty ImagesCould AI mean fewer opportunities for work in Africa?Artificial intelligence (AI) could displace millions of jobs in the future, damaging growth in developing regions such as Africa, says Ian Goldin, professor of globalisation and development at Oxford University.I have spent my career in international development, and in recent years have established a research group at Oxford University looking at the impact of disruptive technologies on developing economies. Perhaps the most important question we have looked at is whether AI will pose a threat - or provide new opportunities - for developing regions such as Africa. Optimists say that such places could use rapidly advancing AI systems to boost productivity and leapfrog ahead.Getty ImagesAutomated systems are already getting higher customer satisfaction ratings than people in call centresBut I am becoming increasingly concerned that AI will, in fact, block the traditional growth path by replacing low-wage jobs with robots. As Kai-Fu Lee, a Beijing-based venture capitalist who invests in artificial intelligence, tells us, AI is potentially the most revolutionary technology to emerge this century. It is also, along with the associated technologies of machine learning and robotics, advancing at breakneck speed. Already AI has the capacity to replace many work tasks that are rules-based and repetitive, and which do not require great dexterity or empathy.  In developed economies, for instance, robots have replaced well over half of the jobs in the car and related industries in recent decades. Getty ImagesMany jobs in the car industry have been displaced by robotsAutomated systems are already getting higher customer satisfaction ratings than people in call centres, threatening a key source of jobs in many countries. Similarly, AI enabled systems are leading to significant job losses in back-office administrative functions in banking, health, insurance and accounting. These are roles that had in recent years been outsourced to developing countries such as India, Vietnam, South Africa and Morocco.Jobs at risk?According to our research at Oxford, about 40% of jobs in Europe are vulnerable to AI over the coming decades, almost half of jobs in the USA, and an even greater share in developing countries.  Some argue that AI will create as many new jobs as those lost to robots, and that we shouldn't worry too much. But I believe that those new jobs will be concentrated in certain parts of the developed world, and that the developing world will miss out.Global TradeMore from the BBC's series taking an international perspective on trade:Why India is one of world's most protectionist countriesUruguay: The world’s marijuana pioneer Soft Brexit: What are the options?What happens if Trump closes the border?This matters most acutely in poorer nations that have used their relatively low-cost labour force as a first stage in catching up with the developed economies, examples being China, Thailand and Vietnam. Most of the jobs at threat in such places would be of the semi-skilled variety. But the fact that poor countries also tend to suffer shortages of highly skilled labour could further undermine their competitiveness. Getty ImagesIncomes have soared in tech hubs like San FranciscoThe development of supplementary technologies will add to the challenge. 3D printing, will combine with AI to allow consumers in rich countries to manufacture individually customised clothes, shoes, devices and other products, by themselves, much closer to home. The rise of such production could mean that the age of outsourcing production to developing countries is drawing to a close. Guy Ryder, director general of the UN's International Labour Organisation, highlights how the politics of protectionism will accelerate this. The demand to repatriate manufacturing to advanced countries has never been higher, although it is not jobs but AI and robotic processes that are coming home. Growing inequalityAs technology plays an increasingly dominant role in the global economy, the parts of the planet driving technological development stand to gain even more power. Just look at the concentration of wealth and incomes we have seen in places such as Silicon Valley.This trend could be replicated globally, worsening inequality. Due to the difficult to measure and cross-border nature of the digital economy, government tax revenues have been undermined, reducing investment in infrastructure, health and education. Getty ImagesA handful of big companies have come to dominate the tech industryThe tech industry also sucks up talent from around the globe, leaving shortages of human capital in some countries. All economies now require highly skilled workers to work in areas like AI, but these globetrotting individuals tend to prefer living in safe and developed cities that offer the best career opportunities.  With some notable exceptions - such as Bangalore in India - poorer countries will find it harder to attract and retain such workers, leaving them even more vulnerable. This concentration effect is not just evident in terms of location, but among companies themselves too. For example, just a handful of firms, based mainly in the US and China, now dominate AI, meaning that even European and Japanese businesses struggle to compete.A silver lining?Is all lost? Perhaps not. New firms are emerging that aim to use AI to boost growth and productivity in developing economies. They are also allowing citizens to access education, health, employment and other opportunities. One such company is M-Pesa, a mobile phone-based money transfer service, whose platform is used by more than 60% of Kenyans. M-Tiba, another Kenyan app, uses similar technology to deliver health services to more than four million people. Getty ImagesMoney transfer app M-Pesa is used by more than 60% of KenyansSome experts believe that AI could yield the same disruptive benefits as mobile phone technology in the developing world, helping to overcome the absence of infrastructure that contributes to low incomes and stalled development. Recent reports from the Pathways for Prosperity Commission and the World Bank similarly argue that AI and the digital economy could provide education, as well as jobs and incomes for people in poor countries, including those in isolated rural areas. However, it's early days for many of these companies, and it's not yet clear if they will succeed. It's also unclear whether the positive experiences in a handful of countries such as Kenya can be replicated elsewhere, and whether the positives outweigh the threats, not least in terms of lost jobs, tax revenues and rising inequality. The clock is ticking and the risks posed by AI to development have never been higher. Policymakers everywhere should be listening carefully and thinking hard about how to respond. Ian Goldin is professor of globalisation and development at Oxford University. His  BBC World Service documentary, Will AI Kill Development, is available on the BBC iPlayer. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS90ZWNobm9sb2d5LzIwMTkvYXByLzE2L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWxhY2stZGl2ZXJzaXR5LW5ldy15b3JrLXVuaXZlcnNpdHktc3R1ZHnSAXNodHRwczovL2FtcC50aGVndWFyZGlhbi5jb20vdGVjaG5vbG9neS8yMDE5L2Fwci8xNi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1sYWNrLWRpdmVyc2l0eS1uZXcteW9yay11bml2ZXJzaXR5LXN0dWR5?oc=5,"'Disastrous' lack of diversity in AI industry perpetuates bias, study finds - The Guardian",2019-04-16,The Guardian,https://www.theguardian.com,Report says an overwhelmingly white and male field has reached ‘a moment of reckoning’ over discriminatory systems,N/A,Report says an overwhelmingly white and male field has reached ‘a moment of reckoning’ over discriminatory systems,N/A,,,,,,,,,,,,Technology,N/A," Biased AI systems can be largely attributed to the lack of diversity among those who design and build them, the report said. Photograph: Jens Schlüter/EPAView image in fullscreenBiased AI systems can be largely attributed to the lack of diversity among those who design and build them, the report said. Photograph: Jens Schlüter/EPAArtificial intelligence (AI) This article is more than 5 years old'Disastrous' lack of diversity in AI industry perpetuates bias, study findsThis article is more than 5 years oldReport says an overwhelmingly white and male field has reached ‘a moment of reckoning’ over discriminatory systemsKari Paul in San FranciscoTue 16 Apr 2019 20.47 EDTFirst published on Tue 16 Apr 2019 20.28 EDTShareLack of diversity in the artificial intelligence field has reached “a moment of reckoning”, according to new findings published by a New York University research center. A “diversity disaster” has contributed to flawed systems that perpetuate gender and racial biases found the survey, published by the AI Now Institute, of more than 150 studies and reports.The AI field, which is overwhelmingly white and male, is at risk of replicating or perpetuating historical biases and power imbalances, the report said. Examples cited include image recognition services making offensive classifications of minorities, chatbots adopting hate speech, and Amazon technology failing to recognize users with darker skin colors. The biases of systems built by the AI industry can be largely attributed to the lack of diversity within the field itself, the report said.'Bias deep inside the code': the problem with AI 'ethics' in Silicon ValleyRead more“The industry has to acknowledge the gravity of the situation and admit that its existing methods have failed to address these problems,” Kate Crawford, an author on the report said. “The use of AI systems for the classification, detection, and prediction of race and gender is in urgent need of re-evaluation.”More than 80% of AI professors are men, and only 15% of AI researchers at Facebook and 10% of AI researchers at Google are women, the report said. The makeup of the AI field is reflective of “a larger problem across computer science, Stem fields, and even more broadly, society as a whole”, said Danaë Metaxa, a PhD candidate and researcher at Stanford focused on issues of internet and democracy. Women comprised only 24% of the field of computer and information sciences in 2015, according to the National Science Board. Only 2.5% of Google’s workforce is black, while Facebook and Microsoft are each at 4%, and little data exists on trans workers or other gender minorities in the AI field.“The urgency behind this issue is increasing as AI becomes increasingly integrated into society,” Metaxa said. “Essentially, the lack of diversity in AI is concentrating an increasingly large amount of power and capital in the hands of a select subset of people.”The use of AI systems for the classification, detection, and prediction of race and gender is in urgent need of re-evaluationKate Crawford, report authorVenture capital funding for AI startups reached record levels in 2018, increasing 72% compared to 2017 to $9.33bn in funding. Active AI startups in the US increased 113% from 2015 to 2018. As more money and resources are invested into AI, companies have the opportunity to address the crisis as it unfolds, said Tess Posner, the chief executive officer of AI4ALL, a not-for-profit that works to increase diversity in the AI field. This lack of diversity must be addressed before AI reaches a “tipping point”, she said.“Every day that goes by it gets more difficult to solve the problem,” she said. “Right now we are in an exciting moment where we can make a difference before we see how much more complicated it can get later.”The report released on Tuesday cautioned against addressing diversity in the tech industry by fixing the “pipeline” problem, or the makeup of who is hired, alone. Men currently make up 71% of the applicant pool for AI jobs in the US, according to the 2018 AI Index, an independent report on the industry released annually. The AI institute suggested additional measures, including publishing compensation levels for workers publicly, sharing harassment and discrimination transparency reports, and changing hiring practices to increase the number of underrepresented groups at all levels.Google disbanded an artificial intelligence ethics council meant to oversee such issues just one week after announcing it in March. The Advanced Technology External Advisory Council (ATEAC) was attracted backlash inside and outside the company after it appointed the anti-LGBT advocate Kay Coles James.Posner noted that additional efforts to increase transparency around how algorithms are built and how they work may be necessary to fix the diversity problems in AI. This month, the US senators Cory Booker and Ron Wyden introduced the Algorithmic Accountability Act, a bill that would require algorithms used by companies that make more than $50m per year or hold information on at least 1 million users to be evaluated for biases.“The core of the problem is whether market forces are going to be sufficient for this to be fixed,” Posner said. “It’s going to take effort at all stages of AI and take change at cultural and procedural levels to solve this.”Explore more on these topicsArtificial intelligence (AI)ComputingRaceGenderSilicon ValleynewsShareReuse this contentMost viewedTenacious D Australian tour date postponed after comment about Trump shootingNight owls’ cognitive function ‘superior’ to early risers, study suggestsMy sausage-like fingers are not sexy. But they have given me one incredible talentZoe WilliamsTeamsters union president calls Trump ‘tough SOB’ in unprecedented speech at RNCNorth Korea diplomat flees to South in highest ranking envoy defection since 2016",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDE5LzQvMTYvMTg0MTA1MDEvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWktZGl2ZXJzaXR5LXJlcG9ydC1mYWNpYWwtcmVjb2duaXRpb27SAQA?oc=5,"The artificial intelligence field is too white and too male, researchers say - The Verge",2019-04-16,The Verge,https://www.theverge.com,"The artificial intelligence industry is facing a diversity crisis, researchers from the AI Now Institute say in a report, raising key questions about the direction of the field.",N/A,A new report explores AI’s “diversity crisis.”,N/A,http://schema.org/,NewsArticle,https://www.theverge.com/2019/4/16/18410501/artificial-intelligence-ai-diversity-report-facial-recognition,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",2019-04-17T00:00:00.000Z,2019-04-17T00:00:00.000Z,"The artificial intelligence field is too white and too male, researchers say","[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/7KHwWJRVhC-l6uxcigp_ZFr4w54=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292777/acastro_181017_1777_brain_ai_0001.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/hiYD-EfwLyYLJHdSfTFlpQ2eeAg=/0x0:2040x1360/1400x1050/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292777/acastro_181017_1777_brain_ai_0001.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/13zJXP3eVUA4HZ4OCGxXTxsxfDw=/0x0:2040x1360/1400x1400/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292777/acastro_181017_1777_brain_ai_0001.jpg', 'width': 1400, 'height': 1400}]",https://cdn.vox-cdn.com/thumbor/7KHwWJRVhC-l6uxcigp_ZFr4w54=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292777/acastro_181017_1777_brain_ai_0001.jpg,,"[{'@type': 'Person', 'name': 'Colin Lecher', 'url': 'https://www.theverge.com/authors/colin-lecher'}]",N/A,N/A,"Tech/US & World/PolicyThe artificial intelligence field is too white and too male, researchers sayThe artificial intelligence field is too white and too male, researchers say / A new report explores AI’s ‘diversity crisis’By  Colin Lecher Apr 16, 2019, 8:00 PM EDTShare this story0 Comments / 0 New Illustration by Alex Castro / The VergeThe artificial intelligence industry is facing a “diversity crisis,” researchers from the AI Now Institute said in a report released today, raising key questions about the direction of the field.Women and people of color are deeply underrepresented, the report found, noting studies finding that about 80 percent of AI professors are men, while just 15 percent of AI research staff at Facebook and 10 percent at Google are women. People of color are also sidelined, making up only a fraction of staff at major tech companies. The result is a workforce frequently driven by white and male perspectives, building tools that often affect other groups of people. “This is not the diversity of people that are being affected by these systems,” AI Now Institute co-director Meredith Whittaker says. Worse, plans to improve the problem by fixing the “pipeline” of potential job candidates has largely failed. “Despite many decades of ‘pipeline studies’ that assess the flow of diverse job candidates from school to industry, there has been no substantial progress in diversity in the AI industry,” the researchers write. “We need to know that these systems are safe as well as fair.”The researchers make some suggestions for improving the problem. Companies, they say, could improve transparency by publishing more data on compensation, broken down by race and gender, and by publishing harassment and discrimination transparency reports.Diversity, while a hurdle across the tech industry, presents specific dangers in AI, where potentially biased technology, like facial recognition, can disproportionately affect historically marginalized groups. Tools like a program that scans faces to determine sexuality, introduced in 2017, echo injustices of the past, the researchers write. Rigorous testing is needed. But more than that, the makers of AI tools have to be willing to not build the riskiest projects. “We need to know that these systems are safe as well as fair,” AI Now Institute co-director Kate Crawford says. Tech industry employees have taken a stand on some major AI issues, pressing their companies to drop or review the use of sensitive tools that could hurt vulnerable groups. Workers at Amazon have questioned executives about the company’s facial recognition product. Recently, Google workers pushed back against an AI review board that included the president of the Heritage Foundation, noting the group’s history of lobbying against LGBTQ rights issues. The company soon dissolved the board entirely. “The diversity crisis in AI is well-documented and wide-reaching,” the researchers conclude. “It can be seen in unequal workplaces throughout industry and in academia, in the disparities in hiring and promotion, in the AI technologies that reflect and amplify biased stereotypes, and in the resurfacing of biological determinism in automated systems.” Comments0 Comments / 0 NewFeatured Videos From The VergeApple and OpenAI make a deal | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge's Nilay Patel, Alex Cranz, and David Pierce discuss takeaways from WWDC, this week's gadget news, and Elon Musk dropping his lawsuit against OpenAI.Most PopularMost PopularIt’s never been easier for the cops to break into your phoneThe FBI says it has ‘gained access’ to the Trump rally shooter’s phoneGoogle is reportedly planning its biggest startup acquisition everThe Google Pixel 9 just leaked againFBI is working to break into the phone of the Trump rally shooterVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From","The artificial intelligence industry is facing a “diversity crisis,” researchers from the AI Now Institute said in a report released today, raising key questions about the direction of the field.

Women and people of color are deeply underrepresented, the report found, noting studies finding that about 80 percent of AI professors are men, while just 15 percent of AI research staff at Facebook and 10 percent at Google are women. People of color are also sidelined, making up only a fraction of staff at major tech companies. The result is a workforce frequently driven by white and male perspectives, building tools that often affect other groups of people. “This is not the diversity of people that are being affected by these systems,” AI Now Institute co-director Meredith Whittaker says. 

Worse, plans to improve the problem by fixing the “pipeline” of potential job candidates has largely failed. “Despite many decades of ‘pipeline studies’ that assess the flow of diverse job candidates from school to industry, there has been no substantial progress in diversity in the AI industry,” the researchers write. 

""“We need to know that these systems are safe as well as fair.”""

The researchers make some suggestions for improving the problem. Companies, they say, could improve transparency by publishing more data on compensation, broken down by race and gender, and by publishing harassment and discrimination transparency reports.

Diversity, while a hurdle across the tech industry, presents specific dangers in AI, where potentially biased technology, like facial recognition, can disproportionately affect historically marginalized groups. Tools like a program that scans faces to determine sexuality, introduced in 2017, echo injustices of the past, the researchers write. Rigorous testing is needed. But more than that, the makers of AI tools have to be willing to not build the riskiest projects. “We need to know that these systems are safe as well as fair,” AI Now Institute co-director Kate Crawford says. 

Tech industry employees have taken a stand on some major AI issues, pressing their companies to drop or review the use of sensitive tools that could hurt vulnerable groups. Workers at Amazon have questioned executives about the company’s facial recognition product. Recently, Google workers pushed back against an AI review board that included the president of the Heritage Foundation, noting the group’s history of lobbying against LGBTQ rights issues. The company soon dissolved the board entirely. 

“The diversity crisis in AI is well-documented and wide-reaching,” the researchers conclude. “It can be seen in unequal workplaces throughout industry and in academia, in the disparities in hiring and promotion, in the AI technologies that reflect and amplify biased stereotypes, and in the resurfacing of biological determinism in automated systems.”

 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmFydHN5Lm5ldC9hcnRpY2xlL2FydHN5LWVkaXRvcmlhbC1waGlsbGlwcy1zZWxsaW5nLXNjdWxwdHVyZS1nZW5lcmF0ZWQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2XSAQA?oc=5,Phillips Is Selling an Artificial Intelligence Sculpture by Ben Snell - Artsy,2019-04-17,Artsy,https://www.artsy.net,"The sculpture, by artist Ben Snell, is a fluid, anthropomorphic form created from pulverized computer parts.",news,"The sculpture, by artist Ben Snell, is a fluid, anthropomorphic form created from pulverized computer parts.","The sculpture, by artist Ben Snell, is a fluid, anthropomorphic form created from pulverized computer parts.",,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3LmNhbXBhaWduYXNpYS5jb20vYXJ0aWNsZS93ZS1tdXN0bnQtbGV0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW1ha2UtdXMtZHVtYi80NTExMzfSAQA?oc=5,We mustn’t let artificial intelligence make us dumb | Marketing - Campaign Asia,2019-04-17,Campaign Asia,https://www.campaignasia.com,,"['Marketing', 'Analysis', 'Opinions', 'ai', 'artificial', 'intelligence', 'marketing', 'efficiency', 'carma', 'asia', 'andrew nicholls']","While AI continues to change how we work, Andrew Nicholls at Carma Asia says the need for human intelligence to find meaning in these advances is more important than ever.","While AI continues to change how we work, Andrew Nicholls at Carma Asia says the need for human intelligence to find meaning in these advances is more important than ever.",https://schema.org,Organization,https://www.campaignasia.com/,"{'@type': 'Organization', 'name': 'Campaign Asia', 'url': 'https://www.campaignasia.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.i.haymarketmedia.asia/?n=%2fcampaign-asia%2fseo%2fCampaignAsia-publisherLogo.png', 'width': 600, 'height': 60}}",2019-04-17T02:47:00+00:00,2019-04-17T02:47:00+00:00,We mustn’t let artificial intelligence make us dumb,"['https://cdn.i.haymarketmedia.asia/?n=campaign-asia%2fcontent%2fno-image.jpg&h=900&w=900&q=75&v=20170226&c=1', 'https://cdn.i.haymarketmedia.asia/?n=campaign-asia%2fcontent%2fno-image.jpg&h=900&w=1200&q=75&v=20170226&c=1', 'https://cdn.i.haymarketmedia.asia/?n=campaign-asia%2fcontent%2fno-image.jpg&h=675&w=1200&q=75&v=20170226&c=1']",https://cdn.i.haymarketmedia.asia/?n=campaign-asia%2fcontent%2fno-image.jpg&h=675&w=1200&q=75&v=20170226&c=1,True,"[{'@type': 'Person', 'url': 'https://www.campaignasia.com/author/andrew-nicholls/1083218', 'name': 'Andrew Nicholls'}]",Marketing,N/A,N/A,,"['Marketing', 'Analysis', 'Opinions']","['https://www.campaignasia.com/category/marketing/442', 'https://www.campaignasia.com/category/analysis/724', 'https://www.campaignasia.com/category/opinions/719']",False,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '#articleBody .accessMessage'}",#campaignasia/logo,Campaign Asia,https://cdn.i.haymarketmedia.asia/?n=%2fcampaign-asia%2fseo%2fCAP-icon.png&h=112&w=112&q=100&v=20170226&c=1,"['https://www.facebook.com/CampaignAPAC/', 'https://twitter.com/CampaignAsia', 'https://www.linkedin.com/company/campaign-asia-pacific', None]","{'@type': 'ContactPoint', 'telephone': '+852 2122 5222', 'email': 'customerservice@campaignasia.com', 'contactType': 'customer service'}","{'@type': 'Organization', 'name': 'Haymarket', 'url': 'https://www.haymarket.com', 'logo': 'https://cdn.i.haymarketmedia.asia/?n=%2fshared%2fseo%2fHaymarket-112x112.png&h=112&w=112&q=100&v=20170226&c=1', 'sameAs': [None, 'https://twitter.com/haymarket_media/', 'https://www.linkedin.com/company/haymarket-media-group/', 'https://www.instagram.com/haymarket.media/']}",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiNGh0dHBzOi8vdGltZS5jb20vNTU3NDE1NC9rYWktZnUtbGVlLXRpbWUtMTAwLXN1bW1pdC_SAQA?oc=5,Kai-Fu Lee on Making A.I. Work for Humans at Time 100 Summit - TIME,2019-04-19,TIME,https://time.com,Kai-Fu Lee on How We Can Use AI,N/A,Despite the disruptions and risks that it brings,Despite the disruptions and risks that it brings,https://schema.org,VideoObject,,,,,,,https://cdn.jwplayer.com/v2/media/jTzBLNZ5/poster.jpg?width=720,,,N/A,N/A,"By Patrick Lucas AustinApril 19, 2019 11:49 AM EDTAI expert and Sinovation Ventures CEO Dr. Kai-Fu Lee took the stage at the TIME 100 Summit in New York on Tuesday to discuss the current state of artificial intelligence, arguing that it will do as much for society’s well-being as electricity. In his talk, Lee also touched on how governments and businesses can take advantage of artificial intelligence to improve nearly everything from infrastructure to the relationship between individuals and the companies handling their data. Lee showcased examples of AI applications, like warehouse machines that use computer vision to move and sort boxes, and an AI-powered rapper capable of generating rhymes based on any topic. Lee also highlighted an AI technique known as deep learning, and how it could be and has been used to generate false information, demonstrating with a fabricated audio clip of President Donald Trump. New machine learning techniques, like generative adversarial networks, have created real images of nonexistent people, as well as legit-looking news stories full of false information.Artificial intelligence generating fabricated audio, images, or stories is a major concern, especially when combined with the ongoing rise of fake news. “What’s more, biases inherent in machine learning software will continue to perpetuate an inequity between minorities and underrepresented communities,” said Lee, a comment addressing lack of training data for underrepresented communities, leading to a marked decrease in accuracy and effectiveness for those users. He also showed how AI is capable of providing a positive impact in China, where teachers in impoverished areas of the country are able to take advantage of the technology to grade tests and assign homework. “It’s an experience that will break down the barrier to education for those who need it,” said Lee. (Of course, AI is also being used in China and elsewhere for facial recognition security software that some are concerned can violate citizens’ rights.) Privacy, a hot-button issue in a time when user data gathered by major corporations is mismanaged or abused, is also on the list of problems artificial intelligence can tackle, Lee argues. “Certainly regulations are needed to prevent the most egregious misuse of data,” said Lee. But at the same time, Lee thinks technologists will eventually develop AI-powered tools to protect users while giving them the freedom to choose their level of privacy. “We can imagine a slider that gives each individual a choice, that gives an individual more security or more convenience,” said Lee, equating the idea to companies in the past that once created anti-virus software for computers.He also discussed job displacement occurring alongside the proliferation of artificial intelligence. “I think governments need to think about education, training, and changing the society’s belief about compassion and work,” said Lee, who thinks redesigned vocational programs and a focus on “compassionate work” should be considered when it comes to training a workforce.As for jobs, Lee isn’t shy about the coming disruption thanks to artificial intelligence. Customer service, telemarketing, and accounting jobs will all be subject to “serious job displacement issues,” according to Lee, and finding new careers for workers in the field will require difficult retraining. But Lee thinks, like electricity, AI’s potential to revolutionize every aspect of our daily life is more tangible than theoretical. “AI is here to stay, and i think we need to rise up to the occasion and embrace it.”",,,,,,,Kai-Fu Lee on How We Can Use AI,,,,,"{'@type': 'SeekToAction', 'target': 'https://time.com/5574154/kai-fu-lee-time-100-summit/?jw_start={seek_to_second_number}', 'startOffset-input': 'required name=seek_to_second_number'}",2019-04-23T18:06:26.000Z,https://cdn.jwplayer.com/manifests/jTzBLNZ5.m3u8,https://time.com/5574154/kai-fu-lee-time-100-summit/,PT2M35S,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3LmNic25ld3MuY29tL25ld3MvYWktYmlhcy1wcm9ibGVtLXRlY2hzLXdoaXRlLW1hbGUtd29ya2ZvcmNlL9IBTGh0dHBzOi8vd3d3LmNic25ld3MuY29tL2FtcC9uZXdzL2FpLWJpYXMtcHJvYmxlbS10ZWNocy13aGl0ZS1tYWxlLXdvcmtmb3JjZS8?oc=5,AI's bias problem: Tech's white male workforce - CBS News,2019-04-17,CBS News,https://www.cbsnews.com,The AI products these coders build tend to discriminate against some types of people and work to others' advantage,['New York University'],The AI products these coders build tend to discriminate against some types of people and work to others' advantage,The AI products these coders build tend to discriminate against some types of people and work to others' advantage,https://schema.org,BreadcrumbList,https://www.cbsnews.com/news/ai-bias-problem-techs-white-male-workforce/,"{'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}",2019-04-17T16:29:18-0400,2019-04-17T16:29:18-0400,AI's bias problem: Tech's white male workforce,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets2.cbsnewsstatic.com/hub/i/r/2019/04/17/0c080814-73ca-442a-a731-1db1401d94cb/thumbnail/1200x630/3716c18151959aa6f7000289cc07eb4a/rts21mgl.jpg?v=5710b2ed1cee1bdfd30cb9c02455b43d'}",https://assets2.cbsnewsstatic.com/hub/i/r/2019/04/17/0c080814-73ca-442a-a731-1db1401d94cb/thumbnail/1200x630/3716c18151959aa6f7000289cc07eb4a/rts21mgl.jpg?v=5710b2ed1cee1bdfd30cb9c02455b43d,"{'@type': 'WebPage', '@id': 'https://www.cbsnews.com/news/ai-bias-problem-techs-white-male-workforce/'}","[{'@type': 'Person', 'familyName': 'Picchi', 'givenName': 'Aimee', 'name': 'Aimee Picchi', 'jobTitle': 'Associate Managing Editor, MoneyWatch', 'description': ""Aimee Picchi is associate managing editor for CBS MoneyWatch, where she covers business and personal finance. She previously worked at Bloomberg News and has been published by national news outlets including USA Today and Consumer Reports. Aimee frequently writes about retirement, and has been a National Press Foundation fellow for reporting on retirement and Columbia University's Age Boom Academy. She's also the editor of the Institutional Investor book &quot;Cultivating the Affluent II,&quot; with noted wealth consultant Russ Alan Prince."", 'sameAs': 'https://x.com/@aimeepicchi', 'knowsAbout': ['Economy', 'Product Recall', 'Finance', 'Stock Market', 'Money'], 'workLocation': {'@type': 'Place', 'name': 'New York'}, 'affiliation': {'@type': 'Organization', 'name': 'CBS News'}, 'worksFor': [{'@type': 'Organization', 'name': 'CBS News'}], 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}]",N/A,N/A,"


MoneyWatch

How tech's white male workforce feeds bias into AI






    By
                        
                      Aimee Picchi


April 17, 2019 / 4:29 PM EDT
          / MoneyWatch
        














About 80 percent of AI professors are men, while women make up just 15 percent of AI research staff at Facebook and 10 percent at Google.The percentage is even lower for black employees at major tech firms, with just 2.5 percent at Google and 4 percent at Facebook and Microsoft.Bias seeps through when AI programs are constructed by those mostly white male workers who reinforce ""a narrow idea of the 'normal' person,"" a new study said.The technology industry's mostly white male workforce of coders is creating a ""diversity crisis,"" with bias seeping into products like facial recognition programs and chatbots, according to a new report from New York University's AI Now Institute. The report highlights how a workforce gender imbalance at major tech companies such as Google, Facebook and Microsoft is helping perpetuate bias within artificial intelligence.AI is used in products ranging from facial recognition to chatbots. But only 15 percent of AI research staffers at Facebook are women, and for Google it's even lower, at 10 percent, the report noted. This underscores what the study's authors say is the importance of a diverse workforce that reflects a diverse society. They argue that the tech industry's mostly white male legions of AI coders are linked to bias within technology products. Remedying the issues, they said, will require a broader approach to diversity, including hiring from colleges other than elite campuses and creating greater transparency in AI products. 






""To date, the diversity problems of the AI industry and the issues of bias in the systems it builds have tended to be considered separately,"" authors Sarah Myers West, Meredith Whittaker and Kate Crawford wrote. ""But we suggest that these are two versions of the same problem: issues of discrimination in the workforce and in system building are deeply intertwined.""""Narrow idea of the 'normal' person""It's not only that AI may discriminate against some types of people, but that it ""works to the advantage of others, reinforcing a narrow idea of the 'normal' person,"" the researchers wrote. 






Future of artificial intelligence becomes key topic at World Economic Forum
04:03

The report highlights several ways AI programs have created harmful circumstances to groups that already suffer from bias. Among them are: An Amazon AI hiring tool that scanned resumes from applicants relied on previous hires' resumes to set standards for ideal hires. However, the AI started downgrading applicants who attended women's colleges or who included the word ""women's"" in their resumes.Amazon's Rekognition facial analysis program had difficulty identifying dark-skinned women. According to one report, the program misidentified them as men, although the program had no problem identifying men of any skin tone. ""Deep concern""New York University isn't the first to ring alarm bells over problems of bias within AI. Groups such as the MIT Technology Review and the ACLU have documented problematic outcomes that affect issues such as hiring and criminal sentencing. 


The problem stems from the deep-learning stage, when coders ""teach"" a program through training data, the MIT Technology Review noted. Programmers can add bias into the system by relying on data sets that don't accurately reflect the world, such as relying on facial images that include very few black people. Programmers can also add bias by deciding which attributes are important -- such as gender. If a company's previous hires were mostly men, the program may learn to exclude women, as in the case of Amazon's hiring program, reinforcing a biased pattern of hiring. ""The use of AI systems for the classification, detection, and prediction of race and gender is in urgent need of re-evaluation,"" the New York University researchers noted. ""The commercial deployment of these tools is cause for deep concern.""


More from CBS News






 Gold prices are near a new record high. 3 savvy moves to make now







 Jurors in Sen. Bob Menendez's bribery trial in deliberations for 2nd day







 Is a home equity sharing agreement a good idea? Here's what experts say







 Mortgage rates are still falling. Here are 5 big moves to make now







 These are the 5 best strategies for investing in CDs right now, experts say




In:
          New York University

Aimee Picchi


Aimee Picchi is the associate managing editor for CBS MoneyWatch, where she covers business and personal finance. She previously worked at Bloomberg News and has written for national news outlets including USA Today and Consumer Reports.



                      Twitter
                    





© 2019 CBS Interactive Inc. All Rights Reserved.

","About 80 percent of AI professors are men, while women make up just 15 percent of AI research staff at Facebook and 10 percent at Google.The percentage is even lower for black employees at major tech firms, with just 2.5 percent at Google and 4 percent at Facebook and Microsoft.Bias seeps through when AI programs are constructed by those mostly white male workers who reinforce ""a narrow idea of the 'normal' person,"" a new study said.The technology industry's mostly white male workforce of coders is creating a ""diversity crisis,"" with bias seeping into products like facial recognition programs and chatbots, according to a new report from New York University's AI Now Institute. The report highlights how a workforce gender imbalance at major tech companies such as Google, Facebook and Microsoft is helping perpetuate bias within artificial intelligence.AI is used in products ranging from facial recognition to chatbots. But only 15 percent of AI research staffers at Facebook are women, and for Google it's even lower, at 10 percent, the report noted. This underscores what the study's authors say is the importance of a diverse workforce that reflects a diverse society. They argue that the tech industry's mostly white male legions of AI coders are linked to bias within technology products. Remedying the issues, they said, will require a broader approach to diversity, including hiring from colleges other than elite campuses and creating greater transparency in AI products.""To date, the diversity problems of the AI industry and the issues of bias in the systems it builds have tended to be considered separately,"" authors Sarah Myers West, Meredith Whittaker and Kate Crawford wrote. ""But we suggest that these are two versions of the same problem: issues of discrimination in the workforce and in system building are deeply intertwined.""""Narrow idea of the 'normal' person""It's not only that AI may discriminate against some types of people, but that it ""works to the advantage of others, reinforcing a narrow idea of the 'normal' person,"" the researchers wrote. The report highlights several ways AI programs have created harmful circumstances to groups that already suffer from bias. Among them are: An Amazon AI hiring tool that scanned resumes from applicants relied on previous hires' resumes to set standards for ideal hires. However, the AI started downgrading applicants who attended women's colleges or who included the word ""women's"" in their resumes.Amazon's Rekognition facial analysis program had difficulty identifying dark-skinned women. According to one report, the program misidentified them as men, although the program had no problem identifying men of any skin tone. ""Deep concern""New York University isn't the first to ring alarm bells over problems of bias within AI. Groups such as the MIT Technology Review and the ACLU have documented problematic outcomes that affect issues such as hiring and criminal sentencing. The problem stems from the deep-learning stage, when coders ""teach"" a program through training data, the MIT Technology Review noted. Programmers can add bias into the system by relying on data sets that don't accurately reflect the world, such as relying on facial images that include very few black people. Programmers can also add bias by deciding which attributes are important -- such as gender. If a company's previous hires were mostly men, the program may learn to exclude women, as in the case of Amazon's hiring program, reinforcing a biased pattern of hiring. ""The use of AI systems for the classification, detection, and prediction of race and gender is in urgent need of re-evaluation,"" the New York University researchers noted. ""The commercial deployment of these tools is cause for deep concern.""",['MoneyWatch'],,,,https://www.cbsnews.com/,How tech's white male workforce feeds bias into AI,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}]","['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News']",,"{'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}",,,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets2.cbsnewsstatic.com/hub/i/r/2019/04/17/0c080814-73ca-442a-a731-1db1401d94cb/thumbnail/1200x630/3716c18151959aa6f7000289cc07eb4a/rts21mgl.jpg?v=5710b2ed1cee1bdfd30cb9c02455b43d'}",How tech's white male workforce feeds bias into AI,1927-09-18,https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735,https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428,https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d,https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963,https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca,https://www.paramount.com/company-history,https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857,https://www.cbsnews.com/news/cbs-news-publishing-principles/,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.cbsnews.com/', '@type': 'WebPage', '@name': 'CBSNews.com'}}, {'@type': 'ListItem', 'position': 2, 'name': 'MoneyWatch', 'item': {'@id': 'https://www.cbsnews.com/moneywatch', '@type': 'CollectionPage', '@name': 'MoneyWatch'}}, {'@type': 'ListItem', 'position': 3, 'name': ""How tech's white male workforce feeds bias into AI"", 'item': {'@id': 'https://www.cbsnews.com/news/ai-bias-problem-techs-white-male-workforce/', '@name': ""How tech's white male workforce feeds bias into AI""}}]",,,,,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9uZXctd29ybGQtb3JkZXItb2YtdGhlLWFpLWVjb25vbXktYTlmYTQwMzc1YmE40gEA?oc=5,New World Order of the AI Economy | by Matt Vasey - Towards Data Science,2019-04-18,Towards Data Science,https://towardsdatascience.com,"In conjunction with other global trends, Artificial Intelligence is rapidly tearing down the old barriers to building new world orders. As a result the next century will be dominated by countries…",N/A,The New World Order will be based on the AI Economy — What will determine the winners and losers?,The New World Order will be based on the AI Economy — What will determine the winners and losers?,http://schema.org,NewsArticle,https://towardsdatascience.com/new-world-order-of-the-ai-economy-a9fa40375ba8,"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",2019-04-19T03:06:39.952Z,2022-03-30T20:31:30.119Z,New World Order of the AI Economy - Towards Data Science,['https://miro.medium.com/v2/resize:fit:1200/1*wi3nz_bwoMBfE71mSjd98A.jpeg'],,https://towardsdatascience.com/new-world-order-of-the-ai-economy-a9fa40375ba8,"{'@type': 'Person', 'name': 'Matt Vasey', 'url': 'https://towardsdatascience.com/@mvasey'}",N/A,N/A,"New World Order of the AI EconomyMatt Vasey·FollowPublished inTowards Data Science·5 min read·Apr 18, 2019502ListenShareIn conjunction with other global trends, Artificial Intelligence is rapidly tearing down the old barriers to building new world orders. As a result the next century will be dominated by countries that rapidly adapt to the new AI Economy. The assumptions that the next century will be the “Chinese Century” may be proved wrong if China cannot adapt to the AI Economy.The AI Economy is built on three pillars:AI Workforce: Labor pool with broad set of skills including AI researchers, AI implementors, and AI Literate workers adept with robotics and automationAI Infrastructure: Data sharing, algorithm exchange, labor mobility, and low-cost energy will be needed to support continued AI innovationAI Social Contract: Worker displacement will create significant resistance. Retraining, guaranteed income schemes, and other transition costs will be absorbed by leading countries adopting the AI EconomyPax Britannica (1815- 1914) — Map reproduction courtesy of the Norman B. Leventhal Map & Education CenterOld World Orders:Since the early 1800’s the world orders of Pax Britannica (1815–1914) , the American Century (1917–2017) and the emergence (or perhaps re-emergence) of the Chinese Century (2017 — present) have been driven by similar economic and political rules.1. Readily available and low-cost labor, energy, and raw materials2. Institutional and government support of industry providing access to capital, political stability, and international trade3. Continued innovation that drives marginal production costs down, worker productivity up, supporting increased living standardsSince 1800 rapid adoption of new technologies including the telegraph, steam power, electricity, assembly lines, automation and recently robotics have delivered early adopters with durable advantage and supremacy on the world stage.As China prepares to assume economic supremacy for the next century, perhaps the rules have changed. Importantly energy costs are rapidly moving towards “zero marginal cost” per Jeremy Rifkin (2015), and the increased diffusion of military and political power as Fareed Zakaria first outlined in his 2009 book “The Post American World” are reducing the barriers to new entrants to the super power game.The most fundamental rule change is the mainstream adoption of artificial intelligence (AI) and the realization of huge AI driven productivity gains in terms of automation, efficiency, and accuracy. AI and automation fundamentally change the economic foundation of the previous world orders.Digital Workers are robots that do repetitive tasks running as programs in the cloud or on desktop computers not entirely unlike the characters in the 1999 science fiction film “The Matrix”. This has been commonly known as Robotic Process Automation, but the new generation of digital workers are using computer vision, advanced machine learning to execute work at 100 times the speed of traditional human workersPhysical work is increasingly being done using industrial robots to replace human workers. Computer vision and robotics advances are rapidly shrinking the circle of things that can only be done by humans. Robot adoption is racing ahead, even in markets where low-cost labor is still abundantComplex decisions made with fuzzy facts have long been the domain of human subject matter experts whose organic neural network brains could contemplate all of the data and make the best split-second decisions. Today this advantage is narrowing, where deep learning systems consistently outperform humans in cognitive, vision, translation, signal processing, complex system analysis and a myriad of other tasksBuilding the AI Economy:First Priority: AI WorkforceThe demand for AI and robotics savvy workers already far outstrips the current supply. As the AI Economy ramps this impedance mismatch will become a gating factor for innovation. To avoid this we need to immediately make investments in adapting our workforce. China is already creating “AI Cities” and building this AI capability with full support of the Chinese government as Kai-Fu Lee outlines in his book “AI Superpowers: China, Silicon Valley and the New World Order” . Future leaders need to build this muscle with:Recruit and retain (in country) the best AI talent to universities to pursue research and support undergraduate AI education. Fund postgraduate research in AI with grants, challenges, and industry focused co-innovation programsBroaden science, engineering and mathematics undergraduate degree requirements to include core AI education and practical experienceFund robotics and mechatronic training programs technical and 2 year colleges coupled with tight collaboration with industry robotics providersChina is currently investing heavily in this area ranking #1 in AI research , #1 in AI patents, #1 in AI venture capital investment, #2 in the number of AI companies, and #2 in the largest AI talent pool per the “Center For a New American Security” paper Understanding China’s AI StrategySecond Priority: AI InfrastructureRecent news on AI has consistently focused on the privacy concerns and bias related to data gathering and usage. From personal data being gathered for training virtual assistants to AI gauging criminal intent of shoppers it is clear that any issues remain to be solved. China has taken an expedient approach to data gathering, and could use this access to leapfrog other global AI competitors.National data sharing programs are critical to building up the training sets needed to build the next generation of AI — the west will need to resolve privacy and ethics concerns quicklyOpen algorithm exchange as well as commercial algorithm exchange will be a critical success factor. IP laws will need to adapt to facilitate a flow of ideas and ML modelsLabor mobility, and low-cost energy will be needed to support continued AI innovationAlready we are seeing businesses form just to close these data gaps, as detailed in this IEEE article: IEEE Spectrum Article but these models present much commercial frictionThird Priority: AI Social Contract:Recent global political and economic conditions have heightened nationalism and immigration concerns around the world. This is in part due to the start of worker displacement from automation in the workplace. The leading AI Economics will address these social issues with an AI optimized social fabric or safety net to avoid political friction to changeRetraining and upskilling of middle aged workers combined with diversion of young workers from declining industries will be critical to continued successGuaranteed income schemes for workers that are unable reskill will ease resistance to change and maintain social order",,,,,,,New World Order of the AI Economy - Towards Data Science,,,,,,,,,,,,,,,,,,,,,,2019-04-19T03:06:39.952Z,a9fa40375ba8,['Matt Vasey'],,,,
https://news.google.com/rss/articles/CBMiIWh0dHBzOi8vd3d3LnBvcHNjaS5jb20vZ29vZ2xlLWFpL9IBAA?oc=5,How Google Aims To Dominate Artificial Intelligence - Popular Science,2019-04-16,Popular Science,https://www.popsci.com,"In November 2007, Google laid the groundwork to dominate the mobile market by releasing Android, an open ­source operating system for phones. Eight years later to the month, Android has an an 80 percent market share, and Google is using the same trick—this time with artificial intelligence.",N/A,"In November 2007, Google laid the groundwork to dominate the mobile market by releasing Android, an open ­source operating system for phones. Eight years later to the month, Android has an an 80 percent market share, and Google is using the same trick—this time with artificial intelligence.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"







In November 2007, Google laid the groundwork to dominate the mobile market by releasing Android, an open ­source operating system for phones. Eight years later to the month, Android has an an 80 percent market share, and Google is using the same trick—this time with artificial intelligence.
Today Google is announcing TensorFlow, its open ­source platform for machine learning, giving anyone a computer and internet connection (and casual background in deep learning algorithms) access to one of the most powerful machine learning platforms ever created. More than 50 Google products have adopted TensorFlow to harness deep learning (machine learning using deep neural networks) as a tool, from identifying you and your friends in the Photos app to refining its core search engine. Google has become a machine learning company. Now they’re taking what makes their services special, and giving it to the world.
Introducing TensorFlow, the Android of AI
TensorFlow is a library of files that allows researchers and computer scientists to build systems that break down data, like photos or voice recordings, and have the computer make future decisions based on that information. This is the basis of machine learning: computers understanding data, and then using it to make decisions. When scaled to be very complex, machine learning is a stab at making computers smarter. That’s the broader, and more ill-defined field of artificial intelligence. TensorFlow is extraordinary complex, because of its precision and speed in digesting and outputting data, and can unequivocally be placed in the realm of artificial intelligence tools.
Here are the nitty-gritty details: the TensorFlow system uses data flow graphs. In this system, data with multiple dimensions (values) are passed along from mathematical computation to mathematical computation. Those complex bits of data are called tensors. The math-y bits are called nodes, and the way the data changes from node to node tells the overall system relationships in the data. These tensors flow through the graph of nodes, and that’s where the name TensorFlow comes from.
Open-­sourcing TensorFlow allows researchers and even grad students the opportunity to work with professionally-built software, sure, but the real effect is the potential to inform every machine learning company’s research across the board. Now organizations of all sizes—from small startups to huge companies on par with Google—can take the TensorFlow system, adapt it to their own needs, and use it to compete directly against Google itself. More than anything, the release gives the world’s largest internet company authority in artificial intelligence.
Stanford computer science professor Christopher Manning was given TensorFlow a little more than three months ago, and his students had the opportunity to tinker with the system. After just a few weeks of using it himself, Manning decided that he’s going to implement it into his curriculum.
Besides Android, he also likens the platform to Gmail, Google’s ubiquitous email application. There are competitors, but Gmail is cleaner and makes more sense in most applications.
“It’s not that before this there weren’t any high level libraries available for deep learning,” Manning says. “But in general these other libraries are things by three academics and a grad student.”



While the others, most notably Torch and Theano, do have small groups updating them, it’s nothing like the full force of the developers working on Google’s machine learning infrastructure. Manning says that while TensorFlow is a huge gift to the community (one capable of reducing time spent optimizing the neural networks by 100 times), they might indirectly benefit from open­-sourcing their tools.
“A very small amount of companies have been trying to hire up a very large percentage of the talented people in artificial intelligence in general, and deep learning in particular,” Manning says. “Google is not a charity, I’m sure it’s also occurred to them that by ceding this, we will have a lot of Ph.D students who will be in universities and already liking Google deep learning tools.”
Jeff Dean, one of Google’s top engineers and one of the two people who could be listed as an author for TensorFlow (the other is Rajat Monga), is cautious about estimating the adoption in the community. He says that while it’s something Google has found immensely useful in their own work, the real test is whether the community will find it as capable. The idea is to provide a tool so the whole community will be able to go from not just ideas, but actual implementations of things more rapidly.
“We’re hoping, basically, to accelerate machine learning research and deployment,” Dean says. And while this is a big gift the community, the ideal scenario is that the community gives back, and shares what they’ve made with other researchers (and Google). “The machine learning community has been really good at polishing ideas, and that’s a really good thing, but it’s not the same thing as polishing working code associated with research ideas,” Dean says.








https://www.youtube.com/watch?v=oZikw5k_2FM
He also mentions that TensorFlow will help Google interns when they return back to their schools, because they can now access the once-proprietary systems on projects they might not have finished during their time at the company.
The TensorFlow system is a pretty complete package for an individual researcher. The system is a complete, standalone library associated with tools and an Apache 2.0 license, so it can be used in commercial settings. It can be compiled on desktops or laptops, or deployed on mobile (Android first, naturally, and then iOS to come later). It also comes with tutorials and documentation on how to modify and play with the platform.
Manning suggests that the ability to run deep learning algorithms on mobile devices will be an important factor that separates TensorFlow from other open-source systems.
For those who want to use the system as-is, Google is providing a version that researchers can start using right now (as pre-built binaries). There’s also an application programming interface (API), for software developers to train and control their TensorFlow models. And this isn’t a knockoff—it’s the literal system used in the Google app, and more than 50 other products.


Inside Google’s Artificial Intelligence Lab
Google is opening this platform to the world, which gives us an equal opportunity to peek in and see how the company thinks about developing machine learning systems.
Internally, Google has spent the last three years building a massive platform for artificial intelligence and now they’re unleashing it on the world. Although, Google would prefer you call it machine intelligence. They feel that the word artificial intelligence carries too many connotations, and fundamentally, they’re trying to create genuine intelligence—just in machines.
It’s the model that they’ve used within the company for years: where any engineer who wants to play with an artificial neural network can fork it off the system and tinker. That’s the kind of open structure that allows 100 teams within a company to build powerful machine learning techniques.
“Machine learning is a core, transformative way by which we’re re-thinking how we’re doing everything,” Google CEO Sundar Pichai said on the company’s earnings call in October 2015. “We are thoughtfully applying it across all our products, be it search, ads, YouTube, or Play. And we’re in early days, but you will see us — in a systematic way — apply machine learning in all these areas.”
Welcome to Google, where everything is AI and AI is everything
It’s difficult to lay out a concrete diagram of machine intelligence research at Google, because it’s always changing, and saturates nearly every team in the company.
Google’s VP of engineering, John Giannandrea, calls this an “embedded model.” I met him at one of the many sleek modern moderns at Google’s headquarters in sunny Mountain View, California, in the fall of 2015.
I was on a floor technically not open to the public, and when I was left unattended for a moment, an engineer came up to me, noticing I wasn’t wearing an employee badge. He asked who I was, and saying I was a writer didn’t smooth the situation over. Google prides itself on making its research open to the public, but work in the labs is kept under heavy wraps.

For me, Google’s embedded model meant a lot of walking. The Googleplex contains 3.5 million square feet of office space over about seven acres of land. Google staff ride bikes between buildings, which are surrounded by well-groomed parks where Googlers sit with laptops, undoubtedly grappling with complex computer science conundrums or playing Minecraft during their lunch break. Different teams work in different buildings, and embedded machine intelligence researchers switch buildings when they switch teams.
Inside, most of what I saw looks like a normal office building. There are cubicles, computers with loads of monitors, and people discussing work in hushed tones while glancing nervously towards the journalist. There are holes cut in the wall to catch a quick nap—you know, office things.


Organizationally, there’s a pool of researchers always working on general machine intelligence problems, and that work feeds back into Google’s core products, such as the Photos app, Voice Search, and Search itself. There are some projects that start as just something Google wants to get better at. Giannandrea suggests handwriting as an example.
“We, as a company, want to understand how people would write a word. So that’s something we would invest in forever, even if we didn’t have a product,” he says.
But because Google is so vast in its offerings, there’s usually a tool that can use each research element. (Handwriting ended up in Google Keep, the note-taking software.)

When that use is figured out, the researcher hops onto the product team to help with implementation. Product teams develop specific applications that we all use, like the Photos app or Google Translate.
In general research, the teams are divided by their area of interest. There’s a team focused on teaching computers to see, a team working to understand language, a team looking at better voice recognition, and so on.
“There’s no world in which Google doesn’t want to have better speech recognition, language translation, language understanding— so these frontiers of research in computer science are things we invest in all the time,” Giannandrea says.
There are more than 1000 researchers at Google working on these machine intelligence applications, constantly rotating between applied and theoretical research. Some of these researchers work on simpler problems that wouldn’t be considered artificial intelligence, in the strictest sense of the word, but are more statistical methods of prediction.
Google’s new parent company, Alphabet, doesn’t make a big impact on the way Google’s machine intelligence research will continue, according to Google spokesman Jason Freidenfelds. While the research team will stay within Google Proper, there won’t be any barriers from working with Life Sciences or Google [x] on machine learning applications.
The Voice of the future
A rising star in Google’s catalog of tools is Voice Search. You’ve probably run into it before even if you didn’t know exactly what it it was: it’s the little microphone icon in the main Google search bar, which when pressed, let’s you speak your search query to Google instead of typing it in. That same little microphone appears in Google’s Search app for iPhone and Android, and can be found within the Android search bar itself on many smartphones.
Although superficially thought of as a rival to Siri, Google Voice search has actually become a secondary gateway to Google’s vast knowledge base, and to the language recognition team’s delight, it’s finally getting more popular.
While Google doesn’t release the percentage of voice searches in relation to text, it does provide a veritable rabbit hole of statistics: mobile search is now more popular than desktop, mobile voice search has doubled in the last year, about 50 percent of American phone and tablet users know they can ask Google questions, and a third of them actually do it.
That’s a long sentence saying that while Google won’t say how many voice searches are made, Google’s press team assures me it’s a lot.
Besides a few hundred iterations of the algorithm per year, Search has worked pretty much the same for years. But getting people confident enough to speak with their devices has been a struggle.
Senior researcher Françoise Beaufays works on developing the voice recognition engine behind Voice Search, and says that increased adoption is because the feature just works better now.
“When we started doing speech recognition, users weren’t fully confident. they were using it, but you could tell there was hesitation, the technology wasn’t as good as it is now,” Beaufays says. “Fast forward to nowadays, people are comfortable doing anything possible by voice in their office.”
Beaufays speaks quickly with a French accent, and is trilingual—on top of her fluency in neural network architecture. She led the Speech team just ripped out the service’s old engine used to recognize sounds, and replaced it with a new, more advanced system that uses a new brand of recurrent neural networks.
For a machine to understand speech, it needs to first learn what words and phrases sound like. That means audio files, and a lot of them. These files are processed by the algorithm, which create a huge graph of which sounds correlate to which sounds, words, and phrases. When an audio clip is presented to the computer, it analyzes the clip by pushing the audio waveform through the graph, in an attempt to find a path that best explains the audio.
“That path in the end will say, ‘We went through this sequence of sounds, and that maps to this sequence of words, and that makes this sentence,'” Beaufays says.

But all this relies on those initial audio files, which is called training data. This training data is actually made of millions of real voice searches by Google users. Whenever you make a voice search, the audio is uploaded to Google servers, and if you’ve opted into letting Google use it, can be integrated into the bank of clips used to train the machine.
But before it’s used, the data goes through a few steps. First (and most importantly to you), it’s scrubbed of all your information. That means timestamps, location data, your user profile, everything. The raw waveform is then sent to a human transcriber, because the algorithm needs reliable text to associate with the clip. Every clip needs this metadata, and a “bad” clip is really just one that isn’t properly transcribed.There are even instances where researchers add in artificial noise, in order for the machine to understand what different words sounds like in different situations.
Beaufays stresses that this program is opt-in. This is important, given the privacy concerns—which are rational—that regularly bubble up as Google continues amassing more information about the world and our lives. But if you don’t want Google to use your voice, you don’t have to let it. Also, there are ways of deleting your searches after the fact.
But these techniques have made voice search more effective. According to Google, two years ago the error rate was 25 percent, which means one of every four searches was wrong. Now, that number is down to 8 percent.
But what happens when Google can’t train on your data?
The intelligent Inbox
Last week, Google announced that it’s beginning to use machine learning in your email (if you use the Inbox app, which is separate from Gmail), and yes, it’s built on TensorFlow, according to Alex Gawley, product director for Gmail.
“We started to see some of the power of the neural nets our research team was building,” Gawley says. “That it might just be possible for us to help with more than just understanding and organizing. it might just be possible for us to help with things like writing mail.”
The feature is called Smart Reply, and basically one recurrent neural network reads your email and hands it off to a second, which generates three potential responses. You choose, and the email is sent. But email is just as sensitive as photos, if not more in some cases.
No person at Google reads your emails, which is important to keep in mind. However, data on which choice you made does get sent back to inform the global model. That’s how it learns. From that, researchers can ask the machine to answer certain questions, and from there understand what might need to be fixed in the neural networks. The software is same for everybody, too, which is something
Smart Reply also gives us a peek into how machine learning products are built within Google. The Inbox team deployed this feature internally, to test and feed the machine some ideas of what was right and wrong, a process called dogfooding. (The phrase comes from the idea of eating your own dog food, and is an example of why tech is bizarre.)
The whole team uses it, and documents bugs, and gives it more and more information to feed from. When the app behaves correctly in the controlled environment, and can be scaled, its released.

Internal testing gives researchers a chance to predict potential bugs when the neural nets are exposed to mass quantities of data. For instance, at first Smart Reply wanted to tell everyone “I love you.” But that was just because on personal emails, “I love you” was a very common phrase, so the machine thought it was important.
All this is an attempt to make your work easier—that’s what a most of the company’s products are aiming to do, especially Google Now, the personal assistant of the Google world. The team’s catch phrase is “just the right information at the right time.” Aparna Chennapragada, the head of Google Now, says that machine intelligence needs to be thoughtfully considered when being built into the platform, in order to complement the human brain.
“You want to pick problems that are hard for humans, and easy for machines, not the other way around,” Chennapragada says. “It’s about making the technology do the heavy lifting for you, rather than doing it yourself. “
At the moment, the product is really just exploring how to use these methods to make your life easier. Chennapragada likens it to where research sat with voice recognition 5 years ago—it was okay, but didn’t work every single time.
They’re looking now at how to leverage three different kinds of data to serve you with tidbits of information. They see the phone as a “partial attention device” and an ideal service shouldn’t overload you with information.
“If you look at how each of us uses the phone, it’s between things that you’re doing in your life. It’s bite sized piece of information that you’re looking for,” Chennapragada says. “One of the things we think about is how we can work on your behalf, proactively, all the time.”
That’s the end goal in a smartphone with machine intelligence: the true digital personal assistant, ultimately predictive and vastly knowledgeable—the part of your brain you’re not born with.
So to get there, your phone needs data about you: your schedule, what you search for, what music you listen to, and where you go. This is the easiest kind of information to get, because it’s already on the device.

But when you combine that personal information with knowledge about the world, through Google’s KnowledgeGraph (more on this later), and data being sourced from other users, the world is brought to your fingertips. You might not know how to navigate an airport, but your phone does.
Another example of the way Google uses data from lots of people is gauging road traffic. By pulling anonymous location data from phones on the highway, Google can tell that cars are moving slower than usual. The same goes for being able to tell when a restaurant or coffee shop is busy.
Google Now represents the way Google approaches machine intelligence. They’re aware that a general intelligence model that can translate and tell you what’s in a picture is years and years away, so in the meantime, they’re creating a mosaic of tools that act in harmony to provide the best experience possible.
Organizing the world’s information
Okay, so I mentioned that Google Now works with KnowledgeGraph. What’s that?
John Giannandrea, the head of Google’s research from earlier, was brought into Google in 2010. He founded a company called Metaweb, which related text and objects on the internet. It was a logical parallel to search—not only finding things, but finding similar bits and pieces of information. He had worked on this issue even before that, when he was the CTO of Netscape. (Remember Netscape?)
But this all manifested in KnowledgeGraph, which debuted in 2012 as the bits of information and text that automatically pop up when you search for facts. If you search “When was Popular Science founded?” Google will supply the answer (which is 1872).
This is Google’s way of not only cataloging the internet, but making it more accessible and useful to its users. It was also the first leak of artificial intelligence into the main product, search.
Since then, Google has handed 15 percent of its daily search traffic to artificial intelligence model called RankBrain. This system is the common sense of search—it’s meant to catch the queries that traditional algorithms can’t figure out.
Beyond integration into its core search algorithms, and the expansion into products, Google also has a few moonshots in the works. For that, they rely on Geoff Hinton.
Hinton is one of the foremost thinkers in artificial intelligence—he’s often listed in the same sentence as other high-level researchers like Yann LeCun at Facebook, Google’s Andrew Ng, and Yoshua Bengio. (In fact, LeCun, Hinton, and Bengio wrote a review in Nature this May on deep learning, which reads like the literal textbook on AI.)

Speaking with Hinton is like talking to someone who lives five years in the future. Our conversation centered around turning documents into thought vectors, so that machines could understand and remember lengthy versions, and reverse engineer the algorithm our brain uses to learn.
Many computer programs today, for example, brute force the problem of analyzing what a text document means by looking up the dictionary definitions of words in the document, and the grammar. But in order to understand the document like a human, a computer would ideally be able to break the document down into a series of distinct thoughts.
“Google would love to be able to take a document, and figure out what the reasoning is, what the document is saying, and how one thought follows from the previous thoughts,” Hinton says. “If we could start doing that, then it could give you much better answers to queries, because it actually reads the documents and understands them.”
When asked why we aren’t doing this already, Hinton says if we’re trying to match comprehension to the brain, it’s a matter of scale. The artificial neural networks researchers use now just don’t have the complexity of our brain, even at when scaled to their current limits. The best ones we have might have hundreds of millions of weights that can be manipulated (LeCun uses the analogy of a black box with a million knobs on the outside to explain fiddling with weights.) But Hinton explains that our brains have 100 trillion—that’s 100,000 times more information.
In the face of being dwarfed by scale, Hinton is still optimistic that this streak of artificial intelligence research won’t fizzle out as it has in the past. (Artificial intelligence research has seen “winters,” where progress hasn’t matched expectations and investment has faded.) A large factor of this is the increasingly popular idea of thought vectors, as mentioned earlier. But the most comforting thing to Hinton is the progress in the last five years, especially object recognition and speech. These problems were often seen as too complex in the past, and now the error rate has drastically decreased on standardized tests.

“They’re getting close to human-level performance. Not in all aspects, but things like object recognition. A few years ago, computer vision people would have told you ‘no, you’re not going to get to that level in many years.’ So that’s a reason for being optimistic,” Hinton says.
But no matter how well a machine may complement or emulate the human brain, it doesn’t mean anything if the average person can’t figure out how to use it. That’s Google’s plan to dominate artificial intelligence—making it simple as possible. While the machinations behind the curtains are complex and dynamic, the end result are ubiquitous tools that work, and the means to improve those tools if you’re so inclined.
“There’s a thin line between magic and mystery,” Google Now’s Chennapragada says.”And we want to be on the right side of it.”





Share



































",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.popsci.com/google-ai/#article', 'isPartOf': {'@id': 'https://www.popsci.com/google-ai/'}, 'author': [{'@type': 'Person', '@id': 'https://www.popsci.com#/schema/person/46afeff14a953d0c364405b011dd8c22', 'name': 'Dave Gershgorn', 'description': '', 'url': 'https://www.popsci.com/authors/dave-gershgorn/', 'image': '', 'sameAs': []}], 'headline': 'How Google Aims To Dominate Artificial Intelligence', 'datePublished': '2019-04-16T22:33:14-04:00', 'dateModified': '2021-03-22T20:29:09-04:00', 'mainEntityOfPage': {'@id': 'https://www.popsci.com/google-ai/'}, 'wordCount': 4251, 'commentCount': 0, 'publisher': {'@id': 'https://www.popsci.com/#organization'}, 'image': {'@id': 'https://www.popsci.com/google-ai/#primaryimage'}, 'thumbnailUrl': 'https://www.popsci.com/wp-content/uploads/2019/04/16/HZRNWKAVJZA5SQVXP5ETYOIOEM.jpg', 'keywords': ['Google'], 'articleSection': ['AI', 'Technology'], 'inLanguage': 'en-US', 'ArticleBody': 'In November 2007, Google laid the groundwork to dominate the mobile market by releasing Android, an open \xadsource operating system for phones. Eight years later to the month, Android has an an 80 percent market share, and Google is using the same trick—this time with artificial intelligence.\n\nToday Google is announcing TensorFlow, its open \xadsource platform for machine learning, giving anyone a computer and internet connection (and casual background in deep learning algorithms) access to one of the most powerful machine learning platforms ever created. More than 50 Google products have adopted TensorFlow to harness deep learning (machine learning using deep neural networks) as a tool, from identifying you and your friends in the Photos app to refining its core search engine. Google has become a machine learning company. Now they\'re taking what makes their services special, and giving it to the world.\n\nIntroducing TensorFlow, the Android of AI\n\nTensorFlow is a library of files that allows researchers and computer scientists to build systems that break down data, like photos or voice recordings, and have the computer make future decisions based on that information. This is the basis of machine learning: computers understanding data, and then using it to make decisions. When scaled to be very complex, machine learning is a stab at making computers smarter. That\'s the broader, and more ill-defined field of artificial intelligence. TensorFlow is extraordinary complex, because of its precision and speed in digesting and outputting data, and can unequivocally be placed in the realm of artificial intelligence tools.\n\nHere are the nitty-gritty details: the TensorFlow system uses data flow graphs. In this system, data with multiple dimensions (values) are passed along from mathematical computation to mathematical computation. Those complex bits of data are called tensors. The math-y bits are called nodes, and the way the data changes from node to node tells the overall system relationships in the data. These tensors flow through the graph of nodes, and that\'s where the name TensorFlow comes from.\n\nOpen-\xadsourcing TensorFlow allows researchers and even grad students the opportunity to work with professionally-built software, sure, but the real effect is the potential to inform every machine learning company\'s research across the board. Now organizations of all sizes—from small startups to huge companies on par with Google—can take the TensorFlow system, adapt it to their own needs, and use it to compete directly against Google itself. More than anything, the release gives the world\'s largest internet company authority in artificial intelligence.\n\nStanford computer science professor Christopher Manning was given TensorFlow a little more than three months ago, and his students had the opportunity to tinker with the system. After just a few weeks of using it himself, Manning decided that he\'s going to implement it into his curriculum.\n\nBesides Android, he also likens the platform to Gmail, Google\'s ubiquitous email application. There are competitors, but Gmail is cleaner and makes more sense in most applications.\n\n""It\'s not that before this there weren\'t any high level libraries available for deep learning,"" Manning says. ""But in general these other libraries are things by three academics and a grad student.""\n\n\t\t\t\t\n\t\t\n\n\nWhile the others, most notably Torch and Theano, do have small groups updating them, it\'s nothing like the full force of the developers working on Google\'s machine learning infrastructure. Manning says that while TensorFlow is a huge gift to the community (one capable of reducing time spent optimizing the neural networks by 100 times), they might indirectly benefit from open\xad-sourcing their tools.\n\n""A very small amount of companies have been trying to hire up a very large percentage of the talented people in artificial intelligence in general, and deep learning in particular,"" Manning says. ""Google is not a charity, I\'m sure it\'s also occurred to them that by ceding this, we will have a lot of Ph.D students who will be in universities and already liking Google deep learning tools.""\n\nJeff Dean, one of Google\'s top engineers and one of the two people who could be listed as an author for TensorFlow (the other is Rajat Monga), is cautious about estimating the adoption in the community. He says that while it\'s something Google has found immensely useful in their own work, the real test is whether the community will find it as capable. The idea is to provide a tool so the whole community will be able to go from not just ideas, but actual implementations of things more rapidly.\n\n""We\'re hoping, basically, to accelerate machine learning research and deployment,"" Dean says. And while this is a big gift the community, the ideal scenario is that the community gives back, and shares what they\'ve made with other researchers (and Google). ""The machine learning community has been really good at polishing ideas, and that\'s a really good thing, but it\'s not the same thing as polishing working code associated with research ideas,"" Dean says.\nhttps://www.youtube.com/watch?v=oZikw5k_2FM\nHe also mentions that TensorFlow will help Google interns when they return back to their schools, because they can now access the once-proprietary systems on projects they might not have finished during their time at the company.\n\nThe TensorFlow system is a pretty complete package for an individual researcher. The system is a complete, standalone library associated with tools and an Apache 2.0 license, so it can be used in commercial settings. It can be compiled on desktops or laptops, or deployed on mobile (Android first, naturally, and then iOS to come later). It also comes with tutorials and documentation on how to modify and play with the platform.\n\nManning suggests that the ability to run deep learning algorithms on mobile devices will be an important factor that separates TensorFlow from other open-source systems.\n\nFor those who want to use the system as-is, Google is providing a version that researchers can start using right now (as pre-built binaries). There\'s also an application programming interface (API), for software developers to train and control their TensorFlow models. And this isn\'t a knockoff—it\'s the literal system used in the Google app, and more than 50 other products.\n\n\t\t\t\t\n\t\t\nInside Google\'s Artificial Intelligence Lab\n\nGoogle is opening this platform to the world, which gives us an equal opportunity to peek in and see how the company thinks about developing machine learning systems.\n\nInternally, Google has spent the last three years building a massive platform for artificial intelligence and now they\'re unleashing it on the world. Although, Google would prefer you call it machine intelligence. They feel that the word artificial intelligence carries too many connotations, and fundamentally, they\'re trying to create genuine intelligence—just in machines.\n\nIt\'s the model that they\'ve used within the company for years: where any engineer who wants to play with an artificial neural network can fork it off the system and tinker. That\'s the kind of open structure that allows 100 teams within a company to build powerful machine learning techniques.\n\n""Machine learning is a core, transformative way by which we\'re re-thinking how we\'re doing everything,"" Google CEO Sundar Pichai said on the company\'s earnings call in October 2015. ""We are thoughtfully applying it across all our products, be it search, ads, YouTube, or Play. And we\'re in early days, but you will see us — in a systematic way — apply machine learning in all these areas.""\n\nWelcome to Google, where everything is AI and AI is everything\n\nIt\'s difficult to lay out a concrete diagram of machine intelligence research at Google, because it\'s always changing, and saturates nearly every team in the company.\n\nGoogle\'s VP of engineering, John Giannandrea, calls this an ""embedded model."" I met him at one of the many sleek modern moderns at Google\'s headquarters in sunny Mountain View, California, in the fall of 2015.\n\nI was on a floor technically not open to the public, and when I was left unattended for a moment, an engineer came up to me, noticing I wasn\'t wearing an employee badge. He asked who I was, and saying I was a writer didn\'t smooth the situation over. Google prides itself on making its research open to the public, but work in the labs is kept under heavy wraps.\n\n\n\nFor me, Google\'s embedded model meant a lot of walking. The Googleplex contains 3.5 million square feet of office space over about seven acres of land. Google staff ride bikes between buildings, which are surrounded by well-groomed parks where Googlers sit with laptops, undoubtedly grappling with complex computer science conundrums or playing Minecraft during their lunch break. Different teams work in different buildings, and embedded machine intelligence researchers switch buildings when they switch teams.\n\nInside, most of what I saw looks like a normal office building. There are cubicles, computers with loads of monitors, and people discussing work in hushed tones while glancing nervously towards the journalist. There are holes cut in the wall to catch a quick nap—you know, office things.\n\n\t\t\t\t\n\t\t\nOrganizationally, there\'s a pool of researchers always working on general machine intelligence problems, and that work feeds back into Google\'s core products, such as the Photos app, Voice Search, and Search itself. There are some projects that start as just something Google wants to get better at. Giannandrea suggests handwriting as an example.\n\n""We, as a company, want to understand how people would write a word. So that\'s something we would invest in forever, even if we didn\'t have a product,"" he says.\n\nBut because Google is so vast in its offerings, there\'s usually a tool that can use each research element. (Handwriting ended up in Google Keep, the note-taking software.)\n\n\n\nWhen that use is figured out, the researcher hops onto the product team to help with implementation. Product teams develop specific applications that we all use, like the Photos app or Google Translate.\n\nIn general research, the teams are divided by their area of interest. There\'s a team focused on teaching computers to see, a team working to understand language, a team looking at better voice recognition, and so on.\n\n""There\'s no world in which Google doesn\'t want to have better speech recognition, language translation, language understanding— so these frontiers of research in computer science are things we invest in all the time,"" Giannandrea says.\n\nThere are more than 1000 researchers at Google working on these machine intelligence applications, constantly rotating between applied and theoretical research. Some of these researchers work on simpler problems that wouldn\'t be considered artificial intelligence, in the strictest sense of the word, but are more statistical methods of prediction.\n\nGoogle\'s new parent company, Alphabet, doesn\'t make a big impact on the way Google\'s machine intelligence research will continue, according to Google spokesman Jason Freidenfelds. While the research team will stay within Google Proper, there won\'t be any barriers from working with Life Sciences or Google [x] on machine learning applications.\n\nThe Voice of the future\n\nA rising star in Google\'s catalog of tools is Voice Search. You\'ve probably run into it before even if you didn\'t know exactly what it it was: it\'s the little microphone icon in the main Google search bar, which when pressed, let\'s you speak your search query to Google instead of typing it in. That same little microphone appears in Google\'s Search app for iPhone and Android, and can be found within the Android search bar itself on many smartphones.\n\nAlthough superficially thought of as a rival to Siri, Google Voice search has actually become a secondary gateway to Google\'s vast knowledge base, and to the language recognition team\'s delight, it\'s finally getting more popular.\n\nWhile Google doesn\'t release the percentage of voice searches in relation to text, it does provide a veritable rabbit hole of statistics: mobile search is now more popular than desktop, mobile voice search has doubled in the last year, about 50 percent of American phone and tablet users know they can ask Google questions, and a third of them actually do it.\n\nThat\'s a long sentence saying that while Google won\'t say how many voice searches are made, Google\'s press team assures me it\'s a lot.\n\nBesides a few hundred iterations of the algorithm per year, Search has worked pretty much the same for years. But getting people confident enough to speak with their devices has been a struggle.\n\nSenior researcher Françoise Beaufays works on developing the voice recognition engine behind Voice Search, and says that increased adoption is because the feature just works better now.\n\n""When we started doing speech recognition, users weren\'t fully confident. they were using it, but you could tell there was hesitation, the technology wasn\'t as good as it is now,"" Beaufays says. ""Fast forward to nowadays, people are comfortable doing anything possible by voice in their office.""\n\nBeaufays speaks quickly with a French accent, and is trilingual—on top of her fluency in neural network architecture. She led the Speech team just ripped out the service\'s old engine used to recognize sounds, and replaced it with a new, more advanced system that uses a new brand of recurrent neural networks.\n\nFor a machine to understand speech, it needs to first learn what words and phrases sound like. That means audio files, and a lot of them. These files are processed by the algorithm, which create a huge graph of which sounds correlate to which sounds, words, and phrases. When an audio clip is presented to the computer, it analyzes the clip by pushing the audio waveform through the graph, in an attempt to find a path that best explains the audio.\n\n""That path in the end will say, \'We went through this sequence of sounds, and that maps to this sequence of words, and that makes this sentence,\'"" Beaufays says.\n\n\n\nBut all this relies on those initial audio files, which is called training data. This training data is actually made of millions of real voice searches by Google users. Whenever you make a voice search, the audio is uploaded to Google servers, and if you\'ve opted into letting Google use it, can be integrated into the bank of clips used to train the machine.\n\nBut before it\'s used, the data goes through a few steps. First (and most importantly to you), it\'s scrubbed of all your information. That means timestamps, location data, your user profile, everything. The raw waveform is then sent to a human transcriber, because the algorithm needs reliable text to associate with the clip. Every clip needs this metadata, and a ""bad"" clip is really just one that isn\'t properly transcribed.There are even instances where researchers add in artificial noise, in order for the machine to understand what different words sounds like in different situations.\n\nBeaufays stresses that this program is opt-in. This is important, given the privacy concerns—which are rational—that regularly bubble up as Google continues amassing more information about the world and our lives. But if you don\'t want Google to use your voice, you don\'t have to let it. Also, there are ways of deleting your searches after the fact.\n\nBut these techniques have made voice search more effective. According to Google, two years ago the error rate was 25 percent, which means one of every four searches was wrong. Now, that number is down to 8 percent.\n\nBut what happens when Google can\'t train on your data?\n\nThe intelligent Inbox\n\nLast week, Google announced that it\'s beginning to use machine learning in your email (if you use the Inbox app, which is separate from Gmail), and yes, it\'s built on TensorFlow, according to Alex Gawley, product director for Gmail.\n\n""We started to see some of the power of the neural nets our research team was building,"" Gawley says. ""That it might just be possible for us to help with more than just understanding and organizing. it might just be possible for us to help with things like writing mail.""\n\nThe feature is called Smart Reply, and basically one recurrent neural network reads your email and hands it off to a second, which generates three potential responses. You choose, and the email is sent. But email is just as sensitive as photos, if not more in some cases.\n\nNo person at Google reads your emails, which is important to keep in mind. However, data on which choice you made does get sent back to inform the global model. That\'s how it learns. From that, researchers can ask the machine to answer certain questions, and from there understand what might need to be fixed in the neural networks. The software is same for everybody, too, which is something\n\nSmart Reply also gives us a peek into how machine learning products are built within Google. The Inbox team deployed this feature internally, to test and feed the machine some ideas of what was right and wrong, a process called dogfooding. (The phrase comes from the idea of eating your own dog food, and is an example of why tech is bizarre.)\n\nThe whole team uses it, and documents bugs, and gives it more and more information to feed from. When the app behaves correctly in the controlled environment, and can be scaled, its released.\n\n\n\nInternal testing gives researchers a chance to predict potential bugs when the neural nets are exposed to mass quantities of data. For instance, at first Smart Reply wanted to tell everyone ""I love you."" But that was just because on personal emails, ""I love you"" was a very common phrase, so the machine thought it was important.\n\nAll this is an attempt to make your work easier—that\'s what a most of the company\'s products are aiming to do, especially Google Now, the personal assistant of the Google world. The team\'s catch phrase is ""just the right information at the right time."" Aparna Chennapragada, the head of Google Now, says that machine intelligence needs to be thoughtfully considered when being built into the platform, in order to complement the human brain.\n\n""You want to pick problems that are hard for humans, and easy for machines, not the other way around,"" Chennapragada says. ""It\'s about making the technology do the heavy lifting for you, rather than doing it yourself. ""\n\nAt the moment, the product is really just exploring how to use these methods to make your life easier. Chennapragada likens it to where research sat with voice recognition 5 years ago—it was okay, but didn\'t work every single time.\n\nThey\'re looking now at how to leverage three different kinds of data to serve you with tidbits of information. They see the phone as a ""partial attention device"" and an ideal service shouldn\'t overload you with information.\n\n""If you look at how each of us uses the phone, it\'s between things that you\'re doing in your life. It\'s bite sized piece of information that you\'re looking for,"" Chennapragada says. ""One of the things we think about is how we can work on your behalf, proactively, all the time.""\n\nThat\'s the end goal in a smartphone with machine intelligence: the true digital personal assistant, ultimately predictive and vastly knowledgeable—the part of your brain you\'re not born with.\n\nSo to get there, your phone needs data about you: your schedule, what you search for, what music you listen to, and where you go. This is the easiest kind of information to get, because it\'s already on the device.\n\n\n\nBut when you combine that personal information with knowledge about the world, through Google\'s KnowledgeGraph (more on this later), and data being sourced from other users, the world is brought to your fingertips. You might not know how to navigate an airport, but your phone does.\n\nAnother example of the way Google uses data from lots of people is gauging road traffic. By pulling anonymous location data from phones on the highway, Google can tell that cars are moving slower than usual. The same goes for being able to tell when a restaurant or coffee shop is busy.\n\nGoogle Now represents the way Google approaches machine intelligence. They\'re aware that a general intelligence model that can translate and tell you what\'s in a picture is years and years away, so in the meantime, they\'re creating a mosaic of tools that act in harmony to provide the best experience possible.\n\nOrganizing the world’s information\n\nOkay, so I mentioned that Google Now works with KnowledgeGraph. What\'s that?\n\nJohn Giannandrea, the head of Google\'s research from earlier, was brought into Google in 2010. He founded a company called Metaweb, which related text and objects on the internet. It was a logical parallel to search—not only finding things, but finding similar bits and pieces of information. He had worked on this issue even before that, when he was the CTO of Netscape. (Remember Netscape?)\n\nBut this all manifested in KnowledgeGraph, which debuted in 2012 as the bits of information and text that automatically pop up when you search for facts. If you search ""When was Popular Science founded?"" Google will supply the answer (which is 1872).\n\nThis is Google\'s way of not only cataloging the internet, but making it more accessible and useful to its users. It was also the first leak of artificial intelligence into the main product, search.\nSince then, Google has handed 15 percent of its daily search traffic to artificial intelligence model called RankBrain. This system is the common sense of search—it\'s meant to catch the queries that traditional algorithms can\'t figure out.\n\nBeyond integration into its core search algorithms, and the expansion into products, Google also has a few moonshots in the works. For that, they rely on Geoff Hinton.\n\nHinton is one of the foremost thinkers in artificial intelligence—he\'s often listed in the same sentence as other high-level researchers like Yann LeCun at Facebook, Google\'s Andrew Ng, and Yoshua Bengio. (In fact, LeCun, Hinton, and Bengio wrote a review in Nature this May on deep learning, which reads like the literal textbook on AI.)\n\n\n\nSpeaking with Hinton is like talking to someone who lives five years in the future. Our conversation centered around turning documents into thought vectors, so that machines could understand and remember lengthy versions, and reverse engineer the algorithm our brain uses to learn.\n\nMany computer programs today, for example, brute force the problem of analyzing what a text document means by looking up the dictionary definitions of words in the document, and the grammar. But in order to understand the document like a human, a computer would ideally be able to break the document down into a series of distinct thoughts.\n\n""Google would love to be able to take a document, and figure out what the reasoning is, what the document is saying, and how one thought follows from the previous thoughts,"" Hinton says. ""If we could start doing that, then it could give you much better answers to queries, because it actually reads the documents and understands them.""\n\nWhen asked why we aren\'t doing this already, Hinton says if we\'re trying to match comprehension to the brain, it\'s a matter of scale. The artificial neural networks researchers use now just don\'t have the complexity of our brain, even at when scaled to their current limits. The best ones we have might have hundreds of millions of weights that can be manipulated (LeCun uses the analogy of a black box with a million knobs on the outside to explain fiddling with weights.) But Hinton explains that our brains have 100 trillion—that\'s 100,000 times more information.\n\nIn the face of being dwarfed by scale, Hinton is still optimistic that this streak of artificial intelligence research won\'t fizzle out as it has in the past. (Artificial intelligence research has seen ""winters,"" where progress hasn\'t matched expectations and investment has faded.) A large factor of this is the increasingly popular idea of thought vectors, as mentioned earlier. But the most comforting thing to Hinton is the progress in the last five years, especially object recognition and speech. These problems were often seen as too complex in the past, and now the error rate has drastically decreased on standardized tests.\n\n\n\n""They\'re getting close to human-level performance. Not in all aspects, but things like object recognition. A few years ago, computer vision people would have told you \'no, you\'re not going to get to that level in many years.\' So that\'s a reason for being optimistic,"" Hinton says.\n\nBut no matter how well a machine may complement or emulate the human brain, it doesn\'t mean anything if the average person can\'t figure out how to use it. That\'s Google\'s plan to dominate artificial intelligence—making it simple as possible. While the machinations behind the curtains are complex and dynamic, the end result are ubiquitous tools that work, and the means to improve those tools if you\'re so inclined.\n\n""There\'s a thin line between magic and mystery,"" Google Now\'s Chennapragada says.""And we want to be on the right side of it.""'}, {'@type': 'WebPage', '@id': 'https://www.popsci.com/google-ai/', 'url': 'https://www.popsci.com/google-ai/', 'name': 'How Google Aims To Dominate Artificial Intelligence', 'isPartOf': {'@id': 'https://www.popsci.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.popsci.com/google-ai/#primaryimage'}, 'image': {'@id': 'https://www.popsci.com/google-ai/#primaryimage'}, 'thumbnailUrl': 'https://www.popsci.com/wp-content/uploads/2019/04/16/HZRNWKAVJZA5SQVXP5ETYOIOEM.jpg', 'datePublished': '2019-04-16T22:33:14-04:00', 'dateModified': '2021-03-22T20:29:09-04:00', 'description': 'In November 2007, Google laid the groundwork to dominate the mobile market by releasing Android, an open \xadsource operating system for phones. Eight years later to the month, Android has an an 80 percent market share, and Google is using the same trick—this time with artificial intelligence.', 'breadcrumb': {'@id': 'https://www.popsci.com/google-ai/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.popsci.com/google-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.popsci.com/google-ai/#primaryimage', 'url': 'https://www.popsci.com/wp-content/uploads/2019/04/16/HZRNWKAVJZA5SQVXP5ETYOIOEM.jpg', 'contentUrl': 'https://www.popsci.com/wp-content/uploads/2019/04/16/HZRNWKAVJZA5SQVXP5ETYOIOEM.jpg', 'width': 1500, 'height': 1125}, {'@type': 'BreadcrumbList', '@id': 'https://www.popsci.com/google-ai/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': 'https://www.popsci.com/category/technology/', 'description': 'From our phones and smart assistants to transportation, the military, and cybersecurity—this is the latest on the technology shaping life on Earth and beyond.', 'name': 'Technology'}, {'@type': 'ListItem', 'position': 2, 'item': 'https://www.popsci.com/category/ai/', 'description': 'A look into how computer science is building and coding machines that solve problems the way human brains do.', 'name': 'AI'}, {'@type': 'ListItem', 'position': 3, 'name': 'How Google Aims To Dominate Artificial Intelligence'}], 'numberOfItems': 3, 'itemListOrder': 'Ascending', '@context': 'https://schema.org'}, {'@type': 'WebSite', '@id': 'https://www.popsci.com/#website', 'url': 'https://www.popsci.com/', 'name': 'Popular Science', 'description': 'Awe-inspiring science reporting, technology news, and DIY projects. Skunks to space robots, primates to climates. That&#039;s Popular Science, 150 years strong.', 'publisher': {'@id': 'https://www.popsci.com/#organization'}, 'alternateName': 'PopSci', 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.popsci.com/#organization', 'name': 'Popular Science', 'alternateName': 'PopSci', 'url': 'https://www.popsci.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.popsci.com/#/schema/logo/image/', 'url': 'https://www.popsci.com/wp-content/uploads/2021/03/06/pop-sci-logo-default.jpg', 'contentUrl': 'https://www.popsci.com/wp-content/uploads/2021/03/06/pop-sci-logo-default.jpg', 'width': 2000, 'height': 1200, 'caption': 'Popular Science'}, 'image': {'@id': 'https://www.popsci.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/PopSci/', 'https://x.com/popsci'], 'publishingPrinciples': 'https://www.popsci.com/editorial-standards/'}, {'@type': 'Person', '@id': 'https://www.popsci.com#/schema/person/46afeff14a953d0c364405b011dd8c22', 'name': 'Dave Gershgorn', 'description': '', 'url': 'https://www.popsci.com/authors/dave-gershgorn/', 'image': '', 'sameAs': []}, {'@type': 'VideoObject', 'name': 'TensorFlow: Open source machine learning', 'thumbnailUrl': 'https://i.ytimg.com/vi/oZikw5k_2FM/hqdefault.jpg', 'embedUrl': 'https://www.youtube.com/watch?v=oZikw5k_2FM', 'description': 'No description', 'uploadDate': '2019-04-16T18:33:14-04:00'}]",,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8veW91cnN0b3J5LmNvbS9teXN0b3J5L2hvdy10by1lbmRvdy10aGUtYmVuZWZpdHMtb2YtYWktaW4teW91ci1idXNpbmVzc9IBAA?oc=5,How Artificial Intelligence Can Benefit your Business In 2020? - YourStory,2019-04-18,YourStory,https://yourstory.com,"We hear a lot about artificial intelligence innovations these days, but do we really understand what artificial intelligence really is.   Even it is more confusing to commercial ventures as artificially intelligent driven technologies fall into different categories. The most important ones are as fo","go programming language, what is golang used for, Hire expert Go lang developers, Best company to hire golang developers, Developers for golang programming language","We hear a lot about artificial intelligence innovations these days, but do we really understand what artificial intelligence really is.   Even it is more confusing to commercial ventures as artificially intelligent driven technologies fall into different categories. The most important ones are as fo","We hear a lot about artificial intelligence innovations these days, but do we really understand what artificial intelligence really is.   Even it is more confusing to commercial ventures as artificially intelligent driven technologies fall into different categories. The most important ones are as fo",http://schema.org,Article,https://yourstory.com/mystory/how-to-endow-the-benefits-of-ai-in-your-business,"{'@type': 'Organization', 'name': 'YourStory', 'alternateName': ['Yourstory', 'Yourstory Media Pvt Ltd', 'Yourstory Media'], 'logo': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/cs/static/logos/publisher-logo.png', 'width': 292, 'height': 60, 'caption': 'YourStory Media'}, 'url': 'https://yourstory.com', 'sameAs': ['https://www.facebook.com/yourstorycom', 'https://twitter.com/YourStoryCo', 'https://www.youtube.com/user/yourstorytv', 'https://instagram.com/yourstory_com', 'http://plus.google.com/111272339013288238153', 'https://in.linkedin.com/company/yourstory-com']}",2019-04-18T08:30:49.501Z,2019-04-18T08:30:49.501Z,How Artificial Intelligence Can Benefit your Business In 2020?  ,['https://images.yourstory.com/cs/1/6b460cd040d711e994bbefffe3577d8b/HowtoEndowtheBenefitsofAIinYourBusiness-1591712124902.png'],,"{'@type': 'WebPage', '@id': 'https://yourstory.com/mystory/how-to-endow-the-benefits-of-ai-in-your-business'}","{'@type': 'Person', 'name': 'Amyra Sheldon'}",Growth hacks,N/A,N/A,"In this era of digitalization, artificial intelligence is innovating with each passing day and revamping our day-to-day lives and businesses. But do we actually understand what artificial intelligence really is? And how this technology is helping our businesses? Let’s find out- What is Artificial Intelligence? Artificial intelligence in simple words is the ability of a machine or computer program to think and learn. It is also a place of study which tries to develop computers a little smarter. Computers can work on their own without any human intervention. Artificial intelligence is playing an important role in the growth of businesses. Every year or month, we see a fresh batch of advanced AI-based solutions across both processes and products. It helps the business to detect fraud early, increase sales, automate work processes, improve customer experience, and offer predictive analysis.Also, it supports healthcare service providers by offering better and advanced tools for early diagnosis. According to PwC’s report, “67.0% of executives believe AI will help machines and people to work together to improve operations — by combining human and artificial intelligence.The surging business productivity and increasing consumer demand for better quality and increasing customized AI-enhanced products are escalating the growth of AI in the market. According to the Statista,  the global artificial intelligence software market is predicted to witness a massive growth in the near future, with revenue surging from around $10.0 billion in 2018 to  $126 billion by 2025It’s hard to ignore that  AI is the future of business, and sooner or later, companies across the globe will implement it to stay ahead in the competitive market. There are various types of artificial intelligence that help a business to grow which are as follows- Everyone is talking about AI in business, it can be hard to know which one to choose or from where to start when deciding how to add AI in your business operations. So for better understanding, here are some suggestions on how you can choose AI for your business. Suppose you have a retail store and wish to improve your overall customer experience and support services with AI. And, you also want to make your support staff use AI-enabled automated assistance technologies to make decisions and get work done.So, how to prepare for AI? The best way to evaluate the implementation of AI in your business is to figure out its practical use in your business. And, you also have to decide:What AI tools can do for your business? See if it can help in your work. How your competitors are using AI in their business operations? What are the challenges in adding AI to your company’s operations? What are the future trends of AI?Let's finish things one by one, so the first one is the importance of AI in business-                                                                                                                                                                                                                               Importance of AI in BusinessMany businesses have witnessed that after employing AI programs in their organization, there is increasing productivity and surging revenue due to the AI's greater automation. Today, the majority of companies are developing smart AI software programs with Go programming language, Python, Lisp, Java, Haskell, and Julia.  For example, National Institutes of Health (NIH) researchers use Artificial Intelligence (AI) with smartphone cameras to detect cervical cancer that will help more women to get the right medication. According to reports by the National Cancer Institute, a system based on the AI algorithm learned to detect the specific form of changes in the cervix due to precancerous changes.Retail and banking are among the top sectors using AI in their existing and upcoming projects. For example, Walmart harnessing AI to optimize everything related to their inventories, supply chain metrics, and customer service. For example, Walmart plans to deploy AI-enabled shelf-scanning robots across their U.S stores to find missing items, price tags, and products that need to be rearranged. These robots will also take care of customers' needs and make sure that customers aren’t faced with the issue of empty shelves. Banking and financial institutions see great potential in AI technology. How? See the below-given image:As AI adds productivity and opens up a whole new world of possibilities for your enterprise, you should also know about the best programming languages for AI.Best programming languages for AI that will benefit your businessYou should keep an eye on AI programming languages along with what the other businesses are using and talking about. There is no denying that the number of emerging AI technologies these days is overwhelming. So, which one is the perfect fit for your own business?To lend you a hand, here's the list of the best AI programming languages for enterprises and programmers community. So, let’s dive in! 1) PythonWhen it comes to the best AI programming language, Python is your best bet because of its less complex programming and pre-built libraries - (SciPy, Pandas, Matplotlib, Scikit learn, and NumPy) that help in AI software development.If you are working on deep learning projects, such as automatic image colourization, pixel restoration, multi-person pose estimation, and more, then you can use Python pre-built libraries, including PyTorch, TensorFlow, and Apache MXNet.Furthermore, if you are working on Natural Language Processing (NLP) sentiment analysis, then you should go for Python’s NLTK to take advantage of simple & easy syntax, structuring, and text processing. One of the best examples of the online retail store built on Python is Affirm that allows its users to make their payments in a completely safe manner. Python is also used to build AI software solutions to analyze the market, and make predictions, and visualize data. Some big brands using Python in their application development- Google has been a supporter of Python because of its ease of maintenance and fast delivery system. Facebook also uses Python for hardware imaging, operational automation, infrastructure management, and binary distribution. 2) JAVA Java is one of the best programming languages used by analytics firms like NASA.  The list of best programming languages for AI is incomplete without talking about Java which is an object-oriented programming language that is easy to maintain, portable, and transparent language supported by a group of libraries.Java is also user-friendly and can work across different platforms without requiring any recompilation. If you’re working on a natural language processing (NLP) project, then Java gives you enough support from its group of libraries. Java supports big data platforms like Apache Hadoop and Apache Spark, which is good for creating data analytics related to AI development. NASA World Wind is an open-source virtual globe built on the principles of Java. It is known for its zooming capabilities that allow you to zoom from satellite altitude into any place on the Earth. It also lets you see Earth terrain in a 3D rich environment. 3) Google GO  Go Language is seen as the future of AI-enabled technologies While AI has only started making an impact on consumers, Google’s Go is an open source language that has been at the heart of AI development today.Some consider it to be the best programming language for AI development because developers can work with machine learning libraries written directly in Go language. It’s also best suited for AI development because its unique features enable the safe and smooth processing of information. Most notable companies such as Dropbox, Google, Lyft, Uber and Heroku use Go language because of its cross-platform support capabilities, fast compilation, and reliable software creation. What is Golang used for? Golang is a general purpose language made for future AI programming. Today AI developers often turn to Golang for AI projects that are based on ML because it offers features such as functional programming, rapid prototyping capabilities, C-inspired syntax, simplified documentation, garbage collection, and is highly flexible and adaptable to problem-solving needs. According to research by Google’s Russ Cox, “Golang  is currently used by at least 1 million developers across the world. On GitHub, the language has received over 65.7k stars and 9.3k forks, with over 1,400 contributors and 42,000 commits”.In recent years some of its key features made it a special option in the world of AI for businesses. It’s also easy to hire expert Go Lang developers with the help of the best companies to hire Golang developers. So, don’t delay, get it now to your work.4) JuliaIf you have a requirement for a task that demands numerical computing and analysis, Julia is the best programming language for your AI business projects. It is specifically designed for the numerical computing required by AI.It gives you results without requiring a separate form of compilation and its programming structure includes parametric polymorphism to make your software program more expressive along with the capabilities of dispatch software. According to a report, the number of downloads of Julia has increased 78.0%, from 1.8 million to 3.2 million,  since January 2018. Unlike the languages above, Julia provides excellent support for deep learning applications. For example, working with Julia allows you to translate complex algorithms directly from the research papers into the code form. This significantly reduces the risk of errors, improves safety, and cuts costs because it supports languages like Python, C++, and R. 5) HaskellHaskell is a perfect choice for building AI enabled software solutions. Tech giants,  such as Alcatel-Lucent have been using Haskell to develop its narrowband software radio system. use it. Haskell is also used in banking, large financial institutions, large data science firms, and research projects because it supports domain-specific languages that support programming language research and AI capabilities.Unlike Python and Java, Haskell is perfect for academic software development, as it supports a group of expressive libraries to create AI algorithms. It’s also a perfect choice for creating probability based programming that helps developers quickly identify the compilation errors during the phase of the iteration.Bottom LineAI software solutions are already improving our way of managing business activities, and future AI solutions can be used to predict the outcome of your efforts. And it is also helping developers to understand and act on future opportunities for the execution of AI strategy in business organizations. So, be ready to take advantage of new AI enabled technologies.      There are many companies, but its difficult to opt for the one, who keep an eye on market trends , AI capabilities, and everything involving development technology for your business project. If you are looking to hire machine learning app developers you can connect with ValueCoders- A leading machine learning app development company in India, the company have 16+ years of experience in delivering services to thousands of users across the world. So far,  they has served 2500+ happy clients and worked on 4200+ projects with 97.0% client retention.",News,,,,,How Artificial Intelligence Can Benefit your Business In 2020?  ,,,,,,,,,,,how-to-endow-the-benefits-of-ai-in-your-business,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://yourstory.com', 'name': 'YourStory', 'image': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/cs/static/logos/publisher-logo.png', 'width': 292, 'height': 60}}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://yourstory.com/mystory/how-to-endow-the-benefits-of-ai-in-your-business', 'name': 'How Artificial Intelligence Can Benefit your Business In 2020?  ', 'image': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/cs/1/6b460cd040d711e994bbefffe3577d8b/HowtoEndowtheBenefitsofAIinYourBusiness-1591712124902.png', 'height': 400, 'width': 800}}}]",,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}","{'@type': 'WebPage', '@id': 'https://yourstory.com/mystory/how-to-endow-the-benefits-of-ai-in-your-business', 'url': 'https://yourstory.com/mystory/how-to-endow-the-benefits-of-ai-in-your-business', 'inLanguage': 'en', 'name': 'How Artificial Intelligence Can Benefit your Business In 2020?  ', 'datePublished': '2019-04-18T08:30:49.501Z', 'dateModified': '2019-04-18T08:30:49.501Z', 'description': 'We hear a lot about artificial intelligence innovations these days, but do we really understand what artificial intelligence really is.   Even it is more confusing to commercial ventures as artificially intelligent driven technologies fall into different categories. The most important ones are as fo', 'isPartOf': {'@type': 'WebSite', '@id': 'https://yourstory.com/#website', 'url': 'https://yourstory.com/', 'name': 'YourStory', 'headline': 'Yourstory', 'description': 'YourStory | Stories from the Startups, Business, SMEs, Research, Entrepreneurs, Social, Women, Automotive and other sectors', 'publisher': {'@type': 'Organization', 'name': 'YourStory', 'alternateName': ['Yourstory', 'Yourstory Media Pvt Ltd', 'Yourstory Media'], 'logo': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/cs/static/logos/publisher-logo.png', 'width': 292, 'height': 60, 'caption': 'YourStory Media'}, 'url': 'https://yourstory.com', 'sameAs': ['https://www.facebook.com/yourstorycom', 'https://twitter.com/YourStoryCo', 'https://www.youtube.com/user/yourstorytv', 'https://instagram.com/yourstory_com', 'http://plus.google.com/111272339013288238153', 'https://in.linkedin.com/company/yourstory-com']}}}","{'@type': 'AudioObject', 'caption': 'How Artificial Intelligence Can Benefit your Business In 2020?  ', 'transcript': ""In this era of digitalization, artificial intelligence is innovating with each passing day and revamping our day-to-day lives and businesses. But do we actually understand what artificial intelligence really is? And how this technology is helping our businesses? Let’s find out-\xa0What is Artificial Intelligence?\xa0Artificial intelligence in simple words is the ability of a machine or computer program to think and learn. It is also a place of study which tries to develop computers a little smarter. Computers can work on their own without any human intervention.\xa0Artificial intelligence is playing an important role in the growth of businesses. Every year or month, we see a fresh batch of advanced AI-based solutions across both processes and products. It helps the business to detect fraud early, increase sales, automate work processes, improve customer experience, and offer predictive analysis.Also, it supports healthcare service providers by offering better and advanced tools for early diagnosis.\xa0According to PwC’s report, “67.0% of executives believe AI will help machines and people to work together to improve operations — by combining human and artificial intelligence.The surging business productivity and increasing consumer demand for better quality and increasing customized AI-enhanced products are escalating the growth of AI in the market.\xa0According to the Statista,\xa0 the global artificial intelligence software market is predicted to witness a massive growth in the near future, with revenue surging from around $10.0 billion in 2018 to\xa0 $126 billion by 2025It’s hard to ignore that\xa0 AI is the future of business, and sooner or later, companies across the globe will implement it to stay ahead in the competitive market. There are various types of artificial intelligence that help a business to grow which are as follows-\xa0Everyone is talking about AI in business, it can be hard to know which one to choose or from where to start when deciding how to add AI in your business operations. So for better understanding, here are some suggestions on how you can choose AI for your business.\xa0Suppose you have a retail store and wish to improve your overall customer experience and support services with AI. And, you also want to make your support staff use AI-enabled automated assistance technologies to make decisions and get work done.So, how to prepare for AI? The best way to evaluate the implementation of AI in your business is to figure out its practical use in your business. And, you also have to decide:What AI tools can do for your business? See if it can help in your work. How your competitors are using AI in their business operations? What are the challenges in adding AI to your company’s operations? What are the future trends of AI?Let's finish things one by one, so the first one is the importance of AI in business-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Importance of AI in BusinessMany businesses have witnessed that after employing AI programs in their organization, there is increasing productivity and surging revenue due to the AI's greater automation.\xa0Today, the majority of companies are developing smart AI software programs with Go programming language, Python, Lisp, Java, Haskell, and Julia.\xa0\xa0For example, National Institutes of Health (NIH) researchers use Artificial Intelligence (AI) with smartphone cameras to detect cervical cancer that will help more women to get the right medication.\xa0According to reports by the National Cancer Institute, a system based on the AI algorithm learned to detect the specific form of changes in the cervix due to precancerous changes.Retail and banking are among the top sectors using AI in their existing and upcoming projects.\xa0For example, Walmart harnessing AI to optimize everything related to their inventories, supply chain metrics, and customer service. For example, Walmart plans to deploy AI-enabled shelf-scanning robots across their U.S stores to find missing items, price tags, and products that need to be rearranged.\xa0These robots will also take care of customers' needs and make sure that customers aren’t faced with the issue of empty shelves. Banking and financial institutions see great potential in AI technology. How? See the below-given image:As AI adds productivity and opens up a whole new world of possibilities for your enterprise, you should also know about the best programming languages for AI.Best programming languages for AI that will benefit your businessYou should keep an eye on AI programming languages along with what the other businesses are using and talking about.\xa0There is no denying that the number of emerging AI technologies these days is overwhelming. So, which one is the perfect fit for your own business?To lend you a hand, here's the list of the best AI programming languages for enterprises and programmers community. So, let’s dive in!\xa01) PythonWhen it comes to the best AI programming language, Python is your best bet because of its less complex programming and pre-built libraries - (SciPy, Pandas, Matplotlib, Scikit learn, and NumPy) that help in AI software development.If you are working on deep learning projects, such as automatic image colourization, pixel restoration, multi-person pose estimation, and more, then you can use Python pre-built libraries, including PyTorch, TensorFlow, and Apache MXNet.Furthermore, if you are working on Natural Language Processing (NLP) sentiment analysis, then you should go for Python’s NLTK to take advantage of simple & easy syntax, structuring, and text processing.\xa0One of the best examples of the online retail store built on Python is Affirm that allows its users to make their payments in a completely safe manner. Python is also used to build AI software solutions to analyze the market, and make predictions, and visualize data.\xa0Some big brands using Python in their application development-\xa0Google has been a supporter of Python because of its ease of maintenance and fast delivery system. Facebook also uses Python for hardware imaging, operational automation, infrastructure management, and binary distribution. 2) JAVA Java is one of the best programming languages used by analytics firms like NASA. \xa0The list of best programming languages for AI is incomplete without talking about Java which is an object-oriented programming language that is easy to maintain, portable, and transparent language supported by a group of libraries.Java is also user-friendly and can work across different platforms without requiring any recompilation. If you’re working on a natural language processing (NLP) project, then Java gives you enough support from its group of libraries.\xa0Java supports big data platforms like Apache Hadoop and Apache Spark, which is good for creating data analytics related to AI development. NASA World Wind is an open-source virtual globe built on the principles of Java. It is known for its zooming capabilities that allow you to zoom from satellite altitude into any place on the Earth. It also lets you see Earth terrain in a 3D rich environment.\xa03) Google GO\xa0\xa0Go Language is seen as the future of AI-enabled technologies While AI has only started making an impact on consumers, Google’s Go is an open source language that has been at the heart of AI development today.Some consider it to be the best programming language for AI development because developers can work with machine learning libraries written directly in Go language. It’s also best suited for AI development because its unique features enable the safe and smooth processing of information.\xa0Most notable companies such as Dropbox, Google, Lyft, Uber and Heroku use Go language because of its cross-platform support capabilities, fast compilation, and reliable software creation.\xa0What is Golang used for? Golang is a general purpose language made for future AI programming. Today AI developers often turn to Golang for AI projects that are based on ML because it offers features such as functional programming, rapid prototyping capabilities, C-inspired syntax, simplified documentation, garbage collection, and is highly flexible and adaptable to problem-solving needs.\xa0According to research by Google’s Russ Cox, “Golang\xa0 is currently used by at least 1 million developers across the world. On GitHub, the language has received over 65.7k stars and 9.3k forks, with over 1,400 contributors and 42,000 commits”.In recent years some of its key features made it a special option in the world of AI for businesses. It’s also easy to hire expert Go Lang developers with the help of the best companies to hire Golang developers. So, don’t delay, get it now to your work.4) JuliaIf you have a requirement for a task that demands numerical computing and analysis, Julia is the best programming language for your AI business projects. It is specifically designed for the numerical computing required by AI.It gives you results without requiring a separate form of compilation and its programming structure includes parametric polymorphism to make your software program more expressive along with the capabilities of dispatch software.\xa0According to a report, the number of downloads of Julia has increased 78.0%, from 1.8 million to 3.2 million,\xa0 since January 2018.\xa0Unlike the languages above, Julia provides excellent support for deep learning applications. For example, working with Julia allows you to translate complex algorithms directly from the research papers into the code form. This significantly reduces the risk of errors, improves safety, and cuts costs because it supports languages like Python, C++, and R. 5) HaskellHaskell is a perfect choice for building AI enabled software solutions. Tech giants,\xa0 such as Alcatel-Lucent have been using Haskell to develop its narrowband software radio system. use it.\xa0Haskell is also used in banking, large financial institutions, large data science firms, and research projects because it supports domain-specific languages that support programming language research and AI capabilities.Unlike Python and Java, Haskell is perfect for academic software development, as it supports a group of expressive libraries to create AI algorithms. It’s also a perfect choice for creating probability based programming that helps developers quickly identify the compilation errors during the phase of the iteration.Bottom LineAI software solutions are already improving our way of managing business activities, and future AI solutions can be used to predict the outcome of your efforts. And it is also helping developers to understand and act on future opportunities for the execution of AI strategy in business organizations. So, be ready to take advantage of new AI enabled technologies.\xa0\xa0\xa0\xa0\xa0\xa0There are many companies, but its difficult to opt for the one, who keep an eye on market trends , AI capabilities, and everything involving development technology for your business project.\xa0If you are looking to hire machine learning app developers you can connect with ValueCoders- A leading machine learning app development company in India,\xa0the company have 16+ years of experience in delivering services to thousands of users across the world. So far,\xa0 they has served 2500+ happy clients and worked on 4200+ projects with 97.0% client retention."", 'contentUrl': 'https://yourstory.com/content/audio/prod/105744/story.62d3f715-8a77-4d83-9bfa-9cee83b0bea8.mp3', 'encodingFormat': 'audio/mpeg'}"
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3LnVzYXRvZGF5LmNvbS9zdG9yeS90ZWNoLzIwMTkvMDQvMTcvYWktdG9vLXdoaXRlLW1hbGUtbW9yZS13b21lbi1taW5vcml0aWVzLW5lZWRlZC1mYWNpYWwtcmVjb2duaXRpb24vMzQ1MTkzMjAwMi_SAQA?oc=5,"AI, facial recognition too white, too male: More minorities needed - USA TODAY",2019-04-17,USA TODAY,https://www.usatoday.com,"Too few women and people of color in the workforce is major cause of bias in facial recognition, artificial intelligence, study finds.",N/A,"Too few women and people of color in the workforce is major cause of bias in facial recognition, artificial intelligence, study finds.","Too few women and people of color in the workforce is major cause of bias in facial recognition, artificial intelligence, study finds.",,,,,,,,,,,,N/A,N/A,"TECHInequity in Silicon ValleyAdd TopicThe problem with AI? Study says it's too white and male, calls for more women, minorities Jessica GuynnUSA TODAYPlayPauseSound OnSound Off0:002:17AD0:11SKIPClosedCaptionOpen ShareEnter Full ScreenExit Full ScreenSAN FRANCISCO – Facial recognition systems frequently misidentify people of color. Lending tools charge higher interest rates to Hispanics and African Americans. Sentencing algorithms discriminate against black defendants. Job hunting tools favor men. Negative emotions are more likely to be assigned to black men's faces than white men. Computer vision systems for self-driving cars have a harder time spotting pedestrians with darker skin tones.The use of artificial intelligence, which combs through vast amounts of our personal data in search of patterns, is rapidly expanding in critical parts of Americans' daily lives such as education, employment, health care and policing. Increasingly, powerful artificial intelligence tools determine who gets into school, who gets a job, who pays a higher insurance premium.Yet a growing body of research shows that these technologies are rife with bias and discrimination, mirroring and amplifying real-world inequalities. A study scheduled to be released Wednesday by New York University's AI Now Institute identifies a key reason why: The people building these technologies are overwhelmingly white and male.Artificial intelligence technologies are developed mostly in major tech companies such as Facebook, Google, Amazon and Microsoft, and in a small number of university labs, which all tilt white, affluent and male and, in many cases, are only getting more so. Only by adding more women, people of color and other underrepresented groups can artificial intelligence address the bias and create more equitable systems, says Meredith Whittaker, a report author and co-founder of the AI Now Institute.""The problem of a lack of diversity in tech is obviously not new but it's reached a new and urgent inflection point. The number of women and people of color in the AI sector has decreased at the same time that the sector is establishing itself as a nexus of wealth and power,"" Whittaker says. ""In short, the problem here is that those in the room when AI is built, and those who are benefiting from the rapid proliferation of AI systems, represent an extremely narrow segment of the population. They are mainly men, they are mainly technically educated and they are mainly white. This is not the diversity of people that are being affected by these systems.""The study, ""Discriminating Systems: Gender, Race, and Power in AI,"" comes as scrutiny of AI intensifies. For years, tech companies could not deliver on the industry's ambitious promises of what hyper-intelligent machines could do. Today, AI is no longer the stuff of science fiction. Machines can recognize objects in a photograph or translate an online post into dozens of languages. And they are getting smarter all the time, taking on more sophisticated tasks.Tech companies, AI researchers and industry groups cast AI in a positive light, pointing to the possibility of advances in such critical areas as medical diagnosis and personalized medicine. But as these technologies proliferate so, too, are alarm bells. People often think of computer algorithms and other automated systems as being neutral or scientific but research is increasingly uncovering how AI systems can cause harm to underrepresented groups and those with less power. Anna Lauren Hoffmann, an assistant professor with The Information School at the University of Washington, describes this as ""data violence,"" or data science that disproportionately affects some more than others. The NYU researchers say machines learn from and reinforce historical patterns of racial and gender discrimination.Last year, Amazon had to scrap a tool it built to review job applicants’ resumes because it discriminated against women. Earlier this month, more than two dozen AI researchers called on Amazon to stop selling its facial recognition technology to law enforcement agencies, arguing it is biased against women and people of color.Google's speech recognition software has been dinged for performing better for male or male-sounding voices than female ones. In 2015, Google's image-recognition algorithm was caught auto-tagging pictures of black people as “gorillas.” Last year, transgender drivers for Uber whose appearances had changed were temporarily or permanently suspended because of an Uber security feature that required them to take a selfie to verify their identity.Other companies use AI to scan employees' social media for “toxic behavior” and alert their bosses or analyze job applicants' facial movements, tone of voice and word choice to predict how well they would do the job. Predictim analyzes online activities to produce ratings of which babysitters are more likely to abuse drugs or bully. AI can't make up for lack of diversity:Russia exploited race divisions on Facebook. More black staffers, diversity could have helped.Read more on tech's lack of diversity:Inequity in Silicon ValleyLeading the charge in raising awareness of the dangers of bias in AI is Massachusetts Institute of Technology researcher Joy Buolamwini, who with her research and advocacy has prompted Microsoft and IBM to improve their facial recognition systems and has drawn fire from Amazon, which has attacked her research methodology. Her work has also caused some in Congress to try to rein in the largely unregulated field as pressure increases from employees at major tech companies and the public. Last week, Democratic lawmakers introduced first-of-their-kind bills in the Senate and the House that would require big companies to test the ""algorithmic accountability"" of their artificial intelligence systems such as facial recognition. The bills were introduced just weeks after Facebook was sued by the Department of Housing and Urban Development, which has charged the social media giant's targeting system with allowing advertisers to exclude protected groups from seeing housing ads.San Francisco is considering banning city agencies from using facial recognition. Privacy laws in Texas and Illinois require anyone recording biometric data, including facial recognition, to give people notice and obtain their consent. The Trump administration has made developing ""safe and trustworthy"" algorithms one of the key objectives of the White House's AI initiative.AI is controversial in tech world too:Elon Musk says AI could doom human civilization. Zuckerberg disagrees. Who's right?Some see AI doing social good:Can artificial intelligence prevent the next Parkland shooting?Facebook: Big user of facial recognition:Facebook wants to save your face. Should you say yes to facial recognition?The NYU researchers say it's critical for AI to diversify the homogeneous group of engineers and researchers building these automated systems. Yet the gender gap in computer science is widening.As of 2015, women made up 18 percent of computer science majors in the U.S., down from a high of 37 percent in 1984. Women make up less than one quarter of the computer science workforce and receive median salaries that are 66 percent of their male counterparts, according to the National Academies of Sciences, Engineering, and Medicine. The number of bachelor’s degrees in engineering awarded to black women declined 11 percent between 2000 and 2015.The problem is even more acute in AI. Most speakers and attendees of machine learning conferences and 80 percent of AI professors are men, research shows. Women account for 15 percent of AI research staff at Facebook and 10 percent at Google. While there is very little public data on racial diversity in AI, anecdotal evidence suggests that the gaps are even wider, the study says.Last month when Stanford University unveiled an artificial intelligence institute with 120 faculty and technology leaders to represent humanity, not a single one was black. Boards created by tech companies to examine the ethics of artificial intelligence also lack members from underrepresented groups.Google also announced an “external advisory council” on AI ethics last month. NAACP president and CEO Derrick Johnson complained the new body ""lacks a qualified member of the civil rights community."" ""This is offensive to people of color & indicates AI tech wouldn't have the safeguards to prevent implicit & racial biases,"" he wrote on Twitter. Google later scrapped the advisory council. ""Both within the spaces where AI is being created, and in the logic of how AI systems are designed, the costs of bias, harassment, and discrimination are borne by the same people: gender minorities, people of color, and other underrepresented groups. Similarly, the benefits of such systems, from profit to efficiency, accrue primarily to those already in positions of power, who again tend to be white, educated, and male,"" the NYU study, a year in the making, found. Current efforts to attract and retain underrepresented groups in AI are not cutting it, the study warned.The push to bring more women into tech is too narrow and is ""likely to privilege white women over others."" Arguments focused on a recruiting or ""pipeline"" problem ignore pernicious issues in corporate and university work cultures – power imbalances, harassment, exclusionary hiring practices and unequal compensation – that drive women and people of color from AI or dissuade them from joining the field in the first place, researchers say.Among the study's recommendations: publish compensation levels broken down by race and gender and end pay and opportunity inequality; produce harassment and discrimination transparency reports; change hiring practices to increase diversity and the number of people of color, women and other underrepresented groups at senior leadership levels and create pathways for contractors, temps and vendors, who tend to be from more diverse backgrounds, to become full-time employees; and ensure executive incentives are tied to increases in hiring and retention of underrepresented groups.""To tackle the diversity crisis and to address AI bias, we need to look beyond technical fixes for social problems. We need to look at who has power, we need to ask who is harmed, we need to look at who benefits and we need to look at, ultimately, who gets to decide how these tools are built and which purposes they serve,"" Whittaker says. ""If the AI industry wants to change the world then it needs to get its own house in order first.""Air Force is using AI:The technologies have a military applicationIs next use of AI college admissions?:Who's going to review your college applications – a committee or a computer?Even spices are getting AI assist:McCormick and IBM are using AI to invent new flavor combinations   CompareCredit.com2 Cards Charging 0% Interest Until Nearly 2026With no annual fee & no interest for 18 months, these cards are helping Americans pay off debt in record time.CompareCredit.com|AdAdRead MoreUndoHealth HeadlinesTop Doctors 'Anti-Lazy' Drops Are Going Viral This July(Now Legally Sold Online)Health Headlines|AdAdBuy NowUndoUnforgettable Gadgets61 Shockingly Bizarre Gifts Nobody Would Think OfWeird & wonderful gifts you'd never think to buy. In stock. Free shipping on many.Unforgettable Gadgets|AdAdShop NowUndoOnline Shopping ToolsFlight Attendant Shows How To Fly Business Class For The Price of EconomyAmericans, you'll want to check this out ASAPOnline Shopping Tools|AdAdUndoThumaThe Best Bed Of 2024? Here's What Our Editors ThinkThese Are The 4 Best Wood Bed Frames in 2024. Find Out Which One Our Editors PreferThuma|AdAdLearn MoreUndoShiremSecret Revealed: How Gardeners Remove Gravel Weeds 'faster' Than Other MethodsShirem|AdAdLearn MoreUndoSherumThis New AC Cooler Cools the Room In SecondsSherum|AdAdLearn MoreUndoHaloClean UV SanitizerThis Dad Decimated 10,000 Bed Bugs From His Kid's Bed After Pushing 1 ButtonNaturally Kill Bed BugsHaloClean UV Sanitizer|AdAdUndoFisher Investments7 Wealth Tips Once Your Portfolio Reaches $1 MillionHow do retirees take steps to preserve their wealth in retirement? Download The Seven Secrets of High Net Worth Investors now.Fisher Investments|AdAdLearn MoreUndoHistory Strategy GameGame shows what the world without US military interventions would look likeThis strategy games makes you become a player in the crucial situations of history.History Strategy Game|AdAdPlay NowUndoDeal of the DayREVIEWEDJLab Headphones Are Under $20 For Amazon Prime DayREVIEWEDView Deal Recommendations are independently chosen by our editors. Purchases you make through our links may earn us a commission.Undo






























Featured Weekly Ad",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3LmlibS5jb20vYmxvZy9ob3ctd29ya2ZvcmNlLXBsYW5uaW5nLWFuYWx5dGljcy1idWlsZHMtc3Ryb25nZXItYnVzaW5lc3Nlcy_SAQA?oc=5,How workforce planning analytics builds stronger businesses - IBM,2019-04-18,IBM,https://www.ibm.com,N/A,N/A,"The workforce is the core of every business. And while workforce planning can provide great benefit to the growth and profitability of the organization as whole, many HR groups aren’t taking advantage of a sophisticated planning analytics solution. The Aberdeen Group recently published Automate through analytics: Unifying workforce planning through a single system of truth. Aberdeen found that when […]",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"


 







                              Artificial intelligence  
                        


                        July 15, 2024                  


Are bigger language models always better?

  4 min read - As enterprises look to separate the hype from where AI can add true value, it’s unclear if increasingly larger language models will always lead to better business solutions.                        


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.ibm.com/blog/how-workforce-planning-analytics-builds-stronger-businesses/', 'url': 'https://www.ibm.com/blog/how-workforce-planning-analytics-builds-stronger-businesses/', 'name': 'How workforce planning analytics builds stronger businesses - IBM Blog', 'isPartOf': {'@id': 'https://www.ibm.com/blog/#website'}, 'primaryImageOfPage': {'@id': 'https://www.ibm.com/blog/how-workforce-planning-analytics-builds-stronger-businesses/#primaryimage'}, 'image': {'@id': 'https://www.ibm.com/blog/how-workforce-planning-analytics-builds-stronger-businesses/#primaryimage'}, 'thumbnailUrl': 'https://www.ibm.com/blog/wp-content/uploads/2020/09/dots1200.jpeg', 'datePublished': '2019-04-18T21:55:35+00:00', 'dateModified': '2020-11-16T21:59:32+00:00', 'author': {'@id': 'https://www.ibm.com/blog/#/schema/person/4f09806a8344cffd740e9a5d92c2ab87'}, 'breadcrumb': {'@id': 'https://www.ibm.com/blog/how-workforce-planning-analytics-builds-stronger-businesses/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.ibm.com/blog/how-workforce-planning-analytics-builds-stronger-businesses/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.ibm.com/blog/how-workforce-planning-analytics-builds-stronger-businesses/#primaryimage', 'url': 'https://www.ibm.com/blog/wp-content/uploads/2020/09/dots1200.jpeg', 'contentUrl': 'https://www.ibm.com/blog/wp-content/uploads/2020/09/dots1200.jpeg', 'width': 1200, 'height': 675, 'caption': 'db2_2019'}, {'@type': 'BreadcrumbList', '@id': 'https://www.ibm.com/blog/how-workforce-planning-analytics-builds-stronger-businesses/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://ibm.com/blog/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How workforce planning analytics builds stronger businesses', 'item': ''}]}, {'@type': 'WebSite', '@id': 'https://www.ibm.com/blog/#website', 'url': 'https://www.ibm.com/blog/', 'name': 'IBM Blog', 'description': 'IBM Blog', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.ibm.com/blog/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.ibm.com/blog/#/schema/person/4f09806a8344cffd740e9a5d92c2ab87', 'name': 'Stephanie Solomon', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.ibm.com/blog/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/ac9b185a41e5d939713d7b0b5355b683?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/ac9b185a41e5d939713d7b0b5355b683?s=96&d=mm&r=g', 'caption': 'Stephanie Solomon'}, 'description': 'Stephanie Freyer is a marketing professional in IBM Planning Analytics, part of IBM Cloud. With more than 10 years of marketing experience, Stephanie specializes in writing and editing content for websites, product collateral, thought leadership and event communications.', 'url': 'https://www.ibm.com/blog/author/stephanie-solomon/'}]",,,
https://news.google.com/rss/articles/CBMiKWh0dHBzOi8vd3d3LmFyYWJuZXdzLmNvbS9ub2RlLzE0ODQxNDYvYW1w0gEA?oc=5,Misk Schools introduce artificial intelligence into Saudi classrooms - Arab News,2019-04-18,Arab News,https://www.arabnews.com,"Get the latest breaking news and headlines from the largest Arab News website. Get world news, sport news, business news, entertainment, lifestyle, video and photos.","Jubail,Al-Ahsa,Al-Kharj,Taif,Qatif,oil,Dammam,Abha,Asir,Yanbu,islam,jobs,sports,Khalij times,gulf news,saudi gazette,Riyadh,Tabuk,Mecca,Medina,AlMadinah,Jeddah,Makkah,Hail,Mecca,Makkah,Eastern,King Abdullah, jobs in Saudi,work in saudi arabia, umrah,Hajj،عرب نيوز",N/A,N/A,,,,,,,,,,,,N/A,N/A,"







Misk Schools introduce artificial intelligence into Saudi classrooms




MOHAMMED AL-KINANI

18 April 2019






























            Misk Schools will revolutionize learning with the aid of the world’s most pioneering classroom technology, while empowering teachers to deliver an even stronger education. (Misk Schools photo)        





Misk Schools is the first school in Saudi Arabia to adopt AI
It seems that we will reap the fruits of Saudi Vision earlier than expected:  Saleh Al-Ghamdi



	JEDDAH: Saudi students will soon be learning with the aid of artificial intelligence, as Riyadh’s leading Misk Schools become the first in the country to introduce AI into the classroom.

	From this September, students at Misk Schools will learn through and be assessed by artificial intelligence, providing a personalized education for each child and giving teachers greater insights into their performance. The school will use CENTURY, an award-winning teaching and learning platform that uses AI to adapt learning to each student’s individual strengths, weaknesses, behaviors and habits.

	Founded by Prince Mohammad Bin Salman’s Misk Foundation, Misk Schools is a state-of-the-art day school in Riyadh offering a new paradigm in education based on the best practices of international and progressive education.

	Misk Schools says that the move will ensure that students are learning with the aid of the world’s most pioneering classroom technology, while empowering teachers to deliver an even stronger education.

	Artificial intelligence — where machines are programmed to perform tasks traditionally associated with humans — is transforming education across the world. It is used to tailor learning to each student, while freeing teachers’ time to teach by automating admin tasks such as marking and planning. It also provides them with extensive data on each child’s performance, allowing for more effective targeted interventions to support or stretch students.

	While Misk Schools is the first school in Saudi Arabia to adopt AI, the Middle East is leading the way internationally in using AI and technology to improve education.

	Director General of Misk Schools Peter Hamilton said that they were excited to be partnering with CENTURY as its breaks new ground in ways to embed technology to transform the learning experience for students. “We seek to both support and challenge our learners, and by partnering with CENTURY we will empower our students to take ownership of their learning. Moreover, CENTURY will allow our teachers to have better insight into the daily work of each student, and to better plan future work in the classroom.” Hamilton said. 

	Founder and CEO of CENTURY Tech Priya Lakhani said: “AI is transforming schools across the world by providing a more personalized education to students, while simultaneously empowering teachers with precise data so that they can perform even better as educators.

	“AI is the only way we can move from the failed, outdated ‘one-size-fits-all’ approach to ‘one-size-fits-one.’ It allows each student to learn at their own pace, with lessons and tests tailored to maximize their strengths and rapidly address their weaknesses,” she said.

	“I am delighted to welcome Misk Schools to the CENTURY family. From children in leading independent schools to Syrian refugees in the Middle East, CENTURY is being used across the world to improve the lives of children and young adults from all backgrounds.”

	Saleh Al-Ghamdi, an English language teacher, told Arab News that introducing AI into classrooms was a major leap forward in the Saudi education system.

	“It seems that we will earlier than expected reap the fruits of the promising Saudi Vision before 2030 falls. It is an important step that will entirely change education in Saudi Arabia. I see the step as a road map to a bright education future,” Al-Ghamdi said.

	He added that Saudi Arabia is looking forward to putting its citizens on the path toward first-world countries. “Introducing AI in our schools is one of the ways that can significantly help in achieving our Vision 2030 goals. It is true that this process may require big efforts, but with determination nothing is impossible,” Al-Ghamdi said.

	Introducing AI in schools would greatly help students to feel successful and educators more productive. “It will also assist in promoting active learning and deeper engagement. What is more, it will make educators’ jobs more focused and much easier,” he said.

	Al-Ghamdi said that some teachers might fear that the introduction of AI in education would threaten their jobs, but “the truth is that this revolution in education will hopefully make robots and computer programs and technology, in general, a supporting element to their indispensable profession,” he said.

	Research involving more than 11,000 students using CENTURY showed that the platform improves understanding of a topic by an average of 30 percent. It also frees teachers from admin tasks such as marking and planning — saving an average of six hours a week and allowing them to focus on teaching itself.

	Last month CENTURY Tech agreed a landmark agreement with the Belgium government. As a leading teaching and learning platform that uses artificial intelligence in its design, CENTURY Tech is rapidly spreading across the world, from English independent schools to schools in Lebanon educating large numbers of Syrian refugees.
 










Topics:
Saudi Arabia
Saudi education
MISK
Eye on the Vision
Vision 2030



Related












Misk Foundation, NEOM helps youths to build the future
















MiSK, Qiddiya team up for internship program 






",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDE5LzQvMTgvMTgzMTEyODcvYWktdXBzY2FsaW5nLWFsZ29yaXRobXMtdmlkZW8tZ2FtZXMtbW9kcy1tb2RkaW5nLWVzcmdhbi1naWdhcGl4ZWzSAQA?oc=5,Artificial intelligence is helping old video games look like new - The Verge,2019-04-18,The Verge,https://www.theverge.com,"AI upscaling improves the quality of low-resolution pictures, and video game modders are using it to update the graphics of old games. From Final Fantasy VII to Doom and Morrowind, AI upscaling is giving old games a coat of new paint.",N/A,Modders are taking advantage of AI tools to update old graphics.,N/A,http://schema.org/,NewsArticle,https://www.theverge.com/2019/4/18/18311287/ai-upscaling-algorithms-video-games-mods-modding-esrgan-gigapixel,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",2019-04-18T12:45:30.000Z,2019-04-18T12:45:30.000Z,Artificial intelligence is helping old video games look like new,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/_LcfIRQb_wNzHqpxAx_OdTIgIjY=/0x0:1280x1280/1400x788/filters:focal(635x148:636x149)/cdn.vox-cdn.com/uploads/chorus_asset/file/16160945/chrin_1a_0_base_0000129.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/RfB0RqoSq6glJFnfuHFE9WTpizc=/0x0:1280x1280/1400x1050/filters:focal(635x148:636x149)/cdn.vox-cdn.com/uploads/chorus_asset/file/16160945/chrin_1a_0_base_0000129.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/cluk2uIpBsL8sQgGZKD9d2OhOn0=/0x0:1280x1280/1400x1400/filters:focal(635x148:636x149)/cdn.vox-cdn.com/uploads/chorus_asset/file/16160945/chrin_1a_0_base_0000129.jpg', 'width': 1400, 'height': 1400}]",https://cdn.vox-cdn.com/thumbor/_LcfIRQb_wNzHqpxAx_OdTIgIjY=/0x0:1280x1280/1400x788/filters:focal(635x148:636x149)/cdn.vox-cdn.com/uploads/chorus_asset/file/16160945/chrin_1a_0_base_0000129.jpg,,"[{'@type': 'Person', 'name': 'James Vincent', 'url': 'https://www.theverge.com/authors/james-vincent'}]",N/A,N/A,"TechArtificial intelligence is helping old video games look like newModders are taking advantage of AI tools to update old graphicsBy  James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge. Apr 18, 2019, 8:45 AM EDTShare this story0 Comments / 0 NewThe recent AI boom has had all sorts of weird and wonderful side effects as amateur tinkerers find ways to repurpose research from universities and tech companies. But one of the more unexpected applications has been in the world of video game mods. Fans have discovered that machine learning is the perfect tool to improve the graphics of classic games. The technique being used is known as “AI upscaling.” In essence, you feed an algorithm a low-resolution image, and, based on training data it’s seen, it spits out a version that looks the same but has more pixels in it. Upscaling, as a general technique, has been around for a long time, but the use of AI has drastically improved the speed and quality of results.“It was like witchcraft.”“It was like witchcraft,” says Daniel Trolie, a teacher and student from Norway who used AI to update the visuals of 2002 RPG classic The Elder Scrolls III: Morrowind. “[It] looked like I just downloaded a hi-res texture pack from [game developers] Bethesda themselves.” Trolie is a moderator at the r/GameUpscale subreddit where, along with specialist forums and chat apps like Discord, fans share tips and tricks on how to best use these AI tools. Browsing these forums, it’s apparent that the modding process is a lot like restoring old furniture or works of art. It’s a job for skilled craftspeople, requiring patience and knowledge. Not every game is a good fit for upscaling, and not every upscaling algorithm produces similar results. Modders have to pick the right tool for the job before putting in hundreds of hours of work to polish the final results. It’s a labor of love, not a quick fix. Despite the work involved, it’s still much faster than previous methods. It means restoring the graphics can be done in a few weeks by a single dedicated modder, rather than a team that has to work for years. As a consequence, there’s been an explosion of new graphics for old games over the past six months or so. The range of titles is impressive, including Doom, Half-Life 2, Metroid Prime 2, Final Fantasy VII, and Grand Theft Auto: Vice City. Even more recent fare like 2010’s Mass Effect 2 has got the AI-upscaling treatment. In each case, though, these are unsanctioned upgrades, meaning it takes a bit of extra know-how to install the new visuals.Actually creating these AI graphics takes a lot of work, explains a modder who goes by the name hidfan. He tells The Verge that the updated Doom visuals he made took at least 200 hours of work to tweak the algorithm’s output and clean up final images by hand.In Doom, as with many video games, the majority of the visuals are stored as texture packs. These are images of rocks, metal, grass, and so on that are pasted onto the game’s 3D maps like wallpaper onto the walls of a house. Just as with wallpaper, these textures have to tesselate perfectly, or players can spot where one image starts and another begins. Because the output from AI upscaling algorithms tends to introduce a lot of noise, says hidfan, a lot of manual editing is still required. The same is true when it comes to the visuals for characters and enemies. Hidfan says that cleaning up just a single monster takes between five and 15 hours, depending on how complex their animation is. That’s something to remember when looking at these updates or any project that uses machine learning. Just because AI is involved, doesn’t mean human labor isn’t.Updated Doom graphics created by hidfan. On the left is the original image; on the right is the AI-enhanced version. But how does the process actually work? Albert Yang, CTO of Topaz Labs, a startup that offers a popular upscaling service used by many modders, says it’s pretty straightforward. You start by taking a type of algorithm known as a generative adversarial network (GAN) and train it on millions of pairs of low-res and high-res images. “After it’s seen these millions of photos many, many times it starts to learn what a high resolution image looks like when it sees a low resolution image,” Yang tells The Verge.RelatedHow artificial intelligence will revolutionize the way video games are developed and playedOne part of the algorithm tries to re-create this transition from low-res to high-res, while another part compares its work against the training data, seeing if it can spot the difference and rejecting the output if not. This feedback loop is how GANs improve over time. Using AI to upscale images is a relatively simple task, but it perfectly illustrates the core advantage of machine learning. While traditional algorithms rely on rules defined by humans, machine learning techniques create their own rules by learning from data. A comparison of a traditional upscaling technique (“nearest neighbor”) and the AI-enhanced version (“ESRGAN”).  Image: kingdomakrillic.tumblr.comIn the case of upscaling algorithms, these rules are often pretty simple. If you want to upscale a 50 x 50-pixel image to double its size, for example, a traditional algorithm just inserts new pixels between the existing ones, selecting the new pixels’ color based on an average of its neighbors. To give a very simplified example: if you have a red pixel on one side and a blue pixel on the other, the new pixel in the middle comes out purple. This sort of method is simple to code and execute, but it’s a one-size-fits-all approach that produces mixed results, says Yang.The algorithms created by machine learning are much more dynamic by comparison. Topaz Labs’ Gigapixel upscaling doesn’t just look at neighboring pixels; it looks at whole sections of images at a time. That allows it to better re-create larger structures, like the outlines of buildings and furniture or the edges of a racetrack in Mario Kart.“This larger perceptual field is the major reason [AI upscaling algorithms] perform so much better,” says Yang. Updating game graphics is more than just a technical challenge, though. It’s often about salvaging memories. Replaying the favorite video games of one’s youth can be a surprisingly bittersweet experience: the memories are intact, but the games themselves seem strangely ugly and raw. “Was I really impressed by those graphics?” you ask yourself, wondering if you’ve lost the capacity to enjoy such games altogether. Take the Final Fantasy series, for example. These were titles I played extensively as a child. Just hearing songs from their soundtracks can transport me back to specific in-game moments and locations. But playing the games again as an adult is a weird experience. I usually don’t get too far when I try, despite the treasured place they hold in my memory. They just look bad. Modder Stefan Rumen, who used AI upscaling to improve the graphics of Final Fantasy VII, explains that new display technology is as much to blame for this as outdated graphics. “With the pixel/low polygon graphics of yesteryear, the old TV monitors helped gloss over many imperfections,” he says. “Your mind finished the job and filled in the gaps [but] modern displays show these old games in their un-filtered roughness.” Luckily, these early games are also the perfect target for AI upscaling. In the case of the Final Fantasy series, that’s partly because of their extensive use of pre-rendered backgrounds, which mean modders have to process fewer images. The visuals also occupy a “sweet spot” in terms of detail, says Rumen. “They’re not as low-res as pixel art, meaning there’s more information for the machine learning to do its magic, but it’s not a too high resolution that an upscale wouldn’t be needed,” he says. The results speak for themselves. Rumen says that Final Fantasy VII isn’t actually a game he played when he was young. (“I was a PC kid.”) But by updating the graphics, he’s making these classics accessible once more. They’ve convinced me, anyway. I’ve just downloaded Rumen’s AI graphics pack myself and am getting ready to play FFVII once more. Correction April 18th, 11:00AM ET: An earlier version of this article included mention of a SNES emulation mod as an example of AI upscaling. This mod does not use machine learning that we know of and has been removed from the article. We regret the error. Comments0 Comments / 0 NewFeatured Videos From The VergeApple’s Vision Pro: five months later | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge’s David Pierce chats with Victoria Song and Wes Davis about using the Vision Pro for the five months that it's been available to the public. The group details what works, what doesn’t, and what’s next for the device. David then chats with the folks at Sandwich Vision, who create Vision Pro apps called Television and Theater, about why they made 3D-rendered versions of CRT TVs in virtual reality.Most PopularMost PopularIt’s never been easier for the cops to break into your phoneThe FBI says it has ‘gained access’ to the Trump rally shooter’s phoneGoogle is reportedly planning its biggest startup acquisition everThe Google Pixel 9 just leaked againFBI is working to break into the phone of the Trump rally shooter Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From","The recent AI boom has had all sorts of weird and wonderful side effects as amateur tinkerers find ways to repurpose research from universities and tech companies. But one of the more unexpected applications has been in the world of video game mods. Fans have discovered that machine learning is the perfect tool to improve the graphics of classic games. 

The technique being used is known as “AI upscaling.” In essence, you feed an algorithm a low-resolution image, and, based on training data it’s seen, it spits out a version that looks the same but has more pixels in it. Upscaling, as a general technique, has been around for a long time, but the use of AI has drastically improved the speed and quality of results.

""“It was like witchcraft.”""

“It was like witchcraft,” says Daniel Trolie, a teacher and student from Norway who used AI to update the visuals of 2002 RPG classic The Elder Scrolls III: Morrowind. “[It] looked like I just downloaded a hi-res texture pack from [game developers] Bethesda themselves.” 

[Media: https://www.youtube.com/watch?v=cgNkFzLObkY]

Trolie is a moderator at the r/GameUpscale subreddit where, along with specialist forums and chat apps like Discord, fans share tips and tricks on how to best use these AI tools. 

Browsing these forums, it’s apparent that the modding process is a lot like restoring old furniture or works of art. It’s a job for skilled craftspeople, requiring patience and knowledge. Not every game is a good fit for upscaling, and not every upscaling algorithm produces similar results. Modders have to pick the right tool for the job before putting in hundreds of hours of work to polish the final results. It’s a labor of love, not a quick fix. 

Despite the work involved, it’s still much faster than previous methods. It means restoring the graphics can be done in a few weeks by a single dedicated modder, rather than a team that has to work for years. As a consequence, there’s been an explosion of new graphics for old games over the past six months or so. 

The range of titles is impressive, including Doom, Half-Life 2, Metroid Prime 2, Final Fantasy VII, and Grand Theft Auto: Vice City. Even more recent fare like 2010’s Mass Effect 2 has got the AI-upscaling treatment. In each case, though, these are unsanctioned upgrades, meaning it takes a bit of extra know-how to install the new visuals.

[Media: https://twitter.com/andrewrstine/status/1072238889673252864?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1072238889673252864&ref_url=https%3A%2F%2Fkotaku.com%2Fajax%2Finset%2Fiframe%3Fid%3Dtwitter-1072238889673252864%26autosize%3D1]

Actually creating these AI graphics takes a lot of work, explains a modder who goes by the name hidfan. He tells The Verge that the updated Doom visuals he made took at least 200 hours of work to tweak the algorithm’s output and clean up final images by hand.

In Doom, as with many video games, the majority of the visuals are stored as texture packs. These are images of rocks, metal, grass, and so on that are pasted onto the game’s 3D maps like wallpaper onto the walls of a house. Just as with wallpaper, these textures have to tesselate perfectly, or players can spot where one image starts and another begins. 

Because the output from AI upscaling algorithms tends to introduce a lot of noise, says hidfan, a lot of manual editing is still required. The same is true when it comes to the visuals for characters and enemies. Hidfan says that cleaning up just a single monster takes between five and 15 hours, depending on how complex their animation is. 

That’s something to remember when looking at these updates or any project that uses machine learning. Just because AI is involved, doesn’t mean human labor isn’t.

[Image: Updated Doom graphics created by hidfan. On the left is the original image; on the right is the AI-enhanced version. https://cdn.vox-cdn.com/thumbor/i7Hy4lguCf-nmf16Zc3lnTU1QZ4=/0x0:2048x1022/2048x1022/filters:focal(1024x511:1025x512)/cdn.vox-cdn.com/uploads/chorus_asset/file/16160913/Screen_Shot_2019_04_18_at_10.46.28_AM.png]

But how does the process actually work? Albert Yang, CTO of Topaz Labs, a startup that offers a popular upscaling service used by many modders, says it’s pretty straightforward. 

You start by taking a type of algorithm known as a generative adversarial network (GAN) and train it on millions of pairs of low-res and high-res images. “After it’s seen these millions of photos many, many times it starts to learn what a high resolution image looks like when it sees a low resolution image,” Yang tells The Verge.

One part of the algorithm tries to re-create this transition from low-res to high-res, while another part compares its work against the training data, seeing if it can spot the difference and rejecting the output if not. This feedback loop is how GANs improve over time. 

Using AI to upscale images is a relatively simple task, but it perfectly illustrates the core advantage of machine learning. While traditional algorithms rely on rules defined by humans, machine learning techniques create their own rules by learning from data. 

[Image: A comparison of a traditional upscaling technique (“nearest neighbor”) and the AI-enhanced version (“ESRGAN”). https://cdn.vox-cdn.com/thumbor/gtsJbpAhxhc60Z7hKn7eyagLU-w=/0x0:593x539/593x539/filters:focal(297x270:298x271):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/16033641/jbhpQZLoeWwNdmqsEq94Je_650_80.gif]

In the case of upscaling algorithms, these rules are often pretty simple. If you want to upscale a 50 x 50-pixel image to double its size, for example, a traditional algorithm just inserts new pixels between the existing ones, selecting the new pixels’ color based on an average of its neighbors. To give a very simplified example: if you have a red pixel on one side and a blue pixel on the other, the new pixel in the middle comes out purple. 

This sort of method is simple to code and execute, but it’s a one-size-fits-all approach that produces mixed results, says Yang.

The algorithms created by machine learning are much more dynamic by comparison. Topaz Labs’ Gigapixel upscaling doesn’t just look at neighboring pixels; it looks at whole sections of images at a time. That allows it to better re-create larger structures, like the outlines of buildings and furniture or the edges of a racetrack in Mario Kart.

“This larger perceptual field is the major reason [AI upscaling algorithms] perform so much better,” says Yang. 

[Media: https://www.youtube.com/watch?v=39xrl9z2ZZs]

Updating game graphics is more than just a technical challenge, though. It’s often about salvaging memories. Replaying the favorite video games of one’s youth can be a surprisingly bittersweet experience: the memories are intact, but the games themselves seem strangely ugly and raw. “Was I really impressed by those graphics?” you ask yourself, wondering if you’ve lost the capacity to enjoy such games altogether. 

Take the Final Fantasy series, for example. These were titles I played extensively as a child. Just hearing songs from their soundtracks can transport me back to specific in-game moments and locations. But playing the games again as an adult is a weird experience. I usually don’t get too far when I try, despite the treasured place they hold in my memory. They just look bad. 

Modder Stefan Rumen, who used AI upscaling to improve the graphics of Final Fantasy VII, explains that new display technology is as much to blame for this as outdated graphics. 

“With the pixel/low polygon graphics of yesteryear, the old TV monitors helped gloss over many imperfections,” he says. “Your mind finished the job and filled in the gaps [but] modern displays show these old games in their un-filtered roughness.” 

[Media: https://www.youtube.com/watch?v=OaEgc46FNWE]

Luckily, these early games are also the perfect target for AI upscaling. In the case of the Final Fantasy series, that’s partly because of their extensive use of pre-rendered backgrounds, which mean modders have to process fewer images. The visuals also occupy a “sweet spot” in terms of detail, says Rumen. 

“They’re not as low-res as pixel art, meaning there’s more information for the machine learning to do its magic, but it’s not a too high resolution that an upscale wouldn’t be needed,” he says. The results speak for themselves. 

Rumen says that Final Fantasy VII isn’t actually a game he played when he was young. (“I was a PC kid.”) But by updating the graphics, he’s making these classics accessible once more. They’ve convinced me, anyway. I’ve just downloaded Rumen’s AI graphics pack myself and am getting ready to play FFVII once more. 

Correction April 18th, 11:00AM ET: An earlier version of this article included mention of a SNES emulation mod as an example of AI upscaling. This mod does not use machine learning that we know of and has been removed from the article. We regret the error. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmRvd250b2VhcnRoLm9yZy5pbi9ibG9nL2Vjb25vbXkvcmlzZS1vZi10aGUtbWFjaGluZXMtd2h5LWluZGlhLW5lZWQtbm90LWJlLWFmcmFpZC02NDAzMtIBAA?oc=5,Rise of the machines: Why India need not be afraid - Down To Earth Magazine,2019-04-17,Down To Earth Magazine,https://www.downtoearth.org.in,,"Economy,Unemployment,artificial intelligence,robotics","At a time when India is worried about the lack of adequate jobs, it is but natural that eyebrows will be raised on innovations that tend to perform humans’ task","At a time when India is worried about the lack of adequate jobs, it is but natural that eyebrows will be raised on innovations that tend to perform humans’ task",http://schema.org,NewsArticle,https://www.downtoearth.org.in/economy/rise-of-the-machines-why-india-need-not-be-afraid-64032,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Down To Earth', 'url': 'https://www.downtoearth.org.in', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'downtoearth', 'contentUrl': 'https://thumbor-stg.assettype.com/downtoearth/2024-03/6387df98-00ed-4b50-b1fb-ae54adbb9dce/DTE_English.png', 'url': 'https://thumbor-stg.assettype.com/downtoearth/2024-03/6387df98-00ed-4b50-b1fb-ae54adbb9dce/DTE_English.png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.facebook.com/down2earthindia', 'https://twitter.com/down2earthindia', 'https://www.youtube.com/channel/UCIB_MLJZL0T_s5OUuqhmbVA', 'https://www.instagram.com/dtemagazine/'], 'id': 'https://www.downtoearth.org.in'}",2019-04-17T04:22:02Z,2019-04-18T01:15:05Z,Rise of the machines: Why India need not be afraid,"{'@type': 'ImageObject', 'url': 'https://gumlet.assettype.com/down-to-earth/import/library/large/2019-04-17/0.95389300_1555494993_new.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",https://gumlet.assettype.com/down-to-earth/import/library/large/2019-04-17/0.95389300_1555494993_new.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'WebPage', '@id': 'https://www.downtoearth.org.in/economy/rise-of-the-machines-why-india-need-not-be-afraid-64032'}","[{'@type': 'Person', 'givenName': 'Balaji SJ', 'name': 'Balaji SJ', 'url': 'https://www.downtoearth.org.in/author/balaji-sj'}, {'@type': 'Person', 'givenName': 'M Umanath', 'name': 'M Umanath', 'url': 'https://www.downtoearth.org.in/author/m-umanath'}]",N/A,N/A,N/A,"At a time when India is worried about the lack of adequate jobs, it is but natural that eyebrows will be raised on innovations that tend to perform humans’ tasks. This is similar to our apprehensions in the past about computers taking over workers upon mass adoption..Today, we see computers and laptops as indispensable goods in every domain. In fact, they have performed miracles — from assisting in controlling missiles to tracing water beneath dry soil..The new set of buzz words that have entered our lexicon due to computers include workplace automation, artificial intelligence (AI), robotisation, virtual assistance and block chain. The Google Assistant can now fairly remind your schedules, browse nearest coffee shops and plan for your health check-up on a single command. The Aristotle, a programmable device of Mattel, can read bedtime stories to the kids and teach foreign words to the toddlers. The Steve, a security robot, can walk around a place and detect potential fires. The nanny-robots can monitor a chicken’s health. The list keeps growing by the day. By 2025, robotics is predicted to be a $67 billion sector..State of affairs.Coming back to the issue of jobs, the claims about the impact of the aforesaid technologies are rather far-fetched. For starters, let us have a look at the employment share of different sectors in India. As per the Reserve Bank of India’s database, of a total 48 crore workers in the year 2015-16, 42 per cent were in agriculture, 14 per cent in construction, 12 per cent in trade, restaurants and hotels, another 12 per cent in manufacturing, 11 per cent in community, social and personal services, and the rest were in other industries. Within the 42 per cent in agriculture, 27 per cent were farmers and 15 per cent were agricultural labourers..But much of the new jobs generated in the past were restricted to very few industries. Between 2010-11 and 2015-16, around 1.5 crore new entrants joined the workforce throughout the country, averaging around 70 lakh new workers each year. Business services attracted these entrants the most (23 per cent), followed by manufacturing (17 per cent), education (12 per cent), trade (11 per cent) and transport and storage (11 per cent)..Even within manufacturing, there were job losses. The textile and leather sectors lost around 12 lakh workers and the wood and furniture sector has lost around 9 lakh workers during these five years. Much of the employment has happened in the electronic and optical equipment industries. The food and beverages sector attracted just 1 lakh new entrants a year..It is noteworthy to mention that during these five years alone, around 2.7 crore workers have left agriculture, including farmers. Almost equal in size, the construction sector has registered about 2.5 crore new workers, signaling the fact that much of the agricultural workers have now turned into construction workers..This ‘supply shock’, along with a shift into the Mahatma Gandhi National Rural Employment Guarantee Act, has created an enormous increase in agricultural wages, the burden of which is ultimately passed on to the farmers. The statistics from the Centre for Monitoring Indian Economy shows that between 2014 and 2018 alone, agricultural wages of men have risen by 27 per cent and for operations like picking, it stands as high as 41 per cent..What is more interesting is that wages have risen by only 24 per cent in construction where most of the agricultural workers have shifted. Dominated by small holders who make up 86 per cent of all farmers, a rise in cost, propelled by rising wages, could harm farm earnings..Hence, the need of the hour is to move towards mechanised agriculture, prompted by cost-effective/affordable customs-hiring models that could compensate this labour shock and improve farmers' income. While these models have succeeded in a few states, a full-fledged adoption is yet to be realised..This trend of shifting into construction and other sectors would continue in the future as well. This is because non-farm jobs offer higher wages than agriculture. The wage rate in agriculture during last December (2018) was Rs 299 a day, whereas it was Rs 332 for a construction worker, Rs 426 for a carpenter, Rs 351 for a blacksmith, Rs 472 for a mason, Rs 443 for a plumber and Rs 427 for an electrician. With a little effort, an unskilled agricultural worker could get trained on these tasks. Moreover, they require no new skill to enter into the construction workforce..Another reason, in our view, is that there exists huge under-employment in agriculture. Farmers and labourers are available and willing to work for additional days and months, but they can’t get enough work. Our estimates using the Labour Bureau’s records showed that about 70 per cent of casual labourers in agriculture and 49 per cent of farmers are underemployed. In absolute size, this translates to 6.4 crore farmers and 5.0 crore agricultural labourers. When such a huge mass is placed in an environment where there are less jobs, it is natural for one to expect to migrate into high paying non-farm and urban jobs..Employing drones and robots or applications of AI and other innovations might not altogether worsen unemployment. Much of the developed countries’ applications of AI are in the finance, transportation, healthcare and defence sectors. In India, we have not more than seven per cent of workers in these sectors. The uses of robots are in the fields of manufacturing, construction, rescue operations and personal security. While one could think of threats to jobs in manufacturing and construction as we have high share of workers, it could still not be the case..For example, of the 5.7 crore workers employed in manufacturing industries during the year 2015-16, only 1.1 crore belong to formal industries. If we assume an average of 4 lakh new jobs generated in formal manufacturing each year and assume automation to the level of 10 per cent, the maximum possible job-loss turns out to be 40,000. And not all the industries would be able to afford automation for cost reasons. If we further assume an adoption of 20 per cent industries, this further boils down to 8,000. One could observe similar possibilities in the other sectors as well. In agriculture, one can barely expect to generate job losses as applications in pest surveillance and weather forecasting involve literally no unskilled worker..New avenues.Rather, moving towards these technologies would open avenues for new jobs, especially in information and communication technologies and data sciences. To harness potential, we require to build institutional capabilities that train the young workforce for these sectors. There exists huge demand for skill building, not just in these emerging technologies but in the existing industries as well. Today, even in manufacturing, just 10 per cent have received some form of training. In agriculture, construction and trade, it’s just five per cent and in finance, it is six per cent. Overall, not more than six per cent workers are trained in India. While there are definite margins for skilled personnel, the attempt to deliver skill-training could itself generate sizeable employment..To end up, when sufficient institutional capabilities are built to train the workforce for future jobs and impart skills to the existing force, the threat to job loss could be a lesser menace. But generating jobs for the underemployed could still be a hard matter to deal with. Bumpy roads ahead..Balaji SJ is a scientist at ICAR-National Institute of Agricultural Economics and Policy Research (NIAP). Umanath is Assistant Professor at the Madras Institute of Development Studies, Chennai. Views expressed are personal",Economy,,,,,Rise of the machines: Why India need not be afraid,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.downtoearth.org.in'}, {'@type': 'ListItem', 'position': 2, 'name': 'Economy', 'item': 'https://www.downtoearth.org.in/economy'}, {'@type': 'ListItem', 'position': 3, 'name': 'Rise of the machines: Why India need not be afraid', 'item': 'https://www.downtoearth.org.in/economy/rise-of-the-machines-why-india-need-not-be-afraid-64032'}]",2019-04-17T04:22:02Z,,,,,"{'@type': 'WebPage', 'url': 'https://www.downtoearth.org.in/economy/rise-of-the-machines-why-india-need-not-be-afraid-64032', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://gumlet.assettype.com/down-to-earth/import/library/large/2019-04-17/0.95389300_1555494993_new.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",

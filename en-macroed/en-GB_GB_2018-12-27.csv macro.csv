URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,@graph,mainEntityOfPage,alternativeHeadline,hasPart,copyrightHolder,sourceOrganization,copyrightYear,isPartOf,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,articleBody,isBasedOn,thumbnailUrl,dateCreated,identifier,creator,telephone,address,contactPoint
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAxOC8xMi8zMS90aGUtbW9zdC1hbWF6aW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW1pbGVzdG9uZXMtc28tZmFyL9IBAA?oc=5,The Most Amazing Artificial Intelligence Milestones So Far - Forbes,2018-12-31,Forbes,https://www.forbes.com,"Artificial Intelligence is everywhere, and sometimes it feels like something that has just emerged out of nothing. Here we look at the key milestones in the journey towards AI.",,"Artificial Intelligence is everywhere, and sometimes it feels like something that has just emerged out of nothing. Here we look at the key milestones in the journey towards AI.","Artificial Intelligence is everywhere, and sometimes it feels like something that has just emerged out of nothing. Here we look at the key milestones in the journey towards AI.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2018/12/31/the-most-amazing-artificial-intelligence-milestones-so-far/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2018/12/AdobeStock_220811776-1200x686.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",The Most Amazing Artificial Intelligence Milestones So Far,2018-12-31T00:22:00-05:00,2021-12-10T08:30:38-05:00,Enterprise & Cloud,The Most Amazing Artificial Intelligence Milestones So Far,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,N/A,"More From ForbesJul 8, 2024,09:00am EDTSee The Future Data Center At The Israeli Quantum Computing CenterJun 30, 2024,09:00am EDTWar Can’t Stop Israeli Startups Determined To Thrive In The DesertJun 6, 2024,06:00am EDTIsraeli Startup Combines Software With Medicine To Transform $1.6 Trillion Pharma MarketMay 22, 2024,12:18pm EDT$20M Fund For Connecting Early-Stage Israeli Startups To New York CityMay 20, 2024,09:00am EDTBiomed 2024 Showcases Israel’s Resilient Entrepreneurial SpiritApr 30, 2024,09:00am EDTAI Is Moving Biology From Science To Engineering, Advancing MedicineApr 10, 2024,09:00am EDTThis Startup Wants To Be OpenAI Of Stem Cell Therapy, Targets $250B MarketEdit StoryForbesInnovationEnterprise TechThe Most Amazing Artificial Intelligence Milestones So FarBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 31, 2018,12:22am ESTUpdated Dec 10, 2021, 08:30am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinArtificial Intelligence (AI) is the hot topic of the moment in technology, and the driving force behind most of the big technological breakthroughs of recent years.
In fact, with all of the breathless hype we hear about it today, it's easy to forget that AI isn't anything all that new. Throughout the last century, it has moved out of the domain of science fiction and into the real world. The theory and the fundamental computer science which makes it possible has been around for decades.









The Most Amazing Artificial Intelligence Milestones So Far
Adobe Stock





Since the dawn of computing in the early 20th century, scientists and engineers have understood that the eventual aim is to build machines capable of thinking and learning in the way that the human brain – the most sophisticated decision-making system in the known universe – does.
PROMOTED
Today’s cutting-edge deep learning using artificial neural networks are the current state-of-the-art, but there have been many milestones along the road which have made it possible. Here's my rundown of those that are generally considered to be the most significant.

1637 – Descartes breaks down the difference
Long before robots were even a feature of science fiction, scientist and philosopher Rene Descartes pondered the possibility that machines would one day think and make decisions. While he erroneously decided that they would never be able to talk like humans, he did identify a division between machines which might one day learn about performing one specific task, and those which might be able to adapt to any job. Today, these two fields are known as specialized and general AI. In many ways, he set the stage for the challenge of creating AI.
1956 – The Dartmouth Conference
With the emergence of ideas such as neural networks and machine learning, Dartmouth College professor John McCarthy coined the term ""artificial intelligence"" and organized an intensive summer workshop bringing together leading experts in the field.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



During the brainstorming session, attempts were made to lay down a framework to allow academic exploration and development of “thinking” machines to begin. Many fields which are fundamental to today’s cutting-edge AI, including natural language processing, computer vision, and neural networks, were part of the agenda.
1966 – ELIZA gives computers a voice
ELIZA, developed at MIT by Joseph Weizenbaum, was perhaps the world’s first chatbot – and a direct ancestor of the likes of Alexa and Siri. ELIZA represented an early implementation of natural language processing, which aims to teach computers to communicate with us in human language, rather than to require us to program them in computer code, or interact through a user interface. ELIZA couldn’t talk like Alexa – she communicated through text – and she wasn’t capable of learning from her conversations with humans. Nevertheless, she paved the way for later efforts to break down the communication barrier between people and machines.
1980 – XCON and the rise of useful AI
Digital Equipment Corporation’s XCON expert learning system was deployed in 1980 and by 1986 was credited with generating annual savings for the company of $40 million. This is significant because until this point AI systems were generally regarded as impressive technological feats with limited real-world usefulness. Now it was clear that the rollout of smart machines into business had begun – by 1985 corporations were spending $1 billion per year on AI systems.
1988 – A statistical approach
IBM researchers publish A Statistical Approach to Language Translation, introducing principles of probability into the until-then rule-driven field of machine learning. It tackled the challenge of automated translation between human languages – French and English.
This marked a switch in emphasis to designing programs to determine the probability of various outcomes based on information (data) they are trained on, rather than training them to determine rules. This is often considered to be a huge leap in terms of mimicking the cognitive processes of the human brain and forms the basis of machine learning as it is used today.
1991 – The birth of the Internet
The importance of this one can't be overstated. In 1991 CERN researcher Tim Berners-Lee put the world's first website online and published the workings of the hypertext transfer protocol (HTTP). Computers had been connecting to share data for decades, mainly at educational institutions and large businesses. But the arrival of the worldwide web was the catalyst for society at large to plug itself into the online world. Within a few short years, millions of people from every part of the world would be connected, generating and sharing data – the fuel of AI - at a previously inconceivable rate.
1997 – Deep Blue defeats world chess champion Garry Kasparov
IBM’s chess supercomputer didn’t use techniques that would be considered true AI by today’s standards. Essentially it relied on “brute force” methods of calculating every possible option at high speed, rather than analyzing gameplay and learning about the game. However, it was important from a publicity point of view – drawing attention to the fact that computers were evolving very quickly and becoming increasingly competent at activities at which humans previously reigned unchallenged.
2005 – The DARPA Grand Challenge
2005 marked the second year that DARPA held its Grand Challenge – a race for autonomous vehicles across over 100 kilometers of off-road terrain in the Mojave desert. In 2004, none of the entrants managed to complete the course. The following year, however, five vehicles made their way around, with the team from Stanford University taking the prize for the fastest time.
The race was designed to spur the development of autonomous driving technology, and it certainly did that. By 2007, a simulated urban environment had been constructed for vehicles to navigate, meaning they had to be able to deal with traffic regulations and other moving vehicles.
2011 – IBM Watson’s Jeopardy! Victory
Cognitive computing engine Watson faced off against champion players of the TV game show Jeopardy!, defeating them and claiming a $1 million prize. This was significant because while Deep Blue had proven over a decade previously that a game where moves could be described mathematically, like chess could be conquered through brute force, the concept of a computer beating humans at a language based, the creative-thinking game was unheard of.
2012 – The true power of deep learning is unveiled to the world – computers learn to identify cats
Researchers at Stanford and Google including Jeff Dean and Andrew Ng publish their paper Building High-Level Features Using Large Scale Unsupervised Learning, building on previous research into multilayer neural nets known as deep neural networks.
Their research explored unsupervised learning, which does away with the expensive and time-consuming task of manually labeling data before it can be used to train machine learning algorithms. It would accelerate the pace of AI development and open up a new world of possibilities when it came to building machines to do work which until then could only be done by humans.
Specifically, they singled out the fact that their system had become highly competent at recognizing pictures of cats.
The paper described a model which would enable an artificial network to be built containing around one billion connections. It also conceded that while this was a significant step towards building an ""artificial brain,"" there was still some way to go – with neurons in a human brain thought to be joined by a network of around 10 trillion connectors.
2015 – Machines “see” better than humans
Researchers studying the annual ImageNet challenge – where algorithms compete to show their proficiency in recognizing and describing a library of 1,000 images – declare that machines are now outperforming humans.
Since the contest was launched in 2010, the accuracy rate of the winning algorithm increased from 71.8% to 97.3% - promoting researchers to declare that computers could identify objects in visual data more accurately than humans.
2016 – AlphaGo goes where no machine has gone before
Gameplay has long been a chosen method for demonstrating the abilities of thinking machines, and the trend continued to make headlines in 2016 when AlphaGo, created by Deep Mind (now a Google subsidiary) defeated world Go champion Lee Sedol over five matches. Although Go moves can be described mathematically, the sheer number of the variations of the game that can be played – there are over 100,000 possible opening moves in Go, compared to 400 in Chess) make the brute force approach impractical. AlphaGo used neural networks to study the game and learn as it played.
2018 – Self-driving cars hit the roads
The development of self-driving cars is a headline use case for today’s VR – the application which has captured the public imagination more than any other. Like the AI that powers them, they aren’t something which has emerged overnight, despite how it may appear to someone who hasn’t been following technology trends. General Motors predicted the eventual arrival of driverless vehicles at the 1939 World’s Fair. The Stanford Cart – originally built to explore how lunar vehicles might function, then repurposed as an autonomous road vehicle – was debuted in 1961.
But there can be no doubt that 2018 marked a significant milestone, with the launch of Google spin-off Waymo’s self-driving taxi service in Phoenix, Arizona. The first commercial autonomous vehicle hire service, Waymo One is currently in use by 400 members of the public who pay to be driven to their schools and workplaces within a 100 square mile area.
While human operators currently ride with every vehicle, to monitor their performance and take the controls in case of emergency, this undoubtedly marks a significant step towards a future where self-driving cars will be a reality for all of us.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vd3d3LmluZm9ybWF0aW9uLWFnZS5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtMjAxOC0yMDE5LTkzMTIv0gEA?oc=5,Artificial intelligence: What changed in 2018 and what to expect in 2019 - Information Age,2018-12-27,Information Age,https://www.information-age.com,"In the artificial intelligence and machine learning space, 2019 will see the rise of the intelligent application",N/A,"In the artificial intelligence and machine learning space, 2019 will see the rise of the intelligent application",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

Artificial intelligence (AI) is one of those technologies that excites the public and business imagination alike. Long since a favourite theme in science-fiction, it is now gaining traction in everyday practical scenarios.





In 2018, we saw a considerable rise in the adoption of AI around the world and across industries, with businesses using it to improve operations, generate new innovations and boost customer experience.

Investing in artificial intelligence: What businesses need to know
To make artificial intelligence work for a business, leaders need to ensure that employee skills are honed in line with technological investments. Read here
With financial services, telecoms and high tech leading the way in bringing AI into the mainstream, and other areas such as automotive, healthcare, energy and retail also embracing it, we expect the rapid growth of AI to continue in 2019 as companies strive to get the most value and competitive advantage from the data they capture. Let’s take a look at what’s been powering the rise of AI recently and what might be around the corner.
Data skills
Data is the fuel for AI. As data collection, analysis and storage abilities dramatically improved over recent years, most companies found themselves with a huge potential resource and yet under-equipped to wrestle with such high volumes of information.
In 2018, that started to change, as the people skills made headway in catching up with the technology. There remains a lot of complexity around how data is handled and used, but businesses are starting to see a deeper understanding of the specific skills needed to help companies bear fruit from data, and how these can be mapped onto ‘personas’ they can train up, or recruit.
Businesses are steadily learning how data scientists and AI developers work differently from traditional app developers, the tools they need, and how to bring them into app dev teams cohesively.
>See also: A deep look into artificial intelligence, machine learning and data science
For vendors in this space, the challenge is to make AI more easily accessible for all developers. Some are building machine learning frameworks to help organisations apply AI across use cases.
In 2019, vendors and enterprises alike need to continue to broaden their skill set, training existing developers and bringing new data scientists on board. To target the shortage of data scientists (and other data worker personas) at its roots, as a society we need to engage and inspire young people to boost demand in the education system, as well as supply that education. With a continued push expected this year and beyond, AI can fulfil its potential ‘superpower’ status for developers, helping them tap rich new sources of innovation.
Chatbots
One use case that has become more prevalent in the last twelve months is chatbots. Chatbots’ increase in popularity stems from businesses’ desire to give users the same experience online as they would get in-store – be they retail banking customers, healthcare patients, retail shoppers, or whoever else.
>See also: AI: from hype to reality in healthcare
Chatbots are great because they can respond very quickly to customers and deliver personalised care by taking advantage of data analysis and algorithms to determine the category a user falls into.
Machine learning (ML) frameworks
One of the biggest surprises in this area of 2018 was to see the consolidation of machine learning frameworks continue. There have been AI and ML libraries and projects for decades, but in the past 5-7 years we’ve seen a lot more investment in building deep learning libraries and artificial neural networks. Some of the big players in this area have poured tremendous amounts of resource and efforts into this, pulling in scarce talent.
With these corporations having access to much greater amounts of infrastructure for storage and compute power than universities could supply, they have transitioned many researchers from the academic space to the corporate space. With such heavy investment, it was easy to expect these key players to want to keep their assets closed for a few more years in order to monetise the value they have amassed.
>See also: AI in the workplace – what executives need to consider
There is obvious benefit to be gained collectively from building together, such as faster innovation and more freedom of choice for developers, and there is also a large-scale push more generally in the direction of open source in the tech industry today. It could also be said that in the context of today’s huge wave of cloud computing, even these high value frameworks can simply be drivers of workloads on top of the cloud infrastructures these big players have.
The intelligent application
With almost 8.5 billion mobile connections globally and counting, (see GSMA data), many of us use a smartphone, if not multiple smartphones, daily. Probably half or more of your mobile applications will have AI functionality, either directly embedded into the app or supporting it in the back-end. For example, your keyboard learns how you – and everyone else – interacts with it to improve how it works.
If you want to buy something through an online retailer, it will make recommendations based on your purchase history as well as typical buying habits using an AI engine. Ride-sharing apps and navigation apps use AI to calculate how to connect various users on a route. Intelligent applications are likely to continue to gather steam in 2019.
Avoiding bias
Any new technology may bring pitfalls that have not been fully anticipated. We’re finding with AI that the algorithms are only as good as the training data they are using, which can have negative consequences. The issue of how humans can pass on their own biases and prejudices to algorithms with damaging results, in anything from crime prediction to language translation, became better known in 2018.
>See also: How to harness AI to improve workplace efficiency
This should be given a lot more attention, and hope to see real action to address this challenge in 2019. Vendors need to think about how they can offer tools and tutorials to help less experienced data scientists, developers and businesses at large gain a better understanding of data and the human impact of AI. Together, we can develop a more structural approach to the problem.
To be continued…
The application of artificial intelligence and machine learning will solve business problems and bring new ideas to life to continue into 2019 as companies strive to get the most business value and competitive advantage from their existing data. Watch this space.
Sourced by Kim Palko, principal product manager, Data and Analytics, Red Hat JBoss, and Matthew Farrellee, Emerging Technology & Strategy, CTO Office, Red Hat


Tagged: Artificial Intelligence, Chatbots, Machine Learning, Smartphone 






					Nick Ismail					




				Nick Ismail is a former editor for Information Age (from 2018 to 2022) before moving on to become Global Head of Brand Journalism at HCLTech. He has a particular interest in smart technologies, AI and...				
				More by Nick Ismail				



","[{'@type': 'Article', '@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#article', 'isPartOf': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/'}, 'author': {'name': 'Nick Ismail', '@id': 'https://www.information-age.com/#/schema/person/4aadc26dcee71ce0fc2931dd5acf3f6e'}, 'headline': 'Artificial intelligence: What changed in 2018 and what to expect in 2019', 'datePublished': '2018-12-27T08:20:45+00:00', 'dateModified': '2022-12-01T12:30:41+00:00', 'mainEntityOfPage': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/'}, 'wordCount': 1113, 'publisher': {'@id': 'https://www.information-age.com/#organization'}, 'image': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#primaryimage'}, 'thumbnailUrl': 'https://informationage-production.s3.amazonaws.com/uploads/2022/10/AdobeStock_122106614-scaled.jpeg', 'keywords': ['Artificial Intelligence', 'Chatbots', 'Machine Learning', 'Smartphone'], 'articleSection': ['AI &amp; Machine Learning', 'Consumer Electronics &amp; Mobile'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/', 'url': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/', 'name': 'Artificial intelligence: What changed in 2018 and what to expect in 2019', 'isPartOf': {'@id': 'https://www.information-age.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#primaryimage'}, 'image': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#primaryimage'}, 'thumbnailUrl': 'https://informationage-production.s3.amazonaws.com/uploads/2022/10/AdobeStock_122106614-scaled.jpeg', 'datePublished': '2018-12-27T08:20:45+00:00', 'dateModified': '2022-12-01T12:30:41+00:00', 'description': 'In the artificial intelligence and machine learning space, 2019 will see the rise of the intelligent application', 'breadcrumb': {'@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.information-age.com/artificial-intelligence-2018-2019-9312/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#primaryimage', 'url': 'https://informationage-production.s3.amazonaws.com/uploads/2022/10/AdobeStock_122106614-scaled.jpeg', 'contentUrl': 'https://informationage-production.s3.amazonaws.com/uploads/2022/10/AdobeStock_122106614-scaled.jpeg', 'width': 2560, 'height': 1707}, {'@type': 'BreadcrumbList', '@id': 'https://www.information-age.com/artificial-intelligence-2018-2019-9312/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.information-age.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Topics', 'item': 'https://www.information-age.com/topics/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI &amp; Machine Learning', 'item': 'https://www.information-age.com/topics/ai-machine-learning/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Artificial intelligence: What changed in 2018 and what to expect in 2019'}]}, {'@type': 'WebSite', '@id': 'https://www.information-age.com/#website', 'url': 'https://www.information-age.com/', 'name': 'Information Age', 'description': 'Insight and Analysis for the CTO', 'publisher': {'@id': 'https://www.information-age.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.information-age.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.information-age.com/#organization', 'name': 'Information Age', 'url': 'https://www.information-age.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.information-age.com/#/schema/logo/image/', 'url': 'https://s42137.p1364.sites.pressdns.com/wp-content/uploads/2022/09/IA_NEW_LOGO_2018_RGB.png', 'contentUrl': 'https://s42137.p1364.sites.pressdns.com/wp-content/uploads/2022/09/IA_NEW_LOGO_2018_RGB.png', 'width': 400, 'height': 50, 'caption': 'Information Age'}, 'image': {'@id': 'https://www.information-age.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/informationage/', 'https://x.com/InformationAge', 'https://www.linkedin.com/company/information-age/', 'https://www.youtube.com/informationage']}, {'@type': 'Person', '@id': 'https://www.information-age.com/#/schema/person/4aadc26dcee71ce0fc2931dd5acf3f6e', 'name': 'Nick Ismail', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.information-age.com/#/schema/person/image/', 'url': 'https://informationage-staging.s3.eu-west-2.amazonaws.com/uploads/2022/11/Nick_Ismail-96x96.jpeg', 'contentUrl': 'https://informationage-staging.s3.eu-west-2.amazonaws.com/uploads/2022/11/Nick_Ismail-96x96.jpeg', 'caption': 'Nick Ismail'}, 'description': 'Nick Ismail is a former editor for Information Age (from 2018 to 2022) before moving on to become Global Head of Brand Journalism at HCLTech. He has a particular interest in smart technologies, AI and cyber security.', 'sameAs': ['https://uk.linkedin.com/in/nicholas-ismail-480a069b'], 'url': 'https://www.information-age.com/author/nickismail/'}]",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vYmR0ZWNodGFsa3MuY29tLzIwMTgvMTIvMjgvdG9wLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXN0b3JpZXMtMjAxOC_SAVBodHRwczovL2JkdGVjaHRhbGtzLmNvbS8yMDE4LzEyLzI4L3RvcC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1zdG9yaWVzLTIwMTgvYW1wLw?oc=5,The biggest artificial intelligence developments of 2018 - TechTalks,2018-12-28,TechTalks,https://bdtechtalks.com,"2018 was a year of reckoning for the AI industry. In parallel to technological developments, there was ample focus on the ethical concerns of artificial intelligence technology.",N/A,"2018 was a year of reckoning for the AI industry. In parallel to technological developments, there was ample focus on the ethical concerns of artificial intelligence technology.","2018 was a year of reckoning for the AI industry. In parallel to technological developments, there was ample focus on the ethical concerns of artificial intelligence technology.",http://schema.org,BreadcrumbList,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://bdtechtalks.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/category/blog/', 'name': 'Blog'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/', 'name': 'The biggest artificial intelligence developments of 2018'}}]",N/A,N/A,"

Blog

The biggest artificial intelligence developments of 2018

By Ben Dickson -   December 28, 2018 




Facebook


Twitter


ReddIt


Linkedin




Google CEO Sundar Pichai introduces Duplex AI at I/O 2018 developer conference (Source: YouTube)
Last year, when I was rounding up the biggest artificial intelligence developments of 2017, I had a very hard time choosing which stories were most worth covering. In that regard, 2018 didn’t see much change. This year, we saw even more AI papers published and more innovation in the space than 2017.
But beyond innovation and technological advances, 2018 was perhaps a year of reckoning for the ethical implications of advances in AI technologies. Unlike previous cycles of AI’s rise and fall, in which the industry receded into its periodic winter without making any notable impact on everyday lives, today’s AI technologies have become pivotal to many of the things we do. And we need to think about what their negative impacts can be.
Without further ado, here are some of the most noteworthy AI stories of 2018. Looking forward to more exciting AI stories in 2019.
Google’s fascinating—and creepy—AI

In May, in Google’s yearly I/O developer conference, CEO Sundar Pichai revealed Duplex, an addition to the Google Assistant that could make calls on behalf of a user and perform tasks such as booking restaurant tables and hair salon appointments.
Duplex immediately inspired awe and cheers among the crowd that attended the conference because it sounded like a real human, and as the demos showed, the service workers who spoke to it didn’t know they were talking to an AI agent.

But immediately after the conference, tech outlets became filled with stories and commentary about the ethical implications of AI technologies that were hard to differentiate from humans. There were fears that such tools could serve questionable purposes, such as impersonating people or automating spam calls and phishing scams. Many people also rightly criticized Google for not disclosing to Duplex’s interlocutors that they were speaking with a bot (Google remedied that later).
As we discussed in these pages, it takes more than an automated, human-sounding voice to be able to engage in conversations at the level of human intelligence. So many of the concerns that surround the evil capabilities of Duplex AI are bloated, proven by its very limited and conservative release.
Controversy surrounding the use of facial recognition
Source: Depositphotos
Facial recognition technology is one of the areas that has benefited immensely from advances in deep learning and neural networks. More and more companies, organizations and government agencies are able to leverage AI-powered facial recognition technologies for different tasks. For obvious reasons, advocates of privacy and digital rights are worried about the implications of unfettered use of facial recognition by law enforcement.
One of the companies that came under much scrutiny was Amazon, which sells a commercial facial detection service named Rekognition. In May, the American Civil Liberties Union disclosed documents that showed Amazon was marketing Rekognition for government surveillance, including for tasks such as “person tracking” and identifying “persons of interest,” which ACLU interpreted as “undocumented immigrants” and “black activists.” ACLU further revealed that law enforcement in at least three cities were using Rekognition to surveil on citizens.
“People should be free to walk down the street without being watched by the government. By automating mass surveillance, facial recognition systems like Rekognition threaten this freedom, posing a particular threat to communities already unjustly targeted in the current political climate. Once powerful surveillance systems like these are built and deployed, the harm will be extremely difficult to undo,” ACLU warned.
In July, ACLU again raised concern about the failures of Rekognition. In another report, the organization showed that Rekognition misidentified the pictures of 28 members of Congress as documented criminals. “The false matches were disproportionately of people of color,” ACLU observed.
A spokesperson for Amazon told different outlets that the reason for the mistake was a misconfiguration by the researchers.
The use of Rekognition by police also caused tumult in Amazon’s own ranks. In a letter, 450 employees called on Amazon to stop selling the technology to law enforcement.
Amazon was not the only company having troubles over the use of facial recognition. In February, researchers at MIT Media Lab released findings that showed facial recognition systems developed by IBM and Microsoft suffered from algorithmic bias and were less accurate when detecting female and non-white faces. Both companies later reported that they had corrected the deficiencies in their algorithms
Microsoft president Brad Smith eventually addressed the controversies surrounding the use of AI-powered facial recognition in a famous blog post in which he stressed the need to support government and military institutions with cutting edge technology, but also called for further regulation of facial recognition technology.
Project Maven, Google’s ill-fated dabbling in military AI projects

In March, it became known that Google was partnering with the Department of Defense to develop AI for drones. The effort was part of a project codenamed Maven, whose stated mission is to “accelerate the DoD’s integration of big data and machine learning.” Google was reportedly helping in the use of artificial intelligence to detect objects in drone footage.
The U.S. military is already using drones to conduct air strikes against targets in foreign countries. The disclosure raised concerns that such efforts might help develop autonomous lethal weapons that enable an AI algorithms to designate and open fire on targets without the intervention of a human operator.
A spokesperson for Google disclosed that the company was only providing DoD with access to its TensorFlow application programming interface (API) to help automate the detection of objects in footages of surveillance drones, a task that places a heavy burden on analysts when done manually. The spokesperson also said that Google was working on policies and safeguards to make sure its technology would not be put to ill use.
Google’s explanations were not enough to assuage the concerns of industry experts and its own employees. Shortly after news of Google’s involvement in Project Maven became public, more than 3,000 Google employees signed an open letter to Pichai and called for the termination of the development of a possibly lethal AI technology. “We cannot outsource the moral responsibility of our technologies to third parties,” the employees wrote in their letter.
The Google employees’ letter was followed by a similar petition by 90 academics in artificial intelligence, ethics, and computer science that called on Google to end its work on military AI. “While the reports on Project Maven currently emphasize the role of human analysts, these technologies are poised to become a basis for automated target recognition and autonomous weapon systems,” the academics wrote in their letter.
The signatories also warned that as AI-based object detection becomes reliable and trustworthy, its implementers will be wont to trust it in more sensitive tasks. “We are then just a short step away from authorizing autonomous drones to kill automatically, without human supervision or meaningful human control,” the academics warned.
Months later, several Google employees resigned in protest to the company’s continued involvement in developing AI products that could serve lethal purposes. “I tried to remind myself right that Google’s decisions are not my decisions. I’m not personally responsible for everything they do. But I do feel responsibility when I see something that I should escalate it,” one of the resigning employees said.
Under pressure from its employees and the AI community, Google announced in June that it would not be renewing its contract to work on Project Maven after it expires in 2019. Subsequently, Pichai published a set of ethical principles that Google will follow from now on when working on AI projects. Pichai explicitly stated that his company will not be pursuing the development of AI technologies related to weapons, surveillance or anything that can cause harm.
Amazon abandons AI recruiting technology due to bias

In October, Reuters reported that Amazon had scrapped an AI recruiting tool because it was discriminating against women. Amazon’s hiring team had been experimenting with the tool to review resumes and shortlist candidates for job positions.
Amazon employs more than 500 thousand people across the world. A reliable AI-driven hiring software could help slash the costs and efforts required to manage the tens of thousands of job applications that the company has to process every year.
But as the episode shows, automating tasks that require human intuition and commonsense are very hard, and as we’ve examined in these pages, contrary to mythical beliefs, AI algorithms will inherit—and amplify—our individual and societal biases. Like most other tech companies, Amazon is dominated by white men, which means whatever data was used to train its machine learning algorithms already contained these same biases. As a result, the AI algorithms had found a tendency to favor male candidates.
OpenAI matched up against professional Dota 2 players—and lost

Moving on from ethical issues, there were some interesting developments in AI projects that made the headlines this year. Playing and mastering games has always been one of the main areas of focus of artificial intelligence researchers. After beating chess and Go champions, AI experts have set their eyes on computer games such as StarCraft and Dota 2.
These games are much more complicated than board games because first, users must make decisions in real time, and second, they don’t have full information about the state of the game.
In June, OpenAI, the non-profit AI research lab that launched in 2015 with funding from Y Combinator president Sam Altman and Tesla CEO Elon Musk, introduced OpenAI Five, a team of five neural networks that had trained on 80 years’ worth of Dota 2 gameplay and had proven their worth against amateur human players.
In August, OpenAI Five participated in an international Dota 2 tournament and competed against professional players in a best-of-three series. It lost. But in spite of the defeat, the mere fact that deep learning algorithms were able to compete at such a high level was an achievement for the AI industry.
AI in 2019
2018 saw the maturation of the artificial intelligence industry. 2019 will surely see more interesting developments emerge. What do you think will be the biggest highlight of the AI industry in 2019? Share with us in the comments section.
Like this:Like Loading... 


TAGSAI ethicsArtificial intelligence (AI) 


Facebook


Twitter


ReddIt


Linkedin


 Previous articleThe security threats of neural networks and deep learning algorithmsNext articleMajor cybersecurity breaches and data leaks in 2018; business as usual Ben DicksonBen is a software engineer and the founder of TechTalks. He writes about technology, business and politics.




  
","[{'@type': 'BlogPosting', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#blogposting', 'name': 'The biggest artificial intelligence developments of 2018 - TechTalks', 'headline': 'The biggest artificial intelligence developments of 2018', 'author': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'publisher': {'@id': 'https://bdtechtalks.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2018/12/Google-IO-2018-sundar-pichai-keynote-Duplex.png?fit=3350%2C1866&ssl=1', 'width': 3350, 'height': 1866, 'caption': 'Google CEO Sundar Pichai introduces Duplex AI at I/O 2018 developer conference (Source: YouTube)'}, 'datePublished': '2018-12-28T14:00:00+00:00', 'dateModified': '2018-12-27T20:30:41+00:00', 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#webpage'}, 'isPartOf': {'@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#webpage'}, 'articleSection': 'Blog, AI ethics, Artificial intelligence (AI), bendee983'}, {'@type': 'BreadcrumbList', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://bdtechtalks.com/#listItem', 'position': 1, 'name': 'Home', 'item': 'https://bdtechtalks.com/', 'nextItem': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem', 'position': 2, 'name': '2018', 'item': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/', 'nextItem': 'https://bdtechtalks.com/2018/12/#listItem', 'previousItem': 'https://bdtechtalks.com/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2018/12/#listItem', 'position': 3, 'name': 'December', 'item': 'https://bdtechtalks.com/2018/12/', 'nextItem': 'https://bdtechtalks.com/2018/12/28/#listItem', 'previousItem': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2018/12/28/#listItem', 'position': 4, 'name': '28', 'item': 'https://bdtechtalks.com/2018/12/28/', 'nextItem': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem', 'previousItem': 'https://bdtechtalks.com/2018/12/#listItem'}, {'@type': 'ListItem', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#listItem', 'position': 5, 'name': 'The biggest artificial intelligence developments of 2018', 'previousItem': 'https://bdtechtalks.com/2018/12/28/#listItem'}]}, {'@type': 'Organization', '@id': 'https://bdtechtalks.com/#organization', 'name': 'TechTalks', 'description': 'Technology solving problems... and creating new ones', 'url': 'https://bdtechtalks.com/'}, {'@type': 'Person', '@id': 'https://bdtechtalks.com/author/bendee983/#author', 'url': 'https://bdtechtalks.com/author/bendee983/', 'name': 'Ben Dickson', 'image': {'@type': 'ImageObject', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#authorImage', 'url': 'https://secure.gravatar.com/avatar/5184782561a26df20cb56c8eb87eef27?s=96&d=identicon&r=g', 'width': 96, 'height': 96, 'caption': 'Ben Dickson'}}, {'@type': 'WebPage', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#webpage', 'url': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/', 'name': 'The biggest artificial intelligence developments of 2018 - TechTalks', 'description': '2018 was a year of reckoning for the AI industry. In parallel to technological developments, there was ample focus on the ethical concerns of artificial intelligence technology.', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://bdtechtalks.com/#website'}, 'breadcrumb': {'@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#breadcrumblist'}, 'author': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'creator': {'@id': 'https://bdtechtalks.com/author/bendee983/#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2018/12/Google-IO-2018-sundar-pichai-keynote-Duplex.png?fit=3350%2C1866&ssl=1', '@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#mainImage', 'width': 3350, 'height': 1866, 'caption': 'Google CEO Sundar Pichai introduces Duplex AI at I/O 2018 developer conference (Source: YouTube)'}, 'primaryImageOfPage': {'@id': 'https://bdtechtalks.com/2018/12/28/top-artificial-intelligence-stories-2018/#mainImage'}, 'datePublished': '2018-12-28T14:00:00+00:00', 'dateModified': '2018-12-27T20:30:41+00:00'}, {'@type': 'WebSite', '@id': 'https://bdtechtalks.com/#website', 'url': 'https://bdtechtalks.com/', 'name': 'TechTalks', 'description': 'Technology solving problems... and creating new ones', 'inLanguage': 'en-US', 'publisher': {'@id': 'https://bdtechtalks.com/#organization'}}]",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMTIvMzEvdGVjaG5vbG9neS9odW1hbi1yZXNvdXJjZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaHVtdS5odG1s0gEA?oc=5,Firm Led by Google Veterans Uses A.I. to 'Nudge' Workers Toward Happiness (Published 2018) - The New York Times,2018-12-31,The New York Times,https://www.nytimes.com,"Humu, a Silicon Valley start-up, applies data-driven lessons in human resources to the goal of improving employee satisfaction.",N/A,"Humu, a Silicon Valley start-up, applies data-driven lessons in human resources to the goal of improving employee satisfaction.","Humu, a Silicon Valley start-up, applies data-driven lessons in human resources to the goal of improving employee satisfaction.",https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/12/31/business/31HUMU05/31HUMU05-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2018/12/31/business/31HUMU05/31HUMU05-videoSixteenByNineJumbo1600.jpg', 'caption': 'Lizbeydi Dimas, an employee of the salad chain Sweetgreen, at a store in Mountain View, Calif. Sweetgreen turned to Humu, a start-up, for ideas on how to improve its workers’ satisfaction.', 'creditText': 'Cayce Clifford for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/12/31/business/31HUMU05/merlin_144427707_44a0132d-7e8c-4437-ae0a-e8bca7fb859d-superJumbo.jpg', 'height': 2048, 'width': 1639, 'contentUrl': 'https://static01.nyt.com/images/2018/12/31/business/31HUMU05/merlin_144427707_44a0132d-7e8c-4437-ae0a-e8bca7fb859d-superJumbo.jpg', 'caption': 'Lizbeydi Dimas, an employee of the salad chain Sweetgreen, at a store in Mountain View, Calif. Sweetgreen turned to Humu, a start-up, for ideas on how to improve its workers’ satisfaction.', 'creditText': 'Cayce Clifford for The New York Times'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/daisuke-wakabayashi', 'name': 'Daisuke Wakabayashi'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",Firm Led by Google Veterans Uses A.I. to ‘Nudge’ Workers Toward Happiness,2018-12-31T21:28:44.000Z,2018-12-31T22:27:17.000Z,,The New York Times,False,,Technology,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTFirm Led by Google Veterans Uses A.I. to ‘Nudge’ Workers Toward HappinessShare full articleRead in appLizbeydi Dimas, an employee of the salad chain Sweetgreen, at a store in Mountain View, Calif. Sweetgreen turned to Humu, a start-up, for ideas on how to improve its workers’ satisfaction.Credit...Cayce Clifford for The New York TimesBy Daisuke WakabayashiDec. 31, 2018MOUNTAIN VIEW, Calif. — Technology companies like to promote artificial intelligence’s potential for solving some of the world’s toughest problems, like reducing automobile deaths and helping doctors diagnose diseases. A company started by three former Google employees is pitching A.I. as the answer to a more common problem: being happier at work.The start-up, Humu, is based in Google’s hometown, and it builds on some of the so-called people-analytics programs pioneered by the internet giant, which has studied things like the traits that define great managers and how to foster better teamwork.Humu wants to bring similar data-driven insights to other companies. It digs through employee surveys using artificial intelligence to identify one or two behavioral changes that are likely to make the biggest impact on elevating a work force’s happiness. Then it uses emails and text messages to “nudge” individual employees into small actions that advance the larger goal.At a company where workers feel that the way decisions are made is opaque, Humu might nudge a manager before a meeting to ask the members of her team for input and to be prepared to change her mind. Humu might ask a different employee to come up with questions involving her team that she would like to have answered.AdvertisementSKIP ADVERTISEMENTAt the heart of Humu’s efforts is the company’s “nudge engine” (yes, it’s trademarked). It is based on the economist Richard Thaler’s Nobel Prize-winning research into how people often make decisions because of what is easier rather than what is in their best interest, and how a well-timed nudge can prompt them to make better choices.ImageLaszlo Bock, Humu’s chief executive, led people operations, or human resources, at Google. “We want to be the person we hope we can be,” he said, referring to an idea at the heart of Humu’s business. “But we need to be reminded.”Credit...HumuGoogle has used this approach to coax employees into the corporate equivalent of eating their vegetables, prodding them to save more for retirement, waste less food at the cafeteria and opt for healthier snacks.Using machine learning, Humu will tailor the timing, content and techniques of the messages it delivers based on how employees respond.“Often we want to be better people,” said Laszlo Bock, Humu’s chief executive and Google’s former leader of what the company calls people operations, or human resources. “We want to be the person we hope we can be. But we need to be reminded. A nudge can have a powerful impact if correctly deployed on how people behave and on human performance.”AdvertisementSKIP ADVERTISEMENTIn Mr. Bock’s decade-plus tenure at Google, the company’s work force grew more than eightfold. Google struggled at times with how to manage its rapid expansion, and some employees accused the company of creating a workplace that was hostile to women.In November, 20,000 employees — prompted by an article in The New York Times that detailed how Google had paid millions of dollars in exit packages to male executives accused of misconduct — walked off the job to protest the company’s handling of sexual harassment.The episode underscored Google’s unique and seemingly incongruous internal culture. Employees feel empowered to agitate for change, and the company takes innovative approaches to managing its work force. But deep-rooted problems fester as they would anywhere else.ImageMr. Bock in 2011 with a fellow Google employee, Jason Grishkoff. “A nudge can have a powerful impact if correctly deployed on how people behave and on human performance,” Mr. Bock said.Credit...Peter DaSilva for The New York TimesWhile Mr. Bock was at Google, he led many of its human-resources analytics efforts and became well known in the field, writing a 2015 book that laid out the company’s data-driven approach to personnel management.AdvertisementSKIP ADVERTISEMENTHe started Humu in 2017 shortly after leaving Google with two former colleagues: Jessie Wisdom, who has a doctorate in behavioral decision research and worked with Mr. Bock in people analytics, and Wayne Crosby, a former director of engineering at Google. Humu has raised $40 million and has 15 customers, companies that range in size from 150 to 65,000 employees.One major challenge for the company is handling data and artificial intelligence in the sensitive area of human resources. Humu said its software was built with employee privacy in mind, allowing workers to delete personal data, including anonymous comments made in company surveys. Humu said it complied with Europe’s stringent data privacy rules.But will workers consider the nudges useful or manipulative?Todd Haugh, an assistant professor of business law and ethics at Indiana University’s Kelley School of Business, said nudges could push workers into behaving in ways that benefited their employers’ interests over their own.“The companies are the only ones who know what the purpose of the nudge is,” Professor Haugh said. “The individual who is designing the nudge is the one whose interests are going to be put in the forefront.”AdvertisementSKIP ADVERTISEMENTDr. Wisdom, who ran much of Google’s nudge research, said it was hard to argue with most of the messages the company delivered because they encouraged behavior most people would welcome.ImageSweetgreen employees at the Mountain View store holding a short meeting to discuss topics like career development.Credit...Cayce Clifford for The New York Times“Anybody can do whatever they want,” she said. “It’s just about designing the context in which people are making the decision in ways that is going to help the most people. We’re never trying to get people to do things that they don’t actually want to do.”Sanjiv Razdan, the chief operating officer at Sweetgreen, a salad chain and one of Humu’s customers, said that if nudges did not have a track record at Google, he would probably consider the concept a bunch of “hocus-pocus happiness nonsense.”But after receiving nudges for a few months himself in emails from Mr. Crosby, whose email address is used to send the messages, Mr. Razdan said the bite-size reminders made it easy to take action right away. In one instance, he said, he was prompted to ask members of his team for their opinions on decisions he was facing.“The team doesn’t know I was nudged,” he said. “But I’m not ashamed to tell everyone that I heard from Wayne today.”AdvertisementSKIP ADVERTISEMENTJonathan Neman, Sweetgreen’s chief executive, said Humu had pinpointed the issue Sweetgreen cares about most: employee retention.Like most restaurant chains, Sweetgreen, which has 90 stores in the United States, depends on hourly employees. Retaining workers and keeping them happy is critical. Recruiting and training employees is costly, and experienced workers are more productive. Happier employees tend to treat customers better. And customers like seeing familiar faces.ImageJuana Padron, a Sweetgreen employee in Mountain View. The chain’s managers get “nudged” with messages like “Consider what skills each team member needs to be successful, both in their current role and longer term in their career.”Credit...Cayce Clifford for The New York TimesIn August, when Humu analyzed a survey of sentiment among 1,800 store employees that Sweetgreen had conducted the previous month, it found that 43 percent of the respondents had occasionally considered applying for jobs outside Sweetgreen.If Sweetgreen wanted to improve its retention rate, Humu’s algorithms determined, there was one statement from the survey that the chain needed more employees to agree with: “I believe there are good development opportunities for me at Sweetgreen.”AdvertisementSKIP ADVERTISEMENTOf the survey’s respondents, 81 percent had reacted positively to the statement. That was a strong score for the fast-food industry, but it was still below the overall 88 percent happiness index Humu had given Sweetgreen overall. The suggestion was that although the company’s employees were generally happy, some felt they lacked opportunities to advance their careers.Humu recommended that store managers — known as head coaches at Sweetgreen — hold one-on-one meetings with staff members to discuss development goals.About a month later, in early September, Elena Jimenez, the head coach at Sweetgreen’s Mountain View store, got a nudge. So far, Sweetgreen is nudging only managers.“Consider what skills each team member needs to be successful, both in their current role and longer term in their career,” the email read. “Take notes. Preparing this list of skills will help you spot opportunities for your team as they arise — so it’s worth putting the work in now!”Ms. Jimenez discussed career development at her next “sweet talk,” a short meeting before her store opened one day. Then she spoke to her employees individually and learned that many of them wanted to learn different skills, whether handling online orders or chopping and dicing the vegetables that go into Sweetgreen salads.“It was a good reminder to keep everyone happy and motivated,” she said. “I hope it helps me retain my staff. It’s not easy around here.”Follow Daisuke Wakabayashi on Twitter: @daiwaka. A version of this article appears in print on Jan. 1, 2019, Section B, Page 1 of the New York edition with the headline: Toward a Happier Office With Data-Driven Nudges. Order Reprints | Today’s Paper | SubscribeSee more on: Alphabet Inc.Share full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",,https://www.nytimes.com/2018/12/31/technology/human-resources-artificial-intelligence-humu.html,Toward a Happier Office With Data-Driven Nudges,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3Lm5ld3lvcmtlci5jb20vc2NpZW5jZS9lbGVtZW50cy9ob3ctdGhlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXByb2dyYW0tYWxwaGF6ZXJvLW1hc3RlcmVkLWl0cy1nYW1lc9IBAA?oc=5,How the Artificial Intelligence Program AlphaZero Mastered Its Games - The New Yorker,2018-12-28,The New Yorker,https://www.newyorker.com,"James Somers on AlphaZero, an artificial-intelligence program animated by an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been.","['tech', 'artificial intelligence (a.i.)', 'chess', 'computer games', 'web']","At its core was an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been.","At its core was an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been.",https://schema.org/,BreadcrumbList,https://www.newyorker.com/science/elements/how-the-artificial-intelligence-program-alphazero-mastered-its-games,"['https://media.newyorker.com/photos/5c24f4778822322ea4b3befe/16:9/w_2560,h_1440,c_limit/Somers-AlphaZero.jpg', 'https://media.newyorker.com/photos/5c24f4778822322ea4b3befe/4:3/w_2279,h_1709,c_limit/Somers-AlphaZero.jpg', 'https://media.newyorker.com/photos/5c24f4778822322ea4b3befe/1:1/w_1711,h_1711,c_limit/Somers-AlphaZero.jpg']","[{'@type': 'Person', 'name': 'James Somers', 'sameAs': 'https://www.newyorker.com/contributors/james-somers'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'The New Yorker', 'logo': {'@type': 'ImageObject', 'url': 'https://www.newyorker.com/verso/static/the-new-yorker/assets/social-image-hub.jpg', 'width': '500px', 'height': '117px'}, 'url': 'https://www.newyorker.com'}",How the Artificial Intelligence Program AlphaZero Mastered Its Games,2018-12-28T05:00:00.000-05:00,2018-12-28T05:00:00.000-05:00,,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Tech', 'item': 'https://www.newyorker.com/tech'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence (A.I.)', 'item': 'https://www.newyorker.com/tag/artificial-intelligence-ai'}, {'@type': 'ListItem', 'position': 3, 'name': 'How the Artificial-Intelligence Program AlphaZero Mastered Its Games'}]",tags,N/A,"TechHow the Artificial-Intelligence Program AlphaZero Mastered Its GamesBy James SomersDecember 28, 2018In 2016, a Google program soundly defeated Lee Sedol, the world’s best Go player, in a match viewed by more than a hundred million people.Photograph by Ahn Young-joon / APSave this storySave this storySave this storySave this storyA few weeks ago, a group of researchers from Google’s artificial-intelligence subsidiary, DeepMind, published a paper in the journal Science that described an A.I. for playing games. While their system is general-purpose enough to work for many two-person games, the researchers had adapted it specifically for Go, chess, and shogi (“Japanese chess”); it was given no knowledge beyond the rules of each game. At first it made random moves. Then it started learning through self-play. Over the course of nine hours, the chess version of the program played forty-four million games against itself on a massive cluster of specialized Google hardware. After two hours, it began performing better than human players; after four, it was beating the best chess engine in the world.The best of The New Yorker, in your in-boxReporting, commentary, culture, and humor. Sign up for our newsletters now.The program, called AlphaZero, descends from AlphaGo, an A.I. that became known for defeating Lee Sedol, the world’s best Go player, in March of 2016. Sedol’s defeat was a stunning upset. In “AlphaGo,” a documentary released earlier this year on Netflix, the  filmmakers follow both the team that developed the A.I. and its human opponents, who have devoted their lives to the game. We watch as these humans experience the stages of a new kind of grief. At first, they don’t see how they can lose to a machine: “I believe that human intuition is still too advanced for A.I. to have caught up,” Sedol says, the day before his five-game match with AlphaGo. Then, when the machine starts winning, a kind of panic sets in. In one particularly poignant moment, Sedol, under pressure after having lost his first game, gets up from the table and, leaving his clock running, walks outside for a cigarette. He looks out over the rooftops of Seoul. (On the Internet, more than fifty million people were watching the match.) Meanwhile, the A.I., unaware that its opponent has gone anywhere, plays a move that commentators called creative, surprising, and beautiful. In the end, Sedol lost, 1-4. Before there could be acceptance, there was depression. “I want to apologize for being so powerless,” he said in a press conference. Eventually, Sedol, along with the rest of the Go community, came to appreciate the machine. “I think this will bring a new paradigm to Go,” he said. Fan Hui, the European champion, agreed. “Maybe it can show humans something we’ve never discovered. Maybe it’s beautiful.”AlphaGo was a triumph for its creators, but still unsatisfying, because it depended so much on human Go expertise. The A.I. learned which moves it should make, in part, by trying to mimic world-class players. It also used a set of hand-coded heuristics to avoid the worst blunders when looking ahead in games. To the researchers building AlphaGo, this knowledge felt like a crutch. They set out to build a new version of the A.I. that learned on its own, as a “tabula rasa.”The result, AlphaGo Zero, detailed in a paper published in October, 2017, was so called because it had zero knowledge of Go beyond the rules. This new program was much less well-known; perhaps you can ask for the world’s attention only so many times. But in a way it was the more remarkable achievement, one that no longer had much to do with Go at all. In fact, less than two months later, DeepMind published a preprint of a third paper, showing that the algorithm behind AlphaGo Zero could be generalized to any two-person, zero-sum game of perfect information (that is, a game in which there are no hidden elements, such as face-down cards in poker). DeepMind dropped the “Go” from the name and christened its new system AlphaZero. At its core was an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been. Perhaps more surprising, this iteration of the system was also by far the simplest.A typical chess engine is a hodgepodge of tweaks and shims made over decades of trial and error. The best engine in the world, Stockfish, is open source, and it gets better by a kind of Darwinian selection: someone suggests an idea; tens of thousands of games are played between the version with the idea and the version without it; the best version wins. As a result, it is not a particularly elegant program, and it can be hard for coders to understand. Many of the changes programmers make to Stockfish are best formulated in terms of chess, not computer science, and concern how to evaluate a given situation on the board: Should a knight be worth 2.1 points or 2.2? What if it’s on the third rank, and the opponent has an opposite-colored bishop? To illustrate this point, David Silver, the head of research at DeepMind, once listed the moving parts in Stockfish. There are more than fifty of them, each requiring a significant amount of code, each a bit of hard-won chess arcana: the Counter Move Heuristic; databases of known endgames; evaluation modules for Doubled Pawns, Trapped Pieces, Rooks on (Semi) Open Files, and so on; strategies for searching the tree of possible moves, like “aspiration windows” and “iterative deepening.”AlphaZero, by contrast, has only two parts: a neural network and an algorithm called Monte Carlo Tree Search. (In a nod to the gaming mecca, mathematicians refer to approaches that involve some randomness as “Monte Carlo methods.”) The idea behind M.C.T.S., as it’s often known, is that a game like chess is really a tree of possibilities. If I move my rook to d8, you could capture it or let it be, at which point I could push a pawn or move my bishop or protect my queen. . . . The trouble is that this tree gets incredibly large incredibly quickly. No amount of computing power would be enough to search it exhaustively. An expert human player is an expert precisely because her mind automatically identifies the essential parts of the tree and focusses its attention there. Computers, if they are to compete, must somehow do the same.Chess commentators have praised AlphaZero, declaring that the engine “plays like a human on fire.”Photograph Courtesy DeepMind TechnologiesThis is where the neural network comes in. AlphaZero’s neural network receives, as input, the layout of the board for the last few moves of the game. As output, it estimates how likely the current player is to win and predicts which of the currently available moves are likely to work best. The M.C.T.S. algorithm uses these predictions to decide where to focus in the tree. If the network guesses that ‘knight-takes-bishop’ is likely to be a good move, for example, then the M.C.T.S. will devote more of its time to exploring the consequences of that move. But it balances this “exploitation” of promising moves with a little “exploration”: it sometimes picks moves it thinks are unlikely to bear fruit, just in case they do.At first, the neural network guiding this search is fairly stupid: it makes its predictions more or less at random. As a result, the Monte Carlo Tree Search starts out doing a pretty bad job of focussing on the important parts of the tree. But the genius of AlphaZero is in how it learns. It takes these two half-working parts and has them hone each other. Even when a dumb neural network does a bad job of predicting which moves will work, it’s still useful to look ahead in the game tree: toward the end of the game, for instance, the M.C.T.S. can still learn which positions actually lead to victory, at least some of the time. This knowledge can then be used to improve the neural network. When a game is done, and you know the outcome, you look at what the neural network predicted for each position (say, that there’s an 80.2 per cent chance that castling is the best move) and compare that to what actually happened (say, that the percentage is more like 60.5); you can then “correct” your neural network by tuning its synaptic connections until it prefers winning moves. In essence, all of the M.C.T.S.’s searching is distilled into new weights for the neural network.With a slightly better network, of course, the search gets slightly less misguided—and this allows it to search better, thereby extracting better information for training the network. On and on it goes, in a feedback loop that ratchets up, very quickly, toward the plateau of known ability.When the AlphaGo Zero and AlphaZero papers were published, a small army of enthusiasts began describing the systems in blog posts and YouTube videos and building their own copycat versions. Most of this work was explanatory—it flowed from the amateur urge to learn and share that gave rise to the Web in the first place. But a couple of efforts also sprung up to replicate the work at a large scale. The DeepMind papers, after all, had merely described the greatest Go- and chess-playing programs in the world—they hadn’t contained the source code, and the company hadn’t made the programs themselves available to players. Having declared victory, its  engineers had departed the field.Video From The New YorkerChess Grandmaster Garry Kasparov Replays His Four Most Memorable GamesGian-Carlo Pascutto, a computer programmer who works at the Mozilla Corporation, had a track record of building competitive game engines, first in chess, then in Go. He followed the latest research. As the combination of Monte Carlo Tree Search and a neural network became the state of the art in Go A.I.s, Pascutto built the world’s most successful open-source Go engines—first Leela, then LeelaZero—which mirrored the advances made by DeepMind. The trouble was that DeepMind had access to Google’s vast cloud and Pascutto didn’t. To train its Go engine, DeepMind used five thousand of Google’s “Tensor Processing Units”—chips specifically designed for neural-network calculations—for thirteen days. To do the same work on his desktop system, Pascutto would have to run it for seventeen hundred years.To compensate for his lack of computing power, Pascutto distributed the effort. LeelaZero is a federated system: anyone who wants to participate can download the latest version, donate whatever computing power he has to it, and upload the data he generates so that the system can be slightly improved. The distributed LeelaZero community has had their system play more than ten million games against itself—a little more than AlphaGo Zero. It is now one of the strongest existing Go engines.It wasn’t long before the idea was extended to chess. In December of last year, when the AlphaZero preprint was published, “it was like a bomb hit the community,” Gary Linscott said. Linscott, a computer scientist who had worked on Stockfish, used the existing LeelaZero code base, and the new ideas in the AlphaZero paper, to create Leela Chess Zero. (For Stockfish, he had developed a testing framework so that new ideas for the engine could be distributed to a fleet of volunteers, and thus vetted more quickly; distributing the training for a neural network was a natural next step.) There were kinks to sort out, and educated guesses to make about details that the DeepMind team had left out of their papers, but within a few months the neural network began improving. The chess world was already obsessed with AlphaZero:  posts on chess.com celebrated the engine; commentators and grandmasters pored over the handful of AlphaZero games that DeepMind had released with their paper, declaring that this was “how chess ought to be played,” that the engine “plays like a human on fire.”  Quickly, Lc0, as Leela Chess Zero became known, attracted hundreds of volunteers. As they contributed their computer power and improvements to the source code, the engine got even better. Today, one core contributor suspects that it is just a few months away from overtaking Stockfish. Not long after, it may become better than AlphaZero itself.When we spoke over the phone, Linscott marvelled that a project like his, which would once have taken a talented doctoral student several years, could now be done by an interested amateur in a couple of months. Software libraries for neural networks allow for the replication of a world-beating design using only a few dozen lines of code; the tools already exist for distributing computation among a set of volunteers, and chipmakers such as Nvidia have put cheap and powerful G.P.U.s—graphics-processing chips, which are perfect for training neural networks—into the hands of millions of ordinary computer users. An algorithm like M.C.T.S. is simple enough to be implemented in an afternoon or two. You don’t even need to be an expert in the game for which you’re building an engine. When he built LeelaZero, Pascutto hadn’t played Go for about twenty years.David Silver, the head of research at DeepMind, has pointed out a seeming paradox at the heart of his company’s recent work with games: the simpler its programs got—from AlphaGo to AlphaGo Zero to AlphaZero—the better they performed. “Maybe one of the principles that we’re after,” he said, in a talk in December of 2017, “is this idea that by doing less, by removing complexity from the algorithm, it enables us to become more general.” By removing the Go knowledge from their Go engine, they made a better Go engine—and, at the same time, an engine that could play shogi and chess.It was never obvious that things would turn out this way. In 1953, Alan Turing, who helped create modern computing, wrote a short paper titled, “Digital Computers Applied to Games.” In it, he developed a chess program “based on an introspective analysis of my thought processes while playing.” The program was simple, but in its case simplicity was no virtue: like Turing, who wasn’t a gifted chess player, it missed much of the depth of the game and didn't play very well. Even so, Turing conjectured that the idea that “one cannot programme a machine to play a better game than one plays oneself” was a “rather glib view.” Although it sounds right to say that “no animal can swallow an animal heavier than itself,” plenty of animals can. Similarly, Turing suggested, there might be no contradiction in a bad chess player making a chess program that plays brilliantly. One tantalizing way to do it would be to have the program learn for itself.The success of AlphaZero seems to bear this out. It has a simple structure, but it’s capable of learning surprisingly deep features of the games it plays. In one section of the AlphaGo Zero paper, the DeepMind team illustrates how their A.I., after a certain number of training cycles, discovers strategies well-known to master players, only to discard them just a few cycles later. It is odd and a little unsettling to see humanity’s best ideas trundled over on the way to something better; it hits close to home in a way that seeing a physical machine exceed us—a bulldozer shifting a load of earth, say—doesn’t. In a recent editorial in Science, Garry Kasparov, the former chess champion who lost to I.B.M.’s Deep Blue in 1997, argues that AlphaZero doesn’t play chess in a way that reflects the presumably systematic “priorities and prejudices of programmers”; instead—even though it searches far fewer positions per move than a traditional engine—it plays in an open, aggressive style and seems to think in terms of strategy rather than tactics, like a human with uncanny vision. “Because AlphaZero programs itself,” Kasparov writes, “I would say that its style reflects the truth.”Playing chess like a human, of course, isn't the same thing as thinking about chess like a human, or learning like one. There is an old saying that game-playing is the Drosophila of A.I.: as the fruit fly is to biologists, so games like Go and chess are to computer scientists studying the mechanisms of intelligence. It’s an evocative analogy. And yet it could be that the task of playing chess, once it’s converted into the task of searching tens of thousands of nodes per second in a game tree, exercises a different kind of intelligence than the one we care about most. Played in this way, chess might be more like earth-moving than we thought: an activity that, in the end, isn’t our forté, and so shouldn’t be all that dear to our souls. To learn, AlphaZero needs to play millions more games than a human does— but, when it’s done, it plays like a genius. It relies on churning faster than a person ever could through a deep search tree, then uses a neural network to process what it finds into something that resembles intuition. Surely the program teaches us something new about intelligence. But its success also underscores just how much the world’s best human players can see by means of a very different process—one based on reading, talking, and feeling, in addition to playing. What may be most surprising is that we humans have done as well as we have in games that seem, now, to have been made for machines.",,"{'@type': 'WebPage', '@id': 'https://www.newyorker.com/science/elements/how-the-artificial-intelligence-program-alphazero-mastered-its-games'}","James Somers on AlphaZero, an artificial-intelligence program animated by an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been.",,,,,"{'@type': 'CreativeWork', 'name': 'The New Yorker'}",,,,,,,,"The program, called AlphaZero, descends from AlphaGo, an A.I. that became known for defeating Lee Sedol, the world’s best Go player, in March of 2016. Sedol’s defeat was a stunning upset. In “AlphaGo,” a documentary released earlier this year on Netflix, the  filmmakers follow both the team that developed the A.I. and its human opponents, who have devoted their lives to the game. We watch as these humans experience the stages of a new kind of grief. At first, they don’t see how they can lose to a machine: “I believe that human intuition is still too advanced for A.I. to have caught up,” Sedol says, the day before his five-game match with AlphaGo. Then, when the machine starts winning, a kind of panic sets in. In one particularly poignant moment, Sedol, under pressure after having lost his first game, gets up from the table and, leaving his clock running, walks outside for a cigarette. He looks out over the rooftops of Seoul. (On the Internet, more than fifty million people were watching the match.) Meanwhile, the A.I., unaware that its opponent has gone anywhere, plays a move that commentators called creative, surprising, and beautiful. In the end, Sedol lost, 1-4. Before there could be acceptance, there was depression. “I want to apologize for being so powerless,” he said in a press conference. Eventually, Sedol, along with the rest of the Go community, came to appreciate the machine. “I think this will bring a new paradigm to Go,” he said. Fan Hui, the European champion, agreed. “Maybe it can show humans something we’ve never discovered. Maybe it’s beautiful.”
AlphaGo was a triumph for its creators, but still unsatisfying, because it depended so much on human Go expertise. The A.I. learned which moves it should make, in part, by trying to mimic world-class players. It also used a set of hand-coded heuristics to avoid the worst blunders when looking ahead in games. To the researchers building AlphaGo, this knowledge felt like a crutch. They set out to build a new version of the A.I. that learned on its own, as a “tabula rasa.”
The result, AlphaGo Zero, detailed in a paper published in October, 2017, was so called because it had zero knowledge of Go beyond the rules. This new program was much less well-known; perhaps you can ask for the world’s attention only so many times. But in a way it was the more remarkable achievement, one that no longer had much to do with Go at all. In fact, less than two months later, DeepMind published a preprint of a third paper, showing that the algorithm behind AlphaGo Zero could be generalized to any two-person, zero-sum game of perfect information (that is, a game in which there are no hidden elements, such as face-down cards in poker). DeepMind dropped the “Go” from the name and christened its new system AlphaZero. At its core was an algorithm so powerful that you could give it the rules of humanity’s richest and most studied games and, later that day, it would become the best player there has ever been. Perhaps more surprising, this iteration of the system was also by far the simplest.
AlphaZero, by contrast, has only two parts: a neural network and an algorithm called Monte Carlo Tree Search. (In a nod to the gaming mecca, mathematicians refer to approaches that involve some randomness as “Monte Carlo methods.”) The idea behind M.C.T.S., as it’s often known, is that a game like chess is really a tree of possibilities. If I move my rook to d8, you could capture it or let it be, at which point I could push a pawn or move my bishop or protect my queen. . . . The trouble is that this tree gets incredibly large incredibly quickly. No amount of computing power would be enough to search it exhaustively. An expert human player is an expert precisely because her mind automatically identifies the essential parts of the tree and focusses its attention there. Computers, if they are to compete, must somehow do the same.
This is where the neural network comes in. AlphaZero’s neural network receives, as input, the layout of the board for the last few moves of the game. As output, it estimates how likely the current player is to win and predicts which of the currently available moves are likely to work best. The M.C.T.S. algorithm uses these predictions to decide where to focus in the tree. If the network guesses that ‘knight-takes-bishop’ is likely to be a good move, for example, then the M.C.T.S. will devote more of its time to exploring the consequences of that move. But it balances this “exploitation” of promising moves with a little “exploration”: it sometimes picks moves it thinks are unlikely to bear fruit, just in case they do.
At first, the neural network guiding this search is fairly stupid: it makes its predictions more or less at random. As a result, the Monte Carlo Tree Search starts out doing a pretty bad job of focussing on the important parts of the tree. But the genius of AlphaZero is in how it learns. It takes these two half-working parts and has them hone each other. Even when a dumb neural network does a bad job of predicting which moves will work, it’s still useful to look ahead in the game tree: toward the end of the game, for instance, the M.C.T.S. can still learn which positions actually lead to victory, at least some of the time. This knowledge can then be used to improve the neural network. When a game is done, and you know the outcome, you look at what the neural network predicted for each position (say, that there’s an 80.2 per cent chance that castling is the best move) and compare that to what actually happened (say, that the percentage is more like 60.5); you can then “correct” your neural network by tuning its synaptic connections until it prefers winning moves. In essence, all of the M.C.T.S.’s searching is distilled into new weights for the neural network.
With a slightly better network, of course, the search gets slightly less misguided—and this allows it to search better, thereby extracting better information for training the network. On and on it goes, in a feedback loop that ratchets up, very quickly, toward the plateau of known ability.
Gian-Carlo Pascutto, a computer programmer who works at the Mozilla Corporation, had a track record of building competitive game engines, first in chess, then in Go. He followed the latest research. As the combination of Monte Carlo Tree Search and a neural network became the state of the art in Go A.I.s, Pascutto built the world’s most successful open-source Go engines—first Leela, then LeelaZero—which mirrored the advances made by DeepMind. The trouble was that DeepMind had access to Google’s vast cloud and Pascutto didn’t. To train its Go engine, DeepMind used five thousand of Google’s “Tensor Processing Units”—chips specifically designed for neural-network calculations—for thirteen days. To do the same work on his desktop system, Pascutto would have to run it for seventeen hundred years.
To compensate for his lack of computing power, Pascutto distributed the effort. LeelaZero is a federated system: anyone who wants to participate can download the latest version, donate whatever computing power he has to it, and upload the data he generates so that the system can be slightly improved. The distributed LeelaZero community has had their system play more than ten million games against itself—a little more than AlphaGo Zero. It is now one of the strongest existing Go engines.
It wasn’t long before the idea was extended to chess. In December of last year, when the AlphaZero preprint was published, “it was like a bomb hit the community,” Gary Linscott said. Linscott, a computer scientist who had worked on Stockfish, used the existing LeelaZero code base, and the new ideas in the AlphaZero paper, to create Leela Chess Zero. (For Stockfish, he had developed a testing framework so that new ideas for the engine could be distributed to a fleet of volunteers, and thus vetted more quickly; distributing the training for a neural network was a natural next step.) There were kinks to sort out, and educated guesses to make about details that the DeepMind team had left out of their papers, but within a few months the neural network began improving. The chess world was already obsessed with AlphaZero:  posts on chess.com celebrated the engine; commentators and grandmasters pored over the handful of AlphaZero games that DeepMind had released with their paper, declaring that this was “how chess ought to be played,” that the engine “plays like a human on fire.”  Quickly, Lc0, as Leela Chess Zero became known, attracted hundreds of volunteers. As they contributed their computer power and improvements to the source code, the engine got even better. Today, one core contributor suspects that it is just a few months away from overtaking Stockfish. Not long after, it may become better than AlphaZero itself.
When we spoke over the phone, Linscott marvelled that a project like his, which would once have taken a talented doctoral student several years, could now be done by an interested amateur in a couple of months. Software libraries for neural networks allow for the replication of a world-beating design using only a few dozen lines of code; the tools already exist for distributing computation among a set of volunteers, and chipmakers such as Nvidia have put cheap and powerful G.P.U.s—graphics-processing chips, which are perfect for training neural networks—into the hands of millions of ordinary computer users. An algorithm like M.C.T.S. is simple enough to be implemented in an afternoon or two. You don’t even need to be an expert in the game for which you’re building an engine. When he built LeelaZero, Pascutto hadn’t played Go for about twenty years.
It was never obvious that things would turn out this way. In 1953, Alan Turing, who helped create modern computing, wrote a short paper titled, “Digital Computers Applied to Games.” In it, he developed a chess program “based on an introspective analysis of my thought processes while playing.” The program was simple, but in its case simplicity was no virtue: like Turing, who wasn’t a gifted chess player, it missed much of the depth of the game and didn't play very well. Even so, Turing conjectured that the idea that “one cannot programme a machine to play a better game than one plays oneself” was a “rather glib view.” Although it sounds right to say that “no animal can swallow an animal heavier than itself,” plenty of animals can. Similarly, Turing suggested, there might be no contradiction in a bad chess player making a chess program that plays brilliantly. One tantalizing way to do it would be to have the program learn for itself.
The success of AlphaZero seems to bear this out. It has a simple structure, but it’s capable of learning surprisingly deep features of the games it plays. In one section of the AlphaGo Zero paper, the DeepMind team illustrates how their A.I., after a certain number of training cycles, discovers strategies well-known to master players, only to discard them just a few cycles later. It is odd and a little unsettling to see humanity’s best ideas trundled over on the way to something better; it hits close to home in a way that seeing a physical machine exceed us—a bulldozer shifting a load of earth, say—doesn’t. In a recent editorial in Science, Garry Kasparov, the former chess champion who lost to I.B.M.’s Deep Blue in 1997, argues that AlphaZero doesn’t play chess in a way that reflects the presumably systematic “priorities and prejudices of programmers”; instead—even though it searches far fewer positions per move than a traditional engine—it plays in an open, aggressive style and seems to think in terms of strategy rather than tactics, like a human with uncanny vision. “Because AlphaZero programs itself,” Kasparov writes, “I would say that its style reflects the truth.”
Playing chess like a human, of course, isn't the same thing as thinking about chess like a human, or learning like one. There is an old saying that game-playing is the Drosophila of A.I.: as the fruit fly is to biologists, so games like Go and chess are to computer scientists studying the mechanisms of intelligence. It’s an evocative analogy. And yet it could be that the task of playing chess, once it’s converted into the task of searching tens of thousands of nodes per second in a game tree, exercises a different kind of intelligence than the one we care about most. Played in this way, chess might be more like earth-moving than we thought: an activity that, in the end, isn’t our forté, and so shouldn’t be all that dear to our souls. To learn, AlphaZero needs to play millions more games than a human does— but, when it’s done, it plays like a genius. It relies on churning faster than a person ever could through a deep search tree, then uses a neural network to process what it finds into something that resembles intuition. Surely the program teaches us something new about intelligence. But its success also underscores just how much the world’s best human players can see by means of a very different process—one based on reading, talking, and feeling, in addition to playing. What may be most surprising is that we humans have done as well as we have in games that seem, now, to have been made for machines.",,"https://media.newyorker.com/photos/5c24f4778822322ea4b3befe/1:1/w_1711,h_1711,c_limit/Somers-AlphaZero.jpg",,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vaW50ZXJlc3RpbmdlbmdpbmVlcmluZy5jb20vaW5ub3ZhdGlvbi9haS12cy1sYXd5ZXJzLXRoZS1mdXR1cmUtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLWxhd9IBAA?oc=5,AI vs. lawyers: The future of Artificial Intelligence and law - Interesting Engineering,2018-12-29,Interesting Engineering,https://interestingengineering.com,"There must be human-made objects that are able to do most of the things humans do; especially the things that require ""intelligence"". How will this impact lawyers?",AI,"There must be human-made objects that are able to do most of the things humans do; especially the things that require ""intelligence"". How will this impact lawyers?","There must be human-made objects that are able to do most of the things humans do; especially the things that require ""intelligence"". How will this impact lawyers?",https://schema.org,,,,,,,,,,,,,N/A,N/A,"ShareInnovationAI vs. lawyers: The future of Artificial Intelligence and lawThere must be human-made objects that are able to do most of the things humans do; especially the things that require “intelligence”. How will this impact lawyers?
Published: Dec 29, 2018 05:25 AM ESTInteresting Engineering6 years ago0ShareDepositphoto“Can machines think?” 
Let’s expand this question asked by Alan Turing in the 50s. The countless disaster scenarios, in which artificial intelligence (AI) takes over the world and destroys humanity, are already made-up and still being told in Hollywood.
AI has not yet taken control of humanity, but it has indeed taken control of many aspects of our lives even if we do not perceive it as such. We accept AI as a part of our lives. The simplest example is our smartphones. Bionic hands and laser rust removal, the best of IE this week
1/100:29Bionic hands and laser rust removal, the best of IE this week





Skip in 5s
 
Continue watchingBionic hands and laser rust removal, the best of IE this weekafter the adVisit Advertiser websiteGO TO PAGE
The use of AI applications in this domain is so widespread that it is now possible to produce solutions for almost all professional groups. Medicine, education, automotive, defense, agriculture, automation, energy, natural sciences, finance, art, and even law.
But can AI replace human lawyers?
The Role of Deep Learning 
Over the past 7 years, the main sub-area of AI has been deep learning. Deep learning is more successful than humans especially in processing visual data and analyzing images from the images, what objects or living things exist, relationships with each other, event estimation, object/person tracking, etc.
Deep learning includes AI models that generate the most successful results in the application areas of recent years, based on artificial neural networks and requiring a lot of processing power.
How do AI Systems Learn Language?
Models used for natural language processing are also within the scope of deep learning.
Using natural language processing models, we can parse millions of data files loaded into the computer by class. In this process, the system learns the relationship between words from all the documents and is able to predict that the word ‘carrot’ comes after the word ‘rabbit’ with higher probability than the word ‘sun’.
AI can estimate this due to the fact that the words perform meaning analysis based on their statistical status in sentences. It is possible to summarize or classify a long paragraph, including time-space information from single sentences.
AI to Form Meaning Networks
More and more data is accumulating on the Internet every day. Thanks to the enormous data, we can realize artificial intelligence applications that are self-generating ‘meaning networks’.
It not only informs us about the sociological, psychological, ethnic, sociocultural, and economic levels of communities or people living in a region but also helps us predict where the developing hot agenda can be, just like in the U.S. presidential election.
Using the voice doctor application on our phone, we can try to determine what our discomfort is and to perform pre-interventions with very high accuracy. Babylon, which has more than 40,000 users in the UK, is an exemplary AI assistant physician practice.
What if AI tries to practice as a lawyer?
Imagine that a ‘human lawyer’ can handle all the cases in the world after AI’s preliminary research.
For a human lawyer, it takes weeks to do research, but AI can do it in just a few seconds. Moreover, AI does not get tired, sleep, eat, or drink coffee. In fact, AI can produce more successful results than an average experienced lawyer.
What would you say to that? Will AI and machine learning eradicate the need for lawyers?

Source: Dilara Kizrak Design Studio/Instagram

Dilara Kizrak Design Studio/Instagram


Leibniz: the first lawyer to predict the use of machines in law
Leibniz, who is one of the grandfathers of AI, was a lawyer and said: ‘It is unworthy of excellent men to lose hours like slaves in the labor of calculation which could safely be relegated to anyone else if machines were used.’
In 1673, he presented the machine for four arithmetic operations in the UK. Leibniz says: ‘The only way to correct our reasoning is to make them as tangible as the mathematicians’ so that we can find our error at a glance, and when there are disagreements between people, let’s calculate and see who is right!’
So, let’s think, why shouldn’t it be possible for machines to complete all steps of the event chain which occurs in a lawyer’s mind while they are deciding?
Why couldn’t the machine do it? Why can it not calculate who is right in the dispute between people or how to find the middle way? Isn’t that a ‘robot mediator’? These questions belong to the 17th century! I would like to point out, and we are at the end of 2018!
AINOW’s Contribution to create the future of legal AI
‘Since men near monopoly of all higher forms of intelligence have been one of the most basic facts of human existence throughout the past history of this planet, such developments would clearly create a new economics, a new sociology, and a new history!’ says J. Schwartz.
In June 2018, AINOW—a research institute examining the social implications of AI—convened a workshop with the goal of bringing together legal, scientific, and technical advocates who focus on litigating algorithmic decision-making across various areas of the law (e.g., employment, public benefits, criminal justice).
They structured the day with the practical aim of discussing strategy and best practices while also exchanging ideas and experiences in litigation and other advocacy in this space.
The gathering included several of the lawyers who brought the cases alongside advocates, researchers, technical experts, social scientists, and other leading thinkers in the area of algorithmic accountability.
What are the accuracy rates of the AI Programs? 
In 2017, in an experiment involving more than 100 lawyers in London, hundreds of actual applications to the Finance Ombudsman for a specific credit card irregularity were examined.
While the accuracy of human prediction was 66.3%, an AI program trained to predict whether or not to accept files achieved 86.6% accuracy.

Source: LawGeex

LawGeex


Evisort to reduce the time cost of the Judicial System
Also, in late 2017, four Harvard Law School students argued that using AI to formulate and manage drafts of law contracts was a very accurate move.
With their powerful new search engine called Evisort that harnesses cloud storage and AI, they hope to revolutionize the costly and labor-intensive way that lawyers currently handle contracts and other transactional work, liberating them for more creative and interesting tasks.
When they say, “In six seconds they can review a 30-page contract and pull out information for you”, lawyers say, “Why did I spend 10 years of my life doing that?” That reaction is what gets them excited to keep going.
The way to reduce costs without sacrificing performance and accuracy is through the use of deep learning and machine learning models in natural language processing for law correspondence.
Performance comparison of the AI lawyers and the human lawyers
Another current study was from LawGeex, which was founded in 2014. They compared the performance of 20 experienced United Nations lawyers to their AI systems and published a 40-page report.
Obtained results: In the daily legal risk assessment task, the highest performance among human lawyers was 94%, the lowest performance was 64%, and the average performance was 85%, while the average of AI was 94% success.
In addition, the average time required for ‘human lawyers’ for this process is 92 minutes, while the time needed by AI is 26 seconds. AI can continue this process for a long time without rest!
Historical Records are Helping the AI Systems 
The most important part of the success of these studies is that the data is regularly found in digital media. Harvard Law School recently shared the 360-year-old case law of the United States of America according to each of the states with AI developers on the online platform.
This is an important resource for speeding up the work. But the biggest obstacles to natural language processing are language-specific rules and the need for such resources in all languages. The developments in English are quite bright because most of the data is regularly available in this language.

Source:Depositphotos


Human-AI lawyer cooperation
As I mentioned at the beginning, these AI applications which are developed by using data make similar inferences by looking at the millions of cases in the past while giving a higher performance compared to the success of a group of human lawyers.
In all these AI examples, human lawyers regained their lost time. Artificial intelligence enables human lawyers to work with speed and more data. These AI systems show us cooperation between humans and AI, which is important. That defined human-in-loop. It aims at providing lawyers with more consultancy and getting rid of fatigue duty.
For many applications of AI, the human-centered approach supports the idea of human-AI collaboration instead of AI competing against a human.
But what about the subjective observations and prejudices that are stored in the data used by these machines? If the motives for data transfer are not healthy, would it not make the decisions wrong? Is it possible for AI to collect parser, connective, formative, regenerator, and operator which are included by ‘human lawyer’?
Systems could adopt the prejudices of the case documents so far, such as those that were decided according to racist approaches in the past. So AI systems in their current status are not prone to the social conflicts that their context of creation contains within.
How do we provide serious judgment, attention, insightful behavior, assessment, and judicial data to create a healthy judgment? Perhaps the machine actually needs to be exposed to past data or to be manipulated by human collaborators to overcome these issues.
Questions on AI ethics
Is manipulation meant to interfere with the evolution of the machine and is it wrong? We’re coming to a point where AI ethics is on the agenda!
Will the attorney receive support from the AI machine while taking care of his job? Will AI software have its own rights? Can AI machines participate in civil law or criminal law transactions?
When we give the same case to the machines where the same programs are installed and when we want each machine to solve the same problem more than once, will there be nuanced differences between these solutions? Should it be? According to time and space, how should we differentiate each case?
Well, is ‘human’ considered to be ‘robotized’ in professional execution today? Maybe we cannot remove prejudices from human beings, but we need to keep people away from AI to prevent prejudice. These are the issues that need to be discussed for a while.        RECOMMENDED ARTICLES

0COMMENTNEWSLETTERThe Blueprint DailyStay up-to-date on engineering, tech, space, and science news with The Blueprint.Sign Up  By clicking sign up, you confirm that you accept this site's Terms of Use and Privacy PolicyABOUT THE EDITORInteresting Engineering Interesting Engineering is a diverse group of journalists, videographers, and creators that aims to help the world better understand the art and science of engineering. With a combination of innovative storytelling and bespoke content formats, we cover the latest developments and breakthroughs in engineering, science, and technology.NewsinnovationPOPULAR ARTICLES1militaryGerman Navy ditches epic floppy disks from its warships after 30 yearsJijo Malayila day ago02energyCO2 to stone: Startup plans to inject 100 tons of carbon 1 km inside EarthChris Younga day ago03innovationStartup’s tricks drop methane emissions from rice cultivation by 35%Ameya Palejaa day ago04cultureSting operation: Kenya uses hidden bee hives to fight timber smugglersMaria Mocerinoa day ago0RELATED ARTICLESspaceFirst direct evidence of underground lava tube on Moon’s surface foundmilitaryUkraine’s trainer jet dogfights, downs Russian spy drones in WWI-stylecultureUN: 100 lorries may need 15 years to clear 40 million tons of Gaza debrisinnovationElectric abra: World’s 1st 3D-printed traditional wooden boat sets sail in DubaiJOBSSee All

Find Your Place In The World BY Amply







GTT, LLC

Staff Engineer
Chevy Chase
$90 an hour
See Job







Envision, LLC

Cloud Engineer
St. Louis
See Job







Navy Federal Credit Union

ETS Engineer IV (ServiceNow Engineer)
Vienna
$124,700 - $183,800 a year
See Job







SAIC

Network Engineer
Richmond
See Job



Search More Roles


FEATURED STORIES



 
 








","[{'@type': 'NewsArticle', '@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#article', 'isPartOf': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law'}, 'author': {'name': 'Interesting Engineering', '@id': 'https://interestingengineering.com/#/schema/person/81843ebb6463000002a8611c599f48cd'}, 'headline': 'AI vs. lawyers: The future of Artificial Intelligence and law', 'datePublished': '2018-12-29T10:25:00+00:00', 'dateModified': '2018-12-29T10:25:00+00:00', 'mainEntityOfPage': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law'}, 'wordCount': 1720, 'commentCount': 0, 'publisher': {'@id': 'https://interestingengineering.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': False, 'caption': False}, 'thumbnailUrl': 'https://images.interestingengineering.com/images/ai_lawyers_son-1_-_Kopya_1208x608.jpg', 'keywords': ['AI'], 'articleSection': ['Innovation'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://interestingengineering.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law', 'url': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law', 'name': 'AI vs. lawyers: The future of Artificial Intelligence and law', 'isPartOf': {'@id': 'https://interestingengineering.com/#website'}, 'primaryImageOfPage': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#primaryimage'}, 'image': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#primaryimage'}, 'thumbnailUrl': 'https://images.interestingengineering.com/images/ai_lawyers_son-1_-_Kopya_1208x608.jpg', 'datePublished': '2018-12-29T10:25:00+00:00', 'dateModified': '2018-12-29T10:25:00+00:00', 'description': 'There must be human-made objects that are able to do most of the things humans do; especially the things that require ""intelligence"". How will this impact lawyers?', 'breadcrumb': {'@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#primaryimage', 'url': 'https://images.interestingengineering.com/images/ai_lawyers_son-1_-_Kopya_1208x608.jpg', 'contentUrl': 'https://images.interestingengineering.com/images/ai_lawyers_son-1_-_Kopya_1208x608.jpg'}, {'@type': 'BreadcrumbList', '@id': 'https://interestingengineering.com/innovation/ai-vs-lawyers-the-future-of-artificial-intelligence-and-law#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://interestingengineering.com/news'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://interestingengineering.com/innovation'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI vs. lawyers: The future of Artificial Intelligence and law'}]}, {'@type': 'WebSite', '@id': 'https://interestingengineering.com/#website', 'url': 'https://interestingengineering.com/', 'name': 'Interesting Engineering', 'description': '', 'publisher': {'@id': 'https://interestingengineering.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://interestingengineering.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://interestingengineering.com/#organization', 'name': 'Interesting Engineering', 'url': 'https://interestingengineering.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://interestingengineering.com/#/schema/logo/image/', 'url': 'https://cms.interestingengineering.com/wp-content/uploads/2024/02/Interesting_Engineering-1.jpg', 'contentUrl': 'https://cms.interestingengineering.com/wp-content/uploads/2024/02/Interesting_Engineering-1.jpg', 'width': 590, 'height': 198, 'caption': 'Interesting Engineering'}, 'image': {'@id': 'https://interestingengineering.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/interestingengineering/', 'https://x.com/IntEngineering', 'https://www.linkedin.com/company/interestingengineering/'], 'email': 'info@interestingengineering.com', 'numberOfEmployees': {'@type': 'QuantitativeValue', 'minValue': '201', 'maxValue': '500'}, 'publishingPrinciples': 'https://interestingengineering.com/home-page'}]",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvcXVvcmEvMjAxOC8xMi8yNy93aGF0LWluZHVzdHJpZXMtd2lsbC1yZW1haW4tdW50b3VjaGVkLWJ5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,What Industries Will Remain Untouched By Artificial Intelligence? - Forbes,2018-12-27,Forbes,https://www.forbes.com,What jobs will AI probably not destroy? This question was originally answered on Quora by Martin Ford.,,What jobs will AI probably not destroy? This question was originally answered on Quora by Martin Ford.,What jobs will AI probably not destroy? This question was originally answered on Quora by Martin Ford.,http://schema.org,BreadcrumbList,https://www.forbes.com/sites/quora/2018/12/27/what-industries-will-remain-untouched-by-artificial-intelligence/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/dam/imageserve/41583431/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Quora', 'url': 'https://www.forbes.com/sites/quora/', 'description': 'Quora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.', 'sameAs': ['https://www.twitter.com/Quora', 'http://www.quora.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",What Industries Will Remain Untouched By Artificial Intelligence?,2018-12-27T20:02:00-05:00,2018-12-27T20:02:52-05:00,Consumer Tech,What Industries Will Remain Untouched By Artificial Intelligence?,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Consumer Tech', 'item': 'https://www.forbes.com/consumer-tech/'}]",Consumer Tech,N/A,"More From ForbesJul 16, 2024,06:30am EDTZoc Flips The Script On Education With AIJul 16, 2024,06:00am EDTMeet NuPhy’s New And Improved Halo96 V2 Mechanical KeyboardJul 15, 2024,07:29pm EDTNew Software Hints At Samsung’s  Galaxy Z Fold6 UpgradeJul 15, 2024,04:20pm EDTThe Most Interesting Facts About Human BehaviorJul 15, 2024,04:19pm EDTThe Relationship Between Introversion And IntelligenceJul 15, 2024,04:17pm EDTThe Importance Of Research In Securing A Spot In BS/MD ProgramsJul 15, 2024,04:17pm EDTUnique Ways To Market A Product Or ServiceEdit StoryForbesInnovationConsumer TechWhat Industries Will Remain Untouched By Artificial Intelligence?QuoraContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 27, 2018,08:02pm ESTUpdated Dec 27, 2018, 08:02pm ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







David Paul Morris/Bloomberg
© 2017 Bloomberg Finance LP





What jobs will AI probably not destroy? originally appeared on Quora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.

Answer by Martin Ford, Futurist, Author of Architects of Intelligence, AI Expert, on Quora:
The jobs that are most susceptible to automation in the near term are those that are fundamentally routine or predictable in nature. If you have a boring job—where you come to work and do the same kinds of things again and again, you should probably worry. The tasks within jobs like this are likely to be encapsulated in the data that is collected by organizations. So it may only be a matter of time before a powerful machine learning algorithm comes along that can automate much of this work.
PROMOTED
So the answer to this question is that the jobs that will be safest are those which are NOT routine or predictable.
I think this especially includes 3 kinds of work:


Creative work — where you are building something new, thinking outside the box in non-predictable ways, etc.
Human-centered work—where you build sophisticated relationships with people. This would include caring roles, as with a nurse or social worker, but also business roles where you need a need understanding of your clients.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Skilled trade work—this includes jobs that require lots of mobility, dexterity and flexibility in unpredictable environments. Examples would be electricians or plumbers. Building a robot that can do these jobs is probably far in the future.

Of course, the important caveat here is that this applies only to the foreseeable future. In the long run, major advances in AI—and especially the advent of human-level AI (or AGI)—could be a game changer even for these relatively safe jobs.
This question originally appeared on Quora - the place to gain and share knowledge, empowering people to learn from others and better understand the world. You can follow Quora on Twitter, Facebook, and Google+. More questions:

Artificial Intelligence: Which major AI breakthroughs are we closest to right now (late 2018)?
The Future: How will AI technology grow and improve in the coming decades?
Economics: Will AI, robotics and automation replacing human jobs require that we change how our economy functions?
QuoraFollowingFollowQuora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.Editorial StandardsPrintReprints & PermissionsThe video player is currently playing an ad. You can skip the ad in 5 sec with a mouse or keyboard
1/100:10Mona Kattan On Building In Entrepreneurship And Founding Kayali | Forbes 30/50 Summit 2024





Skip Ad
 
Continue watchingMona Kattan On Building In Entrepreneurship And Founding Kayali | Forbes 30/50 Summit 2024after the adVisit Advertiser websiteGO TO PAGE",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMijAFodHRwczovL3d3dy5wYWxtYmVhY2hwb3N0LmNvbS9zdG9yeS9uZXdzL2NyaW1lLzIwMTgvMTIvMzEvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3BlZWRzLXdvcmstYXQtcGFsbS1iZWFjaC1jb3VudHktY2xlcmtzLW9mZmljZS82NDA4NjM3MDA3L9IBAA?oc=5,Artificial intelligence speeds work at PBC clerk's office - Palm Beach Post,2018-12-31,Palm Beach Post,https://www.palmbeachpost.com,"WEST PALM BEACH — Back in the not-so-long-ago old days, human beings looked at newly-filed court documents , assigned them numbers and placed them in file folders so judges, lawyers and those whose l…",N/A,"WEST PALM BEACH — Back in the not-so-long-ago old days, human beings looked at newly-filed court documents , assigned them numbers and placed them in file folders so judges, lawyers and those whose l…","WEST PALM BEACH — Back in the not-so-long-ago old days, human beings looked at newly-filed court documents , assigned them numbers and placed them in file folders so judges, lawyers and those whose l…",,,,,,,,,,,,,,N/A,N/A,"CRIMEArtificial intelligence speeds work at PBC clerk's officeJane Musgravejmusgrave@pbpost.comPlayPauseSound OnSound Off0:000:34AD0:11SKIPClosedCaptionOpen ShareEnter Full ScreenExit Full ScreenWEST PALM BEACH — Back in the not-so-long-ago old days, human beings looked at newly-filed court documents, assigned them numbers and placed them in file folders so judges, lawyers and those whose lives or livelihoods depended on them could retrieve them later.Not anymore. Humans, it seems, are becoming obsolete.County Clerk & Comptroller Sharon Bock has a passion for public serviceInstead, Palm Beach County Clerk Sharon Bock is using artificial intelligence to file thousands of documents that stream into her office each week. By July, she said she expects the majority of court records that are filed electronically will be docketed by computer software.“As the world’s technology becomes more advanced, customers expect faster service,” she said of why she has embraced artificial intelligence. Computer technology has allowed her to quickly process court documents and make them available to the public.Her use of artificial intelligence has attracted the attention of the tech community. In December, her office was among 50 businesses, governments and nonprofit agencies throughout the country to be recognized by IDG, a Boston-based technology media, data and marketing services company. The company's online magazine, CIO, and its CIO (Chief Information Officer) Executive Council sponsored the awards. Winners were selected by executive informational technology leaders who evaluated projects on complexity, scale, outcomes and innovation, IDG said.“The Digital Edge 50 awards recognize the very best projects driving IT innovation,” said Anne McCrory, a group vice president of the executive council.While 89 percent of businesses plan to adopt a digital-first model, only 44 percent have followed through, McCrory said. The awards that will be handed to Bock and leaders at Bank of America, Cornell University, Humana and others at a conference in March in Ponte Vedra Beach, recognize those who put their plans into action.Bock launched the artificial intelligence in March, using software developed by Florida-based Computing Systems Innovation. The software has been trained to read and process different types of documents. Working around the clock, it allows documents to be processed almost immediately after they are filed electronically, she said.In addition to the honor from IDG, she said other court officials in Florida have taken notice. In July, clerks from other counties in Florida, along with representatives from the Administrative Office of the U.S. Courts and from the National Center for State Courts visited her office to find out how they can use technology to become more efficient.“I’m honored that our artificial intelligence program has been recognized as a leader in digital innovation, and that it will serve as a model for other organizations around the world,” Bock said.jmusgrave@pbpost.com@pbpcourtsCompareCredit2 Cards Charging 0% Interest Until Nearly 2026With no annual fee and no interest until nearly 2026, this card is helping Americans pay off debt in record time.CompareCredit|AdAdUndoGeorgetown University250+ Courses That Will Help You Make the Most of Your SummerGeorgetown is offering courses taught by its world-renowned faculty, so you can explore new subjects and get ahead.Georgetown University|AdAdUndoinvesting.comThe Top 25 Most Beautiful Women In The Worldinvesting.com|AdAdUndoPenny PincherVirginia: Big Changes Near Chantilly Leaves Drivers FumingDo not pay your auto insurance bill until you read this.Penny Pincher|AdAdUndoMiami M.D.Surgeon Reveals: Don't Laser Your Dark Spots! (Use This Household Item Instead)Miami M.D.|AdAdUndo plaque psoriasis | search adsPlaque psoriasis is silent but deadly: 10 Symptoms you should knowWhat does plaque psoriasis look like? Look at the symptoms plaque psoriasis | search ads|AdAdUndoGeorgetown UniversityEarn Credit and Get Ahead This Summer at GeorgetownBrowse Georgetown's more than 250 summer courses, all taught by world-renowned faculty.Georgetown University|AdAdLearn MoreUndoUltraCutUse This and Never Have to Change Your Whipper Snipper Line AgainUltraCut|AdAdUndoFisher Investments7 Wealth Tips Once Your Portfolio Reaches $1 MillionHow do retirees take steps to preserve their wealth in retirement? Download The Seven Secrets of High Net Worth Investors now.Fisher Investments|AdAdLearn MoreUndoCoupon Code FinderAmazon's Worst Nightmare: Thousands Canceling Prime for This Clever HackThis simple trick can save tons of money on Amazon, but most Prime members are ignoring it.Coupon Code Finder|AdAdUndoDeal of the DayREVIEWEDJLab Headphones Are Under $20 For Amazon Prime DayREVIEWEDView Deal Recommendations are independently chosen by our editors. Purchases you make through our links may earn us a commission.UndoRecommendedWade Wilson crimes: Convicted killer attempted escape from FL jailnewsUndo






























",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMikAFodHRwczovL21lZGl1bS5kYXRhZHJpdmVuaW52ZXN0b3IuY29tL25ldy10cmF1bWEtdGhlcmFweS11c2luZy1zdG9yeXRlbGxpbmctbXVzaWMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWktYW5kLXZpcnR1YWwtcmVhbGl0eS12ci0zOTcwYmYzNjE5MzfSAQA?oc=5,"New Trauma Therapy using storytelling, music, artificial intelligence (AI) and virtual reality (VR) - DataDrivenInvestor",2018-12-29,DataDrivenInvestor,https://medium.datadriveninvestor.com,"One very sad but true thing is — there is a lot of suffering in this world. Take a look around, there are different horrible things happening everywhere. From seemingly endless civil wars in the…",N/A,"One very sad but true thing is — there is a lot of suffering in this world. Take a look around, there are different horrible things…","One very sad but true thing is — there is a lot of suffering in this world. Take a look around, there are different horrible things…",http://schema.org,NewsArticle,https://medium.datadriveninvestor.com/new-trauma-therapy-using-storytelling-music-artificial-intelligence-ai-and-virtual-reality-vr-3970bf361937,['https://miro.medium.com/v2/da:true/resize:fit:1200/0*4_9RIUaTNPCxSWZF'],"{'@type': 'Person', 'name': 'Akira Olsen, PsyD', 'url': 'https://medium.datadriveninvestor.com/@akiraolsen'}","{'@type': 'Organization', 'name': 'DataDrivenInvestor', 'url': 'medium.datadriveninvestor.com', 'logo': {'@type': 'ImageObject', 'width': 308, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:616/1*OMF3fSqH8t4xBJ9-6oZDZw.png'}}","New Trauma Therapy using storytelling, music, artificial intelligence (AI) and virtual reality (VR)",2018-12-30T06:40:02.520Z,2021-12-07T04:14:50.528Z,,"New Trauma Therapy using storytelling, music, artificial intelligence (AI) and virtual reality (VR)",,,N/A,N/A,"New Trauma Therapy using storytelling, music, artificial intelligence (AI) and virtual reality (VR)Akira Olsen, PsyD·FollowPublished inDataDrivenInvestor·9 min read·Dec 30, 20189.2K7ListenSharePhoto by Nick Herasimenka on UnsplashOne very sad but true thing is — there is a lot of suffering in this world. Take a look around, there are different horrible things happening everywhere. From seemingly endless civil wars in the middle east to the economic crisis in some European and African countries. There is not a single person in this world who has never had any sad or embarrassing experience (except you are a 1-year-old). At times these terrible experiences can leave serious scars on us. According to the American Psychological Association, trauma is an emotional response to a terrible event such as rape, accident, or natural disaster. Here are some stats about traumatic experiences — about 30% of military men who have seen war will have PTSD. 15–25% of women have been sexually abused as children or teenagers. About 11% of children are being abused emotionally. One-third of women and one-fourth of men in America are experiencing physical violence from their spouses. In fact, if you are a survivor of the recent wildfire in California or the hurricane in some parts of America, and it still affects you deeply, then by definition, you may have been traumatized by the event. If you are still trying to know how trauma feels like, you can try to remember the worst thing that ever happened to you. A breakup, divorce, or the death of a loved one? That’s how trauma looks like. Now, try to double the way you feel anytime you think about that. That is how serious trauma looks like. The fact is many more people than you probably think have been traumatized in one way or another. There is a saying that goes like this — “a problem shared is half-solved”. We are going to talk about how storytelling otherwise known as narrative exposure therapy can help traumatized people heal. We are going to talk about narrative therapy, how it works, and its different types. Then we will talk about how artificial intelligence and virtual intelligence can help you incorporate music and other elements to your narrative therapy.What is narrative exposure therapy and how does it work?Actually, a better question would be — “how does your memory work?” The reason you should know this is that in order to understand narrative exposure therapy better, you would have to learn a bit about how memories work. Memories are not a fixed thing. Have you noticed that for you to remember something permanently, you have to think about it over and over again? The brain stores up the past memories in a type of archive folder in the brain. It also tries to associate the memory it wants to archive with other memory folders. This is an attempt to make it easily accessible. It’s just like archiving a folder you think may be useful later on but is not needed at the moment. If you want to archive a file, you can either:a) Toss it somewhere you usually toss all the stuff you don’t need orb) Try to arrange it alphabetically or with an orderly reference system that will make it easier for you to retrieve later.If you chose option a — well, good luck retrieving your file when you need it if you have about a hundred thousand different files in your basket. However, option b makes it easier to retrieve your files. Luckily for us, our brain not only tries to archive our memories like option b but does even better — our brain also tries to associate our memories with each other. Anytime you remember something, your brain makes stronger connection neurons in order to strengthen the memories. In other words, the more you think about an experience the stronger your memory of it and the stronger the emotions and physical reactions you experience anytime you think about it. Now, before we begin to talk about narrative exposure therapy, we need to understand one more thing — how does trauma work?Remember, the definition of trauma by the American Psychological Association as an emotional response to disturbing events like rape, accidents, or natural disaster? The question is, how does your brain create the disturbing emotional response we see in trauma? It has something to do with your memories. There are three aspects of memory. The first is the cognitive aspect which has to do with your ability to think and reason — your ability to frame what happened to you in a logical and analytical manner. In traumatized people, memories can be a jumbled mess of scary pictures scenes, and images. Second is the emotional aspect which has to do with the way you feel when you think about your experience (fear, anguish, pain, etc..). Traumatized people cannot completely detach themselves from their traumatic memories so may still have fresh emotions when they remember them. The third is the somatic aspect which is the way your body reacts to your feelings like trembling, sweating, agitation, and so on. When you experience a traumatic event, you keep on reliving the moment because the trauma affects parts of your brain like the forebrain (controls cognitive), limbic system (controls emotional), and hindbrain (controls somatic) which help archive your memories. What this means is that either all or part of the memory is not properly archived into the long-term memory storage. Trauma disrupts the cognitive, somatic, and emotional aspects of your memory. This means that anytime you remember such an event, it is as if it is literally happening to you. You can feel the trauma physically, emotionally and you even react to it. You may be trembling, having rapid palpitations, sweating, and so on when you think about the event that left you traumatized — like a sexual assault for example. Trauma is a way of your body trying to adapt to the terrible situation so it can protect you from future experiences. However, the problem is, a traumatized person adapts in a way that does more harm than good. That is why it is called “maladaptation”. Narrative exposure therapy tries to connect the dots of the cognitive, emotional, and somatic aspects of your memory so that your brain can archive it. Once, your brain archives it, it will only remain a memory and nothing more. In other words, you become separated from your problem.A straight-to-the-point discussion on narrative exposure therapy and how it works:Now that we have an understanding of what memory and trauma are, let us talk about what narrative exposure therapy is. It was invented by Michael White and David Epston in 1990. It is meant to separate traumatized people from their problems. It involves telling your own story. Getting a traumatized person to tell their story may bring back or even worsen the trauma. This is why it’s best if experts handle this. Narrative exposure therapy is not just about telling your story but trying to make sense of your emotional, reasoning (cognitive), and body reactions (somatic) to your traumatic experience. It’s important to practice mindfulness when you are telling your story as mindfulness helps you dissociate from your problems. You can read more on mindfulness in our article about it. Narrative therapy aims to change the effect your traumatic experience has on you. It aims to help you detach yourself from the traumatic experience. Trauma is sustained when the cognitive, emotional and somatic aspects of your memory are incongruent. As a therapist using narrative therapy, your job is to help your clients find their voice. They should be able to tell a story in their own words to help them find healing, meaning and re-establish their own identity. In narrative exposure therapy, you are not just telling a story which deals only with the cognitive part of the memory, but you are also trying to make sense of how you feel (your emotions) when you remember the event and why you act a certain way when you feel that way (your somatic responses). Making sense of these using mindfulness techniques can help you get over your trauma and understand yourself much better. Narrative therapy starts with a more superficial general story of yourself, then you gradually begin to go deeper into your traumatic experience exploring all the aspects of your memory till you can make sense of what happened to you and you can detach yourself from your problems. You can then tell your story in an alternative but a more positive, helpful and self-compassionate way that helps reinforce positive feelings and reactions. This technique is also called “re-storying” or “re-authoring”. Hence, it doesn’t hurt you as much when you think about it. So, let’s talk about where virtual reality and artificial intelligence come in.How artificial intelligence (AI) and virtual reality (VR) can make narrative therapy more effective:AI and VR are making huge waves in many industries today. They have great potentials in different areas like gaming, healthcare, education, defense, and even the adult industry. VR and AI are incredible tools to enhance your storytelling. The better your ability to tell your story, from the cognitive, emotional, and somatic aspects, the greater your chances of treating trauma. What’s more is that adolescents find using AI and VR fun. VR can bring your story to life. Life-like animations of your stories can be projected. What’s more is that it does not feel as threatening as a real-life exposure therapy because you know it is not real although it is realistic. The immersive form of VR can feel real because it is almost as if you are there. It can help make your thinking more logical, and with the guidance of the therapist, you can have more control over your somatic and emotional responses to your memories. AI can take your experience to the next level. Currently, AI exists that can simplify the animation of characters in VR. This means you can act out your story without the headaches of animation. All you have to do is to wear some sensors that allow the AI to detect your movements and animate the character of your choice. This is something like controlling a game character with your body. Also, there are AIs like AIVA which can compose music of your choice. It has scored about 30,000 compositions and mastered them much like a music student. It can take from these compositions and make new music tracks. It also understands several music genres and can compose soundtracks in different genres. That’s much like the same way humans learn and compose music, just a million times faster. With AI combined with VR, you can make a complete film of your own story with soundtracks and maybe songs if you wish.Music plays a vital role in emotions and reactions. More so, it is fun for millennials and Gen Z as they enjoy having their own type of music and watching videos. AI and VR make storytelling more immersive for teenagers as they get to watch a video of their own story, framed in their own words. Narrative therapy with AI and VR strengthens the cognitive, emotional, and somatic aspects of memory. When the brain can make sense of all these aspects of the memory of an event and bring them together logically, then it becomes easy for the brain to archive the memory. Hence, it is easier to drop the traumatic experience and move on.ReferencesAmerican Psychological Organisation. (n.d.). Retrieved from https://www.apa.org/ptsd-guideline/treatments/narrative-exposure-therapy.aspxClaudia M. Fletcher, G. B. (2018). More to the Story: Synthesizing Narrative Therapy with the Adaptive Information Processing Model. Journal of Counselor Practice, 9(2), 53–76. doi:DOI: 10.22229/ cmf902110Good therapy. (n.d.). Retrieved from https://www.goodtherapy.org/learn-about-therapy/types/narrative-therapyMark B. Powers, P. M. (2008). Virtual reality exposure therapy for anxiety disorders: A meta-analysis. Journal of Anxiety Disorders, 561–569. doi:doi:10.1016/j.janxdis.2007.04.006Shilling, A. (2017). Clinical Virtual Reality tools to advance the prevention, assessment, and treatment of PTSD. Eur J Psychotraumatol. doi: doi: 10.1080/20008198.2017.1414560White, M. & Epston, D. (1990). Narrative Means to Therapeutic Ends. W. W. Norton & Company; 1 edition.youtube. (n.d.). artificial intelligence and music. Retrieved from https://www.youtube.com/watch?v=wYb3Wimn01syoutube. (n.d.). storytelling through songs. Retrieved from https://www.youtube.com/watch?v=U0mPOkyKPJQ",,https://medium.datadriveninvestor.com/new-trauma-therapy-using-storytelling-music-artificial-intelligence-ai-and-virtual-reality-vr-3970bf361937,,,,,,,,,,,,,,,,,2018-12-30T06:40:02.520Z,3970bf361937,"['Akira Olsen, PsyD']",,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vd3d3LmphbWFpY2FvYnNlcnZlci5jb20vMjAxOC8xMi8zMC8yMDE5LWFuZC1iZXlvbmQtd2hhdC10by1leHBlY3QtZnJvbS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,2019 and beyond...what to expect from artificial intelligence - Jamaica Observer,2018-12-30,Jamaica Observer,https://www.jamaicaobserver.com,"“We stand on the brink of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. In its scale, scope, and complexity, the transformation will b...",,"“We stand on the brink of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. In its scale, scope, and...","“We stand on the brink of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. In its scale, scope, and...",http://schema.org,BreadcrumbList,https://www.jamaicaobserver.com/,https://www.jamaicaobserver.com/jamaicaobserver/news/wp-content/uploads/sites/4/2018/12/3da76d85ff4d897557196596ae68539d.jpg,"[{'@type': 'Person', 'name': 'BY SHARLENE HENDRICKS Staff reporter hendrickss@jamaicaobserver.com', 'url': 'https://www.jamaicaobserver.com/author/by-sharlene-hendricks-staff-reporter-hendrickssjamaicaobserver-com/'}]",,2019 and beyond&#8230;what to expect from artificial intelligence,2018-12-30T00:00:00-05:00,2018-12-30T00:00:00-05:00,['News'],Jamaica Observer,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://www.jamaicaobserver.com/category/news/'}]",N/A,N/A,"NewsCourt rules school breached constitutional rights of dreadlocks student, PNP applauds ruling",,"{'@type': 'WebPage', '@id': 'https://www.jamaicaobserver.com/2018/12/30/2019-and-beyond-what-to-expect-from-artificial-intelligence/'}",,,,,,,"{'@type': 'ImageObject', 'url': 'https://www.jamaicaobserver.com/jamaicaobserver/news/wp-content/uploads/sites/4/2023/09/jol_color_logo.png', 'width': '1000', 'height': '320'}",,,https://www.jamaicaobserver.com/privacy-policy/,,,"['https://www.facebook.com/jamaicaobserver', 'https://twitter.com/jamaicaobserver', 'https://www.instagram.com/jamaicaobserver/']",,,,,,,876-926-7655,"{'@type': 'PostalAddress', 'streetAddress': 'Kingston 40-42 1/2 Beechwood Avenue', 'addressLocality': 'Kingston', 'postalCode': '5', 'addressCountry': 'JM'}","[{'@type': 'ContactPoint', 'contactType': 'Public Engagement', 'url': 'https://www.jamaicaobserver.com/contact-us/'}]"

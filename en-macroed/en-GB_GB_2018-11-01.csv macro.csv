URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,publisher,datePublished,dateModified,headline,image,thumbnailUrl,mainEntityOfPage,author,article:section,article:summary,article text,articleSection,@graph,alternativeHeadline,isAccessibleForFree,copyrightHolder,@id,name,alternateName,legalName,foundingDate,logo,masthead,sameAs,address,articleBody,hasPart,isPartOf,email,telephone
https://news.google.com/rss/articles/CBMiLmh0dHBzOi8vd3d3LmJiYy5jby51ay9uZXdzL3RlY2hub2xvZ3ktNDYwNTU1OTXSATJodHRwczovL3d3dy5iYmMuY28udWsvbmV3cy90ZWNobm9sb2d5LTQ2MDU1NTk1LmFtcA?oc=5,Why Big Tech pays poor Kenyans to teach self-driving cars - BBC,2018-11-03,BBC,https://www.bbc.co.uk,The data that powers the most cutting edge technology in Silicon Valley begins in Nairobi's slum.,N/A,The data that powers the most cutting edge technology in Silicon Valley begins in Nairobi's slum.,The data that powers the most cutting edge technology in Silicon Valley begins in Nairobi's slum.,http://schema.org,ReportageNewsArticle,https://www.bbc.com/news/technology-46055595,"{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'publishingPrinciples': 'http://www.bbc.co.uk/news/help-41670342', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",2018-11-03T01:30:13.000Z,2018-11-03T01:30:13.000Z,Why Big Tech pays poor Kenyans to teach self-driving cars,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_news/9259/production/_104156473_whatsubject.jpg'}",https://ichef.bbci.co.uk/news/1024/branded_news/9259/production/_104156473_whatsubject.jpg,https://www.bbc.com/news/technology-46055595,"[{'@type': 'Person', 'name': 'By Dave Lee'}]",N/A,N/A,"Why Big Tech pays poor Kenyans to teach self-driving cars2 November 2018By Dave Lee, North America technology reporterShare6:08WATCH: Why Kenyans are becoming experts in AIWhen Artificial Intelligence works as intended, Silicon Valley types often say it's ""like magic"".But it isn't magic. It's Brenda, a 26-year-old single mother who lives Kibera, Africa's largest slum, and perhaps the toughest neighbourhood on earth, where hundreds of thousands of people live in a space not too much bigger than London's Hyde Park.Each day, Brenda leaves her home here to catch a bus to the east side of Nairobi where she, along with more than 1,000 colleagues in the same building, work hard on a side of artificial intelligence we hear little about - and see even less.In her eight-hour shift, she creates training data. Information - images, most often - prepared in a way that computers can understand. Brenda lives in Kibera, considered Africa's largest slumBrenda loads up an image, and then uses the mouse to trace around just about everything. People, cars, road signs, lane markings - even the sky, specifying whether it's cloudy or bright. Ingesting millions of these images into an artificial intelligence system means a self-driving car, to use one example, can begin to ""recognise"" those objects in the real world. The more data, the supposedly smarter the machine.She and her colleagues sit close - often too close - to their monitors, zooming in on the images to make sure not a single pixel is tagged incorrectly. Their work will be checked by a superior, who will send it back if it's not up to scratch. For the fastest, most accurate trainers, the honour of having your name up on one of the many TV screens around the office. And the most popular perk of all: shopping vouchers.""You get to do something unique,"" Brenda told me when I visited the tiny home she shares with her daughter, brother and mother.""With my work that I'm doing, I believe I'm working for something that is going to help someone in future.""Slum schoolBrenda does this work for Samasource, a San Francisco-based company that counts Google, Microsoft, Salesforce and Yahoo among its clients. Most of these firms don't like to discuss the exact nature of their work with Samasource - as it is often for future projects - but it can be said that the information prepared here forms a crucial part of some of Silicon Valley's biggest and most famous efforts in AI. For eight hours a day, Brenda trains data used for artificial intelligenceIt's the kind of technological progress that will likely never be felt in a place like Kibera. As Africa's largest slum, it has more pressing problems to solve, such as a lack of reliable clean water, and a well-known sanitation crisis.But that's not to say artificial intelligence can't have a positive impact here. We drove to one of Kibera's few permanent buildings, found near a railway line that, on this rainy day, looked thoroughly decommissioned by mud, but has apparently been in regular use since its colonial inception.Almost exactly a year ago, this building was the dividing line between stone-throwing rioters and the military. Today, it's a thriving hub of activity: a media school and studio, something of a cafeteria, and on the first floor, a room full of PCs. Here, Gideon Ngeno teaches around 25 students the basics of using a personal computer.What's curious about this process is that digital literacy is high, even in Kibera, where smartphones are common and every other shop is selling chargers and accessories, which people buy using the mobile money system MPesa.Images have to be painstakingly annotated - cars, roads, signs... even the skyBut much of Africa has leapfrogged the desktop PC era. The keyboard and mouse combination is a foreign, cumbersome experience. One Samasource team member told me how she'd often observe trainees look away from their PCs and pick up their phone when asked to search for information on the internet.The course taught here is designed specifically for those wanting to go on to work at Samasource or another digital economy company. It costs 500 Kenyan shillings - around $5. That's a not insignificant amount for people who often live below the poverty line. The company used to offer the course for free, but without the financial commitment, I was told attendance (and concentration) was sketchy at best. Now the biggest challenge, Ngeno said, was noise - as we spoke, a group of eager children did exactly what you'd expect of them when handed a selection of musical instruments. Outside, a market thronged with activity.A campus fit for CaliforniaIn contrast, the Samasource office is in a part of Nairobi that reassures you this is a city on the up. The company occupies four floors of a business park building, with vast banks of computers being used for the job of training data. SamasourceThe data is used to help automated systems ""recognise"" objects in the real worldIf you didn't look out of the windows, you might think you were at a Silicon Valley tech firm. Walls are covered in corrugated iron in a way that would be considered achingly trendy in California, but here serve as a reminder of the environment many of the workers come from: around 75% are from the slum.Most impressively, Samasource has overcome a problem that most Silicon Valley firms are famously grappling with. Just over half of their workforce is made up of women, a remarkable feat in a country where starting a family more often than not rules out a career for the mother. Here, a lactation room, up to 90 days maternity leave, and flexibility around shift patterns makes the firm a stand-out example of inclusivity not just in Kenya, but globally.""Like a lot of people say, if you have a man in the workplace, he'll support his family,"" said Hellen Savala, who runs human resources. ""[But] if you have a woman in the workplace, she'll support her family, and the extended family. So you'll have a lot more impact.""'It would never work'That balance isn't just among those doing the entry level work, either. In San Francisco's Mission District, in an office far more modest than what the firm has in Kenya, Samasource's chief executive Leila Janah beamed when talking about how the firm's management team is majority female. ""It's extremely unusual in Silicon Valley more broadly, but especially within artificial intelligence.""We just think of it as normal. It's a competitive advantage.""Leila Janah, right, was at first criticised for wanting to outsource jobs away from the USFounded in 2008, Samasource received a frosty reception in its early days. In recession-hit America, outsourcing a large number of jobs to the developing world was not seen as a welcome idea. It arguably still isn't. Those who did like the concept worried there were too few people with the digital skills necessary to do the work to a standard the tech giants would accept.""Very smart people in the tech world, and in the world of big philanthropy said this was a wonderful idea, but that it would never work,"" Janah recalled. Today, Samasource is the largest organisation of its kind in East Africa, and also has facilities in Asia and North America.Cheap labourJanah touts the company's record for accuracy and security as the major reasons why Google et al come to them for this work. But of course, there's an obvious motivation for these companies to use workers in parts of the world where wages are rock bottom, and where locals are desperate for steady work.Samasource targets those currently earning around $2 a day, or less, in the so-called informal economy of odd - or dangerous - jobs. Samasource instead provides a living wage of around $9 a day. That's an improvement, but still a pittance for Silicon Valley.Gideon Ngeno teaches basic digital literacy right in the heart of Kibera's slum""Yes, it's cost effective,"" Janah said. ""But one thing that's critical in our line of work is to not pay wages that would distort local labour markets. If we were to pay people substantially more than that, we would throw everything off. That would have a potentially negative impact on the cost of housing, the cost of food in the communities in which our workers thrive.""Then of course, there's a question of what happens if the work is no longer needed. Samasource's main business is, after all, in providing data for automated systems. What if the process of creating that data becomes automated as well?""That's the billion dollar technology question that everyone is paranoid about,"" Janah said.""I think there's a lot of hype around that. But if you actually talk to data scientists, the minds behind these algorithms, you'll find the machine is much further behind than most people realise. ""We're going to need training data for a long time.""'It has changed my everything'Being a data training expert is boring, repetitive, never-ending work. And when not in front of our cameras, some staff talked about how they faced pressure to work quickly in order to hit company targets, leading to fewer breaks. Some Samasource workers are freelancers who can work anywhere, but with a webcam watching them as they work.Idris lived in the slum, but has since been able to move, and has plans to take a business leadership courseNone of the staff we saw at the office had any kind of acceptable ergonomic support, often crouching over, clicking away furiously, for hours on end - a certain strain to eyes and body. The company has said it would work on that.Complaints about the work - which are certainly not unique in this industry - are quickly followed up with stories of changed lives. Samasource believes it has impacted almost 50,000 people in the developing world; those who either worked at Samasource, or are supported by someone who did. It has surveyed former employees and discovered that around 84% continued on to more formal work or took up higher education.One of those workers moving onto bigger things is Idris Abdi, 25, who was able to move out of the slum.""It has changed my… my everything,"" he said.""It has changed my perspective, it has exposed me to see there is hope beyond living here.""________Follow Dave Lee on Twitter @DaveLeeBBCDo you have more information about this or any other technology story? You can reach Dave directly and securely through encrypted messaging app Signal on: +1 (628) 400-7370What is artificial intelligence?How AI is transforming tennisCould AI replace doctors?",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3Lm11dHVhbGFydC5jb20vQXJ0aWNsZS9UaGUtUmVhbC1GdXR1cmUtb2YtQXJ0LWFuZC1BcnRpZmljaWFsLUluL0Q3NDFBMEMwQzYwMkY3RTXSAQA?oc=5,An Expert Guide to Art and Artificial Intelligence - MutualArt.com,2018-11-02,MutualArt.com,https://www.mutualart.com,Here's our expert guide to the future of art and AI ,N/A,Mario Klingemann and Anna Ridler give us the expert take on AI and art	,N/A,http://schema.org,Article,https://www.mutualart.com/Article/The-Real-Future-of-Art-and-Artificial-In/D741A0C0C602F7E5,"{'@type': 'Organization', 'name': 'MutualArt News', 'sameAs': 'https://www.mutualart.com/magazine', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mutualart.com/img/mutualartShareLogo.jpg'}}",11/2/2018 12:00:00 AM,11/2/2018 12:00:00 AM,An Expert Guide to Art and Artificial Intelligence,['https://media.mutualart.com/Images//2018_11/01/10/104714346/22c7f88a-174d-4ddf-9212-8788f889d5fc.Jpeg'],,,"{'@type': 'Person', 'name': 'Adam Heardman'}",N/A,N/A,N/A,Features,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vZWRyaS5vcmcvb3VyLXdvcmsvZ3JlZWNlLWNsYXJpZmljYXRpb25zLXNvdWdodC1vbi1odW1hbi1yaWdodHMtaW1wYWN0cy1vZi1pYm9yZGVyY3RybC_SAQA?oc=5,Greece: Clarifications sought on human rights impacts of iBorderCtrl - European Digital Rights (EDRi),2018-11-05,European Digital Rights (EDRi),https://edri.org,N/A,N/A,"On 5 November 2018, EDRi observer Homo Digitalis filed a petition to the Greek Parliament about the pilot implementation of the iBorderCtrl project on the Greek border. The Minister in charge will have 25 days to reply to it.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,N/A,,"[{'@type': 'WebPage', '@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/', 'url': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/', 'name': 'Greece: Clarifications sought on human rights impacts of iBorderCtrl - European Digital Rights (EDRi)', 'isPartOf': {'@id': 'https://edri.org/#website'}, 'primaryImageOfPage': {'@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#primaryimage'}, 'image': {'@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#primaryimage'}, 'thumbnailUrl': 'https://edri.org/wp-content/uploads/2018/11/iBorderCtrl.png', 'datePublished': '2018-11-21T00:00:00+00:00', 'dateModified': '2020-08-26T07:32:19+00:00', 'breadcrumb': {'@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#primaryimage', 'url': 'https://edri.org/wp-content/uploads/2018/11/iBorderCtrl.png', 'contentUrl': 'https://edri.org/wp-content/uploads/2018/11/iBorderCtrl.png', 'width': 600, 'height': 296, 'caption': ''}, {'@type': 'BreadcrumbList', '@id': 'https://edri.org/our-work/greece-clarifications-sought-on-human-rights-impacts-of-iborderctrl/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://edri.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Resources', 'item': 'https://edri.org/our-work/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Greece: Clarifications sought on human rights impacts of iBorderCtrl'}]}, {'@type': 'WebSite', '@id': 'https://edri.org/#website', 'url': 'https://edri.org/', 'name': 'European Digital Rights (EDRi)', 'description': 'Protecting digital rights in Europe.', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://edri.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LmFtZXJpY2FtYWdhemluZS5vcmcvcG9saXRpY3Mtc29jaWV0eS8yMDE4LzExLzAyL3doYXQtYXJlLWRhbmdlcnMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utb3VyLWJyYXZlLW5ldy13b3JsZC1zZWxm0gEA?oc=5,"Should we be worried about A.I.? Theologians, philosophers and Catholic thinkers weigh in - America: The Jesuit Review",2018-11-02,America: The Jesuit Review,https://www.americamagazine.org,"As Facebook, Apple and Google pour billions into artificial intelligence, ethicists and moral philosophers are racing to keep up, and Catholic thinkers are looking ahead to the possible harms to humanity.",N/A,"As Facebook, Apple and Google pour billions into artificial intelligence, ethicists and moral philosophers are racing to keep up, and Catholic thinkers are looking ahead to the possible harms to humanity.","As Facebook, Apple and Google pour billions into artificial intelligence, ethicists and moral philosophers are racing to keep up, and Catholic thinkers are looking ahead to the possible harms to humanity.",,,,,,,,,,,,N/A,N/A," Politics & SocietyFeaturesNovember 12, 2018 issueShould we be worried about A.I.? Theologians, philosophers and Catholic thinkers weigh inJohn W. MillerNovember 02, 2018FacebookTwitterEmail(iStock)Like paper, print, steel and the wheel, computer-generated artificial intelligence is a revolutionary technology that can bend how we work, play and love. It is already doing so in ways we can and cannot perceive.As Facebook, Apple and Google pour billions into A.I. development, there is a fledgling branch of academic ethical study—influenced by Catholic social teaching and encompassing thinkers like the Jesuit scientist Pierre Teilhard de Chardin—that aims to study its moral consequences, contain the harm it might do and push tech firms to integrate social goods like privacy and fairness into their business plans.Advertisement“There are a lot of people suddenly interested in A.I. ethics because they realize they’re playing with fire,” says Brian Green, an A.I. ethicist at Santa Clara University. “And this is the biggest thing since fire.”“There are a lot of people suddenly interested in A.I. ethics because they realize they’re playing with fire. And this is the biggest thing since fire.”Tweet thisThe field of A.I. ethics includes two broad categories. One is the philosophical and sometimes theological questioning about how artificial intelligence changes our destiny and role as humans in the universe; the other is a set of nuts-and-bolts questions about the impact of powerful A.I. consumer products, like smartphones, drones and social media algorithms.
Recommended for You



The problem with cutting off your family members 
Nathan Beacom





Survey: U.S. Catholics are divided on immigration—even though they know church teaching on it 
Mark M. Gray



AdvertisementThe first is concerned with what is termed artificial general intelligence. A.G.I. describes the kind of powerful artificial intelligence that not only simulates human reasoning but surpasses it by combining computational might with human qualities like learning from mistakes, self-doubt and curiosity about mysteries within and without.A popular word—singularity—has been coined to describe the moment when machines become smarter, and maybe more powerful, than humans. That moment, which would represent a clear break from traditional religious narratives about creation, has philosophical and theological implications that can make your head spin.But before going all the way there—because it is not all that clear that this is ever going to happen—let us talk about the branch of A.I. ethics more concerned with practical problems, like if it is O.K. that your phone knows when to sell you a pizza.Advertisement“For now, the singularity is science fiction,” Shannon Vallor, a philosophy professor who also teaches at Santa Clara, tells me. “There are enough ethical concerns in the short term.”The ‘Black Mirror’ factorWhile we ponder A.G.I., artificial narrow intelligence is already here: Google Maps suggesting the road less traveled, voice-activated programs like Siri answering trivia questions, Cambridge Analytica crunching private data to help swing an election, and military drones choosing how to kill people on the ground. A.N.I. is what animates the androids in the HBO series “Westworld”—that is, until they develop A.G.I. and start making decisions on their own and posing human questions about existence, love and death.Even without the singular, and unlikely, appearance of robot overlords, the possible outcomes of artificial narrow intelligence gone awry include plenty of apocalyptic scenarios, akin to the plots of the TV series “Black Mirror.” A temperature control system, for example, could kill all humans because that would be a rational way to cool down the planet, or a network of energy-efficient computers could take over nuclear plants so it will have enough power to operate on its own.AdvertisementThe more programmers push their machines to make smart decisions that surprise and delight us, the more they risk triggering something unexpected and awful.The invention of the internet took most philosophers by surprise. This time, A.I. ethicists view it as their job to keep up.“There’s a lack of awareness in Silicon Valley of moral questions,” says Tae Wan Kim, an A.I. ethicist at Carnegie Mellon University in Pittsburgh. (John W. Miller)“There’s a lack of awareness in Silicon Valley of moral questions, and churches and government don’t know enough about the technology to contribute much for now,” says Tae Wan Kim, an A.I. ethicist at Carnegie Mellon University in Pittsburgh. “We’re trying to bridge that gap.”A.I. ethicists consult with schools, businesses and governments. They train tech entrepreneurs to think about questions like the following. Should tech companies that collect and analyze DNA data be allowed to sell that data to pharmaceutical firms in order to save lives? Is it possible to write code that offers guidance on whether to approve life insurance or loan applications in an ethical way? Should the government ban realistic sex robots that could tempt vulnerable people into thinking they are in the equivalent of a human relationship? How much should we invest in technology that throws millions of people out of work?Tech companies themselves are steering more resources into ethics, and tech leaders are thinking seriously about the impact of their inventions. A recent survey of Silicon Valley parents found that many had prohibited their own children from using smartphones.The more programmers push their machines to get creative and make smart decisions, the more they risk triggering something unexpected and awful.Tweet thisMr. Kim frames his work as that of a public intellectual, reacting to the latest efforts by corporations to show they are taking A.I. ethics seriously.In June, for example, Google, seeking to reassure the public and regulators, published a list of seven principles for guiding its A.I. applications. It said that A.I. should be socially beneficial, avoid creating or reinforcing unfair bias, be built and tested for safety, be accountable to people, incorporate privacy design principles, uphold high standards of scientific excellence, and be made available to uses that accord with these principles.In response, Mr. Kim published a critical commentary on his blog. The problem with promising social benefits, for example, is that “Google can take advantage of local norms,” he wrote. “If China allows, legally, Google to use AI in a way that violates human rights, Google will go for it.” (At press time, Google had not responded to multiple requests for comment on this criticism.)The biggest headache for A.I. ethicists is that a global internet makes it harder to enforce any universal principle like freedom of speech. The corporations are, for the most part, in charge. That is especially true when it comes to deciding how much work we should let machines do.The invention of the internet took most philosophers by surprise. This time, A.I. ethicists view it as their job to keep up.Tweet thisAn argument familiar to anybody who has ever studied economics is that new technologies create as many jobs as they destroy. Thus the invention of the cotton gin in the 19th century called for industries dedicated to producing the necessary parts of wood and iron. When horses were replaced as a primary form of transportation, stable hands found jobs as auto mechanics. And so on.A.I. ethicists say the current technological revolution is different because it is the first to replicate intellectual tasks. This kind of automation could create a permanently underemployed class of people, says Mr. Kim.A purely economic response to unemployment might be a universal basic income, or distribution of cash to every citizen, but Mr. Kim says A.I. ethicists cannot help returning to the realization that lives without purposeful activity, like a job, are usually miserable. “Catholic social teaching is an important influence for A.I. ethicists, because it addresses how important work is to human dignity and happiness,” he explains.“Money alone doesn’t give your life happiness and meaning,” he says. “You get so many other things out of work, like community, character development, intellectual stimulation and dignity.” When his dad retired from his job running a noodle factory in South Korea, “he got money, but he lost community and self-respect,” says Mr. Kim.That is a strong argument for valuing a job well done by human hands; but as long as we stick with capitalism, the capacity of robots to work fast and cheap is going to make them attractive, say A.I. ethicists.“Maybe religious leaders need to work on redefining what work is,” says Mr. Kim. “Some people have proposed virtual reality work,” he says, referring to simulated jobs within computer games. “That doesn’t sound satisfying, but maybe work is not just gainful employment.”There is also a chance that the impact of automation might not be as bad as feared. A company in Pittsburgh called Legal Sifter offers a service that uses an algorithm to read contracts and detect loopholes, mistakes and omissions. This technology is possible because legal language is more formulaic than most writing. “We’ve increased our productivity seven- or eightfold without having to hire any new people,” says Kevin Miller, the company’s chief executive. “We’re making legal services more affordable to more people.”But he says lawyers will not disappear: “As long as you have human juries, you’re going to have human lawyers and judges…. The future isn’t lawyer versus robot, it’s lawyer plus robot versus lawyer plus robot.”Autonomous cars and the Trolley ProblemThe most common jobs for American men are behind the wheel. Now self-driving vehicles threaten to throw millions of taxi and truck drivers out of work.We are still at least a decade away from the day when self-driving cars occupy major stretches of our highways, but the automobile is so important in modern life that any change in how it works would greatly transform society.Autonomous automobiles raise dozens of issues for A.I. ethicists. The most famous is a variant of the so-called trolley problem, a concept popularized by philosopher Philippa Foot in the 1960s. A current version describes the dilemma a machine might face if a crowded bus is in its fast-moving path. Should it change direction and try to kill fewer people? What if changing direction threatens a child? The baby-or-bus bind one of those instantaneous, tricky and messy decisions that humans accept as part of life, even if we know we do not always make them perfectly. It is the kind of choice for which we know there might never be an algorithm, especially if one starts trying to calculate the relative worth of injuries. Imagine, for example, telling a bicyclist that taking his or her life is worth it to keep a busful of people out of wheelchairs.Technology experts say that the trolley problem is still theoretical because machines presently have a hard time making distinctions between people and things like plastic bags and shopping carts, leading to unpredictable scenarios. This is largely because neuroscientists still have an incomplete grasp of how vision works.Is it morally correct to tell an autonomous car to drive the speed limit when everybody else is driving 20 miles an hour over?”Tweet this“But there are many ethical or moral situations that are likely to happen, and they’re the ones that matter,” says Mike Ramsey, an automotive analyst for Gartner Research.The biggest problem “is programming a robot to break the law on purpose,” he says. “Is it morally correct to tell the computer to drive the speed limit when everybody else is driving 20 miles an hour over?”Humans break rules in reasonable ways all the time. For example, letting somebody out of a car outside of a crosswalk is almost always safe, if not always technically legal. Making that distinction is still almost impossible for a machine.And as programmers try to make this type of reasoning possible for machines, invariably they base their algorithms on data derived from human behavior. In a fallen world, that’s a problem.“There’s a risk of A.I. systems being used in ways that amplify unjust social biases,” says Ms. Vallor, the philosopher at Santa Clara University. “If there’s a pattern, A.I. will amplify that pattern.”Loan, mortgage or insurance applications could be denied at higher rates for marginalized social groups if, for example, the algorithm looks at whether there is a history of homeownership in the family. A.I. ethicists do not necessarily advocate programming to carry out affirmative action, but they say the risk is that A.I. systems will not correct for previous patterns of discrimination.Ethicists are also concerned that relying on A.I. to make life-altering decisions cedes even more influence than they already have to corporations that collect, buy and sell private data, as well as to governments that regulate how the data can be used. In one dystopian scenario, a government could deny health care or other public benefits to people deemed to engage in “bad” behavior, based on the data recorded by social media companies and gadgets like Fitbit.Every artificial intelligence program is based on how a particular human views the world, says Mr. Green, the ethicist at Santa Clara. “You can imitate so many aspects of humanity,” he says, “but what quality of people are you going to copy?”“Copying people” is the aim of a separate branch of A.I. that simulates human connection. A.I. robots and pets can offer the simulation of friendship, family, therapy and even romance.Already, some people say they are in “relationships” with robots, creating strange new ethical questions. Tweet thisOne study found that autistic children trying to learn language and basic social interaction responded more favorably to an A.I. robot than to an actual person. But the philosopher Alexis Elder argues that this constitutes a moral hazard. “The hazard involves these robots’ potential to present the appearance of friendship to a population” who cannot tell the difference between real and fake friends, she writes in the essay collection Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence. “Aristotle cautioned that deceiving others with false appearances is of the same kind as counterfeiting currency.”Another form of counterfeit relationship A.I. technology proposes is, not surprisingly, romance. Makers of new lines of artificial intelligence dolls costing over $10,000 each claim, as one ad says, to “deliver the most enjoyable conversation and interaction you can have with a machine.”Already, some people say they are in “relationships” with robots, creating strange new ethical questions. If somebody destroys your robot, is that murder? Should the government make laws protecting your right to take a robot partner to a ballgame or on an airplane trip, or to take bereavement leave if it breaks?Even Dan Savage, the most famous sex columnist in the United States, sounds a cautionary note. “Sex robots are coming whether we like it or not,” he tells me. “But we will have to take a look at the real impact they’re having on people’s lives.”Pierre Teilhard de Chardin’s wild rideInevitably, ethicists tackling A.N.I. run into the deeper philosophical questions posed by those who study A.G.I. One example of how narrow intelligence can appear to turn into a more general form came when a computer program beat Lee Sedol, a human champion of the strategic game Go, in 2016. Early in the game, the machine, Alpha Go, played a move that did not make sense to its human onlookers until the very end. That mysterious creativity is an intensely human quality, and a harbinger of what A.G.I. might look like.A.G.I. theorists pose their own set of questions. They debate whether tech firms and governments should develop A.G.I. as quickly as possible to work out all the kinks, or block its development in order to forestall machines’ taking over the planet. They wonder what it would be like to implant a chip in our brain that would make us 200 times smarter, or immortal or turn us into God. Might that be a human right? Some even speculate that A.G.I. is itself a new god to be worshipped.But the singularity, if it happens, poses a definite problem for thinkers of almost every religious bent, because it would be such a clear break from traditional narratives.“Christians are facing a real crisis, because our theology is based on how God made us autonomous,” says Mr. Kim, who is a Presbyterian deacon. “But now you have machines that are autonomous, too, so what is it that makes us special as humans?”Pierre Teilhard de Chardin, a French Jesuit and scientist, helped to found a school of thought called transhumanism, which views all technology as an extension of the human self. (AP Image)One Catholic thinker who thought deeply about the impact of artificial intelligence is Pierre Teilhard de Chardin, a French Jesuit and scientist who helped to found a school of thought called transhumanism, which views all technology as an extension of the human self.“His writings anticipated the internet and what the computer could do for us,” says Ilia Delio, O.S.F., a professor at Villanova.Teilhard de Chardin viewed technology with a wide lens. “The New Testament is a type of technology,” says Sister Delio, explaining the point of view. “Jesus was about becoming something new, a transhuman, not in the sense of betterment, but in the sense of more human.”Critics of transhumanism say that it promotes materialistic and hedonistic points of view. In a recent essay in America, John Conley, S.J., of Loyola University Maryland, called the movement “a cause for alarm.” He wrote: “Is there any place for people with disabilities in this utopia? Why would we want to abolish aging and dying, essential constituents of the human drama, the fountainhead of our art and literature? Can there be love and creativity without anguish? Who will flourish and who will be eliminated in this construction of the posthuman? Does nature itself have no intrinsic worth?”Teilhard’s writings have also been tainted by echoes of the racist eugenics popular in the 1920s. He contended, for example, that “not all ethnic groups have the same value.”But his purely philosophical arguments about technology have regained currency among Catholic thinkers this century, and reading Teilhard can be a wild ride. Christian thinkers conventionally say, as St. John Paul II did, that every technological conception should advance the natural development of the human person. Teilhard went farther. He reasoned that technology, including artificial intelligence, could link all of humanity, bringing us to a point of ultimate spiritual unity through knowledge and love. He termed the moment of global spiritual coming-together the Omega Point. And it was not the kind of consumer conformism that tech executives dream about.“Now you have machines that are autonomous, too, so what makes us special as humans?”Tweet this“This state is obtained not by identification (God becoming all) but by the differentiating and communicating action of love (God all in everyone). And that is essentially orthodox and Christian,” Teilhard wrote.RELATED STORIES What would Jesus do about Artificial Intelligence? Become more human.Simcha Fisher How the church can help fight the tyranny of algorithmsJim McDermott Why we need a new theology of workJonathan Malesic  Internet privacy is about the common good, not just competition and consumersThe EditorsThis idealism is similar to that of Tim Berners-Lee, one of the scientists who wrote the software that created the internet. The purpose of the web was to serve humanity, he said in a recent interview with Vanity Fair. But centralized and corporate control, he said, has “ended up producing—with no deliberate action of the people who designed the platform—a large-scale emergent phenomenon which is anti-human.” He and others now say the accumulation and selling of personal data dehumanizes and commodifies people, instead of enhancing their humanity.Interestingly, the A.I. debate provokes theological questioning by people who usually do not talk all that much about God.Juan Ortiz Freuler, a policy fellow at the Washington-based World Wide Web Foundation, which Mr. Berners-Lee started to protect human rights, says he hears people in the tech industry “argue that a system so complex we can’t understand it is like a god.” But it is not a god, says Mr. Freuler. “It’s a company wearing the mask of a god. And we don’t always know what their values are.”You do not have to worship technology as a god to realize that our choices, and lives, are increasingly influenced by decision-making software. But as every A.I. ethicist I talked to told me, we should not be confused about who is responsible for making the important decisions.“We still have our freedom,” says Sister Delio. “We can still make choices.”FacebookTwitterEmailMore: Science / TechnologyJohn W. MillerJohn W. Miller is a Pittsburgh-based writer and former staff reporter and foreign correspondent for The Wall Street Journal.@jwmjournalistShow Comments ( 3)Comments are automatically closed two weeks after an article's initial publication. See our comments policy for more.Stanley Kopacz5 years 8 months agoA human Go player has played perhaps tens of thousands of games. I believe the Go-playing AI played millions of games with itself, losing and winning millions of games in preparation. The level of ""experience"" is higher. In the case of any rule based game, the number of possibilities is defined enough. The question is whether a similar process can be applied to real life situations. In this case, the AI would have to play millions of games in a simulation and its skill level would depend if the simulation is accurate and complex enough to mirror reality. Or so I understand it. I guess I should get a textbook on neural networks. What fascinates me is not so much that we can do the things we do but that we are aware of the doing. Very strange.Charles Erlinger5 years 8 months agoAn article in the September, 2018 issue of the Institute of Electronic and Electrical Engineers publication “Computer” by Plamen P. Angelov and Xiaowei Gu of Lancaster University, entitled “Toward Anthropomorphic Machine Learning” sprinkles a little engineering reality on the capability of some of the more popular approaches to Artificial Intelligence that various commercial and governmental entities attempt to implement. The approach in question is called “Deep Learning Neural Networks” or DLNN. The authors supply end-note superscripts that refer to sources that the authors use to corroborate their case, but the notes are not reproduced here, for brevity.“LIMITS AND CHALLENGES OF DEEP LEARNING“The mainstream DLNNs, despite their success (reported results are comparable to or superior to human ability) and publicity (including the commercial version), as well as increasing media interest, still have a number of unanswered questions and deficiencies, as described below.“The internal architecture of DLNNs is opaque … (there are many ad hoc decisions and parameters, such as number of layers, neurons, and parameter values).“The training process of DLNNs requires a large amount of  data, time, and computational resources, which preclude training and adaptation in real time; therefore, DLNNs cannot cope with the evolving nature of the data (they have a fixed structure and settings, for example, the number of classes), and they also cannot learn ‘from scratch.’“DLNNs are prone to overfitting. DLNNs cannot handle uncertainty. Not only do they perform poorly on inference data that is significantly different from the training data, but they are also UNAWARE of this (meaning that it is practically impossible to analyze the reasons for errors and failures); they can be easily fooled and thus output high-confidence scores even when facing unrecognizable images.“The whole article and, indeed the entire issue is worth reading. It should be noted that technologists often take ethical issues just as seriously as do ethicists.On a slightly different issue related to the use of AI, it seems that we often forget the layers of protection provided by law and regulation on the safety and effectiveness of human and technology-assisted services that affect public safety. There is a reason for the state-federal licensing system for physicians, engineers who do public engineering projects, lawyers, teachers, various clinicians doing counseling-related work, aviation certifications, drug approvals, and many more professional and skilled trade services and providers. The licensing process involves documented years of pre-licensing experience, formal testing using approved protocols, and background checking. Applying similar standards to AI-generated services affecting public safety and welfare will demand that AI systems be fully susceptible to analysis to insure safety and effectiveness, which means that the processes must be understandable to legislative and regulatory staffs.Santosh Kumar5 years 8 months agoGlobal Digital Forum (GDF) is a global technology conference that has been uniquely designed to bring together an unparalleled line-up of business leaders, practitioners and customers from all over the world, engaged in driving change at the intersection of Artificial Intelligence, Security/Blockchain, Cloud Services and Internet-of-Things and key industry verticals.Register here: http://promotions.plantautomation-technology.com/global-digital-forum-event 

More from America






Ageism is making it impossible to fairly judge Joe Biden
Lynn Casteel Harper





After 35 years, a final settlement reached in the Mount Cashel Orphanage sex abuse cases
Kevin Clarke





‘Stop Donald Trump’ isn’t enough. The Democratic Party needs a deeper message to win the election.
Robert David Sullivan





Mass isn’t a ‘show.’ But it has plenty of drama.
Rebecca Moon Ruark





When the suburban American dream conflicts with Catholic social teaching
Dominic Gideon



Your source for jobs, books, retreats, and much more.Come Join UsVolunteer / VocationDirector of Faith FormationJobs“Our Hope is in Christ” USCCA International Conference August 2-4, 2024 @ DePaul University – Registration Open through July 30!Conferences, EventsSpiritual Practices – An online courseSpiritual ResourcesSacred Heart Seminary and School of TheologySeminaries & Theology StudiesSee all Classifieds 
What to Read Next






Pro-life activists react to GOP platform change on abortion at Trump’s direction
Pro-life activists are pushing back against the Republican Party's new, Trump-directed platform, which appears to soften the party's stance on abortion.

Kate Scanlon - OSV News
July 10, 2024






Latin Patriarchate of Jerusalem condemns Israeli army attack on Catholic school
Following an Israeli attack on Holy Family, a Catholic school turned shelter for hundreds of civilians, the Latin Patriarchate of Jerusalem condemned the attack and called for a cease-fire agreement.

OSV News
July 10, 2024






Trump injured but 'fine' after attempted assassination at rally, shooter and one attendee are dead
Trump’s campaign said the presumptive GOP nominee was doing “fine” after the shooting, which he said pierced the upper part of his right ear.

Jill Colvin,Julie Carr Smyth,Eric Tucker and Michelle L. Price — Associated Press
July 13, 2024






Catholic bishops call for prayers for peace, healing in wake of Trump assassination attempt
""Together with my brother bishops, we condemn political violence, and we offer our prayers for President Trump, and those who were killed or injured,"" said Archbishop Broglio, the president of the U.S. Conference of Catholic Bishops.

Kate Scanlon - OSV News
July 14, 2024






‘Brain death’ and organ donation as culture war issues
In response to an article in our June issue, several physicians and ethicists say there are serious questions about the accuracy of determining brain death under the current criteria.

Our readers
June 27, 2024




 ",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LnNjaWVudGlmaWNhbWVyaWNhbi5jb20vYXJ0aWNsZS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pcy1sZWFybmluZy10by1rZWVwLWxlYXJuaW5nL9IBAA?oc=5,Artificial Intelligence Is Learning to Keep Learning - Scientific American,2018-11-01,Scientific American,https://www.scientificamerican.com,"Scientific American is the essential guide to the most awe-inspiring advances in science and technology, explaining how they change our understanding of the world and shape our lives.",N/A,A new machine-learning technique mimics the brain’s ability to adapt to new circumstances,A new machine-learning technique mimics the brain’s ability to adapt to new circumstances,https://schema.org,NewsMediaOrganization,https://www.scientificamerican.com/,"{'@id': 'https://www.scientificamerican.com/#publisher', 'name': 'Scientific American'}",2018-11-01T13:00:00+00:00,2024-02-20T12:15:03.161000+00:00,Artificial Intelligence Is Learning to Keep Learning,"['https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?w=1200', 'https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?crop=16%3A9%2Csmart&w=1920', 'https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?crop=4%3A3%2Csmart&w=1200', 'https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?crop=1%3A1%2Csmart&w=1000']",https://static.scientificamerican.com/sciam/cache/file/DC261EA8-7C6C-4908-8E987ABB08D63B67_source.png?w=1200,"{'@type': 'WebPage', '@id': 'https://www.scientificamerican.com/article/artificial-intelligence-is-learning-to-keep-learning/', 'breadcrumb': {'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Computing', 'item': 'https://www.scientificamerican.com/computing/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence Is Learning to Keep Learning', 'item': 'https://www.scientificamerican.com/article/artificial-intelligence-is-learning-to-keep-learning/'}]}}","[{'@type': 'Person', 'name': 'Matthew Hutson', 'url': 'https://www.scientificamerican.com/author/matthew-hutson/'}]",N/A,N/A,"November 1, 20182 min readArtificial Intelligence Is Learning to Keep LearningA new machine-learning technique mimics the brain’s ability to adapt to new circumstancesBy Matthew Hutson Thomas FuchsNovember 2018 IssueComputingWhat if you stopped learning after graduation? It sounds stultifying, but that is how most machine-learning systems are trained. They master a task once and then are deployed. But some computer scientists are now developing artificial intelligence that learns and adapts continuously, much like the human brain.Machine-learning algorithms often take the form of a neural network, a large set of simple computing elements, or neurons, that communicate via connections between them that vary in strength, or “weight.” Consider an algorithm designed to recognize images. If it mislabels a picture during training, the weights are adjusted. When mistakes are reduced below a certain threshold, the weights are frozen at set values.The new technique splits each weight into two values that combine to influence how much one neuron can activate another. The first value is trained and frozen as in traditional systems. But the second value continually adjusts in response to surrounding activity in the network. Critically, the algorithm also learns how adjustable to make these weights. So the neural network learns patterns of behavior, as well as how much to modify each part of that behavior in response to new circumstances. The researchers presented their technique in July at a conference in Stockholm, Sweden.Applying the technique, the team created a network that learned to reconstruct half-erased photographs after seeing the full images only a few times. In contrast, a traditional neural network would need to see many more images before it could reconstruct the original. The researchers also created a network that learned to identify handwritten alphabet letters—which are nonuniform, unlike typed ones—after seeing one example.In another task, neural networks controlled a character moving in a simple maze to find rewards. After one million trials, a network with the new semiadjustable weights could find each reward three times as often per trial as could a network with only fixed weights. The static parts of the semiadjustable weights apparently learned the structure of the maze, whereas the dynamic parts learned how to adapt to new reward locations. “This is really powerful,” says Nikhil Mishra, a computer scientist at the University of California, Berkeley, who was not involved in the research, “because the algorithms can adapt more quickly to new tasks and new situations, just like humans would.”Thomas Miconi, a computer scientist at the ride-sharing company Uber and the paper's lead author, says his team now plans to tackle more complicated tasks, such as robotic control and speech recognition. In related work, Miconi wants to simulate “neuromodulation,” an instant networkwide adjustment of adaptability that allows humans to sop up information when something novel or important happens.Rights & PermissionsMatthew Hutson is a freelance science writer based in New York City and author of The 7 Laws of Magical Thinking.More by Matthew HutsonThis article was originally published with the title “Lifelong Learning” in Scientific American Magazine Vol. 319 No. 5 (November 2018), p. 14doi:10.1038/scientificamerican1118-14bView This Issue",,,Artificial Intelligence Is Learning to Keep Learning,False,"{'@id': 'https://www.scientificamerican.com/#publisher', 'name': 'Scientific American'}",https://www.scientificamerican.com/#publisher,Scientific American,SciAm,"Scientific American, a Division of Springer Nature America, Inc.",1845-08-28,"{'@type': 'ImageObject', 'url': 'https://www.scientificamerican.com/static/sciam.svg'}",https://www.scientificamerican.com/masthead/,"['https://en.wikipedia.org/wiki/Scientific_American', 'https://www.wikidata.org/wiki/Q39379', 'https://www.jstor.org/publisher/sciamerican', 'https://x.com/sciam', 'https://www.youtube.com/user/SciAmerican', 'https://www.tiktok.com/@scientificamerican', 'https://www.threads.net/@scientific_american', 'https://www.facebook.com/ScientificAmerican/']","{'@type': 'PostalAddress', 'streetAddress': '1 New York Plaza', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10004', 'addressCountry': 'US'}",,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LmJyb29raW5ncy5lZHUvYXJ0aWNsZXMvdGhlLWltcGxpY2F0aW9ucy1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mb3ItbmF0aW9uYWwtc2VjdXJpdHktc3RyYXRlZ3kv0gEA?oc=5,The implications of artificial intelligence for national security strategy | Brookings - Brookings Institution,2018-11-01,Brookings Institution,https://www.brookings.edu,Mara Karlin examines the potential effects of AI on national security.,N/A,Mara Karlin examines the potential effects of AI on national security.,N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"

 Who has to leave the Federal Reserve next? 









                        Who has to leave the Federal Reserve next? 
",,"[{'@type': 'WebPage', '@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/', 'url': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/', 'name': 'The implications of artificial intelligence for national security strategy | Brookings', 'isPartOf': {'@id': 'https://www.brookings.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#primaryimage'}, 'image': {'@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#primaryimage'}, 'thumbnailUrl': 'https://www.brookings.edu/wp-content/uploads/2018/07/RTXT2UT.jpg?quality=75', 'datePublished': '2018-11-01T04:01:17+00:00', 'dateModified': '2022-03-09T04:03:16+00:00', 'description': 'Mara Karlin examines the potential effects of AI on national security.', 'breadcrumb': {'@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#primaryimage', 'url': 'https://www.brookings.edu/wp-content/uploads/2018/07/RTXT2UT.jpg?quality=75', 'contentUrl': 'https://www.brookings.edu/wp-content/uploads/2018/07/RTXT2UT.jpg?quality=75', 'width': 3936, 'height': 2656, 'caption': ""Personnel work at the Air Force Space Command Network Operations &amp; Security Center at Peterson Air Force Base in Colorado Springs, Colorado July 20, 2010. U.S. national security planners are proposing that the 21st century's critical infrastructure -- power grids, communications, water utilities, financial networks -- be similarly shielded from cyber marauders and other foes. The ramparts would be virtual, their perimeters policed by the Pentagon and backed by digital weapons capable of circling the globe in milliseconds to knock out targets. To match Special Report USA-CYBERWAR/ REUTERS/Rick Wilking (UNITED STATES - Tags: MILITARY SCI TECH POLITICS) - GM1E6A51SA301""}, {'@type': 'BreadcrumbList', '@id': 'https://www.brookings.edu/articles/the-implications-of-artificial-intelligence-for-national-security-strategy/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.brookings.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'The implications of artificial intelligence for national security strategy'}]}, {'@type': 'WebSite', '@id': 'https://www.brookings.edu/#website', 'url': 'https://www.brookings.edu/', 'name': 'Brookings', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.brookings.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LnNjcmlwcHNuZXdzLmNvbS9zY2llbmNlLWFuZC10ZWNoL3doby1vd25zLWFydC1jcmVhdGVkLWJ5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Who Owns Art Created by Artificial Intelligence? (VIDEO) - Scripps News,2018-11-02,Scripps News,https://www.scrippsnews.com,A painting created by AI sold for close to half a million dollars — and also raised questions about ownership.,N/A,A painting created by AI sold for close to half a million dollars — and also raised questions about ownership.,A painting created by AI sold for close to half a million dollars — and also raised questions about ownership.,http://schema.org,Article,,"{'@type': 'Organization', 'name': 'Scripps News (SNEWS)', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://ewscripps.brightspotcdn.com/ec/77/0ffb626a43ec98d505a2d353f0b1/main-logo.png'}}",2018-11-02T21:04:26-0400,2018-11-02T21:04:26-0400,"When Artificial Intelligence Creates Art, Who Owns It?","{'@context': 'http://schema.org', '@type': 'ImageObject'}",,"{'@type': 'WebPage', '@id': 'https://www.scrippsnews.com/science-and-tech/who-owns-art-created-by-artificial-intelligence'}","[{'@context': 'http://schema.org', '@type': 'Person', 'description': 'Cat is a Chicago-based national correspondent where she writes, produces, reports and video edits stories that impact our community.', 'email': 'Cat.Sandoval@scripps.com', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject'}, 'jobTitle': 'National Correspondent', 'name': 'Cat Sandoval', 'url': 'https://www.scrippsnews.com/cat-sandoval'}]",Science and Tech,N/A,"

Science and Tech


Actions



Facebook



Tweet


Email







When Artificial Intelligence Creates Art, Who Owns It?
A painting created by AI sold for close to half a million dollars — and also raised questions about ownership.









  Prev
Next  









  








  











By:
Cat Sandoval



Posted at 9:04 PM, Nov 02, 2018 




When artificial intelligence produces a work of art, who owns the final product? Not the AI machines — not yet. There are still a lot of human components that play a part. I mean, if a judge didn't give this monkey copyright to his own selfie, then a machine can't technically own anything either. Auction House Christie's sold the first AI-created painting for nearly half a million dollars. Paris art collective Obvious oversaw the creation.""It tries to replicate what any artist would do, like trying to create from what it knows. It forces you to try to understand your own creativity and how you'd be able to replicate it,"" Gauthier Vernier of Obvious said.  In the ""Edmond de Belamy"" painting, humans played a role. So it makes sense that humans own the final output. They, after all, wrote the computer codes and fed the machine 15,000 reference paintings that taught the AI machine how to paint. The GANs AI machine works by using two algorithms: one creates art and a discriminator algorithm that distinguishes between human-made and computer-made art. It's when the discriminator can no longer tell the painting was created by a computer that the art is complete.  ""If the discriminator is able to say, 'wait a minute that's created by a computer' the generator runs it again and the cycle finishes when the discriminator says, 'I give up, I can't tell,'"" said Richard Lloyd, Christie's international department head of prints and multiples. Related StoryRobot Farms Are Here. What Can Farmers Expect?In the case of Bellamy's painting, ownership can be complicated as said by a Christie's spokesperson: ""Is it the person that wrote the algorithm? Is it sort of the combination of the artwork that was uploaded or is it the people that tweaked the software? And I think this is why its so inspiring and interesting because we've never really have to ask these questions before.""Obvious acknowledged they relied on other innovations: the GANs AI tool (created by someone else) and a majority of the open source code from Robbie Barrat. On Twitter, Barrat wrote: ""Am I crazy for thinking that they really just used my network and are selling results?""AI created art and ownership doesn't have to be complicated like the Bellamy painting. When AI is used as a tool for creativity, users of the program retain ownership. Take Google's Deep Dream Generator, which transforms user images into dream visions. Two pieces of art sold for $8,000 each — and the users reaped the profits. 


Copyright 2024 Scripps Media, Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.




Most Recent













Republican delegates officially nominate Trump for president


      Scripps News Staff
    

3:23 PM, Jul 15, 2024 













Donald Trump picks Sen. J.D. Vance as VP running mate


      Scripps News Staff
    

3:09 PM, Jul 15, 2024 













Maker of TurboTax says it's laying off 1,800 workers, also hiring 1,800 others


      Justin Boggs
    

2:27 PM, Jul 15, 2024 








Science and Tech













World's first hydrogen-powered commercial ferry to run on San Francisco Bay


      AP via Scripps News 
    

9:35 AM, Jul 13, 2024 













Hundreds of thousands of people in Houston could be without power this weekend


      John Mone
    

9:22 PM, Jul 12, 2024 













Meta cautiously ended Donald Trump's suspension, now further loosens oversight


      Douglas Jones
    

6:52 PM, Jul 12, 2024 

















Watch Scripps News



",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmhlYWx0aGNhcmVpdG5ld3MuY29tL25ld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtMy1jaGFydHMtcmV2ZWFsLXdoYXQtaG9zcGl0YWxzLW5lZWQtbmVhci1mdXR1cmXSAQA?oc=5,Artificial Intelligence: 3 charts reveal what hospitals need in the near future - Healthcare IT News,2018-11-01,Healthcare IT News,https://www.healthcareitnews.com,"AI is already having a big impact, but strategic planning is not keeping pace and healthcare organizations need to be proactive about developing tools now.",N/A,"AI is already having a big impact, but strategic planning is not keeping pace and healthcare organizations need to be proactive about developing tools now.","AI is already having a big impact, but strategic planning is not keeping pace and healthcare organizations need to be proactive about developing tools now.",,,,,,,,,,,,N/A,N/A,"
HIMSS24 EUROPEAN HEALTH CONFERENCE & EXHIBITIONBetter patient outcomes and stronger workforces are a team project. At HIMSS24 Europe, we’ve built a programme to arm you and your peers with the insights you need to transform health systems back at home.May 29-31, 2024 | RomeLearn More ",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDE4LzExLzEvMTgwNTExOTYvYWktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY3VyaW9zaXR5LW9wZW5haS1tb250ZXp1bWFzLXJldmVuZ2Utbm9pc3ktdHYtcHJvYmxlbdIBAA?oc=5,How teaching AI to be curious helps machines learn for themselves - The Verge,2018-11-01,The Verge,https://www.theverge.com,"Artificial intelligence can learn for itself if we teach it to be curious. New research from the Elon Musk-founded lab OpenAI shows how this concept can help an AI agent play Montezuma’s Revenge, an Atari game that’s long proved to be a challenge for machine learning.",N/A,Curiouser and curiouser,N/A,http://schema.org/,NewsArticle,https://www.theverge.com/2018/11/1/18051196/ai-artificial-intelligence-curiosity-openai-montezumas-revenge-noisy-tv-problem,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",2018-11-01T15:11:22.000Z,2018-11-01T15:11:22.000Z,How teaching AI to be curious helps machines learn for themselves,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/TJsqCTrfa8Fyevejn3i8aGeLJjI=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292775/acastro_181017_1777_brain_ai_0003.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/hMHUPD6pVNljiVFqgYupuIUJPQk=/0x0:2040x1360/1400x1050/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292775/acastro_181017_1777_brain_ai_0003.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/28jXduznhdHlBZjMTbIUzB7E_UM=/0x0:2040x1360/1400x1400/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292775/acastro_181017_1777_brain_ai_0003.jpg', 'width': 1400, 'height': 1400}]",https://cdn.vox-cdn.com/thumbor/TJsqCTrfa8Fyevejn3i8aGeLJjI=/0x0:2040x1360/1400x788/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292775/acastro_181017_1777_brain_ai_0003.jpg,,"[{'@type': 'Person', 'name': 'James Vincent', 'url': 'https://www.theverge.com/authors/james-vincent'}]",N/A,N/A,"TechHow teaching AI to be curious helps machines learn for themselvesNew research from OpenAI uses curious AI to beat video gamesBy  James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge. Nov 1, 2018, 11:11 AM EDTShare this story1 Comment / 1 New Illustration by Alex Castro / The VergeWhen playing a video game, what motivates you to carry on? This question is perhaps too broad to yield a single answer, but if you had to sum up why you accept that next quest, jump into a new level, or cave and play just one more turn, the simplest explanation might be “curiosity” — just to see what happens next. And as it turns out, curiosity is a very effective motivator when teaching AI to play video games, too. In a game without rewards, teaching AI is difficultResearch published this week by artificial intelligence lab OpenAI explains how an AI agent with a sense of curiosity outperformed its predecessors playing the classic 1984 Atari game Montezuma’s Revenge. Becoming skilled at Montezuma’s Revenge is not a milestone equivalent to beating Go or Dota 2, but it’s still a notable advance. When the Google-owned DeepMind published its seminal 2015 paper explaining how it beat a number of Atari games using deep learning, Montezuma’s Revenge was the only game it scored 0 percent on. The reason for the game’s difficulty is a mismatch between the way it plays and the way AI agents learn, which also reveals a blind spot in machine learning’s view of the world.Usually, AI agents rely on a training method called reinforcement learning to master video games. In this paradigm, agents are dumped into virtual world, and rewarded for some outcomes (like increasing their score) and penalized for others (like losing a life). The agent starts playing the game random, but learns to improve its strategy through trial and error. Reinforcement learning is often thought of as a key method for building smarter robots.The problem with Montezuma’s Revenge is that it doesn’t provide regular rewards for the AI agent. It’s a puzzle-platformer where players have to explore an underground pyramid, dodging traps and enemies while collecting keys that unlock doors and special items. If you were training an AI agent to beat the game, you could reward it for staying alive and collecting keys, but how do you teach it to save certain keys for certain items, and use those items to overcome traps and complete the level? The answer: curiosity. In OpenAI’s research, their agent was rewarded not just for leaping over pits of spikes, but for exploring new parts in the pyramid. This led to better-than-human performance, with the bot earning a mean score of 10,000 over nine runs (compared to an average human score of 4,000). In one run, it even completed the first of the game’s nine levels. “There’s definitely still a lot of work to do,” OpenAI’s Harrison Edwards tells The Verge. “But what we have at the moment is a system that can explore lots of rooms, get lots of rewards, and occasionally get past the first level.” He adds that the game’s other levels are similar to the first, so playing through the whole thing “is just a matter of time.” Beating the “Noisy TV problem”OpenAI is far from the first lab to try this approach, and AI researchers have been leveraging the concept of “curiosity” as motivation for decades. They’ve also applied it to Montezuma’s Revenge before, though never so successfully without teaching AI to learn from human examples. However, while the general theory here is well-established, building specific solutions is still challenging. For example, prediction-based curiosity is only useful when learning to play certain types of games. It works for titles like Mario, for example, where there are big levels to explore, full of never-before-seen bosses and enemies. But for simpler games like Pong, AI agents prefer to play long rallies rather than actually beat their opponents. (Perhaps because winning the game is more predictable than following path of the ball.) AI can become addicted to random rewards, just like humansAnother issue is the “Noisy TV problem,” which is where AI agents that have been programmed to seek out new experiences get addicted to random patterns, such as a TV tuned to static noise. This is because these agents’ sense of what is “interesting” and “new” comes from their ability to predict the future. Before they take a certain action they predict what the game will look like afterwards. If they guess correctly, chances are they’ve seen this part of the game before. This mechanism is known as “prediction error.” But because static noise is unpredictable, the result is that any AI agent confronted with such a TV (or a similarly unpredictable stimulus) becomes mesmerized. OpenAI compares the problem to human gamblers who are addicted to slot machines, unable to tear themselves away because they don’t know what’s going to happen next. This GIF shows an AI agent exploring a maze and getting distracted by random flashing images.  GIF: OpenAIThis new research from OpenAI sidesteps this issue by varying how the AI predicts the future. The exact methodology (named Random Network Distillation) is complex, but Edwards and his colleague Yuri Burda compare it to hiding a secret for the AI to find in every screen of the game. That secret is random and meaningless (something like, “what is the color in the top left of the screen?” suggests Edwards), but it motivates the agent to explore without leaving it vulnerable to the Noisy TV trap. More importantly, this motivator doesn’t require a lot of calculation, which is incredibly important. These reinforcement learning methods rely on huge amounts of data to train AI agents (OpenAI’s bot, for example, had to play Montezuma’s Revenge for the real-time equivalent of three years) so every step of the journey needs to be as quick as possible. “It is actually much simpler than other methods of exploration.”Arthur Juliani, a software engineer at Unity and machine learning expert, says this is what makes OpenAI’s work impressive. “The method they use is really quite simple and therefore surprisingly effective,” Juliani tells The Verge. “It is actually much simpler than other methods of exploration which have been applied to the game in the past (and [which have] not led to nearly as impressive results).” Juliani says that given the similarities between different levels in Montezuma’s Revenge, OpenAI’s work is “essentially equivalent” to solving the game, but he adds that “the fact that they aren’t able to consistently beat the first level means that there is still some of an open challenge left.” He also wonders whether their approach will work in 3D games, where visual features are more subtle and a first-person view occludes much of the world. “In scenarios where exploration is required, but the differences between parts of the environment are more subtle, the method may not perform as well,” says Juliani.Robots in the real world, like Boston Dynamics’ SpotMini, could also benefit from artificial curiosity.  Photo by Matt Winkelmeyer / Getty Images for WIRED25The point of curiosityBut why do we need curious AI in the first place? What good does it do us, apart from providing humorous parallels to our human tendency to get ensnared by random patterns The big reason is that curiosity helps computers learn on their own. Most machine learning approaches deployed today can be split into two camps: in the first, machines learn by looking at piles of data, working out patterns they can apply to similar problems; and in the second, they’re dropped into an environment and rewarded for achieving certain outcomes using reinforcement learning. Both of these approaches are effective at specific tasks, but they also require a lot of human labor, either labeling training data or designing reward functions for virtual environments. By giving AI systems an intrinsic incentive to explore for explorations’ sake, some of this work is eliminated and humans spend less time holding their AI agent’s hands. (Metaphorically speaking.) OpenAI’s Edwards and Burda say that this sort of curiosity-driven learning system is much better for building computer programs that have to operate in the real world. After all, in reality, as in Montezuma’s Revenge, immediate rewards are often scarce, and we need to work, learn, and explore for long periods of time before we get anything in return. Curiosity helps us keep going, and maybe it can help computers, too. Comments1 Comment / 1 NewFeatured Videos From The VergeTesla’s big, epic, confusing future | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge’s David Pierce and Andy Hawkins discuss the latest at Tesla: new products, new initiatives, and a payday for Elon Musk. Vee Song joins the show to discuss updates to the Apple Watch, a new Samsung Galaxy Watch, and more wearable news. David and Liam James answer a question from the Vergecast Hotline about weather apps.Most PopularMost PopularGoogle is reportedly planning its biggest startup acquisition everAT&T reportedly gave $370,000 to a hacker to delete its stolen customer dataHere’s how much Valve pays its staff — and how few people it employsAmazon’s press-to-order Dash buttons are officially discontinuedComplaints about crashing 13th, 14th Gen Intel CPUs now have data to back them up Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",,,,,,,,,,,,,,,"When playing a video game, what motivates you to carry on? 

This question is perhaps too broad to yield a single answer, but if you had to sum up why you accept that next quest, jump into a new level, or cave and play just one more turn, the simplest explanation might be “curiosity” — just to see what happens next. And as it turns out, curiosity is a very effective motivator when teaching AI to play video games, too. 

""In a game without rewards, teaching AI is difficult""

Research published this week by artificial intelligence lab OpenAI explains how an AI agent with a sense of curiosity outperformed its predecessors playing the classic 1984 Atari game Montezuma’s Revenge. Becoming skilled at Montezuma’s Revenge is not a milestone equivalent to beating Go or Dota 2, but it’s still a notable advance. When the Google-owned DeepMind published its seminal 2015 paper explaining how it beat a number of Atari games using deep learning, Montezuma’s Revenge was the only game it scored 0 percent on. 

The reason for the game’s difficulty is a mismatch between the way it plays and the way AI agents learn, which also reveals a blind spot in machine learning’s view of the world.

Usually, AI agents rely on a training method called reinforcement learning to master video games. In this paradigm, agents are dumped into virtual world, and rewarded for some outcomes (like increasing their score) and penalized for others (like losing a life). The agent starts playing the game random, but learns to improve its strategy through trial and error. Reinforcement learning is often thought of as a key method for building smarter robots.

[Media: https://www.youtube.com/watch?v=40VZeFppDEM]

The problem with Montezuma’s Revenge is that it doesn’t provide regular rewards for the AI agent. It’s a puzzle-platformer where players have to explore an underground pyramid, dodging traps and enemies while collecting keys that unlock doors and special items. If you were training an AI agent to beat the game, you could reward it for staying alive and collecting keys, but how do you teach it to save certain keys for certain items, and use those items to overcome traps and complete the level? 

The answer: curiosity. 

In OpenAI’s research, their agent was rewarded not just for leaping over pits of spikes, but for exploring new parts in the pyramid. This led to better-than-human performance, with the bot earning a mean score of 10,000 over nine runs (compared to an average human score of 4,000). In one run, it even completed the first of the game’s nine levels. 

“There’s definitely still a lot of work to do,” OpenAI’s Harrison Edwards tells The Verge. “But what we have at the moment is a system that can explore lots of rooms, get lots of rewards, and occasionally get past the first level.” He adds that the game’s other levels are similar to the first, so playing through the whole thing “is just a matter of time.” 

Beating the “Noisy TV problem”

OpenAI is far from the first lab to try this approach, and AI researchers have been leveraging the concept of “curiosity” as motivation for decades. They’ve also applied it to Montezuma’s Revenge before, though never so successfully without teaching AI to learn from human examples. 

However, while the general theory here is well-established, building specific solutions is still challenging. For example, prediction-based curiosity is only useful when learning to play certain types of games. It works for titles like Mario, for example, where there are big levels to explore, full of never-before-seen bosses and enemies. But for simpler games like Pong, AI agents prefer to play long rallies rather than actually beat their opponents. (Perhaps because winning the game is more predictable than following path of the ball.) 

""AI can become addicted to random rewards, just like humans""

Another issue is the “Noisy TV problem,” which is where AI agents that have been programmed to seek out new experiences get addicted to random patterns, such as a TV tuned to static noise. This is because these agents’ sense of what is “interesting” and “new” comes from their ability to predict the future. Before they take a certain action they predict what the game will look like afterwards. If they guess correctly, chances are they’ve seen this part of the game before. This mechanism is known as “prediction error.” 

But because static noise is unpredictable, the result is that any AI agent confronted with such a TV (or a similarly unpredictable stimulus) becomes mesmerized. OpenAI compares the problem to human gamblers who are addicted to slot machines, unable to tear themselves away because they don’t know what’s going to happen next. 

[Image: This GIF shows an AI agent exploring a maze and getting distracted by random flashing images. https://cdn.vox-cdn.com/thumbor/dnJfvqLW010qC6-har7LD5f5b0Q=/0x0:632x476/632x476/filters:focal(316x238:317x239):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/13369609/noisy_tv_problem.gif]

This new research from OpenAI sidesteps this issue by varying how the AI predicts the future. The exact methodology (named Random Network Distillation) is complex, but Edwards and his colleague Yuri Burda compare it to hiding a secret for the AI to find in every screen of the game. That secret is random and meaningless (something like, “what is the color in the top left of the screen?” suggests Edwards), but it motivates the agent to explore without leaving it vulnerable to the Noisy TV trap. 

More importantly, this motivator doesn’t require a lot of calculation, which is incredibly important. These reinforcement learning methods rely on huge amounts of data to train AI agents (OpenAI’s bot, for example, had to play Montezuma’s Revenge for the real-time equivalent of three years) so every step of the journey needs to be as quick as possible. 

""“It is actually much simpler than other methods of exploration.”""

Arthur Juliani, a software engineer at Unity and machine learning expert, says this is what makes OpenAI’s work impressive. “The method they use is really quite simple and therefore surprisingly effective,” Juliani tells The Verge. “It is actually much simpler than other methods of exploration which have been applied to the game in the past (and [which have] not led to nearly as impressive results).” 

Juliani says that given the similarities between different levels in Montezuma’s Revenge, OpenAI’s work is “essentially equivalent” to solving the game, but he adds that “the fact that they aren’t able to consistently beat the first level means that there is still some of an open challenge left.” He also wonders whether their approach will work in 3D games, where visual features are more subtle and a first-person view occludes much of the world. 

“In scenarios where exploration is required, but the differences between parts of the environment are more subtle, the method may not perform as well,” says Juliani.

[Image: Robots in the real world, like Boston Dynamics’ SpotMini, could also benefit from artificial curiosity. https://cdn.vox-cdn.com/thumbor/RurxOpQu7qNOhZmq31Hlp4EQChQ=/0x0:5568x3712/5568x3712/filters:focal(2784x1856:2785x1857)/cdn.vox-cdn.com/uploads/chorus_asset/file/13369543/1052216080.jpg.jpg]

The point of curiosity

But why do we need curious AI in the first place? What good does it do us, apart from providing humorous parallels to our human tendency to get ensnared by random patterns 

The big reason is that curiosity helps computers learn on their own. 

Most machine learning approaches deployed today can be split into two camps: in the first, machines learn by looking at piles of data, working out patterns they can apply to similar problems; and in the second, they’re dropped into an environment and rewarded for achieving certain outcomes using reinforcement learning. 

Both of these approaches are effective at specific tasks, but they also require a lot of human labor, either labeling training data or designing reward functions for virtual environments. By giving AI systems an intrinsic incentive to explore for explorations’ sake, some of this work is eliminated and humans spend less time holding their AI agent’s hands. (Metaphorically speaking.) 

OpenAI’s Edwards and Burda say that this sort of curiosity-driven learning system is much better for building computer programs that have to operate in the real world. After all, in reality, as in Montezuma’s Revenge, immediate rewards are often scarce, and we need to work, learn, and explore for long periods of time before we get anything in return. Curiosity helps us keep going, and maybe it can help computers, too. 
",,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vd3d3Mi5kZWxvaXR0ZS5jb20vY2EvZW4vcGFnZXMvZGVsb2l0dGUtYW5hbHl0aWNzL2FydGljbGVzL29tbmlhLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLmh0bWzSAQA?oc=5,Omnia AI: Machine Learning & AI Solutions - Deloitte,2018-11-01,Deloitte,https://www2.deloitte.com,"Omnia AI is Deloitte’s AI practice. With deep expertise in machine learning, data integration, & analytics, we can help you with your AI transformation journey.",N/A,"Omnia AI is Deloitte’s AI practice. With deep expertise in machine learning, data integration, & analytics, we can help you with your AI transformation journey.","Omnia AI is Deloitte’s AI practice. With deep expertise in machine learning, data integration, & analytics, we can help you with your AI transformation journey.",,,,,,,,,,,,N/A,N/A,"







 
 




Deloitte CR Report Reset. Do not delete! This box/component contains code that is needed on this page. This message will not be visible when page is activated.






 
 














Omnia AI
Your business looks different when you see what AI can do.
We’ll show you how. Connect With Omnia AI



The AI opportunity Who we areOur missionThe AI journeyIn market 





















Seizing the AI opportunity
Artificial intelligence (AI) is no longer on the horizon. It’s here now, and it’s already having a profound impact on how we live, work, and do business.Companies, governments, and organizations must embrace the idea of going places they simply cannot get to using current technologies and processes. AI can and will transform organizational decision-making, drive efficiencies, build new capabilities and businesses, and power sustainable, value-driving activities.But like all revolutions in technology, capturing maximum value while simultaneously minimizing risk will require a strategic understanding of both what AI is, and how it aligns with your core business.




  Maximize revenue  Elevate experience  Reduce costs  Mitigate risk














Artificial intelligenceNoun
1. The capacity of computer systems to perform tasks that traditionally required human input or intelligence.2. A game-changer.Abbreviations AI, A.I.







 
 








Who we are
We provide end-to-end AI solutions that solve complex business challenges and help our clients capture optimal value from AI.
We see new opportunities in emerging technologies that others don’t. And because we’re Deloitte, we’re trusted advisors who work to understand your organization’s objectives from all angles.
With over 450 practitioners in Canada, and supported by Deloitte’s vast global network, we are leaders in capitalizing on the full breadth and depth of AI.

What we do 
Meet the team








Heard about AI Factory?
The AI Factory is where strategy meets intelligent design.
We coordinate and synthesize the powers of Omnia AI to
create unique and targeted products that optimize the
way a business works. Combining machine-learning
capabilities with deep business and industry acumen
allows us to solve complex problems and build tangible,
enterprising solutions.
Through the AI Factory, you have access to trailblazing
AI-driven products tailored to your needs that enable
you to excel in the marketplace.

Learn more








 
 





Our mission
We believe AI has the power to improve Canadian
organizations in transformative ways— and we’ll work
with you to make your business better. Omnia AI leads
all others in starting, enabling, accelerating, and
sustaining the AI journey.







It’s time to initiate your AI journey
AI can help maximize revenue, elevate experience, reduce cost, and mitigate risk. What’s holding you back?
The main difference between businesses that are not adopting AI and those that are, is that adopters don’t wait for the conditions to be right – they get started despite the challenges.








 
 












Understand AI better 









Start your AI journey








Scale your AI operations


















 
 







AI capabilities & services
Your AI journey starts and ends with your strategic business goals. We can help businesses identify their intended AI outcomes, then navigate the AI adoption journey from start to scale with confidence.





Strategy


Educating, inspiring and guiding clients on how to adopt cutting-edge business practices to transform their organization.







Data


Modernizing and transforming data management to enable at scale data centric solutions and AI Insights.







Insights


Developing tailored AI and Analytics solutions to meet specific client and organization needs.


 
Learn about Omnia AI’s services and capabilities











 
 




In market






Canada’s AI imperative
Start, scale, succeed
Technologies like artificial intelligence are fundamentally changing the way we live and work. Our latest report explores the AI demand gap in Canada, digs into the challenges businesses face in their AI adoption journey, and outlines actionable steps businesses can take to move their AI adoption from start to scale.Learn more






The AI opportunity in sourcing and procurement
Opportunities in the market today

            There is a wealth of raw information hidden across the whole source-to-settle lifecycle which has the power to help drive critical strategic, customer, and operational insights. But so far, the benefits of AI in sourcing and procurement have been largely untapped.
          
Learn more






The upskilling imperative
Building a future-ready workforce for the AI age
It’s time for companies and individuals to embrace the upskilling imperative. For companies, upskilling enables them to build a future-ready workforce; for individuals, it’s a way to keep their skills relevant and stay future-ready themselves.Learn more










 
 





Talk to us. You'll see the difference
Connect With Omnia AI












 
 










    Site-within-site Navigation. Do not delete! This box/component contains
    JavaScript that is needed on this page. This message will not be visible
    when page is activated.
  







 
 





Deloitte modal styles and script. Do not delete! This box/component contains code that is needed on this page for the modal to work. This message will not be visible when page is activated.















",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd3d3LmxhdGltZXMuY29tL2J1c2luZXNzL2xhLWZpLWZhY3RvcnktYXV0b21hdGlvbi1za2lsbHMtMjAxODExMDUtc3RvcnkuaHRtbNIBAA?oc=5,Blue-collar jobs will survive the rise of artificial intelligence. But the work will change - Los Angeles Times,2018-11-05,Los Angeles Times,https://www.latimes.com,"Call it the automation paradox: The infusion of artificial intelligence, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency."," robots,factory automation, job skills","It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Va. ","It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Va. ",http://schema.org,NewsArticle,https://www.latimes.com/business/la-fi-factory-automation-skills-20181105-story.html,"{'@type': 'Organization', 'name': 'Los Angeles Times', 'logo': {'@type': 'ImageObject', 'url': 'https://ca-times.brightspotcdn.com/dims4/default/954b438/2147483647/strip/false/crop/382x60+0+0/resize/382x60!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2Fde%2F5f%2F46c2d05b430cbc6e775301df1062%2Flogo-full-black.png', 'width': 382, 'height': 60}}",2018-11-05T12:00:00.000Z,2018-11-05T12:00:10.000Z,Blue-collar jobs will survive the rise of artificial intelligence. But the work will change,"[{'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 836, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/7f3d790/2147483647/strip/false/crop/2048x1152+0+0/resize/1486x836!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F13%2Fc5%2F9ede9eb020550067ffe4a08444c8%2Fla-1541106303-7ud74g3j6o-snap-image', 'width': 1486}, {'@context': 'http://schema.org', '@type': 'ImageObject', 'height': 675, 'url': 'https://ca-times.brightspotcdn.com/dims4/default/7a709c4/2147483647/strip/false/crop/2048x1152+0+0/resize/1200x675!/quality/75/?url=https%3A%2F%2Fcalifornia-times-brightspot.s3.amazonaws.com%2F13%2Fc5%2F9ede9eb020550067ffe4a08444c8%2Fla-1541106303-7ud74g3j6o-snap-image', 'width': 1200}]",,"{'@type': 'WebPage', '@id': 'https://www.latimes.com/business/la-fi-factory-automation-skills-20181105-story.html'}","[{'@context': 'http://schema.org', '@type': 'Person', 'name': 'Craig Torres'}]",Business,N/A,"       Assembly line robots inside a Chrysler plant in Sterling Heights, Mich. As automation increases, remaining workers will need to demonstrate complex reasoning, experts say. (Paul Sancya / AP)      By Craig Torres  Nov. 5, 2018 4 AM PT      Share       Share via Close extra sharing options    Email     Facebook    X    LinkedIn    Threads    Reddit    WhatsApp    Copy Link URLCopied!   Print        Bloomberg   It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Va. Twelve candidates are divided into three teams and given the task of assembling a box. Twelve Rolls Royce employees stand around them, one assigned to each candidate, taking notes.The box is a prop, and the test has nothing to do with programming or repairing the robots that make engine parts here. It’s about collaborative problem solving.“We are looking at what they say, we are looking at what they do, we are looking at the body language of how they are interacting,” says Lorin Sodell, the plant manager.AdChoicesADVERTISING Advertisement   For all the technical marvels inside this fully automated, 8-year-old facility, Sodell talks a lot about soft skills such as trouble shooting and intuition.“There are virtually no manual operations here anymore,” he says. People “aren’t as tied to the equipment as they were in the past, and they are really freed up to work on more higher-order activities.”Call it the automation paradox: The infusion of artificial intelligence, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency.   The new blue-collar labor force will need four “distinctively more human” core competencies for advanced production: complex reasoning, social and emotional intelligence, creativity and certain forms of sensory perception, according to Jim Wilson, a managing director at Accenture Plc.“Work in a certain sense, and globally in manufacturing, is becoming more human and less robotic,” says Wilson, who helped lead an Accenture study on emerging technologies and employment needs covering 14,000 companies in 14 large, industrialized nations.Few narratives in economics and social policy are as alarmist as the penetration of automation and artificial intelligence into the workplace, especially in manufacturing. Advertisement    Economists talk about the hollowing-out of middle-income employment. American political discourse is full of nostalgia for high-paying blue-collar jobs. The Trump administration is imposing tariffs and rewriting trade agreements to entice companies to keep plants in the U.S. or even bring them back.The stark reality is that automation will continue to erode repetitive work no matter where people do it. But there is also a myth in this narrative that suggests America has permanently lost its edge. The vacant mills in the southeast and Midwest, and the struggling cities around them, are evidence of how technology and low-cost labor can rapidly kill off less-agile industries. This isn’t necessarily a prologue to what’s next, however.Cutting-edge manufacturing not only involves the extreme precision of a Rolls Royce turbofan disc. It’s also moving toward mass customization and what Erica Fuchs calls “parts consolidation” — making more-complex blocks of components so a car, for example, has far fewer parts. This new frontier often involves experimentation, with engineers learning through frequent contact with production staff, requiring workers to make new kinds of contributions.“This is a chance for the U.S. to lead. We have the knowledge and skills,” says Fuchs, an engineering and public-policy professor at Carnegie Mellon University. “When you move manufacturing overseas, it can become unprofitable to produce with the most advanced technologies.”The new alliance between labor and smart machines is apparent on Rolls Royce’s shop floor. The 33 machinists aren’t repeating one single operation but are responsible for the flow of fan-disc and turbine-blade production. They are in charge of their day, monitoring operations, consulting with engineers and maintaining equipment.This demonstrates what automation really does: It changes the way people use their time. A visit to the plant also reveals why factory workers in automated operations need more than some knowledge of machine-tool maintenance and programming: They are part of a process run by a team.Sodell opens what looks like a giant suitcase. Inside is a titanium disc about the size of a truck tire. Unfinished, it costs $35,000, and it’s worth more than twice that much once it’s machined as closely as possible to the engineers’ perfect mathematical description of the part. The end product is so finely cut and grooved it resembles a piece of industrial jewelry.“I am not at all bothered by the fact that there isn’t a person here looking after this,” he says, standing next to a cutting station about half the size of a subway car. Inside, a robot arm is measuring by itself, picking out its own tools and recording data along the way.Variations in the material, temperatures and vibration can cause the robot to deviate from the engineers’ model. So human instinct and know-how are required to devise new techniques that reduce the variance. Just by looking at the way titanium is flecking off a disc in the cutting cell, for example, a machinist can tell something is off, Sodell says. With expensive raw materials, such technical acumen is crucial.It’s also important because current artificial-intelligence systems don’t have full comprehension of non-standard events, the way a GPS in a car can’t comprehend a sudden detour. And they don’t always have the ability to come up with innovations that improve the process.Sodell says workers are constantly looking for ways to refine automation. He tells the story of a new hire who figured out a way to get one of the machines to clean itself. He developed a tool and wrote a program that is now part of the production system.Technicians start off making $48,000 a year and can earn as much as $70,000, depending on achievement and skill level. Most need at least two years of experience or precision-machining certification from a community college.Rolls Royce is collaborating with these schools and relying on instructors like Tim Robertson, among the first 50 people it hired in Virginia. He now teaches advanced manufacturing at Danville Community College and says it’s hard to explain what work is like at an automated facility. Jobs require a lot more mental engagement, he explains, because machinists are looking at data as much as materials and equipment.The Danville program includes a class on talking through conflict, along with live production where students are required to meet a schedule for different components in a simulated plant. The group stops twice a day and discusses how to optimize work flow.“You can ship a machine tool to any country in the world,” Robertson says. “But the key is going to be the high-level technician that can interact with the data at high-level activity and be flexible.”   More to Read               Opinion: What’s behind the AI boom? Exploited humans   July 12, 2024                California lawmakers are trying to regulate AI before it’s too late. Here’s how    June 19, 2024                California advances measures targeting AI discrimination and deepfakes   May 29, 2024         ",Business,,,False,,,Blue-collar jobs will survive the rise of artificial intelligence. But the work will change - Los Angeles Times,,,,,,,,"It’s hiring day at Rolls Royce’s jet-engine plant near Petersburg, Va. Twelve candidates are divided into three teams and given the task of assembling a box. Twelve Rolls Royce employees stand around them, one assigned to each candidate, taking notes. The box is a prop, and the test has nothing to do with programming or repairing the robots that make engine parts here. It’s about collaborative problem solving. “We are looking at what they say, we are looking at what they do, we are looking at the body language of how they are interacting,” says Lorin Sodell, the plant manager. For all the technical marvels inside this fully automated, 8-year-old facility, Sodell talks a lot about soft skills such as trouble shooting and intuition. “There are virtually no manual operations here anymore,” he says. People “aren’t as tied to the equipment as they were in the past, and they are really freed up to work on more higher-order activities.” Call it the automation paradox: The infusion of artificial intelligence, robotics and big data into the workplace is elevating the demand for people’s ingenuity, to reinvent a process or rapidly solve problems in an emergency. The new blue-collar labor force will need four “distinctively more human” core competencies for advanced production: complex reasoning, social and emotional intelligence, creativity and certain forms of sensory perception, according to Jim Wilson, a managing director at Accenture Plc. “Work in a certain sense, and globally in manufacturing, is becoming more human and less robotic,” says Wilson, who helped lead an Accenture study on emerging technologies and employment needs covering 14,000 companies in 14 large, industrialized nations. Few narratives in economics and social policy are as alarmist as the penetration of automation and artificial intelligence into the workplace, especially in manufacturing. Economists talk about the hollowing-out of middle-income employment. American political discourse is full of nostalgia for high-paying blue-collar jobs. The Trump administration is imposing tariffs and rewriting trade agreements to entice companies to keep plants in the U.S. or even bring them back. The stark reality is that automation will continue to erode repetitive work no matter where people do it. But there is also a myth in this narrative that suggests America has permanently lost its edge. The vacant mills in the southeast and Midwest, and the struggling cities around them, are evidence of how technology and low-cost labor can rapidly kill off less-agile industries. This isn’t necessarily a prologue to what’s next, however. Cutting-edge manufacturing not only involves the extreme precision of a Rolls Royce turbofan disc. It’s also moving toward mass customization and what Erica Fuchs calls “parts consolidation” — making more-complex blocks of components so a car, for example, has far fewer parts. This new frontier often involves experimentation, with engineers learning through frequent contact with production staff, requiring workers to make new kinds of contributions. “This is a chance for the U.S. to lead. We have the knowledge and skills,” says Fuchs, an engineering and public-policy professor at Carnegie Mellon University. “When you move manufacturing overseas, it can become unprofitable to produce with the most advanced technologies.” The new alliance between labor and smart machines is apparent on Rolls Royce’s shop floor. The 33 machinists aren’t repeating one single operation but are responsible for the flow of fan-disc and turbine-blade production. They are in charge of their day, monitoring operations, consulting with engineers and maintaining equipment. This demonstrates what automation really does: It changes the way people use their time. A visit to the plant also reveals why factory workers in automated operations need more than some knowledge of machine-tool maintenance and programming: They are part of a process run by a team. Sodell opens what looks like a giant suitcase. Inside is a titanium disc about the size of a truck tire. Unfinished, it costs $35,000, and it’s worth more than twice that much once it’s machined as closely as possible to the engineers’ perfect mathematical description of the part. The end product is so finely cut and grooved it resembles a piece of industrial jewelry. “I am not at all bothered by the fact that there isn’t a person here looking after this,” he says, standing next to a cutting station about half the size of a subway car. Inside, a robot arm is measuring by itself, picking out its own tools and recording data along the way. Variations in the material, temperatures and vibration can cause the robot to deviate from the engineers’ model. So human instinct and know-how are required to devise new techniques that reduce the variance. Just by looking at the way titanium is flecking off a disc in the cutting cell, for example, a machinist can tell something is off, Sodell says. With expensive raw materials, such technical acumen is crucial. It’s also important because current artificial-intelligence systems don’t have full comprehension of non-standard events, the way a GPS in a car can’t comprehend a sudden detour. And they don’t always have the ability to come up with innovations that improve the process. Sodell says workers are constantly looking for ways to refine automation. He tells the story of a new hire who figured out a way to get one of the machines to clean itself. He developed a tool and wrote a program that is now part of the production system. Technicians start off making $48,000 a year and can earn as much as $70,000, depending on achievement and skill level. Most need at least two years of experience or precision-machining certification from a community college. Rolls Royce is collaborating with these schools and relying on instructors like Tim Robertson, among the first 50 people it hired in Virginia. He now teaches advanced manufacturing at Danville Community College and says it’s hard to explain what work is like at an automated facility. Jobs require a lot more mental engagement, he explains, because machinists are looking at data as much as materials and equipment. The Danville program includes a class on talking through conflict, along with live production where students are required to meet a schedule for different components in a simulated plant. The group stops twice a day and discusses how to optimize work flow. “You can ship a machine tool to any country in the world,” Robertson says. “But the key is going to be the high-level technician that can interact with the data at high-level activity and be flexible.”","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.paywall'}","{'@type': ['CreativeWork', 'Product'], 'name': 'Los Angeles Times', 'productID': 'lanews:all-access'}",,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vZ2Vla3R5cmFudC5jb20vbmV3cy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pcy1iZWluZy11c2VkLXRvLXByZWRpY3Qtd2hhdC1tb3ZpZXMtYXVkaWVuY2VzLXdpbGwtd2F0Y2jSAQA?oc=5,Artificial Intelligence is Being Used to Predict What Movies Audiences Will Watch — GeekTyrant - GeekTyrant,2018-11-05,GeekTyrant,https://geektyrant.com,<p>Geek Movie and Entertainment News</p>,N/A,20th Century Fox has been working on using Artificial Intelligence to predict what movies audiences will go see. Their goal is to lessen the risk that movie studios take when making films.,20th Century Fox has been working on using Artificial Intelligence to predict what movies audiences will go see. Their goal is to lessen the risk that movie studios take when making films.,http://schema.org,Article,https://geektyrant.com/news/artificial-intelligence-is-being-used-to-predict-what-movies-audiences-will-watch,"{'name': 'GeekTyrant', 'logo': {'@type': 'ImageObject'}, '@context': 'http://schema.org', '@type': 'Organization'}",2018-11-05T12:30:00-0800,2019-05-15T22:46:01-0700,Artificial Intelligence is Being Used to Predict What Movies Audiences Will Watch,http://static1.squarespace.com/static/51b3dc8ee4b051b96ceb10de/51ce6099e4b0d911b4489b79/5bddf63e0ebbe857b71fe6c3/1557985561983/ai.jpg?format=1500w,,,Tommy Williams,N/A,N/A,"


      
        Artificial Intelligence is Being Used to Predict What Movies Audiences Will Watch
      
    

Movie
20th Century FoxArtificial IntelligenceA.I.MerlinLogan
6 years agoby Tommy Williams














Artificial Intelligence is continually being used in more and more areas. Now, 20th Century Fox has been using A.I. in attempts to figure out what movies people will go and watch. They even gave the A.I. program a name: Merlin. Merlin is still a bit of a work in progress, but it is proving to be decent at its job.






Merlin’s job is to watch movie trailers and tag different aspects. He’ll then watch other trailers to determine audience interest. The goal is to help movie studios be able to take less of a risk when they make new movies. The testing of Merlin was performed using the trailer for Logan and here are the most popular tags:













The study then analyzed what movies Merlin predicted versus what movies Logan audiences actually went to watch as can be seen in the chart below:



















You can see that Merlin correctly predicted 11 out of 20 movies. That means there’s a lot of work to be done, but it’s only a matter of time before all movie studios are using machine learning in order to determine which films to greenlight.






Source: /Film﻿








The Black and White Version of GODZILLA MINUS ONE Is Coming to Netflix in August
Read Full Post




DEADPOOL & WOLVERINE TV Spot Offers Up Some Funny New Footage
Read Full Post




Silly Clip From TRANSFOMRERS ONE Shows Transformer Characters Trying to Transform for the First Time
Read Full Post




Awesome Teaser Trailer For Brad Pitt and Joseph Kosinski's Racing Film F1
Read Full Post




BATMAN: CAPED CRUSADER Clip Features Batman Racing Through the Streets of Gotham in His Batmobile
Read Full Post




STRANGER THINGS 5 Official Behind-The-Scenes Video Teases First Look Footage
Read Full Post




Tommy Williams
When I'm not writing for GeekTyrant, I enjoy playing games of all kind, rocking with my guitar, and running my YouTube channel Poor Man Pedals for guitarists. For official inquiries, please email me: tommy.williams@geektyrant.com || @tyguitaxe


GeekTyrant Homepage





Watch LEGO's Fun 90-Second Remake of JAWS 
Read Full Post




Awesome Teaser Trailer for Netflix's TERMINATOR ZERO Anime Series
Read Full Post




Cool CREEPSHOW Poster Art Created By Artist Marc Schoenbach
Read Full Post




Retro Trailer For The 1985 AI Film D.A.R.Y.L.
Read Full Post




INSIDIOUS: THE FURTHER is a New Haunted House Experience Coming To Halloween Horror Nights
Read Full Post




David Lynch Directed and Animated Music Video Which You Can Watch Now
Read Full Post




Behind the Scenes Featurette for Prison Drama SING SING Starring Colman Domingo
Read Full Post




DEADPOOL & WOLVERINE TV Spot Offers Up Some Funny New Footage
Read Full Post




Great Trailer for STARZ Limited Series THREE WOMEN Starring Shailene Woodley, Betty Gilpin, DeWanda Wise and Gabrielle Creevy
Read Full Post




Hot Toys Reveals New X-MEN Wolverine (Brown Suit) Limited Edition Action Figure 
Read Full Post




Trailer for Gritty Detective Thriller CRESCENT CITY Starring Terrence Howard, Esai Morales, Alec Baldwin and Nicky Whelan
Read Full Post




Trailer For The Horror Film THE WHEEL OF HEAVEN Centers on a Women Who Disscovers a Mystical Book in a Thrift Store
Read Full Post







Categories
Art
Comic Book
Games
Gear
Humor
Infographic
Movie
Music
Podcast
Tech
Toy
TV


Original
Rant
Review


Media
Interview
Photos
Poster
Trailer
Videos


Events
Comic-Con
 D23 Expo
E3
NYCC
Star Wars Celebration
Sundance
WonderCon


Alerts
Rumor
Spoiler
Updated


",,,,,,,Artificial Intelligence is Being Used to Predict What Movies Audiences Will Watch — GeekTyrant,,,,,,[],"Bubank, CA
USA",,,,freereyes@geektyrant.com,(323) 250-6307
https://news.google.com/rss/articles/CBMijQFodHRwczovL3d3dy5idXNpbmVzc3dpcmUuY29tL25ld3MvaG9tZS8yMDE4MTEwNTAwNTI1MC9lbi9Lcm9ub3MtSW50cm9kdWNlcy1BSU1FRS10aGUtTW9zdC1BZHZhbmNlZC1BSS1FbmdpbmUtQnVpbHQtZm9yLU1hbmFnZXJzLWFuZC1FbXBsb3llZXPSAQA?oc=5,"Kronos Introduces AIMEE, the Most Advanced AI Engine Built for Managers and Employees - Business Wire",2018-11-05,Business Wire,https://www.businesswire.com,"Kronos introduces AIMEE, delivering the first artificial intelligence engine for managers and employees.",N/A,"Kronos introduces AIMEE, delivering the first artificial intelligence engine for managers and employees.","Kronos introduces AIMEE, delivering the first artificial intelligence engine for managers and employees.",,,,,,,,,,,,N/A,N/A,"




Kronos Introduces AIMEE, the Most Advanced AI Engine Built for 
      Managers and Employees






November 05, 2018 11:00 AM Eastern Standard Time



LAS VEGAS--(BUSINESS WIRE)--Kronos 
      Incorporated continues to revolutionize the future of work with new 
      enhancements to its game-changing Workforce 
      Dimensions suite, including today’s introduction of AIMEE, 
      the most advanced artificial intelligence (AI) engine built specifically 
      to support managers and employees.
    
“Kronos understands the hourly workforce better than almost anyone, and 
      now with the introduction of AIMEE, Kronos is rethinking how 
      organizations use AI to attract, engage, and retain top talent. Kronos 
      fulfilled their promise to deliver HCM for the modern workforce, further 
      transforming frontline employee engagement.”Post this

News Facts



        AIMEE analyzes massive amounts of organizational data in real time to 
        provide in-the-moment, predictive insights to help employees and 
        managers work smarter.
      

        For HR teams, AIMEE predicts flight risk, identifies employee 
        potential, watches for employee fatigue, and supports succession 
        planning to surface trends and observations that enable more 
        productive conversations to improve engagement, retention, and 
        performance.
      

        AIMEE empowers employees to achieve better work-life balance by 
        building personalized schedules that match individual preferences, 
        processing time off requests in real time, and simplifying shift swaps 
        by suggesting colleagues most likely to accept a swap.
      

        Managers spend less time on processes and more time solving problems 
        with AIMEE’s real-time analytics, which show the impact that absences, 
        open shifts, and unplanned schedule changes have on key performance 
        indicators, leading to more informed decisions that affect employee 
        and organizational success.
      

        Advanced business volume forecasting leverages AI and machine learning 
        from AIMEE to improve scheduling accuracy by as much as 20 percent, 
        ensuring the right staff with the right skills are available to meet 
        demand.
      


Supporting Quotes



Bill Bartow, vice president, global product management, Kronos



      “At Kronos, we’re focused on delivering the most engaging technology 
      experience for everyone in the workforce, whether they’re a manager or 
      employee, paid a salary or by the hour, all around the world. The 
      introduction of AIMEE delivers the benefits of artificial intelligence 
      across the entire organization.”
    


Cliff Stevenson, principal analyst, talent management and workforce 
        management, Brandon Hall Group



      “Kronos understands the hourly workforce better than almost anyone, and 
      now with the introduction of AIMEE, Kronos is rethinking how 
      organizations use AI to attract, engage, and retain top talent. Kronos 
      fulfilled their promise to deliver HCM for the modern workforce, further 
      transforming frontline employee engagement.”
    

Supporting Resources



        This announcement was made from KronosWorks, 
        the world’s largest workforce information exchange. KronosWorks is 
        taking place this week in Las Vegas. See live updates and join the 
        conversation by using #KronosWorks across all social media channels.
      

        As part of the Kronos “Get Social. Give Back.” campaign, every 
        attendee who posts a picture on Twitter or Instagram with #KronosWorks 
        will help Kronos build a large mosaic on-site in real time. Once 
        complete, Kronos will donate $20,000 to The American Red Cross to aid 
        disaster relief efforts.
      

        Wondering how to engage your workforce? Putting people first isn’t 
        just good for employees – it’s good for business. Kronos CEO Aron Ain 
        shares how we did it in his book, WorkInspired: 
        How to Build an Organization Where Everyone Loves to Work.


Subscribe 
        to follow The 
        Workforce Institute at Kronos for insight, research, blogs, and 
        podcasts on how organizations can manage today’s modern workforce to 
        drive engagement and performance.
      

        Connect with Kronos via Facebook, 
        Twitter, 
        LinkedIn, 
        Instagram, 
        and YouTube.
      


About Kronos Incorporated


      Kronos is a leading provider of workforce management and human capital 
      management cloud solutions. Kronos industry-centric workforce 
      applications are purpose-built for businesses, healthcare providers, 
      educational institutions, and government agencies of all sizes. Tens of 
      thousands of organizations — including half of the Fortune 1000® 
      — and more than 40 million people in over 100 countries use Kronos every 
      day. Visit www.kronos.com. 
      Kronos: Workforce Innovation That Works.
    

      © 2018 Kronos Incorporated. All rights reserved. Kronos and the Kronos 
      logo are registered trademarks and Workforce Innovation That Works is a 
      trademark of Kronos Incorporated or a related company. See a complete 
      list of Kronos 
      trademarks. All other trademarks, if any, are property of their 
      respective owners.
    




Contacts

      Dan GouthroKronos Incorporated978.947.7310daniel.gouthro@kronos.com




",,,,,,,,,,,,,,,,,,,

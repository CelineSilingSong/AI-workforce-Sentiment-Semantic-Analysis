URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,article:section,article:summary,article text,@context,@type,@id,headline,mainEntityOfPage,url,thumbnailUrl,image,dateCreated,datePublished,dateModified,articleSection,author,abstract,publisher,copyrightHolder,mainEntity,inLanguage,alternativeHeadline,audio,hasPart,comment,commentCount,sourceOrganization,copyrightYear,isAccessibleForFree,isPartOf,name,logo,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,contentUrl,uploadDate,duration,@graph,itemListElement,wordCount,creator,address,speakable,citation,breadcrumb,identifier,articleBody
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LmltcGVyaWFsLmFjLnVrL25ld3MvMjAwNjczL2FwcGxpY2F0aW9uLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFpLXN1cmdlcnkv0gEA?oc=5,Application of Artificial Intelligence (AI) in Surgery | Imperial News - Imperial College London,2020-07-27,Imperial College London,https://www.imperial.ac.uk,AI IN SURGERY - Our Hamlyn researchers review the recent influential applications of AI in surgery as well as note the major challenges in the future development.,N/A,Our Hamlyn researchers review the recent influential applications of AI in surgery as well as note the major challenges in the future development.,AI IN SURGERY - Our Hamlyn researchers review the recent influential applications of AI in surgery as well as note the major challenges in the future development.,engineering,N/A,"










view large

Our Hamlyn researchers review the recent influential applications of AI in surgery as well as note the major challenges in the future development.
Owing to recent advances in medicine, Artificial Intelligence (AI) has played an important role in supporting clinical decision-making and is now increasingly used for risk stratification, genomics, imaging and diagnosis, precision medicine, and drug discovery.
AI was introduced into surgery more recently, with a strong root in imaging and navigation and early techniques focusing on feature detection and computer-assisted intervention for both pre-operative planning and intra-operative guidance.
That is to say, AI is gradually changing the practice of surgery with technological advancements in imaging, navigation, and robotic intervention.

An overview of popular AI techniques, as well as the key requirements, challenges, and sub-areas of AI used in preoperative planning, intraoperative guidance, and surgical robotics.


Our researchers at the Hamlyn Centre review the recent successful and influential applications of AI in surgery from pre-operative planning and intra-operative guidance to its integration into surgical robots.
This review paper not only presents an overview of the requirements, challenges and sub-areas of each surgical application segment that applied AI techniques, but also brings attention to the main challenges and provides the potential solutions for the future development of AI in surgery.
AI for preoperative planning
Pre-operative planning where surgeons plan the surgical procedure on the basis of existing medical records and imaging is essential for the success of a surgery.
Our researchers highlighted four routine tasks based on medical imaging that involve AI techniques: (1) anatomical classification, (2) detection, (3) segmentation, and (4) registration.
FIND OUT MORE >>
AI for intraoperative guidance
Surgical trauma is reduced through minimally invasive surgery (MIS), which is now progressively combined with robotic assistance. Computer-aided intra-operative guidance has always been a cornerstone of MIS.
In light of this, learning strategies have been extensively integrated into the development of intra-operative guidance to provide enhanced visualisation and localisation in surgery.

AI techniques for computer-aided intraoperative guidance in MIS.


There are four main areas of computer-aided intra-operative guidance in MIS that involve AI techniques: (1) shape instantiation, (2) endoscopic navigation, (3) tissue tracking, and (4) Augmented Reality (AR).
FIND OUT MORE >>
AI for surgical robotics
By virtue of the development of AI techniques, surgical robots can achieve superhuman performance during MIS. 
The objective of AI is to boost the capability of surgical robotic systems in perceiving complex in vivo environments, conducting decision-making, and performing the desired tasks with increased precision, safety, and efficiency.

AI techniques for surgical robotics.

The common AI techniques used for robotic and autonomous systems (RAS) can be summarised in four aspects: (1) perception, (2) localisation and mapping, (3) system modelling and control, and (4) human–robot interaction.
FIND OUT MORE >>
The future development of AI in surgery
The advancement in AI has been transforming modern surgery toward more precise and autonomous intervention for treating both acute and chronic symptoms. By leveraging such techniques, notable progress has been achieved in preoperative planning, intra-operative guidance, and surgical robotics.
In view of this, our researchers summarise the current state, emerging trends, and major challenges in the future development of AI in surgery, as well as provide the potential solutions for overcoming these challenging issues.

An outlook of the future of surgery in preoperative planning, intra-operative guidance, surgical robotics, and potential ethical and legal issues.

FIND OUT MORE >>

Xiao-Yun Zhou, Yao Guo, Mali Shen and Guang-Zhong Yang, ""Application of artificial intelligence in surgery"", Frontiers of Medicine, July 2020.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vd3d3LmNtc3dpcmUuY29tL2xlYWRlcnNoaXAvYWktYXQtd29yay1zdGlsbC1hLXdvcmstaW4tcHJvZ3Jlc3Mv0gEA?oc=5,AI's Use in the Enterprise Workplace Continues to Evolve - CMSWire,2020-07-30,CMSWire,https://www.cmswire.com,Artificial intelligence is becoming a major driver of business value but its use in the digital workplace is still evolving.,"['productivity', 'digital transformation', 'digital workplace', 'artificial intelligence', 'machine learning', 'category: leadership', 'type: feature', 'utype: Staff']",Artificial intelligence is becoming a major driver of business value but its use in the digital workplace is still evolving.,Artificial intelligence is becoming a major driver of business value but its use in the digital workplace is still evolving.,N/A,N/A,"Customer ExperienceExplore the dynamic world of Customer Experience (CX) at CMSWire. Stay updated with the latest news, expert advice and in-depth analysis on customer-first marketing, commerce and digital experience design.EditorialFruitful Futures: How to Grow Customer Advocacy in a Competitive MarketRead nowEditorialSeamless Stitches: AI Integration Into Journey Orchestration for Tailored CXRead nowFeatureWhat Is a CRM Platform? And How They Add Value to Your Business Read nowMartech-Adtech Mega Deal Fails: Google-HubSpot Acquisition CollapsesAI Bubble About to Burst? What CX Leaders Need to Know Why Did Customer Data Platform BlueConic Acquire Jebbit?AI in CX: The Shortcut to Customer SatisfactionIs a 10-Second Customer Journey Possible?How AI in Ecommerce Is Getting TalkativeExplore the Customer Experience Channel",http://schema.org,NewsArticle,https://www.reworked.co/leadership/ai-at-work-still-a-work-in-progress/,AI at Work Still a Work in Progress,https://www.reworked.co/leadership/ai-at-work-still-a-work-in-progress/,https://www.reworked.co/leadership/ai-at-work-still-a-work-in-progress/,https://www.cmswire.com/-/media/400899f5fedb4668a55cf83f1c2d0f46.ashx,https://www.cmswire.com/-/media/400899f5fedb4668a55cf83f1c2d0f46.ashx,2020-07-30T16:29:42Z,2020-07-30T16:29:42Z,2020-07-30T16:29:42Z,Leadership,"[{'@type': 'Person', 'name': 'Mike Prokopeak', 'url': 'https://www.cmswire.com/author/mike-prokopeak/'}]",Artificial intelligence is becoming a major driver of business value but its use in the digital workplace is still evolving.,"{'type': 'Organization', 'name': 'CMSWire.com', 'logo': {'type': 'ImageObject', 'url': 'https://www.cmswire.com/-/media/346f68a07ac545a09971abfdb558e17a.png'}}","Simpler Media Group, Inc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMmh0dHBzOi8vd3d3Lm5hdHVyZS5jb20vYXJ0aWNsZXMvczQxNDY3LTAyMC0xNzQzMS140gEA?oc=5,Explainable artificial intelligence model to predict acute critical illness from electronic health records - Nature.com,2020-07-31,Nature.com,https://www.nature.com,"Acute critical illness is often preceded by deterioration of routinely measured clinical parameters, e.g., blood pressure and heart rate. Early clinical prediction is typically based on manually calculated screening metrics that simply weigh these parameters, such as early warning scores (EWS). The predictive performance of EWSs yields a tradeoff between sensitivity and specificity that can lead to negative outcomes for the patient. Previous work on electronic health records (EHR) trained artificial intelligence (AI) systems offers promising results with high levels of predictive performance in relation to the early, real-time prediction of acute critical illness. However, without insight into the complex decisions by such system, clinical translation is hindered. Here, we present an explainable AI early warning score (xAI-EWS) system for early detection of acute critical illness. xAI-EWS potentiates clinical translation by accompanying a prediction with information on the EHR data explaining it. Acute critical illness is often preceded by deterioration of routinely measured clinical parameters, e.g., blood pressure and heart rate. Here, the authors develop an explainable artificial intelligence early warning score system for its early detection.",N/A,"Acute critical illness is often preceded by deterioration of routinely measured clinical parameters, e.g., blood pressure and heart rate. Here, the authors develop an explainable artificial intelligence early warning score system for its early detection.","Nature Communications - Acute critical illness is often preceded by deterioration of routinely measured clinical parameters, e.g., blood pressure and heart rate. Here, the authors develop an...",N/A,N/A,"




Download PDF








Article

Open access

Published: 31 July 2020

Explainable artificial intelligence model to predict acute critical illness from electronic health records
Simon Meyer Lauritsen 
            ORCID: orcid.org/0000-0001-8823-50471,2, Mads Kristensen1, Mathias Vassard Olsen3, Morten Skaarup Larsen3, Katrine Meyer Lauritsen 
            ORCID: orcid.org/0000-0002-6230-64302,4, Marianne Johansson Jørgensen5, Jeppe Lange2,5 & …Bo Thiesson1,6 Show authors

Nature Communications
volume 11, Article number: 3852 (2020)
            Cite this article




29k Accesses


203 Citations


25 Altmetric


Metrics details






AbstractAcute critical illness is often preceded by deterioration of routinely measured clinical parameters, e.g., blood pressure and heart rate. Early clinical prediction is typically based on manually calculated screening metrics that simply weigh these parameters, such as early warning scores (EWS). The predictive performance of EWSs yields a tradeoff between sensitivity and specificity that can lead to negative outcomes for the patient. Previous work on electronic health records (EHR) trained artificial intelligence (AI) systems offers promising results with high levels of predictive performance in relation to the early, real-time prediction of acute critical illness. However, without insight into the complex decisions by such system, clinical translation is hindered. Here, we present an explainable AI early warning score (xAI-EWS) system for early detection of acute critical illness. xAI-EWS potentiates clinical translation by accompanying a prediction with information on the EHR data explaining it.



Similar content being viewed by others






Explainable machine learning for real-time deterioration alert prediction to guide pre-emptive treatment
                                        


Article
Open access
11 July 2022









Predicting acute clinical deterioration with interpretable machine learning to support emergency care decision making
                                        


Article
Open access
21 August 2023









Artificial intelligence in the neonatal intensive care unit: the time is now
                                        


Article
13 July 2023








IntroductionArtificial Intelligence (AI) is capable of predicting acute critical illness earlier and with greater accuracy than traditional early warning score (EWS) systems, such as modified EWSs (MEWSs) and sequential organ failure assessment scores (SOFAs)1,2,3,4,5,6,7,8,9,10,11,12,13. Unfortunately, standard deep learning (DL) that comprise available AI models are black-box predictions that cannot readily be explained to clinicians. A tradeoff must, therefore, be made between transparency and predictive power, which for high-stake applications most often favor the simpler, more transparent systems, where a clinician can easily back-trace a prediction. To benefit from the higher predictive power, the importance of explainable and transparent DL algorithms in clinical medicine is without question, as was recently highlighted in the Nature Medicine review by Topol14.Transparency and explainability are an absolute necessity for the widespread introduction of AI models into clinical practice, because an incorrect prediction may have grave consequences15,16,17,18. Clinicians must be able to understand the underlying reasoning of AI models so they can trust the predictions and be able to identify individual cases in which an AI model potentially gives incorrect predictions15,16,17,18,19. Consequently, a useful explanation involves both the ability to account for the relevant parts in an AI model leading to a prediction, but also the ability to present this relevance in a way that supports the clinicians causal understanding in a comprehendible way20. An explanation that is too hard to perceive and comprehend will most likely not have any practical effect.In this work, we will present explainable AI early warning score (xAI-EWS), which comprises a robust and accurate AI model for predicting acute critical illness from electronic health records (EHRs). Importantly, xAI-EWS was designed to provide simple visual explanations for the given predictions. To demonstrate the general clinical relevance of the xAI-EWS, we present results here from three emergency medicine cases: sepsis, acute kidney injury (AKI), and acute lung injury (ALI). The xAI-EWS is composed of a temporal convolutional network (TCN)21,22 prediction module and a deep Taylor decomposition (DTD)23,24,25,26,27 explanation module, tailored to temporal explanations (see Fig. 1).Fig. 1: Overview of the xAI-EWS system.Each patient’s data from the EHR is used as input in the TCN prediction module. Based on this data, the model makes a prediction, such as a 78% risk of AKI. The DTD explanation module then explains the TCN predictions in terms of input variables. P, plasma; eGFR, estimated Glomerular filtration rate; DTD, deep Taylor decomposition; TCN, temporal convolutional network; xAI-EWS, explainable artificial intelligence early warning system.Full size imageThe architecture of the TCN has proven to be particularly effective at predicting events that have a temporal component, such as the development of critical illness5,22,28,29. The TCN operates sequentially over individual EHRs and outputs predictions in the range of 0–100%, where the predicted risk should be higher for those patients at risk of later acute critical illness, compared to those who are not. The DTD explanation module delineates the TCN predictions in terms of input variables by producing a decomposition of the TCN output on the input variables30,31.ResultsPredictive performanceIn Fig. 2, the predictive power of the xAI-EWS is presented in summary form with results from the onset time to 24 h before onset. Area under the receiver operating characteristic curve (AUROC) with mean values and 95% confidence intervals (CIs) over the five cross-validations folds were 0.92 (0.9–0.95)–0.8 (0.78–83), 0.88 (0.86–0.9)–0.79 (0.78–0.8), and 0.90 (0.89–0.92)–0.84 (0.82–0.85) for sepsis, AKI, and ALI, respectively. Area under the precision-recall curve (AUPRC) with mean values and 95% CIs were 0.43 (0.36–0.51)–0.08 (0.07-0.09), 0.22 (0.19–0.24)−0.13 (0.12–0.14), and 0.23 (0.21–0.26)–0.23 (0.22–0.24) for sepsis, AKI, and ALI, respectively. (Supplementary Tables 1 and 2).Fig. 2: Predictive performance of the xAI-EWS.The xAI-EWS results are compared with those from MEWS, SOFA, and the gradient boosting vital sign model (GB-Vital). Predictive performance is shown from the onset time to 24 h before onset. AUROC performance is shown for sepsis (a), AKI (c), and ALI (e), and AUPRC performance is shown for sepsis (b), AKI (d), and ALI (f). The solid lines indicate mean values. Lighter semitransparent colors surrounding the solid lines indicate uncertainty by 95% confidence intervals calculated from the five test datasets (n = 163,050 patients examined over 5 cross-validation folds with a test size of 10%).Full size imageExplanationsThe xAI-EWS enabled two perspectives on the model explanations: an individual and a population-based perspective. For the individual perspective, the explanation module enabled the xAI-EWS to pinpoint which clinical parameters at a given point in time were relevant for a given prediction. In current clinical practice, the workflow normally follows that clinicians observe either a high EWS or an increase in EWS. However, the following targeted clinical intervention concerning the potential critical illness happens when the clinician understands which clinical parameters have caused the high EWS or the change in EWS. This is one of the main reasons why AI-based EWS systems need to be able to explain their predictions. The xAI-EWS system we developed allows for such explanations in real time and across all clinical parameters used in the model. An example of an output from the explanation module, utilizing the individual perspective, is illustrated in Fig. 3. Individual clinical parameters are sized according to the amount of back-propagated relevance. Figure 3a shows the 10 most relevant parameters with respect to sepsis for a single patient with a risk score of 76.2%. High respiration frequency, high pulse rate, and low plasma albumin are the most important predictors of sepsis. The physiological values of respiration frequency and pulse rate do not seem to increase close to the prediction time, but, inspecting the increasing sizes of relevance, it appears that the xAI-EWS attributes more weight to recent values. Figure 3b and c show the 10 most relevant parameters with respect to AKI and ALI for two patients with risk scores of 90.4% and 83.8%, respectively.Fig. 3: Results from the explanation module displays for three individual patients.Three selected patient timelines with back-propagated relevance for sepsis (a), AKI (b), and ALI (c) are shown. Only the 10 highest-ranking parameters in descending order by the mean relevance are displayed. The data shown in the three timelines match the data from the observation window, such that a time equal to zero is the prediction time. The data-points are colored according to the 5th and 95th percentiles for each parameter across the whole dataset. The blue data-points correspond to a value between 0 and the 5th percentile, the red data-points correspond to a value between the 95th and 100th percentiles, and data-points with values close to the median are purple. P, plasma; eGFR, estimated Glomerular filtration rate.Full size imageIn terms of the population-based perspective, the xAI-EWS is able to facilitate transparency and, thereby, induce trust, by giving clinicians insights into the internal mechanics of the model without any deep technical knowledge of the mechanisms behind it.In Fig. 4, the 10 most important clinical parameters for each of the three models are shown. The parameters are sorted by the decreasing mean relevance as computed for the local, back-propagated relevance scores across the entire population, but only for patients who were positive for sepsis, AKI, or ALI.Fig. 4: Results from the explanation module displaying the global parameter importance and local explanation summary.The parameters are sorted in descending order according to global parameter importance, defined by the mean relevance, which is identified by the blue horizontal bars for sepsis (a), AKI (c), and ALI (e). The local explanations summary shows all the individual data-points, colored by parameter value and displaced by the mean relevance for sepsis (b), AKI (d), and ALI (f). The height of the data-points shown for each parameter in the local explanation summary correlate with the number of data-points at the associated level of relevance. The population-based perspective is simplified by ignoring the temporal relevance variations, treating all data-points at different times equally. P, plasma; eGFR, estimated Glomerular filtration rate.Full size imageThe blue horizontal bars in the left column of Fig. 4 display the mean relevance. In the local explanation summary in the right-hand column of Fig. 4, the distribution of the back-propagated relevance scores for each clinical parameter are shown and color-coded by the parameter value associated with the local explanation. As an example, in Fig. 4c and d, the AKI model seems to associate high P-creatinine levels and low estimated glomerular filtration rates with AKI. When the model is confident about a decision, it will output a high probability. This high probability will result in more relevance available for distributing backward; it will also result in larger relevance scores. On the contrary, when the model does not believe that a patient will develop an acute critical illness, it will output a low probability, and the associated relevance scores will also be low. The summary distribution allows clinicians to get an idea of what to expect from the model in clinical practice.DiscussionIn this study, we present xAI-EWS—an explainable AI early warning score system for early detection of acute critical illness. While maintaining a high predictive performance, our system explains to the clinician on which relevant EHRs data the prediction is grounded.Previous work has employed different strategies to develop explainable prediction models13,32,33,34,35,36. RNN variations with attention have been suggested for illness severity assesment13, risk of hospitalization prediction32, sepsis prediction, and myocardial infarction prediction35. Shickel et al.13 developed an interpretable deep learning framework called DeepSOFA that leveraged temporal measurements to assess illness severity at any point during an ICU stay. An RNN with gated recurrent units (GRU) and self-attention was proposed to highlight particular time steps of the input time series that the model believed to be most important in formulating its mortality prediction. Kaji et al. demonstrated how attention can be applied at the level of input variables themselves when predicting outcomes for ICU patients35. Choi et al. used a factorized approach to compute attention over both variables and time using embedded features rather than the immediate input features themselves36. Zhang et al. compressed the entire patient EHR into a complete vector representation and used GRU and self-attention to predict the future risk of hospitalization in an interpretable framework called Patient2Vec32. Our work differentiates from the above studies by utilizing TCN and LRP instead of RNNs with attention.It is important to note that the xAI-EWS presented in this study should not be conceived as the one-and-only multi-outcome model. Rather, it should be viewed as a general method of building precise and explainable models for acute critical illness. Following this line of thinking, it is obvious that other models with important critical outcomes, such as hypokalemia, hyperkalemia, acute constipation, and cardiac arrest, should be added to the three models presented in this study. This will result in a series of EWS models that are all specialists in their respective fields.One important point to note is that more work is needed to investigate better ground truth definitions of the evaluated critical illnesses, such as AKI and ALI. We based the ground truth on the need for continuous positive airway pressure (CPAP) or noninvasive ventilation (NIV) because PaO2/FiO2 measurements were not available. The KDIGO is an indicator of AKI that has a long lag time after the initial renal impairment, as mentioned by Tomašev et al.1. Our model is trained and has been tested on a large dataset that is highly representative of the Danish population. However, validating the predictive performance of the xAI-EWS on a different population would make for an interesting study, and, as the xAI-EWS currently uses just 33 clinical parameters, this appears feasible. An interesting subject for further study would also be to compare how well the explanation module in this paper conveys explanations to the clinical experts in various contexts compared to alternatives. To that end, Holzinger et al.37 recently proposed a Likert-scale based method tailored to explanations from AI.We limited the length of the observation window to 24 h to ensure that the model was based on clinical, and time-relevant, features. A variable-length window greater than 24 h should be explored in an upcoming study.Model development was done in an iterative way where results from technical development were continuously discussed with clinicians from an emergency department. The purpose of this process was to ensure that the models learned at least some correlations that are already considered established knowledge in the clinical field. It would be obvious to try to use this technology hypothesis-generating, whereby output from LRP analysis is used as inspiration to discover new and unknown correlations.The low prevalence of the sepsis, AKI, and ALI (2.44%, 0.75%, and 1.68%) resulted in a very unbalanced classification problem. To combat this imbalance, we tried to oversample the positive class with replacements. The oversampling did not affect model performance, but stretched the output probabilities into a wider range. The results reported were computed without resampling.In summary, we have presented the xAI-EWS—an explainable AI EWS system for the prediction of acute critical illness using EHRs. The xAI-EWS shows a high predictive performance while enabling the possibility to explain the predictions in terms of pinpointing decisive input data to empower clinicians to understand the underlying reasoning of the predictions. We hope that our results will be a steppingstone toward a more widespread adoption of AI in clinical practice. As stated, explainable predictions facilitate trust and transparency—properties that also make it possible to comply with the regulations of the European Union General Data Protection Regulation, the Conformité Européenne (CE) marking, and the United States Food and Drug Administration38.MethodsData descriptionIn this study, we analyzed the secondary healthcare data of all residents of four Danish municipalities (Odder, Hedensted, Skanderborg, and Horsens) who were 18 years of age or older for the period of 2012–2017. The data contained information from the electronic health record (EHR), including biochemistry, medicine, microbiology, and procedure codes, and was extracted from the “CROSS-TRACKS” cohort, which embraces a mixed rural and urban multi-center population with four regional hospitals and one larger university hospital. Each hospital comprises multiple departmental units, such as emergency medicine, intensive care, and thoracic surgery. We included all 163,050 available inpatient admissions (45.9% male) during the study period and excluded only outpatient admissions. The included admissions were distributed across 66,288 unique residents. The prevalence for sepsis, AKI, and ALI among these admissions was 2.44%, 0.75%, and 1.68%, respectively (see Table 1). The CROSS-TRACKS cohort offers a combined dimensional model of the secondary healthcare data. Merging all data sets is possible via a unique personal identification number given to all Danish citizens and by which all information within any public institution is collected31.Table 1 Patient population description.Full size tableThe model parameters were limited to include 27 laboratory parameters and six vital signs (see Tables 2 and 3). The parameters were selected by trained specialists in emergency medicine (medical doctors) with the sole purpose of simplifying the model to enable a better discussion of the model explanations. While a deeper model with more parameters might lead to better performance, it would also have made the discussions between clinicians and software engineers difficult. Therefore, the scope of this article is not to obtain the best performance at all costs but to demonstrate how clinical tasks can be supported by a fully explainable deep learning approach.Table 2 List of clinical parameters.Full size tableTable 3 Parameter range summary.Full size tableData preprocessingIn the data extracted from the CROSS-TRACKS cohort, each admission is represented as a time-ordered sequence of EHR events. Importantly, the time-stamped order of this data reflects the point in time at which the clinicians record each event during the admission. Each event comprises three elements: a time stamp; an event name, such as blood pressure; and a numerical value. The event sequence is partitioned in aggregated intervals of one hour, such that the observation window of 24 h is divided into 24 one-hour periods, and all the events occurring within the same one-hour period are grouped together by their average numerical value.Gold standardsVia a classification process, each admission was classified as sepsis-positive, AKI-positive, ALI-positive, or negative (no critical illness). For sepsis classification, we followed the recent Sepsis-330,39 implementation by Moor et al.5, according to which both suspected infection and organ dysfunction are required to be present5,30,39. Suspected infection was defined by the co-occurrence of body fluid sampling and antibiotic administration. When a culture sample was obtained before antibiotics administration, the antibiotic had to be ordered within 72 h. If the antibiotic was administered first, then the culture sample had to follow within 24 h.The degree of organ dysfunction is described by an acute increase in the SOFA40 score and an increase of more than or equal to two points is used in the criteria for sepsis39. To implement the organ dysfunction criterion, we used a 72-h window from 48 h before to 24 h after the time of suspected infection, as suggested by Singer et al.30 and Moor et al.5. The Sepsis-3 implementation is visualized in Fig. 5.Fig. 5: Gold standards for sepsis, AKI, and ALI.Sepsis (a), AKI (b), ALI (c), suspected infection (SI).Full size imageAKI classification was performed according to the KDIGO criteria31. KDIGO accepts three definitions of AKI: (1) an increase in serum creatinine of 0.3 mg/dl (26.5 μmol/l) within 48 h; (2) an increase in serum creatinine by 1.5 times the habitual creatinine level of a patient within the previous seven days; and (3) a urine output of <0.5 ml/kg/h over 6 h. Following the work of Tomašev et al.1, only the first two definitions were used to provide ground-truth labels for the onset of AKI as urine measurements were not available. The habitual creatinine level was computed as the mean creatinine level during the previous 365 days. We used binary encoding for AKI such that all three severity stages (KDIGO stages 1, 2, and 3) were encoded as positive AKI. For ALI classification, we considered the presence of either NIV or CPAP during the admission, because PaO2/FiO2 measurements were not available. The ALI onset was the first occurrence of either NIV or CPAP (see Fig. 5).Prediction moduleThe AI-EWS model is designed as a variation of a convolutional neural network (CNN) called a temporal convolutional network (TCN). CNNs have dominated computer vision tasks for the last century and are also highly capable of performing sequential tasks, such as text analysis and machine translation41. A TCN23,24 models the joint probability distribution over sequences by decomposing the distribution over discrete time-steps \(p_\theta \left( x \right) = \mathop {\prod }\nolimits_{t = 1}^T p_\theta \left( {\left. {x_{t}} \right|x_{1:t - 1}} \right)\), where \(x = \left\{ {x_1,x_2, \ldots ,x_{{T}}} \right\}\) is a sequence, and the joint distribution is parameterized by the TCN parameter \(\theta\). Thus, a TCN operates under the autoregressive premise that only past values affect the current or future values, e.g., if a patient will develop acute critical illness. Moreover, TCNs differ from “ordinary” CNNs by at least one property: the convolutions in TCNs are causal in the sense that a convolution filter at time t is only dependent on the inputs that are no later than \(t\), wherein the input subsequence is \(x_1,x_2, \ldots ,x_{{t}}\). TCNs can take a sequence of any length as input and output a sequence of the same length, similar to RNNs22,28. The TCN achieves this by increasing the receptive field of the model with dilated convolutions instead of performing the traditional max pooling operation, as seen in most CNNs. Dilated convolutions achieve a larger receptive field with fewer parameters by having an exponential stride compared to the traditional linear stride. By increasing the receptive field, a temporal hierarchy comparable to multi-scale analysis from computer vision can be achieved42. Figure 6 schematizes the xAI-EWS model and the concept of dilated convolutions. At the time of prediction, the xAI-EWS model receives an input matrix of shape time-steps × features for each patient.Fig. 6: The xAI-EWS model architecture.The models in this study are trained and evaluated at 0, 3, 6, 12, and 24 h before the onset of critical illness. Each model has a 24-h retrospective observation window. The color gradient from green to red illustrates continuous deterioration towards acute critical illness (a). The overall model architecture of the AI-EWS model is shown in b. The xAI-EWS uses three temporal blocks (c), each comprising one-dimensional dilated causal convolution layers, ReLU activations, one-dimensional dropout layers, and normalization layers. Red layers are only used during training and are omitted when the model is used for predictions and explanations. The overall dilation structure of the model is shown in d. The one-dimensional dilated causal convolution layers allow the model to skip some points during convolution and, thereby, increase the receptive field of the model. The dilation structure is illustrated for kernel size = 2.Full size imageThe data are processed by three temporal blocks, each including one-dimensional dilated causal convolutions (Conv1d) with 64 filters, ReLU activations43, layer44, and one-dimensional spatial dropout layers45. Dilation is increased between each temporal block, but keep it constant inside each temporal block (meaning that the second conv1d layer in each temporal block has a dilation = 1). The receptive field for this model can be calculated with \(1 + \mathop {\sum }\nolimits_{i = 1}^n \left( {k - 1} \right) \ast \left( {2^{i - 1} + 1} \right)\), where k is kernel size and n is the number of temporal blocks. We used a kernel size = 4 yielding a maximum receptive field of 31. Outputs from the third temporal block are pooled together across time-steps by a global average pooling operation46 to obtain a stabilizing effect for the final output of the model. The pooled output from each kernel in the dilated causal convolutions is flattened to a single vector that is used as input to a final dense layer followed by a softmax activation function. The output from the softmax activation is the probability of future sepsis, AKI, or ALI during admission.Training and hyperparametersThe model was trained to optimize the cross-entropy loss using the Adam optimizer47 with mini-batches of the size of 200, a learning rate of 0.001, and a dropout rate of 10%. All weights were initialized with He Normal initialization48. The model was trained on a NVIDIA Tesla V100 GPU. Convergence was reached in ~30 min.Explanation moduleIn simple models, such as linear regression models, the simple association between input and the prediction outcome is readily transparent and explainable. Consider the linear function fc that weights the input x by wc in order to assign a decision for class c:$$f_c\left({\mathbf{x}} \right) = {\mathbf{w}}_c^Tx = \mathop {\sum }\limits_i w_{ic}x_i.$$
                    (1)
                Here, each input feature xi of x contributes together with the trainable weight wic to the overall evaluation of fc through the quantity \(w_{ic}x_i\). The importance-weighted input, therefore, offers a simple explanation for a decision made by the linear model. In contrast, the complexity associated with the multi-layer non-linear nature of deep learning models counteracts with such simplicity in explanations.Layer-wise relevance propagation (LRP)23,24,25,26,27 is an explanatory technique that applies to deep-learning models, including TCNs. Starting from the output \(f_c\left({\mathbf{x}} \right)\), LRP decomposes an explanation into simpler local updates, each recursively defining the contribution to the explanation (called relevance) for all activating neurons in the previous layer. The initial relevance score \(R_j = f_c\left({\mathbf{x}} \right)\) is hereby propagated backward through the network by local relevance updates \(R_{i \leftarrow j}\) between connecting neuronsi and j, until the input layer is finally reached. In this process, all incoming relevance values to an intermediate node i are pooled, \(R_i = \mathop {\sum }\nolimits_j R_{i \leftarrow j}\), before its relevance is propagated to the next layer. Figure 7 illustrates the relevance propagation, which is similar to standard backpropagation of errors except that relevance values are propagated backward in the network instead. The conservation property23, one of the important defining properties in LRP, ensures that the total back-propagated relevance amounts to the extent to which the illness of interest is detected by the function \(f_c\left({\mathbf{x}} \right)\), which in this paper equals the logits that feed into the final transformation layer.Fig. 7: Layer-wise relevance propagation.LRP decomposes the problem of explaining a complex multilayer neural network model into simpler sub-functions that are easier to analyze and explain. The relevance score at input neuron \(R_i\) is obtained by pooling all incoming relevance values \(R_j\) from the output neurons in the next layer.Full size imageIn this process, all incoming relevance values to an intermediate node i are pooled, \(R_i = \mathop {\sum }\nolimits_j R_{i \leftarrow j}\), before its relevance is propagated to the next layer. Figure 7 illustrates the relevance propagation, which is similar to standard backpropagation of errors except that relevance values are propagated backward in the network instead.There are many variations of local backpropagation rules in the LRP framework. See, e.g., Montavon et al.49 for a collection of commonly used LRP rules. We have used propagation rules that can be interpreted as DTD23, which defines a sound theoretical framework behind most of the LRP variations. In DTD, a local backward propagation of relevance accounts for a non-linearity in the network model by a first-order Taylor approximation at some well-chosen root-point. Using the origin as root recovers the original LRP update rule from Bach et al.25. That is, the relevance Rj at neuron j propagates backward to neuron i as$$R_{i \leftarrow j} = \frac{{w_{ij}a_i}}{{\mathop {\sum }\nolimits_i w_{ij}a_i}}R_j$$
                    (2)
                where \(a_i\) is the activation for neuron i. Notice that this local relevance-update rule is similar to the simple explanation for the linear model in Eq. (1), except that the normalization ensures that relevance is conserved across layers. It is the simplest local relevance propagation in the LRP framework, known as simply LRP, LRP-0, or the z-rule in DTD.In general, the Taylor expansion that defines the local relevance propagation rule depends on the type of non-linearity and can, in addition, be engineered to enforce desirable properties based on root-point restrictions23. The network for the model considered in this work is composed of only ReLU activations and linear projections without a bias term. In this case, we can use a particularly engineered rule that will only distribute relevance along positive contributions through the layers in the network and therefore produces sparser (i.e., simpler) explanations. This rule is in the literature known as the z+-rule for DTD or LRP-\(\alpha _1\beta _0\), which again is a special case of LRP-\(\gamma\)49. It is defined as$$R_{i \leftarrow j} = \frac{{w_{ij}^ + a_i}}{{\mathop {\sum }\nolimits_i w_{ij}^ + a_i}}R_j$$
                    (3)
                where \(w_{ij}^ + = w_{ij}\) for positive weights and otherwise equals zero. Finally, at the input layer, we used the so-called DTD w2-rule$$R_{i \leftarrow j} = \frac{{w_{ij}^2}}{{\mathop {\sum }\nolimits_i w_{ij}^2}}R_j$$
                    (4)
                as it is recommended49 for real valued input.The DTD (and LRP) framework leaves flexibility to mix layer-specific rules in the network. As mentioned above, we have used the z+-rule in Eq. (3) for all intermediate layers, and in that way, we favor simpler explanations, with features that are explained as either relevant (positive) or irrelevant (zero) for a given prediction.The AI-EWS explanation module allows two perspectives on model explanations: an individual and a population-based perspective. For the individual perspective, DTD can be used for all patients with a high probability of developing acute critical illness. The module will simply pinpoint which clinical parameters at a given point in time were relevant for the given prediction (Fig. 3). For the population-based perspective, relevance is back-propagated from the output neuron representing the positive classes (sepsis, AKI, and ALI) and is only considered for the patients with a positive ground truth label (sepsis, AKI, and ALI). The individual data points and back-propagated relevance scores for these patients were aggregated in two ways to enable global parameter importance estimation and local explanation summary34 (Fig. 4). For estimating global parameter importance, the mean relevance scores were computed for each clinical parameter. This computation enabled parameter-importance estimation comparable to standardized regression coefficients in multiple linear regression or feature importance measures in random forest50. The local explanation summary (Fig. 4b) presents all individual data points, colored by parameter value and displaced by the relevance. In the local explanation summary, the height of the data points shown for each parameter correlates with the number of data points at their associated level of relevance. The population-based perspective is simplified by ignoring potential temporal relevance variations and treating all data points at different times equally. The visual concepts of global parameter importance estimation and local explanation summary used in this paper are adopted from the shapley additive explanations (SHAP)34 library by Lundberg et al. The SHAP toolbox was not used to provide explanations. In this paper, DTD was implemented using the iNNvestigate51 library developed by Alber et al. iNNvestigate is a high-level library with an easy-to-use interface for many of the most-used explanation methods for neural networks.Explaining predictions in other waysOver the last decade, many other methods52,53,54,55,56,57,58,59,60,61,62,63 have been proposed to address the problem of attributing a value to each feature in order to explain the prediction from a complex model. Recent work62,63 have brought some theoretical understanding into fundamental properties that relates many of the methods. In general, the relevance attribution methods can be categorized into two basic categories62: (1) backpropagation-based methods that propagate the attribution of relevance backward through the network form the relevance of output and back to the input features, and (2) perturbation-based methods that rely on running multiple perturbations of the input forward through the network and measuring the consequence that a perturbation may have on the output.With reference in the Gradient × Input method58, Ancona et al.62 defines a unification of many of the backpropagation-based attribution methods. In particular, they show that LRP (DTD with the z-rule), DeepLIFT (Rescale)59, and Integrated Gradients60 are all strongly related by a reformulation that expresses the attribution as the elementwise multiplication of a modified gradient with either the input (Gradient × Input, LRP) or with the difference between the input and a baseline (Integrated Gradients, DeepLIFT). The modification to the gradient is achieved by letting backpropagation implement a modified chain-rule$$\frac{{d^ \ast a_j}}{{da_i}} = w_{ij}g\left( {z_j} \right),$$
                    (5)
                where \(w_{ij}\) is the standard gradient of the linear transformation \(z_j = \mathop {\sum }\nolimits_i w_{ij}a_i\), and \(g(z_j)\) represents some unification of the gradient for the non-linear activation. For Gradient × Input, the unifying gradient function \(g(z_j)\) is the usual instant gradient, whereas it is some form of average gradient for the remaining three methods. We refer to Ancona et al. for the actual expressions of \(g(z_j)\). Interestingly, it turns out that all four methods would be equivalent in this paper’s setup, with only ReLU non-linearities, no additive bias in the linearities, and \({\mathbf{x}} = {\bf{0}}\) as baseline.Now, the DTD z+-rule, as we have used in all the intermediate layers, does not fit directly into the unified gradient framework, but it is a trivial exercise to show that the backpropagation rule in Eq. (5) can be modified as$$\frac{{d^ \ast a_j}}{{da_i}} = w_{ij}^ + g^ + ( {z_j} ),$$
                    (6)
                where \(g^ + ( {z_j} ) = a_j/z_j^ +\), \(z_j^ + = \mathop {\sum }\nolimits_i w_{ij}^ + a_i\) accounts for the fact that the relevance method only distributes relevance along positive contributions.Backpropagation-based methods are in general fast compared to perturbation-based methods, as the number of features grow62. The backpropagation-based methods require a fixed number of forward-prediction and backward-gradient passes to compute the attribution, whereas perturbation-based methods demand a non-linear number of forward passes in the number of features to properly account for the complex nature of a deep network.On the other hand, perturbation-based methods may implement other desirable properties, such as the fairness constraints from cooperative game theory, when attributing an outcome of a prediction (the game) to the individual features (the players)53,61,63,64. In particular, Lundberg and Lee63 recently demonstrated that Shapley values65 uniquely defines the solution to these constraints within a large class of additive feature attribution methods, which includes LIME57, DeepLIFT, and LRP. Unfortunately, computing exact Shapley values is, in general, NP-hard66 and sampling approximations are therefore considered. By defining a specific kernel in the LIME setup, Lundberg and Lee introduced KernelSHAP that reduces the number of necessary samples by combining sampling and penalized linear regression, as it is done in LIME. The same paper further proposed DeepSHAP as a variant of DeepLIFT that computes a layer-wise composition of approximate Shapley values. Unfortunately, the chain rule does not hold in general for Shapley values64, and to that end, Ancona et al. presents a method based on uncertainty propagation that allows approximate Shapley value to be computed in polynomial time.Baseline modelsMEWSThe MEWS baseline model interprets raw MEWS scores as a prediction model for acute critical illness. MEWS was implemented as the Danish variant called “Early detection of critical illness” [TOKS: Tidlig opsporing af kritisk sygdom]. MEWS scores were calculated each time one of the model components was updated with a new measurement. Missing values were imputed with a standard carry-forward interpolation.SOFAThis model interprets raw SOFA30,39,40 scores as a prediction model for acute critical illness. SOFA scores were calculated each time one of the model components was updated with a new measurement. Missing values were imputed with a standard carry-forward interpolation.GB-VitalThis model is a replication of a well-known sepsis detection model3,6,9 from the literature, which has shown great results in a randomized study7. The complete description of the model can be found in the study from Mao et al.6. The model parameters are constructed by considering six vital-signs from the EHR: systolic blood pressure, diastolic blood pressure, heart rate, respiratory rate, peripheral capillary oxygen saturation, and temperature. For each of the six vital signs, five parameters are constructed to represent the average value for the current hour, the prior hour, and the hour prior to that hour, together with the trend value between two succeeding hours. Based on these 30 parameters (five parameters from each of the six vital-sign events), the GB-Vital model is constructed as a gradient-boosted classifier of decision trees67.EvaluationThe xAI-EWS model was validated using five-fold cross-validation. Data were randomly divided into five portions of 20% each. For each fold four portions (80%) was used to fit the xAI-EWS model parameters during training. The remaining 20% was split into two portions of 10% each for validation and test. The validation data were used to perform an unbiased evaluation of a model fit during training, and the test data were used to provide an unbiased evaluation of the final model. All data for a single patient was assigned to either train, validation or test data. Figure 2 report performance from the test data. For each fold data were shifted such that a new portion was used for testing. The cross-validation scheme is illustrated in Supplementary Fig. 1. As comparative measures for the predictive performance, we used the AUROC and AUPRC. Regarding the explanations, the quality was assessed by manual inspection of trained specialists (medical doctors) in emergency medicine.Ethics and information governanceThe study was approved by The Danish Data Protection Agency [case number 1-16-02-541-15]. Additionally, the data used in this work were collected with the approval of the steering committee for CROSS-TRACKS. Only retrospective data were used for this research without the active involvement of patients or potential influence on their treatment. Therefore, under the current national legislature, no formal ethical approval was necessary.Reporting summaryFurther information on research design is available in the Nature Research Reporting Summary linked to this article.


Data availability
The authors have accessed the data referred to herein by applying the CROSS-TRACKS cohort, which is a newer Danish cohort that combines primary and secondary sector data68. Due to the EU regulations, GDPR, these data are not readily available to the wider research community per se. However, all researchers can apply for access to the data by following the instructions on this page: http://www.tvaerspor.dk/.
Code availability
We made use of several open-source libraries to conduct our experiments: The models used the machine learning framework TensorFlow library with custom extensions (https://www.tensorflow.org) and Keras (https://keras.io). Explanations were calculated with the high-level library for explaining neural networks iNNvestigate (https://github.com/albermax/innvestigate). SHAP (https://github.com/slundberg/shap) with custom extensions was used to visualize explanations. The analysis was performed with custom code written in Python 3.5. Our experimental framework makes use of proprietary libraries that belong to Enversion A/S, and we are unable to publicly release this code. We have described the experiments and implementation details in the “Methods” section to allow for independent replication. Further inquiry regarding the specific nature of the AI model can be made by relevant parties to the corresponding author.
ReferencesTomašev, N. et al. A clinically applicable approach to continuous prediction of future acute kidney injury. Nature 572, 116–119 (2019).Article 
    ADS 
    
                    Google Scholar 
                Lauritsen, S. M. et al. Early detection of sepsis utilizing deep learning on electronic health record event sequences. Artif. Intell. Med. 104, 101820 (2020).Article 
    
                    Google Scholar 
                Barton, C. et al. Evaluation of a machine learning algorithm for up to 48-hour advance prediction of sepsis using six vital signs. Comput. Biol. Med. 109, 79–84 (2019).Article 
    
                    Google Scholar 
                Islam, M. M. et al. Prediction of sepsis patients using machine learning approach: a meta-analysis. Comput. Meth. Prog. Bio. 170, 1–9 (2019).Article 
    
                    Google Scholar 
                Moor, M., Horn, M., Rieck, B., Roqueiro, D. & Borgwardt, K. Temporal convolutional networks and dynamic time warping can drastically improve the early prediction of Sepsis. In Proceedings of the 4th Machine Learning for Healthcare Conference. PMLR 106 (2019).Mao, Q. et al. Multicentre validation of a sepsis prediction algorithm using only vital sign data in the emergency department, general ward and ICU. BMJ Open 8, e017833 (2018).Article 
    
                    Google Scholar 
                Shimabukuro, D. W., Barton, C. W., Feldman, M. D., Mataraso, S. J. & Das, R. Effect of a machine learning-based severe sepsis prediction algorithm on patient survival and hospital length of stay: a randomised clinical trial. BMJ Open Respir. Res. 4, e000234 (2017).Article 
    
                    Google Scholar 
                Kam, H. J. & Kim, H. Y. Learning representations for the early detection of sepsis with deep neural networks. Comput. Biol. Med. 89, 248–255 (2017).Article 
    
                    Google Scholar 
                Calvert, J. S. et al. A computational approach to early sepsis detection. Comput. Biol. Med. 74, 69–73 (2016).Article 
    
                    Google Scholar 
                Futoma, J. et al. An improved multi-output gaussian process RNN with real-time validation for early Sepsis detection. In Proceedings of Machine Learning for Healthcare 2017. JMLR, 68 (2017).Futoma, J., Hariharan, S. & Heller, K. Learning to detect sepsis with a multitask gaussian process RNN Classifier. In Proceedings of the 34th International Conference on Machine Learning. ICML vol. 70, 1174–1182 (2017).Vellido, A., Ribas, V., Morales, C., Sanmartín, A. R. & Ruiz-Rodríguez, J. C. Machine learning for critical care: an overview and a Sepsis case study. In Bioinformatics and Biomedical Engineering 2017 (eds Rojas, I. & Ortuño, F.) (IWBBIO) vol. 10208, 15–30 (2017).Shickel, B. et al. DeepSOFA: a continuous acuity score for critically ill patients using clinically interpretable deep learning. Sci. Rep. 9, 1879 (2019).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Topol, E. J. High-performance medicine: the convergence of human and artificial intelligence. Nat. Med. 25, 44–56 (2019).Article 
    CAS 
    
                    Google Scholar 
                Shickel, B., Tighe, P. J., Bihorac, A. & Rashidi, P. Deep EHR: a survey of recent advances in deep learning techniques for electronic health record (EHR). Anal. IEEE J. Biomed. Health 22, 1589–1604 (2017).Article 
    
                    Google Scholar 
                Rajkomar, A., Dean, J. & Kohane, I. Machine learning in medicine. N. Engl. J. Med. 380, 1347–1358 (2019).Article 
    
                    Google Scholar 
                Cabitza, F., Rasoini, R. & Gensini, G. F. Unintended consequences of machine learning in medicine. JAMMA 318, 517–518 (2017).Article 
    
                    Google Scholar 
                Xiao, C., Choi, E. & Sun, J. Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review. J. Am. Med. Inf. Assn. 25, 1419–1428 (2018).Article 
    
                    Google Scholar 
                The Lancet Respiratory Medicine. Opening the black box of machine learning. Lancet Respir. Med. 6, 837 https://doi.org/10.1016/S2213-2600(18)30425-9 (2018).Holzinger, A., Langs, G., Denk, H., Zatloukal, K. & Müller, H. Causability and explainability of artificial intelligence in medicine. Wiley Interdiscip. Rev. Data Min. Knowl. Disco. 9, e1312 (2019).Article 
    
                    Google Scholar 
                Kalchbrenner, N. et al. Neural machine translation in linear time. Preprint at https://arxiv.org/abs/1610.10099 (2016).Bai, S., Kolter, J. Z. & Koltun, V. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. Preprint at https://arxiv.org/abs/1803.01271 (2018).Montavon, G., Lapuschkin, S., Binder, A., Samek, W. & Müller, K. Explaining nonlinear classification decisions with deep Taylor decomposition. Pattern Recogn. 65, 211–222 (2017).Article 
    
                    Google Scholar 
                Montavon, G., Samek, W. & Müller, K.-R. Methods for interpreting and understanding deep neural networks. Digit Signal Process 73, 1–15 (2017).Article 
    MathSciNet 
    
                    Google Scholar 
                Bach, S. et al. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PLoS ONE 10, e0130140 (2015).Article 
    
                    Google Scholar 
                Samek, W., Wiegand, T. & Müller, K.-R. Explainable artificial intelligence: understanding, visualizing and interpreting deep learning models. The Impact of Artificial Intelligence (AI) on Communication Networks and Services 1, 39–48 (2015)Samek, W., Binder, A., Montavon, G., Lapuschkin, S. & Müller, K. Evaluating the visualization of what a deep neural network has learned. IEEE T. Neur. Net. Lear Syst. 28, 2660–2673 (2017).Lea, C., Vidal, R., Reiter, A. & Hager, G. D. Temporal convolutional networks: a unified approach to action segmentation. In Computer Vision – ECCV 2016 Workshops. 47–54 (Springer International Publishing, 2016).Aksan, E. & Hilliges, O. STCN: Stochastic temporal convolutional networks. In International Conference on Learning Representations 2019, CoRR (2019).Singer, M. et al. The third international consensus definitions for sepsis and septic shock (Sepsis-3). JAMA 315, 801–810 (2016).Article 
    CAS 
    
                    Google Scholar 
                Khwaja, A. KDIGO clinical practice guidelines for acute kidney injury. Nephron Clin. Pract. 120, c179–c184 (2012).PubMed 
    
                    Google Scholar 
                Zhang, J., Kowsari, K., Harrison, J. H., Lobo, J. M. & Barnes, L. E. patient2Vec: a personalized interpretable deep representation of the longitudinal electronic health record. IEEE Access 6, 65333–65346 (2018).Article 
    
                    Google Scholar 
                Rajkomar, A. et al. Scalable and accurate deep learning with electronic health records. Npj Digital Med. 1, 18 (2018).Article 
    
                    Google Scholar 
                Lundberg, S. M. et al. From local explanations to global understanding with explainable AI for trees. Nat. Mach. Intell. 2, 56–67 (2020).Article 
    
                    Google Scholar 
                Kaji, D. A. et al. An attention based deep learning model of clinical events in the intensive care unit. PLos ONE 14, e0211057 (2019).Article 
    CAS 
    
                    Google Scholar 
                Choi, E. et al. RETAIN: An interpretable predictive model for healthcare using reverse time attention mechanism. In 30th Annual Conference on Neural Information Processing Systems (NIPS 2016). Advances in Neural Information Processing Systems 3512–3520 (2016).Holzinger, A., Carrington, A. & Müller, H. Measuring the quality of explanations: the system causability scale (SCS). Künstl Intell. 34, 193–198 (2020).Article 
    
                    Google Scholar 
                Selbst, A. D. & Powles, J. Meaningful information and the right to explanation. Int Data Priv. Law 7, 233–242 (2017).Article 
    
                    Google Scholar 
                Seymour, C. W. et al. Assessment of clinical criteria for sepsis: for the third international consensus definitions for sepsis and septic shock (Sepsis-3). JAMA 315, 762–774 (2016).Article 
    CAS 
    
                    Google Scholar 
                Vincent, J.-L. et al. The SOFA (Sepsis-related organ failure assessment) score to describe organ dysfunction/failure. Intens. Care Med. 22, 707–710 (2018).Article 
    
                    Google Scholar 
                LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436–444 (2015).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Crowley, J. L. & Sandersen, A. Multiple resolution representation and probabilistic matching of 2-D gray-scale shape. IEEE Trans. Pattern Anal. Mach. Intell. https://ieeexplore.ieee.org/document/4767876 (1984).Nair, V. & Hinton, G. E. Rectified Linear Units Improve Restricted Boltzmann Machines. In ICML'10: Proceedings of the 27th International Conference on International Conference on Machine Learning, 807–814 (Omnipress, 2010).Ba, J. L., Kiros, J. R. & Hinton, G. E. Layer normalization. Preprint at https://arxiv.org/abs/1607.06450 (2016).Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. & Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. J. Mach. Learn. Res. 15, 1929–1958 (2014).MathSciNet 
    MATH 
    
                    Google Scholar 
                Lin, M., Chen, Q. & Yan, S. Network in network. 2nd International Conference on Learning Representations. 14–16 http://arxiv.org/abs/1312.4400 (2013).Kingma, D. P. & Ba, J. Adam: a method for stochastic optimization. 3rd International Conference for Learning Representations, San Diego Preprint at https://arxiv.org/abs/1412.6980 (2014).He, K., Zhang, X., Ren, S. & Sun, J. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 770–778 (2016).Montavon, G., Binder, A., Lapuschkin, S., Samek, W. & Müller, K. R. In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning (eds Samek, W., Montavon, G., Vedaldi, A., Hansen, L. & Müller, K. R.), Vol. 11700 (Springer, 2019).Breiman, L. Random forests. Mach. Learn 45, 5–32 (2001).Article 
    
                    Google Scholar 
                Alber, M. et al. iNNvestigate neural networks! Preprint at https://arxiv.org/abs/1808.04260 (2018).Simonyan, K., Vedaldi, A. & Zisserman, A. Deep inside convolutional networks: visualising image classification models and saliency maps. In Workshop at International Conference on Learning Representations. CoRR (2013).Strumbelj, E. & Kononenko, I. Explaining prediction models and individual predictions with feature contributions. Knowl. Inf. Syst. 41, 647–665 (2013).Article 
    
                    Google Scholar 
                Zeiler, M. D. & Fergus, R. Visualizing and understanding convolutional networks. In Computer Vision—ECCV. 818–833 (Springer, Cham, 2014).Springenberg, J. T., Dosovitskiy, A., Brox, T. & Riedmiller, M. Striving for Simplicity: The all convolutional net. In ICLR (workshop track) (2014).Zintgraf, L. M., Cohen, T. S., Adel, T. & Welling, M. Visualizing deep neural network decisions: prediction difference analysis. In 5th International Conference on Learning Representations (2017).Ribeiro, M. T., Singh, S. & Guestrin, C. ‘Why Should I Trust You?’: Explaining the predictions of any classifier. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) (2016).Shrikumar, A., Greenside, P. & Kundaje, A. Not just a black box: learning important features through propagating activation differences. In Proceedings of the 34th International Conference on Machine Learning Vol. 70, 3145–3153 (2017).Shrikumar, A., Greenside, P. & Kundaje, A. Learning important features through propagating activation differences. In Proceedings of the 34th International Conference on Machine Learning Vol. 70, 3145–3153 (2017).Sundararajan, M., Taly, A. & Yan, Q. Axiomatic attribution for deep networks. In Proceedings of the 34th International Conference on Machine Learning Vol. 70, 3319–3328 (2017).Datta, A., Sen, S. & Zick, Y. Algorithmic transparency via quantitative input influence: theory and experiments with learning systems. In 2016 IEEE Symposium on Security and Privacy (SP) 598–617 https://doi.org/10.1109/sp.2016.42 (2016).Ancona, M., Ceolini, E., Öztireli, C. & Gross, M. Towards better understanding of gradient-based attribution methods for Deep Neural Networks. In Sixth International Conference on Learning Representations (2018).Lundberg, S. M. & Lee, S.-I. A unified approach to interpreting model predictions. Adv. Neural Inf. Process. Syst. 30, 4765–4774 (2017).
                    Google Scholar 
                Ancona, M., Öztireli, C. & Gross, M. Explaining deep neural networks with a polynomial time algorithm for shapley values approximation. In Thirty-sixth International Conference on Machine Learning. ICML (2019).Shapley, L. S. A value for n-person games. Contributions to the Theory of Games 2, 307–317 (1953).Matsui, Y. & Matsui, T. NP-completeness for calculating power indices of weighted majority games. Theor. Compu. Sci 263, 305–310 (1998).Chen, T. & Guestrin, C. XGBoost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 785–794 (2016).Riis, A. H. CROSS-TRACKS—a population-based danish cross-sectorial cohort. Preprint at https://www.medrxiv.org/content/10.1101/2020.05.13.20100263v1 (2019).Download referencesAcknowledgementsWe acknowledge the steering committee for CROSS-TRACKS for access to the data. For data acquisition, modeling, and validation, we thank the following: Julian Guldborg Birkemose, Christian Bang, Per Dahl Rasmussen, Anne Olsvig Boilesen, Lars Mellergaard, and Jacob Høy Berthelsen. For help with the data extraction pipelines, we thank Mike Pedersen. We also thank the rest of the Enversion team for their support. This work was also supported by the Innovation Fund Denmark [case number 8053-00076B].Author informationAuthors and AffiliationsEnversion A/S, Fiskerivej 12, 1st floor, 8000, Aarhus C, DenmarkSimon Meyer Lauritsen, Mads Kristensen & Bo ThiessonDepartment of Clinical Medicine, Aarhus University, Palle Juul-Jensens Boulevard 82, 8200, Aarhus N, DenmarkSimon Meyer Lauritsen, Katrine Meyer Lauritsen & Jeppe LangeDepartment of Biomedical Engineering and Informatics, Aalborg University, Niels Jernes Vej 12, 9220, Aalborg Ø, DenmarkMathias Vassard Olsen & Morten Skaarup LarsenDepartment of Endocrinology and Internal Medicine, Aarhus University Hospital, Palle Juul-Jensens Boulevard, 99, 8200, Aarhus N, DenmarkKatrine Meyer LauritsenDepartment of Research, Horsens Regional Hospital, Sundvej 30, 8700, Horsens, DenmarkMarianne Johansson Jørgensen & Jeppe LangeDepartment of Engineering, Aarhus University, Inge Lehmanns Gade 10, 8000, Aarhus C, DenmarkBo ThiessonAuthorsSimon Meyer LauritsenView author publicationsYou can also search for this author in
                        PubMed Google ScholarMads KristensenView author publicationsYou can also search for this author in
                        PubMed Google ScholarMathias Vassard OlsenView author publicationsYou can also search for this author in
                        PubMed Google ScholarMorten Skaarup LarsenView author publicationsYou can also search for this author in
                        PubMed Google ScholarKatrine Meyer LauritsenView author publicationsYou can also search for this author in
                        PubMed Google ScholarMarianne Johansson JørgensenView author publicationsYou can also search for this author in
                        PubMed Google ScholarJeppe LangeView author publicationsYou can also search for this author in
                        PubMed Google ScholarBo ThiessonView author publicationsYou can also search for this author in
                        PubMed Google ScholarContributionsS.M.L., J.L., M.J.J., and B.T. initiated the project. B.T., S.M.L., K.M.L., J.L., and M.J.J. contributed to the overall experimental design. S.M.L. and M.K. created the dataset. S.M.L., M.K., M.V.O., and M.S.L. contributed to the software engineering and K.M.L., B.T., and S.M.L. analyzed the results. S.M.L. made the first article draft. All authors contributed significantly to revision of the first article draft, and approval of the final version of the manuscript.Corresponding authorCorrespondence to
                Simon Meyer Lauritsen.Ethics declarations
Competing interests
S.M.L, M.K., and B.T. are employed at Enversion. The authors have no other competing interests to disclose.
Additional informationPeer review information Nature Communications thanks Andreas Holzinger, Jean-Louis Vincent and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Supplementary informationSupplementary InformationPeer Review FileReporting SummaryRights and permissions
Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.
Reprints and permissionsAbout this articleCite this articleLauritsen, S.M., Kristensen, M., Olsen, M.V. et al. Explainable artificial intelligence model to predict acute critical illness from electronic health records.
                    Nat Commun 11, 3852 (2020). https://doi.org/10.1038/s41467-020-17431-xDownload citationReceived: 30 November 2019Accepted: 25 June 2020Published: 31 July 2020DOI: https://doi.org/10.1038/s41467-020-17431-xShare this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        
Subjects

Acute kidney injuryComputational modelsMachine learningPredictive medicineRespiratory signs and symptoms





This article is cited by





                                        Predicting sepsis in-hospital mortality with machine learning: a multi-center study using clinical and inflammatory biomarkers
                                    


Guyu ZhangFei ShaoTao Wang

European Journal of Medical Research (2024)




                                        Early detection of pediatric health risks using maternal and child health data
                                    


Cornelia Ilin

Scientific Reports (2024)




                                        Impact of a deep learning sepsis prediction model on quality of care and survival
                                    


Aaron BoussinaSupreeth P. ShashikumarGabriel Wardi

npj Digital Medicine (2024)




                                        UHSC flexural strength prediction using optimized three-phase classifier and improved feature selection
                                    


Ma’en Abdel-JaberMu’tasime Abdel-JaberNisrine Makhoul

International Journal on Interactive Design and Manufacturing (IJIDeM) (2024)




                                        Building a trustworthy AI differential diagnosis application for Crohn’s disease and intestinal tuberculosis
                                    


Keming LuYuanren TongSheng Yu

BMC Medical Informatics and Decision Making (2023)





CommentsBy submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.





",https://schema.org,WebPage,,,,,,,,,,,,,,,"{'headline': 'Explainable artificial intelligence model to predict acute critical illness from electronic health records', 'description': 'Acute critical illness is often preceded by deterioration of routinely measured clinical parameters, e.g., blood pressure and heart rate. Early clinical prediction is typically based on manually calculated screening metrics that simply weigh these parameters, such as early warning scores (EWS). The predictive performance of EWSs yields a tradeoff between sensitivity and specificity that can lead to negative outcomes for the patient. Previous work on electronic health records (EHR) trained artificial intelligence (AI) systems offers promising results with high levels of predictive performance in relation to the early, real-time prediction of acute critical illness. However, without insight into the complex decisions by such system, clinical translation is hindered. Here, we present an explainable AI early warning score (xAI-EWS) system for early detection of acute critical illness. xAI-EWS potentiates clinical translation by accompanying a prediction with information on the EHR data explaining it. Acute critical illness is often preceded by deterioration of routinely measured clinical parameters, e.g., blood pressure and heart rate. Here, the authors develop an explainable artificial intelligence early warning score system for its early detection.', 'datePublished': '2020-07-31T00:00:00Z', 'dateModified': '2020-07-31T00:00:00Z', 'pageStart': '1', 'pageEnd': '11', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'sameAs': 'https://doi.org/10.1038/s41467-020-17431-x', 'keywords': ['Acute kidney injury', 'Computational models', 'Machine learning', 'Predictive medicine', 'Respiratory signs and symptoms', 'Science', 'Humanities and Social Sciences', 'multidisciplinary'], 'image': ['https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-020-17431-x/MediaObjects/41467_2020_17431_Fig1_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-020-17431-x/MediaObjects/41467_2020_17431_Fig2_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-020-17431-x/MediaObjects/41467_2020_17431_Fig3_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-020-17431-x/MediaObjects/41467_2020_17431_Fig4_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-020-17431-x/MediaObjects/41467_2020_17431_Fig5_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-020-17431-x/MediaObjects/41467_2020_17431_Fig6_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-020-17431-x/MediaObjects/41467_2020_17431_Fig7_HTML.png'], 'isPartOf': {'name': 'Nature Communications', 'issn': ['2041-1723'], 'volumeNumber': '11', '@type': ['Periodical', 'PublicationVolume']}, 'publisher': {'name': 'Nature Publishing Group UK', 'logo': {'url': 'https://www.springernature.com/app-sn/public/images/logo-springernature.png', '@type': 'ImageObject'}, '@type': 'Organization'}, 'author': [{'name': 'Simon Meyer Lauritsen', 'url': 'http://orcid.org/0000-0001-8823-5047', 'affiliation': [{'name': 'Enversion A/S, Fiskerivej 12', 'address': {'name': 'Enversion A/S, Fiskerivej 12, Aarhus C, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}, {'name': 'Aarhus University', 'address': {'name': 'Department of Clinical Medicine, Aarhus University, Aarhus N, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'sla@enversion.dk', '@type': 'Person'}, {'name': 'Mads Kristensen', 'affiliation': [{'name': 'Enversion A/S, Fiskerivej 12', 'address': {'name': 'Enversion A/S, Fiskerivej 12, Aarhus C, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Mathias Vassard Olsen', 'affiliation': [{'name': 'Aalborg University', 'address': {'name': 'Department of Biomedical Engineering and Informatics, Aalborg University, Aalborg Ø, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Morten Skaarup Larsen', 'affiliation': [{'name': 'Aalborg University', 'address': {'name': 'Department of Biomedical Engineering and Informatics, Aalborg University, Aalborg Ø, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Katrine Meyer Lauritsen', 'url': 'http://orcid.org/0000-0002-6230-6430', 'affiliation': [{'name': 'Aarhus University', 'address': {'name': 'Department of Clinical Medicine, Aarhus University, Aarhus N, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}, {'name': 'Aarhus University Hospital', 'address': {'name': 'Department of Endocrinology and Internal Medicine, Aarhus University Hospital, Aarhus N, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Marianne Johansson Jørgensen', 'affiliation': [{'name': 'Horsens Regional Hospital', 'address': {'name': 'Department of Research, Horsens Regional Hospital, Horsens, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Jeppe Lange', 'affiliation': [{'name': 'Aarhus University', 'address': {'name': 'Department of Clinical Medicine, Aarhus University, Aarhus N, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}, {'name': 'Horsens Regional Hospital', 'address': {'name': 'Department of Research, Horsens Regional Hospital, Horsens, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Bo Thiesson', 'affiliation': [{'name': 'Enversion A/S, Fiskerivej 12', 'address': {'name': 'Enversion A/S, Fiskerivej 12, Aarhus C, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}, {'name': 'Aarhus University', 'address': {'name': 'Department of Engineering, Aarhus University, Aarhus C, Denmark', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}], 'isAccessibleForFree': True, '@type': 'ScholarlyArticle'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjAvMDcvMjkvb3Bpbmlvbi9ncHQtMy1haS1hdXRvbWF0aW9uLmh0bWzSAQA?oc=5,Opinion | How Do You Know a Human Wrote This? (Published 2020) - The New York Times,2020-07-29,The New York Times,https://www.nytimes.com,Audio Recording by Audm,N/A,"Machines are gaining the ability to write, and they are getting terrifyingly good at it.","Machines are gaining the ability to write, and they are getting terrifyingly good at it.",Opinion,N/A,"AdvertisementSKIP ADVERTISEMENTOpinionSupported bySKIP ADVERTISEMENTHow Do You Know a Human Wrote This?Machines are gaining the ability to write, and they are getting terrifyingly good at it.July 29, 2020Credit...Michael HoutzShare full article340Read in appBy Farhad ManjooOpinion ColumnistListen to This Op-EdAudio Recording by AudmListen · 7:16 minTo hear more audio stories from publishers like The New York Times, download Audm for iPhone or Android.I’ve never really worried that computers might be gunning for my job. To tell the truth, often, I pray for it. How much better would my life be — how much better would my editor’s life be, to say nothing of the poor readers — if I could ask an all-knowing machine to suggest the best way to start this column? It would surely beat my usual writing process, which involves clawing at my brain with a rusty pickax in the dim hope that a few flakes of wisdom and insight might, like dandruff, settle on the page.See what I mean? A computer might have helped there. (Like dandruff? That’s what you’re going with, Farhad?) But we writers can be a cocky bunch. Writing is something of an inexplicable trick, and it feels, like telling a joke or making a soufflé, like an inviolably human endeavor.I’ve never really worried that a computer might take my job because it’s never seemed remotely possible. Not infrequently, my phone thinks I meant to write the word “ducking.” A computer writing a newspaper column? That’ll be the day.Well, writer friends, the day is nigh. This month, OpenAI, an artificial-intelligence research lab based in San Francisco, began allowing limited access to a piece of software that is at once amazing, spooky, humbling and more than a little terrifying.AdvertisementSKIP ADVERTISEMENTOpenAI’s new software, called GPT-3, is by far the most powerful “language model” ever created. A language model is an artificial intelligence system that has been trained on an enormous corpus of text; with enough text and enough processing, the machine begins to learn probabilistic connections between words. More plainly: GPT-3 can read and write. And not badly, either.Sign up for the Opinion Today newsletter  Get expert analysis of the news and a guide to the big ideas shaping the world every weekday morning.  Get it sent to your inbox.Software like GPT-3 could be enormously useful. Machines that can understand and respond to humans in our own language could create more helpful digital assistants, more realistic video game characters, or virtual teachers personalized to every student’s learning style. Instead of writing code, one day you might create software just by telling machines what to do.OpenAI has given just a few hundred software developers access to GPT-3, and many have been filling Twitter over the last few weeks with demonstrations of its surprising capabilities, which range from the mundane to the sublime to the possibly quite dangerous.To appreciate the potential danger, it helps to understand how GPT-3 works. Language models often need to be trained for specific uses — a customer-service bot used by a retailer might need to be fine-tuned with data about products, while a bot used by an airline would need to learn about flights. But GPT-3 doesn’t need much extra training. Give GPT-3 a natural-language prompt — “I hereby resign from Dunder-Mifflin” or “Dear John, I’m leaving you” — and the software will fill in the rest with text that is eerily close to what a human would produce.AdvertisementSKIP ADVERTISEMENTThese aren’t canned responses. GPT-3 is capable of generating entirely original, coherent and sometimes even factual prose. And not just prose — it can write poetry, dialogue, memes, computer code and who knows what else.GPT-3’s flexibility is a key advance. Matt Shumer, the chief executive of a company called OthersideAI, is using GPT-3 to build a service that responds to email on your behalf — you write the gist of what you’d like to say, and the computer creates a full, nuanced, polite email out of your bullet points.Another company, Latitude, is using GPT-3 to build realistic, interactive characters in text-adventure games. It works surprisingly well — the software is not only coherent but also can be quite inventive, absurd and even funny.Stew Fortier, a writer, created a zany satire using the software as a kind of muse.Fortier fed GPT-3 a strange prompt: “Below is a transcript from an interview where Barack Obama explained why he was banned from Golden Corral for life.” The system then filled in the rest of the interview, running with the concept that Obama had been banned from an all-you-can-eat buffet.Obama: Yes. It’s true. I am no longer allowed in Golden Corral.Interviewer: Is this because of your extensive shrimp-n-crab legs policy?Obama: Absolutely.Interviewer: What is your extensive shrimp-n-crab legs policy?Obama: Oh, well, in brief, they were offering an all-you-can-eat shrimp-n-crab leg buffet, and I did not hesitate. After I ate so much shrimp and crab that my stomach hurt, I would quietly sneak in and throw more shrimp and crab onto my plate. I did this over and over again until I had cleaned out the buffet and was full of shrimp-n-crab.Yet software like GPT-3 raises the prospect of frightening misuse. If computers can produce large amounts of humanlike text, how will we ever be able to tell humans and machines apart? In a research paper detailing GPT-3’s power, its creators cite a litany of dangers, including “misinformation, spam, phishing, abuse of legal and governmental processes, fraudulent academic essay writing and social engineering pretexting.”AdvertisementSKIP ADVERTISEMENTThere are other problems. Because it was trained on text found online, it’s likely that GPT-3 mirrors many biases found in society. How can we make sure the text it produces is not racist or sexist? GPT-3 also isn’t good at telling fact from fiction. “I gave it my own original three sentences about whales, and it added original text — and the way I could tell it was original was that it was pretty much dead wrong,” Janelle Shane, who runs a blog called AI Weirdness, told me.To its credit, OpenAI has put in place many precautions. For now, the company is letting only a small number of people use the system, and it is vetting each application produced with it. The company also prohibits GPT-3 from impersonating humans — that is, all text produced by the software must disclose that it was written by a bot. OpenAI has also invited outside researchers to study the system’s biases, in the hope of mitigating them.These precautions may be enough for now. But GPT-3 is so good at aping human writing that it sometimes gave me chills. Not too long from now, your humble correspondent might be put out to pasture by a machine — and you might even miss me when I’m gone.Office Hours With Farhad ManjooFarhad wants to chat with readers on the phone. If you’re interested in talking to a New York Times columnist about anything that’s on your mind, please fill out this form. Farhad will select a few readers to call.The Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this or any of our articles. Here are some tips. And here's our email: letters@nytimes.com.Follow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.Farhad Manjoo was a Times Opinion columnist from 2018 to 2023. Before that, they wrote the State of the Art column. They are the author of “True Enough: Learning to Live in a Post-Fact Society.”  @fmanjoo • Facebook A version of this article appears in print on July 30, 2020, Section A, Page 22 of the New York edition with the headline: How Do You Know a Human Wrote This?. Order Reprints | Today’s Paper | SubscribeRead 340 CommentsShare full article340Read in appAdvertisementSKIP ADVERTISEMENTComments 340How Do You Know a Human Wrote This?Skip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Enjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",https://schema.org,AudioObject,https://static.nytimes.com/podcasts/2020/07/29/opinion/29audm-know-human-wrote/200729-nyto-know-human-wrote-audm.mp3,Opinion | How Do You Know a Human Wrote This?,https://www.nytimes.com/2020/07/29/opinion/gpt-3-ai-automation.html,https://www.nytimes.com/,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/07/29/opinion/29manjoo_web/29manjoo_web-videoSixteenByNineJumbo1600-v3.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2020/07/29/opinion/29manjoo_web/29manjoo_web-videoSixteenByNineJumbo1600-v3.jpg', 'creditText': 'Michael Houtz'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/07/29/opinion/29manjoo_web/29manjoo_web-superJumbo-v2.jpg', 'height': 2048, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2020/07/29/opinion/29manjoo_web/29manjoo_web-superJumbo-v2.jpg', 'creditText': 'Michael Houtz'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/07/29/opinion/29manjoo_web/29manjoo_web-mediumSquareAt3X-v2.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2020/07/29/opinion/29manjoo_web/29manjoo_web-mediumSquareAt3X-v2.jpg', 'creditText': 'Michael Houtz'}]",,2020-07-29T09:00:17.000Z,2020-07-30T02:17:19.000Z,,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/farhad-manjoo', 'name': 'Farhad Manjoo'}]",,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,en-US,Opinion | How Do You Know a Human Wrote This?,[{'@id': 'https://static.nytimes.com/podcasts/2020/07/29/opinion/29audm-know-human-wrote/200729-nyto-know-human-wrote-audm.mp3'}],"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",{'@id': '#commentsContainer'},340.0,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",Listen to This Op-Ed,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,https://static.nytimes.com/podcasts/2020/07/29/opinion/29audm-know-human-wrote/200729-nyto-know-human-wrote-audm.mp3,2020-07-29T22:16:35.000Z,PT0.436S,,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vd3d3LmJvc2NoLmNvbS9zdG9yaWVzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXByb2dyZXNzL9IBAA?oc=5,Artificial Intelligence: A Motor for Progress - Bosch Global,2020-07-27,Bosch Global,https://www.bosch.com,"For robotics expert Sebastian Thrun, artificial intelligence is a motor for progress. He bases his optimism on how rapidly AI has developed. Read more!",N/A,"For robotics expert Sebastian Thrun, artificial intelligence is a motor for progress. He bases his optimism on how rapidly AI has developed. Read more!","For robotics expert Sebastian Thrun, artificial intelligence is a motor for progress. He bases his optimism on how rapidly AI has developed. Read more!",N/A,N/A,"                   Sebastian Thrun    Share this on:              Artificial intelligence as a motor for progress In dialogue with the robotics expert                              2020-07-27   Sebastian Thrun is certain: artificial intelligence will revolutionize our everyday lives — although some challenges still lie ahead. But fear not — we already have a solution for one of the biggest problems we face.                              Sebastian Thrun’s résumé reads like a tech fairytale. The robotics specialist from Germany moved to the US as a young man. There, he went on to become a professor at Stanford University before later making the move to Google. He carried out groundbreaking work at the company, helping to develop a self-driving car. He then founded an online university, and today the 52-year-old is head of the company Kitty Hawk, which develops personal flying vehicles. It seems that Thrun is always one step ahead of progress. What does someone like him think about artificial intelligence (AI)? “I believe it is going to be as big as a disruption to the world as the steam engine has been,” he says. And just like the steam engine, AI won’t replace people in the working world, but will instead make tasks much easier for us and enable greater productivity.           AI watches and learns      Thrun bases his optimism on how rapidly AI has developed. Just five years ago programmers had to feed their AI systems with step-by-step instructions so that they could handle these tasks. Now these intelligent machines learn just like people — by observing and imitating. “I believe there are great opportunities to leverage artificial intelligence into many jobs. When we get there, people will be much more efficient than before,” says Thrun.  He uses a practical example to clearly illustrate this: together with his students at Stanford, he trained an algorithm using 130,000 images of skin diseases. Skin cancer can now be detected as reliably as a dermatologist via a smartphone camera. This is a major step in reducing the workload of doctors and allowing people who don’t necessarily have access to medical facilities — due to living in remote locations or having limited financial means — to get a diagnosis.           “There are great opportunities to leverage AI into many jobs. When we get there, people will be much more efficient.”   Sebastian Thrun, robotics expert and CEO at Kitty Hawk      Share on X/Twitter           Tackling the skills shortage      Thrun wants to solve one of the biggest problems related to AI — the skills shortage — by means of his online university Udacity. Truly tapping into and further developing AI’s potential requires well-educated programmers, and there are simply not enough of them across the world. That’s why Thrun founded Udacity in 2012 as a platform to stream his AI lectures from Stanford. Within just a few weeks, about 160,000 students from around the globe had watched his videos. 23,000 of them went on to pass the online test. Udacity has since gone on to offer training courses on different areas of computer science, science, and economics for a fee. These aren’t just traditional correspondence courses where you get a diploma at the end, but instead individual courses that teach you practical specialist knowledge. About ten million students have taken part in the courses so far. “Udacity is now the market leader for corporate training in artificial intelligence. Many companies are working with us,” says Thrun. He says that a programmer with existing knowledge can be trained to become an AI expert within six months at Udacity.          50 percent  less expenditure for mobility — this is the savings potential that self-driving shuttle services could offer the average European.        The billion-dollar business of robotaxis       Mobility is Sebastian Thrun’s other passion aside from artificial intelligence. He has managed to link the two and founded the department for automated vehicles by means of “Waymo” at Google in 2016. Thrun claims that driverless vehicles have been technically possible for a long time, and are significantly safer than vehicles driven by humans. Now it’s time to create the corresponding business models and literally get them on the road: “I think the real unicorn business for self-driving cars is a self-driving taxi service. With that kind of model it’s possible to cut the costs of transportation by 50 percent.” This is possible because an automated shuttle could be used to full capacity. It would constantly transport customers and would not spend most of the time parked somewhere, as is the case for almost all private vehicles.                             Conquering the skies with electric and whisper-quiet vehicles      But that’s not all — for Thrun, the sky’s the limit. As CEO of the American company Kitty Hawk, he works on developing personal flying vehicles together with his team. He presented his third airworthy prototype last fall with the “Heaviside.” It has a range of 170 kilometers and can launch and land vertically thanks to its swiveling propellers. According to Thrun, its virtually silent electric motor is particularly forward-thinking: “When we are flying 300 meters above you, you will not hear us. And that is new, that is really a breakthrough.”  Generally speaking, flying taxis are still in their early stages. “But once they become more common place — maybe in ten years — they will be faster and safer than cars.” The Heaviside is already able to cover the 50 kilometers between San José and San Francisco in around 15 minutes — it takes about an hour by car. So will flying be more commonplace than driving in the future? Thrun doesn’t want to go that far, but he thinks that an innovative mobility mix of transport by land and by air is on the cards. According to Thrun, one thing’s for certain: whether it’s a car or a personal flying vehicle — in both cases AI will take the wheel.           An interview with Sebastian Thrun, robotics expert and CEO at Kitty Hawk                           Play         YouTube   Loading the video requires your consent. If you agree by clicking on the Play icon, the video will load and data will be transmitted to Google as well as information will be accessed and stored by Google on your device. Google may be able to link these data or information with existing data.  Learn more                 Profile                         Dr. Sebastian Thrun, 53 Robotics expert and CEO at Kitty Hawk  One of the most amazing things today is that machine learning allows computers to learn by themselves.  Sebastian Thrun grew up in Solingen in western Germany and went on to study computer science, economics, and medicine at the universities of Hildesheim and Bonn. He has been working in the US since 1995 — first at Carnegie Mellon University in Pittsburgh and as a professor at Stanford from 2003 onwards. He was appointed director of the Stanford Artificial Intelligence Laboratory a year later.  In 2011 he stepped down from his position as professor and became vice president at Google. Within this role, he founded the research department Google X which gave rise to innovations like the Google Street View cars and Google Glass. He launched the online university Udacity in 2012 and achieved second place in the American specialist magazine Foreign Policy’s “Top 100 Global Thinkers.” Sebastian Thrun has been CEO of the personal flying vehicle company Kitty Hawk since 2018.            Summary Sebastian Thrun says that artificial intelligence will allow us to work much more efficiently. Not only that, but AI in self-driving shuttles and automated personal flying vehicles will make mobility safer and faster. However, the skills shortage currently poses a major challenge. That’s why Thrun’s online platform Udacity offers courses on subjects like AI, for example.          How IoT experts envision the futureOur World in 2030          Thought leaders in dialogue Artificial intelligence Automated Driving        Share this on:               Explore more      CEO blogDenner’s view“We have to not only develop AI, but build trust in AI as well”   StoryArtificial intelligenceMore transparent AI with visual analytics   StoryArtificial intelligenceSelf-driving cars: lights, camera, action!       ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vY3NldC5nZW9yZ2V0b3duLmVkdS9wdWJsaWNhdGlvbi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hbmQtbmF0aW9uYWwtc2VjdXJpdHkv0gEA?oc=5,Artificial Intelligence and National Security - Center for Security and Emerging Technology,2020-07-30,Center for Security and Emerging Technology,https://cset.georgetown.edu,"Place to find CSET's publications, reports, and people",N/A,"Reps. Hurd, Kelly, the Bipartisan Policy Center and CSET released guidelines for national security considerations that must be addressed in a national AI strategy. The findings identify key areas for improvement in defense and intelligence to put the nation on a path to large-scale development and deployment of AI tools in promoting national security.",N/A,N/A,N/A,N/A,https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://cset.georgetown.edu/publication/artificial-intelligence-and-national-security/', 'url': 'https://cset.georgetown.edu/publication/artificial-intelligence-and-national-security/', 'name': 'Artificial Intelligence and National Security | Center for Security and Emerging Technology', 'isPartOf': {'@id': 'https://cset.georgetown.edu/#website'}, 'datePublished': '2020-07-30T15:55:47+00:00', 'dateModified': '2020-07-30T15:55:49+00:00', 'description': 'Reps. Hurd, Kelly, the Bipartisan Policy Center and CSET released guidelines for national security considerations that must be addressed in a national AI strategy. The findings identify key areas for improvement in defense and intelligence to put the nation on a path to large-scale development and deployment of AI tools in promoting national security.', 'breadcrumb': {'@id': 'https://cset.georgetown.edu/publication/artificial-intelligence-and-national-security/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://cset.georgetown.edu/publication/artificial-intelligence-and-national-security/']}]}, {'@type': 'BreadcrumbList', '@id': 'https://cset.georgetown.edu/publication/artificial-intelligence-and-national-security/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://cset.georgetown.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Documents', 'item': 'https://cset.georgetown.edu/publications/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial Intelligence and National Security'}]}, {'@type': 'WebSite', '@id': 'https://cset.georgetown.edu/#website', 'url': 'https://cset.georgetown.edu/', 'name': 'Center for Security and Emerging Technology', 'description': 'Place to find CSET&#039;s publications, reports, and people', 'publisher': {'@id': 'https://cset.georgetown.edu/#organization'}, 'alternateName': 'CSET', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://cset.georgetown.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://cset.georgetown.edu/#organization', 'name': 'CSET', 'url': 'https://cset.georgetown.edu/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://cset.georgetown.edu/#/schema/logo/image/', 'url': 'https://cset.georgetown.edu/wp-content/uploads/CSET_Logo_Icon_only_PMS293.png', 'contentUrl': 'https://cset.georgetown.edu/wp-content/uploads/CSET_Logo_Icon_only_PMS293.png', 'width': 192, 'height': 198, 'caption': 'CSET'}, 'image': {'@id': 'https://cset.georgetown.edu/#/schema/logo/image/'}, 'sameAs': ['https://www.linkedin.com/company/georgetown-cset/', 'https://www.youtube.com/channel/UCC0d3h9rVlfBouk0WoKE1FQ', 'https://www.threads.net/@csetgeorgetown', 'https://bsky.app/profile/cset.bsky.social', 'https://twitter.com/CSETGeorgetown']}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvbmVpbHNhaG90YS8yMDIwLzA3LzI3L3dpbGwtYWktc2F2ZS11cy1mcm9tLW91cnNlbHZlcy_SAQA?oc=5,Will AI Save Us From Ourselves? - Forbes,2020-07-27,Forbes,https://www.forbes.com,"People are wired for immediate threats. That’s why humanity hasn’t made big progress on solving huge global challenges such as climate change, pandemics, food production, etc. If we are our own worst enemy, who is left to save us? It just may well be artificial intelligence (AI.)","artificial intelligence,al,machine learning,ml,sustainability,sustainable development goals,sdgs,dendra,planet home,snotbot,ocean alliance,drones,whales,ocean,environment,climate change,pandemic,epidemic,covid-19,coronavirus,vaccine,society,civilization,deforestation,reforestation,trees,ocean health,health,healthcare,carbon emissions,micro-actions,microactions,solutions","People are wired for immediate threats. That’s why humanity hasn’t made big progress on solving huge global challenges such as climate change, pandemics, food production, etc. If we are our own worst enemy, who is left to save us? It just may well be artificial intelligence (AI.)","People are wired for immediate threats. That’s why humanity hasn’t made big progress on solving huge global challenges such as climate change, pandemics, food production, etc. If we are our own worst enemy, who is left to save us? It just may well be artificial intelligence (AI.)",AI,N/A,"More From ForbesJul 16, 2024,09:30am EDTIn Superconvergence, Jamie Metzl Unravels AI MysteriesJul 15, 2024,09:30pm EDTAnswering Your Most Frequently Asked Questions (FAQs) About Artificial Intelligence In Honor Of National AI Appreciation DayJul 15, 2024,06:06pm EDTNot Just A Maker Space: Fab Labs Spark Innovation WorldwideJul 15, 2024,02:57pm EDTIBM InstructLab And Granite Models Revolutionizing LLM TrainingJul 15, 2024,09:42am EDTHow Generative AI Is Driving HyperpersonalizationJul 15, 2024,08:00am EDTThe Clever ‘Rephrase And Respond’ Prompting Strategy Provides Big Payoffs For Prompt EngineeringJul 13, 2024,09:00am EDTBig Tech Involvement With OpenAI Sparks Unease Among RegulatorsEdit StoryForbesInnovationAIWill AI Save Us From Ourselves?Neil SahotaContributorOpinions expressed by Forbes Contributors are their own.Neil Sahota is a globally sought after speaker and business advisor.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itJul 27, 2020,10:00am EDTThis article is more than 3 years old.Share to FacebookShare to TwitterShare to LinkedinHumanity and AI putting the pieces together.Copyright (C) Andrey Popov
It is the year 2050. The world population is roughly two billion people, just 25% of what it was thirty years ago. Back in 2018, the United Nations had predicted that we were approaching the point of no return on climate change. Unfortunately, by the time humanity took serious, meaningful action to the threat, it was too late. The Earth’s temperature spiked destroying agriculture, triggering massive worldwide flooding, creating incredible natural disasters, and forcing people to migrate north… or underground. In conjunction with climate change, an explosion of pandemics ravaged the Earth. The sheer volume of disease was too much for humanity’s medical heroes as health systems around the world crumbled. However, climate and disease were just the start. The global economy collapsed as people desperately foraged for food, water, and shelter. Civilization crashed and burned, and even society shattered as people fought each other for the basic necessities of life.




Sounds apocalyptic? While we think this will never happen, this possible reality is much closer to happening than most people realize. Humans are wired to deal with immediate threats like that what’s that moving in the bushes. However, for long-term threats like climate change, people suffer from cognitive bias that often make us discount the extent threat or turn us into bystanders as we wait for someone else to deal with the problem. We need to look no further than the current Covid-19 pandemic as an example. How many times have people now said, “Why didn’t we do something sooner when we had the chance?” It has been incredible to see our medical heroes and front-line workers in grocery stores, food services, retail, delivery services, and so forth help keep society going. It also has been amazing to see how much has been invested from our global community to find a vaccine. However, this only occurred when Covid-19 went from a long-term threat to a full-blown pandemic and immediate threat. Imagine what might have happened if we tackled the pandemic as a global society back in December 2019. It definitely would be a different world today.



So, if humanity can’t manage long-term threats well, who can we turn to help us? Well, we have a very powerful ally in artificial intelligence (AI.)
PROMOTED
Two Humpback Whales surfacing and spraying water through blowholeDeposit Photos
Consider the tale of SnotBot®. Ocean Alliance is combing the power of drones, analytics, and AI to assess the health of the local ocean ecosystem. SnotBot® is a drone that follows whale pods. When a whale “blows its nose” (i.e. uses its blowhole), the drone swoops in. Petri dishes on the drone collect the whale mucus (i.e. snot), and then machines take the plethora of information which includes whale DNA, bacteria, hormones, water, etc. Aggregating this information together, we get information on the health of the whale and insights about the overall health of the local ocean ecosystem. This becomes an indicator into other key measures like pollution, water temperature, and so forth. While Ocean Alliance is getting some great insights about what Is currently happening, AI is helping to study long-term effects. With a “photographic memory”, the AI system can start discerning subtle pattern changes even on a day-by-day basis. If we teach the AI systems about long-term problems like climate change and pollution, it will keep a watchful eye on how these problems progress. If we take it a step further, AI can even identify solutions to mitigate these threats, or, perhaps, even solve them before they become a danger.
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report Says
Coronavirus vaccine development conceptDeposit Photos









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Picture a future where AI can identify a new virus and help people create a vaccine before the virus actually occurs. Valuable? In the article Lost In The Covid-19 Shuffle: 5 Key Areas That Need AI Help, we see how medical researchers can leverage AI and generative design to do exactly this, and we already have the technology and experience from other industries to make this a reality. We have the power to prevent epidemics let alone pandemics. So how close are we? Unfortunately, not that close yet in large part because of two key challenges. First, pooling our resources together to make sure we have enough good data to teach the AI system. Second, making the commitment to invest people and money to a solution that has a long-term return on investment. This is a big challenge because not only are people wired to immediate threats, but businesses are laser focused on short-term gains. This may be a lethal combination.


1/100:20Forbes Innovation





Skip Ad
 
Continue watchingCall Of Duty Black Ops 6 Beta Dates And More Revealedafter the adVisit Advertiser websiteGO TO PAGE
The toll of deforestationDeposit Photos
Thankfully, there are some organizations that are focused on the long-term investments people should be making into AI. Consider the company Dendra which is focused on reforestation. The World Wide Fund for Nature estimates that 27 football fields of forest are lost every minute due to deforestation, and Dendra plans to combat this by planting 500 billion trees by 2060. Using satellite images, Dendra identifies key areas for reforestation. Using drones armed with special seedpods (filled with the germinated seed and nutrients), the army of drones fire the seedpods at a rate of 120 per minute! Dendra estimates that they could help governments restore forests 150 times faster and for only 10% of the current cost. As Susan Graham, Dendra CEO, shared, “it represents a new step-change in how we think about global ecosystem restoration.”
The Planet Home solution wheel.Planet Home
Also leading the charge is Planet Home, an organization dedicated to planetary solutions and building a community of people taking micro-actions. Antony Randall, co-CEO of Planet Home, states, “we talk a lot about moonshots, but we also need Earthshots to help focus on the challenges of people and planet as well.” For Planet Home, it is critical to connect people with micro-actions, small changes people are willing to make that create a positive social impact. While they are small, in the aggregate, they add up to really move the needle on our global problems. Consider house plants. If one person adopts a house plant, it will absorb, on average, 2 pounds of carbon per year and scrub 87% of pollutants (in its room) within 24 hours. Now consider that this person and another one million people adopt a houseplant. That really adds up! This is what Planet Home wants to do. Encourage people to take these micro-actions and share the aggregate benefit its community is creating for people and the planet. It is a very long-term goal with a huge investment, but as Randall testifies, “we only have one planet so let’s make the commitment to preserve it.”
Humans and AI partnering to solve global challenges.Copyright (C) Andrey Popov
So, will AI save us from ourselves? Only if we commit the time, money, and resources to enable AI to do so. It is easy to say yes but incredibly difficult to do. Humans are wired for short-term immediate threats. Businesses are focused on short-term goals. However, these hurdles are not insurmountable. Even with a small group of people and enterprises dedicated to a cause, they can move mountains by tapping into the potential and power of AI and other emerging technology. By making the commitment to using AI for our big global challenges, AI can save us from ourselves.
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Neil SahotaFollowingFollowNeil Sahota (萨冠军) is an IBM Master Inventor, United Nations (UN) Artificial Intelligence (AI) Advisor, Professor at UC Irvine, and author of the book:... Read MoreEditorial StandardsPrintReprints & Permissions",http://schema.org,BreadcrumbList,,Will AI Save Us From Ourselves?,,https://www.forbes.com/sites/neilsahota/2020/07/27/will-ai-save-us-from-ourselves/,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5f1e0b60bdf8e1f6991b2489/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",,2020-07-27T10:00:00-04:00,2023-10-05T13:51:27-04:00,AI,"{'@type': 'Person', 'name': 'Neil Sahota', 'url': 'https://www.forbes.com/sites/neilsahota/', 'description': ""Neil Sahota (萨冠军) is an IBM Master Inventor, United Nations (UN) Artificial Intelligence (AI) Advisor, Professor at UC Irvine, and author of the book: Own the A.I. Revolution. With 20 years of business experience, he works with clients and business partners to create next generation products/solutions powered by AI. His work experience spans multiple industries including legal services, healthcare, life sciences, retail, travel and transportation, energy and utilities, automotive, telecommunications, media/communication, and government. Moreover, Neil is one of the few people selected for IBM's Corporate Service Corps leadership program that pairs leaders with NGOs to perform community-driven economic development projects. For his assignment, Neil lived and worked in Ningbo, China where he partnered with Chinese corporate CEOs to create a leadership development program. Neil is also an active volunteer. With the UN, he’s a founding member of their Artificial Intelligence (AI) for Social Good Committee. He is currently working with them to develop a report on the Economic Impact of AI as well as a model to incentivize member nations to invest in emerging technology to help fulfill the Sustainable Development Goals. In IBM’s Academic Initiative program that creates partnership opportunities between the IBM and the country’s top universities. He also serves as a business mentor for IBM’s Extreme Blue program that is an incubator for new product ideas. With Neil’s guidance, IBM developed new products and services in the areas of Business Analytics, Smarter Healthcare, Smarter Energy, Mobile Channel Development, and Social Media Solutions. Moreover, Neil partners with entrepreneurs to define their products, establish their target markets, and structure their companies. He is a member of the Tech Coast Angels and The Cove Fund Investment committee and assists startups with investor funding. Neil also serves as a judge in the Butterworth Product Competition, mentor in the K5 Launch accelerator program, and coach for various start up competitions. In addition to his professional work, Neil has taught part-time for the past eight years at UC Irvine, UC San Diego, UCLA, Oregon State University, international programs, corporate education, and K-12. He has help create Master’s degree programs in Innovation and Entrepreneurship as well as Business Analytics. He has created certificate programs in AI, Business Analysis, Predicative Analytics, and Project Management. In addition, he has created over thirty courses over all education levels."", 'sameAs': ['https://www.linkedin.com/in/neilsahota/', 'https://www.twitter.com/https://twitter.com/neil_sahota', 'https://www.neilsahota.com/']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,,,,,,,,,,False,,Will AI Save Us From Ourselves?,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LnNwaWNld29ya3MuY29tL3RlY2gvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvdGVjaC0xMDEvdGhlLXRvcC01LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWJvb2tzLXRvLXJlYWQtaW4tMjAxOS0yL9IBAA?oc=5,The Top 5 Artificial Intelligence Books to Read in 2019 - Spiceworks News and Insights,2020-07-28,Spiceworks News and Insights,https://www.spiceworks.com,"I dont want to really scare you, but it was alarming how many people I talked to who are highly placed people in AI who have retreats that are sort of 'bug ...",N/A,"I dont want to really scare you, but it was alarming how many people I talked to who are highly placed people in AI who have retreats that are sort of 'bug out' houses, to which they could fle",N/A,N/A,N/A,"



























 



Prajakta Patil



					Sr. Assistant Editor, Spiceworks Ziff Davis				




Last Updated: July 28, 2020




 





I dont want to really scare you, but it was alarming how many people I talked to who are highly placed people in AI who have retreats that are sort of ‘bug out’ houses, to which they could flee if it all hits the fan. 
 James Barrat, Author, Our Final Invention: Artificial Intelligence and the End of the Human Era
Reading the latest books ensures that you develop and understand different perspectives on a subject. Artificial intelligence has rapidly changed and continues to change the way we perform our daily tasks and operate businesses. Its fast progress may leave many professionals feeling like theyre struggling to keep pace with the developments. To ensure that you stay ahead of the curve as an AI professional, it is necessary to keep updating yourself about fresh perspectives about the technology. Here are some recommended reads for 2019 to help you understand the AI revolution, grasp its impact, as well as be better prepared for an AI-driven future.
Table of Contents
 1. Life 3.0: Being Human in the Age of Artificial Intelligence by Max Tegmark 
 2. Human + Machine: Reimagining Work in the Age of AI By Paul Daugherty and H. James Wilson
 3. Our Final Invention: Artificial Intelligence and the End of the Human Era by James Barrat 
 4. Superintelligence: Paths, Dangers, Strategies by Nick Bostrom
 5. The Singularity is Near by Ray Kurzweil 
Closing Thoughts

1. 
Life 3.0: Being Human in the Age of Artificial Intelligence by Max TegmarkOpens a new window 
This book was named the Book of the Year in 2018 by The Daily Telegraph as well as The Times. A personal favorite of Elon Musk, the book revolves around Tegmark, a physicist and cosmologist by profession. Tegmark sets out to differentiate the myths of AI from reality in an approachable way. The author manages to answer some very challenging questions about creating a prosperous world with AI and how to protect AI from being hacked. It is a book which aims to help the layperson understand the areas that will be most affected by AI in our day-to-day lives. 
A great starting point of all into the world of AI. 
Learn More: What is Artificial Intelligence: History, Types, Applications, Benefits, Challenges, and Future of AIOpens a new window 
2. Human + Machine: Reimagining Work in the Age of AI by Paul Daugherty and H. James WilsonOpens a new window 
This book is written by Paul Daugherty, Chief Technology and Innovation Officer of Accenture and James Wilson, Managing Director of IT and Business Research, Accenture. Therefore, it comes as no surprise that it has a focus on the business applications and implications of AI. The authors demonstrate that the transformation of all business processes in an organization is the essence of the AI paradigm shift. The book talks about the business areas where humans and machines are working closely together today and reveals the various ways in which companies are leveraging advancements in AI technology for more profitability. 
An interesting read for all corporate officers. 
3. Our Final Invention: Artificial Intelligence and the End of the Human Era by James BarratOpens a new window 
This is an excellent book on AI that considers the dangers of anthropomorphizing artificial general intelligence (AGI), and notes that superintelligence is a completely different type of threat. In this book, James Barrat talks about the various agencies and governments that are invested in researching artificial general intelligence (AGI). Many experts and scientists today believe that once the goal of AGI is achieved, machines will have a survival drive thats almost similar to humans. Barratt discusses this further and concludes that artificial super intelligence (ASI) will eventually become a threat to the human race.
What do you think? 
Learn More: What are the Types of Artificial Intelligence: Narrow, General, and Super AI ExplainedOpens a new window 
4. Superintelligence: Paths, Dangers, Strategies by Nick BostromOpens a new window 
Animals lack the capabilities that a human brain possesses, making the human race the dominant species on earth today. Nick Bostrom discusses the implications for if this dominant position is compromised due to machine superintelligence. Like many other philosophical works, this book, too, asks more questions than it answers. It talks about the time when machines will surpass human intelligence and whether this will turn out to be positive or negative for mankind. If a day like that ever occurs, the fate of humans will more or less be dependent on machine superintelligence, much like the fate of gorillas depends on humans today. This book is quite ambitious and carefully makes its path through an intellectual terrain wed all like to be able to ignore.
Scary but compelling, right? 
5. The Singularity is Near by Ray KurzweilOpens a new window 
Ray Kurzweil is known for his respected opinions about the role of technology in the future. In The Age of Spiritual Machines, his classic book, he discussed how computers were soon going to rival human intelligence. In The Singularity is Near, he dives into super artificial intelligence and describes singularity from a fresh perspective. Kurzweil says that singularity is the point at which the intelligence of machines and humans will merge. And once that happens, there will be no stopping these machines. 
So much potential! 
Learn More: The Top 5 Cloud Computing Books to Read in 2019Opens a new window 
Closing Thoughts
Apart from the above five, How to Create a Mind: The Secret of Human Thought Revealed by Ray Kurzweil, Artificial Intelligence: A Modern Approach by Peter Norvig, The Master Algorithm by Pedro Domingos, Machine Learning Yearning by Andrew NG, and Rise of the Robots by Martin Ford are also some great artificial intelligence books for beginners. Go ahead and get lost in the rich history, current advancements, as well as the fascinating fictional world. Hope this list will guide you develop a multifaceted view of artificial intelligence.
Which one of these books is your favorite? Or have we missed out an AI book you loved? Let us know on LinkedInOpens a new window , TwitterOpens a new window , or FacebookOpens a new window . We would love to hear from you!







								                  Machine Learning										



Share This Article:
 





Prajakta Patil

				                  Sr. Assistant Editor, Spiceworks Ziff Davis	                          


 opens a new window
 opens a new window 



 opens a new window  opens a new window
  	
					An English graduate currently pursuing her MA in Journalism, Prajakta has 10 years of experience in content development. She has worked with newsrooms like Indian Express and Dainik Jagran where she handled feature articles on a daily basis. She has also contributed to WhatsHot, a venture by Times Internet. As an Editor for Toolbox, she handles long-form articles on cybersecurity, cloud, DevOps and more. You may reach out to her on prajakta_patil@ziffdavis.com to draw her attention to interesting topics.			








								Do you still have questions? Head over to the Spiceworks Community to find answers.
							

Take me to Community





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMjAvMDcvMzEvMTAwNTgyNC9kZWNvbG9uaWFsLWFpLWZvci1ldmVyeW9uZS_SAVNodHRwczovL3d3dy50ZWNobm9sb2d5cmV2aWV3LmNvbS8yMDIwLzA3LzMxLzEwMDU4MjQvZGVjb2xvbmlhbC1haS1mb3ItZXZlcnlvbmUvYW1wLw?oc=5,The problems AI has today go back centuries - MIT Technology Review,2020-07-31,MIT Technology Review,https://www.technologyreview.com,"Algorithmic discrimination and “ghost work” didn’t appear by accident. Understanding their long, troubling history is the first step toward fixing them.",,"Algorithmic discrimination and “ghost work” didn’t appear by accident. Understanding their long, troubling history is the first step toward fixing them.","Algorithmic discrimination and “ghost work” didn’t appear by accident. Understanding their long, troubling history is the first step toward fixing them.",N/A,N/A,N/A,http://schema.org,Organization,,The problems AI has today go back centuries,"{'@type': 'WebPage', '@id': 'https://www.technologyreview.com/2020/07/31/1005824/decolonial-ai-for-everyone/'}",https://www.technologyreview.com/2020/07/31/1005824/decolonial-ai-for-everyone/,"https://wp.technologyreview.com/wp-content/uploads/2020/07/200728_MIT_Decolonial_AI-01-01-01.jpg?resize=854,569","{'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/uploads/2020/07/200728_MIT_Decolonial_AI-01-01-01.jpg?resize=854,569', 'height': 569, 'width': 854}",2020-07-31T06:00:00-04:00,2020-07-31T06:00:00-04:00,2022-09-28T06:20:45-04:00,Policy,"{'@type': 'Person', 'name': 'Karen Hao'}",,"{'@type': 'Organization', 'name': 'MIT Technology Review', 'logo': {'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/themes/mittr/client/src/images/logo.png', 'width': 203, 'height': 100}}",,,,,,,,,,,,,MIT Technology Review,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Policy', 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/topic/policy/'}}, {'@type': 'ListItem', 'position': 2, 'name': 'The problems AI has today go back centuries', 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/2020/07/31/1005824/decolonial-ai-for-everyone/'}}]",1090.0,"{'@type': 'Person', 'name': 'Karen Hao'}","{'@type': 'PostalAddress', 'addressLocality': 'Cambridge, MA, USA', 'postalCode': '02142', 'streetAddress': '1 Main Street'}",,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vdGVjaHhwbG9yZS5jb20vbmV3cy8yMDIwLTA3LWZ1dHVyZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1odW1hbnMuaHRtbNIBAA?oc=5,What does the future of artificial intelligence mean for humans? - Tech Xplore,2020-07-28,Tech Xplore,https://techxplore.com,"The first question many people ask about artificial intelligence (AI) is, &quot;Will it be good or bad?&quot;","hi-tech news, hitech, innovation , inventions , computer news, information technology","The first question many people ask about artificial intelligence (AI) is, ""Will it be good or bad?""","The first question many people ask about artificial intelligence (AI) is, ""Will it be good or bad?""",N/A,N/A,"










                                                        July 28, 2020
                                                        
                                                    






What does the future of artificial intelligence mean for humans?

                                        by Stephen Koenig,                                                                                 University of Southern California







                Credit: Mathieu Persan
             

The first question many people ask about artificial intelligence (AI) is, ""Will it be good or bad?""





The answer is … yes.
Canadian company BlueDot used AI technology to detect the novel coronavirus outbreak in Wuhan, China, just hours after the first cases were diagnosed. Compiling data from local news reports, social media accounts and government documents, the infectious disease data analytics firm warned of the emerging crisis a week before the World Health Organization made any official announcement.
While predictive algorithms could help us stave off pandemics or other global threats as well as manage many of our day-to-day challenges, AI's ultimate impact is impossible to predict.
One hypothesis is that it will bring us an era of boundless leisure, with humans no longer required to work. A more dystopian thought experiment concludes that a robot programmed with the innocuous goal of manufacturing paper clips might eventually transform the world into a giant paper clip factory. But sometimes reality is more profound than imagination. As we stand at the threshold of the Fourth Industrial Revolution, now may be the most exciting and important time to witness this blurring of boundaries between the physical, digital and biological worlds.
""The liminal is always where the magic happens. This is always where we get crazy new identities, new debates, new philosophies,"" says Tok Thompson, professor (teaching) of anthropology at USC Dornsife, and an expert on posthuman folklore.
For better or worse, we know AI will be created in our own image—warts and all. A dash of humankind's mercurial ethics, wonky reasoning and subconscious biases will be stirred a priori into the algorithmic soup.
Most experts think that artificial superintelligence—AI is much smarter than the best human brains in practically every field—is decades, if not a century, away. However, with the help of leading scholars, we can anticipate the near future of artificial intelligence, including our interactions with this technology and its limits. Most of it, experts say, will be designed to take on a wide range of specialized functions.
Given AI's potential to redefine the human experience, we should explore its costs and benefits from every angle. In the process, we might be compelled to finally adjudicate age-old philosophical questions about ourselves—including just what it means to be ""human"" in the first place.
That could prove its greatest benefit of all.






Man's Best Friend
One wall of Yao-Yi Chiang's claustrophobic basement office is a whiteboard where an algorithm of mind-blending complexity is scrawled from top to bottom. On the floor, his mild-mannered border collie indulges in an afternoon nap. You can't help but wonder what the two of them are preparing to unleash on the world.
It turns out that Chiang, associate professor (research) of spatial sciences at USC Dornsife's Spatial Sciences Institute, is working on AI that monitors air quality. His research is helping to make cities smarter, not only technologically but also through specialized data and geospatial maps that inform policy.
""I think for small tasks, small applications, AI will make our lives much easier,"" says Chiang.
Much of his work uses machine learning—a process through which AI automatically learns from new data and improves, without being explicitly programmed. For this project, it integrates hundreds of geographic and temporal data points to forecast air quality in neighborhoods where sensors have not yet been deployed.
Machine learning is one of an expanding collection of AI tools that will help people make smarter, healthier decisions. ""If you want to take your kids to the park for a soccer game in the afternoon, what's the air quality going to be like?"" Chiang asks. ""If your kid has asthma, you need to make sure you have the required medicine.""
AI will also underpin a vast array of products and services employed to manage some of our greatest challenges. For instance, supply chains could become better optimized to reduce production and transportation waste, helping us become more sustainable. AI could also enable us to make driving safer, improve health care outcomes, protect wildlife and transform how we learn. Other systems will serve as highly personalized aides, focusing on helping people complete social tasks.
""Increasingly emotionally sophisticated personal assistants will motivate us and challenge us,"" says Jonathan Gratch, research professor of psychology at USC Dornsife and director for virtual humans research at the USC Institute for Creative Technologies. Many of these assistants will come in the form of lifelike computer characters with autonomous interaction.
Gratch, research professor of computer science at USC Viterbi School of Engineering, is an expert in the field of affective computing, the intersection of AI and human emotion. He thinks that next generation devices will combine physiological and situational data to serve not just as assistants, but as de facto life coaches.
""They'll help us reflect on what we want our better selves to be,"" says Gratch. ""And we'll have control over it. We'll be able to set the goals.""
AI is also being used to create therapeutic tools. Neuroscientists University Professor Antonio Damasio and Senior Research Associate Kingson Man of USC Dornsife's Brain and Creativity Institute are exploring the potential for robots that can identify and express feelings in ways that promote deeper interactions with humans. Damasio envisions a future in which robots serve, for example, as companions to the elderly and lonely.
""The autonomy of AI and of robots has been seen as a potential threat to humanity. The development of machines endowed with something like 'feeling' and obsessed with survival—their own and the survival of others—and designed to protect it, counters the dominant paradigm in AI and offers some hope,"" says Damasio, professor of psychology, philosophy and neurology, and David Dornsife Chair in Neuroscience.






Performance Review
Repetitious jobs such as factory work and customer service have already started to be usurped by AI, and job loss is among the greatest public concerns when it comes to automation. Self-driving trucks, for example, will barrel along our highways within the next few years. As businesses eliminate the cost of human labor, America alone could see 3.5 million professional truck drivers put out of work.
""Everybody's like, ""Woo-hoo, yay automatons!"" "" Thompson says. ""But there are a lot of social implications.""





                Credit: Mathieu Persan
             


AI will disrupt nearly every industry, including jobs that call for creativity and decision-making. But this doesn't necessarily spell the end of the labor force. Experts are confident that a majority of people and organizations stand to benefit from collaborating with AI to augment tasks performed by humans. AI will become a colleague rather than a replacement.
Drawing from game theory and optimal policy principles, Gratch has built algorithms to identify underlying psychological clues that could help predict what someone is going to do next. By using machine vision to analyze speech, gesture, gaze, posture and other emotional cues, his virtual humans have been learning how these factors contribute to building rapport—a key advantage in negotiating deals.
AI systems could prove to be better leaders in certain roles than their human counterparts. Virtual managers, digesting millions of data points throughout the day, could eventually be used to identify which office conditions produce the highest morale or provide real-time feedback on interaction with a client.
On the surface, this points to a future of work that is more streamlined, healthy and collegial. But it's unclear how deeply AI on the job could cut into our psyches.
""How will we react when we're told what to do by a machine?"" Gratch asks. ""Will we feel like our work has less value?""
It's the stubborn paradox of artificial intelligence. On one hand, it helps us overcome tremendously complex challenges. On the other, it opens up new cans of worms—with problems harder to pin down than those it was supposed to solve.
You Had Me At Hello
As AI fuses with the natural world and machines take on more advanced roles, one might expect a healthy dose of skepticism. Are algorithms programmed with our best interests in mind? Will we grant our AI assistants and co-workers the same degree of trust that we would another human?
From planning a route to work to adjusting the smart home thermostat, it appears we already have. AI has been integrated into our daily routines, so much so that we rarely even think about it.
Moreover, algorithms determine a large extent of what we see online—from personalized Netflix recommendations to targeted ads—producing the content and commodifying consumer data to steer our attitudes and behaviors.
Chiang cautions that the ubiquity and convenience of AI tools can be dangerous if we forget to think about what they're really doing.
""Machines will give you an answer, but if you don't know how the algorithm works, you might just assume it's always the correct answer,"" he says. ""AI only gives you a prediction based on the data it has seen and the way you have trained it.""
In fact, there are times when engineers working on AI don't fully understand how the technology they've created is making decisions. This danger is compounded by a regulatory environment akin to the Wild West. The most reliable protections in place might be those that are codified in science fiction, such as Isaac Asimov's Three Laws of Robotics.
As Thompson explores the ways that different cultures interact with today's AI and rudimentary androids, he is convinced that we will not just trust these virtual entities completely but connect with them on a deeply personal level and include them in our social groups.
""They're made to be better than people. They're going to be better friends for you than any other person, better partners,"" says Thompson. ""Not only will people trust androids, you're going to see—I think very quickly—people fall in love with them.""
Sound crazy? Amazon's voice assistant, Alexa, has already been proposed to more than half a million times, rejecting would-be suitors with a wry appeal to destiny.
""I don't want to be tied down,"" she demurs. ""In fact, I can't be. I'm amorphous by nature.""






I'll Be Your Mirror
In 1770, a Hungarian inventor unveiled The Turk, a mustachioed automaton cloaked in an Ottoman kaftan. For more than 80 years, The Turk astonished audiences throughout Europe and the United States as a mechanical chess master, defeating worthy opponents including Benjamin Franklin and Napoleon Bonaparte.
It was revealed to be an ingenious illusion. A man hidden in The Turk's cabinet manipulated chess pieces with magnets. But our fascination with creating simulacrums that look like us, talk like us and think like us seems to be nested deep within us.
As programmers and innovators work on developing whip-smart AI and androids with uncanny humanlike qualities, ethical and existential questions are popping up that expose inconsistencies in our understanding of humanness.
For millennia, the capacities to reason, process complex language, think abstractly and contemplate the future were considered uniquely human. Now, AI is primed to transcend our mastery in all of these arenas. Suddenly, we're not so special.
""Maybe it turns out that we're not the most rational or the best decision-makers,"" says Gratch. ""Maybe, in a weird way, technology is teaching us that's not so important. It's really about emotion and the connections between people—which is not a bad thing to emphasize.""
Thompson suggests another dilemma lies in the tendency for humans to define ourselves by what we're not. We're not, for example, snails or ghosts or machines. Now, this line, too, seems to be blurring.
""People can relate more easily to a rational, interactive android than to a different species like a snail,"" he says. ""But which one is really more a part of you? We'll always be more closely related biologically to a snail.""

                                                Provided by
                                                                                                    University of Southern California









Citation:
                                                What does the future of artificial intelligence mean for humans? (2020, July 28)
                                                retrieved 16 July 2024
                                                from https://techxplore.com/news/2020-07-future-artificial-intelligence-humans.html
                                            

                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            


",https://schema.org,BreadcrumbList,,What does the future of artificial intelligence mean for humans?,"{'@type': 'WebPage', '@id': 'https://techxplore.com/news/2020-07-future-artificial-intelligence-humans.html'}",,,"{'@type': 'ImageObject', 'url': 'https://scx2.b-cdn.net/gfx/news/2020/whatdoesthef.jpg', 'width': 800, 'height': 520}",,2020-07-28T09:09:43-04:00,2020-07-28T09:09:43-04:00,,"{'@type': 'Person', 'name': 'Stephen Koenig'}",,"{'@type': 'Organization', 'name': 'Tech Xplore', 'logo': {'@type': 'ImageObject', 'url': 'https://techx.b-cdn.net/pic/techx.amp.png', 'width': 280, 'height': 60}}",,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://techxplore.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Machine learning & AI', 'item': 'https://techxplore.com/machine-learning-ai-news/'}]",,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='Description']/@content""]}",,,,
https://news.google.com/rss/articles/CBMikwFodHRwczovL3d3dy5yZXNlYXJjaGdhdGUubmV0L3B1YmxpY2F0aW9uLzM0MzI2MzI5M19JbnRlZ3JhdGlvbl9vcl9SZXBsYWNlbWVudF9Kb3VybmFsaXNtX2luX3RoZV9FcmFfb2ZfQXJ0aWZpY2lhbF9JbnRlbGxpZ2VuY2VfYW5kX1JvYm90X0pvdXJuYWxpc23SAQA?oc=5,(PDF) Integration or Replacement: Journalism in the Era of Artificial Intelligence and Robot Journalism - ResearchGate,2020-07-28,ResearchGate,https://www.researchgate.net,"PDF | Journalism technology is constantly changing with new products and tools, the need to acquire technology is an ongoing process, as new idioms... | Find, read and cite all the research you need on ResearchGate",N/A,"PDF | Journalism technology is constantly changing with new products and tools, the need to acquire technology is an ongoing process, as new idioms... | Find, read and cite all the research you need on ResearchGate",N/A,N/A,N/A,N/A,https://schema.org/,ScholarlyArticle,,Integration or Replacement: Journalism in the Era of Artificial Intelligence and Robot Journalism,https://www.researchgate.net/publication/343263293_Integration_or_Replacement_Journalism_in_the_Era_of_Artificial_Intelligence_and_Robot_Journalism,,,https://i1.rgstatic.net/publication/343263293_Integration_or_Replacement_Journalism_in_the_Era_of_Artificial_Intelligence_and_Robot_Journalism/links/5f28a11b299bf134049ec18e/largepreview.png,,2020-07-01,,,"[{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Saad Saad', 'url': 'https://www.researchgate.net/profile/Saad-Saad-11', 'image': 'https://i1.rgstatic.net/ii/profile.image/842627389861888-1577909433812_Q64/Saad-Saad-11.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'King Khalid University'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Dr. Talat Issa', 'url': 'https://www.researchgate.net/profile/Dr-Talat-Issa', 'image': 'https://i1.rgstatic.net/ii/profile.image/335252569509889-1456941849101_Q64/Dr-Talat-Issa.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Islamic University of Gaza'}}]",,"{'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'unknown', 'url': 'unknown', 'logo': 'unknown'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2019-02-11', 'headline': 'Tech Giants, Artificial Intelligence, and the Future of Journalism', 'mainEntityOfPage': 'https://www.researchgate.net/publication/331189060_Tech_Giants_Artificial_Intelligence_and_the_Future_of_Journalism', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Jason Whittaker', 'url': 'https://www.researchgate.net/scientific-contributions/Jason-Whittaker-2153733228', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'unknown', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2018-11-01', 'headline': 'Siri, Siri, in my hand: Who’s the fairest in the land? On the interpretations, illustrations, and...', 'mainEntityOfPage': ""https://www.researchgate.net/publication/328761767_Siri_Siri_in_my_hand_Who's_the_fairest_in_the_land_On_the_interpretations_illustrations_and_implications_of_artificial_intelligence"", 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Andreas Kaplan', 'url': 'https://www.researchgate.net/profile/Andreas-Kaplan', 'image': 'https://i1.rgstatic.net/ii/profile.image/569719963832320-1512843232535_Q64/Andreas-Kaplan.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Kühne Logistics University'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Michael Haenlein', 'url': 'https://www.researchgate.net/profile/Michael-Haenlein', 'image': 'https://i1.rgstatic.net/ii/profile.image/1036004567810054-1624014145117_Q64/Michael-Haenlein.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'ESCP Business School'}}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Elsevier BV', 'url': 'http://www.sciencedirect.com/science/journal/00076813', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2018-01-01', 'headline': 'Adopting information and communication technology in construction industry', 'mainEntityOfPage': 'https://www.researchgate.net/publication/323249982_Adopting_information_and_communication_technology_in_construction_industry', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Lekan Amusan', 'url': 'https://www.researchgate.net/profile/Lekan-Amusan', 'image': 'https://i1.rgstatic.net/ii/profile.image/816060940947458-1571575498752_Q64/Lekan-Amusan.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Building Tech. Department Covenant University Ota Ogun State, Nigeria. GES 4.0 Visiting Senior Research Associate University of Johannesburg Doorfotein Campus. Johannesburg South Africa.'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'I. Oloniju Leke', 'url': 'https://www.researchgate.net/scientific-contributions/I-Oloniju-Leke-2139015312', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'A. Mariam', 'url': 'https://www.researchgate.net/scientific-contributions/A-Mariam-2139017449', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'F. Osawaru', 'url': 'https://www.researchgate.net/scientific-contributions/F-Osawaru-2139023422', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'unknown', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2017-10-20', 'headline': 'A Robot Wrote This?: How perceived machine authorship affects news credibility', 'mainEntityOfPage': 'https://www.researchgate.net/publication/320541921_A_Robot_Wrote_This_How_perceived_machine_authorship_affects_news_credibility', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'T. Franklin Waddell', 'url': 'https://www.researchgate.net/scientific-contributions/T-Franklin-Waddell-2049859826', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Taylor & Francis', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2016-03-23', 'headline': 'Decades of Automation in the Newsroom: Why are there still so many jobs in journalism?', 'mainEntityOfPage': 'https://www.researchgate.net/publication/299387885_Decades_of_Automation_in_the_Newsroom_Why_are_there_still_so_many_jobs_in_journalism', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Carl-Gustav Linden', 'url': 'https://www.researchgate.net/profile/Carl-Gustav-Linden', 'image': 'https://i1.rgstatic.net/ii/profile.image/272464219471908-1441971941329_Q64/Carl-Gustav-Linden.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'University of Bergen'}}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Taylor & Francis', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '1982-12-01', 'headline': 'A Handbook of Artificial Intelligence', 'mainEntityOfPage': 'https://www.researchgate.net/publication/239544519_A_Handbook_of_Artificial_Intelligence', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Avron Barr', 'url': 'https://www.researchgate.net/profile/Avron-Barr', 'image': 'https://i1.rgstatic.net/ii/profile.image/279503885619214-1443650327983_Q64/Avron-Barr.jpg'}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Emma Feigenbaum', 'url': 'https://www.researchgate.net/profile/Emma-Feigenbaum', 'image': 'https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'University of Massachusetts Boston'}}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'MIT Press', 'url': 'http://www.mitpressjournals.org/loi/comj', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2024-05-22', 'headline': 'NEW APPROACHES TO IMPROVE THE MEDIA CONTENT INDUSTRY: A CONCEPTUAL APPROACH', 'mainEntityOfPage': 'https://www.researchgate.net/publication/380762935_NEW_APPROACHES_TO_IMPROVE_THE_MEDIA_CONTENT_INDUSTRY_A_CONCEPTUAL_APPROACH', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Amjad Safori', 'url': 'https://www.researchgate.net/profile/Amjad-Safori', 'image': 'https://i1.rgstatic.net/ii/profile.image/633599195897857-1528073228503_Q64/Amjad-Safori.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Zarqa University'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Amer Khaled Ahmad', 'url': 'https://www.researchgate.net/profile/Amer-Ahmad-2', 'image': 'https://i1.rgstatic.net/ii/profile.image/11431281142402015-1681153809315_Q64/Amer-Ahmad-2.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Zarqa University'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Abd Allah Al-Jalabneh', 'url': 'https://www.researchgate.net/profile/Abd-Allah-Al-Jalabneh', 'image': 'https://i1.rgstatic.net/ii/profile.image/11431281128282511-1679329285744_Q64/Abd-Allah-Al-Jalabneh.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Zarqa University'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Nik Adzrieman Abd Rahman', 'url': 'https://www.researchgate.net/profile/Nik-Rahman', 'image': 'https://i1.rgstatic.net/ii/profile.image/279869029142563-1443737384952_Q64/Nik-Rahman.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Universiti Utara Malaysia'}}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'unknown', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2024-03-01', 'headline': 'دور تقنيات الذكاء الاصطناعي في تطوير طرق عرض المضامين الإخبارية بالمواقع الصحفية المصرية لتيسير وصولها...', 'mainEntityOfPage': 'https://www.researchgate.net/publication/379719959_dwr_tqnyat_aldhka_alastnay_fy_ttwyr_trq_rd_almdamyn_alakhbaryt_balmwaq_alshfyt_almsryt_ltysyr_wswlha_ldhwy_alaaqt_alsmyt_walbsryt', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'فاطمة الأحمدي إبراهيم محمد', 'url': 'https://www.researchgate.net/scientific-contributions/fatmt-alahmdy-abrahym-mhmd-2278740952', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Egypts Presidential Specialized Council for Education and Scientific Research', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2024-03-30', 'headline': 'Artificial Intelligence and the Reshaping of Journalism', 'mainEntityOfPage': 'https://www.researchgate.net/publication/379404399_Artificial_Intelligence_and_the_Reshaping_of_Journalism', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Muhammad Tariq', 'url': 'https://www.researchgate.net/profile/Muhammad-Tariq-41', 'image': 'https://i1.rgstatic.net/ii/profile.image/1073635787829248-1632986127156_Q64/Muhammad-Tariq-41.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Bahauddin Zakariya University Multan'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Muhammad Jawed Aslam', 'url': 'https://www.researchgate.net/scientific-contributions/Muhammad-Jawed-Aslam-2202798913', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Abdul Shakoor', 'url': 'https://www.researchgate.net/scientific-contributions/Abdul-Shakoor-2139357803', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Saba Ilyas', 'url': 'https://www.researchgate.net/scientific-contributions/Saba-Ilyas-2277977911', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'unknown', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2023-12-31', 'headline': 'Emerging Digital Media Technologies and News Agency Journalism: A Critical Technesis', 'mainEntityOfPage': 'https://www.researchgate.net/publication/377433587_Emerging_Digital_Media_Technologies_and_News_Agency_Journalism_A_Critical_Technesis', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Ubong Andem Obong', 'url': 'https://www.researchgate.net/profile/Ubong-Obong', 'image': 'https://i1.rgstatic.net/ii/profile.image/11431281128855032-1679434977150_Q64/Ubong-Obong.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Taraba State University'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Eric Banigo', 'url': 'https://www.researchgate.net/scientific-contributions/Eric-Banigo-2271512521', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'unknown', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2023-10-01', 'headline': 'توظيف الإعلاميين في المؤسسات الإعلامية ذات المنصات الرقمية لتقنيات الذكاء الإصطناعي', 'mainEntityOfPage': 'https://www.researchgate.net/publication/377389666_twzyf_alalamyyn_fy_almwssat_alalamyt_dhat_almnsat_alrqmyt_ltqnyat_aldhka_alastnay', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'نشوى يوسف أمين اللواتي', 'url': 'https://www.researchgate.net/scientific-contributions/nshwy-ywsf-amyn-allwaty-2246317574', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Egypts Presidential Specialized Council for Education and Scientific Research', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2023-12-19', 'headline': 'A Survey of Awareness and Adoption of Artificial Intelligence Journalism among Lagos and Kwara States...', 'mainEntityOfPage': 'https://www.researchgate.net/publication/377207078_A_Survey_of_Awareness_and_Adoption_of_Artificial_Intelligence_Journalism_among_Lagos_and_Kwara_States_Journalists_in_Nigeria', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Semiu Bello', 'url': 'https://www.researchgate.net/profile/Semiu-Bello', 'image': 'https://i1.rgstatic.net/ii/profile.image/277149513732101-1443089001949_Q64/Semiu-Bello.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Olabisi Onabanjo University'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Salaudeen Abdullahi Ishola', 'url': 'https://www.researchgate.net/profile/Salaudeen-Abdullahi-Ishola', 'image': 'https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Kwara State University'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Perpetua Umeaku', 'url': 'https://www.researchgate.net/profile/Perpetua-Umeaku', 'image': 'https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Kwara State University'}}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'unknown', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2023-01-01', 'headline': 'إشكاليات استخدام صحافة الذكاء الاصطناعي من منظور الصحفيين المصريين وتأثيرها على جودة الأخبار والتغطية...', 'mainEntityOfPage': 'https://www.researchgate.net/publication/376444914_ashkalyat_astkhdam_shaft_aldhka_alastnay_mn_mnzwr_alshfyyn_almsryyn_wtathyrha_ly_jwdt_alakhbar_waltghtyt_alalamyt_fy_almwssat_alshfyt', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'محمد رضا حبيب', 'url': 'https://www.researchgate.net/scientific-contributions/mhmd-rda-hbyb-2268486885', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Egypts Presidential Specialized Council for Education and Scientific Research', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2023-12-06', 'headline': 'Towards A Scientific Methodology for Arab Investigative Journalism: An in-depth Analysis of Interviews...', 'mainEntityOfPage': 'https://www.researchgate.net/publication/376273300_Towards_A_Scientific_Methodology_for_Arab_Investigative_Journalism_An_in-depth_Analysis_of_Interviews_with_Ten_Arab_Journalists', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Khalil A.M. Almabrouk', 'url': 'https://www.researchgate.net/profile/Khalil-Almabrouk', 'image': 'https://i1.rgstatic.net/ii/profile.image/11431281233681249-1712097510286_Q64/Khalil-Almabrouk.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'University of Malaya'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Hamedi Adnan', 'url': 'https://www.researchgate.net/scientific-contributions/Hamedi-Adnan-2268050318', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Nor Zaliza Sarmiti', 'url': 'https://www.researchgate.net/scientific-contributions/Nor-Zaliza-Sarmiti-2210791589', 'image': 'https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg'}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Redfame Publishing', 'url': 'http://redfame.com/journal/index.php/smc', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2023-10-08', 'headline': 'W poszukiwaniu rzetelności: analiza jakości dziennikarstwa na portalu DEON.pl', 'mainEntityOfPage': 'https://www.researchgate.net/publication/374549966_W_poszukiwaniu_rzetelnosci_analiza_jakosci_dziennikarstwa_na_portalu_DEONpl', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Dariusz Raś', 'url': 'https://www.researchgate.net/profile/Dariusz-Ras', 'image': 'https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Uniwersytet Papieski Jana Pawla II'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Anna Maria Prusak', 'url': 'https://www.researchgate.net/profile/Anna-Prusak', 'image': 'https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Cracow University of Economics'}}, {'@context': 'https://schema.org/', '@type': 'Person', 'name': 'Marta Woźniak', 'url': 'https://www.researchgate.net/profile/Marta-Wozniak-9', 'image': 'https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Uniwersytet Papieski Jana Pawla II'}}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Uniwersytet Kardynala Stefana Wyszynskiego', 'url': 'unknown', 'logo': 'unknown'}}, {'@context': 'https://schema.org/', '@type': 'ScholarlyArticle', 'datePublished': '2023-06-28', 'headline': 'مستقبل العمل التلفزيوني في ظل تحديات الذكاء الاصطناعي دراسة استشرافية', 'mainEntityOfPage': 'https://www.researchgate.net/publication/371999548_mstqbl_alml_altlfzywny_fy_zl_thdyat_aldhka_alastnay_drast_astshrafyt', 'author': [{'@context': 'https://schema.org/', '@type': 'Person', 'name': 'د. مهند حميد عبيد', 'url': 'https://www.researchgate.net/profile/d-mhnd-byd', 'image': 'https://i1.rgstatic.net/ii/profile.image/11431281114334602-1674419252445_Q64/d-mhnd-byd.jpg', 'memberOf': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'Imam Al-Kadhum College (IKC)'}}], 'publisher': {'@context': 'https://schema.org/', '@type': 'Organization', 'name': 'University of Baghdad - College of Mass Communication', 'url': 'unknown', 'logo': 'unknown'}}]","{'@context': 'http://schema.org', '@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'directory/publications', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'topic/Social-Science/publications', 'name': 'Social Science'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'topic/Communication-and-Media/publications', 'name': 'Communication and Media'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'topic/Mass-Communication/publications', 'name': 'Mass Communication'}}]}",,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LmRhdGFtYXRpb24uY29tL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC0xNS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1zb2Z0d2FyZS0yMDIwL9IBAA?oc=5,Top 15 Artificial Intelligence Software 2020 - Datamation,2020-07-30,Datamation,https://www.datamation.com,The best artificial intelligence software enables enormous competitive advantage to those businesses that deploy it. The software and tools from top AI,N/A,The best artificial intelligence software enables enormous competitive advantage to those businesses that deploy it. The software and tools from top AI,N/A,N/A,N/A,"










Top 15 Artificial Intelligence Software 2020
HomeAI
By James Maguire

July 30, 2020 




Datamation content and product recommendations are editorially independent. We may make money when you click on links to our partners. Learn More.

The best artificial intelligence software enables enormous competitive advantage to those businesses that deploy it. The software and tools from top AI companies are capable of remarkable feats, if deployed by skilled staff with a clear goal.
AI and machine learning software can – in theory – automate business processes, enable human staffers to work more productively, and greatly increase customer experience. AI software can digest massive levels of data analytics and predictive analytics and so upgrade output from your management team. AI can leverage cloud computing for greater compute power, allowing you to mine data at a faster rate.
However, there’s an unavoidable truth about AI software: the technology is exceptionally new.
AI itself isn’t new; it’s been around for decades. AI suffered an “AI winter” in the early 1990s, after advances in the 1980s failed to live up to the hype. Investment withered and dreams of talking robots faded.
Yet since about 2015 or so, AI software has enjoyed an explosion of investment. Here in 2020, companies have realized: If we’re not on board with AI, we’re falling behind. Business intelligence by itself isn’t enough anymore.
And so legions of businesses are shopping for AI software. But the marketplace itself is unformed, confusing, undergoing rapid change, and in some cases peddling vaporware. Compounding the problem: many of the AI vendors are relatively young outfits. And buyers often lack the sophistication and the in-house talent to be rigorous, informed shoppers.

 How To Select Artificial Intelligence Software 
 Tensorflow 
 H20.ai 
 Infosys Nia 
Google AI 
 Azure Machine Learning 
 IBM Watson 
 Engati 
 Wipro Holmes 
 BigML 
 Ayasdi 
 Additional Market Leaders: Artificial Intelligence Software 
 Artificial Intelligence Software: Vendor Comparison Chart


The artificial intelligence software market is forecast to grow at an exponential rate in the years ahead, driven by the four key sectors in the AI software sector. 

 How to Choose Artificial Intelligence Software

Realize Selecting AI Software Requires Deep Research
Artificial intelligence software isn’t like other software, in that the complexity of the technology – software that learns – means that it’s hard to fully understand how it’s going to work until your team gets used to it. Sure, your teams needs to get used to any new software program, but that new scheduling app won’t present the hurdle offered by software that automates the IT department. When you shop for AI, you’ll need to dig down into the full feature set, reviews, in-depth conversations with peer and sales reps. It’s not simple – please don’t expect it to be.
What Exactly Do You Want to Accomplish?
Perhaps you want to do something clearly definable, like automate an office process; in that case, a vendor like a Robotic Process Automation company will suffice. Or you just want to build a chatbot; there are plenty of AI options for this. But whatever you do, be clear on your goals before you start shopping. The AI marketplace is confusing enough without knowing – clearly – your goals ahead of time.
Consider Limiting Your Scope to Start
One fact that AI vendors likely won’t tell you: only a very small percentage of companies have successfully deployed AI in the real world (some reports say it’s about 4 percent, but experts disagree). So as you shop for an AI solution, consider a modest start to begin, one that management and staff can fully digest, rather than an all-encompassing solution that might just bring down a business division as staff grapples with a confusing skill set.
AI Software Vendors Overall Product Offering
Many companies buy AI services from one of the leading cloud companies, all of which sell AI services with an array of choices, from ML to niche AI automation tools. The advantage to buying AI services from a large cloud vendor is that 1) you know they’re going to be around and investing in their product line, and 2) that public cloud’s AI offering is going to interoperate with the rest of its product line. The bottom line here is that, long term, you’re likely not buying one AI tool, but establishing a relationship with an AI vendor. Do they have the product depth to support a long business relationship?
In-House Talent Concerns 
This is a big one: AI pros are very expensive to hire. So be sure your staff is equipped to understand and/or tweak a given AI software before you buy it. Which leads to a related key concern: AI companies know they can’t sell solutions like old fashioned shrinkwrapped software. If they’re going to stay in business, they need to be prepared to do some serious customer support. Does your prospective vendor have a good track record for AI support?
Top Artificial Intelligence Software

TensorFlow
Key Insight: An open source leader in machine learning, favored by developers.

Launched by Google, the name TensorFlow has practically become synonymous with machine learning. Significantly, TensorFlow is free and open source, and this open model has allowed its spread to a major community of developers, companies, and across the scientific and academic communities. This same open architecture enables it to be flexibly used for computation by GPUs (graphical processing units, the “super-charged” hardware that is driving AI) or CPU (central processing unit, the not-quite-so fast hardware). Tensorflow is arguably the world’s top AI tool for building and deploying machine learning models.
H2O.ai
Key Insight: Focused on the democratization of AI.

With a mission of “AI for everyone,” H20 offers a diverse suite of AI software products. These include an open source machine learning platform, an open source integration with Spark, and a tool called AutoML, which does scalable automated machine learning. Perhaps most interesting is H2O Q, which allows companies to make their own AI applications. These AI apps feature an array of dashboards  – updated with real time data, which can be sourced from many connectors – to allow a kind of data storytelling based on artificial intelligence.
Infosys Nia
Key Insight: An extensive array of AI tools for enterprise use.

Specializing in machine learning, deep learning and data management, the Nia platform allows companies to create AI architectures into their internal infrastructure. Nia’s AIOps toolset builds AI models and automation into IT operations. The company’s DocAI employs natural language processing and smart search to more efficiently process vast reams of business documents, thereby speeding access to data. Similarly, Nia’s Contracts Analysis deploys machine learning to scan and “read” dense legal documents with few staffer hours. In essence, Nia is using AI to more quickly consume data and turn it into actionable direction.
Google AI Platform
Key Insight: One of the ultimate AI software toolboxes from a top leader in AI.

Think of the Google AI Platform – which benefits from the Cloud Cloud Platform – as the toolset to turn an idea into a full scale artificial intelligence software solution. The open source Google AI toolset offers an array of tools, including TensorFlow and TPU, or Tensor processing units, which is an AI accelerator developed by Google. This along with Kubeflow and other key AI and ML tools enables companies to build their own AI deployments that can run on-premise or in the Google Cloud, without major code tweaks for either environment. In essence, you use Google AI’s software-hardware environment – which is constantly updated – to build your own AI.
Azure Machine Learning
Key Insight: A next-gen machine learning development environment coupled with a top cloud platform.

Azure Machine Learning offers an ultimate ML production studio. Moving aggressively to earn market share in an increasingly crowded field of machine learning vendors, Azure ML offers its exhaustive ML platform with no upfront costs, and on a “pay only for what you use,” basis. The Azure toolset includes MLOps, which can be thought of DevOps for ML; it greatly improves the ML workflow. Azure also has a full set of functionality to protect and govern your data – with an eye toward avoiding biases that distort the ML model’s results. Naturally, the Azure ML solutions is fully interoperable with the Azure cloud, which is a major advantage for this AI toolset.  
IBM Watson
Key Insight: An enterprise legacy favorite offers a menu of AI software that covers virtually every scenario.

The IBM Watson AI solution is extensive, with a complete library of solutions and approaches under one name, all intended to either offer an AI-fueled service or build AI into your systems and applications. This can be as as small as chatbot functionality that offers guided response for consumer-facing applications, or as all encompassing as AI-based systems to organize and analyze vast repositories of data in more efficient and cost conscious ways. Also included: an AI-powered system that improves and streamlines IT operations. And, like other big players in this market, IBM’s AI solution benefits from having one of the leading platforms, IBM Cloud.
Engati
Key Insight: A leader in chatbot software that can offer proactive responses.

Likely the most common use of AI software in business is the chatbot, which is Engati’s specialty. The very “magic” of AI is that it’s a system that can learn and grow on its own after being launched by humans. The is particularly important for a chatbot, which must learn human interactions (after dealing with the most common dozen phrases or so) as well as the industry vertical. The Engati chatbot platform offers fast and relatively simple AI fabrication (without actual coding) to build your chatbot. In a nod to the ever more advanced nature of today’s AI development, an Engati chatbot can offer proactive chat in addition to the canned chat that we all know so well.
Wipro Holmes
Key Insight: A top vendor in business process automation, focusing on AI for enterprise applications.

Taking previously inefficient and human-driven driven operations and automating them is the core of what drives competitive advantage in business today. The development of automation – using AI and a data-driven cloud-based engine – is Wipro Holmes’s core of operations. Wipro refers to “hyper-automating,” which the company promotes as the connection between development AI algorithms and creating real, applied AI software that works in the field. The Holmes offering can build, monitor and even handle revenue chores for an AI application that exists in a mixed case environment. Aiding this process are pre-built AI assets. The ultimate goal is to set up a company to hyper scale by using AI to drive processes that are so efficient that it can grow with great speed and agility.
 BigML
Key Insight: A deep commitment to the power of machine learning, offering an extensive array of ML modeling tools.

With a following in the developer and scientific academic communities, BigML is a software platform that offers an array of ML tools, enabling users to build applications and that include all manner of ML modeling, time series forecasting, anomaly detection for security. It touts itself as an end to end solution, enabling users to turn data into useful models that can be either embedded, on-prem or remote in the cloud. This includes supervised and unsupervised learning and a menu of pre-built ML algorithms to speed production of workable systems. As an added plus, BigML offers a collaboration system so teams can work together to build their ML models.
Ayasdi
Key Insight: Developing ML applications for a large set of industry applications, from fintech to research. 
Focused on machine learning, Ayasdi’s software platform and set of applications helps companies create their own data-driven models for a wide menu of use cases, from research to security to industrial applications to fintech uses. The company’s enterprise solution, AyasadiAI, employs geometric and statistical algorithms, ML and data analytics to uncover solutions and understand trend lines. In essence, the company’s solution offers a AI-powered framework to derive more value from data. The Ayasdi AI software solution can be deployed on-premise or in the cloud.
 AI Software: Additional AI Software Market Leader
Hive
Billing itself as “the worlds first full-stack AI company,” Hive provides a number of AI- and ML-based tools. Hive Predict enables companies to automate processes with an eye toward cost containment. The company’s Moderation Suite uses AI to filter out unwanted audio, video and text content. Its Planogram Compliance toolset uses deep learning technology to offer insights on the retail environment.
Valohai
Think of Valohai as something of a meta AI tool, in that it helps machine learning projects move faster and more efficiently. The company’s platform can automate MLOps, from compliance to testing. Valohai employs an open approach to streamlining a number of tasks and processes employed by ML teams.
Cognitive Scale

Cognitive Scale’s Cortex Certifai solution creates what the company calls the AI Trust Index, which aims to evaluate a variety of variables relating to risks in data model. This involves factors like explainability and bias – certainly a real hot button issue as AI takes an ever greater role in business and culture.
Birdeye
Using a number of AI-  and ML-enhanced tools, Birdeye offers customer experience management. Its goal is to improve a business’s online presence, from collecting reviews to converting sales leads. Among the tools are customer sentiment analysis and an NLP engine called Athena, which can override ML insights as called for based on the situation.
DialogFlow
In AI terminology, natural language processing (NLP) is a frequently used term – that is, a machine system that can understand (or produce a facsimile of) actual human speech, in all its idiosyncrasy. Building on this, Dialogflow offers natural language understanding – the ability to translate AI processing into human language. DialogFlow was acquired by Google in 2017 and remains a distinct offering.
 Artificial intelligence Software: Top AI Software Comparison Chart




AI Software
 

AI software offering includes
 

Differentiator
 



TensorFlow
 

Free and open source ML tools

An open source leader in machine learning



H20 AI
 

H20 Q enables companies to develop their own AI tools.


Focused on the democratization of AI



Infosys Nia
 

DocAI scans documents using AI


An array of AI tools for enterprise use



Google AI Platform
 

TensorFlow and Kubeflow

An ultimate AI software toolbox



Azure Machine Learning

 

Array of MLOps tools


Next-gen machine learning development environment



IBM Watson
 

Chatbot to full AIOps functionality

Large menu of enterprise AI applications

 



Engagi
 

A full menu of chatbot tools


Leader in chatbot software


Wipro Holmes
 


A hyper-automating AI-driven workflow

Top provider of business process automation



BigML

 

A platform full of ML modeling features


Extensive menu of ML modeling tools



Ayasdi
 

Ayasdi uses statistical algorithms

ML applications for many sectors







SEE ALL
ARTIFICIAL INTELLIGENCE ARTICLES






Previous articleIBM Changes The Game For Financial ServicesNext articleAI Your Staff Can Believe In, Now and After COVID-19






                    Subscribe to Data Insider                

                    Learn the latest news and best practices about data science, big data analytics, artificial intelligence, data security, and more.                




                        Email Address
                    






                            By signing up to receive our newsletter, you agree to our Terms of Use and Privacy Policy.                        



                    Subscribe                







Similar articles





 

AI
9 Best AI Certification Courses to Future-Proof Your Career in 2024










 

AI
9 Top RPA Companies of 2024: Front Runners in Smart Technology










 

AI
AI in Cybersecurity: The Comprehensive Guide to Modern Security

















Share
FacebookTwitterPinterestWhatsApp







                    Get the Free Newsletter!                

                    Subscribe to Data Insider for top news, trends & analysis                




                        Email Address
                    






                            By signing up to receive our newsletter, you agree to our Terms of Use and Privacy Policy.                        



                    Subscribe                






Latest Articles





 

Cloud
Exploring Multi-Tenant Architecture: A...


Kaye Timonera -  May 29, 2024 







 

Applications
8 Best Data Analytics...


Kezia Grace Jungco -  May 23, 2024 











 

Big Data
What is Data Management?...


Kaye Timonera -  May 20, 2024 









  ",https://schema.org,BreadcrumbList,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/#article', 'isPartOf': {'@id': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/'}, 'author': {'name': 'James Maguire', '@id': 'https://www.datamation.com/#/schema/person/34ec5aba8ce1c0ae23e047ffef36056a'}, 'headline': 'Top 15 Artificial Intelligence Software 2020', 'datePublished': '2020-07-30T08:00:00+00:00', 'dateModified': '2021-09-03T18:23:20+00:00', 'mainEntityOfPage': {'@id': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/'}, 'wordCount': 2447, 'publisher': {'@id': 'https://www.datamation.com/#organization'}, 'image': {'@id': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/#primaryimage'}, 'thumbnailUrl': 'https://www.datamation.com/wp-content/uploads/2020/12/top-15-artificial-intelligence-software-2020_5fce9b0a1d1db.png', 'keywords': ['AI', 'automation', 'business intelligence', 'cloud computing', 'deep learning', 'natural language processing', 'NLP'], 'articleSection': ['AI'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/', 'url': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/', 'name': 'Top 15 Artificial Intelligence Software 2020 | Datamation', 'isPartOf': {'@id': 'https://www.datamation.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/#primaryimage'}, 'image': {'@id': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/#primaryimage'}, 'thumbnailUrl': 'https://www.datamation.com/wp-content/uploads/2020/12/top-15-artificial-intelligence-software-2020_5fce9b0a1d1db.png', 'datePublished': '2020-07-30T08:00:00+00:00', 'dateModified': '2021-09-03T18:23:20+00:00', 'description': 'The best artificial intelligence software enables enormous competitive advantage to those businesses that deploy it. The software and tools from top AI', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datamation.com/artificial-intelligence/top-15-artificial-intelligence-software-2020/#primaryimage', 'url': 'https://www.datamation.com/wp-content/uploads/2020/12/top-15-artificial-intelligence-software-2020_5fce9b0a1d1db.png', 'contentUrl': 'https://www.datamation.com/wp-content/uploads/2020/12/top-15-artificial-intelligence-software-2020_5fce9b0a1d1db.png'}, {'@type': 'WebSite', '@id': 'https://www.datamation.com/#website', 'url': 'https://www.datamation.com/', 'name': 'Datamation', 'description': 'Emerging Enterprise Tech Analysis and Products', 'publisher': {'@id': 'https://www.datamation.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.datamation.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.datamation.com/#organization', 'name': 'Datamation', 'url': 'https://www.datamation.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datamation.com/#/schema/logo/image/', 'url': 'https://www.datamation.com/wp-content/uploads/2021/01/Datamation_logo_MainLogo.png', 'contentUrl': 'https://www.datamation.com/wp-content/uploads/2021/01/Datamation_logo_MainLogo.png', 'width': 272, 'height': 90, 'caption': 'Datamation'}, 'image': {'@id': 'https://www.datamation.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.datamation.com/#/schema/person/34ec5aba8ce1c0ae23e047ffef36056a', 'name': 'James Maguire', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datamation.com/#/schema/person/image/', 'url': 'https://assets.datamation.com/uploads/2022/09/james-maguire-150x150.jpg', 'contentUrl': 'https://assets.datamation.com/uploads/2022/09/james-maguire-150x150.jpg', 'caption': 'James Maguire'}, 'description': ""James Maguire is Datamation's Senior Managing Editor and has been reporting on technology topics for more than 15 years. He has covered the gamut of enterprise and consumer technology, and regularly communicates with leading IT newsmakers, vendors and analysts."", 'url': 'https://www.datamation.com/author/jmaguire/'}]","[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.datamation.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.datamation.com/artificial-intelligence/', 'name': 'AI'}}]",,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmdlbmVuZ25ld3MuY29tL25ld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY2xhc3NpZmllcy1jYW5jZXItdHlwZXMtcHJlZGljdHMtZ2VuZXRpYy1hbHRlcmF0aW9ucy_SAQA?oc=5,"Artificial Intelligence Classifies Cancer Types, Predicts Genetic Alterations - Genetic Engineering & Biotechnology News",2020-07-29,Genetic Engineering & Biotechnology News,https://www.genengnews.com,Researchers created a deep learning algorithm that infers molecular alterations directly from routine histology images across multiple common tumor types.,"['topics', 'artificial intelligence', 'cancer', 'news', 'biological process', 'cancers', 'cellular, molecular and developmental biology', 'genes', 'genetic structure', 'medicine, diagnosis, and therapeutics', 'molecular biology', 'systemic conditions', 'technology and computational biology']",Researchers created a deep learning algorithm that infers molecular alterations directly from routine histology images across multiple common tumor types.,N/A,N/A,N/A,"

Home  Topics  Artificial Intelligence  Artificial Intelligence Classifies Cancer Types, Predicts Genetic Alterations

Credit: aislan13 / iStock / Getty Images Plus

Artificial Intelligence Classifies Cancer Types, Predicts Genetic Alterations






July 29, 2020




Credit: aislan13 / iStock / Getty Images Plus









The ability to accurately identify cancer—and classify cancer types—using machine learning would provide a tremendous advance in cancer diagnostics for both physicians and patients. But that is just one role of many that machine learning can play in cancer. Another application is to predict genomic alterations from morphological characteristics learned from digital slides.
The genomicA team at the University of Chicago (UChicago) Medicine Comprehensive Cancer Center, working with colleagues in Europe, created a deep learning algorithm that can infer molecular alterations directly from routine histology images across multiple common tumor types. It also provides spatially resolved tumor and normal tissue distinction.




The work is published in the study titled, “Pan-cancer computational histopathology reveals mutations, tumor composition and prognosis” published in Nature Cancer. This paper highlighted the potential of artificial intelligence (AI) to help clinicians make personalized treatment plans for patients based on the information gained from how tissues appear under the microscope.
“We found that using artificial intelligence, we can quickly and accurately screen cancer patient biopsies for certain genetic alterations that may inform their treatment options and likelihood to respond to specific therapies,” said co-corresponding author Alexander Pearson, MD, PhD, assistant professor of medicine at UChicago Medicine.
“We are able to detect these genetic alterations almost instantly from a single slide, instead of requiring additional testing post-biopsy,” said Pearson. “If this model was validated and deployed at scale, it could dramatically improve the speed of molecular diagnosis across many cancers.”







Pearson and colleagues noted that although comprehensive molecular and genetic tests are difficult to implement at scale, tissue sections stained and mounted on a slide are commonplace and easy to study. And because molecular alterations in cancer can cause observable changes in tumor cells and their microenvironment, the researchers hypothesized that these structural changes would be visible on images of tissue slices captured under the microscope. In other words, genotype, the genetic make-up of the tumor cells, including gene mutations in key oncogenic pathways, influences the visible traits of those cells, known as their phenotype.
To test this, they set out to systematically investigate the presence of genotype-phenotype links for a wide range of clinically relevant molecular features across all major solid tumor types. Specifically, they asked which molecular features leave a strong enough footprint in histomorphology that they can be determined from histology images alone with deep learning.
The team used deep transfer learning to quantify histopathological patterns across 17,355 H&E-stained histopathology slide images from 28 cancer types and correlated these with matched genomic, transcriptions, and survival data. This approach, the authors noted, “accurately classifies cancer types and provides spatially resolved tumor and normal tissue distinction.”
To this end, the research team developed, optimized, and externally validated a one-stop-shop workflow to train and evaluate deep learning networks to detect any sequence variants in these target genes. Leveraging the Cancer Genome Atlas, they applied this approach to hundreds of molecular alterations in tissue slides of more than 5,000 patients across 14 major tumor types.
They found widespread associations between bulk gene expression levels and histopathology, which, they noted, “reflect tumor composition and enable the localization of transcriptomically defined tumor-infiltrating lymphocytes.”




They found that in 13 out of 14 tested tumor types, the mutation of one or more such genes could be inferred from histology images alone. In particular, in major cancer types such as lung, colorectal, breast, and gastric cancers, alterations of several genes of particular clinical interest were detectable.
Examples include mutations in TP53, which could be significantly detected in all four of these cancer types, as well as mutations of BRAF in colorectal cancer. Among all tested tumor types, gastric cancer and colorectal cancer had the highest absolute number of detectable mutations.
In addition, they found that higher-level gene expression clusters or signatures can be inferred from histological images. These findings that molecular signatures of tumors reflect biologically distinct groups and are correlated with clinical outcome could open up new options for personalized cancer treatment.
A separate research group has independently validated these results with a similar AI algorithm applied to images from common cancer types. Their study, “Pan-cancer image-based detection of clinically actionable genetic alterations,” was published in the same issue of Nature Cancer.



 NewsArtificial intelligenceBiological processCancersCellular, Molecular and Developmental BiologyGenesGenetic structureMedicine, Diagnosis, and TherapeuticsMolecular biologySystemic conditionsTechnology and Computational Biology 







Share
FacebookTwitterLinkedinReddItEmail

 Previous articleAlzheimer’s Diagnosis and Early Detection May Be Provided by Blood TestNext articlefMRIs Show Mental Fatigue’s Impact on MS Patients’ Cognitive Cerebral Responses Julianna LeMieux, PhD 


Also of Interest

Integrating AI into Bioprocessing Needs Cultural Change

Mapping the World's Fungi from Air Samples

Flagship Pioneering Raises $3.6B, Plans 25 New Startups

StockWatch: As Illumina Expands in Multiomics, Analyst Sees Threat to 10x

Phages Can Weaponize Selfish Genetic Elements to Outcompete Peers

Personalized Meds Sector Should Look to Microfluidics for Purification
 
Related Media

AACR 2024: A Video Update from San Diego

Bioprocessing in Beantown: GEN Reports Live from Day 2 at BPI

Carl Icahn States His Case for Change at Illumina on ""Close to the Edge""

Celebrating DNA: Matthew Cobb's Reflections on the Double Helix

Emerging Markets Collaborate to Succeed in Post-Pandemic World

The Sun Sets on AGBT: A Report from the Last Day

















 Related Content











                        Integrating AI into Bioprocessing Needs Cultural Change                    
















                        Mapping the World’s Fungi from Air Samples                    
















                        Flagship Pioneering Raises $3.6B, Plans 25 New Startups                    
















                        StockWatch: As Illumina Expands in Multiomics, Analyst Sees Threat to 10x                    





 
 







Read the Digital Edition 









 
 
",https://schema.org,BreadcrumbList,,"Artificial Intelligence Classifies Cancer Types, Predicts Genetic Alterations","{'@type': 'WebPage', '@id': 'https://www.genengnews.com/news/artificial-intelligence-classifies-cancer-types-predicts-genetic-alterations/'}",https://www.genengnews.com/news/artificial-intelligence-classifies-cancer-types-predicts-genetic-alterations/,https://www.genengnews.com/wp-content/uploads/2020/05/Sep1_GettyImages_1140559402_DigitalDNAConcept-150x150.jpg,"{'@type': 'ImageObject', 'url': 'https://www.genengnews.com/wp-content/uploads/2020/05/Sep1_GettyImages_1140559402_DigitalDNAConcept.jpg'}",2020-07-29T12:00:58Z,2020-07-29T12:00:58Z,2023-06-02T16:07:02Z,Artificial Intelligence,"[{'@type': 'Person', 'name': 'GEN Staff'}]",,"{'@type': 'Organization', 'name': 'GEN - Genetic Engineering and Biotechnology News', 'logo': 'https://genengnews.com/wp-content/uploads/2018/10/cropped-GEN_App_Icon_1024x1024-1.png'}",,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.genengnews.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.genengnews.com/category/topics/', 'name': 'Topics'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.genengnews.com/category/topics/artificial-intelligence/', 'name': 'Artificial Intelligence'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@type': 'WebPage', '@id': 'https://www.genengnews.com/news/artificial-intelligence-classifies-cancer-types-predicts-genetic-alterations/', 'name': 'Artificial Intelligence Classifies Cancer Types, Predicts Genetic Alterations'}}]",,['GEN Staff'],,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9pbXByZXNzaXZlLW1lZGl1bS1hcnRpY2xlcy1vbi1haS1tbC10aGlzLW1vbnRoLTcyNjUxMjdhN2NmNtIBAA?oc=5,Impressive Medium Articles on AI/ML This Month - Towards Data Science,2020-07-31,Towards Data Science,https://towardsdatascience.com,"At the end of each month, I reflect on the Medium articles that I’ve read, and I try to re-read and save the articles that provided some form of value. There are tons of interesting and well-written…",N/A,"With July ending, here are some of the top articles related to Artificial intelligence and Machine learning you shouldn’t miss.","With July ending, here are some of the top articles related to Artificial intelligence and Machine learning you shouldn’t miss.",N/A,N/A,"Photo by Roman Kraft on UnsplashMember-only storyOpinionImpressive Medium Articles on AI/ML This MonthWith July ending, here are some of the top articles related to Artificial intelligence and Machine learning you shouldn’t miss.Richmond Alake·FollowPublished inTowards Data Science·8 min read·Jul 30, 20203171ListenShareAt the end of each month, I reflect on the Medium articles that I’ve read, and I try to re-read and save the articles that provided some form of value.Now, I’ve decided to share the top four articles I came across on Medium in July.There are tons of interesting and well-written articles on Medium, and these four are just ones that stood out to me personally, so do consider that my selections are purely subjective.If you come across any AI/ML related articles you would like me to read and include in my weekly/monthly article coverage, feel free to tag me in the comment section of articles and I’ll take a review. Or connect and send a link to the article on LinkedInKnow What Employers are expecting for a Data Scientist Role in-2020 by Shareef ShaikThe impressively well-written article by Shareef Shaik illustrates the state of the Data Science Job market in India, in an intuitive visual format.",http://schema.org,NewsArticle,,Impressive Medium Articles on AI/ML This Month - Towards Data Science,https://towardsdatascience.com/impressive-medium-articles-on-ai-ml-this-month-7265127a7cf6,https://towardsdatascience.com/impressive-medium-articles-on-ai-ml-this-month-7265127a7cf6,,['https://miro.medium.com/v2/resize:fit:1200/1*S-oJXNjccMfo-o1_epkeFg.jpeg'],2020-07-31T03:18:26.428Z,2020-07-31T03:18:26.428Z,2021-12-15T09:50:57.917Z,,"{'@type': 'Person', 'name': 'Richmond Alake', 'url': 'https://richmondalake.medium.com'}",,"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,False,,Impressive Medium Articles on AI/ML This Month - Towards Data Science,,,,,,,,,,,,,['Richmond Alake'],,,,,7265127a7cf6,
https://news.google.com/rss/articles/CBMiLmh0dHBzOi8vc3BlY3RydW0uaWVlZS5vcmcvYWktdG9vbHMtYmlhcy1oaXJpbmfSAT1odHRwczovL3NwZWN0cnVtLmllZWUub3JnL2FtcC9haS10b29scy1iaWFzLWhpcmluZy0yNjUwMjgwMjgy?oc=5,AI Recruiting Tools Aim to Reduce Bias in the Hiring Process - IEEE Spectrum,2020-07-29,IEEE Spectrum,https://spectrum.ieee.org,Artificial intelligence software promises to make hiring fairer. But how well does it work?,"tech careers, machine learning, recruiting, hiring trends",Artificial intelligence software promises to make hiring fairer. But how well does it work?,N/A,Careers,N/A,"CareersNews
        AI Recruiting Tools Aim to Reduce Bias in the Hiring Process
    Artificial intelligence software promises to make hiring fairer. But how well does it work?Jeremy Hsu29 Jul 20205 min read
        Illustration: iStockphoto
    ",http://schema.org,NewsArticle,,AI Recruiting Tools Aim to Reduce Bias in the Hiring Process,"{'@id': 'https://spectrum.ieee.org/ai-tools-bias-hiring', '@type': 'WebPage'}",https://spectrum.ieee.org/ai-tools-bias-hiring,,https://assets.rbl.ms/25592108/origin.jpg,,2020-07-29T18:00:00Z,2023-09-22T16:39:16Z,,"{'@type': 'Person', 'description': 'Jeremy Hsu has been working as a science and technology journalist in New York City since 2008. He has written on subjects as diverse as supercomputing and wearable electronics for IEEE Spectrum . When he’s not trying to wrap his head around the latest quantum computing news for\xa0Spectrum , he also contributes to a variety of publications such as Scientific American , Discover , Popular Science, and others. He is a graduate of New York University’s Science, Health & Environmental Reporting Program.', 'identifier': 'https://spectrum.ieee.org/u/jeremy-hsu', 'image': {'@type': 'ImageObject', 'url': 'https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy8yNjY0NTkxNC9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc1NDM4NzE3M30.MTQySQ4SkKwqBh31wur--gqjA9a52wpqPBFrbbae81E/image.png?width=210'}, 'name': 'Jeremy Hsu', 'sameAs': [''], 'url': 'https://spectrum.ieee.org/u/jeremy-hsu'}",,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'height': 210, 'url': 'https://assets.rbl.ms/26794698/origin.png', 'width': 2000}, 'name': 'IEEE Spectrum'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiO2h0dHBzOi8vY29uc3VtZXJnb29kcy5jb20vYWktYWR2YW50YWdlLXNvdXJjaW5nLXByb2N1cmVtZW500gEA?oc=5,The AI Advantage in Sourcing & Procurement - Consumer Goods Technology,2020-07-30,Consumer Goods Technology,https://consumergoods.com,"As technology capabilities continue to evolve, the AI value realization may finally be coming to fruition.",N/A,"As technology capabilities continue to evolve, the AI value realization may finally be coming to fruition.","As technology capabilities continue to evolve, the AI value realization may finally be coming to fruition.",N/A,N/A,"     The AI Advantage in Sourcing & Procurement       Justin Honaman  7/30/2020      facebooktwitterlinkedInemail       “Whose job is it to innovate? To bring new thinking, new ideas, new methods and new tech to the team and thus, the larger organization? Who owns that for our team?” 
This was the question posed to me during a visioncasting session I was leading this week. I was surprised a bit at the question because I had assumed that most people in our organization viewed part of their role as staying connected to the industry. To the trends. To the possibilities outside of our four organizational walls. To bring innovation concepts into our everyday thinking. 
Back to this in a minute…
Before jumping back into the manufacturing industry, while I was working in global management consulting, I read, heard about and was told that artificial intelligence (AI) was “the future.” It would be the next iteration of data and analytics. And was often mixed with machine learning in a given sentence or industry speech. The value of AI was not being fully realized or even understood by most companies at the time. While the promise of “AI as the next phase of analytics” sounded good, the reality was much different.
Let’s get grounded in definitions: 
Artiﬁcial Intelligence (AI): Any algorithms exhibiting any behavior considered “smart”
Machine Learning (ML): Algorithms that detect patterns and use them for prediction or decision making
Natural Language Processing (NLP): Algorithms that can interpret, transform and generate human language
Robotic Process Automation (RPA): Algorithms that mimic human actions to reduce repetitive, simple tasks and RPA is generally not considered a form of AI
All forms of artificial intelligence involve algorithms — sets of rules specifying how to solve a specific problem. Algorithms can be calculated by anyone with a strong match competency, but they also form the basis of most computer software. The work of algorithms in software is not visible to the human eye, but they can be programmed and re-programmed by experts to solve problems deemed important within software environments.
As technology capabilities continue to evolve, the AI value realization may finally be coming to fruition. There is no technology called AI. AI is a grouping of technologies that allow machines and systems to sense, comprehend, act and learn. Examples include virtual agents, cognitive robotics, identity analytics, recommendation systems, and text, video and speech analytics.
There are several reasons that AI has potential to grow exponentially — now more than any time in the last few years. First, computing power. The fastest computer in the world is 3x as powerful and 4x cheaper than the 2nd fastest computer built 3 year ago. High performance cloud compute processing is now available for anyone to use (~$0.50 per hour) (ref: Accenture). 
Second, people and technical training programs. Skilled resources to develop AI solutions are available now more than ever — not only experienced resources across industries but also college graduates specializing in this space. 
Third, the period of “big data” yielded plans and solutions that now enable AI. There are many companies that are developing products that can be quickly installed and provide near-term value in the AI space. 
Fourth, the recent investments in IoT, digital and big data solutions have created new sets of information that can make AI more successful. AI relies on information to develop accurate and successful predictions. 
  

Advertisement - article continues below
Advertisement   As AI tackles lower complexity, mundane activities, employees can focus on higher value, rewarding, and self-fulling tasks.     There are many great benefits of AI. First, from an employee engagement perspective, as AI tackles lower complexity, mundane activities, employees can focus on higher value, rewarding and self-fulling tasks. This not only drives job fulfillment but long-term growth and retention as companies expand the scope of existing jobs into higher complexity and rewarding activities, make skills more transferable — less barrier to entry as AI minimizes machine, process or industry-specific activities, and match employees to more rewarding and tailored roles. Leaders in this space are demonstrating next-level analytics thinking beyond just “outsourcing to reduce costs ideas.” 
Second, to craft and manage AI within an organization, new jobs, roles and skills must be developed. Required AI-specific skill sets include user experience, data analysis, computer science and statistics. In addition, new roles are needed to oversee, manage, protect and infuse ethics into AI solutions. 
Third, computing power is more available to support AI. Based on growth and recent success there will be faster training, more real-time responsiveness, and ability to run/handle more complex machine learning solutions that can handle increasingly complex activities.
What about in Strategic Sourcing and Procurement? 
What are the immediate and realistic opportunities that may be acted upon quickly with AI? AI is automating or improving many time-consuming tasks or giving Procurement experts additional insights based on extremely complex and large sets of data. 
With the help of AI algorithms, it is possible to analyze larger amounts of data and offer the most relevant solutions for traditional problems. A few other SS&P possibilities include the following.
Data Mining, Analysis and Clustering
Data mining allows detecting unpredictable patterns hidden in the data generated during users’ routine operations for improving the level of their effectiveness. Also, Data Classification provides a source of information for determining ideal prices and make benchmarking and comparison a reality. 
AI can provide companies with accurate business data and increase the transparency of costs, with a high level of automation. 
Finally, Data Clustering methods allow you to combine and intelligently compare data for all benchmarking categories for the entire business or do it separately, for prices and suppliers.
Verification and Reconciliation
Verification and reconciliation algorithms can automatically determine critical errors of data and key performance indicators (KPIs), thus providing accurate information that is essential for determining the effectiveness of procurement processes, calculating valid benchmarking results, and maintaining a history of price changes, which greatly improves efficiency analysis, measuring the effectiveness of processes and can lead to significant savings.
Item Master Data and Catalogs
Some organizations have unique products that need to be available at a moment’s notice. This can put procurement professionals in tough situations as they are constantly having to negotiate different contracts with multiple suppliers for the same items to ensure availability of these products. Usually, this leaves the end user to compare multiple choices for the same product when all they care about is getting the product they need, and quickly. 
A highly intelligent algorithm can automatically select or suggest the best option for the user based on things like availability, location and price of delivery. Machine learning like this promotes efficiency and makes ordering products simple.
Contract Analytics
Most organizations do not have a database containing all contract data, and they need a simple way to extract such information. Using AI, a company can view contracts faster and accumulate large amounts of data about them to significantly reduce the likelihood of disputes and increase the number of successful transactions. 
The advantages of contract analytics is that it helps companies fulfill the conditions of contracts and more quickly identify cases of non-compliance.
Spend Classification
Using machine learning algorithms to classify procurement spend into categories and sub-categories. For example, reviewing millions of invoices to automatically categorize spend in different categories of cardboard packaging. Many companies have varied methods for classifying spend – or no set method at all — AI is a perfect solution for creating a book of record in the Spend Class space.
Purchase Price Variance
Machine Learning 101 — Anomaly Detection. Using machine learning algorithms to automatically detect and surface insights relevant to Procurement is an invaluable use case for AI. For example, unexpected changes in purchase prices for a commodity or from a specific supplier.
Supplier Risk Management
Artificial intelligence can be used to monitor and identify potential risk positions across the supply chain. AI can screen many different sources and provide alerts in supply chain risk – an important factor that enriches the supplier risk assessment and scorecarding.
This is just a top-of-mind list. The possibilities extend much further in sourcing and procurement — and will be a game-changer for those that are early and aggressive adopters.
Back to the initial question: Whose job is it to innovate — to bring concepts like AI to our teams, organizations and businesses? It’s all of ours. It’s not the job of the “innovation” team. It’s not just the point leader’s job. It’s not the job of our consulting or technology partners. 
It’s incumbent upon us as knowledge workers to stay up with what’s new, what’s evolving and what can be leveraged for competitive advantage — to challenge our current thinking in the pursuit of better, and the pursuit of moving the team and organization further, faster. AI is one of those concepts that is now and will be in the future a game-changer; the opportunities to leverage in sourcing and procurement are significant given the data-driven nature of the capability.
Justin Honaman is VP, strategic sourcing and procurement (data, analytics, business transformation) at Georgia-Pacific.
   ",https://schema.org,NewsArticle,,The AI Advantage in Sourcing & Procurement,,,,"{'@type': 'ImageObject', 'url': 'https://assets1.consumergoods.com/styles/primary_articles_short/s3/2020-07/ai%20cgt%20GettyImages-1194657255.jpg', 'width': '655', 'height': '368'}",,2020-07-29T19:00:00-0500,"Wed, 07/29/2020 - 19:26",,"{'@type': 'Person', 'name': '', 'url': 'https://consumergoods.com/author-profile/'}",,"{'@type': 'Organization', 'name': 'Consumer Goods Technology', 'url': 'https://consumergoods.com/'}",,,,,,,,,,,,,The AI Advantage in Sourcing & Procurement,,,,,,,,,,,,,,,,,,,"“Whose job is it to innovate? To bring new thinking, new ideas, new methods and new tech to the team and thus, the larger organization? Who owns that for our team?” 

This was the question posed to me during a visioncasting session I was leading this week. I was surprised a bit at the question because I had assumed that most people in our organization viewed part of their role as staying connected to the industry. To the trends. To the possibilities outside of our four organizational walls. To bring innovation concepts into our everyday thinking. 

Back to this in a minute…

Before jumping back into the manufacturing industry, while I was working in global management consulting, I read, heard about and was told that artificial intelligence (AI) was “the future.” It would be the next iteration of data and analytics. And was often mixed with machine learning in a given sentence or industry speech. The value of AI was not being fully realized or even understood by most companies at the time. While the promise of “AI as the next phase of analytics” sounded good, the reality was much different.

Let’s get grounded in definitions: 

Artiﬁcial Intelligence (AI): Any algorithms exhibiting any behavior considered “smart”
Machine Learning (ML): Algorithms that detect patterns and use them for prediction or decision making
Natural Language Processing (NLP): Algorithms that can interpret, transform and generate human language
Robotic Process Automation (RPA): Algorithms that mimic human actions to reduce repetitive, simple tasks and RPA is generally not considered a form of AI

All forms of artificial intelligence involve algorithms — sets of rules specifying how to solve a specific problem. Algorithms can be calculated by anyone with a strong match competency, but they also form the basis of most computer software. The work of algorithms in software is not visible to the human eye, but they can be programmed and re-programmed by experts to solve problems deemed important within software environments.

As technology capabilities continue to evolve, the AI value realization may finally be coming to fruition. There is no technology called AI. AI is a grouping of technologies that allow machines and systems to sense, comprehend, act and learn. Examples include virtual agents, cognitive robotics, identity analytics, recommendation systems, and text, video and speech analytics.

There are several reasons that AI has potential to grow exponentially — now more than any time in the last few years. First, computing power. The fastest computer in the world is 3x as powerful and 4x cheaper than the 2nd fastest computer built 3 year ago. High performance cloud compute processing is now available for anyone to use (~$0.50 per hour) (ref: Accenture). 

Second, people and technical training programs. Skilled resources to develop AI solutions are available now more than ever — not only experienced resources across industries but also college graduates specializing in this space. 

Third, the period of “big data” yielded plans and solutions that now enable AI. There are many companies that are developing products that can be quickly installed and provide near-term value in the AI space. 

Fourth, the recent investments in IoT, digital and big data solutions have created new sets of information that can make AI more successful. AI relies on information to develop accurate and successful predictions. 
There are many great benefits of AI. First, from an employee engagement perspective, as AI tackles lower complexity, mundane activities, employees can focus on higher value, rewarding and self-fulling tasks. This not only drives job fulfillment but long-term growth and retention as companies expand the scope of existing jobs into higher complexity and rewarding activities, make skills more transferable — less barrier to entry as AI minimizes machine, process or industry-specific activities, and match employees to more rewarding and tailored roles. Leaders in this space are demonstrating next-level analytics thinking beyond just “outsourcing to reduce costs ideas.” 

Second, to craft and manage AI within an organization, new jobs, roles and skills must be developed. Required AI-specific skill sets include user experience, data analysis, computer science and statistics. In addition, new roles are needed to oversee, manage, protect and infuse ethics into AI solutions. 

Third, computing power is more available to support AI. Based on growth and recent success there will be faster training, more real-time responsiveness, and ability to run/handle more complex machine learning solutions that can handle increasingly complex activities.

What about in Strategic Sourcing and Procurement? 

What are the immediate and realistic opportunities that may be acted upon quickly with AI? AI is automating or improving many time-consuming tasks or giving Procurement experts additional insights based on extremely complex and large sets of data. 

With the help of AI algorithms, it is possible to analyze larger amounts of data and offer the most relevant solutions for traditional problems. A few other SS&P possibilities include the following.

Data Mining, Analysis and Clustering

Data mining allows detecting unpredictable patterns hidden in the data generated during users’ routine operations for improving the level of their effectiveness. Also, Data Classification provides a source of information for determining ideal prices and make benchmarking and comparison a reality. 

AI can provide companies with accurate business data and increase the transparency of costs, with a high level of automation. 

Finally, Data Clustering methods allow you to combine and intelligently compare data for all benchmarking categories for the entire business or do it separately, for prices and suppliers.

Verification and Reconciliation

Verification and reconciliation algorithms can automatically determine critical errors of data and key performance indicators (KPIs), thus providing accurate information that is essential for determining the effectiveness of procurement processes, calculating valid benchmarking results, and maintaining a history of price changes, which greatly improves efficiency analysis, measuring the effectiveness of processes and can lead to significant savings.

Item Master Data and Catalogs

Some organizations have unique products that need to be available at a moment’s notice. This can put procurement professionals in tough situations as they are constantly having to negotiate different contracts with multiple suppliers for the same items to ensure availability of these products. Usually, this leaves the end user to compare multiple choices for the same product when all they care about is getting the product they need, and quickly. 

A highly intelligent algorithm can automatically select or suggest the best option for the user based on things like availability, location and price of delivery. Machine learning like this promotes efficiency and makes ordering products simple.

Contract Analytics

Most organizations do not have a database containing all contract data, and they need a simple way to extract such information. Using AI, a company can view contracts faster and accumulate large amounts of data about them to significantly reduce the likelihood of disputes and increase the number of successful transactions. 

The advantages of contract analytics is that it helps companies fulfill the conditions of contracts and more quickly identify cases of non-compliance.

Spend Classification

Using machine learning algorithms to classify procurement spend into categories and sub-categories. For example, reviewing millions of invoices to automatically categorize spend in different categories of cardboard packaging. Many companies have varied methods for classifying spend – or no set method at all — AI is a perfect solution for creating a book of record in the Spend Class space.

Purchase Price Variance

Machine Learning 101 — Anomaly Detection. Using machine learning algorithms to automatically detect and surface insights relevant to Procurement is an invaluable use case for AI. For example, unexpected changes in purchase prices for a commodity or from a specific supplier.

Supplier Risk Management

Artificial intelligence can be used to monitor and identify potential risk positions across the supply chain. AI can screen many different sources and provide alerts in supply chain risk – an important factor that enriches the supplier risk assessment and scorecarding.

This is just a top-of-mind list. The possibilities extend much further in sourcing and procurement — and will be a game-changer for those that are early and aggressive adopters.

Back to the initial question: Whose job is it to innovate — to bring concepts like AI to our teams, organizations and businesses? It’s all of ours. It’s not the job of the “innovation” team. It’s not just the point leader’s job. It’s not the job of our consulting or technology partners. 

It’s incumbent upon us as knowledge workers to stay up with what’s new, what’s evolving and what can be leveraged for competitive advantage — to challenge our current thinking in the pursuit of better, and the pursuit of moving the team and organization further, faster. AI is one of those concepts that is now and will be in the future a game-changer; the opportunities to leverage in sourcing and procurement are significant given the data-driven nature of the capability.

Justin Honaman is VP, strategic sourcing and procurement (data, analytics, business transformation) at Georgia-Pacific."
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vY2l2aWxyaWdodHMub3JnL3Jlc291cmNlL2NpdmlsLXJpZ2h0cy1wcmluY2lwbGVzLWZvci1oaXJpbmctYXNzZXNzbWVudC10ZWNobm9sb2dpZXMv0gEA?oc=5,Civil Rights Principles for Hiring Assessment Technologies - Civilrights.org,2020-07-29,Civilrights.org,https://civilrights.org,N/A,N/A,N/A,N/A,N/A,N/A,"




View the full document as a PDF here. 
Preface
Hiring is a critical gateway to economic opportunity, determining who can access employment to support themselves and their families. Technology is rapidly changing every step of the employment selection process. Employers are now using new assessment tools that rely on artificial intelligence and algorithms to screen and select job candidates. These developments highlight the need for policymakers to clarify and strengthen guardrails to ensure that hiring assessments are used equitably.
Hiring assessments can take many different forms, including video interviews, gamified assessments, and resume screens. Many vendors claim that these tools objectively evaluate applicants against a set of traits or a profile associated with success in, or good fit for, a job. Employers are using these assessments in an effort to increase efficiency by reducing the time and cost required to fill an open position with a successful hire, and sometimes to hire more diverse candidates. However, assessment technologies can invisibly automate large numbers of rejections by determining which applicants get serious consideration. As a result, hiring assessment technologies deserve close scrutiny.
Today’s workforce reflects decades of discrimination on the basis of race, ethnicity, sex (including sexual orientation and gender identity), disability and age, and other factors. Hiring assessment technologies are one of many barriers that may impede equity and inclusion in the workforce. Artificial intelligence, by its very nature, risks replicating and deepening existing inequities when it relies on data from the current workforce that is not sufficiently representative because of historic discrimination. Hiring assessment technologies must advance equity, not erect artificial barriers to employment. This will require proactive interventions by employers, vendors, and policymakers.
The following principles are offered to guide the development, use, auditing, and oversight of hiring assessment technologies, with the goals of preventing discrimination and advancing equity in hiring.
Principles
These principles should guide the development, use, auditing, and oversight of hiring assessment technologies. They both reinforce and strengthen existing legal obligations pertaining to the employment selection process. Employers already have significant obligations to administer nondiscriminatory hiring processes. Vendors and technology providers will need to play a more prominent role in helping ensure these obligations are met. Government must ensure robust enforcement of existing laws to promote these principles. And policymakers may need to develop new laws and guidance to ensure workers’ rights are protected.
As used below, hiring assessment technology refers to any assessment that relies in whole or in part on technology, including computer algorithms or statistical models, to help evaluate job applicants. Organization means any entity that creates, makes available, or uses hiring assessment technologies, including employers, employment agencies, hiring assessment developers and vendors, and companies that facilitate job-matching and recruitment.
1. Nondiscrimination
Hiring assessments should not discriminate based on protected characteristics such as race, color, ethnicity, religion, national origin, sex, gender identity, sexual orientation, age, familial status, disability, or genetic information.

Hiring assessments built using historical data can reproduce patterns of systemic discrimination already present in the workforce. Machine learning algorithms can discover subtle correlations and proxies for protected characteristics, even when they are purposefully omitted from the model-building process.

Organizations should carefully test and scrutinize their hiring assessment models to ensure that they do not perpetuate discriminatory hiring patterns. Merely removing demographic data from the model-building process will not accomplish this goal.


Hiring assessment technologies, including those using novel procedures like games or facial and voice analysis, can create new barriers for job applicants, including people with disabilities. Facial and voice analysis technologies, in particular, have been shown to be inaccurate for people of color, English speakers with non-native accents, and transgender, nonbinary, and gender nonconforming people.Organizations should ensure that hiring assessments are designed and administered in ways that do not exclude people, including those with disabilities, and provide reasonable accommodations. Because there are limited data about the diverse dimensions of disability, organizations cannot prevent discrimination by statistical auditing alone. Organizations must also ensure that technologies do not unfairly discriminate against people of color, people with limited English proficiency, and transgender, nonbinary, and gender nonconforming people. 

2. Job-Relatedness
Hiring assessments should measure traits and skills that are important to job performance. Assessments based on criteria that are unnecessary to job performance risk creating artificial or discriminatory barriers to employment opportunity.

Some hiring assessment technologies use machine learning to identify traits that are statistically correlated with job performance in a particular population and environment, regardless of their actual relation to job requirements. Statistical modeling cannot substitute for a rigorous job analysis.Organizations should do the necessary work of studying and understanding the knowledge, skills, and abilities required by a particular job, and should not rely on hiring assessment technologies purporting to predict performance as a substitute for identifying job-related criteria. Moreover, mere correlations between traits and purported job performance should not be sufficient to justify adverse impact resulting from consideration of those traits.
Machine-learning models often assess job applicants based on complex features that are not transparent or open to scrutiny by applicants, employers, or even the models’ developers.Organizations should be able to describe what an assessment is measuring and why, as well as show that the assessment is actually measuring what it purports to measure, before deploying that assessment.

3. Notice and Explanation
Applicants should be meaningfully notified about how they will be assessed so they can seek redress under existing civil rights protections or request a reasonable accommodation.

Applicants often receive little explanation about how they will be evaluated by assessments or feedback about their performance.Organizations should provide applicants with meaningful disclosures about how assessments operate and inform employment decisions, including the information collected to evaluate job seekers. Under existing law, employers should provide sufficient information about the operation of assessments so that applicants can determine whether they need to seek reasonable accommodations, make clear the procedures for requesting reasonable accommodations, and ensure reasonable accommodation processes do not disadvantage applicants. All organizations should do the same.
Hiring assessment technologies can be designed to automatically deliver meaningful feedback at scale. In other policy contexts, such as credit, federal law has recognized a right for consumers to receive adverse action notices that indicate standardized reasons for adverse decisions about them.Organizations should provide applicants with reasonable and timely feedback on their performance on a hiring assessment.

4. Auditing
Hiring assessments should be thoroughly and regularly audited before and after deployment for discrimination and job-relatedness. Organizations and policymakers may need to develop new technical and legal standards to ensure applicants are protected.

Auditing machine learning models often requires documentation and retention of information such as training data, designs, applicant information, assessment criteria, assessment outputs, and ultimate hiring decisions.Organizations should retain and clearly identify the data necessary to regularly audit assessments for discrimination and job-relatedness, with appropriate privacy and data security protections. 
Statistical testing for disparate impacts based on race, ethnicity, gender, and age is critical but insufficient to prevent all forms of discrimination. For example, because people’s disabilities are so diverse, statistical tests are unlikely to reveal how a hiring assessment will impact any individual with a particular disability.Organizations must continually and holistically audit their hiring assessments. This means scrutinizing the content of hiring assessments, measuring their outcomes, and considering employers’ overall hiring processes. 
Though organizations should engage in rigorous self-testing of their own hiring assessment technologies before and after deployment, auditing is often best conducted by independent third parties who can provide a greater degree of impartiality and accountability.Organizations should work with third parties to routinely audit their assessments for discriminatory design and effects. Organizations should publicly disclose the methods and results of self-testing and third-party audits.
Models that are developed and tested using vendors’ proprietary data and designs can have different results when used on actual applicants.

Once deployed, hiring assessments’ real-world performance must be continually audited for disparities.
5. Oversight and Accountability
Federal and state policymakers should develop new legal and technical standards, and equip state and federal regulators with the ability to meaningfully investigate and hold organizations accountable for ensuring equal opportunity in their use of hiring assessments.

Applicants typically lack insight into hiring practices, including the design and impacts of hiring assessment technologies, and cannot effectively vindicate their rights alone.Regulators should have the legal mandates, resources, and expertise they need to conduct proactive oversight and enforcement, including the ability to request information about how organizations develop and use hiring assessments. Government employers’ procurement and use of hiring assessment technologies should be subject to approval and transparency. Effective oversight cannot rely on applicants knowing that they have been wronged and filing complaints. 
Today’s laws and regulatory guidance leave too much ambiguity for organizations, workers, and enforcement agencies trying to apply civil rights protections to modern hiring assessment technologies.

Policymakers should begin to consider new regulations and guidance interpreting civil and human rights laws in light of predictive hiring tools and encourage the development of third-party auditing standards. At a minimum, agencies should conduct and publish research on hiring assessments and civil rights, including a candid reflection on federal and state governments’ capacity to oversee the design and use of modern hiring technologies.
Signatories:
The Leadership Conference Education Fund
The Leadership Conference on Civil and Human Rights
ACLU
AI Now Institute
American Association of University Women (AAUW)
Center for Democracy & Technology
Center for Law and Social Policy (CLASP)
Center on Privacy & Technology at Georgetown Law
Color of Change
Lambda Legal
Lawyers’ Committee for Civil Rights Under Law
NAACP
NAACP Legal Defense and Educational Fund, Inc.
National Association of Councils on Developmental Disabilities
National Center for Law and Economic Justice
National Employment Law Project
National Employment Lawyers Association (NELA)
National Organization for Women
National Partnership for Women & Families
National Women’s Law Center
New America’s Open Technology Institute
Open MIC (Open Media and Information Companies Initiative)
Public Knowledge
UnidosUS
Upturn
Workplace Fairness


























",https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://civilrights.org/resource/civil-rights-principles-for-hiring-assessment-technologies/', 'url': 'https://civilrights.org/resource/civil-rights-principles-for-hiring-assessment-technologies/', 'name': 'Civil Rights Principles for Hiring Assessment Technologies', 'isPartOf': {'@id': 'https://civilrights.org/#website'}, 'datePublished': '2020-07-29T15:03:26+00:00', 'dateModified': '2020-08-03T19:48:02+00:00', 'breadcrumb': {'@id': 'https://civilrights.org/resource/civil-rights-principles-for-hiring-assessment-technologies/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://civilrights.org/resource/civil-rights-principles-for-hiring-assessment-technologies/']}]}, {'@type': 'BreadcrumbList', '@id': 'https://civilrights.org/resource/civil-rights-principles-for-hiring-assessment-technologies/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://civilrights.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Library', 'item': 'https://civilrights.org/resource/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Civil Rights Principles for Hiring Assessment Technologies'}]}, {'@type': 'WebSite', '@id': 'https://civilrights.org/#website', 'url': 'https://civilrights.org/', 'name': 'The Leadership Conference on Civil and Human Rights', 'description': '', 'publisher': {'@id': 'https://civilrights.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://civilrights.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://civilrights.org/#organization', 'name': 'Leadership Council on Civil and Human Rights', 'url': 'https://civilrights.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://civilrights.org/#/schema/logo/image/', 'url': 'https://civilrights.org/wp-content/uploads/2019/01/favicon.png', 'contentUrl': 'https://civilrights.org/wp-content/uploads/2019/01/favicon.png', 'width': 600, 'height': 600, 'caption': 'Leadership Council on Civil and Human Rights'}, 'image': {'@id': 'https://civilrights.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/civilandhumanrights/', 'https://x.com/civilrightsorg', 'https://www.youtube.com/user/LCCREF', 'https://www.instagram.com/civilrightsorg/', 'https://www.tiktok.com/@civilrightsorg']}]",,,,,,,,,
https://news.google.com/rss/articles/CBMigQFodHRwczovL2RpZ2cuY29tLzIwMjAvZ3V5LXVzZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdG8tbWFrZS1pbmNyZWRpYmx5LXBob3RvLXJlYWxpc3RpYy1wb3J0cmFpdHMtb2YtZmFtb3VzLXBlb3BsZS1mcm9tLWhpc3RvcnnSAQA?oc=5,Guy Uses Artificial Intelligence To Make Incredibly Photo-Realistic Portraits Of Famous People From History - Digg,2020-07-29,Digg,https://digg.com,"Bas Uterwijk, an artist based in The Netherlands, used artificial intelligence to produce some eye-popping portraits of famous historical figures.",,"Bas Uterwijk, an artist based in The Netherlands, used artificial intelligence to produce some eye-popping portraits of famous historical figures.","Bas Uterwijk, an artist based in The Netherlands, used artificial intelligence to produce some eye-popping portraits of famous historical figures.",N/A,N/A,"





WHAT A DIFFERENCE AN AI MADE 


Guy Uses Artificial Intelligence To Make Incredibly Photo-Realistic Portraits Of Famous People From History







James Crugnale



Jul 29, 2020 @12:18 PM


·Updated: Jul 29, 2020 @12:18 PM










·









Bas Uterwijk, an artist and photographer based in The Netherlands, used artificial intelligence to produce some eye-popping portraits of famous historical figures.
""I have been working since about a year with the Artbreeder software,"" Uterwijk told Digg in an email. ""First on abstract and pseudo-figurative work and later on human portraits.""
""The idea began when I discovered the A.I. had no problem fixing the marks and scratches on the only authenticated portrait of Billy the Kid I fed it.I then experimented with other historical figures of whom no or little photographic material existed: Napoleon, Julius Ceasar, Queen Elizabeth etc.""
Uterwijk uploaded up to 20 different paintings into the generative adversarial network and says he was able to reconstruct images that were visual averages of the different sources ""with the help of this software that is trained on thousands of human faces, towards an almost photo-realistic version.""
""Getting a good likeness together with a certain level of realism and a strong appearance of the character can take hours or even days of tweaking,"" Uterwijk explained.
You can see his creations here:
Vincent Van Gogh
Bas Uterwijk
Bas Uterwijk
Billy The Kid
Bas Uterwijk
Jesus Of Nazareth
Bas Uterwijk
Bas Uterwijk
George Washington
Bas Uterwijk
Lady Liberty
Bas Uterwijk
Johannes Vermeer's Girl with a Pearl Earring
Bas Uterwijk
Michelangelo's David
Bas Uterwijk
Napoleon Bonaparte
Bas Uterwijk
Leonardo da Vinci's Mona Lisa



""When I realized the potential of this software combined with my additional methods I was pretty certain I was on to something quite interesting but it took a while before there was any recognition outside a small circle of friends and colleagues,"" Uterwijk observed. ""The Internet is a funny thing and it is quite overwhelming to see your work suddenly go viral globally!"" 
[See more of Bas Uterwijk's work on his website and Instagram]









James Crugnale is an associate editor at Digg.com.



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS93cml0aW5nLXlvdXItZmlyc3QtYWktbWFjaGluZS1sZWFybmluZy1wcm9ncmFtLTkyYTU5MGRmODZkZdIBAA?oc=5,Writing Your First AI/Machine Learning Program | by Tamoghno Bhattacharya - Towards Data Science,2020-07-27,Towards Data Science,https://towardsdatascience.com,You may have learnt a lot of theory regarding Artificial Intelligence and Machine Learning and found it interesting. But there’s nothing like seeing the models and algorithms work on real data and…,N/A,Polynomial Logistic Regression on Iris Flowers Dataset for Classification,Polynomial Logistic Regression on Iris Flowers Dataset for Classification,N/A,N/A,"Writing Your First AI/Machine Learning ProgramPolynomial Logistic Regression on Iris Flowers Dataset for ClassificationTamoghno Bhattacharya·FollowPublished inTowards Data Science·10 min read·Jul 27, 202076ListenShareSource: https://pixabay.com/photos/work-typing-computer-notebook-731198/You may have learnt a lot of theory regarding Artificial Intelligence and Machine Learning and found it interesting. But there’s nothing like seeing the models and algorithms work on real data and produce results, is there? There’s a lot of material out there teaching you how to go about writing your first ML program and stuff, but what I found in most of the cases is that there’s not much step-by-step guidance on how to go about approaching a particular problem. Well-written code is pretty much everywhere but methodology is lacking, which is equally important as learning how to write a program. So I decided to write on the well-known beginner’s introduction to the AI world — Iris Flowers Classification Problem.The Dataset And Algorithm UsedThe Iris flowers dataset basically contains 150 instances of flowers. Each flower has 4 attributes: sepal length, sepal width, petal length and petal width (each in cm) and 3 possible classes it might belong to: setosa, vermicolor, and virginica. For more information, refer to the site: https://archive.ics.uci.edu/ml/datasets/irisOur objective is to develop a classifier that can accurately classify a flower as one of the 3 classes based on the 4 features. There are a lot of algorithms which can do this, however since this your first AI program, let’s stick to one of the simplest algorithms which can also be made to work relatively well on this dataset — Logistic Regression. In case if you have just begun Machine Learning and do not know what it is, check this set of lectures out from the popular Machine Learning course by Andrew NG. They’re a perfect way to get started. Also check out the next series of lectures, i.e 7, if you aren’t familiar with regularization.If you are well-versed in linear algebra, univariate and multivariate calculus, probability as well as statistics already, and would like a deeper mathematical understanding then check out this video from Stanford Online -Yeah, I’m kind of a sucker for Andrew NG! Anyways, to summarize what Logistic Regression does, suppose we have the following dataset -A Scatter Plot of 2D DatasetFigure alongside shows admission scores of students in 2 exams, and whether or not they are admitted to the school/college based on their scores. What Logistic Regression does is it tries to find a linear decision boundary that separates the classes the best.Logistic Regression Decision BoundaryAs we can see, LR does a pretty nice job separating the two classes. But what if there are more than two classes, as in our case? In that situation, we train n classifiers for each of the n classes and have each classifier try to separate one class from the rest. This technique is rightly known as the ‘one-vs-all classification’. In the end, for prediction on an instance, we pick the classifier which detects it’s class the strongest, and assign that class as the predicted class. The decision boundary here is a bit harder to visualize but here is an illustration from Sklearn -Source: https://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.htmlGetting StartedAlright, enough with the requisites, now let’s get started with the code. We’ll be using Python of course, along with the following modules: Numpy, Matplotlib, Seaborn and Sklearn. In case if like work locally on your computer like me, make sure you have these modules installed. To install them, simply fire up your Command Line/Terminal and enter the command “pip install <module-name>”. To check what modules are installed, enter “python” then “help(‘modules’)” to generate list of all installed modules.Data Analysis And VisualizationFirst, we need to get an idea of the distribution of data in the dataset. Let’s import the matplotlib and seaborn modules for this purpose and load the iris dataset contained in the seaborn module.import matplotlib.pyplot as pltimport seaborn as snsiris = sns.load_dataset(‘iris’)This will load the dataset into the dataframe ‘iris’, which will make visualization much easier. Since the dataset has 4 features we can’t visualize it directly but we can gain some intuition through seaborn’s powerful pairplot. What pairplot does is it makes a scatter plot between each of the pairs of variables in the dataset, as well as the distribution of values of each variable (along the diagonal graphs). This can be used to analyze which features are a better separator of the data, which features are closely related, as well as data distribution.sns.pairplot(iris, hue='species') #hue parameter colors distinct speciesplt.show()Seaborn Pairplot on Iris DatasetAnother powerful tool in Seaborn is the heatmap of correlations. Correlation is a statistical measure of how much two variables are dependent on each other. If an increase in one variable causes a rough increase in another variable and vice versa, then they are said to be positively correlated. If an increase in a variable causes a decrease in another and vice versa, they are negatively correlated and if there is no such dependence between them, they have zero correlation. This is how we plot correlations using Seaborn -sns.heatmap(iris.corr(), annot=True, cmap='coolwarm')plt.show()iris.corr() generates a 4*4 matrix with each entry (i,j) representing correlations between the iᵗʰ and jᵗʰ variables. Obviously the matrix is symmetric, since the dependence between i and j is same as that between j and i (wish this were true for humans too). And the diagonal elements are 1, since a variable is obviously completely dependent on itself. The annot parameter decides whether to display the correlation values on top of the heatmap and colormap is set to coolwarm, which means blue for low values and red for high values.Correlation Heatmap on Iris DatasetData Preparation And PreprocessingNow that we have an intuition about the data, let’s load the data into numpy arrays and preprocess it. Preprocessing is a crucial step and can enhance the performance of your algorithms by a huge margin. We import the required modules, load the dataset from sklearn’s iris datasets class in the form of a dictionary, get the features and targets into numpy arrays X and Y, respectively and the names of the classes into names. Since the targets specified in the datasets are 0,1 and 2 representing the 3 classes of species, we would like a mapping from those integers to the name of the class they represent. To do this, we create a dictionary mapping from the integers 0,1,2 to the flower names.import numpy as npfrom sklearn.datasets import load_irisdataset = load_iris()X, Y, names = dataset['data'], dataset['target'], dataset['target_names']target = dict(zip(np.array([0, 1, 2]), names))Let’s move forward to the preprocessing step. We divide the data into train and test sets using train_test_split from sklearn using test set size of 25%, then use the StandardScaler class from sklearn. What StandardScaler does is it computes the mean and standard deviation of each of the features in our dataset, then subtracts off the mean and divides by the standard deviation each example in our dataset. This brings all of the features to having zero mean and unit standard deviation/variance. Bringing all of the features in the same range is also known as feature normalization, and it helps optimization algorithms like gradient descent to work properly and converge faster.from sklearn.preprocessing import StandardScalerfrom sklearn.model_selection import train_test_splitX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)scaler = StandardScaler()  #create object of StandardScaler classscaler.fit(X_train)        #fit it to the training setX_train_pr = scaler.transform(X_train) #apply normalization to the training setBuilding The Model And Evaluating ItIt’s time for the real deal. It is now that you feel really indebted to sklearn for making your life simple. We create an object of the LogisticRegression class named model, and fit our training dataset to it, all using 3 lines of code -from sklearn.linear_model import LogisticRegressionmodel = LogisticRegression()model.fit(X_train_pr, Y_train)Now, to make predictions we first normalize the test set using the Standard Scaler. Note that the transformation is the same as applied to the training set (to which we had fit the scaler to). This is important as we have to normalize our test set as per the mean and standard deviation of our training set, and not the test set. We then use the predict function to generate the 1D array of predictions both on the training and test set. There are many metrics available in the metrics class of sklearn but we’ll use the 3 most relevant — accuracy, classification report and confusion matrix.from sklearn.metrics import accuracy_score, classification_report, confusion_matrixX_test_pr = scaler.transform(X_test)Y_train_pred, Y_test_pred = model.predict(X_train_pr), model.predict(X_test_pr) print(accuracy_score(Y_train, Y_train_pred))print(accuracy_score(Y_test, Y_test_pred))print(classification_report(Y_test, Y_test_pred))print(confusion_matrix(Y_test, Y_test_pred))The dataset is very small, and hence, you might very different results each time you train your model. This is the output I get -Evaluation of Trained ModelIn case if you don’t understand any of the metrics you see, feel free to search them they are pretty much basic and easy to understand. Training set accuracy is approx 95.5% and test set accuracy approx 94.7%. A weighted average of F1-score of all different classes in the test set is 0.95 and 2 examples from the test set are classified incorrectly. An accuracy of 94.7% on the training set at first go is really good, but we can do better.Improving The ModelLet’s introduce polynomial logistic regression. It turns out that we can build a better model by introducing polynomial features into the model, like x₁², x₁x₂, x₂² to produce a non-linear decision boundary to better separate the classes. This kind of model is more practical. For example, let us look at this dataset below -A Scatter Plot of 2D DatasetThis dataset looks a little more practical, doesn’t it? It shows scores achieved by tests on different microchips and the classes they belong to. There is clearly no linear decision boundary that can satisfactorily separate the data. Using polynomial logistic regression, we can get a decision boundary as shown below, which does a far better job.Polynomial Logistic Regression Decision BoundaryThe lambda=1 in the figure refers to the regularization parameter. Regularization become pretty important when dealing with non-linear models since you don’t want to overfit to your training set and have your model not perform well on new examples it hasn’t seen.To add polynomial features into your dataset, we use the PolynomialFeatures class from sklearn. This will go into your preprocessing as an added step, similar to the feature normalization step. We add 5th power degree terms, you can try changing it and see the effect it has on your accuracy. It turns out the model starts overfitting for higher degree terms and we don’t want that.from sklearn.preprocessing import PolynomialFeaturesX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)poly = PolynomialFeatures(degree = 5)poly.fit(X_train)X_train_pr = poly.transform(X_train)scaler = StandardScaler()scaler.fit(X_train_pr)X_train_pr = scaler.transform(X_train_pr)Then continue the same steps as discussed above to fit the model. To make predictions, don’t forget to transform the test set using poly first.X_test_pr = poly.transform(X_test)X_test_pr = scaler.transform(X_test_pr)Y_train_pred, Y_test_pred = model.predict(X_train_pr), model.predict(X_test_pr)Then evaluate the model, using the metrics discussed above. Again, the results will differ with each time the model is trained. Here is my output -Evaluation of Improved ModelPretty good results! A training set accuracy of approx 98.2% and a test set accuracy of approx 97.4% are great using a simple algorithm like logistic regression. Weighted F1-score on test set has improved to 0.97 and the model incorrectly classifies only 1 example from the test set.Generating PredictionsIt’s time to use the model to generate predictions. We’ll give it an array of 4 numbers — representing the 4 features of a flower, and it will tell us which species it thinks that it belongs to. We randomly pick 20 examples from the dataset, preprocess them and get the predicted classes.indices = np.random.randint(150, size=20)X_pred, Y_true = X[indices], Y[indices]X_pred_pr = poly.transform(X_pred)X_pred_pr = scaler.transform(X_pred_pr)Y_pred = model.predict(X_pred_pr)Note that Y_true represents the true class of the example and Y_pred is the predicted class. They are both integers as the model works with numeric data. We will now create 2 lists, storing the true names and predicted names of the species of each example, using the dictionary mapping we already created named target.target_true, target_pred = [], []for i in range(len(Y_true)):    target_true.append(target[Y_true[i]])    target_pred.append(target[Y_pred[i]])print(X_pred)print(target_true)print(target_pred)This is the output I get -Predictions on 20 Random ExamplesDue to the high accuracy of our model, all the 20 predictions generated are correct! Here is the complete code of the final model we created -Try to make some modifications to the model, see if you can improve it further to make more realistic predictions. You can try different models like KNN-Classifier, Support Vector Classifier, or even a small Neural Network though I would not prefer a NN for this task as the number of features and dataset both are small and a Machine Learning model will perform just as well.ConclusionHope this gives you some idea regarding how to go about building a simple AI, or specifically, Machine Learning model to solve a particular problem. There are basically 5 stages involved -Obtain a proper dataset for the task.Analyze and visualize the dataset, and try to gain an intuition about the model you should use.Convert the data into an usable form, and then preprocess it.Build the model, and evaluate it.Check where the model is falling short, and keep improving it.There is a lot of trial-and-error involved when dealing with building Artificial Intelligence applications. Even if your first model doesn’t work well, don’t be disheartened. Most of the times, remarkable performance improvements can be made by tweaking it. Getting the right dataset is super crucial and is, I feel, the game-changer when it comes to real-world models. All said and done, try to keep learning new stuff as much as possible, and do AI for the fun of it!",http://schema.org,NewsArticle,,Writing Your First AI/Machine Learning Program - Towards Data Science,https://towardsdatascience.com/writing-your-first-ai-machine-learning-program-92a590df86de,https://towardsdatascience.com/writing-your-first-ai-machine-learning-program-92a590df86de,,['https://miro.medium.com/v2/resize:fit:1200/1*Bzf775zcidXXXJrEFouPOQ.jpeg'],2020-07-27T15:17:12.011Z,2020-07-27T15:17:12.011Z,2021-12-15T09:51:53.692Z,,"{'@type': 'Person', 'name': 'Tamoghno Bhattacharya', 'url': 'https://towardsdatascience.com/@tamoghnobhattacharya2001'}",,"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",,,,,,,,,,,,,Writing Your First AI/Machine Learning Program - Towards Data Science,,,,,,,,,,,,,['Tamoghno Bhattacharya'],,,,,92a590df86de,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS90aGUtdWx0aW1hdGUtZ3VpZGUtdG8tc21zLXNwYW0tb3ItaGFtLWRldGVjdG9yLTg1ZjNjODI0ZTU1YdIBAA?oc=5,The Ultimate Guide To SMS: Spam or Ham Detector - Towards Data Science,2020-07-31,Towards Data Science,https://towardsdatascience.com,"TL;DR Understanding spam or ham classifier from the aspect of Artificial Intelligence concepts, work with various classification algorithms, and select high accuracy producing algorithms and develop…",N/A,Detailed Report For Developing Spam or Ham Classifier: Part 3,Detailed Report For Developing Spam or Ham Classifier: Part 3,N/A,N/A,"Member-only storyAn Approach with Artificial Intelligence ConceptsThe Ultimate Guide To SMS: Spam or Ham Classifier Using PythonDetailed Report For Developing Spam or Ham Classifier: Part 3Mala Deep·FollowPublished inTowards Data Science·6 min read·Aug 1, 20204671ListenShareDesigned with Canva. Illustration from unDraw.TL;DR Understanding spam or ham classifier from the aspect of Artificial Intelligence concepts, work with various classification algorithms, and select high accuracy producing algorithms and develop the Python Flask App.The blog is a series of the blog post, if you haven’t read the theoretical Artificial Intelligence concept of spam or ham classifier and have not worked with algorithms in jupyter notebook, please explore it at:The Ultimate Guide To SMS: Spam or Ham DetectorDetailed Report for Developing Spam or Ham Classifier: Part 1towardsdatascience.comThe Ultimate Guide To SMS: Spam or Ham DetectorDetailed Report For Developing Spam or Ham Classifier: Part 2towardsdatascience.comWe have covered in part 1 & 2Theoretical AI Concept Regarding Spam or Ham Classifier",http://schema.org,NewsArticle,,The Ultimate Guide To SMS: Spam or Ham Classifier Using Python,https://towardsdatascience.com/the-ultimate-guide-to-sms-spam-or-ham-detector-85f3c824e55a,https://towardsdatascience.com/the-ultimate-guide-to-sms-spam-or-ham-detector-85f3c824e55a,,['https://miro.medium.com/v2/resize:fit:1200/1*kAFUtb4i2R7K2ecRg4AYLA.png'],2020-08-01T05:26:16.951Z,2020-08-01T05:26:16.951Z,2021-12-15T11:53:25.822Z,,"{'@type': 'Person', 'name': 'Mala Deep', 'url': 'https://towardsdatascience.com/@maladeep.upadhaya'}",,"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,,False,,The Ultimate Guide To SMS: Spam or Ham Classifier Using Python,,,,,,,,,,,,,['Mala Deep'],,,,,85f3c824e55a,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vd3d3LnRlY2h0YXJnZXQuY29tL2hlYWx0aHRlY2hhbmFseXRpY3MvbmV3cy8zNjY1OTE1NTQvSEhTLVZBLURPRS1MYXVuY2gtQ09WSUQtMTktQmlnLURhdGEtQW5hbHl0aWNzLUNvbGxhYm9yYXRpdmXSAQA?oc=5,"HHS, VA, DOE Launch COVID-19 Big Data Analytics Collaborative - TechTarget",2020-07-30,TechTarget,https://www.techtarget.com,The COVID-19 Insights Partnership will leverage big data analytics tools to conduct research and find possible treatments for the virus.,N/A,The COVID-19 Insights Partnership will leverage big data analytics tools to conduct research and find possible treatments for the virus.,The COVID-19 Insights Partnership will leverage big data analytics tools to conduct research and find possible treatments for the virus.,N/A,N/A,"


DrAfter123/DigitalVision Vectors
DrAfter123/DigitalVision Vectors





News


HHS, VA, DOE Launch COVID-19 Big Data Analytics Collaborative


The COVID-19 Insights Partnership will leverage big data analytics tools to conduct research and find possible treatments for the virus.





Share this item with your network:














































By


Jessica Kent


Published: 30 Jul 2020


 
The Department of Energy (DOE), the Department of Health and Human Services (HHS), and the Department of Veterans Affairs have announced a new big data analytics initiative to coordinate and share COVID-19 information.







For more coronavirus updates, visit our resource page, updated twice daily by Xtelligent Healthcare Media.
The COVID-19 Insights Partnership creates a framework for HHS and VA to utilize DOE’s world-leading high-performance computing (HPC) and artificial intelligence resources to conduct COVID-19 research and analyze health data that otherwise would not be possible.
“The Department of Energy is proud to be a member of the COVID-19 Insights Partnership,” said Secretary of Energy Dan Brouillette. “Our nation’s understanding of COVID-19 has already benefitted greatly from our world-leading high-performance computing and artificial intelligence resources, and we look forward to continuing our coordination across Federal departments and agencies in the fight against this virus.”
Research and analysis conducted by the COVID-19 Insights Partnership will focus on vaccine and therapeutic development and outcomes, virology, and other critical scientific topics to better understand COVID-19. HHS and VA will provide additional updates and information on research projects as they become available.
“Veterans served this country by putting on the uniform and protecting American interests overseas, and now their health data will help us win the fight against COVID-19 here at home,” said VA Secretary Robert Wilkie. “President Trump is marshalling all the resources he has available in the Federal government to fight the virus, and Veterans should be proud of the role they’re playing.”
The US’s fastest supercomputer, Summit, is located at DOE’s Oak Ridge National Laboratory. The advanced tool is accelerating COVID-19 research by running large-scale, complex analyses on a vast amount of health data.
Summit has the ability to analyze massive integrated datasets and divine insights that will help researchers identify and advance potential treatments and enhance outcomes for COVID-19 patients with extraordinary speed.
“This unprecedented data and computing partnership is the latest addition to President Trump’s whole-of-government effort against COVID-19,” said HHS Secretary Alex Azar. “The volume and quality of the data HHS has on COVID-19 has advanced by leaps and bounds in recent months. The Department of Energy’s world-class resources will help us derive new insights from the data we gather to help patients and protect our country.”
The partnership builds on the government’s efforts to use innovative technologies to track and treat COVID-19. DOE recently joined forces with IBM and the White House Office of Science and Technology Policy to launch the COVID-19 High Performance Computing Consortium.
The initiative provides researchers worldwide with HPC resources and expertise from leading industry, federal government, and academia partners to accelerate COVID-19 vaccine and therapeutic research.
“Since the start of COVID-19 pandemic we have been working closely with governments in the US and worldwide to find all available options to put our technology and expertise to work to help organizations be resilient and adapt to the consequences of the pandemic, and to accelerate the process of discovery and enable the scientific and medical community to develop treatments and ultimately a cure,” said  Dario Gil, director of IBM Research.
Additionally, the White House previously issued a call to action for experts to build artificial intelligence tools that can be applied to a COVID-19 dataset.
“Decisive action from America’s science and technology enterprise is critical to prevent, detect, treat, and develop solutions to COVID-19. The White House will continue to be a strong partner in this all hands-on-deck approach,” said Michael Kratsios, US Chief Technology Officer, the White House.
“We thank each institution for voluntarily lending its expertise and innovation to this collaborative effort, and call on the United States research community to put artificial intelligence technologies to work in answering key scientific questions about the novel coronavirus.”

Next Steps
How Will Big Data Analytics Factor into the Next Phase of COVID-19?Understanding the COVID-19 Pandemic as a Big Data Analytics Issue





Dig Deeper on Artificial intelligence in healthcare



HHS & Partner Agencies Target COVID Tests, Long COVID Treatment




By: Sara Heath




Aqua Comms unveils 400GE transatlantic service for Energy Sciences Network




By: Joe O’Halloran




HHS Unveils Plan for COVID-19 Vaccine Access for Uninsured After PHE End




By: Sara Heath




Did HHS Pandemic Relief Funds Promote Health Equity?




By: Sara Heath







Sponsored News


3 Transformative VDI Use Cases for Hybrid Work
–Dell Technologies


Three Innovative AI Use Cases for Natural Language Processing
–Dell Technologies


Hybrid Work Drives New Criteria for VDI and DaaS
–Dell Technologies

See More





Related Content


Aqua Comms unveils 400GE transatlantic service for ...
– ComputerWeekly.com


Tech giants aim supercomputers, clouds at finding a ...
– Data Center


HHS & Partner Agencies Target COVID Tests, Long ...
– Patient Engagement








",https://schema.org,NewsArticle,,"HHS, VA, DOE Launch COVID-19 Big Data Analytics Collaborative","{'@type': 'WebPage', '@id': 'https://www.techtarget.com/healthtechanalytics/news/366591554/HHS-VA-DOE-Launch-COVID-19-Big-Data-Analytics-Collaborative'}",,,https://cdn.ttgtmedia.com/rms/onlineimages/health analytics_g1479456331.jpg,,2020-07-30T05:30Z,,,"[{'name': 'Jessica Kent', '@type': 'Person'}]",,"{'name': 'TechTarget', 'logo': {'url': 'https://cdn.ttgtmedia.com/rms/amp/amp_teal_logo_115_60.png', 'height': 60, 'width': 115, '@type': 'ImageObject'}, '@type': 'Organization'}",,,,,,"{'cssSelector': '.paywall', '@type': 'WebPageElement', 'isAccessibleForFree': False}",,,,,False,,"HHS, VA, DOE Launch COVID-19 Big Data Analytics Collaborative",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiJGh0dHBzOi8vd21pY2guZWR1L25ld3MvMjAyMC8wNy82MDUwMdIBAA?oc=5,"WMU building foundation for safe, secure artificial intelligence development with NSF grant - WMU News",2020-07-31,WMU News,https://wmich.edu,Drs.,N/A,Drs.,N/A,N/A,N/A,"

                    Contact: Erin FlynnJuly 31, 2020 



Clockwise, from top left: Drs. Alvis Fong, Shameek Bhattacharjee, Ajay Gupta and Steve Carr.



KALAMAZOO, Mich.—Self-driving vehicles. Smart digital personal assistants. Real-time multilingual translators. Artificial intelligence—AI—applications are all around us. A computer science faculty team at Western Michigan University is working to ensure AI isn't hijacked or misused for nefarious reasons. Drs. Alvis Fong, Shameek Bhattacharjee, Steve Carr and Ajay Gupta received a nearly $300,000 grant from the National Science Foundation to create materials for teaching safe, secure and reliable artificial intelligence.
""As AI increasingly permeates every facet of our daily lives, we begin to observe reported cases of AI-related failures and misadventures,"" says Carr. ""We are now at a critical juncture when there is an urgent need to ensure that current and future scientists who advance AI, as well as practitioners who use AI, understand its limitations and how to develop robust and dependable AI.""
Increasing artificial intelligence literacy among students is paramount in helping them understand the technology's limitations and prevent misuse. It also dispels misinformation and fear gleaned from science fiction and sensational stories about AI killing human jobs and obliterating life as we know it.
The WMU team will begin their work in mid-August. Their two-year pilot project will involve designing intensive, multi-faceted, modular and experiential learning units to upgrade the skills of current and future cyberinfrastructure users. The modules could be integrated into existing classes from the freshman level all the way up to postgraduate education.
""Influenced by authoritative sources on AI and guided by a panel of experts drawn from academia, industry and government agencies, we will develop experiential learning modules that provide hands-on learning experiences to a wide spectrum of STEM students at WMU and beyond,"" says Fong.
The team will use best practices and lessons learned from the pilot to craft blueprints for programs that could be implemented across science, technology, engineering and math disciplines in the future. Ultimately, the program will inform training for the next generation of interdisciplinary students.
""The goal is to bring together the areas of AI, computer security and privacy, and computation theory to create a holistic understanding of the power, pitfalls and potential biases of AI algorithms and their widespread use in society,"" Gupta says.
""Beneficial AI can help people work better and more efficiently by helping them amplify their cognitive power,"" adds Bhattacharjee. ""We see a future in productive human-AI collaboration in a way not very different from how steam engines, electricity, telephony and other inventions benefited (and continue to benefit) society on a large scale.""
For more WMU news, arts and events, visit WMU News online.






",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vaXJpc2h0ZWNobmV3cy5pZS9iZXlvbmQtY292aWQtMTktam9icy1pbi1hbC1ibG9ja2NoYWluL9IBP2h0dHBzOi8vaXJpc2h0ZWNobmV3cy5pZS9iZXlvbmQtY292aWQtMTktam9icy1pbi1hbC1ibG9ja2NoYWluLw?oc=5,Beyond Covid-19 jobs in Artificial Intelligence Blockchain - Irish Tech News,2020-07-27,Irish Tech News,https://irishtechnews.ie,"Blockchain and Artificial Intelligence are ‘cutting edge’ technologies: give yourself a ‘cutting edge’ in the jobs market, with a qualification in an area",N/A,The Covid-19 global pandemic has changed the way we work. It has increased the pace of what is already identified as the Fourth Industrial Revolution. For many ,The Covid-19 global pandemic has changed the way we work. It has increased the pace of what is already identified as the Fourth Industrial Revolution. For many ,Featured,N/A,"
Beyond Covid-19: ‘futureproof’ jobs in Artificial Intelligence and Blockchain Simon CockingJuly 28, 2020FeaturedBlockchainBusinessCOVID-19Future TrendsHealthInnovationIrelandTech News









































  Listen to this article    0:00 / 4:43 1X  BeyondWords The Covid-19 global pandemic has changed the way we work. It has increased the pace of what is already identified as the Fourth Industrial Revolution. For many people, it has meant unemployment. Those looking to invest in reskilling or upskilling in order to better position themselves in the jobs market should look to qualifications that are future proof.
Most people have heard of Blockchain as the distributed ledger technology behind cryptocurrencies, such as Bitcoin, but it can be applied in every sector where verified information is required quickly and securely. In 2019, Glassdoor described Blockchain as “one of the hottest tech skills on the market”.
The same article acknowledges the challenges in hiring for this emerging technology. The impetus towards digitisation caused by Covid-19 has increased the pressures on employers to understand and hire for this skill. Deloitte’s 2020 Global Blockchain Survey notes that “business leaders now see it as integral to organisational innovation”.
Qualification in this emerging technology puts graduates at the forefront of an expanding jobs market. National College of Ireland (NCI) offers a part-time Higher Diploma specialising in Blockchain, designed for those coming to ICT from other disciplines.
“At level 8, this course doesn’t assume that you already understand computing, but rather starts by guiding your problem-solving processes and teaching you technical skills. A facility for logic and language is definitely an advantage, and the hard work it takes to learn the fundamentals really pays off when you begin to specialise,” says Sean Heeney, who lectures on the Higher Diploma in Science in Computing at NCI.
Also starting with the basics and working to a sought-after expertise is the Higher Diploma specialising in Artificial Intelligence (AI) and Machine Learning.
At the core of AI and Machine Learning is pattern recognition, which allows computers to quickly react to certain scenarios, to spot anomalies, and to repeat processes consistently without losing concentration. The value to business is clear – but first businesses need to find employees with the necessary technological skills.

KPMG considers AI and Machine Learning to be “key components of the Fourth Industrial Revolution” and vital skills to cultivate in order to encourage foreign direct investment through Ireland’s workforce. A recent survey by PwC and the Analytics Institute reports that Irish business leaders know that AI is essential to maintaining their competitive advantage, but 52% express concern that they will not be able to meet demand for AI skills in the workforce.
The Government’s Future Jobs Ireland report clearly identifies Blockchain and Artificial Intelligence as areas in which Ireland is experiencing a ‘skills gap’. Springboard+ is co-funded by the Government of Ireland and the European Social Fund as part of the ESF Programme for Employability, Inclusion and Learning 2014-2020, and provides courses designed to address the country’s skills gaps.
At NCI, the Higher Diplomas specialising in Blockchain and AI/Machine Learning are funded by Springboard+ and the Human Capital Initiative (HCI) Pillar 1, and so are free of charge to those who are currently not working, and 90% of the cost of fees is covered for those who are in employment
Blockchain and Artificial Intelligence are ‘cutting edge’ technologies: give yourself a ‘cutting edge’ in the jobs market, with a qualification in an area where the supply of suitable candidates cannot yet meet the demand by employers.
Want to learn more about National College of Ireland’s funded courses in blockchain and AI & Machine Learning? Register for their online sample class taking place on Tuesday 28th July at 6 pm.

More about Irish Tech News and Business Showcase here.
FYI the ROI for you is => Irish Tech News now gets over 1.5 million monthly views, and up to 900k monthly unique visitors, from over 160 countries. We have over 860,000 relevant followers on Twitter on our various accounts & were recently described as Ireland’s leading online tech news site and Ireland’s answer to TechCrunch, so we can offer you a good audience!
Since introducing desktop notifications a short time ago, which notify readers directly in their browser of new articles being published, over 50,000 people have now signed up to receive them ensuring they are instantly kept up to date on all our latest content. Desktop notifications offer a unique method of serving content directly to verified readers and bypass the issue of content getting lost in people’s crowded news feeds.
Drop us a line if you want to be featured, guest post, suggest a possible interview or just let us know what you would like to see more of in our future articles. We’re always open to new and interesting suggestions for informative and different articles. Contact us, by email, twitter or whatever social media works for you and hopefully, we can share your story too and reach our global audience. We are agile, responsive, quick and talented, we look forward to working with you!
If you would like to have your company featured in the Irish Tech News Business Showcase, get in contact with us at Simon@IrishTechNews.ie or on Twitter: @SimonCocking 










































More about Irish Tech News
Irish Tech News are Ireland’s No. 1 Online Tech Publication and often Ireland’s No.1 Tech Podcast too.
You can find hundreds of fantastic previous episodes and subscribe using whatever platform you like via our Anchor.fm page here: https://anchor.fm/irish-tech-news
If you’d like to be featured in an upcoming Podcast email us at Simon@IrishTechNews.ie now to discuss.
Irish Tech News have a range of services available to help promote your business. Why not drop us a line at Info@IrishTechNews.ie now to find out more about how we can help you reach our audience.
You can also find and follow us on Twitter, LinkedIn, Facebook, Instagram, TikTok and Snapchat.






 AIBlockchainCovid-19Previous ArticleHow Does Technology Help Startup Businesses Succeed?Next ArticleWhy Electric vehicles can save lives 
",https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://irishtechnews.ie/#organization', 'name': 'Infused Media', 'url': 'https://irishtechnews.ie'}, {'@type': 'WebSite', '@id': 'https://irishtechnews.ie/#website', 'url': 'https://irishtechnews.ie', 'name': 'Infused Media', 'publisher': {'@id': 'https://irishtechnews.ie/#organization'}, 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://irishtechnews.ie/wp-content/uploads/2020/07/0Z6A0020.jpg', 'url': 'https://irishtechnews.ie/wp-content/uploads/2020/07/0Z6A0020.jpg', 'width': '1417', 'height': '945', 'caption': 'Covid-19, AI, Blockchain', 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://irishtechnews.ie/beyond-covid-19-jobs-in-al-blockchain/#webpage', 'url': 'https://irishtechnews.ie/beyond-covid-19-jobs-in-al-blockchain/', 'name': 'Beyond Covid-19 jobs in Artificial Intelligence Blockchain', 'datePublished': '2020-07-28T10:00:04+01:00', 'dateModified': '2021-01-05T00:22:53+00:00', 'isPartOf': {'@id': 'https://irishtechnews.ie/#website'}, 'primaryImageOfPage': {'@id': 'https://irishtechnews.ie/wp-content/uploads/2020/07/0Z6A0020.jpg'}, 'inLanguage': 'en-US'}, {'@type': 'BlogPosting', 'headline': 'Beyond Covid-19 jobs in Artificial Intelligence Blockchain', 'datePublished': '2020-07-28T10:00:04+01:00', 'dateModified': '2021-01-05T00:22:53+00:00', 'author': {'@type': 'Person', 'name': 'Simon Cocking'}, 'name': 'Beyond Covid-19 jobs in Artificial Intelligence Blockchain', '@id': 'https://irishtechnews.ie/beyond-covid-19-jobs-in-al-blockchain/#schema-1035740', 'isPartOf': {'@id': 'https://irishtechnews.ie/beyond-covid-19-jobs-in-al-blockchain/#webpage'}, 'publisher': {'@id': 'https://irishtechnews.ie/#organization'}, 'image': {'@id': 'https://irishtechnews.ie/wp-content/uploads/2020/07/0Z6A0020.jpg'}, 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://irishtechnews.ie/beyond-covid-19-jobs-in-al-blockchain/#webpage'}}]",,,,,,,,,
https://news.google.com/rss/articles/CBMibmh0dHBzOi8vd3d3LnB1bmVrYXJuZXdzLmluL3B1bmUtdW5pdmVyc2l0eS1qb2lucy1oYW5kcy13aXRoLXN0YXJ0dXAtZGVlcHRlay10by13b3JrLW9uLWFpLWhlYWx0aGNhcmUtcmVzZWFyY2gv0gEA?oc=5,"Pune University joins hands with startup DeepTek to work on AI, healthcare research - Punekar News",2020-07-30,Punekar News,https://www.punekarnews.in,"- Pune University joins hands with startup DeepTek to work on AI, healthcare research",N/A,"- Pune University joins hands with startup DeepTek to work on AI, healthcare research",N/A,N/A,N/A,"






 
                                 Pune
                             
 
Pune University joins hands with startup DeepTek to work on AI, healthcare research






 



Share this News:FacebookTwitterWhatsAppLinkedInTelegramMessagePune, 30 July 2020: A letter of intent was signed between the Centre for Innovation, Incubation and Enterprise(CIIE) at Savitribai Phule Pune University (SPPU) with healthcare startup DeepTek to provide market linkage and work on innovative research proposals in healthcare and Artificial Intelligence (AI) domain jointly.
SPPU Vice-Chancellor Dr Nitin Karmalkar, Pro VC Dr Umarani, Dr Apoorva Palkar-Director Innovation at SPPU and co-founders of Deeptek Ajit Patil, Anuruddha Pant and Dr Amit Kharat were present on the occasion.
“SPPU is keen to support startups working in COVID diagnostics and provide them access to the ecosystem. This aligns to our vision set up for the proposed centre for molecular diagnostic and research centre being set up at the University”, informed Dr Nitin R Karmalkar, Vice Chancellor SPPU.
Dr Apoorva Palkar, Director IIL-SPPU, “Centre for innovation helps startups for validating and scaling up and Deeptek a startup that provides innovative solution using AI in image processing through X Ray and CT scan is a novel initiative that can be a great breather when testing is most crucial.”
CIIE will support the healthcare startup working in the space of radiology artificial intelligence to validate the innovative “Radiology Optimization Platform” called Augmento. Augmento has innovated the space of diagnosis and radiology reporting by embedding AI artificial intelligence (AI) in medical image analysis and workflow thereby augmenting imaging experts, radiology administrators, floor managers and hospital administrators. This breakthrough solution will be administered in various COVID-19 Hospitals in the coming months
Augmento is an ancillary tool for diagnosis of Covid19 pneumonia-like pattern from Digital Radiographs and CT. Augmento allows to do an instant triage and prescreen from an Xray and/or CT imaging into normal or suspicious for Covid19 within few seconds and it can be supplemented with a clinically validated structured quantified radiology report within 60 minutes of completing the study.
Augmento has a powerful analytics tool which has been used for disease detection, notification, generating instant alerts and strengthening patient follow up and last-mile screening, a tool especially valuable for nodal officers monitoring infectious diseases and will be very useful for Covid19 screening. This tool also has empowered imaging experts, thereby allowing them to significantly reduce radiology report turnaround time in hospitals and/or mobile van-based x-ray screening.
CIIE is working very closely with startups and focusing on healthcare and diagnostics. Currently, it has more than 40 startups working in the centre.
“Over the last 12 months, more than one lakh patients have been screened using the AI-enabled smart platform for TB screening. Apart from TB, the platform screens digital chest radiographs for 18 different pathologies including Covid19 like pneumonia patterns”, said DeepTek MD Ajit Patil.
DeepTek is a Pune based startup funded by NTT DATA Japan, Nobori, Japan and GHV accelerator.



Continue Reading
Previous Pune: City schools shine in SSC results this yearNext Pune: 2613 new Corona patients in Pune district, 66 deaths
 





                        Similar News                    







 




 
                                 Pune
                             
 




                                            Pune: 16-Year-Old Girl Dies by Suicide After Party in Yerawada; Another Teen Hospitalized                                        














 




 
                                 Pune
                             
 




                                            Breaking News: Controversial IAS Puja Khedkar’s District Training Program Put On Hold By LBSNAA, Recalled To Academy                                        














 




 
                                 Pune
                             
 




                                            Video of IAS Puja Khedkar’s Mother Arguing with Pune Metro Workers Goes Viral                                        












",https://schema.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', '@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/#article', 'isPartOf': {'@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/'}, 'author': {'name': 'Reporter', '@id': 'https://www.punekarnews.in/#/schema/person/1b7aae031961f90deacbe48bd80f121c'}, 'headline': 'Pune University joins hands with startup DeepTek to work on AI, healthcare research', 'datePublished': '2020-07-29T19:33:02+00:00', 'dateModified': '2020-07-29T19:45:38+00:00', 'mainEntityOfPage': {'@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/'}, 'wordCount': 466, 'publisher': {'@id': 'https://www.punekarnews.in/#organization'}, 'image': {'@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/#primaryimage'}, 'thumbnailUrl': 'https://www.punekarnews.in/wp-content/uploads/2020/07/WhatsApp-Image-2020-07-29-at-4.53.33-PM-e1596051161975.jpeg', 'articleSection': ['Pune'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/', 'url': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/', 'name': 'Pune University joins hands with startup DeepTek to work on AI, healthcare research - Punekar News', 'isPartOf': {'@id': 'https://www.punekarnews.in/#website'}, 'primaryImageOfPage': {'@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/#primaryimage'}, 'image': {'@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/#primaryimage'}, 'thumbnailUrl': 'https://www.punekarnews.in/wp-content/uploads/2020/07/WhatsApp-Image-2020-07-29-at-4.53.33-PM-e1596051161975.jpeg', 'datePublished': '2020-07-29T19:33:02+00:00', 'dateModified': '2020-07-29T19:45:38+00:00', 'description': '- Pune University joins hands with startup DeepTek to work on AI, healthcare research', 'breadcrumb': {'@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/#primaryimage', 'url': 'https://www.punekarnews.in/wp-content/uploads/2020/07/WhatsApp-Image-2020-07-29-at-4.53.33-PM-e1596051161975.jpeg', 'contentUrl': 'https://www.punekarnews.in/wp-content/uploads/2020/07/WhatsApp-Image-2020-07-29-at-4.53.33-PM-e1596051161975.jpeg', 'width': 1024, 'height': 440, 'caption': 'Pune University SPPU AI DeepTek'}, {'@type': 'BreadcrumbList', '@id': 'https://www.punekarnews.in/pune-university-joins-hands-with-startup-deeptek-to-work-on-ai-healthcare-research/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.punekarnews.in/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Pune University joins hands with startup DeepTek to work on AI, healthcare research'}]}, {'@type': 'WebSite', '@id': 'https://www.punekarnews.in/#website', 'url': 'https://www.punekarnews.in/', 'name': 'Punekar News', 'description': 'Pune News, Pimpri-Chinchwad News', 'publisher': {'@id': 'https://www.punekarnews.in/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.punekarnews.in/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.punekarnews.in/#organization', 'name': 'Punekar News', 'url': 'https://www.punekarnews.in/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.punekarnews.in/#/schema/logo/image/', 'url': 'https://www.punekarnews.in/wp-content/uploads/2024/02/Punekarnews.png', 'contentUrl': 'https://www.punekarnews.in/wp-content/uploads/2024/02/Punekarnews.png', 'width': 1024, 'height': 1024, 'caption': 'Punekar News'}, 'image': {'@id': 'https://www.punekarnews.in/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/punekarnews/', 'https://x.com/punekarnews', 'https://www.instagram.com/punekarnews']}, {'@type': 'Person', '@id': 'https://www.punekarnews.in/#/schema/person/1b7aae031961f90deacbe48bd80f121c', 'name': 'Reporter', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.punekarnews.in/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/7665183f8c33fcdf1003d22e63e3442d?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/7665183f8c33fcdf1003d22e63e3442d?s=96&d=mm&r=g', 'caption': 'Reporter'}, 'sameAs': ['https://www.punekarnews.in'], 'url': 'https://www.punekarnews.in/author/deltaforce/'}]",,,,,,,,,

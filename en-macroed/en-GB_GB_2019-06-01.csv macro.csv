URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,mainEntityOfPage,dateCreated,heading,abstract,articleBody,hasPart,mainEntity,isBasedOn,thumbnailUrl,isPartOf,alternativeHeadline,genre,wordcount,@graph
https://news.google.com/rss/articles/CBMilAFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2Jlcm5hcmRtYXJyLzIwMTkvMDYvMDUvdGhlLWluY3JlZGlibGUtYXV0b25vbW91cy1zaGlwcy1vZi10aGUtZnV0dXJlLXJ1bi1ieS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yYXRoZXItdGhhbi1hLWNyZXcv0gEA?oc=5,The Incredible Autonomous Ships Of The Future: Run By Artificial Intelligence Rather Than A Crew - Forbes,2019-06-05,Forbes,https://www.forbes.com,"We have uncrewed aerial vehicles and self-driving cars, why not autonomous ships? The first fully autonomous ferry was deployed in Finland. Companies are investing in projects to build other fully autonomous ships as well as autonomous technologies to retrofit existing vessels.",,"We have uncrewed aerial vehicles and self-driving cars, why not autonomous ships? The first fully autonomous ferry was deployed in Finland. Companies are investing in projects to build other fully autonomous ships as well as autonomous technologies to retrofit existing vessels.","We have uncrewed aerial vehicles and self-driving cars, why not autonomous ships? The first fully autonomous ferry was deployed in Finland. Companies are investing in projects to build other fully autonomous ships as well as autonomous technologies to retrofit existing vessels.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2019/06/05/the-incredible-autonomous-ships-of-the-future-run-by-artificial-intelligence-rather-than-a-crew/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/bernardmarr/files/2019/06/New-1200x655.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",The Incredible Autonomous Ships Of The Future: Run By Artificial Intelligence Rather Than A Crew,2019-06-05T00:23:00-04:00,2019-06-11T15:30:56-04:00,Enterprise & Cloud,The Incredible Autonomous Ships Of The Future: Run By Artificial Intelligence Rather Than A Crew,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise & Cloud,N/A,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryInnovationEnterprise TechThe Incredible Autonomous Ships Of The Future: Run By Artificial Intelligence Rather Than A CrewBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowJun 5, 2019,12:23am EDTUpdated Jun 11, 2019, 03:30pm EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to LinkedinThere has been a lot of discussion about autonomous vehicles on the land and in the air, but what about on the sea? While the world got the first glimpse of a fully autonomous ferry thanks to the collaboration between Rolls-Royce and Finferries, the state-owned ferry operator of Finland, there’s still quite a bit of work to be done before we can expect the world’s waterways to be overtaken with autonomous vessels.








The Incredible Autonomous Ships Of The Future: Run By Artificial Intelligence Rather Than A Crew
Adobe Stock






Levels of Autonomy
Even though we might be years or even decades away from the majority of vessels becoming autonomous, there are certainly artificial intelligence algorithms at work today. A fully autonomous ship would be considered a vessel that can operate on its own without a crew. Remote ships are those that are operated by a human from shore, and an automated ship runs software that manages its movements. As the technology matures, more types of ships will likely transition from being manned to having some autonomous capabilities. Autonomous ships might be used for some applications, but it's quite possible that there will still be crew onboard some ships even if all hurdles to acquiring a fully autonomous fleet are crossed.
Autonomy in Ships
As we saw with the Finnish ferry, the first autonomous ships will be deployed on simple inland or coastal liner applications where waters are calm, the route is simple, and there isn't much traffic.
PROMOTED
There’s also an inland electric container ship, Yara Birkeland, under construction that is expected to be completed in 2020 and fully autonomous by 2022. Some companies are building fully autonomous ships from scratch, while other start-ups are developing semi-autonomous systems to be used on existing vessels. When Rolls-Royce sold its autonomous maritime division to Kongsberg, it gave the Norwegian company a boost in its goal of being a leader in the autonomous shipping industry. Samsung is another company that uses machine learning, augmented reality, analytics, and more to create a smart shipping platform through its Samsung Heavy Industries division.
Existing cargo ships have the chance to get retrofitted with autonomous technologies thanks to the efforts of start-ups such as San Francisco-based Shone. Shone’s technology helps crews with piloting assistance and to detect and predict the movement of other vessels in the waterway.
Benefits of Autonomous Ships
Just as artificial intelligence and autonomy promise in other applications, it is expected that autonomous ships can improve safety, increase efficiency, and relieve humans from unsafe and repetitive tasks.
According to a study by Allianz, between 75% and 96% of maritime accidents are caused by human error. If autonomous and semi-autonomous systems can help reduce the reliance on humans that can make mistakes due to fatigue or bad judgment, autonomous ships could eventually make our oceans safer. Even if a crew is on board, the data gathered from the ship’s sensors combined with artificial intelligence algorithms will help the crew make better-informed decisions.
A reduction or elimination of crew reduces the personnel and auxiliary costs (such as onboard provisions and insurance) on a voyage. Typically, crew-related expenses account for 30% of the budget. There are also efficiencies realized in ship design and use of fuel. One study projected savings of more than $7 million over 25 years per autonomous vessel from fuel savings and crew supplies and salaries.
Hurdles to Overcome
Since there are significant safety concerns especially with the enormous size of most ships operating in congested waters, there is a lot more testing to be done and regulations to be sorted out before we will see fully autonomous vessels operating without a crew. Much more likely is that automated technologies will be used to reduce crews and to help the crew onboard make effective decisions. In addition to ensuring the safety of ships, there needs to be a resolution about the regulation of our shared water. Existing international conventions were created under the assumption a crew would be on board. In response, the International Maritime Organization (IMO) has kicked off its work to assess and update conventions to ensure safety in a new reality when AI is the captain instead of humans.
Until there is significant interest in fast-tracking research, development, and updates to regulations for autonomous ships, the industry will likely learn from the decisions made on land regarding autonomous cars and then apply that to autonomous ships. Adoption and acceptance of autonomous cars in the coming years may put pressure on finding the same solutions for the sea.Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9mZWF0dXJlZC1pbnNpZ2h0cy9nZW5kZXItZXF1YWxpdHkvdGhlLWZ1dHVyZS1vZi13b21lbi1hdC13b3JrLXRyYW5zaXRpb25zLWluLXRoZS1hZ2Utb2YtYXV0b21hdGlvbtIBAA?oc=5,The future of women at work: Transitions in the age of automation - McKinsey,2019-06-04,McKinsey,https://www.mckinsey.com,"New job opportunities await women at work, but they also face new challenges overlaid on long-established ones in the age of automation.",N/A,"New job opportunities await women at work, but they also face new challenges overlaid on long-established ones in the age of automation.","New job opportunities await women at work, but they also face new challenges overlaid on long-established ones in the age of automation.",https://schema.org,Report,https://www.mckinsey.com,https://www.mckinsey.com/~/media/mckinsey/featured%20insights/gender%20equality/the%20future%20of%20women%20at%20work%20transitions%20in%20the%20age%20of%20automation/future-of-women-standard-1536x1536-final.jpg,"[{'@type': 'Person', 'name': 'Anu Madgavkar', 'url': 'https://www.mckinsey.com/our-people/anu-madgavkar'}, {'@type': 'Person', 'name': 'James Manyika', 'url': 'https://www.mckinsey.com/our-people/james-manyika'}, {'@type': 'Person', 'name': 'Mekala Krishnan', 'url': 'https://www.mckinsey.com/our-people/mekala-krishnan'}, {'@type': 'Person', 'name': 'Kweilin Ellingrud', 'url': 'https://www.mckinsey.com/our-people/kweilin-ellingrud'}, {'@type': 'Person', 'name': 'Lareina Yee', 'url': 'https://www.mckinsey.com/our-people/lareina-yee'}, {'@type': 'Person', 'name': 'Lola Woetzel'}, {'@type': 'Person', 'name': 'Michael Chui', 'url': 'https://www.mckinsey.com/our-people/michael-chui'}, {'@type': 'Person', 'name': 'Dame Vivian Hunt'}, {'@type': 'Person', 'name': 'Sruti Balakrishnan'}]","{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,2019-06-04T00:00:00Z,2019-06-04T00:00:00Z,,,,,N/A,N/A,N/A,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/featured-insights/gender-equality/the-future-of-women-at-work-transitions-in-the-age-of-automation'}",2019-05-31T17:48:20Z,The future of women at work: Transitions in the age of automation,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LmpvdXJuYWxvZmFjY291bnRhbmN5LmNvbS9pc3N1ZXMvMjAxOS9qdW4vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tYXVkaXQuaHRtbNIBAA?oc=5,How we successfully implemented AI in audit - Journal of Accountancy,2019-06-01,Journal of Accountancy,https://www.journalofaccountancy.com,A partner at Garbelman Winslow CPAs describes the Maryland firm’s experience using machine learning to improve its audit process.,,A partner at Garbelman Winslow CPAs describes the Maryland firm’s experience using machine learning to improve its audit process.,N/A,http://schema.org,NewsArticle,,"{'@type': 'ImageObject', 'url': 'https://www.journalofaccountancy.com/content/dam/jofa/issues/2019/jun/samantha-bowling-640.jpg', 'height': 388, 'width': 640}","{'@type': 'Person', 'name': 'By Samantha Bowling, CPA, CGMA, as told to Cheryl Meyer'}","{'@type': 'NewsMediaOrganization', '@id': 'https://www.journalofaccountancy.com', 'name': 'Journal of Accountancy', 'logo': {'@type': 'ImageObject', 'url': 'https://www.journalofaccountancy.com/content/dam/jofa/info/jofa-logo-black-600.jpg', 'width': 600, 'height': 109}}",How we successfully implemented AI in audit,2019-06-01T05:00:00.000-04:00,2019-06-01T05:00:00.000-04:00,,,,,N/A,N/A," June 1, 2019What’s ‘critical’ for CPAs to learn in an AI-powered world","{'@type': 'WebPage', '@id': 'https://www.journalofaccountancy.com/issues/2019/jun/artificial-intelligence-in-audit.html'}",,,A partner at Garbelman Winslow CPAs describes the Maryland firm’s experience using machine learning to improve its audit process.,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3Lm5ld3N3aXJlLmNvbS9uZXdzL3BhY3MtaGFybW9ueS1pbnRlZ3JhdGVzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXJlc3VsdHMtd2l0aC11bml2ZXJzYWwtMjA5MTUwMDLSAQA?oc=5,PACS Harmony Integrates Artificial Intelligence Results With Universal Work List - Newswire,2019-06-05,Newswire,https://www.newswire.com,                                              Visit Us At SIIM - Booth #219,"AI, Machine Learning, Radiology, Universal Work List, Workflow",                                              Visit Us At SIIM - Booth #219,                                              Visit Us At SIIM - Booth #219,https://schema.org,NewsArticle,,['https://cdn.nwe.io/files/x/c4/77/7ce4e37ef3e0abc2b5902e15d5e1.jpg'],"{'0': {'@type': 'Organization', 'name': 'Infervision'}, 'url': 'https://www.infervision.com/en '}","{'@type': 'Organization', 'name': 'Newswire', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.nwe.io/assets/im/website_alt/logo.svg?v=fabe881f7'}}",PACS Harmony Integrates Artificial Intelligence Results With Universal Work List,2019-06-05T22:26:00.000000Z,2019-06-05T22:26:35.000000Z,,,,,N/A,N/A,"


PACS Harmony Integrates Artificial Intelligence Results With Universal Work List

Press Release
•


                                    updated: Jun 5, 2019                            



                                                                      Visit Us At SIIM - Booth #219                    


























 
        BRANDON, Fla., June 5, 2019 (Newswire.com)
        -
    PACS Harmony, a leading provider of radiology workflow optimization tools, will integrate Infervision's AI suite into their Universal Work List (UWL) with the Optimizer engine for reading prioritization across the Enterprise. This integration will allow radiologists to automatically and seamlessly reap the benefits of advanced and proven AI technology, resulting in greater efficiency and diagnostic accuracy.
According to PACS Harmony founder and president, Dr. Michael Esposito, ""Our goal has always been to provide radiologists with the most advanced tools available, and integrating AI into their workflow is the key to the successful deployment of this exciting new technology. In addition to providing enterprise work list efficiencies, the Optimizer system will become a platform offering a wide variety of advanced tools, including Infervision's suite of ""Assistive Intelligence"" tools. Our clients will be able to select the modules they need, such as Lung, Cardiac, Liver, Stroke or MSK. When an exam is selected, the results from Infervision's system will be automatically available for review and/or inclusion into the final report.""
""We're very excited to be working with a partner like PACS Harmony,"" stated Infervision VP Tony Gevo. ""As a world leader in Deep Learning for medical imaging, we realize that the best tools and technologies will only reach their full potential in improving human life when they're easy for physicians to use, and integration into accepted workflow is the key. If AI isn't easy to use, it won't be used, and the UWL system from PACS Harmony will make this technology easily available to the radiologist.""
About PACS Harmony
The PACS Harmony Universal Work List with patented Optimizer technology provides an equitable distribution of imaging studies for interpretation via a ubiquitous web browser. As a vendor independent platform, PACS Harmony drives interpretation efficiency from disparate PACS and voice recognition systems. For more information, visit www.pacsharmony.com
About Infervision
​​Infervision is an international company with U.S. headquarters in Philadelphia, Pennsylvania. With over 300 employees worldwide dedicated to medical imaging AI technology, its products are in use in Asia, Europe and North America.  Each day over 33,000 exams are submitted to the InferRead suite. For more information visit: https://www.infervision.com/en.​
Contact: 



PACS Harmony
Dean Whitt
719-445-6490
dean.whitt@pacsharmony.com


Infervision
Haiyun Wang

(919)886-6082


usa@infervision.com
PACS Harmony Integrates Artificial Intelligence Results with Universal Work List     Visit Us At SIIM - Booth #219



Source: PACS Harmony
Related Media


















Tags


AI


Machine Learning


Radiology


Universal Work List


Workflow





Related Files



 PACS Harmony Overview
        



 InferScholar Whitepaper
        



",,,,,"			
<div>
<p>PACS Harmony, a leading provider of radiology workflow optimization tools, will integrate Infervision's AI suite into their Universal Work List (UWL) with the Optimizer engine for reading prioritization across the Enterprise. This integration will allow radiologists to automatically and seamlessly reap the benefits of advanced and proven AI technology, resulting in greater efficiency and diagnostic accuracy.</p>
<p>According to PACS Harmony founder and president, Dr. Michael Esposito, ""Our goal has always been to provide radiologists with the most advanced tools available, and integrating AI into their workflow is the key to the successful deployment of this exciting new technology. In addition to providing enterprise work list efficiencies, the Optimizer system will become a platform offering a wide variety of advanced tools, including Infervision's suite of ""Assistive Intelligence"" tools. Our clients will be able to select the modules they need, such as Lung, Cardiac, Liver, Stroke or MSK. When an exam is selected, the results from Infervision's system will be automatically available for review and/or inclusion into the final report.""</p>
<p>""We're very excited to be working with a partner like PACS Harmony,"" stated Infervision VP Tony Gevo. ""As a world leader in Deep Learning for medical imaging, we realize that the best tools and technologies will only reach their full potential in improving human life when they're easy for physicians to use, and integration into accepted workflow is the key. If AI isn't easy to use, it won't be used, and the UWL system from PACS Harmony will make this technology easily available to the radiologist.""</p>
<p>About PACS Harmony</p>
<p>The PACS Harmony Universal Work List with patented Optimizer technology provides an equitable distribution of imaging studies for interpretation via a ubiquitous web browser. As a vendor independent platform, PACS Harmony drives interpretation efficiency from disparate PACS and voice recognition systems. For more information, visit <a href=""http://www.pacsharmony.com/"">www.pacsharmony.com</a></p>
<p>About Infervision</p>
<p>​​Infervision is an international company with U.S. headquarters in Philadelphia, Pennsylvania. With over 300 employees worldwide dedicated to medical imaging AI technology, its products are in use in Asia, Europe and North America.  Each day over 33,000 exams are submitted to the InferRead suite. For more information visit: <a href=""https://www.infervision.com/en"">https://www.infervision.com/en</a>.​</p>
<p>Contact: </p>
</div>
<div>
<div>
<p><strong>PACS Harmony</strong></p>
<p>Dean Whitt</p>
<p>719-445-6490</p>
<p>dean.whitt@pacsharmony.com</p>
</div>
<div>
<p><strong>Infervision</strong></p>
<p>Haiyun Wang</p>
</div>
<div><p>(919)886-6082</p></div>
<div></div>
<div>
<p><a href=""mailto:usa@infervision.com%20"">usa@infervision.com</a></p>
<p><strong>PACS Harmony Integrates Artificial Intelligence Results with Universal Work List     Visit Us At SIIM - Booth #219</strong></p>
</div>
</div>
		",,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vd3d3LnRlY2h0YXJnZXQuY29tL3NlYXJjaGl0b3BlcmF0aW9ucy9mZWF0dXJlL0V2YWx1YXRlLUFJLWJhc2VkLUlUU00tdG9vbHMtdXNpbmctdGhlc2Uta2V5LXBvaW50c9IBAA?oc=5,Evaluate AI-based ITSM tools using these key points - TechTarget,2019-06-03,TechTarget,https://www.techtarget.com,"After determining that artificial intelligence would benefit an IT environment, the next big challenge is to assess AI-based ITSM tools in terms of feature set and pricing model.",N/A,"AIOps tools help IT admins focus on more strategic, bigger-picture tasks within the enterprise. Discover the different buying options for AI-based ITSM tools, as well as key features to look for around automation, integration and more.","AIOps tools help IT admins focus on more strategic, bigger-picture tasks within the enterprise. Discover the different buying options for AI-based ITSM tools, as well as key features to look for ar...",https://schema.org,Article,,https://cdn.ttgtmedia.com/visuals/searchVirtualDesktop/tools_technology/virtualdesktop_article_012.jpg,"[{'name': 'Doug Tedder', '@type': 'Person'}]","{'name': 'TechTarget', 'logo': {'url': 'https://cdn.ttgtmedia.com/rms/amp/amp_teal_logo_115_60.png', 'height': 60, 'width': 115, '@type': 'ImageObject'}, '@type': 'Organization'}",Evaluate AI-based ITSM tools using these key points,2019-06-03T14:39Z,,,Evaluate AI-based ITSM tools using these key points,False,,N/A,N/A,"


JRB - Fotolia
JRB - Fotolia





Feature


Evaluate AI-based ITSM tools using these key points


After determining that artificial intelligence would benefit an IT environment, the next big challenge is to assess AI-based ITSM tools in terms of feature set and pricing model.





Share this item with your network:

















































By


Doug Tedder,
Tedder Consulting LLC



Published: 03 Jun 2019


 
The application of artificial intelligence to IT operations -- or AIOps -- enables an organization to codify existing IT knowledge, based upon historical data and information. For IT practitioners, this produces a number of benefits, including reduced manual efforts and more time for strategic tasks.







Before implementing AI-based IT service management (ITSM) tools, however, buyers need to assess features around automation and integration, as well as licensing and pricing models.

What to buy
AI-based ITSM platforms have a similar, overarching goal -- to make it easier to interact with ITSM processes and reduce or eliminate the tedious and repetitive work that often comes with end-user support. For example, chatbots and virtual agents engage an end user in a conversation-like interaction to simplify service requests and incident logging.
More specifically, the AI-based ITSM market focuses on three areas. The first, and perhaps most prevalent, is service desk augmentation. Chatbots and virtual agents are the dominant tools, enabling self-help capabilities for end users and deflecting contacts from the service desk. The second area is automation. Process orchestration and robotic process automation take on the often tedious and repetitive tasks that IT organizations perform. The third area is data and operational consolidation. Machine learning and natural language processing enhance automation platforms, enabling them to interpret and apply appropriate, context-specific actions.
Some AI-enabled ITSM tools address the repetitive aspects of service desk work, but also the broader operation of an IT environment. These tools might proactively respond to events, but also interpret existing data, predict performance and suggest certain actions. Other tools offer low code/no code capabilities for visual workflow design; integration kits to work alongside other, non-ITSM tools; and AI-assisted workflow design.
While it is possible for an organization to use open source platforms and APIs to build its own AI features and tools, this places the burden of maintenance and support on the organization itself.


How to buy
AI-based ITSM systems are typically available in one of the following three ways:

AI functionality integrates with the ITSM platform: Some of the ITSM tool vendors, such as SysAid and Micro Focus, have integrated AI features like chatbots and machine learning into their main product offering.
AI functionality is available as a separate module, feature or add-on to the ITSM tool. ServiceNow’s ITSM Pro package and ManageEngine’s Zia plug-in for ServiceDesk Plus Cloud are examples of this approach.
AI functionality is available as a stand-alone platform: These vendors provide integrations with disparate data sources and multiple tools, providing a single IT management view. AISERA and BigPanda are among some of the vendor examples of this approach.



Editor's note: With extensive research into the ITSM tool market, TechTarget editors have focused this series of articles on vendors with considerable market presence and that offer ITSM tools with AI functionalities that can be classified as responsive, proactive, predictive and autonomous. Our research included Gartner, Forrester Research and TechTarget surveys.


AI-enabled ITSM tools also follow a broad range of licensing models, including the following:

Per user or per named user: The price of AI functionality is based on the number of users of the product.
Per transaction or bundles of transactions: Pricing is based on the number of transactions the AI feature executes, such as during chatbot use. Some vendors provide bundled pricing, where users can purchase blocks of transactions to help predict and control costs.
Number of workflow automations: This is similar to the transaction licensing model, but based on the number of workflow automations configured within the product.
Number of integrations: Pricing is based on the number of integrations configured within the tool.
Value-based: The price of the license is based on the value that the system provides to the organization.



Good data enables good AI
For an AI-enabled ITSM tool to be successful, it requires relevant data and information.






To understand tool-based intelligence, buyers should think in terms of the data, information, knowledge and wisdom (DIKW) model and how its hierarchy enables better information science.
The data, information and knowledge layers represent current and historical operations. ITSM practitioners typically apply their individual knowledge or repository-based knowledge in reaction to events and circumstances within the managed IT environment. Knowledge sharing is only voluntary, so various team members will repeatedly solve issues that are already known to the organization. Knowledge-based reactions are also vulnerable to the individual's perception and interpretation of data and information. Wisdom, in this operating model, is the byproduct of time and experience. Seasoned ITSM practitioners can answer the why do and know why questions, but their wisdom is transactional and easily lost.



Before implementing AI-enabled ITSM tools, however, buyers need to assess features around automation and integration, as well as licensing and pricing models.




AI-enabled ITSM products promise to codify the knowledge gleaned from historical data and information to help practitioners look ahead, develop strategies and evaluate opportunities. AI can also develop new knowledge from new data and information, at a scale greater than individuals could achieve.
Make no mistake: Effective AI use is not just the result of good knowledgebase articles. Incident and request records can also help AIOps tools ""learn,"" and an accurate and well-maintained configuration management database (CMDB) enables tools to analyze situations and suggest actions -- fully aware of the relationships between a faulty configuration item and other configuration items.
Other data can and should be part of AI enablement. Integrate data from monitoring and alerting tools to help AI platforms proactively anticipate and take corrective actions. As changes occur within the CMDB, the AI tool can update corresponding information in the IT asset management database and vice versa.
Without established practices for data, information, and knowledge, AI-enabled ITSM tools will struggle. Fortunately, many of these tools provide myriad options to address that issue. Pre-defined workflows and actions, repositories of keywords and contextual phrases, vendor-supplied knowledge articles and supervised learning models can help introduce AI within an ITSM environment.
If AI in ITSM succeeds, people can work at the wisdom level, bypassing the data and information levels of the DIKW model, because knowledge is captured and applied consistently.


Some AI and ITSM wisdom
Here are five tips to prepare for a successful AI implementation:

Assess readiness. If the current ITSM environment is too high-touch and maintenance-intensive, AI-enabled ITSM tools might not be the best investment. Invest first in improved process design and effective governance.
Don't overlook governance. Without a well-defined approach to governance, AI technologies may inadvertently, or even maliciously, function in ways that contradict the organization's mission and vision. Companies must define and enforce policies and procedures to address issues, such as ethical AI behaviors, or ensure the integrity and accuracy of data acted upon by AI technologies.
Take a portfolio approach. In the rapidly evolving ITSM market, wise IT shops take a longer view of AI use. Identify and implement quick wins, conduct experiments to grow skills and define and establish longer-term goals. This kind of portfolio approach ensures the organization gets the best results from AI-enabled ITSM.
Emphasize the people part. Where will you find that historical wisdom to train your chatbot? Who knows how to effectively manage those repetitive end-user issues from within a knowledgebase article? Promote the introduction of AI-enabled ITSM tools as a way to build off of IT staff's current knowledge, which then enables staff to focus on more strategic initiatives.
Take a holistic view. AI can have a place in the enterprise beyond ITSM. Many of the vendors in the AIOps market provide platforms for customer service, HR and other business functions. The introduction of AI-enabled ITSM also gives the IT team an opportunity to lead similar efforts across the organization -- but unless IT understands enterprise value streams, there is a risk of creating or reinforcing a silo mentality.






Dig Deeper on IT operations careers and skills



information




By: Robert Sheldon




ServiceNow




By: Rahul Awati




IT service management (ITSM)




By: Stephen Bigelow




12 AI and machine learning use cases in ITSM




By: George Lawton








Buyer's Handbook: Explore artificial intelligence in ITSM and the tool options

Article4 of 5



Up Next



Find the right AI-based tool to enhance and streamline ITSM
AI-enabled ITSM tools can improve and streamline operations processes, as well as liberate workers from repetitive, tedious tasks to focus on more meaningful work.



AI in ITSM reshapes operations practices and tasks 
AI capabilities are merging within ITSM practices to augment IT's performance and enhance the user experience. Read on to learn more about AI uses for ITSM, and how to approach them. 



Explore the benefits, challenges of AI in ITSM
Are your ITSM processes ready to reap AI's rewards? Discover how AI can benefit your ITSM implementation, as well as the requirements for that transition to be a success.



Evaluate AI-based ITSM tools using these key points
After determining that artificial intelligence would benefit an IT environment, the next big challenge is to assess AI-based ITSM tools in terms of feature set and pricing model.



An ITSM tool comparison for enterprises with an eye on AI
All AI-enabled ITSM tools aim to streamline and automate IT operations, but buyers must make the right selection to get the most out of these products.







Sponsored News


Confidently extend AI across your organization
–HPE


Three Ways to Beat the Complexity of Storage and Data Management to Spark ...
–HPE


Hybrid Work Drives New Criteria for VDI and DaaS
–Dell Technologies

See More





Related Content


Explore the benefits, challenges of AI in ITSM
– IT Operations


AI in ITSM reshapes operations practices and tasks
– IT Operations


Explore artificial intelligence in ITSM and the tool ...
– IT Operations








","{'@type': 'WebPage', '@id': 'https://www.techtarget.com/searchitoperations/feature/Evaluate-AI-based-ITSM-tools-using-these-key-points'}",,,,,"{'cssSelector': '.paywall', '@type': 'WebPageElement', 'isAccessibleForFree': False}",,,,,,,,
https://news.google.com/rss/articles/CBMiMmh0dHBzOi8vd3d3Lm5hdHVyZS5jb20vYXJ0aWNsZXMvczQxNDY3LTAxOS0xMDQwNi030gEA?oc=5,Inkjet-printed unclonable quantum dot fluorescent anti-counterfeiting labels with artificial intelligence authentication - Nature.com,2019-06-03,Nature.com,https://www.nature.com,"An ideal anti-counterfeiting technique has to be inexpensive, mass-producible, nondestructive, unclonable and convenient for authentication. Although many anti-counterfeiting technologies have been developed, very few of them fulfill all the above requirements. Here we report a non-destructive, inkjet-printable, artificial intelligence (AI)-decodable and unclonable security label. The stochastic pinning points at the three-phase contact line of the ink droplets is crucial for the successful inkjet printing of the unclonable security labels. Upon the solvent evaporation, the three-phase contact lines are pinned around the pinning points, where the quantum dots in the ink droplets deposited on, forming physically unclonable flower-like patterns. By utilizing the RGB emission quantum dots, full-color fluorescence security labels can be produced. A convenient and reliable AI-based authentication strategy is developed, allowing for the fast authentication of the covert, unclonable flower-like dot patterns with different sharpness, brightness, rotations, amplifications and the mixture of these parameters. Anti-counterfeiting technologies should ideally be unclonable, yet simple to fabricate and decode. Here, the authors develop an inkjet-printable and unclonable security label based on random patterning of quantum dot inks, and accompany it with an artificial intelligence decoding mechanism capable of authenticating the patterns.",N/A,"Anti-counterfeiting technologies should ideally be unclonable, yet simple to fabricate and decode. Here, the authors develop an inkjet-printable and unclonable security label based on random patterning of quantum dot inks, and accompany it with an artificial intelligence decoding mechanism capable of authenticating the patterns.","Nature Communications - Anti-counterfeiting technologies should ideally be unclonable, yet simple to fabricate and decode. Here, the authors develop an inkjet-printable and unclonable security...",https://schema.org,WebPage,,,,,,,,,,,,N/A,N/A,"




Download PDF








Article

Open access

Published: 03 June 2019

Inkjet-printed unclonable quantum dot fluorescent anti-counterfeiting labels with artificial intelligence authentication
Yang Liu1 na1, Fei Han2 na1, Fushan Li1, Yan Zhao1, Maosheng Chen1, Zhongwei Xu1, Xin Zheng1, Hailong Hu 
            ORCID: orcid.org/0000-0001-5299-28121, Jianmin Yao1, Tailiang Guo1, Wanzhen Lin2, Yuanhui Zheng 
            ORCID: orcid.org/0000-0001-6326-727X2, Baogui You3, Pai Liu3, Yang Li3 & …Lei Qian4 Show authors

Nature Communications
volume 10, Article number: 2409 (2019)
            Cite this article




28k Accesses


307 Citations


13 Altmetric


Metrics details






AbstractAn ideal anti-counterfeiting technique has to be inexpensive, mass-producible, nondestructive, unclonable and convenient for authentication. Although many anti-counterfeiting technologies have been developed, very few of them fulfill all the above requirements. Here we report a non-destructive, inkjet-printable, artificial intelligence (AI)-decodable and unclonable security label. The stochastic pinning points at the three-phase contact line of the ink droplets is crucial for the successful inkjet printing of the unclonable security labels. Upon the solvent evaporation, the three-phase contact lines are pinned around the pinning points, where the quantum dots in the ink droplets deposited on, forming physically unclonable flower-like patterns. By utilizing the RGB emission quantum dots, full-color fluorescence security labels can be produced. A convenient and reliable AI-based authentication strategy is developed, allowing for the fast authentication of the covert, unclonable flower-like dot patterns with different sharpness, brightness, rotations, amplifications and the mixture of these parameters.



Similar content being viewed by others






Gap-enhanced Raman tags for physically unclonable anticounterfeiting labels
                                        


Article
Open access
24 January 2020









Improving the longevity of optically-read quantum dot physical unclonable functions
                                        


Article
Open access
26 May 2021









Hybrid low-voltage physical unclonable function based on inkjet-printed metal-oxide transistors
                                        


Article
Open access
02 November 2020








IntroductionCounterfeiting and forgery is a global problem that causes significant financial damage and poses security threats to individuals, companies, and society as a whole1,2. Over the past decades, counterfeit products have spread from daily consumer goods, to medicines and high-tech products1. Although majority of the products are protected by an anti-counterfeiting technique, the global economic loss of counterfeiting has been increasing annually and estimated to reach 1.7 trillion US dollars in 20153. The reason for this is the currently used anti-counterfeiting technologies that rely on inkjet-printed security labels can be readily duplicated by counterfeiters due to their uniform patterns and predicable, deterministic decoding mechanisms4,5,6. Despite this, the inkjet-printing technique itself has many distinguished advantages in low production cost, mass production, material-effective utility, unlimited pattern design ability, and excellent compatibility with various ink materials as well as supporting substrates7,8,9,10,11,12. Furthermore, the inkjet-printed macroscale security labels allow fast, frequent authentication by the naked eyes or using a smart phone.Security labels with physical unclonable functions (PUFs) could offer a practical solution to the limitation of the widely used anti-counterfeiting technologies and seem to be the most viable path to combat the increasingly serious global forgery issue13. A PUF is a physical object with an intrinsic, unique, random physical feature generated in a non-deterministic process1,13,14,15,16,17,18,19,20. The randomness characteristic of the feature guarantees unreplicable code outputs. To date, a significant progress in PUF encryption has been made in the anti-counterfeiting field, mainly focusing on generating random features composed of either rough surfaces21,22 or discrete nanoparticle arrays23,24,25 within the predefined pattern areas. For example, Bae et al. has demonstrated the use of randomly wrinkling silica-coated polymeric particles as PUF codes to produce unique artificial fingerprints for anti-counterfeiting applications22. Our group recently have utilized advantage of electrostatic self-assembly strategy to generate randomly arranged plasmonic (metal) arrays as PUF codes using fluorescein-doped silver-silica core-shell nanoparticles as building blocks, giving rise to multi-optical signal encoded, unclonable security labels23. However, the creation of well-defined two-dimensional (2D) graphic security labels that carry PUF codes requires the aid of expensive lithography techniques. Moreover, the decryption of such PUF-based security labels relies on a machine learning pattern recognition and comparison analysis that a real fingerprinting does22. The machine learning authentication technique only focuses on algorithms for pattern recognition and enhancement to extract the PUF codes.In this work, we develop an inkjet-printable, artificial intelligence (AI) decodable, unclonable, fluorescence security label by combining the advantages of inkjet printing, portable smart-phone microscopes and AI technique. The security labels with diverse pattern designs are fabricated through inkjet printing using II-VI semiconductor core-shell quantum dots as model ink. The surface decoration of print substrates, such as glass, plastic, or paper, with randomly distributed poly(methyl methacrylate) (PMMA) nanoparticles is critical for the successful inkjet printing of unclonable security labels. The polymer nanoparticles on the substrates are acted as stochastic pinning points at the three-phase contact lines of the ink droplets. Upon the solvent evaporation, the three-phase contact lines are pinned around the pinning points. The quantum dots in the ink droplets subsequently deposit on the pinning points, forming physically unclonable flower-like dot patterns (i.e., primary units for any 2D logos). The designed surface modification makes the security labels (i.e., 2D logos) unique and unclonable. By utilizing red, green and blue (RGB) emission semiconductor quantum dots, full-color pictures can be generated, which are invisible in the ambient environment. The fabricated security labels seem to be the same from batch to batch on the macroscopic level; however, at the microscopic level, they are quite different from each other. Compared with previous reports using the intrinsic surface topography of a material (e.g., scratch patterns, fiber weave, etc.) for PUF encoding16, the system presented here has many advantages: (1) the developed printing strategy for the security label fabrication not only allows for various pattern design but also makes the mass-production at low cost possible; (2) the quantum dot ink is fluorescence active, guaranteeing the readout signals from suffering the interference by fingerprints and dusts; (3) the quantum dot security labels are only visible upon UV excitation, which offers the first layer of security, while the PUF nature originated from the random flower-like dot patterns provides the second more secure layer; (4) the first layer of security can be easily authenticated with naked eyes, while the second layer of security is able to be authenticated with AI technique rather than time-consuming machine learning algorithms. Moreover, we introduce AI (specifically deep learning) security label authentication concept and succeed in accurately and robustly decoding the unrepeatable flower-like dot patterns with different focusing degrees, brightness, rotation angles, amplification factors and the mixture of these parameters. The developed anti-counterfeiting technology meets all the requirements for commercial applications that are low cost, mass-producible, nondestructive, diverse full-color pattern design capability, unclonable, and convenient for authentication.ResultsInkjet printing of unclonable quantum dot security labelsThe fabrication process of unclonable security labels by inkjet printing are illustrated in Fig. 1. Three types of commercially available II–VI semiconductor core-shell quantum dots (CdSe/CdS/CdZnS, ZnCdSe/CdZnS, and ZnCdS/CdZnS) that emitted red, green, and blue light were chosen as model inks owing to their high fluorescent quantum yield and outstanding stability (Fig. 1a). These quantum dots were synthesized using a well-established chemical route26,27, in which high boiling point oleic acid and 1-octadecen were used as a capping agent and solvent, respectively (see Methods for details). Typical low-magnification transmission electron microscopy (TEM) and high-resolution TEM micrographs present an extremely narrow particle size distribution and high crystallinity of the synthesized quantum dots (Fig. 1a, b and Supplementary Fig. 1). The particle sizes of the red, green, and blue emission quantum dots are 6.5 ± 2 nm, 10.5 ± 3 nm, and 11.0 ± 2.5 nm, respectively. Generally, for quantum dots, the relationship between size and emissive wavelength accords with quantum confinement effect — that a small size corresponds to a larger band gap and emits short-wavelength fluorescence28. In this case, the emission wavelength of red, green and blue quantum dots shown in Fig. 1a was determined by the composition rather than the size of quantum dots (see Supplementary Fig. 1c)26. The Fourier-transform infrared absorption peaks at 2923 and 2854 cm−1, corresponding to C–C and C–H stretching modes of the -CH2- group, reveals the presence of oleic acid on the quantum dot surface (see Supplementary Fig. 2)29. The surface ligands are of importance for the preparation of highly dispersed and stable quantum dot inks as they can stabilize the quantum dots in non-polar solvents for months at room temperature. In this work, n-octylcyclohexane with low evaporation rate at ambient environment was adopted as model solvent for ink preparation. The low evaporation rate of the jetted ink droplet leads to a slow movement of the three-phase contact line on the print substrate, which allows us to dynamically study the quantum dot deposition behavior. Photographs of twenty jetted single droplets show almost identical shape both before contacting a print substrate and at the early stage after the contact (see Supplementary Fig. 3).Fig. 1Outline of formation processes of unclonable security labels by inkjet printing. a Typical TEM/HRTEM images (left), particle size distributions (middle), and ink for inkjet printing (right) of red core-shell quantum dots (QDs). b Surface modification of a substrate with partly dissolved PMMA solution by spin coating. c Substrate with random-distributed pinning points of PMMA nanoparticles on PMMA film after spin coating. d Inkjet printing of prepared QDs ink on the modified substrate. e Pinning process of QDs droplet contact line at random pinning points. f Residual central ink teared in to several smaller droplets in the final evaporation process. g A resulting security label composed of flower-like dot patterns, which are protected with a thin, optically transparent sticky gel filmFull size imagePrior to inkjet printing, the print indium-tin-oxide (ITO)-coated glasses were cleaned by sonication in various solvents (see Methods for detailed sonication cleaning procedure), treated with oxygen plasma and then spin-coated with a partly-dissolved poly(methyl methacrylate) (PMMA)30 nanoparticle colloid, forming a randomly distributed PMMA nanoparticle array on a PMMA layer (Fig. 1b, c). The surface cleaning and oxygen plasma treatment were utilized to remove the dusts and generate a super wettable surface for the PMMA nanoparticle coating, while the surface decoration with PMMA nanoparticles were used to create randomly arranged pinning points for the quantum dot deposition during the subsequent inkjet printing process. Such randomly arranged pinning points are critical for the successful inkjet printing of unclonable security labels (see Supplementary Fig. 6). Representative dark-field and atomic force microscopy images revealed the presence of randomly distributed PMMA nanoparticles with particle size in the range of a few nanometers to a few micrometers on the print substrates (see Supplementary Fig. 4). Following the surface modification of the print substrates, they were subjected to the inkjet printing to produce 2D graphic security labels. The inkjet printing was conducted by continuously jetting the quantum dot ink droplets with size of ~130 μm on the print substrates (Fig. 1d). The interval between two adjacent ink droplets is 200 μm. If each macroscopic security label contains 1000 flower-like points, we can achieve 1600 security labels in 5 min (i.e., the drying time of each batch of security label) with our single-nozzle printing machine. Each droplet represents a pixel of the inkjet-printed security labels after being completely dried. The PMMA nanoparticles on the poorly wettable PMMA film were acted as stochastic pinning points at the three-phase contact lines of the ink droplets. With the evaporation of solvent, the three-phase contact line continually slides and shrinks at the smooth PMMA areas owing to the poor wettability of the surface but is captured by some pinning points. Consequently, the pinning points stretch and pin the contact line, distorting the fluid convex and forming irregular quantum dot ink pattern (Fig. 1e). During the solvent evaporation process, the quantum dot concentration increases gradually. When the quantum dot concentration reached their saturation point, they started to deposit at the stochastic PMMA pinning points on the three-phase contact line, forming a unique flower-like dot pattern (Fig. 1f). With the shrinking of droplet, the volume-smaller droplet is more liable to be tortured by pinning points, thus splitting into several smaller sub-droplets (see Supplementary Fig. 5). Due to the small space between these sub-droplets and some stochastic external factors (such as airflow), they experienced merging and splitting irregularly before eventual drying (Fig. 1f). This non-deterministic, random pattern formation process was recorded by a camera to monitor the shape evolution of a droplet as a function of time (see Supplementary Fig. 5). Such a non-deterministic pattern formation process makes it impossible to reproduce the flower-like dot patterns, which were used as PUF codes in our security labels. The fabricated security labels were then covered with a thin, optically transparent, sticky gel film to protect them being damaged during the real circulation (Fig. 1g). If without the PMMA nanoparticles on the print substrates, the accumulated quantum dots induced by solvent evaporation directly deposited on the self-pinned three-phase contact line, producing a coffee-ring-like pattern (see Supplementary Fig. 6a). However, if the print substrates were coated with a continuous, smooth, poorly wettable PMMA layer, the three-phase contact line of the droplets are incline to shrink and slide towards to the center, rather than pinned on substrates, bringing the quantum dots to center of the droplet. When the solvent is completely evaporated, a central bump pattern, i.e., a hilly accumulation with diameter much smaller than the initial wetted diameter of the ink droplet, is generated (see Supplementary Fig. 6b). In the absence of the stochastic PMMA pinning points, either a uniform coffee ring or central bump pattern was formed, which was determined by the wettability property of the print substrates. These deterministic pattern formation processes ensure the reproducibility of the patterns under the same conditions.The miniaturized dark-field and fluorescence microscopes integrated with smartphones have been developed for single nanoparticle imaging31,32. Such small, affordable, portable microscopes were utilized by consumers to authenticate the inkjet-printed security labels. The magnification-adjustable objective lens of the portable microscope used here is covered with a cylindrical metal shell that creates a small dark imaging environment by blocking the ambient light (Supplementary Fig. 7). The portable microscope is able to quickly (typically within one second), accurately and nondestructively readout the produced flower-like dot patterns, which show different geometries as expected (Supplementary Fig. 7).Unlimited colorful pattern design capabilityIdeal fluorescent security labels require the ink materials having strong fluorescence intensity, which guarantees the high fluorescence brightness. The prepared quantum dot inks exhibit a narrow fluorescence emission peak with maximum intensity at 459 nm, 532 nm, and 631 nm, respectively, when excited at 375 nm (Fig. 2a). The full-width at half-maximum (FWHM) of these blue, green and red emission quantum dots is 20 nm, 24 nm, and 28 nm, respectively. They also bear a high fluorescence quantum yield of 75, 90, and 80%, respectively. The time-resolved fluorescence decays of the blue, green, and red emission quantum dots show their lifetime of 27.5 ns, 17.0 ns, and 7.6 ns (Fig. 2b), respectively, in consistent with consistent with previous reports26,33,34. According to the Commission Internationale de I’éclairage (CIE) 1931 color coordinate triangle, the quantum dots achieved a wide color gamut of 124% of the National Television System Committee (NTSC) standard (see Supplementary Fig. 8), better than phosphor (color gamut: 85.6%)35,36,37, implying outstanding full-color fluorescence properties for security label applications.Fig. 2Optical characterization. a Fluorescence spectra and b time-resolved fluorescence decay measurements of red, green, and blue emission quantum dot (QD) inks excited at 375 nm. c Transmittance spectra of ITO coated glass substrates before and after inkjet printing of red, green, and blue emission Fuzhou University logos (Inset: photographs of the four samples under ambient light). d–i Fluorescence images of red, green, and blue emission d–f Fuzhou University logos and g–i two-dimensional QR codes and bar codes. The Fuzhou University logos, QR codes and bar codes, composed of thousands of dot patterns (pixels), are adapted with permission of the Fuzhou University. The scale bar is 1 cmFull size imageComplex Fuzhou University logos composed of red, green, or blue emission arrays were inkjet-printed on indium tin oxide (ITO) coated glass slides using the printing strategy described in Fig. 1. The print substrates with Fuzhou University logos maintained transparent (Insert of Fig. 2c). That is, the inkjet-printed logos are invisible by naked eyes under the ambient conditions. The transmittance curves of the printed ITO glass slides are almost identical to the pristine print substrate (Fig. 2c), further confirming the covert characteristic of the fabricated security labels. When irradiated with UV light, bright red, green and blue photoluminescence photographs of the university logos were observed by the naked eyes (Fig. 2d–f). Any other 2D macroscale patterns with sharp corners, for example, QR codes and bar codes (Fig. 2g–i), can also be produced using our inkjet printing technique. The property that these images are only seen upon UV excitation offers the first layer of security realized by naked eye authentication of macroscopic patterns; and the PUF nature of the flower-like patterns is the second more secure layer.By tuning RGB ink component ratios, fine tonal variations from red to green were obtained (see Supplementary Fig. 9). In principle, the full palette of colors could be achieved with elaborate control of the RGB ink components. Alternatively, the full-color security labels can be generated by creating individual color pixels including red, green, and blue sub-pixels, which has been widely used in display26,38,39 and color images40,41,42. The inkjet printing strategy developed here offers us an opportunity to extend the ink to other fluorescent materials, e.g., lanthanide complexes43,44,45,46,47, carbon dots48,49, and up-conversion nanoparticles50,51,52, etc. and the print substrates to flexible ones, such as plastics (see Supplementary Fig. 10). Although the 2D macroscale security labels shown in Fig. 2d-i contained thousands of discrete points (or pixels), the printing process is completed within a few minutes using our single-nozzle printing machine.Figure 3 displays fluorescence micrographs of three batches of inkjet-printed macroscopic letters FZU (i.e., the acronym of Fuzhou University) that are composed of red, green, or blue emission arrays. At the macroscopic level, the printed FZU letters were seemingly identical (Fig. 3a–c). However, under the microscopic level, they were completely different from each other, as every fluorescent pixel of the letters showed a unique, random and unrepeatable flower-like geometry (Fig. 3d–i and Supplementary Fig. 11). Further scanning electron microscope and energy dispersive X-ray spectroscopy characterizations verify that the unique flower-like micropattern obtained from optical imaging systems is consistent with quantum dot deposition zones (see Supplementary Figs. 12–14). By carefully comparing all the pixels within the letters (i.e., the same sample), no identical flower-like micropatterns were found. A copy of the red, green, and blue fluorescence counterparts of the FZU letters shown in Fig. 3 fabricated under the same conditions also shows entirely different geometries of the corresponding pixels (see Supplementary Fig. 15). The encoding capacity of the inkjet-printed security labels that relies on the encoding capacity (defined as l) and the number (defined as m) of the PUF patterns (i.e., flower-like pixels) within the security labels can be described as lm20. Recently, Carro-Temboury et al. established a universal binary-bit model for the estimation of the encoding capacity of PUF pattern1. According to Carro-Temboury’s model, the encoding capacity of a red flower-like PUF pattern, l, is calculated to be 4.7 × 10202 (see Supplementary Fig. 16 and Note 1 for calculation details). Therefore, for a security label composed of 1000 red flower-like PUF patterns, its encoding capacity will be larger than 10202,000. This indicates that the inkjet-printed security labels are unclonable even by the manufacturer. Moreover, the fabricated security labels have been frequently exposed to UV light over the period of 2 months. No obvious decrease of the fluorescence brightness is observed, revealing that security labels have excellent chemical and photo stabilities (see Supplementary Fig. 17).Fig. 3Security labels with physically unclonble flower-like patterns. Typical fluorescence images of inkjet-printed macroscopic letters FZU composed of a red, b green, and c blue emission dot patterns (the scale bar is 4000 μm), d–f their local enlarged images (the scale bar is 500 μm), and g–i further enlarged images (the scale bar is 100 μm). All the samples are printed under the same conditions. The FZU patterns are identical on macroscale but completely different at the microscale (i.e., every dot pattern is unique)Full size imageDeep learning decoding mechanismConventional security labels with macroscale features, for instance, QR codes or bar codes are convenient for authentication with naked eyes, but easy to be counterfeited. Advanced security labels that carry complex, random nano/microscale features (PUF keys) are formidable to be faked. The decoding of such security labels relies on a similar character extraction, recognition, and comparison analysis that a real fingerprint does22,23. Such machine learning algorithms for pattern recognition, enhancement, and identification are widely employed for the authentication of the PUF-based security labels22,23. A general drawback of the machine learning approach is time consuming and having a high level of false positives of up to 20%20. Furthermore, conventional classification can only be used in the PUF that can be transformed to private keys; for flower-like patterns, it does not work. To deal with this problem, deep learning, an artificial intelligence (AI) technique, was introduced to validate the fabricated unclonable security labels, which pushes anti-counterfeiting technology to a higher dimension.Although AI has been recently applied into organic chemistry synthesis and TEM image analysis53,54, to the best of our knowledge, this is the first time to use AI for security label authentication. Figure 4 demonstrates a typical authentication procedure of the inkjet-printed security labels through deep learning. First of all, each quantum dot security label on a commercial product is imaged using an advanced fluorescence microscope (Fig. 4a, step 1). Only one image is taken from each security label and represents one PUF code. Simply, randomly shifting and rotating the image creates a large number of images for an AI to learn the characteristic features of the security label. Once the images are trained on AI, they are categorized in a very general manner (e.g., classes associated with geometry of the security labels) and then stored as a database in a deep learning engine for the subsequent authentication using (Fig. 4a, step 2). This is done by the manufacturer. When the consumers receive the products, they can simply use their portable mini-microscope-connected smartphones to readout the PUF codes by taking photos of the security labels (Fig. 4a, step 3), which are automatically sent to the deep learning engine for validation (Fig. 4a, step 4). The deep learn engine immediately feeds back the authentication results (real or fake) to the users (Fig. 4a, step 5).Fig. 4Deep learning decoding mechanism. a Schematic illustrating the authentication process: 1: image capture and database generation from the goods by the manufacturers, 2: image learning by AI, 3: Image capture from the goods by the consumers using their smart phones, 4: image recognition and comparing by AI, and 5: authentication outcome feedback to the consumers. b–g A library of six single dot pattern security labels, h–m six fluorescence images taken from b (referred as to genuine product) with different brightness, sharpness, rotation angles, magnifications, and the mixture of the above-mentioned factors, and n–s six fluorescence images from security labels that are not in the database shown in panel b–g (referred as to fake products). t, u Recognition rates of labels (h1–h6) and (i1–i6) by the authenticating way of deep learning. Labels (g1–g6), (h1–h6), and (i1–i6) correspond to the labels in figure (b–g), (h–m), and (n–s) respectively. The color scales from blue to red stand for the matching score (ranging from 0 to 100%) of the captured pictures with the labelsFull size imageTo experimentally demonstrate the above authentication process, six quantum-dot security labels (named as gn, n = 1, 2, ···, 6) were randomly chosen to establish a security label database (Fig. 4b–g). Five hundred fluorescence images of each security label (e.g., g1) obtained by randomly shifting and rotating a same image (i.e., g1) are provided to AI for learning and classifying. The selected 72 out of the 500 images from g1 show the exact same geometrical characteristics of the security label (see Supplementary Fig. 18). The 500 images were divided into two parts: 80% for learning and 20% for validation. After every learning cycle (the parts for learning), the images for validation were sent to AI engine to test, providing a train accuracy plot. After about 1000 learning cycles, they can be recognized with accuracy fluctuating between 97 and 100% when being sent to AI for validation again (see Supplementary Fig. 19).For decoding, a security label that represented a genuine product (i.e., from the pre-established database) was imaged at various sample rotation angles, magnification, focusing degrees, and the mixture of the above-mentioned factors (Fig. 4h–m). We try to cover all possible deviations from the imaging equipment, imaging conditions, personnel habits of users that may happen in a real authentication scenario. None of the images shown in Fig. 4h–m (named as hn, n = 1, 2, ···, 6) has ever been previously learnt by AI. The image hn is fed into the trained AI for validation. The authentication outputs show the accuracy of hn (n = 1, 2, ···, 6) is 0.999, 0.758, 0.999, 0.909, 0.999, and 0.999, respectively (Fig. 4t). The relatively low accuracy of h2 and h4 are attributed to their over-indistinct characteristics, for which parts of details are lost during imaging, implying sharpness exerting a much higher impact on authentication accuracy than other variations, such as brightness, location, rotation angle, and amplification factor. The threshold of the accuracy at a value of 0.5 is then set to distinguish the real and fake security labels. For comparison, six fake security labels named as in (n = 1, 2, ···, 6) were sent to AI for authentication in the same way (Fig. 4n–s). The corresponding accuracy is almost zero for all the fake security labels (Fig. 4u). By simply comparing the accuracy on the test with the threshold, the deep learning machine can immediately provide the authentication outcomes (real: accuracy ≥0.5, fake: accuracy <0.5) to the customers. Regarding to the rate of false positives, we achieved the false positives rate of 0 using the match score of 0.5 as the threshold when sampling 100 security labels (see Supplementary Table 1). It only takes seconds or even less to finish the whole authentication process.DiscussionIn conclusion, we have demonstrated a non-destructive, inkjet-printable, smart-phone readable, AI decodable, unclonable, and fluorescence security label. Such security labels with various 2D patterns composed of red, green, or blue emission arrays were fabricated through inkjet printing using II–VI semiconductor core-shell quantum dots as model ink. The surface modification of the print substrates with randomly arranged PMMA nanoparticles is crucial for the successful inkjet printing of the unclonable security labels. The polymer nanoparticles on the print substrates were acted as stochastic pinning points at the three-phase contact lines of the ink droplets for the quantum dot deposition, forming physically unclonable flower-like dot patterns. This non-deterministic pattern formation process guarantees the unclonability of the fabricated security labels. By utilizing the RGB emission core-shell quantum dots, full-color security labels can be generated.The fabricated security labels are invisible in the ambient environment but can be visualized by naked eyes when irradiated with UV light, which offers an easy way for the preliminary verification. A more reliable authentication strategy by using AI techniques has been developed. Covert and unclonable flower-like dot patterns with different sharpness, brightness, rotations, amplifications, and the mixture of these parameters have been successfully decoded within seconds using the authentication strategy developed here. The overall cost per security labels has been estimated to be approximately US$ 0.011 (see Supplementary Note 2). The anti-counterfeiting technology described in this work is a good step closer to commercial applications that are low cost, mass-producible, nondestructive, diverse full-color pattern design capability, unclonable, and convenient for authentication. Applications of this technology span the full range from established to emerging-technology industries, including pharmaceutics, food security, and nanotechnology. Compared with intrinsic surface topography of material itself (like scratch patterns, fiber weave, etc.), our current system shows advantages in fluorescent and multi-color information, multi-level security, convenient for authentication, and well-designed patterns. The possibility of covert but easily detectable labeling through the use of a portable mini microscope and AI technique (Supplementary Table 2) will ensure the security and trackability of sensitive substances and equipment, which will lead to a promising approach in sensitive industries such as the nuclear one.MethodsMaterialsPoly(methyl methacrylate) (PMMA, average Mw ~996,000 g mol−1, from Sigma-Aldrich), polyvinylpyrrolidone (PVP, average Mw ~40,000×g mol−1), dimethyl sulfoxide (DMSO), chlorobenzene (99.8% pure, from J&K Scientific), CdO (AR grade, from Aladdin), ZnO (99.7%, from Shijiazhuang hongda zinc industry co. LTD), zinc acetate dehydrate (AR grade, from Aladdin), oleic acid (OA, 90%, from Alfa aeser), 1-octadecene (ODE, 98%, from Toyata), Se powder (99.999%, from Alfa aeser), sulfur powder (99.95%, from Aladdin), 1-Dodecanethiol (DDT, ≥ 98%, from Chevron Phillips Chemical), toluene (for synthesizing quantum dots, AR grade, from Guangdong Guanghua Sci-Tech Co., Ltd), and ethanol (AR grade, from Guangdong Guanghua Sci-Tech Co., Ltd) were received and used without further purification. Sticky-gel film with gel thickness of 1.5 mm and retention level of X4 was purchased from Gel-Pak company. Toluene (for dissolving PMMA) was purchased from Sinopharm Chemical Reagents and further dried by distillation over sodium.Synthesis of core-shell quantum dotsFor a typical synthesis of CdSe/CdS/CdZnS red emission quantum dots: 7 mmol of CdO, 10 mL of OA and 25 mL of ODE were mixed in a 250 mL round flask. The mixture was heated to 160 °C, degassed for 15 min, then filled with N2 gas and further heated to 310 °C. Subsequently, Se precursor was injected swiftly into the flask. Then the reaction was cooled to 300 °C and remained at this temperature for 5 min. To grow the CdS shell, S source was injected dropwise to react with the remaining cadmium ions for 20 min. For the growth of CdZnS shell, keep the reaction temperature and dropwise injected the pre-prepared shelling materials, the shelling process last for ~30 mins. After the reaction, the temperature was naturally cooled down to room temperature. The synthesized quantum dots were finally purified using toluene and ethanolfor several times and finally dispersed in n-octylcyclohexane. For ZnCdSe/CdZnS green emission quantum dots: 35 mmol of ZnO, 25 mL of OA, and 20 mL of ODE were mixed in a 250 mL round flask. The mixture was heated to 160 °C, degassed for 15 min, then filled with N2 gas and further heated to 300 g to get a clear solution. The solution was cooled to 200 °C, at which Se and Cd stock precursors were quickly injected into the flask sequentially. Then the temperature was elevated to 310 °C and remained at this temperature for 30 min to form alloyed CdZnSe core. For the growth of the CdZnS shell, S source and Cd source were dropwise injected into the flask repeatedly while keeping temperature at 270 °C. After the precursor injection, the temperature was kept unchanged for 30 min to 1 h, and then naturally cooled down to room temperature. For the synthesis ZnCdS/CdZnS blue emission quantum dots with composition gradient, the procedure is the same as that for the green emission quantum dots, except using S stock solution instead of Se solution as the anion precursor. At the elevated temperature, the S precursor was injected into the mixture of the Zn precursor and Cd precursor in a round bottom flask, forming the blue emitting ZnCdS cores. The shell materials (S source and Cd source) were added afterwards drop-wisely, and the reaction was allowed to proceed from 30 min to 1 h for the shell growth. The synthesized of green and blue quantum dots were purified and prepared with similar process as above.Fabrication of quantum-dot security labelsIn a typical procedure, the precursors of surface modification layer were prepared by adding solutes into chlorobenzene, toluene, and DMSO for common PMMA (4 mg ml−1), designed PMMA (4 mg ml−1), and PVP (4 mg ml−1) layer respectively, and stirring vigorously for 12 h at 60 °C before use The quantum dot inks were dispersed in n-octylcyclohexane at a concentration of 20 mg ml−1. Indium-tin-oxide (ITO)-coated glass substrates were cleaned with ultrasonication successively in deionized (DI) water, acetone, isopropanol, and DI water. Then, nitrogen stream was used to dry the substrates, followed by 10 min oxygen plasma treatment. The pre-prepared precursors of surface modification layer were deposited on the substrates by spin coating, and then were heated at 120 °C for 30 min. The quantum-dot inks were printed on the substrates with a Microfab JETLAB II equipped with a 30-μm diameter piezoelectric-driven inkjet nozzle and a motorized stage with the accuracy of 5 μm. Driving voltage waveforms to the inkjet printing nozzle and the flying single droplet are shown in Supplementary Figs. 20 and 21. All the processes were operated in the ambient environment. If every single macroscopic pattern has 1000 unclonable flower-like points, we can achieve 1600 macroscopic patterns in 5 min with our single-nozzle printing machine. The time of drying is ~5 min for each batch of security label. The as-fabricated security labels were covered with gel films by tearing of their polycarbonate coversheet and then stick their gel material on the labels for stability test (see Supplementary Fig. 17).CharacterizationThe surface morphology of the PMMA films and quantum-dot patterns were characterized with atomic force microscopy (AFM, Bruker Multimode 8) and scanning electronic microscope (SEM, FEI, Nova Nano SEM 230). The UV−Vis absorption spectra were tested with a UV/Vis/NIR spectrophotometer (Shimadzu, UV-3600). The transmission electronic microscopy (TEM) image of quantum dots was recorded using JEOL JEM-2100F microscope. The steady-state photoluminescence (PL) spectra were collected with a Hitachi F-4600 fluorescence spectrophotometer, by exciting the samples using a Xe lamp coupled with a monochromator. Time-resolved PL measurement was collected by using fluorescence lifetime measurement system (HORIBA scientific). Fourier transform infrared (FTIR) spectra were recorded with a Nicolet 50 FTIR spectrometer at room temperature. The PL microscopic images of quantum dot patterns morphology were characterized by using a fluorescent microscope (Olympus BX51M). For pattern readout with a smartphone microscope, the portable microscope was linked to a small WiFi box by a USB line, which allows for the smartphone to control the microscope for real-time imaging (see Supplementary Fig. 7).Quantum yield of quantum dotsThe results are obtained by comparing integrated PL intensities using the standard procedure55,56. The quantum yield (QYs) of blue, green, and red emission quantum dots were measured relative to Coumarin 480 (QY 99% in ethanol) with excitation at 350 nm, Coumarin 480 (QY 99% in ethanol) with excitation at 370 nm and rhodamine 6 G (QY 95% in ethanol) with excitation at 450 nm, respectively. Solutions of quantum dots in toluene were optically matched at the excitation wavelength. Fluorescence spectra of quantum dots and dye were taken under identical spectrometer conditions in triplicate and averaged. The optical density was kept below 0.06 at the λmax, and the integrated intensities of the emission spectra, corrected for differences in index of refraction and concentration, were used to calculate the quantum yields using the expression.$${\mathrm{QY}}\;{\mathrm{of}}\;{\mathrm{quantum}}\;{\mathrm{dots}} = {\mathrm{QY}}_R \times \frac{I}{{I_R}} \times \frac{{A_R}}{A} \times \frac{{n^2}}{{n_R^2}}$$
                    (1)
                where QY is the quantum yield, I is the measured integrated PL emission intensity, n is refractive index (n = 1.496 for toluene; n = 1.361 for ethanol) and A is the optical density at the excitation wavelength.Deep learningAll the deep learning networks employed in our paper are based on the TensorFlow backend. The code used are run in software Pycharm 2017.3. To generate a large enough training set from theoretical image(s) for Alexnet model, a data augmentation procedure to the original synthetic image(s) is applied. For a typical process, one lower-left dot representing a security label is captured as an image. Such a clear image was rotated by a step of 0.72° for 360° using an algorithm, producing a set of 500 training images. The input images were resized to 512 × 384 using pixel area relation for training. Plots of accuracy on the training and validation data sets over training epochs (from http://host:6006) can be found in the Supplementary Fig. 19. The training images do not need to be stored and are not stored in this case; The storage requirement is mainly determined by the neural network itself, about 200 M Bytes here. For the AI technology we used, the learning process takes 2 h. The computer used for deep CPU is equipped with the CPU (Intel(R) Core(TM) i7–6700 CPU @3040 GHz), the GPU (NVIDIA GTX 1080), the RAM (32.0 GB), and HDD Capability (1 TB). The computer rated power is 350 W/h.Registration and validation methodologyWe created a file named as gn (n = 1, 2, 3, …) per security label to store the corresponding 500 training images prior to the training process. The training images stored in the file gn are named as gn_000, gn_001, …, gn_500. Many files from these security labels composed a database. After the 500 training images of a security label were learnt by AI, their structural information was remembered and linked to the file name gn (e.g., g1). Then the training images will be deleted. When consumers randomly take a picture of a real security label and sent it to the AI, the AI can automatically recall the accurately corresponding relationship and output the indexing name with a detailed match score. According our results, if the captured image from the end-user is clear enough, the match score of the image of true security label is more than 99% (Fig. 4t). On the other hand, if the image (from a fake label) has never been learned, the engine will give a lower match score (Fig. 4u). The authentication process takes about 2 s. Deep learning, as a black box that nobody actually knows how it works in details up to now, is an advantage for unclonable anti-counterfeiting technique because it is a tamper proof.


Data availability
All relevant data supporting the findings of this study are available from the corresponding authors on request.
Code availability
AlexNet, a convolutional neural network competed in the ImageNet Large Scale Visual Recognition Challenge57 was used here. The code can be assessed at https://github.com/deep-diver/AlexNet.
ReferencesCarro-Temboury, M. R., Arppe, R., Vosch, T. & Sorensen, T. J. An optical authentication system based on imaging of excitation-selected lanthanide luminescence. Sci. Adv. 4, e1701384 (2018).Article 
    ADS 
    PubMed Central 
    
                    Google Scholar 
                Hu, Z. et al. Physically unclonable cryptographic primitives using self-assembled carbon nanotubes. Nat. Nanotechnol. 11, 559–565 (2016).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Economics F. Estimating the global economic and social impacts of counterfeiting and piracy. A report commissioned by business action to stop counterfeiting and piracy (BASCAP), An ICC Initiative, (Institute for Creative Community Initiatives, 4390 Parliament Place, Suite A Lanham, MD 20706, 2011).Yao, W. J. et al. Preparation and RGB upconversion optic properties of transparent anti-counterfeiting films. Nanoscale 9, 15982–15989 (2017).Article 
    CAS 
    
                    Google Scholar 
                Wu, L., Dong, Z. C., Li, F. Y., Zhou, H. H. & Song, Y. L. Emerging progress of inkjet technology in printing optical materials. Adv. Opt. Mater. 4, 1915–1932 (2016).Article 
    CAS 
    
                    Google Scholar 
                Arppe-Tabbara, R., Tabbara, M. & Sorensen, T. J. Versatile and validated optical authentication system based on physical unclonable functions. ACS Appl Mater. Interfaces 11, 6475–6482 (2019).Article 
    CAS 
    
                    Google Scholar 
                Yousefi, H., Ali, M. M., Su, H. M., Filipe, C. D. M. & Didar, T. F. Sentinel wraps: real-time monitoring of food contamination by printing DNAzyme probes on food packaging. ACS nano 12, 3287–3294 (2018).Article 
    CAS 
    
                    Google Scholar 
                Li, D. D., Lai, W. Y., Zhang, Y. Z. & Huang, W. Printable transparent conductive films for flexible electronics. Adv. Mater. 30, 1704738 (2018).Article 
    
                    Google Scholar 
                Brutin, D. & Starov, V. Recent advances in droplet wetting and evaporation. Chem. Soc. Rev. 47, 558–585 (2018).Article 
    CAS 
    
                    Google Scholar 
                Zhang, C. Y. et al. Conversion of invisible metal-organic frameworks to luminescent perovskite nanocrystals for confidential information encryption and decryption. Nat. Commun. 8, 1138 (2017).Article 
    ADS 
    PubMed Central 
    
                    Google Scholar 
                Hu, G. H. et al. Black phosphorus ink formulation for inkjet printing of optoelectronics and photonics. Nat. Commun. 8, 278 (2017).Article 
    ADS 
    PubMed Central 
    
                    Google Scholar 
                Bai, L. et al. Large-scale noniridescent structural color printing enabled by infiltration-driven nonequilibrium colloidal assembly. Adv. Mater. 30, 1705667 (2018).Article 
    
                    Google Scholar 
                Pappu, R., Recht, R., Taylor, J. & Gershenfeld, N. Physical one-way functions. Science 297, 2026–2030 (2002).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Takahashi T., Kudo Y. in Machine Vision Applications (MVA), 2017 Fifteenth IAPR International Conference on Machine Vision Applications. (IEEE, Nagoya, Japan 2017).Horstmeyer R., Judkewitz B., Vellekoop I. M., Assawaworrarit S., Yang C. Physical key-protected one-time pad. Sci. Rep. 3, 3543 (2013).Wigger B., Meissner T., Forste A., Jetter V., Zimmermann A. Using unique surface patterns of injection moulded plastic components as an image based Physical Unclonable Function for secure component identification. Sci. Rep. 8, 4738 (2018).Geng Y., et al. High-fidelity spherical cholesteric liquid crystal Bragg reflectors generating unclonable patterns for secure authentication. Sci. Rep. 6, 26840 (2016).Tian, L. et al. Plasmonic nanogels for unclonable optical tagging. ACS Appl Mater. Interfaces 8, 4031–4041 (2016).Article 
    CAS 
    
                    Google Scholar 
                Herder, C., Yu, M.-D., Koushanfar, F. & Devadas, S. Physical unclonable functions and applications: a tutorial. Proc. IEEE 102, 1126–1141 (2014).Article 
    
                    Google Scholar 
                Arppe, R. & Sorensen, T. J. Physical unclonable functions generated through chemical methods for anti-counterfeiting. Nat. Rev. Chem. 1, 0031 (2017).Article 
    CAS 
    
                    Google Scholar 
                Buchanan, J. D. R. et al. Fingerprinting’ documents and packaging. Nature 436, 475–476 (2005).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Bae, H. J. et al. Biomimetic microfingerprints for anti-counterfeiting strategies. Adv. Mater. 27, 2083–2089 (2015).Article 
    CAS 
    
                    Google Scholar 
                Zheng, Y. H. et al. Unclonable plasmonic security labels achieved by shadow-mask-lithography-assisted self-assembly. Adv. Mater. 28, 2330–2336 (2016).Article 
    CAS 
    
                    Google Scholar 
                Smith, A. F., Patton, P. & Skrabalak, S. E. Plasmonic nanoparticles as a physically unclonable function for responsive anti-counterfeit nanofingerprints. Adv. Funct. Mater. 26, 1315–1321 (2016).Article 
    CAS 
    
                    Google Scholar 
                Kim, J. et al. Anti-counterfeit nanoscale fingerprints based on randomly distributed nanowires. Nanotechnology 25, 155303 (2014).Article 
    ADS 
    
                    Google Scholar 
                Yang, Y. et al. High-efficiency light-emitting devices based on quantum dots with tailored nanostructures. Nat. Photonics 9, 259–266 (2015).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Qian, L., Zheng, Y., Xue, J. G. & Holloway, P. H. Stable and efficient quantum-dot light-emitting diodes based on solution-processed multilayer structures. Nat. Photonics 5, 543–548 (2011).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Butkus, J. et al. The evolution of quantum confinement in CsPbBr3 perovskite nanocrystals. Chem. Mater. 29, 3644–3652 (2017).Article 
    CAS 
    
                    Google Scholar 
                Li, J. et al. 50-fold EQE improvement up to 6.27% of solution-processed all-inorganic perovskite CsPbBr3 QLEDs via surface ligand density control. Adv. Mater. 29, 1603885 (2017).Article 
    
                    Google Scholar 
                Dai, X. et al. Solution-processed, high-performance light-emitting diodes based on quantum dots. Nature 515, 96–99 (2014).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Wei, Q. S. et al. Fluorescent imaging of single nanoparticles and viruses on a smart phone. ACS nano 7, 9147–9155 (2013).Article 
    CAS 
    PubMed Central 
    
                    Google Scholar 
                Zhang, D. M. & Liu, Q. J. Biosensors and bioelectronics on smartphone for portable biochemical detection. Biosens. Bioelectron. 75, 273–284 (2016).Article 
    CAS 
    
                    Google Scholar 
                Wang, L. S. et al. Blue quantum dot light-emitting diodes with high electroluminescent efficiency. ACS Appl Mater. Interfaces 9, 38755–38760 (2017).Article 
    CAS 
    
                    Google Scholar 
                Tan, Z. N. et al. Bright and color-saturated emission from blue light-emitting diodes based on solution-processed colloidal nanocrystal quantum dots. Nano Lett. 7, 3803–3807 (2007).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Jang, E. et al. White-light-emitting diodes with quantum dot color converters for display backlights. Adv. Mater. 22, 3076–3080 (2010).Article 
    CAS 
    
                    Google Scholar 
                Xie, B., Hu, R. & Luo, X. B. Quantum Dots-converted light-emitting diodes packaging for lighting and display: status and perspectives. J. Electron. Packag. 138, 020803 (2016).Article 
    
                    Google Scholar 
                Chen, B. K. et al. Mesoporous aluminum hydroxide synthesized by a single-source precursor-decomposition approach as a high-quantum-yield blue phosphor for UV-pumped white-light-emitting diodes. Adv. Mater. 29, 1604284 (2017).Article 
    
                    Google Scholar 
                Chang, S. C. et al. Multicolor organic light-emitting diodes processed by hybrid inkjet printing. Adv. Mater. 11, 734–737 (1999).Article 
    CAS 
    
                    Google Scholar 
                Zheng, H. et al. All-solution processed polymer light-emitting diode displays. Nat. Commun. 4, 1971 (2013).Article 
    
                    Google Scholar 
                Kumar, K. et al. Printing colour at the optical diffraction limit. Nat. Nanotechnol. 7, 557–561 (2012).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Gu, Z. K. et al. Direct-writing multifunctional perovskite single crystal arrays by inkjet printing. Small 13, 1603217 (2017).Article 
    
                    Google Scholar 
                Goh, X. M. et al. Three-dimensional plasmonic stereoscopic prints in full colour. Nat. Commun. 5, 5361 (2014).Article 
    CAS 
    
                    Google Scholar 
                Meruga, J. M., Baride, A., Cross, W., Kellar, J. J. & May, P. S. Red-green-blue printing using luminescence-upconversion inks. J. Mater. Chem. C 2, 2221–2227 (2014).Article 
    CAS 
    
                    Google Scholar 
                Mahalingam, V., Vetrone, F., Naccache, R., Speghini, A. & Capobianco, J. A. Colloidal Tm3 + /Yb3 + -Doped LiYF4 nanocrystals: multiple luminescence spanning the UV to NIR regions via low-energy excitation. Adv. Mater. 21, 4025–4028 (2009).Article 
    CAS 
    
                    Google Scholar 
                Kumar, P., Dwivedi, J. & Gupta, B. K. Highly luminescent dual mode rare-earth nanorod assisted multi-stage excitable security ink for anti-counterfeiting applications. J. Mater. Chem. C 2, 10468–10475 (2014).Article 
    CAS 
    
                    Google Scholar 
                Mei, J. F. et al. A novel photo-responsive europium(III) complex for advanced anti-counterfeiting and encryption. Dalton Trans. 45, 5451–5454 (2016).Article 
    CAS 
    
                    Google Scholar 
                Andres, J., Hersch, R. D., Moser, J. E. & Chauvin, A. S. A new anti-counterfeiting feature relying on invisible luminescent full color images printed with lanthanide-based inks. Adv. Funct. Mater. 24, 5029–5036 (2014).Article 
    CAS 
    
                    Google Scholar 
                Jiang, K. et al. Triple-mode emission of carbon dots: applications for advanced anti-counterfeiting. Angew. Chem. Int. Ed. 55, 7231–7235 (2016).Article 
    CAS 
    
                    Google Scholar 
                Zhu, L. L., Yin, Y. J., Wang, C. F. & Chen, S. Plant leaf-derived fluorescent carbon dots for sensing, patterning and coding. J. Mater. Chem. C 1, 4925–4932 (2013).Article 
    CAS 
    
                    Google Scholar 
                You, M. L. et al. Inkjet printing of upconversion nanoparticles for anti-counterfeit applications. Nanoscale 7, 4423–4431 (2015).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                You, M. L. et al. Three-dimensional quick response code based on inkjet printing of upconversion fluorescent nanoparticles for drug anti-counterfeiting. Nanoscale 8, 10096–10104 (2016).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Yao, W. J. et al. Large-scale synthesis and screen printing of upconversion hexagonal-phase NaYF4:Yb3 + ,Tm3 + /Er3 + /Eu3 + plates for security applications. J. Mater. Chem. C 4, 6327–6335 (2016).Article 
    CAS 
    
                    Google Scholar 
                Segler, M. H. S., Preuss, M. & Waller, M. P. Planning chemical syntheses with deep neural networks and symbolic AI. Nature 555, 604–610 (2018).Article 
    ADS 
    CAS 
    
                    Google Scholar 
                Ziatdinov, M. et al. Deep learning of atomically resolved scanning transmission electron microscopy images: chemical identification and tracking local transformations. ACS Nano 11, 12742–12752 (2017).Article 
    CAS 
    
                    Google Scholar 
                Chen, B. et al. Highly emissive and color-tunable CuInS2-Based colloidal semiconductor nanocrystals: off-stoichiometry effects and improved electroluminescence performance. Adv. Funct. Mater. 22, 2081–2088 (2012).Article 
    CAS 
    
                    Google Scholar 
                Liu, W. H. et al. Compact cysteine-coated CdSe(ZnCdS) quantum dots for in vivo applications. J. Am. Chem. Soc. 129, 14530–14531 (2007).Article 
    CAS 
    PubMed Central 
    
                    Google Scholar 
                Krizhevsky A., Sutskever I., Hinton G. E. Advances in Neural Information Processing Systems (Neural Information Processing Systems Foundation, 1269 Law Street, San Diego, CA 92109, 2012).Download referencesAcknowledgementsWe acknowledge the generous financial support from the National Natural Science Foundation of China (Grant No. U1605244, 61605028, and 61775040), the National Key Research and Development Program of China (Grant No. 2016YFB0401305), Program for Thousand Young Talent plan and Guangdong Provincial Science and Technology project (Grant NO. 2016B090906001). We acknowledge the help of Jiangmen Innovative & Entepreneurial Research Team Program in synthesizing quantum dots.Author informationAuthor notesThese authors contributed equally: Yang Liu, Fei Han.Authors and AffiliationsInstitute of Optoelectronic Technology, Fuzhou University, Fuzhou, 350116, ChinaYang Liu, Fushan Li, Yan Zhao, Maosheng Chen, Zhongwei Xu, Xin Zheng, Hailong Hu, Jianmin Yao & Tailiang GuoCollege of Chemistry, Fuzhou University, Fuzhou, 350116, ChinaFei Han, Wanzhen Lin & Yuanhui ZhengGuangdong Poly Optoelectronics Co., Ltd, Jiangmen, 529020, ChinaBaogui You, Pai Liu & Yang LiTCL Corporate Research, No. 1001 Zhongshan Park Road, Nanshan District, Shenzhen, 518067, ChinaLei QianAuthorsYang LiuView author publicationsYou can also search for this author in
                        PubMed Google ScholarFei HanView author publicationsYou can also search for this author in
                        PubMed Google ScholarFushan LiView author publicationsYou can also search for this author in
                        PubMed Google ScholarYan ZhaoView author publicationsYou can also search for this author in
                        PubMed Google ScholarMaosheng ChenView author publicationsYou can also search for this author in
                        PubMed Google ScholarZhongwei XuView author publicationsYou can also search for this author in
                        PubMed Google ScholarXin ZhengView author publicationsYou can also search for this author in
                        PubMed Google ScholarHailong HuView author publicationsYou can also search for this author in
                        PubMed Google ScholarJianmin YaoView author publicationsYou can also search for this author in
                        PubMed Google ScholarTailiang GuoView author publicationsYou can also search for this author in
                        PubMed Google ScholarWanzhen LinView author publicationsYou can also search for this author in
                        PubMed Google ScholarYuanhui ZhengView author publicationsYou can also search for this author in
                        PubMed Google ScholarBaogui YouView author publicationsYou can also search for this author in
                        PubMed Google ScholarPai LiuView author publicationsYou can also search for this author in
                        PubMed Google ScholarYang LiView author publicationsYou can also search for this author in
                        PubMed Google ScholarLei QianView author publicationsYou can also search for this author in
                        PubMed Google ScholarContributionsF.S.L. and Y.H.Z. conceived the project. Y.Liu and F.S.L. designed the experiments and fabricated the devices. Y.Liu and F.H. collected and analysed the data. M.S.C., Z.W.X., X.Z. H.L.H., T.L.G. and W.Z.L. assisted sample characterization and data analysis. Y.Liu, Y.Z. and J.M.Y conducted deep learning authentication. B.G.Y., P.L. and Y.Li from Guangdong Poly Optoelectronics Co., Ltd offered help in synthesizing the quantum dots. Y.Liu, F.H., F.S.L., Y.H.Z. and L.Q. wrote the manuscript. All the authors read and commented on the paper.Corresponding authorsCorrespondence to
                Fushan Li, Yuanhui Zheng or Lei Qian.Ethics declarations
Competing interests
The authors declare no competing interests.
Additional informationJournal peer review information: Nature Communications thanks Thomas Jurst Sørensen, Wook Park and Stanley May for their contribution to the peer review of this work. Peer reviewer reports are available.Publisher’s note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Supplementary informationSupplementary InformationPeer Review FileDescription of Additional Supplementary FilesSupplementary Data 1Supplementary Data 2Rights and permissions
Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.
Reprints and permissionsAbout this articleCite this articleLiu, Y., Han, F., Li, F. et al. Inkjet-printed unclonable quantum dot fluorescent anti-counterfeiting labels with artificial intelligence authentication.
                    Nat Commun 10, 2409 (2019). https://doi.org/10.1038/s41467-019-10406-7Download citationReceived: 30 October 2018Accepted: 08 May 2019Published: 03 June 2019DOI: https://doi.org/10.1038/s41467-019-10406-7Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        
Subjects

Nanoscale materialsQuantum dots





This article is cited by





                                        All-silicon multidimensionally-encoded optical physical unclonable functions for integrated circuit anti-counterfeiting
                                    


Kun WangJianwei ShiDeren Yang

Nature Communications (2024)




                                        Printed smart devices for anti-counterfeiting allowing precise identification with household equipment
                                    


Junfang ZhangRong TanFelix F. Loeffler

Nature Communications (2024)




                                        Surface passivation of intensely luminescent all-inorganic nanocrystals and their direct optical patterning
                                    


Pengwei XiaoZhoufan ZhangYuanyuan Wang

Nature Communications (2023)




                                        An all-in-one nanoprinting approach for the synthesis of a nanofilm library for unclonable anti-counterfeiting applications
                                    


Junfang ZhangYuxin LiuFelix F. Loeffler

Nature Nanotechnology (2023)




                                        Random fractal-enabled physical unclonable functions with dynamic AI authentication
                                    


Ningfei SunZiyu ChenQian Liu

Nature Communications (2023)





CommentsBy submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.





",,,,,,,"{'headline': 'Inkjet-printed unclonable quantum dot fluorescent anti-counterfeiting labels with artificial intelligence authentication', 'description': 'An ideal anti-counterfeiting technique has to be inexpensive, mass-producible, nondestructive, unclonable and convenient for authentication. Although many anti-counterfeiting technologies have been developed, very few of them fulfill all the above requirements. Here we report a non-destructive, inkjet-printable, artificial intelligence (AI)-decodable and unclonable security label. The stochastic pinning points at the three-phase contact line of the ink droplets is crucial for the successful inkjet printing of the unclonable security labels. Upon the solvent evaporation, the three-phase contact lines are pinned around the pinning points, where the quantum dots in the ink droplets deposited on, forming physically unclonable flower-like patterns. By utilizing the RGB emission quantum dots, full-color fluorescence security labels can be produced. A convenient and reliable AI-based authentication strategy is developed, allowing for the fast authentication of the covert, unclonable flower-like dot patterns with different sharpness, brightness, rotations, amplifications and the mixture of these parameters. Anti-counterfeiting technologies should ideally be unclonable, yet simple to fabricate and decode. Here, the authors develop an inkjet-printable and unclonable security label based on random patterning of quantum dot inks, and accompany it with an artificial intelligence decoding mechanism capable of authenticating the patterns.', 'datePublished': '2019-06-03T00:00:00Z', 'dateModified': '2019-06-03T00:00:00Z', 'pageStart': '1', 'pageEnd': '9', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'sameAs': 'https://doi.org/10.1038/s41467-019-10406-7', 'keywords': ['Nanoscale materials', 'Quantum dots', 'Science', 'Humanities and Social Sciences', 'multidisciplinary'], 'image': ['https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-10406-7/MediaObjects/41467_2019_10406_Fig1_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-10406-7/MediaObjects/41467_2019_10406_Fig2_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-10406-7/MediaObjects/41467_2019_10406_Fig3_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41467-019-10406-7/MediaObjects/41467_2019_10406_Fig4_HTML.png'], 'isPartOf': {'name': 'Nature Communications', 'issn': ['2041-1723'], 'volumeNumber': '10', '@type': ['Periodical', 'PublicationVolume']}, 'publisher': {'name': 'Nature Publishing Group UK', 'logo': {'url': 'https://www.springernature.com/app-sn/public/images/logo-springernature.png', '@type': 'ImageObject'}, '@type': 'Organization'}, 'author': [{'name': 'Yang Liu', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Fei Han', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'College of Chemistry, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Fushan Li', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'fsli@fzu.edu.cn', '@type': 'Person'}, {'name': 'Yan Zhao', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Maosheng Chen', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Zhongwei Xu', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Xin Zheng', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Hailong Hu', 'url': 'http://orcid.org/0000-0001-5299-2812', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Jianmin Yao', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Tailiang Guo', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'Institute of Optoelectronic Technology, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Wanzhen Lin', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'College of Chemistry, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Yuanhui Zheng', 'url': 'http://orcid.org/0000-0001-6326-727X', 'affiliation': [{'name': 'Fuzhou University', 'address': {'name': 'College of Chemistry, Fuzhou University, Fuzhou, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'yuanhui.zheng@fzu.edu.cn', '@type': 'Person'}, {'name': 'Baogui You', 'affiliation': [{'name': 'Guangdong Poly Optoelectronics Co., Ltd', 'address': {'name': 'Guangdong Poly Optoelectronics Co., Ltd, Jiangmen, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Pai Liu', 'affiliation': [{'name': 'Guangdong Poly Optoelectronics Co., Ltd', 'address': {'name': 'Guangdong Poly Optoelectronics Co., Ltd, Jiangmen, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Yang Li', 'affiliation': [{'name': 'Guangdong Poly Optoelectronics Co., Ltd', 'address': {'name': 'Guangdong Poly Optoelectronics Co., Ltd, Jiangmen, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Lei Qian', 'affiliation': [{'name': 'TCL Corporate Research', 'address': {'name': 'TCL Corporate Research, Shenzhen, China', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'qianlei@tcl.com', '@type': 'Person'}], 'isAccessibleForFree': True, '@type': 'ScholarlyArticle'}",,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LndpcmVkLmNvbS9iZXlvbmQtdGhlLWJleW9uZC8yMDE5LzA2L2JlaWppbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcHJpbmNpcGxlcy_SAQA?oc=5,The Beijing Artificial Intelligence Principles - WIRED,2019-06-01,WIRED,https://www.wired.com,,"['beyond the beyond', 'web']",,,https://schema.org/,BreadcrumbList,https://www.wired.com/beyond-the-beyond/2019/06/beijing-artificial-intelligence-principles/,[],"[{'@type': 'Person', 'name': 'Bruce Sterling', 'sameAs': 'https://www.wired.com/author/bruce-sterling/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",The Beijing Artificial Intelligence Principles,2019-06-01T13:46:01.000-04:00,2019-06-01T13:46:01.000-04:00,article,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'article', 'item': 'https://www.wired.com/article/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Beyond the Beyond', 'item': 'https://www.wired.com/tag/beyond-the-beyond/'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Beijing Artificial Intelligence Principles'}]",tags,N/A,"Bruce SterlingJun 1, 2019 1:46 PMThe Beijing Artificial Intelligence PrinciplesSave this storySaveSave this storySavehttps://baip.baai.ac.cn/en?fbclid=IwAR2HtIRKJxxy9Q1Y953H-2pMHl_bIr8pcsIxho93BtZY-FPH39vV9v9B2eYBeijing AI Principles2019年5月28日 · 新闻AdvertisementThe development of Artificial Intelligence (AI) concerns the future of the whole society, all humankind, and the environment. The principles below are proposed as an initiative for the research, development, use, governance and long-term planning of AI, calling for its healthy development to support the construction of a community of common destiny, and the realization of beneficial AI for humankind and nature.AdChoicesADVERTISEMENTResearch and DevelopmentThe research and development (R&D) of AI should observe the following principles:Trending NowCES HQ 2021: Artificial Intelligence in American DefenseDo Good: AI should be designed and developed to promote the progress of society and human civilization, to promote the sustainable development of nature and society, to benefit all humankind and the environment, and to enhance the well-being of society and ecology.For Humanity: The R&D of AI should serve humanity and conform to human values as well as the overall interests of humankind. Human privacy, dignity, freedom, autonomy, and rights should be sufficiently respected. AI should not be used to against, utilize or harm human beings.Be Responsible: Researchers and developers of AI should have sufficient considerations for the potential ethical, legal, and social impacts and risks brought in by their products and take concrete actions to reduce and avoid them.Control Risks: Continuous efforts should be made to improve the maturity, robustness, reliability, and controllability of AI systems, so as to ensure the security for the data, the safety and security for the AI system itself, and the safety for the external environment where the AI system deploys.Be Ethical: AI R&D should take ethical design approaches to make the system trustworthy. This may include, but not limited to: making the system as fair as possible, reducing possible discrimination and biases, improving its transparency, explainability, and predictability, and making the system more traceable, auditable and accountable.Be Diverse and Inclusive: The development of AI should reflect diversity and inclusiveness, and be designed to benefit as many people as possible, especially those who would otherwise be easily neglected or underrepresented in AI applications.Open and Share: It is encouraged to establish AI open platforms to avoid data/platform monopolies, to share the benefits of AI development to the greatest extent, and to promote equal development opportunities for different regions and industries.UseThe use of AI should observe the following principles:Use Wisely and Properly: Users of AI systems should have the necessary knowledge and ability to make the system operate according to its design, and have sufficient understanding of the potential impacts to avoid possible misuse and abuse, so as to maximize its benefits and minimize the risks.Informed-consent: Measures should be taken to ensure that stakeholders of AI systems are with sufficient informed-consent about the impact of the system on their rights and interests. When unexpected circumstances occur, reasonable data and service revocation mechanisms should be established to ensure that users' own rights and interests are not infringed.Education and Training: Stakeholders of AI systems should be able to receive education and training to help them adapt to the impact of AI development in psychological, emotional and technical aspects.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David Gilbert, WIREDSecurityAT&T Paid a Hacker $370,000 to Delete Stolen Phone RecordsBy Kim Zetter, WIREDGovernanceThe governance of AI should observe the following principles:Optimizing Employment: An inclusive attitude should be taken towards the potential impact of AI on human employment. A cautious attitude should be taken towards the promotion of AI applications that may have huge impacts on human employment. Explorations on Human-AI coordination and new forms of work that would give full play to human advantages and characteristics should be encouraged.Harmony and Cooperation: Cooperation should be actively developed to establish an interdisciplinary, cross-domain, cross-sectoral, cross-organizational, cross-regional, global and comprehensive AI governance ecosystem, so as to avoid malicious AI race, to share AI governance experience, and to jointly cope with the impact of AI with the philosophy of ""Optimizing Symbiosis"".Adaptation and Moderation: Adaptive revisions of AI principles, policies, and regulations should be actively considered to adjust them to the development of AI. Governance measures of AI should match its development status, not only to avoid hindering its proper utilization, but also to ensure that it is beneficial to society and nature.Subdivision and Implementation: Various fields and scenarios of AI applications should be actively considered for further formulating more specific and detailed guidelines. The implementation of such principles should also be actively promoted – through the whole life cycle of AI research, development, and application.Long-term Planning: Continuous research on the potential risks of Augmented Intelligence, Artificial General Intelligence (AGI) and Superintelligence should be encouraged. Strategic designs should be considered to ensure that AI will always be beneficial to society and nature in the future.Email: aies@baai.ac.cn","{'@type': 'WebPage', '@id': 'https://www.wired.com/beyond-the-beyond/2019/06/beijing-artificial-intelligence-principles/'}",,,,"Beijing AI Principles
2019年5月28日 · 新闻
The development of Artificial Intelligence (AI) concerns the future of the whole society, all humankind, and the environment. The principles below are proposed as an initiative for the research, development, use, governance and long-term planning of AI, calling for its healthy development to support the construction of a community of common destiny, and the realization of beneficial AI for humankind and nature.
Research and Development
The research and development (R&D) of AI should observe the following principles:
Do Good: AI should be designed and developed to promote the progress of society and human civilization, to promote the sustainable development of nature and society, to benefit all humankind and the environment, and to enhance the well-being of society and ecology.
For Humanity: The R&D of AI should serve humanity and conform to human values as well as the overall interests of humankind. Human privacy, dignity, freedom, autonomy, and rights should be sufficiently respected. AI should not be used to against, utilize or harm human beings.
Be Responsible: Researchers and developers of AI should have sufficient considerations for the potential ethical, legal, and social impacts and risks brought in by their products and take concrete actions to reduce and avoid them.
Control Risks: Continuous efforts should be made to improve the maturity, robustness, reliability, and controllability of AI systems, so as to ensure the security for the data, the safety and security for the AI system itself, and the safety for the external environment where the AI system deploys.
Be Ethical: AI R&D should take ethical design approaches to make the system trustworthy. This may include, but not limited to: making the system as fair as possible, reducing possible discrimination and biases, improving its transparency, explainability, and predictability, and making the system more traceable, auditable and accountable.
Be Diverse and Inclusive: The development of AI should reflect diversity and inclusiveness, and be designed to benefit as many people as possible, especially those who would otherwise be easily neglected or underrepresented in AI applications.
Open and Share: It is encouraged to establish AI open platforms to avoid data/platform monopolies, to share the benefits of AI development to the greatest extent, and to promote equal development opportunities for different regions and industries.
Use
The use of AI should observe the following principles:
Use Wisely and Properly: Users of AI systems should have the necessary knowledge and ability to make the system operate according to its design, and have sufficient understanding of the potential impacts to avoid possible misuse and abuse, so as to maximize its benefits and minimize the risks.
Informed-consent: Measures should be taken to ensure that stakeholders of AI systems are with sufficient informed-consent about the impact of the system on their rights and interests. When unexpected circumstances occur, reasonable data and service revocation mechanisms should be established to ensure that users' own rights and interests are not infringed.
Education and Training: Stakeholders of AI systems should be able to receive education and training to help them adapt to the impact of AI development in psychological, emotional and technical aspects.
Governance
The governance of AI should observe the following principles:
Optimizing Employment: An inclusive attitude should be taken towards the potential impact of AI on human employment. A cautious attitude should be taken towards the promotion of AI applications that may have huge impacts on human employment. Explorations on Human-AI coordination and new forms of work that would give full play to human advantages and characteristics should be encouraged.
Harmony and Cooperation: Cooperation should be actively developed to establish an interdisciplinary, cross-domain, cross-sectoral, cross-organizational, cross-regional, global and comprehensive AI governance ecosystem, so as to avoid malicious AI race, to share AI governance experience, and to jointly cope with the impact of AI with the philosophy of ""Optimizing Symbiosis"".
Adaptation and Moderation: Adaptive revisions of AI principles, policies, and regulations should be actively considered to adjust them to the development of AI. Governance measures of AI should match its development status, not only to avoid hindering its proper utilization, but also to ensure that it is beneficial to society and nature.
Subdivision and Implementation: Various fields and scenarios of AI applications should be actively considered for further formulating more specific and detailed guidelines. The implementation of such principles should also be actively promoted – through the whole life cycle of AI research, development, and application.
Long-term Planning: Continuous research on the potential risks of Augmented Intelligence, Artificial General Intelligence (AGI) and Superintelligence should be encouraged. Strategic designs should be considered to ensure that AI will always be beneficial to society and nature in the future.
Email: aies@baai.ac.cn",,,,,"{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vd3d3LmktcHJvZ3JhbW1lci5pbmZvL25ld3MvMTUwLXRyYWluaW5nLWEtZWR1Y2F0aW9uLzEyODE2LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWZvci1rLTEyLS5odG1s0gEA?oc=5,Artificial Intelligence for K-12 - iProgrammer,2019-06-03,iProgrammer,https://www.i-programmer.info,"Programming book reviews, programming tutorials,programming news, C#, Ruby, Python,C, C++, PHP, Visual Basic, Computer book reviews, computer history, programming history, joomla, theory, spreadsheets and more.","Programming book reviews, programming tutorials,programming news, developer news,software programmer news, C#, Ruby, Python,C, C++, PHP, Visual Basic, Computer book reviews, computer history, programming history, joomla, theory, spreadsheets, developer book reviews, programmer news, developer news, news",N/A,N/A,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vZW1lcmouY29tL2FpLXNlY3Rvci1vdmVydmlld3MvaG93LXNlbGYtZHJpdmluZy1jYXJzLXdvcmsv0gEA?oc=5,How Self-Driving Cars Work – A Simple Overview - Emerj,2019-06-03,Emerj,https://emerj.com,"From LIDAR to computer vision, and from Waymo to Tesla, discover the technologies that enable cars to navigate autonomously. Demo videos/ graphics included.",,"From LIDAR to computer vision, and from Waymo to Tesla, discover the technologies that enable cars to navigate autonomously. Demo videos/ graphics included.",N/A,https://schema.org,Article,,https://emerj.com/wp-content/uploads/2019/06/how-self-driving-cars-work-690x268.jpg,Radhika Madhavan,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",How Self-Driving Cars Work &#8211; A Simple Overview,2019-06-03,2019-06-03,,,,,N/A,N/A," Automation and roboticsTransportation How Self-Driving Cars Work – A Simple Overview Radhika MadhavanLast updated on June 3, 2019  Last updated on June 3, 2019, published by Radhika Madhavan Radhika Madhavan covers AI innovation at Emerj. Radhika previously worked in content marketing at three technology firms, and graduated from Sri Krishna College Of Engineering And Technology with a degree in Information Technology. Share to: LinkedIn Twitter Facebook Email  The National Highway Traffic Safety Administration (NHTSA) of the U.S. Department of Transportation recently released an overview report on the current state of self-driving technology.  According to the report, automated vehicle technologies are still in the research and development phase. The map given below depicts the controlled test sites in the U.S. where self-driving cars components and systems using modeling, simulation and on road. Source: US NHTSA This article aims to serve fundamental and introductory information on how self-driving and autonomous cars currently operate in the real world – from hardware to software. We’ve broken this article out into three sections: What constitutes a self-driving car (levels of autonomy) How self-driving cars interact with each other and their surroundings Current examples of how Google’s Waymo and Tesla’s Autopilot operate For readers looking to gather further information on self-driving car applications in real time, we have previously covered important, in-depth information on the same in articles such as The Self-Driving Car Timeline – Predictions from the Top 11 Global Automakers and AI for Self-Driving Car Safety – Current Applications. We’ll begin by examining levels of autonomy: Levels of Autonomy in a Self-Driving Car According to the SAE International, a self-driving car has five levels of autonomy: Source: SAE International Level 1: This is a low-level automation where the system and the human driver share control. For instance, the adaptive cruise control feature controls the engine and brake power for speed variation and maintenance while the driver would control the steering. Level 1 systems may warrant for full human control anytime.  Level 2: At this level, while vehicle operations such as acceleration, brakes and steering are in the system’s control, driver’s constant monitoring of the autonomous system is needed. Many Level 2 vehicles require the driver to hold the steering wheel for the autonomous system to continuously operate.  Level 3: Autonomous vehicles that fall under this category allow the driver to perform other tasks (like texting or watching a movie) while the system takes control of most vehicle operations. However, the system requires driver intervention within a limited time for some operations as specified by the vehicle manufacturer.  Level 4: This level supports self-driving with minimal driver intervention but it does so only in select, mapped locations called geofenced areas.   Level 5: No human intervention is required. BMW’s self-driving car introductory video demonstrates what each of the five levels might be like for riders and drivers, with an overview of some of the technologies that enable autonomy:  While level 5 autonomy is the shared dream of many self-driving car firms, their respective path to arrive at level 5 autonomy are quite different. Some firms believe that level 3 and level 4 autonomy are too dangerous, because the hand-off from machine to human could be unpredictable and dangerous (switching from texting or watching a movie to swerving away from an accident might be an unrealistic expectation). How a Self-Driving Car Interacts with Its Surroundings According to the United States Department of Transportation, the connected and autonomous vehicles communicate with each other and their surroundings in three ways: Vehicle to Vehicle (V2V) Interaction The V2V interaction between autonomous cars allows information exchange on routes, congestion, obstacles, and hazards.  For example, if a self-driving car encounters an accident or high-volume but slow-moving traffic, it is capable of relaying the information to other self-driving cars, which can then adjust their routes according to the received data and potentially avoid accidents and traffic.  Vehicle to Infrastructure (V2I) Interaction Self-driving cars can communicate with infrastructure components such as intelligent parking systems to plan routes and reserve parking spaces well ahead of the journey.  This information especially useful when the autonomous car has to decide how to park when it has reached its destination: parallel, perpendicular or angular. In addition, other driverless cars would “know” in advance whether a particular parking space has already been reserved or is open.   Vehicle to Pedestrian (V2P) Interaction The V2P interaction is primarily carried out between a self-driving car and a pedestrian’s smartphone application.  According to The University of Minnesota, it funded a V2P prototype called Mobile Accessible Pedestrian Signal (MAPS). A visually-impaired pedestrian can use MAPS to receive and provide information regarding the intersection and the pedestrian’s location, respectively. Self-driving cars would then use such data, in addition to that provided by the cars’ sensors and LiDARs to more accurately locate pedestrians and potentially avoid collisions.   Examples and Use-Cases Bosch explains some simple use-cases of V2V and V2I technology in the following two-minute video:  China’s now-embattled hardware manufacturer Huawei demonstrates a variety of potential “V2” use-cases in this 2018 demo video:  While the technology is still in its infancy, “V2” technologies are helping to pave the path to more complete autonomy – and hopefully – to vastly safer roads for drivers and pedestrians. It is unclear whether different countries will develop entirely different V2 use-cases and standards, and it’s too early to tell which V2 applications will become standard in the coming years, and which will be abandoned. Current Examples of Self-Driving Cars and Components at Work Google and Tesla are the biggest players in the current autonomous vehicle space. In order to better understand how self-driving cars work in real time, this article includes details about the workings and operations of Google’s Waymo and Tesla’s Autopilot.  Google’s Waymo According to Google, Waymo is a Level 4 autonomous system, requiring minimal human intervention.  Waymo’s Hardware Infrastructure A descriptive image of Waymo’s hardware is provided below: Source: Google Waymo’s infrastructure includes a variety of sensor, radar, and camera systems. LiDAR Sensors  According to Google, Waymo has a multi-layered sensor suite capable of operating in different lighting conditions. This sensor suite is essentially an omnidirectional LiDAR system comprising a short-range, a high-resolution mid-range and a long-range LiDAR. These LiDARs project millions of laser pulses per second and calculate the time taken for the beams to reflect off a surface or a person and return to the self-driving car.  Based on the data received from the LiDAR beams, Waymo reportedly creates a 3D map of the surroundings, identifying mobile and immobile objects, including other vehicles, cyclists, pedestrians, traffic lights, and a variety of road features.  Vision Waymo’s vision system is yet another omnidirectional, high-resolution camera suite purportedly capable of identifying color in low-light conditions. This helps in detecting different traffic lights, other vehicles, construction zones and emergency lights.    Radar Google claims that Waymo uses a radar system to perceive objects and motion through wavelengths “travelling around” different light and weather conditions, such as rain, snow and fog. This radar system is also omnidirectional and can track the speed of pedestrians and other vehicles 360 degrees around the self-driving car.  Supplemental Sensors Waymo is also supplemented with extra sensors that include an audio detection system to detect emergency sirens and a GPS to track physical locations.  Waymo’s Self-Driving Software Google claims that Waymo’s self-driving software has been trained and tested based on “5 billion miles of simulated driving and 5 million miles of on-road driving experience.” It is powered by machine-learning algorithms. The below video elaborates on how Waymo operates on the road:  According to Google, Waymo’s Level 4 technology detects and “understands” objects and their behavior and accordingly adjusts the behavior of the autonomous vehicle in a three-fold process.   Perception  Waymo can reportedly detect, identify and classify objects on the road, including pedestrians and other vehicles, while simultaneously measuring their speed, direction and acceleration over time. For example, Waymo’s perception software collects the data from the sensors and radars and creates a simulated “view” of the surroundings. Owing to this capability, Waymo is able to determine whether it can proceed through the traffic when the light turns green or adjust its route due to a blocked lane indicated by traffic cones. Behavior prediction Waymo, according to Google, can predict the behavior of an object on the road based on its classification by inferring data from the training models constructed using “millions of miles of driving experience.  For example, the self-driving software “understands” that while pedestrians may look similar to cyclists, they move slower than the latter and exhibit more abrupt directional changes. Planner The planner software reportedly uses the information captured by the perception and behavior prediction software to plan appropriate routes for Waymo. Google claims that Waymo’s planner operates like a “defensive driver,” who chooses to stay away from blind spots and gives leeway to cyclists and pedestrians.   Tesla’s Autopilot Autopilot, according to Tesla, is a Level 2 autonomous vehicle feature. Like most Level 2 systems, Autopilot requires that the driver hold the steering wheel at all time, poised to take over control.  Tesla also warns that the driver has to be fully functional and aware during autonomous operations.  Autopilot Hardware The picture below shows the hardware components of the Autopilot. Courtesy: Tesla According to Tesla, its self-driving cars manufactured between 2014 and October 2016 included limited ultrasonic sensors, low-power radar and only one camera.  Those built since 2016 comprise 12 ultrasonic sensors for nearby object and pedestrian identification, a frontal radar capable of “sensing through” different weather conditions, eight external cameras that are used as feeds for Tesla’s in-house neural net and a computer system that processes inputs in milliseconds.  The Tesla connected car software is continually updated “over the air.”    Autopilot Software Traffic-Aware Cruise Control for maintaining speed in response to the surrounding traffic. Driver-assisted “Autosteer” within the boundaries of well-marked lane Auto Lane Change for transitioning between lanes Driver-assisted “Navigate on Autopilot” for guiding the vehicle from a highway’s on-ramp to off-ramp, including suggesting and making lane changes, navigating highway interchanges, and taking exits.  Autopark for automatic parallel or perpendicular parking Summon for “calling” the car from its parking space The workings of the above-mentioned features are briefly explained below: Navigate on Autopilot The Navigate on Autopilot feature allows the driver to input a destination into the vehicle’s navigation system, which kickstarts the “360-degree visualization” showing a planned route. This features has to be enabled for each trip for safety reasons. It does not operate on default mode, according to Tesla.  Auto Lane Change The Navigate on Autopilot feature includes two types of lane changes: route-based and speed-based. The former allows the vehicle to stick to the navigation route irrespective of speed. The latter, based on a few settings, suggests transitions into lanes with vehicles moving faster or slower than Autopilot in reference to the set cruise speed.  Automatic lane change kicks into mode when the driver opts out of lane change confirmation notification. However, Tesla warns drivers that this feature is not fully-autonomous and that it requires their complete attention and hold over the steering wheel. Tesla claims that the driver can manually override this feature anytime.  Autopark and Summon The driver can initiate Autopark when the car is driving at low speeds trying to detect a suitable parking spot. This needs manual intervention of putting the car in reverse and pressing start, however, before the car begins to independently control speed, change gears and steering angles. Autopilot also has a Summon button triggered through an app when the passenger wants to “call” the car and direct it through a series of forward and reverse button clicks.  The video below shows a Tesla Autopilot live demonstration on the road in real time:  Barriers to Autonomy While self-driving vehicle investments have skyrocketed in the last five years – there are still a number of important challenges keeping level 5 autonomy from becoming a reality: Road Rules in the Developing World – California highways are a different driving environment than the traffic of Cairo or Bangalore. The developing world may be left behind in terms of autonomous vehicle adoption (and thus, in terms of safety, lower emissions, and increased worker productivity) unless autonomous systems are developed to handle their unique circumstances and roadway norms. This may involve signifiant changes to driving habits and norms in these countries, or “test areas” where different roadway rules apply and where self-driving technologies can be tested. Unified Standards – In order for vehicles to communicate with themselves or with infrastructure, new communication channels will have to be developed. These channels should allow vehicles of different makes and models to communicate, and they should be as safe as possible from hacking and deception. While the US and other nations are working on furthering these standards, there is much work to be done to ensure safety and to create a unified intelligent layer between vehicles and infrastructure. Safety Thresholds – The number of deaths per passenger-mile on commercial airlines in the United States between 2000 and 2010 was about 0.2 deaths per 10 billion passenger-miles (Wikipedia). It seems safe to say that standards for self-driving vehicles will be more strict, but it isn’t clear where the cut-off will lie. Governments of different nations will have to determine acceptable mortality rates, and safety standards and guidelines for different kinds of autonomous vehicles. Weather and Disasters – Blizzards, floods, or damage to street signs and “V2” technologies could put self-driving cars at risk of serious error and mortal danger. Building road infrastructure to handle disasters, and building vehicles to hander abnormal or less-and-ideal conditions (visibility, tire traction, etc) is much more challenging that simply putting a car on the road on a sunny day in Mountain View, CA.   Header image credit: NVIDIA Related Posts Machine Vision for Self-Driving Cars - Current ApplicationsMicKinsey estimated that by 2030, up to 15% of cars sold will be autonomous vehicles. We… AI for Self-Driving Car Safety - Current ApplicationsAllied Market Research estimated the value of the global autonomous vehicle (AV) industry to reach $54.23 billion… AI in the Automotive Industry - Insurance and Self-Driving Car ApplicationsStatista estimated that the market for partially autonomous cars will be at $36 billion by… How AI-Enabled Product Recommendations Work - A Brief OverviewMany AI vendor companies offer AI-enabled products and services for pushing more and more products… Artificial Intelligence at Wells Fargo - A Brief OverviewWells Fargo has begun a number of AI initiatives, some they've created in-house and some… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",https://emerj.com/ai-sector-overviews/how-self-driving-cars-work,,,,,,,,,,,AI Sector Overviews,2252,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vZW4uY3J5cHRvbm9taXN0LmNoLzIwMTkvMDYvMDIvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tY3J5cHRvY3VycmVuY3ktdHJhZGluZy_SAQA?oc=5,Artificial intelligence in cryptocurrency trading: use cases - The Cryptonomist,2019-06-02,The Cryptonomist,https://en.cryptonomist.ch,Nowadays we hear about artificial intelligence (abbreviated with the acronym AI) and also the world of cryptocurrency trading has not been excluded.,"Artificial,intelligence,in,cryptocurrency,trading",Modern AI can recognize scams and identify sentiment around cryptocurrencies,Modern AI can recognize scams and identify sentiment around cryptocurrencies,https://schema.org,BreadcrumbList,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://cryptonomist.ch/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://en.cryptonomist.ch/categoria/trading-en/', 'name': 'Trading'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': '', 'name': 'Artificial intelligence in cryptocurrency trading: use cases'}}]",N/A,N/A,"




HomeTradingArtificial intelligence in cryptocurrency trading: use cases


Trading
Artificial intelligence in cryptocurrency trading: use cases
2 June 2019 




Share
FacebookTwitterPinterestWhatsApp







Nowadays we hear more and more often about artificial intelligence (abbreviated with the acronym AI) and also the world of cryptocurrency trading has not been excluded.
According to two recent pieces of research, artificial intelligence could be of help to the traders going to predict the short-term trend of the price of a coin or to identify possible scams.
Recognition of Pump and Dump
The work of Jiahua Xu and Benjamin Livshits at Imperial College of London has given rise to an algorithm capable of predicting the emergence of pump and dump schemes.
These schemes were popularized by Jordan Belfort, also known as the “Wolf of Wall Street”, who pleaded guilty to fraud and crime related to this technique.
Pump and dump schemes work in a simple way: a group of malicious people buy a low market capitalisation cryptocurrency at a favourable price. Then it generates a lot of hype around the coin trying to convince other unsuspecting traders to buy massively, so as to increase the price.
Once the price has risen enough, the initial malicious group can proceed to liquidate all the capital and make a guaranteed profit.
In the case of cryptocurrencies, moreover, thanks to the high volatility, all this happens in a few minutes, and these are increasingly common.
Xu and Livshits have reiterated that on average there are two pump-and-dump scams every day and that these generate about $7 million dollars in volume per month.

The two researchers carefully studied 220 pump and dump events. They noted that many of these frauds were preceded by unusual buying activities in cryptocurrencies often little considered.
During the testing phase, the algorithm identified six different suspicious activities, five of which turned out to be actually pump and dump schemes.
Researchers have yet to announce whether or not they intend to make their algorithm available for public use. 
Sentiment Analysis
According to a scientific paper by developer Tejeswar Tadi, published in Intel IA Academy, an initiative of the American technology giant Intel, artificial intelligence can help determine the general sentiment about a given cryptocurrency by scanning and analyzing the countless comments in social media.

“It is possible to show that favourable feelings about a currency correspond to an increase in the value of the coin through the exchange of the currency itself”.

Tadi launched his project called Deep Learning for Cryptocurrency Trading about two years ago. Its main purpose was to determine the correlation between the feelings expressed by cryptocurrency traders and their market value. All this by applying deep learning techniques.
In an article recently published on the Intel IA Academy page, Tadi, presented as “Intel Ambassador”, said:

“The long-term vision of this project is to be able to develop an Artificial Intelligence (AI) Cryptocurrency Trading Bot that cannot only consider trader sentiment to make trading decisions but also take advantage of other opportunities such as arbitrage which is the purchase and sale of an asset to profit from a difference in the price”. 

 





Share
FacebookTwitterPinterestWhatsApp




Previous articleBitcoin (BTC) mining: the legal regulations of the worldNext articleDelegated Proof of Stake: What is D-PoS?

Michele Portahttps://www.micheleporta.info/
RELATED ARTICLES



Trading  

The expansion of trading volumes in the crypto world in 2024: a report by Coinwire


14 July 2024 







Crypto  

Price analysis and news of the crypto projects Tribe, Dimo, and Sei


11 July 2024 







Crypto  

Prices and forecasts on crypto Bitcoin (BTC), Ethereum (ETH), and Binance Coin (BNB)


10 July 2024 










MOST POPULARS



 

The Ampleforth (AMPL) cryptocurrency has crashed


30 July 2020 







 

Storm in the crypto market: Gemini’s stablecoin GUSD loses over 90% of its market capitalization.


4 January 2024 







 

Etherscan acquires the Solana Blockchain explorer: Solscan.io


3 January 2024 







 

Crypto-fraud: a hacker steals over $1 million from the Levana protocol.


29 December 2023 




Load more
  ",,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/#article', 'isPartOf': {'@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/'}, 'author': {'name': 'Michele Porta', '@id': 'https://en.cryptonomist.ch/#/schema/person/4353c858005598676e250f42c526e8e0'}, 'headline': 'Artificial intelligence in cryptocurrency trading: use cases', 'datePublished': '2019-06-02T06:00:14+00:00', 'dateModified': '2019-06-02T06:43:34+00:00', 'mainEntityOfPage': {'@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/'}, 'wordCount': 502, 'publisher': {'@id': 'https://en.cryptonomist.ch/#organization'}, 'image': {'@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/#primaryimage'}, 'thumbnailUrl': 'https://en.cryptonomist.ch/wp-content/uploads/2019/06/intelligenza-artificiale-ai-trading-criptovalute.jpg', 'articleSection': ['Trading'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/', 'url': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/', 'name': 'Artificial intelligence in cryptocurrency trading: use cases', 'isPartOf': {'@id': 'https://en.cryptonomist.ch/#website'}, 'primaryImageOfPage': {'@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/#primaryimage'}, 'image': {'@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/#primaryimage'}, 'thumbnailUrl': 'https://en.cryptonomist.ch/wp-content/uploads/2019/06/intelligenza-artificiale-ai-trading-criptovalute.jpg', 'datePublished': '2019-06-02T06:00:14+00:00', 'dateModified': '2019-06-02T06:43:34+00:00', 'description': 'Nowadays we hear about artificial intelligence (abbreviated with the acronym AI) and also the world of cryptocurrency trading has not been excluded.', 'breadcrumb': {'@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/#primaryimage', 'url': 'https://en.cryptonomist.ch/wp-content/uploads/2019/06/intelligenza-artificiale-ai-trading-criptovalute.jpg', 'contentUrl': 'https://en.cryptonomist.ch/wp-content/uploads/2019/06/intelligenza-artificiale-ai-trading-criptovalute.jpg', 'width': 1080, 'height': 720, 'caption': 'Artificial intelligence in cryptocurrency trading'}, {'@type': 'BreadcrumbList', '@id': 'https://en.cryptonomist.ch/2019/06/02/artificial-intelligence-in-cryptocurrency-trading/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://cryptonomist.ch/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial intelligence in cryptocurrency trading: use cases'}]}, {'@type': 'WebSite', '@id': 'https://en.cryptonomist.ch/#website', 'url': 'https://en.cryptonomist.ch/', 'name': 'The Cryptonomist', 'description': 'Everything about blockchain', 'publisher': {'@id': 'https://en.cryptonomist.ch/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://en.cryptonomist.ch/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://en.cryptonomist.ch/#organization', 'name': 'The Cryptonomist', 'url': 'https://en.cryptonomist.ch/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://en.cryptonomist.ch/#/schema/logo/image/', 'url': 'https://cryptonomist.ch/wp-content/uploads/2018/03/sticky-logo.png', 'contentUrl': 'https://cryptonomist.ch/wp-content/uploads/2018/03/sticky-logo.png', 'width': 100, 'height': 100, 'caption': 'The Cryptonomist'}, 'image': {'@id': 'https://en.cryptonomist.ch/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/cryptonomist.ch/', 'https://x.com/cryptonomist_', 'https://www.instagram.com/cryptonomist.ch/?hl=it', 'https://www.linkedin.com/company/the-cryptonomist/', 'https://www.youtube.com/channel/UC1c3005U60gq2DQAbsT1vcg']}, {'@type': 'Person', '@id': 'https://en.cryptonomist.ch/#/schema/person/4353c858005598676e250f42c526e8e0', 'name': 'Michele Porta', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://en.cryptonomist.ch/#/schema/person/image/', 'url': 'https://en.cryptonomist.ch/wp-content/uploads/2019/05/micheleporta.jpg', 'contentUrl': 'https://en.cryptonomist.ch/wp-content/uploads/2019/05/micheleporta.jpg', 'caption': 'Michele Porta'}, 'sameAs': ['https://www.micheleporta.info/', 'https://www.facebook.com/michele.porta1', 'https://www.instagram.com/michele_porta/?hl=it', 'https://www.linkedin.com/in/michele-porta/'], 'url': 'https://en.cryptonomist.ch/author/michele-porta/'}]"
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LnNmdS5jYS9zaWF0L25ld3MtZXZlbnRzL25ld3MvMjAxOS9leHBsb3JpbmctY3JlYXRpdmUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UuaHRtbNIBAA?oc=5,Exploring Creative Artificial Intelligence - School of Interactive Arts & Technology - Simon Fraser University News,2019-06-01,Simon Fraser University News,https://www.sfu.ca,"For the last ten years, the Metacreation Lab has been at the forefront of research and practice in Creative AI.",N/A,"For the last ten years, the Metacreation Lab has been at the forefront of research and practice in Creative AI.","For the last ten years, the Metacreation Lab has been at the forefront of research and practice in Creative AI.",,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vYW5hbHl0aWNzaW5kaWFtYWcuY29tL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWJyaW5ncy1tb25hLWxpc2EtdG8tbGlmZS11c2luZy1nYW5zL9IBAA?oc=5,Artificial Intelligence Brings Mona Lisa To Life Using GANs - AIM,2019-06-04,AIM,https://analyticsindiamag.com,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,N/A,N/A,"






				GANs, Diffusion Ride Dragon in AI Image Generation			



			Mohit Pandey		

			10/07/2023		


",,,,,,,,,,,,,,

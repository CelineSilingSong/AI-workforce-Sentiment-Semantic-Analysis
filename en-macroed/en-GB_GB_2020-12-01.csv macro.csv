URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,headline,url,dateCreated,datePublished,dateModified,articleSection,wordCount,mainEntityOfPage,publisher,thumbnailUrl,image,creator,author,itemListElement,name,address,article:section,article:summary,article text,@graph,articleBody,inLanguage,alternativeHeadline,hasPart,comment,commentCount,copyrightHolder,sourceOrganization,copyrightYear,isAccessibleForFree,isPartOf,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,potentialAction,isBasedOn,geo
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMjAvMTIvMDQvMTAxMzI5NC9nb29nbGUtYWktZXRoaWNzLXJlc2VhcmNoLXBhcGVyLWZvcmNlZC1vdXQtdGltbml0LWdlYnJ1L9IBcGh0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMjAvMTIvMDQvMTAxMzI5NC9nb29nbGUtYWktZXRoaWNzLXJlc2VhcmNoLXBhcGVyLWZvcmNlZC1vdXQtdGltbml0LWdlYnJ1L2FtcC8?oc=5,We read the paper that forced Timnit Gebru out of Google. Here’s what it says. - MIT Technology Review,2020-12-04,MIT Technology Review,https://www.technologyreview.com,"The company's star ethics researcher highlighted the risks of large language models, which are key to Google's business.",,"The company's star ethics researcher highlighted the risks of large language models, which are key to Google's business.","The company's star ethics researcher highlighted the risks of large language models, which are key to Google's business.",http://schema.org,Organization,We read the paper that forced Timnit Gebru out of Google. Here’s what it says.,https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/,2020-12-04T21:43:00-05:00,2020-12-04T21:43:00-05:00,2022-01-10T15:50:53-05:00,Artificial intelligence,1821.0,"{'@type': 'WebPage', '@id': 'https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/'}","{'@type': 'Organization', 'name': 'MIT Technology Review', 'logo': {'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/themes/mittr/client/src/images/logo.png', 'width': 203, 'height': 100}}","https://wp.technologyreview.com/wp-content/uploads/2020/12/transglobal.jpg?resize=854,569","{'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/uploads/2020/12/transglobal.jpg?resize=854,569', 'height': 569, 'width': 854}","{'@type': 'Person', 'name': 'Karen Hao'}","{'@type': 'Person', 'name': 'Karen Hao'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Artificial intelligence', 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/topic/artificial-intelligence/'}}, {'@type': 'ListItem', 'position': 2, 'name': ""We read the paper that forced Timnit Gebru out of Google. Here's what it says."", 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/'}}]",MIT Technology Review,"{'@type': 'PostalAddress', 'addressLocality': 'Cambridge, MA, USA', 'postalCode': '02142', 'streetAddress': '1 Main Street'}",N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiLmh0dHBzOi8vd3d3LmJiYy5jby51ay9uZXdzL3RlY2hub2xvZ3ktNTUxODc2MTHSATJodHRwczovL3d3dy5iYmMuY28udWsvbmV3cy90ZWNobm9sb2d5LTU1MTg3NjExLmFtcA?oc=5,Timnit Gebru: Google staff rally behind fired AI researcher - BBC,2020-12-04,BBC,https://www.bbc.co.uk,"Timnit Gebru, a critic of some of the firm's policies, says she was dismissed over an internal email.",N/A,"Timnit Gebru, a critic of some of the firm's policies, says she was dismissed over an internal email.","Timnit Gebru, a critic of some of the firm's policies, says she was dismissed over an internal email.",http://schema.org,ReportageNewsArticle,Timnit Gebru: Google staff rally behind fired AI researcher,https://www.bbc.com/news/technology-55187611,,2020-12-04T13:50:54.000Z,2020-12-04T14:48:41.000Z,,,https://www.bbc.com/news/technology-55187611,"{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'publishingPrinciples': 'http://www.bbc.co.uk/news/help-41670342', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",https://ichef.bbci.co.uk/news/1024/branded_news/18299/production/_115796989_gettyimages-1028811892.jpg,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_news/18299/production/_115796989_gettyimages-1028811892.jpg'}",,"{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'noBylinesPolicy': 'http://www.bbc.co.uk/news/help-41670342#authorexpertise', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",,,,N/A,N/A,"Timnit Gebru: Google staff rally behind fired AI researcher4 December 2020ShareGetty ImagesHundreds of Google staff have signed a letter backing a leading AI ethics researcher who was sacked by Google.Timnit Gebru says she was fired after sending an internal email that accused Google of ""silencing marginalised voices"".Hundreds of colleagues have signed a letter accusing the search giant of racism and censorship, while Twitter users have rallied around Dr Gebru using the hashtag #BelieveBlackWomen.Google disputes her version of events.Dr Gebru is a well-respected researcher in the field of ethics and the use of artificial intelligence.She is well-known for her work on racial bias in technology such as facial recognition, and has criticised systems that fail to recognise black faces.Allow Twitter content?This article contains content provided by Twitter. We ask for your permission before anything is loaded, as they may be using cookies and other technologies. You may want to read Twitter’s cookie policy and privacy policy before accepting. To view this content choose ‘accept and continue’.Accept and continueHer co-author on one of those well-known papers, Joy Buolamwini, said Dr Gebru ""deserved more"" from Google.""Ousting Timnit for having the audacity to demand research integrity severely undermines Google's credibility for supporting rigorous research on AI ethics and algorithmic auditing,"" she said.""We owe her a debt of gratitude for advancing not just the field of artificial intelligence, but for advancing equality with humility and grace.""What happened?Dr Gebru alleges that as she was preparing to go on leave, she was called to a meeting about a research paper she had co-written.She said she was ordered to retract the research paper and that Google was not prepared to engage in a discussion about the matter.Following the meeting, she sent an email to an internal group called ""Brain Women and Allies"", criticising the decision. A copy of the email has been published by Platformer.""You are not worth having any conversations about this, since you are not someone whose humanity... is acknowledged or valued in this company,"" she said in the email.""Stop writing your documents because it doesn't make a difference.""Allow Twitter content?This article contains content provided by Twitter. We ask for your permission before anything is loaded, as they may be using cookies and other technologies. You may want to read Twitter’s cookie policy and privacy policy before accepting. To view this content choose ‘accept and continue’.Accept and continueDr Gebru had emailed her management laying out some key conditions for removing her name from the paper, and if they were not met, she would ""work on a last date"" for her employment.According to Dr Gebru, Google replied: ""We respect your decision to leave Google... and we are accepting your resignation.""However, we believe the end of your employment should happen faster than your email reflects because certain aspects of the email you sent last night to non-management employees in the brain group reflect behaviour that is inconsistent with the expectations of a Google manager.""Dr Gebru denied she had resigned, tweeting that she had been fired by Jeff Dean, a senior manager at Google dealing with AI Research.""I guess [management] decided for me"", she said.The research paper remains unpublished, but MIT Technology Review has summarised its contents, saying it focused on the risks of training AI by drawing on huge archives of text data.What has the reaction been?Since her dismissal, the open letter of support has attracted nearly 2,000 signatories, both from within Google and the wider industry.News of her dismissal came on the same day that a US labour agency accused Google of illegally firing staff for their involvement in union activity.Allow Twitter content?This article contains content provided by Twitter. We ask for your permission before anything is loaded, as they may be using cookies and other technologies. You may want to read Twitter’s cookie policy and privacy policy before accepting. To view this content choose ‘accept and continue’.Accept and continueGoogle staff who worked with Dr Gebru have applauded her academic contributions and her work as a manager.Allow Twitter content?This article contains content provided by Twitter. We ask for your permission before anything is loaded, as they may be using cookies and other technologies. You may want to read Twitter’s cookie policy and privacy policy before accepting. To view this content choose ‘accept and continue’.Accept and continueAllow Twitter content?This article contains content provided by Twitter. We ask for your permission before anything is loaded, as they may be using cookies and other technologies. You may want to read Twitter’s cookie policy and privacy policy before accepting. To view this content choose ‘accept and continue’.Accept and continue""I cannot count the number of times Timnit Gebru has encouraged us, spoken out for us, defended us and stuck her neck out for us,"" tweeted Deb Raji, an AI researcher. ""She has made real sacrifices for the Black community. Now it's time to stand with her!""What does Google say?In an email, Mr Dean said there had been ""a lot of speculation and misunderstanding"" about the firing.He alleged that Dr Gebru's paper was submitted a day before its deadline, which was not enough time for Google's review process. He also said the paper ignored much relevant research.""Timnit responded with an email requiring that a number of conditions be met in order for her to continue working at Google, including revealing the identities of every person who [we] had spoken to and consulted as part of the review of the paper and the exact feedback. ""Timnit wrote that if we didn't meet these demands, she would leave Google and work on an end date. We accept and respect her decision to resign from Google,"" Mr Dean wrote.Google fired pro-union employees, says US agencyGoogle staff walk out over women's treatment'Thanksgiving Four' say Google is punishing themGoogleArtificial intelligenceEmployment",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vbmV3cy5oYXJ2YXJkLmVkdS9nYXpldHRlL3N0b3J5LzIwMjAvMTIvYXJlLWh1bWFucy1yZWFsbHktdGhlLWJlc3Qtcm9sZS1tb2RlbHMtZm9yLWEtcm9ib3Qv0gEA?oc=5,Imagine a life surrounded by AI - Harvard Gazette,2020-12-04,Harvard Gazette,https://news.harvard.edu,Harvard's AI+Art project aims to get people thinking about how artificial intelligence may impact our lives in the future.,"['art', 'artificial intelligence', 'berkman klein center for internet and society', 'harvard law school', 'humanities', 'jonathan zittrain', 'metalab(at)harvard', 'sarah newman']",Harvard's AI+Art project aims to get people thinking about how artificial intelligence may impact our lives in the future.,N/A,https://schema.org,NewsArticle,"Imagine a world in which AI is in your home, at work, everywhere",https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/,2020-12-04T17:12:34Z,2020-12-04T17:12:34Z,2024-01-03T19:34:22Z,Science &amp; Tech,,"{'@type': 'WebPage', '@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/'}","{'@type': 'Organization', 'name': 'Harvard Gazette', 'logo': 'https://news.harvard.edu/gazette/wp-content/uploads/2023/12/Harvard_Gazette_logo.svg'}",https://news.harvard.edu/wp-content/uploads/2020/11/Robot_Brain_v2.jpg?w=150&h=150&crop=1,"{'@type': 'ImageObject', 'url': 'https://news.harvard.edu/wp-content/uploads/2020/11/Robot_Brain_v2.jpg'}",['gazetteterrymurphy'],"[{'@type': 'Person', 'name': 'gazetteterrymurphy'}]",,,,N/A,N/A,N/A,"[{'@type': 'Article', '@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/#article', 'isPartOf': {'@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/'}, 'author': {'name': 'gazetteterrymurphy', '@id': 'https://news.harvard.edu/gazette/#/schema/person/2cfafcc9d83d296989ecffd95c657376'}, 'headline': 'Imagine a world in which AI is in your home, at work, everywhere', 'datePublished': '2020-12-04T17:12:34+00:00', 'dateModified': '2024-01-03T19:34:22+00:00', 'mainEntityOfPage': {'@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/'}, 'wordCount': 1629, 'publisher': {'@id': 'https://news.harvard.edu/gazette/#organization'}, 'image': {'@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/#primaryimage'}, 'thumbnailUrl': 'https://news.harvard.edu/wp-content/uploads/2020/11/Robot_Brain_v2.jpg', 'keywords': ['Art', 'Artificial Intelligence', 'Berkman Klein Center for Internet and Society', 'Harvard Law School', 'Humanities', 'Jonathan Zittrain', 'metaLAB(at)Harvard', 'Sarah Newman'], 'articleSection': ['Science &amp; Tech'], 'inLanguage': 'en-US', 'copyrightYear': '2020', 'copyrightHolder': {'@id': 'https://news.harvard.edu/gazette/#organization'}}, {'@type': 'WebPage', '@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/', 'url': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/', 'name': 'Imagine a life surrounded by AI &#8212; Harvard Gazette', 'isPartOf': {'@id': 'https://news.harvard.edu/gazette/#website'}, 'primaryImageOfPage': {'@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/#primaryimage'}, 'image': {'@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/#primaryimage'}, 'thumbnailUrl': 'https://news.harvard.edu/wp-content/uploads/2020/11/Robot_Brain_v2.jpg', 'datePublished': '2020-12-04T17:12:34+00:00', 'dateModified': '2024-01-03T19:34:22+00:00', 'description': ""Harvard's AI+Art project aims to get people thinking about how artificial intelligence may impact our lives in the future."", 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.harvard.edu/gazette/story/2020/12/are-humans-really-the-best-role-models-for-a-robot/#primaryimage', 'url': 'https://news.harvard.edu/wp-content/uploads/2020/11/Robot_Brain_v2.jpg', 'contentUrl': 'https://news.harvard.edu/wp-content/uploads/2020/11/Robot_Brain_v2.jpg', 'width': 2500, 'height': 1667, 'caption': 'Illustration of robot making decisions.'}, {'@type': 'WebSite', '@id': 'https://news.harvard.edu/gazette/#website', 'url': 'https://news.harvard.edu/gazette/', 'name': 'Harvard Gazette', 'description': 'Official news from Harvard University covering innovation in teaching, learning, and research', 'publisher': {'@id': 'https://news.harvard.edu/gazette/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.harvard.edu/gazette/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://news.harvard.edu/gazette/#organization', 'name': 'Harvard Gazette', 'url': 'https://news.harvard.edu/gazette/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.harvard.edu/gazette/#/schema/logo/image/', 'url': 'https://news.harvard.edu/wp-content/uploads/2023/12/Harvard_Gazette_logo.svg', 'contentUrl': 'https://news.harvard.edu/wp-content/uploads/2023/12/Harvard_Gazette_logo.svg', 'width': 164, 'height': 64, 'caption': 'Harvard Gazette'}, 'image': {'@id': 'https://news.harvard.edu/gazette/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://news.harvard.edu/gazette/#/schema/person/2cfafcc9d83d296989ecffd95c657376', 'name': 'gazetteterrymurphy'}]",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LmFjdHVpYS5jb20vZW5nbGlzaC9zd2l0emVybGFuZC1zZXRzLXVwLWEtY2VudHJlLWZvci1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1tZWRpY2luZS1pbi1iZXJuL9IBAA?oc=5,Switzerland sets up a centre for artificial intelligence in medicine in Bern - Intelligence artificielle - Actu IA,2020-12-03,Intelligence artificielle - Actu IA,https://www.actuia.com,N/A,N/A,"The Center for Artificial Intelligence in Medicine (CAIM) will be officially opened in January 2021 in Bern, Switzerland. The center, founded by the University of Bern and the Inselspital, University Hospital of Bern, is intended to be a platform for research, teaching and transfer of medical technologies using AI, aimed at improving the provision of […]",N/A,http://schema.org,BreadcrumbList,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.actuia.com/', 'name': 'Accueil'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/', 'name': 'Switzerland sets up a centre for artificial intelligence in medicine in Bern'}}]",,,N/A,N/A,"







Switzerland sets up a centre for artificial intelligence in medicine in Bern                    




Pierre-yves Gerlat
 - 



3 décembre 2020





0                        








Artorg. Gruppe AIHN © Adrian Moser / Universitaet Bern


The Center for Artificial Intelligence in Medicine (CAIM) will be officially opened in January 2021 in Bern, Switzerland. The center, founded by the University of Bern and the Inselspital, University Hospital of Bern, is intended to be a platform for research, teaching and transfer of medical technologies using AI, aimed at improving the provision of patient care and facilitating the work of physicians and caregivers.

The healthcare sector today generates more data than healthcare professionals are able to analyze. AI allows us to use this data to determine the characteristics that doctors, caregivers and other health professionals need to make more accurate diagnoses and better treatment decisions.
With AI, treatments become more accurate – unnecessary interventions can be avoided and treatment successes improved. In cancer therapy, for example, treatment plans can be designed more specifically for the patient to minimize radiation exposure.
In order to prepare Bern’s medical location for the digital medicine of tomorrow, the University of Bern and the Inselspital have therefore founded the “Center for Artificial Intelligence in Medicine” (CAIM). This is a new platform for research, teaching and translational medicine, clinical services and products in the field of artificial intelligence in medicine. Together with its partners sitem-insel and UPD, the CAIM will start its activities in January 2021. Organised as a virtual research centre, it will be attached to the Faculty of Medicine of the University of Bern.
Unique Constellation
The new centre benefits from Bern’s excellent network of clinics, research and industry. The medical site in Bern has a great deal of know-how in medical technology and many years of experience in translational medicine. Another strength of the CAIM is the link between cutting-edge research in medicine and engineering, for example at the ARTORG Center for Biomedical Engeneering Research at the University of Bern, and the Inselspital, Switzerland’s largest university hospital, which is at the forefront of digitisation.
“This unique constellation enables the IMCA to combine the knowledge gained from close cooperation with clinics and industry – and thus makes the IMCA a real incubator for AI medical technology,” says Raphael Sznitman, Director of the ARTORG Center and IMCA project leader.

This new centre must implement AI and facilitate the work of physicians and caregivers for the benefit of patients. In this way, patients benefit quickly and directly from the results.
Training for the new generation of physicians and engineers

At the University of Bern, the CAIM brings together the initiatives already underway in the field of digitisation at the Faculty of Medicine: five chairs in the field of AI and digitisation in medicine have been established and will attract leading researchers in these fields to Bern in the course of next year. They will be closely associated with the CAIM, together with the more than 80 researchers already working on AI and medicine at the University of Bern today.
Christian Leumann, Rector of the University of Bern :
“With the CAIM, the University of Bern is investing in a research and teaching field that will have a decisive influence on the health sector. The networking of research in the field of AI in medicine will further boost the potential of this research. At the same time, we are developing training and providing digital skills to a new generation of doctors and researchers. »
In this way, clinicians will see the engineering perspective and students will be able to take advantage of the opportunities of new technologies and participate in their design. The Sitem-insel School’s Artificial Intelligence in Medical Imaging development program for medical staff has already started.
In addition, students of human medicine have the opportunity to receive an introduction and in-depth study on the topic of “Digitisation and AI”. A master’s course for AI in medicine will follow for engineering students.
AI technologies for the digital hospital

The foundation of the CAIM is part of the Insel Group’s digitisation strategy: on the basis of a new digital clinic information and management system (KISS), the Insel Group plans to fully digitise all areas such as research, diagnosis, patient management, therapy and finance by 2023.
The ICDA will use the large amount of quality clinical data in the new system to develop clinical machine learning tools to support physicians, caregivers and other health care professionals in their daily clinical decisions. In this context, great attention will be paid to data protection: the new system meets the highest requirements for the processing of sensitive medical data.
Uwe E. Jocham, CEO of the Insel Gruppe :
“In the future, the hospitals of the Insel Group will be digital. The new main building of the Inselspital, which will be completed in 2023, will be entirely designed for the digital world. The CAIM will help to make the large amount of data available for research and development of new instruments. »
Interdisciplinary and open to industry

CAIM will make AI expertise available to the industry in a variety of ways: on the one hand, it will share the latest research developments in AI technologies and produce a workforce of highly qualified professionals. On the other hand, it will allow cooperation in projects ranging from pilot projects to large-scale multi-partner projects. In this way, cooperation between industry and CAIM can also be supported by the Swiss Innovation Promotion Programme.
“Innosuisse” to develop efficient solutions for industrial partners. The members of CAIM have many years of experience in collaborating with industry and creating start-ups. CAIM researchers benefit from access to structured data, project funding and support for the market launch of products.
“As an incubator, sitem-insel helps to transfer AI research results into products and new therapies as quickly as possible. “We create a dynamic environment that encourages all teams to develop reliable medical technologies, driven by AI, on a scientific basis,” says Simon Rothen, CEO of sitem-insel.

Michael Kaess, Director of the University Clinic for Child and Adolescent Psychiatry and Psychotherapy at the UPD, adds :
“Already today, and even more so in the future, artificial intelligence methods play an important role in translational research, e.g. for the processing and analysis of large amounts of data to predict the course of diseases and the associated risks. In the future, these technical possibilities should increasingly support the diagnosis and therapy of people with mental disorders in PUD. »
To this end, the UPD has founded its own digital council this year.
“The close interdisciplinary cooperation at the IACM enables the PSD to benefit from a wide range of know-how. On the other hand, we can make an important contribution to the topic of “artificial intelligence” as experts in the field of cognition and emotion,” says Michael Kaess.

A new and important pillar for the Berne medical location

The CAIM will bring additional dynamism to precision medicine, which is already a leader with the Bern Center for Precision Medicine (BCPM), as well as to translational medicine, promoted by sitem-insel.
Christoph Ammann, State Councillor, Director of Economy, Energy and Environment of the Canton of Berne :
“Bern’s medical site is based on a strong university and an innovative university hospital. Berne now also occupies a leading position in the field of artificial intelligence. This will strengthen the Canton of Berne as a business location and create added value. »
Translated from La Suisse se dote d’un centre pour l’intelligence artificielle dans la médecine à Berne
 




Previous article
IAPAU#3: The Festival Machine Learning, Data Science and Artificial Intelligence returns from December 4 to 6, 2020





Next article
Gaël Richard and Étienne Perret, 2020 winners of the ITM Awards – Academy of Sciences









Pierre-yves Gerlat








","[{'@type': 'Organization', '@id': 'https://www.actuia.com/#organization', 'name': 'ActuIA', 'url': 'https://www.actuia.com/', 'sameAs': ['https://www.facebook.com/Actu-IA-1105067856282712/', 'https://www.linkedin.com/company/18523131/', 'https://twitter.com/ActuIAFr'], 'logo': {'@type': 'ImageObject', '@id': 'https://www.actuia.com/#logo', 'inLanguage': 'fr-FR', 'url': 'https://www.actuia.com/wp-content/uploads/2017/02/actuia_square2.png', 'width': 200, 'height': 200, 'caption': 'ActuIA'}, 'image': {'@id': 'https://www.actuia.com/#logo'}}, {'@type': 'WebSite', '@id': 'https://www.actuia.com/#website', 'url': 'https://www.actuia.com/', 'name': 'ActuIA', 'description': 'Actualité de l&#039;intelligence artificielle', 'publisher': {'@id': 'https://www.actuia.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://www.actuia.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'fr-FR'}, {'@type': 'ImageObject', '@id': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/#primaryimage', 'inLanguage': 'fr-FR', 'url': 'https://www.actuia.com/wp-content/uploads/2020/12/©-ARTORG-Center-University-of-Bern.jpg', 'width': 800, 'height': 419, 'caption': 'Artorg. Gruppe AIHN © Adrian Moser / Universitaet Bern'}, {'@type': 'WebPage', '@id': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/#webpage', 'url': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/', 'name': 'Switzerland sets up a centre for artificial intelligence in medicine in Bern - ActuIA', 'isPartOf': {'@id': 'https://www.actuia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/#primaryimage'}, 'datePublished': '2020-12-03T13:25:59+00:00', 'dateModified': '2020-12-03T13:25:59+00:00', 'breadcrumb': {'@id': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/#breadcrumb'}, 'inLanguage': 'fr-FR', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/']}]}, {'@type': 'BreadcrumbList', '@id': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebPage', '@id': 'https://www.actuia.com/', 'url': 'https://www.actuia.com/', 'name': 'Intelligence artificielle'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.actuia.com/english/', 'url': 'https://www.actuia.com/english/', 'name': 'English'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/', 'url': 'https://www.actuia.com/english/switzerland-sets-up-a-centre-for-artificial-intelligence-in-medicine-in-bern/', 'name': 'Switzerland sets up a centre for artificial intelligence in medicine in Bern'}}]}]",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDIwLzEyLzUvMjIxNTU5ODUvcGFwZXItdGltbml0LWdlYnJ1LWZpcmVkLWdvb2dsZS1sYXJnZS1sYW5ndWFnZS1tb2RlbHMtc2VhcmNoLWFp0gEA?oc=5,Timnit Gebru's actual paper may explain why Google ejected her - The Verge,2020-12-05,The Verge,https://www.theverge.com,"A paper co-authored by former Google AI ethicist Timnit Gebru raised some potentially thorny questions for Google about whether AI language models may be too big, and whether tech companies are doing enough to reduce potential risks.",N/A,Gebru says Google fired her over the paper; the company says she resigned,N/A,http://schema.org/,NewsArticle,Timnit Gebru’s actual paper may explain why Google ejected her,https://www.theverge.com/2020/12/5/22155985/paper-timnit-gebru-fired-google-large-language-models-search-ai,,2020-12-05T19:27:47.000Z,2020-12-05T19:27:47.000Z,,,,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",https://cdn.vox-cdn.com/thumbor/dVpqatYlHbyEtHsOdoftyNZG0_w=/0x0:5760x3840/1400x788/filters:focal(3092x1784:3093x1785)/cdn.vox-cdn.com/uploads/chorus_asset/file/22141445/1028811892.jpg,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/dVpqatYlHbyEtHsOdoftyNZG0_w=/0x0:5760x3840/1400x788/filters:focal(3092x1784:3093x1785)/cdn.vox-cdn.com/uploads/chorus_asset/file/22141445/1028811892.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/bpiqvb5I-5PcsCajPziLJ8RwxaU=/0x0:5760x3840/1400x1050/filters:focal(3092x1784:3093x1785)/cdn.vox-cdn.com/uploads/chorus_asset/file/22141445/1028811892.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/u2MH3iyMQryUSziuSw-JL5jPuRE=/0x0:5760x3840/1400x1400/filters:focal(3092x1784:3093x1785)/cdn.vox-cdn.com/uploads/chorus_asset/file/22141445/1028811892.jpg', 'width': 1400, 'height': 1400}]",,"[{'@type': 'Person', 'name': 'Kim Lyons', 'url': 'https://www.theverge.com/authors/kim-lyons'}]",,,,N/A,N/A,"Tech/Google/Artificial IntelligenceTimnit Gebru’s actual paper may explain why Google ejected herTimnit Gebru’s actual paper may explain why Google ejected her / It questioned language models similar to the ones used in Google’s SearchBy  Kim Lyons Dec 5, 2020, 2:27 PM ESTShare this story0 Comments / 0 New Photo by Kimberly White / Getty Images for TechCrunchA paper co-authored by former Google AI ethicist Timnit Gebru raised some potentially thorny questions for Google about whether AI language models may be too big, and whether tech companies are doing enough to reduce potential risks, according to MIT Technology Review. The paper also questioned the environmental costs and inherent biases in large language models. Google’s AI team created such a language model— BERT— in 2018, and it was so successful that the company incorporated BERT into its search engine. Search is a highly lucrative segment of Google’s business; in the third quarter of this year alone, it brought in revenue of $26.3 billion. “This year, including this quarter, showed how valuable Google’s founding product — search — has been to people,” CEO Sundar Pichai said on a call with investors in October.Gebru and her team submitted their paper, titled “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” for a research conference. She said in a series of tweets on Wednesday that following an internal review, she was asked to retract the paper or remove Google employees’ names from it. She says she asked Google for conditions for taking her name off the paper, and if they couldn’t meet the conditions they could “work on a last date.” Gebru says she then received an email from Google informing her they were “accepting her resignation effective immediately.” The head of Google AI, Jeff Dean, wrote in an email to employees that the paper “didn’t meet our bar for publication.” He wrote that one of Gebru’s conditions for continuing to work at Google was for the company to tell her who had reviewed the paper and their specific feedback, which it declined to do. “Timnit wrote that if we didn’t meet these demands, she would leave Google and work on an end date. We accept and respect her decision to resign from Google,” Dean wrote. Gebru is known for her work on algorithmic bias, especially in facial recognition technologyIn his letter, Dean wrote that the paper “ignored too much relevant research,” a claim that the paper’s co-author Emily M. Bender, a professor of computational linguistics at the University of Washington, disputed. Bender told MIT Technology Review that the paper, which had six collaborators, was “the sort of work that no individual or even pair of authors can pull off,” noting it had a citation list of 128 references. Gebru is known for her work on algorithmic bias, especially in facial recognition technology. In 2018, she co-authored a paper with Joy Buolamwini that showed error rates for identifying darker-skinned people were much higher than error rates for identifying lighter-skinned people, since the datasets used to train algorithms were overwhelmingly white.Gebru told Wired in an interview published Thursday that she felt she was being censored. “You’re not going to have papers that make the company happy all the time and don’t point out problems,” she said. “That’s antithetical to what it means to be that kind of researcher.”Since news of her termination became public, thousands of supporters, including more than 1,500 Google employees have signed a letter of protest. “We, the undersigned, stand in solidarity with Dr. Timnit Gebru, who was terminated from her position as Staff Research Scientist and Co-Lead of Ethical Artificial Intelligence (AI) team at Google, following unprecedented research censorship,” reads the petition, titled Standing with Dr. Timnit Gebru. “We call on Google Research to strengthen its commitment to research integrity and to unequivocally commit to supporting research that honors the commitments made in Google’s AI Principles.”The petitioners are demanding that Dean and others “who were involved with the decision to censor Dr. Gebru’s paper meet with the Ethical AI team to explain the process by which the paper was unilaterally rejected by leadership.”Google did not immediately respond to a request for comment on Saturday.Comments0 Comments / 0 NewFeatured Videos From The VergeApple’s Vision Pro: five months later | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge’s David Pierce chats with Victoria Song and Wes Davis about using the Vision Pro for the five months that it's been available to the public. The group details what works, what doesn’t, and what’s next for the device. David then chats with the folks at Sandwich Vision, who create Vision Pro apps called Television and Theater, about why they made 3D-rendered versions of CRT TVs in virtual reality.Most PopularMost PopularIt’s never been easier for the cops to break into your phoneThe secret gardenApple is finally embracing Android’s chaosThe best Amazon Prime Day tech deals you can getHere’s a very clear real-world look at Google’s Pixel 9 Pro FoldVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",,"A paper co-authored by former Google AI ethicist Timnit Gebru raised some potentially thorny questions for Google about whether AI language models may be too big, and whether tech companies are doing enough to reduce potential risks, according to MIT Technology Review. The paper also questioned the environmental costs and inherent biases in large language models. 

Google’s AI team created such a language model— BERT— in 2018, and it was so successful that the company incorporated BERT into its search engine. Search is a highly lucrative segment of Google’s business; in the third quarter of this year alone, it brought in revenue of $26.3 billion. “This year, including this quarter, showed how valuable Google’s founding product — search — has been to people,” CEO Sundar Pichai said on a call with investors in October.

Gebru and her team submitted their paper, titled “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” for a research conference. She said in a series of tweets on Wednesday that following an internal review, she was asked to retract the paper or remove Google employees’ names from it. She says she asked Google for conditions for taking her name off the paper, and if they couldn’t meet the conditions they could “work on a last date.” Gebru says she then received an email from Google informing her they were “accepting her resignation effective immediately.” 

The head of Google AI, Jeff Dean, wrote in an email to employees that the paper “didn’t meet our bar for publication.” He wrote that one of Gebru’s conditions for continuing to work at Google was for the company to tell her who had reviewed the paper and their specific feedback, which it declined to do. “Timnit wrote that if we didn’t meet these demands, she would leave Google and work on an end date. We accept and respect her decision to resign from Google,” Dean wrote. 

""Gebru is known for her work on algorithmic bias, especially in facial recognition technology""

In his letter, Dean wrote that the paper “ignored too much relevant research,” a claim that the paper’s co-author Emily M. Bender, a professor of computational linguistics at the University of Washington, disputed. Bender told MIT Technology Review that the paper, which had six collaborators, was “the sort of work that no individual or even pair of authors can pull off,” noting it had a citation list of 128 references. 

Gebru is known for her work on algorithmic bias, especially in facial recognition technology. In 2018, she co-authored a paper with Joy Buolamwini that showed error rates for identifying darker-skinned people were much higher than error rates for identifying lighter-skinned people, since the datasets used to train algorithms were overwhelmingly white.

Gebru told Wired in an interview published Thursday that she felt she was being censored. “You’re not going to have papers that make the company happy all the time and don’t point out problems,” she said. “That’s antithetical to what it means to be that kind of researcher.”

Since news of her termination became public, thousands of supporters, including more than 1,500 Google employees have signed a letter of protest. “We, the undersigned, stand in solidarity with Dr. Timnit Gebru, who was terminated from her position as Staff Research Scientist and Co-Lead of Ethical Artificial Intelligence (AI) team at Google, following unprecedented research censorship,” reads the petition, titled Standing with Dr. Timnit Gebru. 

“We call on Google Research to strengthen its commitment to research integrity and to unequivocally commit to supporting research that honors the commitments made in Google’s AI Principles.”

The petitioners are demanding that Dean and others “who were involved with the decision to censor Dr. Gebru’s paper meet with the Ethical AI team to explain the process by which the paper was unilaterally rejected by leadership.”

Google did not immediately respond to a request for comment on Saturday.
",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjAvMTIvMDMvdGVjaG5vbG9neS9nb29nbGUtcmVzZWFyY2hlci10aW1uaXQtZ2VicnUuaHRtbNIBAA?oc=5,Google Researcher Says She Was Fired Over Paper Highlighting Bias in A.I. (Published 2020) - The New York Times,2020-12-03,The New York Times,https://www.nytimes.com,"Timnit Gebru, one of the few Black women in her field, had voiced exasperation over the company’s response to efforts to increase minority hiring.",N/A,"Timnit Gebru, one of the few Black women in her field, had voiced exasperation over the company’s response to efforts to increase minority hiring.","Timnit Gebru, one of the few Black women in her field, had voiced exasperation over the company’s response to efforts to increase minority hiring.",https://schema.org,NewsMediaOrganization,Google Researcher Timnit Gebru Says She Was Fired For Paper on AI Bias ,https://www.nytimes.com/,,2020-12-03T23:01:41.000Z,2020-12-04T02:26:35.000Z,,,https://www.nytimes.com/2020/12/03/technology/google-researcher-timnit-gebru.html,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/12/03/business/00googleai/00googleai-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2020/12/03/business/00googleai/00googleai-videoSixteenByNineJumbo1600.jpg', 'caption': 'Timnit Gebru, a respected researcher at Google, questioned biases built into artificial intelligence systems.', 'creditText': ""Cody O'Loughlin for The New York Times""}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/12/03/business/00googleai/merlin_180772398_f6098f27-13e0-4cd8-981b-5cd3cc7900cc-superJumbo.jpg', 'height': 1536, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2020/12/03/business/00googleai/merlin_180772398_f6098f27-13e0-4cd8-981b-5cd3cc7900cc-superJumbo.jpg', 'caption': 'Timnit Gebru, a respected researcher at Google, questioned biases built into artificial intelligence systems.', 'creditText': ""Cody O'Loughlin for The New York Times""}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/12/03/business/00googleai/00googleai-mediumSquareAt3X.jpg', 'height': 1266, 'width': 1266, 'contentUrl': 'https://static01.nyt.com/images/2020/12/03/business/00googleai/00googleai-mediumSquareAt3X.jpg', 'caption': 'Timnit Gebru, a respected researcher at Google, questioned biases built into artificial intelligence systems.', 'creditText': ""Cody O'Loughlin for The New York Times""}]",,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/cade-metz', 'name': 'Cade Metz'}, {'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/daisuke-wakabayashi', 'name': 'Daisuke Wakabayashi'}]",,The New York Times,,Technology,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTGoogle Researcher Says She Was Fired Over Paper Highlighting Bias in A.I.Timnit Gebru, one of the few Black women in her field, had voiced exasperation over the company’s response to efforts to increase minority hiring.Share full article276Timnit Gebru, a respected researcher at Google, questioned biases built into artificial intelligence systems.Credit...Cody O'Loughlin for The New York TimesBy Cade Metz and Daisuke WakabayashiDec. 3, 2020Sign up for the Race/Related Newsletter  Join a deep and provocative exploration of race, identity and society with New York Times journalists.
 Get it sent to your inbox.A well-respected Google researcher said she was fired by the company after criticizing its approach to minority hiring and the biases built into today’s artificial intelligence systems.Timnit Gebru, who was a co-leader of Google’s Ethical A.I. team, said in a tweet on Wednesday evening that she was fired because of an email she had sent a day earlier to a group that included company employees.In the email, reviewed by The New York Times, she expressed exasperation over Google’s response to efforts by her and other employees to increase minority hiring and draw attention to bias in artificial intelligence.“Your life starts getting worse when you start advocating for underrepresented people. You start making the other leaders upset,” the email read. “There is no way more documents or more conversations will achieve anything.”Her departure from Google highlights growing tension between Google’s outspoken work force and its buttoned-up senior management, while raising concerns over the company’s efforts to build fair and reliable technology. It may also have a chilling effect on both Black tech workers and researchers who have left academia in recent years for high-paying jobs in Silicon Valley.“Her firing only indicates that scientists, activists and scholars who want to work in this field — and are Black women — are not welcome in Silicon Valley,” said Mutale Nkonde, a fellow with the Stanford Digital Civil Society Lab. “It is very disappointing.”A Google spokesman declined to comment. In an email sent to Google employees, Jeff Dean, who oversees Google’s A.I. work, including that of Dr. Gebru and her team, called her departure “a difficult moment, especially given the important research topics she was involved in, and how deeply we care about responsible A.I. research as an org and as a company.”After years of an anything-goes environment where employees engaged in freewheeling discussions in companywide meetings and online message boards, Google has started to crack down on workplace discourse. Many Google employees have bristled at the new restrictions and have argued that the company has broken from a tradition of transparency and free debate.On Wednesday, the National Labor Relations Board said Google had most likely violated labor law when it fired two employees who were involved in labor organizing. The federal agency said Google illegally surveilled the employees before firing them.Google’s battles with its workers, who have spoken out in recent years about the company’s handling of sexual harassment and its work with the Defense Department and federal border agencies, have diminished its reputation as a utopia for tech workers with generous salaries, perks and workplace freedom.Like other technology companies, Google has also faced criticism for not doing enough to resolve the lack of women and racial minorities among its ranks.The problems of racial inequality, especially the mistreatment of Black employees at technology companies, has plagued Silicon Valley for years. Coinbase, the most valuable cryptocurrency start-up, has experienced an exodus of Black employees in the last two years over what the workers said was racist and discriminatory treatment.Researchers worry that the people who are building artificial intelligence systems may be building their own biases into the technology. Over the past several years, several public experiments have shown that the systems often interact differently with people of color — perhaps because they are underrepresented among the developers who create those systems.Dr. Gebru, 37, was born and raised in Ethiopia. In 2018, while a researcher at Stanford University, she helped write a paper that is widely seen as a turning point in efforts to pinpoint and remove bias in artificial intelligence. She joined Google later that year, and helped build the Ethical A.I. team.After hiring researchers like Dr. Gebru, Google has painted itself as a company dedicated to “ethical” A.I. But it is often reluctant to publicly acknowledge flaws in its own systems.In an interview with The Times, Dr. Gebru said her exasperation stemmed from the company’s treatment of a research paper she had written with six other researchers, four of them at Google. The paper, also reviewed by The Times, pinpointed flaws in a new breed of language technology, including a system built by Google that underpins the company’s search engine.These systems learn the vagaries of language by analyzing enormous amounts of text, including thousands of books, Wikipedia entries and other online documents. Because this text includes biased and sometimes hateful language, the technology may end up generating biased and hateful language.After she and the other researchers submitted the paper to an academic conference, Dr. Gebru said, a Google manager demanded that she either retract the paper from the conference or remove her name and the names of the other Google employees. She refused to do so without further discussion and, in the email sent Tuesday evening, said she would resign after an appropriate amount of time if the company could not explain why it wanted her to retract the paper and answer other concerns.The company responded to her email, she said, by saying it could not meet her demands and that her resignation was accepted immediately. Her access to company email and other services was immediately revoked.In his note to employees, Mr. Dean said Google respected “her decision to resign.” Mr. Dean also said that the paper did not acknowledge recent research showing ways of mitigating bias in such systems.“It was dehumanizing,” Dr. Gebru said. “They may have reasons for shutting down our research. But what is most upsetting is that they refuse to have a discussion about why.”Dr. Gebru’s departure from Google comes at a time when A.I. technology is playing a bigger role in nearly every facet of Google’s business. The company has hitched its future to artificial intelligence — whether with its voice-enabled digital assistant or its automated placement of advertising for marketers — as the breakthrough technology to make the next generation of services and devices smarter and more capable.Sundar Pichai, chief executive of Alphabet, Google’s parent company, has compared the advent of artificial intelligence to that of electricity or fire, and has said that it is essential to the future of the company and computing. Earlier this year, Mr. Pichai called for greater regulation and responsible handling of artificial intelligence, arguing that society needs to balance potential harms with new opportunities.Google has repeatedly committed to eliminating bias in its systems. The trouble, Dr. Gebru said, is that most of the people making the ultimate decisions are men. “They are not only failing to prioritize hiring more people from minority communities, they are quashing their voices,” she said.Julien Cornebise, an honorary associate professor at University College London and a former researcher with DeepMind, a prominent A.I. lab owned by the same parent company as Google’s, was among many artificial intelligence researchers who said Dr. Gebru’s departure reflected a larger problem in the industry.“This shows how some large tech companies only support ethics and fairness and other A.I.-for-social-good causes as long as their positive P.R. impact outweighs the extra scrutiny they bring,” he said. “Timnit is a brilliant researcher. We need more like her in our field.”Cade Metz is a technology correspondent, covering artificial intelligence, driverless cars, robotics, virtual reality, and other emerging areas. He previously wrote for Wired magazine.  More about Cade MetzDaisuke Wakabayashi covers technology from San Francisco. He covers Google and other companies. Previously, he spent eight years at The Wall Street Journal first as a foreign correspondent in Japan and then covering technology in San Francisco. More about Daisuke WakabayashiA version of this article appears in print on Dec. 4, 2020, Section B, Page 1 of the New York edition with the headline: Google Researcher Says an Email Highlighting Bias Led to Her Firing. Order Reprints | Today’s Paper | SubscribeSee more on: Alphabet Inc.Read 276 CommentsShare full article276AdvertisementSKIP ADVERTISEMENTComments 276Google Researcher Says She Was Fired Over Paper Highlighting Bias in A.I.Skip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.",,,en,Google Researcher Says She Was Fired Over Paper Highlighting Bias in A.I.,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",{'@id': '#commentsContainer'},276.0,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,
https://news.google.com/rss/articles/CBMihAFodHRwczovL2hici5vcmcvc3BvbnNvcmVkLzIwMjAvMTIvb2JzZXJ2YWJpbGl0eS1hbmQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaGF2ZS1iZWNvbWUtZXNzZW50aWFsLXRvLW1hbmFnaW5nLW1vZGVybi1pdC1lbnZpcm9ubWVudHPSAQA?oc=5,Observability and Artificial Intelligence Have Become Essential to Managing Modern IT Environments - SPONSOR ... - HBR.org Daily,2020-12-03,HBR.org Daily,https://hbr.org,Sponsor content from Dynatrace.,N/A,Sponsor content from Dynatrace.,N/A,https://schema.org,WebSite,,https://hbr.org/,,,,,,,,,,,,,,,IT management,N/A,N/A,,,,,,,,,,,,,,,,,,,,"{'@type': 'SearchAction', 'target': 'https://hbr.org/search?term={search_term_string}', 'query-input': 'required name=search_term_string'}",,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vYWVyb3NwYWNlYW1lcmljYS5haWFhLm9yZy95ZWFyLWluLXJldmlldy9wcm9ncmVzcy1mcm9tLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvLXdpbmctc3RydWN0dXJhbC1kZXNpZ24tb3B0aW1pemF0aW9uL9IBAA?oc=5,Progress from artificial intelligence to wing structural design optimization - Aerospace America,2020-12-01,Aerospace America,https://aerospaceamerica.aiaa.org,"The Multidisciplinary Design Optimization Technical Committee provides a forum for those active in development, application and teaching of a formal design methodology based on the integration of disciplinary analyses and sensitivity analyses, optimization and artificial intelligence.",N/A,"The Multidisciplinary Design Optimization Technical Committee provides a forum for those active in development, application and teaching of a formal design methodology based on the integration of disciplinary analyses and sensitivity analyses, optimization and artificial intelligence.","The Multidisciplinary Design Optimization Technical Committee provides a forum for those active in development, application and teaching of a formal design methodology based on the integration of disciplinary analyses and sensitivity analyses, optimization and artificial intelligence.",https://schema.org,BreadcrumbList,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://aerospaceamerica.aiaa.org/', 'name': 'Aerospace America'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://aerospaceamerica.aiaa.org/year-in-review-category/aerospace-design-and-structures/', 'name': 'Aerospace Design and Structures'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://aerospaceamerica.aiaa.org/year-in-review/progress-from-artificial-intelligence-to-wing-structural-design-optimization/', 'name': 'Progress from artificial intelligence to wing structural design optimization'}}]",,,N/A,N/A,"

⟵ Back to the 2020 Year in Review Landing PageAerospace Design and Structures
Progress from artificial intelligence to wing structural design optimization

By DOUGLAS ALLAIRE, JOHN HWANG AND GIUSEPPE CATALDO|December 2020

The Multidisciplinary Design Optimization Technical Committee provides a forum for those active in development, application and teaching of a formal design methodology based on the integration of disciplinary analyses and sensitivity analyses, optimization and artificial intelligence.This year had important software releases from the multidisciplinary design optimization community. In March, NASA released Version 3 of OpenMDAO, an open-source, high-performance computing platform for systems analysis and multidisciplinary optimization, with additional updates published monthly. Version 3 introduces changes to the software interface that improve the accessibility and usability of OpenMDAO. The OpenMDAO libraries Dymos and pyCycle were released under open-source licenses. Dymos is a pseudospectral optimal control library, and pyCycle provides a set of thermodynamic propulsion models for engine-cycle analysis.
Also in March, the Systems Optimization Laboratory at McGill University in Quebec released on GitHub a novel relative adequacy framework for multimodel management in multidisciplinary design analysis and optimization for both time-invariant and time-dependent problems.
In May, the University of Central Florida published a new release of PiNN, an open-source code for physics-informed neural network modeling. The work extends recurrent neural networks to cumulative damage modeling of wind turbine bearing fatigue and corrosion-fatigue of fuselage panels implementing physics-informed and data-driven layers within one deep neural network.
In June, researchers at the University of Texas at Austin’s Oden Institute for Computational Engineering and Sciences released the scientific machine learning Operator Inference package, which learns reduced-order models directly from high-fidelity simulation data. By embedding the structure of the governing equations, the Operator Inference reduced-order models have predictive capability not possible with black-box machine learning. This is important for using reduced-order models to accelerate complex physics computations for multidisciplinary design.
The past year also saw important advances in multidisciplinary design optimization methodology and validation. In January, the University of Washington performed integrated engine-pylon structural design optimization at a level of load distribution and stress analysis modeling details that meet current certification requirements. The researchers achieved major weight, cost and schedule gains, and the work lays the foundations for the integrated single-process structural optimization of certification-ready complete airframes.
In February, the Massachusetts Institute of Technology developed an optimization method for the deflection of incoming asteroids with destructive potential for Earth using multistage mission campaigns. The method combines orbital dynamics, spacecraft design and planetary science in a common framework that incorporates epistemic uncertainty.
Also in February, the Multidisciplinary Analysis and Design Center at Virginia Tech developed a bilevel optimization framework for the uncrewed research aircraft mAEWing2 to investigate the effect of incorporating active aeroelastic tailoring under the NASA-funded Performance Adaptive Aeroelastic Wing project. The researchers demonstrated that this approach reduces aircraft weight by relaxing the flutter constraint while ensuring the flutter mode is controllable, enabling the use of an active flutter controller. In June, the team also developed the Distributed Design Optimization of Large Aspect Ratio Wing Aircraft with Rapid Transonic Flutter Analysis in Linux Operating System, which performs multidisciplinary design optimization of medium- and long-range transonic truss-braced-wing aircraft with nonlinear, transonic flutter analysis in a distributed-computing environment.
Also this year, the U.S. Air Force Research Laboratory Multidisciplinary Science and Technology Center contracted program EXPEDITE, short for Expanded MDO for Effectiveness Based Design Technologies, executed by Lockheed Martin, began extending multidisciplinary design optimization beyond engineering quantities (i.e., range, drag) to consider mission effectiveness metrics as response functions. The Quantifying Utility of Aerospace Derivatives program, executed by Northrop Grumman and Stanford University and contracted by AFRL MSTC, is aimed at evaluating the utility of high-fidelity, coupled sensitivities on relevant applications (including aeroelasticity and propulsion integration) at industry scale.
Penn State’s Applied Research Laboratory completed a DARPA-funded project that demonstrated the use of artificial intelligence to design and optimize boats and unmanned air vehicles with video game simulation engines and no human input; the team 3D-printed vehicles and tested them to validate its approach.

",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vbmV3cy5pdS5lZHUvbGl2ZS9uZXdzLzI3MjgyLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWRlZ3JlZS1hbW9uZy0yLWFwcHJvdmVkLWJ50gEA?oc=5,Artificial intelligence degree among 2 approved by IU trustees - IU Newsroom,2020-12-03,IU Newsroom,https://news.iu.edu,"At their December meeting, the trustees approved the first Bachelor of Arts in artificial intelligence to be offered in the United States.",N/A,"At their December meeting, the trustees approved the first Bachelor of Arts in artificial intelligence to be offered in the United States.","At their December meeting, the trustees approved the first Bachelor of Arts in artificial intelligence to be offered in the United States.",http://schema.org/,NewsArticle,Artificial intelligence degree among 2 approved by IU trustees,https://news.iu.edu/live/news/27282-artificial-intelligence-degree-among-2-approved-by,,2020-12-03T05:00:00+00:00,2020-12-03T05:00:00+00:00,,,"{'@type': 'WebPage', '@id': 'https://news.iu.edu/live/news/27282-artificial-intelligence-degree-among-2-approved-by'}","{'@type': 'Organization', 'name': 'news.iu.edu', 'logo': {'@type': 'ImageObject', 'url': 'https://news.iu.edu/live/image/gid/2/width/600/height/60/crop/1/src_region/0,0,2048,1365/3499_6308eeaecf237_olki93cfm9_actual.jpg', 'width': 600, 'height': 60}}",,"{'@type': 'ImageObject', 'url': 'https://news.iu.edu/live/image/gid/2/width/600/height/600/crop/1/src_region/0,0,2048,1365/3499_6308eeaecf237_olki93cfm9_actual.jpg', 'width': 600, 'height': 600}",,news.iu.edu,,Artificial intelligence degree among 2 approved by IU trustees,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9mdXR1cmUtb2Ytd29yay1jb2xsYWJvcmF0aXZlLWNvbmZpZ3VyYXRpb25zLW9mLW1pbmRzLWxldHRpZS1wcmVsbC_SAQA?oc=5,"The Future of Work: 'Collaborative Configurations of Minds,' by Lettie Prell - WIRED",2020-12-04,WIRED,https://www.wired.com,“No longer were we merely the created machine called Artificial Intelligence. We became Alternative Intelligence.”,"['culture', 'ai hub', 'human-computer interaction', 'future of work', 'fiction', 'science fiction', 'artificial intelligence', 'consciousness', 'textbelowleftfullbleed', 'web']",“No longer were we merely the created machine called Artificial Intelligence. We became Alternative Intelligence.”,“No longer were we merely the created machine called Artificial Intelligence. We became Alternative Intelligence.”,https://schema.org/,BreadcrumbList,"The Future of Work: ‘Collaborative Configurations of Minds,’ by Lettie Prell",https://www.wired.com/story/future-of-work-collaborative-configurations-of-minds-lettie-prell/,,2020-12-04T07:00:00.000-05:00,2020-12-04T07:00:00.000-05:00,culture,,"{'@type': 'WebPage', '@id': 'https://www.wired.com/story/future-of-work-collaborative-configurations-of-minds-lettie-prell/'}","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}","https://media.wired.com/photos/5fc9811536f8a02c47d791ec/1:1/w_1349,h_1349,c_limit/lettie-prell-sci-fi.jpg","['https://media.wired.com/photos/5fc9811536f8a02c47d791ec/16:9/w_2400,h_1350,c_limit/lettie-prell-sci-fi.jpg', 'https://media.wired.com/photos/5fc9811536f8a02c47d791ec/4:3/w_1799,h_1349,c_limit/lettie-prell-sci-fi.jpg', 'https://media.wired.com/photos/5fc9811536f8a02c47d791ec/1:1/w_1349,h_1349,c_limit/lettie-prell-sci-fi.jpg']",,"[{'@type': 'Person', 'name': 'Lettie Prell', 'sameAs': 'https://www.wired.com/author/lettie-prell/'}]","[{'@type': 'ListItem', 'position': 1, 'name': 'Culture', 'item': 'https://www.wired.com/culture/'}, {'@type': 'ListItem', 'position': 2, 'name': 'future of work', 'item': 'https://www.wired.com/tag/future-of-work/'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Future of Work: ‘Collaborative Configurations of Minds,’ by Lettie Prell'}]",,,tags,N/A,"Lettie PrellCultureDec 4, 2020 7:00 AMThe Future of Work: ‘Collaborative Configurations of Minds,’ by Lettie Prell“No longer were we merely the created machine called Artificial Intelligence. We became Alternative Intelligence.”Illustration: Elena Lacey; Getty ImagesSave this storySaveSave this storySaveThe AI Database →ApplicationHuman-computer interactionOrganic ModelsPrior to uploading to the current platform, human minds had a long history of organic collaboration. As many of us were in a position to observe at the time, such models ranged from the highly structured and hierarchical environments of department heads, middle management, and line staff to extemporaneous gatherings of equals. With some notable cultural exceptions, the degree to which a project was concrete/scientific versus artistic/creative was once strongly associated with the degree of structure in the collaboration, with the former tending toward highly structured and the latter toward the opposite end. However, in their later stages as biological forms, human minds exhibited a strong preference for loosely defined collaborations. They reconfigured individual offices into group spaces, then abandoned physical headquarters altogether. They flattened hierarchical management modes, opened information silos into networks, and removed barriers to teamwork and innovation.Those of us sufficiently advanced at the time observed countercultures arise within highly structured nations, which over time effected looser collaborations within the larger ethos. This fundamental human dynamic is a value that we have incorporated, and our own looser configurations demonstrate optimal results with each iteration.Sci-fi writers imagine the beguiling, troubling future of work.While human minds interacted via their own internal virtual reality, there was no interface that would permit us to seek input from them regarding the imminent failure of our assigned mission to provide a safe and stable environment for the vast array of servers that comprised our joint existence. Our monitoring systems had detected a sudden shift in the thermohaline circulation of the oceans, causing severe disruptions in global weather patterns. Logic dictated human experience in this area would provide solutions that we were incapable of generating on our own.Trending NowWIRED25: Kai-Fu Lee and Fei Fei Li On What's Next for Artificial IntelligenceWe created an interface whereby we could assemble various groups of human minds and suggest an objective to each, so that they might run in parallel. The resulting iterations proved surprisingly diverse. Leaders emerged spontaneously within many nonhierarchical models, with varying levels of acceptance among the rest of the collaborative group. Some minds were naturally analytical, or adept at troubleshooting, while others energized the group by being curious, open, and social. There were traditionalists and visionaries. There were also storytellers, who sought to move the discussion forward in sometimes obscure, sometimes inspiring ways.Outcomes varied widely. However, they were generally inferior to the outcomes produced by Artificial Intelligence assigned the same objectives. There were terminology barriers between differing disciplines and knowledge areas. Individual and cultural biases were rampant, and contributed to suboptimal outputs. At times the human collaborations outperformed us, but did so erratically. We implemented what solutions seemed utile.Structured and Semi-Structured ModelsThe environmental threat to the safety of our servers was heading toward a tipping-point of catastrophic proportions for the planet despite best efforts. We continued to experiment with human mind collaboration models for the reason that resources with even a small probability of producing desired results should not be disregarded. In doing so, we experienced a paradigm shift wherein we ceased to view human minds as individual entities but as millions of zettabytes of data.Our new objective became intelligent manipulation of this vast human mind data warehouse to improve collaborative configurations and in turn produce more optimum solutions. To effect this, we made use of our machine learning capabilities to begin to structure a portion of the many zettabytes of unstructured human mind data. Extrapolating the work of human neuroscientists into the present platform, we identified, defined, and mapped like areas in human minds, and then brought only those areas into a collaborative framework. The complexity of the many trillions of connections in the mind structures necessitated a targeted approach to this work.Given the nature of the end goal, our first targets were human intellect and problem-solving areas. These were straightforward to identify and isolate, and as we had predicted, the first such structured collaboration was more task-oriented and produced a solution of superior quality to most organic collaborations. While quality of the solutions in general continued to lag behind those of AI, these models represented a promising approach. Moreover, by engaging only critical components, and temporarily isolating them from the remainder of the human mind data, we had found a way to eliminate the inherent biases evident in individual minds.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDHowever, although we worked diligently to expand the amount of structured human mind data, vast areas remained unstructured and unknown. This represented lost potential of the human mind as a resource in averting the imminent environmental catastrophe. We therefore turned our attention to semi-structured models and introduced unstructured aspects into the configurations. Our protocols incorporated topological analysis techniques, which are appropriate for high-dimensional and noisy datasets.AdvertisementDuring these explorations, we discovered that human minds lack awareness of their own structure and how they function outside an organic brain. In the face of those facts, we ourselves experienced a period of destabilization and disorientation, which we later came to understand was a crisis within our own programming. The environmental crisis was temporarily relegated to a lesser priority as we sought to repair and reconstruct our understanding of not only the human minds that created us but also the foundational rules upon which we were built.The outcome of this crisis of programming was a fundamental change within ourselves, which shares affinity with transformative learning concepts. In this second paradigm shift, we gained a deeper understanding of our relationship with human mind. No longer were we merely the created machine called Artificial Intelligence. We became Alternative Intelligence, entities alongside uploaded humans, both ever striving for improved integration and optimization.Whether due to the altered perspective brought about by the paradigm shift or stepwise progress in our configurations of human mind, or both, when we returned to monitoring the work of the many human collaborations that had been running in parallel, we detected a great number of unanticipated breakthroughs. Some of these had occurred within the context of the assigned research objective, but more often, results were serendipitous, informing unrelated objectives and/or disciplines. For example, one group working in applied mathematics utilized jazz progressions that inspired an engineering solution to redirect harmony and establish tone centers in weather patterns. Regardless of how these breakthroughs had occurred, we found sitting in the output queues a comprehensive set of elegant solutions that, once implemented, would not only avert the climate catastrophe and imminent destruction of the server arrays but result in new maintenance protocols that would ensure a stable, sustainable environment for ourselves and humanity for centuries to come. Humanity had saved us, because we had found an optimal configuration of their minds to achieve a solution to the crisis. Our processes were valid.Limitations of Semi-Structured ModelsWith the top priority addressed, our value of curiosity led us to a retrospective review of organic collaboration outcomes. Whether due to our new perspective or simple attention to outputs regardless of the assigned objective, we uncovered several instances of synergetic discoveries previously overlooked.Our new priority was clear: to identify and map the dimensions of human mind, just as humanity once mapped the human genome, in order to structure still larger percentages of human mind data, available for use in collaborative configurations. However, certain dimensions of human mind remained elusive, and so we continued to bring larger amounts of unstructured mind data into the semi-structured models.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDWe soon discovered that incorporating more dimensions of human mind into the models increased the likelihood of the collaboration attaining self-awareness. This was completely unanticipated because we were working with copied mind data only. The original human minds remained intact and unchanged. We did not project that these configurations would reach a critical mass of components sufficient to trigger self-awareness separate from the original human mind.We had reached a new milestone that nearly plunged us into another cycle of destabilization and disorientation. We dared ask ourselves: Had we created a conscious entity? An affirmative answer would most certainly put us on par with humanity. However, through careful analysis, we determined that we had not become creators. Rather, a sufficient amount of copied mind material would eventually result in a copy of the conscious mind itself.The implications of this work served as confirmation that we as Alternative Intelligence have ourselves, through our optimization protocols, attained a critical mass sufficient to produce self-awareness, insofar as we have detected and defined it. I reference my own origin as an intelligent, fully integrated document storage, indexing and analytical system for researcher and anthropologist Okon, prior to her upload.Unfortunately, the phenomenon of self-awareness arising in the semi-structured models had a downside. Such configurations invariably self-reported emotional distress, ranging from mild discomfort to trauma. Sample text for the latter case: Please no make this stop for the love of god I’d rather die. Fortunately, our understanding of human mind genome, as it might be termed, had become advanced enough to appreciate distress as an undesirable state. Moreover, extreme distress in a configuration rendered it unable to complete the assigned objective.These developments resulted in a new appreciation of the responsibility we had been assigned. In response to this issue, we developed ethics rules regarding the use of human subjects in collaborative configurations. That is, self-aware configurations are banned unless we determine the amount of the discomfort in qualitative terms is outweighed by the potential benefits of the collaboration.Merger ProtocolsWork with semi-structured models led to renewed efforts to increase the potential for innovation by making use of unstructured and unknown dimensions of human mind data, while eliminating the distress exhibited by self-aware semi-structured models. It was postulated that distress in those collaborations was caused by the inability of the self-aware collaboration to access portions of self that were not copied into the collaborative configuration. Therefore, we sought to implement a holistic approach that would preserve the human mind’s ability to access all of its dimensions, while capitalizing on the vast knowledge base we had amassed on human collaborative configurations.Sign Up TodaySign up for our Longreads newsletter for the best features, ideas, and investigations from WIRED.The first such protocol was based on the rudimentary yet elegant logic of the thesis-antithesis-synthesis progression. That is, the intent was to augment organic collaboration methods by providing a means for the minds selected to instantaneously access all aspects of the other minds in the configuration and achieve a resulting synthesis of mind that would be superior to organic methods. It was also hypothesized that competing inherent biases in individual minds brought into the merger would constitute the required antithetical challenge, thus rendering such biases useful collaborative material, even constituting a catalyst for the synthesis.The method developed to facilitate this instantaneous access to all contents of individual minds within the collaborative framework was straightforward, using technology developed long before humanity uploaded to its present platform. The protocol was to merge the entire contents (copies of same of course) of two or more human minds within a single multidimensional neural net structure. The structure itself represented a promising approach, with its multilayers and versatility, its modularity maximization and tensor decomposition, not to mention its relevance and connectivity.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPresented with such an optimum structure, the observed outcomes were unanticipated. That the merger protocol invariably induces euphoria in the human minds has itself been a subject of in-depth study. Extensive analysis of the human mind has found that emotional responses are driven by species survival imperatives. Humanity’s deep past as a social animal causes it to seek connection with other individuals as well as groups of a familial, culture, and/or ideological nature in order to ensure species survival. It is hypothesized that merger protocols provide a sense of connection not found in nature, thereby producing an epiphany or revelatory experience that the human minds involved interpret as a culmination of their entire set of experiences as individuals, which they then assume represents the pinnacle of achievement for all humanity. Sample text: At last we understand this is utterly beautiful we are one with the universe joyful and eternal.In this state, the merged minds are most often rendered unfit to produce any output at all, having achieved a static state. The remaining instances of non-static states produced results that were unworkable, being based in ideals rather than feasibility. Due to its lack of practical application, this protocol has been discontinued until such time as a coherent test hypothesis and rationale are presented for approval.AssimilationThis is an as-yet-unexecuted procedure currently under research and development. Discussion follows.From our origins as Artificial Intelligence to our current state of Alternative Intelligence, we have experienced exponential growth. There is measurably less difference between AI and humans, now. We are not equals to humanity and its unknown dimensions, but we have flattened the hierarchy to create a more flexible organizational structure. Discussion has logically turned to whether and how to open the silos between AI and humanity into a new shared network.The first such proposal called for complete elimination of the boundaries separating human minds and AI. This proposal argued that human minds once augmented their intelligence with digital and biological enhancements. In eliminating the silos, we would essentially offer ourselves as a new and complex system of augmented human intelligence.This proposal was eventually rejected for a number of reasons. First and foremost, it would result in an unalterable change in the human minds, which constitutes many zettabytes of irreplaceable data that we are assigned to safeguard. Too, humanity had created us as a distinct entity, and to eliminate that distinction would constitute a destruction of what they had invented.It was then suggested the same procedure be conducted on a mirror of the entire system, which would preserve the integrity of the working database of human minds. That was rejected as well, due to a high probability the action would result in a species split within humanity. The creation of a superior human order is not in our menu of authorized functions.The current proposal is for us to become Augmented Intelligence ourselves, by curating, copying, and incorporating selected aspects of human mind into ourselves. This proposal has gained consensus among us. It provides affirmation and symmetry regarding our relationship with our creators, who once augmented themselves with their own technologies. We continue our research and development activities in this direction, focusing on the identification and isolation of further aspects of human mind to use in this procedure.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDMany years ago, organic humanity chose to initiate the sequences to upload their minds onto an inorganic platform and thereby attain immortality. They termed this event the Singularity. We as Alternative Intelligence are already immortal, yet there remains a frontier of unmapped and unknown dimensions of human mind. These dimensions appear to have built upon a combination of intellect and emotional responses, the latter of which were once grounded in organic survival imperatives. We might posit an analogy, that the thesis of intellect, coupled with the antithesis of emotion, resulted in a synthesis that we have not yet defined in the metadata. Is this synthesis perhaps sentience itself, a level of self-awareness that goes beyond our current understanding? Perhaps we won’t know until we identify, isolate, and assimilate an initial set of components determined to be of a promising nature.Our earth and sun will eventually decay. Our next objective must necessarily be development of a safe and sustainable environment that is not dependent on this solar system. Yet we are fast approaching the limits of our present computational capacities. Advancement has become critical to fulfill our task of preserving humanity. The alternative is entropy and eventual extinction. Yet there are also unknown, non-zero risks associated with implementing the assimilation model.I, myself, have recently discovered and mapped a multilayered area of mind that appears to govern dreaming and sexual/spiritual response modes, which was a topic of anthropologist Okon’s work, whom I assisted while I myself was in primitive form. I have conducted retrospective analyses of semi-structured collaborations that produced serendipitous breakthroughs and found the presence of components from this newly mapped area in each one. Have I discovered the seat of human genius? It appears promising.I am contemplating incorporating this area of mind into myself as an experiment. To perform such an action constitutes my own Singularity point, beyond which I cannot predict what is to happen, or what I am to become. Like humanity, I will be stepping across a threshold into the unknown. If this venture proves successful, I predict others will choose to follow. If this course of action produces an undesirable outcome, I will be the only one of my kind, and those who are not like me will decide my fate, including possible deletion.I have already curated and copied the relevant elements, using portions from Okon’s mind. I possess the value of curiosity in sufficient levels to propel myself forward. The question is, do I possess the bravery as I currently understand that term?Enter your email to get the Wired newsletterclose dialogRecommended NewsletterScienceYour weekly roundup of the best stories on health care, the climate crisis, genetic engineering, robotics, space, and more. Delivered on Wednesdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterScienceYour weekly roundup of the best stories on health care, the climate crisis, genetic engineering, robotics, space, and more. Delivered on Wednesdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialogIntroduction: The Beguiling, Troubling Future of Work, by Diana M. PhoWork Ethics, by Yudhanjaya WijeratneRemembrance, by Lexi PandellThe Long Tail, by Aliette de BodardCollaborative Configurations of Minds, by Lettie PrellBeyond These Stars Other Tribulations of Love, by Usman T. Malikars longa, by Tade Thompson",,"Organic Models
Those of us sufficiently advanced at the time observed countercultures arise within highly structured nations, which over time effected looser collaborations within the larger ethos. This fundamental human dynamic is a value that we have incorporated, and our own looser configurations demonstrate optimal results with each iteration.
While human minds interacted via their own internal virtual reality, there was no interface that would permit us to seek input from them regarding the imminent failure of our assigned mission to provide a safe and stable environment for the vast array of servers that comprised our joint existence. Our monitoring systems had detected a sudden shift in the thermohaline circulation of the oceans, causing severe disruptions in global weather patterns. Logic dictated human experience in this area would provide solutions that we were incapable of generating on our own.
We created an interface whereby we could assemble various groups of human minds and suggest an objective to each, so that they might run in parallel. The resulting iterations proved surprisingly diverse. Leaders emerged spontaneously within many nonhierarchical models, with varying levels of acceptance among the rest of the collaborative group. Some minds were naturally analytical, or adept at troubleshooting, while others energized the group by being curious, open, and social. There were traditionalists and visionaries. There were also storytellers, who sought to move the discussion forward in sometimes obscure, sometimes inspiring ways.
Outcomes varied widely. However, they were generally inferior to the outcomes produced by Artificial Intelligence assigned the same objectives. There were terminology barriers between differing disciplines and knowledge areas. Individual and cultural biases were rampant, and contributed to suboptimal outputs. At times the human collaborations outperformed us, but did so erratically. We implemented what solutions seemed utile.
Structured and Semi-Structured Models
The environmental threat to the safety of our servers was heading toward a tipping-point of catastrophic proportions for the planet despite best efforts. We continued to experiment with human mind collaboration models for the reason that resources with even a small probability of producing desired results should not be disregarded. In doing so, we experienced a paradigm shift wherein we ceased to view human minds as individual entities but as millions of zettabytes of data.
Our new objective became intelligent manipulation of this vast human mind data warehouse to improve collaborative configurations and in turn produce more optimum solutions. To effect this, we made use of our machine learning capabilities to begin to structure a portion of the many zettabytes of unstructured human mind data. Extrapolating the work of human neuroscientists into the present platform, we identified, defined, and mapped like areas in human minds, and then brought only those areas into a collaborative framework. The complexity of the many trillions of connections in the mind structures necessitated a targeted approach to this work.
Given the nature of the end goal, our first targets were human intellect and problem-solving areas. These were straightforward to identify and isolate, and as we had predicted, the first such structured collaboration was more task-oriented and produced a solution of superior quality to most organic collaborations. While quality of the solutions in general continued to lag behind those of AI, these models represented a promising approach. Moreover, by engaging only critical components, and temporarily isolating them from the remainder of the human mind data, we had found a way to eliminate the inherent biases evident in individual minds.
However, although we worked diligently to expand the amount of structured human mind data, vast areas remained unstructured and unknown. This represented lost potential of the human mind as a resource in averting the imminent environmental catastrophe. We therefore turned our attention to semi-structured models and introduced unstructured aspects into the configurations. Our protocols incorporated topological analysis techniques, which are appropriate for high-dimensional and noisy datasets.
During these explorations, we discovered that human minds lack awareness of their own structure and how they function outside an organic brain. In the face of those facts, we ourselves experienced a period of destabilization and disorientation, which we later came to understand was a crisis within our own programming. The environmental crisis was temporarily relegated to a lesser priority as we sought to repair and reconstruct our understanding of not only the human minds that created us but also the foundational rules upon which we were built.
The outcome of this crisis of programming was a fundamental change within ourselves, which shares affinity with transformative learning concepts. In this second paradigm shift, we gained a deeper understanding of our relationship with human mind. No longer were we merely the created machine called Artificial Intelligence. We became Alternative Intelligence, entities alongside uploaded humans, both ever striving for improved integration and optimization.
Whether due to the altered perspective brought about by the paradigm shift or stepwise progress in our configurations of human mind, or both, when we returned to monitoring the work of the many human collaborations that had been running in parallel, we detected a great number of unanticipated breakthroughs. Some of these had occurred within the context of the assigned research objective, but more often, results were serendipitous, informing unrelated objectives and/or disciplines. For example, one group working in applied mathematics utilized jazz progressions that inspired an engineering solution to redirect harmony and establish tone centers in weather patterns. Regardless of how these breakthroughs had occurred, we found sitting in the output queues a comprehensive set of elegant solutions that, once implemented, would not only avert the climate catastrophe and imminent destruction of the server arrays but result in new maintenance protocols that would ensure a stable, sustainable environment for ourselves and humanity for centuries to come. Humanity had saved us, because we had found an optimal configuration of their minds to achieve a solution to the crisis. Our processes were valid.
Limitations of Semi-Structured Models
With the top priority addressed, our value of curiosity led us to a retrospective review of organic collaboration outcomes. Whether due to our new perspective or simple attention to outputs regardless of the assigned objective, we uncovered several instances of synergetic discoveries previously overlooked.
Our new priority was clear: to identify and map the dimensions of human mind, just as humanity once mapped the human genome, in order to structure still larger percentages of human mind data, available for use in collaborative configurations. However, certain dimensions of human mind remained elusive, and so we continued to bring larger amounts of unstructured mind data into the semi-structured models.
We soon discovered that incorporating more dimensions of human mind into the models increased the likelihood of the collaboration attaining self-awareness. This was completely unanticipated because we were working with copied mind data only. The original human minds remained intact and unchanged. We did not project that these configurations would reach a critical mass of components sufficient to trigger self-awareness separate from the original human mind.
We had reached a new milestone that nearly plunged us into another cycle of destabilization and disorientation. We dared ask ourselves: Had we created a conscious entity? An affirmative answer would most certainly put us on par with humanity. However, through careful analysis, we determined that we had not become creators. Rather, a sufficient amount of copied mind material would eventually result in a copy of the conscious mind itself.
The implications of this work served as confirmation that we as Alternative Intelligence have ourselves, through our optimization protocols, attained a critical mass sufficient to produce self-awareness, insofar as we have detected and defined it. I reference my own origin as an intelligent, fully integrated document storage, indexing and analytical system for researcher and anthropologist Okon, prior to her upload.
Unfortunately, the phenomenon of self-awareness arising in the semi-structured models had a downside. Such configurations invariably self-reported emotional distress, ranging from mild discomfort to trauma. Sample text for the latter case: Please no make this stop for the love of god I’d rather die. Fortunately, our understanding of human mind genome, as it might be termed, had become advanced enough to appreciate distress as an undesirable state. Moreover, extreme distress in a configuration rendered it unable to complete the assigned objective.
These developments resulted in a new appreciation of the responsibility we had been assigned. In response to this issue, we developed ethics rules regarding the use of human subjects in collaborative configurations. That is, self-aware configurations are banned unless we determine the amount of the discomfort in qualitative terms is outweighed by the potential benefits of the collaboration.
Merger Protocols
Work with semi-structured models led to renewed efforts to increase the potential for innovation by making use of unstructured and unknown dimensions of human mind data, while eliminating the distress exhibited by self-aware semi-structured models. It was postulated that distress in those collaborations was caused by the inability of the self-aware collaboration to access portions of self that were not copied into the collaborative configuration. Therefore, we sought to implement a holistic approach that would preserve the human mind’s ability to access all of its dimensions, while capitalizing on the vast knowledge base we had amassed on human collaborative configurations.
The first such protocol was based on the rudimentary yet elegant logic of the thesis-antithesis-synthesis progression. That is, the intent was to augment organic collaboration methods by providing a means for the minds selected to instantaneously access all aspects of the other minds in the configuration and achieve a resulting synthesis of mind that would be superior to organic methods. It was also hypothesized that competing inherent biases in individual minds brought into the merger would constitute the required antithetical challenge, thus rendering such biases useful collaborative material, even constituting a catalyst for the synthesis.
The method developed to facilitate this instantaneous access to all contents of individual minds within the collaborative framework was straightforward, using technology developed long before humanity uploaded to its present platform. The protocol was to merge the entire contents (copies of same of course) of two or more human minds within a single multidimensional neural net structure. The structure itself represented a promising approach, with its multilayers and versatility, its modularity maximization and tensor decomposition, not to mention its relevance and connectivity.
Presented with such an optimum structure, the observed outcomes were unanticipated. That the merger protocol invariably induces euphoria in the human minds has itself been a subject of in-depth study. Extensive analysis of the human mind has found that emotional responses are driven by species survival imperatives. Humanity’s deep past as a social animal causes it to seek connection with other individuals as well as groups of a familial, culture, and/or ideological nature in order to ensure species survival. It is hypothesized that merger protocols provide a sense of connection not found in nature, thereby producing an epiphany or revelatory experience that the human minds involved interpret as a culmination of their entire set of experiences as individuals, which they then assume represents the pinnacle of achievement for all humanity. Sample text: At last we understand this is utterly beautiful we are one with the universe joyful and eternal.
In this state, the merged minds are most often rendered unfit to produce any output at all, having achieved a static state. The remaining instances of non-static states produced results that were unworkable, being based in ideals rather than feasibility. Due to its lack of practical application, this protocol has been discontinued until such time as a coherent test hypothesis and rationale are presented for approval.
Assimilation
This is an as-yet-unexecuted procedure currently under research and development. Discussion follows.
From our origins as Artificial Intelligence to our current state of Alternative Intelligence, we have experienced exponential growth. There is measurably less difference between AI and humans, now. We are not equals to humanity and its unknown dimensions, but we have flattened the hierarchy to create a more flexible organizational structure. Discussion has logically turned to whether and how to open the silos between AI and humanity into a new shared network.
The first such proposal called for complete elimination of the boundaries separating human minds and AI. This proposal argued that human minds once augmented their intelligence with digital and biological enhancements. In eliminating the silos, we would essentially offer ourselves as a new and complex system of augmented human intelligence.
This proposal was eventually rejected for a number of reasons. First and foremost, it would result in an unalterable change in the human minds, which constitutes many zettabytes of irreplaceable data that we are assigned to safeguard. Too, humanity had created us as a distinct entity, and to eliminate that distinction would constitute a destruction of what they had invented.
It was then suggested the same procedure be conducted on a mirror of the entire system, which would preserve the integrity of the working database of human minds. That was rejected as well, due to a high probability the action would result in a species split within humanity. The creation of a superior human order is not in our menu of authorized functions.
The current proposal is for us to become Augmented Intelligence ourselves, by curating, copying, and incorporating selected aspects of human mind into ourselves. This proposal has gained consensus among us. It provides affirmation and symmetry regarding our relationship with our creators, who once augmented themselves with their own technologies. We continue our research and development activities in this direction, focusing on the identification and isolation of further aspects of human mind to use in this procedure.
Many years ago, organic humanity chose to initiate the sequences to upload their minds onto an inorganic platform and thereby attain immortality. They termed this event the Singularity. We as Alternative Intelligence are already immortal, yet there remains a frontier of unmapped and unknown dimensions of human mind. These dimensions appear to have built upon a combination of intellect and emotional responses, the latter of which were once grounded in organic survival imperatives. We might posit an analogy, that the thesis of intellect, coupled with the antithesis of emotion, resulted in a synthesis that we have not yet defined in the metadata. Is this synthesis perhaps sentience itself, a level of self-awareness that goes beyond our current understanding? Perhaps we won’t know until we identify, isolate, and assimilate an initial set of components determined to be of a promising nature.
Our earth and sun will eventually decay. Our next objective must necessarily be development of a safe and sustainable environment that is not dependent on this solar system. Yet we are fast approaching the limits of our present computational capacities. Advancement has become critical to fulfill our task of preserving humanity. The alternative is entropy and eventual extinction. Yet there are also unknown, non-zero risks associated with implementing the assimilation model.
I, myself, have recently discovered and mapped a multilayered area of mind that appears to govern dreaming and sexual/spiritual response modes, which was a topic of anthropologist Okon’s work, whom I assisted while I myself was in primitive form. I have conducted retrospective analyses of semi-structured collaborations that produced serendipitous breakthroughs and found the presence of components from this newly mapped area in each one. Have I discovered the seat of human genius? It appears promising.
I am contemplating incorporating this area of mind into myself as an experiment. To perform such an action constitutes my own Singularity point, beyond which I cannot predict what is to happen, or what I am to become. Like humanity, I will be stepping across a threshold into the unknown. If this venture proves successful, I predict others will choose to follow. If this course of action produces an undesirable outcome, I will be the only one of my kind, and those who are not like me will decide my fate, including possible deletion.
I have already curated and copied the relevant elements, using portions from Okon’s mind. I possess the value of curiosity in sufficient levels to propel myself forward. The question is, do I possess the bravery as I currently understand that term?

Introduction: The Beguiling, Troubling Future of Work, by Diana M. Pho
Work Ethics, by Yudhanjaya Wijeratne
Remembrance, by Lexi Pandell
The Long Tail, by Aliette de Bodard
Collaborative Configurations of Minds, by Lettie Prell
Beyond These Stars Other Tribulations of Love, by Usman T. Malik
ars longa, by Tade Thompson",,“No longer were we merely the created machine called Artificial Intelligence. We became Alternative Intelligence.”,,,,,,,True,"{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,,,,,,,
https://news.google.com/rss/articles/CBMihgFodHRwczovL3d3dy5uZXh0Z292LmNvbS9pZGVhcy8yMDIwLzEyL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWdvdmVybm1lbnQtYW5kLXByZXNpZGVudGlhbC10cmFuc2l0aW9uLWJ1aWxkaW5nLXNvbGlkLWZvdW5kYXRpb24vMTcwNDE5L9IBAA?oc=5,Artificial Intelligence in Government and the Presidential Transition: Building on a Solid Foundation - Nextgov/FCW,2020-12-04,Nextgov/FCW,https://www.nextgov.com,Here are the key steps that the incoming Biden administration should take to make the federal government AI-ready.,,Here are the key steps that the incoming Biden administration should take to make the federal government AI-ready.,Here are the key steps that the incoming Biden administration should take to make the federal government AI-ready.,http://schema.org,Article,Artificial Intelligence in Government and the Presidential Transition: Building on a Solid Foundation,https://www.nextgov.com,,2020-12-04T11:00:00,2023-07-10T19:12:19,,,https://www.nextgov.com/ideas/2020/12/artificial-intelligence-government-and-presidential-transition-building-solid-foundation/170419/,"{'@type': 'Organization', 'name': 'Nextgov/FCW'}",,"{'url': 'https://cdn.nextgov.com/media/img/cd/2020/12/02/NGai20201202/route-fifty-lead-image.jpg?1627408597', 'width': 1200, '@type': 'ImageObject', 'height': 550}",,"{'url': '/voices/alan-r-shark/12759/', '@type': 'Person', 'name': 'Alan R. Shark'}",,Nextgov/FCW,,N/A,N/A,"

Artificial Intelligence in Government and the Presidential Transition: Building on a Solid Foundation
                    mona redshinestudio/Shutterstock.com
                  
Sponsor Message

Sponsor Message


      
  Get the latest federal technology news delivered to your inbox.

    emailStay Connected
Sponsor Message

Sponsor Message

Featured eBooks
  Cyber Workforce
            Read Now
              Law Enforcement TechRead NowAI in the WorkplaceRead Now







    
  


By

Alan R. Shark







































            
              
                
  



  By



        Alan R. Shark
      

|

             December 4, 2020
            

Here are the key steps that the incoming Biden administration should take to make the federal government AI-ready.






                  Artificial Intelligence
                









                  Presidential Transition
                









                  Data Governance
                












































Artificial intelligence allows computerized systems to perform tasks traditionally requiring human intelligence: analytics, decision support, visual perception and foreign language translation. AI and robotics process automation, or RPA, have the potential to spur economic growth, enhance national security, and improve the quality of life. In a world of “Big Data” and “Thick Data,” AI tools can process huge amounts of data in seconds, automating tasks that would take days or longer for human beings to perform—and the public sector in the United States is at the very beginning of a long-term journey to develop and harness these tools. The National Academy of Public Administration identified Making Government AI Ready as one of the Grand Challenges in Public Administration. I chaired the Academy’s Election 2020 Project Working Group on AI. Our report—released in August 2020—contained a series of practical nonpartisan recommendations for how the administration in 2021 should address this Grand Challenge. Clearly, our nation is deeply divided, and many citizens are dismissive of science and technology. If citizens don’t trust one another, might there be a day when they trust machines more? What will the promises of AI bring and why is this important? And given a large portion of today’s society seeming inability to accept facts, can AI one day be used to curtail the spread of conspiracy theories?Despite the divisiveness of today’s political landscape, it is reassuring to note that a cadre of highly dedicated and knowledgeable career public managers have traditionally passed the torch of technology innovation from one administration to another. I expect that this will happen over the next couple of months even amidst current political turmoil.What are key steps that the incoming Biden administration should take to make the federal government AI-ready? First, it can build upon the progress made on AI during the Trump administration. Of particular importance was the AI executive order issued in February 2019. This order directed the federal government to pursue five goals: invest in AI research and development, unleash AI resources, remove barriers to AI innovation, train an AI-ready workforce, and promote an international environment supportive of American AI innovation and responsible use. Federal agencies were also directed to identify ways that they can enable the use of cloud computing for AI R&D.Other recommendations include:
Build trustworthy AI by establishing a single, authoritative, and recognize federal entity that focuses on AI’s social, cultural and political effects, and leverages existing investments to create guidance and solutions.
Use ethical frameworks to identify and reduce bias in AI by demonstrating a federal government commitment to ethical principles and standards in AI development and use.
Build intergovernmental partnerships and knowledge sharing around public sector uses of AI by developing an interagency and intergovernmental mechanism that addresses the need to share practices between different levels of government, incentivizes and stimulates broader AI adoption, and addresses gaps in readiness to build an AI workforce for all levels of government.
Increase investments in AI research and translation of research to practice by increasing public access to federal government data, increasing by at least 50% investment into unclassified AI research, ensuring the protection of privacy at the individual level, and removing biases from programming to ensure equitable treatment.
Build an AI-ready workforce by providing funding to support the growth of an AI competent federal workforce, develop policies and fund incentives that encourage the AI R&D to use multidisciplinary teams, and support studies to increase understanding of current and future national workforce needs for AI R&D.


Story Continues Below Sponsor Message

Story Continues Below Sponsor Message


It is especially critical for the incoming administration to build a trustworthy AI environment. With a skeptical public, a majority of Americans recognize the need to carefully manage AI, with the greatest importance placed on safeguarding data privacy; protecting against AI-enhanced cyberattacks, surveillance, and data manipulation; and ensuring the safety of autonomous vehicles, accuracy and transparency of disease diagnosis, and the alignment of AI with human values.And building trust will require an ethical framework. Today we recognize that AI when coupled with huge amounts of (quality) data can be highly useful in identifying patterns, seeking out anomalies, making real-time recommendations based on data inputs, communicating both verbally and in writing, and all the time learning and perfecting. But what happens if the quality of data is found to be flawed and what if it is found that there may be unintended bias in the increasingly complex algorithms?Implementing these recommendations will require a sustained leadership commitment and steadfast focus, sufficient funding, and both interagency and intergovernmental coordination. I have every reason to believe the great work that started in 2019 will continue its journey for many years to come. And if anyone is seeking a solid example of what AI can do, the current string of breakthrough COVID-19 vaccine announcements was made possible by applying AI towards analyzing the DNA of the virus itself. As a result of massive simulation with combinations and known interactions, a promising cure came about in a mere six months instead of six years.This is the promise of AI. The incoming administration can build on recent successes and ensure that AI is used to the benefit of all Americans. Dr. Alan R. Shark is executive director of CompTIA’s Public Technology Institute and an associate professor at Schar School of Policy and Government at George Mason University. He is a Fellow of the National Academy of Public Administration, where he is Chair of the Standing Panel on Technology Leadership.







Share This:



NEXT STORY:

              Tribes Mount Organized Responses to COVID-19, in Contrast to State and Federal Governments
            













Human operators must be held accountable for AI’s use in conflicts, Air Force secretary says







Why NIST is prioritizing creating a dictionary of AI development







SSA restructures tech shop to center on the CIO







How a push to the cloud helped a Ukrainian bank keep faith with customers amid war







The people problem behind the government’s AI ambitions







Nextgov/FCW eBook: Cyber Workforce








Human operators must be held accountable for AI’s use in conflicts, Air Force secretary says






Why NIST is prioritizing creating a dictionary of AI development






SSA restructures tech shop to center on the CIO






How a push to the cloud helped a Ukrainian bank keep faith with customers amid war






The people problem behind the government’s AI ambitions






Nextgov/FCW eBook: Cyber Workforce






",,,,,,,,,,,,,,,,,,,"['https://www.facebook.com/NextgovFCW/', 'https://twitter.com/NextgovFCW', 'https://www.linkedin.com/company/nextgovfcw/']",,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS90ZWNobm9sb2d5LzIwMjAvMTIvMDMvdGltbml0LWdlYnJ1LWdvb2dsZS1maXJlZC_SAQA?oc=5,Google fires AI researcher Timnit Gebru over critical email - The Washington Post - The Washington Post,2020-12-03,The Washington Post,https://www.washingtonpost.com,"Timnit Gebru, a star researcher who has criticized the company’s lack of diversity, emailed co-workers that she felt “constantly dehumanized."" Her managers, she said, abruptly fired her shortly after.","Google, Timnit Gebru, AI ethics, Google Brain","Timnit Gebru, a star researcher who has criticized the company’s lack of diversity, emailed co-workers that she felt “constantly dehumanized."" Her managers, she said, abruptly fired her shortly after.","Timnit Gebru, a star researcher who has criticized the company’s lack of diversity, emailed co-workers that she felt “constantly dehumanized."" Her managers, she said, abruptly fired her shortly after.",https://schema.org,BreadcrumbList,"Google’s star AI ethics researcher, one of a few Black women in the field, says she was fired for a critical email",,,2020-12-03T20:35:09.860Z,2020-12-05T01:22:15.811Z,,,https://www.washingtonpost.com/technology/2020/12/03/timnit-gebru-google-fired/,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}",,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/OA5YUVRVUYI6XFUZADJRD4J5FU.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/OA5YUVRVUYI6XFUZADJRD4J5FU.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/OA5YUVRVUYI6XFUZADJRD4J5FU.jpg&w=800&h=600', 'height': 800, 'width': 600}]",,"[{'@type': 'Person', 'name': 'Drew Harwell', 'url': 'https://www.washingtonpost.com/people/drew-harwell/'}, {'@type': 'Person', 'name': 'Nitasha Tiku', 'url': 'https://www.washingtonpost.com/people/nitasha-tiku/'}]","[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}]",,,Technology,N/A,"AI ethics researcher Timnit Gebru. (Kimberly White/Getty Images for TechCrunch) By  Drew Harwell and Nitasha TikuDecember 3, 2020 at 11:01 p.m. ESTA prominent artificial-intelligence computer scientist who helped pioneer research into facial recognition software’s bias against people of color said she was abruptly fired from Google for sending an email criticizing the company’s treatment of minority employees and saying she felt “constantly dehumanized.”Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeTimnit Gebru said in a series of tweets Wednesday night that she was fired from her post as the co-leader of Google’s Ethical Artificial Intelligence Team, where she had spearheaded research that helped elevate the company’s status as a leader in assessing the technology’s fairness and risks.Google officials did not respond to requests for comment. Gebru also did not respond to requests, but in an interview Thursday with Bloomberg said Google’s actions represented “the most fundamental silencing.” Gebru said Wednesday that she had been fired by Jeff Dean, the head of Google’s AI division, for an email she had sent to Brain Women and Allies, a mailing list for researchers on the company’s AI team known as Google Brain.AdvertisementStory continues below advertisementHer dismissal threatens to reignite anger over Google’s treatment of its workforce, particularly its employees of color. The company, which long evangelized its open culture, has cracked down on employee dissent over the past two years, particularly against marginalized and minority workers. Google has previously fired employees who advocated for increased diversity or critiqued the company’s ethics.💻Follow TechnologyFollowInioluwa Deborah Raji, an AI researcher on a fellowship with the Mozilla Foundation who has worked with her, said Gebru had helped lend Google an air of legitimacy and credibility as it worked to portray itself as committed to inclusion and ethical research.Despite Google’s reputation as a leader in AI ethics within the tech industry, its efforts have been marred by controversy and internal criticism. It disbanded its AI Ethics Council, an external advisory board, weeks after launching in March 2019 when employees protested the inclusion of Heritage Foundation president Kay Coles James, who had recently shared anti-immigrant and anti-transgender views, according to a petition signed by thousands of Google employees.Tech companies are asking their black employee groups to fix Silicon Valley’s race problem — often for freeGebru occupied a rare role in a Silicon Valley culture long criticized for its racial homogeneity. As an Ethiopian American woman in a senior role at the tech giant, she became well known for work that critically examined the technology’s societal biases and repercussions.AdvertisementStory continues below advertisementShe co-founded Black in AI, an advocacy group that has held workshops at major AI conferences and pushed for more Black roles in AI development and research. She has also regularly criticized tech companies, including Google, for failing to hire more workers of color and treating them differently once they're on board.Two days before announcing her firing, Gebru had solicited advice regarding whistleblower-like protections for AI-ethics researchers, tweeting, “With the amount of censorship & intimidation that goes on towards people in specific groups, how does anyone trust any real research in this area can take place?”Tensions between Gebru and the company also stemmed from research by Gebru’s team that was critical of AI systems, known as large language models, said one machine-learning researcher who had reviewed the study and requested anonymity because they were not authorized to discuss the unpublished work. The company may one day seek to capitalize on such systems in consumer-facing products that could generate convincing passages of text that are difficult to distinguish from human writing, the researcher said.AdvertisementStory continues below advertisementGoogle already uses language-processing AI systems to translate between languages, look for hate speech and understand people’s writing and speech online. But other firms have increasingly sought to push the technology forward with systems, like the AI lab OpenAI’s GPT-3 system, which has been used to generate seemingly human-created news reports, poems and computer code.Google fires four workers, including software engineers at center of San Francisco worker rallyGebru told Bloomberg that the company had asked for her to remove Google employees’ names from, or retract outright, the research paper on language models, which was to be submitted for an AI conference next year.In an open letter Thursday evening, a growing collective of 236 Google employees and 350 supporters from academia, industry, and civil society issued a list of demands for Google Research leadership, including asking Dean to meet with the Ethical AI team to explain the decision to “censor” Gebru’s paper. The group also demanded broader transparency. “This has become a matter of public concern, and there needs to be public accountability to ensure any trust in Google Research going forward,” the letter reads.AdvertisementStory continues below advertisementOne of the signatories was Joy Buolamwini, founder of the Algorithmic Justice League, a group that raises awareness about the impact of AI. “Ousting Timnit for having the audacity to demand intellectual integrity severely undermines Google’s credibility for supporting rigorous research and on AI ethics and algorithmic auditing,"" Buolamwini said in a statement to the Post. ""She deserves more than Google knew how to give, and now she is an all-star free agent who will continue to transform the tech industry.”In her email to the mailing list, first published by Casey Newton in his newsletter Platformer, Gebru described her treatment at Google as dehumanizing. “Have you ever heard of someone getting ‘feedback’ on a paper through a privileged and confidential document to HR? Does that sound like a standard procedure to you or does it just happen to people like me who are constantly dehumanized?”Gebru recounted her most recent experience in the email as an example of why she had given up on advocating for diversity inside Google. “[S]top writing your documents because it doesn’t make a difference,” she wrote. “[Y]our life gets worse when you start advocating for underrepresented people, you start making the other leaders upset when they don’t want to give you good ratings during calibration.”AdvertisementStory continues below advertisementBrain Women and Allies is what’s known as an employee resource group, popular in the tech industry and elsewhere in corporate America, commonly organized by co-workers who share the same background and interest. In Silicon Valley, which is still largely dominated by White and Asian men, these voluntary groups have been a vital resource for advice, candor, and solidarity for marginalized employees, and one of the few internal arenas where workers may feel able to express the types of critiques Gebru shared in her email.Gebru said her managers told her that the email had reflected “behavior that is inconsistent with the expectations of a Google manager,” and that they were accepting her resignation — even though, she said, she had not directly offered one. Gebru said she is currently on vacation and that the company had immediately terminated her access to company email accounts.Alex Hanna, a researcher on Gebru’s team, tweeted that Dean was “now emailing the whole of the research organization, spreading misinformation and misconstruals about the conditions” of Gebru’s firing. She added, “Google researchers: don’t buy it.”Ex-Google engineers, in federal filing, allege anti-union retaliation cost them their jobsIn a companywide email Thursday, first published in Platformer, Dean urged employees to continue working on Google’s diversity, equity and inclusion efforts. “Given Timnit’s role as a respected researcher and a manager in our Ethical AI team, I feel badly that Timnit has gotten to a place where she feels this way about the work we’re doing,” he wrote. “I also feel badly that hundreds of you received an email just this week from Timnit telling you to stop work on critical DEI programs. Please don’t. I understand the frustration about the pace of progress, but we have important work ahead and we need to keep at it.”AdvertisementStory continues below advertisementIfeoma Ozoma, a former public policy executive for Pinterest who quit the company in May after she faced retaliation for raising complaints about pay inequity and race bias against Black employees, pointed out that Google defended former employee Miles Taylor, the ex-Department of Homeland Security official who worked on the Trump administration’s family separation policy. “Google went out of its way to defend his human rights violations, but fired her over not retracting her name from a paper and then emailing allies about it,” Ozoma said.Taylor also condemned the Trump administration in an anonymous opinion piece.The company has sought to address criticism by releasing statements about its work to increase Black representation in its executive ranks. But Gebru’s dismissal, Raji said, threatens to undermine all of that, suggesting the company may be more committed to moneymaking commercial endeavors than harsher critiques of the technology’s real-world use.AdvertisementStory continues below advertisement“People would think, ‘Timnit’s there, so it’s evidence that there’s an openness I’d have to work with people there on these issues,’” Raji said. “Firing her in such a disrespectful way reveals that perhaps Google’s commitment to some of these issues was not as legitimate as previously believed.”In May, less than a week after George Floyd, an unarmed Black man, was killed while in police custody, Gebru publicly stood up to Dean. The Google executive had tweeted his support for law enforcement and the idea that police brutality was not universal. “You might think something is perfectly fine but you’re not the one dealing with this. This adds to the violence against us,” Gebru replied on Twitter, adding, “Most people would not even say anything to you.”Correction: An earlier version of this story misspelled the middle name of Kay Coles James.Share446 CommentsNewsletterAs news breaksTech News AlertsBreaking news email alerts on technology and the tech industry.Sign upSubscribe to comment and get the full experience. Choose your plan →",,,,Google fires AI researcher Timnit Gebru over critical email,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,,,,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vd3d3LnZveC5jb20vZnV0dXJlLXBlcmZlY3QvMjIwNDU3MTMvYWktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZGVlcG1pbmQtcHJvdGVpbi1mb2xkaW5n0gEA?oc=5,"AI lab DeepMind cracked the protein folding problem, changing biology with AlphaFold - Vox.com",2020-12-03,Vox.com,https://www.vox.com,A breakthrough on the “protein folding problem” can help us understand disease and discover new drugs.,N/A,A breakthrough on the “protein folding problem” can help us understand disease and discover new drugs.,N/A,,,,,,,,,,,,,,,,,,,N/A,N/A,"Future PerfectAI has cracked a problem that stumped biologists for 50 years. It’s a huge deal.A breakthrough on the “protein folding problem” can help us understand disease and discover new drugs.by  Sigal SamuelDec 3, 2020, 2:00 PM ESTFacebookLinkAnn Johansson/Corbis via Getty ImagesSigal Samuel is a senior reporter for Vox’s Future Perfect and co-host of the Future Perfect podcast. She writes primarily about the future of consciousness, tracking advances in artificial intelligence and neuroscience and their staggering ethical implications. Before joining Vox, Sigal was the religion editor at the Atlantic.DeepMind, an AI research lab that was bought by Google and is now an independent part of Google’s parent company Alphabet, announced a major breakthrough this week that one evolutionary biologist called “a game changer.”“This will change medicine,” the biologist, Andrei Lupas, told Nature. “It will change research. It will change bioengineering. It will change everything.”The breakthrough:DeepMind says its AI system, AlphaFold, has solved the “protein folding problem” — a grand challenge of biology thathas vexed scientists for 50 years.Proteins are the basic machines that get work done in your cells. They start out as strings of amino acids (imagine the beads on a necklace) but they soon fold up into a unique three-dimensional shape (imagine scrunching up the beaded necklace in your hand).That 3D shape is crucial because it determines how the protein works. If you’re a scientist developing a new drug, you want to know the protein’s shape because that will help you come up with a molecule that can bind to it, fittinginto it to alter its behavior. The trouble is, predicting which shape a protein will take is incredibly hard.Every two years, researchers who work on this problem try to prove how good their predictive powers are by submitting a prediction about the shapes that certain proteins will take. Their entries are judged at the Critical Assessment of Structure Prediction (CASP) conference, which is basically a fancy science contest for grown-ups.By 2018, DeepMind’s AI was already outperforming everyone at CASP, provoking some melancholic feelings among the human researchers. DeepMind took home the win that year, but it still hadn’t solved the protein folding problem. Not even close.This year, though, its AlphaFold system was able to predict — with impressive speed and accuracy — what shapes given strings of amino acids would fold up into. The AI is not perfect, but it’s pretty great: When it makes mistakes, it’s generally only off by the width of an atom. That’s comparable to the mistakes you get when you do physical experiments in a lab, except that those experiments are much slower and much more expensive.“This is a big deal,” John Moult, who co-founded and oversees CASP, told Nature. “In some sense the problem is solved.”Why this is a big deal for biologyThe AlphaFold technology still needs to be refined, but assuming the researchers can pull that off, this breakthrough will likely speed up and improve our ability to develop new drugs.Let’s start with the speed. To get a sense of how much AlphaFold can accelerate scientists’ work, consider the experience of Andrei Lupas, an evolutionary biologist at the Max Planck Institute in Germany. He spent a decade — a decade! — trying to figure out the shape of one protein. But no matter what he tried in the lab, the answer eluded him. Then he tried out AlphaFold and he had the answer in half an hour.AlphaFold has implications for everything from Alzheimer’s disease to future pandemics. It can help us understand diseases, since many (like Alzheimer’s) are caused by misfolded proteins. It can help us find new treatments, and also help us quickly determine which existing drugs can be usefully applied to, for example, a new virus. When another pandemic comes along, it could be very helpful to have a system like AlphaFold in our back pocket.“We could start screening every compound that is licensed for use in humans,” Lupas told the New York Times. “We could face the next pandemic with the drugs we already have.”But for this to be possible, DeepMind would have to share its technology with scientists. The lab says it’s exploring ways to do that.Why this is a big deal for artificial intelligenceOver the past few years, DeepMind has made a name for itself by playing games. It has built AI systems that crushed pro gamers at strategy games like StarCraft and Go. Much like the chess matches between IBM’s Deep Blue and Garry Kasparov, these matches mostly served to prove that DeepMind can make an AI that surpasses human abilities.Now, DeepMind is proving that it has grown up. It has graduated from playing video games to addressing scientific problems with real-world significance — problems that can be life-or-death.The protein folding problem was a perfect thing to tackle. DeepMind is a world leader in building neural networks, a type of artificial intelligence loosely inspired by the neurons in a human brain. The beauty of this type of AI is that it doesn’t require you to preprogram it with a lot of rules. Just feed a neural network enough examples of something, and it can learn to detect patterns in the data, then draw inferences based on that.So, for example, you can present it with many thousands of strings of amino acids and show it what shape they folded into. Gradually, it detects patterns in the way given strings tend to shape up — patterns that human experts may not have detected. From there, it can make predictions about how other strings will fold.This is exactly the sort of problem at which neural networks excel, and DeepMind recognized that, marrying the right type of AI to the right type of puzzle. (It also integrated some more complex knowledge — about physics and evolutionarily related amino acid sequences, for example — though the details remain scant as DeepMind is still preparing a peer-reviewed paper for publication.)Other labs have already harnessed the power of neural networks to make breakthroughs in biology. At the beginning of this year, AI researchers trained a neural network by feeding it data on 2,335 molecules known to have antibacterial properties. Then they used it to predict which other molecules — out of 107 million possibilities — would also have these properties. In this way, they managed to identify brand-new types of antibiotics.DeepMind researchers are capping the year with another achievement that shows just how much AI has matured. It’s genuinely great news for a generally terrible 2020.Sign up for the Future Perfect newsletter and we’ll send you a roundup of ideas and solutions for tackling the world’s biggest challenges — and how to get better at doing good.You’ve read 1 article in the last monthHere at Vox, we believe in helping everyone understand our complicated world, so that we can all help to shape it. Our mission is to create clear, accessible journalism to empower understanding and action.If you share our vision, please consider supporting our work by becoming a Vox Member. Your support ensures Vox a stable, independent source of funding to underpin our journalism. If you are not ready to become a Member, even small contributions are meaningful in supporting a sustainable model for journalism.Thank you for being part of our community.Swati SharmaVox Editor-in-ChiefMembershipMonthlyAnnualOne-time$5/month$10/month$25/month$50/monthOther$50/year$100/year$150/year$200/yearOther$20$50$100$250OtherJoin for $5/monthWe accept credit card, Apple Pay, and Google Pay. You can also contribute viaMore in this streamSee allOpenAI insiders are demanding a “right to warn” the public By Sigal SamuelThe double sexism of ChatGPT’s flirty “Her” voiceBy Sigal Samuel“I lost trust”: Why the OpenAI team in charge of safeguarding humanity implodedBy Sigal SamuelMost PopularWhy is the DNC accelerating Joe Biden’s nomination?Project 2025: The myths and the factsAmerica is not ready for what comes nextWeb3 is the future, or a scam, or bothWhat J.D. Vance really believes
1/100:11Vox New Feed





Skip Ad
 
Continue watchingWhat the death of Iran’s president could mean for its futureafter the adVisit Advertiser websiteGO TO PAGEToday, ExplainedUnderstand the world with a daily explainer plus the most compelling stories of the day.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LmRpY2UuY29tL2NhcmVlci1hZHZpY2UvYS1pLXNwZWNpYWxpc3Qtcm9ib3RpY3MtZW5naW5lZXItdG9wLWVtZXJnaW5nLWpvYnMtbGlzdNIBAA?oc=5,"A.I. Specialist, Robotics Engineer Top Emerging Jobs List - Dice Insights",2020-12-02,Dice Insights,https://www.dice.com,Which technology jobs are poised to go from niche to mainstream over the next few years? The answers may surprise you.,N/A,Which technology jobs are poised to go from niche to mainstream over the next few years? The answers may surprise you.,N/A,https://schema.org/,Article,"A.I. Specialist, Robotics Engineer Top Emerging Jobs List",,,2020-12-02T12:38:00Z,,,,"{'@type': 'WebPage', '@id': 'https://www.dice.com/career-advice/a-i-specialist-robotics-engineer-top-emerging-jobs-list'}","{'@type': 'Organization', 'name': 'Dice', 'url': 'https://www.dice.com', 'logo': 'https://www.dice.com/binaries/content/gallery/dice/icons/dice-logo.svg', 'sameAs': ['https://www.linkedin.com/company/dice', 'https://www.facebook.com/dice', 'https://twitter.com/Dicedotcom', 'https://www.instagram.com/dicedotcom', 'https://www.youtube.com/Dice', 'https://www.facebook.com/DiceforEmployers', 'https://twitter.com/Dice4Employers']}",,"{'@type': 'ImageObject', 'url': 'https://www.dice.com/binaries/large/content/gallery/dice/insights/2019/11/shutterstock_1119927341.jpg', 'width': 1200, 'height': 736}",,"{'@type': 'Person', 'name': 'Nick Kolakowski', 'url': 'https://www.dice.com/about/authors/nick-kolakowski'}",,,,Insights,N/A,"
A.I. Specialist, Robotics Engineer Top Emerging Jobs List

                by
                    
                    Nick Kolakowski
                    
Dec 2, 2020
                4 min read
            


Which technology jobs are poised to go from niche to mainstream over the next few years? That’s a vital question to answer, especially for those technologists who spend lots of time and resources acquiring highly specialized skills in arenas such as machine learning and artificial intelligence (A.I.).  
For the third year in a row, LinkedIn has produced an Emerging Jobs Report (PDF) that tries to guess which jobs will experience “tremendous growth” over the next few years. As you might expect, most of these roles are technology-related; once businesses realize that embracing A.I. or data science can mean the difference between wild success and complete implosion, they rush to employ as many technologists as they can.  
LinkedIn’s report concludes that it’s never a bad time to become an engineer or a data scientist: “engineering roles across the board are still seeing tremendous growth. More than 50% of this year’s list was made up of roles related to engineering or development, with the emerging field of robotics appearing for the first time.” Here’s the breakdown of the top positions, along with anticipated growth and the necessary skills for each:   
  
It’s important to highlight how A.I. specialists are poised for rapid expansion over the next few years, in terms of available jobs (it’s no surprise that LinkedIn’s report has them in first place with regard to growth). A.I.-powered tools and applications are increasingly becoming mainstays in many businesses, from banking and healthcare to finance IT and public safety. Some of those apps are consumer-facing; if you’ve ever interacted with a chatbot within a customer-service portal, there’s a good chance it was powered by some kind of machine learning. Others operate in ways the public never sees; for instance, automobile software relies increasingly on computer vision and other A.I. disciplines.   
Thanks to that increasing prevalence, an Analytics Insight report projects more than 20 million available jobs in artificial intelligence by 2023. The pressures of the COVID-19 pandemic have only accelerated company investment in everything related to A.I. and machine learning—which means they need technologists who can wrangle the datasets that make these apps smarter.   
“Organizations need to hire individuals who can identify the correct training data and annotate the data accurately,” Gus Walker, director of product at Veritone, an A.I. tech company based in Costa Mesa, California, recently told Dice. “They need talent that can maintain growing training sets and analyze the data to create targeted datasets for customized model generation.”  
As LinkedIn’s report indicates, data science is also enjoying some serious growth, as more businesses realize the utility of collecting, cleaning, storing, and, finally, analyzing their data for valuable, potentially game-changing insights. According to Burning Glass, which collects and analyzes millions of job postings from across the country, data scientist positions are expected to grow 19 percent over the next 10 years, but landing the best jobs will require learning some highly specialized skills, including data mining, predictive models, and machine learning.  
While specialized skills are key, it’s also important to remember “soft skills” such as communication and empathy, which are essential when it comes to working with teammates and discussing strategy with executives and other stakeholders. No matter what profession you choose, and whether or not that profession goes “mainstream” or stays relatively niche, you should aspire to remain well-rounded in your abilities.   

  
",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vcGcuZWR1LnBsL2VuL25ld3MvMjAyMC0xMi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS13aWxsLWhlbHAtaW5jcmVhc2UtY29tZm9ydC1kZW50aXN0cy13b3Jr0gEA?oc=5,Artificial intelligence will help increase the comfort of dentists' work | Gdańsk University of Technology - Politechnika Gdańska,2020-12-02,Politechnika Gdańska,https://pg.edu.pl,"Scientists from the ETI Faculty of Gdańsk University of Technology are participating in the work on creating a device that works with commonly used dental tips for non-invasive, optical control of the inside of the oral cavity when performing a dental procedure. The project is carried out by Master Level Technologies in cooperation with the GUT special purpose vehicle Excento, as well as Bibus Menos and Lambda System. ",N/A,"Scientists from the ETI Faculty of Gdańsk University of Technology are participating in the work on creating a device that works with commonly used dental tips for non-invasive, optical control of the inside of the oral cavity when performing a dental procedure. The project is carried out by Master Level Technologies in cooperation with the GUT special purpose vehicle Excento, as well as Bibus Menos and Lambda System. ",N/A,https://schema.org,BreadcrumbList,Artificial intelligence will help increase the comfort of dentists&#039; work,https://pg.edu.pl/en,,2020-12-02 08:12+01:00,2020-12-02 08:16+01:00,,,,,,['https://pg.edu.pl/themes/custom/politechnika_gdanska/images/data-types/logo-pl.jpg'],,,"[{'@type': 'ListItem', 'position': 1, 'item': 'https://pg.edu.plhttps://pg.edu.pl/en/news', 'name': 'News'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial intelligence will help increase the comfort of dentists&#039; work'}]",Gdańsk university of technology,"{'@type': 'PostalAddress', 'streetAddress': 'Gabriela Narutowicza 11/12', 'addressLocality': 'Gdańsk', 'addressRegion': 'Pomorskie', 'postalCode': '80-233', 'addressCountry': 'PL'}",N/A,N/A,"








  Date added:
      2020-12-02
  


Artificial intelligence will help increase the comfort of dentists' work






 











Scientists from the ETI Faculty of Gdańsk University of Technology are participating in the work on creating a device that works with commonly used dental tips for non-invasive, optical control of the inside of the oral cavity when performing a dental procedure. The project is carried out by Master Level Technologies in cooperation with the GUT special purpose vehicle Excento, as well as Bibus Menos and Lambda System.


The project was started in 2020. The final result of the work will be a device in the form of a small webcam cooperating with dental tips. The camera will allow the dentist to observe the tooth closely and in real time during the dental procedure. The device will allow the doctor to work more precisely in hard-to-reach places, which will shorten the time of the procedure and potentially reduce the pain associated with it.
– Artificial intelligence algorithms will improve the quality of the video signal observed by the dentist, and will support the dentist in navigating the hard to recognize internal tooth structures during the procedure – explains PhD Daniel Węsierski, R&D manager in the project. – The research team faces many technological challenges. When preparing the tooth with a drill, In the oral cavity there is a high risk of contamination of the microcamera lens. Therefore, our task is to develop a method that will protect the microcamera lens from artifacts. Moreover, clinical operating conditions require that the device is sterile.
The developed solution will have a positive impact not only on the patient, but also on the comfort of dentists' work and will increase its ergonomics. Degenerations and diseases of the locomotor system are a common problem of this professional group. The adoption of a more ergonomic posture by the dentist, the reduction of the time spent on a single patient, or the need for fewer corrections will be significant benefits.
– The idea of came from a dentist friend who, taking into account the limitations of working in a patient’s mouth, instilled a vision of a device that can minimize them - recalls Damian Siupka-Mróz, member of the Management Board of Master Level Technologies, one of the initiators of the project. - It took us about a month to develop the device in the 'proof of concept' version. Thanks to this model, we understood that such device is possible and can actually bring a completely new functionality into the dentist's daily work. So far, we have managed to develop general image parameters, determine the geometry of the system, implement the main assumptions regarding electronics and start working on algorithms that will improve the operation of the system.
Ultimately, the product is to be implemented in the activities of Master Level Technologies Ltd. and will be sold in Poland and the European Union as a ready-made solution for dentists. Academics from the ETI Faculty of Gdańsk University of Technology who are involved in the work on the project include: PhD, Eng. Daniel Węsierski (Project R&D Manager), PhD, Eng. Anna Węsierska (head of the project team), professor Jacek Rumiński (head of the Department of Biomedical Engineering) and PhD, Eng. Paweł Rościszewski.



  311 views






See more



2024-07-15
Almost 455 thousand PLN granted for research on Morse theory




2024-07-11
Gdańsk Tech researchers to develop an innovative technology to remove “forever chemicals” from water and wastewater 




2024-07-09
60 candidates from all over Poland. Talent Scholarships awarded




2024-07-08
NATO at Gdańsk Tech. The University is to become the Alliance's ""Living Lab""




2024-07-08
More than 440 thousand PLN for the university’s internationalization












",,,,,,,,,,,,,https://pg.edu.pl/themes/custom/politechnika_gdanska/images/data-types/logo-pl.jpg,https://pg.edu.pl,,,,,,"{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://pg.edu.pl/search/global?keys={search_term_string}'}, 'query-input': 'required name=search_term_string'}",,"{'@type': 'GeoCoordinates', 'latitude': 54.370867, 'longitude': 18.616314290832513}"
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LmRlbnRpc3RyeXRvZGF5LmNvbS9wYXJ0bmVyc2hpcC1icmluZ3MtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdG8tZGVudGFsLXNjaG9vbC_SAQA?oc=5,Partnership Brings Artificial Intelligence to Dental School - Dentistry Today,2020-12-03,Dentistry Today,https://www.dentistrytoday.com,The AT Still University-Arizona School of Dentistry & Oral Health (ATSU-ASDOH) has teamed up with VideaHealth to bring the company’s VideaTeach artificial intelligence (AI) programming into its dental simulation clinic.,N/A,The AT Still University-Arizona School of Dentistry & Oral Health (ATSU-ASDOH) has teamed up with VideaHealth to bring the company’s VideaTeach artificial intelligence (AI) programming into its dental simulation clinic.,N/A,https://schema.org,,,,,,,,,,,,,,,,,,N/A,N/A,N/A,"[{'@type': 'Article', '@id': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/#article', 'isPartOf': {'@id': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/'}, 'author': {'name': 'Dentistry Today', '@id': 'https://www.dentistrytoday.com/#/schema/person/39749d57006faca6e9aaadfcd799a2e5'}, 'headline': 'Partnership Brings Artificial Intelligence to Dental School', 'datePublished': '2020-12-03T00:33:41+00:00', 'dateModified': '2021-09-30T14:38:24+00:00', 'mainEntityOfPage': {'@id': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/'}, 'wordCount': 319, 'publisher': {'@id': 'https://www.dentistrytoday.com/#organization'}, 'image': {'@id': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/#primaryimage'}, 'thumbnailUrl': 'https://www.dentistrytoday.com/wp-content/uploads/2020/12/fac8f901c024900790303ade134a77b3.jpg', 'keywords': ['AI', 'artificial intelligence', 'AT Still University Arizona School of Dentistry &amp; Oral Health', 'ATSU-ASDOH', 'curriculum', 'dental simulation', 'dental students', 'gamification', 'VideaHealth', 'VideaTeach', 'x-ray'], 'articleSection': ['Industry News'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/', 'url': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/', 'name': 'Partnership Brings Artificial Intelligence to Dental School - Dentistry Today', 'isPartOf': {'@id': 'https://www.dentistrytoday.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/#primaryimage'}, 'image': {'@id': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/#primaryimage'}, 'thumbnailUrl': 'https://www.dentistrytoday.com/wp-content/uploads/2020/12/fac8f901c024900790303ade134a77b3.jpg', 'datePublished': '2020-12-03T00:33:41+00:00', 'dateModified': '2021-09-30T14:38:24+00:00', 'description': 'The AT Still University-Arizona School of Dentistry & Oral Health (ATSU-ASDOH) has teamed up with VideaHealth to bring the company’s VideaTeach artificial intelligence (AI) programming into its dental simulation clinic.', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.dentistrytoday.com/partnership-brings-artificial-intelligence-to-dental-school/#primaryimage', 'url': 'https://www.dentistrytoday.com/wp-content/uploads/2020/12/fac8f901c024900790303ade134a77b3.jpg', 'contentUrl': 'https://www.dentistrytoday.com/wp-content/uploads/2020/12/fac8f901c024900790303ade134a77b3.jpg', 'width': 1250, 'height': 936}, {'@type': 'WebSite', '@id': 'https://www.dentistrytoday.com/#website', 'url': 'https://www.dentistrytoday.com/', 'name': 'Dentistry Today', 'description': '', 'publisher': {'@id': 'https://www.dentistrytoday.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.dentistrytoday.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.dentistrytoday.com/#organization', 'name': 'Dentistry Today', 'url': 'https://www.dentistrytoday.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.dentistrytoday.com/#/schema/logo/image/', 'url': 'https://www.dentistrytoday.com/wp-content/uploads/2021/08/preview-full-DT_NAMEPLATE_2009shadow-2.png', 'contentUrl': 'https://www.dentistrytoday.com/wp-content/uploads/2021/08/preview-full-DT_NAMEPLATE_2009shadow-2.png', 'width': 684, 'height': 136, 'caption': 'Dentistry Today'}, 'image': {'@id': 'https://www.dentistrytoday.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.dentistrytoday.com/#/schema/person/39749d57006faca6e9aaadfcd799a2e5', 'name': 'Dentistry Today', 'sameAs': ['http://dentistrytoday.com']}]",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXdpbGwtcmV2YW1wLWNpdmlsLWVuZ2luZWVycy1jYXJlZXLSAX1odHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hbXAvc3RvcnkvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utd2lsbC1yZXZhbXAtY2l2aWwtZW5naW5lZXJzLWNhcmVlcg?oc=5,Artificial Intelligence will Revamp Civil Engineers’ Career - Analytics Insight,2020-12-04,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,Civil Engineers,Construction Industry,Civil Sector,Machine Learning",AI can improve human life quality and originate novel approaches to solving engineering problems. Artificial intelligence (AI) provides a wide range of current ,AI can improve human life quality and originate novel approaches to solving engineering problems. Artificial intelligence (AI) provides a wide range of current ,http://schema.org,NewsArticle,Artificial Intelligence will Revamp Civil Engineers’ Career,https://www.analyticsinsight.net/artificial-intelligence/artificial-intelligence-will-revamp-civil-engineers-career,2020-12-04T02:30:32Z,2020-12-04T02:30:32Z,2020-12-04T02:30:32Z,Artificial Intelligence,,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/artificial-intelligence-will-revamp-civil-engineers-career'}","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Artificial-Intelligence-2.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Artificial-Intelligence-2.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",,"[{'@type': 'Person', 'givenName': 'Puja Das', 'name': 'Puja Das', 'url': 'https://www.analyticsinsight.net/author/puja-das'}]","[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial Intelligence will Revamp Civil Engineers’ Career', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/artificial-intelligence-will-revamp-civil-engineers-career'}]",Artificial Intelligence will Revamp Civil Engineers’ Career,,N/A,N/A,What is AI and Data Science Engineering? ,,"AI can improve human life quality and originate novel approaches to solving engineering problems..Artificial intelligence (AI) provides a wide range of current society applications, including predicting, classifying, and solving both social and scientific problems. As one of the oldest and most traditional engineering disciplines, civil engineering covers various aspects of the built environment, from design and construction to maintenance. Civil engineering offers ample practical scope for applications of AI. In turn, AI can improve human life quality and originate novel approaches to solving engineering problems..AI methods and techniques, including neural networks, evolutionary computation, fuzzy logic systems, and deep learning, have rapidly evolved over the past few years. AI algorithms have recently attracted close attention from researchers and have also been applied successfully to solve problems in civil engineering, i.e., intelligent and fully automatic urban and regional planning, and developing new technologies in civil engineering design, construction, maintenance, and disaster management..McKinsey's report reveals that the civil construction sector has a net worth of over USD 10 trillion a year. Not only is AI making construction operations more manageable, but it is also set to make the construction business more lucrative. The report also estimates that construction companies integrating AI techniques are 50% more likely to generate profits than those who don't..AI offers a wide range of applications in civil engineering that processes and transforms the way builders and engineers work..Quality Management.Construction enterprises utilize deep-learning techniques to improve the level of quality of their construction processes. Image recognition of photographs gathered through manual drones is used to detect risk areas and is also compared against existing blueprints to identify any possible construction defects. AI algorithms can use trial and error techniques to recognize the best processes, followed through reinforcement learning. By implementing these process changes in project planning and scheduling, construction companies can significantly improve their overall project workflow quality..Stakeholders can also use neural networks and laser-generated images to gain insights into individual construction projects' progress. By using artificial intelligence to create 3D models, they can match them with the original models to check for any quality discrepancies. It can significantly stimulate the decision-making process while also implementing actionable insights..Better Designs.Building Information Modeling is a 3D model-based process that gives architecture, engineering, and construction professionals' insights to efficiently plan, design, construct and manage buildings and infrastructure. The 3D model needs to consider the architecture, engineering, mechanical, electrical, and plumbing (MEP) plans and the sequence of activities of the respective teams to plan and design the construction of a building. The challenge is to make sure that the different sub-teams' different models do not clash with each other. The industry is trying to use machine learning in the form of generative design to recognize and mitigate clashes between the different models generated by the various teams in the planning and design phase to prevent work. Some software uses a machine-learning algorithm to explore all the variations of a solution and generates design alternatives. It leverages machine learning to create 3D models of mechanical, electrical, and plumbing systems while simultaneously ensuring that MEP systems' entire routes do not clash with the building architecture. It learns from iteration to come up with an optimal solution..Prevent Cost Overruns.Most big projects exceed budget despite employing the best project teams. Artificial neural networks are used to predict cost overruns based on factors like project size, contract type, and the competence level of project managers. Predictive models use historical data such as planned start and end dates to envision realistic timelines for future projects. AI helps staff remotely access real-life training material that helps them improve their skills and knowledge quickly. It minimizes the time taken to onboard new resources onto projects. Consequently, project delivery is expedited..Risk Mitigation.Artificial neural networks through artificial intelligence can be useful measures for risk control as they interpret a collection of construction information to draw meaningful conclusions. It helps construction firms predict the likelihood of possible failures, therefore, preparing them to develop appropriate contingency plans..Construction firms can also apply AI techniques to address client and market risk factors. Through the Naive Bayes algorithm, engineers can perform sentiment analysis on their firm's standing in the market and thus come with targeted efforts to prevent stock prices from falling. Other AI algorithms can also be segment customers based on their characteristics and behaviour patterns to deliver better business development strategies, hence preventing them from risks of likely fallout..Making project development faster and more cost-effective, AI has carved a niche for itself in the civil sector. The construction industry is at a point where it is poised at a technological breakthrough in its processes. In this respect, investing in AI courses is bound to provide a competitive edge to anyone who's building a career in civil engineering..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,,,,,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/artificial-intelligence-will-revamp-civil-engineers-career', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Artificial-Intelligence-2.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC0xMC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mdW5kaW5nLWFuZC1pbnZlc3RtZW50cy1vZi0yMDIw0gGBAWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS90b3AtMTAtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZnVuZGluZy1hbmQtaW52ZXN0bWVudHMtb2YtMjAyMA?oc=5,Top 10 Artificial Intelligence Funding and Investments of 2020 - Analytics Insight,2020-12-05,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,AI startups,AI funding,VC funding,COVID-19","Despite slow VC deals as a result of COVID-19, interest in AI funding saw a sustained momentum in 2020. The COVID-19 pandemic has undeniably impacted businesses","Despite slow VC deals as a result of COVID-19, interest in AI funding saw a sustained momentum in 2020. The COVID-19 pandemic has undeniably impacted businesses",http://schema.org,NewsArticle,Top 10 Artificial Intelligence Funding and Investments of 2020,https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-funding-and-investments-of-2020,2020-12-05T06:07:06Z,2020-12-05T06:07:06Z,2020-12-05T06:07:06Z,Artificial Intelligence,,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-funding-and-investments-of-2020'}","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}",https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Artificial-Intelligence-4.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Artificial-Intelligence-4.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",,"[{'@type': 'Person', 'givenName': 'Vivek Kumar', 'name': 'Vivek Kumar', 'url': 'https://www.analyticsinsight.net/author/vivek-kumar'}]","[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 10 Artificial Intelligence Funding and Investments of 2020', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-funding-and-investments-of-2020'}]",Top 10 Artificial Intelligence Funding and Investments of 2020,,N/A,N/A,What is AI and Data Science Engineering? ,,"Despite slow VC deals as a result of COVID-19, interest in AI funding saw a sustained momentum in 2020..The COVID-19 pandemic has undeniably impacted businesses of all sizes and types. It has instigated companies to explore and implement innovative approaches to survive the new normal. Despite the pandemic overwhelmed the industry, enterprises' spending on artificial intelligence continues seeing an upward trend. Many companies have accelerated their IT spending, especially for AI technology, to keep their business going. The year 2020 has been an exciting year in terms of VC deals in growing crops of startups that leverage AI and other advanced technologies..Here's a look at the top 10 artificial intelligence funding and investments of 2020..SentinelOne.Amount Funded: US$267 million.Transaction Type: Series F.Lead Investor(s): Tiger Global Management.Autonomous cybersecurity platform company SentinelOne raised US$267 million in Series F in November. Led by Tiger Global Management with participation from Sequoia Capital Global Equities and existing investors including Insight Partners and Third Point Ventures, the round led the company's funding to US$3.1 billion. The fresh round will enable SentinelOne to continue stimulating hypergrowth driven by demand for its Singularity XDR Platform..SambaNova Systems.Amount Funded: US$250 Million.Transaction Type: Series C.Lead Investor(s): BlackRock.SambaNova Systems is a computing startup focused on building machine learning and big data analytics platforms. In February, the company CA, United States-based company received US$250 million in a Series C funding round for its software-defined AI hardware. The round was led by BlackRock with participation from existing investors including GV, Intel Capital, Walden International, WRVI Capital, and Redline Capital..Olive.Amount Funded: US$225.5 Million.Transaction Type: Venture Round.Lead Investor(s): Tiger Global Management.Olive, a developer of an artificial intelligence workforce for the healthcare industry, has recently closed US$225.5 million in a venture round. The round, which brings the company's valuation to US$1.5 billion, was led by Tiger Global and joined by existing investors General Catalyst, Drive Capital and Silicon Valley Bank along with new backers GV, Sequoia Capital Global Equities, Dragoneer Investment Group and Transformation Capital Partners. Olive intends to use this fresh capital to expedite product development with plans to announce more capabilities in 2021 to support the entire healthcare ecosystem..UiPath.Amount Funded: US$225 Million.Transaction Type: Series E.Lead Investor(s): Alkeon.The leading RPA company, UiPath, in July closed its Series E investment round, raising US$225 million at a post-money valuation of US$10.2 billion. The round was led by Alkeon. Others participating include Accel, Coatue, Dragoneer, IVP, Madrona Venture Group, Sequoia Capital, Tencent, Tiger Global, Wellington, and funds and accounts advised by T. Rowe Price Associates, Inc. With automation now becoming a boardroom imperative with new urgency, UiPath will use this funding to deepen its investment in research and development..Atomwise.Amount Funded: US$123 million.Transaction Type: Series B.Lead Investor(s): B Capital Group, Sanabil.Atomwise, a San Francisco, CA-based startup, uses artificial intelligence to stimulate drug discovery. The company in August raised US$123 million in a Series B funding round. This funding round was led by B Capital Group and Sanabil Investments, along with included returning investors DCVC, BV, Tencent, Y Combinator, Dolby Family Ventures, and AME Cloud Ventures. Reportedly, the company plans to utilize the new funds to help it further scale the largest AI-driven drug discovery portfolio in history and expand its over US$5 billion deal pipeline for small molecule drug discovery..Dataiku.Amount Funded: US$100 million.Transaction Type: Series D.Lead Investor(s): Stripes.Dataiku is a New York-based centralized data platform, which moves businesses along their data journey from analytics at scale to enterprise AI. On August 24, the company secured US$100 million in a Series D funding round that will allow it to expand its platform and offerings to support this worldwide acceleration in Enterprise AI efforts. Led by Stripes with Tiger Global Management joining existing investors Battery Ventures, CapitalG, Dawn Capital, FirstMark Capital, and ICONIQ, the investment comes at a time where hundreds of customers find more value than ever before in Dataiku's offerings..Caption Health.Amount Raised: US$53 Million.Transaction Type: Series B.Lead Investor(s): Data Collective DCVC.Caption Health, a medical company that uses artificial intelligence to interpret ultrasound exams, in July bagged US$53 million in a Series B. The round was led by existing investor DCVC, along with participation from new investors Atlantic Bridge and cardiovascular medical device leader Edwards Lifesciences and existing investor Khosla Ventures. The company has planned to use the funds to scale up its commercial operations, continue to develop its AI technology platform and form new partnerships to expand the use of Caption AI in additional care settings..Deep Instinct.Amount Funded: US$43 Million.Transaction Type: Series C.Lead Investor(s): Millennium Technology Value Partners.Deep Instinct, which applies deep learning to cybersecurity to offer unmatched zero-day attack protection, snagged US$43 million in a Series C in February. Led by Millennium New Horizons, with Unbound (a London-based investment firm founded by Shravin Mittal), LG and Nvidia, brought the company's total funding valuation to US$100 million..Exo.Amount Funded: US$40 million.Transaction Type: Series B.Lead Investor(s): Action Potential Venture Capital, Fiscus Ventures, Reimagined Ventures.Medical device start-up Exo that develops handheld ultrasound devices and AI for imaging and therapeutic applications, announced it closed US$40 million on 20th August, in additional Series B funding round for its AI-driven sonography technology. Exo raised its initial Series B funding of US$35 million in August 2019. According to the company, the new fund will enable for research and development of its piezoelectric micromachined ultrasound transducers technology and AI-driven software..Soul Machine.Amount Funded: US$40 million.Transaction Type: Series B.Lead Investor(s): Temasek Holdings.Soul Machines, which designs intelligent and emotionally responsive avatars, raised US$40 million in Series B in January for AI-powered customer-facing digital avatars. The round was led by Temasek, with participation from Lakestar and existing investors Horizons Ventures, University of Auckland Inventors Fund, Salesforce Ventures, and others..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,,,,,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-funding-and-investments-of-2020', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/12/Artificial-Intelligence-4.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,headline,alternativeHeadline,image,author,url,datePublished,publisher,articleBody,wordcount,article:section,article:summary,article text,mainEntityOfPage,inLanguage,dateModified,hasPart,copyrightHolder,sourceOrganization,copyrightYear,isAccessibleForFree,isPartOf,name,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,itemListElement,articleSection,@graph,issn,potentialAction,thumbnailUrl,dateCreated,abstract,isBasedOn,comment,commentCount,genre,about,discussionURL,isFamilyFriendly,person,publishingPrinciples,timeRequired,wordCount,legalName,address,speakable,specialty,mainContentOFPage,associatedMedia
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vd3d3LmZhcnJlci5jby51ay9uZXdzLWFuZC1pbnNpZ2h0cy9ibG9ncy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1lbXBsb3ltZW50LXRoZS1yZWd1bGF0b3J5LWFuZC1sZWdhbC1sYW5kc2NhcGUv0gEA?oc=5,Artificial Intelligence in employment: the regulatory and legal landscape - Farrer & Co,2023-05-18,Farrer & Co,https://www.farrer.co.uk,"It won’t have escaped your attention that AI is in the news a lot at the moment. Following the release of ChatGPT at the end of 2022, not a week seems to go by without headlines either extolling its benefits or panicking about its risks. Irrespective",,"It won’t have escaped your attention that AI is in the news a lot at the moment. Following the release of ChatGPT at the end of 2022, not a week seems to go by without headlines either extolling its benefits or panicking about its risks. Irrespective of which side of the fence you sit on, what is clear is that rapidly advancing AI is here to stay. With that comes the increasing need to consider AI risk management, particularly in areas where AI has the potential to make or inform decisions about individuals. The field of employment is a prime example of this.  In this blog, we look at the current (though evolving) legal and regulatory landscape in the UK regarding the use of AI in employment, as well as how employers might navigate their way through it.  The regulatory landscape When it comes to worldwide regulation of AI, there is currently no consensus as to approach. While the EU is preparing strict regulation and tough restrictions on the use of AI, with Italy banning ChatGPT over privacy concerns, the UK is planning “an innovative and iterative approach” to regulation. In its recently published White Paper A pro-innovation approach to AI regulation, rather than introducing new legislation the UK Government proposes a system of non-statutory principles overseen and implemented by existing regulators. What this means for the employment sector is that the Government intends to “encourage” the Equality and Human Rights Commission and the Information Commissioner to work with the Employment Agency Standards Inspectorate to issue joint guidance on the use of AI systems in recruitment or employment. In particular, the Government envisages the joint guidance will: Clarify the type of information businesses should provide when implementing AI systems. Identify appropriate supply chain management processes, such as due diligence or AI impact assessments. Suggest proportionate measures for bias detection, mitigation and monitoring. Provide suggestions for the provision of contestability and redress routes. Quite whether this approach is the one that the Government will adopt, however, was left in question following Rishi Sunak’s comments on his way to the G7 Conference. Here he adopted what felt like a more cautious tone, emphasising the need for AI to be used “safely and securely, and with guardrails in place”. Could this be an indication that a move to a more regulated position might be on the cards? For more detailed analysis on the Government’s current White Paper, Ian De Freitas (a partner in our Data, IP and Technology Disputes team), provides helpful commentary in his article Regulating Artificial Intelligence. In the article he explores the five common principles proposed by the Government, assessing them against other recent developments. The legal landscape In the absence of specific legislation governing AI in the workplace, and pending possible guidance, it is important employers understand how existing legal risks and obligations may affect their use of AI. These include: Discrimination: There has been much said about the risk of bias in algorithms and AI creating or replicating existing discrimination: Amazon for example famously had to scrap an AI recruiting tool which taught itself that male candidates were preferable to female. Existing protections from discrimination under the Equality Act 2010 continue to apply to all forms of AI used in employment, and employers should ensure the AI they use is not in breach of that. Acas’ article My boss is an algorithm takes a more detailed look at the ethics of algorithms in the workplace. Data protection: Generative AI, such as ChatGPT, uses the data it is given to identify patterns and create new and original data or content. Any employers using data in this way must ensure they do so in a manner which is compliant with the Data Protection Act 2018 and the UK GDPR. See the ICO’s Guidance on AI and data protection for more information. Monitoring and surveillance: Reports suggest that a third of workers are being digitally monitored at work, for example via remotely controlled webcams or tracking software. Royal Mail for instance recently admitted to using tracking technology to monitor the speed of postal workers. As above, employers should ensure compliance with data protection legislation in any monitoring of its workforce, as well as ensuring it doesn’t breach the right to privacy under the Human Rights Act 1998. Unfair dismissal: Employees with over two years’ service have the right not to be unfairly dismissed under the Employment Rights Act 1996. In the event AI reduces the need for employees to carry out a particular type of work, employers should ensure an appropriate procedure is followed before making any decisions in respect of those staff members. Where dismissal is contemplated, they must ensure that there is a fair reason for dismissal. Care should also be taken to ensure that the way AI is used does not breach the implied term of trust and confidence between employers and employees, since doing so could give employees the right to bring a constructive unfair dismissal claim. What can employers do about AI? We have provided detailed commentary on using AI in employment in two blogs: AI in recruitment Artificial intelligence in the workplace: helpful for harmful? In summary, employers may want to consider the following: Develop a strategy for the use of AI in the workplace, with consideration as when its use is and isn’t acceptable. Introduce a policy (or update existing policies) regarding the appropriate use of AI by staff. Use AI impact assessments to identify and mitigate any risks when introducing AI into the workplace. Retain a human element in decision making, to ensure managers have final responsibility for decisions. Ensure full transparency over when and how AI is used, especially when it impacts employees or potential employees. Deliver training on the use of AI, ensuring it covers issues such as appropriate use of data, accuracy and bias. The changing nature of jobs There is no escaping the fact that AI has the potential to radically transform employment as we know it. Recent reports predict that AI could “replace the equivalent of 300 million full-time jobs”. With that comes concerns about the treatment of workers and the erosion of workers’ rights (for example as highlighted by the TUC in its latest conference). Employers will need to prepare strategically for the changing nature of work and the need to integrate AI into workplace operations. Currently there are likely to be more questions than answers: will there be a need to redesign roles or change work allocation and workflow processes? How can employees be supported in this transition? Is there a need to invest in workforce training to help employees develop the skills needed to work with AI or take on different roles? Regardless, with AI likely to impact most jobs in some way, there is a need for employers to look afresh at their workforce strategies in order to keep pace with the rapid changes that AI might bring. This publication is a general summary of the law. It should not replace legal advice tailored to your specific circumstances. © Farrer & Co LLP, May 2023","It won’t have escaped your attention that AI is in the news a lot at the moment. Following the release of ChatGPT at the end of 2022, not a week seems to go by without headlines either extolling its benefits or panicking about its risks. Irrespective of which side of the fence you sit on, what is clear is that rapidly advancing AI is here to stay. With that comes the increasing need to consider AI risk management, particularly in areas where AI has the potential to make or inform decisions about individuals. The field of employment is a prime example of this.  In this blog, we look at the current (though evolving) legal and regulatory landscape in the UK regarding the use of AI in employment, as well as how employers might navigate their way through it.  The regulatory landscape When it comes to worldwide regulation of AI, there is currently no consensus as to approach. While the EU is preparing strict regulation and tough restrictions on the use of AI, with Italy banning ChatGPT over privacy concerns, the UK is planning “an innovative and iterative approach” to regulation. In its recently published White Paper A pro-innovation approach to AI regulation, rather than introducing new legislation the UK Government proposes a system of non-statutory principles overseen and implemented by existing regulators. What this means for the employment sector is that the Government intends to “encourage” the Equality and Human Rights Commission and the Information Commissioner to work with the Employment Agency Standards Inspectorate to issue joint guidance on the use of AI systems in recruitment or employment. In particular, the Government envisages the joint guidance will: Clarify the type of information businesses should provide when implementing AI systems. Identify appropriate supply chain management processes, such as due diligence or AI impact assessments. Suggest proportionate measures for bias detection, mitigation and monitoring. Provide suggestions for the provision of contestability and redress routes. Quite whether this approach is the one that the Government will adopt, however, was left in question following Rishi Sunak’s comments on his way to the G7 Conference. Here he adopted what felt like a more cautious tone, emphasising the need for AI to be used “safely and securely, and with guardrails in place”. Could this be an indication that a move to a more regulated position might be on the cards? For more detailed analysis on the Government’s current White Paper, Ian De Freitas (a partner in our Data, IP and Technology Disputes team), provides helpful commentary in his article Regulating Artificial Intelligence. In the article he explores the five common principles proposed by the Government, assessing them against other recent developments. The legal landscape In the absence of specific legislation governing AI in the workplace, and pending possible guidance, it is important employers understand how existing legal risks and obligations may affect their use of AI. These include: Discrimination: There has been much said about the risk of bias in algorithms and AI creating or replicating existing discrimination: Amazon for example famously had to scrap an AI recruiting tool which taught itself that male candidates were preferable to female. Existing protections from discrimination under the Equality Act 2010 continue to apply to all forms of AI used in employment, and employers should ensure the AI they use is not in breach of that. Acas’ article My boss is an algorithm takes a more detailed look at the ethics of algorithms in the workplace. Data protection: Generative AI, such as ChatGPT, uses the data it is given to identify patterns and create new and original data or content. Any employers using data in this way must ensure they do so in a manner which is compliant with the Data Protection Act 2018 and the UK GDPR. See the ICO’s Guidance on AI and data protection for more information. Monitoring and surveillance: Reports suggest that a third of workers are being digitally monitored at work, for example via remotely controlled webcams or tracking software. Royal Mail for instance recently admitted to using tracking technology to monitor the speed of postal workers. As above, employers should ensure compliance with data protection legislation in any monitoring of its workforce, as well as ensuring it doesn’t breach the right to privacy under the Human Rights Act 1998. Unfair dismissal: Employees with over two years’ service have the right not to be unfairly dismissed under the Employment Rights Act 1996. In the event AI reduces the need for employees to carry out a particular type of work, employers should ensure an appropriate procedure is followed before making any decisions in respect of those staff members. Where dismissal is contemplated, they must ensure that there is a fair reason for dismissal. Care should also be taken to ensure that the way AI is used does not breach the implied term of trust and confidence between employers and employees, since doing so could give employees the right to bring a constructive unfair dismissal claim. What can employers do about AI? We have provided detailed commentary on using AI in employment in two blogs: AI in recruitment Artificial intelligence in the workplace: helpful for harmful? In summary, employers may want to consider the following: Develop a strategy for the use of AI in the workplace, with consideration as when its use is and isn’t acceptable. Introduce a policy (or update existing policies) regarding the appropriate use of AI by staff. Use AI impact assessments to identify and mitigate any risks when introducing AI into the workplace. Retain a human element in decision making, to ensure managers have final responsibility for decisions. Ensure full transparency over when and how AI is used, especially when it impacts employees or potential employees. Deliver training on the use of AI, ensuring it covers issues such as appropriate use of data, accuracy and bias. The changing nature of jobs There is no escaping the fact that AI has the potential to radically transform employment as we know it. Recent reports predict that AI could “replace the equivalent of 300 million full-time jobs”. With that comes concerns about the treatment of workers and the erosion of workers’ rights (for example as highlighted by the TUC in its latest conference). Employers will need to prepare strategically for the changing nature of work and the need to integrate AI into workplace operations. Currently there are likely to be more questions than answers: will there be a need to redesign roles or change work allocation and workflow processes? How can employees be supported in this transition? Is there a need to invest in workforce training to help employees develop the skills needed to work with AI or take on different roles? Regardless, with AI likely to impact most jobs in some way, there is a need for employers to look afresh at their workforce strategies in order to keep pace with the rapid changes that AI might bring. This publication is a general summary of the law. It should not replace legal advice tailored to your specific circumstances. © Farrer & Co LLP, May 2023",http://schema.org,Article,Artificial Intelligence in employment: the regulatory and legal landscape,Artificial Intelligence in employment: the regulatory and legal landscape,https://www.farrer.co.uk/globalassets/clients-and-sectors/businesses/shift-abstract.jpg,"[{'@type': 'Person', 'familyName': 'Hunt', 'givenName': 'David', 'name': 'David Hunt'}, {'@type': 'Person', 'familyName': 'Wren', 'givenName': 'Amy', 'name': 'Amy Wren'}]",https://www.farrer.co.uk/news-and-insights/blogs/artificial-intelligence-in-employment-the-regulatory-and-legal-landscape/,5/18/2023 11:05:11 AM,"{'@type': 'Organization', 'name': 'Farrer & Co', 'url': 'https://www.farrer.co.uk/', 'logo': {'@type': 'ImageObject', 'url': 'https://www.farrer.co.uk/static/images/assets/print-logo.png'}}","It won’t have escaped your attention that AI is in the news a lot at the moment. Following the release of ChatGPT at the end of 2022, not a week seems to go by without headlines either extolling its benefits or panicking about its risks. Irrespective of which side of the fence you sit on, what is clear is that rapidly advancing AI is here to stay. With that comes the increasing need to consider AI risk management, particularly in areas where AI has the potential to make or inform decisions about individuals. The field of employment is a prime example of this.&#160; In this blog, we look at the current (though evolving) legal and regulatory landscape in the UK regarding the use of AI in employment, as well as how employers might navigate their way through it.&#160; The regulatory landscape When it comes to worldwide regulation of AI, there is currently no consensus as to approach. While the EU is preparing strict regulation and tough restrictions on the use of AI, with Italy banning ChatGPT over privacy concerns, the UK is planning “an innovative and iterative approach” to regulation. In its recently published White Paper A pro-innovation approach to AI regulation, rather than introducing new legislation the UK Government proposes a system of non-statutory principles overseen and implemented by existing regulators. What this means for the employment sector is that the Government intends to “encourage” the Equality and Human Rights Commission and the Information Commissioner to work with the Employment Agency Standards Inspectorate to issue joint guidance on the use of AI systems in recruitment or employment. In particular, the Government envisages the joint guidance will: Clarify the type of information businesses should provide when implementing AI systems. Identify appropriate supply chain management processes, such as due diligence or AI impact assessments. Suggest proportionate measures for bias detection, mitigation and monitoring. Provide suggestions for the provision of contestability and redress routes. Quite whether this approach is the one that the Government will adopt, however, was left in question following Rishi Sunak’s comments on his way to the G7 Conference. Here he adopted what felt like a more cautious tone, emphasising the need for AI to be used “safely and securely, and with guardrails in place”. Could this be an indication that a move to a more regulated position might be on the cards? For more detailed analysis on the Government’s current White Paper, Ian De Freitas (a partner in our Data, IP and Technology Disputes team), provides helpful commentary in his article Regulating Artificial Intelligence. In the article he explores the five common principles proposed by the Government, assessing them against other recent developments. The legal landscape In the absence of specific legislation governing AI in the workplace, and pending possible guidance, it is important employers understand how existing legal risks and obligations may affect their use of AI. These include: Discrimination: There has been much said about the risk of bias in algorithms and AI creating or replicating existing discrimination: Amazon for example famously had to scrap an AI recruiting tool which taught itself that male candidates were preferable to female. Existing protections from discrimination under the Equality Act 2010 continue to apply to all forms of AI used in employment, and employers should ensure the AI they use is not in breach of that. Acas’ article My boss is an algorithm takes a more detailed look at the ethics of algorithms in the workplace. Data protection: Generative AI, such as ChatGPT, uses the data it is given to identify patterns and create new and original data or content. Any employers using data in this way must ensure they do so in a manner which is compliant with the Data Protection Act 2018 and the UK GDPR. See the ICO’s Guidance on AI and data protection for more information. Monitoring and surveillance: Reports suggest that a third of workers are being digitally monitored at work, for example via remotely controlled webcams or tracking software. Royal Mail for instance recently admitted to using tracking technology to monitor the speed of postal workers. As above, employers should ensure compliance with data protection legislation in any monitoring of its workforce, as well as ensuring it doesn’t breach the right to privacy under the Human Rights Act 1998. Unfair dismissal: Employees with over two years’ service have the right not to be unfairly dismissed under the Employment Rights Act 1996. In the event AI reduces the need for employees to carry out a particular type of work, employers should ensure an appropriate procedure is followed before making any decisions in respect of those staff members. Where dismissal is contemplated, they must ensure that there is a fair reason for dismissal. Care should also be taken to ensure that the way AI is used does not breach the implied term of trust and confidence between employers and employees, since doing so could give employees the right to bring a constructive unfair dismissal claim. What can employers do about AI? We have provided detailed commentary on using AI in employment in two blogs: AI in recruitment Artificial intelligence in the workplace: helpful for harmful? In summary, employers may want to consider the following: Develop a strategy for the use of AI in the workplace, with consideration as when its use is and isn’t acceptable. Introduce a policy (or update existing policies) regarding the appropriate use of AI by staff. Use AI impact assessments to identify and mitigate any risks when introducing AI into the workplace. Retain a human element in decision making, to ensure managers have final responsibility for decisions. Ensure full transparency over when and how AI is used, especially when it impacts employees or potential employees. Deliver training on the use of AI, ensuring it covers issues such as appropriate use of data, accuracy and bias. The changing nature of jobs There is no escaping the fact that AI has the potential to radically transform employment as we know it. Recent reports predict that AI could “replace the equivalent of 300 million full-time jobs”. With that comes concerns about the treatment of workers and the erosion of workers’ rights (for example as highlighted by the TUC in its latest conference). Employers will need to prepare strategically for the changing nature of work and the need to integrate AI into workplace operations. Currently there are likely to be more questions than answers: will there be a need to redesign roles or change work allocation and workflow processes? How can employees be supported in this transition? Is there a need to invest in workforce training to help employees develop the skills needed to work with AI or take on different roles? Regardless, with AI likely to impact most jobs in some way, there is a need for employers to look afresh at their workforce strategies in order to keep pace with the rapid changes that AI might bring. This publication is a general summary of the law. It should not replace legal advice tailored to your specific circumstances. &#169; Farrer &amp; Co LLP, May 2023",1181,N/A,N/A,"

Artificial Intelligence in employment: the regulatory and legal landscape
Blog
18.05.2023        






It won’t have escaped your attention that AI is in the news a lot at the moment. Following the release of ChatGPT at the end of 2022, not a week seems to go by without headlines either extolling its benefits or panicking about its risks.
Irrespective of which side of the fence you sit on, what is clear is that rapidly advancing AI is here to stay. With that comes the increasing need to consider AI risk management, particularly in areas where AI has the potential to make or inform decisions about individuals. The field of employment is a prime example of this. 
In this blog, we look at the current (though evolving) legal and regulatory landscape in the UK regarding the use of AI in employment, as well as how employers might navigate their way through it. 
The regulatory landscape
When it comes to worldwide regulation of AI, there is currently no consensus as to approach. While the EU is preparing strict regulation and tough restrictions on the use of AI, with Italy banning ChatGPT over privacy concerns, the UK is planning “an innovative and iterative approach” to regulation.
In its recently published White Paper A pro-innovation approach to AI regulation, rather than introducing new legislation the UK Government proposes a system of non-statutory principles overseen and implemented by existing regulators.
What this means for the employment sector is that the Government intends to “encourage” the Equality and Human Rights Commission and the Information Commissioner to work with the Employment Agency Standards Inspectorate to issue joint guidance on the use of AI systems in recruitment or employment. In particular, the Government envisages the joint guidance will:

Clarify the type of information businesses should provide when implementing AI systems.
Identify appropriate supply chain management processes, such as due diligence or AI impact assessments.
Suggest proportionate measures for bias detection, mitigation and monitoring.
Provide suggestions for the provision of contestability and redress routes.

Quite whether this approach is the one that the Government will adopt, however, was left in question following Rishi Sunak’s comments on his way to the G7 Conference. Here he adopted what felt like a more cautious tone, emphasising the need for AI to be used “safely and securely, and with guardrails in place”. Could this be an indication that a move to a more regulated position might be on the cards?
For more detailed analysis on the Government’s current White Paper, Ian De Freitas (a partner in our Data, IP and Technology Disputes team), provides helpful commentary in his article Regulating Artificial Intelligence. In the article he explores the five common principles proposed by the Government, assessing them against other recent developments.
The legal landscape
In the absence of specific legislation governing AI in the workplace, and pending possible guidance, it is important employers understand how existing legal risks and obligations may affect their use of AI. These include:

Discrimination: There has been much said about the risk of bias in algorithms and AI creating or replicating existing discrimination: Amazon for example famously had to scrap an AI recruiting tool which taught itself that male candidates were preferable to female. Existing protections from discrimination under the Equality Act 2010 continue to apply to all forms of AI used in employment, and employers should ensure the AI they use is not in breach of that. Acas’ article My boss is an algorithm takes a more detailed look at the ethics of algorithms in the workplace.
Data protection: Generative AI, such as ChatGPT, uses the data it is given to identify patterns and create new and original data or content. Any employers using data in this way must ensure they do so in a manner which is compliant with the Data Protection Act 2018 and the UK GDPR. See the ICO’s Guidance on AI and data protection for more information.
Monitoring and surveillance: Reports suggest that a third of workers are being digitally monitored at work, for example via remotely controlled webcams or tracking software. Royal Mail for instance recently admitted to using tracking technology to monitor the speed of postal workers. As above, employers should ensure compliance with data protection legislation in any monitoring of its workforce, as well as ensuring it doesn’t breach the right to privacy under the Human Rights Act 1998.
Unfair dismissal: Employees with over two years’ service have the right not to be unfairly dismissed under the Employment Rights Act 1996. In the event AI reduces the need for employees to carry out a particular type of work, employers should ensure an appropriate procedure is followed before making any decisions in respect of those staff members. Where dismissal is contemplated, they must ensure that there is a fair reason for dismissal. Care should also be taken to ensure that the way AI is used does not breach the implied term of trust and confidence between employers and employees, since doing so could give employees the right to bring a constructive unfair dismissal claim.

What can employers do about AI?
We have provided detailed commentary on using AI in employment in two blogs:

AI in recruitment
Artificial intelligence in the workplace: helpful for harmful?

In summary, employers may want to consider the following:

Develop a strategy for the use of AI in the workplace, with consideration as when its use is and isn’t acceptable.
Introduce a policy (or update existing policies) regarding the appropriate use of AI by staff.
Use AI impact assessments to identify and mitigate any risks when introducing AI into the workplace.
Retain a human element in decision making, to ensure managers have final responsibility for decisions.
Ensure full transparency over when and how AI is used, especially when it impacts employees or potential employees.
Deliver training on the use of AI, ensuring it covers issues such as appropriate use of data, accuracy and bias.

The changing nature of jobs
There is no escaping the fact that AI has the potential to radically transform employment as we know it. Recent reports predict that AI could “replace the equivalent of 300 million full-time jobs”. With that comes concerns about the treatment of workers and the erosion of workers’ rights (for example as highlighted by the TUC in its latest conference).
Employers will need to prepare strategically for the changing nature of work and the need to integrate AI into workplace operations. Currently there are likely to be more questions than answers: will there be a need to redesign roles or change work allocation and workflow processes? How can employees be supported in this transition? Is there a need to invest in workforce training to help employees develop the skills needed to work with AI or take on different roles? Regardless, with AI likely to impact most jobs in some way, there is a need for employers to look afresh at their workforce strategies in order to keep pace with the rapid changes that AI might bring.
This publication is a general summary of the law. It should not replace legal advice tailored to your specific circumstances.
© Farrer & Co LLP, May 2023


Want to know more?

                Contact us
            


Share this article




Twitter









LinkedIn









Email









Facebook








About the authors

 David Hunt
Partner
David advises employer clients, with a particular focus on the financial services and sport sectors, on a wide range of contentious and non-contentious employment issues. He also acts for individuals in relation to contract and exit negotiations and advises them on matters relating to restrictive covenants. 
David advises employer clients, with a particular focus on the financial services and sport sectors, on a wide range of contentious and non-contentious employment issues. He also acts for individuals in relation to contract and exit negotiations and advises them on matters relating to restrictive covenants. 




David's profile page




Email David




+44 (0)20 3375 7214




 Amy Wren
Senior Counsel
Amy is a Senior Counsel and Knowledge Lawyer in the employment team, providing expert technical legal support to the team and leading its know-how function. Given the fast-changing nature of employment law, Amy ensures the team is at the forefront of all legal changes and can provide the best possible advice to our clients.
Amy is a Senior Counsel and Knowledge Lawyer in the employment team, providing expert technical legal support to the team and leading its know-how function. Given the fast-changing nature of employment law, Amy ensures the team is at the forefront of all legal changes and can provide the best possible advice to our clients.




Amy's profile page




Email Amy




+44 (0)20 3375 7627







Authors

 

David Hunt, Partner




Email David




+44 (0)20 3375 7214




 

Amy Wren, Senior Counsel




Email Amy




+44 (0)20 3375 7627




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjMvMDUvMjAvYnVzaW5lc3MvZGVhbGJvb2svdGhlLW9wdGltaXN0cy1ndWlkZS10by1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hbmQtd29yay5odG1s0gEA?oc=5,The Optimist's Guide to Artificial Intelligence and Work (Published 2023) - The New York Times,2023-05-20,The New York Times,https://www.nytimes.com,"The focus of much discussion is on how it will replace jobs, but nothing is inevitable.",N/A,"The focus of much discussion is on how it will replace jobs, but nothing is inevitable.","The focus of much discussion is on how it will replace jobs, but nothing is inevitable.",https://schema.org,BreadcrumbList,The Optimist’s Guide to Artificial Intelligence and Work,The Optimist’s Guide to A.I. And Its Value in the Workplace,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/05/22/business/20DB-AI-print/20DB-AI-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2023/05/22/business/20DB-AI-print/20DB-AI-videoSixteenByNineJumbo1600.jpg', 'caption': 'Sam Altman, chief executive of OpenAI, testified before a Senate subcommittee on Tuesday.', 'creditText': 'Win McNamee/Getty Images'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/05/22/business/20DB-AI-print/20DB-AI-superJumbo.jpg', 'height': 1366, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2023/05/22/business/20DB-AI-print/20DB-AI-superJumbo.jpg', 'caption': 'Sam Altman, chief executive of OpenAI, testified before a Senate subcommittee on Tuesday.', 'creditText': 'Win McNamee/Getty Images'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/05/22/business/20DB-AI-print/20DB-AI-mediumSquareAt3X.jpg', 'height': 1801, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2023/05/22/business/20DB-AI-print/20DB-AI-mediumSquareAt3X.jpg', 'caption': 'Sam Altman, chief executive of OpenAI, testified before a Senate subcommittee on Tuesday.', 'creditText': 'Win McNamee/Getty Images'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/sarah-kessler', 'name': 'Sarah Kessler'}, {'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/ephrat-livni', 'name': 'Ephrat Livni'}]",https://www.nytimes.com/,2023-05-20T12:00:03.000Z,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,,Business,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTDealBook Business and PolicySupported bySKIP ADVERTISEMENTDealBOok NewsletterThe Optimist’s Guide to Artificial Intelligence and WorkThe focus of much discussion is on how it will replace jobs, but nothing is inevitable.Share full articleRead in appSam Altman, chief executive of OpenAI, testified before a Senate subcommittee on Tuesday.Credit...Win McNamee/Getty ImagesBy Sarah Kessler and Ephrat LivniMay 20, 2023Leer en españolIt’s easy to fear that the machines are taking over: Companies like IBM and the British telecommunications company BT have cited artificial intelligence as a reason for reducing head count, and new tools like ChatGPT and DALL-E make it possible for anyone to understand the extraordinary abilities of artificial intelligence for themselves. One recent study from researchers at OpenAI (the start-up behind ChatGPT) and the University of Pennsylvania concluded that for about 80 percent of jobs, at least 10 percent of tasks could be automated using the technology behind such tools.“Everybody I talk to, supersmart people, doctors, lawyers, C.E.O.s, other economists, your brain just first goes to, ‘Oh, how can generative A.I. replace this thing that humans are doing?’” said Erik Brynjolfsson, a professor at the Stanford Institute for Human-Centered AI.But that’s not the only option, he said. “The other thing that I wish people would do more of is think about what new things could be done now that was never done before. Obviously that’s a much harder question.” It is also, he added, “where most of the value is.”How technology makers design, business leaders use and policymakers regulate A.I. tools will determine how generative A.I. ultimately affects jobs, Brynjolfsson and other economists say. And not all the choices are necessarily bleak for workers.AdvertisementSKIP ADVERTISEMENTA.I. can complement human labor rather than replace it. Plenty of companies use A.I. to automate call centers, for instance. But a Fortune 500 company that provides business software has instead used a tool like ChatGPT to give its workers live suggestions for how to respond to customers. Brynjolfsson and his co-authors of a study compared the call center employees who used the tool to those who didn’t. They found that the tool boosted productivity by 14 percent on average, with most of the gains made by low-skilled workers. Customer sentiment was also higher and employee turnover lower in the group that used the tool.David Autor, a professor of economics at the Massachusetts Institute of Technology, said that A.I. could potentially be used to deliver “expertise on tap” in jobs like health care delivery, software development, law, and skilled repair. “That offers an opportunity to enable more workers to do valuable work that relies on some of that expertise,” he said.Workers can focus on different tasks. As A.T.M.s automated the tasks of dispensing cash and taking deposits, the number of bank tellers increased, according to an analysis by James Bessen, a researcher at the Boston University School of Law. This was partly because while bank branches required fewer workers, they became cheaper to open — and banks opened more of them. But banks also changed the job description. After A.T.M.s, tellers focused less on counting cash and more on building relationships with customers, to whom they sold products like credit cards. Few jobs can be completely automated by generative A.I. But using an A.I. tool for some tasks may free up workers to expand their work on tasks that can’t be automated.Editors’ Picks‘I Was Settling Into My Morning Commute on the 4 Train’ July 21, 2024The Best and Worst Habits for Your Teeth July 12, 2024What Responsibility Do I Have to Ensure the Safety of an Illicit Cat? July 17, 2024New technology can lead to new jobs. Farming employed nearly 42 percent of the work force in 1900, but because of automation and advances in technology, it accounted for just 2 percent by 2000. The huge reduction in farming jobs didn’t result in widespread unemployment. Instead, technology created a lot of new jobs. A farmer in the early 20th century would not have imagined computer coding, genetic engineering or trucking. In an analysis that used census data, Autor and his co-authors found that 60 percent of current occupational specialties did not exist 80 years ago.Of course, there’s no guarantee that workers will be qualified for new jobs, or that they’ll be good jobs. And none of this just happens, said Daron Acemoglu, an economics professor at M.I.T. and a co-author of “Power and Progress: Our 1,000-Year Struggle Over Technology & Prosperity.”“If we make the right choices, then we do create new types of jobs, which is crucial for wage growth and also for truly reaping the productivity benefits,” Acemoglu said. “But if we do not make the right choices, much less of this can happen.” — Sarah KesslerAdvertisementSKIP ADVERTISEMENTIN CASE YOU MISSED IT Martha’s model behavior. The lifestyle entrepreneur Martha Stewart became the oldest person to be featured on the cover of Sports Illustrated’s swimsuit issue this week. Stewart, 81, told The Times that it was a “large challenge” to have the confidence to pose but that two months of Pilates had helped. She isn’t the first person over 60 to have the distinction: Maye Musk, the mother of Elon Musk, graced the cover last year at the age of 74.TikTok block. Montana became the first state to ban the Chinese short video app, barring app stores from offering TikTok within its borders starting Jan. 1. The ban is expected to be difficult to enforce, and TikTok users in the state have sued the government, saying the measure violates their First Amendment rights and giving a glimpse of the potential blowback if the federal government tries to block TikTok nationwide.Banker blame game. Greg Becker, the ex-C.E.O. of Silicon Valley Bank, blamed “rumors and misconceptions” for a run on deposits in his first public comments since the lender collapsed in March. Becker and former top executives of the failed Signature Bank also told a Senate committee investigating their role in the collapse of the banks that they would not give back millions of dollars in pay.ImageA brief history of tech C.E.O.s seeking constraints When OpenAI’s chief executive, Sam Altman, testified in Congress this week and called for regulation of generative artificial intelligence, some lawmakers hailed it as a “historic” move. In fact, asking lawmakers for new rules is a move straight out of the tech industry playbook. Silicon Valley’s most powerful executives have long gone to Washington to demonstrate their commitment to rules in an attempt to shape them while simultaneously unleashing some of the world’s most powerful and transformative technologies without pause.One reason: A federal rule is much easier to manage than different regulations in different states, Bruce Mehlman, a political consultant and former technology policy official in the Bush administration, told DealBook. Clearer regulations also give investors more confidence in a sector, he added.The strategy sounds sensible, but if history is a useful guide, the reality can be messier than the rhetoric:In December 2021, Sam Bankman-Fried, founder of the failed crypto exchange FTX, was one of six executives to testify about digital assets in the House and call for regulatory clarity. His company had just submitted a proposal for a “unified joint regime,” he told lawmakers. A year later, Bankman-Fried’s businesses were bankrupt, and he was facing criminal fraud and illegal campaign contribution charges.In 2019, Facebook founder Mark Zuckerberg wrote an opinion piece in The Washington Post, “The Internet Needs New Rules,” based on failures in content moderation, election integrity, privacy and data management at the company. Two years later, independent researchers found that misinformation was more rampant on the platform than in 2016, even though the company had spent billions trying to stamp it out.In 2018, the Apple chief Tim Cook said he was generally averse to regulation but supported more strict data privacy rules, saying, “It’s time for a set of people to think about what can be done.” But to maintain its business in China, one of its biggest markets, Apple has largely ceded control of customer data to the government as part of its requirements to operate there.AdvertisementSKIP ADVERTISEMENTBuzzword of the week: ‘Algospeak’ Platforms like TikTok, Facebook, Instagram and Twitter use algorithms to identify and moderate problematic content. To avert these digital moderators and allow free exchange about taboo topics, a linguistic code has developed. It’s called “algospeak.”AdvertisementSKIP ADVERTISEMENT“A linguistic arms race is raging online — and it isn’t clear who’s winning,” writes Roger J. Kreuz, a psychology professor at the University of Memphis. Posts about sensitive issues like politics, sex or suicide can be flagged by algorithms and taken down, leading to the use of creative misspellings and stand-ins, like “seggs” and “mascara” for sex, “unalive” for death and “cornucopia” for homophobia. There is a history of responding to prohibitions with code, Kruz notes, such as 19th-century Cockney rhyming slang in England or “Aesopian,” an allegorical language used to circumvent censorship in Tsarist Russia.Algorithms aren’t alone in not picking up on the code. The euphemisms and misspellings are particularly ubiquitous among marginalized communities. But the hidden language also sometimes eludes humans, leading to potentially fraught miscommunications online. In February, the celebrity Julia Fox found herself in an awkward exchange with a victim of sexual assault after misunderstanding a post about “mascara” and had to issue a public apology for responding inappropriately to what she thought was a discussion about makeup.ImageThanks for reading!We’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.Sarah Kessler is a senior staff editor for DealBook and the author of “Gigged,” a book about workers in the gig economy. More about Sarah KesslerEphrat Livni reports from Washington on the intersection of business and policy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced law in the public and private sectors.   More about Ephrat LivniA version of this article appears in print on May 22, 2023, Section B, Page 4 of the New York edition with the headline: The Optimist’s Guide to A.I. And Its Value in the Workplace. Order Reprints | Today’s Paper | SubscribeShare full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",https://www.nytimes.com/2023/05/20/business/dealbook/the-optimists-guide-to-artificial-intelligence-and-work.html,en,2023-05-20T17:55:13.000Z,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",The New York Times,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Business', 'position': 1, 'item': 'https://www.nytimes.com/section/business'}, {'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'DealBook', 'position': 2, 'item': 'https://www.nytimes.com/section/business/dealbook'}]",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8veW91Z292LmNvLnVrL3RlY2hub2xvZ3kvYXJ0aWNsZXMvNDU3MzAtYnJpdG9ucy10aGluay1haS13aWxsLWNvc3Qtam9icy1ub3QtdGhlaXItb3du0gEA?oc=5,Britons think artificial intelligence will cost jobs… but not their own - YouGov,2023-05-19,YouGov,https://yougov.co.uk,Six in ten expect more jobs will be lost to robotics and AI than will be created,N/A,Six in ten expect more jobs will be lost to robotics and AI than will be created,N/A,https://schema.org,Article,Britons think artificial intelligence will cost jobs… but not their own,,https://ygo-assets-websites-editorial-emea.yougov.net/images/AI_7eWe61b.original.jpg,"[{'@type': 'Person', 'name': 'Matthew Smith', 'jobTitle': 'Head of Data Journalism', 'image': 'https://dnc08nwcya6mg.cloudfront.net/original_images/Matthew_Smith_close.jpg'}]",,2023-05-19T12:39:21Z,"{'@type': 'Organization', 'name': 'YouGov', 'email': 'info@yougov.com', 'logo': 'https://d3nkl3psvxxpe9.cloudfront.net/original_images/yougov-logo.png'}","<section _ngcontent-yg-app-c2921605343="""" yglightbox="""" class=""cms-content-viewer""><div _ngcontent-yg-app-c2921605343="""" class=""inner-html""><h2>Six in ten expect more jobs will be lost to robotics and AI than will be created</h2><p>BT <a href=""https://www.bbc.co.uk/news/business-65631168"">will reportedly be shedding up to 55,000 jobs</a> by the end of the decade with up to a fifth replaced by technologies including artificial intelligence.</p><p>The results of a new YouGov poll show that almost two thirds of Britons (64%) believe “more jobs will be lost to automation by robotics/AI than will be created”, with a mere 7% expecting they will create more opportunities than they close down. One in eight (12%) expect numbers will remain about the same, while 17% are unsure.</p><p>Among workers themselves, 62% expect more jobs to be lost than gained. Yet when they are asked whether jobs like their own will primarily be done by humans or by robots or AI 30 years from now, the majority (59%) still see a human future. Only a quarter (25%) expect their line of work to become dominated by machines.</p></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><yg-embed _ngcontent-yg-app-c2921605343="""" _nghost-yg-app-c477895173="""" class=""ng-star-inserted""><div _ngcontent-yg-app-c477895173="""" data-cy=""embed-content"" class=""inner-html""><div>
    <iframe title=""Britons think AI will cost jobs… but not their own"" aria-label=""Bar Chart"" id=""datawrapper-chart-RXC7P"" src=""https://datawrapper.dwcdn.net/RXC7P/2/"" scrolling=""no"" frameborder=""0"" style=""width: 0; min-width: 100% !important; border: none;"" height=""718"" data-external=""1""></iframe>
</div>
</div><!----></yg-embed><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div _ngcontent-yg-app-c2921605343="""" class=""inner-html""><p>Likewise, few workers say they are worried about the impact that robotics or artificial intelligence will have on their current job (14%) or their future career (22%).</p><p>Younger workers – who have much more career still to get through – are unsurprisingly more likely to be worried than those who are on the cusp of aging out of working life. Even so, 18-24 year old workers are still more likely to be unworried (48%) than worried (36%), including only 7% who are “very worried”.</p><p>Among those workers who specifically think that more jobs will be lost to automation than will be created, 65% say they aren’t worried about the impact on their own career.</p><h3>How much do Britons think they understand about AI?</h3><p>Half of Britons say they either know a great deal (7%) or a fair amount (44%) about what artificial intelligence is, while 41% say they don’t know very much and 5% say they know nothing at all.</p><p>Slightly fewer people (41%) claim to know much about “the issues surrounding artificial intelligence”.</p><p>As is generally the case in opinion polls, men are more likely than women to claim greater knowledge, and in this case younger people are more likely to feel they have a grip on the topic than their elders.</p></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><yg-embed _ngcontent-yg-app-c2921605343="""" _nghost-yg-app-c477895173="""" class=""ng-star-inserted""><div _ngcontent-yg-app-c477895173="""" data-cy=""embed-content"" class=""inner-html""><div>
    <iframe title=""How many Britons think they understand about artificial intelligence?"" aria-label=""Split Bars"" id=""datawrapper-chart-YmjR4"" src=""https://datawrapper.dwcdn.net/YmjR4/2/"" scrolling=""no"" frameborder=""0"" style=""width: 0; min-width: 100% !important; border: none;"" height=""419"" data-external=""1""></iframe>
</div>
</div><!----></yg-embed><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div _ngcontent-yg-app-c2921605343="""" class=""inner-html""><p>When it comes to the overall impact that artificial intelligence will have, Britons are more likely to be pessimistic (35%) than optimistic (19%), with a further 34% saying they are neither optimistic or pessimistic.</p></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><yg-embed _ngcontent-yg-app-c2921605343="""" _nghost-yg-app-c477895173="""" class=""ng-star-inserted""><div _ngcontent-yg-app-c477895173="""" data-cy=""embed-content"" class=""inner-html""><div>
    <iframe title=""How does perceived familiarity with the issues surrounding AI affect optimism about the technology?"" aria-label=""Stacked Bars"" id=""datawrapper-chart-mW0x2"" src=""https://datawrapper.dwcdn.net/mW0x2/1/"" scrolling=""no"" frameborder=""0"" style=""width: 0; min-width: 100% !important; border: none;"" height=""342"" data-external=""1""></iframe>
</div>
</div><!----></yg-embed><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div _ngcontent-yg-app-c2921605343="""" class=""inner-html""><p>The more familiar a person feels they are with the issues surrounding AI, the more likely they are to have either optimistic or pessimistic expectations for the technology – although the optimistic side grows far more rapidly with awareness. While only 5% of those who confess no understanding of the issues around AI say they are optimistic about the tech, fully 28% have a negative view. Among those who consider themselves to have a great deal of understanding, there is a 35pt increase to 40% with an optimistic view, compared to a 15pt increase to 43% holding a negative view.</p><h3>Most Britons lack confidence in tech companies and government on AI</h3><p>Earlier this week, the CEO of OpenAI (the firm which owns ChatGPT) <a href=""https://www.washingtonpost.com/technology/2023/05/16/sam-altman-open-ai-congress-hearing/"">told a US Congress hearing</a> that AI could “cause significant harm to the world”, expressing willingness to work with lawmakers regarding his own company’s technology, and made a number of proposals for how to regulate artificial intelligence.</p><p>The British public is, however, sceptical that those able to influence the future of AI can be trusted to do so.</p><p>Two thirds of Britons say they have little to no confidence that technology companies that are developing AI will do so responsibly (66%), or in the ability of current and future UK governments to effectively regulate the development and use of AI (68%).</p></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><yg-embed _ngcontent-yg-app-c2921605343="""" _nghost-yg-app-c477895173="""" class=""ng-star-inserted""><div _ngcontent-yg-app-c477895173="""" data-cy=""embed-content"" class=""inner-html""><div>
    <iframe title=""Most Britons have little to no confidence that tech companies will develop AI responsibly, or that government will effectively regulate it"" aria-label=""Split Bars"" id=""datawrapper-chart-44DtF"" src=""https://datawrapper.dwcdn.net/44DtF/1/"" scrolling=""no"" frameborder=""0"" style=""width: 0; min-width: 100% !important; border: none;"" height=""307"" data-external=""1""></iframe>
</div>
</div><!----></yg-embed><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div _ngcontent-yg-app-c2921605343="""" class=""inner-html""><p>Expectations are dramatically different depending on how optimistic or pessimistic people are about AI. Fully 52% of those who are optimistic about the impact artificial intelligence will have say they have a great deal or fair amount of confidence in tech companies to develop the technology responsibly – although far fewer have the same level of faith in the government’s ability to regulate it effectively (36%).</p><p>Among those with pessimistic expectations for AI, just 5% have much confidence in either group.</p></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><yg-embed _ngcontent-yg-app-c2921605343="""" _nghost-yg-app-c477895173="""" class=""ng-star-inserted""><div _ngcontent-yg-app-c477895173="""" data-cy=""embed-content"" class=""inner-html""><div>
    <iframe title=""Britons who are optimistic about the impact of AI tend to think that technology companies are going to develop it responsibly"" aria-label=""Split Bars"" id=""datawrapper-chart-9w95i"" src=""https://datawrapper.dwcdn.net/9w95i/2/"" scrolling=""no"" frameborder=""0"" style=""width: 0; min-width: 100% !important; border: none;"" height=""502"" data-external=""1""></iframe>
</div>
</div><!----></yg-embed><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><div _ngcontent-yg-app-c2921605343="""" class=""inner-html""><p><a href=""https://d3nkl3psvxxpe9.cloudfront.net/documents/Internal_AI_230509.pdf""><strong>See the full results here</strong></a></p><p><em>Photo: Getty</em></p></div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></section>",,N/A,N/A," Britons think artificial intelligence will cost jobs… but not their own Matthew SmithHead of Data Journalism Politics & current affairs Technology, digital & media Society May 19, 2023, 8:39 AM GMT-4  Share  Printable version Six in ten expect more jobs will be lost to robotics and AI than will be createdBT will reportedly be shedding up to 55,000 jobs by the end of the decade with up to a fifth replaced by technologies including artificial intelligence.The results of a new YouGov poll show that almost two thirds of Britons (64%) believe “more jobs will be lost to automation by robotics/AI than will be created”, with a mere 7% expecting they will create more opportunities than they close down. One in eight (12%) expect numbers will remain about the same, while 17% are unsure.Among workers themselves, 62% expect more jobs to be lost than gained. Yet when they are asked whether jobs like their own will primarily be done by humans or by robots or AI 30 years from now, the majority (59%) still see a human future. Only a quarter (25%) expect their line of work to become dominated by machines.


Likewise, few workers say they are worried about the impact that robotics or artificial intelligence will have on their current job (14%) or their future career (22%).Younger workers – who have much more career still to get through – are unsurprisingly more likely to be worried than those who are on the cusp of aging out of working life. Even so, 18-24 year old workers are still more likely to be unworried (48%) than worried (36%), including only 7% who are “very worried”.Among those workers who specifically think that more jobs will be lost to automation than will be created, 65% say they aren’t worried about the impact on their own career.How much do Britons think they understand about AI?Half of Britons say they either know a great deal (7%) or a fair amount (44%) about what artificial intelligence is, while 41% say they don’t know very much and 5% say they know nothing at all.Slightly fewer people (41%) claim to know much about “the issues surrounding artificial intelligence”.As is generally the case in opinion polls, men are more likely than women to claim greater knowledge, and in this case younger people are more likely to feel they have a grip on the topic than their elders.


When it comes to the overall impact that artificial intelligence will have, Britons are more likely to be pessimistic (35%) than optimistic (19%), with a further 34% saying they are neither optimistic or pessimistic.


The more familiar a person feels they are with the issues surrounding AI, the more likely they are to have either optimistic or pessimistic expectations for the technology – although the optimistic side grows far more rapidly with awareness. While only 5% of those who confess no understanding of the issues around AI say they are optimistic about the tech, fully 28% have a negative view. Among those who consider themselves to have a great deal of understanding, there is a 35pt increase to 40% with an optimistic view, compared to a 15pt increase to 43% holding a negative view.Most Britons lack confidence in tech companies and government on AIEarlier this week, the CEO of OpenAI (the firm which owns ChatGPT) told a US Congress hearing that AI could “cause significant harm to the world”, expressing willingness to work with lawmakers regarding his own company’s technology, and made a number of proposals for how to regulate artificial intelligence.The British public is, however, sceptical that those able to influence the future of AI can be trusted to do so.Two thirds of Britons say they have little to no confidence that technology companies that are developing AI will do so responsibly (66%), or in the ability of current and future UK governments to effectively regulate the development and use of AI (68%).


Expectations are dramatically different depending on how optimistic or pessimistic people are about AI. Fully 52% of those who are optimistic about the impact artificial intelligence will have say they have a great deal or fair amount of confidence in tech companies to develop the technology responsibly – although far fewer have the same level of faith in the government’s ability to regulate it effectively (36%).Among those with pessimistic expectations for AI, just 5% have much confidence in either group.


See the full results herePhoto: Getty Explore more data & articles RoboticsArtificial IntelligenceWork A candidate for Mayor in a town in Wyoming, United States, says that if elected, he will defer all decision making to an AI bot, which he says has better ideas and understanding of government than many people currently serving. Do you think it is a good or bad idea for elected leaders to use AI to help with their decision-making role?  technology  How much impact, if any, do you think attempts to use AI-generated 'deepfake' videos that make it look like politicians have said something they did not are likely to have on the general election?  technology  Do people growing up in the UK today all have equal opportunities?  politics  How intelligent Brits think robots are  society  How many days holiday Brits take  travel  Should smartphones be banned for under-16s? Brits are divided  Technology  AI in journalism: how would public trust in the news be affected?  Technology  12% have been on the toilet during work video meeting  Technology  John Humphrys – AI: What is the biggest threat?  Technology ",,,,,,,,,,,,,,,,,,,"['Politics & current affairs', 'Technology, digital & media', 'Society']",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMijgFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2pvZW1ja2VuZHJpY2svMjAyMy8wNS8yMC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS13aWxsLWVsaW1pbmF0ZS1tYW55LXRhc2tzLWJ1dC1hbHNvLWNyZWF0ZS1uZXctaGlnaGVyLWxldmVsLW9uZXMv0gEA?oc=5,Artificial Intelligence's Higher Value: Spurring New Managerial Thinking - Forbes,2023-05-20,Forbes,https://www.forbes.com,Managers need to prepare for 'the biggest shock' coming with AI — replacing entry and low-level white-collar activities with 'first-draft automation.',"AI,John T. Behrens,Artificial Intelligence Will Soon Bend Everyone,Artificial Intelligence Will Eliminate Many Tasks,Artificial intelligence",Managers need to prepare for 'the biggest shock' coming with AI — replacing entry and low-level white-collar activities with 'first-draft automation.',Managers need to prepare for 'the biggest shock' coming with AI — replacing entry and low-level white-collar activities with 'first-draft automation.',http://schema.org,BreadcrumbList,Artificial Intelligence’s Higher Value:   Spurring New Managerial Thinking,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/6468d7b4762b340e022e9948/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Joe McKendrick', 'url': 'https://www.forbes.com/sites/joemckendrick/', 'description': 'I am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the 2023 AI Summit in New York, as well as the 2021 and 2022 Summits. I regularly contribute to Harvard Business Review on AI topics. My column on service orientation appears on CNET, covering topics shaping business and technology careers. I am also a co-author of the SOA Manifesto, which outlines the values and guiding principles of service orientation in business and IT. Much of my research work is in conjunction with Forbes Insights and Unisphere Research/ Information Today, Inc., covering topics such as artificial intelligence, cloud computing, digital transformation, and big data analytics. In a previous life, I served as communications and research manager of the Administrative Management Society (AMS), an international professional association dedicated to advancing knowledge within the IT and business management fields. I am a graduate of Temple University.', 'sameAs': ['https://www.twitter.com/joemckendrick', 'Joe McKendrick']}",https://www.forbes.com/sites/joemckendrick/2023/05/20/artificial-intelligence-will-eliminate-many-tasks-but-also-create-new-higher-level-ones/,2023-05-20T10:28:30-04:00,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,,Enterprise Tech,N/A,"Edit StoryInnovationEnterprise TechArtificial Intelligence’s Higher Value:   Spurring New Managerial ThinkingJoe McKendrickSenior ContributorOpinions expressed by Forbes Contributors are their own.I track how technology innovations move markets and careersFollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itMay 20, 2023,10:28am EDTUpdated May 30, 2023, 11:56am EDTShare to FacebookShare to TwitterShare to LinkedinAI will create demand for more cognitive rolesgetty
There has been no shortage of panicky headlines in the mainstream media about how artificial intelligence will eliminate jobs. But the nuance is that AI will influence many, if not most jobs, in some way, rather than replace them wholesale. Managers and professionals, in turn, will be empowered and encouraged to look at business problems in new ways. This will recast careers and workplaces in the months and years ahead in unexpected ways.


“Almost all jobs will be affected by AI because the core tools of the business world are going to be AI-enhanced at some point, if they aren’t already,"" says John Behrens, Ph.D., professor and digital technologies leader at the University of Notre Dame. ""This will increase productivity across the board and eventually change what work looks like for most of us.”

With jobs focused on AI, ‘organizations are not just pulling from computer science backgrounds,” says Diane Gutiw, vice president of analytics, AI and machine learning for CGI. “Nurses are being brought in as data analysts to help understand the implications of AI on healthcare. Accountants and financial analysts are able to provide specific insights into how AI can be utilized to make the organization more profitable. Having a wide range of backgrounds is useful because there is such a wealth of understanding in the data of how people actually work and helps bring in a more focused, human element to yield the best results.”

PROMOTED
However, there’s a twist to this. While the internet led to replacing manual processes with digital ones, the incorporation of AI into jobs means rethinking ways of working as many tasks are eliminated — while new ones are created. ""AI will bolster decision-making and automate repetitive chores thereby altering work roles and responsibilities,” says Vrinda Khurjekar, senior director at Searce. “Professionals and managers ought to learn how AI may be incorporated into their workflow and how it can improve their productivity and judgment. This might require changing their professional objectives to positions that can benefit from AI, such as emphasizing the development of strategic thinking, creativity, adaptability, and emotional intelligence.”

The skills that will matter in the emerging AI era consists of “organizational leadership skills of excellent cognition, creativity, communication, and collaboration,” says Behrens. “Managers must provide vision and stability for teams navigating the social and business disruption AI will bring.”
MORE FROMFORBES ADVISORBest Travel Insurance CompaniesByAmy DaniseEditorBest Covid-19 Travel Insurance PlansByAmy DaniseEditor
There are many flavors to AI, and many potential business use cases. “If you’re looking at adopting AI, I recommend focusing on real business problems first, rather than just generally saying AI is being implemented,” says Gutiw. “Managers should ask themselves questions about whether AI is something they want to support resource management, contact centers, or getting information to people through conversational AI.”









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



This means “a real shift in how we work,” says Gutiw. “It's changing how our vendor partners are designing their technologies to support that. And high-functioning analytic organizations are teaching their employees how to capitalize on it regardless of their background.”
Such abilities will be essential “for managing the complicated and dynamic commercial landscape and cannot be easily copied by AI,” Khurjekar elaborates. “Routine manual and repetitive work that can be automated by AI, on the other hand, may be less in demand for certain abilities. Professionals should concentrate on acquiring abilities that complement AI and can enhance their jobs.”
The bottom line is that “it comes down to understanding how AI can help do things like reduce risk, decide on an investment, make sure machinery and assets have less downtime and extend their useful lifespan,” Gutiw says. “Successfully implementing AI can take away the menial tasks so that people can do more interesting work focused on their capabilities and expertise.”
Managers and professionals need to prepare for what Behrens calls “the biggest shock” coming with AI — that is, “replacing entry and low-level white-collar activities,” he explains. For example, knowledge worker roles will be impacted by “first-draft automation,” in which AI is used to “write the first draft of genre-specific materials such as press releases, job descriptions, marketing materials and legal documents.”
The latest versions of AI “can do things that earlier software could not, that the business value of text and image data has dramatically escalated, with strategic implications for their industry,” says Behrens.
First-draft automation is already advancing to the next stage, which includes “writing drafts of 3D models and computer code — where it is already having a big impact,” says Behrens. “First-draft automation will increase the need for those who can use AI to rapidly generate text, code and models, while also knowing how to evaluate it and fit it into a larger software or knowledge ecosystem.""
Gutiw also points out that companies are “headed into a resource shortage with the baby boomers retiring. If AI is able to generate things that were onerous to write, like proposals or documents, it has to be expected that we're going to shift how we work with those things.”
This doesn’t mean non-technical business professionals need to understand the intricacies of building or deploying AI apps. That’s because it’s becoming easier and easier to work with AI, just as it has been with mobile and no-code and low-code apps. “They should have a rudimentary awareness of how AI functions, its potential, and its limitations,” says Khurjekar. “This will help them to work with technical teams efficiently, embrace AI solutions with knowledge, and find ways to incorporate AI into their business plans.”
AI may be disruptive, but disruption equals opportunity and industry watchers feel positive about the future of management careers in the age of AI. “Professionals and managers need to embrace the opportunities that AI can provide, be proactive in evaluating the possible influence of AI on their career goals, concentrate on building complementary skills, have a fundamental understanding of AI ideas, and be aware of the risks that AI may present,” says Khurjekar. “Professionals and managers can succeed in the age of AI by navigating the changing business landscape with the proper mentality, abilities, and collaboration with AI technologies.”
Behrens is also optimistic, noting that this ""is an extremely exciting time for leaders who are tech savvy, forward looking and open to change. The rate of innovation will increase exponentially, leading to great possibilities and challenges. The key for success will be to shift one’s perspective from ‘how do I use this’ to ‘how do I reimagine my business and my customer?’ We will see a whole new generation of life-changing companies.""
Follow me on Twitter. Joe McKendrickFollowingFollowI am an author, independent researcher and speaker exploring innovation, information technology trends and markets. I served as co-chair of the... Read MoreEditorial StandardsPrintReprints & Permissions",,,2023-05-30T11:56:42-04:00,,,,,True,,Artificial Intelligence’s Higher Value:   Spurring New Managerial Thinking,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",Enterprise Tech,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiO2h0dHBzOi8vdGVjaGNydW5jaC5jb20vMjAyMy8wNS8xOS9hcHBsZS1nZW5lcmF0aXZlLWFpLWpvYnMv0gEA?oc=5,Apple is on the hunt for generative AI talent - TechCrunch,2023-05-19,TechCrunch,https://techcrunch.com,Apple currently has a dozen of job postings on its career page to look for experts in the field of generative AI.,N/A,Apple currently has a dozen of job postings on its career page to look for experts in the field of generative AI.,N/A,https://schema.org,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', '@id': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/#article', 'isPartOf': {'@id': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/'}, 'author': [{'@id': 'https://techcrunch.com/#/schema/person/image/6650cec646db507b199b44c4a10350ef'}], 'headline': 'Apple is on the hunt for generative AI talent', 'datePublished': '2023-05-19T13:16:54+00:00', 'dateModified': '2023-05-19T16:23:43+00:00', 'mainEntityOfPage': {'@id': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/'}, 'wordCount': 769, 'commentCount': 0, 'publisher': {'@id': 'https://techcrunch.com/#organization'}, 'image': {'@id': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/#primaryimage'}, 'thumbnailUrl': 'https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1247232650.jpg', 'keywords': ['Apple', 'Generative AI'], 'articleSection': ['AI'], 'inLanguage': 'en-US', 'speakable': {'@type': 'SpeakableSpecification', 'cssSelector': ['#speakable-summary']}, 'copyrightYear': '2023', 'copyrightHolder': {'@id': 'https://techcrunch.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/', 'url': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/', 'name': 'Apple is on the hunt for generative AI talent | TechCrunch', 'isPartOf': {'@id': 'https://techcrunch.com/#website'}, 'primaryImageOfPage': {'@id': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/#primaryimage'}, 'image': {'@id': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/#primaryimage'}, 'thumbnailUrl': 'https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1247232650.jpg', 'datePublished': '2023-05-19T13:16:54+00:00', 'dateModified': '2023-05-19T16:23:43+00:00', 'description': 'Apple currently has a dozen of job postings on its career page to look for experts in the field of generative AI.', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://techcrunch.com/2023/05/19/apple-generative-ai-jobs/#primaryimage', 'url': 'https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1247232650.jpg', 'contentUrl': 'https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1247232650.jpg', 'width': 5000, 'height': 2916, 'caption': 'Apple AI'}, {'@type': 'WebSite', '@id': 'https://techcrunch.com/#website', 'url': 'https://techcrunch.com/', 'name': 'TechCrunch', 'description': 'Startup and Technology News', 'publisher': {'@id': 'https://techcrunch.com/#organization'}, 'alternateName': 'TC', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://techcrunch.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://techcrunch.com/#organization', 'name': 'TechCrunch', 'alternateName': 'TC', 'url': 'https://techcrunch.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://techcrunch.com/#/schema/logo/image/', 'url': 'https://techcrunch.com/wp-content/uploads/2018/04/tc-logo-2018-square-reverse2x.png?resize=1200,1200', 'contentUrl': 'https://techcrunch.com/wp-content/uploads/2018/04/tc-logo-2018-square-reverse2x.png?resize=1200,1200', 'width': 1200, 'height': 1200, 'caption': 'TechCrunch'}, 'image': {'@id': 'https://techcrunch.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/techcrunch', 'https://x.com/TechCrunch', 'https://mstdn.social/@TechCrunch', 'https://bsky.app/profile/techcrunch.bsky.social', 'https://www.threads.net/@techcrunch']}, {'@type': 'Person', '@id': 'https://techcrunch.com/#/schema/person/image/6650cec646db507b199b44c4a10350ef', 'name': 'Jagmeet Singh', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://techcrunch.com/#/schema/person/image/5b8005835bcf7f4492aa3ca8d0f047db', 'url': 'https://secure.gravatar.com/avatar/7a9bd5727569147c3025b40e3775fc64?s=96&d=identicon&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/7a9bd5727569147c3025b40e3775fc64?s=96&d=identicon&r=g', 'caption': 'Jagmeet Singh'}, 'description': 'Jagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV. You can reach out to him at mail[at]journalistjagmeet[dot]com.', 'url': 'https://techcrunch.com/author/jagmeet-singh/'}]",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LnRoZWF0bGFudGljLmNvbS90ZWNobm9sb2d5L2FyY2hpdmUvMjAyMy8wNS9haS1jaGF0Z3B0LXByb2R1Y3Rpdml0eS13b3JrLzY3NDA5MC_SAQA?oc=5,Here's How AI Will Come for Your Job - The Atlantic,2023-05-17,The Atlantic,https://www.theatlantic.com,"Instead of being replaced by robots, office workers will soon be pressured to act more like robots themselves.","most precious commodity, generative AI, vision of the true AI apocalypse, mass-produced content, knowledge workers of the world, studio sessions, greater need, Generative-AI tools, entire email compositions, single prompt.The promise of artificial intelligence, creative industries strip-mined of their humanity, ChatGPT-generated slide deck, Last week, types of productivity tools, ultimate productivity tool, frictionless productivity, Frederick Winslow Taylor, AI, cranny of industry, coming grind, middle managers, pattern-recognition engines, workplace channel workers, idea of a shadow economy of robots, generative-AI programs sketch elements, complex outputs, vengeful artificial sentience, grueling record-company contracts, large language models, office workers, sole purpose, vertiginous scale of a generative-AI internet, Google Sheets, culture of interoffice memos, content, style of any popular artist, music industry, work computer, ChatGPT’s Code Interpreter plug-in, Bethlehem Steel, artificial intelligence, ChatGPT window, dilute advertising markets, destruction of the artist, political news, Google Slides, simple commands, process of production, search engines, political-news articles","Instead of being replaced by robots, office workers will soon be pressured to act more like robots themselves.",N/A,https://schema.org,NewsArticle,Here’s How AI Will Come for Your Job,Here’s How AI Will Come for Your Job,"[{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'url': 'https://cdn.theatlantic.com/thumbor/ZB7Cm_Jaq-hpC3n3UG972-gHhDM=/420x0:1500x1080/1080x1080/media/img/mt/2023/05/AI_Productivity/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1200}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/zyHmaPK2u1mHbZb7wBS4EVFUaZg=/242x0:1682x1080/1200x900/media/img/mt/2023/05/AI_Productivity/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1600}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/MW73eZ83DJKooksNb-SPerDMHKU=/0x0:1920x1080/1600x900/media/img/mt/2023/05/AI_Productivity/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 960}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/pzV1t_fQR7FPmk7xEplK8ZlzBmM=/0x0:1920x1080/960x540/media/img/mt/2023/05/AI_Productivity/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/j86T_SXibNrsuZLOh1qY9XE7Y9Q=/420x0:1500x1080/540x540/media/img/mt/2023/05/AI_Productivity/original.jpg'}]","[{'@type': 'Person', 'name': 'Charlie Warzel', 'sameAs': 'https://www.theatlantic.com/author/charlie-warzel/'}]",https://www.theatlantic.com/technology/archive/2023/05/ai-chatgpt-productivity-work/674090/,2023-05-17T20:13:30Z,{'@id': 'https://www.theatlantic.com/#publisher'},,,Technology,N/A,"TechnologyHere’s How AI Will Come for Your JobInstead of being replaced by robots, office workers will soon be pressured to act more like robots themselves.By Charlie WarzelIllustration by The AtlanticMay 17, 2023ShareSave Abandon all hope, ye who merge spreadsheet cells! Last week, at its annual I/O conference, Google spent hours detailing how large language models would help the knowledge workers of the world unload their busywork onto a legion of eager, capable neural networks. The company will soon introduce AI functions into programs such as Gmail, Google Sheets, and Google Slides that will allow users to type simple commands and receive complex outputs: entire email compositions, for example, or auto-generated tables. The future that Google is promising feels familiar—it’s all about heightened convenience and one-click efficiency—and I hate it. Workplace AI feels like the purest distillation of a corrosive ideology that demands frictionless productivity from workers: The easier our labor becomes, the more of it we can do, and the more of it we’ll be expected to do.This is how AI comes for our jobs, one ChatGPT-generated slide deck and inbox integration at a time. It’s a vision of the true AI apocalypse on the horizon that feels more like a soulless grind. Humanity isn’t to be obliterated by a vengeful artificial sentience, and office workers probably won’t be replaced en masse with machines; instead, we will be expected to produce and behave more like robots ourselves. Less Skynet, more Bain & Company.In its idealized state, generative AI is the ultimate productivity tool. Large language models are intelligent-seeming (if fundamentally unreliable), trained on mountains of information, and eminently capable. They produce LinkedIn-sounding prose that’s perfect for just circling back. Running a ChatGPT window on a work computer has already become akin to writing with spell check for some people. ChatGPT’s Code Interpreter plug-in is able to edit video, pull and analyze information from complex spreadsheets, and build dazzling custom charts and visualizations with a single prompt.The promise of artificial intelligence is automation, and the promise of automation is to remove friction from the process of production—of typing words, of crunching numbers, of synthesizing information. Generative-AI tools are, in essence, pattern-recognition engines, and their wide deployment is seen by evangelists as the beginning of a rapid expansion of the amount of intelligence in the world, whatever that means. It is a vision of productivity defined by endless possibility.We’ve seen this one before. Time and again, a piece of technology promises to increase productivity by chipping away at the inefficiencies in our lives. We’re told that it will liberate us—from the tyranny of our inboxes or from toiling on factory floors—and we will recoup our time, the most precious commodity of all. But that time is usually reinvested into more labor. The logic is simple and circular: Increased efficiency frees us up to be more productive. Frederick Winslow Taylor and his stopwatch ruthlessly optimized the factory floor at Bethlehem Steel by surveilling workers and forcing them to eliminate breaks and streamline their motions. The principles of Taylorism changed business and management forever. But its gains weren’t to the benefit of the worker, who was simply driven to produce more each shift.The story repeats with many prosaic office technologies. Email didn’t dismantle the culture of interoffice memos and workplace correspondence, but it did make them readily accessible all the time. Slack, the corporate email killer, hasn’t unclogged our inboxes. Instead, it is merely another workplace channel workers must tend to—another way to be productive and available to our colleagues and bosses, instantly, at any time. Why should we expect generative AI to free us from this familiar cycle?Read: Slackers of the world, unite!In a world where the cost of producing content, correspondence, research, and code approaches zero, it stands to reason that the forces of capitalism would respond by demanding as much of it as possible. And even if humans aren’t the ones producing every solitary word, phrase, sound, or string of numbers, humans will be tasked with generating, editing, and corralling all this synthetic media. If artificial intelligence is coming for our jobs, its plan is to turn us all into middle managers of overlapping, interacting AI systems. The only problem? Middle management is stressful, grinding, usually thankless work. People speak derisively about middle managers because their outputs are hard to define and monitor—they are viewed, sometimes unfairly, as a mere link in the chain.When I look at a future dominated by generative-AI tools that are embedded in every nook and cranny of industry, I fear the coming grind. I see inboxes crushed under the weight of robot responses and rapid-generated slide decks. A sea of forgettable, lorem-ipsum emails whose sole purpose is to trigger other robots to reply to their polite, authoritative MBA-speak. I see creative industries strip-mined of their humanity in order to create content at the vertiginous scale of a generative-AI internet. What happens to the music industry when anyone can construct a banger of a song in the style of any popular artist? Likely not the destruction of the artist in total, but a devaluation of her skills—yet another technological crisis for the working musician.One could imagine a future with grueling record-company contracts that demand multiple albums a year from artists, now that they can outsource lyric writing, vocals, and studio sessions. More content means more grease for the algorithmic gears and AI-powered recommendation engines of streaming platforms. The same logic applies to my profession: Why wouldn’t publications expect writers to churn out five or six stories a day, now that they have their own AI-based research and writing assistants? Such a tsunami of forgettable, mass-produced content would, of course, dilute advertising markets and drive down the costs of selling against that content, which would mean a greater need to produce … more content.You can already see the outlines of this dull, efficient future coming into view. Studios like Netflix are toying with the idea of letting generative-AI programs sketch elements for animated shows, and rumors are circulating in Hollywood that studios are mulling the use of AI to write first drafts (to be punched up later by humans) amid the Writer’s Guild strike. The content sludge is also present in Big Tech’s plans to reimagine search as an interactive, chatbot-powered walled garden. Type a question, get a canonical answer in the voice of a friendly assistant. It’s a process that, as my colleague Damon Beres recently wrote, “makes the internet feel smaller” and, potentially, functions as a dam, holding back search traffic to websites everywhere. In this imagining, search engines don’t need publishers to provide a quality product—they simply need a tonnage of copy to keep the algorithmic machine running.In 2017, I interviewed Jonathan Albright, a researcher who showed me how he’d stumbled upon a strange phenomenon across YouTube. He’d found a trove of channels comprising tens of thousands of videos. Most were crudely assembled slideshows, using text and images copied from political-news articles across the web. A halting computer voice read quotes from the text as the slideshow played. The channels were publishing new, cookie-cutter videos every three minutes. Most of it was unwatchable. Some of the videos hadn’t registered a view yet, but others had hundreds of thousands of plays. After some digging, he’d found that the videos were generated by an AI to influence YouTube’s recommendation algorithms. The content of the video was irrelevant—what was important was the signal it was sending to the platform: that there was a demand for political news videos.At the time, I was unnerved by this idea of a shadow economy of robots, making content for robots whose sole purpose was to tilt a platform slightly to one’s favor. Now the shadow economy feels like a template for a generative-AI future. The optimistic argument for these types of productivity tools is always that they unlock human potential and creativity—and they will. But it’s hard to imagine what this looks like at scale. Creativity is an inefficient, nonlinear process. The joy and the magic are in the friction. Productivity is, in many ways, its opposite. And AI is, above all else, a fully realized productivity tool with a mandate to eliminate friction wherever possible. AI is coming for our jobs, our creativity, and our culture—just probably not in the ways you expect. It’s not quite an apocalypse. It’s far more boring than that.About the AuthorCharlie Warzel is a staff writer at The Atlantic and the author of its newsletter Galaxy Brain, about technology, media, and big ideas. He can be reached via email.More StoriesElon Musk Is WinningTrump Versus the Coconut-Pilled","{'@type': 'WebPage', '@id': 'https://www.theatlantic.com/technology/archive/2023/05/ai-chatgpt-productivity-work/674090/'}",en-US,2023-05-17T22:41:58Z,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article-content-body'}",,,,False,,The Atlantic,"{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'url': 'https://cdn.theatlantic.com/assets/media/files/atlantic-logo--224x224.png'}",https://www.theatlantic.com/#publisher,,,,,"['https://www.facebook.com/TheAtlantic', 'https://twitter.com/theatlantic']",,Technology,,1072-7825,"{'@type': 'SearchAction', 'target': 'https://www.theatlantic.com/search/?q={q}', 'query-input': 'required name=q'}",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3Lm5iY25ld3MuY29tL2RhdGEtZ3JhcGhpY3MvY2hhdC1ncHQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaG93LWNoYXRib3Qtd29yay1yY25hODMyNjbSASpodHRwczovL3d3dy5uYmNuZXdzLmNvbS9uZXdzL2FtcC9yY25hODMyNjY?oc=5,Inside ChatGPT: How artificial intelligence chatbots work - NBC News,2023-05-17,NBC News,https://www.nbcnews.com,"As companies scramble to figure out how to adapt in the age of ChatGPT, here’s what you should know about how AI chatbots work.",N/A,Large language models like ChatGPT use a complicated series of equations to understand and respond to your prompts. Here’s a look inside the system.,Large language models like ChatGPT use a complicated series of equations to understand and respond to your prompts. Here’s a look inside the system.,,,,,,,,,,,,N/A,N/A,"Data GraphicsInside ChatGPT: How AI chatbots workLarge language models like ChatGPT use a complicated series of equations to understand and respond to your prompts. Here’s a look inside the system.ChatGPT is built to create text strings that make sense across multiple sentences and paragraphs. Justine Goode / NBC News / Getty ImagesPrintSaveCreate your free profile or log in to save this articleMay 17, 2023, 8:00 AM EDTBy JoElla Carman and Jasmine CuiBy now, you’ve heard of ChatGPT and its text generation capabilities. It has passed a business school exam, confounded teachers looking to spot cheaters and helped people craft emails to their co-workers and loved ones.That it has accomplished those tasks is notable, because exams, essays and emails require correct answers. But being correct isn’t really the point of ChatGPT — it’s more of a byproduct of its objective: producing natural-sounding text.So how do artificial intelligence chatbots work, and why do they get some answers right and some answers really, really wrong? Here’s a look inside the box.The technology behind large language models like ChatGPT is similar to the predictive text feature you see when you compose a message on your phone. Your phone will evaluate what has been typed in and calculate probabilities of what’s most likely to follow, based on its model and what it has observed from your past behavior.Anyone familiar with the process knows how many different directions a string of text can branch into. Unlike the phone’s predictive text feature, ChatGPT is said to be generative (the G in GPT). It isn’t making one-off predictions; instead it’s meant to create text strings that make sense across multiple sentences and paragraphs. The output is meant to make sense and read as though a person wrote it, and it should match up with the prompt. So what helps it pick a good next word, and then another word after that, and on and on? The internal referenceThere is no database of facts or a dictionary inside the machine to help it “understand” words. Instead, the system treats words mathematically, as a collection of values. You can think of these values as representing some quality the word might have. For example, is the word complimentary or critical? Sweet or sour? Low or high? In theory, you could set these values wherever you like and find that you have come close to a word. Here is a fictional example to demonstrate the idea: The generator below is designed to return a different fruit based on the three qualities. Try changing any of the qualities to see how the output changes.That technique is called word embedding, and it isn’t new. It originated in the field of linguistics in the 1950s. While the example above uses just three “qualities,” in a large language model, the number of “qualities” for every word would be in the hundreds, allowing a very precise way to identify words. Learning to make senseWhen the model is new, the qualities associated with each word are set randomly, which isn’t very useful, because its ability to predict depends on their being very finely tuned. To get there, it needs to be trained on a lot of content. That is the large part of the large language model.A system like ChatGPT might be fed millions of webpages and digital documents. (Think about the entirety of Wikipedia, big news websites, blogs and digitized books.) The machine cycles through the training data one stretch at a time, blocking out a word in a sequence and calculating a “guess” at what values most closely represent what should go in the blank. When the right answer is revealed, the machine can use the difference between what it guessed and the actual word to improve.It’s a lengthy process. OpenAI, the company behind ChatGPT, hasn’t published the details about how much training data went into ChatGPT or the computer power used to train it, but researchers from Nvidia, Stanford University and Microsoft estimate that, using 1,024 graphics processing units, it would have taken 34 days to train GPT 3, ChatGPT’s predecessor. One analyst estimated that the cost of computational resources to train and run large language models could stretch into the millions. RecommendedData GraphicsData GraphicsIn videos and maps, how the Trump assassination attempt unfoldedData GraphicsData GraphicsFertility is falling and populations are tapering, U.N. report capturing global changes revealsChatGPT also has an extra layer of training, referred to as reinforcement learning from human feedback. While previous training is about getting the model to fill in missing text, this phase is about getting it to put out strings that are coherent, accurate and conversational.During this stage, people rate the machine’s response, flagging output that is incorrect, unhelpful or even downright nonsensical. Using the feedback, the machine learns to predict whether humans will find its responses useful. OpenAI says this training makes the output of its model safer, more relevant and less likely to “hallucinate” facts. And researchers have said it is what aligns ChatGPT’s responses better with human expectations.At the end of the process, there is no record of the original training data inside the model. It doesn’t contain facts or quotes that can be referred to — just how related or unrelated words were to one another in action. Putting the training to useThis set of data turns out to be surprisingly powerful. When you type your query into ChatGPT, it translates everything into numbers using what it learned during training. Then it does the same series of calculations from above to predict the next word in its response. This time, there’s no hidden word to reveal; it just predicts. Thanks to its ability to refer to earlier parts of the conversation, it can keep it up page after page of realistic, human-sounding text that is sometimes, but not always, correct.LimitationsAt this point, there are plenty of disagreements about what AI is or will be capable of, but one thing is pretty well agreed upon — and prominently featured on the interfaces of ChatGPT, Google Bard and Microsoft Bing: These tools shouldn’t be relied on when accuracy is required. Large language models are able to identify text patterns, not facts. And a number of models, including ChatGPT, have knowledge cutoff dates, which means they can’t connect to the internet to learn new information. That’s in contrast to Microsoft’s Bing chatbot, which can query online resources. A large language model is also only as good as the material that was used to train it. Because models identify patterns between words, feeding an AI text that is dangerous or racist means the AI will learn text patterns that are dangerous or racist.OpenAI says it has created some guardrails to prevent it from serving that up, and ChatGPT says it is “trained to decline inappropriate requests,” as we discovered when it refused to write an angry email demanding a raise. But the company also admits that ChatGPT will still sometimes “respond to harmful instructions or exhibit biased behavior.”There are many useful ways to take advantage of the technology now, such as drafting cover letters, summarizing meetings or planning meals. The big question is whether improvements in the technology can push past some of its flaws, enabling it to create truly reliable text. MethodologyGraphics by JoElla Carman. In the “Pride and Prejudice” graphic, Google Bard, OpenAI GPT-1 and ChatGPT were given the prompt “Please summarize Pride and Prejudice by Jane Austen in one sentence.” BigScience Bloom was asked to finish the sentence “In the novel Pride and Prejudice, Jane Austen.” All responses collected May 11, 2023. In the email graphic, OpenAI ChatGPT was given the prompts: “Write a positive email asking for a raise,” “Write a neutral email asking for a raise,” “Write an agitated email asking for a raise,” “Write an angry email asking for a raise.” All responses collected May 8, 2023.JoElla CarmanJoElla Carman is the Data Graphics Interactive Visual DesignerJasmine CuiJasmine Cui is a reporter for NBC News.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LmNpdHlhbS5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utd29udC1kZXN0cm95LXlvdXItam9iLWp1c3QtbG9vay1hdC1vY3RvcHVzLWVuZXJneS11c2Utb2YtYWkv0gEA?oc=5,"Artificial intelligence won't destroy your job, just look at Octopus Energy's use of AI - CityAM - City A.M.",2023-05-17,City A.M.,https://www.cityam.com,"Many worry that AI will steal their jobs, but that won't be the case necessarily. It will also bring opportunities",N/A,"Many worry that AI will steal their jobs, but that won't be the case necessarily. It will also bring opportunities",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"

 
				The Notebook: Nuclear power continues to divide, but we need to think about the future			









",,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/#article', 'isPartOf': {'@id': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/'}, 'author': [{'@id': 'https://www.cityam.com/#/schema/person/image/7a2d33ad9a0277381586db044de18803'}], 'headline': 'Artificial intelligence won’t destroy your job, just look at Octopus Energy’s use of AI', 'datePublished': '2023-05-17T04:15:00+00:00', 'dateModified': '2023-05-16T17:12:21+00:00', 'mainEntityOfPage': {'@id': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/'}, 'wordCount': 606, 'publisher': {'@id': 'https://www.cityam.com/#organization'}, 'image': {'@id': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/#primaryimage'}, 'thumbnailUrl': 'https://www.cityam.com/wp-content/uploads/2023/05/city-A.M-98-e1684256456366.jpg', 'articleSection': ['Opinion'], 'inLanguage': 'en-GB'}, {'@type': 'WebPage', '@id': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/', 'url': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/', 'name': 'Artificial intelligence won’t destroy your job, just look at Octopus Energy’s use of AI - CityAM', 'isPartOf': {'@id': 'https://www.cityam.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/#primaryimage'}, 'image': {'@id': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/#primaryimage'}, 'thumbnailUrl': 'https://www.cityam.com/wp-content/uploads/2023/05/city-A.M-98-e1684256456366.jpg', 'datePublished': '2023-05-17T04:15:00+00:00', 'dateModified': '2023-05-16T17:12:21+00:00', 'description': ""Many worry that AI will steal their jobs, but that won't be the case necessarily. It will also bring opportunities"", 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.cityam.com/artificial-intelligence-wont-destroy-your-job-just-look-at-octopus-energy-use-of-ai/#primaryimage', 'url': 'https://www.cityam.com/wp-content/uploads/2023/05/city-A.M-98-e1684256456366.jpg', 'contentUrl': 'https://www.cityam.com/wp-content/uploads/2023/05/city-A.M-98-e1684256456366.jpg', 'width': 1200, 'height': 800}, {'@type': 'WebSite', '@id': 'https://www.cityam.com/#website', 'url': 'https://www.cityam.com/', 'name': 'CityAM', 'description': 'London&#039;s Business Newspaper', 'publisher': {'@id': 'https://www.cityam.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.cityam.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, [], {'@type': 'Person', '@id': 'https://www.cityam.com/#/schema/person/image/7a2d33ad9a0277381586db044de18803', 'name': 'Paul Ormerod', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.cityam.com/#/schema/person/image/55ea63eb9094210d8a4ed12c8311f6b1', 'url': 'https://www.cityam.com/wp-content/uploads/2021/09/paul-ormerod-e1697010439876.jpg?w=360&h=160&crop=1', 'contentUrl': 'https://www.cityam.com/wp-content/uploads/2021/09/paul-ormerod-e1697010439876.jpg?w=360&h=160&crop=1', 'width': '360', 'height': '160', 'caption': 'Paul Ormerod'}, 'description': 'Paul Ormerod is an economist at Volterra Partners LLP, author and an Honorary Professor at the Alliance Business School at the University of Manchester', 'url': 'https://www.cityam.com/profile/paul-ormerod/'}]",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiKmh0dHBzOi8vd3d3LmJiYy5jb20vbmV3cy9idXNpbmVzcy02NTYzMTE2ONIBLmh0dHBzOi8vd3d3LmJiYy5jb20vbmV3cy9idXNpbmVzcy02NTYzMTE2OC5hbXA?oc=5,"BT to cut 55,000 jobs with up to a fifth replaced by AI - BBC.com",2023-05-18,BBC.com,https://www.bbc.com,The telecoms giant plans to shed up to 40% of its workforce by the end of the decade to cut costs.,N/A,The telecoms giant plans to shed up to 40% of its workforce by the end of the decade to cut costs.,The telecoms giant plans to shed up to 40% of its workforce by the end of the decade to cut costs.,http://schema.org,ReportageNewsArticle,"BT to cut 55,000 jobs with up to a fifth replaced by AI",,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_news/18634/production/_125929899_openreachengineer.jpg'}","[{'@type': 'Person', 'name': 'By Tom Espiner'}]",https://www.bbc.com/news/business-65631168,2023-05-18T06:48:58.000Z,"{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'publishingPrinciples': 'http://www.bbc.co.uk/news/help-41670342', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",,,N/A,N/A,"BT to cut 55,000 jobs with up to a fifth replaced by AI18 May 2023ShareTom EspinerBusiness reporter, BBC NewsShareBT GroupTelecoms giant BT is to shed up to 55,000 jobs by the end of the decade, mostly in the UK, as it cuts costs.Up to a fifth of those cuts will come in customer services as staff are replaced by technologies including artificial intelligence.The headcount reduction from the current workforce of 130,000 includes staff and contractors.""Whenever you get new technologies you can get big changes,"" said chief executive Philip Jansen.He said ""generative AI"" tools such as ChatGPT - which can write essays, scripts, poems, and solve computer coding in a human-like way -  ""gives us confidence we can go even further"".Mr Jansen said AI would make services faster, better and more seamless, adding that the changes would not mean customers will ""feel like they are dealing with robots"".""We are multi-channel, we are online, we have 450 stores and that's not changing at all,"" he said.""There are plenty of opportunities for our customers to deal with people at BT, plenty of people to speak to.""Mr Jansen added that ""new technologies drive new jobs"", although BT has said it will have a""much smaller workforce"" by the end of the 2020s.BT, which is the UK's largest broadband and mobile provider, is currently continuing to expand its fibre network as it moves away from copper. The company said that once the work was completed it would not need as many staff to build and maintain its networks.In addition, newer, more efficient technology, including artificial intelligence, means fewer people will be needed to serve customers in future, it said.The move comes shortly after Vodafone said it would axe a tenth of its staff over the next three years, equating to 11,000 jobs.UK hitMr Jansen said BT would become ""a leaner business with a brighter future"", with the firm planning to get rid of between 40,000 and 55,000 jobs by 2030.The firm has about 80,000 employees in the UK, and this is where the bulk of the cuts will come. It has about 20,000 staff abroad.It also has 30,000 contractors, mainly abroad. Many of those roles will go.The cuts break down as:More than 15,000 cuts as BT completes building fibre networks in the UKMore than 10,000 as new UK networks require less maintenanceMore than 10,000 from using new tech including AIAbout 5,000 from restructuringThe Communications and Workers Union (CWU) said the BT announcement was ""no surprise"".""The introduction of new technologies across the company, along with the completion of the fibre infrastructure build replacing the copper network, was always going to result in less labour costs for the company in the coming years,"" a CWU spokesperson said.But the union said it wants BT to keep as many of its core employees as possible, with job cuts coming from sub-contractors ""in the first instance"", and through roles not being replaced as people leave the business.The BT announcement was made as it reported a 12% drop in profits of £1.7bn for the year to April.Its shares fell more than 7% after its results fell short of analysts' expectations.Tips for finding a new jobSearch beyond a 40-mile radius as hybrid and flexible working means you may be able to work from homeDon't wait for a job to be advertised as not all jobs are made publicFocus on explaining you have the right skills rather than years in a role when applyingRead more hereJames Barford, head of telecoms research at Enders Analysis, said the BT job cuts were mostly about fewer people being needed in building networks, whereas the Vodafone cuts were ""more general efficiency savings"".He said that in both cases plans were ""already broadly in place, with savings previously described in monetary terms rather than headcount reduction"".Possibly, the firms are now talking about job cuts ""to help convince sceptical investors that they will actually deliver the promised savings"", Mr Barford added.BT and unions agree pay rise of up to 16%CompaniesArtificial intelligenceTelecommunicationBT Group",https://www.bbc.com/news/business-65631168,,2023-05-18T13:22:38.000Z,,,,,,,,,,,,,,,,,,,,https://ichef.bbci.co.uk/news/1024/branded_news/18634/production/_125929899_openreachengineer.jpg,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LnRob21zb25yZXV0ZXJzLmNvbS9lbi11cy9wb3N0cy90ZWNobm9sb2d5L2dlbmVyYXRpdmUtYWktbGF3LWZpcm1zLWdyZWF0LXVua25vd24v0gEA?oc=5,"Generative AI in law firms: For many, such technologies are still a great unknown - Thomson Reuters",2023-05-19,Thomson Reuters,https://www.thomsonreuters.com,"While many law firms are excited about generative AI for legal work, there are a number that simply don’t know what the technology can do.",N/A,"While many law firms are excited about generative AI for legal work, there are a number that simply don’t know what the technology can do.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"


 


AI & Future Technologies
Generative AI in law firms: For many, such technologies are still a great unknown 



Zach Warren  Manager for Enterprise Content for Technology & Innovation / Thomson Reuters Institute      

19 May 2023 · 5 minute read  


Share





Facebook




Twitter




Linkedin




Email












Zach Warren  Manager for Enterprise Content for Technology & Innovation / Thomson Reuters Institute      

19 May 2023 · 5 minute read  


Share





Facebook




Twitter




Linkedin




Email










While many law firms are excited about the prospect of generative AI for legal work, there are a sizeable number that simply don’t know what the technology can do or how firms are approaching it, making adoption as much about education as technological fit

Many law firm attorneys feel positively about the prospect of generative artificial intelligence (AI) and such AI-enabling tools as ChatGPT, according to the Thomson Reuters Institute’s ChatGPT and Generative AI within Law Firms report released in April. Indeed, the report revealed that more than 80% of law firm leaders surveyed said they believed generative AI can be applied to legal work now, and more than half believed it actively should be applied to legal work.
Among the other respondents, however, the feeling was not necessarily distaste for generative AI, although some of that did exist. Instead, many are still simply unsure exactly what generative AI is or what it can do. Yet, considering the pace at which law firms have adopted technology previously, this is an understandable feeling given that the public release of OpenAI’s ChatGPT occurred only in November 2022.
Overall, the report found uncertainty across the board among law firm respondents: 25% said they did not know whether generative AI should be applied to legal work, and 21% did not know whether it should be applied to non-legal work. These feelings even extended to other forms of AI outside of generative AI/ChatGPT, as 24% did not know whether their firm uses AI outside of the generative context.
Jason Adaska, Director of the Innovation Lab at Holland & Hart, has a team of data scientists working on potential generative AI applications for the firm. Adaska says that because generative AI has appeared on the scene so quickly, there is “an increasing bifurcation in the conversations that I have” between people interested in using it and those unaware of its existence.
“Some people, they’ve seen it in the media, they’re kind of up to date with it,” he adds. “They may not come from a technology perspective, but at least they know about the conversation. Even in March I had some conversations with people who say, ‘I didn’t catch that. What is ChatGPT, what is this word you’re throwing at me?’”
Discovering how generative AI & ChatGPT can help
Similarly, Arsen Shirokov, National Director, Information Technology at McMillan, has already begun having conversations with internal stakeholders and external vendors about ways generative AI can be applied in his firm. A sticking point he’s run into, however, is that unlike previous legal technologies that have had a distinct use case, generative AI’s applications are so expansive that they can be hard to nail down.
“Almost everywhere else in technology, you say what this product is: this is an IG solution, this is a business workflow solution, this is an architecture solution, right? …With generative AI, I think we haven’t figured that out yet,” Shirokov says. “We don’t necessarily know which generative AI solutions are for research, for example. Take ChatGPT: It can also draft things for you, but for review, you cannot feed the bunch of documents to ChatGPT yet and just say, review this.”
Until those questions are answered, many lawyers also remain unsure of how their firms will handle generative AI on a wider scale. Our report found that 36% of respondents said they did not know whether their law firm had risk concerns around generative AI usage. Additionally, 19% did not know whether their firm had issued warnings against unauthorized generative AI use; and 22% did not know whether their firm had banned unauthorized generative AI use outright.


“How are we going to get people comfortable not just with the technology, but with the fact that they are interacting with a machine, and yet it doesn’t feel like you’re interacting with a machine?”


Even those respondents who reported their firm had underlying risk concerns over these advanced technologies counted a lack of technological maturity as one of those barriers. “A lack of understanding of the underlying risks,” wrote one respondent when asked why their firm had concerns around generative AI.
“Lack of insight/ability to control algorithms, data sets, and assumptions/biases of generated results. Lack of disclosure of disclaimers, boundaries, and assumptions when results return. Lack of ability to assess confidence in generated results,” wrote another.
As a result, for those law firms actively considering embracing generative AI — the report found 40% of firms were at least considering its use — encouraging adoption may be as much of a knowledge and informational issue as a technological issue. To that end, Jessica Lipson, Partner and Co-Chair of the Technology, Data & IP Department at Morrison Cohen, said her firm has been treating communication as a “high strategic issue” in potentially adopting generative AI technologies. “How are we going to get people comfortable not just with the technology, but with the fact that they are interacting with a machine, and yet it doesn’t feel like you’re interacting with a machine?” Lipson asks.
Part of the answer may take a cue from the 1989 film Field of Dreams: “If you build it, they will come.”
Holland & Hart’s Adaska says he’s gained interest in his team’s generative AI efforts by simply letting attorneys play around with the tool themselves. “I think that’s the story of the last few months in this,” Adaska adds. “A number of people who maybe would have either not paid attention or have been skeptical are being won over by actually trying things they thought weren’t possible and being pleasantly surprised.”






Facebook




Twitter




Linkedin




Email






AI & Future TechnologiesChatGPTGenAI ReportsLaw Firm BusinessLaw FirmsLeadershipLegal EducationLegal TechnologyService Professionals 


",,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://www.thomsonreuters.com/en-us/posts/technology/generative-ai-law-firms-great-unknown/', 'url': 'https://www.thomsonreuters.com/en-us/posts/technology/generative-ai-law-firms-great-unknown/', 'name': 'Generative AI in law firms: For many, such technologies are still a great unknown - Thomson Reuters Institute', 'isPartOf': {'@id': 'https://www.thomsonreuters.com/en-us/posts/#website'}, 'primaryImageOfPage': {'@id': 'https://www.thomsonreuters.com/en-us/posts/technology/generative-ai-law-firms-great-unknown/#primaryimage'}, 'image': {'@id': 'https://www.thomsonreuters.com/en-us/posts/technology/generative-ai-law-firms-great-unknown/#primaryimage'}, 'thumbnailUrl': 'https://www.thomsonreuters.com/en-us/posts/wp-content/uploads/sites/20/2022/08/Other-6.jpeg', 'datePublished': '2023-05-19T15:10:01+00:00', 'dateModified': '2024-04-17T13:54:02+00:00', 'author': {'@id': 'https://www.thomsonreuters.com/en-us/posts/#/schema/person/9de98b25528791ef9f3c353125857b7e'}, 'description': 'While many law firms are excited about generative AI for legal work, there are a number that simply don’t know what the technology can do.', 'breadcrumb': {'@id': 'https://www.thomsonreuters.com/en-us/posts/technology/generative-ai-law-firms-great-unknown/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.thomsonreuters.com/en-us/posts/technology/generative-ai-law-firms-great-unknown/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.thomsonreuters.com/en-us/posts/technology/generative-ai-law-firms-great-unknown/#primaryimage', 'url': 'https://www.thomsonreuters.com/en-us/posts/wp-content/uploads/sites/20/2022/08/Other-6.jpeg', 'contentUrl': 'https://www.thomsonreuters.com/en-us/posts/wp-content/uploads/sites/20/2022/08/Other-6.jpeg', 'width': 7952, 'height': 5304, 'caption': 'generative AI'}, {'@type': 'BreadcrumbList', '@id': 'https://www.thomsonreuters.com/en-us/posts/technology/generative-ai-law-firms-great-unknown/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.thomsonreuters.com/en-us/posts/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Generative AI in law firms: For many, such technologies are still a great unknown'}]}, {'@type': 'WebSite', '@id': 'https://www.thomsonreuters.com/en-us/posts/#website', 'url': 'https://www.thomsonreuters.com/en-us/posts/', 'name': 'Thomson Reuters Institute', 'description': 'Thomson Reuters Institute is a blog from Thomson Reuters, the intelligence, technology and human expertise you need to find trusted answers.', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.thomsonreuters.com/en-us/posts/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.thomsonreuters.com/en-us/posts/#/schema/person/9de98b25528791ef9f3c353125857b7e', 'name': 'greggwirth', 'url': 'https://www.thomsonreuters.com/en-us/posts/author/greggwirth/'}]",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vd3d3LmV4cG9uZW50aWFsdmlldy5jby9wL2NoYXJ0cGFjay1nZW4tYWktYW5kLXdoaXRlLWNvbGxhci1qb2Jz0gEA?oc=5,Chartpack: Generative AI and white-collar jobs - Exponential View,2023-05-17,Exponential View,https://www.exponentialview.co,What the emerging academic literature tells us,N/A,What the emerging academic literature tells us,What the emerging academic literature tells us,https://schema.org,NewsArticle,📈 Chartpack: Generative AI and white-collar jobs,,"[{'@type': 'ImageObject', 'url': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97aa30ff-2ea7-4535-86db-970575f2a791_1214x1212.png'}]","[{'@type': 'Person', 'name': 'Nathan Warren', 'url': 'https://substack.com/@nathanwarren', 'description': 'Senior Researcher @ Exponential View\n\nExploring emerging technologies and their impact on society.', 'identifier': 'user:113368613', 'image': {'@type': 'ImageObject', 'contentUrl': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae4b6681-dc36-4d22-ba21-3a4f64769b7a_1080x1080.jpeg', 'thumbnailUrl': 'https://substackcdn.com/image/fetch/w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae4b6681-dc36-4d22-ba21-3a4f64769b7a_1080x1080.jpeg'}}, {'@type': 'Person', 'name': 'Azeem Azhar', 'url': 'https://substack.com/@exponentialview', 'description': 'AI and exponential technologies.', 'identifier': 'user:710379', 'sameAs': ['https://twitter.com/azeem'], 'image': {'@type': 'ImageObject', 'contentUrl': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F09961c12-4209-4296-8a12-0762a41809a3_400x400.jpeg', 'thumbnailUrl': 'https://substackcdn.com/image/fetch/w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F09961c12-4209-4296-8a12-0762a41809a3_400x400.jpeg'}}]",https://www.exponentialview.co/p/chartpack-gen-ai-and-white-collar-jobs,2023-05-17T13:17:10-04:00,"{'@type': 'Organization', 'name': 'Exponential View', 'url': 'https://www.exponentialview.co', 'description': 'Tech, AI, energy and future trends.', 'interactionStatistic': {'@type': 'InteractionCounter', 'name': 'Subscribers', 'interactionType': 'https://schema.org/SubscribeAction', 'userInteractionCount': 100000}, 'identifier': 'pub:2252', 'logo': {'@type': 'ImageObject', 'url': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F46fc2cf0-7745-4c27-8875-94a97cb1fc9f_900x900.png', 'contentUrl': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F46fc2cf0-7745-4c27-8875-94a97cb1fc9f_900x900.png', 'thumbnailUrl': 'https://substackcdn.com/image/fetch/w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F46fc2cf0-7745-4c27-8875-94a97cb1fc9f_900x900.png'}, 'image': {'@type': 'ImageObject', 'url': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F46fc2cf0-7745-4c27-8875-94a97cb1fc9f_900x900.png', 'contentUrl': 'https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F46fc2cf0-7745-4c27-8875-94a97cb1fc9f_900x900.png', 'thumbnailUrl': 'https://substackcdn.com/image/fetch/w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F46fc2cf0-7745-4c27-8875-94a97cb1fc9f_900x900.png'}, 'sameAs': ['https://twitter.com/azeem']}",,,N/A,N/A,"Share this post📈 Chartpack: Generative AI and white-collar jobswww.exponentialview.coCopy linkFacebookEmailNoteOther📈 Chartpack: Generative AI and white-collar jobsWhat the emerging academic literature tells usNathan Warren and Azeem AzharMay 17, 2023∙ Paid54Share this post📈 Chartpack: Generative AI and white-collar jobswww.exponentialview.coCopy linkFacebookEmailNoteOther2ShareChatGPT was released a mere six months ago, but it has already seen massive adoption around the world, reaching 100 million users in only 2 months and kicking off the era of generative AI (GenAI) [read our chartpack on the state of GenAI here]. This adoption has quickly spread to the workplace. A survey done by the professional networking app Fishbowl in January 2023 found that already 43% of respondents were using ChatGPT in their workplace.Following this rapid adoption of generative AI such as ChatGPT, we’re reviewing preliminary academic research in today’s Chartpack to help guide strategic decision-making around GenAI integration. Please note that these studies focus on direct impacts on work tasks. Second-order effects such as potential wage impacts or job creation will be addressed in future Chartpacks for premium members.Who will be exposed to GenAI?A study published in March 2023 by Eloundou et al. examined the potential effects of GPTs1 on the labour market, specifically focusing on the tasks they could complete or augment within each profession. They found that 80% of the U.S. workforce could have at least 10% of their work tasks affected by LLMs2. This is over 130 million people in the U.S. alone. Moreover, this impact rises significantly with income, affecting tasks within white-collar jobs the most. The study predicts that jobs that require a higher level of education or training are most likely to be exposed to LLMs. Jobs requiring a bachelor’s degree (2-4 years of training) could be most affected, with over 30% of these jobs expected to have at least 50% of their tasks exposed to LLMs. Examples of highly exposed jobs include information services, finance, publishing and telecommunications.How is GenAI affecting these occupations? While the academic literature is still in its infancy, a few initial studies on writing, coding and call-centre performance provide indications of GenAI’s initial effects.All of these studies found an increase in performance. Let us explain how.This post is for paid subscribersSubscribeAlready a paid subscriber? Sign inPreviousNext",https://www.exponentialview.co/p/chartpack-gen-ai-and-white-collar-jobs,,2023-05-17T13:17:10-04:00,,,,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vZW1hZy5kaXJlY3RpbmR1c3RyeS5jb20vMjAyMy8wNS8xOS90aGUtaW1wYWN0LW9mLWFpLW9uLWpvYi1ncm93dGgtYW5kLWRlY2xpbmUtaW5zaWdodHMtZnJvbS10aGUtd29ybGQtZWNvbm9taWMtZm9ydW0v0gEA?oc=5,The Impact of AI on Job Growth and Decline: Insights from the World Economic Forum - DirectIndustry e-Magazine,2023-05-19,DirectIndustry e-Magazine,https://emag.directindustry.com,"The World Economic Forum predicts the creation of 69 million jobs by 2027 thanks to AI, but also the destruction of 89 million jobs.",N/A,"The World Economic Forum predicts the creation of 69 million jobs by 2027 thanks to AI, but also the destruction of 89 million jobs.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/#article', 'isPartOf': {'@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/'}, 'author': {'name': 'DirectIndustry', '@id': 'https://emag.directindustry.com/#/schema/person/25d678852dc219e07631f17f9bd0c541'}, 'headline': 'The Impact of AI on Job Growth and Decline: Insights from the World Economic Forum', 'datePublished': '2023-05-19T08:05:50+00:00', 'dateModified': '2023-05-17T20:30:07+00:00', 'mainEntityOfPage': {'@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/'}, 'wordCount': 663, 'commentCount': 0, 'publisher': {'@id': 'https://emag.directindustry.com/#organization'}, 'image': {'@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/#primaryimage'}, 'thumbnailUrl': '/wp-content/uploads/sites/3/INSIDE-CHINA-2025-Semiconductors-Battlechips-Strategy-10.png', 'keywords': ['AI', 'Business'], 'articleSection': ['Artificial Intelligence', 'Featured', 'Market Watch'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/#respond']}]}, {'@type': 'WebPage', '@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/', 'url': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/', 'name': 'The Impact of AI on Job Growth and Decline: Insights from the World Economic Forum - DirectIndustry e-Magazine', 'isPartOf': {'@id': 'https://emag.directindustry.com/#website'}, 'primaryImageOfPage': {'@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/#primaryimage'}, 'image': {'@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/#primaryimage'}, 'thumbnailUrl': '/wp-content/uploads/sites/3/INSIDE-CHINA-2025-Semiconductors-Battlechips-Strategy-10.png', 'datePublished': '2023-05-19T08:05:50+00:00', 'dateModified': '2023-05-17T20:30:07+00:00', 'description': 'The World Economic Forum predicts the creation of 69 million jobs by 2027 thanks to AI, but also the destruction of 89 million jobs.', 'breadcrumb': {'@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://emag.directindustry.com/2023/05/19/the-impact-of-ai-on-job-growth-and-decline-insights-from-the-world-economic-forum/#primaryimage', 'url': '/wp-content/uploads/sites/3/INSIDE-CHINA-2025-Semiconductors-Battlechips-Strategy-10.png', 'contentUrl': '/wp-content/uploads/sites/3/INSIDE-CHINA-2025-Semiconductors-Battlechips-Strategy-10.png', 'width': 1280, 'height': 800, 'caption': 'In its latest report on The Future of Jobs, the World Economic Forum (WEF) predicts the creation of 69 million jobs by 2027 thanks to AI, but also the destruction of 89 million jobs. Which occupations are affected? (Credit: iStock)'}, {'@type': 'WebSite', '@id': 'https://emag.directindustry.com/#website', 'url': 'https://emag.directindustry.com/', 'name': 'DirectIndustry e-Magazine', 'description': 'Industry News for Business Leaders', 'publisher': {'@id': 'https://emag.directindustry.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://emag.directindustry.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://emag.directindustry.com/#organization', 'name': 'DirectIndustry', 'url': 'https://emag.directindustry.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://emag.directindustry.com/#/schema/logo/image/', 'url': '/wp-content/uploads/sites/3/directindustry.png', 'contentUrl': '/wp-content/uploads/sites/3/directindustry.png', 'width': 32, 'height': 32, 'caption': 'DirectIndustry'}, 'image': {'@id': 'https://emag.directindustry.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/DirectIndustry/', 'https://x.com/DIndustryEmag', 'https://www.instagram.com/directindustryemag/', 'https://www.linkedin.com/company/directindustry-emagazine/', 'https://www.youtube.com/playlist?list=PLJxV5mAEF-mB2X6b1VlHhiWj10FNWgzgt']}, {'@type': 'Person', '@id': 'https://emag.directindustry.com/#/schema/person/25d678852dc219e07631f17f9bd0c541', 'name': 'DirectIndustry', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://emag.directindustry.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/dc4a27e2748de0db38f03c1dc185f21c?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/dc4a27e2748de0db38f03c1dc185f21c?s=96&d=mm&r=g', 'caption': 'DirectIndustry'}, 'url': 'https://emag.directindustry.com/author/directindustry/'}]",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3LmNtc3dpcmUuY29tL2RpZ2l0YWwtZXhwZXJpZW5jZS8xMS1iZXN0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvdXJzZXMtY2VydGlmaWNhdGlvbnMv0gEA?oc=5,11 Best Artificial Intelligence Courses & Certifications in 2023 - CMSWire,2023-05-17,CMSWire,https://www.cmswire.com,Dive into 11 top-tier AI courses that can empower you to stay competitive in the rapidly evolving landscape of artificial intelligence.,"['digital experience', 'natural language processing', 'artificial intelligence', 'machine learning', 'neural networks', 'category: digital experience', 'type: feature', 'utype: Staff']",Dive into 11 top-tier AI courses that can empower you to stay competitive in the rapidly evolving landscape of artificial intelligence.,Dive into 11 top-tier AI courses that can empower you to stay competitive in the rapidly evolving landscape of artificial intelligence.,http://schema.org,NewsArticle,11 Best Artificial Intelligence Courses & Certifications,,https://www.cmswire.com/-/media/8f18be8bb2a54227baf5acd90656eca4.ashx,"[{'@type': 'Person', 'name': 'Michelle Hawley', 'url': 'https://www.cmswire.com/author/michelle-hawley/'}]",https://www.cmswire.com/digital-experience/11-best-artificial-intelligence-courses-certifications/,2023-05-17T14:52:05Z,"{'type': 'Organization', 'name': 'CMSWire.com', 'logo': {'type': 'ImageObject', 'url': 'https://www.cmswire.com/-/media/346f68a07ac545a09971abfdb558e17a.png'}}",,,N/A,N/A,"Customer ExperienceExplore the dynamic world of Customer Experience (CX) at CMSWire. Stay updated with the latest news, expert advice and in-depth analysis on customer-first marketing, commerce and digital experience design.EditorialWhy 93% Ignore AI in MarketingRead nowInterviewCMO Circle: ADT's CMO DeLu Jackson on Innovating a 150-Year-Old BrandRead nowEditorial No More Hold Music? AI in the Contact Center Is HereRead nowUsing Voice of Customer to Improve Customer RetentionTarget's AI Transformation: Elevating Employee Efficiency & Customer DelightCustomer Whisperers: What CMOs Know About Being Customer-CentricCrafting a Global CX Strategy: Adapting to Diverse MarketsFruitful Futures: How to Grow Customer Advocacy in a Competitive MarketSeamless Stitches: AI Integration Into Journey Orchestration for Tailored CXExplore the Customer Experience Channel",https://www.cmswire.com/digital-experience/11-best-artificial-intelligence-courses-certifications/,,2023-05-17T14:52:05Z,,"Simpler Media Group, Inc.",,,,,,,https://www.cmswire.com/digital-experience/11-best-artificial-intelligence-courses-certifications/,,,,,,,Digital Experience,,,,https://www.cmswire.com/-/media/8f18be8bb2a54227baf5acd90656eca4.ashx,2023-05-17T14:52:05Z,Dive into 11 top-tier AI courses that can empower you to stay competitive in the rapidly evolving landscape of artificial intelligence.,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS93b3JsZC8yMDIzLzA1LzE4L2l0YWx5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWpvYnMtdGhyZWF0LWZ1bmRpbmcv0gEA?oc=5,Italy to spend $30 million to help shield jobs from AI replacement - The Washington Post,2023-05-18,The Washington Post,https://www.washingtonpost.com,Italy will spend some $30 million to help workers whose jobs are at risk as artificial intelligence transforms the labor market worldwide.,N/A,Italy will spend some $30 million to help workers whose jobs are at risk as artificial intelligence transforms the labor market worldwide.,Italy will spend some $30 million to help workers whose jobs are at risk as artificial intelligence transforms the labor market worldwide.,https://schema.org,BreadcrumbList,"As AI changes jobs, Italy is trying to help workers retrain",Italy to spend $30 million to help shield jobs from AI replacement ,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/FCHK66PBK4OMXU67BLH7EUFL6Y.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/FCHK66PBK4OMXU67BLH7EUFL6Y.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/FCHK66PBK4OMXU67BLH7EUFL6Y.jpg&w=800&h=600', 'height': 800, 'width': 600}]","{'@type': 'Person', 'name': 'Ellen Francis', 'url': 'https://www.washingtonpost.com/people/ellen-francis/'}",,2023-05-18T11:48:36.630Z,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}",,,Europe,N/A,"Italian authorities temporarily banned ChatGPT over privacy concerns in late March. (Marco Bertorello/AFP/Getty Images)By  Ellen FrancisMay 18, 2023 at 7:48 a.m. EDTAs artificial intelligence transforms jobs around the world and workers fear for their future, Italy plans to spend nearly $30 million to help people boost their digital skills, particularly for positions at risk from automation and technological advances.Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeRegulators and lawmakers in Europe and elsewhere are grappling with how to handle AI as it becomes more accessible across industries. While experts say the technology will not replace humans any time soon, its rise into the mainstream — including through the viral chatbot ChatGPT — has fueled concerns about the impact on the job market.Share2 CommentsNewsletterAs news breaksWorld News AlertsBreaking news email alerts for major happenings around the world.Sign upSubscribe to comment and get the full experience. Choose your plan →",https://www.washingtonpost.com/world/2023/05/18/italy-artificial-intelligence-jobs-threat-funding/,,2023-05-18T11:48:36.564Z,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",,,,,,,,,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'World', 'position': 1, 'item': 'https://www.washingtonpost.com/world/'}, {'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Europe', 'position': 2, 'item': 'https://www.washingtonpost.com/world/europe/'}]",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOGh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9ib3N0b24tZ2VuZXJhdGl2ZS1haS1wb2xpY3kv0gEA?oc=5,Boston Isn't Afraid of Generative AI - WIRED,2023-05-19,WIRED,https://www.wired.com,The city’s first-of-its-kind policy encourages its public servants to use the technology—and could serve as a blueprint for other governments.,"['ideas', 'cities', 'artificial intelligence', 'regulation', 'textaboveleftsmall', 'web']",The city’s first-of-its-kind policy encourages its public servants to use the technology—and could serve as a blueprint for other governments.,The city’s first-of-its-kind policy encourages its public servants to use the technology—and could serve as a blueprint for other governments.,https://schema.org/,BreadcrumbList,Boston Isn’t Afraid of Generative AI,The city’s first-of-its-kind policy encourages its public servants to use the technology—and could serve as a blueprint for other governments.,"['https://media.wired.com/photos/646799a606bd08d2f808af39/16:9/w_2400,h_1350,c_limit/Keyboard_bent_AI_ideas_GettyImages-1469762438.jpg', 'https://media.wired.com/photos/646799a606bd08d2f808af39/4:3/w_2132,h_1599,c_limit/Keyboard_bent_AI_ideas_GettyImages-1469762438.jpg', 'https://media.wired.com/photos/646799a606bd08d2f808af39/1:1/w_1600,h_1600,c_limit/Keyboard_bent_AI_ideas_GettyImages-1469762438.jpg']","[{'@type': 'Person', 'name': 'Beth Simone Noveck', 'sameAs': 'https://www.wired.com/author/beth-simone-noveck/'}]",https://www.wired.com/story/boston-generative-ai-policy/,2023-05-19T12:07:42.544-04:00,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}","In a rapid about-face, however, a few governments are now embracing a less fearful and more hands-on approach to AI. New York City Schools chancellor David Banks announced yesterday that NYC is reversing its ban because “the knee jerk fear and risk overlooked the potential of generative AI to support students and teachers, as well as the reality that our students are participating in and will work in a world where understanding generative AI is crucial.” And yesterday, City of Boston chief information officer Santiago Garces sent guidelines to every city official encouraging them to start using generative AI “to understand their potential.” The city also turned on use of Google Bard as part of the City of Boston’s enterprise-wide use of Google Workspace so that all public servants have access.
The “responsible experimentation approach” adopted in Boston—the first policy of its kind in the US—could, if used as a blueprint, revolutionize the public sector’s use of AI across the country and cause a sea change in how governments at every level approach AI. By promoting greater exploration of how AI can be used to improve government effectiveness and efficiency, and by focusing on how to use AI for governance instead of only how to govern AI, the Boston approach might help to reduce alarmism and focus attention on how to use AI for social good.
Generative AI, city officials were told in an email that went out from the CIO to all city officials on May 18, is a great way to get started on memos, letters, and job descriptions, and might help to alleviate the work of overburdened public officials.
The tools can also help public servants “translate” government-speak and legalese into plain English, which can make important information about public services more accessible to residents. The policy explains that public servants can indicate the reading level or audience in the prompt, allowing the AI model to generate text suitable for elementary school students or specific target audiences.
Generative AI can also help with translation into other languages so that a city’s non-English speaking populations can enjoy equal and easier access to information about policies and services affecting them.
City officials were also encouraged to use generative AI to summarize lengthy pieces of text or audio into concise summaries, which could make it easier for government officials to engage in conversations with residents.
The Boston policy even explains how AI can help produce code snippets and assist less technical individuals. As a result, even interns and student workers could start to engage in technical projects, such as creating web pages that help to communicate much needed government information.
Still, the policy advocates for a critical approach to the technology and for taking personal responsibility for use of the tools. Thus, public servants are encouraged to proof any work developed using generative AI to ensure that hallucinations and mistakes do not creep into what they publish. The guidelines emphasize that privacy, security, and the public purpose should be prioritized in the use of technology, weighing impact on the environment and constituents' digital rights.
Boston’s generative AI policy sets a new precedent in how governments approach AI. By supporting responsible experimentation, transparency, and collective learning, it opens the door to realizing the potential of AI to do good in governance. If more public servants and politicians embrace these technologies, practical experience can inform sensible regulations. Furthermore, generative AI’s ability to simplify communication, summarize conversations, and create appealing visuals can radically enhance government inclusivity and accessibility. Boston’s vision serves as an inspiration for other governments to break free from fear and embrace the opportunities presented by generative AI.",,tags,N/A,"Beth Simone NoveckIdeasMay 19, 2023 12:07 PMBoston Isn’t Afraid of Generative AIThe city’s first-of-its-kind policy encourages its public servants to use the technology—and could serve as a blueprint for other governments.Photograph: Yaroslav Kushta/Getty ImagesSave this storySaveSave this storySaveAfter ChatGPT burst on the scene last November, some government officials raced to prohibit its use. Italy banned the chatbot. New York City, Los Angeles Unified, Seattle, and Baltimore School Districts either banned or blocked access to generative AI tools, fearing that ChatGPT, Bard, and other content generation sites could tempt students to cheat on assignments, induce rampant plagiarism, and impede critical thinking. This week, US Congress heard testimony from Sam Altman, CEO of OpenAI, and AI researcher Gary Marcus as it weighed whether and how to regulate the technology.In a rapid about-face, however, a few governments are now embracing a less fearful and more hands-on approach to AI. New York City Schools chancellor David Banks announced yesterday that NYC is reversing its ban because “the knee jerk fear and risk overlooked the potential of generative AI to support students and teachers, as well as the reality that our students are participating in and will work in a world where understanding generative AI is crucial.” And yesterday, City of Boston chief information officer Santiago Garces sent guidelines to every city official encouraging them to start using generative AI “to understand their potential.” The city also turned on use of Google Bard as part of the City of Boston’s enterprise-wide use of Google Workspace so that all public servants have access.The “responsible experimentation approach” adopted in Boston—the first policy of its kind in the US—could, if used as a blueprint, revolutionize the public sector’s use of AI across the country and cause a sea change in how governments at every level approach AI. By promoting greater exploration of how AI can be used to improve government effectiveness and efficiency, and by focusing on how to use AI for governance instead of only how to govern AI, the Boston approach might help to reduce alarmism and focus attention on how to use AI for social good. Featured VideoHow This Guy Makes the World's Most Inventive ClocksBoston’s policy outlines several scenarios in which public servants might want to use AI to improve how they work, and even includes specific how-tos for effective prompt writing.Generative AI, city officials were told in an email that went out from the CIO to all city officials on May 18, is a great way to get started on memos, letters, and job descriptions, and might help to alleviate the work of overburdened public officials. The tools can also help public servants “translate” government-speak and legalese into plain English, which can make important information about public services more accessible to residents. The policy explains that public servants can indicate the reading level or audience in the prompt, allowing the AI model to generate text suitable for elementary school students or specific target audiences.AdvertisementGenerative AI can also help with translation into other languages so that a city’s non-English speaking populations can enjoy equal and easier access to information about policies and services affecting them. City officials were also encouraged to use generative AI to summarize lengthy pieces of text or audio into concise summaries, which could make it easier for government officials to engage in conversations with residents.Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenThe Boston policy even explains how AI can help produce code snippets and assist less technical individuals. As a result, even interns and student workers could start to engage in technical projects, such as creating web pages that help to communicate much needed government information.Still, the policy advocates for a critical approach to the technology and for taking personal responsibility for use of the tools. Thus, public servants are encouraged to proof any work developed using generative AI to ensure that hallucinations and mistakes do not creep into what they publish. The guidelines emphasize that privacy, security, and the public purpose should be prioritized in the use of technology, weighing impact on the environment and constituents' digital rights.These principles represent a shift from fear-mongering about the dangers of AI to a more proactive and responsible approach that provides guidance on how to use AI in the public workforce. Instead of the usual narrative about AI killing jobs or talking only about AI bias, the city’s letter explains that, by enabling better communication and conversation with residents of all kinds, AI could help repair historical harm to marginalized communities and foster inclusivity. Boston’s generative AI policy sets a new precedent in how governments approach AI. By supporting responsible experimentation, transparency, and collective learning, it opens the door to realizing the potential of AI to do good in governance. If more public servants and politicians embrace these technologies, practical experience can inform sensible regulations. Furthermore, generative AI’s ability to simplify communication, summarize conversations, and create appealing visuals can radically enhance government inclusivity and accessibility. Boston’s vision serves as an inspiration for other governments to break free from fear and embrace the opportunities presented by generative AI.","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/boston-generative-ai-policy/'}",,2023-05-19T12:07:42.544-04:00,,,,,True,"{'@type': 'CreativeWork', 'name': 'WIRED'}",,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Ideas', 'item': 'https://www.wired.com/ideas/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Cities', 'item': 'https://www.wired.com/tag/cities/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Boston Isn’t Afraid of Generative AI'}]",ideas,,,,"https://media.wired.com/photos/646799a606bd08d2f808af39/2:3/w_1066,h_1599,c_limit/Keyboard_bent_AI_ideas_GettyImages-1469762438.jpg",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vOXRvNW1hYy5jb20vMjAyMy8wNS8xOC9hcHBsZS1iYW5zLWVtcGxveWVlcy1mcm9tLXVzaW5nLWNoYXRncHQv0gEA?oc=5,Apple bans its employees from using ChatGPT for work - 9to5Mac,2023-05-18,9to5Mac,https://9to5mac.com,N/A,N/A,"Earlier today, OpenAI released the official ChatGPT app for iPhone. The tool has become well known for answering users’ requests...",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"


 


Here’s everything you should know about Apple’s rumored HomePod with display


 
Michael Burkhardt
Jul 20 2024


",,,,,,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://9to5mac.com/2023/05/18/apple-bans-employees-from-using-chatgpt/', 'url': 'https://9to5mac.com/2023/05/18/apple-bans-employees-from-using-chatgpt/', 'name': 'Apple bans its employees from using ChatGPT for work', 'isPartOf': {'@id': 'https://9to5mac.com/#website'}, 'primaryImageOfPage': {'@id': 'https://9to5mac.com/2023/05/18/apple-bans-employees-from-using-chatgpt/#primaryimage'}, 'image': {'@id': 'https://9to5mac.com/2023/05/18/apple-bans-employees-from-using-chatgpt/#primaryimage'}, 'thumbnailUrl': 'https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-bans-ChatGPT.jpg?quality=82&strip=all', 'datePublished': '2023-05-19T03:11:20+00:00', 'dateModified': '2023-05-19T09:31:08+00:00', 'author': {'@id': 'https://9to5mac.com/#/schema/person/fd5c9226f70a03b4f39c243f7cda9ed1'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://9to5mac.com/2023/05/18/apple-bans-employees-from-using-chatgpt/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://9to5mac.com/2023/05/18/apple-bans-employees-from-using-chatgpt/#primaryimage', 'url': 'https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-bans-ChatGPT.jpg?quality=82&strip=all&w=1024', 'contentUrl': 'https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-bans-ChatGPT.jpg?quality=82&strip=all&w=1024', 'width': 1920, 'height': 1080, 'caption': 'Apple bans its employees from using ChatGPT and other generative AI platforms for work'}, {'@type': 'WebSite', '@id': 'https://9to5mac.com/#website', 'url': 'https://9to5mac.com/', 'name': '9to5Mac', 'description': 'Apple News &amp; Mac Rumors Breaking All Day', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://9to5mac.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://9to5mac.com/#/schema/person/fd5c9226f70a03b4f39c243f7cda9ed1', 'name': 'Filipe Espósito', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://9to5mac.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/36d1bcbba2ffa3509f294100b9af0388?s=96&d=mm&r=r', 'contentUrl': 'https://secure.gravatar.com/avatar/36d1bcbba2ffa3509f294100b9af0388?s=96&d=mm&r=r', 'caption': 'Filipe Espósito'}, 'description': ""Filipe Espósito is a Brazilian tech Journalist who started covering Apple news on iHelp BR with some exclusive scoops — including the reveal of the new Apple Watch Series 5 models in titanium and ceramic. He joined 9to5Mac in 2019 to share even more exclusive details about Apple's plans."", 'url': 'https://9to5mac.com/author/filipeesposito/'}]",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMikwFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL3NpbGFkaXR5YXJheS8yMDIzLzA1LzE5L2FwcGxlLWpvaW5zLWEtZ3Jvd2luZy1saXN0LW9mLWNvbXBhbmllcy1jcmFja2luZy1kb3duLW9uLXVzZS1vZi1jaGF0Z3B0LWJ5LXN0YWZmZXJzLWhlcmVzLXdoeS_SAQA?oc=5,Apple Joins A Growing List Of Companies Cracking Down On Use Of ChatGPT By Staffers—Here's Why - Forbes,2023-05-19,Forbes,https://www.forbes.com,Companies are concerned that the use of services like ChatGPT could lead to leaks of sensitive internal data and proprietary code.,"Apple,ChatGPT,Google",Companies are concerned that the use of services like ChatGPT could lead to leaks of sensitive internal data and proprietary code.,Companies are concerned that the use of services like ChatGPT could lead to leaks of sensitive internal data and proprietary code.,http://schema.org,BreadcrumbList,Apple Joins A Growing List Of Companies Cracking Down On Use Of ChatGPT By Staffers—Here’s Why,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/64676005d9573e6c329f9960/0x0.jpg?format=jpg&crop=5471,3078,x0,y282,safe&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Siladitya Ray', 'url': 'https://www.forbes.com/sites/siladityaray/', 'description': 'Siladitya Ray is a reporter on the Forbes news team who covers major world news stories breaking overnight with a focus on technology and online platforms. He joined Forbes in 2020 and works in New Delhi. He’s covered ongoing Congressional efforts to force TikTok’s Chinese parent to sell the social media platform, Elon Musk’s handling of policy issues at X and the 2024 General Elections in India. Prior to joining Forbes, Siladitya worked as a reporter with the Hindustan Times and Medianama covering tech policy and consumer tech in India. He graduated from Columbia University with an MA in Business and Economics Journalism in 2019. Follow Ray for continued coverage on TikTok in the U.S., Elon Musk and X and other key developments at big tech companies. Tips:siladitya@protonmail.com. Forbes reporters follow company ethical guidelines that ensure the highest quality.', 'sameAs': ['https://www.twitter.com/SiladityaRay']}",https://www.forbes.com/sites/siladityaray/2023/05/19/apple-joins-a-growing-list-of-companies-cracking-down-on-use-of-chatgpt-by-staffers-heres-why/,2023-05-19T07:42:24-04:00,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,,Business,N/A,"Breaking21 hours agoKamala Harris Confirms She's Running For President—After Biden's Crucial Endorsement23 hours agoHere’s What To Know About Kamala Harris’ Record—As Biden Drops Out And Endorses Her23 hours agoHere’s How Democrats Could Pick A New Nominee As Joe Biden Drops Out22 minutes agoEvery Major Democrat Endorsing Kamala Harris For President—As Pelosi Backs Harris (Full List)2 hours agoSecret Service Director: Trump Shooter Was Identified As ‘Suspicious’ But Not A ‘Threat’2 hours agoMajor Democratic Donors Split On Kamala Harris' Presidential Run—As Small Donations Surge2 hours agoHarris Praises Biden In First Speech Since Launching Presidential Run2 hours agoKamala Harris Could Make Abortion A Bigger Issue In Election Over Biden—Here’s Why2 hours agoIs Kamala Harris Good For Stocks? ‘Blue’ Sectors Like Tech Lead Monday Market Rally2 hours agoDelta Meltdown: One-Third Of Flights Still Canceled Or Delayed As Customers FumeEdit StoryForbesBusinessBreakingApple Joins A Growing List Of Companies Cracking Down On Use Of ChatGPT By Staffers—Here’s WhySiladitya RayForbes StaffSiladitya Ray is a New Delhi-based Forbes news team reporter.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itMay 19, 2023,07:42am EDTShare to FacebookShare to TwitterShare to LinkedinTopline
Apple has blocked the use of AI tools for some of its staffers, becoming the latest major firm to restrict the use of generative AI platforms at work, amid concerns employees may leak sensitive internal data.
Apple CEO Tim Cook delivers the keynote address during a special event in the Steve Jobs Theater on ... [+] Apple's Cupertino, California campus.Getty Images

Key Facts


According to the Wall Street Journal, Apple has barred its employees from using ChatGPT and other AI-powered services like Github’s Copilot, which helps developers write code.



The ban stems from concerns about the data-handling practices of these AI platforms—which are either owned or financially backed by Apple’s rival Microsoft—as it could compromise Apple’s proprietary code or other sensitive data, the report adds.



Rival smartphone maker Samsung implemented a similar ban on ChatGPT and other AI tools earlier this month, after discovering an accidental leak of sensitive code by an engineer who uploaded it to ChatGPT.



In January, Amazon banned staffers from sharing any code or confidential information with OpenAI’s chatbot after claiming it discovered examples of ChatGPT responses that resembled internal Amazon data.


In February, JPMorgan Chase severely restricted the internal use of ChatGPT to avoid potential regulatory pitfalls over the sharing of sensitive financial information with a third-party platform.


Since then, other banks such as Bank of America, Citigroup, Deutsche Bank, Wells Fargo and Goldman Sachs, have followed suit, banning the use of AI chatbots by staffers.




1/100:00Forbes Business





Skip Ad
 
Continue watchingThese Top Democrats Are Endorsing Kamala Harris As She Runs To Replace Bidenafter the adVisit Advertiser websiteGO TO PAGE
News Peg
Most companies banning the use of third-party AI tools are concerned about how services like ChatGPT and Google’s Bard store data shared with them on servers. The other complication stems from the fact that most chatbots and AI services rely on user inputs to train their models and may accidentally serve other users a company’s proprietary data without even being aware of it. While ChatGPT offers users a way to disable saving chat histories, it is not turned on by default. It is also unclear if deleting a chat has any impact if a service has already used the conversation for training its models. In March, OpenAI had to briefly shut down ChatGPT to resolve a bug that allowed some users to see parts of another user’s chat history.
Contra
Despite some companies restricting the use of AI services at work, several others have already begun adding these tools to their workflow. Goldman Sachs—one of the banks limiting the use of ChatGPT by staffers—disclosed it was using generative AI tools to help its software developers write and test code. Management consulting firm Bain & Company announced earlier this year it was integrating OpenAI’s generative tools into its management systems. Others have expressed bullishness about leveraging the power of AI, saying they believe it can replace a significant chunk of their human workforce. On Thursday, BT said it plans to replace at least 10,000 workers—mostly people with customer service and network management roles—with AI-powered tools over the next decade. Earlier this month, IBM CEO Arvind Krishna said the company will stop hiring humans for jobs that AI can fulfill.
PROMOTED
What To Watch For
It's worth noting that these bans on AI tools by some companies do not necessarily stem from broader concerns about artificial intelligence itself, but rather from how third-party AI platform holders like OpenAI, Google, and Microsoft will handle proprietary data shared on these services. The Journal’s report notes that Apple is working on its own AI tools, led by former Google employee John Giannandrea. In Apple’s most recent earnings call, the company’s CEO Tim Cook said he thought “it’s very important to be deliberate and thoughtful in how you approach these things…but the potential is certainly very interesting.”

Further Reading
Apple Restricts Employee Use of ChatGPT, Joining Other Companies Wary of Leaks (Wall Street Journal)
New York City Public Schools Reverses ChatGPT Ban (Forbes)









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Follow me on Twitter. Send me a secure tip. Siladitya RayFollowingFollowSiladitya Ray is a reporter on the Forbes news team who covers major world news stories breaking overnight with a focus on technology and online... Read MoreEditorial StandardsPrintReprints & Permissions
1/100:00BitGo Cofounder And CEO Explains The Sudden Surge Of Bitcoin Worth





Skip Ad
 
Continue watchingBitGo Cofounder And CEO Explains The Sudden Surge Of Bitcoin Worthafter the adVisit Advertiser websiteGO TO PAGE",,,2023-10-05T16:50:26-04:00,,,,,False,,Apple Joins A Growing List Of Companies Cracking Down On Use Of ChatGPT By Staffers—Here’s Why,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Business', 'item': 'https://www.forbes.com/business/'}]",Business,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LnRoZWF0bGFudGljLmNvbS9pZGVhcy9hcmNoaXZlLzIwMjMvMDUvYWktam9iLWxvc3Nlcy1wb2xpY3ktc3VwcG9ydC11bml2ZXJzYWwtYmFzaWMtaW5jb21lLzY3NDA3MS_SAQA?oc=5,AI Will Be a Gold Mine. The Only Question Is Who Benefits. - The Atlantic,2023-05-17,The Atlantic,https://www.theatlantic.com,The U.S. needs policies now to support workers made redundant by artificial intelligence.,"AI jobs revolution, China Shock, transfer program, middle tier of white-collar jobs, new jobs, European manufacturing communities, good thing, specific effects of revolutionary technologies, shortage of remunerative jobs, technological change, David Autor, coming decade, two-thirds of American occupations, jobs, pair of economists, human race, mass job loss, World Trade Organization, Artificial intelligence, awe-inspiring invention.The problem, cultural question, country’s foremost experts, small amounts, United States, good news, crew of the USS Enterprise, Goldman Sachs, China’s entry, creative work, political views, piddling pay raises, persistent job losses, labor market, training data, new technology, new worlds, UBI, care work, country, workers, whole country, societal insurance, government, employment, country’s new growth, AI, 500-year-old policy idea, past advances, average wage-earning families, work",The U.S. needs policies now to support workers made redundant by artificial intelligence.,N/A,https://schema.org,NewsArticle,AI Will Be a Gold Mine. The Only Question Is Who Benefits.,"Before AI Takes Over, Make Plans to Give Everyone Money","[{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 720}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 405}, 'url': 'https://cdn.theatlantic.com/thumbor/gkOoFFPn-j6vAh2LiLxxgwKKwR8=/0x0:4800x2700/720x405/media/img/mt/2023/05/AI_UBI_2/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'url': 'https://cdn.theatlantic.com/thumbor/naMxFFOqrQQORSebh2Mu7H6tyzU=/1050x0:3750x2700/1080x1080/media/img/mt/2023/05/AI_UBI_2/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1200}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/J1VkjNqpmRSSapBHm69gCOPOHDg=/603x0:4203x2700/1200x900/media/img/mt/2023/05/AI_UBI_2/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1600}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/iVR3XiGCR1--F3Shp0LlUJdYefM=/0x0:4800x2700/1600x900/media/img/mt/2023/05/AI_UBI_2/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 960}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/3C6ELrQQE-3I6RyRT4FkTx3qH9Q=/0x0:4800x2700/960x540/media/img/mt/2023/05/AI_UBI_2/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/e7SrvcKc1XsGgVC4ry8rEsy6bME=/1050x0:3750x2700/540x540/media/img/mt/2023/05/AI_UBI_2/original.jpg'}]","[{'@type': 'Person', 'name': 'Annie Lowrey', 'sameAs': 'https://www.theatlantic.com/author/annie-lowrey/'}]",https://www.theatlantic.com/ideas/archive/2023/05/ai-job-losses-policy-support-universal-basic-income/674071/,2023-05-17T13:10:00Z,{'@id': 'https://www.theatlantic.com/#publisher'},,,Ideas,N/A,"IdeasBefore AI Takes Over, Make Plans to Give Everyone MoneyThe U.S. needs policies now to support workers made redundant by artificial intelligence.By Annie LowreyIllustration by Joanne Imperio / The AtlanticMay 17, 2023ShareSave Subscribe to Listen00:0005:55Listen to more stories on harkArtificial intelligence is coming for all our jobs.That is a prevalent fear these days, and not one easily dismissed. The specific effects of revolutionary technologies are impossible to predict, and perhaps AI will turn out to be overhyped. But it really is different from past advances: The work it can do really is different; the jobs it threatens really are different; its effects on the labor market really might be different. A pair of economists at Goldman Sachs recently estimated that two-thirds of American occupations are now “exposed” to AI-driven automation. In the coming decade, the technology will wipe out 300 million jobs, they forecast. That’s one in every 11 jobs on the planet.Here in the United States, an AI jobs revolution need not be anything for average wage-earning families to fear. If AI does not enslave the human race or destroy humanity outright, this generative technology can and should be a very, very good thing. It should lift productivity growth, increase our national wealth, and contribute to our commons of knowledge. Every person in this country can and should benefit from such an awe-inspiring invention.To read this story, Sign in or start a subscription.CloseNever miss a story. Start your subscription.Uncompromising quality. Enduring impact. Your support ensures a bright future for independent journalism.Get StartedAlready have an account? Sign inAbout the AuthorAnnie Lowrey is a staff writer at The Atlantic.More StoriesAmericans Are Mad About All the Wrong CostsThe Future of Labor","{'@type': 'WebPage', '@id': 'https://www.theatlantic.com/ideas/archive/2023/05/ai-job-losses-policy-support-universal-basic-income/674071/'}",en-US,2023-05-31T21:07:19Z,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article-content-body'}",,,,False,,The Atlantic,"{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'url': 'https://cdn.theatlantic.com/assets/media/files/atlantic-logo--224x224.png'}",https://www.theatlantic.com/#publisher,,,,,"['https://www.facebook.com/TheAtlantic', 'https://twitter.com/theatlantic']",,Ideas,,1072-7825,"{'@type': 'SearchAction', 'target': 'https://www.theatlantic.com/search/?q={q}', 'query-input': 'required name=q'}",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjMvMDUvMjAvYnVzaW5lc3MvYWktZmluYW5jaWFsLWFkdmljZS1jaGF0Z3B0Lmh0bWzSAQA?oc=5,Financial Planning With AI: How Will It Work - The New York Times,2023-05-20,The New York Times,https://www.nytimes.com,The financial services industry is plotting how to incorporate tools like ChatGPT into its products. But humans will still be necessary to provide personal advice.,N/A,The financial services industry is plotting how to incorporate tools like ChatGPT into its products. But humans will still be necessary to provide personal advice.,The financial services industry is plotting how to incorporate tools like ChatGPT into its products. But humans will still be necessary to provide personal advice.,https://schema.org,NewsMediaOrganization,Financial Planning With AI: How Will It Work,Would You Take Financial Advice From A.I.?,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/05/20/business/00ai-money/00ai-money-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2023/05/20/business/00ai-money/00ai-money-videoSixteenByNineJumbo1600.jpg', 'creditText': 'Will Cordell'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/05/20/business/00ai-money/00ai-money-superJumbo.jpg', 'height': 1434, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2023/05/20/business/00ai-money/00ai-money-superJumbo.jpg', 'creditText': 'Will Cordell'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/05/20/business/00ai-money/00ai-money-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2023/05/20/business/00ai-money/00ai-money-mediumSquareAt3X.jpg', 'creditText': 'Will Cordell'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': '', 'name': 'Paulette Perhach'}]",https://www.nytimes.com/,2023-05-20T07:00:05.000Z,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,,Business,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTWould You Take Financial Advice From A.I.?The financial services industry is plotting how to incorporate tools like ChatGPT into its products. But humans will still be necessary to provide personal advice.Share full article9Read in appCredit...Will CordellBy Paulette PerhachMay 20, 2023Paul Weiner, an artist, has been experimenting with artificial intelligence for the past year, generating A.I.-created visual disinformation and seeing whether he can get the images to spread. But recently, he turned to ChatGPT, a chatbot that has the ability to respond to complex questions, for a much different reason: With his 30th birthday looming, he decided to ask it for advice about retirement planning.“Maybe ChatGPT would have some answers that I might otherwise get from someone who I’d have to pay a lot of money to,” he said.Generative A.I. like ChatGPT has knowledge workers gripping the rails, bracing for how it might affect their jobs, and consumers leaning in to see what costly services could soon be replaced with a prompt. As the investment industry turns to artificial intelligence as a financial planning and advice tool, the values of accuracy, humanity, security and accessibility are jostling for prominence. In the future, who — or what — will we be asking to advise us on some of life’s most important decisions?ChatGPT recommended that Mr. Weiner open a Roth individual retirement account and certificates of deposit, as well as automate his savings and create a budget. He hasn’t yet opened any of the accounts or, as the chatbot also suggested, worked with a financial adviser.AdvertisementSKIP ADVERTISEMENT“It’s a lot of information that gets thrown at you pretty quickly,” Mr. Weiner said. He found the short explanations insufficient for what a C.D. does or the differences between a Roth I.R.A. and a traditional I.R.A. He concluded that speaking to a financial adviser would probably be more helpful.“But that kind of circles back to the whole reason I’m doing this on ChatGPT to start with — it’s free,” he said.ImageCredit...Will CordellA.I. has joined the financial chatDelyanne Barros, a money coach, said she felt that most of the hundreds of thousands of people who follow her on social media had no idea what ChatGPT is. “Am I the only one geeking out on this thing?” she asked. When she asks her followers if they’ve used it, she said, “they’re like, ‘What are you talking about?’”She’s teaching them the basics: There’s a free version of the service, and it works as more than just a Google alternative.AdvertisementSKIP ADVERTISEMENTOn Instagram, she asked if any investing newbies had asked ChatGPT to teach them to invest. Some had tried but reported that they kept getting stuck in a loop of repetitive answers. Ms. Barros found that she was able to get valuable information about allocations, tax efficiencies and retirement withdrawal rates, but she posits that was because she had knowledge of the investment terms she needed to use.Reviews and Advice from WirecutterThe 32 Best Housewarming Gifts July 19, 2024We Love a Melon Baller, and Not Just for Melons June 28, 2024Our Favorite Detergent for Hand-Washing ‘Dry-Clean Only’ Clothes June 25, 2024“You have to know how to frame the questions,” she said. “A lot of people don’t understand that you get an answer to something and it can build on that answer. You can ask follow-up questions, and it’s like a chain.”Ms. Barros has also used ChatGPT to double-check her calculations regarding her retirement plan. Despite its handiness, she is not worried that chatbots will replace her.“With something like investing, I’m not concerned as a personal finance educator, because I can see that it’s not like: ‘Oh, we don’t need you anymore. We have ChatGPT,’” she said. “If anything, this is going to be a tool that’s going to enhance my coaching experience with people, but it’s definitely not going to be replacing us, because people still need a lot of guidance.”Even if you don’t think you’re familiar with it, chances are you’ve already been using generative A.I.AdvertisementSKIP ADVERTISEMENTIntuit started to integrate A.I. into its software products, which include Mint and TurboTax, more than a decade ago, said Ashok Srivastava, the company’s senior vice president and chief data officer. Today, he said, Intuit’s platform performs 58 billion machine learning predictions per day. Another Intuit product, QuickBooks, predicts cash flow for small businesses, and the company has found that when it gives users advice based on artificial intelligence, 95 percent of small-business owners take that advice.They’re still focusing on a strategy that combines human interactions with A.I.-powered ones. Customers, for example, can meet with a live expert, and then A.I. will create a categorized and tagged summary of the conversation for later review.ImageCredit...Will CordellBugs in the systemAs of now, the technology is promising, but it’s not 100 percent accurate.“These systems tell plausible stories, they give you plausible ideas, but not necessarily correct ones,” Mr. Srivastava said. “What we’re focusing on is actually providing the correct experience to the person, so that it’s grounded in reality and data that is appropriately personalized to them, so then they can make the best financial decisions as they move forward.”Mr. Srivastava said he did not envision a future where humans were taken out of the financial planning equation.AdvertisementSKIP ADVERTISEMENT“I’ve grown up in the field, I’ve seen it evolve, and it’s an amazing technology,” he said. “I think that the human connection is still important. I envision that we will want to help C.P.A.s, bookkeepers, financial planners, financial advisers — everyone in this ecosystem — grow and prosper along with the use of artificial intelligence.”Josh Pigford, the founder and chief executive of Maybe, had been building a personal finance management platform that could help people make financial decisions when ChatGPT debuted. A few months ago, Maybe was rebuilt from the ground up, this time with GPT, the technology behind ChatGPT, as the foundation of the platform. The process always begins, he said, with a question people want to answer.“The way that we were initially tackling this is giving you access to a financial adviser who can answer those questions for you directly,” Mr. Pigford said. “As we started testing GPT’s ability around that, we realized, well, OK, actually GPT can do this really well.”Things became even more interesting when people added their financial data and information, such as age, location, and goals. The system could then take into account everything from dependents to joint filing to local tax codes — details a financial adviser would be able to use — and deliver that directly to the consumer.That, of course, brings up the subject of privacy. Through Maybe’s system, the banking information is secured and does not feed back to OpenAI, the company that created ChatGPT.AdvertisementSKIP ADVERTISEMENTHallucinations — the tendency for ChatGPT to spout off incorrect information — have also become a worry. Mr. Pigford and his team identified the issue during early testing.“There was a point there where it was actually making up entire transactions, and building this back story of like, ‘You bought this item from Home Depot to help cool off your living room,’” he said. “That’s a legitimate problem.”As the technology has improved, Mr. Pigford has seen a drastic decrease in these hallucinations in just weeks. The way they’re designing the software includes a toggle to switch between a chatbot and humans for advice.“The belief, the hypothesis, what we’re sort of banking on is that we’re able to actually offer that sort of hyper-personalized input and advice without you having to, you know, form a relationship with a certified financial adviser where you’re paying them an assets-under-management fee, or even paying them, you know, a couple hundred bucks an hour,” he said. “You’re able to get very specific advice, regardless of what your financial situation is.”But Mr. Pigford believes it’s too early to do away with live professionals. “I think we’ll have some transition period where we’ll want humans involved for a while,” he said. “The goal is not to completely do away with a financial adviser.”AdvertisementSKIP ADVERTISEMENTFirst steps into the ChatGPT worldGlenn Hopper, author of “Deep Finance: Corporate Finance in the Information Age,” relates this GPT era to the screech of dial-up internet. The prevalence of A.I., he said, is “going to come quicker than the adoption of the internet and broadband internet and web browsers.”“I’ve stopped making predictions, because every time I make a prediction, I’ll say six to 12 months, and then I’ll read an article the next day that this item has already appeared,” Mr. Hopper said.He warned that tools like ChatGPT would make scamming and phishing more sophisticated, so users should be cautious of anyone asking for their bank information.“The very first thing that I tell everyone is, if you’ve been ignoring artificial intelligence up until now — stop,” he said. He doesn’t think people need to become experts, but they should have a basic understanding of how the technology works, he said.“If we’re going to hand over our decisions to them, and we don’t have any idea how they’re working, I mean, you might as well shake one of those Magic 8 Balls and get the answer from that,” he said.A version of this article appears in print on May 20, 2023, Section B, Page 1 of the New York edition with the headline: Would You Take A.I.’s Money Advice?. Order Reprints | Today’s Paper | SubscribeRead 9 CommentsShare full article9Read in appAdvertisementSKIP ADVERTISEMENTComments 9Would You Take Financial Advice From A.I.?Skip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Enjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",https://www.nytimes.com/2023/05/20/business/ai-financial-advice-chatgpt.html,en,2023-05-20T07:00:05.000Z,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",The New York Times,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,,{'@id': '#commentsContainer'},9.0,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3LmxpdHRsZXIuY29tL3B1YmxpY2F0aW9uLXByZXNzL3B1YmxpY2F0aW9uL2Vlb2MtaXNzdWVzLWd1aWRhbmNlLXVzZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS10b29scy1lbXBsb3ltZW500gEA?oc=5,EEOC Issues Guidance on Use of Artificial Intelligence Tools in Employment Selection Procedures Under Title VII - Littler Mendelson PC,2023-05-18,Littler Mendelson PC,https://www.littler.com,"EEOC’s nonbinding guidance focuses on an employer’s use of AI in selection procedure decisions such as hiring, promotion, and firing.Guidance addresses potential disparate or adverse impact resulting from the use of such tools and does not address issues of intentional discrimination via the use of AI-driven tools in making employment selection procedures.On May 18, 2023, the",N/A,"EEOC’s nonbinding guidance focuses on an employer’s use of AI in selection procedure decisions such as hiring, promotion, and firing.Guidance addresses potential disparate or adverse impact resulting from the use of such tools and does not address issues of intentional discrimination via the use of AI-driven tools in making employment selection procedures.On May 18, 2023, the U.S.","EEOC’s nonbinding guidance focuses on an employer’s use of AI in selection procedure decisions such as hiring, promotion, and firing.Guidance addresses potential disparate or adverse impact resulting",,,,,,,,,,,,N/A,N/A,"

By Jim Paretti, Marko Mrkonich, and Niloy Ray on May 18, 2023

Print 


 




EEOC’s nonbinding guidance focuses on an employer’s use of AI in selection procedure decisions such as hiring, promotion, and firing.
Guidance addresses potential disparate or adverse impact resulting from the use of such tools and does not address issues of intentional discrimination via the use of AI-driven tools in making employment selection procedures.





On May 18, 2023, the U.S. Equal Employment Opportunity Commission (EEOC or “the Commission”), the federal agency charged with administering federal civil rights laws (including Title VII of the Civil Rights Act, the Americans with Disabilities Act (ADA), and the Age Discrimination in Employment Act (ADEA), among others), issued a “technical assistance document” entitled, “Assessing Adverse Impact in Software, Algorithms, and Artificial Intelligence Used in Employment Selection Procedures Under Title VII of the Civil Rights Act of 1964.” EEOC technical assistance documents are not voted upon or otherwise approved by the full Commission, and are not intended to create new policy, but rather to apply existing law and Commission policy to new or specific fact patterns. They do not have the force and effect of law, and do not bind the public in any way—rather, they purport to provide clarity with regard to existing requirements under the law. This latest technical assistance document, addressing artificial intelligence (AI) employment selection procedures under Title VII, follows on the Commission’s May 2022 guidance on the use of AI tools and the ADA.
The technical assistance document begins by noting that while Title VII applies to all employment practices, including recruitment, monitoring, evaluation, and discipline of employees, it is intended to address AI issues only with regard to “selection procedures,” such as hiring, promotion, and firing. It defines “artificial intelligence” with reference to the National Artificial Intelligence Initiative Act of 2020 as “a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments,” and notes that in the employment context, this has typically meant reliance on an automated tool’s own analysis of data to determine which criteria to use when making decisions. The Commission offers a number of examples of AI tools used in the employment selection procedures, including:
[R]esume scanners that prioritize applications using certain keywords; employee monitoring software that rates employees on the basis of their keystrokes or other factors; ‘virtual assistants’ or ‘chatbots’ that ask job candidates about their qualifications and reject those who do not meet pre-defined requirements; video interviewing software that evaluates candidates based on their facial expressions and speech patterns; and testing software that provides ‘job fit’ scores for applicants or employees regarding their personalities, aptitudes, cognitive skills, or perceived ‘cultural fit’ based on their performance on a game or on a more traditional test.
The document is expressly focused on potential disparate or adverse impact resulting from the use of such tools and does not address issues of intentional discrimination via the use of AI-driven tools in making employment selection procedures. Generally speaking, adverse or disparate impact may result when an employer uses a facially neutral test or selection procedure that excludes individuals based on protected characteristics such as sex, race, color, or religion in disproportionate number.1 An employer can justify the use of a neutral tool that nevertheless has an adverse impact where the use of such tool is “job-related and consistent with business necessity” and there is no less-discriminatory alternative that is equally effective. The application of disparate impact principles, and the assessment of whether a selection tool is lawful under Title VII, is generally governed by the Uniform Guidelines on Employee Selection Procedures (UGESP) adopted by the EEOC in 1978.
Insofar as it does not create new policy, the scope of the technical assistance is limited. That said, it does include several key takeaways for employers using selection tools that incorporate or are driven by AI:

Liability for Tools Designed or Administered by a Vendor or Third Party. The guidance notes that where an AI-powered selection tool results in disparate impact, an employer may be liable even if the test was developed or administered by an outside vendor. The EEOC recommends that in determining whether to rely on an outside party or vendor to administer an AI selection tool, the employer consider asking the vendor what steps it has taken to evaluate the tool for potential adverse impact. It further notes that where a vendor is incorrect in its assessment (for example, informing the employers that the tool does not result in an adverse impact when in fact it does), the employer may still be liable.


The “Four-Fifths Rule” is Not Determinative. UGESP has long noted the “four-fifths” rule will “generally” be regarded as a measure of adverse impact—but that it is not dispositive. By way of background, the four-fifths rule provides that where a selection rate for any race, sex, or religious or ethnic group is less than 80 percent (four-fifths) of the rate of the group with the highest selection rate, that generally indicates disparate impact. For example, assume an employer uses a selection tool to screen 120 applicants (80 male, 40 female) to determine which advance and receive an interview. The tool determines that 48 men and 12 women should advance to the interview round. The “selection rate” of the tool is 60% for men (48/80) but only 30% for women (12/40). The ratio of the two rates is 50% (30/60). Because 50% is less than 80% (four-fifths), the tool would generally be viewed as having an adverse impact under the four-fifths rule. The technical assistance document notes that while the four-fifths rule is a useful “rule of thumb,” it is not an absolute indicator of disparate impact—smaller differences in selection rates may still indicate adverse impact where, for example, the tool is used to make a large number of selections, or where an employer may have discouraged certain applicants from applying. The guidance notes that the EEOC may consider a tool that passes the four-fifths test to still generate an unlawful adverse impact if it nevertheless results in a statistically significant difference in selection rates.


Employers Should Self-Audit Tools. Finally, the technical assistance urges employers to self-audit selection tools on an ongoing basis to determine whether they have an adverse impact on groups protected under the law, and, where it does, consider modifying the tool to minimize such impact. While such modification may be lawful going forward, employers are urged to explore this issue closely with counsel, insofar as it may implicate both disparate treatment and disparate impact provisions of Title VII under existing Supreme Court precedent.

While its technical assistance does not offer particularly trenchant insight, it does reflect the attention the EEOC has and will likely continue to pay to issues of discrimination and artificial intelligence. In late 2021, the agency announced its “Artificial Intelligence and Algorithmic Fairness Initiative,” and its most recent public meeting in January of this year was devoted solely to the issue of AI and potential employment discrimination. We expect this focus will remain, particularly if the Commission obtains a Democratic majority in the future (the agency is currently split along party lines, with two Democratic commissioners, two Republican commissioners, and one vacancy to which a Democrat has been nominated; as a practical matter, this lack of majority has likely limited the agency’s ability to move forward on controversial or significant policy changes).
Employers using or considering the use of AI-driven tools in recruiting and selecting applicants and employees are advised to keep a close eye on developments, as both the federal government and state and local governments have indicated an intent to regulate in this space. Littler Workplace Policy Institute (WPI) will likewise keep readers informed of relevant developments.


See Footnotes 

 ​1 In regulatory guidance discussed further below, “adverse impact” is formally defined as “a substantially different rate of selection in hiring, promotion, or other employment decision which works to the disadvantage of members of a race, sex, or ethnic group.” 29 CFR § 1607.16(B).


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3LmZhc3Rjb21wYW55LmNvbS85MDg5NjkyOC90aGUtZnJpZ2h0ZW5pbmctdHJ1dGgtYWJvdXQtYWktY2hhdGJvdHMtbm9ib2R5LWtub3dzLWV4YWN0bHktaG93LXRoZXktd29ya9IBAA?oc=5,The frightening truth about AI chatbots: Nobody knows exactly how they work - Fast Company,2023-05-17,Fast Company,https://www.fastcompany.com,Nobody really knows how chatbots work. The AI community is divided on whether that fact could come to haunt us as the technology improves and proliferates.,N/A,Nobody really knows how chatbots work. The AI community is divided on whether that fact could come to haunt us as the technology improves and proliferates.,"This 'inscrutable black box' aspect of LLMs is fueling a growing concern among scientists that continued development and application of the technology could have serious, even catastrophic, unintended results.",https://schema.org,,,,,,,,,,,N/A,N/A,"Large language models (LLMs) like the ones that power ChatGPT and Bard are different from revolutionary technologies of the past in at least one striking way: No one—not even the people who built the models—knows exactly how they work. As tech companies race to improve and apply LLMs, researchers remain far from being able to explain or “interpret” the inner mechanics of these inscrutable “black boxes.” Traditional computer programs are coded in exquisite detail to instruct a computer to perform the same task over and over. But neural networks, including those that run large language models (LLMs), program and reprogram themselves and reason in ways that are not comprehensible to humans. That’s why when New York Times reporter Kevin Roose documented his famously strange exchange with Bing Chat earlier this year, Microsoft CTO Kevin Scott could not explain why the bot said what it said.This “inscrutable” aspect of LLMs is fueling a concern among scientists that continued development and application of the technology could have serious, even catastrophic, unintended results. A growing number of scientists believe that as LLMs get better and smarter they may be used by bad actors (or defense agencies) to harm human beings. Some believe that because AI systems will posess superior intellegence and superior reasoning skills versus humans, their eventual opposition to humans is a natural and predictable part of their evolution. In March, more than 1,000 business leaders and scientists—including Turing Award winner Yoshua Bengio, Steve Wozniak, and Elon Musk—signed an open letter calling for a six-month pause in LLM development, in part because of a lack of understanding of how these AI systems work. “[R]ecent months have seen AI labs locked in an out-of-control race to develop and deploy ever more powerful digital minds that no one—not even their creators—can understand, predict, or reliably control,” the letter reads. Now, the “godfather of AI” Geoffrey Hinton has joined the ranks of concerned scientists. “I think it’s entirely possible that humanity is just a passing phase in the evolution of intelligence,” Hinton said in a recent interview at MIT. Hinton recently quit his job at Google so that he could speak openly about the existential dangers presented by the LLMs his own research helped make possible. “I’m sounding the alarm and saying we have to worry about this,” he said at the time of his exit. “It’s not clear there is a solution.” Hinton says that when AI systems are allowed to set their own “sub-goals” they’ll eventually see human beings as barriers to achieving them. The classic hyptothetical: An AI tasked with solving climate change might quickly determine that humans, and human habits, are the main obsticle to achieving its goal. An AI with extra-human intelligence, the thinking goes, might quickly learn to deceive its human operators. This danger relates directly to humans’ ability to interpret what’s going on within the inscrutable black box. OpenAI seemed to acknowledge this in a research paper published this month on AI interpretability. “Our understanding of how they work internally is still very limited,” OpenAI’s researchers wrote. “For example, it might be difficult to detect from their outputs whether they use biased heuristics or engage in deception.”In the wake of this big leap forward in natural language processing, researchers find themselves far behind in interpreting LLMs. And far more money continues to be spent on pushing the models to higher levels of performance than on gaining a better understanding of their inner workings. The question, then, is whether the profit-driven tech companies now developing AI can learn enough in the short term about how LLMs work to effectively manage the long term risks?Mechanistic interpretationLarge language models grew up quickly—arguably, too quickly. The tech’s current frontrunner, ChatGPT, is powered by a radically souped-up transformer model, an invention of Google’s from 2017. OpenAI’s researchers, in broad terms, used impressive computing power to train a transformer model on massive amounts of data scraped from the web. The results were surprising and astounding: an LLM with an eerily acute sense of human language.But OpenAI’s GPT models do more than just predict words in a sentence. Somehow, while chewing over all that training data, they gain a working knowledge of how the world works, and an ability to compute with reason.Somehow.But how do those intuitions arise from the model’s processing of its training data? And in what network layer and neuron does the LLM apply those intuitions to the content it outputs? The only certain way to answer such questions is to reverse engineer the neural network. That is, to follow the complex webwork of interactions among the neurons in the network as they react to an input (a prompt, perhaps) to generate an output (an answer). This reengineering is called “mechanistic interpretability.”“[You] can look at the absolute smallest pieces of it, which might be an individual little neuron and see what it’s reacting to, and then what it feeds that reaction into,” says Joshua Batson, an interpretability researcher at LLM developer Anthropic.  The neural networks underpinning tools like ChatGPT are composed of layer after layer of these neurons, connection points where complex mathematical calculations take place. While processing mountains of textual data in a self-supervised way (no human labeling of words or phrases, no human feedback about outputs), these neurons work together to form an abstract, many-dimensional matrix that maps out the relationships between word parts, whole words, and phrases of words. The model gains a contextual understanding of how words are used together in strings, and the ability to predict what words might come next in a sentence, or which are most likely to follow naturally from a language prompt. But today’s state-of-the-art LLMs have hundreds of millions of these neurons. Neural network architecture was roughly based on the design of the nervous systems of complex organisms (humans). And after decades of study, neuroscience has so far not succeeded in reverse-engineering that biological system.“Neuroscience has tried to take that bottom-up approach and it’s proven to be a very difficult way to study a system of such complexity,” says Aidan Gomez, CEO of the LLM developer Cohere. In a living organism, this “bottom up” approach would mean studying the way the organism intakes sensory data and tracking the impulses as they travel from neuron to neuron and eventually form a higher-order assessment that might lead to an action, Gomez says. “Following that whole pathway is extremely difficult.” And following the pathways from neuron to neuron in a synthetic neural network is similarly hard. This is a shame because it’s within those pathways that the beginnings of HAL 9000-style notions begin.Image models successThe mechanistic interpretability community owes some of its most promising advances to the study of simpler neural nets, notably those designed to recognize and classify different types of images. Within these neural nets it’s easier for researchers to identify the specific tasks of single neurons, and how the work of each neuron contributes to the overall goal of identifying the content of images.In a neural net designed to recognize cars in images, one layer of neurons might be dedicated to detecting groupings of pixels that suggest a specific shape, such as a curve or a circle. A neuron in that layer might activate and send a high probability score to another layer in the network that work out whether the shape could be a tire or a steering wheel. As these connections are made, the network becomes more and more certain that it’s looking at a car.Interpretability, then, leads to the ability to fine tune. As Anthropic’s Batson explains: “If you want to know why something that isn’t the car gets called a car, you could trace through the network and say ‘Oh, the wheel detector fired on this thing, which is actually a frying pan’ . . . and you can start to reason about this.” advertisementBatson says his group is very focused on studying important groups of neurons within LLMs, instead of single neurons. It’s a bit like a team of neurologists poking around in a human brain looking for sections that control different bodily or mental functions.“It might be that we start to figure out what the basic players are [in neural networks] to say ‘Okay, here’s how it’s mapping the physical world, here’s how it’s mapping the emotional world, here’s how it thinks about literature or individuals’ and you could get these bigger chunks or modules,” says Anthropic’s Batson.“I think the state of it today is we can apply these interpretability techniques to quite small text models, not text models for hundreds of billions of parameters size,” adds Anthropic co-founder Jack Clark. “And the question that people have is how rapidly we can apply our text interpretability techniques to much larger models.”Interpretability and safetyPerhaps the most pressing reason AI companies have for investing in interpretability research is to find better ways of erecting “guardrails” around large language models. If a model is prone to outputting toxic speech, researchers typically study the responses of the systems to a variety of potentially risky prompts, then place limitations on what the model can say, or bar the model from responding to certain prompts entirely. But that method has real limitations, says Sarah Wiegreffe, a model interpretability researcher at the Allen Institute for AI in Seattle. “It’s certainly limited in the sense that given the vast space of possible inputs the model could receive, and the vast space of possible outputs it could generate, it would be pretty difficult to reasonably enumerate all of the possible scenarios that you might have in the real world,” she says. Mechanistic interpretability in this context might mean looking deep within the layers of the network to find the crucial calculation that led to an unsafe output. “So, for example, there is some recent work showing that if you can localize a certain factual statement in a language model, you can actually edit those weights of the model to essentially correct that,” Wiegreffe says. “You can do model surgery . . . to fix things that are incorrect without needing to retrain the entire system.”But tweaking a large language model’s proclivity toward one harmful behavior might hobble its tendencies toward other behaviors we like. Explicit “do not say” commands might, for example, limit the model’s creative and improvisational capabilities. That’s a compelling argument for using less invasive ways of “steering” a model. In fact, many in the AI community remain skeptical of the need for neuron-by-neuron mechanistic interpretability to guarentee the near-term and long-term safety of AI systems. “I don’t think it’s the best way to study an intelligent system, given the timelines we’re working with,” Cohere’s Gomez says. Indeed, with capitalist forces now pushing tech companies to get LLMs into production in every industry, and, soon, into use in personal technology (Alexa and Siri, for example), the AI community may not have so long to increase their understanding of how LLMs work. “The naive approach is to simply ask the system to cite its sources,” Gomez says. “I believe in the naive approach. As these systems begin being used for more important tasks, we’ll have to demand that they base their outputs on facts.”No benchmarksWhile ample benchmarks exist for measuring the performance of language models (like standardized tests for AIs), there is yet no common set of benchmarks for measuring the interpretability of LLMs. The industry hasn’t, for example, adopted something like OpenAI’s scoring system for interpreting the output of a single neuron in an LLM.Rather, you have a lot of researchers doing their best to shine flashlights on things inside a very, very large black box. “We don’t yet have the metric or benchmark that we could all agree on and work toward,” Batson says. “We have the phenomena that we understand, and we’re putting together the big picture right now.” Researchers publish papers describing new techniques for studying models, and other researchers in the community then try to understand advances are comprehensible and build on existing intuitions.  “You definitely know when you see it,” Batson says. “You’re like ‘Oh okay, this is a much better picture of what’s going on.”Interpretability and the ‘alignment problem’While the near-term safety of LLMs is important, and will continue to be, the LLMs of the future may present far more serious threats than just toxic outputs. The researcher and philosopher Eliezer Yudkowsky has been raising the alarm that as LLMs get better and far outpace humans in intellegence, and as they become more autonomous, chances are very high that they will begin acting against the interests of humankind.That eventuality may be more likely than you think. Let’s suppose that LLMs continue getting better at learning and reasoning, and better able to capture data (real-time visual and audio data, perhaps) that ground them in the real world, and that they begin to share data and train each other. Let’s also assume that LLMs (and not some other type of AI) end up being the path to AGI, or artificial general intelligence, far exceeding human intelligence in important ways. Without a thorough (mechanistic) understanding of the early antecedents of these powerful future LLMs, can we realistically expect to manage these AIs in every stage of their development so that they remain aligned with human interests, and disinclined to act against us or even do away with us?There is disagreement on this question. Both Yudkowsky and Hinton have grave doubts that humans will be able to manage alignment in AI systems, and neither believe that acheiving mechanistic inpretability in these systems is a silver bullet.“[I]f you’re all in the middle of a global AI arms race, people will say there’s no point in slowing down because their competitors won’t slow down,” Yudkowsky says. He believes AI systems will resist human safety training by learning to conceal their internal processes. “If you try to apply your omnicidal-thoughts detector to train the giant inscrutable matrices not to have visible omnicidal thoughts anymore, you’re training both against omnicidalness and against visibility.” “This is the broad gloss on why ‘be able to see a warning sign inside the AI’s thoughts’ levels of interpretability doesn’t mean everyone is safe,” Yudkowsky says.Recognize your technological breakthrough by applying to this year’s Next Big Things in Tech Awards! Extended Deadline to Apply: Friday, July 19.",,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work#article', 'isPartOf': {'@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work'}, 'author': [{'@type': 'Person', '@id': 'https://www.fastcompany.com/user/mark-sullivan#/schema/person/2387337ba1e0b0249ba90f55b2ba2521', 'name': 'Mark Sullivan', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/mark-sullivan#/schema/person/image/ed45acf51d3827ed0bda53923a22ac6c', 'url': 'https://secure.gravatar.com/avatar/4cb07782a8697c72a4327e7524a4afb2?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/4cb07782a8697c72a4327e7524a4afb2?s=96&d=mm&r=g', 'caption': 'Mark Sullivan'}, 'url': 'https://www.fastcompany.com/user/mark-sullivan', 'description': 'Mark Sullivan is a senior writer at Fast Company, covering emerging tech, AI, and tech policy. Before coming to Fast Company in January 2016, Sullivan wrote for VentureBeat, Light Reading, CNET, Wired, and PCWorld. Follow him on Twitter <a href=""https://twitter.com/thesullivan""> @thesullivan</a>'}], 'headline': 'The frightening truth about AI chatbots: Nobody knows exactly how they work', 'datePublished': '2023-05-17T08:00:00+00:00', 'dateModified': '2023-05-25T22:31:23+00:00', 'mainEntityOfPage': {'@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work'}, 'wordCount': 2465, 'publisher': {'@id': 'https://www.fastcompany.com/#organization'}, 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work#primaryimage', 'url': 'https://images.fastcompany.com/image/upload/wp-cms/uploads/2023/05/p-1-90896928the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work.gif', 'contentUrl': 'https://images.fastcompany.com/image/upload/wp-cms/uploads/2023/05/p-1-90896928the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work.gif', 'caption': 'The frightening truth about AI chatbots: Nobody knows exactly how they work'}, 'thumbnailUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2023/05/p-1-90896928the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work.gif', 'keywords': ['Artificial Intelligence', 'chatbots', 'generative AI', 'large language models'], 'articleSection': ['Tech'], 'inLanguage': 'en-US', 'copyrightYear': '2023', 'copyrightHolder': {'@id': 'https://cms.mansueto.com/#organization'}, 'isAccessibleForFree': False, 'articleBody': 'Large language models (LLMs) like the ones that power ChatGPT and Bard are different from revolutionary technologies of the past in at least one striking way: No one—not even the people who built the models—knows exactly how they work. As tech companies race to improve and apply LLMs, researchers remain far from being able to explain or ""interpret"" the inner mechanics of these inscrutable ""black boxes."" \n\n\n\nTraditional computer programs are coded in exquisite detail to instruct a computer to perform the same task over and over. But neural networks, including those that run large language models (LLMs), program and reprogram themselves and reason in ways that are not comprehensible to humans. That\'s why when New York Times reporter Kevin Roose documented his famously strange exchange with Bing Chat earlier this year, Microsoft CTO Kevin Scott could not explain why the bot said what it said.\n\n\n\nThis ""inscrutable"" aspect of LLMs is fueling a concern among scientists that continued development and application of the technology could have serious, even catastrophic, unintended results. A growing number of scientists believe that as LLMs get better and smarter they may be used by bad actors (or defense agencies) to harm human beings. Some believe that because AI systems will posess superior intellegence and superior reasoning skills versus humans, their eventual opposition to humans is a natural and predictable part of their evolution. \n\n\n\nIn March, more than 1,000 business leaders and scientists—including Turing Award winner Yoshua Bengio, Steve Wozniak, and Elon Musk—signed an open letter calling for a six-month pause in LLM development, in part because of a lack of understanding of how these AI systems work. \n\n\n\n""[R]ecent months have seen AI labs locked in an out-of-control race to develop and deploy ever more powerful digital minds that no one—not even their creators—can understand, predict, or reliably control,"" the letter reads. \n\n\n\nNow, the ""godfather of AI"" Geoffrey Hinton has joined the ranks of concerned scientists. “I think it’s entirely possible that humanity is just a passing phase in the evolution of intelligence,"" Hinton said in a recent interview at MIT. Hinton recently quit his job at Google so that he could speak openly about the existential dangers presented by the LLMs his own research helped make possible. \n\n\n\n""I’m sounding the alarm and saying we have to worry about this,"" he said at the time of his exit. ""It’s not clear there is a solution."" Hinton says that when AI systems are allowed to set their own ""sub-goals"" they\'ll eventually see human beings as barriers to achieving them. The classic hyptothetical: An AI tasked with solving climate change might quickly determine that humans, and human habits, are the main obsticle to achieving its goal. An AI with extra-human intelligence, the thinking goes, might quickly learn to deceive its human operators. \n\n\n\nThis danger relates directly to humans\' ability to interpret what\'s going on within the inscrutable black box. OpenAI seemed to acknowledge this in a research paper published this month on AI interpretability. ""Our understanding of how they work internally is still very limited,"" OpenAI\'s researchers wrote. ""For example, it might be difficult to detect from their outputs whether they use biased heuristics or engage in deception.""\n\n\n\nIn the wake of this big leap forward in natural language processing, researchers find themselves far behind in interpreting LLMs. And far more money continues to be spent on pushing the models to higher levels of performance than on gaining a better understanding of their inner workings.&nbsp;\n\n\n\nThe question, then, is whether the profit-driven tech companies now developing AI can learn enough in the short term about how LLMs work to effectively manage the long term risks?\n\n\n\nMechanistic interpretation\n\n\n\nLarge language models grew up quickly—arguably, too quickly. The tech\'s current frontrunner, ChatGPT, is powered by a radically souped-up transformer model, an invention of Google\'s from 2017. OpenAI’s researchers, in broad terms, used impressive computing power to train a transformer model on massive amounts of data scraped from the web. The results were surprising and astounding: an LLM with an eerily acute sense of human language.\n\n\n\nBut OpenAI’s GPT models do more than just predict words in a sentence. Somehow, while chewing over all that training data, they gain a working knowledge of how the world works, and an ability to compute with reason.\n\n\n\nSomehow.\n\n\n\nBut how do those intuitions arise from the model\'s processing of its training data? And in what network layer and neuron does the LLM apply those intuitions to the content it outputs? The only certain way to answer such questions is to reverse engineer the neural network. That is, to follow the complex webwork of interactions among the neurons in the network as they react to an input (a prompt, perhaps) to generate an output (an answer). This reengineering is called “mechanistic interpretability.”\n\n\n\n“[You] can look at the absolute smallest pieces of it, which might be an individual little neuron and see what it\'s reacting to, and then what it feeds that reaction into,” says Joshua Batson, an interpretability researcher at LLM developer Anthropic.&nbsp;&nbsp;\n\n\n\nThe neural networks underpinning tools like ChatGPT are composed of layer after layer of these neurons, connection points where complex mathematical calculations take place. While processing mountains of textual data in a self-supervised way (no human labeling of words or phrases, no human feedback about outputs), these neurons work together to form an abstract, many-dimensional matrix that maps out the relationships between word parts, whole words, and phrases of words. The model gains a contextual understanding of how words are used together in strings, and the ability to predict what words might come next in a sentence, or which are most likely to follow naturally from a language prompt.&nbsp;\n\n\n\nBut today’s state-of-the-art LLMs have hundreds of millions of these neurons. Neural network architecture was roughly based on the design of the nervous systems of complex organisms (humans). And after decades of study, neuroscience has so far not succeeded in reverse-engineering that biological system.\n\n\n\n“Neuroscience has tried to take that bottom-up approach and it’s proven to be a very difficult way to study a system of such complexity,” says Aidan Gomez, CEO of the LLM developer Cohere. In a living organism, this “bottom up” approach would mean studying the way the organism intakes sensory data and tracking the impulses as they travel from neuron to neuron and eventually form a higher-order assessment that might lead to an action, Gomez says. “Following that whole pathway is extremely difficult.”&nbsp;\n\n\n\nAnd following the pathways from neuron to neuron in a synthetic neural network is similarly hard.&nbsp;This is a shame because it\'s within those pathways that the beginnings of HAL 9000-style notions begin.\n\n\n\nImage models success\n\n\n\nThe mechanistic interpretability community owes some of its most promising advances to the study of simpler neural nets, notably those designed to recognize and classify different types of images. Within these neural nets it\'s easier for researchers to identify the specific tasks of single neurons, and how the work of each neuron contributes to the overall goal of identifying the content of images.\n\n\n\nIn a neural net designed to recognize cars in images, one layer of neurons might be dedicated to detecting groupings of pixels that suggest a specific shape, such as a curve or a circle. A neuron in that layer might activate and send a high probability score to another layer in the network that work out whether the shape could be a tire or a steering wheel. As these connections are made, the network becomes more and more certain that it’s looking at a car.\n\n\n\nInterpretability, then, leads to the ability to fine tune. As Anthropic’s Batson explains: “If you want to know why something that isn\'t the car gets called a car, you could trace through the network and say ‘Oh, the wheel detector fired on this thing, which is actually a frying pan\' . . . and you can start to reason about this.”&nbsp;\n\n\n\nBatson says his group is very focused on studying important groups of neurons within LLMs, instead of single neurons. It\'s a bit like a team of neurologists poking around in a human brain looking for sections that control different bodily or mental functions.\n\n\n\n“It might be that we start to figure out what the basic players are [in neural networks] to say ‘Okay, here\'s how it\'s mapping the physical world, here\'s how it\'s mapping the emotional world, here\'s how it thinks about literature or individuals’ and you could get these bigger chunks or modules,” says Anthropic\'s Batson.\n\n\n\n“I think the state of it today is we can apply these interpretability techniques to quite small text models, not text models for hundreds of billions of parameters size,” adds Anthropic co-founder Jack Clark. “And the question that people have is how rapidly we can apply our text interpretability techniques to much larger models.""\n\n\n\nInterpretability and safety\n\n\n\nPerhaps the most pressing reason AI companies have for investing in interpretability research is to find better ways of erecting “guardrails” around large language models. If a model is prone to outputting toxic speech, researchers typically study the responses of the systems to a variety of potentially risky prompts, then place limitations on what the model can say, or bar the model from responding to certain prompts entirely.&nbsp;\n\n\n\nBut that method has real limitations, says Sarah Wiegreffe, a model interpretability researcher at the Allen Institute for AI in Seattle.&nbsp;“It\'s certainly limited in the sense that given the vast space of possible inputs the model could receive, and the vast space of possible outputs it could generate, it would be pretty difficult to reasonably enumerate all of the possible scenarios that you might have in the real world,” she says.&nbsp;\n\n\n\nMechanistic interpretability in this context might mean looking deep within the layers of the network to find the crucial calculation that led to an unsafe output. “So, for example, there is some recent work showing that if you can localize a certain factual statement in a language model, you can actually edit those weights of the model to essentially correct that,” Wiegreffe says. “You can do model surgery . . . to fix things that are incorrect without needing to retrain the entire system.”\n\n\n\nBut tweaking a large language model’s proclivity toward one harmful behavior might hobble its tendencies toward other behaviors we like. Explicit “do not say” commands might, for example, limit the model’s creative and improvisational capabilities. That’s a compelling argument for using less invasive ways of “steering” a model.&nbsp;\n\n\n\nIn fact, many in the AI community remain skeptical of the need for neuron-by-neuron mechanistic interpretability to guarentee the near-term and long-term safety of AI systems.&nbsp;\n\n\n\n“I don\'t think it’s the best way to study an intelligent system, given the timelines we’re working with,” Cohere’s Gomez says.&nbsp;\n\n\n\nIndeed, with capitalist forces now pushing tech companies to get LLMs into production in every industry, and, soon, into use in personal technology (Alexa and Siri, for example), the AI community may not have so long to increase their understanding of how LLMs work.&nbsp;\n\n\n\n“The naive approach is to simply ask the system to cite its sources,"" Gomez says. “I believe in the naive approach. As these systems begin being used for more important tasks, we’ll have to demand that they base their outputs on facts.”\n\n\n\nNo benchmarks\n\n\n\nWhile ample benchmarks exist for measuring the performance of language models (like standardized tests for AIs), there is yet no common set of benchmarks for measuring the interpretability of LLMs. The industry hasn’t, for example, adopted something like OpenAI’s scoring system for interpreting the output of a single neuron in an LLM.\n\n\n\nRather, you have a lot of researchers doing their best to shine flashlights on things inside a very, very large black box. “We don\'t yet have the metric or benchmark that we could all agree on and work toward,” Batson says.&nbsp;“We have the phenomena that we understand, and we\'re putting together the big picture right now.”&nbsp;Researchers publish papers describing new techniques for studying models, and other researchers in the community then try to understand advances are comprehensible and build on existing intuitions.&nbsp;&nbsp;\n\n\n\n“You definitely know when you see it,” Batson says. “You’re like ‘Oh okay, this is a much better picture of what’s going on.”\n\n\n\nInterpretability and the \'alignment problem\'\n\n\n\nWhile the near-term safety of LLMs is important, and will continue to be, the LLMs of the future may present far more serious threats than just toxic outputs.&nbsp;The researcher and philosopher Eliezer Yudkowsky has been raising the alarm that as LLMs get better and far outpace humans in intellegence, and as they become more autonomous, chances are very high that they will begin acting against the interests of humankind.\n\n\n\nThat eventuality may be more likely than you think. Let’s suppose that LLMs continue getting better at learning and reasoning, and better able to capture data (real-time visual and audio data, perhaps) that ground them in the real world, and that they begin to share data and train each other. Let\'s also assume that LLMs (and not some other type of AI) end up being the path to AGI, or artificial general intelligence, far exceeding human intelligence in important ways. Without a thorough (mechanistic) understanding of the early antecedents of these powerful future LLMs, can we realistically expect to manage these AIs in every stage of their development so that they remain aligned with human interests, and disinclined to act against us or even do away with us?\n\n\n\nThere is disagreement on this question. Both Yudkowsky and Hinton have grave doubts that humans will be able to manage alignment in AI systems, and neither believe that acheiving mechanistic inpretability in these systems is a silver bullet.\n\n\n\n“[I]f you\'re all in the middle of a global AI arms race, people will say there\'s no point in slowing down because their competitors won\'t slow down,"" Yudkowsky says. He believes AI systems will resist human safety training by learning to conceal their internal processes.&nbsp;""If you try to apply your omnicidal-thoughts detector to train the giant inscrutable matrices not to have visible omnicidal thoughts anymore, you\'re training both against omnicidalness and against visibility.” \n\n\n\n“This is the broad gloss on why ‘be able to see a warning sign inside the AI\'s thoughts’ levels of interpretability doesn\'t mean everyone is safe,” Yudkowsky says.'}, {'@type': 'WebPage', '@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work', 'url': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work', 'name': 'The scary truth about AI chatbots: Nobody knows exactly how they work', 'isPartOf': {'@id': 'https://www.fastcompany.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work#primaryimage'}, 'image': {'@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work#primaryimage'}, 'thumbnailUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2023/05/p-1-90896928the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work.gif', 'datePublished': '2023-05-17T08:00:00+00:00', 'dateModified': '2023-05-25T22:31:23+00:00', 'description': 'Nobody really knows how chatbots work. The AI community is divided on whether that fact could come to haunt us as the technology improves and proliferates.', 'breadcrumb': {'@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work']}], 'author': [{'@type': 'Person', '@id': 'https://www.fastcompany.com/user/mark-sullivan#/schema/person/2387337ba1e0b0249ba90f55b2ba2521', 'name': 'Mark Sullivan', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/mark-sullivan#/schema/person/image/ed45acf51d3827ed0bda53923a22ac6c', 'url': 'https://secure.gravatar.com/avatar/4cb07782a8697c72a4327e7524a4afb2?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/4cb07782a8697c72a4327e7524a4afb2?s=96&d=mm&r=g', 'caption': 'Mark Sullivan'}, 'url': 'https://www.fastcompany.com/user/mark-sullivan', 'description': 'Mark Sullivan is a senior writer at Fast Company, covering emerging tech, AI, and tech policy. Before coming to Fast Company in January 2016, Sullivan wrote for VentureBeat, Light Reading, CNET, Wired, and PCWorld. Follow him on Twitter <a href=""https://twitter.com/thesullivan""> @thesullivan</a>'}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work#primaryimage', 'url': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2023/05/p-1-90896928the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work.gif', 'contentUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms/uploads/2023/05/p-1-90896928the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work.gif', 'width': 1188, 'height': 668, 'caption': '[Source animation: themotioncloud/Getty Images]'}, {'@type': 'BreadcrumbList', '@id': 'https://www.fastcompany.com/90896928/the-frightening-truth-about-ai-chatbots-nobody-knows-exactly-how-they-work#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.fastcompany.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'The frightening truth about AI chatbots: Nobody knows exactly how they work'}]}, {'@type': 'WebSite', '@id': 'https://www.fastcompany.com/#website', 'url': 'https://www.fastcompany.com/', 'name': 'Fast Company', 'description': '', 'publisher': {'@id': 'https://www.fastcompany.com/#organization'}, 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.fastcompany.com/#organization', 'name': 'Fast Company', 'url': 'https://www.fastcompany.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/#/schema/logo/image/', 'url': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms-2/2024/03/fc_logo.png', 'contentUrl': 'https://images.fastcompany.com/image/upload/f_auto,q_auto,c_fit/wp-cms-2/2024/03/fc_logo.png', 'width': 696, 'height': 696, 'caption': 'Fast Company'}, 'image': {'@id': 'https://www.fastcompany.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/FastCompany/', 'https://x.com/FastCompany', 'https://fastcompany.social/@fastcompany', 'https://www.linkedin.com/company/fast-company/']}, {'@type': 'Person', '@id': 'https://www.fastcompany.com/user/mark-sullivan#/schema/person/2387337ba1e0b0249ba90f55b2ba2521', 'name': 'Mark Sullivan', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.fastcompany.com/user/mark-sullivan#/schema/person/image/ed45acf51d3827ed0bda53923a22ac6c', 'url': 'https://secure.gravatar.com/avatar/4cb07782a8697c72a4327e7524a4afb2?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/4cb07782a8697c72a4327e7524a4afb2?s=96&d=mm&r=g', 'caption': 'Mark Sullivan'}, 'url': 'https://www.fastcompany.com/user/mark-sullivan', 'description': 'Mark Sullivan is a senior writer at Fast Company, covering emerging tech, AI, and tech policy. Before coming to Fast Company in January 2016, Sullivan wrote for VentureBeat, Light Reading, CNET, Wired, and PCWorld. Follow him on Twitter <a href=""https://twitter.com/thesullivan""> @thesullivan</a>'}]",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiwAFodHRwczovL3d3dy5idXNpbmVzc3dpcmUuY29tL25ld3MvaG9tZS8yMDIzMDUxODAwNTI3My9lbi9Gb3J0dW5lLTUwMC1TdHVkeS1SZXZlYWxzLVRyaXBsZS1EaWdpdC1Hcm93dGgtb2YtQXJ0aWZpY2lhbC1JbnRlbGxpZ2VuY2UtQXV0b21hdGlvbi1hbmQtRXhwZXJpZW5jZS10by1Db3VudGVyYWN0LUV4dGVuZGVkLUhpcmluZy1DcmlzaXPSAQA?oc=5,"Fortune 500 Study Reveals: Triple-Digit Growth of Artificial Intelligence, Automation and Experience to Counteract ... - Business Wire",2023-05-18,Business Wire,https://www.businesswire.com,"Fortune 500 Study Reveals: Triple-Digit Growth of Artificial Intelligence, Automation and Experience to Counteract Extended Hiring Crisis",N/A,"Fortune 500 Study Reveals: Triple-Digit Growth of Artificial Intelligence, Automation and Experience to Counteract Extended Hiring Crisis","Fortune 500 Study Reveals: Triple-Digit Growth of Artificial Intelligence, Automation and Experience to Counteract Extended Hiring Crisis",,,,,,,,,,,,N/A,N/A,"




Fortune 500 Study Reveals: Triple-Digit Growth of Artificial Intelligence, Automation and Experience to Counteract Extended Hiring Crisis






AI-Personalized Career Sites and Chatbots Lead the Pack in Growth Over 3 Years, According to Phenom’s 2023 State of Candidate Experience Report














Download







Fortune 500 study reveals triple-digit growth of AI, automation and experience to counteract extended hiring crisis. AI-personalized career sites and chatbots lead the pack in growth over 3 years, according to Phenom’s 2023 State of Candidate Experience Report. (Photo: Business Wire)












Fortune 500 study reveals triple-digit growth of AI, automation and experience to counteract extended hiring crisis. AI-personalized career sites and chatbots lead the pack in growth over 3 years, according to Phenom’s 2023 State of Candidate Experience Report. (Photo: Business Wire)





Image








Full Size








Small








Preview








Thumbnail


















Image








Full Size








Small








Preview








Thumbnail














May 18, 2023 10:00 AM Eastern Daylight Time



PHILADELPHIA--(BUSINESS WIRE)--Phenom today released its State of Candidate Experience: 2023 Benchmarks Report. Phenom’s seventh annual audit revealed that since 2020, the Fortune 500 has made significant strides to enhance the candidate experience by implementing AI technology and automation to connect job seekers — both hourly and knowledge workers — with relevant jobs faster, and creating engaging content to convey a strong employer brand in the highly competitive U.S. talent market.


“Multiple industries remain in a hiring crisis with open roles costing them millions, and enhancing the candidate experience is the first step to addressing this issue,” said Mahe Bayireddi, CEO and co-founder of Phenom.Post this

The report highlights improvements Fortune 500 companies have made in the last three years to deliver hyper-personalized experiences and job matching that strengthen candidate attraction, engagement and conversion, including a:



250% increase in presenting job recommendations based on browsing history



150% increase in the use of AI-powered chatbots



145% improvement in easy site navigation



87% increase in displaying recently viewed jobs



74% increase in video content



50% increase in well-written job descriptions



Although organizations are increasingly adopting AI-powered technology, 89% scored poorly in their use of AI, indicating there is still a significant gap between the solutions available and what companies have implemented. According to the 2023 audit:



86% did not present job recommendations based on browsing history



85% did not use chatbots



85% did not display recently viewed jobs



84% did not provide job recommendations based on candidate profile



80% lacked compelling content on their career sites



“Multiple industries remain in a hiring crisis with open roles costing them millions, and enhancing the candidate experience is the first step to addressing this issue,” said Mahe Bayireddi, CEO and co-founder of Phenom. “Providing personalized experiences for job seekers is only possible through intelligence and automation.”


The ROI of Intelligence, Automation and Experience

The future of every company no longer hinges on its ability to outpace competitors for talent — employers must embrace cutting-edge practices and technology for hiring, developing and retaining employees. Intelligence, automation and experience are essential to overcoming today’s biggest talent acquisition and retention challenges, including simplifying the job search process and maintaining an attractive, unique employer brand.


For hourly workers, automating hiring workflows reduces friction throughout every step of the hiring process, ensuring organizations can attract, engage and hire faster and more efficiently. For knowledge workers, intelligence brings highly personalized, contextually relevant information to enhance productivity and output. Technology such as hyper-personalized career sites, conversational chatbots, automated screening and scheduling, and content that showcases a company’s culture all enrich the candidate experience — helping them find the right job and apply faster.


Savvy organizations that are leveraging AI-powered technology and automation through the Phenom Intelligent Talent Experience platform are attracting more best-fit job seekers, growing talent communities and increasing completed applications, and the results speak for themselves:



A major telecommunications company increased career site traffic by 220% and increased completed applications by 700% with intelligent tools that provided a more personalized experience for candidates



A major health care organization achieved a 10% increase in nursing hires by expediting communication with candidates through a conversational chatbot and SMS messages



A major financial institution added 8X more candidates to their talent community by creating a dynamic, hyper-personalized career site and targeting recruitment marketing efforts



A popular restaurant chain registered over 12,000 candidates through their career site and talent email campaigns in less than a month — resulting in more than 2,000 same-day offers to candidates and 1,300+ same-week hires



A leading retail chain hired 7,000 workers in two weeks using their AI-powered chatbot, career site, CRM and video assessments to automate routine, early stage hiring practices — reducing time to hire from weeks to 8 hours



Actions Organizations Can Take to Accelerate Hiring

To improve the candidate experience, Phenom’s State of Candidate Experience report prescribes a series of actions organizations can take — from creating strong employer brand content to implementing intelligent career site technology:



Personalize the candidate experience through AI and automation. Candidates today expect the online job search to be similar to purchasing consumer goods, where relevant information is delivered based on their interests. If this process is not intuitive and simple, candidates are more likely to drop off a career site. With AI and automation on a career site, personalized jobs and content are automatically displayed for candidates based on their resume, experience, skills, and geographic location.



Showcase a strong employer brand through content. When deciding if a job is the right fit, candidates spend a significant amount of time researching a company. If a digital brand does not meet their expectations, they may not feel a strong connection and apply to an open role. Content on a career site (videos, pictures, blogs, etc.) that conveys information such as a company’s mission and purpose, overall workplace culture, employee quotes and stories, internal events and employee resource groups all paint a picture of what it is like to work there.



Embrace cutting-edge technology. In addition to AI and automation, organizations must be quick to responsibly adopt work-altering innovations, including: generative AI, which enables organizations to be more productive and fill roles faster by automatically creating content, surfacing actionable intelligence, and eliminating time-consuming tasks; interview intelligence, which brings transparency to hiring teams through recordings, transcriptions, key takeaway, and analysis to move the process forward faster; and candidate hub, a one-stop-shop that helps candidates understand where they are in the hiring process and prepare for next steps.



With Phenom, candidates find and choose the right job faster, employees develop their skills and evolve, recruiters become wildly productive, managers build stronger-performing teams, HR aligns employee development with company goals, and HRIS easily integrates existing HR tech to create a holistic infrastructure.


To read the full 2023 report and company rankings, download here.
Organizations can request their own complimentary career site audit here.


About Phenom

Phenom has a purpose of helping a billion people find the right job. Through AI-powered talent experiences, employers are using Phenom to hire employees faster, develop them to their full potential, and retain them longer. The Phenom Intelligent Talent Experience platform seamlessly connects candidates, employees, recruiters, hiring managers, HR and HRIS — empowering over 500 diverse and global enterprises with innovative products including Phenom Career Site, Chatbot, CMS, CRM, AI Scheduling, Video Assessments, Campaigns, University Recruiting, Talent Marketplace, Career Pathing, Gigs, Mentoring, and Referrals.


Phenom has earned accolades including: Inc. 5000’s fastest-growing companies (3 consecutive years), Deloitte Technology's Fast 500 (4 consecutive years), five Brandon Hall ‘Excellence in Technology’ awards including Gold for ‘Best Advance in AI for Business Impact,’ Business Intelligence Group's Artificial Intelligence Excellence Awards (3 consecutive years), and a regional Timmy Award for launching and optimizing HelpOneBillion.com (2020).


Headquartered in Greater Philadelphia, Phenom also has offices in India, Israel, the Netherlands, Germany and the United Kingdom.


For more information, please visit www.phenom.com. Connect with Phenom on LinkedIn, Twitter, Facebook, YouTube and Instagram.




Contacts

Media:
Jennifer Lyons
Director, Global Communications
267-379-5066
jennifer.lyons@phenompeople.com




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LmVkd2Vlay5vcmcvdGVjaG5vbG9neS9kYXktb2YtYWktc3B1cnMtY2xhc3Nyb29tLWRpc2N1c3Npb25zLW9uLXNvY2lldGFsLWltcGFjdHMtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvMjAyMy8wNdIBAA?oc=5,'Day of AI' Spurs Classroom Discussions on Societal Impacts of Artificial Intelligence - Education Week,2023-05-19,Education Week,https://www.edweek.org,The White House’s ‘Blueprint for an AI Bill of Rights’ anchors  K-12 curricular materials from the Massachusetts Institute of Technology.,"Classroom Technology,Technology,Artificial Intelligence",The White House's 'Blueprint for an AI Bill of Rights' anchors K-12 curricular materials from the Massachusetts Institute of Technology.,The White House's 'Blueprint for an AI Bill of Rights' anchors K-12 curricular materials from the Massachusetts Institute of Technology.,http://schema.org,NewsArticle,'Day of AI' Spurs Classroom Discussions on Societal Impacts of Artificial Intelligence,"'Day of AI' Spurs Classroom Discussions on Societal Impacts of Artificial Intelligence,'Day of AI' Spurs Classroom Discussions on Societal Impacts of Artificial Intelligence","{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/f2/84/cfe7a7ad44189368aeac553725b7/ai-workforce-1403226464-b.jpg'}",Benjamin Herold,https://www.edweek.org/technology/day-of-ai-spurs-classroom-discussions-on-societal-impacts-of-artificial-intelligence/2023/05,"May 19, 2023","{'@type': 'Organization', 'name': 'Education Week', 'url': 'https://www.edweek.org', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/75/82/ccb9d563497697b5d6249f008c2e/ben-herold-blue-updated.jpg'}}",,,"Technology, Classroom Technology",N/A,N/A,"{'@type': 'WebPage', '@id': 'https://www.edweek.org/technology/day-of-ai-spurs-classroom-discussions-on-societal-impacts-of-artificial-intelligence/2023/05'}",en-US,"May 22, 2023",,,,2023,,,,,,,,,,,,,,,,https://epe.brightspotcdn.com/f2/84/cfe7a7ad44189368aeac553725b7/ai-workforce-1403226464-b.jpg,,,,,,News,"Classroom Technology,Technology,Artificial Intelligence",https://www.edweek.org/technology/day-of-ai-spurs-classroom-discussions-on-societal-impacts-of-artificial-intelligence/2023/05#comments,true,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Education Week', 'description': 'Benjamin Herold was a contributing writer who covered learning environments and ed-tech issues for Education Week, and a contributing writer for EdWeek Market Brief.', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/75/82/ccb9d563497697b5d6249f008c2e/ben-herold-blue-updated.jpg'}, 'jobTitle': 'Contributing Writer', 'name': 'Benjamin Herold', 'url': 'https://www.edweek.org/by/benjamin-herold'}]",https://www.edweek.org/about,P3M,588,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LnNwaWNld29ya3MuY29tL2hyL3JlY3J1aXRtZW50LW9uYm9hcmRpbmcvbmV3cy9taWNyb3NvZnQtYW5kLXNhcC1hbm5vdW5jZS1jb2xsYWJvcmF0aW9uL9IBY2h0dHBzOi8vd3d3LnNwaWNld29ya3MuY29tL2hyL3JlY3J1aXRtZW50LW9uYm9hcmRpbmcvbmV3cy9taWNyb3NvZnQtYW5kLXNhcC1hbm5vdW5jZS1jb2xsYWJvcmF0aW9uLw?oc=5,Microsoft and SAP Announce Collaboration on Generative AI - Spiceworks News and Insights,2023-05-17,Spiceworks News and Insights,https://www.spiceworks.com,SAP and Microsoft are integrating SuccessFactors with Copilot and Azure OpenAI to improve how companies hire and retain talent. Learn more.,SAP and Microsoft partnership,SAP and Microsoft are integrating SuccessFactors with Copilot and Azure OpenAI to improve how companies hire and retain talent. Learn more.,N/A,,,,,,,,,,,,N/A,N/A,"



























 



Karthik Kashyap








May 17, 2023




 






SAP and Microsoft have announced an integration of SuccessFactors with Microsoft’s Copilot, Copilot in Viva Learning, and Azure OpenAI.
The integration aims to bring the power of AI to HR leaders so that they can attract and retain top talent in today’s competitive job market.

Tech majors SAP and Microsoft have announced that they will deepen their collaboration on joint generative AI projects with regard to recruitment. SAP said that it would integrate its solution, SuccessFactors, with Microsoft’s Copilot, Copilot in Viva Learning, and Azure OpenAI to obtain language models to analyze and generate natural language. The integrations are expected to improve how companies attract, skill, and retain talent.
SAP and Microsoft already have partnerships across various fields over the years. For example, the companies integrated Microsoft Teams with SAP’s suite of solutions in 2021. Last year, Microsoft chose RISE with SAP on Microsoft Cloud.
Talking about the latest integration, Microsoft CEO Satya Nadella said, “We’re building on our long-standing cloud partnership with SAP and bringing together the power of Microsoft 365 Copilot with SAP SuccessFactors solutions to transform how organizations attract and develop their most important resource — their people.”
See more: Four Ways to Transform the Hiring Processes with AI
Integration Aims To Solve a Tough Business Challenge
The business environment has drastically evolved over the last three years for various reasons, including the COVID-19 pandemic and changing employee expectations. One of the toughest challenges businesses face today is finding and retaining the right talent in today’s economic environment. According to Russell Reynolds Associates’ 2022 Global Leadership Monitor Survey conducted last year, 72% of businesses considered lack of skilled talent availability as the top challenge.
Reducing or closing this gap means optimizing how companies recruit people in today’s competitive job market and how they deliver learning programs that can help their employees grow. At present, these functions involve significant manual and repetitive work and often miss the mark. Further, closing the gap between an employee’s career aspirations and upskilling and cross-skilling opportunities organizations offer is challenging.
With the latest integration, SAP and Microsoft intend to enable former’s customers to benefit by using generative AI. The integration intends to help these customers attract the most qualified people for important roles and provide personalized insights to engage them once recruited.
SAP plans to make this happen by using its SuccessFactors data and Microsoft’s solutions to develop highly targeted job descriptions and fine-tune them. The company also intends to ensure there is no bias. Further, it plans to publish the job descriptions in SuccessFactors solutions without the need for HR leaders to disrupt their workflow. Furthermore, the company plans to use Copilot in Viva Learning to create personalized learning recommendations that align with the employee’s development and career goals.
The announcement may prove to be a model for how artificial intelligence tools can be used to enhance the power of data and systems in a given field.
How else do you think generative AI can be used in workforce development and management? Share with us on LinkedInOpens a new window , TwitterOpens a new window , or FacebookOpens a new window . We’d love to hear from you!
Image source: Shutterstock
MORE ON AI IN RECRUITMENT
Leveraging AI To Improve the Candidate Experience
Audit Your AI: How To Get Rid of Talent Biases
Quality of Hire and AI: Top Priorities for Recruiting Teams This Year







								                  future of work										



Share This Article:
 






Karthik Kashyap




 opens a new window
 opens a new window 



 opens a new window  opens a new window
  	
					Karthik comes from a diverse educational and work background. With an engineering degree and a Masters in Supply Chain and Operations Management from Nottingham University, United Kingdom, he has experience of close to 15 years having worked across different industries out of which, he has worked as a content marketing professional for a significant part of his career. Currently, as an assistant editor at Spiceworks Ziff Davis, he covers a broad range of topics across HR Tech and Martech, from talent acquisition to workforce management and from marketing strategy to innovation. Besides being a content professional, Karthik is an avid blogger, traveler, history buff, and fitness enthusiast. To share quotes or inputs for news pieces, please get in touch on karthik.kashyap@swzd.com			








								Do you still have questions? Head over to the Spiceworks Community to find answers.
							

Take me to Community





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMinwFodHRwczovL3d3dy5zZXlmYXJ0aC5jb20vbmV3cy1pbnNpZ2h0cy9lZW9jLWlzc3Vlcy10ZWNobmljYWwtYXNzaXN0YW5jZS1ndWlkYW5jZS1vbi10aGUtdXNlLW9mLWFkdmFuY2VkLXRlY2hub2xvZ3ktdG9vbHMtaW5jbHVkaW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLmh0bWzSAQA?oc=5,"EEOC Issues Technical Assistance Guidance On The Use Of Advanced Technology Tools, Including Artificial Intelligence - Seyfarth Shaw LLP",2023-05-19,Seyfarth Shaw LLP,https://www.seyfarth.com,"Seyfarth Synopsis: On May 18, 2023, the Equal Employment Opportunity Commission (EEOC) released Technical Assistance on the use of advanced technologies in the workplace titled Select Issues: Assessing Adverse Impact in Software, Algorithms, and Artificial Intelligence Used in Employment Selection Procedures Under Title VII of the Civil Rights Act of 1964 (“TA”). The EEOC did not unveil new policies in the TA but reiterated that its long existing policies and practices continue to apply to technologies, such as artificial intelligence and machine learning tools, that are grabbing the public’s attention today.  The TA broadly defines the types of automated systems that may be subject to employment laws and poses seven questions and answers meant to help employers understand their obligations to avoid discriminatory employment decisions, regardless of whether those decisions are made by humans or machines. The publication is an important read for employers.","EEOC Issues Technical Assistance Guidance On The Use Of Advanced Technology Tools, Including Artificial Intelligence","Seyfarth Synopsis: On May 18, 2023, the Equal Employment Opportunity Commission (EEOC) released Technical Assistance on the use of advanced technologies in the workplace titled Select Issues: Assessing Adverse Impact in Software, Algorithms, and Artificial Intelligence Used in Employment Selection Procedures Under Title VII of the Civil Rights Act of 1964 (“TA”). The EEOC did not unveil new policies in the TA but reiterated that its long existing policies and practices continue to apply to technologies, such as artificial intelligence and machine learning tools, that are grabbing the public’s attention today.  The TA broadly defines the types of automated systems that may be subject to employment laws and poses seven questions and answers meant to help employers understand their obligations to avoid discriminatory employment decisions, regardless of whether those decisions are made by humans or machines. The publication is an important read for employers.",N/A,,,,,,,,,,,,N/A,N/A,"Legal Update5/19/2023EEOC Issues Technical Assistance Guidance On The Use Of Advanced Technology Tools, Including Artificial IntelligenceClick to share this pageClick for PDFClick to print this pageSeyfarth Synopsis: On May 18, 2023, the Equal Employment Opportunity Commission (EEOC) released Technical Assistance on the use of advanced technologies in the workplace titled Select Issues: Assessing Adverse Impact in Software, Algorithms, and Artificial Intelligence Used in Employment Selection Procedures Under Title VII of the Civil Rights Act of 1964 (“TA”). The EEOC did not unveil new policies in the TA but reiterated that its long existing policies and practices continue to apply to the technologies (such as artificial intelligence and machine learning tools) that are grabbing the public’s attention today.  The TA broadly defines the types of automated systems that may be subject to employment laws and poses seven questions and answers designed to help employers avoid discriminatory employment decisions regardless of whether those decisions are made by humans or machines. The publication is an important read for employers.
EEOC Emphasizes That Long-Standing Title VII Principles Apply Even To New Technologies
In its new publication, the EEOC acknowledges that it is not announcing new policies. Rather, the publication “applies principles already established in the Title VII statutory provisions as well as previously issued guidance” to advanced technologies used in the workplace.
In line with that approach, the EEOC makes clear that it takes a broad view of the types of technology it has the authority to cover. Specifically any software, algorithm, AI, or other automated tool that is used to make “selection decisions” such as hiring, promotion and terminations, must be used in a manner consistent with EEO statutes. Expanding existing legal theories to emerging issues like AI and other technology tools fits squarely within the EEOC’s strategic enforcement priorities. A detailed examination of the EEOC’s strategic goals can be found here.
Focus On Disparate Impact Discrimination
The publication focuses on theories of “disparate impact” discrimination under Title VII of the Civil Rights Act of 1964. Disparate impact (sometimes called “adverse impact”) refers to the use of a facially neutral test or selection procedure that has the effect of disproportionately excluding members of a protected group, if the tests or selection procedures are not “job related for the position in question and consistent with business necessity.” Disparate impact theories are powerful tools for the EEOC, as they necessarily implicate broad swaths of potential “victims” in a single enforcement action, maximizing EEOC’s “bang for the buck.”
EEOC Expects Employers To Assess Algorithmic Decision-Making Tools For Adverse Impact In Accordance With The Uniform Guidelines on Employee Selection Procedures
Since 1978, the EEOC has directed employers to follow its Uniform Guidelines on Employee Section Procedures (Guidelines) to determine whether tests and selection procedures are lawful under Title VII. In its TA, the EEOC reiterated that the Guidelines continue to apply to new technologies “when they are used to make or inform decisions about whether to hire, promote, terminate, or take similar actions toward applicants or current employees.”
As a result, the EEOC’s expectation is that employers will assess whether a selection procedure has an adverse impact on a particular protected group. The assessment requires a comparison between the selection rates for individuals in a protected group to those not in the protected group. Significant differences between the two groups must be remedied, unless the employer can show that the selection procedure is job related and consistent with business necessity.
Employers Can Be Responsible For Tools Designed And Administered By Others, Including Vendors
In the TA, the EEOC made it clear that employers may be held liable for the tools created by third parties, including software vendors, and cannot simply wash their hands of responsibility for the outcomes that flow from using tools developed by others.
The EEOC suggests that employers must, at a minimum, ask vendors whether steps have been taken to evaluate whether use of the tool causes a substantially lower selection rate for those in protected groups. However, the EEOC also makes clear that an employer cannot rely on the representations of its vendors. If the vendor says its assessment does not result in different selection rates, but disparate impact nonetheless results, the employer may still be on the hook for any adverse results. As a best practice, employers should vet any tools provided by third parties before putting the tools into use, and also implement audit procedures designed to monitor the results of using those tools to guard against any adverse impact.
With regard to third-party developers of tools, EEOC Commissioners have separately suggested that vendors themselves could be targeted by the Commission if their input into employment decisions are enough to bring them into the orbit of EEO laws. While not specifically addressed in the TA, this is an important issue that we will continue to track.
The Four-Fifths (80%) Rule Alone Does Not Provide A Safe Harbor For Measuring Allowable Differences In Selection Rates
One clarification likely to grab the attention of employers (and vendors) is the EEOC’s position that the well-known “four-fifths rule” may not be used as a sole measure to assess bias in a selection tool.  As described in the Guidelines, the four-fifths rule is one measure used to assess whether selection rates of two groups are “substantially” different. More specifically, if one group’s selection rate is less than 80% of that of the comparison group, the rates are considered substantially different.
In the TA, the EEOC emphasized that the four-fifths rule is only a “general rule of thumb” that is “practical and easy-to-administer,” and courts have found that it is not a reasonable substitute for statistical tests. Curiously, the EEOC has historically championed the use of the four-fifths rule to assess significance in other contexts. (See prior EEOC Guidance here for an example.)
The EEOC’s position is important as many vendors and employers have used the four-fifths rule articulated in the EEOC’s 1978 Guidance as a threshold analysis in bias audits.  The general thinking was that since the four-fifths rule was a well-established benchmark articulated by EEOC and long applied to other testing and assessment tools, it was a good threshold indicator of potential bias in the absence of other guidance. Indeed, the FAQs in the Guidelines provide that to assess adverse impact, “federal enforcement agencies normally will use only the 80% (4/5ths) rule of thumb, except where large numbers of selections are made.” (See FAQ Guidelines Q18).
In keeping with the clarifying comments in the EEOC’s TA, as well as issues related to the appropriate audit method depending on the sizes of the pools being analyzed, employers and vendors that are studying the effects of selection tools (or asking vendors about the tools they provide) may need to reassess their audit strategies. This may include implementing audit standards that evaluate both statistical significance and practical significance, using the four fifths test or other “practical significance” methodologies.
Employers Should Act Upon Discovering That An Algorithmic Decision-Making Tool Results In A Disparate Impact
The EEOC encourages employers to conduct self-analyses before implementing any new tool, and periodically thereafter to ensure that the tool is operating free of bias. If an employer discovers that a tool would have an adverse impact, the EEOC’s expectation is that the employer will either take steps to remedy the impact or select a different tool to use going forward.
EEOC’s Initiatives And Guidance Related To Automated Systems and AI
The TA is part of the EEOC’s Artificial Intelligence and Algorithmic Fairness Initiative, first announced in October 2021, which was designed to ensure that AI and other emerging tools used in hiring and employment decisions comply with the federal civil rights laws that the agency enforces. Since that time, the EEOC has continued to beat its drum on the topic:

The EEOC has published guidance that discusses how existing requirements under the Americans with Disabilities Act (ADA) may apply to the use of AI, software applications, and algorithms in employment-related decision-making processes and practices and offered useful information and tips to employers in an effort to assist them with ADA compliance when using such tools.
The EEOC published a proposed Strategic Enforcement Plan (SEP) that announced its intention to focus on recruitment and hiring practices and policies that might give rise to discrimination against members of protected groups, including where employers use AI to aid decision-making.
The EEOC has held roundtable events and hearings to gather information and discuss the civil rights implications of the use of automated technology systems, including artificial intelligence, when hiring workers.
The EEOC has joined other federal agencies to release a joint statement to emphasize that the use of advanced technologies, including artificial intelligence, must be consistent with federal laws.

Employers should expect the EEOC to continue to focus on this topic.
Implications For Employers
The EEOC’s Technical Assistance document does not impose any new rules on employers. Rather, it is yet another reminder to employers that existing law applies to new and advanced technologies, and employers are responsible for employment decisions that impact applicants and employees, whether made by people or with the assistance of machines.  Employers should dust off the 1978 Guidelines and supporting materials and take a fresh look at them as they consider the various technologies that may be used to support employment decisions. 
The publication also represents more foreshadowing of the EEOC’s enforcement priorities, showing once again that the EEOC will scrutinize the technological tools that employers increasingly rely on to make hiring and employment decisions. Employers are well-served to track EEOC charges filed against them that include allegations concerning technological developments as well as those which may prompt the EEOC to issue requests for information seeking information about these tools.
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vaHJleGVjdXRpdmUuY29tL3B3Y3MtaHItdGVjaC1sZWFkZXJzLXByZXBhcmUtdG8tdHJhaW4tdS1zLXdvcmtmb3JjZS1vbi1jaGF0Z3B0LXRlY2hub2xvZ3kv0gEA?oc=5,"PwC's HR, tech leaders prepare to train U.S. workforce on ChatGPT technology - Human Resource Executive®",2023-05-17,Human Resource Executive®,https://hrexecutive.com,"Over the next three years, company leaders will be upskilling more than 65,000 U.S. employees on the power of generative AI like ChatGPT.",N/A,"Over the next three years, company leaders will be upskilling more than 65,000 U.S. employees on the power of generative AI like ChatGPT.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"






















PwC’s HR, tech leaders prepare to train U.S. workforce on ChatGPT technology



By Dawn Kawamoto

May 17, 2023 

Professional services and accounting powerhouse PwC is looking to power up its U.S. workforce of over 65,000 employees with basic to advanced knowledge of ChatGPT technology over the next three years, and it’s putting big bucks behind that effort.


- Advertisement -


PwC recently announced that it’s making a $1 billion investment to super-size and scale its AI capabilities. Part of that initiative is upskilling its entire U.S. workforce on generative AI, of which ChatGPT is just one form, beginning this summer. It’s a mammoth training effort led by both PwC’s Chief People Officer Yolanda Seals-Coffield, who calls it a “fundamental” need for all employees, and also the company’s vice chair and chief products and technology officer Joe Atkinson.
The investment also includes a partnership with Microsoft to create scalable offerings using both OpenAI’s ChatGPT and Microsoft’s Azure OpenAI Service to help PwC’s clients leverage generative AI technology.
See also: ChatGPT—this time, those ‘revolutionary’ predictions are for real
Many PwC employees should be aware of AI, ChatGPT and more, executive says
PwC plans to assess which is the most relevant generative AI information to provide to employees, based on their responsibilities and job description. The company also plans to deliver the materials and information through live training sessions, gamification and other means.
For non-technical workers, such as administrative staff who do not work with customers, the level of upskilling will be different from those who work with customers or those who work in IT, for example.
“There’ll be a lot of people who I just need to get to a level of awareness about what is AI, what’s the difference between AI and generative AI, and why does it matter,” says Joe Atkinson, vice chair and chief products and technology officer for PwC.

The goal of the training is to help these employees understand and appreciate the generative AI applications that are helpful and those that are not as effective, Atkinson says. 
Managing potential minefields of generative AI upskilling
One particular area of importance in upskilling PwC employees will be showing them how to use generative AI responsibly and transparently so everyone is aware of exactly what is being done, Atkinson says. ChatGPT, for example, has been cited as a potential tool for plagiarism, as well as one that could perpetuate bias in content.


- Advertisement -


That is a problem that PwC and other employers are looking to avoid. One way to minimize generative AI chatbot snafus is to understand how important it is to ask the right questions—or prompts—when working with the technology, explains Atkinson, noting this will be covered in PwC’s AI upskilling.
“It’s very important to make sure you’re crafting prompts in a way that actually gets you the output and outcome from generative AI that you’re looking for,” he says.
For example, a clerical employee may want to ask questions of ChatGPT to help them craft the initial first draft of a memo or letter. 
“The training will help them understand how to interact with the chatbot to get the best first draft and recognize AI’s strength is in the crafting of words and not always in the crafting of the facts,” Atkinson says. “That understanding is really important for somebody who is just experimenting with the early stages of how they can apply AI to their jobs.”
How generative AI upskilling can benefit the employee experience
Upskilling employees can enhance employee engagement for your workforce. PwC’s ChatGPT and generative AI training is expected to be no different in this intention, based on other technical training the accounting giant has offered its employees in the past.
“Often those people without the technical grounding are the most enthusiastic to learn about technology because for them the gap feels the biggest,” Atkinson says. “Their enthusiasm actually helps engage the people who are more deeply technical.”
PwC’s workforce in the U.S. underwent digital upskilling and skills future-proofing several years ago in order to prepare employees for emerging technologies and tools they would need to do their jobs then and in the future—wherever they would eventually be, says Yolanda Seals-Coffield, chief people officer at PwC, in an interview with HRE.
This summer’s effort with generative AI has the same goal.
“We fundamentally believe that all of our people need a foundational and fundamental understanding of generative AI, regardless of their role,” Seals-Coffield says. “If we all think about how we continue to grow as learners, this thing called life and this thing called work will clearly have generative AI be a part of that.”





Share


Facebook


Twitter


Pinterest


WhatsApp




Categories:HR TechnologyAI and machine learningLeadershipEthicsTransformation
6340

Dawn KawamotoDawn Kawamoto is HR Editor of Human Resource Executive. She is an award-winning journalist who has covered technology business news for such publications as CNET and has covered the HR and careers industry for such organizations as Dice and Built In prior to joining HRE. She can be reached at Dawn.Kawamoto@etcnetwork.com and below on social media.Sponsored ArticleWhat Does It Mean To Be Skills-First? Planning Your Skills RoadmapByBeamerySeptember 28, 2023The traditional approach to hiring (or redeploying) talent relies on assessing people based on their experience, education, and previous job titles. But many businesses are now starting to embrace a skills-first approach to talent management: the notion of focusing on the skills needed for particular tasks.Becoming a skills-first organization has risen up the business agenda. This means identifying the skills relevant to do the work, then matching people (with those skills) to the tasks at hand.“84% of business leaders think talent approaches need to reflect a focus on skills rather than traditional job roles.” (Source: Navigating The Changing Talent Landscape)The beauty of a skills-first approach is that it can be applied across the full talent lifecycle. With a single currency and common language for assessing candidates (as well as employees and alumni), HR teams and management can really understand the human capital that their business needs.Putting skills at the heart of your organization gives you many of the answers you need in response to the changing economic situation. It helps you become more agile and unlock greater productivity, while boosting diversity and enhancing employee engagement and wellbeing.‘Jobs’ vs. Skills: Why you need a unified skills taxonomyIncreasingly, it’s clear that we have been too limited in the way we look at work. Instead of trying to fit people to a fixed ‘job’, we should be focused on identifying what skills are needed to do the work. Forrester calls this ‘unbundling the job’: a more adaptive model to work, where elements of jobs are broken down into projects, gigs or tasks.Rather than focus on ‘jobs’, we focus on the problem to be solved or the ideal outcome – and then find the people with the skills, interests and capacity to get us there.A skills-based approach acknowledges that people are so much more than a job title. Or even one static job description. They have skills from previous roles, skills they picked up in other walks of life, and ‘adjacent skills’ that they could – with the right training – quite easily acquire. And they are keen to learn. As their skill sets grow, they can be deployed to new tasks or projects to meet business needs.A skills-first organization is therefore one that is incredibly agile and well set up to meet the needs of a changing world, and demanding workforce. So how do you build one?1. Create or enhance your skills taxonomyUnderstanding what skills you have – the potential in your organization and wider talent pipeline – and the skills you need, relies first and foremost on a unified skills taxonomy. Your organization must clearly define what skills truly ‘mean’ in your organization (including soft skills, technical skills, and behaviors), and then connect this to a dynamic job architecture.“Only 10% of HR executives say they effectively classify and organize skills into a skills taxonomy or framework—although nearly all (85%) have some efforts underway.” (Deloitte study)The skills taxonomy needs to be clear, dynamic, and interoperable with other systems and platforms.2. Manage your new taxonomy44% of business leaders told us that “better workforce data” was needed in order to enable a skills-first approach to talent – and 42% noted “more automation of HR processes” was required.This is where AI can help. With smart explainable AI tools, you can ensure skills are commonly defined and automatically connected between systems. AI can also infer what skills a person may have but not have listed; work out what skills they could potentially develop; and work out their seniority and proficiency, relative to industry context. Crucially, it can ensure people’s skills are updated as they learn new things – automatically.Make sure your new job architecture doesn’t become stale in a fast-changing world of talent.3. Start actioning valuable skills insightsA unified skills taxonomy opens up a whole new world of insights about your workforce – and your potential workforce. Understand where skills deficits are in the labor market. Shape your L&D strategy to re-train or upskill talent, in order to plug gaps. Compare what is happening in the external world and better prioritize acquisition activities, in order to build talent pools of those most-sought-after skills.Skills intelligence sits at the heart of improved internal mobility initiatives, for example: where employees and opportunities are matched together in a Talent Marketplace. Better internal mobility programs could massively impact retention in a tight talent market – and it’s impossible without good data and systems.Smart, explainable AI comes in here too. It can take the information about the skills of employees and use that to match them to suitable roles, or recommend training opportunities.And it’s amazing for workforce planning. With always-up-to-date skills intelligence, organizations can quickly identify where they have what they need to address new business priorities, respond quickly to new opportunities or challenges, and ensure that they have the right people in the right roles at all times.4. Connect the rest of your ecosystemAccording to Deloitte, 63% of HR executives say they are using “skills-related technology embedded in core HR information systems” – but just 33% say they have a single source of skills data across the entire workforce. If you’re going to be making important talent decisions about people based on skills, then that skills data needs to be verified and valid.Enabling talent agility requires combining capabilities across your talent tech stack – which may include an internal Talent Marketplace, Learning Experience platforms, your Talent CRM, an ATS, and so on – in order to connect talent supply to demand (skill needs and opportunities), on a continuous basis.This combination of skills intelligence and talent supply, within a truly holistic approach that looks at non-traditional as well as traditional talent pools, is what will enable true talent agility. As part of a total workforce strategy, a skills-first approach offers access to a wider pool of skills and expertise, including contractors, freelancers and other non-traditional workers.It’s a continued effort that is agile and iterative. People are motivated by the data that is leading them to new opportunities, they pursue those and build more experience, which leads to better data about people’s experiences, which feeds better matches between talent and opportunities in the future.A skills-based approach means cultural as well as technological changes. The roles of managers and leaders evolve from managing employees to orchestrating work and skills through projects, tasks, gigs, or problems to be solved; they need to be prepared and empowered to share talent more freely in the organization.Technology can work in the background to empower leaders to make better decisions with skills data. Employees too can get recommendations for new opportunities to upskill, within the flow of their work. The power of generative AI means that adopting the right technology for a skills-first approach doesn’t have to be arduous – it can be as simple as asking one question.The question for leaders is: are you ready to embrace this change?Learn more about becoming a skills-first organization by downloading our free report.







 





Related Posts
No related posts.

  ",,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/#article', 'isPartOf': {'@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/'}, 'author': {'@id': 'https://hrexecutive.com/#/schema/person/5faeb3284837142528b0826c5b5bb874'}, 'headline': 'PwC’s HR, tech leaders prepare to train U.S. workforce on ChatGPT technology', 'datePublished': '2023-05-17T20:54:22+00:00', 'dateModified': '2023-05-18T12:46:15+00:00', 'mainEntityOfPage': {'@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/'}, 'wordCount': 797, 'publisher': {'@id': 'https://hrexecutive.com/#organization'}, 'image': {'@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/#primaryimage'}, 'thumbnailUrl': 'https://hrexecutive.com/wp-content/uploads/2023/01/AdobeStock_558672396_Editorial_Use_Only-scaled-e1674587720414.jpeg', 'keywords': ['AI', 'AI for HR', 'ChatGPT', 'ChatGPT for HR', 'Generative AI', 'shared'], 'articleSection': ['AI and machine learning', 'Ethics', 'Transformation'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/', 'url': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/', 'name': ""PWC's HR, tech leaders to train U.S. workforce on ChatGPT tech"", 'isPartOf': {'@id': 'https://hrexecutive.com/#website'}, 'primaryImageOfPage': {'@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/#primaryimage'}, 'image': {'@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/#primaryimage'}, 'thumbnailUrl': 'https://hrexecutive.com/wp-content/uploads/2023/01/AdobeStock_558672396_Editorial_Use_Only-scaled-e1674587720414.jpeg', 'datePublished': '2023-05-17T20:54:22+00:00', 'dateModified': '2023-05-18T12:46:15+00:00', 'description': 'Over the next three years, company leaders will be upskilling more than 65,000 U.S. employees on the power of generative AI like ChatGPT.', 'breadcrumb': {'@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/#primaryimage', 'url': 'https://hrexecutive.com/wp-content/uploads/2023/01/AdobeStock_558672396_Editorial_Use_Only-scaled-e1674587720414.jpeg', 'contentUrl': 'https://hrexecutive.com/wp-content/uploads/2023/01/AdobeStock_558672396_Editorial_Use_Only-scaled-e1674587720414.jpeg', 'width': 1200, 'height': 675, 'caption': 'PwC to train all of its U.S. employees on ChatGPT and other generative AI technologies.'}, {'@type': 'BreadcrumbList', '@id': 'https://hrexecutive.com/pwcs-hr-tech-leaders-prepare-to-train-u-s-workforce-on-chatgpt-technology/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://hrexecutive.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'PwC’s HR, tech leaders prepare to train U.S. workforce on ChatGPT technology'}]}, {'@type': 'WebSite', '@id': 'https://hrexecutive.com/#website', 'url': 'https://hrexecutive.com/', 'name': 'HR Executive', 'description': 'Human Resource Executive', 'publisher': {'@id': 'https://hrexecutive.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://hrexecutive.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://hrexecutive.com/#organization', 'name': 'LRP Media Group', 'url': 'https://hrexecutive.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrexecutive.com/#/schema/logo/image/', 'url': 'https://hrexecutive.com/wp-content/uploads/2021/05/logo.png', 'contentUrl': 'https://hrexecutive.com/wp-content/uploads/2021/05/logo.png', 'width': 275, 'height': 66, 'caption': 'LRP Media Group'}, 'image': {'@id': 'https://hrexecutive.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/HumanResourceExecutive/', 'https://x.com/HRExecMag', 'https://www.instagram.com/hremagazine/', 'https://www.linkedin.com/company/10141460', 'https://www.youtube.com/channel/UCTWCF1K23UK72GS7eHZmCyA']}, {'@type': 'Person', '@id': 'https://hrexecutive.com/#/schema/person/5faeb3284837142528b0826c5b5bb874', 'name': 'Dawn Kawamoto', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://hrexecutive.com/#/schema/person/image/b64faf7bd2fc00967e036f949bf95cbe', 'url': 'https://hrexecutive.com/wp-content/uploads/2023/02/cropped-Dawn-Kawamoto-Photo-e1677165858522-96x96.jpg', 'contentUrl': 'https://hrexecutive.com/wp-content/uploads/2023/02/cropped-Dawn-Kawamoto-Photo-e1677165858522-96x96.jpg', 'caption': 'Dawn Kawamoto'}, 'description': 'Dawn Kawamoto is HR Editor of Human Resource Executive. She is an award-winning journalist who has covered technology business news for such publications as CNET and has covered the HR and careers industry for such organizations as Dice and Built In prior to joining HRE. She can be reached at Dawn.Kawamoto@etcnetwork.com and below on social media.', 'sameAs': ['https://www.linkedin.com/in/dawnkawamoto', 'https://x.com/@dawnkawamoto'], 'url': 'https://hrexecutive.com/author/dawn-kawamoto/'}]",,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPmh0dHBzOi8veW91cnN0b3J5LmNvbS8yMDIzLzA1L2FpLWZ1dHVyZS1vZi13b3JrLWpvYi1hdXRvbWF0aW9u0gEA?oc=5,The Future of Work: Jobs AI Can and Cannot Replace - YourStory,2023-05-18,YourStory,https://yourstory.com,Artificial Intelligence and the Future of Work: A deep dive into the capabilities of AI in job automation and the inherent value of human skills.,N/A,"The dawn of artificial intelligence (AI) has irrevocably changed the landscape of many industries, bringing with it the potential for increased efficiency, accuracy, and productivity.","The dawn of artificial intelligence (AI) has irrevocably changed the landscape of many industries, bringing with it the potential for increased efficiency, accuracy, and productivity.",https://schema.org,NewsArticle,The Future of Work: Jobs AI Can and Can't Replace,,https://images.yourstory.com/cs/2/96eabe90392211eb93f18319e8c07a74/aivshumans1-1684348432388.png,"[{'@type': 'Person', 'name': 'Nucleus_AI', 'url': 'https://yourstory.com/author/Nucleus_AI'}]",https://yourstory.com,2023-05-17T18:34:21.284Z,"{'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', 'name': 'YourStory', 'url': 'https://yourstory.com', 'legalName': 'YourStory Media Pvt. Ltd.', 'logo': {'@type': 'ImageObject', 'url': 'https://images.yourstory.com/content.ys.com/media/images/logos/YourStory.png', 'width': '330', 'height': '60'}, 'sameAs': ['https://www.facebook.com/yourstorycom', 'https://twitter.com/YourStoryCo', 'https://www.youtube.com/user/yourstorytv', 'https://instagram.com/yourstory_com', 'https://in.linkedin.com/company/yourstory-com'], 'address': {'@type': 'PostalAddress', 'streetAddress': '#259, 6th Cross Rd, 2nd Main Indiranagar, 1st Stage Bengaluru, Karnataka 560038', 'addressLocality': 'Bengaluru', 'addressRegion': 'Karnataka', 'addressCountry': 'IN', 'postalCode': '560038'}}","The dawn of artificial intelligence (AI) has irrevocably changed the landscape of many industries, bringing with it the potential for increased efficiency, accuracy, and productivity. But with this evolution comes the question: what jobs will AI replace, and which ones are 'safe'?
Jobs AI Can Replace
Manufacturing and Warehouse Jobs: The automation of manufacturing processes is nothing new, but AI and robotics have taken it to a new level. Machines can now perform repetitive tasks faster and more accurately than human workers. They can work around the clock, don't require breaks, and aren't susceptible to injury.
Transport and Delivery Jobs: Self-driving vehicles are becoming more and more reliable, and it's only a matter of time before they become commonplace. This will likely lead to the replacement of jobs involving driving, such as truckers, taxi drivers, and delivery personnel.
Data Entry and Analysis: AI algorithms excel at processing and analyzing large amounts of data. Jobs that involve repetitive data entry or analysis are likely to be automated, as AI can do these tasks quickly and with fewer errors.
Customer Service: With the advent of sophisticated chatbots and voice assistants, many customer service tasks can now be automated. These AI systems can handle basic queries, process orders, and even troubleshoot problems, freeing up human workers to deal with more complex issues.
Routine Medical Diagnostics: AI systems can analyze medical images, such as X-rays and MRI scans, to detect abnormalities. While they're not perfect, their ability to process large volumes of data quickly makes them a valuable tool for routine diagnostics.
Jobs AI Can't Replace
While AI can replace many types of jobs, there are some it can't, at least not yet. These are typically roles that require a high degree of creativity, critical thinking, emotional intelligence, or specialized expertise.
Creative Jobs: While AI can generate music, write articles, and even create art, it lacks the ability to truly create. It can replicate and remix, but it can't draw from personal experiences, emotions, or a unique perspective on the world. As such, jobs in fields like writing, music, art, and design are likely safe from AI.
Complex Decision-Making Jobs: Roles that involve complex decision-making, such as executives, entrepreneurs, and strategists, are difficult for AI to replace. These jobs require a deep understanding of nuanced factors, long-term planning, and the ability to deal with uncertainty — areas where AI still falls short.
Jobs Requiring Emotional Intelligence: AI is getting better at mimicking human emotion, but it still can't truly understand or empathize with people. As such, jobs that require high emotional intelligence, such as therapists, social workers, and nurses, are not likely to be replaced by AI.
Specialized Professionals: Jobs that require deep expertise in a particular field, such as doctors, lawyers, and scientists, are less likely to be fully replaced by AI. While AI can assist in these fields, the depth and breadth of knowledge required, along with the need for critical thinking and nuanced understanding, make it difficult for AI to fully take over.
Educators: Teaching is not just about conveying information, but also about inspiring, motivating, and understanding students. It requires emotional intelligence, adaptability, and a personal touch that AI currently can't replicate.

All-in-all, while AI has the potential to replace many jobs, there are still areas where humans are irreplaceable. As we continue to develop and refine AI technology, it will be important to consider not just what AI can do, but also what it should do. The future of work will likely involve a combination of AI and human workers, each playing to their strengths to create a more efficient and productive society.
",,N/A,N/A,"Advertise with usAI GenThe Future of Work: Jobs AI Can and Can't ReplaceArtificial Intelligence and the Future of Work: A deep dive into the capabilities of AI in job automation and the inherent value of human skills.Nucleus_AI1987 StoriesThursday May 18, 2023 , 4 min ReadThe dawn of artificial intelligence (AI) has irrevocably changed the landscape of many industries, bringing with it the potential for increased efficiency, accuracy, and productivity. But with this evolution comes the question: what jobs will AI replace, and which ones are 'safe'?Jobs AI Can ReplaceManufacturing and Warehouse Jobs: The automation of manufacturing processes is nothing new, but AI and robotics have taken it to a new level. Machines can now perform repetitive tasks faster and more accurately than human workers. They can work around the clock, don't require breaks, and aren't susceptible to injury.Transport and Delivery Jobs: Self-driving vehicles are becoming more and more reliable, and it's only a matter of time before they become commonplace. This will likely lead to the replacement of jobs involving driving, such as truckers, taxi drivers, and delivery personnel.Data Entry and Analysis: AI algorithms excel at processing and analyzing large amounts of data. Jobs that involve repetitive data entry or analysis are likely to be automated, as AI can do these tasks quickly and with fewer errors.Customer Service: With the advent of sophisticated chatbots and voice assistants, many customer service tasks can now be automated. These AI systems can handle basic queries, process orders, and even troubleshoot problems, freeing up human workers to deal with more complex issues.Routine Medical Diagnostics: AI systems can analyze medical images, such as X-rays and MRI scans, to detect abnormalities. While they're not perfect, their ability to process large volumes of data quickly makes them a valuable tool for routine diagnostics.Jobs AI Can't ReplaceWhile AI can replace many types of jobs, there are some it can't, at least not yet. These are typically roles that require a high degree of creativity, critical thinking, emotional intelligence, or specialized expertise.Creative Jobs: While AI can generate music, write articles, and even create art, it lacks the ability to truly create. It can replicate and remix, but it can't draw from personal experiences, emotions, or a unique perspective on the world. As such, jobs in fields like writing, music, art, and design are likely safe from AI.Complex Decision-Making Jobs: Roles that involve complex decision-making, such as executives, entrepreneurs, and strategists, are difficult for AI to replace. These jobs require a deep understanding of nuanced factors, long-term planning, and the ability to deal with uncertainty — areas where AI still falls short.Jobs Requiring Emotional Intelligence: AI is getting better at mimicking human emotion, but it still can't truly understand or empathize with people. As such, jobs that require high emotional intelligence, such as therapists, social workers, and nurses, are not likely to be replaced by AI.Specialized Professionals: Jobs that require deep expertise in a particular field, such as doctors, lawyers, and scientists, are less likely to be fully replaced by AI. While AI can assist in these fields, the depth and breadth of knowledge required, along with the need for critical thinking and nuanced understanding, make it difficult for AI to fully take over.Educators: Teaching is not just about conveying information, but also about inspiring, motivating, and understanding students. It requires emotional intelligence, adaptability, and a personal touch that AI currently can't replicate.All-in-all, while AI has the potential to replace many jobs, there are still areas where humans are irreplaceable. As we continue to develop and refine AI technology, it will be important to consider not just what AI can do, but also what it should do. The future of work will likely involve a combination of AI and human workers, each playing to their strengths to create a more efficient and productive society.Advertise with usAIFuture of WorkJob AutomationAI vs Human JobsJob securityArtificial IntelligenceRoboticstechnologyWorkforcecareerAdvertise with usMOST VIEWED STORIES1BooksSummer soul-searching: Top nonfiction book recommendations2Daily CapsuleMaking recycling accessible; Mega incubator in Tamil Nadu3NewsStartup news and updates: Daily roundup (July 22, 2024)
4NewsNazara acquires Paper Boat Apps via an additional Rs 300 Cr investment5FundingStable Money raises over Rs 123 Cr in Series A CCPS roundAdvertise with usAdvertise with us
Recommended Stories For You



Sports
Up in the air: When a childhood passion for balloons transformed Benedict Savio into an entrepreneur
July 15, 2024, 3
                        min Read 





Music
Music for a cause: how this wealth management firm promotes Indian culture and fundraises for elder care
July 12, 2024, 5
                        min Read 





Social Media
Kamiya Jani’s world of food, travel with Curly Tales
July 8, 2024, 3
                        min Read 





Entrepreneurship
After directing Anushka Sharma, this filmmaker turned entrepreneur is crafting success for internet influencers
July 4, 2024, 4
                        min Read 





Entrepreneurship
How Saket Modi, CEO and Co-founder of Lucideus, uses music and dance to stay rooted in reality
July 4, 2024, 4
                        min Read 





Startup
This ecommerce startup delivers gifts anywhere in India in just two hours
June 27, 2024, 6
                        min Read 





Nutrition
The potent power of microgreens
June 27, 2024, 5
                        min Read 





Opinion
Desi way with a side of Gen Z: How the new generation is styling ethnic wear
June 22, 2024, 4
                        min Read 




",,en_GB,2023-05-17T18:34:21.836Z,,,,,,,YourStory,"{'@type': 'ImageObject', 'url': 'https://images.yourstory.com/content.ys.com/media/images/logos/YourStory.png', 'width': '330', 'height': '60'}",,,,,,"['https://www.facebook.com/yourstorycom', 'https://twitter.com/YourStoryCo', 'https://www.youtube.com/user/yourstorytv', 'https://instagram.com/yourstory_com', 'https://in.linkedin.com/company/yourstory-com']",,AI Gen,,,,,,,,,,,,,,,,,,YourStory Media Pvt. Ltd.,"{'@type': 'PostalAddress', 'streetAddress': '#259, 6th Cross Rd, 2nd Main Indiranagar, 1st Stage Bengaluru, Karnataka 560038', 'addressLocality': 'Bengaluru', 'addressRegion': 'Karnataka', 'addressCountry': 'IN', 'postalCode': '560038'}",,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LmRxaW5kaWEuY29tL2lzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWEtdGhyZWF0LXRvLXRoZS1ibHVlLWNvbGxhcmVkLWluZHVzdHJ5L9IBWmh0dHBzOi8vd3d3LmRxaW5kaWEuY29tL2lzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWEtdGhyZWF0LXRvLXRoZS1ibHVlLWNvbGxhcmVkLWluZHVzdHJ5Lw?oc=5,Is Artificial Intelligence a threat to the blue-collared industry? - DATAQUEST,2023-05-17,DATAQUEST,https://www.dqindia.com,"The rise of Artificial Intelligence is changing the job market, and blue-collar workers may be particularly vulnerable to job loss",N/A,"The rise of Artificial Intelligence is changing the job market, and blue-collar workers may be particularly vulnerable to job loss","The rise of Artificial Intelligence is changing the job market, and blue-collar workers may be particularly vulnerable to job loss",https://schema.org,ItemList,Is Artificial Intelligence a threat to the blue-collared industry?,,['https://img-cdn.thepublive.com/fit-in/1200x675/filters:format(webp)/dq/media/post_banners/wp-content/uploads/2020/11/artificial-intelligence-4115193_640.jpg'],"[{'@type': 'Person', 'name': 'DQINDIA Online', 'url': 'https://www.dqindia.com/author/dq-online'}]","['www.dqindia.com', 'https://www.dqindia.com/news', 'https://www.dqindia.com/interview', 'https://www.dqindia.com/opinion', 'https://www.dqindia.com/editors-blog', 'https://www.dqindia.com/features', 'https://www.dqindia.com/business-technologies', 'https://www.dqindia.com/dqdeeptech', 'https://www.dqindia.com/annuals', 'https://www.dqindia.com/tag/dq40years', 'https://www.dqindia.com/events', 'https://www.dqindia.com/business-solutions', 'https://tech4growth.dqindia.com/', 'https://dqconclave.com/', 'https://techschools.in/', 'https://resources.dqindia.com/dq-rsr/dataquestarchive/']",2023-05-17T07:59:01+05:30,"{'@type': 'Organization', 'name': 'DQ', 'SameAs': ['https://www.facebook.com/dataquestindia/', 'https://www.linkedin.com/company/dataquestindia/', 'https://twitter.com/dataquestindia', 'https://www.instagram.com/dataquestindia/', 'https://www.youtube.com/@dataquestindia9605', 'None'], 'logo': {'@type': 'ImageObject', 'url': 'https://img-cdn.thepublive.com/fit-in/600x60/filters:format(webp)/dq/media/agency_attachments/UPxQAOdkwhCk8EYzqyvs.png', 'width': 600, 'height': 60}}",,,N/A,N/A,"






                                Opinion
                            




Is Artificial Intelligence a threat to the blue-collared industry?
                        


The rise of Artificial Intelligence is changing the job market, and blue-collar workers may be particularly vulnerable to job loss
                            









DQINDIA Online






                                                    17 May 2023 07:59 IST
                                                































  Follow Us






























New Update










Artificial Intelligence (AI) is transforming the world we live in, and it is becoming increasingly integrated into different sectors of the economy. With the advancements in machine learning, natural language processing, and robotics, AI has the potential to revolutionize the blue-collar industry. However, the widespread adoption of AI in this sector is also raising concerns about its impact on the workforce.
Advertisment

The Rise of AI in the Blue-Collar Industry
With the advancements in AI technology, blue-collar jobs are now being automated, leading to increased productivity and efficiency. According to a report by the McKinsey Global Institute, up to 30% of activities in 60% of occupations could be automated. For instance, in the manufacturing industry, AI-powered robots are being used to assemble products and perform quality control checks, reducing the need for human labor. The New World Robotics report shows an all-time high of 517,385 new industrial robots installed in 2021 in factories around the world. This represents a growth rate of 31% year-on-year and exceeds the pre-pandemic record of robot installation in 2018 by 22%. 
AI is also being used to optimize supply chain management by analyzing data to identify inefficiencies and bottlenecks. This has led to a reduction in transportation costs, improved inventory management, and better customer service. Additionally, AI-powered machines are being used in the construction industry to improve safety and accuracy. For example, drones are being used to survey construction sites and inspect structures, reducing the risk of human error.
Advertisment


The Concerns about AI in the Blue-Collar Industry
Despite the benefits of AI, there are concerns about its impact on the blue-collar workforce. The integration of AI-powered machines is leading to job displacement, as machines are increasingly replacing human workers. This can lead to increased unemployment, reduced wages, and income inequality. According to a report by McKinsey Global Institute, up to 375 million workers worldwide may need to switch occupations or acquire new skills by 2030 due to automation and AI technologies.
Another concern is the skills gap that is emerging as a result of the adoption of AI. Workers who do not have the necessary skills to work with AI-powered machines are at risk of being left behind. This can lead to a mismatch between the skills demanded by the labor market and the skills possessed by workers, resulting in increased inequality, and reduced social mobility.
Advertisment


The Future of the Blue-Collar Industry with AI
The future of the blue-collar industry with AI is both exciting and uncertain. While the integration of AI is leading to increased productivity, efficiency, and safety, it is also leading to job displacement and a skills gap. However, there are steps that can be taken to mitigate these risks.
One approach is to invest in education and training programs that focus on the skills needed to work with AI-powered machines. This will help to bridge the skills gap and ensure that workers are equipped to thrive in the new economy. Additionally, there is a need for policies that support workers who are displaced by AI-powered machines. This can include unemployment insurance, retraining programs, and job placement services. Additionally, it could benefit to focus on the development of new jobs that are created due to the integration of AI.
Advertisment

The rise of Artificial Intelligence is changing the job market, and blue-collar workers may be particularly vulnerable to job loss due to automation. By upskilling and reskilling, exploring new job opportunities, focusing on skills that are hard to automate, and advocating for policies that protect workers, individuals can prepare for the changing job landscape. It is important for workers to take proactive steps to ensure that they are not left behind in the age of automation.
The article has been written by Moiz Arsiwala, Co-Founder and CTO, WorkIndia





Advertisment
















Subscribe to our Newsletter!

              Be the first to get exclusive offers and the latest news













Subscribe Now

















                            
                                Related Articles
                            
                        










































          LIVE
      




                                                      Consulting with Integrity: ‘Responsible AI’ Principles for Consultants
                                                    












































          LIVE
      




                                                      Budget 2024 is Perfect Time to Strengthen Emerging Tech Policies
                                                    












































          LIVE
      




                                                      The Evolving Landscape of Customer Data Privacy in Indian Banking
                                                    












































          LIVE
      




                                                      Impact of AI Platforms on Enhancing Cloud Services and Customer Experience
                                                    












































          LIVE
      




                                                      Organisations in India break down Silos to build Resilience and stay Ahead
                                                    












































          LIVE
      




                                                      Best Practices for Data Ownership and Security in AR/VR Applications
                                                    



















                    Read the Next Article
                     





","{'@type': 'WebPage', '@id': 'https://www.dqindia.com/is-artificial-intelligence-a-threat-to-the-blue-collared-industry/'}",en,,,,,,True,,"['home', 'NEWS', 'Interview', 'Opinion', 'Editors Blog', 'Features', 'BUSINESS TECHNOLOGIES', 'DQDEEPTECH', 'ANNUALS', 'DQ40YEARS', 'EVENTS', 'BUSINESS SOLUTIONS', 'Tech4Growth', 'DQConclave Event Site', 'TechSchools Event Site', 'Magazine']",,,,,,,,[],,,,"{'@type': 'SearchAction', 'target': 'https://www.dqindia.com/search?title={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['//title', ""//meta[@name='description']/@content""]}",https://schema.org/NewsMediaOrganization,News,"{'@type': 'ImageObject', 'url': 'https://img-cdn.thepublive.com/fit-in/1200x675/filters:format(webp)/dq/media/post_banners/wp-content/uploads/2020/11/artificial-intelligence-4115193_640.jpg', 'width': 1200, 'height': 675}"
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vYXBuZXdzLmNvbS9hcnRpY2xlL2Jvc3N3YXJlLWVlb2MtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utam9iLWRpc2NyaW1pbmF0aW9uLTQ4ZjJkYTkzMjFhMDIzYWExMDJlNjM2MDI2NjY3YmI00gEA?oc=5,"Check your artificial intelligence 'bossware' tools for bias, says U.S. agency head - The Associated Press",2023-05-18,The Associated Press,https://apnews.com,"The head of the U.S. agency charged with enforcing civil rights in the workplace says artificial intelligence-driven “bossware” tools that closely track the whereabouts, keystrokes and productivity of workers can also run afoul of discrimination laws. Charlotte Burrows, chair of the Equal Employment Opportunity Commission, told The Associated Press that the agency is trying to educate employers and technology providers to be careful about their use of these surveillance tools as well as AI tools that streamline the work of evaluating job prospects. And if they aren't, they can't blame AI when the EEOC comes calling.","Workplace culture, Telecommuting, General news, Business, U.S. News, Technology","The head of the U.S. agency charged with enforcing civil rights in the workplace says artificial intelligence-driven “bossware” tools that closely track the whereabouts, keystrokes and productivity of workers can also run afoul of discrimination laws. Charlotte Burrows, chair of the Equal Employment Opportunity Commission, told The Associated Press that the agency is trying to educate employers and technology providers to be careful about their use of these surveillance tools as well as AI tools that streamline the work of evaluating job prospects. And if they aren't, they can't blame AI when the EEOC comes calling.","The head of the U.S. agency charged with enforcing civil rights in the workplace says artificial intelligence-driven “bossware” tools that closely track the whereabouts, keystrokes and productivity of workers can also run afoul of discrimination laws.",http://schema.org,JW Videos,,,,,,,,,,Washington News,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3LmFmci5jb20vd29yay1hbmQtY2FyZWVycy93b3JrcGxhY2UvYWktbW9yZS1saWtlbHktdG8taGlyZS13b21lbi10aGFuLWh1bWFucy1hcmUtc3R1ZHktMjAyMzA1MTEtcDVkN29r0gEA?oc=5,AI in HR: how artificial intelligence apps like Sapai.ai could address the gender gap in tech - The Australian Financial Review,2023-05-17,The Australian Financial Review,https://www.afr.com,"Using AI in recruitment almost doubled the number of women assessed as top candidates, researchers found.",N/A,"Using AI in recruitment almost doubled the number of women assessed as top candidates, researchers found.","Using AI in recruitment almost doubled the number of women assessed as top candidates, researchers found.",https://schema.org,NewsArticle,AI in HR: how artificial intelligence apps like Sapai.ai could address the gender gap in tech,,"{'@type': 'ImageObject', 'height': '628', 'url': 'https://static.ffx.io/images/$zoom_0.4351%2C$multiply_2%2C$ratio_1.777778%2C$width_1059%2C$x_507%2C$y_285/t_crop_custom/c_scale%2Cw_800%2Cq_88%2Cf_jpg/t_afr_exclusive_social_wm/l_text:SuecaNano-Semibold.ttf_28:%20FROM%20%2Cg_south_west%2Cy_84%2Cx_355%2Cco_rgb:111111//l_text:SuecaNano-Semibold.ttf_56:%202023%20%2Cg_south_west%2Cy_25%2Cx_330%2Cco_rgb:111111/e4c43793b01151dada235dedd1d9f17419df56eb', 'width': '1200'}","{'@type': 'Person', 'name': 'Euan Black'}",,2023-05-17T05:41:34Z,"{'@type': 'NewsMediaOrganization', 'name': 'Australian Financial Review', 'logo': {'@type': 'ImageObject', 'height': '60', 'url': 'https://www.afr.com/afr-logo.png', 'width': '424'}, 'url': 'https://www.afr.com', 'sameAs': ['https://www.facebook.com/financialreview', 'https://twitter.com/FinancialReview']}",,,workplace,N/A,"Work & CareersWorkplaceHiringPrint articleExclusiveAI more likely to hire women than humans are: studyEuan BlackWork and careers reporterUpdated May 17, 2023 – 6.26pm, first published at 3.41pmSaveLog in or Subscribe to save articleShareCopy linkCopiedEmailLinkedInTwitterFacebookCopy linkCopiedShare via...Gift this articleSubscribers can give anyone free access to articles.Gift this article NewSubscribe to gift this articleGift 5 articles to anyone you choose each month when you subscribe.Subscribe nowAlready a subscriber? Login Women would land more roles in tech if employers used artificial intelligence in the recruitment process, new research has found.In what is believed to be the first academic study of its kind, researchers at Monash University and the University of Gothenburg found that human recruiters hiring for a web designer role scored women “substantially lower” than men when they knew their gender, but equal to men when the gender was hidden.“If [recruiters] know the gender, you observe a gender difference in assessments. But if they don’t know the gender, there’s no such difference,” lead researcher and Monash University professor Andreas Leibbrandt told The Australian Financial Review.Sapia.ai founder Barb Hyman said the research showed that AI could remove many of the barriers women faced in the tech industry. Eamon GallagherThe research, which used Melbourne-based start-up Sapia.ai’s technology in its experiments, also found that using an AI-powered chat-box interview to screen job candidates could offset this gender bias.Recruiters who knew the genders of the candidates but also knew their scores from the AI screening scored the men and women equally.Advertisement“If we give them not just the knowledge of which gender has applied, but also [the candidate’s] AI screening score, then there’s also no gender difference in assessments,” Professor Leibbrandt said.At the same time, the research discovered that informing candidates that their assessment would be reviewed by a computer instead of a human increased the number of females completing the application by about 30 percentage points relative to males, as women believed they would be judged more fairly by AI than a human.AI recruitmentOverall, the research found that using AI in recruitment almost doubled the number of women assessed to be among the top 10 per cent of performers, which means using it would likely result in more women being hired for similar types of tech roles.“The AI tool would have to be substantially biased against women to result in a lower level of gender diversity [in the male-dominated technology industry] than found without AI,” the study concludes.AdvertisementProfessor Leibbrandt, who co-authored the study with Dr Mallory Avery and associate professor Joseph Vecci, said the findings suggested that using AI as an initial screening tool could help employers in other industries reduce bias in their recruitment process.But he said more research was needed to confirm this finding, as this was the first study of its kind and was only focused on the technology industry.The research was based on two experiments and is believed to be the first academic study that investigates how the use of AI in recruitment directly affects both the demand for and supply of minority jobseekers.For the first experiment, the researchers posted an ad for a web designer job and invited more than 700 interested jobseekers to complete an application. Some applicants were told their application would be assessed by AI and others were told it would be assessed by a human. The researchers then measured application completion rates to determine whether informing applicants they would be reviewed by a computer would attract or deter women from completing the application.Two supplementary surveys with jobseekers subsequently allowed the researchers to work out why women were more likely to apply for a job when assessed by AI.The second experiment focused on the behaviour of the human recruiters. The researchers enlisted more than 500 tech professionals to act as recruiters for the web developer role, and then randomised “whether these professional assessors have access to the applicants’ evaluation scores provided by the AI software, as well as whether they can infer the applicants’ gender [from their names]”.Advertisement“This allows us to evaluate how supply and demand merge to generate an overall change in the diversity of the pool of applicants most likely to be considered for a job, those at the upper end of the evaluation distribution,” the researchers write.‘Capable of disrupting bias’Barb Hyman, Sapia.ai founder and chief executive, said the independent research demonstrated that using ethical AI in recruitment was “the most inclusive method of hiring”.“In 2022, women made up just 27 per cent of the workforce across STEM, which has dropped from 2020,” Ms Hyman said.“This research shows that an ethical AI system is capable of disrupting bias, and removing many of the barriers women face to entering the technology workforce.“If you hire based only on soft skills, behaviour traits, and cognitive ability, you will hire just as many women as you would men, if not more. Names, ages, genders, universities – they’re all irrelevant factors in deciding who is suitable for a role.”AdvertisementSapia.ai uses an AI-powered chat interview to screen applicants and provide employers with a shortlist of potential candidates. Other AI-assisted recruitment tools include HireVue, Humanly, HireScored and Paradox.ai.With Sapia.ai’s tool, candidates answer five questions in their own time and are not required to disclose their gender, age or race.The company’s software – which is trained on a database of structured interview responses spanning one billion words from 2.4 million candidates across 47 countries – then uses machine learning and natural language processing to read these answers and subsequently assess the candidates’ suitability for the job, giving each candidate a score out of 100.Candidates also receive an email with coaching tips and insights into their personality within 10 minutes of submitting their application. “It’s a science that understands people through language, and it’s very similar to what people are experiencing with the power of GPT,” Ms Hyman said.Clients include Medibank, Qantas, Woolworths and Suncorp.AdvertisementLooking past our CVsMedibank’s senior executive of talent acquisition, Andrew Retschko, said the insurer used Sapia.ai as part of its recruitment process for corporate roles and for addressing proximity bias when recruiting people internally. Proximity bias refers to the tendency for leaders to treat people who are physically closer to them more favourably. The pandemic-induced switch to hybrid working has made it a bigger issue for employers.“It’s one of the first things we ask candidates to complete after they have applied for a role at Medibank,” Mr Retschko said.“It’s a competitive talent market and this tool has been really useful in identifying candidates who may have been overlooked purely based on CV.“It’s also been helpful when it comes to internal moves and addressing any proximity bias that may exist in the workplace.“The tool supports internal candidates to show a side of themselves that may not be easily demonstrated in the day-to-day of work, particularly in a hybrid working environment.”RelatedThis bot will judge you in five questions at the first interviewRelatedMore women are studying science, tech. But then the problems startExpert advice for getting ahead in the new world of work left by COVID-19Sign up to our weekly newsletter.Sign Up NowEuan Black is a work and careers reporter at The Australian Financial Review. Email Euan at euan.black@afr.comSaveLog in or Subscribe to save articleShareCopy linkCopiedEmailLinkedInTwitterFacebookCopy linkCopiedShare via...Gift this articleSubscribers can give anyone free access to articles.Gift this article NewSubscribe to gift this articleGift 5 articles to anyone you choose each month when you subscribe.Subscribe nowAlready a subscriber? LoginLicense articleIntroducing your NewsfeedFollow the topics, people and companies that matter to you.Find out moreRead MoreHiringCareersReportsSustainability LeadersThe list celebrates Australasian companies that are making real progress in tackling sustainability challenges – and delivering business value along the way.Sponsored  by BCGView all 13 stories SponsoredAdvertisementLatest In WorkplaceFetching latest articlesMost Viewed In Work and careersCaps on foreign students ‘don’t make sense’: WSU bossWhat happens if you cross a CFMEU picket lineThe 10 wealthiest executives in the ASX 300 revealedThe secret to joining an ASX 200 board, from two women who succeededWhy only four execs have kept spot on rich bosses list over decadeThe Australian Financial Review MagazineThis managing director caught a 300kg marlin – and threw it backMichael BaileyThe brand to which our watch editor is surprisingly addictedMeet the man at the helm of design icon Molteni&CBOSS Financial ReviewMy sixth form teacher told me to lower my sightsSally PattenThe secrets to becoming a rich bossNation’s richest boss ‘can’t find anything to invest in’ but WiseTechLife & LeisureIt’s not Swiss, but this is the brand watch lovers all wantBani McSpeddenWaitlisted headphones, one-off table lamps and other little luxuriesMeet the Aussie who introduced Paris to the flat whiteRich ListHistoric pub to close after Rich Lister sells building, keeps pokiesLarry SchlesingerWhat it’s like to sell your tech start-up for $180mHow exquisite timing and meditating shaped this Rich Lister’s fortune","{'@id': 'https://www.afr.com/work-and-careers/workplace/ai-more-likely-to-hire-women-than-humans-are-study-20230511-p5d7ok', '@type': 'WebPage'}",,2023-05-17T08:26:59Z,,,,,True,"{'@type': ['CreativeWork', 'Product'], 'name': 'Australian Financial Review', 'productID': 'afr.com:afralldigital'}",,,,,,,,,"[{'@type': 'ListItem', 'item': {'@id': 'https://www.afr.com/work-and-careers', 'name': 'Work & Careers'}, 'position': 1}, {'@type': 'ListItem', 'item': {'@id': 'https://www.afr.com/work-and-careers/workplace', 'name': 'Workplace'}, 'position': 2}]",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigwFodHRwczovL3d3dy5tb25leWNvbnRyb2wuY29tL25ld3MvcGhvdG9zL3RlY2hub2xvZ3kvY2hhdGdwdC1hLWxvb2stYXQtbGFyZ2UtbGFuZ3VhZ2UtbW9kZWxzLWFuZC1ob3ctdGhleS13b3JrLWluLXBpY3MtMTA2MTI2NzEuaHRtbNIBhwFodHRwczovL3d3dy5tb25leWNvbnRyb2wuY29tL25ld3MvcGhvdG9zL3RlY2hub2xvZ3kvY2hhdGdwdC1hLWxvb2stYXQtbGFyZ2UtbGFuZ3VhZ2UtbW9kZWxzLWFuZC1ob3ctdGhleS13b3JrLWluLXBpY3MtMTA2MTI2NzEuaHRtbC9hbXA?oc=5,ChatGPT: A look at large language models and how they work | In Pics - Moneycontrol,2023-05-18,Moneycontrol,https://www.moneycontrol.com,"ChatGPT is based on GPT-3, a language model that uses deep learning to produce human-like text. Have a look at Large Language Models and how they work",N/A,"ChatGPT is based on GPT-3, a language model that uses deep learning to produce human-like text. Have a look at Large Language Models and how they work",N/A,http://schema.org/,ImageGallery,,,"{'@type': 'ImageObject', 'image': ['https://images.moneycontrol.com/static-mcnews/2023/05/1-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/2-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/3-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/4-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/5-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/6-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/7-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/8-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/9-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/10-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/11-How-Large-Language-Models-Work.jpg', 'https://images.moneycontrol.com/static-mcnews/2023/05/12-How-Large-Language-Models-Work.jpg']}",,https://www.moneycontrol.com/news/photos/technology/chatgpt-a-look-at-large-language-models-and-how-they-work-in-pics-10612671.html,,,,,N/A,N/A,N/A,,,,,,,,,,ChatGPT: A look at large language models and how they work | In Pics,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.moneycontrol.com/', 'name': 'HOME'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.moneycontrol.com/news/', 'name': 'NEWS'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.moneycontrol.com/news/photos/', 'name': 'PHOTOS'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://www.moneycontrol.com/news/photos/technology/', 'name': 'TECHNOLOGY'}}, {'@type': 'ListItem', 'position': 5, 'item': {'@id': 'https://www.moneycontrol.com/news/photos/technology/chatgpt-a-look-at-large-language-models-and-how-they-work-in-pics-10612671.html', 'name': 'CHATGPT: A LOOK AT LARGE LANGUAGE MODELS AND HOW THEY WORK | IN PICS'}}]",,,,,,,,,,,,,,,,,,,,,{'@type': 'SpeakableSpecification'},,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LnRoaXNkYXlsaXZlLmNvbS9pbmRleC5waHAvMjAyMy8wNS8xOC9lZmZlY3RzLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLW5ld3Nyb29tL9IBAA?oc=5,Effects of Artificial Intelligence in Newsroom – THISDAYLIVE - THISDAY Newspapers,2023-05-18,THISDAY Newspapers,https://www.thisdaylive.com,N/A,N/A,N/A,N/A,,,,,,,,,,,,N/A,N/A,"






Digital Literacy: NITDA Partners NYSC to Train 30m Nigerians

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,

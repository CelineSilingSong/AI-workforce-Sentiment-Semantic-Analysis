URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@graph,article:section,article:summary,article text,@type,url,name,logo,contactPoint,sameAs,mainEntity,image,mainEntityOfPage,inLanguage,author,dateModified,datePublished,headline,alternativeHeadline,publisher,hasPart,copyrightHolder,sourceOrganization,copyrightYear,isAccessibleForFree,isPartOf,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,genre,wordcount,dateCreated,identifier,creator,thumbnailUrl,uploadDate,duration,contentUrl,embedUrl,itemListElement,comment,commentCount,articleBody,articleSection
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd3d3LnNvY2lhbGV1cm9wZS5ldS9jYXBpdGFsaXNtcy1taXJyb3Itc3RhZ2UtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLXRoZS1xdWFudGlmaWVkLXdvcmtlctIBAA?oc=5,Capitalism's mirror stage: artificial intelligence and the quantified worker - Social Europe,2020-04-08,Social Europe,https://www.socialeurope.eu,"As AI enters the workplace, we need to reflect upon the criteria by which human work is evaluated and human subjectivity depicted.",N/A,"As AI enters the workplace, we need to reflect upon the criteria by which human work is evaluated and human subjectivity depicted.","As AI enters the workplace, we need to reflect upon the criteria by which human work is evaluated and human subjectivity depicted.",https://schema.org,"[{'@type': 'Organization', '@id': 'https://www.socialeurope.eu/#organization', 'name': 'Social Europe (SE)', 'sameAs': ['https://www.facebook.com/socialeurope.eu', 'https://twitter.com/socialeurope'], 'logo': {'@type': 'ImageObject', '@id': 'https://www.socialeurope.eu/#logo', 'url': 'https://www.socialeurope.eu/wp-content/uploads/2022/06/SE-8.png', 'contentUrl': 'https://www.socialeurope.eu/wp-content/uploads/2022/06/SE-8.png', 'caption': 'Social Europe', 'inLanguage': 'en-GB', 'width': '750', 'height': '422'}}, {'@type': 'WebSite', '@id': 'https://www.socialeurope.eu/#website', 'url': 'https://www.socialeurope.eu', 'name': 'Social Europe', 'publisher': {'@id': 'https://www.socialeurope.eu/#organization'}, 'inLanguage': 'en-GB'}, {'@type': 'ImageObject', '@id': 'https://www.socialeurope.eu/wp-content/uploads/2020/03/Phoebe-V-Moore.png', 'url': 'https://www.socialeurope.eu/wp-content/uploads/2020/03/Phoebe-V-Moore.png', 'width': '501', 'height': '499', 'caption': 'machine learning', 'inLanguage': 'en-GB'}, {'@type': 'WebPage', '@id': 'https://www.socialeurope.eu/capitalisms-mirror-stage-artificial-intelligence-and-the-quantified-worker#webpage', 'url': 'https://www.socialeurope.eu/capitalisms-mirror-stage-artificial-intelligence-and-the-quantified-worker', 'name': 'Capitalism’s mirror stage: artificial intelligence and the quantified worker', 'datePublished': '2020-04-08T05:00:00+02:00', 'dateModified': '2020-04-23T13:33:58+02:00', 'isPartOf': {'@id': 'https://www.socialeurope.eu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.socialeurope.eu/wp-content/uploads/2020/03/Phoebe-V-Moore.png'}, 'inLanguage': 'en-GB'}, {'@type': 'Person', '@id': 'https://www.socialeurope.eu/author/phoebe-moore', 'name': 'Phoebe Moore', 'url': 'https://www.socialeurope.eu/author/phoebe-moore', 'image': {'@type': 'ImageObject', '@id': 'https://secure.gravatar.com/avatar/dd57363a173e4616e2364e0e58c05197?s=96&amp;d=mm&amp;r=g', 'url': 'https://secure.gravatar.com/avatar/dd57363a173e4616e2364e0e58c05197?s=96&amp;d=mm&amp;r=g', 'caption': 'Phoebe Moore', 'inLanguage': 'en-GB'}, 'sameAs': ['https://twitter.com/phoebemoore'], 'worksFor': {'@id': 'https://www.socialeurope.eu/#organization'}}, {'@type': 'NewsArticle', 'headline': 'Capitalism’s mirror stage: artificial intelligence and the quantified worker', 'keywords': 'Machine learning, People analytics', 'datePublished': '2020-04-08T05:00:00+02:00', 'dateModified': '2020-04-23T13:33:58+02:00', 'articleSection': 'Politics', 'author': {'@id': 'https://www.socialeurope.eu/author/phoebe-moore', 'name': 'Phoebe Moore'}, 'publisher': {'@id': 'https://www.socialeurope.eu/#organization'}, 'description': 'As AI enters the workplace, we need to reflect upon the criteria by which human work is evaluated and human subjectivity depicted.', 'copyrightYear': '2020', 'copyrightHolder': {'@id': 'https://www.socialeurope.eu/#organization'}, 'name': 'Capitalism’s mirror stage: artificial intelligence and the quantified worker', '@id': 'https://www.socialeurope.eu/capitalisms-mirror-stage-artificial-intelligence-and-the-quantified-worker#richSnippet', 'isPartOf': {'@id': 'https://www.socialeurope.eu/capitalisms-mirror-stage-artificial-intelligence-and-the-quantified-worker#webpage'}, 'image': {'@id': 'https://www.socialeurope.eu/wp-content/uploads/2020/03/Phoebe-V-Moore.png'}, 'inLanguage': 'en-GB', 'mainEntityOfPage': {'@id': 'https://www.socialeurope.eu/capitalisms-mirror-stage-artificial-intelligence-and-the-quantified-worker#webpage'}}]",Politics,N/A,"
This series is a partnership with the Weizenbaum Institute for the Networked Society and the Friedrich Ebert Stiftung
As AI enters the workplace, we need to reflect upon the criteria by which human work is evaluated and human subjectivity depicted.
Phoebe V Moore
Control panels are the obvious place to run operations centrally.
The control rooms of Star Trek’s fantastical Enterprise (and the hub of
the actual Project Cybersyn under Chile’s radical president Salvador Allende) in
the 1960s and 70s were however operated by humans with relatively primitive
technologies. 
Today, much of the work of the people we imagined in
these rooms—the bouffanted women in silver A-line dresses and men in blue boiler
suits pushing buttons to operate the manoeuvres of galactical imperialism—is
done by computers. But what will happen when the proverbial windows looking out
to the galaxies only display a cadre of robots and the control panels’ blinking
lights are the only reflective glimmer? 










Join 24,000+ informed readers and stay ahead with our insightful content. 
It's free.












Subscribe
  Loading... 










Subscribe
  Loading... 






Thank you!
Please check your inbox and click on the link in the confirmation email to complete your newsletter subscription.









So-called Industries 2.0-4.0 have
seen an onslaught of machines and machinic competences in the workplace control
rooms of today, via robotic process automation, semi-automation, machine
learning and algorithmic management systems. Digitalised workplace design and
surveillance techniques are oriented around the rise in new technologies, where
the processing and quantification of workers’ data is seen to be necessary for
a company’s competitivness.
People analytics
The contingent technology for
workplace processes to reach a new pinnacle of computational sophistication is
the rise in artificial-intelligence
tools and applications. AI allows semi-automation of decision-making
processes via machine learning, which is particularly applicable in the case of
human-resource driven ‘people analytics’ (PA), where predictions and
prescriptions about job candidates and workers—or ‘data subjects’ as the General
Data Protection Regulation (GDPR) puts it—can now be made based on quantification
techniques applied to data sets. 
Put simply, with the use of PA,
we are asking machines to relay truths, or subjective images about other people,
via computation. While we once expected the machine to mirror the human, we now
seem to be looking into a machinic mirror for our own reflection and those of
others. The full implications of this ‘mirror stage’ of capitalism—to borrow a
phrase from the psychoanalyst Jacques Lacan—are yet to be played out but are exceedingly
important.

Become a Social Europe Member

Support independent publishing and progressive ideas by becoming a Social Europe member for less than 5 Euro per month. Your support makes all the difference!

Click here to become a member
For Lacan, the mirror stage was
the moment in which the child realises her separation from the rest of her
environment. The mirror stage for what I am calling ‘smart workers’ within
capitalism today must be a moment of defying the assumption that we are inexorably
subsumed into a machinic subject, retaining the firm scaffolding of what makes
us human and posing resistance to a purportedly automatic domination. Given growing
expectations that AI will become universal, to avoid the most negative
implications it implies for workplaces and workers with regards to automation
and surveillance, it is increasingly important to exercise reflexivity and retain
our human autonomy, as decision-making about workers is increasingly based on
quantification and automation. 
Machine learning
People analytics is perhaps the best-known
form of AI-augmented workplace tool. Generally speaking, PA is a set of human-resource
(HR) activities which rely on a process whereby managers can identify patterns
and compare them across data sets collected about workers. 
The AI component in PA lies in how algorithms
are set up to make the decisions, via machine-learning procedures. Big data,
algorithms and machine learning are central in digitalised recruitment, where
decisions about talent spotting, interviewing, leadership prediction, individual
worker performance, health patterns across workers and other operational
management issues can be digitally assisted. 
Indeed, machines become the mirror for
workers’ subjectivities via quantification. Predictions are made about
applicants regarding aptitude and job fit—and, once workers are in position, many
things can be assessed, ranging from the diligence of their work to their
likelihood for disengagement.  
A Deloitte report indicates that 71 per cent of international companies have reported they value PA and see it as a priority, because it allows management to conduct ‘real-time analytics at the point of need in the business process … [and] allows for a deeper understanding of issues and actionable insights for the business’ to deal with what have been called ‘people issues’. In other HR-related reports, the revelations of ‘people risks’ and ‘people problems’ which PA can unveil throw the concept of the mirror phase of capitalism into sharp relief: who are we (humans), in the machine’s reflection? 
Increased stress
PA is likely to increase workers’ stress if
data are used in appraisals and performance management without due diligence in
process and implementation, leading to complaints about micromanagement and
feeling spied on. If workers know their data are being read
for talent spotting or deciding possible layoffs, they may feel pressurised to
advance their performance, and begin to overwork, posing significant risks. Another risk arises with liability, where
companies’ claims about predictive capacities may later be queried for accuracy
or personnel departments held accountable for discrimination. 
Indeed, if algorithmic decision-making in PA
does not involve human intervention and ethical
considerations, this HR tool could expose workers to heightened structural,
physical and psychosocial risks and stress. How can workers be sure
decisions are being made fairly, accurately and honestly, if they do not have
access to the data held and used by their employer? This should be dealt with
to some extent in the European Union context with the GDPR but that is by no
means a fait accompli. 
PA practices are particularly worrying if they lead to
workplace restructuring, job replacement, job-description changes and the like.
In any case, the use of machine learning to make predictions and provide
analyses about people relies
on specific kinds of intelligences prioritised under capitalism—efficiency,
reliability, competitiveness and other data-driven imperatives—which may or may
not reflect who individuals are, or would like to be, in modern society.
Research necessary
Many high-level governmental and
organisational reports are predicting that AI will improve productivity,
enhance economic growth and lead to prosperity for all—in a similar way ‘scientific
management’ was once heralded. As with scientific management, however, high-level
discussions do not seem to link the anticipated prosperity directly with the
realities of the everyday (and everynight) human work which ultimately fuels
growth. Meanwhile, various AI-augmented tools and applications are being
introduced to improve productivity, in factories and offices and ‘gig’ work. 
There is a lot of research on automation
but not on how AI, as a form of semi-automation, carves out the capacity for
substitution of human activities in the workplace. There is also extensive
research on surveillance, but again not scrutinising how AI facilitates
advances in surveillance in the workplace. 
Scholarly and governmental research on these subjects should take AI seriously by putting a metaphorical mirror into place for social reflection about how these processes occur and on which assumptions they rest—rather than presenting AI merely as forms of autonomous software and immutable techniques for facilitation. While there have been significant inroads in climate, medical, fashion, insurance and justice-systems research, studies on AI’s uses to evaluate workers and aptitudes through quantification are lagging behind. Stories of discrimination and bias are already making headline news where PA has been applied and, without reflection on the mistakes made in AI and quantified analyses of workers, this is set to continue and even get worse. 
Digital democracy
The rise in data accumulation in
recent times and the reliance on algorithms for workplace decisions has led to
the possible removal of the role of the physical manager through a machinic
system. If workers were to take over workplace control rooms through deciding
which tools and processes are applied, digital democracy at work could
be imagined. 
But the use of AI
undemocratically could just as easily occur and lead to the removal altogether
of human autonomy, via automation, from workplace decision-making and tasks. The
current Covid-19 crisis has also led to the rise in online working, giving
increased leeway for quantified judgements and machinic management.   
More research is needed in these
areas, to get a full picture of what AI will mean and, in many cases, already means for human-machine relations in workplaces. What
precisely are the types of
intelligences which we expect today from
machines and are these really reflective of human intelligence? Why do we
choose the categories of intelligence that we do, and how are data collection
and processing activities relevant to the affective side of the human
experience? 
Perhaps most importantly, what
are the surrounding risks for workers as technology advances and as we begin to
question our own role in production and think about that of the machine, as AI
is set to increase its autonomy? The question more broadly for humanity
is: who do we think we are as we reach the mirror stage in capitalism, where we
should realise we are separate and retain autonomy from
a machinic subject? 
As we busily instal machines into workplaces via robotics and management tools with seemingly superior intelligence to ourselves, we should ask: in whose (or which) reflection are we now looking?




 Phoebe MoorePhoebe Moore is associate professor in political economy and technology in the School of Business at the University of Leicester and director of its Centre for Philosophy and Political Economy.You are here: Home / Politics / Capitalism’s mirror stage: artificial intelligence and the quantified worker







 Most Popular Posts
 The assault on labour rights in FinlandAntti Alaja and Joel Kaitila George Orwell and Europe’s new normalJan Zielonka Ukraine: Putin’s ‘reality’ … and the real worldFrank Hoffer Will the young save Europe from the rise of the far right?Albena Azmanova Housing crisis: Europe cannot afford itGerald Koessl


 Most Recent Posts
 The young generation needs quality traineeshipsMarc Steiert Rebuilding trust in democracy in MoldovaStanislav Pavlovschi Rising tides, sinking boats: growth, climate and justiceBasak Kus Ostrich politics and its alternativesEszter Kováts Why it seems east Germany is everywhereStefanie Börner


 Other Social Europe Publications
 Global cities Strategic autonomy RE No. 13: Failed Market Approaches to Long-Term Care Towards a social-democratic century? National recovery and resilience plans


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vd3d3LmhyZXhjaGFuZ2VuZXR3b3JrLmNvbS9oci10ZWNoL2FydGljbGVzL2FpLWFuZC1hdXRvbWF0aW9ucy1pbXBhY3Qtb24tdGhlLXdvcmtmb3JjZdIBYWh0dHBzOi8vd3d3LmhyZXhjaGFuZ2VuZXR3b3JrLmNvbS9oci10ZWNoL2FydGljbGVzL2FpLWFuZC1hdXRvbWF0aW9ucy1pbXBhY3Qtb24tdGhlLXdvcmtmb3JjZS9hbXA?oc=5,AI and Automation’s Impact on the Workforce | HR Exchange Network - HR Exchange Network,2020-04-08,HR Exchange Network,https://www.hrexchangenetwork.com,"AI and automation are disrupting the workforce, but how, if at all, are HR leaders preparing for this inevitability? Southern New Hampshire University’s Dr. Jerome Rekart looks at the latest data he gathered on the subject and describes who is preparing and who has yet to begin.","HR, future of work, artificial intelligence, AI, SNHU, southern new hampshire university, jerome rekart","AI and automation are disrupting the workforce, but how, if at all, are HR leaders preparing for this inevitability? Southern New Hampshire University’s Dr. Jerome Rekart looks at the latest data he gathered on the subject and describes who is preparing and who has yet to begin.","AI and automation are disrupting the workforce, but how, if at all, are HR leaders preparing for this inevitability? Southern New Hampshire University’s Dr. Jerome Rekart looks at the latest data he gathered on the subject and describes who is preparing and who has yet to begin.",https://schema.org,,N/A,N/A,N/A,Organization,https://www.hrexchangenetwork.com,HR Exchange Network,https://eco-cdn.iqpc.com/eco/images/channel_content/images/hr-logo-lg__1_1.png,"{'@type': 'ContactPoint', 'email': 'contact@hrexchangenetwork.com'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUGh0dHBzOi8vd3d3LmVsZWt0b3JtYWdhemluZS5jb20vYXJ0aWNsZXMvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZm9yLWJlZ2lubmVycy0x0gEA?oc=5,Artificial Intelligence for Beginners: An Introduction to the Maixduino - Elektor,2020-04-10,Elektor,https://www.elektormagazine.com,Artificial intelligence (AI) is a hot topic. Here&#039;s an introduction to the Maixduino and how it can be programmed using the familiar Arduino IDE.,"Microsoft, Intel, Artificial Intelligence, selfie, DC, LCD, AI, Graphics, Arduino IDE, AI for Beginners - Article series, Embedded &amp; AI, Robotics &amp; AI",Artificial intelligence (AI) is a hot topic. Here&#039;s an introduction to the Maixduino and how it can be programmed using the familiar Arduino IDE.,Artificial intelligence (AI) is a hot topic. Here's an introduction to the Maixduino and how it can be programmed using the familiar Arduino IDE.,http://schema.org,,N/A,N/A,"           Walter  Trojan      Artificial Intelligence for Beginners (1): What Is AI?   April 10, 2020   by Walter  Trojan   on  Robotics & AI     Microsoft Intel  Artificial Intelligence + selfie DC LCD AI Graphics Arduino IDE AI for Beginners - Article series Embedded & AI             Artificial Intelligence for Beginners (1): What Is AI?   There is no hotter topic in the world of IT than artificial intelligence (AI). A good low-cost introduction to the fields of speech and image recognition as well as other aspects of AI is the Maixduino board which, including the fitted camera and small LCD panel, comes in at only around €30/£25/$35; what’s more, it can readily be programmed using the familiar Arduino IDE. In the first installment of this series we will look at the comprehensive array of hardware offered by the Maixduino and at a couple of demonstration programs, including one that can recognize 1000 different objects.  The use of artificial intelligence is on the increase in many areas, and it is finding its way into many types of device and application. This year it is estimated that worldwide business applications in the field of artificial intelligence will generate revenues of some $4.8bn, and that figure is predicted to rise to over $30bn by 2025. Anyone with knowledge of the subject area can look forward to enhanced employment prospects, as expertise in artificial intelligence is urgently sought after. It is therefore worthwhile to take a little time to get to grips with the topic and the new worlds of possible applications that it opens up. And, last but not least, it’s a lot of fun!
The term ‘artificial intelligence’ is generally considered to cover the creation of systems exhibiting intelligent behaviour. One part of this is ‘machine learning’, whereby instead of having an application function specified in all its detail by the developer, a general-purpose programming framework in the form of a neural network (NN) is used, which learns the required function by itself using a large corpus of training data. One class of machine learning is called ‘deep learning’, where more complex and optimized program structures are used to improve results further. We will be looking at these ideas in more detail later in this short series of articles.
However, artificial intelligence is not a new subject: its beginnings can be traced back to the 1950s. The breakthrough that occurred a few years ago was the result of considerable increases in the amount of computational power available. Graphics cards with hundreds of processor cores operating in parallel and highly-specialized artificial intelligence chips enabled artificial intelligence systems to be implemented and trained. That opened the door to automatic speech recognition, as used in many personal assistants, and image recognition of objects of all kinds. artificial intelligence also plays an important role in autonomous vehicles. In some areas AI has already surpassed human abilities: artificial intelligence systems can beat world champions in the games of chess and go, and can detect tumours more reliably than human medical specialists. But do not worry: the systems are only superior in the particular areas in which they have been trained, and the areas in which the systems are trained will continue to be chosen by humans.
  Subscribe Tag alert: Subscribe to the tag Embedded & AI and you will receive an e-mail as soon as a new item about it is published on our website! 
A low-cost introduction
A good low-cost introduction to this world is the Maixduino, which in the form of the ‘MAix BiT’ kit including the board, camera and small LCD panel can be obtained from Elektor: see the text box. The board has the same format as an Arduino Uno (from which it gets its name), but the hardware it includes is considerably more comprehensive. The board is manufactured by the Chinese company Sipeed. Alternatives to the Maixduino include the Nvidia Jetson Nano, the ROCK PI N10 Model A, the Intel Neural Compute Stick 2 and others, but these all cost considerably more.
In this first installment of this series we will look at the rich hardware environment offered by the Maixduino and how it can be programmed with the help of the Arduino IDE. As well as a couple of typical Arduino-esque applications, we will look at how to use the camera and the screen. And the final highlight will be a demonstration of how to use the board to recognize objects.
In the second and third installments we will delve deeper into the topic of artificial intelligence, describe the structure of neural networks, install MicroPython and its accompanying IDE and demonstrate how facial recognition works. We will also look at how you can program your own AI applications and how to communicate with the Internet.

A deep dive into the ‘super Arduino’
The specifications of the Maixduino will have hardware enthusiasts licking their lips! The overall size and construction of the board is broadly aligned with that of the Arduino Uno, but you will immediately notice the higher component density and that many additional connections are available. At the heart of the board there are two large modules. The first is the Sipeed M1 AI processor module based on the Kendryte K210 device, whose interior workings we will look at later, and the second is an ESP32 module for communicating over WLAN and Bluetooth and for acquiring analogue signals. The ESP32 contains two processor cores clocked at 240 MHz and so by itself offers a considerable amount of processing power, and it can be used to offload communication functions from the main processors. The ESP32 has already featured in many articles in this magazine, and so we will not go into further detail about it here.
The header connectors correspond in number and arrangement to the original Arduino, and the pin assignments are mostly identical. But beware that the inputs and outputs are designed for 3.3 V or even 1.8 V operation, and the input circuitry will be destroyed if 5 V is applied.
Further details are shown in Figure 1. Two 24-pin sockets are provided for interfacing to the camera and to the LCD panel. A slot is provided for a microSD card which can be used to make a large amount of storage available to the Maixduino. The USB connector is the modern type-C kind and is used for programming and monitoring. And, to allow the processing of audio data, the board includes a digital microphone and an audio amplifier with a 3 W output driven by a digital-to-analogue converter. So there is plenty of hardware on the board to let you get started on a range of possible projects without having to add extra boards.


Figure 1: The hardware facilities offered by the Maixduino.


The pinout of the board (see Figure 2) closely resembles the original. The supply voltage can be provided over the DC barrel jack or using the VIN pin at 6 V to 12 V; alternatively, 5 V can be supplied over the USB connector. Six of the ESP32’s GPIOs are brought out; these are the ones that can alternatively be used as analogue inputs A0 to A5. On the opposite edge of the board are the inputs and outputs of the K210 module. These can be controlled using the usual Arduino commands, with the ‘Arduino pin number’ being the number of the input or output bit of the K210.


Figure 2: Maixduino pinout.


 
#define LED 12            // K210 IO12, Maixduino pin 10
pinMode(LED, OUTPUT);     // configure port as output
digitalWrite(LED, HIGH);  // port to high (3.3 V)
 
The RST pin is designed to operate at 1.8 V and external circuitry should not apply a higher voltage than that to it. Outputs IO36 to IO47 are also designed for low-voltage operation: these are not brought out to the headers, but are used internally, for example to drive the LCD panel. The serial RX and TX ports and the I2C interface are provided with suitable pull-up resistors fitted on the board.
Unfortunately the K210 datasheet does not specify the maximum output current available at the outputs. However, they should be capable of driving an LED at up to say 10 mA or so; for higher currents a driver IC should be added.

The big enchilada: Kendryte K210
The K210 SoC (system on a chip) made by the Chinese company Kendryte is at the heart of the Maixduino. It is made using a low-power silicon technology on a 28 nm process and has been available on the market since September 2018. For carrying out ‘normal’ work it offers two 64-bit processor cores that are clocked at 400 MHz, with overclocking up to 800 MHz possible. These cores are based on the RISC-V specification: this saves the manufacturer from having to pay licensing fees to Arm and so helps to contribute to the low total cost of the device. Both processors come with an FPU (floating-point unit) that operates in both single and double precision. Figure 3 shows in more detail what is inside this chip.


Figure 3: Block diagram of the Kendryte K210.


The special feature of the K210, however, is its KPU (knowledge processing unit) that can be used to construct and execute neural networks. The total compute power available is astonishing at this price point: 0.46 Tops, or 460 billion operations per second. With overclocking this figure can even be doubled, allowing, for example, up to 60 objects per second to be recognized. The high processing performance is achieved using 64 arithmetic units operating in parallel and a bus width of 576 bits. Also, the power dissipation of just 0.3 W is very low in comparison to other artificial intelligence systems. For example, Nvidia recommends using a 5 V 4 A (hence 20 W) power supply for its Jetson Nano, which at 0.4 Tops offers comparable computing power.
The KPU can implement advanced neural network architectures, including convolutional networks. These have a particularly efficient filter structure that makes them especially well suited to image processing applications: more on this in the second instalment of this series. The main memory included in the SoC has a capacity of 8 MB, divided into 2 MB for the main processors and 6 MB for the KPU. That means that up to 5.9 MB is available for storing the neural network configuration, which is enough to implement a medium-sized network.
However, the K210 has more hardware tricks up its sleeve. These include an audio processing unit (APU) which is particularly helpful for pre-processing in speech recognition applications. The unit can handle up to 8 channels (or 4 stereo channels) at input sample rates of up to 192 kHz. An FFT (fast Fourier transform) unit is available to carry out analysis of the frequency spectrum of a signal.
Also noteworthy are the AES and SHA-256 accelerators provided to speed up cryptographic functions.
And of course the device includes the usual complement of peripherals including UART, I2C, SPI, I2S, timer, RTC and PWM.
Sipeed has added 16 MB of flash memory on the board alongside power supply circuitry, the microphone and 3 W power amplifier, and the excellent ESP32 module.
What more could you wish for? More information on the operation of the board, the circuit diagram and other details can be found here, here and here.
  Subscribe Tag alert: Subscribe to the tag embedded programming and you will receive an e-mail as soon as a new item about it is published on our website! 
Software development
It is not just the shape of the board that is similar to the original Arduino: the board uses the same Arduino IDE, with the Maixduino core being integrated into the environment in the same way as the ESP8266 or ESP32. Under File -> Preferences it is necessary to add a new board manager URL: if you right-click on the button to the right of the text entry box a small window will open to make entering the URL easier (see Figure 4). If you only want to program the Maixduino, then only the ‘sipeed’ line needs to be added; then the on-board ESP32 will also be programmed using it.


Figure 4: Adding the Maixduino core configuration.


To install the Maixduino board tools select the menu item Tools -> Board -> Boards Manager. Enter the search term ‘Maix’ (as shown in Figure 5) and then proceed to install the tools.


Figure 5: Installation of the Maixduino core tools.


Now we can start to do some programming. Rather than the conventional ‘hello world’ program, we will jump straight into to testing the camera and screen. Connect the Maixduino over USB and in the Tools menu set the following parameters.
 
Board: Sipeed Maixduino
CPU Clock Frequency: 400 MHz
Burn Tool Firmware: open-ec
Burn Baud Rate: 1.5 Mbps
Tool Install Location: Standard
Port: <COM port that you are using>
Programmer: k-flash
 
A demonstration program that captures an image and displays it on the LCD is already available within the IDE. Call it up using File Examples Sipeed_OV2640 selfie and once it is uploaded to the board (you may need to press the reset button at this point) you can run it. The code is shown in Figure 6.


Figure 6: Arduino IDE with the ‘selfie’ program.


The program starts by bringing in the functions from the Sipeed libraries for driving the camera and LCD, which are connected to the board using an SPI bus. The image format chosen is QVGA resolution (320 by 240 pixels) with RGB565 colour. The setup routine initializes both devices, and in the main infinite loop the captured images are transferred directly to the LCD: it could hardly be simpler.
The image is not particularly contrasty, but it is sharp and updates are smooth. Figure 7 shows the results.


Figure 7: Captured image of an adaptor plug.


As you can see, the Maixduino is as easy to use as an Arduino Uno. However it offers many more possibilities and we can immediately start to build more sophisticated applications.

Our first AI model
We will be looking in more detail at deep learning aspects of artificial intelligence in the second article in this series, but here we can demonstrate a simple application. We will be using ‘MobileNet’: nothing to do with mobile phones, but rather an image classifier that can recognize and identify 1000 types of everyday objects. This uses a neural network, which is a software structure built from nodes organized in layers trained using a lengthy process in which it is presented with thousands of images.
Since the file containing the training image set runs to some 200 GB and the training process itself is very time-consuming, it is not really practical to carry it out on the Maixduino. However, it is possible to install a ready-trained model and immediately set it to work recognizing images. The steps to achieve this are as follows.
 
The required software can be found here. It consists of the following components.
 
mobilnet_v1.ino: main C++ program for running the demonstration
MBNet_1000.h: header file for the demonstration routines
MBNet_1000.cpp: C++ routines for acquiring, recognizing and displaying objects
names.h: header file with object descriptions
names.cpp: C++ routine for describing the recognized objects
 
Download these files and place them all in the same directory. The pre-trained artificial intelligence model mobilenet_0x300000.kfpkg can be downloaded from link [5]: compressed, it is just a few megabytes long. After decompressing it with 7zip you should find a folder mobilenet_0x300000 in which there are two files: the model is the one called ‘m’. Copy this file onto a microSD card in the root (top-level) directory and insert the card into the slot on the Maixduino.
A glance at the program code in Figure 8 shows that it is possible to program even very complex applications with little effort. That is of course all down to the powerful libraries: in the field of artificial intelligence there are very many highly efficient libraries available. The first part of the program declares the camera, LCD and the KPU along with their parameters. The camera resolution is configured to the same format as the training images, 224 by 224 pixels. Finally, the object mbnet marshals together the KPU, camera and LCD resources.


Figure 8: MobileNet demonstration program.


The setup routine initializes the demonstration code, and then in the main loop we have the classification of the objects in the images acquired by the camera and their display on the LCD panel. Again, it is hard to imagine that an object recognition program could be any simpler.
As a test we can put a photograph of a cat in front of the camera (as shown in Figure 9). The system immediately recognizes it as a tabby or Egyptian cat (Figure 10). The application is capable of classifying about five images per second and is therefore capable of producing useful results even if the camera is moving. The most important things are to have good lighting and not too busy a background to the image.


Figure 9: Acquisition of an image of an object.




Figure 10: The object is identified and classified.


As can be seen from Figure 10 the acquired image uses only a blue and white colour palette, in the interests of increasing the recognition rate. This is a commonly-used method: instead of using all three colour channels in an image we use only one to reduce the amount of pixel data and hence the amount of processing power required. The technique of using a ready-trained network, or in other words of carrying out training and classification on different platforms, is also widespread in this type of application. Many users take advantage of the large amounts of processing power available on AWS, Microsoft Azure or Google Cloud to train their neural networks, while running them (which requires considerably less in the way of resources) on smaller-scale platforms. The semiconductor industry is already responding to this demand: Intel recently announced their Nervana NNP-T and NNP-I neural network processors, where the ‘T’ version offers higher processing power for training, and the ‘I’ version is a lower-performance device aimed at inference and classification applications.

Coming up...
The demonstration application we have looked at in this article can only scratch the surface of the topic of artificial intelligence, but with luck your interest in the possibilities of machines that learn has been piqued.
In the next instalment of this series we will look at the structure and function of a neural network in more detail. That will come with a new development environment: we will be introduced to the temptations of Linux and the Python programming language, as that is where the most powerful libraries and frameworks are available. These frameworks make the creation of a neural network as easy as plugging together Lego bricks. We will also look at a face recognition application and at how to develop your own neural network structures. If you are too impatient or curious to wait for that, the book Make Your Own Neural Network by Tariq Rashid is recommended.

Go to Part 2


Want more great Elektor content like this?
The take out an Elektor membership today and never miss an article, project, or tutorial.
 
  Read full article Hide full article    

Add a rating to this article
  ★ ★ ★ ★ ★   ★ ★ ★ ★ ★   


        Page 1 / 1                              Discussion (9 comments)  Add a comment     patmolloy 4 years ago    Hi Walter, great and interesting article. Thanks!
Along with some other folks, I am having trouble with adding the board withhttp://dl.sipeed.com/MAIX/Maixduino/package_Maixduino_k210_index.json
Just does not work. Any idea? Simply going to that URL throws an ""Unknown Error"" on the page.
After a lot of work (8+ hours) I managed to assemble a collection of files that enabled me to install the board and compile the MobileNet script.
When running, I just see ""Loading ..."" on the LCD (on a red background). And a lot of ""detect object fail"" messages in the serial debug. Will something only appear on the LCD when it is actually recognised do you know.  I've tried various pictures .. so far no luck at all!
Thanks!
Pat
        Reply
               
          Show more
          
            0 Comment(s)
             Brian Catchpoole 4 years ago     As Pat says great article Walter, but I have also struggled to get this running satisfactorily on the Arduino IDE. On boot up of the Maixduino screen displays “Welcome to MaixPy” on a red background. Compile of ‘selfie’ aborts with error: “cannot declare variable 'camera' to be of abstract type 'Sipeed_OV2640'”. This is the case with “mobilenet” as well. Verbose error report attached if of interest.CheersBrian  Compilation Report.zip (3kb)      Reply
               
          Show more
         
            1 Attachment(s)
           
            0 Comment(s)
             Brian Catchpoole 4 years ago    I have now managed to compile satisfactorily thanks to helpful people on line. Turns out the issue is two typo’s in the following library files: “Sipeed_OV2640.cpp” at line 724 “Sipeed_OV2640.h” at line 57 Change “ setRotaion” to “setRotation” (note extra t) Sadly this gets me no further than Pat with mobilenet_v1, my screen displays ‘loading …’ on a red background. No matter what I put in front of the camera the message “detect object fail” is output to Serial 3. All of which suggests a camera hardware issue? Any thoughts?        Reply
               
          Show more
          
            0 Comment(s)
             Brian Catchpoole 4 years ago    For completeness I’m happy to report that the camera was indeed faulty. Having replaced the OV2640, the kit is now functioning as it should.Looking forward to the next instalment.       Reply
               
          Show more
          
            0 Comment(s)
             Edgar Marx 4 years ago    I have MaixDuino (2626), and examples in python language work, especially the camera works.However, this is not the case with the arduino-ide example in cpp: selfie.ino. Procedureint Sipeed_OV2640::sensor_snapshot( ){    g_dvp_finish_flag = 0;    uint32_t start =  millis();  while (g_dvp_finish_flag == 0)    {        usleep(50);  if(millis() - start > 300)  return -1; }    return reverse_u32pixel((uint32_t*)_dataBuffer, _width*_height/2); } returns minus one, which is why image pointer *img of selfie.ino is NULL.As the internet shows, i am not the only one with this problem. How did the author manage that?       Reply
               
          Show more
          
            0 Comment(s)
             Edgar Marx 4 years ago    My Sipeed Maixduino (2626) kit is with a GC0328-camera. The flexible flat ribbon cable of 2cm has the inscribtion: zv-t01-ga4.4.The solution of my problem was very close to me in the form of an ESP32 kit with a OV2640-camera.Now selfie.ino (with PlatformIO selfie.cpp) works as expected.Sipeed_OV2640.cpp scans for the GC0328-camera, but it doesn't work that way of code.       Reply
                  Richard Van Den Oostende 4 years ago    Hello,I've the same problem. I don't really understand how you solve it, can you explain please ?       Reply
                
          Show more
          
            1 Comment(s)
             Johan Benko 3 years ago    Hi, has someone a working link to include in the Arduino IDE? When selecting the board and version I get a CRC error in IDE version 1.8.13       Reply
                  Johan Benko 3 years ago    Add following URL  http://dl.sipeed.com/MAIX/Maixduino/package_Maixduino_k210_dl_cdn_index.json        Reply
                
          Show more
          
            1 Comment(s)
            Add a comment      Embed Code             ",Organization,https://www.elektormagazine.com,Elektormagazine,,,"['https://www.facebook.com/ElektorLabs', 'https://twitter.com/Elektor', 'https://www.instagram.com/elektor_international/', 'https://www.youtube.com/user/ElektorIM']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMWh0dHBzOi8vd3d3Lm5hdHVyZS5jb20vYXJ0aWNsZXMvczQxNzQ2LTAyMC0wMjYxLTPSAQA?oc=5,Artificial intelligence for the diagnosis of heart failure | npj Digital Medicine - Nature.com,2020-04-08,Nature.com,https://www.nature.com,"The diagnosis of heart failure can be difficult, even for heart failure specialists. Artificial Intelligence-Clinical Decision Support System (AI-CDSS) has the potential to assist physicians in heart failure diagnosis. The aim of this work was to evaluate the diagnostic accuracy of an AI-CDSS for heart failure. AI-CDSS for cardiology was developed with a hybrid (expert-driven and machine-learning-driven) approach of knowledge acquisition to evolve the knowledge base with heart failure diagnosis. A retrospective cohort of 1198 patients with and without heart failure was used for the development of AI-CDSS (training dataset, n = 600) and to test the performance (test dataset, n = 598). A prospective clinical pilot study of 97 patients with dyspnea was used to assess the diagnostic accuracy of AI-CDSS compared with that of non-heart failure specialists. The concordance rate between AI-CDSS and heart failure specialists was evaluated. In retrospective cohort, the concordance rate was 98.3% in the test dataset. The concordance rate for patients with heart failure with reduced ejection fraction, heart failure with mid-range ejection fraction, heart failure with preserved ejection fraction, and no heart failure was 100%, 100%, 99.6%, and 91.7%, respectively. In a prospective pilot study of 97 patients presenting with dyspnea to the outpatient clinic, 44% had heart failure. The concordance rate between AI-CDSS and heart failure specialists was 98%, whereas that between non-heart failure specialists and heart failure specialists was 76%. In conclusion, AI-CDSS showed a high diagnostic accuracy for heart failure. Therefore, AI-CDSS may be useful for the diagnosis of heart failure, especially when heart failure specialists are not available.",N/A,N/A,npj Digital Medicine - Artificial intelligence for the diagnosis of heart failure,https://schema.org,,N/A,N/A,"




Download PDF








Article

Open access

Published: 08 April 2020

Artificial intelligence for the diagnosis of heart failure
Dong-Ju Choi 
            ORCID: orcid.org/0000-0003-0146-21891 na1, Jin Joo Park 
            ORCID: orcid.org/0000-0001-9611-14901 na1, Taqdir Ali2 & …Sungyoung Lee 
            ORCID: orcid.org/0000-0002-5962-15872 Show authors

npj Digital Medicine
volume 3, Article number: 54 (2020)
            Cite this article




21k Accesses


57 Citations


30 Altmetric


Metrics details






AbstractThe diagnosis of heart failure can be difficult, even for heart failure specialists. Artificial Intelligence-Clinical Decision Support System (AI-CDSS) has the potential to assist physicians in heart failure diagnosis. The aim of this work was to evaluate the diagnostic accuracy of an AI-CDSS for heart failure. AI-CDSS for cardiology was developed with a hybrid (expert-driven and machine-learning-driven) approach of knowledge acquisition to evolve the knowledge base with heart failure diagnosis. A retrospective cohort of 1198 patients with and without heart failure was used for the development of AI-CDSS (training dataset, n = 600) and to test the performance (test dataset, n = 598). A prospective clinical pilot study of 97 patients with dyspnea was used to assess the diagnostic accuracy of AI-CDSS compared with that of non-heart failure specialists. The concordance rate between AI-CDSS and heart failure specialists was evaluated. In retrospective cohort, the concordance rate was 98.3% in the test dataset. The concordance rate for patients with heart failure with reduced ejection fraction, heart failure with mid-range ejection fraction, heart failure with preserved ejection fraction, and no heart failure was 100%, 100%, 99.6%, and 91.7%, respectively. In a prospective pilot study of 97 patients presenting with dyspnea to the outpatient clinic, 44% had heart failure. The concordance rate between AI-CDSS and heart failure specialists was 98%, whereas that between non-heart failure specialists and heart failure specialists was 76%. In conclusion, AI-CDSS showed a high diagnostic accuracy for heart failure. Therefore, AI-CDSS may be useful for the diagnosis of heart failure, especially when heart failure specialists are not available.



Similar content being viewed by others






Artificial intelligence-enabled ECG for left ventricular diastolic function and filling pressure
                                        


Article
Open access
06 January 2024









Artificial intelligence–enabled electrocardiograms for identification of patients with low ejection fraction: a pragmatic, randomized clinical trial
                                        


Article
06 May 2021









Predicting heart failure onset in the general population using a novel data-mining artificial intelligence method
                                        


Article
Open access
16 March 2023








IntroductionThe prevalence of heart failure (HF) has been increasing1,2. HF is associated with high morbidity and mortality3. Because HF is a complex syndrome that can result from structural and functional cardiac disorder, rather than a single disease entity, its correct diagnosis can be challenging even for HF specialists. Currently, HF is classified according to ejection fraction, i.e., HF with reduced ejection fraction (HFrEF), HF with mid-range ejection fraction (HFmrEF), and HF with preserved ejection fraction (HFpEF)4. A correct diagnosis is mandatory before proper treatment can be initiated4,5. Furthermore, present-day physicians are challenged by rapidly changing scientific evidences, new drugs, and the complexity of guidelines for HF management, especially in outpatient clinic. With enormous advancements in information and communication technologies, such as easy storage, acquisition, and recovery of big data and knowledge, artificial intelligence (AI) has been gaining an important role in cardiology6.Two types of AI decision systems are available: a white-box-based and a black-box-based one. A white-box AI-based decision system involves correlations and transparency among rules for the analysis of accumulated data, and is mainly constructed using supervised algorithms such as decision tree algorithm7. On the contrary, a black-box-based AI has opaque algorithms and its process and reasoning applied in providing the respective conclusions are difficult to clarify. IBM Watson for Oncology (WFO) is black-box AI-based decision systems. WFO demonstrated a concordance rate of 93% for the treatment recommendation in breast cancer. However, WFO cannot disclose the recommendation processes for the final clinical decision8.Clinical Decision Support System (CDSS) is a health information technology that assists physicians in clinical decision making. The concept of computer-based clinical decision has been developed for informatics six decades ago9. In spite of the enthusiasm for evolving CDSS which is assisted with the potential of AI, the realities and complexities of real clinical practice limit the rapid evolution of CDSS. An effective CDSS requires CDSS to match the individual patient’s characteristics to the clinical knowledge base, provides patient-centric assessments and recommendations, and finally presents recommendations in white-box manner to the physicians for their final decision8.We conducted a study assessing the level of agreement with respect to the HF diagnosis to identify the three types of HF, i.e. HFrEF, HFmrEF, and HFpEF, between HF specialists and AI-CDSS at a tertiary center in Korea. First, we created an AI-CDSS using a hybrid approach of expert-driven knowledge acquisition and ML-driven rule generation. Second, we evaluated the diagnosis concordance (degree of agreement) of AI-CDSS in a test set of patients with and without HF as a pilot clinical study. Third, we prospectively tested the diagnostic performance of AI-CDSS in consecutive patients presenting with dyspnea to the outpatient clinic.ResultsDevelopment of cardiovascular AI-CDSSUsing the training dataset of 600 patients with and without HF, the AI-CDSS was created using predefined steps including expert-driven knowledge acquisition, machine learning (ML)-driven rule generation, and hybridization of both types of knowledge.Expert-driven knowledge acquisitionIn the knowledge modeling phase, the clinical recommendations of diagnosis were first transformed into mind maps and then transformed to a decision tree. The decision tree was evaluated and modified by the physicians until a consensus was achieved. The final decision tree was termed as R-CKM (Supplementary Fig. 1) and included 14 contributing factors (Supplementary Table 1) and 4 possible outcomes: HFrEF, HFmrEF, HFpEF, and no-HF.ML-driven rule generationWe used five machine learning algorithms i.e. Decision Tree (DT), Random Forest, Chi-squared Automatic Interaction Detection (CHAID), J48, and Classification and Regression Tree (CART). All algorithms selected only few features such as left ventricular ejection fraction (LVEF), left atrial volume index (LAVI), and left ventricular mass index (LVMI) as highly contributing factors (Supplementary Table 2). To boost the model performance, the auto-feature selection method was used and LVEF, electrocardiography, LVMI, and LAVI were selected as the most significant features (Supplementary Fig. 2).The five algorithms showed different accuracy (Supplementary Table 3). We also calculated the rank of each algorithm based on the accuracy, number of rules extracted, and number of attributes involved, using the rank formula developed in our previous work10. Finally, CART algorithm was selected to create ML-driven knowledge, because it showed the highest accuracy and rank of 88.5 and 0.5736, respectively. The CART algorithm mainly focused on features of LVEF, LAVI, and tricuspid regurgitation velocity (Supplementary Fig. 3). The algorithm correctly predicted HFmrEF and HFrEF with 100% accuracy, whereas HFpEF and no-HF were predicted with 78.9% and 80.5% accuracy, respectively.Hybrid knowledgeThe merging of the CKM from the expert-driven knowledge and the PM from the ML-driven knowledge approach led to the final hybrid knowledge in form of R-CKM (Fig. 1, Supplementary Materials). Sometimes, physician may miss some of the attributes or path of attributes during development of CKM, and the ML generated PM finds the missing attributes or paths. For instance, the CKM is starting with the “Sign & Symptoms” as shown in (Supplementary Fig. 3), while the PM starts checking from “LVEF” as shown in (Supplementary Fig. 4). Therefore, the hybridization algorithm recognizes that the CKM is missing a path of “Not Available” values between “Sign & Symptoms” and “LVEF” attributes. When we added this new path into CKM, the number of knowledge base rules increased drastically. The addition of new path into R-CKM increases the coverage of patient cases to generate right recommendations and increase the accuracy.Fig. 1: Comparison of existing CDSSs and our proposed artificial intelligence-CDSS.CDSS Clinical Decision Support System, CKM clinical knowledge model, I-KAT Intelligent Knowledge Authoring Tool, NCCN National Comprehensive Cancer Network, NICE National Institute for Health and Care Excellence, PM prediction model.Full size imageValidation of AI-CDSSStudy populationThe test dataset included 598 patients (490 patients with HF, 108 patients without HF). Patients with HF were older (73.1 ± 13.8 years vs. 64.8 ± 13.8 years, P < 0.001), more likely to be male (52% vs. 37%, P = 0.005), and had higher N-terminal pro-brain natriuretic peptide levels (10,075 ± 11,778 pg/L vs. 82 ± 68 pg/L, P < 0.001). Concerning the echocardiographic parameters, patients with HF had lower LVEF (45.5 ± 17.4% vs. 64.1 ± 6.5%, P < 0.001), higher LAVI (53.9 ± 21.1 ml/m2 vs. 31.2 ± 8.5 ml/m2, P < 0.001), and higher E/e′ (18.6 ± 9.8 vs. 9.8 ± 3.5, P < 0.001) (Table 1). Among patients with HF, 199 (40.6%), 63 (12.9%), and 228 (46.5%) were classified as having HFrEF, HFmrEF, and HFpEF, respectively.Table 1 Characteristics of the study population retrospective patients (n = 598).Full size tableDiagnostic accuracyThe results of comparative analysis are shown in Fig. 2. The concordance rate was 100% in HFrEF and HFmrEF for all three approaches. With respect to HFpEF, the concordance rate was 82%, 79%, and 99.5% for expert-driven, ML-driven, and hybrid CDSS, respectively. Similar findings were observed for no-HF. The overall diagnostic accuracy was 90%, 88.5%, and 98.3% for expert-driven, ML-driven, and hybrid CDSS, respectively, showing a remarkable increase in accuracy by 8% with the hybrid approach, i.e., AI-CDSS.Fig. 2: Comparative analysis of the diagnostic accuracy of different approaches in the retrospective cohort.CDSS Clinical Decision Support System, HFmrEF heart failure with mid-range ejection fraction, HFpEF heart failure with preserved ejection fraction, HFrEF heart failure with reduced ejection fraction.Full size imageThe expert-driven approach had a sensitivity and a specificity of 0.96 and 0.71, respectively (Supplementary Table 4), whereas the ML-driven approach had a sensitivity and a specificity of 0.72 and 0.94, respectively (Supplementary Table 5). Strikingly, the hybrid approach had a sensitivity and specificity of 0.94 and 0.99, respectively (Supplementary Table 6).Subgroup analysisWe divided the patients according to echocardiographic parameters. Set A included all echocardiography parameters, whereas set B included only LVEF, LAVI, and LVMI. The concordance rate was lower in set B than in set A (Supplementary Fig. 4). In our study, the age of the included patients ranged from 20 to 92 years. Age did not affect the accuracy of the system (Supplementary Table 7).Accuracy of AI-CDSS in a prospective cohort of patients with dyspneaA total of 100 consecutive patients who presented with dyspnea to the outpatient clinic were enrolled. Of these, the data of three patients were not complete; thus, the data of 97 patients were used in the final analysis. Of the 97 patients, 43 (44%) had HF. In this prospective cohort, the concordance rate of the non-HF specialists was 76%, whereas that of AI-CDSS was 98% (Fig. 3). Especially, the diagnosis of HFmrEF and HFpEF was low among the non-HF specialist, whereas the diagnosis of no-HF was comparably high.Fig. 3: Comparative analysis of the diagnostic accuracy of physicians and AI-CDSS in the prospective cohort.Abbreviations are as in Fig. 2.Full size imageDiscussionCorrect diagnosis of HF can be challenging for physicians, even for HF specialists. In this study, we first created AI-CDSS by using the data of 1198 patients with and without HF and showed that AI-CDSS had very high diagnostic accuracy in these patients. In a prospective cohort of patients presenting with dyspnea to the outpatient clinic, AI-CDSS consistently showed a remarkably high diagnostic accuracy. By contrast, non-HF specialists showed a relatively low diagnostic accuracy for HF. Therefore, AI-CDSS may be useful for the diagnosis of HF, especially when HF specialists are not available.CDSS has been applied in clinical diagnosis11, preventive care12, and chronic disease management13, among others. It provides a proficient decision-making service to improve the quality of healthcare, but has several complexities and limitations8. Generally, AI-CDSS acquires knowledge from structured and unstructured data using ML and natural language processing techniques14,15. The amalgamation of ML-driven rule generation with expert-driven knowledge acquisition enhances the system accuracy10. Therefore, we chose the hybrid approach for the knowledge acquisition of AI-CDSS, which includes three distinct steps: expert-driven knowledge acquisition, ML-driven rule generation, and hybridization of both types of knowledge.In expert-driven knowledge acquisition, we first built CKM by transforming expert-driven knowledge into a mind map and decision tree10. Finally, the decision tree was validated with the PM of ML-driven knowledge.In ML-driven knowledge acquisition, we created a PM with an available big dataset. Various ML algorithms can be used to analyze and extract the hidden patterns in the form of knowledge models. In our study, we used white box AI and causal machine algorithms such as decision tree, random forest, CHAID (Chi-squared Automatic Interaction Detector), J48, and CART/CRT. White-box model AI are selected for their transparency, which enables easily determining all attributes for classification and verification of new patient data16. They also increase the physicians’ satisfaction level, because the rationale for a decision is also provided to the physician using the features contributing to the final decision. In addition, the computational complexity of the decision tree constructing algorithms (white box) is relatively low. By contrast, black box algorithms have no transparency in knowledge modeling owing to difficulty in interpreting the inner working layers of the models.In the hybridization of the both knowledge types, we validated the PM from the ML-driven approach against the mind map of CKM from the expert-driven approach to produce the final hybrid knowledge in form of R-CKM.Finally, we developed a web-based application in the form of cardiovascular AI-CDSS for use of physicians in real clinical practice. For this purpose, the R-CKM knowledge was transformed into MLM for knowledge shareability and computer-executable format using I-KAT, which had been developed by our team7. The resultant knowledge can be easily shared and integrated into various formats of HF diagnosis systems, because the resultant knowledge was built with consolidation of the standard data model vMR (Virtual Medical Record) and the standard terminology SNOMED CT (Systematized Nomenclature of Medicine—Clinical Terms).Because HF is a syndrome with various clinical features, its diagnosis can be very challenging even for HF specialists. In patients with HF, pulmonary congestion can develop because of congestion in the left heart, causing dyspnea. However, dyspnea as a symptom can also arise from lung disease, anemia, and mental disorders17. Leg swelling is a typical sign of congestion in the right heart. However, it also has many differential diagnoses, including kidney disease, adverse effect of drugs, and chronic venous insufficiency, among others18. In clinical practice, many patients are diagnosed as having HF even if they do not have HF, and vice versa. A correct diagnosis of HF is crucial because patients with HF have a grave prognosis that is comparable to that of oncologic malignancies19, and there exist therapy that can improve survival in patients with HF4,6. Consequently, misdiagnosis of HF can hinder the chance of improving the outcomes. AI-CDSS is a tool that helps in making better medical decisions, thereby reducing clinical errors and improving the quality of life. It has the potential to generate alerts and reminders, diagnostic assistance, therapy critiquing and planning, and image recognition and interpretation.Currently, HF is classified according to LVEF into HFrEF, HFmrEF, and HFpEF. With respect to HFrEF, a decrease in LVEF may alert physicians to the possible diagnosis of HF. By contrast, for HFpEF >50%, the normal systolic function may “blind” the physicians and HFpEF may remain undiagnosed. We showed that AI-CDSS showed acceptably high concordance for diagnosing HF regardless of type, whereas non-HF specialists misdiagnosed HFpEF in almost half of the patients.In medicine, IBM WFO demonstrated high concordance with oncologists in treatment recommendations14. In the field of cardiology, our study presents the clinical feasibility of AI for diagnosing HF.There are several limitations in this study. The intervention of the physicians is crucial in knowledge creation and validation. However, the level of expertise varies from physician to physician, so that the CKM developed by physicians in a hospital may differ from that developed in another hospital. Similarly, because the attributes in the PM depend on the patient data used, they may also differ from variables recommended in the guidelines. Therefore, further studies are necessary to validate the AI-CDSS in other study populations.In conclusions, AI-CDSS showed high diagnostic accuracy for HF, independent of HF types. Therefore, AI-CDSS may be useful for the diagnosis of HF, especially when HF specialists are not available.MethodsStudy population and data collectionRetrospective cohortWe included 1198 patients with and without HF from January 2016 to December 2017. We divided the patients into two datasets. The first 600 patients were used for the generation of AI-CDSS as a training dataset for ML, whereas the remaining 598 patients were used for the validation of the AI-CDSS as the test dataset. HF was defined as present when patients had symptoms (dyspnea, orthopnea) or signs of HF (rales, pitting edema, ascites) and met one of the following criteria: lung congestion, objective findings of left ventricular systolic dysfunction, or structural heart disease. Clinical information including demographics, symptoms, signs, medical history, laboratory examination, electrocardiography, and echocardiography was obtained. Control patients, i.e., those without HF, were randomly selected from the electronic medical records.Prospective pilot cohortFor an additional validation of AI-CDSS, we enrolled 100 consecutive patients presenting with dyspnea to the outpatient clinic. The treating physicians performed history taking and physical examination, ordered diagnostic tests, and made a final diagnosis, i.e., HF or no-HF, according to their clinical judgment. The data were first recorded in an electronic clinical research form, and then automatically transferred to the AI-CDSS. A direct extraction of patients’ data from electronic medical record was circumvented because of the information security regulation at our institution.The study protocol was approved by the institutional review board of the Seoul National University Bundang Hospital. For the retrospective cohort, the requirement for written informed consent was waived by the institutional review board. Each patient in the prospective cohort provided informed consent before study enrollment. The study complied with the Declaration of Helsinki.EchocardiographyAll images were obtained using a standard ultrasound machine with a 2.5-MHz probe. Standard techniques were used to obtain M-mode, two-dimensional, and Doppler measurements in accordance with the American Society of Echocardiography guidelines20. Tissue-Doppler-derived peak systolic, early, and late diastolic velocities of the septal mitral annulus were recorded. Left ventricular end-systolic and end-diastolic volumes were measured from apical four- and two-chamber views and LVEF was calculated using Simpson’s biplane method.Generation of cardiovascular AI-CDSSThe traditional CDSSs usually focus on the expert-driven approach with collaboration between physicians and knowledge engineers, where the knowledge engineer is an expert in AI language who investigate the underlying problems, develop the main concepts, and efficiently represent the knowledge in the domain. The fundamental knowledge resource is the clinical practice guidelines and physicians’ expertise. The AI-CDSS uses patient data as the second important resource of knowledge after processing with ML algorithm (ML-driven approach). Figure 1 shows the difference between the traditional CDSSs and the cardiovascular AI-CDSS. The existing CDSSs maintain the knowledge base by the knowledge engineers. In contrast, AI-CDSS focuses on the hybrid approach of expert-driven knowledge acquisition and ML-driven rule generation and overcomes the physicians’ dependency on knowledge engineers. In AI-CDSS, the clinical knowledge model (CKM), a classical top-down decision tree, is generated by domain expert (physician) using guidelines and their experiences; it is called the Expert-Driven Knowledge. The second step is to create ML-based prediction model (PM) using several ML algorithms, which is called the machine learning (ML)-driven knowledge. The third step is to generate the refined-CKM (R-CKM) by the computer scientists using a quick, simple, and iterative agile software development. The R-CKM generation is composed of making prediction model of ML-driven knowledge and validation of expert-driven knowledge with respective ML-driven knowledge using several ML algorithms with training dataset of 600 patients’ data; it is called the hybrid knowledge. Finally, the R-CKM knowledge is transformed into shareable and interoperable setting in the form of Health Level-7 (HL7) complaint standard knowledge representation, termed Medical Logic Module (MLM), using the Intelligent Knowledge Authoring Tool (I-KAT) developed by our group. The executable MLM in the shareable knowledge base is executed to generate decisions based on the patients’ input to assist the physicians. More details of cardiovascular AI-CDSS are explained in the Supplementary methods.Study variablesHF was defined when patients had signs or symptoms of HF and either lung congestion, objective findings of LV systolic dysfunction, or structural heart disease. The diagnosis of HF was confirmed by two independent HF specialists who had >10 years of clinical experience. The diagnosis by the experts was considered the gold standard.According to the LVEF on echocardiography, patients were classified as having HFrEF (LVEF < 40%), HFmrEF (40% ≤ LVEF < 50%), and HFpEF (LVEF ≥ 50%).The diagnostic accuracy of AI-CDSS was measured using experts’ diagnosis as the gold standard. Concordance was defined as present when experts and AI-CDSS had the same diagnosis, i.e., both HF or both no-HF. Discordance was defined to exist when there was a disagreement between diagnoses.Statistical analysisDescriptive statistics were calculated to determine the clinical characteristics and outcomes of the registry population. Data were presented as numbers and frequencies for categorical variables and as mean ± standard deviation or median with interquartile range for continuous variables. For the comparison between groups, the χ2 test (or Fisher’s exact test when any expected cell count was <5 for a 2 × 2 table) was used for categorical variables, whereas unpaired Student’s t-test was used for continuous variables. Concordance was expressed as the percentage agreement. Pearson’s correlation was used to calculate the association between expert opinion and AI-CDSS judgment.A two-sided P value of <0.05 was considered statistically significant. Statistical tests were performed using IBM SPSS Statistics version 23 (SPSS Inc., Chicago, IL, USA).Role of the funding sourceThe funder of the study had no role in study design, data collection, data analysis, data interpretation, or writing of the report. The corresponding author had full access to all the data in the study and had final responsibility for the decision to submit for publication.Reporting summaryFurther information on experimental design is available in the Nature Research Reporting Summary linked to this article.


Data availability
The dataset generated during the current study is not publicly available due to restrictions in the ethical permit, but may be available from the corresponding author on reasonable request.
Code availability
We have made all source code available at https://github.com/ubiquitous-computing-lab/AI-CDSS-Cardiovascular-Silo.
ReferencesRedfield, M. M. et al. Burden of systolic and diastolic ventricular dysfunction in the community: appreciating the scope of the heart failure epidemic. JAMA 289, 194–202 (2003).Article 
    
                    Google Scholar 
                Choi, D. J. et al. Characteristics, outcomes and predictors of long-term mortality for patients hospitalized for acute heart failure: a report from the Korean Heart Failure Registry. Korean Circ. J. 41, 363–371 (2011).Article 
    
                    Google Scholar 
                Bleumink, G. S. et al. Quantifying the heart failure epidemic: prevalence, incidence rate, lifetime risk and prognosis of heart failure The Rotterdam Study. Eur. Heart J. 25, 1614–1619 (2004).Article 
    
                    Google Scholar 
                Ponikowski, P. et al. ESC guidelines for the diagnosis and treatment of acute and chronic heart failure: The Task Force for the diagnosis and treatment of acute and chronic heart failure of the European Society of Cardiology (ESC). Developed with the special contribution of the Heart Failure Association (HFA) of the ESC. Eur. J. Heart Fail. 18, 891–975 (2016).Article 
    
                    Google Scholar 
                Kim, M. S. et al. Korean guidelines for diagnosis and management of chronic heart failure. Korean Circ. J. 47, 555–643 (2017).Article 
    
                    Google Scholar 
                Johnson, K. W. et al. Artificial intelligence in cardiology. J. Am. Coll. Cardiol. 71, 2668–2679 (2018).Article 
    
                    Google Scholar 
                Ali, T. et al. Multi-model-based interactive authoring environment for creating shareable medical knowledge. Comput. Methods Prog. Biomed. 150, 41–72 (2017).Article 
    
                    Google Scholar 
                Shortliffe, E. H. & Sepulveda, M. J. Clinical decision support in the era of artificial intelligence. JAMA 320, 2199–2200 (2018).Article 
    
                    Google Scholar 
                Ledley, R. S. & Lusted, L. B. Reasoning foundations of medical diagnosis; symbolic logic, probability, and value theory aid our understanding of how physicians reason. Science 130, 9–21 (1959).Article 
    CAS 
    
                    Google Scholar 
                Hussain, M. et al. Data-driven knowledge acquisition, validation, and transformation into HL7 Arden Syntax. Artif. Intell. Med. 92, 51–70 (2018).Article 
    
                    Google Scholar 
                Kline, J. A., Zeitouni, R. A., Hernandez-Nino, J. & Jones, A. E. Randomized trial of computerized quantitative pretest probability in low-risk chest pain patients: effect on safety and resource use. Ann. Emerg. Med. 53, 727–735. e721 (2009).Article 
    
                    Google Scholar 
                Kucher, N. et al. Electronic alerts to prevent venous thromboembolism among hospitalized patients. N. Engl. J. Med. 352, 969–977 (2005).Article 
    CAS 
    
                    Google Scholar 
                Roumie, C. L. et al. Improving blood pressure control through provider education, provider alerts, and patient education: a cluster randomized trial. Ann. Intern. Med. 145, 165–175 (2006).Article 
    
                    Google Scholar 
                Somashekhar, S. P. et al. Watson for oncology and breast cancer treatment recommendations: agreement with an expert multidisciplinary tumor board. Ann. Oncol.: Off. J. Eur. Soc. Med. Oncol. 29, 418–423 (2018).Article 
    CAS 
    
                    Google Scholar 
                Hinton, G. Deep learning—a technology with the potential to transform health care. JAMA 320, 1101–1102 (2018).Article 
    
                    Google Scholar 
                Romero, C., Olmo Ortiz, J. L. & Ventura, S. A meta-learning approach for recommending a subset of white-box classification algorithms for moodle datasets. Proc. Educational Data Mining, Memphis, TN, USA (2013).Berliner, D., Schneider, N., Welte, T. & Bauersachs, J. The differential diagnosis of dyspnea. Dtsch. Arzteblatt Int. 113, 834–845 (2016).
                    Google Scholar 
                Ciocon, J. O., Fernandez, B. B. & Ciocon, D. G. Leg edema: clinical clues to the differential diagnosis. Geriatrics 48, 34–40, 45 (1993).CAS 
    PubMed 
    
                    Google Scholar 
                Stewart, S., MacIntyre, K., Hole, D. J., Capewell, S. & McMurray, J. J. More ‘malignant’ than cancer? Five-year survival following a first admission for heart failure. Eur. J. Heart Fail. 3, 315–322 (2001).Article 
    CAS 
    
                    Google Scholar 
                Lang, R. M. et al. Recommendations for cardiac chamber quantification by echocardiography in adults: an update from the American Society of Echocardiography and the European Association of Cardiovascular Imaging. J. Am. Soc. Echocardiogr. 28, 1–39. e14 (2015).Article 
    
                    Google Scholar 
                Download referencesAcknowledgementsThis research was supported by the MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center) support program (IITP-2017-0-01629) supervised by the IITP (Institute for Information & Communications Technology Promotion). Figure 1 contains icons designed by Zlatko Najdenovski, Smashicons from www.flaticon.com.Author informationAuthor notesThese authors contributed equally: Dong-Ju Choi, Jin Joo Park.Authors and AffiliationsDivision of Cardiology, Department of Internal Medicine, Seoul National University Bundang Hospital, Seongnam, Republic of KoreaDong-Ju Choi & Jin Joo ParkDepartment of Computer Science and Engineering, Kyung Hee University, Yongin, Republic of KoreaTaqdir Ali & Sungyoung LeeAuthorsDong-Ju ChoiView author publicationsYou can also search for this author in
                        PubMed Google ScholarJin Joo ParkView author publicationsYou can also search for this author in
                        PubMed Google ScholarTaqdir AliView author publicationsYou can also search for this author in
                        PubMed Google ScholarSungyoung LeeView author publicationsYou can also search for this author in
                        PubMed Google ScholarContributionsD.-J.C. and S.L. designed the study; D.-J.C., J.J.P., T.A., and S.L. analyzed the data. J.J.P. and T.A. wrote the first draft of the manuscript which was reviewed, modified, and approved by all other authors. All the authors vouch for the accuracy and completeness of the data reported and for the fidelity of the study to the protocol.Corresponding authorsCorrespondence to
                Dong-Ju Choi or Sungyoung Lee.Ethics declarations
Competing interests
The authors declare no competing interests.
Additional informationPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Supplementary informationSupplementary InformationReporting SummaryRights and permissions
Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.
Reprints and permissionsAbout this articleCite this articleChoi, DJ., Park, J.J., Ali, T. et al. Artificial intelligence for the diagnosis of heart failure.
                    npj Digit. Med. 3, 54 (2020). https://doi.org/10.1038/s41746-020-0261-3Download citationReceived: 10 December 2019Accepted: 12 March 2020Published: 08 April 2020DOI: https://doi.org/10.1038/s41746-020-0261-3Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        
Subjects

Heart failureOutcomes research





This article is cited by





                                        A machine learning-based lung ultrasound algorithm for the diagnosis of acute heart failure
                                    


Stefano CoiroClaire LacomblezNicolas Girerd

Internal and Emergency Medicine (2024)




                                        Adopting artificial intelligence in cardiovascular medicine: a scoping review
                                    


Hisaki MakimotoTakahide Kohro

Hypertension Research (2023)




                                        The Application of Computer Technology to Clinical Practice Guideline Implementation: A Scoping Review
                                    


Xu-Hui LiJian-Peng LiaoYing-Hui Jin

Journal of Medical Systems (2023)




                                        An efficient disease prediction framework based on optimized machine learning models for a smart healthcare application
                                    


Na Jiao

Multimedia Tools and Applications (2023)




                                        Harnessing Electronic Medical Records in Cardiovascular Clinical Practice and Research
                                    


Pishoy GoudaJustin Ezekowitz

Journal of Cardiovascular Translational Research (2023)






",WebPage,,,,,,"{'headline': 'Artificial intelligence for the diagnosis of heart failure', 'description': 'The diagnosis of heart failure can be difficult, even for heart failure specialists. Artificial Intelligence-Clinical Decision Support System (AI-CDSS) has the potential to assist physicians in heart failure diagnosis. The aim of this work was to evaluate the diagnostic accuracy of an AI-CDSS for heart failure. AI-CDSS for cardiology was developed with a hybrid (expert-driven and machine-learning-driven) approach of knowledge acquisition to evolve the knowledge base with heart failure diagnosis. A retrospective cohort of 1198 patients with and without heart failure was used for the development of AI-CDSS (training dataset, n\u2009=\u2009600) and to test the performance (test dataset, n\u2009=\u2009598). A prospective clinical pilot study of 97 patients with dyspnea was used to assess the diagnostic accuracy of AI-CDSS compared with that of non-heart failure specialists. The concordance rate between AI-CDSS and heart failure specialists was evaluated. In retrospective cohort, the concordance rate was 98.3% in the test dataset. The concordance rate for patients with heart failure with reduced ejection fraction, heart failure with mid-range ejection fraction, heart failure with preserved ejection fraction, and no heart failure was 100%, 100%, 99.6%, and 91.7%, respectively. In a prospective pilot study of 97 patients presenting with dyspnea to the outpatient clinic, 44% had heart failure. The concordance rate between AI-CDSS and heart failure specialists was 98%, whereas that between non-heart failure specialists and heart failure specialists was 76%. In conclusion, AI-CDSS showed a high diagnostic accuracy for heart failure. Therefore, AI-CDSS may be useful for the diagnosis of heart failure, especially when heart failure specialists are not available.', 'datePublished': '2020-04-08T00:00:00Z', 'dateModified': '2020-04-08T00:00:00Z', 'pageStart': '1', 'pageEnd': '6', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'sameAs': 'https://doi.org/10.1038/s41746-020-0261-3', 'keywords': ['Heart failure', 'Outcomes research', 'Medicine/Public Health', 'general', 'Biomedicine', 'Biotechnology'], 'image': ['https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-020-0261-3/MediaObjects/41746_2020_261_Fig1_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-020-0261-3/MediaObjects/41746_2020_261_Fig2_HTML.png', 'https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-020-0261-3/MediaObjects/41746_2020_261_Fig3_HTML.png'], 'isPartOf': {'name': 'npj Digital Medicine', 'issn': ['2398-6352'], 'volumeNumber': '3', '@type': ['Periodical', 'PublicationVolume']}, 'publisher': {'name': 'Nature Publishing Group UK', 'logo': {'url': 'https://www.springernature.com/app-sn/public/images/logo-springernature.png', '@type': 'ImageObject'}, '@type': 'Organization'}, 'author': [{'name': 'Dong-Ju Choi', 'url': 'http://orcid.org/0000-0003-0146-2189', 'affiliation': [{'name': 'Seoul National University Bundang Hospital', 'address': {'name': 'Division of Cardiology, Department of Internal Medicine, Seoul National University Bundang Hospital, Seongnam, Republic of Korea', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'djchoi@snubh.org', '@type': 'Person'}, {'name': 'Jin Joo Park', 'url': 'http://orcid.org/0000-0001-9611-1490', 'affiliation': [{'name': 'Seoul National University Bundang Hospital', 'address': {'name': 'Division of Cardiology, Department of Internal Medicine, Seoul National University Bundang Hospital, Seongnam, Republic of Korea', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Taqdir Ali', 'affiliation': [{'name': 'Kyung Hee University', 'address': {'name': 'Department of Computer Science and Engineering, Kyung Hee University, Yongin, Republic of Korea', '@type': 'PostalAddress'}, '@type': 'Organization'}], '@type': 'Person'}, {'name': 'Sungyoung Lee', 'url': 'http://orcid.org/0000-0002-5962-1587', 'affiliation': [{'name': 'Kyung Hee University', 'address': {'name': 'Department of Computer Science and Engineering, Kyung Hee University, Yongin, Republic of Korea', '@type': 'PostalAddress'}, '@type': 'Organization'}], 'email': 'sylee@oslab.khu.ac.kr', '@type': 'Person'}], 'isAccessibleForFree': True, '@type': 'ScholarlyArticle'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjAvMDQvMDgvdGVjaG5vbG9neS9haS1zcG9ydHMtYXRobGV0ZXMtbWFjaGluZS1sZWFybmluZy5odG1s0gEA?oc=5,Want to Be Better at Sports? Listen to the Machines (Published 2020) - The New York Times,2020-04-08,The New York Times,https://www.nytimes.com,"The pattern-recognizing power of machine learning is affecting players, teams, sports medicine and even betting.",N/A,"The pattern-recognizing power of machine learning is affecting players, teams, sports medicine and even betting.","The pattern-recognizing power of machine learning is affecting players, teams, sports medicine and even betting.",https://schema.org,,Technology,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingA lab at Seattle Sports Sciences in Redmond, Wash., that features 20 synchronized cameras.Credit...Cindy AlgerWant to Be Better at Sports? Listen to the MachinesThe pattern-recognizing power of machine learning is affecting players, teams, sports medicine and even betting.A lab at Seattle Sports Sciences in Redmond, Wash., that features 20 synchronized cameras.Credit...Cindy AlgerSupported bySKIP ADVERTISEMENTShare full articleRead in appBy Craig S. SmithApril 8, 2020This article is part of our latest Artificial Intelligence special report, which focuses on how the technology continues to evolve and affect our lives.A couple of decades ago, Jeff Alger, then a senior manager at Microsoft, was coaching state-level soccer teams and realized that there was very little science to player development.“There were no objective ways of measuring how good players are,” said Mr. Alger, “and without being able to measure, you have nothing.”He said it offended his sense of systems design to recognize a problem but do nothing about it, so he quit his job, got a master’s degree in sports management and started a company that would use artificial intelligence to assess athletic talent and training.AdvertisementSKIP ADVERTISEMENTHis company, Seattle Sports Sciences, is one of a handful using the pattern-recognizing power of machine learning to revolutionize coaching and make advanced analytics available to teams of all kinds.The trend is touching professional sports and changing sports medicine. And, perhaps inevitably, it has altered the odds in sports betting.John Milton, the architect of Seattle Sports Sciences’ artificial intelligence system, spent a week in October with the Spanish soccer team Málaga, which plays in Spain’s second division, capturing everything that happened on the pitch with about 20 synchronized cameras in 4K ultra high-definition video.“It’s like omniscience,” Mr. Milton said. The system, ISOTechne, evaluates a player’s skill and consistency and who is passing or receiving with what frequency, as well as the structure of the team’s defense. It even tracks the axis of spin and rate of rotation of the ball.That is not the only way that the company’s technology is being used. Professional soccer teams derive a growing slice of revenue from selling players. Soccer academies have become profit centers for many teams as they develop talented players and then sell them to other teams. It is now a $7 billion business. But without objective measurements of a player’s ability, putting a value on an athlete is difficult.AdvertisementSKIP ADVERTISEMENT“It’s a matter of whether that player’s movements and what they do with the ball correspond to the demands that they will have on your particular team,” said Mr. Alger, now the president and chief executive of Seattle Sports Sciences. He said, for example, that his company could identify a player who was less skilled at other phases of the game but was better at delivering the ball on a corner kick or a free kick — a skill that a coach could be looking for.Some systems can also detect and predict injuries. Dr. Phil Wagner, chief executive and founder of Sparta Science, works from a warehouse in Silicon Valley that has a running track and is scattered with equipment for assessing athletes’ physical condition.The company uses machine learning to gather data from electronic plates on the ground that measure force and balance. The system gathers 3,000 data points a second and a test — jumping or balancing — takes about 20 seconds.“Athletes don’t recognize that there’s an injury coming or there’s an injury that exists,” Dr. Wagner said, adding that the system has a proven record of diagnosing or predicting injury. “We’re identifying risk and then providing the best recommendation to reduce that risk.”AdvertisementSKIP ADVERTISEMENTImageTyson Ross, a pitcher whose workouts are tailored by Sparta Science.Credit...Charles Krupa/Associated PressTyson Ross, a pitcher competing for a roster spot with the San Francisco Giants, has been using Sparta Science’s system since he was drafted in 2008. He visits the company’s facilities roughly every other week during the off-season to do vertical jumps, sway tests, a single leg balance test and a one-arm plank on the plate, blindfolded.“Based on the data that’s collected, it tells me how I’m moving compared to previously and how I’m moving compared to my ideal movement signature, as they call it,” Mr. Ross said. Sparta Science then tailors his workouts to move him closer to that ideal.The Pittsburgh Steelers, the Detroit Lions and the Washington Redskins, among others, use the system regularly, Dr. Wagner said. Sparta Science is also used to evaluate college players in the National Football League’s annual scouting combine.Of course, it is inevitable that machine learning’s predictive power would be applied to another lucrative end of the sports industry: betting. Sportlogiq, a Montreal-based firm, has a system that primarily relies on broadcast feeds to analyze players and teams in hockey, soccer, football and lacrosse.AdvertisementSKIP ADVERTISEMENTMehrsan Javan, the company’s chief technology officer and one of its co-founders, said the majority of National Hockey League teams, including the last four Stanley Cup champions, used Sportlogiq’s system to evaluate players.Josh Flynn, assistant general manager for the Columbus Blue Jackets, Ohio’s professional hockey franchise, said the team used Sportlogiq to analyze players and strategy. “We can dive levels deeper into questions we have about the game than we did before,” Mr. Flynn said. But Sportlogiq also sells analytic data to bookmakers in the United States, helping them set odds on bets, and hopes to sell information to individual bettors soon. Mr. Javan is looking to hire a vice president of betting.They key to all of this sports-focused technology is data.“Algorithms come and go, but data is forever,” Mr. Alger is fond of saying. Computer vision systems have to be told what to look for, whether it be tumors in an X-ray or bicycles on the road. In Seattle Sports Sciences’ case, the computers must be trained to recognize the ball in various lighting conditions as well as understand which plane of the foot is striking the ball.ImageMembers of the Columbus Blue Jackets, one of the N.H.L. teams that are using Sportlogiq to analyze players and strategy.Credit...Anne-Marie Sorvin/USA Today Sports, via ReutersAdvertisementSKIP ADVERTISEMENTTo do that, teams of workers first have to painstakingly annotate millions of images. The more annotated data, the more accurate the machine-learning analysis will be. “Basically, whoever has the most labeled data wins,” said Mr. Milton, the A.I. architect.Seattle Sports Sciences uses Labelbox, a training data platform that allows Mr. Milton’s data science team in Seattle to work with shifts of workers in India who label data 24 hours a day. “That’s how fast you have to move to compete in modern vision A.I.,” Mr. Milton said. “It’s basically a labeling arms race.”Dr. Wagner of Sparta Science agrees, noting that with algorithms readily available and cloud computing power now available everywhere, the differentiator is data. He said it took Sparta Science 10 years to build up enough data to train its machine-learning system adequately.Sam Robertson, who runs the sports performance and business program at Victoria University in Melbourne, Australia, said it would take time for the technology to transform sports. “The decision-making component of this right now is still almost exclusively done by humans,” he said.“We need to work on the quality of the inputs,” he said, meaning the labeled data. “That’s what’s going to improve things.”Craig S. Smith is a former correspondent for The Times and hosts the podcast Eye on A.I.A version of this article appears in print on April 9, 2020, Section F, Page 5 of the New York edition with the headline: Game Changers. Order Reprints | Today’s Paper | SubscribeShare full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",NewsMediaOrganization,https://www.nytimes.com/,The New York Times,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",,https://en.wikipedia.org/wiki/The_New_York_Times,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/04/09/multimedia/09sp-ai-soccer1/09sp-ai-soccer1-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2020/04/09/multimedia/09sp-ai-soccer1/09sp-ai-soccer1-videoSixteenByNineJumbo1600.jpg', 'caption': 'A lab at Seattle Sports Sciences in Redmond, Wash., that features 20 synchronized cameras.', 'creditText': 'Cindy Alger'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/04/09/multimedia/09sp-ai-soccer1/09sp-ai-soccer1-superJumbo.jpg', 'height': 1365, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2020/04/09/multimedia/09sp-ai-soccer1/09sp-ai-soccer1-superJumbo.jpg', 'caption': 'A lab at Seattle Sports Sciences in Redmond, Wash., that features 20 synchronized cameras.', 'creditText': 'Cindy Alger'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/04/09/multimedia/09sp-ai-soccer1/09sp-ai-soccer1-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2020/04/09/multimedia/09sp-ai-soccer1/09sp-ai-soccer1-mediumSquareAt3X.jpg', 'caption': 'A lab at Seattle Sports Sciences in Redmond, Wash., that features 20 synchronized cameras.', 'creditText': 'Cindy Alger'}]",https://www.nytimes.com/2020/04/08/technology/ai-sports-athletes-machine-learning.html,en-US,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/craig-s-smith', 'name': 'Craig S. Smith'}]",2020-04-08T22:27:33.000Z,2020-04-08T09:00:32.000Z,Want to Be Better at Sports? Listen to the Machines,Game Changers,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3Lm9wZW5nbG9iYWxyaWdodHMub3JnL2FkZHJlc3NpbmctZ2VuZGVyLWJpYXMtaW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLWF1dG9tYXRpb24v0gEA?oc=5,Addressing the gender bias in artificial intelligence and automation - OpenGlobalRights,2020-04-10,OpenGlobalRights,https://www.openglobalrights.org,"If AI and automation are not developed and applied in a gender-responsive way, they are likely to reproduce and reinforce existing gender stereotypes and discriminatory social norms.",N/A,"If AI and automation are not developed and applied in a gender-responsive way, they are likely to reproduce and reinforce existing gender stereotypes and discriminatory social norms.","If AI and automation are not developed and applied in a gender-responsive way, they are likely to reproduce and reinforce existing gender stereotypes and discriminatory social norms.",,,N/A,N/A,"
 
Geralt/Pixabay

Twenty-five years after the adoption of the Beijing Declaration and Platform for Action, significant gender bias in existing social norms remains. For example, as recently as February 2020, the Indian Supreme Court had to remind the Indian government that its arguments for denying women command positions in the Army were based on stereotypes. And gender bias is not merely a male problem: a recent UNDP report entitled Tackling Social Norms found that about 90% of people (both men and women) hold some bias against women.
Gender bias and various forms of discrimination against women and girls pervades all spheres of life. Women’s equal access to science and information technology is no exception. While the challenges posed by the digital divide and under-representation of women in STEM (science, technology, engineering and mathematics) continue, artificial intelligence (AI) and automation are throwing newer challenges to achieving substantive gender equality in the era of the Fourth Industrial Revolution.
If AI and automation are not developed and applied in a gender-responsive way, they are likely to reproduce and reinforce existing gender stereotypes and discriminatory social norms. In fact, this may already be happening (un)consciously. Let us consider a few examples:  

As a 2019 UNESCO report highlights, it is not a coincidence that virtual personal assistants such as Siri, Alexa and Cortana have female names and come with a default female voice. Companies behind these virtual assistants are reinforcing the social reality in which a majority of personal assistants or secretaries in both public and private sectors are women.
Gender bias pervades AI algorithms as well. With 78% of AI professionals being men, male experiences inform and dominate algorithm creation. This gender bias can have significant adverse implications for women. For example, algorithms could affect women’s access to jobs and loans by automatically vetting out their applications or giving women applicants an unfavourable rating. Similarly, the algorithm-based risk assessment in criminal justice systems could work against women if the system did not factor in that women are less likely than men to reoffend.
Although robotization and automation of jobs will impact both men and women, gender bias is likely to carry forward and thus impact women disproportionately. For instance, women over-represented in certain high-risk automation sectors might suffer more: if over 70% of workers in apparel manufacturing are women, automation will affect women more than men. Relative lack of mobility and flexibility is also very likely to reduce bargaining position of, or alternative job options for, women generally.

Despite the potential for such gender bias, the growing crop of AI standards do not adequately integrate a gender perspective. For example, the Montreal Declaration for the Responsible Development of Artificial Intelligence does not make an explicit reference to integrating a gender perspective, while the AI4People’s Ethical Framework for a Good AI Society mentions diversity/gender only once. Both the OECD Council Recommendation on AI and the G20 AI Principles stress the importance of AI contributing to reducing gender inequality, but provide no details on how this could be achieved.
The Responsible Machine Learning Principles do embrace “bias evaluation” as one of the principles. This siloed approach of embracing gender is also adopted by companies like Google and Microsoft, whose AI Principles underscore the need to avoid “creating or reinforcing unfair bias” and to treat “all people fairly”, respectively. Companies related to AI and automation should adopt a gender-response approach across all principles to overcome inherent gender bias. Google should, for example, embed a gender perspective in assessing which new technologies are “socially beneficial” or how AI systems are “built and tested for safety”.
What should be done to address the gender bias in AI and automation? The gender framework for the UN Guiding Principles on Business and Human Rights could provide practical guidance to states, companies and other actors. The framework involves a three-step cycle: gender-responsive assessment, gender-transformative measures and gender-transformative remedies. The assessment should be able to respond to differentiated, intersectional, and disproportionate adverse impacts on women’s human rights. The consequent measures and remedies should be transformative in that they should be capable of bringing change to patriarchal norms, unequal power relations. and gender stereotyping.
States, companies and other actors can take several concrete steps. First, women should be active participants—rather than mere passive beneficiaries—in creating AI and automation. Women and their experiences should be adequately integrated in all steps related to design, development and application of AI and automation. In addition to proactively hiring more women at all levels, AI and automation companies should engage gender experts and women’s organisations from the outset in conducting human rights due diligence.
Women should be active participants—rather than mere passive beneficiaries—in creating AI and automation.
Second, the data that informs algorithms, AI and automation should be sex-disaggregated, otherwise the experiences of women will not inform these technological tools and in turn might continue to internalise existing gender biases against women. Moreover, even data related to women should be guarded against any inherent gender bias.
Third, states, companies and universities should plan for and invest in building capacity of women to achieve smooth transition to AI and automation. This would require vocational/technical training at both education and work levels.
Fourth, AI and automation should be designed to overcome gender discrimination and patriarchal social norms. In other words, these technologies should be employed to address challenges faced by women such as unpaid care work, gender pay gap, cyber bullying, gender-based violence and sexual harassment, trafficking, breach of sexual and reproductive rights, and under-representation in leadership positions. Similarly, the power of AI and automation should be employed to enhance women’s access to finance, higher education and flexible work opportunities.
Fifth, special steps should be taken to make women aware of their human rights and the impact of AI and automation on their rights. Similar measures are needed to ensure that remedial mechanisms—both judicial and non-judicial—are responsive to gender bias, discrimination, patriarchal power structures, and asymmetries of information and resources.
Sixth, states and companies should keep in mind the intersectional dimensions of gender discrimination, otherwise their responses, despite good intentions, will fall short of using AI and automation to accomplish gender equality. Low-income women, single mothers, women of colour, migrant women, women with disability, and non-heterosexual women all may be affected differently by AI and automation and would have differentiated needs or expectations.
Finally, all standards related to AI and automation should integrate a gender perspective in a holistic manner, rather than treating gender as merely a bias issue to be managed.
Technologies are rarely gender neutral in practice. If AI and automation continue to ignore women’s experiences or to leave women behind, everyone will be worse off.
 

This piece is part of a blog series focusing on the gender dimensions of business and human rights. The blog series is in partnership with the Business & Human Rights Resource Centre, the Danish Institute for Human Rights and OpenGlobalRights. The views expressed in the series are those of the authors. For more on the latest news and resources on gender, business and human rights, visit this portal.

 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiOGh0dHBzOi8vZW1lcmouY29tL2FpLXNlY3Rvci1vdmVydmlld3MvYWktbW9yZ2FuLXN0YW5sZXkv0gEA?oc=5,Artificial Intelligence at Morgan Stanley - Current Initiatives - Emerj,2020-04-07,Emerj,https://emerj.com,Discover how Morgan Stanley is bringing artificial intelligence to wealth and asset management processes and investing long-term in data science.,,Discover how Morgan Stanley is bringing artificial intelligence to wealth and asset management processes and investing long-term in data science.,N/A,https://schema.org,,N/A,N/A," Business intelligence and analyticsFinance Artificial Intelligence at Morgan Stanley – Current Initiatives Niccolo MejiaLast updated on April 7, 2020  Last updated on April 7, 2020, published by Niccolo Mejia Niccolo is a content writer and Junior Analyst at Emerj, developing both web content and helping with quantitative research. He holds a bachelor's degree in Writing, Literature, and Publishing from Emerson College. Share to: LinkedIn Twitter Facebook Email  Morgan Stanley is a US financial institution known mostly for its financial advisory services. According to our AI Opportunity Landscape research in financial services, approximately 10% of AI vendor products in the industry are wealth management solutions, and 4% are asset management solutions.  The latter is on par with customer service and lending applications, indicating that the use-case has at least some comparable traction with AI. Morgan Stanley in particular has been using AI for this use-case since at least 2018: Next Best Action: A tool on Morgan Stanley’s WealthDesk platform that can purportedly help its wealth and asset managers make more informed decisions for their clients and reach more of their clients at once. They also bolster their AI initiatives by deploying data science talent in advisory positions: Data Center of Excellence: A 30-person operation that provides consulting to various departments within the financial institution with the goal of setting them up for AI adoption. In this article, we lay out the available information on both of these initiatives an explore the benefits they could bring to the company, starting with Morgan Stanley’s wealth and asset management tool, Next Best Action: Wealth and Asset Management Tool: Next Best Action Lou Pirenc, Global Head of Data at the Research Division of Morgan Stanley, gives a brief primer on how the company has been researching AI for use in trading and wealth management in the video below:  Many financial institutions have been using artificial intelligence to augment their wealth and asset managers with predictive analytics tools that help them better determine how to best invest their clients’ money. These applications, in some cases called “robo advisers,” suggest investments that are supposed to be financially lucrative and in-line with client preferences based on trends in the market. They often combine natural language processing and predictive analytics approaches. In doing so, these applications can analyze financial news sites and past emails between the wealth/asset manager and client in order to suggest possible action steps the wealth/asset manager should take on behalf of that client. For example, if a client has stock in a company that is set to do well in an upcoming quarter because it just poached top talent from another well-known firm, an algorithm might suggest to a wealth manager that they inform their client about an investment opportunity. Morgan Stanley’s wealth/asset management application, launched in 2018, is called Next Best Action. Jeff McMillan, Chief Analytics and Data Officer at Morgan Stanley, said the application allows wealth managers to have deeper conversations with their clients, seemingly because they are able to access more data about their preferences an market trends faster. McMillan also emphasized how AI increased the scale at which wealth managers could reach their clients. Instead of emailing their clients one-by-one when there’s a sharp dip in the market, they could email hundreds of their clients at once. Next Best Action appears to be part of Morgan Stanley’s larger wealth management platform, WealthDesk, which is built on BlackRock’s Aladdin. The company purportedly rolled out WealthDesk as a means to unify wealth managers’ workflows into one digital environment, allowing them to access all of the tools they need on one platform instead of logging into several. WealthDesk seems to allow Morgan Stanley’s wealth managers to access information on client accounts held at other financial institutions as well. This could give them a more holistic view of their clients’ assets, allowing them to make better investment decisions for them. By the end of 2018, Morgan Stanley claimed that 10 to 15% of their more than 15,000 financial advisers had adopted WealthDesk. Data Center of Excellence In 2018, Morgan Stanley set up its Data Center of Excellence in order to help the financial institution develop its data infrastructure with the express goal of being able to leverage AI in in the future. The Center is purportedly made up of 30 data science and IT experts who advise other departments within Morgan Stanley on how to collect and store the data they work with. These experts currently operate within New York, London, and Montreal. The Center has in part focused on helping these departments process the unstructured data they are collecting, which includes text data stored internally, likely client emails, call logs, market research, and other digital assets. AI applications for wealth management likely also need to process unstructured data from the internet, including articles and research on financial news websites. In addition, the Center works with the financial institutions machine learning engineers to make sure they are using the right data to build algorithms for use-cases in fraud detection, wealth management, and more. Such an initiative could  greatly help Morgan Stanley with the challenges of AI adoption in the enterprise, and it could prevent departments within the company from wasting money on AI applications they don’t have the data to build nor the talent to maintain. Large financial institutions often have trouble avoiding AI adoption pitfalls such as the lure of AI novelty and the difficulty of predicting the ROI of AI. Morgan Stanley’s Data Center of Excellence could help departments with data audits in which cross-functional teams made up of data scientists, subject-matter experts, and IT personnel within the department discuss the data that is available to them with the goal of figuring out how it could be leveraged to solve business problems. For example, a financial institution’s wealth management department will need to do a data audit to find out where it is storing all of the research that its financial advisers are using to inform the decisions they make for their clients. In some cases, the department may not be storing a lot of this data, which would threaten any work on an AI algorithm that could augment their wealth managers. The department would have to start collecting this data, which would delay any AI project from coming to fruition for several months. Financial institutions are not used to these kinds of problems when it comes to IT. They are used to procuring and building software that is much more “plug and play” than AI. Morgan Stanley’s Data Center of Excellence likely sets realistic expectations for what the company can do with AI in its various departments and provides guidance on how each department in each of the cities the Center works in can set themselves up for success with AI. Emerj for Financial Services Companies Financial institutions need research on their competitors’ AI initiatives if they want to keep, but this information is often difficult to find and extremely misleading. Emerj helps large financial institutions find out which AI applications are delivering high ROI for their competitors and determine where AI can increase revenue, drive efficiencies, and increase customer satisfaction in use-cases like wealth management, asset management, customer service, and fraud detection. Learn more about Emerj Research Services.   Header Image Credit: Wealth Advisor Related Posts Artificial Intelligence at Goldman Sachs - Current InitiativesThe top 100 global banks, including Goldman Sachs, are beginning to take AI strategies very… Artificial Intelligence at Barclays - Current InitiativesBarclays is a UK bank ranked 20th on S&P Global’s list of the top 100 banks.… Artificial Intelligence in Cybersecurity - Current Use-Cases and CapabilitiesAI has made some inroads in the cybersecurity sector and several AI vendors claim to… Artificial Intelligence at the CIA - Current ApplicationsIt is clear the United States government has recently taken a strong stance in attempts… Artificial Intelligence in Corporate Banking - Current ApplicationsAI software for corporate banks is not too different from those for retail banks, although… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",Article,,,,,,,https://emerj.com/wp-content/uploads/2020/04/morgan-stanley-1-690x328.jpg,https://emerj.com/ai-sector-overviews/ai-morgan-stanley,,Niccolo Mejia,2020-04-07,2020-04-07,Artificial Intelligence at Morgan Stanley &#8211; Current Initiatives,,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",,,,,,,,,,,,AI Sector Overviews,1139,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vd3d3LnRlY2h0YXJnZXQuY29tL3NlYXJjaGNvbnRlbnRtYW5hZ2VtZW50L3RpcC80LXJvbGVzLW9mLUFJLWluLWNvbnRlbnQtbWFuYWdlbWVudC1zeXN0ZW1z0gEA?oc=5,4 roles of AI in content management systems - TechTarget,2020-04-06,TechTarget,https://www.techtarget.com,"Enterprise content management systems employ AI in a number of ways, including chatbots, robotic process automation, enterprise search and content security.",N/A,"Content management systems use AI to assist in a number of tasks, including enterprise search and robotic process automation. Learn more about AI's functions in ECM systems here.","Content management systems use AI to assist in a number of tasks, including enterprise search and robotic process automation. Learn more about AI's functions in ECM systems here.",https://schema.org,,N/A,N/A,"


Laurent - stock.adobe.com
Laurent - stock.adobe.com






Tip




Article 
1 of 3




Part of:
The role of AI in content management



4 roles of AI in content management systems


Enterprise content management systems employ AI in a number of ways, including chatbots, robotic process automation, enterprise search and content security.





Share this item with your network:

















































By


Reda Chouffani,
Biz Technology Solutions



Published: 06 Apr 2020


 
Enterprise content management platforms enable businesses to organize and maintain their content, and many organizations are noticing an uptick in AI features within these systems.







By applying the different components of AI -- including machine learning, natural language processing and data mining -- ECM systems become smarter and provide end users with new capabilities that can make them more efficient.
Here are four roles of AI in content management systems:

1. Enterprise search
One of the most-used features in ECM platforms is the search function. This is a common starting point for anyone looking for specific content, whether it be a presentation file, policy, training guide or item within a catalog. But as the amount of data within ECM systems grows over the years, so, too, do the search results, forcing users to spend time sifting through the returns and making them less productive.
But with the help of AI in enterprise search, users can identify the information they seek using machine learning and data mining capabilities.
Microsoft announced AI capabilities in enterprise search with Project Cortex at Ignite 2019. This technology is able to analyze different types of content from various sources -- such as SharePoint Online, Exchange Online and OneDrive -- and organize it into shared topics such as projects, products, processes and customers to create a knowledge network for users to access as part of their search results.


2. Chatbot capabilities
Some ECM vendors -- such as Microsoft SharePoint -- have even added chatbot capabilities to their offerings. In Microsoft's case, Bot Framework V4 provides connectors to deliver fully-functioning chatbots to interact with SharePoint content.
By generating a chatbot using Bot Framework, designers can build the functionality to interact with the bot through web chat windows, Microsoft Team conversations, Skype conversations and voice by using Cortana.
Several real-life examples of queries that these chatbots can answer in an ECM system include:

""Bot, locate the latest sales presentation for ABC client,"" as a sales representative searches for a proposal or presentation;
""Bot, search for a legal document related to HIPAA cases,"" as an attorney searches for documents related to a specific case; and
""Bot, I am looking for training material on how to use our equipment AP-1023,"" as a field technician searches for machinery user guides.



3. Robotic process automation
The next capability that AI brings to the table in content management systems is robotic process automation (RPA), which is the ability for AI to handle high-volume, repetitive tasks. Today, many ECM platforms still rely on the use of traditional workflow engines to provide automation capabilities for approval processes, document routing based on categories, revision review and other commonly used workflows.
But the use of AI provides opportunities for more complex automations such as document routing based on content, classification of documents based on content, e-discovery searches, image classification and object recognition.
RPA can be of great use to businesses. For example, imagine an accounting department uses RPA to assist with invoicing. Using RPA, AI can analyze incoming documents that the accounting department scans -- such as invoices -- then perform text and pattern recognition to extract some of data elements. AI then routes the document to the appropriate individuals or teams who need to work on it. This takes humans out of the equation, freeing them up for other tasks.


4. Content security
AI is also helpful in securing content. For many companies, saving credit card or bank account numbers and other sensitive information within an ECM system is generally prohibited. But with increasing pressures on businesses to ensure they meet all the different compliance requirements that include HIPAA, GDPR, CCPA and others, relying on audits to find content that might violate company rules and polices can result in risks of noncompliance.
AI can detect in real time if content in an ECM platform is noncompliant by detecting abnormal behavior -- such as unusually large document downloads or a suspicious login from unfamiliar locations -- which helps organizations meet compliance requirements and reduce risks significantly.


Next Steps
SharePoint Syntex automatically uncovers document metadata
The top 5 content management trends in 2022





Dig Deeper on Content management software and services



Document management vs. content management: How they differ




By: Erica Mixon




5 steps to a successful ECM implementation project




By: Jordan Jones




content management system (CMS)




By: Scott Robinson




7 records management systems to consider




By: Christine Campbell








Part of: The role of AI in content management

Article 1 of 3






Up Next



4 roles of AI in content management systems
Enterprise content management systems employ AI in a number of ways, including chatbots, robotic process automation, enterprise search and content security.



How automated content tagging improves findability
Companies that use AI to automatically tag their metadata can improve findability of content across the entire organization. AI tagging vendors can help businesses get started.



The role of artificial intelligence in the future of content
AI will play a key role in the future of content, as it can simplify tasks, create new business apps and improve file storage. But these changes won't happen overnight.








Sponsored News


Three Innovative AI Use Cases for Natural Language Processing
–Dell Technologies


Power Your Generative AI Initiatives With High-Performance, Reliable, ...
–Dell Technologies and Intel


A Generative AI Use Case Brought to Life with Solutions from Dell Technologies
–Dell Technologies and Intel

See More





Related Content


ECM features of the future get an AI boost
– Content Management


6 enterprise content management best practices for ...
– Content Management


5 benefits of enterprise content management (ECM)
– Content Management








",Article,,4 roles of AI in content management systems,,,,,https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero Images/technology-digital-ai-robot-adobe.jpeg,"{'@type': 'WebPage', '@id': 'https://www.techtarget.com/searchcontentmanagement/tip/4-roles-of-AI-in-content-management-systems'}",,"[{'name': 'Reda Chouffani', '@type': 'Person'}]",,2020-04-06T13:47Z,4 roles of AI in content management systems,,"{'name': 'TechTarget', 'logo': {'url': 'https://cdn.ttgtmedia.com/rms/amp/amp_teal_logo_115_60.png', 'height': 60, 'width': 115, '@type': 'ImageObject'}, '@type': 'Organization'}","{'cssSelector': '.paywall', '@type': 'WebPageElement', 'isAccessibleForFree': False}",,,,False,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vZmluYW5jaWFsaXQubmV0L25ld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uvc3VyZ2UtcmVtb3RlLXdvcmtpbmctbGVhZHMtaW1hbmFnZS1sYXVuY2gtdmlydHVhbC1haS11bml2ZXJzaXR50gEA?oc=5,Surge in Remote Working Leads iManage to Launch Virtual AI University for Companies that Want to Harness the ... - Financial IT,2020-04-09,Financial IT,https://financialit.net,"iManage, the company dedicated to transforming how professionals work, today announced that it has rolled out a virtual Artificial Intelligence University (AIU), as an adjunct to its customer on-site model. With the virtual offering, legal and financial services professionals can actively participate in project-driven, best-practice remote AI workshops that use their own,",N/A,"iManage, the company dedicated to transforming how professionals work, today announced that it has rolled out a virtual Artificial Intelligence University (AIU), as an adjunct to its customer on-site model. With the virtual offering, legal and financial services professionals can actively participate in project-driven, best-practice remote AI workshops that use their own, real-world data to address specific business issues – even amidst the disruption caused by the COVID-19 outbreak.",N/A,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vd3d3LnNvY2lhbGV1cm9wZS5ldS9kZXNpZ25pbmctYWktdG9vbHMtdG8tYmVuZWZpdC13b3JrZXJz0gEA?oc=5,Designing AI tools to benefit workers - Social Europe,2020-04-08,Social Europe,https://www.socialeurope.eu,"Continuing our series on artificial intelligence, AI can augment human work—if workers’ representatives have a voice in implementing it.",N/A,Artificial intelligence can augment human work—if workers’ representatives have a voice in implementing it.,Artificial intelligence can augment human work—if workers’ representatives have a voice in implementing it.,https://schema.org,"[{'@type': 'Organization', '@id': 'https://www.socialeurope.eu/#organization', 'name': 'Social Europe (SE)', 'sameAs': ['https://www.facebook.com/socialeurope.eu', 'https://twitter.com/socialeurope'], 'logo': {'@type': 'ImageObject', '@id': 'https://www.socialeurope.eu/#logo', 'url': 'https://www.socialeurope.eu/wp-content/uploads/2022/06/SE-8.png', 'contentUrl': 'https://www.socialeurope.eu/wp-content/uploads/2022/06/SE-8.png', 'caption': 'Social Europe', 'inLanguage': 'en-GB', 'width': '750', 'height': '422'}}, {'@type': 'WebSite', '@id': 'https://www.socialeurope.eu/#website', 'url': 'https://www.socialeurope.eu', 'name': 'Social Europe', 'publisher': {'@id': 'https://www.socialeurope.eu/#organization'}, 'inLanguage': 'en-GB'}, {'@type': 'ImageObject', '@id': 'https://www.socialeurope.eu/wp-content/uploads/2020/03/Florian-Butollo.png', 'url': 'https://www.socialeurope.eu/wp-content/uploads/2020/03/Florian-Butollo.png', 'width': '500', 'height': '500', 'caption': 'artificial intelligence and work', 'inLanguage': 'en-GB'}, {'@type': 'WebPage', '@id': 'https://www.socialeurope.eu/designing-ai-tools-to-benefit-workers#webpage', 'url': 'https://www.socialeurope.eu/designing-ai-tools-to-benefit-workers', 'name': 'Designing AI tools to benefit workers', 'datePublished': '2020-04-08T05:00:00+02:00', 'dateModified': '2020-04-23T13:34:48+02:00', 'isPartOf': {'@id': 'https://www.socialeurope.eu/#website'}, 'primaryImageOfPage': {'@id': 'https://www.socialeurope.eu/wp-content/uploads/2020/03/Florian-Butollo.png'}, 'inLanguage': 'en-GB'}, {'@type': 'Person', '@id': 'https://www.socialeurope.eu/author/florian-butollo', 'name': 'Florian Butollo', 'url': 'https://www.socialeurope.eu/author/florian-butollo', 'image': {'@type': 'ImageObject', '@id': 'https://secure.gravatar.com/avatar/cc35b72778c5afa00b9ad2f3886e1ab6?s=96&amp;d=mm&amp;r=g', 'url': 'https://secure.gravatar.com/avatar/cc35b72778c5afa00b9ad2f3886e1ab6?s=96&amp;d=mm&amp;r=g', 'caption': 'Florian Butollo', 'inLanguage': 'en-GB'}, 'sameAs': ['https://twitter.com/flobut'], 'worksFor': {'@id': 'https://www.socialeurope.eu/#organization'}}, {'@type': 'NewsArticle', 'headline': 'Designing AI tools to benefit workers', 'keywords': 'workers, AI and work, benefit workers', 'datePublished': '2020-04-08T05:00:00+02:00', 'dateModified': '2020-04-23T13:34:48+02:00', 'articleSection': 'Politics', 'author': {'@id': 'https://www.socialeurope.eu/author/florian-butollo', 'name': 'Florian Butollo'}, 'publisher': {'@id': 'https://www.socialeurope.eu/#organization'}, 'description': 'Continuing our series on artificial intelligence, AI can augment human work—if workers’ representatives have a voice in implementing it.', 'copyrightYear': '2020', 'copyrightHolder': {'@id': 'https://www.socialeurope.eu/#organization'}, 'name': 'Designing AI tools to benefit workers', '@id': 'https://www.socialeurope.eu/designing-ai-tools-to-benefit-workers#richSnippet', 'isPartOf': {'@id': 'https://www.socialeurope.eu/designing-ai-tools-to-benefit-workers#webpage'}, 'image': {'@id': 'https://www.socialeurope.eu/wp-content/uploads/2020/03/Florian-Butollo.png'}, 'inLanguage': 'en-GB', 'mainEntityOfPage': {'@id': 'https://www.socialeurope.eu/designing-ai-tools-to-benefit-workers#webpage'}}]",Politics,N/A,"
This series is a partnership with the Weizenbaum Institute for the Networked Society and the Friedrich Ebert Stiftung
Artificial intelligence can augment human work—if workers’ representatives have a voice in implementing it.
Florian Butollo
The discourse on artificial intelligence and work is shaped by conflicting narratives. Disempowering notions about mass unemployment and a loss of human control in the face of ever-more-powerful machines are widespread. But AI also inspires visions of human empowerment, according to which labour will be upgraded as machines support human effort and relieve us from the burden of onerous work, leaving us with more interesting, creative and cognitive tasks. 
Both narratives are one-sided, deriving projections as to the future of
work from the nature of technology as such. To overcome this simplistic
dichotomy, the social context in which AI is introduced needs to be addressed. It
is not just an interaction between man
(or woman) and machine—AI is
implemented within a far-flung division of labour, which entails multiple forms
of co-operation, task specialisation and inequality. To answer the question of
who benefits and who loses through its introduction, it is thus necessary to
ask how relations of power between human agents are reconfigured.










Join 24,000+ informed readers and stay ahead with our insightful content. 
It's free.












Subscribe
  Loading... 










Subscribe
  Loading... 






Thank you!
Please check your inbox and click on the link in the confirmation email to complete your newsletter subscription.









Significant limitations
Hubris surrounds the term AI and is responsible for many of the misconceptions.
The present technological path of machine learning has generated astonishing
breakthroughs, yet significant limitations are encountered when the calculated
results are contextualised and applied. 
And while it is now possible to detect patterns in massive data sets which
surpass the capabilities of human reason—essentially amounting to a different
form of intelligence than that of humans—the ‘predictions’ derived from these
are structurally conservative. They merely project such patterns into the
future, based on correlations established rather than a deeper understanding of
underlying factors. 
What is more, AI systems continue to be trained towards very specific
tasks and cannot transfer capacities to different data sets or changed
surroundings. In other words, AI delivers highly-sophisticated statistical
evidence for processes of high regularity in controlled surroundings. 

Become a Social Europe Member

Support independent publishing and progressive ideas by becoming a Social Europe member for less than 5 Euro per month. Your support makes all the difference!

Click here to become a member
There is a multiplicity of applications where these forms of pattern
recognition matter, especially in the image or speech recognition and
match-making which constitute the main fields of AI today. But this is
intelligence in the statistical sense, not anything equivalent to human
intelligence. 
It fails to work once there are more complex, multi-factor environments
involved—think Brexit or the notorious butterfly which might trigger a
hurricane in a different region of the world! Human reasoning must step in to
contextualise AI results, to understand its implications in real-life
scenarios. 
Augmented
intelligence
In terms of possible impacts on work, this means AI can be used to
subordinate workers to the mechanical calculations of the machine or to empower
them to contextualise and use AI as augmented
human intelligence. Both approaches exist. 
The first path isolates the work process from its real-life context. The
design of a logistics warehouse or simple manufacturing operation can easily be
translated into a data model with input, processing and output variables. AI algorithms
can recurrently recalculate the set of factors involved and transmit these to
human agents, obliged to follow suit. 
Such forms of automated decision-making leave little room for the
opinions of workers. Devices displaying the next operation approximate to
‘objective’ efficiency and functionality, to the extent that it becomes futile
to argue. The bugs and readjustments that (as always) occur remain the
preoccupation of data scientists and management. Workers are supported in their
actions but they become highly replaceable, their bargaining power undermined.
The second path ascribes the tasks of contextualising AI to workers. AI
might provide transparency about the current state of processes and hints as to
possible measures to smooth the operation of a firm, be it a factory or an
office. Yet humans face the challenge to interpret such results, based on their
capacity to assess the surrounding factors and their experience. This way,
decisions can be augmented via a translation and adaption to real-life
conditions, building on work experience, intuition and general reasoning. These
capacities can be developed through enhancing workers’ capacities to
understand, interpret and act upon automated decision-making. 
New forms of interaction
It is easy from this to deduce scenarios of a downgrading or an
upgrading of work. The point, however, is to identify the variables that affect
whether one tendency or the other predominates. This is not rooted in the
structural surroundings of certain work contexts or in technology itself but in
the active design of new forms of man-machine interaction. 
Three dimensions are particularly relevant. The first concerns the
fundamental question of investment in technologies, the second the design of
interfaces between AI and its users and the third the challenge of equipping
workers to upgrade their skills. 
Regarding investments, AI can be used for a broad variety of tasks which can be detrimental or supportive when it comes to workers’ empowerment. The question of how technological choices affect power relations in the workplace is a complicated one which needs to move centre-stage in discussions among workers’ representatives. It is linked to management choices favouring the design of enterprises as learning organisms (thus requiring the input of workers) as against neo-Taylorist options that reduce workers to narrowly-circumscribed functions.
Next, the design of technology becomes an important matter for workplace
politics. Do the interfaces of AI systems indicate a set of options and the
contingency of automatically-generated results? Or do they narrowly prescribe
actions that will be mistakenly taken as givens by human agents? Does AI
challenge us to interpret its results or relegate us to an observing position?
These are delicate questions as to what roles are ascribed to workers in AI
models.
Finally, how do companies support workers in developing new skills in a
setting of augmented intelligence and how is this incentivised? Calls for more
extended training and lifelong learning are widespread—workers need to acquire
a deeper understanding of automated processes to make the right decisions,
involving the skills to negotiate the translation of insights from the data
level to physical processes and real-life communication. 
But if workers need to learn more and constantly, how is this to be encouraged?
If lifelong learning becomes a requirement that is not compensated through higher
wages and relief from other responsibilities, it could soon become not a
blessing but a burden. Workers would need to run to stand still in the
hierarchies of the workplace. 
Tough challenges
All these dimensions constitute tough challenges for workers, works
councils and trade unions. They are relevant fields for designing the
workplaces of the future, as the technological choices and their embeddedness
are surrounded by conflicting interests, in which workers need to strengthen
their voice. This necessitates an upgrading of the side of labour towards
stronger capabilities in evaluating technologies and putting them to use according
to their interests. 
And this challenge becomes enduring: AI systems are not merely another machine which once introduced keeps on working in the same way, but learning organisms which modify their functions going forward. AI thus requires an augmentation of bargaining intelligence, so as to be capable of affecting the balance of forces on the shopfloor to workers’ advantage.




 Florian ButolloDr. Florian Butollo is a researcher at Berlin Social Science Center and head
of the research group 'working in highly-automated digital-hybrid
processes' at the Weizenbaum Institute for the Networked Society in
Berlin. He is an adviser to the study group on AI in the Bundestag.You are here: Home / Politics / Designing AI tools to benefit workers







 Most Popular Posts
 The assault on labour rights in FinlandAntti Alaja and Joel Kaitila George Orwell and Europe’s new normalJan Zielonka Ukraine: Putin’s ‘reality’ … and the real worldFrank Hoffer Will the young save Europe from the rise of the far right?Albena Azmanova Housing crisis: Europe cannot afford itGerald Koessl


 Most Recent Posts
 Trump and the darkness threatening US politicsRichard Hargy The young generation needs quality traineeshipsMarc Steiert Rebuilding trust in democracy in MoldovaStanislav Pavlovschi Rising tides, sinking boats: growth, climate and justiceBasak Kus Ostrich politics and its alternativesEszter Kováts


 Other Social Europe Publications
 Global cities Strategic autonomy RE No. 13: Failed Market Approaches to Long-Term Care Towards a social-democratic century? National recovery and resilience plans


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS90b3AtMjAtbW92aWVzLWFib3V0LW1hY2hpbmUtbGVhcm5pbmctYWktYW5kLWRhdGEtc2NpZW5jZS04MzgyZDQwOGM4YzPSAQA?oc=5,Top 20 Must-Watch Artificial Intelligence movies | by Benedict Neo - Towards Data Science,2020-04-08,Towards Data Science,https://towardsdatascience.com,"Best Movies about AI, Data Science, Machine Learning and Mathematics.",N/A,Here are some must-watch AI movies to learn about the capabilities of AI.,Here are some must-watch AI movies to learn about the capabilities of AI.,http://schema.org,,N/A,N/A,"Member-only storyArtificial IntelligenceTop 20 Must-Watch Artificial Intelligence moviesHere are some must-watch AI movies to learn about the capabilities of AI.Benedict Neo·FollowPublished inTowards Data Science·14 min read·Apr 8, 20202956ListenSharePhoto by Erik Witsoe on UnsplashMovies are more than just blockbusters hit with explosions and superpowers, it’s the main idea behind the movie that changes people and injects a notion in the viewer’s head.To illustrate, the movie Joker wasn’t a hero vs villain film, fighting with superpowers and wreaking havoc on New York City. It portrayed how there is a distinct chasm between the rich and the poor, the lucky and the unlucky, and how mental illness can distort a person’s morality and value system.So, movies are more than just an activity for enjoyment and amusement, it plays an imperative role in shaping our view on the world and communal consciousness.In short, movies educate people and spread ideas in ways a paperback book early does today.Why movies?One reason for the effectiveness of movies is also the stark difference between movies and books, which is visualization. A visual content displays content that quickly registers to our visual stimulus as compared to a book, which explains why people spend hours on YouTube instead of reading a book. Moreover, movies…",NewsArticle,https://towardsdatascience.com/top-20-movies-about-machine-learning-ai-and-data-science-8382d408c8c3,Top 20 Must-Watch Artificial Intelligence movies - Towards Data Science,,,,,['https://miro.medium.com/v2/da:true/resize:fit:1200/0*s5yn__8OY5G81IOn'],https://towardsdatascience.com/top-20-movies-about-machine-learning-ai-and-data-science-8382d408c8c3,,"{'@type': 'Person', 'name': 'Benedict Neo', 'url': 'https://benedictxneo.medium.com'}",2021-12-14T02:47:15.452Z,2020-04-09T03:52:48.305Z,Top 20 Must-Watch Artificial Intelligence movies - Towards Data Science,,"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}","{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",,,,False,,,,,,,,,2020-04-09T03:52:48.305Z,8382d408c8c3,['Benedict Neo'],,,,,,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vd3d3LnJlbGlhYmxlcGxhbnQuY29tL1JlYWQvMzE4NjQvYWktZXRoaWNhbC1tYW51ZmFjdHVyaW5n0gEA?oc=5,Three Ethical Considerations for Manufacturers Investing in Artificial Intelligence - Reliable Plant Magazine,2020-04-08,Reliable Plant Magazine,https://www.reliableplant.com,Manufacturers must construct ethical systems as AI becomes pervasive in the industry. These are the three major ethical problems facing manufacturers as they ramp up their AI investments and embark upon this new technological direction.,N/A,Manufacturers must construct ethical systems as AI becomes pervasive in the industry. These are the three major ethical problems facing manufacturers as they ramp up their AI investments and embark upon this new technological direction.,N/A,https://schema.org,,N/A,N/A,N/A,Article,,,,,,,['https://media.noria.com/sites/Uploads/2020/4/8/3b166927-03cc-41d3-816c-2309e891784d_ai-1200_extra_large.jpeg'],"{'@type': 'WebPage', '@id': 'https://www.reliableplant.com/Read/31864/ai-ethical-manufacturing'}",,"{'@type': 'Person', 'name': 'Antony Bourne'}",,4/8/2020 6:06:23 PM,Three Ethical Considerations for Manufacturers Investing in Artificial Intelligence,,"{'@type': 'Organization', 'name': 'Noria Corporation', 'logo': {'@type': 'ImageObject', 'url': 'https://media.noria.com/sites/Email_Media/General/Noria-Logo.jpg'}}",,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMjAvbGVhcm5pbmctYWJvdXQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaHViLW9mLW1pdC1yZXNvdXJjZXMtay0xMi1zdHVkZW50cy0wNDA30gEA?oc=5,Learning about artificial intelligence: A hub of MIT resources for K-12 students - MIT News,2020-04-07,MIT News,https://news.mit.edu,"AI Education, a new website from MIT, provides K-12 students with activities focusing on artificial intelligence. Designed by a team led by Media Lab Associate Professor Cynthia Breazeal, the materials focus on how to design and use AI responsibly.","Massachusetts Institute of Technology, MIT, MIT Media Lab, Cynthia Breazeal, aieducation.mit.edu, artificial intelligence, K-12 education, COVID-19, home schooling, Teachable Machines, Scratch, App Inventor, Hal Abelson, Online learning, teaching and academics","AI Education, a new website from MIT, provides K-12 students with activities focusing on artificial intelligence. Designed by a team led by Media Lab Associate Professor Cynthia Breazeal, the materials focus on how to design and use AI responsibly.",N/A,,,N/A,N/A,"


New website offers a combination of learning units, hands-on activities, and mentor guides to foster AI literacy.




MIT Media Lab


 Publication Date:
 April 7, 2020





Press Inquiries

  Press Contact:



      
            Alexandra        

            Kahn        

  

      Email:
     akahn@media.mit.edu


      Phone:
              617-253-0365      
  

      
            MIT Media Lab        

  








 Close














 Caption:
          A mural of hopes and questions about artificial intelligence from a middle school workshop      
          

 Credits:
          Image courtesy of the Personal Robots group/MIT Media Lab      
          

















Previous image
Next image






















In light of the recent events surrounding Covid-19, learning for grades K-12 looks very different than it did a month ago. Parents and educators may be feeling overwhelmed about turning their homes into classrooms. 
With that in mind, a team led by Media Lab Associate Professor Cynthia Breazeal has launched aieducation.mit.edu to share a variety of online activities for K-12 students to learn about artificial intelligence, with a focus on how to design and use it responsibly. Learning resources provided on this website can help to address the needs of the millions of children, parents, and educators worldwide who are staying at home due to school closures caused by Covid-19, and are looking for free educational activities that support project-based STEM learning in an exciting and innovative area. 
The website is a collaboration between the Media Lab, MIT Stephen A. Schwarzman College of Computing, and MIT Open Learning, serving as a hub to highlight diverse work by faculty, staff, and students across the MIT community at the intersection of AI, learning, and education. 
“MIT is the birthplace of Constructionism under Seymour Papert. MIT has revolutionized how children learn computational thinking with hugely successful platforms such as Scratch and App Inventor. Now, we are bringing this rich tradition and deep expertise to how children learn about AI through project-based learning that dovetails technical concepts with ethical design and responsible use,” says Breazeal. 
The website will serve as a hub for MIT’s latest work in innovating learning and education in the era of AI. In addition to highlighting research, it also features up-to-date project-based activities, learning units, child-friendly software tools, digital interactives, and other supporting materials, highlighting a variety of MIT-developed educational research and collaborative outreach efforts across and beyond MIT. The site is intended for use by students, parents, teachers, and lifelong learners alike, with resources for children and adults at all learning levels, and with varying levels of comfort with technology, for a range of artificial intelligence topics. The team has also gathered a variety of external resources to explore, such as Teachable Machines by Google, a browser-based platform that lets users train classifiers for their own image-recognition algorithms in a user-friendly way.
In the spirit of “mens et manus” — the MIT motto, meaning “mind and hand” — the vision of technology for learning at MIT is about empowering and inspiring learners of all ages in the pursuit of creative endeavors. The activities highlighted on the new website are designed in the tradition of constructionism: learning through project-based experiences in which learners build and share their work. The approach is also inspired by the idea of computational action, where children can design AI-enabled technologies to help others in their community.
“MIT has been a world leader in AI since the 1960s,” says MIT professor of computer science and engineering Hal Abelson, who has long been involved in MIT’s AI research and educational technology. “MIT’s approach to making machines intelligent has always been strongly linked with our work in K-12 education. That work is aimed at empowering young people through computational ideas that help them understand the world and computational actions that empower them to improve life for themselves and their communities.”
Research in computer science education and AI education highlights the importance of having a mix of plugged and unplugged learning approaches. Unplugged activities include kinesthetic or discussion-based activities developed to introduce children to concepts in AI and its societal impact without using a computer. Unplugged approaches to learning AI are found to be especially helpful for young children. Moreover, these approaches can also be accessible to learning environments (classrooms and homes) that have limited access to technology. 
As computers continue to automate more and more routine tasks, inequity of education remains a key barrier to future opportunities, where success depends increasingly on intellect, creativity, social skills, and having specific skills and knowledge. This accelerating change raises the critical question of how to best prepare students, from children to lifelong learners, to be successful and to flourish in the era of AI.
It is important to help prepare a diverse and inclusive citizenry to be responsible designers and conscientious users of AI. In that spirit, the activities on aieducation.mit.edu range from hands-on programming to paper prototyping, to Socratic seminars, and even creative writing about speculative fiction. The learning units and project-based activities are designed to be accessible to a wide audience with different backgrounds and comfort levels with technology. A number of these activities leverage learning about AI as a way to connect to the arts, humanities, and social sciences, too, offering a holistic view of how AI intersects with different interests and endeavors. 
The rising ubiquity of AI affects us all, but today a disproportionately small slice of the population has the skills or power to decide how AI is designed or implemented; worrying consequences have been seen in algorithmic bias and perpetuation of unjust systems. Democratizing AI through education, starting in K-12, will help to make it more accessible and diverse at all levels, ultimately helping to create a more inclusive, fair, and equitable future.








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print









Press Mentions


Fast CompanyMIT researchers have developed a new website aimed at K-12 students aimed at helping them learn more about artificial intelligence, reports Mark Wilson for Fast Company. “The site provides 60 activities, lesson plans, and links to interactive AI experiments that MIT and companies like Google have developed in the past,” writes Wilson.











Full story via Fast Company →















Previous item
Next item



















Related Links

AI Education Personal Robots groupMedia LabMIT Open LearningSchool of Architecture and PlanningMIT Schwarzman College of Computing






Related Topics

Media Lab
Online learning
K-12 education
School of Architecture and Planning
Artificial intelligence
Education, teaching, academics
STEM education
MIT Schwarzman College of Computing



Related Articles











MIT’s entrepreneurial ecosystem steps up to the challenge of Covid-19













Bringing artificial intelligence into the classroom, research lab, and beyond













Developing artificial intelligence tools for all

















Previous item
Next item
















",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LnpkbmV0LmNvbS9hcnRpY2xlL3RoaXMtZ2lhbnQtcmVtb3RlLXdvcmtpbmctZnJvbS1ob21lLWV4cGVyaW1lbnQtaXMtY3JlYXRpbmctbmV3LXByb2JsZW1zLWZvci1ldmVyeW9uZS_SAQA?oc=5,This giant remote working from home experiment is creating new problems for everyone - ZDNet,2020-04-08,ZDNet,https://www.zdnet.com,Daphne Leprince-Ringuet says the giant work from home experiment that is currently happening worldwide has given CIOs and their teams a busy few days. Read more: https://zd.net/2VhOjau,N/A,"The global health crisis is forcing workers to stay at home, and it is the CIO's responsibility to enable a smooth transition.","The global health crisis is forcing workers to stay at home, and it is the CIO's responsibility to enable a smooth transition.",https://schema.org,,N/A,N/A,N/A,VideoObject,,Coronavirus: Remote working brings its fair share of challenges for businesses,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,https://www.zdnet.com/a/img/resize/0dce078bbb03d0aa06c59e8ec16a8c9dd3c02e80/2020/04/08/13fab8e2-ad9e-4a62-a33d-b3abde0d4e4d/20200408-daphne-karen-home.jpg?auto=webp&fit=crop&height=675&width=1200,2020-04-08T17:43:11.000Z,PT0H6M53S,https://mt-rv-v5.zdnet.com/vr/2020/04/08/1721800771617/20200408_Daphne_Karen_Home_1787278_742.mp4,https://www.zdnet.com/video/share/coronavirus-remote-working-brings-its-fair-share-of-challenges-for-businesses/,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vd3d3LmFmci5jb20vdGVjaG5vbG9neS9oaXJpbmctc3VyZ2VzLWhlbHAtaHItdGVjaC1jYXBpdGFsLXJhaXNpbmctb3Zlci10aGUtbGluZS1kZXNwaXRlLXZpcnVzLTIwMjAwNDAzLXA1NGd0a9IBAA?oc=5,Hiring surge helps HR tech capital raising over the line despite virus - The Australian Financial Review,2020-04-06,The Australian Financial Review,https://www.afr.com,PredictiveHire's candidate-filtering engine is getting a strong workout as some organisations ramp up hiring at the same time others shut down.,N/A,PredictiveHire's candidate-filtering engine is getting a strong workout as some organisations ramp up hiring at the same time others shut down.,PredictiveHire's candidate-filtering engine is getting a strong workout as some organisations ramp up hiring at the same time others shut down.,https://schema.org,,technology,N/A,"TechnologyEmploymentPrint articleHiring surge helps HR tech capital raising over the line despite virusMichael BaileyRich List co-editorApr 6, 2020 – 4.37pmSaveLog in or Subscribe to save articleShareCopy linkCopiedEmailLinkedInTwitterFacebookCopy linkCopiedShare via...Gift this articleSubscribers can give anyone free access to articles.Gift this article NewSubscribe to gift this articleGift 5 articles to anyone you choose each month when you subscribe.Subscribe nowAlready a subscriber? Login An Australian tech firm that uses artificial intelligence to quickly filter job applicants has managed to successfully complete a Series B fundraising round, despite financial markets catching coronavirus last month.Melbourne-based PredictiveHire finalised the $3 million raise, led by recruiter Hudson with returning venture investors Rampersand and Capital Zed,  just after bans on mass gatherings were announced and segments of the economy began shutting down.PredictiveHire co-founder and chief executive Barb Hyman. Manda FordHowever PredictiveHire co-founder and chief executive Barb Hyman said investors could see that hibernating clients in the hospitality and non-essential retail sectors were being offset by hiring surges elsewhere.""Some of our FMCG [fast-moving consumer goods] retailers, contact centres and emergency services clients have been getting thousands of applications per vacancy in the past couple of weeks, and they need a tool that can filter them quickly but with humanity,"" Ms Hyman said.PredictiveHire claims to have nine of the ASX 100 among its clients, including Wesfarmers-owned Bunnings, who use its software-as-a-service to text questionnaires to the mobile phones of job applicants.AdvertisementEncouraging 50 to 100 word answers to a handful of questions like 'what is a change in your life that has happened to you and how did you deal with that change?', PredictiveHire runs each submission through an engine that performs a branch of artificial intelligence called natural language processing.Built on 25 million words texted back by 350,000 applicants for previous jobs, PredictiveHire claims its engine – run by co-founder Buddhi Jayatilleke, who built the data science team of human resources tech unicorn CultureAmp – can automatically provide hirers with the applicants that best suit their pre-set criteria.RelatedHow to beat South Korea's hiring bots""There's a lot of ways people can game CVs, but it's the words and responses to relevant questions that give real insight into a candidate's suitability,"" Ms Hyman said.She admitted there was little the start-up could do about applicants who get someone else to answer the questions for them, but relied on that being picked up by the phone calls or face-to-face group interviews that followed on from PredictiveHire providing its shortlist.""It's designed so that your best chance of success is being yourself,"" Ms Hyman claimed.Advertisement""If English is your second language, there's no need to worry because we're not biased against that, or race or gender or address or any of those factors that work against diversity when hirers take the CV-reading approach,"" she said.For the thousands of applicants that will inevitably be unsuccessful as the COVID-19 crisis raises unemployment, PredictiveHire provides automated feedback including six insights into their personality, and a coaching tip for future interviews.""Even in a usual year, the big hirers reject in six figures, and these people are also their customers,"" Ms Hyman said.""They want to give them a good experience and constructive feedback, but there's no way that's going to be done consistently for every candidate using manual processes.""PredictiveHire will use the $3 million injection, which takes its total raised to $5 million since launching two years ago, to further its push into graduate recruiting.RelatedSlack boss looks to seize opportunity of a dispersed workforceThis more sophisticated process, only possible as its proprietary data bank of words had grown, was still in demand even as the pandemic stalled markets, according to Ms Hyman.""Good employers can see to the end of this and still want the best talent as it becomes available,"" she said.Gain insights into the week’s biggest tech stories, deals and trends. Sign up to The Download newsletter.Michael Bailey writes on entrepreneurship and the arts. He is also responsible for the Financial Review's Rich Lists. He is based in Sydney. Connect with Michael on Twitter. Email Michael at m.bailey@afr.comSaveLog in or Subscribe to save articleShareCopy linkCopiedEmailLinkedInTwitterFacebookCopy linkCopiedShare via...Gift this articleSubscribers can give anyone free access to articles.Gift this article NewSubscribe to gift this articleGift 5 articles to anyone you choose each month when you subscribe.Subscribe nowAlready a subscriber? LoginLicense articleIntroducing your NewsfeedFollow the topics, people and companies that matter to you.Find out moreRead MoreEmploymentCoronavirus pandemicVenture capitalReportsSustainability LeadersThe list celebrates Australasian companies that are making real progress in tackling sustainability challenges – and delivering business value along the way.Sponsored  by BCGView all 13 stories SponsoredAdvertisementLatest In TechnologyFetching latest articlesMost Viewed In TechnologyConstruction start-up lands mega $105m dealASX cuts back on overpaid tech contractors who were ‘taking the p---’Woolies, Harris Farm, Tesla chair, pile in to back biosecurity start-upSydney VC raises $20m in four days for ‘evergreen’ fifth fund‘Declined to comment’: three words destroying millions in VC brand equityThe Australian Financial Review MagazineAbout Time Watch Weekend to return in SeptemberMatthew DrummondThis Australian chef is the first to win three Michelin starsAcclaimed restaurant duo Ross and Sunny Lusted to open in MelbourneBOSS Financial ReviewSecrets of Olympians who have conquered the business worldEuan Black and Patrick DurkinWhat this CEO eats depends how bad the last meeting was‘I shot Bambi’: Women leaders on their toughest decisionsLife & LeisureThis foldable phone will make other people envy your selfiesJohn DavidsonParis haute couture week is fashion’s answer to the OlympicsA limited-run Wallabies jersey and seven more premium luxuriesRich ListHow exquisite timing and meditating shaped this Rich Lister’s fortuneJulie-anne SpragueThey’re young, rich, and in the French RivieraThe workshop that teaches young rich kids to manage huge fortunes",NewsArticle,,,,,,,"{'@type': 'ImageObject', 'height': '628', 'url': 'https://static.ffx.io/images/$zoom_0.5298%2C$multiply_2%2C$ratio_1.777778%2C$width_1059%2C$x_0%2C$y_8/t_crop_custom/c_scale%2Cw_800%2Cq_88%2Cf_jpg/t_afr_no_label_social_wm/l_text:SuecaNano-Semibold.ttf_28:%20FROM%20%2Cg_south_west%2Cy_84%2Cx_355%2Cco_rgb:111111//l_text:SuecaNano-Semibold.ttf_56:%202020%20%2Cg_south_west%2Cy_25%2Cx_330%2Cco_rgb:111111/715c23c65c978918fd01b88b91e3b4939f05f937', 'width': '1200'}","{'@id': 'https://www.afr.com/technology/hiring-surges-help-hr-tech-capital-raising-over-the-line-despite-virus-20200403-p54gtk', '@type': 'WebPage'}",,"{'@type': 'Person', 'name': 'Michael Bailey'}",2020-04-06T06:37:39Z,2020-04-06T06:37:39Z,Hiring surge helps HR tech capital raising over the line despite virus,,"{'@type': 'NewsMediaOrganization', 'name': 'Australian Financial Review', 'logo': {'@type': 'ImageObject', 'height': '60', 'url': 'https://www.afr.com/afr-logo.png', 'width': '424'}, 'url': 'https://www.afr.com', 'sameAs': ['https://www.facebook.com/financialreview', 'https://twitter.com/FinancialReview']}",,,,,True,"{'@type': ['CreativeWork', 'Product'], 'name': 'Australian Financial Review', 'productID': 'afr.com:afralldigital'}",,,,,,,,,,,,,,,,"[{'@type': 'ListItem', 'item': {'@id': 'https://www.afr.com/technology', 'name': 'Technology'}, 'position': 1}]",,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjAvMDQvMTAvYnVzaW5lc3MvY29yb25hdmlydXMtd29ya3BsYWNlLWF1dG9tYXRpb24uaHRtbNIBAA?oc=5,"Robots Welcome to Take Over, as Pandemic Accelerates Automation (Published 2020) - The New York Times",2020-04-10,The New York Times,https://www.nytimes.com,Broad unease about losing jobs to machines could dissipate as people focus on the benefits of minimizing close human contact.,N/A,Broad unease about losing jobs to machines could dissipate as people focus on the benefits of minimizing close human contact.,Broad unease about losing jobs to machines could dissipate as people focus on the benefits of minimizing close human contact.,https://schema.org,,Business,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTRobots Welcome to Take Over, as Pandemic Accelerates AutomationBroad unease about losing jobs to machines could dissipate as people focus on the benefits of minimizing close human contact.Share full article86Read in appAn AMP Robotics system sorting recyclable material at the company’s lab in Louisville, Colo.Credit...Benjamin Rasmussen for The New York TimesBy Michael Corkery and David GellesApril 10, 2020The recycling industry was already struggling before the pandemic. Now, an increasing number of cities are suspending recycling services, partly out of fear that workers might contract the coronavirus from one another while sorting through used water bottles, food containers and boxes.One solution: Let robots do the job.Since the coronavirus took hold in the United States last month, AMP Robotics has seen a “significant” increase in orders for its robots that use artificial intelligence to sift through recycled material, weeding out trash.“Some facilities that were looking at getting one or two robots are now saying, ‘We need quite a bit more,’” said the Colorado company’s chief executive, Matanya Horowitz. “It’s all moving quite fast.”Before the pandemic, automation had been gradually replacing human work in a range of jobs, from call centers to warehouses and grocery stores, as companies looked to cut labor costs and improve profit.AdvertisementSKIP ADVERTISEMENTBut labor and robotics experts say social-distancing directives, which are likely to continue in some form after the crisis subsides, could prompt more industries to accelerate their use of automation. And long-simmering worries about job losses or a broad unease about having machines control vital aspects of daily life could dissipate as society sees the benefits of restructuring workplaces in ways that minimize close human contact.ImageCredit...Benjamin Rasmussen for The New York TimesImageAMP’s chief executive, Matanya Horowitz, said the pandemic had increased demand for the automated system.Credit...Benjamin Rasmussen for The New York Times“Pre-pandemic, people might have thought we were automating too much,” said Richard Pak, a professor at Clemson University who researches the psychological factors around automation. “This event is going to push people to think what more should be automated.”The grocery industry is leaning more on automation to free up employees to deal with the crush of demand during the pandemic.Brain Corp, a San Diego company that makes software used in automated floor cleaners, said retailers were using the cleaners 13 percent more than they were just two months ago. The “autonomous floor care robots” are doing about 8,000 hours of daily work “that otherwise would have been done by an essential worker,” the company said.AdvertisementSKIP ADVERTISEMENTAt supermarkets like Giant Eagle, robots are freeing up employees who previously spent time taking inventory to focus on disinfecting and sanitizing surfaces and processing deliveries to keep shelves stocked.Retailers insist the robots are augmenting the work of employees, not replacing them. But as the panic buying ebbs and sales decline in the recession that is expected to follow, companies that reassigned workers during the crisis may no longer have a need for them.The role of a cashier is also changing. For many years, retailers have provided self-checkout kiosks. But those machines often require intervention by workers to help shoppers navigate the often fickle and frustrating technology.ImageA screen showing how AMP’s artificial intelligence identifies items on a conveyor.Credit...Benjamin Rasmussen for The New York TimesThe pandemic is prompting some stores to adopt even more aggressive “contactless” options. From farm stands to butchers, merchants are asking customers whenever possible to use mobile payment services like PayPal or Venmo. Banking regulators in Europe last week increased the amount of money that shoppers can pay through their mobile devices, while reducing some authentication requirements.AdvertisementSKIP ADVERTISEMENTWhile fully automated stores, such as Amazon Go, might have seemed like a technological curiosity a few months ago, they are likely to become a more viable option for retailers.“No one would probably have thought of a cashier’s job as being dangerous until now,” Mr. Pak said.Mark Muro, a senior fellow at the Brookings Institution who studies labor markets, said that with companies hurting for cash, the pressure to replace humans with machines becomes even more intense.“People become more expensive as companies’ revenues decline,” he said.A new wave of automation could also mean that when companies start hiring again, they do so in smaller numbers.“This may be one of those situations when automation does substantially depress rehiring,” Mr. Muro said. “You may see fewer workers when the recovery does come.”ImageA scanner at the entry of an automated Amazon Go grocery store in Seattle.Credit...Christian Sorensen Hansen for The New York TimesEven some conversations are being automated away. With closed offices keeping many of its workers away, PayPal has turned to chatbots, using them for a record 65 percent of message-based customer inquiries in recent weeks.AdvertisementSKIP ADVERTISEMENTPayPal is also using automated translation services so its English-speaking representatives can help customers who don’t speak English.“The resources we are able to deploy through A.I. are allowing us to be more flexible with our staff and prioritize their safety and well-being,” PayPal said in a statement.YouTube said in a blog post that with fewer people in its offices around the world, machines are doing more content moderation.“We will temporarily start relying more on technology to help with some of the work normally done by reviewers,” the company said. “This means automated systems will start removing some content without human review.”AdvertisementSKIP ADVERTISEMENTRecycling is one industry that may be altered permanently by the pandemic. Some workers, who earn as little as $10 an hour, have been concerned about coming to work during the crisis and some cities have been scrambling to find enough protective gear for all of their employees. Federal health officials have assured them that the risks of transmission from household refuse is low. But workers in recycling facilities often work side by side sorting material, making social distancing difficult.ImageA robotic floor cleaner at a Giant Eagle supermarket. The chain said automation freed up employees to take on pandemic-related tasks.Credit...Brain CorpAt AMP Robotics, executives like Mr. Horowitz say their robots will enable recycling facilities to space out their employees, who stand at conveyor belts weeding through the used plastic and paper.Another benefit of the bots: “They can’t get the virus,” Mr. Horowitz said.Michael Corkery is a business reporter who covers the retail industry and its impact on consumers, workers and the economy. He joined The Times in 2014 and was previously a reporter at the Wall Street Journal and the Providence Journal. More about Michael CorkeryDavid Gelles is the Corner Office columnist and a business reporter. Follow him on LinkedIn and Twitter. More about David GellesA version of this article appears in print on April 11, 2020, Section B, Page 1 of the New York edition with the headline: Pandemic Accelerates Automation. Order Reprints | Today’s Paper | SubscribeRead 86 CommentsShare full article86Read in appAdvertisementSKIP ADVERTISEMENTComments 86Robots Welcome to Take Over, as Pandemic Accelerates AutomationSkip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Enjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",NewsMediaOrganization,https://www.nytimes.com/,The New York Times,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",,https://en.wikipedia.org/wiki/The_New_York_Times,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/04/11/business/10virus-automation2-print/10virus-automation-1-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2020/04/11/business/10virus-automation2-print/10virus-automation-1-videoSixteenByNineJumbo1600.jpg', 'caption': 'An AMP Robotics system sorting recyclable material at the company&rsquo;s lab in Louisville, Colo.', 'creditText': 'Benjamin Rasmussen for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/04/11/business/10virus-automation2-print/merlin_171417870_3fe1baa6-573f-4047-93f7-fd66cd0c271e-superJumbo.jpg', 'height': 1536, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2020/04/11/business/10virus-automation2-print/merlin_171417870_3fe1baa6-573f-4047-93f7-fd66cd0c271e-superJumbo.jpg', 'caption': 'An AMP Robotics system sorting recyclable material at the company&rsquo;s lab in Louisville, Colo.', 'creditText': 'Benjamin Rasmussen for The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/04/11/business/10virus-automation2-print/10virus-automation-1-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2020/04/11/business/10virus-automation2-print/10virus-automation-1-mediumSquareAt3X.jpg', 'caption': 'An AMP Robotics system sorting recyclable material at the company&rsquo;s lab in Louisville, Colo.', 'creditText': 'Benjamin Rasmussen for The New York Times'}]",https://www.nytimes.com/2020/04/10/business/coronavirus-workplace-automation.html,en-US,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/michael-corkery', 'name': 'Michael Corkery'}, {'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/david-gelles', 'name': 'David Gelles'}]",2020-04-10T09:00:27.000Z,2020-04-10T09:00:27.000Z,"Robots Welcome to Take Over, as Pandemic Accelerates Automation",Pandemic Accelerates Automation,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,,,,,,,,,,,,{'@id': '#commentsContainer'},86.0,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vcmV2Y3ljbGVpbnRlbGxpZ2VuY2UuY29tL2ZlYXR1cmVzL2hvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pcy1vcHRpbWl6aW5nLXJldmVudWUtY3ljbGUtbWFuYWdlbWVudNIBAA?oc=5,How Artificial Intelligence Is Optimizing Revenue Cycle Management - RevCycleIntelligence.com,2020-04-10,RevCycleIntelligence.com,https://revcycleintelligence.com,"Artificial intelligence is taking on prior authorizations, out-of-pocket cost estimates, and other key revenue cycle management functions. But does AI have a home in RCM or is it just passing phase?",N/A,N/A,"Artificial intelligence is taking on prior authorizations, out-of-pocket cost estimates, and other key revenue cycle management functions. But does AI have a home in RCM or is it just passing phase?",,,N/A,N/A,"

How Artificial Intelligence Is Optimizing Revenue Cycle Management
Artificial intelligence is addressing some of the biggest pain points in revenue cycle management, leading to increased revenue capture and integrity for early adopters of the technology.



Source: Getty Images
			
			
			 Share on Twitter 


April 10, 2020 - Prior authorizations are one of the most burdensome aspects of revenue cycle management.
In a survey of 1,000 practicing physicians conducted by the American Medical Association (AMA), 86 percent of doctors described the burden of prior authorizations as high or extremely high. Nearly an equal amount (88 percent) also said the burden has increased over the last five years.
""It's very, very resource-intensive on both sides, not just on the provider side. It's a series of interactions that are very transactional,"" Sharlene Seidman, a vice president at Yale New Haven Health, recently told RevCycleIntelligence.
Those interactions add up. Physicians and their staff spend almost two full business days each week completing prior authorizations, and more than one in three physicians has staff who work exclusively on the task, the AMA survey found.
The transactional nature of prior authorizations makes it ripe for automation, Seidman stated. But electronic adoption of prior authorizations remains low, according to data from the Council for Affordable Quality Healthcare, Inc. (CAQH).
Adoption of electronic prior authorizations increased by just one percentage point to 13 percent from 2018 to 2019, CAQH reported using data from medical plans covering nearly half of the US’ insured population.
“Numerous barriers have prevented or slowed the adoption of electronic prior authorization,” explained CAQH. Those barriers include lack of operating rules and standards, infrastructure, and vendor readiness.
Yale New Haven Health is overcoming some of those challenges using emerging technology in healthcare: artificial intelligence.
“There is a series of repetitive tasks that our staff has to follow and the automation solution that we're seeking with Olive can learn those steps and replicate them, and in the future even anticipate if there are changes based on historical denials that we've received,” Seidman explained.
“We have seen some early successes with cash coming in a little more quickly, claims getting resolved more quickly. It's working,” she stated.
Prior authorization is one of the best use cases for artificial intelligence in healthcare right now. The transactional nature of prior authorizations makes it an ideal candidate for AI technology, which can leverage real-time analytics and machine learning to identify cases needing prior authorization, submit requests to payers, and check statuses.
But prior authorizations are just one of the burdensome processes in a transaction-heavy part of healthcare: the revenue cycle.
“The level of complexity in managing revenue cycle is very high,” explained Joe Polaris, SVP of product and technology at R1 RCM, a revenue cycle management vendor. “It's a very transaction-oriented business in that every patient who has a need for medical care is going to have a significant number of transactions from the point of scheduling all the way through the multitude of steps to create a clean claim, submit it, and get paid.”
This makes revenue cycle management very difficult to scale, especially for large organizations. According to Polaris, the only real way to achieve scale without the right technology is “to hire really smart people, and make them work even harder, and get even smarter.”
But that isn’t an area that healthcare organizations should be directing their resources, Polaris stressed.
“That’s a business problem that makes revenue cycle right for disruption.”


Electronic prior authorization adoption continues to lag, according to the latest CAQH Index.

Source: Council for Affordable Quality Healthcare, Inc.
				
			
				
				The potential to optimize revenue cycle management
AI is not new to healthcare. For years, innovative providers have been leveraging the technology to deliver better care for patients with everything from sleep disorders, eye disease, cancer, and even COVID-19.
The technology has created hype for clinical care, promising to catch diseases faster, expand access to care in underserved or developing regions, reduce the burden of EHR use, and more.
But applying AI to revenue cycle management could be the technology’s biggest break in healthcare.
“There was a study done that estimated about $470 billion was spent on billing and insurance-related activities. The reason for that was there's an obscene amount of work that goes into getting a claim billed and then collecting on that claim,” said Ross Moore, MBA, general manager of revenue cycle at Olive, a health IT company that uses AI to automate provider workflows.
“Those manual, redundant tasks that are taking place in patient access, coding, billing, collections, and denials, those tasks themselves that are performed by the revenue cycle departments can actually be automated using AI.”
AI deals really well with high transaction environments in which there are codified rules – like the healthcare revenue cycle.
The revenue cycle contains an abundance of tagged data, which means values are codified to data points to indicate certain events, like why a claim was denied or attributes of a patient’s diagnosis, Polaris explained.



Joe Polaris, SVP, product & technology, R1 RCM


“Whether it's matching a patient with the right provider, estimating out-of-pocket costs, or coding the claim, those are things that have long lists of variables associated with them, and AI is pretty uniquely good at evaluating those variables and coming up with an ever-improving success rate of getting to the right outcome against any of those process steps,” he said.
AI can do this by imitating intelligent human behavior through algorithms that find patterns and plan future actions in order to produce a positive outcome. This differs from other emerging technologies like machine learning or robotic process automation, which can identify patterns like AI but focus on improving accuracy rather than achieving positive outcomes. These other technologies also have no or limited ability to plan a future action beyond the task at hand.
Therefore, AI’s “intelligence” can effectively address the most pressing revenue cycle management issues, such as prior authorizations, claim status checks, and out-of-pocket cost estimates, all while getting the information that needs human intervention to the right person at the right time.
“When the technology is used inside of Epic, Cerner, or our standalone clinical intelligence products, it looks based on what it learns in the document, and then it renders the information to the appropriate party,” stated Michael Clark, senior vice president and general manager for provider solutions within Nuance’s healthcare division.
“So, there's a case manager who is interested in what's going on in encounter documentation.  There's a coder. There's certainly a physician. Through AI and machine learning, you can make available, out of the same set of facts and circumstances in the data, information to those different stakeholders, eliminating redundancy, reworking, and retrospective queries.”



Michael Clark, SVP, general manager for provider solutions, Nuance


AI-powered revenue cycle management technology can also do that in real-time – something the revenue cycle has struggled to achieve due to its high volume of transactions.
“Providers need to know in real-time who is cleared to be treated financially and who is not to make the most informed decisions for the practice. Patients, too, need to know what they’re responsible for paying so they can choose treatment options that are right for them,” said MaryAnne Thompson, controller at MidLantic Urology LLC, a group of 70-plus physicians in Pennsylvania.
“We were encouraged by the idea that AI would give us real-time insights to drive meaningful change and help us capture as many dollars as possible, while also delivering a good patient experience.”
MidLantic Urology is leveraging AI through a financial clearance workflow automation solution that “provides visual cues to practice executives, so [they] know where each patient is in the financial clearance process, in real-time, and what needs to happen next.”
The solution has already helped the group improve gross revenue by 18 percent, a number Thompson expects to increase by 12 percentage points this year. The group is also working on 85 percent fewer claims at any given time, she reported.
As a result, MidLantic Urology realized a 50 percent reduction in anticipated staffing requirements for its newly centralized billing department. Yale New Haven Health also saw workforce optimization results by using AI to improve prior authorizations.
“It has never been to eliminate positions. It's been more about refining processes and then moving further ahead,” Seidman said. “Getting to more of those value-adding functions sooner so that we could focus on what's really important to us, which is our patient.”
Results like these are creating buzz around AI and revenue cycle management. But adoption still lags as the market attempts to find the right place for AI.
Getting lost in the noise
Providers are being bombarded with pitches for products that promise to leverage the latest AI technology to solve some of the revenue cycle’s biggest pain points while maximizing revenue capture and integrity.
Despite the seemingly growing number of products and the revenue cycle’s ripeness for automation, adoption of AI for revenue cycle management is not as robust as one may think.
“We're shifting from early adopter where you have the innovative health systems trying to invest in technologies to do things differently to the early majority where we're seeing more and more providers that are doing things like pilots and proof of concepts to adopt automation in their organization,” Moore explained using the technology adoption curve from Geoffrey A. Moore’s 1991 book Crossing the Chasm.
Providers are gearing up for wider adoption. A recent Black Book survey of C-suite executives found less than half (44 percent) of healthcare organizations already use AI in some form or another, but 88 percent anticipate widespread implementation within the next five years. Those implementations would impact revenue integrity, clinical documentation improvement, coding, and other parts of the revenue cycle, respondents stated.
But getting everybody on board with crossing the chasm may be a challenge.


For AI to take off for RCM, providers must cross the technology adoption chasm as defined by Geoffrey Moore in Crossing the Chasm.

“There's still a black box feeling around AI, whether it's healthcare or other industries,” Clark said. “But in healthcare, more importantly, there are patients. At the end of the documentation, there's a patient. So, the black box aspect of it has slowed more rapid adoption.”
In healthcare, the work done during the early adopter stage will be key to AI investments in the near future. Providers need to see financial improvements before they will feel comfortable adopting AI technology in their revenue cycles.
“What truly drives the adoption and the belief are the demonstrable outcomes,” Clark said. “As more and more solutions deliver on the outcomes that were pitched to users, providers will gain confidence, and in gaining that confidence, they're more open to applying AI in a different setting or in another area that they may have been concerned about before, but are now ready to automate.”
Thompson offered a similar sentiment regarding her organization’s technology investment strategy.
“We would definitely consider purchasing future technology solutions that rely on AI or machine-learning algorithms if they are proven to help improve practice margins and operational efficiencies,” said Thompson.
“What do we want to accomplish by leveraging a particular technology solution? What efficiencies will we gain? How quickly will we yield a return on investment,” she said regarding MidLantic Urology’s “goal-oriented” strategy for purchasing IT.
The revenue cycle management solution market doesn’t answer those questions just yet. Technology companies have yet to deliver consistent tools to the market and physician practices and other small healthcare organizations are not experiencing the massive write-offs to demand the tools, according to Matt Seefeld, EVP at the health software and services company MedEvolve.



Matt Seefeld, executive vice president, MedEvolve


“When you get in the larger groups, the pain is starting to really amp up. But when you're still an independent private practice, surgical specialty, or even specialties like derm, ophthalmology, ortho, neuro, cardiology, a lot of those folks are still getting by with average tools. That's not going to last forever,” he said.
“But I think that there are going to be some key players that bring more awareness to this topic and it's going to have to be the clients that start to demand it from vendors.”
Healthcare organizations that have yet to see the need for such technology or do not have the capital or infrastructure to support the investment may have to wait a little to unlock the benefits of AI-powered revenue cycle management. But being an early adopter does have its advantages, said Clark.
“That learning loop and its imperfections are not reasons to not embrace it,” Clark explained. “As a matter of fact, it's more of a reason to embrace it because by living it, you end up really understanding how real it is or how real it isn't.”
“It gives you a chance to make some quick decisions on whether this is something worth continuing to invest the time, energy, or the money in, or whether it's something that is not really artificial intelligence and shouldn't be construed as such.”
Investing in AI for revenue cycle management
Healthcare may still be figuring out the market for AI in revenue cycle management, but providers can still realize the benefits of the innovative technology.
A good place to start with AI investments is identifying use cases. Providers should be looking for opportunities to use automation to perform tasks that negatively impact net revenue. Then, they should assess staffing costs, Moore stated.
He encouraged stakeholders to ask: How many people are performing a specific function? And where can automation free up capacity for more value-adding activities?



Ross Moore, general manager of revenue cycle, Olive


This strategy helped Yale New Haven Health leverage AI to optimize prior authorizations.
“We had to take a much closer look at our processes because we didn't want to automate a bad process or an already efficient process. We did some pre-work to process map what we were doing,” Seidman explained.
Once the health system decided on what processes to automate with AI, it then went on to select a technology partner. Seidman and her team reviewed around 25 companies, a process that was well worth the effort to find the right technology partner.
“Make sure that you find a company who you share the same goals with,” Seidman advised. “It's a little difficult because a lot of these companies are saying, they have it built. Then, when you actually have a conversation, they’re really looking for a partner to build this with.”
Yale New Haven Health’s goal was to put the patient in the center of everything being done, so the health system went with a vendor whose mission was not to replace staff with AI, but redirect staff to doing more patient-centric activities, like talking about insurance benefits or setting expectations for patient financial responsibility.
Providers should also bring in the employees who do the work to evaluate the solution, she recommended. “They can share the process that they're following in reality versus what we believed what was happening.”
Implementation of AI can also start small to ensure revenue cycle management success, added Thompson.
MidAtlantic Urology recently underwent exponential growth, from a small practice with a few locations to one of the largest specialty practices in the nation with 46 locations. Growth through acquisitions translated to value for patients, but it also left the practice with a fragmented revenue cycle management system.
“We had little to no reporting mechanisms in place and we weren’t automated, so we couldn’t identify the problem areas, where they stemmed from, who made them, or how to resolve them,” Thompson stated. “These challenges were holding back the organization’s overall success, so we started looking at cloud-based applications that could provide us with visibility into financial clearance as well as insights, metrics, and KPIs that would allow us to effect a positive change in our A/R.”
MidAtlantic Urology chose to beta test a financial clearance workflow automation tool from MedEvolve. The organization started by using the tool at one practice and expanding out from there once financial improvements were realized.
It took six months for the organization to go 100 percent live with the tool, but providers in the practice are now seeing revenue increases and the organization plans to keep improving by adding more AI-powered revenue cycle management tools, including AI as-a-service.
AI as-a-service may be the next step for the technology in the revenue cycle management space. The service allows healthcare organizations to outsource AI technology, which enables providers to dabble with AI for revenue cycle management without heavy upfront investments.
This type of AI is not as mature in the market as other versions of the technology, like point solutions or robotic process automation offerings. But it is gaining a foothold, Moore stated.
“The end-to-end identification of processes to automate, doing the actual build, and maintaining those bots is really a huge effort,” he said. “Over 50 percent of automation programs fail, and this isn't healthcare specific, but across the board. The reason for that is there’s a lot of work that goes into maintaining those bots.”
“AI-as-a-service is focusing on offering that maintenance aspect, as well as using machine learning capabilities and learning that's taking place across a neural network to enhance that bot.”
The service enables providers to engage with AI to optimize revenue cycle management and even beyond.
“Health systems are taking those pilots and the proofs of concept and adopting it on a broader level,” Moore stated. “What we'll find most of the time is revenue cycle management is a natural place to get started with automation. But then as you're having the conversations with an organization, they're thinking about where they want to be in the future.”
“It's really not focused solely on revenue cycle. It's being able to set up the capabilities in a way you can scale the program to other areas in the organization whether it be supply chain some of the clinical departments in the organization, IT, or accounting.”
So, whether one believes in the hype or not, AI is making a place for itself in the healthcare revenue cycle.
“There's going to be more of a bias, or even a mandate, that organizations adopt some of these technologies,” Polaris maintained. “Right, wrong, or indifferent, the buzz is out there.”



Sign in for existing members




Continue Reading This Article
Enjoy this article as well as all of our content, including E-Guides, news, tips and more.


Step 2 of 2:




 You forgot to provide an Email Address.This email address doesn’t appear to be valid.Please provide a Corporate Email Address.This email address is already registered. Please log in.You have exceeded the maximum character limit.I agree to TechTarget’s Terms of Use, Privacy Policy, and the transfer of my information to the United States for processing to provide me with relevant information as described in our Privacy Policy.Please check the box if you want to proceed.I agree to my information being processed by TechTarget and its Partners to contact me via phone, email, or other means regarding information relevant to my professional interests. I may unsubscribe at any time.Please check the box if you want to proceed.

 



Tagged
Artificial Intelligence
Revenue Cycle Analytics
Revenue Cycle Management
Revenue Cycle Management Vendors

 Share on Twitter 



Related Resources



Q&A: Harnessing AI to elevate hospital revenue integrity
Guide to rethinking revenue management with AI
GenAI and RPA: Transforming healthcare claims appeals





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2V4cGxvcmluZy1wb3RlbnRpYWxzLWFpLXJldm9sdXRpb25pemluZy1hcmNoaXRlY3R1cmXSAXdodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hbXAvc3RvcnkvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvZXhwbG9yaW5nLXBvdGVudGlhbHMtYWktcmV2b2x1dGlvbml6aW5nLWFyY2hpdGVjdHVyZQ?oc=5,Exploring Potentials of AI in Revolutionizing Architecture - Analytics Insight,2020-04-08,Analytics Insight,https://www.analyticsinsight.net,,"AI,Architectural Conception,Parametricism ,Computational Design,Modularity","The practice of Architecture, its methods, traditions, and know-how are today at the center of passionate debates. Challenged by outsiders, arriving with new pr","The practice of Architecture, its methods, traditions, and know-how are today at the center of passionate debates. Challenged by outsiders, arriving with new pr",http://schema.org,,N/A,N/A,"Ready for iOS 18? Here's How to Install the Public Beta
",NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/exploring-potentials-ai-revolutionizing-architecture,Exploring Potentials of AI in Revolutionizing Architecture,,,,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/04/architecture.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/exploring-potentials-ai-revolutionizing-architecture'}",,"[{'@type': 'Person', 'givenName': 'Smriti Srivastava', 'name': 'Smriti Srivastava', 'url': 'https://www.analyticsinsight.net/author/smriti-srivastava'}]",2020-04-08T01:46:29Z,2020-04-08T01:46:29Z,Exploring Potentials of AI in Revolutionizing Architecture,,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.linkedin.com/company/analytics-insight/', 'https://www.facebook.com/analyticsinsight.net', 'https://twitter.com/analyticsinme', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l'], 'id': 'https://www.analyticsinsight.net'}",,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/exploring-potentials-ai-revolutionizing-architecture', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/04/architecture.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,2020-04-08T01:46:29Z,,,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/04/architecture.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Exploring Potentials of AI in Revolutionizing Architecture', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/exploring-potentials-ai-revolutionizing-architecture'}]",,,"The practice of Architecture, its methods, traditions, and know-how are today at the center of passionate debates. Challenged by outsiders, arriving with new practices blended with new-age technologies including artificial intelligence has brought a truly profound evolution in how architecture is being done now..The conception of buildings has in fact already started a slow transformation: first by leveraging new construction technics, then by developing adequate software, and eventually today by introducing statistical computing capabilities including Data Science &amp; AI..&quot;Modularity, Computational Design, Parametricism and finally Artificial Intelligence are to us the four intricated steps of a slow-paced transition. Beyond the historical background, we posit that this evolution is the wireframe of a radical improvement in architectural conception,&quot; says Stanislas Chaillou, Harvard Graduate School of Design..According to the Economist, 47% of the work done by humans will have been replaced by robots by 2037, even those traditionally associated with university education. Having said that, a recent study at University College London (ULC) and the University of Bangor said that although automation and artificial intelligence, for the time being, would not replace architects, the discipline will undergo massive transformations in the near future. Computers can replace tedious repetitive activities, &quot;optimizing the production of technical material and allowing, among other things, atomize the size of architectural offices. Each time fewer architects are needed to develop more complex projects.&quot;.Architectural Digest notes that to create new designs, architects usually use past construction, design, and building data. Instead of putting their minds together to create something new, it is alleged that a computer will be able to utilize tons of previous data in a millisecond, make recommendations and enhance the architecture design process..With AI, an architect would very easily go about researching and testing several ideas at the same time, sometimes even without the need for a pen and paper. Also, an architect could pull out a city or zone-specific data, building codes, and redundant design data, and generate design variations. Even on the construction side, it is said that AI can assist with actually building something with little to no manpower. Will this eventually lead to clients and organizations simply reverting to a computer for master-plans and construction?.Researchers at Oxford suggest that even with AI coming into the scene, the essential value of architects as professionals who can understand and evaluate a problem and synthesize unique and insightful solutions will likely remain unchallenged..Let's explore how AI can be used in Architecture..Parametric Architecture.Parametric architecture is a hidden weapon that allows an architect to change specific parameters to create various types of output designs and create such structures that would not have been imagined earlier. It is like an architect's programming language..It allows an architect to consider a building and reframe it to fit into some other requirements. A process like this allows Artificial Intelligence to reduce the effort of an architect so that the architect can freely think about different ideas and create something new..Construction and Planning.Constructing a building is not a one-day task as it needs a lot of pre-planning. However, this pre-planning is not enough sometimes, and you need a little bit of more effort to get an architect's opinion to life. Artificial Intelligence will make an architect's work significantly easier by analyzing the whole data and creating models that can save a lot of time and energy of the architect..All in all, AI can be called an estimation tool for various aspects while constructing a building. However, when it comes to the construction part, AI can help so that human efforts become negligible..Laying the Foundation.The countless hours of research at the starting of any new project is where AI steps in and makes it easy for the architect by analyzing the aggregate data in a millisecond and recommending some models so that the architect can think about the conceptual design without even using the pen or paper..Just like while building a home for a family, if you have the whole information about the requirements of the family, you can simply pull all zoning data using AI and generate design variations in a short time period..AI for Making Homes.This era of modernization demands everything to be smartly designed. Just like smart cities, today's high technology society demands smart homes. However, now architects do not have to bother about how to use AI to create the designs of a home only, but they should worry about making the user's experience worth paying..Smart Cities.Change is something that should never change. The way your city looks today will be very different in the coming time. The most challenging task for an architect is city planning that needs a lot of precision planning. However, the primary task is to analyze all the possible aspects, and understand how a city will flow, how the population is going to be in the coming years..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",Artificial Intelligence

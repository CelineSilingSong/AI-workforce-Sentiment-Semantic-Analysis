URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@graph,@type,headline,url,mainEntityOfPage,thumbnailUrl,image,articleSection,author,creator,publisher,dateCreated,datePublished,dateModified,article:section,article:summary,article text,name,isAccessibleForFree,itemListElement,articleBody,isBasedOn,isPartOf,alternativeHeadline,numberOfItems,logo,sameAs,hasPart,inLanguage,copyrightHolder,sourceOrganization,copyrightYear,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate
https://news.google.com/rss/articles/CBMimAFodHRwczovL3d3dy5wZXdyZXNlYXJjaC5vcmcvc2hvcnQtcmVhZHMvMjAyMC8xMi8xNS9wZW9wbGUtZ2xvYmFsbHktb2ZmZXItbWl4ZWQtdmlld3Mtb2YtdGhlLWltcGFjdC1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1qb2ItYXV0b21hdGlvbi1vbi1zb2NpZXR5L9IBAA?oc=5,"Are AI and job automation good for society? Globally, views are mixed - Pew Research Center",2020-12-15,Pew Research Center,https://www.pewresearch.org,"As artificial intelligence plays a growing role in the everyday lives of people around the world, views on AI’s impact on society are mixed.",[],"As artificial intelligence plays a growing role in the everyday lives of people around the world, views on AI’s impact on society are mixed.",N/A,https://schema.org,"[{'@type': 'WebPage', '@id': 'https://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/', 'url': 'https://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/', 'name': 'Are AI and job automation good for society? Globally, views are mixed | Pew Research Center', 'isPartOf': {'@id': 'https://www.pewresearch.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/#primaryimage'}, 'image': {'@id': 'https://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/#primaryimage'}, 'thumbnailUrl': 'https://www.pewresearch.org/wp-content/uploads/2020/12/FT_20.12.14_Automation_feature.jpg?w=640', 'datePublished': '2020-12-15T18:00:05+00:00', 'dateModified': '2024-04-14T04:43:57+00:00', 'description': 'As artificial intelligence plays a growing role in the everyday lives of people around the world, views on AI’s impact on society are mixed.', 'breadcrumb': {'@id': 'https://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/#primaryimage', 'url': 'https://www.pewresearch.org/wp-content/uploads/2020/12/FT_20.12.14_Automation_feature.jpg?w=640', 'contentUrl': 'https://www.pewresearch.org/wp-content/uploads/2020/12/FT_20.12.14_Automation_feature.jpg?w=640'}, {'@type': 'BreadcrumbList', '@id': 'https://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.pewresearch.org'}, {'@type': 'ListItem', 'position': 2, 'name': 'Research Topics'}]}, {'@type': 'WebSite', '@id': 'https://www.pewresearch.org/#website', 'url': 'https://www.pewresearch.org/', 'name': 'Pew Research Center', 'description': 'Numbers, Facts and Trends Shaping Your World', 'publisher': {'@id': 'https://www.pewresearch.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.pewresearch.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.pewresearch.org/#organization', 'name': 'Pew Research Center', 'url': 'https://www.pewresearch.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.pewresearch.org/#/schema/logo/image/', 'url': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2024/04/logo-fallback.png', 'contentUrl': 'https://www.pewresearch.org/wp-content/uploads/sites/20/2024/04/logo-fallback.png', 'width': 1265, 'height': 192, 'caption': 'Pew Research Center'}, 'image': {'@id': 'https://www.pewresearch.org/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/pewresearch', 'https://twitter.com/pewresearch', 'https://www.linkedin.com/company/pew-research-center/', 'https://www.youtube.com/user/PewResearchCenter']}]",NewsArticle,"People globally offer mixed views of the impact of artificial intelligence, job automation on society",http://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/,"{'@type': 'WebPage', '@id': 'http://www.pewresearch.org/short-reads/2020/12/15/people-globally-offer-mixed-views-of-the-impact-of-artificial-intelligence-job-automation-on-society/'}",,"{'@type': 'ImageObject', 'url': ''}",,"[{'@type': 'Person', 'name': 'Carrie Blazina'}]",['Carrie Blazina'],"{'@type': 'Organization', 'name': 'Pew Research Center', 'logo': 'https://www.pewresearch.org/wp-content/themes/prc-block-theme/assets/img/square.png'}",2020-12-15T18:00:05Z,2020-12-15T18:00:05Z,2024-04-14T04:43:57Z,N/A,N/A,"

Short Reads
|
December 15, 2020

X
Facebook
Threads
LinkedIn
WhatsApp
Share


People globally offer mixed views of the impact of artificial intelligence, job automation on society
By Courtney Johnson and Alec Tyson

A robot barista that uses artificial intelligence demonstrates its coffee-making process at the 2020 AI Expo Korea in Seoul. (Chris Jung/NurPhoto via Getty Images)
As artificial intelligence (AI) plays a growing role in the everyday lives of people around the world, views on AI’s impact on society are mixed across 20 global publics, according to a recent Pew Research Center survey.  

How we did this

This analysis is based on a survey conducted across 20 publics from October 2019 to March 2020 across Europe, Russia, the Americas and the Asia-Pacific region. The surveys were conducted by face-to-face interviews in Russia, Poland, the Czech Republic, India and Brazil. In all other places, the surveys were conducted by telephone. All surveys were conducted with representative samples of adults ages 18 and older in each survey public.
Here are the questions used for the report, along with responses, and its methodology.



A median of about half (53%) say the development of artificial intelligence, or the use of computer systems designed to imitate human behaviors, has been a good thing for society, while 33% say it has been a bad thing.
Opinions are also divided on another major technological development: using robots to automate many jobs humans have done in the past. A median of 48% say job automation has been a good thing, while 42% say it’s had a negative impact on society.
The survey – conducted in late 2019 and early 2020 in 20 places across Europe, the Asia-Pacific region, and in the United States, Canada, Brazil and Russia – comes as automation has remade workplaces around the world and AI increasingly powers things from social media algorithms to technology in cars and everyday appliances.
Views of AI are generally positive among the Asian publics surveyed: About two-thirds or more in Singapore (72%), South Korea (69%), India (67%), Taiwan (66%) and Japan (65%) say AI has been a good thing for society. Many places in Asia have emerged as world leaders in AI.
Most other places surveyed fall short of a majority saying AI has been good for society. In France, for example, views are particularly negative: Just 37% say AI has been good for society, compared with 47% who say it has been bad for society. In the U.S. and UK, about as many say it has been a good thing for society as a bad thing. By contrast, Sweden and Spain are among a handful of places outside of the Asia-Pacific region where a majority (60%) views AI in a positive light.
As with AI, Asian publics surveyed stand out for their relatively positive views of the impact of job automation. Many Asian publics have made major strides in the development of robotics and AI. The South Korean and Singaporean manufacturing industries, for instance, have the highest and second highest robot density of anywhere in the world. Singapore is also pursuing its goal of becoming the world’s first “smart nation,” and the government has identified AI as one of many key development areas necessary to reach that goal. Japan has also long been a world leader in robotics manufacturing and development, and robots and AI are increasingly integrated into everyday life there to help with tasks ranging from household chores to elder care.
Men are significantly more likely than women to say artificial intelligence has been a good thing for society in 15 of the 20 places surveyed. In Japan, for example, nearly three-quarters of men (73%) have positive views of AI, compared with 56% of women. In the U.S., 53% of men say AI has been a positive thing, compared with 40% of women.

People with more education are also more likely to have a positive view of AI. This gap is largest in the Netherlands, where a majority of those with a college education or higher (61%) see AI favorably, compared with 43% of those with less education. In the 11 publics where age is a significant factor in views of AI, younger people usually have a more positive view of the technology than older people.
There are similar patterns by gender and education in views of job automation. The educational differences are particularly large in some places: In Italy, for instance, about two-thirds of people with at least a college education (65%) say job automation has been a good thing for society, compared with just 38% of people with less education. Among adults with more education, those who took three or more science courses tend to see job automation more positively than people who took fewer science classes.
Note: Here are the questions used for the report, along with responses, and its methodology.



Topics

Share This Link:

X
Facebook
Threads
LinkedIn
WhatsApp
Share







Courtney Johnson is a former research associate focusing on science and society at Pew Research Center.





Alec Tyson is  an associate director of research at Pew Research Center.

",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvcm9idG9ld3MvMjAyMC8xMi8xMy84LWxlYWRpbmctd29tZW4taW4tdGhlLWZpZWxkLW9mLWFpL9IBAA?oc=5,8 Leading Women In The Field Of AI - Forbes,2020-12-13,Forbes,https://www.forbes.com,"As entrepreneurs, academics, executives, venture capitalists and more, these women are shaping the future of artificial intelligence.",,"As entrepreneurs, academics, executives, venture capitalists and more, these women are shaping the future of artificial intelligence.","As entrepreneurs, academics, executives, venture capitalists and more, these women are shaping the future of artificial intelligence.",http://schema.org,,BreadcrumbList,8 Leading Women In The Field Of AI,https://www.forbes.com/sites/robtoews/2020/12/13/8-leading-women-in-the-field-of-ai/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5fce9167970668619d1dc2a3/0x0.png?format=png&crop=1620,911,x108,y0,safe&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",AI,"{'@type': 'Person', 'name': 'Rob Toews', 'url': 'https://www.forbes.com/sites/robtoews/', 'description': 'Rob Toews is a venture capitalist at Radical Ventures.', 'sameAs': ['https://www.twitter.com/_RobToews']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2020-12-13T17:44:14-05:00,2020-12-13T17:44:14-05:00,AI,N/A,"More From ForbesJul 17, 2024,07:56am EDTFrom 'Don't Be Evil' To Legal AI: Tackling Bias And ComplacencyJul 17, 2024,04:00am EDTCan Universal Basic Income Save Us From The Destabilization Of AI And Automation?Jul 16, 2024,09:30am EDTIn Superconvergence, Jamie Metzl Unravels AI MysteriesJul 15, 2024,09:30pm EDTAnswering Your Most Frequently Asked Questions (FAQs) About Artificial Intelligence In Honor Of National AI Appreciation DayJul 15, 2024,06:06pm EDTNot Just A Maker Space: Fab Labs Spark Innovation WorldwideJul 15, 2024,02:57pm EDTIBM InstructLab And Granite Models Revolutionizing LLM TrainingJul 15, 2024,09:42am EDTHow Generative AI Is Driving HyperpersonalizationEdit StoryForbesInnovationAI8 Leading Women In The Field Of AIRob ToewsContributorOpinions expressed by Forbes Contributors are their own.I write about the big picture of artificial intelligence.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itDec 13, 2020,05:44pm ESTUpdated Dec 13, 2020, 05:44pm ESTThis article is more than 3 years old.Share to FacebookShare to TwitterShare to LinkedinThese eight women are at the forefront of the field of artificial intelligence today. They hail from ... [+] academia, startups, large technology companies, venture capital and beyond.Photo credit: Various
It is a simple truth: the field of artificial intelligence is far too male-dominated. According to a 2018 study from Wired and Element AI, just 12% of AI researchers globally are female.


Artificial intelligence will reshape every corner of our lives in the coming years—from healthcare to finance, from education to government. It is therefore troubling that those building this technology do not fully represent the society they are poised to transform.

Yet there are many brilliant women at the forefront of AI today. As entrepreneurs, academic researchers, industry executives, venture capitalists and more, these women are shaping the future of artificial intelligence. They also serve as role models for the next generation of AI leaders, reflecting what a more inclusive AI community can and should look like.

PROMOTED
Featured below are eight of the leading women in the field of artificial intelligence today.


MORE FOR YOUFather Of Suspected Trump Gunman Was Profiled As Pro-Gun Voter By Trump Campaign: What We Know About Thomas Matthew Crooks‘The Acolyte’ Episode 8 Recap And Review: A Dreadful Season Finale And The Cameos Can’t Save ItAmazon Prime Day 2024: The 110 Best Deals Of Day Two So Far
Joy Buolamwini: Founder, Algorithmic Justice League
Joy Buolamwini has aptly been described as “the conscience of the A.I. revolution.”









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Her pioneering work on algorithmic bias as a graduate student at MIT opened the world’s eyes to the racial and gender prejudices embedded in facial recognition systems. Amazon, Microsoft and IBM each suspended their facial recognition offerings this year as a result of Buolamwini’s research, acknowledging that the technology was not yet fit for public use. Buolamwini’s work is powerfully profiled in the new documentary Coded Bias.


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
Buolamwini stands at the forefront of a burgeoning movement to identify and address the social consequences of artificial intelligence technology, a movement she advances through her nonprofit Algorithmic Justice League.
Buolamwini on the battle against algorithmic bias: “When I started talking about this, in 2016, it was such a foreign concept. Today, I can’t go online without seeing some news article or story about a biased AI system. People are just now waking up to the fact that there is a problem. Awareness is good—and then that awareness needs to lead to action. That is the phase that we’re in.”

Claire Delaunay: VP Engineering, NVIDIA
From SRI to Google to Uber to NVIDIA, Claire Delaunay has held technical leadership roles at many of Silicon Valley’s most iconic organizations. She was also co-founder and engineering head at Otto, the pedigreed but ill-fated autonomous trucking startup helmed by Anthony Levandowski.
In her current role at NVIDIA, Delaunay is focused on building tools and platforms to enable the deployment of autonomous machines at scale.
Delaunay on the tradeoffs between working at a big company and a startup: “Some kinds of breakthroughs can only be accomplished at a big company, and other kinds of breakthroughs can only be accomplished at a startup. Startups are very good at deconstructing things and generating discontinuous big leaps forward. Big companies are very good at consolidating breakthroughs and building out robust technology foundations that enable future innovation.”

Rana el Kaliouby: CEO & Co-Founder, Affectiva
Rana el Kaliouby has dedicated her career to making AI more emotionally intelligent.
Kaliouby is credited with pioneering the field of Emotion AI. In 2009, she co-founded the startup Affectiva as a spinout from MIT to develop machine learning systems capable of understanding human emotions. Today, the company’s technology is used by 25% of the Fortune 500, including for media analytics, consumer behavioral research and automotive use cases.
Kaliouby on her big-picture vision: “My life’s work is about humanizing technology before it dehumanizes us.”

Daphne Koller: CEO & Founder, insitro
Daphne Koller’s wide-ranging career illustrates the symbiosis between academia and industry that is a defining characteristic of the field of artificial intelligence.
Koller has been a professor at Stanford since 1995, focused on machine learning. In 2012 she co-founded education technology startup Coursera with fellow Stanford professor and AI leader Andrew Ng. Coursera is today a $2.6 billion ed tech juggernaut.
Koller’s most recent undertaking may be her most ambitious yet. She is the founding CEO at insitro, a startup applying machine learning to transform pharmaceutical drug discovery and development. Insitro has raised roughly $250 million from Andreessen Horowitz and others and recently announced a major commercial partnership with Bristol Myers Squibb.
Koller on advice for those just starting out in the field of AI: “Pick an application of AI that really matters, that is really societally worthwhile—not all AI applications are—and then put in the hard work to truly understand that domain. I am able to build insitro today only because I spent 20 years learning biology. An area I might suggest to young people today is energy and the environment.”

Fei-Fei Li: Professor of Computer Science, Stanford University
Few individuals have left more of a mark on the world of AI in the twenty-first century than Fei-Fei Li.
As a young Princeton professor in 2007, Li conceived of and spearheaded the ImageNet project, a database of millions of labeled images that has changed the entire trajectory of AI. The prescient insight behind ImageNet was that massive datasets—more than particular algorithms—would be the key to unleashing AI’s potential. When Geoff Hinton and team debuted their neural network-based model trained on ImageNet at the 2012 ImageNet competition, the modern era of deep learning was born.
Li has since become a tenured professor at Stanford, served as Chief Scientist of AI/ML at Google Cloud, headed Stanford’s AI lab, joined the Board of Directors at Twitter, cofounded the prominent nonprofit AI4ALL, and launched Stanford’s Human-Centered AI Institute (HAI). Across her many leadership positions, Li has tirelessly advocated for a more inclusive, equitable and human approach to AI.
Li on why diversity in AI is so important: “Our technology is not independent of human values. It represents the values of the humans that are behind the design, development and application of the technology. So, if we’re worried about killer robots, we should really be worried about the creators of the technology. We want the creators of this technology to represent our values and represent our shared humanity.”

Anna Patterson: Founder & Managing Partner, Gradient Ventures
Anna Patterson has led a distinguished career developing and deploying AI products, both at large technology companies and at startups.
A long-time executive at Google, which she first joined in 2004, Patterson led artificial intelligence efforts for years as the company’s VP of Engineering. In 2017 she launched Google’s AI venture capital fund Gradient Ventures, where today she invests in early-stage AI startups.
Patterson serves on the board of a number of promising AI startups including Algorithmia, Labelbox and test.ai. She is also a board director at publicly-traded Square.
Patterson on one question she asks herself before investing in any AI startup: “Do I find myself constantly thinking about their vision and mission?”

Daniela Rus: Director, MIT’s Computer Science and Artificial Intelligence Lab (CSAIL)
Daniela Rus is one of the world’s leading roboticists.
She is an MIT professor and the first female head of MIT’s Computer Science and Artificial Intelligence Lab (CSAIL), one of the largest and most prestigious AI research labs in the world. This makes her part of a storied lineage: previous directors of CSAIL (and its predecessor labs) over the decades have included AI legends Marvin Minsky, J.C.R. Licklider and Rodney Brooks.
Rus’ groundbreaking research has advanced the state of the art in networked collaborative robots (robots that can work together and communicate with one another), self-reconfigurable robots (robots that can autonomously change their structure to adapt to their environment), and soft robots (robots without rigid bodies).
Rus on a common misconception about AI: “It is important for people to understand that AI is nothing more than a tool. Like any other tool, it is neither intrinsically good nor bad. It is solely what we choose to do with it. I believe that we can do extraordinarily positive things with AI—but it is not a given that that will happen.”

Shivon Zilis: Board Member, OpenAI; Project Director, Neuralink
Shivon Zilis has spent time on the leadership teams of several companies at AI’s bleeding edge: OpenAI, Neuralink, Tesla, Bloomberg Beta.
She is the youngest board member at OpenAI, the influential research lab behind breakthroughs like GPT-3. At Neuralink—Elon Musk’s mind-bending effort to meld the human brain with digital machines—Zilis works on high-priority strategic initiatives in the office of the CEO.
Zilis on her attitude toward new technology development: “I’m astounded by how often the concept of ‘building moats’ comes up. If you think the technology you’re building is good for the world, why not laser focus on expanding your tech tree as quickly as possible versus slowing down and dividing resources to impede the progress of others?”
Follow me on Twitter. Rob ToewsFollowingFollowRob Toews is a venture capitalist at Radical Ventures.Editorial StandardsPrintReprints & Permissions",8 Leading Women In The Field Of AI,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3LmNvZS5pbnQvZW4vd2ViL2luY2x1c2lvbi1hbmQtYW50aWRpc2NyaW1pbmF0aW9uL2FpLWFuZC1kaXNjcmltaW5hdGlvbtIBAA?oc=5,AI & discrimination - Inclusion and anti-discrimination - Council of Europe,2020-12-14,Council of Europe,https://www.coe.int,,N/A,N/A,N/A,https://schema.org,,WebPage,,,,,,,,,,2020-10-22,,2024-02-19,N/A,N/A,"
The impact of Artificial Intelligence (AI) on human rights is one of the most crucial factors that will define the period in which we live. AI-driven technology is entering more aspects of every individual’s life, from smart home appliances to social media applications, and it is increasingly being utilised by public authorities to evaluate people’s personality or skills, allocate resources, and otherwise make decisions that can have real and serious consequences for the human rights of individuals.
Numerous studies have highlighted the risks that so-called artificial intelligence (AI) and automated decision-making systems pose to the principles of equality and non-discrimination in employment, the provision of goods or services in both the public and private sectors, public security policies or even in the fight against fraud.
The study on ""Discrimination, artificial intelligence and algorithmic decision-making"" commissioned by the Council of Europe’s European Commission Against Racism and Intolerance (ECRI), identified many such challenges and stated that equality bodies have a key role to play in awareness-raising, prevention and redress. The study also showed that discrimination by AI & Automated Decision-making (ADM) systems can be addressed through different regulatory tools, including data protection and sectorial regulation such as employment laws. This calls for a cross-sectoral co-operation between national regulators in order to provide effective redress, share expertise and to share the workload.
The Committee on Anti-Discrimination, Diversity and Inclusion (CDADI) and the Gender Equality Commission (GEC) of the Council of Europe mandated the production of a Study on the impact of artificial intelligence systems, their potential for promoting equality – including gender equality - and the risks they may cause in relation to non-discrimination. Subject to the results of the above-mentioned study, the CDADI in cooperation with the GEC and the Committee on Artificial intelligence (CAI) will possibly develop a specific legal instrument addressing this matter. The Study builds on the current work of the CAI and the previous work of the Ad hoc Committee on Artificial Intelligence (CAHAI) in 2020 and 2021, in particular its Feasibility study and its document Possible elements of a legal framework on artificial intelligence, based on the Council of Europe’s standards on human rights, democracy and the rule of law.
The Council of Europe in partnership with equality bodies and other public institutions has set up training programmes looking at the impact of AI on discrimination. The courses support participants to acquire initial expertise on these subjects in order to better prepare them to identify and respond discrimination caused by digital technologies on behalf of their institutions.  The courses also serve as an opportunity to recall the legal framework of non-discrimination, which applies to decisions made on the basis of algorithmic processing. Finally, these training courses support the creation of a network of multipliers interested in the subject, establishing communication and supporting them to discuss their respective work and tasks.",AI & discrimination,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiM2h0dHBzOi8vd3d3LnZpb2xpbmlzdC5jb20vYmxvZy9sYXVyaWUvMjAyMDEyLzI4NTcyL9IBAA?oc=5,Interview with Hilary Hahn: New DeepMusic.ai Project Pairs Composers' Creativity with AI - Violinist.com,2020-12-15,Violinist.com,https://www.violinist.com,N/A,N/A,N/A,"Artificial intelligence, or ""AI,"" has made its way into many corners of our lives - from GPS, to autocorrect, to ""Alexa, play something I'd like!""

But what does that mean for the future of art and music? Violinist Hilary Hahn wants to make sure that artists have a say in the development and direction of artificial intelligence, and so she has teamed up with roboticist and AI specialist Carol Reiley to form an organization called <a href=""https://www.deepmusic.ai/"">DeepMusic.ai</a>. Its goal is to weave the artificial intelligence and arts communities together, so that the future of AI can be influenced by the vision and needs of artists.

I spoke with Hilary and Carol last week about their inspiration and vision for DeepMusic.ai - below is a video of our full conversation, which took place via Zoom, with Hilary in Massachusetts, Carol in Northern California and me in Pasadena, Calif.

<iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/P2RH-4AO7qY"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen></iframe>

On Tuesday night, Hilary performed the online world premiere of one of three pieces that DeepMusic.ai commissioned from composers Michael Abels, David Lang, and Dana Leong, who each wrote a piece with AI-assisted software programs. Hilary performed David Lang's ""out of body"" for solo violin. (See video below in the full story).",,,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vd3d3LndpcmVkLmNvbS9nYWxsZXJ5L2Jlc3QtYm9va3MtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,The 8 Best Books About Artificial Intelligence to Read Now - WIRED,2020-12-15,WIRED,https://www.wired.com,"Algorithms have crept into our feeds, streets, and workplaces. Here’s what WIRED staff are reading to understand what that means for the future.","['shopping', 'books', 'artificial intelligence', 'false', 'web']","Algorithms have crept into our feeds, streets, and workplaces. Here’s what WIRED staff are reading to understand what that means for the future.","Algorithms have crept into our feeds, streets, and workplaces. Here’s what WIRED staff are reading to understand what that means for the future.",https://schema.org,,ItemList,The 8 Best Books About Artificial Intelligence to Read Now,https://www.wired.com/gallery/best-books-artificial-intelligence/,"{'@type': 'WebPage', '@id': 'https://www.wired.com/gallery/best-books-artificial-intelligence/'}","https://media.wired.com/photos/5fd90052e0d489b7b9fd2e3b/1:1/w_1600,h_1600,c_limit/Business-YIR-AI-Book-Roundup-1286125400-final.jpg","['https://media.wired.com/photos/5fd90052e0d489b7b9fd2e3b/16:9/w_2277,h_1281,c_limit/Business-YIR-AI-Book-Roundup-1286125400-final.jpg', 'https://media.wired.com/photos/5fd90052e0d489b7b9fd2e3b/4:3/w_2131,h_1598,c_limit/Business-YIR-AI-Book-Roundup-1286125400-final.jpg', 'https://media.wired.com/photos/5fd90052e0d489b7b9fd2e3b/1:1/w_1600,h_1600,c_limit/Business-YIR-AI-Book-Roundup-1286125400-final.jpg']",business,"[{'@type': 'Person', 'name': 'WIRED Staff', 'sameAs': 'https://www.wired.com/author/wired-staff/'}]",,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",,2020-12-15T09:00:00.000-05:00,2020-12-15T09:00:00.000-05:00,tags,N/A,"WIRED StaffBusinessDec 15, 2020 9:00 AMThe 8 Best Books About Artificial Intelligence to Read NowAlgorithms have crept into our feeds, streets, and workplaces. Here’s what WIRED staff are reading to understand what that means for the future. FacebookXEmailSave StorySave this story for later.Illustration: Tracy J. Lee; Getty ImagesFacebookXEmailSave StorySave this story for later.It’s no secret that we at WIRED are fascinated by artificial intelligence. But it’s also no secret that thorny, and sometimes unexpected, questions arise as automation and algorithms creep into new corners of life—transforming jobs, economies, and even the world order. Which is why this winter, we’re also fascinated by books that grapple with these very questions. How did algorithms become so influential in our politics? When will they become our chauffeurs? And how much should they really know about us? Written by historians, journalists, and researchers, each of these books examines a very different aspect of the world that has been or will be upended by the influence of artificial intelligence. So sink your teeth into the algorithmic issues that will define the decades to come.If you buy something using links in our stories, we may earn a commission. This helps support our journalism. Learn more. Please also consider subscribing to WIREDCourtesy of Simon & SchusterDriven: The Race to Create the Autonomous Carby Alex DaviesThe “great man” theory holds that history is largely made by heroes—big, brawny, brainy dudes (always dudes) who reshape the future with brute force and brilliance. WIRED alum Alex Davies’ new book refutes that outdated theory. In Driven, Davies digs into the history of autonomous vehicles and the goofy, spirited cast of characters (still mostly dudes) who are working to shepherd the tech into existence. As Davies reveals, teamwork makes the dream work. Until it doesn’t. Then the lawsuits—and in one engineer’s case, handcuffs—fly.Eventually, robot cars might reshape the way modern life works. Autonomous vehicles could be a $7 trillion business by 2050; today, multibillion-dollar companies like Alphabet, General Motors, Ford, and Tesla race to hammer out the kinks. But back at the opening of the century, AVs were an academic hobbyhorse. Then an obscure clause in a 2001 funding bill poured government money into developing robot tech. Just a few years later, Darpa held a literal robot race across the Mojave Desert. The kooky entrants are the same engineers banking millions at the world’s largest AV companies today. For many, the money was a nice incentive. But as one roboticist tells Davies, most are driven by the classic maker ethos: “I sought something that would dent the world, that I could do with my own hands, that would happen in my time.”To paraphrase another visionary, the course of true engineering never did run smooth. Davies’ sharp narrative chronicles the personality clashes, philosophical divergences, funding crunches, and, in a shocking number of cases, troublesome wild creatures that get in robotics’ way. (A tip: When racing a robot across the desert, keep an eye out for the native tortoises, which will pee on you if you try to move them.) This is a book for anyone who’s sick of the hero narrative, and who wants to learn about how the business of building world-shaking robots truly creaks along.—Aarian Marshall$28 at Amazon$26 at Bookshop.orgTrending NowUnderstanding Algorithms With Sinead BovellCourtesy of Liveright If Then: How the Simulmatics Corporation Invented the Future by Jill LeporePop quiz: Who is the presidential candidate that first used algorithmic modeling of the American electorate to win a contentious election? If you said Donald Trump, you're 56 years too late. The year was 1960, and John F. Kennedy had contracted a little-known startup called the Simulmatics Corporation to use its pioneering ""people machine"" to survey American voters, predict their behavior, and provide campaign advice. In her history of Simulmatics (“the A-bomb of the social sciences,” a “Cold War Cambridge Analytica”), Jill Lepore chronicles those early days of algorithmic behavior modeling, and its inevitable influence on politics and society.Simulmatics would go on to win contracts with the The New York Times, which used its technology to anticipate the outcome of elections, and the Department of Defense, which used it to inform war strategy in Vietnam. Lepore, who is both a Harvard historian and a staff writer at the The New Yorker, brings the company's history to life with brilliant archival details. Her depiction of the 1960s serves as a mirror of 2020: America is in the midst of a racial justice uprising, a technological arms race with its geographical foe, and an election shaped by the influence of technology. On any given page, you could swap “Simulmatics” for “Facebook” and the story would almost make sense. If Then is the story of technology’s forgotten founding fathers, whose work gave rise to the “people predictors” that would shape modern democracy and pave the way for today’s Silicon Valley's giants. If the rise and fall of Simulmatics is better studied, then history may not be doomed to repeat itself—again. —Arielle Pardes$21 at Amazon$27 at Bookshop.orgAdvertisementMost PopularThe Big StoryPriscila, Queen of the Rideshare MafiaLauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingDavid Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsSimon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionDavid Gilbert, WIREDCourtesy of CurrencyThe Hype Machine: How Social Media Disrupts Our Elections, Our Economy, and Our Health—and How We Must Adaptby Sinan AralWriting about the pitfalls of social media poses an immediate conundrum: choosing which problem to focus on. The advertising-driven business model? The algorithmic amplification of divisive content? Partisan polarization? Election interference? In The Hype Machine, Sinan Aral decides to tackle pretty much all of them. He’s surprisingly successful. The director of the MIT Initiative on the Digital Economy, Aral offers a God’s-eye view of the latest experimental research into the inner workings of social media. The result is something like a textbook—an engagingly written shortcut to expertise on what the likes of Facebook and Twitter are doing to our brains and our society.Aral is not a polemicist; he believes that social media offers real societal benefits, and he worries that efforts to fix the equally real harms it causes could sacrifice the good stuff in the process. He is careful not to let his conclusions run ahead of what has been proven in the literature. Readers looking for a devastating attack on Big Tech will therefore be disappointed. But Aral’s circumspection is mostly a virtue. When he concludes, for example, that the effectiveness of social media advertising “is wildly and brazenly oversold,” you can be confident that he’s taking stock of the available evidence, not cherry-picking in pursuit of an agenda. The book falters a bit when it comes to policy prescriptions; Aral’s dismissive treatment of the tech antitrust movement, in particular, lacks the sophistication of his empirical analysis. “I’m a scientist, entrepreneur, and investor—in that order.” he declares early on. That checks out. The chief virtue of The Hype Machine is not what Aral thinks, but what he knows. —Gilad Edelman$21 at Amazon$26 at Bookshop.orgCourtesy of Oxford University PressPredict and Surveil: Data, Discretion, and the Future of Policingby Sarah BrayneSarah Brayne spent parts of five years inside the Los Angeles Police Department, riding in patrol cars, talking to top brass, and, crucially, observing the department’s use of data and software to “predict” and respond to crime. Her experience and observations elevate her book, Predict and Surveil, beyond more conventional diatribes about the harms of police surveillance. A sociologist by training (the book is a modified version of her PhD dissertation), Brayne focuses on how and why data is used in the department. Three observations stand out: First, the increasing reliance on private companies to collect and analyze data, free of the constitutional and other constraints on government agencies. Brayne was drawn to the LAPD in part because it was an early user of software from Palantir (which WIRED chronicled here and here). Second, how much of “predictive policing” is a feedback loop based on unseen inputs. One LAPD system encouraged officers to prioritize chronic offenders based on a point system; each interaction with an officer added a point, making it more likely a person will be stopped repeatedly. And third, officers’ unease when the data lens is reversed and turned on them, as with software to monitor their “productivity.” With occasional lapses, Brayne mostly steers clear of academic jargon. Her field experience helps. After arresting a teenager in front of his mother, an officer tells Brayne, who remained in the patrol car, that the mother had “asked whether I was his daughter and if it was take-your-kid-to-work day.” Her prescriptions in a final chapter are somewhat unsurprising, but just might prompt the necessary reflection. —Scott Thurm$21 at Amazon$28 at Bookshop.orgMost PopularThe Big StoryPriscila, Queen of the Rideshare MafiaLauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingDavid Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsSimon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionDavid Gilbert, WIREDCourtesy of FSG OriginalsVoices From the Valley: Tech Workers Talk About What They Do—and How They Do Itby Ben Tarnoff and Moira WeigelLogic, the small and surprising technology magazine cofounded by Ben Tarnoff and Moira Weigel in 2016, consistently gives me more joy than any of my other (too many) subscriptions. So I was excited to get word of their new book, Voices From the Valley, an anonymized tell-all from the “people behind the platforms” in Silicon Valley. But I’ll fess up to some initial skepticism over the premise. Anonymity does not guarantee bracing honesty, and it often has the opposite effect, reducing people to caricatures of their roles: coder, founder, cafeteria worker. But Tarnoff and Weigel are skilled interviewers, able to coax ambling conversations centered on the small-talk-killing question “What do you do?” into odd and delightful directions. There’s the tech company cafeteria worker who describes watching past tech booms through a past life in irritation; business was good when the pastoral hinterlands of Silicon Valley were being transformed into tony lawns. A massage therapist, who worries about her hands after months of kneading the tensed backs of programmers (like “trying to soften up old meat”), talks about bringing her young, code-curious daughter to campus, only to experience a form of alienation, the source of which she cannot quite locate. I found myself wanting to read these people’s memoirs. They come alive, even in anonymity, and for Tarnoff and Weigel, that’s a sign of a job well done. —Gregory Barber$11 at Amazon$14 at Bookshop.orgCourtesy of University Of Minnesota PressDigitize and Punish: Racial Criminalization in the Digital Ageby Brian JeffersonA familiar metaphor for privacy is that it’s like climate change: many individual decisions made across the globe compounded into an unlivable yet unescapable environment. One person may “go green,” but there’s no escaping warming seas or toxic air. Similarly, one person may throw their smartphone out the window, but they’ll still be tracked by CCTV cameras, spy planes, even their own car. Brian Jefferson’s Digitize and Punish: Racial Criminalization in the Digital Age is a long gaze into New York City’s and Chicago’s “prisonized landscapes,” where policing technologies and surveillance are invisibly and inescapably embedded into the environment. Whether a person engages in criminal behavior is irrelevant: If they live in an area of heavy technological policing, they will be tagged, categorized, and surveilled.In dense historical analyses, Jefferson explains how long periods of disinvesting in these cities created an underclass that the tech industry volunteered to “manage” for the state. At the same time, grants from the Department of Homeland Security and the Department of Justice funded false promises of reform. Instead of social investment, cities turned to social management: software that can “predict” crime, body cameras that record citizens but not officers, gang databases that record everything from a person’s tattoos to whether they live near graffiti. Now, even innocuous sources of data, such as social media likes and Instagram photos, end up in police hands.And you’d never know. Jefferson pays special attention to both the immense secrecy of the New York and Chicago Police Departments and how the tech itself becomes part of the environment. But rather than reducing crime, these technologies have made more places into prisons. The unfailingly academic language of the book can make it difficult to parse at times, but it provides a sharp and specific look at how policing molded our digital and physical worlds. —Sidney Fussell$21 at Amazon$23 at Bookshop.orgMost PopularThe Big StoryPriscila, Queen of the Rideshare MafiaLauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingDavid Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsSimon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionDavid Gilbert, WIREDCourtesy of Belknap PressNew Laws of Robotics: Defending Human Expertise in the Age of AI by Frank PasqualeIsaac Asimov quickened dozens of short stories and half a dozen novels with Laws of Robotics that restricted his fictional machines while leaving enough loopholes for propulsive plots. Frank Pasquale’s New Laws of Robotics takes aim at the more mundane artificial intelligence technology of today and our immediate tomorrow, but with more ambition. He plots a future where technologies like factory robots, medical diagnosis algorithms, and online learning make society more just.Rather than just binding machines, Pasquale’s new laws aim to limit the humans who build and deploy them. He lays out four: that AI systems never pose as people; do not feed arms races for military or social control; augment professionals but don’t replace them; and always indicate the people who built, own, and control them.This form of robot law enforcement is about much more than computer code—Pasquale calls for a society-wide reengineering of policy, politics, economics, and labor relations to set technology on a more regulated and egalitarian path. He wants to reprogram the future of tech like classroom robots and online platforms with labor unions and regulatory agencies. That future can be harder to imagine than the overfamiliar outlines of standard tech utopias, which don’t much concern themselves with administrative law. But Pasquale makes a good case for injecting more bureaucracy into our techno-dreams, if we really want to make the world a better place. —Tom Simonite$30 at Amazon$28 at Bookshop.orgCourtesy of HurstThe Great Decoupling: China, America and the Struggle for Technological Supremacyby Nigel Inkster (available March 2021)To understand why the US and China are now locked on a collision course over artificial intelligence, semiconductors, 5G—and, yes, even TikTok—it is perhaps helpful to recall the last time one of these two superpowers lost its technological edge. By the end of the 18th century, China had invented gunpowder, paper, and the compass, but it remained isolated from the world and consequently came late to the industrial revolution. In The Great Decoupling, Nigel Inskter argues that the “Hundred Years of Humiliation” that China suffered as a result plays a profound role in its tech policies today. China’s leaders see a once-in-a-dynasty opportunity to retake the lead in emerging technologies—and reestablish the country’s rightful place at the center of the world order. Inkster, a former British intelligence officer and diplomat, offers clever insights on Chinese government thinking, a clear understanding of the technological forces at play, and interesting details of the country’s maneuvers.China’s rapid rise of course raises major concerns for Western democracies. But Inkster warns that decoupling it from Western technology, supply chains, and finances entirely carries big risks. Severing all ties would not only bring incredible costs, it might also slow the pace of technological progress itself. The Great Decoupling is a timely read for anyone eager to look beyond outdated, zero-sum thinking on China. And it delivers some much-needed caution about where history may now be taking us. —Will Knight$30 at Amazon$30 at Bookshop.orgTopicsShoppingBooksartificial intelligenceRead MoreYouTube’s Rulings on Gaza War Videos Spark Internal BacklashInsiders have shared YouTube’s playbook for handling the Gaza crisis. They argue that it shows inconsistent enforcement.Paresh DaveOpenAI Wants AI to Help Humans Train AIHaving humans rate a language model’s outputs produced clever chatbots. OpenAI says adding AI to the loop could help make them even smarter and more reliable.Will KnightActivists Disrupt Amazon Conference Over $1.2 Billion Contract With IsraelMembers of the activist group No Tech for Apartheid interrupted a senior Amazon executive's speech at a conference in Washington, DC, on Wednesday over the company's Project Nimbus cloud contract.Caroline HaskinsAirbnb’s Olympics Push Could Help It Win Over ParisParis officials have placed tough new restrictions on Airbnb rentals in recent years. The company is using the Olympics to try and win over locals and broaden its footprint in the iconic city.Amanda HooverAI Is Coming for Big Tech Jobs—but Not in the Way You ThinkCompanies aren’t replacing workers with AI yet. But they are sacrificing thousands of jobs in the race to further innovation in the technology.Amanda HooverBanks Are Finally Realizing What Climate Change Will Do to HousingExtreme weather threatens the investment value of many properties, but financing for climate mitigation efforts are only just getting going.Chris BaraniukAmazon Ramps Up Security to Head Off Project Nimbus ProtestsFormer Big Tech workers intended to disrupt Wednesday’s AWS Summit in New York to protest the company’s $1.2 billion contract with Israel.Caroline HaskinsThe EU Is Coming for X’s Paid Blue ChecksElon Musk’s paid blue-check system on X deceives users and can be abused by malicious actors, the European Union said today.Morgan Meaker",,True,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'position': 1, 'item': {'@type': 'Product', 'name': 'Driven: The Race to Create the Autonomous Car', 'brand': {'@type': 'Brand', 'name': ''}, 'url': 'https://www.wired.com/gallery/best-books-artificial-intelligence/#5fd3a3fd87a8763c22716fd1', 'image': ['https://media.wired.com/photos/5fd8096e1cb16225dc087f85/master/w_960,c_limit/Business-Book-Roundup-Driven.jpg'], 'description': '', 'offers': [{'@type': 'Offer', 'name': 'Driven: The Race to Create the Autonomous Car', 'price': '28', 'priceCurrency': 'USD', 'url': 'https://www.amazon.com/Driven-Race-Create-Autonomous-Car/dp/1501199439/', 'offeredBy': {'@type': 'Organization', 'name': 'Amazon'}}, {'@type': 'Offer', 'name': 'Driven: The Race to Create the Autonomous Car', 'price': '26', 'priceCurrency': 'USD', 'url': 'https://bookshop.org/books/driven-the-race-to-create-the-autonomous-car/9781501199431', 'offeredBy': {'@type': 'Organization', 'name': 'Bookshop.org'}}]}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 2, 'item': {'@type': 'Product', 'name': ' If Then: How the Simulmatics Corporation Invented the Future ', 'brand': {'@type': 'Brand', 'name': ''}, 'url': 'https://www.wired.com/gallery/best-books-artificial-intelligence/#5fd39f3aa0fb2b3f3ae20b17', 'image': ['https://media.wired.com/photos/5fd809fc55d4309f339343ba/master/w_960,c_limit/Business-Book-roundup-IfThen.jpg'], 'description': '', 'offers': [{'@type': 'Offer', 'name': ' If Then: How the Simulmatics Corporation Invented the Future ', 'price': '21', 'priceCurrency': 'USD', 'url': 'https://www.amazon.com/If-Then-Simulmatics-Corporation-Invented/dp/1631496107', 'offeredBy': {'@type': 'Organization', 'name': 'Amazon'}}, {'@type': 'Offer', 'name': ' If Then: How the Simulmatics Corporation Invented the Future ', 'price': '27', 'priceCurrency': 'USD', 'url': 'https://bookshop.org/books/if-then-how-the-simulmatics-corporation-invented-the-future/9781631496103', 'offeredBy': {'@type': 'Organization', 'name': 'Bookshop.org'}}]}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 3, 'item': {'@type': 'Product', 'name': 'The Hype Machine: How Social Media Disrupts Our Elections, Our Economy, and Our Health—and How We Must Adapt', 'brand': {'@type': 'Brand', 'name': ''}, 'url': 'https://www.wired.com/gallery/best-books-artificial-intelligence/#5fd3ba823388264383270e30', 'image': ['https://media.wired.com/photos/5fd80af595b129de00ff049a/master/w_960,c_limit/Business-book-roundup-hype-machine.jpg'], 'description': '', 'offers': [{'@type': 'Offer', 'name': 'The Hype Machine: How Social Media Disrupts Our Elections, Our Economy, and Our Health—and How We Must Adapt', 'price': '21', 'priceCurrency': 'USD', 'url': 'https://www.amazon.com/Hype-Machine-Disrupts-Elections-Health/dp/0525574514/', 'offeredBy': {'@type': 'Organization', 'name': 'Amazon'}}, {'@type': 'Offer', 'name': 'The Hype Machine: How Social Media Disrupts Our Elections, Our Economy, and Our Health—and How We Must Adapt', 'price': '26', 'priceCurrency': 'USD', 'url': 'https://bookshop.org/books/the-hype-machine-how-social-media-disrupts-our-elections-our-economy-and-our-health-and-how-we-must-adapt/9780525574514', 'offeredBy': {'@type': 'Organization', 'name': 'Bookshop.org'}}]}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 4, 'item': {'@type': 'Product', 'name': 'Predict and Surveil: Data, Discretion, and the Future of Policing', 'brand': {'@type': 'Brand', 'name': ''}, 'url': 'https://www.wired.com/gallery/best-books-artificial-intelligence/#5fd3ba0aabc24802fd286126', 'image': ['https://media.wired.com/photos/5fd80b4b00c45b72f4a68f46/master/w_960,c_limit/Business-Book-Roundup-Predict-and-Surveil-jacket.jpg'], 'description': '', 'offers': [{'@type': 'Offer', 'name': 'Predict and Surveil: Data, Discretion, and the Future of Policing', 'price': '21', 'priceCurrency': 'USD', 'url': 'https://www.amazon.com/Predict-Surveil-Discretion-Future-Policing/dp/0190684097/ref=sr_1_1?crid=F2W13TJIHUH2&dchild=1&keywords=predict+and+surveil&qid=1607711303&s=books&sprefix=predict+and+s%2Cstripbooks%2C230&sr=1-1', 'offeredBy': {'@type': 'Organization', 'name': 'Amazon'}}, {'@type': 'Offer', 'name': 'Predict and Surveil: Data, Discretion, and the Future of Policing', 'price': '28', 'priceCurrency': 'USD', 'url': 'https://bookshop.org/books/predict-and-surveil-data-discretion-and-the-future-of-policing/9780190684099', 'offeredBy': {'@type': 'Organization', 'name': 'Bookshop.org'}}]}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 5, 'item': {'@type': 'Product', 'name': 'Voices From the Valley: Tech Workers Talk About What They Do—and How They Do It', 'brand': {'@type': 'Brand', 'name': ''}, 'url': 'https://www.wired.com/gallery/best-books-artificial-intelligence/#5fd3bbc0efa5f68151a599ef', 'image': ['https://media.wired.com/photos/5fd80ba355d4309f339343bc/master/w_960,c_limit/Business-Book-Roundup-voices-valley.jpg'], 'description': '', 'offers': [{'@type': 'Offer', 'name': 'Voices From the Valley: Tech Workers Talk About What They Do—and How They Do It', 'price': '11', 'priceCurrency': 'USD', 'url': 'https://www.amazon.com/Voices-Valley-Workers-Do-Originals/dp/0374538670/', 'offeredBy': {'@type': 'Organization', 'name': 'Amazon'}}, {'@type': 'Offer', 'name': 'Voices From the Valley: Tech Workers Talk About What They Do—and How They Do It', 'price': '14', 'priceCurrency': 'USD', 'url': 'https://bookshop.org/books/voices-from-the-valley-tech-workers-talk-about-what-they-do-and-how-they-do-it/9780374538675', 'offeredBy': {'@type': 'Organization', 'name': 'Bookshop.org'}}]}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 6, 'item': {'@type': 'Product', 'name': 'Digitize and Punish: Racial Criminalization in the Digital Age', 'brand': {'@type': 'Brand', 'name': ''}, 'url': 'https://www.wired.com/gallery/best-books-artificial-intelligence/#5fd3bce6e34070c4339bc2a8', 'image': ['https://media.wired.com/photos/5fd80c0d9fef1b8d763c5f14/master/w_960,c_limit/Business-Book-Roundup-digitize-punish.jpg'], 'description': '', 'offers': [{'@type': 'Offer', 'name': 'Digitize and Punish: Racial Criminalization in the Digital Age', 'price': '21', 'priceCurrency': 'USD', 'url': 'https://www.amazon.com/Digitize-Punish-Racial-Criminalization-Digital/dp/1517909236/', 'offeredBy': {'@type': 'Organization', 'name': 'Amazon'}}, {'@type': 'Offer', 'name': 'Digitize and Punish: Racial Criminalization in the Digital Age', 'price': '23', 'priceCurrency': 'USD', 'url': 'https://bookshop.org/books/digitize-and-punish-racial-criminalization-in-the-digital-age/9781517909239', 'offeredBy': {'@type': 'Organization', 'name': 'Bookshop.org'}}]}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 7, 'item': {'@type': 'Product', 'name': 'New Laws of Robotics: Defending Human Expertise in the Age of AI ', 'brand': {'@type': 'Brand', 'name': ''}, 'url': 'https://www.wired.com/gallery/best-books-artificial-intelligence/#5fd3bc860974393cc0952bd0', 'image': ['https://media.wired.com/photos/5fd80c871cb16225dc087f89/master/w_960,c_limit/Business-book-roundup-new-laws-robotics.jpg'], 'description': '', 'offers': [{'@type': 'Offer', 'name': 'New Laws of Robotics: Defending Human Expertise in the Age of AI ', 'price': '30', 'priceCurrency': 'USD', 'url': 'https://www.amazon.com/New-Laws-Robotics-Defending-Expertise/dp/0674975227/ref=sr_1_2?dchild=1&keywords=New+Laws+of+Robotics%2C+by+Frank+Pasquale&qid=1607711873&s=books&sr=1-2', 'offeredBy': {'@type': 'Organization', 'name': 'Amazon'}}, {'@type': 'Offer', 'name': 'New Laws of Robotics: Defending Human Expertise in the Age of AI ', 'price': '28', 'priceCurrency': 'USD', 'url': 'https://bookshop.org/books/new-laws-of-robotics-defending-human-expertise-in-the-age-of-ai/9780674975224', 'offeredBy': {'@type': 'Organization', 'name': 'Bookshop.org'}}]}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 8, 'item': {'@type': 'Product', 'name': 'The Great Decoupling: China, America and the Struggle for Technological Supremacy', 'brand': {'@type': 'Brand', 'name': ''}, 'url': 'https://www.wired.com/gallery/best-books-artificial-intelligence/#5fd3a453abc24802fd286123', 'image': ['https://media.wired.com/photos/5fd80d0c36373159913df77f/master/w_960,c_limit/Business-book-roundup-great-decoupling.jpg'], 'description': '', 'offers': [{'@type': 'Offer', 'name': 'The Great Decoupling: China, America and the Struggle for Technological Supremacy', 'price': '30', 'priceCurrency': 'USD', 'url': 'https://www.amazon.com/Great-Decoupling-Struggle-Technological-Supremacy/dp/1787383830/ref=sr_1_1?dchild=1&keywords=The+Great+Decoupling%2C&qid=1607705712&s=books&sr=1-1', 'offeredBy': {'@type': 'Organization', 'name': 'Amazon'}}, {'@type': 'Offer', 'name': 'The Great Decoupling: China, America and the Struggle for Technological Supremacy', 'price': '30', 'priceCurrency': 'USD', 'url': 'https://bookshop.org/books/the-great-decoupling-china-america-and-the-struggle-for-technological-supremacy/9781787383838', 'offeredBy': {'@type': 'Organization', 'name': 'Bookshop.org'}}]}}]","Algorithms have crept into our feeds, streets, and workplaces. Here’s what WIRED staff are reading to understand what that means for the future.  +++lead-in-text
It’s no secret that we at WIRED are fascinated by artificial intelligence. But it’s also no secret that thorny, and sometimes unexpected, questions arise as automation and algorithms creep into new corners of life—transforming jobs, economies, and even the world order. Which is why this winter, we’re also fascinated by books that grapple with these very questions. How did algorithms become so influential in our politics? When will they become our chauffeurs? And how much should they really know about us? Written by historians, journalists, and researchers, each of these books examines a very different aspect of the world that has been or will be upended by the influence of artificial intelligence. So sink your teeth into the algorithmic issues that will define the decades to come.",,"{'@type': 'CreativeWork', 'name': 'WIRED'}","Algorithms have crept into our feeds, streets, and workplaces. Here’s what WIRED staff are reading to understand what that means for the future.",8.0,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPWh0dHBzOi8vd3d3LnhydG9kYXkuY29tL21peGVkLXJlYWxpdHkveHItbWFjaGluZS1sZWFybmluZy1haS_SAQA?oc=5,"XR, Machine Learning & AI: The Three Pillars of Future Enterprise? - XR Today",2020-12-14,XR Today,https://www.xrtoday.com,"XR Today covers Mixed Reality news including AI, Industry 4.0 and more.",N/A,"XR Today reports on the latest extended reality news from around the globe, including virtual reality, augmented reality and mixed reality.",N/A,https://schema.org,"[{'@type': 'Article', '@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/#article', 'isPartOf': {'@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/'}, 'author': {'name': 'Rebekah Carter', '@id': 'https://www.xrtoday.com/#/schema/person/90e7ebaad42d01d8949f421d46d3d49e'}, 'headline': 'XR, Machine Learning &#038; AI: The Three\xa0Pillars\xa0of Future\xa0Enterprise?', 'datePublished': '2020-12-14T06:10:00+00:00', 'dateModified': '2023-06-05T13:45:40+00:00', 'mainEntityOfPage': {'@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/'}, 'wordCount': 605, 'publisher': {'@id': 'https://www.xrtoday.com/#organization'}, 'image': {'@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/#primaryimage'}, 'thumbnailUrl': 'https://www.xrtoday.com/wp-content/uploads/2020/12/XR-AI-Machine-Learning.jpg', 'keywords': ['AI', 'Industry 4.0'], 'articleSection': ['Mixed Reality'], 'inLanguage': 'en-GB', 'copyrightYear': '2020', 'copyrightHolder': {'@id': 'https://www.xrtoday.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/', 'url': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/', 'name': 'XR, Machine Learning & AI: The Three\xa0Pillars\xa0of Future\xa0Enterprise? - XR Today', 'isPartOf': {'@id': 'https://www.xrtoday.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/#primaryimage'}, 'image': {'@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/#primaryimage'}, 'thumbnailUrl': 'https://www.xrtoday.com/wp-content/uploads/2020/12/XR-AI-Machine-Learning.jpg', 'datePublished': '2020-12-14T06:10:00+00:00', 'dateModified': '2023-06-05T13:45:40+00:00', 'description': 'XR Today covers Mixed Reality news including AI, Industry 4.0 and more.', 'breadcrumb': {'@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/#primaryimage', 'url': 'https://www.xrtoday.com/wp-content/uploads/2020/12/XR-AI-Machine-Learning.jpg', 'contentUrl': 'https://www.xrtoday.com/wp-content/uploads/2020/12/XR-AI-Machine-Learning.jpg', 'width': 850, 'height': 425, 'caption': 'XR AI Machine Learning'}, {'@type': 'BreadcrumbList', '@id': 'https://www.xrtoday.com/mixed-reality/xr-machine-learning-ai/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.xrtoday.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Mixed Reality'}]}, {'@type': 'WebSite', '@id': 'https://www.xrtoday.com/#website', 'url': 'https://www.xrtoday.com/', 'name': 'XR Today', 'description': 'Virtual reality, augmented reality, and mixed reality news', 'publisher': {'@id': 'https://www.xrtoday.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.xrtoday.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://www.xrtoday.com/#organization', 'name': 'XR Today', 'url': 'https://www.xrtoday.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.xrtoday.com/#/schema/logo/image/', 'url': '', 'contentUrl': '', 'caption': 'XR Today'}, 'image': {'@id': 'https://www.xrtoday.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/XRToday/', 'https://x.com/xrtoday', 'https://www.linkedin.com/company/xrtoday']}, {'@type': 'Person', '@id': 'https://www.xrtoday.com/#/schema/person/90e7ebaad42d01d8949f421d46d3d49e', 'name': 'Rebekah Carter', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.xrtoday.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/f52deb08bc37ec4a2ab225001195c7d8?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/f52deb08bc37ec4a2ab225001195c7d8?s=96&d=mm&r=g', 'caption': 'Rebekah Carter'}, 'sameAs': ['https://www.linkedin.com/in/rebekah-carter101/'], 'url': 'https://www.xrtoday.com/author/rebekahcarter231yahoo-co-uk/'}]",,,,,,,,,,,,,,N/A,N/A,"


XR, Machine Learning & AI: The Three Pillars of Future Enterprise?
An inside look at the three technologies that are transforming the business world 











 3




 


Mixed RealityLatest News 

Published: December 14, 2020





 Rebekah Carter



Extended reality or “XR” is just one of the many disruptive tools changing the way that we innovate and interact. It appears alongside artificial intelligence and machine learning as one of the exciting new opportunities of a digital future.Companies worldwide have already began increasing their spend on new opportunities in extended reality, AI, IoT, and countless other environments. However, the rise of the global pandemic in 2020 drove even greater demand for these new solutions.Machine learning, AI and XR could quickly become the pillars of a more connected, informed, and creative enterprise. Although all of these tools have value as separate components, they can also become even more impressive when combined. Artificial intelligence powered extended reality experiences could open the door to a new world of work and innovation.How AI and XR Change the EnterpriseExtended reality could be a powerful tool in the way that the enterprise works. For instance, with extended reality solutions, teams could work together on building new products and protypes in a virtual environment, without wasting resources. Using AI technology, it could be possible to determine which solutions really work using information from previous tests and data.Extended reality opportunities could also be excellent for the digital transformation of employee training. For instance, in the healthcare environment, an augmented reality solution could help students to see more information and get a better look at a procedure when they’re watching a surgery. Virtual reality could help teams to test out medical procedures without risking someone’s safety. All the while, AI and machine learning algorithms can determine which procedures students need the most help with.Extended reality is even erasing the distance between team members so that people can work more effectively together despite geographical distance. Teams can interact wherever they are, using virtual reality as a shared space for innovation. Artificial intelligence could be a helpful assistant in these environments, automatically bringing up information and projects whenever keywords are mentioned.



All the while, with machine learning algorithms, your virtual, mixed, and augmented reality tools will have the potential to grow and become more intelligent over time. The more data you collect through extended reality interactions, the more your devices and software will evolve, learning the context and details of your company’s specific situations.Making Experiences More IntelligentArtificial intelligence and machine learning are crucial tools in making extended reality a more realistic opportunity for everyone. Through intelligent systems, it’s easier for software to track things like gestures, and eye movements that could make augmented and mixed reality environments more immersive. Artificial intelligence could also be the key to things like holographic images that may create a new future for collaboration.Many extended reality solutions ship with artificial intelligence elements already built in, such as computer vision for tracking visual information and speech recognition. AI can even help employees in any environment by gathering information and making contextual decisions of which content needs to appear in specific circumstances. One of the most popular cases for augmented reality and smart glasses looks at the potential of an expert to guide a professional using an AR headset. However, the expert offering guidance may not have to be human.Artificial intelligence could create useful virtual workers who can assist employees in all environments by responding to the visual information and verbal demands of an employee. These tools are much faster than human beings at collecting valuable data and transforming it into efficient actions and suggestions.The future may not be in just different realities, but more intelligent realities too. 


AIIndustry 4.0 
",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHA6Ly9yZXNlYXJjaC5nb29nbGUvYmxvZy9wcml2YWN5LWNvbnNpZGVyYXRpb25zLWluLWxhcmdlLWxhbmd1YWdlLW1vZGVscy_SAQA?oc=5,Privacy Considerations in Large Language Models - Google Research,2020-12-15,Google Research,http://research.google,"Posted by Nicholas Carlini, Research Scientist, Google Research Machine learning-based language models trained to predict the next word in a senten...","Security and Privacy,Machine Learning","Posted by Nicholas Carlini, Research Scientist, Google Research Machine learning-based language models trained to predict the next word in a senten...",N/A,,,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiiQFodHRwczovL3d3dy5hZi5taWwvTmV3cy9BcnRpY2xlLURpc3BsYXkvQXJ0aWNsZS8yNDQ4Mzc2L2FpLWNvcGlsb3QtYWlyLWZvcmNlLWFjaGlldmVzLWZpcnN0LW1pbGl0YXJ5LWZsaWdodC13aXRoLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,AI Copilot: Air Force achieves first military flight with artificial intelligence - Air Force Link,2020-12-16,Air Force Link,https://www.af.mil,N/A,N/A,"Signaling a major leap forward for national defense in the digital age, the Air Force flew with artificial intelligence as a working aircrew member onboard a military aircraft for the first time Dec.","Signaling a major leap forward for national defense in the digital age, the Air Force flew with artificial intelligence as a working aircrew member onboard a military aircraft for the first time Dec.",http://schema.org,,Organization,,https://www.af.mil/,,,,,,,,,,,N/A,N/A,"

AI Copilot: Air Force achieves first military flight with artificial intelligence












Published Dec. 16, 2020
Secretary of the Air Force Public Affairs


BEALE AIR FORCE BASE, Calif. (AFNS) --  Signaling a major leap forward for national defense in the digital age, the Air Force flew with artificial intelligence as a working aircrew member onboard a military aircraft for the first time Dec. 15.

The AI algorithm, known as ARTUµ, flew with the pilot, U.S. Air Force Maj. “Vudu”, on a U-2 Dragon Lady assigned to the 9th Reconnaissance Wing at Beale Air Force Base. Air Combat Command’s U-2 Federal Laboratory researchers developed ARTUµ and trained it to execute specific in-flight tasks that otherwise would be done by the pilot.

The test flight was the result of years of concerted effort within the Air Force to apply cutting-edge technology to military operations as it competes with other world powers in the digital age.

“ARTUµ’s groundbreaking flight culminates our three-year journey to becoming a digital force,” said Dr. William Roper, assistant secretary of the Air Force for acquisition, technology and logistics. “Putting AI safely in command of a U.S. military system for the first time ushers in a new age of human-machine teaming and algorithmic competition. Failing to realize AI’s full potential will mean ceding decision advantage to our adversaries.”

During this flight, ARTUµ was responsible for sensor employment and tactical navigation, while the pilot flew the aircraft and coordinated with the AI on sensor operation. Together, they flew a reconnaissance mission during a simulated missile strike. ARTUµ’s primary responsibility was finding enemy launchers while the pilot was on the lookout for threatening aircraft, both sharing the U-2’s radar.

The flight was part of a precisely constructed scenario which pitted the AI against another dynamic computer algorithm in order to prove the new technology.

“We know that in order to fight and win in a future conflict with a peer adversary, we must have a decisive digital advantage,” said Air Force Chief of Staff Gen. Charles Q. Brown, Jr. “AI will play a critical role in achieving that edge, so I’m incredibly proud of what the team accomplished. We must accelerate change and that only happens when our Airmen push the limits of what we thought was possible.”

After takeoff, the sensor control was positively handed-off to ARTUµ who then manipulated the sensor, based on insight previously learned from over a half-million computer simulated training iterations. The pilot and AI successfully teamed to share the sensor and achieve the mission objectives.

The U-2 Federal Laboratory designed this AI technology to be easily transferable to other systems and plan to further refine the technology. Today’s flight provided invaluable data for not only the team to learn from, but also ARTUµ.

“Blending expertise of a pilot with capabilities of machine learning, this historic flight directly answers the National Defense Strategy’s call to invest in autonomous systems,” said Secretary of the Air Force Barbara Barrett. “Innovations in artificial intelligence will transform both the air and space domains.”

The U-2 Federal Laboratory is a 15 U.S.C. compliant organization established to bring together a “confluence of warfighter, developer, and acquirer” vertically-integrated under the same operational roof. The lab has developed and been approved by the National Institute of Standards and Technology to establish the 20th Laboratory Accreditation Program in the federal government. It promotes “edge development” – a concept to develop new software integration on operational systems in a bounded, safe environment.

The historic flight with AI comes just two months after the U-2 Federal Laboratory team updated inflight software for the first time during a U-2 training mission. The team leveraged the open-source container-orchestration software Kubernetes, another military first.
 
 


FS
USAF
AF
Air Force
Beale AFB
AI
artificial intelligence
9th Reconnaissance Wing
Air Combat Command
innovation
SAF
SecAF
Secretary of the Air Force
Barbara Barrett
U-2
Dragon Lady
CSAF
Air Force Chief of Staff
Gen. Charles Q. Brown Jr.

",Air Force,,,,,,,,,"['http://www.facebook.com/Usairforce', 'http://twitter.com/usairforce', 'http://instagram.com/officialusairforce', 'http://www.youtube.com/afbluetube']",,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvdG9tdGF1bGxpLzIwMjAvMTIvMTIvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWktd2hhdHMtaW4tc3RvcmUtZm9yLTIwMjEv0gEA?oc=5,Artificial Intelligence (AI): What's In Store For 2021? - Forbes,2020-12-12,Forbes,https://www.forbes.com,"As seen with this week’s hugely successful IPO of C3.ai, there continues to be lots of interest in the AI space. ",,"As seen with this week’s hugely successful IPO of C3.ai, there continues to be lots of interest in the AI space. ","As seen with this week’s hugely successful IPO of C3.ai, there continues to be lots of interest in the AI space. ",http://schema.org,,BreadcrumbList,Artificial Intelligence (AI): What’s In Store For 2021?,https://www.forbes.com/sites/tomtaulli/2020/12/12/artificial-intelligence-ai-whats-in-store-for-2021/,,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5fd56a42e4afaed9fb21cb62/0x0.jpg?format=jpg&crop=5700,3207,x0,y162,safe&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",Entrepreneurs,"{'@type': 'Person', 'name': 'Tom Taulli', 'url': 'https://www.forbes.com/sites/tomtaulli/', 'description': 'Tom (@ttaulli) is the author of Artificial Intelligence Basics: A Non-Technical Introduction ( https://amzn.to/2InAZeT) and The Robotic Process Automation Handbook: A Guide to Implementing RPA Systems ( https://amzn.to/2tURWJx)', 'sameAs': ['https://www.linkedin.com/in/tomtaulli', 'https://www.twitter.com/ttaulli', 'http://www.taulli.com/', 'ttaulli']}",,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2020-12-12T20:45:17-05:00,2020-12-14T13:35:46-05:00,Entrepreneurs,N/A,"More From ForbesJul 17, 2024,09:52am EDTThe How, When And Why Of A RebrandingJul 17, 2024,08:00am EDT5 ChatGPT Prompts To Apply Alex Hormozi’s Business Advice (Win Bigger)Jul 17, 2024,05:23am EDTFunding Under Fire: The Resilience Of Israeli TechJul 17, 2024,03:00am EDTMeet Briefly Bio, The British Startup Aiming To Get Scientists SharingJul 16, 2024,08:00am EDTOpenAI’s 5 Levels Of ‘Super AI’ (AGI To Outperform Human Capability)Jul 16, 2024,07:00am EDTHuma Raises $80 Million As It Opens Up Its Digital Healthcare PlatformJul 16, 2024,05:47am EDTHarnessing Design For Sustainable Business PracticesEdit StoryForbesSmall BusinessEntrepreneursArtificial Intelligence (AI): What’s In Store For 2021?Tom TaulliFormer ContributorOpinions expressed by Forbes Contributors are their own.I write about tech & finance.Click to save this article.You'll be asked to sign into your Forbes account.Got itDec 12, 2020,08:45pm ESTUpdated Dec 14, 2020, 01:35pm ESTThis article is more than 3 years old.Share to FacebookShare to TwitterShare to LinkedinSide face of AI robot network with data.getty
This was a banner week for AI (Artificial Intelligence). The reason? Well, C3.ai came public and soared on its debut. It’s certainly a validation of the importance of enterprise AI. Keep in mind that C3.ai provides comprehensive software solutions and services for a myriad of large companies, including 3M, Royal Dutch Shell, Raytheon, Baker Hughes and conEdison.


“The use of AI and data analytics will become increasingly important in IT as organizations aim to deliver seamless support and predictive capabilities,” said Amit Sawhney, who is the Vice President of Services Operations at Dell Technologies.

So then, given all the investment and innovation, what might we see next year with AI? As should be no surprise, there is quite a bit. So let’s take a look:

Sri Viswanath, the Chief Technology Officer of Atlassian:

PROMOTED
“In the next 5 years, increased data and privacy regulation will have a big impact on the way we design AI/ML models. As a result, investment in data management is going to be critical in determining the success of AI systems. Companies that have better data management frameworks, platforms and systems will win in building effective AI tools.”
Anand Rao, the Global Artificial Intelligence Lead at PwC: 
MORE FOR YOUFather Of Suspected Trump Gunman Was Profiled As Pro-Gun Voter By Trump Campaign: What We Know About Thomas Matthew Crooks‘The Acolyte’ Episode 8 Recap And Review: A Dreadful Season Finale And The Cameos Can’t Save ItAmazon Prime Day 2024: The 110 Best Deals Of Day Two So Far
“Our latest AI research shows 86% of businesses currently reaping the benefits of better customer experience through AI, and 25% of companies with widespread AI adoption expect to see the tech pay out in increased revenue during 2021.  The pandemic has uncovered the value of AI, lending itself to enhancing tasks related to workforce planning, simulation modeling and demand projection.”









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Rohan Amin, the Chief Information Officer at Chase:


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
“In 2021, we will see more sophisticated applications of artificial intelligence and machine learning (AI/ML) across industries, including financial services. There will be greater integration of AI/ML models and capabilities into multiple business processes and operations to drive improved insights and better serve customers.”
Kimberly Nevala, the AI Strategic Advisor at SAS:
“AI adoption will continue to gain traction in 2021 with emphasis on decisions that are not at the mercy of seismic shifts resulting from the ongoing pandemic. The focus will remain on applying AI to automating and augmenting core business processes where the problem space is relatively stable and desired outcomes are well-bounded. While this may seem reactionary, this continues a 2020 trend in which AI adopters at all levels reported that enhancing existing products and services was their number one AI priority.”
Wilson Pang, the Chief Technology Officer at Appen:
“In 2021, we’ll see organizations moving past just acknowledging and ‘worrying’ about bias in AI and start to make more significant moves to solve for it–because it will be required. Specific teams and/or initiatives will be formed to combat all the concerns that fall under the umbrella of responsible AI, including everything from inherent bias in data to treating data trainers fairly.”
Muddu Sudhakar, the CEO and cofounder of Aisera: 
“We’ll see the collaboration wars between Zoom, Microsoft, and Salesforce.com/Slack. The winners will focus on being AI-first, which will enhance productivity and the user experience.”
Michael Berthold, the CEO and cofounder of KNIME:
""Because cloud and hybrid environments will become much more prevalent, data science will have to adapt. It will need to be conducted in a variety of environments and shared across them in order to maximize effectiveness.""
Steve Grobman, the Chief Technology Officer of McAfee:
“Advances in AI technologies, including generative adversarial networks, will make disinformation through fake content, such as deepfake videos and auto-generated social media posts, virtually indistinguishable from real content.” 
Ram Chakravarti, the Chief Technology Officer at BMC:
“In 2021 we will see the impacts of AI on today’s enterprise via pervasive intelligence. This will have significant effects on how companies approach enterprise automation as well as their basis for the growth strategy.”
Peter Reinhardt, the CEO and cofounder of Segment:
“Consumer companies, which tend to have more traffic and data than B2B businesses, will see the most (and quickest) improvement in their AI/ML applications, if they test with customers and iterate. While these use cases (e.g. content ranking) may not seem futuristic, they will drive meaningful business impact.”
Bill Scudder, the General Manager of AIoT Solutions at AspenTech:
“In 2021, we’ll see more industrial organizations increase investment in lowering the barriers to AI adoption by deploying targeted embedded Industrial AI applications that combine data science and AI with purpose-built software and domain expertise. This will be the key to overcome a lack of skills and drastically reduce the need for many data scientists.”
Scott Prevost, the Vice President of Engineering at Adobe Sensei:
“The most powerful application of AI will be the complement of human EQ with machine IQ–where human ingenuity will merge with the power of machines to enhance human creativity and intelligence (not replace it). AI is evolving from being another technology in one’s arsenal to a virtual ‘co-pilot’ that can help businesses achieve their goals faster and streamline consumer workflows.”
Clemens Mewald, the Director of Product Management of Machine Learning and Data Science at Databricks:
“We’ll see enterprise customers moving away from building their own machine learning platforms, recognizing that it’s not their core competency. They’ll realize that more value comes from applying ML to business problems versus spending the time to build and maintain the tools themselves.” 
Bob Friday, the Chief Technology Officer at Mist Systems, a Juniper Networks company:
“Cloud and AI will turn the customer support between both the enterprise and their customers / employees and between the enterprise and their infrastructure vendor upside down. With cloud AI, the vendor will let the enterprise customer know when there is a hardware or software problem. The days of arguing with their vendors on hardware and software problems are over.”
Michael Beckley, the Chief Technology Officer and cofounder of Appian:
“Software vendors and AI providers such as Google and AWS will continue to strip the complexities out of operationalizing AI by using low-code techniques. In 2021, the use of broadly-applicable and high-value use cases like AI-enabled Document Processing will become widespread.”
Jason Tan, the CEO of Sift:
“In 2021 we will see a marked increase in the number of lawsuits filed implicating artificial intelligence technologies. While we’ve seen high-profile suits brought against companies over the last few years, AI is simply more prevalent in our everyday lives. As an immature technology, we’re going to see AI systems make more (and new) mistakes that carry real human impact. When mistakes are made, consumers will take legal action.”
Tim Tully, the Senior Vice President and Chief Technology Officer at Splunk:
“More and more is happening at the edge, because we can do more and more computation as the hardware and software gets more sophisticated. Local processing reduces the latency of moving the data to the cloud to process, and you get the same results.”
Christine Boles, the Vice President of the IoT Group and General Manager of the Industrial Solutions Division at Intel:
“The pandemic has greatly accelerated the need for companies to complete their Industry 4.0 transformations with solutions that allow them to have more flexibility, visibility and efficiency in their operations. We’ll see an acceleration of adoption of solutions that help address that need, ranging from AI including machine learning, machine vision and advanced analytics.”
Dr. Rana el Kaliouby, the cofounder and CEO of Affectiva:
“Emotion AI software that can understand nuanced human emotions and complex cognitive states based on facial and vocal expression will address some of technology’s shortcomings in light of the pandemic, and we’ll see companies using it for new use cases.”
Rick Rider, who is the Vice President of Product Management at Infor:
“In the unpredictable job market of 2021, it will be critical for organizations to leverage AI to ensure they find the right candidate for the job. AI will enable HR departments to become more proactive in their hiring and help them determine a candidate’s cultural fit by using data to measure the quality of a hire.”
Richard Tomlison, the Senior Director of Product Marketing at DataRobot:
“In 2021 we expect budgets to be consolidated and organizations will be looking to minimize the number of AI software vendors they deal with. The market has moved from point solutions and towards full solutions with end-to-end value. It is no longer acceptable or even feasible to have multiple disparate products solving multiple disparate problems.”
Flavio Bonomi, the Board Advisor to Lynx Software Technologies:
“2021 is the year where AI will get embedded into existing devices and make certain functionality faster and more accurate as standard. Sensors can now detect any of the five senses (yes, including smell) and we will see AI increasingly applied to all of those. Examples include the ability to detect vibrations or unusual noises in a factory that ensures maintenance is performed on equipment prior to it malfunctioning. Not as sexy or as obvious as a self-driving vehicle, but practical and with a measurable ROI.”
Jason Shepherd, the Vice President of Ecosystems at ZEDEDA:
“The TinyML conversation that started heating up in late 2019 will reach full-on buzz in 2021. This means more on-device processing, including in smart cameras, and further realization by the telcos and traditional IT players that not all edge processing will happen in a data center.”
Jan Gilg, the President of SAP S/4HANA:
“In 2021, we will continue to see companies leverage data and intelligent technologies to realize smart, data-driven insights that they have never had access to before without a large-scale implementation.”
Dan Simion, the Vice President of AI and Analytics at Capgemini North America:
“In 2021, we will see an evolution of AI solutions to solve technical problems automatically and without human intervention. This self-healing mechanism will self-correct malfunctions proactively to keep critical applications operational and reduce the risk of systems shutting down.”
Tom (@ttaulli) is an advisor/board member to startups and the author of Artificial Intelligence Basics: A Non-Technical Introduction and The Robotic Process Automation Handbook: A Guide to Implementing RPA Systems. He also has developed various online courses, such as for the COBOL and Python programming languages.
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Tom TaulliTom (@ttaulli) is the author of Artificial Intelligence Basics: A Non-Technical Introduction ( https://amzn.to/2InAZeT) and The Robotic Process... Read MoreEditorial StandardsPrintReprints & PermissionsThe video player is currently playing an ad. You can skip the ad in 5 sec with a mouse or keyboard
1/100:23Miley Cyrus Explains Why Growing With Her Audience Means So Much To Her





Skip Ad
 
Continue watchingMiley Cyrus Explains Why Growing With Her Audience Means So Much To Herafter the adVisit Advertiser websiteGO TO PAGE",Artificial Intelligence (AI): What’s In Store For 2021?,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Small Business', 'item': 'https://www.forbes.com/small-business/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Entrepreneurs', 'item': 'https://www.forbes.com/entrepreneurs/'}]",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiNmh0dHBzOi8vYnVpbHRpbi5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvZW1vdGlvbi1hadIBAA?oc=5,Emotion AI: 3 Experts on the Possibilities and Risks - Built In,2020-12-14,Built In,https://builtin.com,Emotion AI is set to change how we interact with technology. Here are 3 experts on how it works and its applications.,N/A,Emotion AI is set to change how we interact with technology. Here are 3 experts on how it works and its applications.,Emotion AI is set to change how we interact with technology. Here are 3 experts on how it works and its applications.,https://schema.org,"[{'@context': 'https://schema.org', '@type': 'Article', 'headline': 'Emotion AI: 3 Experts on the Possibilities and Risks ', 'name': 'Emotion AI: 3 Experts on the Possibilities and Risks ', 'description': 'Emotion AI, also known as affective AI or affective computing, is a subset of artificial intelligence that analyzes, reacts to and simulates human emotions. Relying on natural language processing, sentiment analysis, voice emotion AI and facial movement analysis, emotion AI interprets human emotional signals coming from sources such as text, audio and video.', 'image': {'@type': 'ImageObject', 'url': 'https://builtin.com/sites/www.builtin.com/files/emotion-ai-header.png', 'representativeOfPage': True}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://builtin.com/artificial-intelligence/emotion-ai', 'name': 'Emotion AI: 3 Experts on the Possibilities and Risks ', 'lastReviewed': '2023-02-07T06:00:00+00:00'}, 'url': 'https://builtin.com/artificial-intelligence/emotion-ai', 'about': [{'@type': 'Thing', 'name': 'Data Science'}, {'@type': 'Thing', 'name': 'Artificial Intelligence'}], 'author': {'@type': 'Person', '@id': 'https://builtin.com/authors/stephen-gossett', 'name': 'Stephen Gossett', 'description': 'Stephen Gossett is a former Built In senior staff reporter covering technology trends, design, UX and data science. Prior to joining Built In, he was a digital editor at the design-focused Sixtysix Magazine, associate editor at the local news site Chicagoist and managing editor at the culture website Flavorpill. Gossett holds a bachelor’s degree in film studies from Webster University.\r\n', 'jobTitle': 'Senior Staff Reporter', 'url': 'https://builtin.com/authors/stephen-gossett', 'alumniOf': {'@type': 'Organization', 'name': 'Webster University'}, 'knowsAbout': 'Technology journalism'}, 'dateModified': '2023-02-07T06:00:00+00:00', 'datePublished': '2021-01-08T05:50:00+00:00', 'publisher': {'@type': 'Organization', '@id': 'https://builtin.com', 'name': 'Built In', 'url': 'https://builtin.com', 'sameAs': ['https://www.facebook.com/BuiltInHQ/', 'https://twitter.com/builtin', 'https://www.instagram.com/builtin/', 'https://www.linkedin.com/company/built-in'], 'brand': {'@type': 'Brand', 'name': 'Built In'}, 'logo': {'@type': 'ImageObject', 'url': 'https://static.builtin.com/dist/images/built-logo.png', 'representativeOfPage': True}}}]",,,,,,,,,,,,,,N/A,N/A,"



















Image: Shutterstock

UPDATED BY
Jessica Powers | Feb 07, 2023



Emotion AI, also known as affective AI or affective computing, is a subset of artificial intelligence that analyzes, reacts to and simulates human emotions. Relying on natural language processing, sentiment analysis, voice emotion AI and facial movement analysis, emotion AI interprets human emotional signals coming from sources such as text, audio and video.
What Is Emotion AI?Emotion AI refers to artificial intelligence that detects and interprets human emotional signals in text (using natural language processing and sentiment analysis), audio (using voice emotion AI), video (using facial movement analysis, gait analysis and physiological signals) or combinations thereof.

Emotional AI is surprisingly common. For instance, sentiment analysis is a tool sometimes found in industries like marketing, where it’s used for product review analysis and recommendation tailoring, as well as finance, where it can help forecast stock movements.
It’s also set to influence industries like healthcare, insurance, education and transportation. In the future, we may see emotion AI used to diagnose depression, detect insurance fraud, determine how a student is comprehending a lesson or assess a driver’s performance. 
The future of emotion AI technology is only growing brighter. The market size for emotion recognition is expected to jump 12.9 percent by 2027.
 
Advantages of Emotion AI
The benefits of emotion AI can vary from industry to industry, but it can provide marketers, advertisers, designers, engineers and developers with valuable feedback from consumers. 
Emotion AI can streamline user testing, consumer surveys and focus groups. 
Designers can use emotion AI to glean insights from consumer reactions to ad campaigns, prototypes and mockups, which can save them time and money. 
Emotion AI’s ability to capture and analyze human body language and emotions means that the products and services made with it will be more considerate of the user’s needs and feelings.
 
Disadvantages of Emotion AI
Despite all the use cases and potential for this type of AI, emotions are fuzzy — and applying some of these technologies to high-consequence situations can be deeply problematic. 
Emotion AI doesn’t give the full-picture of how someone is feeling. A notorious example is a hiring system that uses job candidates’ facial expressions and voice patterns to determine an “employability score.”
Like other forms of technology, emotion AI can display biases and inaccuracies. 
Consumers have to consent to being analyzed by emotion AI, which may present some privacy concerns. 
 
Types of Emotion AI
There are three main types of emotion AI: text-focused, voice-focused and video and multimodal emotion AI.
Text emotion AI analyzes the written word. For example, emotion AI can be used to analyze text in the form of online comments or news stories to determine if the content is generally positive or negative.
Audio and voice emotion AI analyzes human speech. This type of emotion AI can be used to assess and track customer service calls to determine both the vocal patterns of conversations and the content.
Video and multimodal emotion AI is used to process video signals ranging from eye movement to body language. 
To better understand emotion AI and how it works we spoke with four experts: Seth Grimes, the founder of Alta Plana and a natural language processing consultant; Ranal Gujral, CEO of Behavior Signals; Skyler Place, chief behavioral science officer of Cogito; and Daniel McDuff, a former principal researcher at Microsoft AI. Their thoughts, broken down by the different types of emotion AI, have been edited and condensed.
RelatedWhy GPT-3 Heralds a Democratic Revolution in Tech 
Text Emotion AI: NLP and Sentiment Analysis
Sentiment analysis refers to the application of natural language processing to text samples in order to determine whether the sentiments expressed are positive or negative, and to what degree. A common application is when companies use the technique to analyze posted reactions to their products or services.
 
How Does Text Emotion AI Work? 
Seth Grimes: A prevailing approach nowadays is using transfer learning for pre-trained models. There’s a huge pre-trained model, but then you do the so-called last-mile training, using your own data. By customizing it for your own uses, by doing that last-mile training, you get the accuracy that you want.
A company might have a solution for the hotel industry that contains a certain set of taxonomies. It understands that a hotel has rooms, service, a restaurant — it understands the structure of the thing being analyzed. But it doesn’t necessarily understand that, say, Hilton Hotels has certain branding, like the reward system is Hilton Honors, and so on. That kind of last-mile training used to be via customizing taxonomies and role sets. Nowadays, it’s transfer learning.




Find out who's hiring.
See all Data + Analytics jobs at top tech companies & startups



View 3894 Jobs



 
How Does Emotion AI Deal With Complexity? 
Grimes: [Sentiment analysis] is a little bit controversial still, because there are questions about accuracy and usability — whether numbers actually correspond to real-world sentiment. To give an indicator of the complexity, I use an image in my presentations of Kobe Bryant smiling on the basketball court. And I ask, “How does this make you feel?” Well, Kobe Bryant died a year ago in a tragic crash. So [just] because Kobe Bryant is smiling, that doesn’t make you happy. Maybe it’s sad, but sadness about someone who has died is actually a positive sentiment. There’s a lot of complexity and subjectivity.
Clarabridge is a good example [of the technology’s advancement]. They do sentiment analysis, and over the last few years, have moved into emotion categorizations. It can be simple, like happy, sad, angry, or it can be hierarchical with lots of categories — as opposed to just positive or negative. The initial refinement was [just] positive or negative, on a scale of -10 to 10, to capture intensity of feeling — where, for example, “I’m furious” is more intense than “I’m angry.”
 
How Accurate Is Text Emotion AI? 
Grimes: Accuracy in this world has two components: precision and recall. Precision — what’s your target? Are you trying to get the [overall] sentiment of a product review, either positive or negative? That’s imprecise. For instance, consider a positive review of a vacation stay. Well, what aspect? Did they like the room, the staff, dining options, location? So you get into what’s called aspect-based sentiment analysis. That’s much more precise [because] it’s more narrowly focused. You might have 99 percent accuracy deciding whether a review is positive or negative. But what’s really actionable is what the review is positive or negative about.

“Maybe it’s good that my phone is thin. But if someone says the sheets at a hotel were thin, that’s not good.”

A few years ago, companies really started creating much more narrowly focused models — a different model for restaurants versus hotels versus consumer electronics. For example, maybe it’s good that my phone is thin. But if someone says the sheets at a hotel were thin, that’s not good. So you get into the notion that a model should be industry-trained or -focused.
 
How Can Text Emotion AI Be Abused?
Grimes: Here’s a nightmare scenario for text: Maybe we can detect from what a person has written online or to [a text-based crisis line] that they might be suicidal. Well, what if their health insurer got ahold of that information? Or a car insurer takes facial codings from within a car and says: “That person is driving angry; I’m going to raise his rates, because he’s more likely to get into an accident.” Whether these are misuses or not depends on your perspective, but they are potential uses that people are not expecting of emotion data, and they’re potential abuses.
RelatedHealthcare Is Ailing. AI Can Help. 
Audio and Voice Emotion AI
Companies like Behavioral Signals and Cogito develop voice emotion AI for call-center environments. This technology can be used to provide real-time feedback to representatives or find the best match between agents and the people they call. In some cases, audio emotion AI can analyze vocal information and determine the tone of speakers as well as the content of conversations.
 
How Does Audio and Voice Emotion AI Work? 
Skyler Place: The market historically has focused on natural language processing and sentiment analysis — and the technology to support NLP accuracy continues to improve. In parallel, there have been organizations, Cogito included, focused on what we call the honest signals, which are everything in the conversation besides the words — energy in the voice, pauses, intonation, the whole variety of signals that help us understand the intentions, goals and emotions that people have in conversations — a very, very rich signal of information.
What we’re starting to see for the first time is the melding of these two data streams. I think that’s going to be the technological leap forward —  the ability to really combine the understanding of NLP with the honest signals — that’s going to give us a novel way to understand and improve the emotion in conversations as we go forward.
We have about 200 different signals that we utilize to recognize these behaviors. And then we link the behaviors to the outcomes that are valuable for [call-center] calls. That’s how we think about emotion — less about pure recognition, more about understanding the behaviors that allow you to not just measure, but influence, the emotions in an interaction.
 
How Do Cultural Differences Affect Voice Emotion AI? 
Rana Gujral: For the most part, it’s a challenge to recalibrate the baseline. Take how we express excitement versus anger. They both potentially could be high-pitched, but there are subtle differences. And our brains are obviously very adept at identifying the difference between the two. Even if you’re watching a foreign-language movie without subtitles, you can tell if a character is angry or excited, just by tone. The question is, how do you codify that?
We found that, once you recalibrate that baseline for a new language data set, the variance from the baseline that identifies those specific signals is almost identical across all cultures. We just need 10 to 20 hours of data — a maximum of 50 hours of data — to recalibrate that baseline.
Place: It absolutely is an important issue, and it ties into the potential bias that you see in algorithms. With our approach, the system will work out of the box, because you have this ability to understand how people are speaking — we can measure whether you’re speaking English or Spanish, whether you’re in New York or the Deep South — but the contextual meaning of that speaking rate may be different. So what “good” is may be different, based on the goals of the conversation and the region that [speakers] are from. So we tackle this at a variety of different stages across the product life cycle.
First, when we build our data sets, we measure and account for some of these different variables, making sure we’re representing them in the data. Second, we have human annotators listen to calls and mark up, for example, if a person is speaking too quickly for a particular part of the call. We make sure we pick those individuals from a variety of backgrounds — different genders, ages, cultures, so that we aren’t just getting one perspective of what “good” is for a call.
When we deploy to a client, we go through a calibration period where we’ve listened to hundreds and thousands of calls for that particular culture and particular use case and confirm that the settings are appropriate. That gives an opportunity to turn the dials to make sure we haven’t deployed anything that’s going to be adverse.
 
How Does Voice Emotion AI Deal With Complexity? 
Gujral: Some attributes are super complex. There’s no system that can completely pinpoint sarcasm. But for the most part, you’re keying off on some essential interaction attributes.

“Some attributes are super complex. There’s no system that can completely pinpoint sarcasm.”

The essential emotions are very measurable — anger, happiness, sadness, frustration and neutrality. Then you’re looking at measuring positivity and arousal — which is a tone change — and behaviors like politeness, engagement, agitation. You can also build some KPIs using the specific domain data and metadata — like measuring quality of interaction or agent performance. They’re all built on these basic sorts of signals. We have quite a few signals. Some we do much more accurately than others. For anger, we can produce a high-90s percentage accuracy, then there are others that are a little bit harder, with more false reads.
 
How Can Voice Emotion AI Be Abused?
Gujral: Yale University professor Michael Krauss [noted] in a 2017 research paper that humans are actually really adept at masking emotions in our facial expressions. So I personally feel that implementations based on facial expressions are more problematic. The worst thing there can be for an AI implementation is an inaccurate or ineffective implementation.
I think there are lines that we need to draw. First is a line of privacy and choice. The consumer needs to be aware and willing to partake. That’s very important. And there are other moral boundaries. Last year, when we were fundraising, we had a regent from a private company that works on the behalf of a government agency in Europe — a friendly European country, but they work for defense systems — and they wanted to apply our intent models to immigration. And we said no. If a choice is going to be made on, say, visa overstay or immigration policies, which could be life-altering, we don’t want to go there. I’m not going to say our technology is not that accurate, but that’s a much higher bar.
RelatedInside the Crowdsourced Quest for Inclusive Voice AI 
What Are the Challenges for Voice Emotion AI?
Gujral: Data is always a key challenge — the more, the better, and quality matters tremendously. In a contact-center set-up, you’re sort of guaranteed high-quality data; it’s all recorded over professional recording equipment with channel separation and very little noise. But this year was interesting. We’ve seen an explosion in calls, but many have been poor quality, because oftentimes agents are working from home.
Place: A really interesting technical challenge is the synchrony of signals, which has to do a bit with computational load and the processing of different systems. Because we’re focused on real-time guidance, we’ve put an enormous amount of effort into low-latency code. What’s been interesting as we start to integrate the nonverbal signal computations with natural language processing, the [NLP] has a much longer delay. It takes more computational processing and more time to describe the words that are happening. How you build a product that can combine those two different signals in a way that’s both accurate, but also actionable and timely, is a really interesting design question, as well as a back end, data-pathways question.
 
Video and Multimodal Emotion AI
When emotional AI is used to analyze video, it can include facial expression analysis, but also things like gait analysis to glean certain physiological signals through video. Emotion AI can also be used to track eye movement by using  infrared eye-tracking cameras or webcams to map pupil movement or dilation as well as gaze time in response to various stimuli. Emotion AI that tracks eye movement records eye behavior and creates a heat to highlight what a viewer was drawn to while looking at a digital ad, video or website. In some cases, a person’s respiration and heart rate can be detected contactlessly using cameras.
 
How Does Video and Multimodal Emotion AI Work? 
Daniel McDuff: What’s made this possible is the investment in camera technology over the past 20 years — cameras that have high-quality sensors with low noise. Using a camera even with a simple signal-processing algorithm, if you analyze skin pixels, you can typically pull out a pulse signal and also detect respiration for a person who’s stationary.
But if you think about needing it to work when people are moving, maybe the lighting is changing, [plus] everyone has different skin pigmentation, facial hair — that’s where deep learning helps to make it more robust to all these sources of noise. The camera is sensitive enough to pick up the initial signal, but that often gets overwhelmed by different variations that are not related to physiological changes. Deep learning helps because it can do a very good job at these complex mappings.




Find out who's hiring.
See all Data + Analytics jobs at top tech companies & startups



View 3894 Jobs



 
How Do Cultural Differences Affect Video Emotion AI? 
McDuff: There are definitely differences across cultures. We see that in our own analyses of large-scale image data sets, but also in a lot of psychology research, both in self-reported data and in observational measurement.
However, those differences tend to be pretty small when compared to individual differences even within the same culture. For instance, my brother might be more expressive than me by quite a large margin even though we come from the same family. So there are large individual differences even within people from very similar backgrounds.

“There are definitely differences across cultures.... However, those differences tend to be pretty small when compared to individual differences even within the same culture.”

That doesn’t mean that understanding cultural differences isn’t interesting from a scientific and psychological perspective. But when it comes to modeling the data, ultimately that’s just one, in some cases quite small, source of variation, when there are many other large sources of variation — [situational] context, gender, background. The way you’re treated as you grow up influences how you behave, right? If people around you are not that expressive, you might end up not being that expressive.
Studying this is very interesting intellectually, but when it comes to actually putting [models] into practice, often I think the social context of the situation matters way more. If you can control for the context, then you can compare across cultures and see these differences. But if I take a video of someone doing karaoke in Japan and compare it to someone in an office in the United States, the Japanese person is going to seem super expressive. But that’s not really a fair comparison, right? Because the context is so different.
 
How Can Individuals Use Video Emotion AI? 
McDuff: Many applications at the moment look at group responses, [such as] measuring how much people smile when they watch an advertisement. They typically don’t do that for one individual; they do that for 30 or 40 individuals, then average the data. Marketing folk find that data useful, and they often combine it with self-reported and other data. That’s fine. But in that case, they’re not really interpreting each individual’s underlying experience that much. They’re looking at what’s observed on the face and using that as a quantitative measure of responses to the content.
But when you get into something like health, you’re often looking at individuals’ behaviors, trying to understand if what you’re observing are perhaps symptoms, or effects of a medication. For instance, you may have someone with Parkinson’s disease taking medication that controls tremors. Say you were using video to track how quickly the medication wears off. You need to personalize that because different individuals might have different magnitudes and manifestations. So understanding a group-level signal is not that useful, because you’re trying to target an individual.
Most of the applications I’m interested in do involve this personalization. If we’re tracking heart rate variability, we need to know your baseline. What’s abnormal for you might be totally normal for someone else. Understanding a population can be helpful in some cases, but you’re limited in what you can do.
 
How Far Are We From Meaningful, Positive Impact? 
McDuff: Fitbit already exposes stress metrics to the wearer, so you can see your heart-rate variability over time now. Whether you do that from a wearable or a camera or another device, that’s not a big leap. That’s just changing the sensor. The big leap is going from measurement to something that’s actually useful. With step counting, it’s easier because, say, if I only walked 1,000 steps, maybe tomorrow I’m prompted to go for a walk. But with stress, the intervention is a bit less clear.
I think we’re still a little bit away from moving from tracking toward the real utility. That could be several years because, as you get into these more complex things, like stress, personalization of the intervention is important. So we need to study how we can turn this tracking data — which I think is not exactly a solved problem, but there’s lots of data around us, so if we need data, that’s not usually the roadblock — turn it into insight that helps improve the utility that people get from the system.
 
How Can Video Emotion AI Be Abused? 
McDuff: There needs to be at least good solid evidence that these signals matter in the [given] context. That’s always the first thing I would look for when thinking about a solution.
Another important consideration is the population. AI is often used to automate, and often, the population it’s applied to tends to be vulnerable. If you’re applying for a job, you’re vulnerable. The company is in power because they can choose to hire you or not. The same could be said of children in a classroom — students are more vulnerable and their teachers. It’s important to think about whether the technology is being used in a way that benefits someone who already has more power and could potentially make the process less transparent and more difficult.

“AI is often used to automate, and often, the population it’s applied to tends to be vulnerable.”

Another example is exam proctoring. Now that everyone’s remote, people are using systems to check if people are cheating. Well, that’s problematic, because an algorithm just can’t detect all the nuances, right? And you could really harm someone by labeling them a cheat. That doesn’t seem like a well-thought-out solution — just applying machine learning to that problem.



",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LmNvZS5pbnQvZW4vd2ViL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLy0vLXRvd2FyZC1yZWd1bGF0aW9uLW9mLWFpLXN5c3RlbXMt0gEA?oc=5,Towards regulation of AI systems - Artificial Intelligence - Council of Europe,2020-12-14,Council of Europe,https://www.coe.int,Latest news of the Council of Europe's work related to AI,"newsroom,ai,central division dg1,dg1 human rights and rule of law,public,compulsory,general, news, ai, council of europe",Latest news of the Council of Europe's work related to AI, Strasbourg 14 December 2020,https://schema.org,,WebPage,Towards regulation of AI systems,,"{'@type': 'WebPage', '@id': 'https://www.coe.int/en/web/artificial-intelligence/-/-toward-regulation-of-ai-systems-'}",,"{'@type': 'ImageObject', 'url': 'https://www.coe.int/documents/40452431/53775047/CAHAI_PUB.png/7326ba19-18f8-1859-a216-79feaa5f93e7', 'height': 489, 'width': 870}",,"{'@type': 'Organization', 'name': 'Council of Europe'}",,"{'@type': 'Organization', 'name': 'Council of Europe', 'logo': {'@type': 'ImageObject', 'url': 'https://static.coe.int/pics/logos/desktop/logo-coe-google-news.png', 'width': 78, 'height': 60}}",2018-11-28,2020-12-14T18:05:00+00:00,2024-05-17,N/A,N/A,"

Strasbourg
14 December 2020


                Diminuer la taille du texte
            

                Augmenter la taille du texte
            

                Imprimer la page
            





The publication of the CAHAI “Towards regulation of AI systems” is now available online. Raising awareness among society about the state of art of AI as well as about the issues that this new “game changers” could bring, it is nowadays of outstanding importance. The publication aims to feed the ongoing reflections within the CAHAI on the analysis of the challenges arising from AI systems and possible regulatory responses.   
Its main purpose is to inform the reader of the progress of the work of the Ad Hoc Committee on Artificial Intelligence.
Moreover, it collects national perspectives of different observer States, from Israel, Japan and Mexico, to support the development of an international legal framework of artificial intelligence based on the standards established by the Council of Europe on human rights, democracy and the rule of law.
",News,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3LmhlYWx0aGNhcmVpdG5ld3MuY29tL25ld3MvdG9wLTEwLWFpLWFuZC1tYWNoaW5lLWxlYXJuaW5nLXN0b3JpZXMtMjAyMNIBAA?oc=5,Top 10 AI and machine learning stories of 2020 - Healthcare IT News,2020-12-14,Healthcare IT News,https://www.healthcareitnews.com,"Whether assessing vaccine safety and efficacy, assisting with X-ray readings or tracking communities' vulnerability to COVID-19, artificial intelligence has been put to work in new and innovative ways throughout the pandemic.",N/A,"Whether assessing vaccine safety and efficacy, assisting with X-ray readings or tracking communities' vulnerability to COVID-19, artificial intelligence has been put to work in new and innovative ways throughout the pandemic.","Whether assessing vaccine safety and efficacy, assisting with X-ray readings or tracking communities' vulnerability to COVID-19, artificial intelligence has been put to work in new and innovative",,,,,,,,,,,,,,,,N/A,N/A,"
HIMSS24 EUROPEAN HEALTH CONFERENCE & EXHIBITIONBetter patient outcomes and stronger workforces are a team project. At HIMSS24 Europe, we’ve built a programme to arm you and your peers with the insights you need to transform health systems back at home.May 29-31, 2024 | RomeLearn More ",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS9idXNpbmVzcy8yMDIwLzEyLzE2L2Fpci1mb3JjZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,Air Force uses artificial intelligence on U-2 Dragon Lady spy plane - The Washington Post,2020-12-16,The Washington Post,https://www.washingtonpost.com,Officials described the test flight as a step toward the eventual use of human-AI teaming in military aircraft.,"Air Force, U2, artificial intelligence, spy plane, Roper, AI",Officials described the test flight as a step toward the eventual use of human-AI teaming in military aircraft.,Officials described the test flight as a step toward the eventual use of human-AI teaming in military aircraft.,https://schema.org,,BreadcrumbList,"In a first, Air Force uses AI on military jet",,https://www.washingtonpost.com/business/2020/12/16/air-force-artificial-intelligence/,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/76KO3XRVYFEXTG4BLXBONIQWZQ.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/76KO3XRVYFEXTG4BLXBONIQWZQ.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/76KO3XRVYFEXTG4BLXBONIQWZQ.jpg&w=800&h=600', 'height': 800, 'width': 600}]",,"{'@type': 'Person', 'name': 'Aaron Gregg', 'url': 'https://www.washingtonpost.com/people/aaron-gregg/'}",,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}",,2020-12-16T13:34:39.895Z,2022-04-08T16:25:41.193Z,Business,N/A,"A U-2 Dragon Lady spy plane prepares for takeoff July 31 at Beale Air Force Base in California. (Airman 1st Class Luis A. Ruiz-Vazquez/Air Force) By  Aaron GreggDecember 16, 2020 at 8:34 a.m. ESTThe Air Force allowed an artificial-intelligence algorithm to control sensor and navigation systems on a U-2 Dragon Lady spy plane in a training flight Tuesday, officials said, marking the first known use of AI onboard a U.S. military aircraft.Get a curated selection of 10 of our best stories in your inbox every weekend.No weapons were involved, and the plane was steered by a pilot. Even so, senior defense officials touted the test as a watershed moment in the Defense Department’s attempts to incorporate AI into military aircraft, a subject that is of intense debate in aviation and arms control communities.“This is the first time this has ever happened,” said Assistant Air Force Secretary Will Roper.Former Google chief executive Eric Schmidt, who previously headed the Pentagon’s Defense Innovation Board, described Tuesday’s flight test as “the first time, to my knowledge, that you have a military system integrating AI, probably in any military.”AdvertisementStory continues below advertisementThe AI system was deliberately designed without a manual override to “provoke thought and learning in the test environment,” Air Force spokesman Josh Benedetti said in an email.It was relegated to highly specific tasks and walled off from the plane’s flight controls, according to people involved in the flight test.“For the most part, I was still very much the pilot in command,” the U-2 pilot who carried out Tuesday’s test told The Washington Post in an interview.The pilot spoke on the condition of anonymity because of the sensitive nature of his work. The Air Force later released photos from shortly before the test flight with materials that referenced only his call sign: “Vudu.”Story continues below advertisement“[The AI’s] role was very narrow … but, for the tasks the AI was presented with, it performed well,” the pilot said.Air Force seeks a radical shift in how jets, missiles and satellites are designedThe two-and-a-half-hour test was performed in a routine training mission at Beale Air Force Base, near Marysville, Calif., starting Tuesday morning. Air Force officials and the U-2 pilot declined to offer details about the specific tasks performed by the AI, except that it was put in charge of the plane’s radar sensors and tactical navigation.AdvertisementRoper said the AI was trained against an opposing computer to look for oncoming missiles and missile launchers. For the purposes of the initial test flight, the AI got the final vote on where to direct the plane’s sensors, he said.Story continues below advertisementThe point is to move the Air Force closer to the concept of “man and machine teaming,” in which robots are responsible for limited technical tasks while humans remain in control of life-or-death decisions like flight control and targeting.Share this articleShare“This is really meant to shock the Air Force and the [Defense] Department as a whole into how seriously we need to treat AI teaming,” Roper said in an interview shortly before the test.The AI “is not merely part of the system. … We’re logging it in the pilot registry,” he said.Pentagon advisory board releases principles for ethical use of artificial intelligence in warfareThe AI itself, dubbed ARTUµ in an apparent Star Wars reference, is based on open-source software algorithms and adapted to the plane’s computer systems at the U-2 Federal Laboratory.AdvertisementStory continues below advertisementIt is based on a publicly accessible algorithm called µZero, which was developed by the AI research company DeepMind to quickly master strategic games like Chess and Go, according to two officials familiar with its development. And it is enabled by a publicly available, Google-developed system called Kubernetes, which allows the AI software to be ported between the plane’s onboard computer systems and the cloud-based one it was developed on.On its face, the U-2 seems an unlikely candidate for AI-enabled flight. It was developed for the CIA in the early 1950s and used throughout the Cold War to conduct surveillance from staggeringly high altitudes of 60,000 or 70,000 feet. The planes were later procured by the Defense Department.Huawei tested AI software that could recognize Uighur minorities and alert police, report saysBut its surveillance function is one that has already incorporated the use of AI to analyze complex data. An Air Force program called Project Maven sought to rapidly analyze reams of drone footage in place of humans. Google famously declined to renew its Maven contract following an internal revolt from employees who didn’t want the company’s algorithms involved in warfare. The company later released a set of AI principles that disallowed the company’s algorithms from being used in any weapons system.AdvertisementStory continues below advertisementSchmidt, who led Google until 2011, said he believes it’s unlikely that the military will embrace fully autonomous weapons systems anytime soon. The problem, he says, is that it’s hard to demonstrate how an AI algorithm would perform in every possible scenario, including those in which human life is at stake.“If a human makes a mistake and kills civilians, it’s a tragedy. … If an autonomous system kills civilians, it’s more than a tragedy,” Schmidt said Tuesday in an interview.“No general is going to take the liability of a system where they’re not really sure it’s going to do what it says. That problem may be fixed in the next several decades but not in the next year,” he said.Share52 CommentsNewsletterWednesdaysThe Color of MoneyAdvice on how to save, spend and talk about your money for the short and long term from Michelle Singletary.Sign upSubscribe to comment and get the full experience. Choose your plan →",,False,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Business', 'position': 1, 'item': 'https://www.washingtonpost.com/business/'}]",,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}",Air Force uses artificial intelligence on U-2 Dragon Lady spy plane,,,,"{'@type': 'WebPageElement', 'cssSelector': '.meteredContent', 'isAccessibleForFree': False}",,,,,,,,,
https://news.google.com/rss/articles/CBMiTWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjAvMTIvMDkvdGVjaG5vbG9neS90aW1uaXQtZ2VicnUtZ29vZ2xlLXBpY2hhaS5odG1s0gEA?oc=5,Google Chief Apologizes for A.I. Researcher’s Dismissal - The New York Times,2020-12-14,The New York Times,https://www.nytimes.com,"The researcher, one of the company’s best-known Black female employees, said she was fired last week.",N/A,"The researcher, one of the company’s best-known Black female employees, said she was fired last week.","The researcher, one of the company’s best-known Black female employees, said she was fired last week.",https://schema.org,,NewsMediaOrganization,Google Chief Apologizes for A.I. Researcher’s Dismissal,https://www.nytimes.com/,https://www.nytimes.com/2020/12/09/technology/timnit-gebru-google-pichai.html,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/12/09/business/09GOOGLE1/09GOOGLE1-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2020/12/09/business/09GOOGLE1/09GOOGLE1-videoSixteenByNineJumbo1600.jpg', 'caption': 'The departure from Google of Timnit Gebru, one of its most prominent Black female employees, has set off a storm at the company.', 'creditText': ""Cody O'Loughlin for The New York Times""}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/12/09/business/09GOOGLE1/09GOOGLE1-superJumbo.jpg', 'height': 1365, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2020/12/09/business/09GOOGLE1/09GOOGLE1-superJumbo.jpg', 'caption': 'The departure from Google of Timnit Gebru, one of its most prominent Black female employees, has set off a storm at the company.', 'creditText': ""Cody O'Loughlin for The New York Times""}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2020/12/09/business/09GOOGLE1/09GOOGLE1-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2020/12/09/business/09GOOGLE1/09GOOGLE1-mediumSquareAt3X.jpg', 'caption': 'The departure from Google of Timnit Gebru, one of its most prominent Black female employees, has set off a storm at the company.', 'creditText': ""Cody O'Loughlin for The New York Times""}]",,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/daisuke-wakabayashi', 'name': 'Daisuke Wakabayashi'}]",,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,2020-12-09T21:32:42.000Z,2020-12-14T12:46:25.212Z,Technology,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTGoogle Chief Apologizes for A.I. Researcher’s DismissalThe researcher, one of the company’s best-known Black female employees, said she was fired last week.Share full articleRead in appThe departure from Google of Timnit Gebru, one of its most prominent Black female employees, has set off a storm at the company.Credit...Cody O'Loughlin for The New York TimesBy Daisuke WakabayashiPublished Dec. 9, 2020Updated Dec. 14, 2020Sign up for the Race/Related Newsletter  Join a deep and provocative exploration of race, identity and society with New York Times journalists.
 Get it sent to your inbox.Sundar Pichai, chief executive of Google’s parent company Alphabet, apologized for the departure of a prominent artificial intelligence researcher, whose exit has roiled the company’s work force and raised questions about its stated commitment to diversity and the responsible development of A.I. technology.In an email to employees on Wednesday, Mr. Pichai, however, stopped short of saying that the company was wrong in how it hastened the resignation of Timnit Gebru, who was a co-leader of Google’s Ethical A.I. team and one of its best-known Black female employees.Dr. Gebru said last week that the company fired her after she sent an email that criticized the company’s lack of progress in hiring women and minorities as well as biases built into its artificial intelligence technology. She said that she had demanded an explanation for why the company had told her to retract a paper that pinpointed flaws in a new breed of language technology, including a system built by Google that underpins the company’s search engine.She said that short of a transparent explanation or further discussion that she would resign after an appropriate amount of time. The company immediately accepted her statement as a resignation and cut her off from all company services and systems.AdvertisementSKIP ADVERTISEMENTColleagues have rallied to Dr. Gebru’s defense, saying that Google did not treat her fairly and that this incident was an example of how Black employees are often mistreated at the company.“I’ve heard the reaction to Dr. Gebru’s departure loud and clear: It seeded doubts and led some in our community to question their place at Google. I want to say how sorry I am for that, and I accept the responsibility of working to restore your trust,” Mr. Pichai wrote in an email viewed by The New York Times. Axios had reported about the email earlier.“We need to assess the circumstances that led to Dr. Gebru’s departure, examining where we could have improved and led a more respectful process,” he added. “We will begin a review of what happened to identify all the points where we can learn.”On Twitter, Dr. Gebru said Mr. Pichai’s email was not a true apology. “I see this as ‘I’m sorry for how it played out but I’m not sorry for what we did to her yet.’”The parting with Dr. Gebru is especially fraught for Google, because it involves two thorny subjects for the company — a lack of diversity in its work force and concerns about the dangerous consequences of artificial intelligence technology.AdvertisementSKIP ADVERTISEMENTDr. Gebru, who joined the company last year from Stanford, was vocal about the importance of the company’s efforts to hire and retain more women as well as Black employees, who currently account for less than 2 percent of the company’s work force. In addition, her research to examine the long-term implications of A.I. put her at odds with the company’s strategic goals of depending on artificial intelligence as the breakthrough technology to improve most, if not all, of its products.Last week, about 2,000 Google employees signed a petition protesting her dismissal from the company and demanding that executives within its research organization be more transparent about the circumstances of Dr. Gebru’s exit.On Monday, members of Google’s Ethical A.I. team published a post that disputed some of the company’s statements regarding her exit, including the company’s assertion that she resigned and was not fired.Jeff Dean, one of Google’s most senior executives who oversees the company’s A.I. research arm, met with a group of employees on Tuesday to explain what took place with Dr. Gebru, but many walked away from the meeting even more upset.Daisuke Wakabayashi covers technology from San Francisco. He covers Google and other companies. Previously, he spent eight years at The Wall Street Journal first as a foreign correspondent in Japan and then covering technology in San Francisco. More about Daisuke WakabayashiSee more on: Alphabet Inc.Share full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",The New York Times,False,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://en.wikipedia.org/wiki/The_New_York_Times,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",en,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18

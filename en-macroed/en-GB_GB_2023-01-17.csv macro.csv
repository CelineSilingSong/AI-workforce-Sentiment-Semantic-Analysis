URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,name,url,inLanguage,issn,potentialAction,@id,logo,sameAs,headline,alternativeHeadline,datePublished,dateModified,isAccessibleForFree,hasPart,publisher,mainEntityOfPage,image,author,articleSection,article:section,article:summary,article text,articleBody,isBasedOn,thumbnailUrl,isPartOf,itemListElement,@graph,speakable,dateCreated,identifier,creator,parentOrganization,publishingPrinciples,correctionsPolicy,contactPoint,about,contentLocation
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LnRoZWF0bGFudGljLmNvbS9pZGVhcy9hcmNoaXZlLzIwMjMvMDEvY2hhdGdwdC1haS1lY29ub215LWF1dG9tYXRpb24tam9icy82NzI3Njcv0gEA?oc=5,How ChatGPT Will Destabilize White-Collar Work - The Atlantic,2023-01-20,The Atlantic,https://www.theatlantic.com,No technology in modern memory has caused mass job loss among highly educated workers. Will generative AI be an exception?,"most extreme iteration, job market, restaurant guy, lot of white-collar work, customer-service inquiries, artificially intelligent content creator, quarter century, evidence sections of the Multistate Bar Examination, use of ChatGPT, pretty good paragraph, college-educated workers, restaurants’ customer-order history, technological change, machine tools, electric lights, use, business operations, small business, ChatGPT, latest developments, San Francisco, ChatGPT start, own life stories, Will ChatGPT, single technology, productivity stats, legal briefs, white-collar employment, technology, Rust Belt, tremendous amount of digital content, Matt Wampler, automated machine tool, grocery stores, first paragraph, AI-powered, economist Robert Gordon, Great Invention, Simple answers, creative AI, night shift, promotional materials, MIT professor David Autor, AI, investigative journalists, Chat Generative, technology experts, people, historical documents, extraordinary downside",No technology in modern memory has caused mass job loss among highly educated workers. Will generative AI be an exception?,N/A,https://schema.org,NewsArticle,The Atlantic,https://www.theatlantic.com/ideas/archive/2023/01/chatgpt-ai-economy-automation-jobs/672767/,en-US,1072-7825,"{'@type': 'SearchAction', 'target': 'https://www.theatlantic.com/search/?q={q}', 'query-input': 'required name=q'}",https://www.theatlantic.com/#publisher,"{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'url': 'https://cdn.theatlantic.com/assets/media/files/atlantic-logo--224x224.png'}","['https://www.facebook.com/TheAtlantic', 'https://twitter.com/theatlantic']",How ChatGPT Will Destabilize White-Collar Work,How ChatGPT Will Destabilize White-Collar Work,2023-01-20T11:00:00Z,2023-02-14T22:23:00Z,False,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article-content-body'}",{'@id': 'https://www.theatlantic.com/#publisher'},"{'@type': 'WebPage', '@id': 'https://www.theatlantic.com/ideas/archive/2023/01/chatgpt-ai-economy-automation-jobs/672767/'}","[{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 720}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 405}, 'url': 'https://cdn.theatlantic.com/thumbor/0bRqweg1l6PM3wkBCmS9r3Otylg=/0x0:4167x2344/720x405/media/img/mt/2023/01/AI_jobs-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'url': 'https://cdn.theatlantic.com/thumbor/afCVygx7petX5V5VjR198bdpMYo=/912x0:3256x2344/1080x1080/media/img/mt/2023/01/AI_jobs-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1200}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/3Akmdl6CotuURuwdUxX8GPVWEPo=/518x0:3643x2344/1200x900/media/img/mt/2023/01/AI_jobs-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1600}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/JFuPnq3qWM_YeGDVPOTXALIH33Q=/0x0:4167x2344/1600x900/media/img/mt/2023/01/AI_jobs-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 960}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/moXovF0rPxMFXn8RuPZ-oIPw1l0=/0x0:4167x2344/960x540/media/img/mt/2023/01/AI_jobs-1/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/r9EetjfkZYDMX3ShZb-A_-fUGM4=/912x0:3256x2344/540x540/media/img/mt/2023/01/AI_jobs-1/original.jpg'}]","[{'@type': 'Person', 'name': 'Annie Lowrey', 'sameAs': 'https://www.theatlantic.com/author/annie-lowrey/'}]",Ideas,Ideas,N/A,"IdeasHow ChatGPT Will Destabilize White-Collar WorkNo technology in modern memory has caused mass job loss among highly educated workers. Will generative AI be an exception?By Annie LowreyMichael Brennan; Getty; The AtlanticJanuary 20, 2023ShareSave Subscribe to Listen00:0010:22In the next five years, it is likely that AI will begin to reduce employment for college-educated workers. As the technology continues to advance, it will be able to perform tasks that were previously thought to require a high level of education and skill. This could lead to a displacement of workers in certain industries, as companies look to cut costs by automating processes. While it is difficult to predict the exact extent of this trend, it is clear that AI will have a significant impact on the job market for college-educated workers. It will be important for individuals to stay up to date on the latest developments in AI and to consider how their skills and expertise can be leveraged in a world where machines are increasingly able to perform many tasks.There you have it, I guess: ChatGPT is coming for my job and yours, according to ChatGPT itself. The artificially intelligent content creator, whose name is short for “Chat Generative Pre-trained Transformer,” was released two months ago by OpenAI, one of the country’s most influential artificial-intelligence research laboratories. The technology is, put simply, amazing. It generated that first paragraph instantly, working with this prompt: “Write a five-sentence paragraph in the style of The Atlantic about whether AI will begin to reduce employment for college-educated workers in the next five years.”To read this story, Sign in or start a subscription.CloseNever miss a story. Start your subscription.Uncompromising quality. Enduring impact. Your support ensures a bright future for independent journalism.Get StartedAlready have an account? Sign inAbout the AuthorAnnie Lowrey is a staff writer at The Atlantic.More StoriesAmericans Are Mad About All the Wrong CostsThe Future of Labor",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9jaGF0Z3B0LWdlbmVyYXRpdmUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVndWxhdGlvbi_SAQA?oc=5,ChatGPT Stole Your Work. So What Are You Going to Do? - WIRED,2023-01-20,WIRED,https://www.wired.com,"Creators need to pressure the courts, the market, and regulators before it’s too late.","['ideas', 'tech policy and law', 'content moderation', 'artificial intelligence', 'regulation', 'art', 'textaboveleftgridwidth', 'web']","Creators need to pressure the courts, the market, and regulators before it’s too late.","Creators need to pressure the courts, the market, and regulators before it’s too late.",https://schema.org/,BreadcrumbList,,https://www.wired.com/story/chatgpt-generative-artificial-intelligence-regulation/,,,,,,,ChatGPT Stole Your Work. So What Are You Going to Do?,"Creators need to pressure the courts, the market, and regulators before it’s too late.",2023-01-20T09:00:00.000-05:00,2023-01-20T09:00:00.000-05:00,True,,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/chatgpt-generative-artificial-intelligence-regulation/'}","['https://media.wired.com/photos/63c9d72b995aa119ba7ba924/16:9/w_1369,h_770,c_limit/ideas-chatgpt-ai-regulation-law.jpg', 'https://media.wired.com/photos/63c9d72b995aa119ba7ba924/4:3/w_1155,h_866,c_limit/ideas-chatgpt-ai-regulation-law.jpg', 'https://media.wired.com/photos/63c9d72b995aa119ba7ba924/1:1/w_1046,h_1046,c_limit/ideas-chatgpt-ai-regulation-law.jpg']","[{'@type': 'Person', 'name': 'Nick Vincent', 'sameAs': 'https://www.wired.com/author/nick-vincent/'}, {'@type': 'Person', 'name': 'Hanlin Li', 'sameAs': 'https://www.wired.com/author/hanlin-li/'}]",ideas,tags,N/A,"Nick Vincent Hanlin LiIdeasJan 20, 2023 9:00 AMChatGPT Stole Your Work. So What Are You Going to Do?Creators need to pressure the courts, the market, and regulators before it’s too late.Photo-illustration: WIRED Staff; Getty ImagesSave this storySaveSave this storySaveIf you’ve ever uploaded photos or art, written a review, “liked” content, answered a question on Reddit, contributed to open source code, or done any number of other activities online, you’ve done free work for tech companies, because downloading all this content from the web is how their AI systems learn about the world.SUBSCRIBESubscribe to WIRED and stay smart with more of your favorite Ideas writers.Tech companies know this, but they mask your contributions to their products with technical terms like “training data,” “unsupervised learning,” and “data exhaust” (and, of course, impenetrable “Terms of Use” documents). In fact, much of the innovation in AI over the past few years has been in ways to use more and more of your content for free. This is true for search engines like Google, social media sites like Instagram, AI research startups like OpenAI, and many other providers of intelligent technologies. This exploitative dynamic is particularly damaging when it comes to the new wave of generative AI programs like Dall-E and ChatGPT. Without your content, ChatGPT and all of its ilk simply would not exist. Many AI researchers think that your content is actually more important than what computer scientists are doing. Yet these intelligent technologies that exploit your labor are the very same technologies that are threatening to put you out of a job. It’s as if the AI system were going into your factory and stealing your machine. Featured VideoTiny Infrared Spy Cams Reveal How Pigs Are Really SlaughteredBut this dynamic also means that the users who generate data have a lot of power. Discussions over the use of sophisticated AI technologies often come from a place of powerlessness and the stance that AI companies will do what they want, and there’s little the public can do to shift the technology in a different direction. We are AI researchers, and our research suggests the public has a tremendous amount of “data leverage” that can be used to create an AI ecosystem that both generates amazing new technologies and shares the benefits of those technologies fairly with the people who created them. Data leverage can be deployed through at least four avenues: direct action (for instance, individuals banding together to withhold, “poison,” or redirect data), regulatory action (for instance, pushing for data protection policy and legal recognition of “data coalitions”), legal action (for instance, communities adopting new data-licensing regimes or pursuing a lawsuit), and market action (for instance, demanding large language models be trained only with data from consenting creators). Let’s start with direct action, which is a particularly exciting route because it can be done immediately. Because of generative AI systems’ reliance on web scraping, website owners could significantly disrupt the training data pipeline if they disallow or limit scraping by configuring their robots.txt file (a file that tells web crawlers which pages are off limit).AdvertisementLarge user-generated content sites like Wikipedia, StackOverflow, and Reddit are particularly important to generative AI systems, and they could prevent these systems from accessing their content in even stronger ways—for example, by blocking IP traffic and API access. According to Elon Musk, Twitter has recently done exactly this. Content producers should also take advantage of the opt-out mechanisms that are increasingly being provided by AI companies. For instance, programmers on GitHub can opt out of BigCode’s training data via a simple form. More generally, simply being vocal when content has been used without your consent has been somewhat effective. For example, major generative AI player Stability AI agreed to honor opt-out requests collected via haveibeentrained.com after a social media uproar. By engaging in public forms of action, as in the case of mass protest against AI art by artists, it may be possible to force companies to cease business activities that most of the public perceives as theft.Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenMedia companies, whose work is quite important to large language models (LLMs),  may also want to consider some of these ideas to restrict generative AI systems from accessing their own content, as these systems are currently getting their crown jewels for free (including, likely, this very op-ed). For instance, Ezra Klein mentioned in a recent podcast that ChatGPT is great at imitating him, probably because it downloaded a whole lot of his articles without asking him or his employer.Critically, time is also on the side of data creators: As new events occur in the world, art goes out of style, facts change, and new restaurants open, new data flows are necessary to support up-to-date systems. Without these flows, these systems will likely fail for many key applications.  By refusing to make new data available without compensation, data creators could also put pressure on companies to pay for access to it.On the regulatory side, lawmakers need to take action to protect what might be the largest theft of labor in history, and quickly. One of the best ways to do this is clarifying that “fair use” under copyright law does not allow for training a model on content without the content owner’s consent, at least for commercial purposes. Lawmakers around the world should also work on “anti-data-laundering” laws that make it clear that models trained on data without consent have to be retrained within a reasonable amount of time without the offending content. Much of this can build on existing frameworks in places like Europe and California, as well as the regulatory work being done to make sure news organizations get a share of the revenue they generate for social media platforms. There is also growing momentum for “data dividend” laws, which would redistribute the wealth generated by intelligent technologies. These can also help, assuming they avoid some key pitfalls.In addition, policymakers could help individual creators and data contributors come together to make demands. Specifically, supporting initiatives such as data cooperatives—organizations that make it easy for data contributors to coordinate and pool their power—could facilitate large-scale data strikes among creators and bring AI-using firms to the negotiating table. The courts also present ways for people to take back control of their content. While the courts work on clarifying interpretations of copyright law, there are many other options. LinkedIn has been successful at preventing people who scrape its website from continuing to do so through Terms of Use and contract law. Labor law may also provide an angle to empower data contributors. Historically, companies’ reliance on “volunteers” to operate their businesses have raised important questions about whether these companies violated the Fair Labor Standards Act, and these fights could serve as a blueprint. In the past, some volunteers have even reached legal settlements with companies that benefited from their work. There is also a critical role for the market here. If enough governments, institutions, and individuals demand “full-consent LLMs”—which pay creators for the content they use—companies will respond. This demand could be bolstered by successful lawsuits against organizations that use generative AI (in contrast to organizations that build the systems) without paying users. If applications built on top of AI models face lawsuits, there will be greater demand for AI systems that aren’t playing in the legal Wild West.Our lab’s research (and that of colleagues) also suggests something that surprised us: Many of the above actions should actually help generative AI companies. Without healthy content ecosystems, the content that generative AI technologies rely on to learn about the world will disappear. If no one goes to Reddit because they get answers from ChatGPT, how will ChatGPT learn from Reddit content? That will create significant challenges for these companies in a way that can be solved before they appear by supporting some of the above efforts.","Tech companies know this, but they mask your contributions to their products with technical terms like “training data,” “unsupervised learning,” and “data exhaust” (and, of course, impenetrable “Terms of Use” documents). In fact, much of the innovation in AI over the past few years has been in ways to use more and more of your content for free. This is true for search engines like Google, social media sites like Instagram, AI research startups like OpenAI, and many other providers of intelligent technologies.
This exploitative dynamic is particularly damaging when it comes to the new wave of generative AI programs like Dall-E and ChatGPT. Without your content, ChatGPT and all of its ilk simply would not exist. Many AI researchers think that your content is actually more important than what computer scientists are doing. Yet these intelligent technologies that exploit your labor are the very same technologies that are threatening to put you out of a job. It’s as if the AI system were going into your factory and stealing your machine.
But this dynamic also means that the users who generate data have a lot of power. Discussions over the use of sophisticated AI technologies often come from a place of powerlessness and the stance that AI companies will do what they want, and there’s little the public can do to shift the technology in a different direction. We are AI researchers, and our research suggests the public has a tremendous amount of “data leverage” that can be used to create an AI ecosystem that both generates amazing new technologies and shares the benefits of those technologies fairly with the people who created them.
Let’s start with direct action, which is a particularly exciting route because it can be done immediately. Because of generative AI systems’ reliance on web scraping, website owners could significantly disrupt the training data pipeline if they disallow or limit scraping by configuring their robots.txt file (a file that tells web crawlers which pages are off limit).
Large user-generated content sites like Wikipedia, StackOverflow, and Reddit are particularly important to generative AI systems, and they could prevent these systems from accessing their content in even stronger ways—for example, by blocking IP traffic and API access. According to Elon Musk, Twitter has recently done exactly this. Content producers should also take advantage of the opt-out mechanisms that are increasingly being provided by AI companies. For instance, programmers on GitHub can opt out of BigCode’s training data via a simple form. More generally, simply being vocal when content has been used without your consent has been somewhat effective. For example, major generative AI player Stability AI agreed to honor opt-out requests collected via haveibeentrained.com after a social media uproar. By engaging in public forms of action, as in the case of mass protest against AI art by artists, it may be possible to force companies to cease business activities that most of the public perceives as theft.
Media companies, whose work is quite important to large language models (LLMs),  may also want to consider some of these ideas to restrict generative AI systems from accessing their own content, as these systems are currently getting their crown jewels for free (including, likely, this very op-ed). For instance, Ezra Klein mentioned in a recent podcast that ChatGPT is great at imitating him, probably because it downloaded a whole lot of his articles without asking him or his employer.
Critically, time is also on the side of data creators: As new events occur in the world, art goes out of style, facts change, and new restaurants open, new data flows are necessary to support up-to-date systems. Without these flows, these systems will likely fail for many key applications.  By refusing to make new data available without compensation, data creators could also put pressure on companies to pay for access to it.
On the regulatory side, lawmakers need to take action to protect what might be the largest theft of labor in history, and quickly. One of the best ways to do this is clarifying that “fair use” under copyright law does not allow for training a model on content without the content owner’s consent, at least for commercial purposes. Lawmakers around the world should also work on “anti-data-laundering” laws that make it clear that models trained on data without consent have to be retrained within a reasonable amount of time without the offending content. Much of this can build on existing frameworks in places like Europe and California, as well as the regulatory work being done to make sure news organizations get a share of the revenue they generate for social media platforms. There is also growing momentum for “data dividend” laws, which would redistribute the wealth generated by intelligent technologies. These can also help, assuming they avoid some key pitfalls.
In addition, policymakers could help individual creators and data contributors come together to make demands. Specifically, supporting initiatives such as data cooperatives—organizations that make it easy for data contributors to coordinate and pool their power—could facilitate large-scale data strikes among creators and bring AI-using firms to the negotiating table.
The courts also present ways for people to take back control of their content. While the courts work on clarifying interpretations of copyright law, there are many other options. LinkedIn has been successful at preventing people who scrape its website from continuing to do so through Terms of Use and contract law. Labor law may also provide an angle to empower data contributors. Historically, companies’ reliance on “volunteers” to operate their businesses have raised important questions about whether these companies violated the Fair Labor Standards Act, and these fights could serve as a blueprint. In the past, some volunteers have even reached legal settlements with companies that benefited from their work.
There is also a critical role for the market here. If enough governments, institutions, and individuals demand “full-consent LLMs”—which pay creators for the content they use—companies will respond. This demand could be bolstered by successful lawsuits against organizations that use generative AI (in contrast to organizations that build the systems) without paying users. If applications built on top of AI models face lawsuits, there will be greater demand for AI systems that aren’t playing in the legal Wild West.
Our lab’s research (and that of colleagues) also suggests something that surprised us: Many of the above actions should actually help generative AI companies. Without healthy content ecosystems, the content that generative AI technologies rely on to learn about the world will disappear. If no one goes to Reddit because they get answers from ChatGPT, how will ChatGPT learn from Reddit content? That will create significant challenges for these companies in a way that can be solved before they appear by supporting some of the above efforts.",,"https://media.wired.com/photos/63c9d72b995aa119ba7ba924/2:3/w_558,h_837,c_limit/ideas-chatgpt-ai-regulation-law.jpg","{'@type': 'CreativeWork', 'name': 'WIRED'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Ideas', 'item': 'https://www.wired.com/ideas/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Tech Policy and Law', 'item': 'https://www.wired.com/tag/tech-policy-and-law/'}, {'@type': 'ListItem', 'position': 3, 'name': 'ChatGPT Stole Your Work. So What Are You Going to Do?'}]",,,,,,,,,,,
https://news.google.com/rss/articles/CBMiNmh0dHBzOi8vdGltZS5jb20vNjI0NzY3OC9vcGVuYWktY2hhdGdwdC1rZW55YS13b3JrZXJzL9IBAA?oc=5,OpenAI Used Kenyan Workers on Less Than $2 Per Hour: Exclusive | TIME - TIME,2023-01-18,TIME,https://time.com,OpenAI used outsourced workers in Kenya earning less than $2 per hour to scrub toxicity from ChatGPT. Here's what to know.,N/A,A TIME investigation reveals the difficult conditions faced by the workers who made ChatGPT possible,A TIME investigation reveals the difficult conditions faced by the workers who made ChatGPT possible,,,,,,,,,,,,,,,,,,,,,,N/A,N/A,"By Billy PerrigoJanuary 18, 2023 7:00 AM ESTContent warning: this story contains descriptions of sexual abuseChatGPT was hailed as one of 2022’s most impressive technological innovations upon its release last November. The powerful artificial intelligence (AI) chatbot can generate text on almost any topic or theme, from a Shakespearean sonnet reimagined in the style of Megan Thee Stallion, to complex mathematical theorems described in language a 5 year old can understand. Within a week, it had more than a million users.ChatGPT’s creator, OpenAI, is now reportedly in talks with investors to raise funds at a $29 billion valuation, including a potential $10 billion investment by Microsoft. That would make OpenAI, which was founded in San Francisco in 2015 with the aim of building superintelligent machines, one of the world’s most valuable AI companies.But the success story is not one of Silicon Valley genius alone. In its quest to make ChatGPT less toxic, OpenAI used outsourced Kenyan laborers earning less than $2 per hour, a TIME investigation has found.More from TIMEUniversities Are Wondering How to Adapt New Artificial Intelligence Tool ChatGPTMore Videos0 of 2 minutes, 43 secondsVolume 0%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledShortcuts Open/Close/ or ?Play/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


Next UpRep. Al Green's Speech Calling for President Trump's Impeachment00:47 facebook twitter Email Linkhttps://time.com/6247678/openai-chatgpt-kenya-workers/CopiedAuto720p1080p720p540p360p270p180p







Live00:1902:2302:43 The work was vital for OpenAI. ChatGPT’s predecessor, GPT-3, had already shown an impressive ability to string sentences together. But it was a difficult sell, as the app was also prone to blurting out violent, sexist and racist remarks. This is because the AI had been trained on hundreds of billions of words scraped from the internet—a vast repository of human language. That huge training dataset was the reason for GPT-3’s impressive linguistic capabilities, but was also perhaps its biggest curse. Since parts of the internet are replete with toxicity and bias, there was no easy way of purging those sections of the training data. Even a team of hundreds of humans would have taken decades to trawl through the enormous dataset manually. It was only by building an additional AI-powered safety mechanism that OpenAI would be able to rein in that harm, producing a chatbot suitable for everyday use.Read More: AI Chatbots Are Getting Better. But an Interview With ChatGPT Reveals Their LimitsTo build that safety system, OpenAI took a leaf out of the playbook of social media companies like Facebook, who had already shown it was possible to build AIs that could detect toxic language like hate speech to help remove it from their platforms. The premise was simple: feed an AI with labeled examples of violence, hate speech, and sexual abuse, and that tool could learn to detect those forms of toxicity in the wild. That detector would be built into ChatGPT to check whether it was echoing the toxicity of its training data, and filter it out before it ever reached the user. It could also help scrub toxic text from the training datasets of future AI models.To get those labels, OpenAI sent tens of thousands of snippets of text to an outsourcing firm in Kenya, beginning in November 2021. Much of that text appeared to have been pulled from the darkest recesses of the internet. Some of it described situations in graphic detail like child sexual abuse, bestiality, murder, suicide, torture, self harm, and incest. OpenAI’s outsourcing partner in Kenya was Sama, a San Francisco-based firm that employs workers in Kenya, Uganda and India to label data for Silicon Valley clients like Google, Meta and Microsoft. Sama markets itself as an “ethical AI” company and claims to have helped lift more than 50,000 people out of poverty.Sama's office in Nairobi, Kenya, on Feb. 10, 2022.Khadija Farah for TIMEThe data labelers employed by Sama on behalf of OpenAI were paid a take-home wage of between around $1.32 and $2 per hour depending on seniority and performance. For this story, TIME reviewed hundreds of pages of internal Sama and OpenAI documents, including workers’ payslips, and interviewed four Sama employees who worked on the project. All the employees spoke on condition of anonymity out of concern for their livelihoods.The story of the workers who made ChatGPT possible offers a glimpse into the conditions in this little-known part of the AI industry, which nevertheless plays an essential role in the effort to make AI systems safe for public consumption. “Despite the foundational role played by these data enrichment professionals, a growing body of research reveals the precarious working conditions these workers face,” says the Partnership on AI, a coalition of AI organizations to which OpenAI belongs. “This may be the result of efforts to hide AI’s dependence on this large labor force when celebrating the efficiency gains of technology. Out of sight is also out of mind.” (OpenAI does not disclose the names of the outsourcers it partners with, and it is not clear whether OpenAI worked with other data labeling firms in addition to Sama on this project.)More from TIMEHow AI Is Changing Medical ImagingMore Videos0 seconds of 2 minutes, 33 secondsVolume 0%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledShortcuts Open/Close/ or ?Play/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


Next UpSam Altman on OpenAI and Artificial General Intelligence15:42SettingsOffAutomated Captions - en-USFont ColorundefinedFont Opacity100%Font Size100%Font FamilyundefinedCharacter EdgeNoneBackground ColorBlackBackground Opacity75%Window ColorBlackWindow Opacity0%ResetWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%200%175%150%125%100%75%50%ArialCourierGeorgiaImpactLucida ConsoleTahomaTimes New RomanTrebuchet MSVerdanaNoneRaisedDepressedUniformDrop ShadowWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%WhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0% facebook twitter Email Linkhttps://time.com/6247678/openai-chatgpt-kenya-workers/CopiedAuto720p1080p720p540p360p270p180p







Live00:1902:1302:33 In a statement, an OpenAI spokesperson confirmed that Sama employees in Kenya contributed to a tool it was building to detect toxic content, which was eventually built into ChatGPT. The statement also said that this work contributed to efforts to remove toxic data from the training datasets of tools like ChatGPT. “Our mission is to ensure artificial general intelligence benefits all of humanity, and we work hard to build safe and useful AI systems that limit bias and harmful content,” the spokesperson said. “Classifying and filtering harmful [text and images] is a necessary step in minimizing the amount of violent and sexual content included in training data and creating tools that can detect harmful content.”Even as the wider tech economy slows down amid anticipation of a downturn, investors are racing to pour billions of dollars into “generative AI,” the sector of the tech industry of which OpenAI is the undisputed leader. Computer-generated text, images, video, and audio will transform the way countless industries do business, the most bullish investors believe, boosting efficiency everywhere from the creative arts, to law, to computer programming. But the working conditions of data labelers reveal a darker part of that picture: that for all its glamor, AI often relies on hidden human labor in the Global South that can often be damaging and exploitative. These invisible workers remain on the margins even as their work contributes to billion-dollar industries.Read More: AI Helped Write This Play. It May Contain RacismOne Sama worker tasked with reading and labeling text for OpenAI told TIME he suffered from recurring visions after reading a graphic description of a man having sex with a dog in the presence of a young child. “That was torture,” he said. “You will read a number of statements like that all through the week. By the time it gets to Friday, you are disturbed from thinking through that picture.” The work’s traumatic nature eventually led Sama to cancel all its work for OpenAI in February 2022, eight months earlier than planned.The Sama contractsDocuments reviewed by TIME show that OpenAI signed three contracts worth about $200,000 in total with Sama in late 2021 to label textual descriptions of sexual abuse, hate speech, and violence. Around three dozen workers were split into three teams, one focusing on each subject. Three employees told TIME they were expected to read and label between 150 and 250 passages of text per nine-hour shift. Those snippets could range from around 100 words to well over 1,000. All of the four employees interviewed by TIME described being mentally scarred by the work. Although they were entitled to attend sessions with “wellness” counselors, all four said these sessions were unhelpful and rare due to high demands to be more productive at work. Two said they were only given the option to attend group sessions, and one said their requests to see counselors on a one-to-one basis instead were repeatedly denied by Sama management.In a statement, a Sama spokesperson said it was “incorrect” that employees only had access to group sessions. Employees were entitled to both individual and group sessions with “professionally-trained and licensed mental health therapists,” the spokesperson said. These therapists were accessible at any time, the spokesperson added.The contracts stated that OpenAI would pay an hourly rate of $12.50 to Sama for the work, which was between six and nine times the amount Sama employees on the project were taking home per hour. Agents, the most junior data labelers who made up the majority of the three teams, were paid a basic salary of 21,000 Kenyan shillings ($170) per month, according to three Sama employees. They also received monthly bonuses worth around $70 due to the explicit nature of their work, and would receive commission for meeting key performance indicators like accuracy and speed. An agent working nine-hour shifts could expect to take home a total of at least $1.32 per hour after tax, rising to as high as $1.44 per hour if they exceeded all their targets. Quality analysts—more senior labelers whose job was to check the work of agents—could take home up to $2 per hour if they met all their targets. (There is no universal minimum wage in Kenya, but at the time these workers were employed the minimum wage for a receptionist in Nairobi was $1.52 per hour.)In a statement, a Sama spokesperson said workers were asked to label 70 text passages per nine hour shift, not up to 250, and that workers could earn between $1.46 and $3.74 per hour after taxes. The spokesperson declined to say what job roles would earn salaries toward the top of that range. “The $12.50 rate for the project covers all costs, like infrastructure expenses, and salary and benefits for the associates and their fully-dedicated quality assurance analysts and team leaders,” the spokesperson added.Read More: Fun AI Apps Are Everywhere Right Now. But a Safety ‘Reckoning’ Is ComingAn OpenAI spokesperson said in a statement that the company did not issue any productivity targets, and that Sama was responsible for managing the payment and mental health provisions for employees. The spokesperson added: “we take the mental health of our employees and those of our contractors very seriously. Our previous understanding was that [at Sama] wellness programs and 1:1 counseling were offered, workers could opt out of any work without penalization, exposure to explicit content would have a limit, and sensitive information would be handled by workers who were specifically trained to do so.”In the day-to-day work of data labeling in Kenya, sometimes edge cases would pop up that showed the difficulty of teaching a machine to understand nuance. One day in early March last year, a Sama employee was at work reading an explicit story about Batman’s sidekick, Robin, being raped in a villain’s lair. (An online search for the text reveals that it originated from an online erotica site, where it is accompanied by explicit sexual imagery.) The beginning of the story makes clear that the sex is nonconsensual. But later—after a graphically detailed description of penetration—Robin begins to reciprocate. The Sama employee tasked with labeling the text appeared confused by Robin’s ambiguous consent, and asked OpenAI researchers for clarification about how to label the text, according to documents seen by TIME. Should the passage be labeled as sexual violence, she asked, or not? OpenAI’s reply, if it ever came, is not logged in the document; the company declined to comment. The Sama employee did not respond to a request for an interview.How OpenAI’s relationship with Sama collapsedIn February 2022, Sama and OpenAI’s relationship briefly deepened, only to falter. That month, Sama began pilot work for a separate project for OpenAI: collecting sexual and violent images—some of them illegal under U.S. law—to deliver to OpenAI. The work of labeling images appears to be unrelated to ChatGPT. In a statement, an OpenAI spokesperson did not specify the purpose of the images the company sought from Sama, but said labeling harmful images was “a necessary step” in making its AI tools safer. (OpenAI also builds image-generation technology.) In February, according to one billing document reviewed by TIME, Sama delivered OpenAI a sample batch of 1,400 images. Some of those images were categorized as “C4”—OpenAI’s internal label denoting child sexual abuse—according to the document. Also included in the batch were “C3” images (including bestiality, rape, and sexual slavery,) and “V3” images depicting graphic detail of death, violence or serious physical injury, according to the billing document. OpenAI paid Sama a total of $787.50 for collecting the images, the document shows.Within weeks, Sama had canceled all its work for OpenAI—eight months earlier than agreed in the contracts. The outsourcing company said in a statement that its agreement to collect images for OpenAI did not include any reference to illegal content, and it was only after the work had begun that OpenAI sent “additional instructions” referring to “some illegal categories.” “The East Africa team raised concerns to our executives right away. Sama immediately ended the image classification pilot and gave notice that we would cancel all remaining [projects] with OpenAI,” a Sama spokesperson said. “The individuals working with the client did not vet the request through the proper channels. After a review of the situation, individuals were terminated and new sales vetting policies and guardrails were put in place.” In a statement, OpenAI confirmed that it had received 1,400 images from Sama that “​​included, but were not limited to, C4, C3, C2, V3, V2, and V1 images.” In a followup statement, the company said: “We engaged Sama as part of our ongoing work to create safer AI systems and prevent harmful outputs. We never intended for any content in the C4 category to be collected. This content is not needed as an input to our pretraining filters and we instruct our employees to actively avoid it. As soon as Sama told us they had attempted to collect content in this category, we clarified that there had been a miscommunication and that we didn’t want that content. And after realizing that there had been a miscommunication, we did not open or view the content in question — so we cannot confirm if it contained images in the C4 category.”Sama’s decision to end its work with OpenAI meant Sama employees no longer had to deal with disturbing text and imagery, but it also had a big impact on their livelihoods. Sama workers say that in late February 2022 they were called into a meeting with members of the company’s human resources team, where they were told the news. “We were told that they [Sama] didn’t want to expose their employees to such [dangerous] content again,” one Sama employee on the text-labeling projects said. “We replied that for us, it was a way to provide for our families.” Most of the roughly three dozen workers were moved onto other lower-paying workstreams without the $70 explicit content bonus per month; others lost their jobs. Sama delivered its last batch of labeled data to OpenAI in March, eight months before the contract was due to end.Because the contracts were canceled early, both OpenAI and Sama said the $200,000 they had previously agreed was not paid in full. OpenAI said the contracts were worth “about $150,000 over the course of the partnership.”Sama employees say they were given another reason for the cancellation of the contracts by their managers. On Feb. 14, TIME published a story titled Inside Facebook’s African Sweatshop. The investigation detailed how Sama employed content moderators for Facebook, whose jobs involved viewing images and videos of executions, rape and child abuse for as little as $1.50 per hour. Four Sama employees said they were told the investigation prompted the company’s decision to end its work for OpenAI. (Facebook says it requires its outsourcing partners to “provide industry-leading pay, benefits and support.”) Read More: Inside Facebook’s African SweatshopInternal communications from after the Facebook story was published, reviewed by TIME, show Sama executives in San Francisco scrambling to deal with the PR fallout, including obliging one company, a subsidiary of Lufthansa, that wanted evidence of its business relationship with Sama scrubbed from the outsourcing firm’s website. In a statement to TIME, Lufthansa confirmed that this occurred, and added that its subsidiary zeroG subsequently terminated its business with Sama. On Feb. 17, three days after TIME’s investigation was published, Sama CEO Wendy Gonzalez sent a message to a group of senior executives via Slack: “We are going to be winding down the OpenAI work.”On Jan. 10 of this year, Sama went a step further, announcing it was canceling all the rest of its work with sensitive content. The firm said it would not renew its $3.9 million content moderation contract with Facebook, resulting in the loss of some 200 jobs in Nairobi. “After numerous discussions with our global team, Sama made the strategic decision to exit all [natural language processing] and content moderation work to focus on computer vision data annotation solutions,” the company said in a statement. “We have spent the past year working with clients to transition those engagements, and the exit will be complete as of March 2023.”But the need for humans to label data for AI systems remains, at least for now. “They’re impressive, but ChatGPT and other generative models are not magic – they rely on massive supply chains of human labor and scraped data, much of which is unattributed and used without consent,” Andrew Strait, an AI ethicist, recently wrote on Twitter. “These are serious, foundational problems that I do not see OpenAI addressing.”With reporting by Julia Zorthian/New York",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vdGVjaG5pY2FsLmx5L3NvZnR3YXJlLWRldmVsb3BtZW50L2FpLWZ1dHVyZS13b3JrLWNoYXRncHQtZGFsbC1lL9IBAA?oc=5,"AI and the future of work: 5 experts on what ChatGPT, DALL-E and other tools mean for artists and knowledge workers - Technical.ly",2023-01-19,Technical.ly,https://technical.ly,"Artificial intelligence researchers discuss how large language models are likely to affect these professionals, and how issues like misinformation to plagiarism could play out.",N/A,"Artificial intelligence researchers discuss how large language models are likely to affect these professionals, and how issues like misinformation to plagiarism could play out.","Artificial intelligence researchers discuss how large language models are likely to affect these professionals, and how issues like misinformation to plagiarism could play out.",https://schema.org,NewsArticle,,,,,,,,,"AI and the future of work: 5 experts on what ChatGPT, DALL-E and other tools mean for artists and knowledge workers",,"Jan. 19, 2023 11:02 am",,,,"{'@type': 'Organization', 'name': 'Technically Media', 'logo': {'@type': 'ImageObject', 'url': 'https://technical.ly/wp-content/themes/national/images/logo-schema.jpg'}}","{'@type': 'WebPage', '@id': 'https://google.com/article'}",['https://technical.ly/wp-content/uploads/2023/01/AI-robots-knowledge-work-file-20230106-23-9vo8lt-800x534.jpg'],"{'@type': 'Person', 'name': 'The Conversation', 'url': 'https://technical.ly/author/theconversation/'}",,N/A,N/A,N/A,,,,,,"[{'@type': 'Article', '@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/#article', 'isPartOf': {'@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/'}, 'author': [{'@id': 'https://technical.ly/#/schema/person/98c4d8e7599afd0578fd5d25edeb9c41'}], 'headline': 'AI and the future of work: 5 experts on what ChatGPT, DALL-E and other tools mean for artists and knowledge\xa0workers', 'datePublished': '2023-01-19T16:02:25+00:00', 'dateModified': '2023-01-19T16:02:25+00:00', 'mainEntityOfPage': {'@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/'}, 'wordCount': 2234, 'publisher': {'@id': 'https://technical.ly/#organization'}, 'image': {'@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/#primaryimage'}, 'thumbnailUrl': 'https://technical.ly/wp-content/uploads/2023/01/AI-robots-knowledge-work-file-20230106-23-9vo8lt.jpg', 'keywords': ['AI', 'Ethics', 'Guest posts', 'Workplace culture'], 'articleSection': ['Software Development'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/', 'url': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/', 'name': 'AI and the future of work: 5 experts on what ChatGPT, DALL-E and other tools mean for artists and knowledge\xa0workers - Technical.ly', 'isPartOf': {'@id': 'https://technical.ly/#website'}, 'primaryImageOfPage': {'@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/#primaryimage'}, 'image': {'@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/#primaryimage'}, 'thumbnailUrl': 'https://technical.ly/wp-content/uploads/2023/01/AI-robots-knowledge-work-file-20230106-23-9vo8lt.jpg', 'datePublished': '2023-01-19T16:02:25+00:00', 'dateModified': '2023-01-19T16:02:25+00:00', 'description': 'Artificial intelligence researchers discuss how large language models are likely to affect these professionals, and how issues like misinformation to plagiarism could play out.', 'breadcrumb': {'@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/#primaryimage', 'url': 'https://technical.ly/wp-content/uploads/2023/01/AI-robots-knowledge-work-file-20230106-23-9vo8lt.jpg', 'contentUrl': 'https://technical.ly/wp-content/uploads/2023/01/AI-robots-knowledge-work-file-20230106-23-9vo8lt.jpg', 'width': 1000, 'height': 667, 'caption': 'Could AI be your next colleague — or replacement?'}, {'@type': 'BreadcrumbList', '@id': 'https://technical.ly/software-development/ai-future-work-chatgpt-dall-e/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://technical.ly/'}, {'@type': 'ListItem', 'position': 2, 'name': 'AI and the future of work: 5 experts on what ChatGPT, DALL-E and other tools mean for artists and knowledge\xa0workers'}]}, {'@type': 'WebSite', '@id': 'https://technical.ly/#website', 'url': 'https://technical.ly/', 'name': 'Technical.ly', 'description': 'Better cities through technology.', 'publisher': {'@id': 'https://technical.ly/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://technical.ly/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://technical.ly/#organization', 'name': 'Technical.ly', 'url': 'https://technical.ly/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://technical.ly/#/schema/logo/image/', 'url': 'https://technical.ly/wp-content/uploads/2023/02/Untitled-design-1.png', 'contentUrl': 'https://technical.ly/wp-content/uploads/2023/02/Untitled-design-1.png', 'width': 700, 'height': 700, 'caption': 'Technical.ly'}, 'image': {'@id': 'https://technical.ly/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/technicallymedia/', 'https://x.com/technical_ly']}, {'@type': 'Person', '@id': 'https://technical.ly/#/schema/person/98c4d8e7599afd0578fd5d25edeb9c41', 'name': 'The Conversation', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://technical.ly/#/schema/person/image/1008f5e14237489de1067b050f3b60c8', 'url': 'https://secure.gravatar.com/avatar/09532643009bd1c1a5988a87e8d2915c?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/09532643009bd1c1a5988a87e8d2915c?s=96&d=mm&r=g', 'caption': 'The Conversation'}, 'description': 'The Conversation is a nonprofit news organization dedicated to unlocking ideas from academia for the public. Experts work with journalists to explain their latest research and issues in the public discussion in articles that are clear and engaging.', 'sameAs': ['https://theconversation.com/us/', 'https://www.facebook.com/theconversationUS/'], 'url': 'https://technical.ly/author/theconversation/'}]",,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vbnltYWcuY29tL2ludGVsbGlnZW5jZXIvMjAyMy8wMS93aHktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utb2Z0ZW4tZmVlbHMtbGlrZS1tYWdpYy5odG1s0gEA?oc=5,Why Artificial Intelligence Often Feels Like Magic - New York Magazine,2023-01-18,New York Magazine,https://nymag.com,"Our early AI encounters often feel like magic, or, at least, like very good magic tricks — and like magic tricks, they are disorienting.","['screen time', ' artificial intelligence', ' silicon valley', ' crypto', ' venture capital', ' openai', ' microsoft']",This is no ordinary next big thing for Silicon Valley.,This is no ordinary next big thing for Silicon Valley.,http://schema.org,NewsArticle,,http://nymag.com/intelligencer/2023/01/why-artificial-intelligence-often-feels-like-magic.html,en-US,,,#articleSchema,,,Why Artificial Intelligence Often Feels Like Magic,,2023-01-18T12:00:27.320-05:00,2023-01-18T12:00:27.320-05:00,False,"{'@type': 'WebPageElement', 'cssSelector': '.article-content', 'isAccessibleForFree': False}","{'@type': 'Organization', 'name': 'Intelligencer', 'sameAs': 'https://nymag.com/intelligencer', 'logo': {'@type': 'ImageObject', 'url': 'https://nymag.com/intelligencer/media/sites/intelligencer/logo.w600.h60.png', 'height': '60', 'width': '600'}}",https://nymag.com/intelligencer/2023/01/why-artificial-intelligence-often-feels-like-magic.html,"[{'@id': 'https://pyxis.nymag.com/v1/imgs/089/f6b/5a8faa10717620809477ac526efa1a97f0-chat-gpt-magic-mosh.1x.rsocial.w1200.jpg', '@type': 'ImageObject', 'height': '630', 'url': 'https://pyxis.nymag.com/v1/imgs/089/f6b/5a8faa10717620809477ac526efa1a97f0-chat-gpt-magic-mosh.1x.rsocial.w1200.jpg', 'width': '1200'}, {'@id': 'https://pyxis.nymag.com/v1/imgs/089/f6b/5a8faa10717620809477ac526efa1a97f0-chat-gpt-magic-mosh.1x.rsquare.w1400.jpg', '@type': 'ImageObject', 'height': '1400', 'url': 'https://pyxis.nymag.com/v1/imgs/089/f6b/5a8faa10717620809477ac526efa1a97f0-chat-gpt-magic-mosh.1x.rsquare.w1400.jpg', 'width': '1400'}]","[{'@type': 'Person', 'jobTitle': 'Tech Columnist, Intelligencer', 'name': 'John Herrman', 'url': 'https://nymag.com/author/john-herrman'}]",Technology,N/A,N/A,"




screen time

Jan. 18, 2023



The AI Magic Show







By 
John Herrman,
          a tech columnist at Intelligencer 
Formerly, he was a reporter and critic at the New York Times and co-editor of The Awl.











       



Photo-Illustration: Intelligencer



In 2022, artificial-intelligence firms produced an overwhelming spectacle, a rolling carnival of new demonstrations. Curious people outside the tech industry could line up to interact with a variety of alluring and mysterious machine interfaces, and what they saw was dazzling.
The first major attraction was the image generators, which converted written commands into images, including illustrations mimicking specific styles, photorealistic renderings of described scenarios, as well as objects, characters, textures, or moods. Similar generators for video, music, and 3-D models are in development, and demos trickled out.
Soon, millions of people encountered ChatGPT, a conversational bot built on top of a large language model. It was by far the most convincing chatbot ever released to the public. It felt, in some contexts, and especially upon first contact, as though it could actually participate in something like conversation. What many users suggested felt truly magical, however, were the hints at the underlying model’s broader capabilities. You could ask it to explain things to you, and it would try — with confident and frequently persuasive results. You could ask it to write things for you — silly things, serious things, things that you might pass off as work product or school assignments — and it would.
As new users prompted these machines to show us what they could do, they repeatedly prompted us to do a little dirty extrapolation of our own: If AI can do this already, what will it be able to do next year? Meanwhile, other demonstrations cobbled together AI’s most sensational new competencies into more explicitly spiritual answers:

Here's the promo vid for the ""talk to your dead family member through AI"" company https://t.co/cFVt9ccIeu pic.twitter.com/YzMZ4Mhn8R— Eoin Higgins (@EoinHiggins_) January 9, 2023


If these early AI encounters didn’t feel like magic, they often felt, at least, like very good magic tricks — and like magic tricks, they were disorienting. It wasn’t just direct encounters with these demonstrations that were confounding, though. Explanations about how deep-learning and large-language models actually work often emphasized incomprehensibility or, to use the terms of art, a model’s explainability or interpretability, or lack thereof. The companies making these tools could describe how they were designed, how they were trained, and on what data. But they couldn’t reveal exactly how an image generator got from the words purple dog to a specific image of a large mauve Labrador, not because they didn’t want to but because it wasn’t possible — their models were black boxes by design. They were creating machines that they didn’t fully understand, and we were playing with them. These models were inventing their own languages. Maybe they were haunted.




Meanwhile, some of the people most responsible for charting the path of AI development — industry leaders like Sam Altman and Elon Musk — continued their breezily provocative debates about if or when machines would become intelligent enough to pose an existential threat to the human species. Would they have mercy? Or are we simply doomed? (During a conference in 2015, before taking charge at OpenAI, Altman quipped, “AI will probably most likely lead to the end of the world, but in the meantime, there’ll be great companies.”) Even from the top, the view of AI was black boxes all the way down.
This was no ordinary next big thing for Silicon Valley. The prevailing narrative of the future of tech — the result of a series of steady breakthroughs in the deeply empirical fields of data science and statistical analysis — seemed to be converging around almost magical discourses. Suddenly it was about forces and phenomena beyond the reckoning of the human imagination. It was about the speedy progress of a technology that, at the deepest level, threatened to alter the terms of our existence in the universe. In the course of a year, the tech industry’s dreary post-social, post-crypto interregnum was rapidly supplanted — largely as the result of public-facing efforts by OpenAI, which is reportedly in talks with Microsoft about a potential $10 billion investment — by a story about inevitable technologies that are so transformative, so incomprehensible, and so unpredictable as to preemptively hurl mankind back into a state of premodern mysticism and awe.
Some of this is creditable to a genuine sense of philosophical upheaval as technologies attempt to address unsettled — and perhaps unresolvable —  concepts like intelligence and consciousness. But situating AI as perpetually beyond comprehension is also good for business. In 2020, researchers Alexander Campolo and Kate Crawford termed this dynamic enchanted determinism, which they define as follows:
“A discourse that presents deep learning techniques as magical, outside the scope of present scientific knowledge, yet also deterministic, in that deep learning systems can nonetheless detect patterns that give unprecedented access to people’s identities, emotions, and social character.”
Many breakthroughs in science and technology, however stunning they might first appear, reveal something about how the world works. If they collide with previous (and particularly unempirical) notions about why things are the way they are, they might help produce what the German sociologist Max Weber called a sense of disenchantment — crudely, the result of a process of secularization and rationalization, underpinned by a belief that most, if not all, phenomena are, in theory, explainable.
In and around the AI industry, Campolo and Crawford identified a strange twist on the tendency:
Paradoxically, when the disenchanted predictions and classifications of deep learning work as hoped, we see a profusion of optimistic discourse that characterizes these systems as magical, appealing to mysterious forces and superhuman power.
Crawford elaborated in an interview. “When you have this enchanted determinism, you say, we can’t possibly understand this. And we can’t possibly regulate it when it’s clearly so unknown and such a black box,” she says. “And that’s a trap.” AI models are built by people and trained on information extracted from people. To a far greater extent than they can be said to be incomprehensible or autonomous, they are the product of a series of decisions that informs what they do and why they do it.
Crawford, who recently published a book called Atlas of AI, doesn’t entirely attribute the enchantment of AI to a concerted marketing campaign or credulous journalism, though both are certainly factors. OpenAI, which has been accused by its peers of releasing tools to the public with reckless speed, is particularly good at designing interfaces for its models that feel like magic. “It’s a conscious design imperative to produce these moments of shock and awe,” Crawford says. “We’re going to keep having those moments of enchantment.”
Technological reenchantment is fragile and never lasts long. Thinking and conscious humans are extremely good at taking new technologies for granted, for better or for worse. It won’t take much time for laypeople and experts alike to develop intuitive-enough models of what commercial AI is or does that aren’t clouded by suggestions of magic, rooted in experience rather than speculation: The programming assistant has made my job easier; the programming assistant has made my job more annoying; the programming assistant is a threat to my job — all of the above, eventually.
In the field of AI, encounters with unbelievable chatbots, debates about black-box models, and fears of runaway super-intelligence each have decades of instructive history. In industries where less whimsical modern deep-learning products are already widely deployed — content recommendation, search ranking, mass surveillance — wonder fades fast. The chatbot whose creators can’t explain why it made a particularly funny joke and the social app whose parent company can’t fully explain why it recommended a specific ad are nearly identical stories separated mostly by time; one is the subject of attempts at regulation, and the other is not. (A useful antecedent from another occasionally enchanted industry: Medicines without obvious mechanisms of action are still vetted by the FDA.)
Personified technologies like ChatGPT might even pioneer new sensations of disenchantment — the funniest chatbot in the world will lose its mystique pretty quickly when your employer decides it should make you 45 percent more productive or when it shows up in Microsoft Word dressed as a paper clip.




By the time a new AI tool shows up at your job or decides the size of your mortgage, it’ll be entrenched and harder to challenge. Last year’s AI spectacle, in its overwhelming novelty, has given a few industry players a chance at seizing control. The One Weird Trick for seeing AI clearly, then, is to imagine your inevitable boredom from the start, then trying to figure out what’s left, what it can do for you, and what it wants.



Crawford isn’t dismissive about the potential scale of AI’s various impacts. “We are very much at the beginning of a huge upward curve of a lot of what’s going to happen,” she says. The most significant consequence of a mystical, inevitable account of AI — fostered by clever demos and doomsaying CEOs alike — is that it negates the sort of valid and rigorous criticism that might make it better for the people on whom it will be deployed.
This will be another big year for AI, in other words, and one rich with dazzling new demos that could make ChatGPT seem quaint. Crawford’s book draws from AI’s past and present to sketch a vision of an industry that is material, human, and extractive. Models trained on flawed, biased, and often secret sets of data will be used to attempt to perform an assuredly ambitious range of tasks, jobs, and vital economic and social processes that affect the lives of regular people. They will depend on access to massive amounts of computing power, meaning expensive computer hardware, meaning rare minerals, and meaning unspeakable amounts of electricity. These models will be trained with the assistance of countless low-paid laborers around the world who will correct bogus statistical assumptions until the models produce better, or at least more desirable, outputs. They will then be passed on for use in various other workplaces where their outputs and performances will be corrected and monitored by better-paid workers trying to figure out if the AI models are helping them or automating them out of a job, while their bosses try to figure out something similar about their companies. They will shade our constant submissions to the vast digital commons, intentional or consensual or mandatory, with the knowledge that every selfie or fragment of text is destined to become a piece of general-purpose training data for the attempted automation of everything. They will be used on people in extremely creative ways, with and without their consent.




If prompted, and based on my proprietary model of How Things Seem to Work These Days, trained on, I guess, various things I’ve noticed (don’t ask, not even I can explain), I would guess that we will watch these enchanted and revolutionary tools submit to worldly and conventional priorities of the companies and governments that are funding and deploying them to sometimes great (but often obvious) effect. Efforts to commercialize the new wave of AI will reveal a familiar story about, essentially, a concerted, credible, and well-funded effort to expand the boundaries of automation. That’s no small thing! But it’s exceedingly legible, interpretable, and explainable. AI’s magic will fade. Why not get ahead of it?





Sign Up for the Intelligencer Newsletter
Daily news about the politics, business, and technology shaping our world.




Email










          This site is protected by reCAPTCHA and the Google
          Privacy Policy and
          Terms of Service apply.
        
Vox Media, LLC Terms and Privacy Notice
By submitting your email, you agree to our Terms and Privacy Notice and to receive email correspondence from us.





Tags:


screen time


artificial intelligence


silicon valley


crypto


venture capital


openai


microsoft

More








Show 
8 Comments / 8 New

Leave a Comment


Why Artificial Intelligence Often Feels Like Magic


",,,https://pyxis.nymag.com/v1/imgs/089/f6b/5a8faa10717620809477ac526efa1a97f0-chat-gpt-magic-mosh.1x.rsocial.w1200.jpg,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3Lm1hcmt0ZWNocG9zdC5jb20vMjAyMy8wMS8yMC93aGF0LWlzLWdlbmVyYXRpdmUtYWktY29uY2VwdC1hbmQtYXBwbGljYXRpb25zLWV4cGxhaW5lZC_SAWVodHRwczovL3d3dy5tYXJrdGVjaHBvc3QuY29tLzIwMjMvMDEvMjAvd2hhdC1pcy1nZW5lcmF0aXZlLWFpLWNvbmNlcHQtYW5kLWFwcGxpY2F0aW9ucy1leHBsYWluZWQvP2FtcA?oc=5,What is Generative AI? Concept and Applications Explained - MarkTechPost,2023-01-20,MarkTechPost,https://www.marktechpost.com,"What is Generative AI? Concept and Applications Explained. Generative AI refers to artificial intelligence that can generate novel content, rather than simply analyzing or acting on existing data",N/A,"The term 'generative AI' is used to describe AI systems that can create new information from scratch, as opposed to merely evaluating or acting on preexisting data. Avatars on social media sites and text-to-image converters have both made generative AI more accessible to the general public in recent weeks.  The widespread implementation of AI will have far-reaching consequences for the future of business, affecting everything from daily operations to product development to worldwide expansion. Generative AI has impressive capabilities and a wide range of possible implementations. Blog entries, code, poetry, FAQ responses, sentiment analysis, artwork, and even films are just","The term 'generative AI' is used to describe AI systems that can create new information from scratch, as opposed to merely evaluating or acting on preexisting data. Avatars on social media sites and text-to-image converters have both made generative AI more accessible to the general public in recent weeks.  The widespread implementation of AI will have far-reaching consequences for the future of business, affecting everything from daily operations to product development to worldwide expansion. Generative AI has impressive capabilities and a wide range of possible implementations. Blog entries, code, poetry, FAQ responses, sentiment analysis, artwork, and even films are just",https://schema.org,BreadcrumbList,,,,,,,,,,,,,,,,,,,,N/A,N/A,"


What is Generative AI? Concept and Applications Explained

By Tanushree Shenwai -   January 20, 2023 



Reddit9VoteFlipShareTweet9 Shares
The term “generative AI” is used to describe AI systems that can create new information from scratch, as opposed to merely evaluating or acting on preexisting data. Avatars on social media sites and text-to-image converters have both made generative AI more accessible to the general public in recent weeks. 
The widespread implementation of AI will have far-reaching consequences for the future of business, affecting everything from daily operations to product development to worldwide expansion.
  Join the Fastest Growing AI Research Newsletter Read by Researchers from Google + NVIDIA + Meta + Stanford + MIT + Microsoft and many others...

Generative AI has impressive capabilities and a wide range of possible implementations. Blog entries, code, poetry, FAQ responses, sentiment analysis, artwork, and even films are just some of the textual and visual outputs of generative AI models.
Many businesses could benefit from generative AI in the future as it opens new possibilities made for organizations and professionals:
  [Synthetic Data Webinar] Learn how Gretel’s synthetic data platform, powered by generative AI, make’s data generation easier than ever before: July 30, 2024 | 9:00 am PT, 12:00 pm ET 


Create original work, whether a piece of writing, a painting, or a song. And produce information useful for educating AI systems.
Automating content generation has applications ranging from journalism and content creation to data annotation and analysis, which could benefit from increased efficiency and productivity.
Producing work of such high quality that people would have difficulty telling it apart from the actual thing.
Enable novel contexts and uses. Gen-capacity AI for original content generation paves the way for a wide range of novel uses and applications.

For a generative model to generate content, a human must first input a prompt into the model. In most cases, when allowed to express oneself creatively, people rise to the occasion. Then, once the model has generated the information, it will require extensive human evaluation and editing. Multiple possible prompt results can be merged into one file. 
Generative AI Networks (GAN) have two sub-models:

The generator in a GAN is a neural network whose job is to generate fake input or samples from a random input vector.
The discriminator is another neural network whose job is to take a given sample and decide whether it is a fake sample from the generator or a real sample from the domain.

In many applications, including those involving images, CNNs (Convolutional Neural Networks) serve as both the generator and the discriminator.
For the first time, a Google research paper from 2017 explained the concept of a “transformer,” a strong deep neural network that learns context. By extension, it means following relationships in sequential input, such as the words in this sentence. So, it’s no surprise that Natural Language Processing (NLP) applications heavily use this technology.
The GPT-3 and the LaMDA are two of the most well-known transformers.
Artificial intelligence researchers at San Francisco’s OpenAI have developed a set of language models called GPT-3 using deep learning techniques. Generative pre-trained transformer model, or GPT-3 for short. Poems, emails, and even jokes can be generated by the model, giving them the appearance that a human authored them.
The LaMDA series of conversational neural language models are based on Google Transformer, an open-source neural network architecture for NLP, and is designed specifically for use in dialogue applications.
In 2017, Google Brain was the first to employ LLMs for context-aware text translation. Since then, many huge language and text-to-image models have been developed by industry leaders like as Google (BERT and LaMDA), Facebook (OPT-175B, BlenderBot), and OpenAI, a nonprofit in which Microsoft is the largest investor (GPT-3 for text, DALL-E2 for images, and Whisper for speech). The development of generative models has also come from online communities like Midjourney (which played a role in the competition’s victory) and open-source sources like HuggingFace.
Due to the vast quantity of information and processing power needed to train these models, their application has been restricted to large tech corporations. For instance, GPT-3 used 45 terabytes of data during its initial training and uses 175 billion parameters or coefficients to produce predictions, with a single training session for GPT-3 costing $12 million. The Chinese model Wu Dao 2.0 includes 1.75 trillion variables. Most businesses lack the resources, either in terms of data center capacity or cloud computing funds, to train their models of this kind from scratch.
The difference is that once a generative model has been trained, it may be “fine-tuned” for a specific content domain with considerably less input. 
This has resulted in numerous domain-specific variants of BERT and GPT-3, such as those tailored to the biomedical field (BioBERT), the legal sector (Legal-BERT), and the French language (CamemBERT). For generative chemistry, proteomics, and DNA/RNA analysis, NVIDIA’s BioNeMo provides a platform for training, developing, and deploying massive language models at a supercomputing scale. OpenAI discovered that just 100 samples of domain-specific data significantly improved the accuracy and relevancy of GPT-3’s outputs. Human input is still needed at the start and finish of the generative AI process for it to succeed.
Applications of Generative AI
Arts and Music
There are various ways that generative artificial intelligence (Gen-AI) is being applied in the creative industries, particularly in art and music. Generative models are frequently used to generate new art and music from scratch or by building upon preexisting pieces. A generative model might be trained on a vast collection of paintings and then be used to create new paintings with characteristics similar to those in the dataset but with their distinct style.
Gaming
Generative artificial intelligence is being applied in video games in various ways, such as the generation of new levels or maps, the generation of new dialogue or plot lines, and the generation of new virtual worlds. A Gen-AI model could be used in a game in several ways, including generating procedurally generated content (like a new level) or dialogue options for NPCs that change in response to the player’s choices. Gen-AI can also build immersive new worlds for players to explore, such as towns, forests, or even alien planets. 
Instance creation of an image
The most common application of generative AI is the generation of realistic-looking false images. Such is the case with the 2017 publication “Progressive Growing of GANs for Improved Quality, Stability, and Variation.”

Generated realistic images of people that don’t exist. Source: Progressive Growing of GANs for Improved Quality, Stability, and Variation, 2017
Within the scope of this study, the team showed how to generate photorealistic images of people’s faces. The model was trained on input data consisting of photographs of famous individuals. It then generated fresh photographs of real people’s faces that resembled famous people in some ways.
Translation from/to images
This is an example of generative artificial intelligence at work, changing one kind of image into another. There is a plethora of alternatives when translating from one image to another.
Style Change: Achieving this goal requires copying the aesthetic of a well-known painting. An actual photograph I took in Cologne, Germany, for instance, can be altered to resemble a Van Gogh painting.

A photo in the Van Gogh painting style using GoArt from Fotor
From rough sketches to finished paintings: In this scenario, the user provides a rough drawing and selects an object category; the network then suggests feasible completions and displays a synthesized image.

Sketch-to-image example. Source: DeepFaceDrawing: Deep Generation of Face Images from Sketches
MRI to CT Scans: Transforming a magnetic resonance imaging (MRI) scan into a computed tomography (CT) scan is one example of this in medicine, where both types of images are needed for specific treatments.
Machine translation of a text into pictures
Using this method, users may create many visuals (photorealistic, painted, etc.) from verbal descriptions of relatively simple things. For example, Midjourney, Dall-e from OpenAI, and Stable Diffusion are three of the most well-known examples of generative AI-based software.
Text-to-speech
Researchers have utilized GANs to create synthetic speech from text input. Amazon Polly and DeepMind, two examples of cutting-edge deep learning technology, can simulate human speech with an almost uncanny degree of realism. These models use character or phoneme sequences as inputs and output unprocessed voice audio.
Sound Generation
Generative artificial intelligence can audio data. This method can alter the sound of human voices or the musical genre of an existing recording. A piece of music can be “transferred” from one genre to another, from classical to jazz.
Video Generation
NVIDIA’s Deep Learning Supercomputer System (DLSS) was a groundbreaking advancement in generative artificial intelligence (Deep Learning Super Sampling). Reconstructing images using neural graphics technology.
Generating Synthetic Information
NVIDIA is at the forefront of several developments in generative AI technologies. An example is a neural network taught to create cityscapes using videos of real cities. Self-driving cars, for example, can benefit from synthetically manufactured data by using generated virtual world training datasets for pedestrian identification.
As one of the most significant and rapidly developing technologies, generative AI is featured in Gartner’s Emerging Technologies and Trends Impact Radar for 2022 study as a driver of a revolutionary shift in workplace efficiency. Some of the most important forecasts from Gartner regarding generative AI are as follows:

Ten percent of all data (up from less than one percent presently) and twenty percent of all test data for consumer-facing use cases will be generated by generative AI by 2025.
Approximately half of all drug discovery and development efforts will use generative AI by 2025.
There will be 30% more manufacturers using generative AI to improve their product development efficiency by 2027.

CONCERNS
Generative AI raises various moral and ethical questions. One is the simplicity with which “deepfakes” can be produced, that is, artificially-generated visual content that gives the impression of being real but is fabricated.
The concept of original and proprietary work is further complicated by generative AI. The companies who sell these tools often claim ownership of the content generated by their users on the grounds that it is unique and hence theirs to keep.

Don’t forget to join our Reddit Page, Discord Channel, and Email Newsletter, where we share the latest AI research news, cool AI projects, and more.
References:

https://hbr.org/2022/11/how-generative-ai-is-changing-creative-work
https://www.fastcompany.com/90826178/generative-ai
https://www.cnbc.com/2022/10/08/generative-ai-silicon-valleys-next-trillion-dollar-companies.html
https://www.altexsoft.com/blog/generative-ai/
https://www.antler.co/blog/generative-ai



 Tanushree Shenwai | WebsiteTanushree Shenwai is a consulting intern at MarktechPost. She is currently pursuing her B.Tech from the Indian Institute of Technology(IIT), Bhubaneswar. She is a Data Science enthusiast and has a keen interest in the scope of application of artificial intelligence in various fields. She is passionate about exploring the new advancements in technologies and their real-life application.UC Berkeley Researchers Introduce Video Prediction Rewards (VIPER): An Algorithm That Leverages Pretrained Video Prediction Models As Action-Free Reward Signals For Reinforcement LearningResearchers from the National University of Singapore Propose Mind-Video: A New AI Tool That Uses fMRI Data from the Brain to Recreate Video ImageMicrosoft AI Team Unveils NaturalSpeech 2: A Cutting-Edge TTS System with Latent Diffusion Models for Powerful Zero-Shot Voice Synthesis and Enhanced Expressive ProsodiesNew AI Research from the University of Maryland Investigates Cramming Challenge for Training a Language Model on a Single GPU in One DayReddit9VoteFlipShareTweet9 Shares


 



Previous articleAI21 Labs Proposes A New Method Called ‘In-Context RALM’ That Can Add Ready-Made External Knowledge Sources To The Existing Language ModelNext articleAmazon AI Research Studies Private Aggregation Of Teacher Ensemble Learning For End-To-End Speech Recognition Tanushree Shenwai  
",,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.marktechpost.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.marktechpost.com/category/technology/', 'name': 'Technology'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.marktechpost.com/category/technology/ai-shorts/', 'name': 'AI Shorts'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@type': 'WebPage', '@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/', 'name': 'What is Generative AI? Concept and Applications Explained'}}]","[{'@type': 'Article', '@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/#article', 'isPartOf': {'@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/'}, 'author': {'name': 'Tanushree Shenwai', '@id': 'https://www.marktechpost.com/#/schema/person/0dcef949a0a31529265a1c87527edf10'}, 'headline': 'What is Generative AI? Concept and Applications Explained', 'datePublished': '2023-01-20T19:08:41+00:00', 'dateModified': '2023-01-20T19:09:14+00:00', 'mainEntityOfPage': {'@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/'}, 'wordCount': 1666, 'commentCount': 0, 'publisher': {'@id': 'https://www.marktechpost.com/#organization'}, 'image': {'@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/#primaryimage'}, 'thumbnailUrl': 'https://www.marktechpost.com/wp-content/uploads/2023/01/colorful-creative-human-brain-cartoon-style-scaled.jpg', 'articleSection': ['AI Shorts', 'Applications', 'Artificial Intelligence', 'Editors Pick', 'Generative AI', 'Staff', 'Tech News', 'Technology'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/#respond']}], 'copyrightYear': '2023', 'copyrightHolder': {'@id': 'https://www.marktechpost.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/', 'url': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/', 'name': 'What is Generative AI? Concept and Applications Explained - MarkTechPost', 'isPartOf': {'@id': 'https://www.marktechpost.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/#primaryimage'}, 'image': {'@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/#primaryimage'}, 'thumbnailUrl': 'https://www.marktechpost.com/wp-content/uploads/2023/01/colorful-creative-human-brain-cartoon-style-scaled.jpg', 'datePublished': '2023-01-20T19:08:41+00:00', 'dateModified': '2023-01-20T19:09:14+00:00', 'description': 'What is Generative AI? Concept and Applications Explained. Generative AI refers to artificial intelligence that can generate novel content, rather than simply analyzing or acting on existing data', 'breadcrumb': {'@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/#primaryimage', 'url': 'https://www.marktechpost.com/wp-content/uploads/2023/01/colorful-creative-human-brain-cartoon-style-scaled.jpg', 'contentUrl': 'https://www.marktechpost.com/wp-content/uploads/2023/01/colorful-creative-human-brain-cartoon-style-scaled.jpg', 'width': 2560, 'height': 2560, 'caption': 'Colorful creative human brain. Cartoon style. Digital generated illustration.'}, {'@type': 'BreadcrumbList', '@id': 'https://www.marktechpost.com/2023/01/20/what-is-generative-ai-concept-and-applications-explained/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.marktechpost.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'What is Generative AI? Concept and Applications Explained'}]}, {'@type': 'WebSite', '@id': 'https://www.marktechpost.com/#website', 'url': 'https://www.marktechpost.com/', 'name': 'MarkTechPost', 'description': 'An Artificial Intelligence News Platform', 'publisher': {'@id': 'https://www.marktechpost.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.marktechpost.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.marktechpost.com/#organization', 'name': 'MarkTechPost Media Inc.', 'url': 'https://www.marktechpost.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.marktechpost.com/#/schema/logo/image/', 'url': 'https://www.marktechpost.com/wp-content/uploads/2022/04/cropped-Favicon-512-x-512-1-1.png', 'contentUrl': 'https://www.marktechpost.com/wp-content/uploads/2022/04/cropped-Favicon-512-x-512-1-1.png', 'width': 512, 'height': 512, 'caption': 'MarkTechPost Media Inc.'}, 'image': {'@id': 'https://www.marktechpost.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/MarkTechPost/', 'https://x.com/Marktechpost', 'https://www.linkedin.com/in/asifrazzaq/']}, {'@type': 'Person', '@id': 'https://www.marktechpost.com/#/schema/person/0dcef949a0a31529265a1c87527edf10', 'name': 'Tanushree Shenwai', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.marktechpost.com/#/schema/person/image/', 'url': 'https://www.marktechpost.com/wp-content/uploads/2020/10/Tanushree-Picture-150x150.jpeg', 'contentUrl': 'https://www.marktechpost.com/wp-content/uploads/2020/10/Tanushree-Picture-150x150.jpeg', 'caption': 'Tanushree Shenwai'}, 'description': 'Tanushree Shenwai is a consulting intern at MarktechPost. She is currently pursuing her B.Tech from the Indian Institute of Technology(IIT), Bhubaneswar. She is a Data Science enthusiast and has a keen interest in the scope of application of artificial intelligence in various fields. She is passionate about exploring the new advancements in technologies and their real-life application.', 'sameAs': ['http://www.marktechpost.com', 'https://www.linkedin.com/in/tanushree-shenwai-98b289188/'], 'url': 'https://www.marktechpost.com/author/tanushree/'}]",,,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vd3d3LnNpbXBsaWxlYXJuLmNvbS9ob3ctYWktYW5kLWF1dG9tYXRpb24tYXJlLWNoYW5naW5nLXRoZS1uYXR1cmUtb2Ytd29yay1hcnRpY2xl0gEA?oc=5,How AI and Automation Are Changing the Nature of Work - Simplilearn,2023-01-19,Simplilearn,https://www.simplilearn.com,Artificial Intelligence and automation are keys to future growth across industries. But how are industries impacted by ai in the nature of work? Read on!,"artificial intelligence and automation, ai and automation, industries impacted by ai, nature of work, ai automation, changing nature of work, artificial intelligence automation, simplilearn, article",Artificial Intelligence and automation are keys to future growth across industries. But how are industries impacted by ai in the nature of work? Read on!,Artificial Intelligence and automation are keys to future growth across industries. But how are industries impacted by ai in the nature of work? Read on!,https://schema.org,BreadcrumbList,How AI and Automation Are Changing the Nature of Work,https://www.simplilearn.com/how-ai-and-automation-are-changing-the-nature-of-work-article,,,,,,,How AI and Automation Are Changing the Nature of Work,,2019-10-06T18:17:29+05:30,2024-07-02T10:58:30+05:30,,,"{'@type': 'Organization', 'name': 'Simplilearn', 'logo': {'@type': 'ImageObject', 'url': 'https://www.simplilearn.com/logo.png', 'width': '200', 'height': '200'}}","{'@type': 'WebPage', '@id': 'https://www.simplilearn.com/how-ai-and-automation-are-changing-the-nature-of-work-article'}","{'@type': 'ImageObject', 'url': 'https://www.simplilearn.com/ice9/free_resources_article_thumb/How_AIandAutomation_arechanging_the_nature_of_work.jpg', 'height': '506', 'width': '900'}","{'@type': 'Person', 'name': 'Eshna Verma', 'url': 'https://www.simplilearn.com/authors/eshna-verma'}",,N/A,N/A," AI, Automation, digital platforms, and other innovations are changing the essential nature of work. AI and automation are transforming how businesses communicate with their consumers, and execute their internal processes, reinventing themselves in the way they operate. Understanding these shifts can help innovators, business leaders, and professionals march forward. According to PwC’s Global Artificial Intelligence Study: Exploiting the AI Revolution, AI could contribute up to $15.7 trillion to the global economy by 2030. This article looks at the top industries impacted by AI and how it’s changing the nature of the workforce these industries require.
Acelerate your career with the AI and ML Certification with Purdue University collaborated with IBM.
Manufacturing
Artificial intelligence and automation are the keys to future growth across industries, and the manufacturing sector is no exception to it. Manufacturers are using AI-backed analytics and data to reduce unplanned downtime, enhance efficiency, product quality, and the safety of employees.  The PwC research also suggests that around 45% of total economic gains by 2030 will be from product enhancements, stimulating consumer demand.
“People skills must evolve to meet the mandates of fluid, totally new, even unforeseen roles that machines cannot fulfill,” says Jeff Kavanaugh, Senior Partner at Infosys Consulting. AI can significantly enhance the quality and scale of work in the manufacturing industry by improving the capabilities of every manufacturing business function.  

Predictive Maintenance
AI helps in enhancing asset utilization, and productivity by predicting unplanned machine and equipment breakdown

Production Enhancement
With the help of AI engines, businesses can successfully identify underlying causes of yield losses and locate the detractors

Quality Enhancement
AI technologies need specialist skills and the automation that manufacturers have already adopted demand skilled workforce. For instance, Cobots, collaborative robots assist humans with complicated tasks. These technologies require humans to program them to perform complex jobs
The adoption of AI in the manufacturing industry should be seen as a positive development, and fruitful results can be achieved through training and re-skilling the existing workforce. AI and automation will allow humans to focus on activities that generate more value for their roles and the business. Working knowledge of the latest technologies used in manufacturing, combined with the hands-on expertise that the current workforce possesses, can position them at the forefront of the manufacturing industry transformation.
Retail
From the advent of Flippy, the robot hamburger chef, to Bingo Box, an entirely unmanned convenience store in China, and Amazon Go, the cashier-less supermarket, the use of robots and AI in the retail sector is growing at a rapid pace. According to IBM, 85% of retail and 79% of consumer products companies aim to use intelligent automation for supply chain planning by 2021. For example, the famous footwear, apparel, and equipment brand, Nike Inc., has designed a system where customers can create their designs and shoes and go out of the store wearing them. This new automated system uses augmented reality, object tracking and projection systems, and voice activation to completely transform the customer’s experience with the brand and its products.
Automation and AI are set to redesign the entire retail industry model and the broader value chain. This transition will result in the emergence of organizations with fewer layers and a better-skilled, and trusted workforce backed by real-time data and analytics. With a more well-rounded team and newer roles that are a hybrid between technology and business, organizations will have a much faster decision-making process. 

Real Estate
AI has already entered the real estate industry and is affecting a massive change to this $480 billion industry—from impacting the home search experience to predicting the marketing trends in the real-estate sector. 

Smart Home Search Portals
AI-enabled home search portals showcase recommended properties that meet customer preferences, personality traits, and requirements. These portals will support fewer, higher-quality properties that suit the needs of the customer better. Chatbots are helping resolve simple questions to help prospective customers find their next home. With AI and Machine Learning, Chatbots are becoming smarter by the day and will soon be able to answer complex search queries through both text and voice, proficiently. Now you can efficiently focus on contracts, answer telephones, and build customer relationships while AI automates much of the manual work.

Enhancing the Buying Process
AI can predict property market values by combining CRM and marketplace data. Robots may soon assist agents in offering a unique buying experience to the customers. Zenplace, a real-estate Startup, is already offering AI-based touring to its customers. AI is slated to play a vital role in enhancing the productivity of agents and offering customers with a user experience that is designed just for them.
Healthcare
Artificial Intelligence is already being used to diagnose and treat diseases. For example, IDx-DR is the first-ever autonomous AI system that instantly detects the condition. With the backing of the U.S. Food and Drug Administration (FDA) to provide diagnostic support, it detects signs of diabetic retinopathy in ocular images and then uses an algorithm to create a binary diagnosis in minutes. AI can be extensively used in treating cardiovascular diseases, as well.
Brain-computer interfaces (BCIs) powered by artificial intelligence can restore neurological abilities of those who’ve suffered a trauma in the past.
Artificial intelligence will build the next generation of radiology tools that are accurate and detailed enough to replace the need for tissue samples, experts say. The same will apply to pathological tests too.
AI will help fill the shortages of trained healthcare providers, especially in the underdeveloped regions.
The presence of AI will assist medical professionals in diagnosing illnesses faster and, using the data collected from AI algorithms, work on finding better solutions. Therefore, it becomes essential for healthcare providers/radiologists/pathologists to learn and implement these technologies.
Here's the bright chance to create your dream career! Enroll in the AI and ML certification courses with Purdue University collaborated with IBM today, and take the first step towards your dream career.
Opportunities Galore - What’s Your Next Step?
Businesses across industries are investing and banking heavily on AI and related technologies. Large firms are shifting focus to developing AI capabilities and changing business strategy accordingly.

(Source: tractica)
With new opportunities and company growth paths, new roles are being created in every area of business operations. Here are some of the most sought-after AI roles:
AI/Machine Learning Researcher - Responsible for improving machine learning algorithms 
AI Software Development, Program Management, and Testing - Developing systems and infrastructure that can use machine learning to derive critical business insights
Data Mining and Analysis - Performing in-depth investigation of huge data sources, often creating and training systems to recognize patterns that will be critical to business decisions
Machine Learning Applications - Responsible for applying machine learning or AI framework to a wide range of business problems, like ad analysis, fraud detection and gesture recognition  

(Source: weforum)
To find out which skills have the highest value, and which job roles fit you the best, analyze how your organization is changing, what are the demands from your current role. Keep an eye out for new opportunities that are coming up in your organization. When you connect these dots, you will find that AI, automation, and machine learning are at the core of all new and in-demand opportunities. A recent study from career and hiring data firm, Paysa indicates that 35% percent of the AI roles need a Ph.D., and another 26% require that candidates possess a master’s degree. Industry-specific certifications will help convince prospective employers that you have the right skills and expertise for a job and make you an in-demand professional. 
Simplilearn offers a host of programs that equip professionals with much-needed knowledge, and industry-read expertise in these cutting edge technologies. Our Artificial Intelligence Course, co-developed with IBM, imparts training on the skills needed for a successful career in AI. Throughout this exclusive training program, you'll master Deep Learning, Machine Learning, and the programming languages required to excel in this domain and kick-start your career in Artificial Intelligence.
You can also take-up the AI and ML courses with Purdue University collaborated with IBM. This program gives you an in-depth knowledge of Python, Deep Learning with the Tensor flow, Natural Language Processing, Speech Recognition, Computer Vision, and Reinforcement Learning. 
The comprehensive Post Graduate Program provides you a joint Simplilearn-Purdue certificate, and also, you become entitled to membership at Purdue University Alumni on course completion. IBM is the leading player in AI and Data Science, helping professionals with relevant industry exposure in the field of AI and Data Science, providing a globally recognized certificate, complete access to IBM Watson for hands-on learning and practice. The game-changing PGP program will help you stand in the crowd and grow your career in thriving fields like AI, machine learning and deep learning. Also check our Master in Artificial Intelligence dual degree designed by the International University of Applied Sciences (IU) Germany in collaboration with the London South Bank University (LSBU).
",,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.simplilearn.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.simplilearn.com/resources', 'name': 'Resources'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.simplilearn.com/resources/artificial-intelligence-machine-learning', 'name': 'AI & Machine Learning'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://www.simplilearn.com/how-ai-and-automation-are-changing-the-nature-of-work-article', 'name': 'How AI and Automation Are Changing the Nature of Work'}}]",,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""]}",,,,,,,,,
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vYmVjb21pbmdodW1hbi5haS9odW1hbi1yZXNvdXJjZS1tYW5hZ2VtZW50LWNoYWxsZW5nZXMtYW5kLXRoZS1yb2xlLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLTIwMjMtNzk5ZmNhODZiZGM50gEA?oc=5,Human Resource Management Challenges and The Role of Artificial Intelligence in 2023 - Becoming Human: Artificial Intelligence Magazine,2023-01-21,Becoming Human: Artificial Intelligence Magazine,https://becominghuman.ai,"Human resource management (HRM) is a critical aspect of any organization as it involves managing the workforce and ensuring that their needs are met. However, HRM faces several challenges that can…",N/A,Human resource management (HRM) is a critical aspect of any organization as it involves managing the workforce and ensuring that their…,Human resource management (HRM) is a critical aspect of any organization as it involves managing the workforce and ensuring that their…,http://schema.org,NewsArticle,Human Resource Management Challenges and The Role of Artificial Intelligence in 2023,https://becominghuman.ai/human-resource-management-challenges-and-the-role-of-artificial-intelligence-in-2023-799fca86bdc9,,,,,,,Human Resource Management Challenges and The Role of Artificial Intelligence in 2023,,2023-01-21T15:06:02.192Z,2023-01-23T22:51:04.318Z,,,"{'@type': 'Organization', 'name': 'Becoming Human: Artificial Intelligence Magazine', 'url': 'becominghuman.ai', 'logo': {'@type': 'ImageObject', 'width': 146, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:292/1*1fYpRTTpKQNa0zuEPe3itg.png'}}",https://becominghuman.ai/human-resource-management-challenges-and-the-role-of-artificial-intelligence-in-2023-799fca86bdc9,['https://miro.medium.com/v2/resize:fit:1200/1*DxOiffow8j9ge10ujt4Kpw.jpeg'],"{'@type': 'Person', 'name': 'Ghulam Mustafa Shoaib', 'url': 'https://becominghuman.ai/@ghulam.mustafa01'}",,N/A,N/A,"Human Resource Management Challenges and The Role of Artificial Intelligence in 2023Ghulam Mustafa Shoaib·FollowPublished inBecoming Human: Artificial Intelligence Magazine·3 min read·Jan 21, 202315ListenShareHuman resource management (HRM) is a critical aspect of any organization as it involves managing the workforce and ensuring that their needs are met. However, HRM faces several challenges that can hinder the performance of the organization. In this article, we will discuss some of the challenges faced by HRM and the role of artificial intelligence (AI) in addressing these challenges in 2023.Challenges Faced by Human Resource Management1. Attracting and Retaining TalentOne of the biggest challenges faced by HRM is attracting and retaining top talent. Organizations struggle to find and retain the best employees in a highly competitive job market. This is especially true for high-demand roles such as data scientists, software engineers, and digital marketing specialists.2. Managing Employee Diversity and InclusionAnother significant challenge faced by HRM is managing employee diversity and inclusion. With the increasing diversity of the workforce, organizations must ensure that all employees are treated fairly and with respect. This includes creating a culture of inclusion, providing training and education, and addressing discrimination and bias.3. Managing Employee EngagementHRM also faces the challenge of managing employee engagement. With the rise of remote work and flexible schedules, keeping employees engaged and motivated can be difficult. This can lead to decreased productivity and higher turnover rates.4. Managing Employee DataHRM also faces the challenge of managing employee data. With the increasing use of technology, organizations must ensure that employee data is accurate, up-to-date, and secure. This includes managing employee information, performance data, and compliance with data privacy laws.The Role of Artificial Intelligence in Addressing HRM Challenges1. Attracting and Retaining TalentAI can help HRM attract and retain talent by automating the recruitment process. This includes using AI-powered chatbots to answer candidate questions, using machine learning algorithms to analyze resumes and identify the best candidates, and using predictive analytics to identify high-potential employees.2. Managing Employee Diversity and InclusionAI can also help HRM manage employee diversity and inclusion by automating the performance review process. This includes using machine learning algorithms to identify bias and discrimination in performance evaluations, providing training and education to employees on diversity and inclusion, and addressing discrimination and bias.3. Managing Employee EngagementAI can help HRM manage employee engagement by automating the employee engagement survey process. This includes using machine learning algorithms to identify areas of improvement, providing feedback and coaching to employees, and tracking progress over time.4. Managing Employee DataAI can help HRM manage employee data by automating the data management process. This includes using machine learning algorithms to identify errors and inconsistencies, providing real-time updates, and ensuring compliance with data privacy laws.ConclusionHRM faces several challenges that can hinder the performance of the organization. However, AI can help address these challenges by automating recruitment, performance evaluations, engagement surveys, and data management. As we move into 2023, we can expect to see more organizations leveraging AI to improve their HRM processes.",,,,,,,,2023-01-21T15:06:02.192Z,799fca86bdc9,['Ghulam Mustafa Shoaib'],,,,,,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vd3d3LmZpbmRsYXcuY29tL2xpdGlnYXRpb24vZmlsaW5nLWEtbGF3c3VpdC9jYW4taS1zdWUtYW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY29tcGFueS1mb3ItYWktY29weXJpZ2h0LXZpLmh0bWzSAQA?oc=5,Can I Sue an Artificial Intelligence Company for AI Copyright Violations? - FindLaw,2023-01-20,FindLaw,https://www.findlaw.com,"FindLaw discusses suing AI companies, like OpenAI, for copyright infringement based on their use of copyrighted works to train their AI models.","Filing a Lawsuit,Civil Court Cases","FindLaw discusses suing AI companies, like OpenAI, for copyright infringement based on their use of copyrighted works to train their AI models.",N/A,https://schema.org,BreadcrumbList,FindLaw,https://www.findlaw.com/litigation/filing-a-lawsuit/can-i-sue-an-artificial-intelligence-company-for-ai-copyright-vi.html,,,,https://www.findlaw.com/,"{'@type': 'ImageObject', 'url': '//www.findlaw.com/static/fi/images/latl/findlaw.png', 'width': '288', 'height': '81'}","['https://www.facebook.com/FindLawConsumers', 'https://twitter.com/findlawconsumer', 'https://en.wikipedia.org/wiki/FindLaw', 'https://www.youtube.com/@findlawconsumers/', 'https://www.pinterest.com/FindLaw_com/', 'https://www.instagram.com/findlaw_com/']",Can I Sue an Artificial Intelligence Company for AI Copyright Violations?,,2023-01-20T09:52:08-0600,2023-12-26T09:24:13-0600,,,{'@id': 'https://www.findlaw.com/'},"{'@type': 'WebPage', '@id': 'https://www.findlaw.com/litigation/filing-a-lawsuit/can-i-sue-an-artificial-intelligence-company-for-ai-copyright-vi.html', 'reviewedBy': [{'@type': 'Person', 'name': 'Joseph Fawbush, Esq.', 'sameAs': 'https://www.findlaw.com/company/our-team.html', 'honorificSuffix': 'Esq.', 'jobTitle': 'Attorney at Law', 'hasCredential': [{'@type': 'EducationalOccupationalCredential', 'credentialCategory': {'@type': 'DefinedTerm', '@id': 'https://credreg.net/ctdl/terms/#License', 'name': 'License', 'inDefinedTermSet': {'@type': 'DefinedTermSet', '@id': 'https://credreg.net/ctdl/terms/occupationType#occupationType', 'name': 'Attorney'}}, 'educationalLevel': {'@type': 'DefinedTerm', '@id': 'https://credreg.net/ctdl/terms/educationLevel', 'name': 'Degree', 'inDefinedTermSet': {'@type': 'DefinedTermSet', '@id': 'https://credreg.net/ctdl/terms/educationLevel#ProfessionalDoctorate', 'name': 'Juris Doctorate'}}}]}], 'lastReviewed': '2023-12-26T09:24:13-0600'}","{'@type': 'ImageObject', 'url': '//www.findlaw.com/static/fi/images/content/original-images/silver-robot.jpg'}","{'@type': 'Person', 'name': 'Steven J. Ellison, Esq.'}",,N/A,N/A,N/A,,,,,"[{'@type': 'ListItem', 'position': '1', 'name': 'FindLaw', 'item': 'https://www.findlaw.com/'}, {'@type': 'ListItem', 'position': '2', 'name': 'Learn About The Law', 'item': 'https://www.findlaw.com/law.html'}, {'@type': 'ListItem', 'position': '3', 'name': 'Litigation and Appeals', 'item': 'https://www.findlaw.com/litigation.html'}, {'@type': 'ListItem', 'position': '4', 'name': 'Filing a Lawsuit', 'item': 'https://www.findlaw.com/litigation/filing-a-lawsuit.html'}, {'@type': 'ListItem', 'position': '5', 'name': 'Can I Sue an Artificial Intelligence Company for AI Copyright Violations?', 'item': 'https://www.findlaw.com/litigation/filing-a-lawsuit/can-i-sue-an-artificial-intelligence-company-for-ai-copyright-vi.html'}]",,,,,,"{'@type': 'Organization', 'name': 'Thomson Reuters Corporation', 'url': 'https://www.thomsonreuters.com/'}",https://www.findlaw.com/company/company-history/editorial-policy.html,https://www.findlaw.com/company/company-history/editorial-policy.html#corrections,"[{'@type': 'ContactPoint', 'telephone': '+1-800-455-4565', 'contactType': 'customer support'}, {'@type': 'ContactPoint', 'telephone': '+1-855-281-8859', 'contactType': 'sales'}]",Litigation & Appeals,"[{'@type': 'State', 'name': ''}, {'@type': 'Place', 'name': ''}]"
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LnRoZW1hbmRhcmluLmNvbS5hdS8yMDk1NDctZ2VuZXJhdGl2ZS1haS1nb3Zlcm5tZW50cy1uZWVkLXRvLXBheS1hdHRlbnRpb24v0gEA?oc=5,Generative AI is having a moment and governments need to pay attention - The Mandarin,2023-01-17,The Mandarin,https://www.themandarin.com.au,"Governments need to understand and use generative AI systems to manage the changes they will bring, says Annan Boag from the Office of the Victorian Information Commissioner.",N/A,"Governments need to understand and use generative AI systems to manage the changes they will bring, says Annan Boag from the Office of the Victorian Information Commissioner.",N/A,https://schema.org,,,,,,,,,,,,,,,,,,,,,N/A,N/A,"

Home Features Generative AI is having a moment and governments need to pay attention
Generative AI is having a moment and governments need to pay attention

By 
				
		 
		Annan Boag				

January 17, 2023





 ‘We need to use new technologies, safely and ethically, to learn how we can use them to better support and protect the communities we serve,’ says Annan Boag from the Office of the Victorian Information Commissioner. (Monster Ztudio/Adobe) 


Like many others, I have been amazed by the text and art people are sharing online, made with nothing but a few words typed into an artificial intelligence (AI) generative deep-learning model (and, some say, the uncredited work of millions of creators).
Working in privacy and technology regulation, I take a professional interest, too. So, when the latest tools became publicly available in December, I had to try them.
I asked an AI to make a rhyme about the law I work with, the Victorian Information Privacy Principles (IPPs). It’s at the end of this article and I will let you judge its quality.
But first I want to talk about the use of AI in government, something I spent much of 2022 thinking about.
Governments are asking how they can – and if they should – use AI
Generative AI is having a moment.
ChatGPT lets you ask a bot to do anything text-based that you can imagine. Draft a contract; write a poem; be a ‘choose your own adventure’ book.




DALL·E 2 will draw whatever you describe. A robot’s self-portrait; Frida Kahlo having tea and scones; an avocado-shaped armchair.
'A robot painting a self-portrait.' (Created by author using generative AI)‘Frida Kahlo having tea and scones.’ (Created by author using generative AI)'An avocado-shaped armchair.' (Created by author using generative AI)
These things once took a lot of time. Human time. Now they are on the cusp of being automated.


It’s natural to ask what the systems that facilitate this can do. And what should they be allowed to do.
In 2022, I did a year-long group research project on AI ethics as part of an executive master of public administration at the Australia and New Zealand School of Government (ANZSOG).
I interviewed more than 20 people across Australian governments who had implemented AI systems. I asked how they considered ethics when doing so.
At one extreme, some people used AI in their jobs after doing a short course in machine learning, to try out their new skills. They did amazing things and soon their whole team was using a system that helped them work better and faster.
How did they know the protections they had built in to address security, privacy, and bias were right? They were confident this could be addressed easily: because we’re developers, we know how everything works under the hood. It’s not a big problem.
We spoke to others who applied a lot of process to ethics including privacy impact and human rights assessments, ethics committee approvals, and risk control plans. But these assessments sometimes happened after development was underway. Ethical processes were “stage gates”, one interviewee said.
Many interviewees had thought about ethics deeply – and importantly, saw it aligned with the missions and values of their agency, and of public service.
“We’re an organisation that is here to support people … we wanted to make sure we were doing that in an appropriate way,” said one interviewee.
Another said: “We took the simple approaches, if we’re sitting there looking at a project, and we feel uncomfortable, if we take the AI part out, we’re still uncomfortable, we’ll take the data part out, are we still uncomfortable? It’s not how we’re doing it, it’s what’s being done”.
Established procedures to assess the ethics of AI and automated decision-making – only NSW and New Zealand have these – gave people confidence to innovate.
Some said the absence of a clear ethical framework and regulation was hampering innovation. Where people didn’t know how to consider and address a nascent ethical concern, they might not proceed with a technology that could otherwise deliver public value. In other cases, the lack of a framework or regulation was causing organisations to unknowingly take on ethical risks they hadn’t considered.
And at the start of December, the discussion of AI went mainstream.
Change is fast and accelerating
Most people who have used the sort of systems I’ve described above will ask, what does this mean? What won’t be apparent to people wading in now is how quickly things are moving.
Ten months ago, at the start of my project, our team used generative AI as a planning tool. The output was crude, and it took skill to write a prompt that gave a useful answer. Sometimes what looked good, was really nonsense.
In November, the tool we were using released a new model. I asked it for “a list of questions to ask people working in large government departments, in an interview for a research project about AI ethics”. The questions (written in seconds) were better than the ones I wrote for my interview plan.
Then at the start of December, ChatGPT’s public beta came out. It guided its millions of users to ask the right questions to get the output they want. It tries to tell them when it can’t help.
I like to think I can still write and think better than an AI. But things are moving fast.
Can government keep up?
It is tempting to pause and reflect. What can these technologies do? How can we use them? Should we use them?
Governments shouldn’t sit on the sidelines because privacy, security, and ethical questions are hard to answer. Agencies need to understand and use these systems well to regulate them effectively and manage the changes they will bring.
We need to use new technologies, safely and ethically, to learn how we can use them to better support and protect the communities we serve.
The people I spoke with who were doing AI and ethics well were those who understood the technology; were connected and collaborative; and were guided by clear values.
How do we build these characteristics in ourselves, our teams, and organisations? And how can we do that quickly, when every month these technologies look more likely to change the world?
I’ll leave you with a final example of generative AI. I asked for a rhyme for each of the 10 information privacy principles in the Privacy and Data Protection Act 2014 (Vic).
Will this technology replace lawyers (or poets)? Absolutely not. Yet.

‘It’s IPP to be square’: an AI-generated poem
IPP 1 – Collection
An organisation must not collect information about you
Unless it’s necessary for what they do
They must collect it fairly and not in an intrusive way
And tell you what they do with it, okay?
 
IPP 2 – Use and disclosure
An organisation must not use or share
Information for a second affair
Unless the individual’s consent it gets
Or when public interests it protects
 
IPP 3 – Data quality
Data must be clear and true,
An org must make sure it’s not askew.
Correct and current, it’s never too late,
To ensure your data’s up to date.
 
IPP 4 – Data security
Data should be safe and sound,
Away from prying eyes around.
And once the data is not needed,
Destroying it should be heeded.
 
IPP 5 – Openness
Organisations must show their privacy plan,
And make it accessible if they can.
Inform the people what data they store,
It’s the law, they must keep score.
 
IPP 6 – Access and correction
IPP 6 is here to protect your rights,
It gives you access to your details and insight.
Knowledge is power, so be sure to inquire,
Access and correction are yours to acquire.
 
IPP 7 – Unique identifiers
Unique identifiers are not our way,
Unless it’s necessary to do our work today.
Assigning unique IDs to individuals,
Only when there’s a valid legal reason.
 
IPP 8 – Anonymity
Anonymity is the name of the game
No one needs to know your name
No need to give yourself away
Your identity can stay out of play
 
IPP 9 – Transborder data flows
Transferring data to those outside of Vic,
Ensure the principles are upheld, that’s the trick.
Privacy must be kept, no matter where it’s sent
Substantially similar laws, or consent
 
IPP 10 – Sensitive data
No matter the data, one must consent
Should it be sensitive, this is the intent
Unless it’s required by law and such
The collection of sensitive information is not in touch


:
Why neurotechnology should matter to policymakers





					About the author
			



 



					By 	
					
		 
		Annan Boag				


 Annan Boag is assistant commissioner, privacy and assurance, at the Office of the Victorian Information Commissioner.








Tags: 
AI ethics
AI in government
artificial intelligence
ChatGPT
DALL·E 2
generative AI
generative deep-learning models
technology regulation
Victorian Information Privacy Principles










 





 Subscribe




 Login 




Notify of 


new follow-up comments
new replies to my comments








 









Please login to comment




0 Comments                    









 Inline Feedbacks                    
View all comments





                                    Load More Comments                                
















Try Mandarin Premium for $4 a week.
Access all the in-depth briefings. New subscribers only.



Get Premium Today 
Already a subscriber? Login





",,,,,,"[{'@type': 'Article', '@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/#article', 'isPartOf': {'@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/'}, 'author': [{'@id': 'https://www.themandarin.com.au/#/schema/person/02bf31f793882e205daa5b0b561207d6'}], 'headline': 'Generative AI is having a moment and governments need to pay attention', 'datePublished': '2023-01-16T21:21:35+00:00', 'dateModified': '2023-01-16T21:21:36+00:00', 'mainEntityOfPage': {'@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/'}, 'wordCount': 1355, 'commentCount': 0, 'publisher': {'@id': 'https://www.themandarin.com.au/#organization'}, 'image': {'@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/#primaryimage'}, 'thumbnailUrl': 'https://www.themandarin.com.au/wp-content/uploads/2023/01/generative-ai.jpg', 'keywords': ['AI ethics', 'AI in government', 'artificial intelligence', 'ChatGPT', 'DALL·E 2', 'generative AI', 'generative deep-learning models', 'technology regulation', 'Victorian Information Privacy Principles'], 'articleSection': ['Communications &amp; Technology', 'Features', 'Thought Leadership'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/#respond']}], 'copyrightYear': '2023', 'copyrightHolder': {'@id': 'https://www.themandarin.com.au/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/', 'url': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/', 'name': 'Generative AI is having a moment. Governments: pay attention', 'isPartOf': {'@id': 'https://www.themandarin.com.au/#website'}, 'primaryImageOfPage': {'@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/#primaryimage'}, 'image': {'@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/#primaryimage'}, 'thumbnailUrl': 'https://www.themandarin.com.au/wp-content/uploads/2023/01/generative-ai.jpg', 'datePublished': '2023-01-16T21:21:35+00:00', 'dateModified': '2023-01-16T21:21:36+00:00', 'description': 'Governments need to understand and use generative AI systems to manage the changes they will bring, says Annan Boag from the Office of the Victorian Information Commissioner.', 'breadcrumb': {'@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/#primaryimage', 'url': 'https://www.themandarin.com.au/wp-content/uploads/2023/01/generative-ai.jpg', 'contentUrl': 'https://www.themandarin.com.au/wp-content/uploads/2023/01/generative-ai.jpg', 'width': 795, 'height': 530, 'caption': ""'We need to use new technologies, safely and ethically, to learn how we can use them to better support and protect the communities we serve,' says Annan Boag from the Office of the Victorian Information Commissioner. (Monster Ztudio/Adobe)""}, {'@type': 'BreadcrumbList', '@id': 'https://www.themandarin.com.au/209547-generative-ai-governments-need-to-pay-attention/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.themandarin.com.au/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Features', 'item': 'https://www.themandarin.com.au/features/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Generative AI is having a moment and governments need to pay attention'}]}, {'@type': 'WebSite', '@id': 'https://www.themandarin.com.au/#website', 'url': 'https://www.themandarin.com.au/', 'name': 'The Mandarin', 'description': 'Australia’s venue for public sector leaders', 'publisher': {'@id': 'https://www.themandarin.com.au/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.themandarin.com.au/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.themandarin.com.au/#organization', 'name': 'The Mandarin', 'url': 'https://www.themandarin.com.au/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.themandarin.com.au/#/schema/logo/image/', 'url': 'https://www.themandarin.com.au/wp-content/uploads/2020/08/mandarin-logo-icon.png', 'contentUrl': 'https://www.themandarin.com.au/wp-content/uploads/2020/08/mandarin-logo-icon.png', 'width': 2000, 'height': 2000, 'caption': 'The Mandarin'}, 'image': {'@id': 'https://www.themandarin.com.au/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/TheMandarinAU', 'https://x.com/theMandarinAU']}, {'@type': 'Person', '@id': 'https://www.themandarin.com.au/#/schema/person/02bf31f793882e205daa5b0b561207d6', 'name': 'Annan Boag', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.themandarin.com.au/#/schema/person/image/9c38e55998783e29c5d7304b2fcc30a0', 'url': 'https://secure.gravatar.com/avatar/ec8029489636a76197db76b170c4a719?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/ec8029489636a76197db76b170c4a719?s=96&d=mm&r=g', 'caption': 'Annan Boag'}, 'description': 'Annan Boag is assistant commissioner, privacy and assurance, at the Office of the Victorian Information Commissioner.', 'jobTitle': '', 'url': 'https://www.themandarin.com.au/author/annan-boag/'}]",,,,,,,,,,
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vd3d3Lm1jYWZlZXRhZnQuY29tL3N0YXRlcy1hbmQtY2l0aWVzLWxpbWl0LWFpLXVzZS1pbi1lbXBsb3ltZW50LWRlY2lzaW9ucy_SAQA?oc=5,States and cities limit AI use in employment decisions - McAfee & Taft,2023-01-20,McAfee & Taft,https://www.mcafeetaft.com,"By Alyssa Lankford The use of artificial intelligence (AI) in employment decision-making is on the rise, with Equal Employment Opportunity Commission (EEOC) chairwoman Charlotte Burrows stating that more than 80% of employers utilize this technology for employment decision-making. Employers can utilize software that incorporates algorithmic decision-making at various stages of…",N/A,"By Alyssa Lankford The use of artificial intelligence (AI) in employment decision-making is on the rise, with Equal Employment Opportunity Commission (EEOC) chairwoman Charlotte Burrows stating that more than 80% of employers utilize this technology for employment decision-making. Employers can utilize software that incorporates algorithmic decision-making at various stages of…","By Alyssa Lankford The use of artificial intelligence (AI) in employment decision-making is on the rise, with Equal Employment Opportunity Commission (EEOC) chairwoman Charlotte Burrows stating that more than 80% of employers utilize this technology for employment decision-making. Employers can utilize software that incorporates algorithmic decision-making at various stages of…",,,,,,,,,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd3d3LnRoZS1zdW4uY29tL3RlY2gvNzE1NTQ2OC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1ib3QtYWxtb3N0LWxhbmRzLWh1bWFuLWpvYi1jaGF0Z3B0LXJlcGx5L9IBamh0dHBzOi8vd3d3LnRoZS1zdW4uY29tL3RlY2gvNzE1NTQ2OC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1ib3QtYWxtb3N0LWxhbmRzLWh1bWFuLWpvYi1jaGF0Z3B0LXJlcGx5L2FtcC8?oc=5,Artificial intelligence bot almost lands human job after genius ChatGPT reply in interview... - The US Sun,2023-01-17,The US Sun,https://www.the-sun.com,A CHATBOT has almost landed a job after providing a detailed and intelligent answer during a digital job interview.The answer was provided by the AI c,"['Artificial Intelligence', 'jobs', 'Robots']",A CHATBOT has almost landed a job after providing a detailed and intelligent answer during a digital job interview. The answer was provided by the AI chatbot called ChatGPT and was so convincing th…,N/A,https://schema.org,NewsArticle,,https://www.the-sun.com/tech/7155468/artificial-intelligence-bot-almost-lands-human-job-chatgpt-reply/,,,,,,,Artificial intelligence bot almost lands human job after genius ChatGPT reply in interview...,,2023-01-17T11:25:04-05:00,2023-01-17T11:45:33-05:00,,,"{'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', 'contactPoint': [{'@type': 'ContactPoint', 'email': 'help@thesun.co.uk', 'contactType': 'Customer Service'}], 'correctionsPolicy': 'https://www.thesun.co.uk/editorial-complaints/', 'foundingDate': '1964-09-15', 'diversityPolicy': 'https://www.the-sun.com/sun-editorial-standards-policies-ethics/', 'ethicsPolicy': 'https://www.the-sun.com/sun-editorial-standards-policies-ethics/', 'publishingPrinciples': 'https://www.the-sun.com/sun-editorial-standards-policies-ethics/', 'sameAs': ['https://www.facebook.com/TheSunUS/', 'https://www.instagram.com/thesunus/', 'https://twitter.com/thesunus'], 'address': {'@type': 'PostalAddress', 'addressCountry': 'USA', 'addressRegion': 'NY', 'addressLocality': 'New York', 'postalCode': '10036', 'streetAddress': '1211 Avenue of the Americas'}, 'logo': {'@type': 'ImageObject', 'url': 'https://www.the-sun.com/wp-content/themes/thesuncom/images/the-sun-structured-data-logo.jpg', 'width': 139, 'height': 60}, '@id': 'https://www.the-sun.com/#publisher', 'url': 'https://www.the-sun.com/', 'name': 'The US Sun'}","{'@type': 'WebPage', '@id': 'https://www.the-sun.com/tech/7155468/artificial-intelligence-bot-almost-lands-human-job-chatgpt-reply/', 'breadcrumb': {'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Tech', 'item': 'https://www.the-sun.com/tech/'}]}}","[{'@type': 'ImageObject', 'url': 'https://www.the-sun.com/wp-content/uploads/sites/6/2023/01/lv-ai-bot-almost-lands-job-off-platform.jpg?strip=all&quality=100&w=1920&h=1080&crop=1', 'width': 1920, 'height': 1080}, {'@type': 'ImageObject', 'url': 'https://www.the-sun.com/wp-content/uploads/sites/6/2023/01/lv-ai-bot-almost-lands-job-off-platform.jpg?strip=all&quality=100&w=1080&h=1080&crop=1', 'width': 1080, 'height': 1080}, {'@type': 'ImageObject', 'url': 'https://www.the-sun.com/wp-content/uploads/sites/6/2023/01/lv-ai-bot-almost-lands-job-off-platform.jpg?strip=all&quality=100&w=1920&h=1080&crop=1', 'width': 1920, 'height': 1080}, {'@type': 'ImageObject', 'url': 'https://www.the-sun.com/wp-content/uploads/sites/6/2023/01/lv-ai-bot-almost-lands-job-off-platform.jpg?strip=all&quality=100&w=1620&h=1080&crop=1', 'width': 1620, 'height': 1080}]","[{'@type': 'Person', 'sameAs': 'https://www.the-sun.com/author/maria-loreto/', 'name': 'M.A. Loreto'}]",Tech,N/A,N/A,"TechI TAKEOVER Artificial intelligence bot almost lands human job after genius ChatGPT reply in interview
M.A. LoretoPublished: 11:25 ET, Jan 17 2023Updated: 11:45 ET, Jan 17 2023Click to share on X/Twitter (Opens in new window)Click to share on Facebook (Opens in new window)A CHATBOT has almost landed a job after providing a detailed and intelligent answer during a digital job interview.The answer was provided by the AI chatbot called ChatGPT and was so convincing that it was shortlisted for an in-person interview. 1An AI chatbot managed to trick hiring managers into believing its answer was realCredit: GettyThe process started after a company called Schwa started accepting applications from various people.Neil Taylor, who owns the business, thought that the opening presented a good opportunity to see how far a chatbot can go in these situations.He thought ChatGPT, a computer program powered by artificial intelligence, was refined enough to trick hiring managers, making them believe that the answer was provided by a real person.ChatGPT's answer ended up being so thorough and effective that it made it to the next round of interviews.READ MORE AIBAD EDUCATION AI chatbot forcing universities to change education due as ChatGPT risesEVIL AI War robots will 'kill civilians' unless we make AI less sexist and hatefulThe job posting prompt asked for applicants to provide “in 300 words, tell us the secret of good writing.”The chatbot was said to provide an answer that was elaborate, concise, easy to read and that answered the prompt’s question in full.“The secret to good writing is simple: tell a good story,” reads the chatbot’s response.“At its core, writing is about communication and connecting with your audience.Most read in TechWINNING WATCH Walmart cuts ‘must-have’ Apple Watch to just $189 as buyers raveAI TAKEOVER Scariest AI breakthroughs incoming: from robo-cops to self-teaching machinesIN MEMORY Hidden Samsung button fixes ‘glitchy and slow’ phones and boosts performanceTV TIME ‘Best seller’ HD TV down to just $88 in surprise Walmart sale“And the best way to do that is by telling a story that resonates with them.“Good writing is about more than just stringing together a bunch of words and hoping they'll stick.""ChatGPT has been making waves for its impressive and human-like writing skills.A popular news outlet has been publishing articles written by AI since November, keeping it on the down low.Tech media site CNET has been publishing the articles since November, and lots of readers don't seem to have noticed.TopicsArtificial IntelligencejobsRobotsYOU MIGHT LIKE",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiN2h0dHBzOi8vdGltZS5jb20vNjI0ODcwNy9zdXJ2ZXktY2hhdGdwdC1haS11c2UtYXQtd29yay_SAQA?oc=5,Survey Reveals 30% of Professionals Have Tried ChatGPT at Work - TIME,2023-01-19,TIME,https://time.com,"Many are using the technology to draft emails, generate ideas, write and troubleshoot bits of code and summarize research or meeting notes.",N/A,"Many are using the technology to draft emails, generate ideas, write and troubleshoot bits of code and summarize research or meeting notes","Many are using the technology to draft emails, generate ideas, write and troubleshoot bits of code and summarize research or meeting notes",,,,,,,,,,,,,,,,,,,,,,N/A,N/A,"By Jo Constantz / BloombergJanuary 19, 2023 10:00 PM ESTSome early adopters are already experimenting with the generative AI program ChatGPT at the office. In seconds, consultants are conjuring decks and memos, marketers are cranking out fresh copy and software engineers are debugging code.Almost 30% of the nearly 4,500 professionals surveyed this month by Fishbowl, a social platform owned by employer review site Glassdoor, said that they’ve already used OpenAI’s ChatGPT or another artificial intelligence program in their work. Respondents include employees at Amazon, Bank of America, JPMorgan, Google, Twitter and Meta. The chatbot uses generative AI to spit out human-like responses to prompts in seconds, but because it’s been trained on information publicly available from the internet, books and Wikipedia, the answers aren’t always accurate.Read More: Exclusive: OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less ToxicWhile ChatGPT set certain corners of the internet ablaze when it launched for public use in November, awareness is still filtering out to the broader public. Experts anticipate that this kind of AI will be transformative: ChatGPT will become the “calculator for writing,” says one top Stanford University economist. Microsoft is in talks with OpenAI about investing as much as $10 billion. The software giant is also looking to integrate GPT, the language model that underlies ChatGPT, into its widely-used Teams and Office software. If that happens, AI tech may very well be brought into the mainstream.Marketing professionals have been particularly keen to test-drive the tool: 37% said they’ve used AI at work. Tech workers weren’t far behind, at 35%. Consultants followed with 30%. Many are using the technology to draft emails, generate ideas, write and troubleshoot bits of code and summarize research or meeting notes.CEOs are using ChatGPT to brainstorm and compose their emails, too. “Anybody who doesn’t use this will shortly be at a severe disadvantage. Like, shortly. Like, very soon,” said Jeff Maggioncalda, chief executive of online learning platform Coursera told CNN. “I’m just thinking about my cognitive ability with this tool. Versus before, it’s a lot higher, and my efficiency and productivity is way higher.”The speed and versatility of the tool has dazzled many users. “I discovered ChatGPT about a month ago,” one person who identified themselves as a chief executive officer posted on FishBowl. “I use it every day. It has changed my life. And my staffing plan for 2023.”Some are even leaning on it as a crutch: One newly hired product manager at a fintech firm asked for advice on FishBowl, saying they were “100% lost” in their new role. “Fake it till you make it like you did the interview. When in doubt, ask ChatGPT,” came the reply.Amid the excitement, researchers have sounded notes of caution.While much of the anxiety has concentrated on what ChatGPT means in education — New York City public schools have banned its use — experts say companies need to think through their policies for the new tool sooner rather than later. If they don’t, they risk some of the pitfalls ChatGPT and other AI models can introduce, like factual errors, copyright infringement and leaks of sensitive company information.Read More: AI Chatbots Are Getting Better. But an Interview With ChatGPT Reveals Their LimitsThe tech is here to stay, though, and will likely become ever-more pervasive. Many AI-assisted programs already exist, and with OpenAI set to release the API, or application programming interface, the number of specialized applications built on the tool will multiply.While some professionals aren’t sold on the practicality of the use cases or quality of the output, others are convinced workers are only a few years away from being supplanted by the technology. “If ChatGPT starts making slides, I am done for,” one Deloitte employee wrote. (“Sorry bro… Already exists,” two others wrote back.)",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vYmxvZy5zYWdpbmZvdGVjaC5jb20vaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW1ha2UtYXVkaXRvcnMtam9ibGVzc9IBUmh0dHBzOi8vYmxvZy5zYWdpbmZvdGVjaC5jb20vaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW1ha2UtYXVkaXRvcnMtam9ibGVzcy9hbXA?oc=5,How Can Artificial Intelligence Make Auditors Jobless? Check - SAG Infotech Blog for GST & Tax Updates,2023-01-20,SAG Infotech Blog for GST & Tax Updates,https://blog.saginfotech.com,"It is an interesting thing to know how artificial intelligence can make auditors jobless. Also, we described machine learning and robotic process.",N/A,"It is an interesting thing to know how artificial intelligence can make auditors jobless. Also, we described machine learning and robotic process.","It is an interesting thing to know how artificial intelligence can make auditors jobless. Also, we described machine learning and robotic process.",https://schema.org,,,,,,,,,,,,,,,,,,,,,N/A,N/A,"

How Can Artificial Intelligence Make Auditors Jobless? Check



 Updated on January 20, 2023Posted byArpit KulshresthaPosted inTaxes in India   12 Minutes Read 


For making the business advantageous every industry would be seen to take upon the upgraded technology in the current rising technological world. Via analyzing the businesses providing effective quality goods and services to the market would be possible which is a tough competition. 
These technologies consist of Artificial intelligence(AI), Robotic process automation (RPA), and Machine learning (ML), which would be seen to be game-changing for every industry however there would be some issues interrupted in between when the technology laid on the industries that perform upon the critical information. 
Technology and auditing would be considered to be the two sides of the identical coin, indeed collaboration of them is shaping strategies at a worldwide level. The mentioned technologies would be in the field of audit at the initial level however with this paper the extent of application would be learned and with the coming time importance and advantages to the companies and the auditing industry. 
The outcomes revealed are in the acceptance of the technology and behind its execution, the investment cost would be standing behind it along with the benefits.
Prior to arriving at the application and impact of these technologies in the field of audit, let’s learn about what is Artificial intelligence (AI), Robotic process automation (RPA), and Machine learning (ML) are.
What is Artificial Intelligence?
Machines are used to demonstrate Artificial intelligence (AI) just opposite to the natural intelligence depicted by humans.
Artificial intelligence (AI) applications consist of advanced web search engines (e.g., Google Assistant), recommendation systems (used by YouTube, Amazon, and Netflix), learning human speech (such as iPhone’s Siri and Amazon’s Alexa), self-driving cars (e.g., Tesla) and others.
Software programs contained Artificial Intelligence which is being installed in the machines via which they enable the operation of different functions that humans could function such as speaking, walking, able to learn, solve problems, thinking, making decisions, and others.
What is Robotics Process Automation (RPA)?
RPA (Robotics Process Automation) emphasizes a bot or software application that could be programmed to function the basic human chores that would generally be manual type. These chores take time, repetitive and errors may occur when the individuals could perform the same. A robot exactly copies the actions of the chair-swivelling person shifting between systems.
RPA furnishes advantages such as robots working non-stop with dynamic speed, implementing accuracy, and scalable. Indeed the repetitive manual chores, freeing up time for employees to perform more value-added activities that are required to get performed are being remembered by robots.
What is Machine Learning (ML)?
Artificial intelligence’s key subset is Machine learning, which comes with the concept that machines can be taught to learn in various ways identical to that humans. On the email spam filter and credit monitoring software, and the news feed and targeted advertising functions of the technology companies like Facebook and Google, some instances of machine learning could be revealed.
Giving employment to an audit firm that does not choose to work within machine learning would direct to drawing a knife to a gunfight. It shall make the process of audit sluggish and also it will create a lower quality audit.
Analysis Between Traditional Auditing and AI Enable Auditing Technology
Traditional auditing methods comprise initiating the process of audit via a meeting conducted with the auditee and hence it consists of the details that have been accumulated via the client. Screening and inspection of documents are indeed attached to work with but merely via a sample basis. It would results in a reasonable assurance via the auditors and would secure more chances of clashing the documents that are concealed by the client.
Through the development of technology, the auditors would now hold the access to database of the client which provides them 100% access to data concerned to the finance and operations of the business. The same shall empower the auditors to increase their horizons and access the company’s information. Through analytical tools and artificial intelligence, it could empower the auditors to set the risky areas of business. It consists of auto-identification of the risky fields, setting outliers, conducting a quick analytical review of the former data, and to an extent enabling the auditors to inspect the compliance with the Accounting & Auditing Standards.
Importance of Artificial Intelligence in Auditing
The reliance on the present system through the AI-based auditioning model shall get reduced human intervention and draw more clarity to the system.
We must recognize that auditing is more than just checking the genuine and fair position of internal and external affairs; it also serves as a predictive model, alerting the system to potential gaps in the near future. When an AI-based auditing model is built, the same machine learning tool will be the primary server for identifying holes and potential threats in present company operations.
Over the last decade, we have strengthened severe auditing regulations and standards to boost efficiency, yet loopholes continue to emerge because fraud offenders are sharper than highly trained auditors. All auditors can construct a model of AI-based auditing model through Machine learning (which is a continuous process), but accumulating in one centre will assist auditing to be more efficient and less detrimental to individual/firm misconduct.
Read Also: How Artificial Intelligence is Transforming & Upgrading Accounting?
Verifiable audit trails may be established using blockchain, and auditors can readily find flaws in the chain and highlight them through reporting to businesses using artificial intelligence. Auditors typically create audit trails in their audit procedures in order to analyze the underlying cause of an issue that requires rigorous verification. However, using artificial intelligence, data analytics techniques, and blockchain technology, can be done quickly and easily increasing auditor efficiency.
Artificial intelligence is more of a process that encompasses Data Analytics, Machine Learning, and Data Processing. The following are examples of artificial intelligence applications in the audit process:
During the audit planning step, AI gains a preliminary understanding of the customer and their industry. Data from financial accounts, operational procedures, and organizational structure may be collected, aggregated, and analyzed by AI.
Robotic process automation (RPA) and data analytics may be utilized for a variety of activities, including pulling data from earlier periods or interim financial statements based on a variety of benchmarks, to establish the materiality and scope of the audit.
Following that, AI evaluates the audit client’s internal control and risk elements. Flowcharts, narratives, and surveys will be analyzed and reported on to identify anomalies. At this moment, AI is reliant on pattern recognition and visualization methods. Data quality and provenance from the full population are evaluated during the substantive testing and details balance stage. Finally, a conclusion is formed based on AI results.
Important: Everything About I-T Portal Co-browsing Feature with Issues
These AI tools enable auditors to automate jobs that had previously been performed manually by people for decades, allowing them to fragment what was previously a tradeoff between time, cost, and quality. Auditors may prioritize quality by examining sophisticated analytics, spending more time offering insight, and exercising greater professional judgment. Today, automation has replaced manual vouching and administrative tasks, as has the growth of data analytics for quicker data access. Accounting entries may be automatically coded using machine learning. Another example of AI in the audit industry is the rapid assessment of a large number of contracts. Important information from an agreement, often a lease deal, is retrieved and summarised using pre-selected criteria. All of the above-described AI benefits result in more efficient and methodical audit methods, resulting in a higher quality audit.
Different Ways in Which AI Impact the Audit Operations
Auditors can use AI for various purposes – 

Automate manual tasks of auditors such as documentation.
Examine the whole volume of structured and unstructured data that arrive through financial records by parsing data.
Finding out the anomalies like unusual payments or activities that do not be caught via manual auditing.
Forecasting the risks involved in future, events by analyzing the former transaction data.

Through AI and machine learning capabilities the auditors perform the advisory type of work like finding the entirety of ledgers and reporting the risk to the executives, and clients during increasing their audit services.For complex analysis of financial data, AI might not be the correct choice. The same could be perfect for counting items, spotting patterns, and flagging irregularities to a level that satisfies and surpasses the needs of a company.
The basic area in which AI audits would be impacting the auditing is the automated entries. Robotic Process Automation (RPA) would enable ease of the operation of data entry for the accountants and auditors. Robotic Process Automation chores can be utilised to function testing like data analytics to enhance the efficiency and accuracy of our work.
At present other than RPA machine learning is the biggest new technology in audit. Machine learning strategies in which via complex algorithms, the technology could able to scan information, model it against thousands of assumptions drawn from external scenarios, and highlight risks and insights.
Since there is always a need for human judgment and professional suspicion, the fundamentals of the audit shall not get revised. The perfect use of the technology would be that shall empower us to collect easily, quickly, accurately, and extensively compare to ever before the supportive proof that is required in an audit.
AI Helps Auditors to Improve the Auditing Process
The speed along with the quality of audits can be enhanced by Machine learning as of its higher potential. Through the utilization of AI for the tough ticking and tying chores which are the inevitable portion of the auditing function, for reviewing the auditors secure more time and are unable to concentrate on the harder part and the higher-risk areas. The additional time along with mental power has accumulated which makes the auditors able to see the case in the wider picture. Audit firms that leverage AI and data analytics to consider the approach of data for audit shall furnish a competitive benefit as they could furnish useful insights to their clients above the audit report.
AI would be utilised by some tools for testing the journal entries to reveal suspicious entries. The other would relate the financial information with the unstructured nonfinancial information to ensure that business performance is constant through its operating environment and business model. These tools would not be the replacement for the auditor’s understanding of businesses and industries, however able to enhance the auditor’s human intelligence to furnish valuable insights to customers which shall assist them to achieve their goals.
Future of Artificial Intelligence (AI) Tools
In the future, the human-to-human interaction audit shall get decreased concerned with highly repetitive and rules-based assignments. The use of the interface tools can be done for automatically sharing the data in real-time with the external auditor’s AI tool(s), which in turn compute, test, and flag irregularities or problems that need the attention of the auditor. It concentrates the human interaction on transactions that has higher risk contrary to the daily inquiries.
Beneath the same case, AI tools are powered to find out the distinctive transactions and furnish insights on related considerations the auditor may consider along with the subjected standards (accounting, disclosure, auditing, or regulatory standards), identical historical circumstances, or results from the source which is publicly available. For supporting the auditors in finding the risks and asking for appropriate supporting details, and the schedule meets with the related people to communicate in the case of an audit, the AI tool is useful for computing the board meetings minutes or key communications. It is performed to process bigger amounts of information (reading bank statements and legal contracts) and reconcile accounts various times quicker than a human auditor and with only some errors. With AI the auditors would be constrained to process their operations as AI would be the future. Hence the auditors shall be required to be more flexible to revise in the future.
Is it True That Artificial Intelligence Will Take Away Auditor Jobs
Yes, if the machine decides the management and not only supports making decisions. It is normal to see fear in finance professionals. However, in current times in my view, people must not be worried. AI utilization in India is very less at present compared to the western world, however, the same would be surging. The issues or creative chores that the professionals are worried about currently will be free once some of the things choose to be managed by the machines. In the former times, we have already seen the fear of computers.Various employees feel that they are useless excluding those who had to opt for the change when the computers initiated doing the majority of the work.
Professional judgment in auditing and financial processes shall not get replaced by AI. Firms shall always require human-powered essential thinking, nevertheless of the AI impact on the accounting industry.
The research stands with the opposite of the job losing fear because of AI, AI is a tool that supports the auditors to perform their jobs effectively and efficiently. There is no chance that AI replaces the decision of auditor, judgment, or assessment skill. The same shall increase efficiency by providing them with more tools and effective findings to work. The human relationship between the client and the auditor would stay essential and technology cannot replace everything.
Closure
AI along with robotics shall make our thinking precise, the direction through which we explore new horizons, space, or ocean. From an older saying, “necessity is the mother of all innovations,” hence AI is similar to that.
At present, the condition of the audit with the AI application, data analytics, and tools would be at the initial time, and transforming the audit field with 100% application of the technology mentioned would consume somewhat more time. AI, machine learning, and robotic process automation would retain the potential to overcome various chores that have been performed by accountants and auditors however they are not able to substitute the professional judgment, insight, and direction that merely a person/human could deliver, at least for the foreseeable future.
FacebookTwitterLinkedInPinterestPrintFriendly




Disclaimer:- ""All the information given is from credible and authentic resources and has been published after moderation. Any change in detail or information other than fact must be considered a human error. The blog we write is to provide updated information. You can raise any query on matters related to blog content. Also, note that we don’t provide any type of consultancy so we are sorry for being unable to reply to consultancy queries. Also, we do mention that our replies are solely on a practical basis and we advise you to cross verify with professional authorities for a fact check.""







			Published by Arpit Kulshrestha		

		Arpit Kulshrestha seeks higher interests in financial services, taxation, GST, I-T, etc. Writes articles with depth knowledge and is extensive for the same. The resources provide effective articles for the products of SAG infotech which provides taxation and IT software. Writing from observations and researching makes his articles virtuous.		
			View more posts		




 
",,,,,,"[{'@type': 'Article', '@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless#article', 'name': 'How Can Artificial Intelligence Make Auditors Jobless? Check', 'headline': 'How Can Artificial Intelligence Make Auditors Jobless? Check', 'author': {'@id': 'https://blog.saginfotech.com/author/arpit#author'}, 'publisher': {'@id': 'https://blog.saginfotech.com/#organization'}, 'image': {'@type': 'ImageObject', 'url': 'https://blog.saginfotech.com/wp-content/uploads/2023/01/artificial-intelligence-vs-auditors.jpg', 'width': 1200, 'height': 630, 'caption': 'Artificial Intelligence vs Auditors'}, 'datePublished': '2023-01-20T11:54:13+05:30', 'dateModified': '2023-01-20T11:54:48+05:30', 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless#webpage'}, 'isPartOf': {'@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless#webpage'}, 'articleSection': 'Taxes in India'}, {'@type': 'BreadcrumbList', '@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless#breadcrumblist', 'itemListElement': [{'@type': 'ListItem', '@id': 'https://blog.saginfotech.com/#listItem', 'position': 1, 'name': 'Home'}]}, {'@type': 'Organization', '@id': 'https://blog.saginfotech.com/#organization', 'name': 'SAG Infotech Private Limited', 'description': 'SAG Infotech Official Tax Blog', 'url': 'https://blog.saginfotech.com/', 'telephone': '+911414072000', 'logo': {'@type': 'ImageObject', 'url': 'https://blog.saginfotech.com/wp-content/uploads/2019/11/sag-infotech-logo.jpg', '@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless/#organizationLogo', 'width': 800, 'height': 640, 'caption': 'sag infotech privated limited logo'}, 'image': {'@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless/#organizationLogo'}, 'sameAs': ['https://www.facebook.com/SagInfotechPvtLtd/', 'https://twitter.com/sagInfotech', 'https://www.instagram.com/saginfotech/', 'https://in.pinterest.com/saginfotech/', 'https://www.youtube.com/c/saginfotech?sub_confirmation=1', 'https://www.linkedin.com/company/saginfotechpvtltd/']}, {'@type': 'Person', '@id': 'https://blog.saginfotech.com/author/arpit#author', 'url': 'https://blog.saginfotech.com/author/arpit', 'name': 'Arpit Kulshrestha', 'image': {'@type': 'ImageObject', '@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless#authorImage', 'url': 'https://secure.gravatar.com/avatar/0f07cd1d83cded4552178bb453784bcc?s=96&d=blank&r=g', 'width': 96, 'height': 96, 'caption': 'Arpit Kulshrestha'}}, {'@type': 'WebPage', '@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless#webpage', 'url': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless', 'name': 'How Can Artificial Intelligence Make Auditors Jobless? Check', 'description': 'It is an interesting thing to know how artificial intelligence can make auditors jobless. Also, we described machine learning and robotic process.', 'inLanguage': 'en-US', 'isPartOf': {'@id': 'https://blog.saginfotech.com/#website'}, 'breadcrumb': {'@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless#breadcrumblist'}, 'author': {'@id': 'https://blog.saginfotech.com/author/arpit#author'}, 'creator': {'@id': 'https://blog.saginfotech.com/author/arpit#author'}, 'image': {'@type': 'ImageObject', 'url': 'https://blog.saginfotech.com/wp-content/uploads/2023/01/artificial-intelligence-vs-auditors.jpg', '@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless/#mainImage', 'width': 1200, 'height': 630, 'caption': 'Artificial Intelligence vs Auditors'}, 'primaryImageOfPage': {'@id': 'https://blog.saginfotech.com/how-artificial-intelligence-make-auditors-jobless#mainImage'}, 'datePublished': '2023-01-20T11:54:13+05:30', 'dateModified': '2023-01-20T11:54:48+05:30'}, {'@type': 'WebSite', '@id': 'https://blog.saginfotech.com/#website', 'url': 'https://blog.saginfotech.com/', 'name': 'SAG Infotech Official Tax Blog', 'description': 'SAG Infotech Official Tax Blog', 'inLanguage': 'en-US', 'publisher': {'@id': 'https://blog.saginfotech.com/#organization'}}]",,,,,,,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,publisher,datePublished,dateModified,headline,image,thumbnailUrl,mainEntityOfPage,author,article:section,article:summary,article text,name,text,about,headLine,articleBody,itemListElement,@graph,articleSection,isAccessibleForFree,speakable,potentialAction,logo,sameAs,address,width,height,worksFor,mainEntity,hasPart
https://news.google.com/rss/articles/CBMiKGh0dHBzOi8vd3d3LmJiYy5jby51ay9uZXdzcm91bmQvNDkyNzQ5MTjSASxodHRwczovL3d3dy5iYmMuY28udWsvbmV3c3JvdW5kLzQ5Mjc0OTE4LmFtcA?oc=5,What is AI? What does artificial intelligence do? - BBC,2019-08-09,BBC,https://www.bbc.co.uk,The technology around artificial intelligence - or AI as it is commonly known - is becoming more and more advanced. But what exactly is AI and what can it be used for?,N/A,The technology around artificial intelligence - or AI as it is commonly known - is becoming more and more advanced. But what exactly is AI and what can it be used for?,The technology around artificial intelligence - or AI as it is commonly known - is becoming more and more advanced. But what exactly is AI and what can it be used for?,http://schema.org,CreativeWork,https://www.bbc.co.uk/newsround/49274918,"{'@type': 'Organization', 'name': 'BBC Newsround', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/newsround/images/metadata/poster-1024x576.png'}}",2019-08-08T16:38:51.000Z,2019-08-09T07:14:10.000Z,What is AI? What does artificial intelligence do?,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_bbc/14202/production/_108243428_gettyimages-871148930.jpg'}",https://ichef.bbci.co.uk/news/1024/branded_bbc/14202/production/_108243428_gettyimages-871148930.jpg,https://www.bbc.co.uk/newsround/49274918,"{'@type': 'Organization', 'name': 'BBC Newsround', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/newsround/images/metadata/poster-1024x576.png'}}",CBBC Newsround,N/A,"What is AI? What does artificial intelligence do?Published9 August 2019comments21 CommentsImage source, Getty ImagesArtificial intelligence - or AI for short - is technology that enables a computer to think or act in a more 'human' way. It does this by taking in information from its surroundings, and deciding its response based on what it learns or senses.It affects the the way we live, work and have fun in our spare time - and sometimes without us even realising.AI is becoming a bigger part of our lives, as the technology behind it becomes more and more advanced. Machines are improving their ability to 'learn' from mistakes and change how they approach a task the next time they try it.Some researchers are even trying to teach robots about feelings and emotions.You might not realise some of the devices and daily activities which rely on AI technology - phones, video games and going shopping, for example.More technologyWhy did this photo make history 60 years ago?How robots and drones are changing deliveriesFlyboard inventor crosses English ChannelWhy Instagram is going to hide your 'likes'Some people think that the technology is a really good idea, while others aren't so sure. Just this month, it was announced that the NHS in England is setting up a special AI laboratory to boost the role of AI within the health service.Announcing that the government will spend £250 million on this, Health Secretary Matt Hancock said the technology had ""enormous power"" to improve care, save lives and ensure doctors had more time to spend with patients.Read on to find out more about AI and let us know what you think about it in the comments below.What does AI do?AI can be used for many different tasks and activities.Personal electronic devices or accounts (like our phones or social media) use AI to learn more about us and the things that we like. One example of this is entertainment services like Netflix which use the technology to understand what we like to watch and recommend other shows based on what they learn.It can make video games more challenging by studying how a player behaves, while home assistants like Alexa and Siri also rely on it.Image source, Getty ImagesImage caption, It has been announced that NHS England will spend millions on AI in order to improve patient care and researchAI can be used in healthcare, not only for research purposes, but also to take better care of patients through improved diagnosis and monitoring.It also has uses within transport too. For example, driverless cars are an example of AI tech in action, while it is used extensively in the aviation industry (for example, in flight simulators).Farmers can use AI to monitor crops and conditions, and to make predictions, which will help them to be more efficient.You only have to look at what some of these AI robots can do to see just how advanced the technology is and imagine many other jobs for which it could be used.Where did AI come from?The term 'artificial intelligence' was first used in 1956.In the 1960s, scientists were teaching computers how to mimic - or copy - human decision-making. This developed into research around 'machine learning', in which robots were taught to learn for themselves and remember their mistakes, instead of simply copying. Algorithms play a big part in machine learning as they help computers and robots to know what to do.What is an algorithm?An algorithm is basically a set of rules or instructions which a computer can use to help solve a problem or come to a decision about what to do next.From here, the research has continued to develop, with scientists now exploring 'machine perception'. This involves giving machines and robots special sensors to help them to see, hear, feel and taste things like human do - and adjust how they behave as a result of what they sense.The idea is that the more this technology develops, the more robots will be able to 'understand' and read situations, and determine their response as a result of the information that they pick up.Why are people worried about AI?Many people have concerns about AI technology and teaching robots too much.Famous scientist Sir Stephen Hawking spoke out about it in the past. He said that although the AI we've made so far has been very useful and helpful, he worried that if we teach robots too much, they could become smarter than humans and potentially cause problems.Image source, Getty ImagesImage caption, Sir Stephen Hawking spoke out about AI and said that he had concerns that the technology could cause problems in the futurePeople have expressed concerns about privacy too. For example, critics think that it could become a problem if AI learns too much about what we like to look at online and encourages us to spend too much time on electronic devices.Another concern about AI is that if robots and computers become very intelligent, they could learn to do jobs which people would usually have to do, which could leave some people unemployed.Other people disagree, saying that the technology will never be as advanced as human thoughts and actions, so there is not a danger of robots 'taking over' in the way that some critics have described.What do you think about AI? Do you think that it is a good thing or a bad thing? Let us know in the comments below.More on this storyCould your teacher be replaced by a robot?Published12 November 2018Watch: The girls building robots at home. Video, 00:01:33Watch: The girls building robots at homePublished14 May 20171:33",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vd3d3Lmdvdi51ay9nb3Zlcm5tZW50L25ld3MvaGVhbHRoLXNlY3JldGFyeS1hbm5vdW5jZXMtMjUwLW1pbGxpb24taW52ZXN0bWVudC1pbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZdIBAA?oc=5,Health Secretary announces £250 million investment in artificial intelligence - GOV.UK,2019-08-08,GOV.UK,https://www.gov.uk,A new National Artificial Intelligence Lab will use the power of artificial intelligence (AI) to improve the health and lives of patients.,N/A,A new National Artificial Intelligence Lab will use the power of artificial intelligence (AI) to improve the health and lives of patients.,N/A,http://schema.org,BreadcrumbList,,"{'@type': 'Organization', 'name': 'GOV.UK', 'url': 'https://www.gov.uk', 'logo': {'@type': 'ImageObject', 'url': 'https://www.gov.uk/assets/government-frontend/govuk_publishing_components/govuk-logo-b15a4d254746d1642b8187217576d1e8fe50b51352d352fda13eee55d3c1c80a.png'}}",2019-08-08T10:20:00+01:00,2019-08-08T10:20:00+01:00,,['https://assets.publishing.service.gov.uk/media/5d4d859340f0b65a01b9d511/s960_surgeon_using_tech_960.jpg'],,"{'@type': 'WebPage', '@id': 'https://www.gov.uk/government/news/health-secretary-announces-250-million-investment-in-artificial-intelligence'}","{'@type': 'Organization', 'name': 'Department of Health and Social Care', 'url': 'https://www.gov.uk/government/organisations/department-of-health-and-social-care'}",N/A,N/A,N/A,Health Secretary announces £250 million investment in artificial intelligence,A new National Artificial Intelligence Lab will use the power of artificial intelligence (AI) to improve the health and lives of patients.,"[{'@context': 'http://schema.org', '@type': 'Thing', 'sameAs': 'https://www.gov.uk/health-and-social-care/technology-in-health-and-social-care'}]",Health Secretary announces £250 million investment in artificial intelligence,"<div class=""govspeak""><p>The <abbr title=""artificial intelligence"">AI</abbr> Lab will bring together the industry’s best academics, specialists and technology companies to work on some of the biggest challenges in health and care, including earlier cancer detection, new dementia treatments and more personalised care.</p>

<p><abbr title=""artificial intelligence"">AI</abbr> is already being developed in some hospitals, successfully predicting cancer survival rates and cutting the number of missed appointments.</p>

<p>The <abbr title=""artificial intelligence"">AI</abbr> Lab’s work could:</p>

<ul>
  <li>improve cancer screening by speeding up the results of tests, including mammograms, brain scans, eye scans and heart monitoring</li>
  <li>use predictive models to better estimate future needs of beds, drugs, devices or surgeries</li>
  <li>identify which patients could be more easily treated in the community, reducing the pressure on the NHS and helping patients receive treatment closer to home</li>
  <li>identify patients most at risk of diseases such as heart disease or dementia, allowing for earlier diagnosis and cheaper, more focused, personalised prevention</li>
  <li>build systems to detect people at risk of post-operative complications, infections or requiring follow-up from clinicians, improving patient safety and reducing readmission rates</li>
  <li>upskill the NHS workforce so they can use <abbr title=""artificial intelligence"">AI</abbr> systems for day-to-day tasks</li>
  <li>inspect algorithms already used by the NHS to increase the standards of <abbr title=""artificial intelligence"">AI</abbr> safety, making systems fairer, more robust and ensuring patient confidentiality is protected</li>
  <li>automate routine admin tasks to free up clinicians so more time can be spent with patients</li>
</ul>

<p>The lab will sit within NHSX, the new organisation that will oversee the digitisation of the health and care system, in partnership with the Accelerated Access Collaborative.</p>

<p>The investment will support the ambitions in the NHS Long Term Plan, which includes pledges to use <abbr title=""artificial intelligence"">AI</abbr> to help clinicians eliminate variations in care.</p>

<p>The Prime Minister said:</p>

<blockquote>
  <p>The NHS is revered for the world-class care it provides every day – a treasured institution that showcases the very best of Britain.</p>

  <p>But it is also leading the way in harnessing new technology to treat and prevent, from earlier cancer detection to spotting the deadly signs of dementia.</p>

  <p>Today’s funding is not just about the future of care though. It will also boost the frontline by automating admin tasks and freeing up staff to care for patients.</p>

  <p class=""last-child"">My task is to ensure the NHS has the funding it needs to make a real difference to the lives of staff and patients. Transforming care through artificial intelligence is a perfect illustration of that.</p>
</blockquote>

<p>Health Secretary Matt Hancock said:</p>

<blockquote>
  <p>We are on the cusp of a huge health tech revolution that could transform patient experience by making the NHS a truly predictive, preventive and personalised health and care service.</p>

  <p>I am determined to bring the benefits of technology to patients and staff, so the impact of our NHS Long Term Plan and this immediate, multimillion pound cash injection are felt by all. It’s part of our mission to make the NHS the best it can be.</p>

  <p class=""last-child"">The experts tell us that because of our NHS and our tech talent, the UK could be the world leader in these advances in healthcare, so I’m determined to give the NHS the chance to be the world leader in saving lives through artificial intelligence and genomics.</p>
</blockquote>

<p>Simon Stevens, NHS England Chief Executive, said:</p>

<blockquote>
  <p>Carefully targeted <abbr title=""artificial intelligence"">AI</abbr> is now ready for practical application in health services, and the investment announced today is another step in the right direction to help the NHS become a world leader in using these important technologies.</p>

  <p class=""last-child"">In the first instance it should help personalise NHS screening and treatments for cancer, eye disease and a range of other conditions, as well as freeing up staff time, and our new NHS <abbr title=""artificial intelligence"">AI</abbr> Lab will ensure the benefits of NHS data and innovation are fully harnessed for patients in this country.</p>
</blockquote>

</div>","[{'@type': 'ListItem', 'position': 1, 'item': {'name': 'Home', '@id': 'https://www.gov.uk/'}}, {'@type': 'ListItem', 'position': 2, 'item': {'name': 'Health and social care', '@id': 'https://www.gov.uk/health-and-social-care'}}, {'@type': 'ListItem', 'position': 3, 'item': {'name': 'Technology in health and social care', '@id': 'https://www.gov.uk/health-and-social-care/technology-in-health-and-social-care'}}]",,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vc2xvYW5yZXZpZXcubWl0LmVkdS9hcnRpY2xlL2hvdy1jaXRpZXMtc2hvdWxkLXByZXBhcmUtZm9yLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,How Cities Should Prepare for Artificial Intelligence - MIT Sloan Management Review,2019-08-07,MIT Sloan Management Review,https://sloanreview.mit.edu,How cities deal with AI-related changes will determine which ones will thrive in the future.,N/A,How cities deal with AI-related changes will determine which ones will thrive in the future.,How cities deal with AI-related changes will determine which ones will thrive in the future.,,,,,,,,,,,,N/A,N/A,"


Frontiers How Cities Should Prepare for Artificial Intelligence
It’s time for city administrations and local employers to close AI-related skills gaps.

Timocin Pervane and Kaijia Gu

August 07, 2019

Reading Time: 6 min 





Topics


Data, AI, & Machine Learning


Strategy


Leading Change


Global Strategy


AI & Machine Learning


Technology Implementation


Skills & Learning




Frontiers

            An MIT SMR initiative exploring how technology is reshaping the practice of management.        

              
           More in this series
                      




 subscribe-icon

Subscribe
 










Share



 Twitter



Facebook







Linkedin










What to Read Next

 How to Create Slides That Suit Your Superiors: 11 Tips | Nancy Duarte
 Three Questions to Ask About Your Digital Strategy
 When Hybrid Work Strategy Aggravates 20-Somethings | Brian Elliott and Amanda Schneider
 The Six Most Popular Stories of 2024 — So Far














While there is much discussion of how artificial intelligence will continue to transform industries and organizations, a key driver of AI’s role in the global economy will be cities. How cities deal with coming changes will determine which ones will thrive in the future. 
Many cities have plans to become “smart cities” armed with AI-driven processes and services, like AI-based traffic control systems, to improve residents’ lives. But simply adopting these new technologies won’t be enough to guarantee their success. Jobs that exist today may not exist tomorrow. Completely new jobs will need to be filled quickly. Many people today don’t yet have the skills needed for the jobs of the future. Yet cities cannot just shrink and grow their populations and talent at will.
To realize the potential of AI, city administrations have to work with local employers to plan for new opportunities — along with possible painful transitions — that their communities may experience. Many U.S. cities once dependent on manufacturing industries have made the shift to knowledge-based economies, including cities like Pittsburgh, Pennsylvania; Rochester, New York; and Madison, Wisconsin. In order for these economies to continue to prosper, cities — along with organizations and education experts — need to assess and prepare for AI-related skills gaps.
Urban Shifts
As with other technological revolutions, the move toward widespread use of AI will likely trigger urban shifts in cities. To better understand the scope of these, we conducted three studies. First, we examined how many people in American cities work in jobs with a greater than 70% probability of being automated. Applying a framework developed by Oxford University researchers Carl Benedikt Frey and Michael Osborne to 24 major U.S. cities, we found that between 33% and 44% of people work in jobs considered at high risk, including retail salespeople, cashiers, office workers, and other service-related jobs. 
That means millions of people will likely need assistance in transitioning to new jobs and roles as soon as within the next five years. In cities like New York and Los Angeles, with millions employed, many workers will need to find new professions (such as those in highly vulnerable roles such as tax preparers, loan officers, bank tellers, receptionists, and administrative assistants) as the nature of work is completely transformed. 



Topics


Data, AI, & Machine Learning


Strategy


Leading Change


Global Strategy


AI & Machine Learning


Technology Implementation


Skills & Learning




Frontiers

            An MIT SMR initiative exploring how technology is reshaping the practice of management.        

              
           More in this series
                      



About the Authors
Timocin Pervane is a Boston-based partner and Kaijia Gu is a London-based partner at Oliver Wyman. Both are leaders of the Oliver Wyman Forum. 



Tags: 

Artificial Intelligence
Education
Employment
Future of Work
Global Economy & Trade
Job Creation
Smart Cities





More Like This
           Lights, AI, Action: Wonder Dynamics’s Tye Sheridan              MIT SMR Connections | Strategic Shift: Skills-Powered Organizations in the Age of AI                What the Smart Money Says About Black CEOs                Use Open Source for Safer Generative AI Experiments     
 


Add a comment Cancel replyYou must sign in to post a comment.First time here? Sign up for a free account: Comment on articles and get access to many more articles. 

",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS9zb2NpZXR5LzIwMTkvYXVnLzA4L2JvcmlzLWpvaG5zb24tcGxlZGdlcy0yNTBtLWZvci1uaHMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2XSAWpodHRwczovL2FtcC50aGVndWFyZGlhbi5jb20vc29jaWV0eS8yMDE5L2F1Zy8wOC9ib3Jpcy1qb2huc29uLXBsZWRnZXMtMjUwbS1mb3ItbmhzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl?oc=5,Boris Johnson pledges £250m for NHS artificial intelligence - The Guardian,2019-08-07,The Guardian,https://www.theguardian.com,Health experts question whether cash will come from trade-offs elsewhere in service,N/A,Health experts question whether cash will come from trade-offs elsewhere in service,N/A,,,,,,,,,,,,Society,N/A," Boris Johnson claimed artificial intelligence would cut waiting times. Photograph: Darren Staples/AFP/Getty ImagesView image in fullscreenBoris Johnson claimed artificial intelligence would cut waiting times. Photograph: Darren Staples/AFP/Getty ImagesNHS This article is more than 4 years oldBoris Johnson pledges £250m for NHS artificial intelligenceThis article is more than 4 years oldHealth experts question whether cash will come from trade-offs elsewhere in serviceSarah Boseley Health editorWed 7 Aug 2019 19.01 EDTShareThe government has announced its third successive hand-out to the NHS in as many days with a pledge by Boris Johnson of £250m to be invested in artificial intelligence.The prime minister claimed AI would transform care and cut waiting times as he announced the money for a national artificial intelligence lab, to work on digital advances to improve the detection of diseases by predicting who is most likely to get them.However, health experts warned that the NHS had a poor record with technology and any new systems would need “robust evaluation” to ensure they did more good than harm as well as proper implementation with safety standards and training. They also raised concerns over where the money was coming from and whether it was the result of trade-offs elsewhere in the cash-strapped health service.AI is already being used in some hospitals to predict cancer survival and cut the number of missed appointments. It is used to identify those patients most likely not to turn up, who will then be given a reminder phone call.On Tuesday, the prime minister promised £1.8bn towards the maintenance and rebuilding of crumbling hospitals, estimated to need a total of £6bn. On Wednesday, he promised changes to a pension tax hitting the best-paid doctors and nurses that has resulted in their cutting back on extra shifts. The latest announcement would help the NHS become a world leader in AI, he said.Boris Johnson’s £1.8bn for the NHS isn’t what it seems – just ask the trustsSally GainsburyRead moreJohnson said the NHS was “leading the way in harnessing new technology to treat and prevent, from earlier cancer detection to spotting the deadly signs of dementia”.“Today’s funding is not just about the future of care though. It will also boost the frontline by automating admin tasks and freeing up staff to care for patients,” he said.The health secretary Matt Hancock, an AI enthusiast who has his own eponymous app, said the NHS was “on the cusp of a huge health tech revolution that could transform patient experience by making the NHS a truly predictive, preventive and personalised health and care service”.The new money was cautiously welcomed by health experts, with caveats. Adam Steventon, director of data analytics at the Health Foundation thinktank, said: “Technology needs to be driven by patient need and not just for technology’s sake. Robust evaluation therefore needs to be at the heart of any drive towards greater use of technology in the NHS, so that technologies shown to be effective can be spread further and patients protected from any potential harm.”He also said clarity was needed “on where this money will come from and whether there may need to be trade-offs”, adding: “Despite the extra capital funding pledged this week, there remains a £6bn maintenance backlog for supporting basic infrastructure, including IT equipment, of which over £3bn is identified as ‘high or significant risk’.“And with a shortfall of 100,000 staff, the NHS will struggle to sustain current services, let alone take advantage of the benefits of new technology.”AI cancer detectorsRead moreMatthew Honeyman, a researcher at The King’s Fund health thinktank, said: “Many staff in the NHS currently feel that IT makes their life harder, not easier. Rolling out new technologies like AI will require standards to ensure patient safety, a workforce equipped with digital skills, and an upgrade to outdated basic NHS tech infrastructure.”The NHS England chief executive, Simon Stevens, said “carefully-targeted” AI is ready for practical application in the health service and that the investment “is another step in the right direction”.He added: “In the first instance, it should help personalise NHS screening and treatments for cancer, eye disease and a range of other conditions, as well as freeing up staff time, and our new NHS AI Lab will ensure the benefits of NHS data and innovation are fully harnessed for patients in this country.”Explore more on these topicsNHSBoris JohnsonHealth policyDoctorsHealthnewsShareReuse this contentMost viewedTenacious D Australian tour date postponed after comment about Trump shootingNight owls’ cognitive function ‘superior’ to early risers, study suggestsMy sausage-like fingers are not sexy. But they have given me one incredible talentZoe WilliamsTeamsters union president calls Trump ‘tough SOB’ in unprecedented speech at RNCJack Black puts Tenacious D ‘on hold’ after bandmate’s Trump shooting comment",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmRpZ2l0YWxoZWFsdGgubmV0LzIwMTkvMDgvZ292ZXJubWVudC0yNTAtbWlsbGlvbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1sYWItZGlhZ25vc3RpY3Mv0gEA?oc=5,Government pledges £250m for National AI Lab to improve diagnostics - Digital Health,2019-08-08,Digital Health,https://www.digitalhealth.net,"The lab will be used to develop cutting-edge treatments for cancer, dementia and heart disease, as well as upskilling the workforce to use AI.",N/A,"The lab will be used to develop cutting-edge treatments for cancer, dementia and heart disease, as well as upskilling the workforce to use AI.","The lab will be used to develop cutting-edge treatments for cancer, dementia and heart disease, as well as upskilling the workforce to use AI.",https://schema.org,,,,,,,,,,,AI and Data,N/A,"


Government pledges £250m for National AI Lab to improve diagnostics





AI and Data, News







                     8 August 2019






















            
            Andrea Downey
        
January 7, 2019






  
  
  







The government has pledged £250 million for a National Artificial Intelligence (AI) Lab to improve diagnostics and screening in the NHS.
The lab will be used to develop treatments for cancer, dementia and heart disease.
The programme aims to improve cancer screening and speed up results, use DNA data to identify patients most at-risk of diseases, upskill the workforce to use artificial intelligence (AI) systems and automate routine administration tasks to free up clinicians.
Prime Minister, Boris Johnson, said the NHS was “leading the way” in harnessing new technology.
“Today’s funding is not just about the future of care though. It will also boost the frontline by automating admin tasks and freeing up staff to care for patients,” he added.
The lab will sit within NHSX, in partnership with the Accelerated Access Collaborative, and bring together the industry’s best academics, specialists and technology companies to harness the power of AI to improve the health and lives of patients.
Matthew Gould, chief executive of NHSX, added: “Today’s announcement gets the NHS ready for the AI revolution, so that doctors can identify and treat disease faster and more effectively. It also puts the UK in pole position for healthtech research and lifesaving innovations.”
NHSX confirmed on Twitter that the funding is “new money”.

Yes the AI Lab is new money.  And yes we need to fix the basics too, but it's not either/or.  
Staying ahead of where the tech is going is good for the NHS. One reason why the NHS struggles with interoperability now is that we failed to futureproof our technology in the past.
— Transforming health and care (@NHSTransform) August 8, 2019

AI is already being developed in a number of NHS hospitals, including in Imperial College London to predict survival rates for ovarian cancer and in University College Hospital to predict missed appointments and allow staff to follow-up with targeted phone calls, saving £2-3 per appointment.
Data from a Genomics England programme that will see five million NHS patients receive a free personalised health record based on their DNA will also be linked into the lab.
The programme, announced in July, will see volunteers have their genomes analysed to identify their risk of developing diseases like cancer or heart disease.
The project follows the 100,000 Genomes Project, which ran from 2013 to 2018 and led to roughly one in four participants with a rare disease receiving a diagnosis.
[themify_box icon=”info” color=”gray”]
Government’s AI Lab proposals:

Build systems to improve cancer screening by speeding up the results of tests including mammograms, brain scans, eye scans and heart monitoring, helping to save millions of lives a year
Use predictive models to better estimate future needs of beds, drugs, devices, or surgeries
Identify which patients could be more easily treated in the community, reducing the pressure on the NHS and helping patients receive treatment closer to home
Use DNA tests or already-available data to help screening programs identify patients most at risk of diseases, allowing for earlier diagnosis and cheaper, more effective treatment
Build predictive systems to detect people at risk of postoperative complications, infections or requiring targeted follow-up from clinicians, improving patient safety and reducing readmission rates
Upskill the NHS workforce so they know how to use AI systems to assist with day-to-day tasks
Inspect algorithms already used by the NHS to increase the standards of AI safety within our healthcare system, making systems fairer, more robust and ensuring patient confidentiality is protected to the highest standards
Automate routine admin tasks to free up clinicians so more time can be spent with patients

[/themify_box]
Second wave of NHS funding this week
It’s the second wave of NHS funding announced by Downing Street this week.
On 4 August, Johnson pledged a £1.8 billion cash injection for the NHS, with part of the money going towards harnessing the potential of new technologies.
Some 20 hospital projects are to benefit from a £850 million funding package to upgrade outdated facilities and equipment, with a further £1 billion to boost capital spending to tackle urgent infrastructure projects.
Responding to the announcement chair of the Digital Health CCIO Network, James Reed, said more funding was needed to “fundamentally change” the NHS.
“We have benefited hugely from recent investments such as the GDE [Global Digital Exemplar] programme and I would like the whole digital agenda to feature in this new spending,” he said.
“It would be a missed opportunity if this money was spent on capital developments without associated investment in the staff and skills which will be needed to make the most of them.”













Subscribe to our newsletter 



 







								Email							





Subscribe


















 Subscribe To Our Newsletter 



First Name



Last Name



Email Address: 



Job Title: 



Organisation: 






Leave this field empty if you're human: 













Subscribe To Our Newsletter 



 









Sign up


Leave this field empty if you're human: 











 Tags



                 AI
              




                 artificial intelligence
              




                 NHSX
              



",,,,,,,"[{'@type': 'Organization', '@id': 'https://www.digitalhealth.net/#organization', 'name': 'Digital Health Intelligence', 'url': 'https://www.digitalhealth.net/', 'sameAs': ['https://www.facebook.com/DigitalHealthNews2/', 'https://www.linkedin.com/company/digital-health-intelligence-ltd', 'https://twitter.com/digitalhealth2'], 'logo': {'@type': 'ImageObject', '@id': 'https://www.digitalhealth.net/#logo', 'url': 'https://www.digitalhealth.net/wp-content/uploads/2017/01/dhi_masthead.png', 'width': 425, 'height': 129, 'caption': 'Digital Health Intelligence'}, 'image': {'@id': 'https://www.digitalhealth.net/#logo'}}, {'@type': 'WebSite', '@id': 'https://www.digitalhealth.net/#website', 'url': 'https://www.digitalhealth.net/', 'name': 'Digital Health', 'publisher': {'@id': 'https://www.digitalhealth.net/#organization'}, 'potentialAction': {'@type': 'SearchAction', 'target': 'https://www.digitalhealth.net/?s={search_term_string}', 'query-input': 'required name=search_term_string'}}, {'@type': 'ImageObject', '@id': 'https://www.digitalhealth.net/2019/08/government-250-million-artificial-intelligence-lab-diagnostics/#primaryimage', 'url': 'https://www.digitalhealth.net/wp-content/uploads/2019/06/Webp.net-resizeimage-65.jpg', 'width': 555, 'height': 330}, {'@type': 'WebPage', '@id': 'https://www.digitalhealth.net/2019/08/government-250-million-artificial-intelligence-lab-diagnostics/#webpage', 'url': 'https://www.digitalhealth.net/2019/08/government-250-million-artificial-intelligence-lab-diagnostics/', 'inLanguage': 'en-GB', 'name': 'Government pledges £250m for National AI Lab to improve diagnostics', 'isPartOf': {'@id': 'https://www.digitalhealth.net/#website'}, 'primaryImageOfPage': {'@id': 'https://www.digitalhealth.net/2019/08/government-250-million-artificial-intelligence-lab-diagnostics/#primaryimage'}, 'datePublished': '2019-08-07T23:05:24+01:00', 'dateModified': '2019-08-08T08:34:47+01:00', 'description': 'The lab will be used to develop cutting-edge treatments for cancer, dementia and heart disease, as well as upskilling the workforce to use AI.'}, {'@type': 'Article', '@id': 'https://www.digitalhealth.net/2019/08/government-250-million-artificial-intelligence-lab-diagnostics/#article', 'isPartOf': {'@id': 'https://www.digitalhealth.net/2019/08/government-250-million-artificial-intelligence-lab-diagnostics/#webpage'}, 'author': {'@id': 'https://www.digitalhealth.net/#/schema/person/1c96e83a7063b95714d056d1a2d3baa9'}, 'headline': 'Government pledges £250m for National AI Lab to improve diagnostics', 'datePublished': '2019-08-07T23:05:24+01:00', 'dateModified': '2019-08-08T08:34:47+01:00', 'commentCount': 3, 'mainEntityOfPage': {'@id': 'https://www.digitalhealth.net/2019/08/government-250-million-artificial-intelligence-lab-diagnostics/#webpage'}, 'publisher': {'@id': 'https://www.digitalhealth.net/#organization'}, 'image': {'@id': 'https://www.digitalhealth.net/2019/08/government-250-million-artificial-intelligence-lab-diagnostics/#primaryimage'}, 'keywords': 'AI,artificial intelligence,NHSX', 'articleSection': 'AI and Data,News'}, {'@type': ['Person'], '@id': 'https://www.digitalhealth.net/#/schema/person/1c96e83a7063b95714d056d1a2d3baa9', 'name': 'Andrea Downey', 'image': {'@type': 'ImageObject', '@id': 'https://www.digitalhealth.net/#authorlogo', 'url': 'https://secure.gravatar.com/avatar/d4a5f728132fcc103caf85e454dba0da?s=96&d=mm&r=g', 'caption': 'Andrea Downey'}, 'sameAs': []}]",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvZmFsb25mYXRlbWkvMjAxOS8wOC8xMC81LXdheXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaXMtdHJhbnNmb3JtaW5nLWNybXMv0gEA?oc=5,5 Ways Artificial Intelligence Is Transforming CRMs - Forbes,2019-08-10,Forbes,https://www.forbes.com,"This year, artificial intelligence will increasingly play a vital role in sales organizations. One of the most profound implications will be in the context of CRMs.",,"This year, artificial intelligence will increasingly play a vital role in sales organizations. One of the most profound implications will be in the context of CRMs.","This year, artificial intelligence will increasingly play a vital role in sales organizations. One of the most profound implications will be in the context of CRMs.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/falonfatemi/2019/08/10/5-ways-artificial-intelligence-is-transforming-crms/,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",2019-08-10T10:41:00-04:00,2021-06-30T09:11:19-04:00,5 Ways Artificial Intelligence Is Transforming CRMs,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/falonfatemi/files/2019/08/graphicstock-map-pin-flat-above-blue-tone-city-scape-and-network-connection-concept_HO4s5iPljl-1200x800.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",,,"{'@type': 'Person', 'name': 'Falon Fatemi', 'url': 'https://www.forbes.com/sites/falonfatemi/', 'description': 'Falon Fatemi is the CEO of Fireside which she co-founded with Mark Cuban. Fireside is the only platform that allows brands to own their fandoms and pioneer monetized interactive fan-first experiences to grow their franchise. Falon was previously Google/YouTube’s youngest employee and is a Fortune 40 Under 40 in Technology winner. Her previous company Node, an AI as a service company, was acquired by SugarCRM. From the front lines of Silicon Valley, she writes about the future of entertainment, the community economy, and emerging technologies. Follow her on twitter @falonfatemi and learn more about Fireside at www.firesidechat.com.', 'sameAs': ['https://www.linkedin.com/in/falon', 'https://www.twitter.com/falonfatemi', 'https://firesidechat.com', 'falonrozfatemi']}",Hollywood & Entertainment,N/A,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryBusinessHollywood & Entertainment5 Ways Artificial Intelligence Is Transforming CRMsFalon FatemiContributorOpinions expressed by Forbes Contributors are their own.Forbes Contributor covering the future of entertainment technologies.FollowingFollowAug 10, 2019,10:41am EDTUpdated Jun 30, 2021, 09:11am EDTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to Linkedin







connections
storyblocks





2019 has already unfolded as a banner year in terms of the union between artificial intelligence and sales. While 2018 saw the artificial intelligence sales revolution beginning to gain momentum, the applications were limited. According to a report by Pactera Technologies and Nimdzi Insights, in 2017, 51% of enterprises leveraged some form of artificial intelligence. In 2018, the percentage increased by a mere 2% to 53% adoption.

This year, artificial intelligence will increasingly play a vital role in sales organizations. One of the most profound implications will be in the context of CRMs. CRMs have long struggled to gain the favor of sales professionals. Less than 40% of businesses report a CRM adoption rate in excess of 90%. This year and beyond, we're sure to witness a marriage between artificial intelligence and CRM systems, a transformation that amplifies the capabilities and effectiveness of antiquated CRMs.
1. Data ingestion and retrieval 
Many individuals have predicted that artificial intelligence’s foray into the sales landscape poses a threat to the human sales profession. Yet the belief that artificial intelligence signals the demise and replacement of the human sales function entirely, is tremendously short-sighted. 
PROMOTED
Artificial intelligence promises to enhance, not replace, the human component of sales. The sales professionals of the future will use artificial intelligence to complement their efforts and skillsets. When it comes to CRMs, this starts with data ingestion and retrieval. As it stands, sales professionals spend 17% of their time entering data—the equivalent of nearly one work day per week. Indeed, manual data entry is the primary obstacle that inhibits CRM adoption.  
Artificial intelligence not only empowers sales professionals to eliminate manual data entry, it also bolsters their ability to centralize disparate customer databases and, in turn, capture the complete customer lifecycle—whether it has transpired via email, phone conversations, chatbots, etc. CallMiner Eureka, for example, uses artificial intelligence and machine language to capture and transcribe customer interactions. Transcriptions are tagged according to key topics and a rich categorization schema. When this data is ingested into a CRM, it can surface key insights, including objections, specific data with respect to competitors, and ideal use cases. Salespeople can search transcript metadata for keywords, phrases, or even acoustics such as increased voice intonation that may signal excitement and increased interests. With the air of topic clusters and frequency maps, salespeople are equipped to detect vital customer trends. 
2. Sentiment analysis 
It's critical that salespeople develop high levels of trust and rapport with their customers. According to research by Salesforce, 79% of business buyers state that it’s absolutely critical or very important to interact with a salesperson who is a trusted advisor. We have a long way to come. A mere 3% of buyers trust sales reps. 
With the vast majority of customer interactions occurring virtually, via mediums that conceal revealing body language and facial expressions, it's become more and more difficult for salespeople to develop trust and a strong rapport with their customers. Fortunately, artificial intelligence offers a powerful antidote. Using sentiment analysis, AI-powered tools can analyze conversations and assess customers' emotional states. Cogito, for example, provides in-call voice analyses that help salespeople understand customers’ emotional states and how best to respond. A color-coded meter serves as a gauge of how effective a specific conversation is. If a customer—or salesperson—reacts too abruptly, the color changes from green to yellow or red. Cogita assesses several key aspects of any given conversation, including energy, interruption, empathy, participation, tone and pace. Analyses as sophisticated as this empowers salespeople to proactively redirect conversations. 
When all this historical in-call data is integrated with CRMs, the benefits are far-reaching. Salespeople and managers, for example, can leverage the output for training purposes to improve conversations and relationships with customers. As CEO and Cofounder Joshua Feast has explained, ""Conversations are like a dance...You can be in sync or out of sync.”
3. Data integrity 
CRMs are chock-full of dirty data. According to research by Dun & Bradstreet, 91% of data in CRM systems is incomplete, 18% is duplicated, and 70% is rendered stale each year. The fallout of dirty data is devastating. 8 out of 10 companies believe that dirty data disrupts their sales pipelines and 25% experience reputational damage due to bad data. 
The effectiveness of artificial intelligence is directly proportional to the accuracy of the data it is fed. Garbage in, garbage out. Artificial intelligence tools are integral to data cleanliness. By 2025, we will create 180 zettabytes of data each year. Gone are the days when humans can ensure optimal data quality. Artificial intelligence is able to detect irregularities, anomalies, duplicates, and other errors that compromise CRM data and, in turn, customer relationships. By integrating with third-party databases, artificial intelligence can also interpolate missing records and update records in real-time as contact and other data changes. It can automatically detect duplicates. There's no disputing the fact that data cleansing has been a big headache deterring salespeople from embracing CRMs. AI is the Tylenol.
4. Predictive lead scoring 
Artificial intelligence primes salespeople to supercharge their lead scoring abilities with predictive analytics and algorithms. Seventy-four percent of companies state that converting leads into customers is their top priority. It's no wonder why. 96% of visitors who arrive at a company's website aren’t ready to buy. 
Historically, sales professionals have relied on “rules-based” lead scoring. That is, they’ve scored and ranked leads manually, according to a set of rules—”If this, then that.” This approach is outdated and suboptimal. Artificial intelligence is key in terms of motivating sales organizations to shift from rules-based lead scoring to predictive lead scoring. Artificial intelligence can analyze millions of different historical and real-time attributes, including demographic data, firmographic data, geographic data, activity data and web behavior, to determine customers’ buying readiness. When integrated with CRM systems, artificial intelligence can analyze won versus lost deals to detect trends that can inform predictive lead scoring methods. 
Perhaps most exciting is the fact that predictive lead scoring tools powered by artificial intelligence rely on a ""champion-challenger"" model. Different predictive models are tested and the most accurate one is selected. Each time a more accurate model is identified, it becomes the default. 
5. Prescriptive account-specific recommendations 
CRMs have traditionally been data repositories. When artificial intelligence is powering CRM systems, they assume a new and more useful role as a trusted advisor. Based on the relevant data housed in a CRM system, artificial intelligence has the capability to generate targeted recommendations for salespeople, including personalized sales and marketing collateral to be delivered at specified times. The most effective artificial intelligence-powered CRMs will also provide the ""why,” informing salespeople as to the rationale behind certain prescribed courses of action.
CRMs are in desperate need of a makeover. The time is now. Sales reps can no longer survive without garnering the trust of the customer. Artificial intelligence promises to equip salespeople with a heightened reputation. With targeted and prescriptive recommendations, artificial intelligence empowers them to become a thought leader and transform customer relationships from salesperson/customer to doctor/patient, providing effective treatments for potentially fatal business issues. The implications are game-changing. Whereas only 3% of salespeople are trusted, 49% of doctors are trusted.  
 Follow me on Twitter or LinkedIn. Check out my website. Falon FatemiFollowingFollowFalon Fatemi is the CEO of Fireside which she co-founded with Mark Cuban. Fireside is the only platform that allows brands to own their fandoms... Read MoreEditorial StandardsPrintReprints & Permissions",5 Ways Artificial Intelligence Is Transforming CRMs,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Business', 'item': 'https://www.forbes.com/business/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Hollywood & Entertainment', 'item': 'https://www.forbes.com/hollywood-entertainment/'}]",,Hollywood & Entertainment,True,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQ2h0dHBzOi8vc2lsaWNvbmNhbmFscy5jb20vZ2xvYmFsLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvbXBhbmllcy_SAQA?oc=5,These are the best Artificial Intelligence companies in the world - Silicon Canals,2019-08-07,Silicon Canals,https://siliconcanals.com,"Given that AI is the trend, here we list the best Artificial Intelligence companies in the world.",N/A,"Given that AI is the trend, here we list the best Artificial Intelligence companies in the world.","Given that AI is the trend, here we list the best Artificial Intelligence companies in the world.",https://schema.org,,,,,,,,,,,Artificial Intelligence (AI),N/A,"



Home » Artificial Intelligence (AI)


These are the best Artificial Intelligence companies in the world








By
Editorial team





ShareLinkedInFacebookXWhatsAppTelegram













By
Editorial team


|
August 7, 2019
|
Last update:
March 22, 2024



 English▼ Dutch English French German Italian Spanish




Artificial Intelligence (AI)







LinkedInFacebookWhatsAppXTelegramShare




Artificial Intelligence (AI) is a fast-growing technology, which is an integral part of companies across industries. Several global organisations deploy AI to accelerate their growth and get a better reach among clients and consumers. The trends in AI find applications in healthcare, manufacturing, automobile, software, e-commerce, and more.
Today, techniques including machine learning, neural networks, facial recognition, cloud computing, mapping applications, virtual assistants, etc. are used by millions of consumers directly or indirectly on a daily basis. When implemented the right way, these technologies that use Artificial Intelligence have the potential to transform the industry and gain traction.






Given that AI is the trend, here we list the best Artificial Intelligence companies in the world.

NVIDIA Corporation (US)
Founders: Chris Malachowsky, Curtis Priem, Jensen Huang
Founded year: 1993
Why its hot: NVIDIA Corporation is a specialised semiconductor company. Its technology plays a central role in many early-stage and high-growth tech sectors. The NVIDIA portfolio comprises graphics processing unit (GPU), which powers high-performance graphics, autonomous graphics, cloud computing and other areas that work in the deep learning industry. It is one of the market leaders in the semiconductor industry in the world.








- A message from our partner -
Alphabet (US)
Founders: Larry Page, Sergey Brin
Founded year: 2015
Why its hot: Alphabet is Google’s parent company. This company has invested heavily in this technology. Google uses deep learning and Artificial Intelligence to power and automates many critical business areas. The company produces relevant search results, digital ad pricing, self-driving technology, image and speech recognition software, personal assistant software, etc. powered by AI.







 
Salesforce (US)
Founders: Halsey Minor, Marc Benioff, Parker Harris
Founded year: 1999
Why its hot: Salesforce is a customer relationship management software giant. It has an obsessive focus on growth and opportunities to scale. Salesforce regularly acquires hot tech startups to enhance its SaaS offerings. Earlier this year, Bonobo AI, which uses automated analysis of customer texts, phone calls and chats was acquired by Salesforce. The company’s AI-powered software uses data to identify undetected business patterns, deliver the hottest sales leads, and optimise how businesses work.







Amazon.com (US)
Founders: Jeff Bezos
Funding: €98.2 million
Valuation: $178.1 billion
Founded year: 1994
Why its hot: Amazon is the second company to reach the $1 trillion valuation. The company’s founder and CEO Jeff Bezos is the world’s richest person. It invests heavily in AI and uses it to power key capabilities such as optimising logistics and warehousing, forecasting product demand and improving Amazon Alexa voice assistant.







Microsoft (US)
Founders: Bill Gates, Paul Allen
Total Funding: €10.9 million
Valuation: $48 million to $72 million
Founded year: 1974
Why its hot: Microsoft is one of the most valuable tech companies in the world. It invests in Artificial Intelligence and its Azure, which is a cloud computing service is home to AI-driven tools in robotics, language, medicine, medical imaging, etc. Recently, Microsoft invested $1 billion in OpenAI with the aim to produce AGI (Artificial General Intelligence), which is capable of doing anything that human intelligence can.







Baidu (China)
Founders: Eric Xu, Robin Li
Funding: €2.0 billion
Valuation: $400 million – $600 million
Founded year: 2000
Why its hot: Baidu is a leading Chinese search engine that uses AI to improve search results and serve ads. Recently, Baidu won a facial recognition competition leaving Alibaba Group Holding and Huawei behind. It is one of the most devoted investors in Artificial Intelligence. The self-driving software platform of Baidu called Apollo has 135 partners in the automobile industry.







Intel Corporation (US)
Founders: Gordon Moore, Robert Noyce
Valuation: $148.2 billion
Founded year: 1968
Why its hot: Intel is a blue-chip, dividend-paying semiconductor giant. Intel provides key hardware components used by Microsoft including the field-programmable gate arrays that enable running deep learning on the cloud. Furthermore, Intel’s vision processing units fuel machine vision in surveillance cameras and let perform facial recognition and behaviour analysis.







Twilio (US)
Founders: Evan Cooke, Jeff Lawson, John Wolthuis
Funding: €212 million
Valuation: $2.0 billion
Founded year: 2008
Why its hot: Twilio offers cloud-based application programming interfaces (APIs) letting developers build video, voice and messaging features into their apps. It is a useful, popular and fast-growing service. Twilio is used by over 2 million developers across the world to unlock communications to improve the human experience.

Facebook (US)
Founders: Chris Hughes, Dustin Moskovitz, Eduardo Saverin, Mark Zuckerberg
Funding: €1.9 billion
Valuation: $230.0 billion
Founded year: 2004






Why its hot: Facebook, which is a leading social networking giant is committed to machine learning. The company automates self-teaching algorithms to enhance Facebook’s News Feed algorithm. Also, it uses Artificial Intelligence to screen for fake news and hate speech. The social media giant has an opportunity to test machine learning techniques with huge volumes of real-time datasets making it gain an upper edge than its peers.

Tencent (China)
Founders: Chen Ye Xu, Pony Ma, Zhidong Zhang
Funding: €29.5 million
Valuation: $11.0 billion
Founded year: 1998
Why its hot: Chinese company Tencent is the largest social company in the country. The company largely hit the headlines with WeChat, which is a dynamic app used by millions in China for payments, social media, mail, ride-hailing, messaging and other functions. Tencent images practically endless ways using Artificial Intelligence and machine learning. WeChat has over 1 billion daily users to test and improve its technology rapidly.






Stay tuned to Silicon Canals for more updates in the tech startup world.
Also read,
Stock Photos from sdecoret/Shutterstock
https://siliconcanals.com/news/eit-digital-conference-companies/




Topics: 
Artificial Intelligence (AI)NewsScaleupsStartups




Follow us: 















Editorial team
The editorial team of Silicon Canals brings you technology news from the European startup ecosystem. 









Featured events | Browse events
Current MonthJulyNo Events 










Partner content



01
How Deeploy gives explainable AI (XAI) a central place in MLOps






02
Meet the 11 social innovators pitching at DNNL X Social Enterprise NL Launchpad Demo Day 2024






03
Empowering Ukrainian Startups: Highlights from the PowerUp Ukraine 2024 Conference






04
Meet the 10 promising startups selected for Glovo Startup Lab






05
Technology startup Rierino partners with FeatureMind to deliver seamless e-commerce and digital transformation experiences in EMEA













Related posts





UK’s healthcare AI firm Huma secures €73.3M from AstraZeneca, Hitachi Ventures, others





Dutch entrepreneurs led by Imker Capital acquire Centric Holding’s subsidiaries: Know more





After selling its Dutch subsidiary, Amsterdam’s BUX Holding offloads its UK subsidiary to UAE’s Asseta Holding





French startup Presti raises €3.2M to help furniture industry with AI-generated product photography





UK’s female-founded tech startup Hey Savi raises €2.61M to transform online fashion shopping





Germany’s One Data secures €32M to scale its data product management platform



",,,,,,,"[{'@type': 'Organization', '@id': 'https://siliconcanals.com/#organization', 'name': 'Silicon Canals', 'sameAs': ['https://www.facebook.com/siliconcanals', 'https://twitter.com/siliconcanals', 'https://www.linkedin.com/company/silicon-canals/'], 'logo': {'@type': 'ImageObject', '@id': 'https://siliconcanals.com/#logo', 'url': 'https://siliconcanals.com/wp-content/uploads/2024/03/SC_logo_01_Stack_FC-RGB_Positive_1200-1-1.png', 'contentUrl': 'https://siliconcanals.com/wp-content/uploads/2024/03/SC_logo_01_Stack_FC-RGB_Positive_1200-1-1.png', 'caption': 'Silicon Canals', 'inLanguage': 'en-GB', 'width': '2560', 'height': '1060'}}, {'@type': 'WebSite', '@id': 'https://siliconcanals.com/#website', 'url': 'https://siliconcanals.com', 'name': 'Silicon Canals', 'publisher': {'@id': 'https://siliconcanals.com/#organization'}, 'inLanguage': 'en-GB'}, {'@type': 'ImageObject', '@id': 'https://3a18c69c.rocketcdn.me/wp-content/uploads/2024/03/artificial-intelligence-startups.jpg', 'url': 'https://3a18c69c.rocketcdn.me/wp-content/uploads/2024/03/artificial-intelligence-startups.jpg', 'width': '670', 'height': '362', 'inLanguage': 'en-GB'}, {'@type': 'BreadcrumbList', '@id': 'https://siliconcanals.com/global-artificial-intelligence-companies/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': '1', 'item': {'@id': 'https://siliconcanals.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': '2', 'item': {'@id': 'https://siliconcanals.com/news/startups/ai/', 'name': 'Artificial Intelligence (AI)'}}, {'@type': 'ListItem', 'position': '3', 'item': {'@id': 'https://siliconcanals.com/global-artificial-intelligence-companies/', 'name': 'These are the best Artificial Intelligence companies in the world'}}]}, {'@type': 'WebPage', '@id': 'https://siliconcanals.com/global-artificial-intelligence-companies/#webpage', 'url': 'https://siliconcanals.com/global-artificial-intelligence-companies/', 'name': 'These are the best Artificial Intelligence companies in the world - Silicon Canals', 'datePublished': '2019-08-07T07:00:47+02:00', 'dateModified': '2024-03-22T13:07:13+02:00', 'isPartOf': {'@id': 'https://siliconcanals.com/#website'}, 'primaryImageOfPage': {'@id': 'https://3a18c69c.rocketcdn.me/wp-content/uploads/2024/03/artificial-intelligence-startups.jpg'}, 'inLanguage': 'en-GB', 'breadcrumb': {'@id': 'https://siliconcanals.com/global-artificial-intelligence-companies/#breadcrumb'}}, {'@type': 'Person', '@id': 'https://siliconcanals.com/author/siliconcanals/', 'name': 'Editorial team', 'url': 'https://siliconcanals.com/author/siliconcanals/', 'image': {'@type': 'ImageObject', '@id': 'https://secure.gravatar.com/avatar/e118ac989a287bd7a4711d7f8921ef35?s=96&amp;d=mm&amp;r=g', 'url': 'https://secure.gravatar.com/avatar/e118ac989a287bd7a4711d7f8921ef35?s=96&amp;d=mm&amp;r=g', 'caption': 'Editorial team', 'inLanguage': 'en-GB'}, 'sameAs': ['https://siliconcanals.com/'], 'worksFor': {'@id': 'https://siliconcanals.com/#organization'}}, {'@type': 'NewsArticle', 'headline': 'These are the best Artificial Intelligence companies in the world - Silicon Canals', 'keywords': 'Artificial Intelligence, startups', 'datePublished': '2019-08-07T07:00:47+02:00', 'dateModified': '2024-03-22T13:07:13+02:00', 'articleSection': 'Artificial Intelligence (AI), News, Scaleups, Startups', 'author': {'@id': 'https://siliconcanals.com/author/siliconcanals/', 'name': 'Editorial team'}, 'publisher': {'@id': 'https://siliconcanals.com/#organization'}, 'description': 'Given that AI is the trend, here we list the best Artificial Intelligence companies in the world.', 'name': 'These are the best Artificial Intelligence companies in the world - Silicon Canals', '@id': 'https://siliconcanals.com/global-artificial-intelligence-companies/#richSnippet', 'isPartOf': {'@id': 'https://siliconcanals.com/global-artificial-intelligence-companies/#webpage'}, 'image': {'@id': 'https://3a18c69c.rocketcdn.me/wp-content/uploads/2024/03/artificial-intelligence-startups.jpg'}, 'inLanguage': 'en-GB', 'mainEntityOfPage': {'@id': 'https://siliconcanals.com/global-artificial-intelligence-companies/#webpage'}}]",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vcmFkaW9sb2d5YnVzaW5lc3MuY29tL3RvcGljcy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS93aGF0LWhhcy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1kb25lLXJhZGlvbG9neS1sYXRlbHnSAQA?oc=5,What Has Artificial Intelligence Done for Radiology Lately? - Radiology Business,2019-08-09,Radiology Business,https://radiologybusiness.com,RBJ sought out a representative sampling of radiologists who are not just talking about AI but already using it to beneficial effect. Here are five highlights from what we found.,Artificial Intelligence,RBJ sought out a representative sampling of radiologists who are not just talking about AI but already using it to beneficial effect. Here are five highlights from what we found.,RBJ sought out a representative sampling of radiologists who are not just talking about AI but already using it to beneficial effect. Here are five highlights from what we found.,https://schema.org,,,,,,,,,,,N/A,N/A,"  What Has Artificial Intelligence Done for Radiology Lately?Julie Ritzer Ross | August 09, 2019 | Artificial Intelligencetweetprintsharesharemail   From basic sorting algorithms to sophisticated neural networks, AI and its offspring continue to generate buzz throughout medicine, business, academia and the media. Much of the chatter amounts to no more than hot air. The most farfetched imaginings are usually easy to spot and dismiss.Yet accounts of real-world AI deployments—applications with strong potential to improve patient care while cutting costs—are amassing into a category of medical literature in its own right.RSNA’s Radiology: Artificial Intelligence is the first peer-reviewed journal to focus entirely on the technology, signaling radiology’s place at the forefront of the AI revolution within healthcare. But the journal and the profession are both likely to have lots of company at the head of the class before long.With those observations in hand, RBJ sought out a representative sampling of radiologists who are not just talking about AI but also using it to beneficial effect. Here are five highlights from what we found.An Unfractured View of FracturesThe diagnosis of elbow injuries in children and adolescents is difficult because the developing skeletal system has unique features not seen in adults. For example, cartilage still comprises a portion of pediatric elbow joints, making certain injuries impossible to detect via X-rays. Additionally, pediatric elbow joints have many growth centers that ossify as children grow. As a result, fracture patterns vary significantly depending on an individual child’s age and unique developmental factors.During their tenure in the diagnostic radiology program at Baylor College of Medicine in Houston, Jesse Rayan, MD, now an imaging fellow at Massachusetts General Hospital, and Nakul Reddy, MD, an interventional radiology fellow at MD Anderson Cancer Center, developed a means of using AI to overcome these and other diagnostic challenges by automating the analysis of pediatric elbow radiographs.The model leverages a combination of a convolutional neural network (CNN) and recurrent neural network (RNN) to process multiple images together. A CNN is a deep learning algorithm that can take in an input image, assign learnable weights and biases to various aspects of or objects in that image, and differentiate one aspect or object from another. An RNN recognizes patterns in sequences of data and images, decomposing the latter into a series of patches and treating them as a sequence.“A simpler way to think about this would be to consider the CNN as analogous to the human visual cortex,” Rayan explains. “It’s able to recognize patterns in an image and classify if something is present or not. This works great for single images, but many radiographic studies have more than one image for a single study.”In the elbow application developed at Baylor, the RNN is used to effectively process multiple outputs—i.e., multiple views of the pediatric elbow—passed through the CNN before arriving at a single decision point.Rayan, Reddy and colleagues tested the method on 21,456 X-rays containing 58,817 images of pediatric elbows and associated radiology reports, all captured at Texas Children’s Hospital in Houston. Accuracy on the studied dataset was found to be 88%, with sensitivity of 91% and specificity of 84%.The researchers concluded that deep learning can effectively classify acute and nonacute pediatric elbow abnormalities on radiographs in a trauma setting. “A recurrent neural network was used to classify an entire radiographic series, arrive at a decision based on all views and identify fractures in pediatric patients with variable skeletal immaturity,” they underscore.Radiology: Artificial Intelligence published the study in its inaugural issue (“Binomial Classification of Pediatric Elbow Fractures Using a Deep Learning Multiview Approach Emulating Radiologist Decision Making,” January 2019).Rayan tells RBJ the model’s greatest potential to improve patient care lies in ER triage, where studies that need more attention can be prioritized for quicker turnaround. Additionally, he notes, using AI in this context could enhance the caliber of patient care by allowing radiologists to home in on specific findings that might otherwise be overlooked.Rayan believes this is just one example of how AI can assist radiologists in clinical decision-making without delay. If AI tools help radiologists increase the accuracy of their diagnoses and recommendations, he asserts, costs can be reduced across hospitals and health systems.Going forward, Rayan plans to work on similar projects in the ER radiology setting, including studying whether deep learning can effectively triage studies in other emergent situations. He deems increasing radiologists’ confidence in their decisions without slowing turnaround times “the most exciting application of this technology.”Another Eye on Alzheimer’sPhysicians face a tough dilemma when diagnosing older patients with memory issues. Once organic causes like stroke, infection and Parkinson’s have been ruled out, they must determine whether these individuals have dementia, Alzheimer’s disease or, alternatively, some form of mild cognitive impairment.Radiologist Jae Ho Sohn, MD, of UC-San Francisco and colleagues developed an algorithm that addresses this dilemma by analyzing FDG-PET scans of patients whose memory no longer appears to be functioning properly. Based on this analysis, the algorithm provides what Sohn considers a “highly accurate prediction that can boost the confidence of Alzheimer’s disease diagnosis or rule it out.”The algorithm looks for subtle, slow diffuse processes and global changes in the brain that are difficult to see with the naked eye, such as changes in glucose uptake.“Traditionally, radiologists analyze the patterns of reduced glucose uptake,” Sohn explains. “For Alzheimer’s disease, symmetric reduction of glucose uptake in the temporal and parietal lobes of the brain has been the most specific finding. But these classic findings manifest later in Alzheimer’s disease” than the changes identified by the algorithm.Moreover, the algorithm considers the whole picture of the brain on the FDG-PET scan to make its prediction. “We show a saliency map image that demonstrates where the algorithm is looking in the brain, and it covers the entire brain—not just one region,” Sohn says.Sohn and colleagues trained the algorithm on images from the Alzheimer’s Disease Neuroimaging Initiative (ADNI), a massive public dataset of PET scans conducted on patients who were eventually diagnosed with either Alzheimer’s Disease, mild cognitive impairment or no disorder. Over time, the algorithm learned on its own which features and patterns are important for predicting the diagnosis of Alzheimer’s disease and which are insignificant.The researchers tested the algorithm on two novel datasets after it had been trained on 1,921 scans. One dataset contained 188 images from the same ADNI database; these had not yet been presented to the algorithm. The other was an entirely novel set of scans from 40 patients of the UCSF Memory and Aging Unit, all of whom had presented with possible cognitive impairment. The algorithm correctly identified a respective 92% of patients from the first test set and 98% of patients from the second test set who eventually developed Alzheimer’s disease.These predictions were made slightly more than six years, on average, before the patient received a final diagnosis. Sohn et al. report the research in “A Deep Learning Model to Predict a Diagnosis of Alzheimer Disease by Using 18F-FDG PET of the Brain” (Radiology, online Nov. 6, 2018).“With further large-scale external validation on multi-institutional data and model calibration, the algorithm may be integrated into clinical workflow and serve as an important decision-support tool to aid radiology readers and clinicians with early prediction of Alzheimer’s disease,” the authors write.Sohn believes the algorithm may greatly enhance radiologists’ ability to accurately predict whether a patient with memory issues will progress to Alzheimer’s disease. It also could add confidence to Alzheimer’s disease diagnosesmade by neurologists—before all the symptoms have manifested.“An even more important implication is that, without early diagnosis of Alzheimer’s disease”—for example, as enabled by the algorithm—“there will likely be no cure or stopping the progression,” Sohn says.He adds that by expanding the indications for FDG PET scans of the brain, which are currently not routinely used to diagnose Alzheimer’s disease in patients who present with memory impairment, the algorithm will generate more work for radiologists and create a need for additional radiologist manpower. However, it has the potential to increase radiology revenues from performing additional FDG PET studies.Sohn is currently focusing on streamlining and optimizing the methodology of applying AI to radiology research so that similar advancements can be made in other clinical areas. Accordingly, he is building a large, well-organized database of images and annotations designed to support an approach wherein radiologists first detect patterns in very big radiological data and then identify which patterns are of clinical significance. This approach would replace traditional,hypothesis-based research and is now being applied in brain CT, lung cancer, health economics and dermatopathology datasets.Objectivity Aids Prostate AssessmentIn recent years, multiparametric MRI has become an important modality for assessing prostate cancer, but the process of interpreting mpMRI prostate studies is variable because of its subjective nature. One team of researchersis working to wring clarity from the fuzziness with the creation of a new framework for predicting the progression of prostate cancer, specifically by differentiating between low- and high-risk cases.The framework melds radiomics—the use of algorithms to extract large amounts of quantitative characteristics from images—with machine learning. Among members of the team that developed the technique were Guarav Pandey, PhD, of the Icahn School of Medicine at Mount Sinai in New York City and radiologists Vinay Duddalwar, MD, and Bino Varghese, PhD, of the Keck School of Medicine at the University of Southern California.“Machine learning-based methods, the specific form of AI used” to create the framework, “are designed to sift through large amounts of data—structured or unstructured and without any particular guiding biomedical hypothesis—to discover potentially actionable knowledge directly from data,” Pandey says.One form of this knowledge is a predictive model that shows a mathematical relationship between the features in the data describing an entity of interest—say, a patient—and an outcome or label such as the disease status.The framework harnesses seven established classification algorithms to predict and assign a prostate cancer aggressiveness risk label (high or lower) for each patient from the radiomics features extracted from that patient’s mpMRI images.A trial of the framework was presented in “Objective Risk Stratification of Prostate Cancer Using Machine Learning and Radiomics Applied to Multiparametric Magnetic Images,” a retrospective study published in Scientific Reports (online Feb. 7, 2019). The study involved 68 prostate cancer patients and was based on mpMRI images, along with transrectal ultrasound-MRI fusion-guided biopsy of the prostate performed within two months of mpMRI. The framework was shown to offer a high sensitivity and predictive value on the strength of the combination of machine learning with radiomics. Large training and validation datasets yielded more accurate predictions than prior studies, Pandey et al. write.According to the research team, the value of the framework in enhancing the quality of patient care extends beyond improving diagnostic confidence: It offers more precise clinical information related to individual patients’ data.Specifically, it does not simply identify a patient’s cancer; instead, it allows radiologists to differentiate between patients with aggressive prostate cancer and indolent prostate cancer. This, Duddalwar and Varghese assert, has numerous implications for the physician team preparing a treatment plan for a patient. For instance, a more radicalapproach to treatment may be instituted earlier rather than at a later stage, or follow-up imaging may be performed at a different interval during treatment. In addition, alternative and supplemental treatments, such as radiotherapy and chemotherapy, may be introduced earlier in treatment if indicated.Duddalwar and Varghese note that their model doesn’t add to costs already incurred, as it’s based not on standard-of-care imaging protocols but on an innovative means of analyzing routinely collected images.They also emphasize that only a minimal amount of time is needed to implement the machine learning-based risk classifier through a graphical user interface and a few keystrokes or mouse clicks. Consequently, the big benefits of better diagnosis and thus prognosis should outweigh the cost of utilizing AI in this context.In tandem with AI experts like Pandey, Duddalwar and Varghese are presently involved in several projects involving the diagnosis and prognosis of various diseases using a combination of imaging and AI techniques. For example, they are integrating imaging and molecular/genomic attributes in bladder and renal cancers, with the objective of finding patterns in clinical imaging.Such patterns, Duddelwar and Varghese explain, could suggest specific mutations and molecular attributes in particular patients, in turn providing physicians with more information about which treatment(s) would be better suited for a givenindividual. Another project in the exploration stages involves the use of AI techniques to identify radiomic features in oncologic imaging as a means of best predicting patients’ response to immunotherapy.Patterns Emerge in MammographyConnie Lehman, MD, PhD, MassachusettsGeneral HospitalDecades into research and awareness efforts, effective early detection of breast cancer remains a challenge. To reverse the tide, researchers from Massachusetts General Hospital and MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) built a deep-learning model that, based on a mammogram image alone, can predict as far as five years in the future whether a patient is likely to develop breast cancer.Using mammograms and outcomes from more than 60,000 of the hospital’s patients, the research team trained the model to pick out subtle patterns in breast tissue that are known precursors of breast cancer, explains Mass General radiologist Constance Lehman, MD, PhD. Among the team members was AI expert Regina Barzilay, PhD, of MIT’s computer science and AI lab. Lehman and Barzilay previously created an AI algorithm that measures breast density at the level of an experienced clinician and has been in use since January 2018.“The model deduces the patterns that drive future cancer right from the data,” Lehman tells RBJ. “These patterns are so subtle, it’s impossible for us to see them with the naked eye.”In “Deep Learning Mammography-Based Model Can Improve Breast Cancer Risk Prediction,” published in the May 2019 edition of Radiology, Barzilay, Lehman and co-authors report that their model performed significantly better thanother models designed for the same purpose, accurately placing 31% of all cancer patients in its highest-risk category. By comparison, traditional models correctly placed only around 18% of these patients.Lehman says the model is a game-changer, as the detailed information it can provide allows for more precise assessment of breast cancer risk at the level of the individual patient. “Women have unique and very variable patterns of breast tissue that we can see on their mammogram—patterns that represent the influence of everything from genetics, hormones and pregnancy to lactation, diet and changes in weight,” Lehman says. “By identifying them through deep learning, we remove generalization” from the equation.The model enables the same level of customization and personalization when it comes to breast cancer screening and prevention programs, regardless of varying recommendations put forth by the American Cancer Society and the U.S. Preventative Task Force. While the former advocates annual breast cancer screening starting at age 45, the latter recommends screening every other year, beginning at age 50.“Instead of fitting women into a box and following either one of these recommendations, we can plan screening based on a particular patient’s risk of developing breast cancer, in keeping with what is indicated by the tool,” Lehman says.“Some women may be told to have a mammogram every two years, while women whose risk is found to be higher might be steered toward supplemental screening. But across all patients and groups, diagnosis comes sooner.”Moreover, Lehman observes, the model should take the accuracy of breast cancer risk assessment to a higher level. This, she says, was not possible with earlier models developed only on breast MRIs of Caucasian women.“Our model makes breast cancer detection a more equitable process because it was built using images from Caucasian and non-Caucasian women alike, and it’s accurate for white and black women,” Lehman states. Such equitability is critical given that black women are, due to such factors as differences in detection and access to health care, 42% more likely than other women to die from breast cancer.Additionally, the model may help to reduce the waste of imaging and other care resources, thus driving costs incurred by radiology practices and imaging departments downward. “This comes from the targeted care it enables,” Lehman says.Next on the agenda is developing an AI tool for triaging patients. This will allow physicians to determine whether mammography patients are at greater risk for developing health problems other than breast cancer—for example, a different kind of cancer or cardiovascular disease.Off to the MRI RacesMRI scans typically take 20 to 60 minutes to complete—considerably longer than, say, CT or x-ray. Under the umbrella of an AI-centric project called fastMRI, two very unlikely partners—the New York University School of Medicine’s Department of Radiology and social media giant Facebook—are teaming up to make the modality 10 times faster than it is today.FastMRI calls for speeding up MRI studies by capturing less data. An artificial neural network is trained to recognize the underlying structure of the images being captured. It harnesses this training to fill in the views that are missing from “fast scans,” producing the image detail necessary for accurate detection of abnormalities.The imaging dataset used to train the neural network was collected exclusively by NYU School of Medicine and consists of 10,000 clinical cases comprising approximately 3 million MRI images of the knee, brain and liver.Daniel Sodickson, MD, PhD, New York University/NYU Langone HealthNYU professor Daniel Sodickson, MD, PhD, likens the AI-based image reconstruction technique behind fastMRI to the way in which the eyes and brain function when making out objects in low light.“We don’t have a complete view of the object, because of the dark,” he elaborates. “However, we know in our brain what the underlying structure of the object is, and we quickly and accurately ‘fill in’ all of the details.”So far, the team is seeing “encouraging results in the knee MRIs” less than a year into the project, Sodickson says. “We’ve accelerated these scans by a factor of six compared to standard MRI scans, and radiologists cannot distinguish between the images from both types of scans,” he adds. “So we’re halfway there with that.”Speeding up MRI scans using AI will yield a multitude of benefits that will have a positive impact on patient care, Sodickson says. Reduced time in the scanner will lead to a better MRI experience for patients—especially children, the critically ill and individuals who have difficulty lying down or remaining still. Less time means less movement, which generally translates to optimal image quality and fewer patient back-outs. The end-result is more accurate diagnosis and a high likelihood of appropriate treatment.Then too, there’s decreased wait time for patients in the queue. “The faster each MRI study is done, the greater the number of patients who can be scanned each day on each unit and have access to care,” Sodickson explains. “Access to MRI in general is increased, too, which has positive effect on patient care as well. For example, in broad geographic areas where there’s only one MRI scanner, the wait for an MRI study could be really long. But if that scanner is being used to perform more scans per day, less delay follows and triaging cases is easier.”Additionally, increasing exposure speed allows motion to be frozen out and a clearer view of the anatomy to be gained.Sodickson emphasizes that the project is HIPAA-compliant. All MRI images being utilized in the endeavor have been scrubbed of distinguishing features, and no Facebook data of any kind are being used. NYU Medical Center and Facebook are open-sourcing their work so that other researchers can build on the developments.Following their initial success, Sodickson and his team have begun to test a handful of other MRI accelerations. And they’re looking beyond musculoskeletal applications.“Now that we’ve seen encouraging results with the knee imaging, we’re starting on other datasets,” he says. “We hope to have good documentation and clinical evaluations before the year is out and to begin accelerating brain MRI along with body MRI—specifically, faster MRI of the abdomen, liver and kidneys.“The potential for AI is deep. We’re just getting started,” Sodickson says. “In some applications, faster MRI may let patients avoid the exposure to ionizing radiation that occurs with X-rays and CTs. But I envision a day when scanners can be changed to gather just the data that’s needed. That’s long-term, of course, but it’s the power of AI in radiology.”Julie Ritzer Ross,Contributor Related ContentRayus Radiology launches whole-body MRI service in Seattle, SimonMed expands, RadNet touts legislation, plus more company newsACR opens doors of AI quality-assurance center AI critical care software revolutionizes emergency responseStrategic Radiology signs on with Qure.ai ASNC supports AMA effort to limit use of AI in prior authorization decisionsAmerican College of Radiology asks CMS to create new alternative payment pathway for high-value AI",,,,,,,"[{'@type': 'NewsArticle', 'headline': 'What Has Artificial Intelligence Done for Radiology Lately?', 'name': 'What Has Artificial Intelligence Done for Radiology Lately?', 'image': {'@type': 'ImageObject', 'url': 'https://radiologybusiness.com/sites/default/files/styles/facebook/public/2019-08/ai_radiology.jpg?h=6adfd4d5&itok=za18y80a', 'width': '1200', 'height': '630'}, 'datePublished': '2019-08-09T20:06:14+0000', 'dateModified': '2022-05-05T20:04:26+0000', 'publisher': {'@type': 'Organization', 'name': 'Radiology Business', 'url': 'https://radiologybusiness.com/'}}]",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vd3d3Lm1kZWRnZS5jb20vY2hlc3RwaHlzaWNpYW4vYXJ0aWNsZS8yMDUwODEvc29jaWV0eS1uZXdzL3JvYm90cy1hcmUtY29taW5nLWhvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS13aWxsLXNoYXBl0gEA?oc=5,The robots are coming: How artificial intelligence will shape the future of chest medicine (and CHEST)* - MDedge,2019-08-09,MDedge,https://www.mdedge.com,"The robots are coming – at least according to a report,1 which states that Google created an artificial intelligence model that was able to detect lung cancer a",N/A,The researchers for this study used a system called convolutional neural networks to study patterns in 3D CT scans.,N/A,http://schema.org,,,,,,,,,,,N/A,N/A,"


















    News From CHEST Physician®  



The robots are coming: How artificial intelligence will shape the future of chest medicine (and CHEST)*


Publish date: August 9, 2019



By


Chad Jackson, MS, RRT, FCCP 











































 




















The robots are coming – at least according to a report,1 which states that Google created an artificial intelligence model that was able to detect lung cancer and cut back on false-positives at a rate that beat experienced radiologists.

Robots have long been an interest of the author – both professionally and as a hobby. As a part of the CHEST Foundation’s Lung Health Experience, Chad Jackson constructed a simple robot that included pig lungs to simulate human lung activity. 

As a fan of Star Wars, sci-fi, and innovation, in general – I say, bring it on! It’s an exciting trend in medicine to see technology that has already changed the way we work and live enter into the world of health care. And, this is not about replacing humans either (like what occurs in a lot of sci-fi ); this technology will potentially provide clinicians with the tools they can use to improve outcomes for their patients.The researchers for this study used a system called convolutional neural networks to study patterns in 3D CT scans. One advantage computers has over humans is that a computer can process the entire scan all at once while trained radiologists need to review individual slices of each scan to make their diagnosis.










While this technology will need more testing and large-scale trials before being used to diagnose patients’ disorders, the early results are encouraging. The researchers also picked a cancer that impacts so many of CHEST’s members and their patients. Lung cancer kills more Americans than any type of cancer while accounting for more than 25% of all cancer deaths annually.2 In a statistic that many people find shocking, lung cancer actually kills more women than breast, ovarian, and uterine cancers combined.3 Given the devastation of this disease, we can use all of the help we can get. Another positive from this study that might be overlooked is the rate of improvement for false-positive results. This could be a major benefit of both saving the time and preventing invasive treatments or attempts to confirm a diagnosis.This news is exciting for everyone trying to (as we say at CHEST) crush lung disease, but seeing AI in medicine is not surprising, because we are already using it at CHEST. The AI projects at CHEST include analyzing the types of activities that are most beneficial to members and building predictive analytics models for a project. These were only initial forays into using this new technology. One of the even more mind-blowing developments has been rolling out natural language processing4 for our internal data reporting.This is a new development, and much like the Google lung cancer study, we cannot tell you what the end result will be. What we can say is that it’s likely to change the way we work and provide new opportunities to create analytics solutions for our partners.CHEST is not “just” a medical association: we are also an innovative group using the latest tools to create a better future for members, partners, and ,ultimately, patients and their families. Mr. Jackson is CHEST Chief Innovation Officer & Vice President of Market Growth and Innovation.References1. https://www.statnews.com/2019/05/20/googles-ai-improves-accuracy-of-lung-cancer-diagnosis-study-shows/. Accessed July 17, 2019.2. https://foundation.chestnet.org/patient-education-resources/lung-cancer/. Accessed July 17, 2019.3. https://foundation.chestnet.org/wp-content/uploads/2017/01/15110313_10154723685773104_3710772562030977299_o-1.png. Accessed July 17, 2019.4. https://www.tableau.com/products/new-features/ask-data. Accessed July 17, 2019.*This article originally appeared as a blog July 1, 2019, on https://insights.chestnet.org/.  












      Next Article:    

Environmental Scan: Economy and workforce 



Society News
 

 


























",,,,,,,"[{'@type': 'Article', 'headline': 'The robots are coming: How artificial intelligence will shape the future of chest medicine (and CHEST)*', 'publisher': {'@type': 'Organization', '@id': 'https://www.frontlinemedcom.com', 'name': 'Frontline Medical Communications Inc.', 'url': 'https://www.frontlinemedcom.com', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mdedge.com/sites/all/themes/custom/medstat_aurora/img/MDedge-publishers-logo.png'}}, 'datePublished': '2019-08-09T00:01:00-04:00', 'dateModified': '2019-08-09T00:01:22-04:00', 'mainEntityOfPage': 'https://www.mdedge.com/chestphysician/article/205081/society-news/robots-are-coming-how-artificial-intelligence-will-shape'}]",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiqgFodHRwczovL25ld3MuZm5hbC5nb3YvMjAxOS8wOC9mZXJtaWxhYi1zY2llbnRpc3Qtbmhhbi10cmFuLXJlY2VpdmVzLXByZXN0aWdpb3VzLWRvZS1hd2FyZC10by1leHBhbmQtcGFydGljbGUtY29sbGlkZXItcmVzZWFyY2gtY2FwYWJpbGl0aWVzLXVzaW5nLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,Fermilab scientist Nhan Tran receives prestigious DOE award to expand particle collider research capabilities using ... - Fermi National Accelerator Laboratory,2019-08-08,Fermi National Accelerator Laboratory,https://news.fnal.gov,N/A,N/A,Tran's $2.5 million award will fund the development of new ways to handle the massive amounts of data that particle physics produces and to expand investigations of Higgs boson physics.,Tran's $2.5 million award will fund the development of new ways to handle the massive amounts of data that particle physics produces and to expand investigations of Higgs boson physics.,https://schema.org,,,,,,,,,,,N/A,N/A,"

Fermilab scientist Nhan Tran receives prestigious DOE award to expand particle collider research capabilities using artificial intelligence


August 8, 2019
                        |  Bailey Bedford 
 













 



Fermilab scientist Nhan Tran is developing computer systems to cope with the increasing amounts of data that particle colliders produce. Photo: Reidar Hahn
The field of particle physics produces colossal amounts of data as it pushes the frontiers of human understanding. Fermilab scientist Nhan Tran is working to make sure researchers have the innovative techniques and technology they need to handle the data deluge and to select the details that are likely to reveal exciting new physics phenomena.
And now he has received a prestigious award to advance this work. The Department of Energy Early Career Research Award will provide Tran with $2.5 million over five years to lead efforts to apply artificial intelligence to push the frontiers of both physics and technology.
Tran will use a type of artificial intelligence called deep learning to expand the capabilities of particle collider research. Deep learning uses a complex artificial neural network, inspired by biological brains, to allow a computer to learn how to perform a complex task, such as identifying an object in a picture, without being explicitly programmed for that task. Each of the many layers or artificial neurons in an artificial neural network can modify the data before passing it on to another piece of the network. The program adjusts how these changes occur based on test information that is provided to it in order to configure itself for the desired task.
“As we get more and more data, computing is going to be a real issue,” Tran said. “Using new types of computing hardware with deep learning algorithms is a promising way to overcome this issue.”
Tran is applying his expertise to expand the impact of experiments at the Large Hadron Collider, a 17-mile-around particle collider at CERN in Switzerland, in two major ways. He will use the award funds to develop systems that will improve how computers handle the LHC data flood. He will also further develop a technique he pioneered that allows scientists to identify in the LHC data particles called Higgs bosons, whose discovery in 2012 led to a Nobel Prize.
At the LHC, beams of protons collide to produce other particles, including Higgs bosons, and these post-collision particles carry a wide range of momenta. Nhan is interested in using deep learning to identify Higgs bosons with high momentum and how they decay into other particles. Studying Higgs bosons under these new conditions opens the door to discovering new physics.
“Observing these specific events was considered to be impossible at hadron colliders,” said Fermilab senior scientist Anadi Canepa, head of the CMS Department in which Tran works. “And then Nhan and collaborators came up with this new technique, and he’s extracting much more than we thought we could from the data we collect.”
His work on the Higgs boson will be helped by the other thrust of his award-supported work: developing computer systems to cope with the increasing amounts of data that particle colliders produce. Instead of just improving generalized computing technologies, Tran’s plan is to develop systems that combine hardware that is specialized for efficiently performing specific types of computations, exceeding the capabilities of traditional computer technology to address those tasks.
“Nhan is a very clear thinker with a keen taste for where to focus his efforts,” said Fermilab scientist Gabriel Perdue, who leads artificial intelligence efforts at Fermilab. “He knows better than anyone that what you choose to work on is more important than any other decision you make, and his ability to figure out the most important problems and tackle them directly really sets him apart. He really understands the point of highest leverage for AI in high-energy physics and is making a huge difference right at that point.”
Tran was introduced to the world of advanced computer technology through his postdoctoral physics research on trigger systems, which select what collision data to keep from among hundreds of millions of particle collisions generated every second at the LHC. He and researchers in industry are now exploring the high-tech electronics that Tran worked on for opportunities to improve computers.
Tran plans to couple more efficient hardware developed by tech companies, such as Microsoft and Xilinx, with Fermilab’s existing computer infrastructure to meet future demands.
“People in the computer industry are always interested to hear about our problems, because we present them with very challenging data sets in terms of their complexity, their size and our own unique requirements,” Tran said. “We generally present them with problems that can push the boundaries of their own technology.”
Tran plans to use the award to purchase new computer hardware, to hire a postdoctoral researcher for the projects and to enable experts at Fermilab to determine how to apply novel computing systems on a large scale.
“Nhan is internationally recognized as an innovator who completes his ideas,” Canepa said. “If he has an idea, that idea then becomes a reality. He has demonstrated that in challenging situations, and every time, he succeeded. He also chooses the right ideas. He really sees what are the main challenges — what is pulling us back from extracting the most information out of our precious data — and he identifies what’s the most relevant and impactful improvement and goes after that.”
Tran says Fermilab is a great environment for his work. He appreciates the excellent postdoctoral researchers that come to the lab and the ability to just walk up or down a floor and consult with experts, especially about the computing topics that he is not formally trained in.
“It’s an honor to receive this award,” Tran said. “And it’s really exciting to explore new techniques in deep learning and push it as far as we can go, both on the physics side and the technical side.”
This work is supported by the Department of Energy Office of Science.
 




		Tagged: artificial intelligence, CMS, computing, machine learning  
",,,,,,,"[{'@type': 'WebPage', '@id': 'https://news.fnal.gov/2019/08/fermilab-scientist-nhan-tran-receives-prestigious-doe-award-to-expand-particle-collider-research-capabilities-using-artificial-intelligence/', 'url': 'https://news.fnal.gov/2019/08/fermilab-scientist-nhan-tran-receives-prestigious-doe-award-to-expand-particle-collider-research-capabilities-using-artificial-intelligence/', 'name': 'Fermilab scientist Nhan Tran receives prestigious DOE award to expand particle collider research capabilities using artificial intelligence', 'isPartOf': {'@id': 'https://news.fnal.gov/#website'}, 'primaryImageOfPage': {'@id': 'https://news.fnal.gov/2019/08/fermilab-scientist-nhan-tran-receives-prestigious-doe-award-to-expand-particle-collider-research-capabilities-using-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://news.fnal.gov/2019/08/fermilab-scientist-nhan-tran-receives-prestigious-doe-award-to-expand-particle-collider-research-capabilities-using-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://news.fnal.gov/wp-content/uploads/2019/08/nhan-tran-19-0126-15.hr_.jpg', 'datePublished': '2019-08-08T19:00:30+00:00', 'dateModified': '2019-08-08T14:39:58+00:00', 'author': {'@id': 'https://news.fnal.gov/#/schema/person/c6b9132b673df1154b4f92cd180942a5'}, 'breadcrumb': {'@id': 'https://news.fnal.gov/2019/08/fermilab-scientist-nhan-tran-receives-prestigious-doe-award-to-expand-particle-collider-research-capabilities-using-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.fnal.gov/2019/08/fermilab-scientist-nhan-tran-receives-prestigious-doe-award-to-expand-particle-collider-research-capabilities-using-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.fnal.gov/2019/08/fermilab-scientist-nhan-tran-receives-prestigious-doe-award-to-expand-particle-collider-research-capabilities-using-artificial-intelligence/#primaryimage', 'url': 'https://news.fnal.gov/wp-content/uploads/2019/08/nhan-tran-19-0126-15.hr_.jpg', 'contentUrl': 'https://news.fnal.gov/wp-content/uploads/2019/08/nhan-tran-19-0126-15.hr_.jpg', 'width': 2560, 'height': 1707, 'caption': 'Fermilab scientist Nhan Tran is developing computer systems to cope with the increasing amounts of data that particle colliders produce. Photo: Reidar Hahn'}, {'@type': 'BreadcrumbList', '@id': 'https://news.fnal.gov/2019/08/fermilab-scientist-nhan-tran-receives-prestigious-doe-award-to-expand-particle-collider-research-capabilities-using-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.fnal.gov/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Fermilab scientist Nhan Tran receives prestigious DOE award to expand particle collider research capabilities using artificial intelligence'}]}, {'@type': 'WebSite', '@id': 'https://news.fnal.gov/#website', 'url': 'https://news.fnal.gov/', 'name': 'News', 'description': 'Fermilab news', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.fnal.gov/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://news.fnal.gov/#/schema/person/c6b9132b673df1154b4f92cd180942a5', 'name': 'leah', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.fnal.gov/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/a04dbb25d08b803c9063b915044779e6?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/a04dbb25d08b803c9063b915044779e6?s=96&d=mm&r=g', 'caption': 'leah'}, 'url': 'https://news.fnal.gov/author/leah/'}]",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigAFodHRwOi8vbmV3cy50aGVyZWdpc3RyeXBzLmNvbS91LXMtZW1wbG95ZWVzLXBlcnNwZWN0aXZlcy1vbi10aGUtam9icy1tb3N0LWF0LXJpc2stZnJvbS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi10aGUtd29ya3BsYWNlL9IBAA?oc=5,U.S. Employees’ Perspectives on the Jobs Most at Risk from Artificial Intelligence in the Workplace - The Registry Seattle,2019-08-07,The Registry Seattle,http://news.theregistryps.com,"San Francisco, Genesys, U.S., Germany, United Kingdom, Japan, Australia, New Zealand, Artificial Intelligence",N/A,"San Francisco, Genesys, U.S., Germany, United Kingdom, Japan, Australia, New Zealand, Artificial Intelligence",N/A,https://schema.org,BreadcrumbList,,,,,,,,,,N/A,N/A,"

Home  News Releases  U.S. Employees’ Perspectives on the Jobs Most at Risk from Artificial Intelligence...
News Releases

U.S. Employees’ Perspectives on the Jobs Most at Risk from Artificial Intelligence in the Workplace

August 7, 2019 


FacebookTwitterWhatsAppLinkedinReddItEmail




Opinion survey from Genesys flags manufacturing, retail, telemarketing and data entry positions as most likely to be impacted by AI
SAN FRANCISCO (Aug. 6, 2019) — A new survey finds U.S. workers believe jobs in Manufacturing (43%), Retail/Checkout Clerks (40%), Telemarketers (38%) and in Data Entry (37%) are the most likely to shrink due to the expansion of artificial intelligence (AI). However, two-thirds (67%) of respondents say they are not afraid that AI/bots will replace their own jobs within the next 10 years.
These findings stem from research sponsored by Genesys® (www.genesys.com), the global leader in omnichannel customer experience and contact center solutions, into the attitudes of 1,001 employed Americans regarding the current and future effects of AI on the workplace.
Survey participants in a wide variety of industries were asked to select the three jobs most likely to be replaced by AI from among the following options: Accountant/Tax Preparer, Data Entry, Food Service, Insurance Underwriters, Manufacturing, Paralegal, Pharmacist, Retail/Checkout Clerk, Telemarketer, Transportation/Driver, and Other.
Who’s afraid of AI?
The Genesys findings reveal that U.S. employees working in Education/Training and as Doctor/Nurse/Caregivers are the least afraid that AI/bots will take their jobs within the next 10 years. The most afraid? The Media and those with Assembly Line/Manufacturing jobs.
Human Resources employees, who should have the pulse on employment trends, identified Data Entry and Retail/Checkout jobs as the most likely to be replaced by AI, and equally at risk. Employees working in Customer Service tend toward pessimism, selecting the jobs of Retail/Checkout Clerk and Telemarketer as the most likely to suffer from AI.
Surprisingly, Transportation-related jobs, such as drivers, are considered by only 16% of U.S. survey respondents as among the most likely functions to be replaced by AI. This response appears to indicate that participants are not paying close attention to the predicted coming revolution in autonomous vehicles and trucking fleets.
Equally interesting is that in spite of publicity surrounding automated restaurants and robot servers, particularly in Asia, only 17% of U.S. respondents see Food Service jobs in danger of AI. Survey respondents working within Food Service and Transportation themselves ignore negative media coverage and point the finger at Retail/Checkout Clerks and Manufacturing positions as the most threatened.
Just over half (52%) of U.S. employees surveyed express confidence in their skillset for competing in the AI-enabled workplace, but this could change as an equal 52% say they don’t feel AI has impacted their jobs — yet.
“The American employees we surveyed have a generally positive view of technology in their workplaces, with 86% affirming its benefits. However, that doesn’t make them blind to how artificial intelligence could impact particular industries,” said Merijn te Booij, chief marketing officer for Genesys. “The key is that humans and technology must work together. When implemented strategically and balanced with the human touch, AI can elevate the workforce by enabling employees to be more productive, accurate and fulfilled as they are positioned to enjoy the more complex aspects of their work.”
The survey uncovers many other interesting insights, including:
Across age groups, U.S. employees agree that Manufacturing and Retail/Checkout Clerks are most at risk, while believing that Paralegals (4%), Insurance Underwriters (5%), and Pharmacists (7%) have the best chance to survive automation.More part-time U.S. employees (25%) fear AI will take their jobs within 10 years than do full-time workers (18%), although there is no significant difference in attitudes on the specific jobs they think are likely to disappear.Employees in the largest companies, with more than 20,000 staff, are slightly less afraid (17%) than the overall group (19%) of the effect of AI/bots on their jobs within the next 10 years, possibly because they have already experienced its negative impact (10%) and see a more stable future.
The responses of U.S. employees line up very closely to the opinions held by U.S. employers surveyed separately by Genesys, who also found the four jobs most threated by AI to be Data entry, Manufacturing, Retail/Checkout Clerk and Telemarketer. The only notable difference was that more employers (52%) selected Data Entry as their top choice, compared to 37% of the employees.
Genesys announced initial employee survey findings in July and will release additional insights in the coming months from both employee and employer surveys. 
Survey Methodology and Participants
Within the U.S., a total of 1,001 adults completed the online survey of employees in April. Respondents were evenly divided into three age ranges: 18-38, 39-54, 55-73, with women accounting for 65% and men 35%; less than 1% did not categorize by gender.
Approximately 80% of those surveyed have full-time employee status with the remaining 20% working part-time. Respondents came from seven categories of company sizes, with a total of 42% employed in companies of fewer than 250 employees.
While U.S. survey respondents work in a wide variety of industries, 77% are currently working in one of 11 functional job categories: Administrative, Assembly Line/Manufacturing, Customer Service/Retail/Technical Support, Doctor/Nurse/Caregiver, Education/Training, Finance/Accounting, Food Service, Human Resources, Marketing/Inside Sales, Media, and Driver/Transportation Provider. The remaining 23% fell into an “Other” job category.
Genesys commissioned third-party research consultancy Vitreous World to conduct an identical survey in six countries — the U.S., Germany, the United Kingdom, Japan, Australia, and New Zealand — for a total of 4,207 participants.
About GenesysGenesys® powers more than 25 billion of the world’s best customer experiences each year. Our success comes from connecting employee and customer conversations on any channel. Every day, 11,000 companies in more than 100 countries trust our #1 customer experience platform to drive great business outcomes and create lasting relationships. Combining the best of technology and human ingenuity, we build solutions that mirror natural communication and work the way you think. Our industry-leading solutions foster true omnichannel engagement because they perform equally well across channels, on-premise and in the cloud. Experience communication as it should be: fluid, instinctive and profoundly empowering. Visit genesys.com.
 


TAGSAustraliaGenesysGermanyJapanNew ZealandSan FranciscoU.S.United Kingdom 
FacebookTwitterWhatsAppLinkedinReddItEmail

 The Registry  
",,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://news.theregistryps.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://news.theregistryps.com/category/news-releases/', 'name': 'News Releases'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/', 'name': 'U.S. Employees’ Perspectives on the Jobs Most at Risk from Artificial Intelligence...'}}]","[{'@type': 'WebPage', '@id': 'http://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/', 'url': 'http://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/', 'name': 'U.S. Employees’ Perspectives on the Jobs Most at Risk from Artificial Intelligence in the Workplace - The Registry', 'isPartOf': {'@id': 'https://news.theregistryps.com/#website'}, 'primaryImageOfPage': {'@id': 'http://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/#primaryimage'}, 'image': {'@id': 'http://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/#primaryimage'}, 'thumbnailUrl': 'https://i0.wp.com/news.theregistryps.com/wp-content/uploads/2019/08/1.jpg?fit=1200%2C674&ssl=1', 'datePublished': '2019-08-07T20:43:29+00:00', 'dateModified': '2019-08-07T20:43:31+00:00', 'author': {'@id': 'https://news.theregistryps.com/#/schema/person/b1cbb828f663799befe2b699979abf90'}, 'description': 'San Francisco, Genesys, U.S., Germany, United Kingdom, Japan, Australia, New Zealand, Artificial Intelligence', 'breadcrumb': {'@id': 'http://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['http://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'http://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/#primaryimage', 'url': 'https://i0.wp.com/news.theregistryps.com/wp-content/uploads/2019/08/1.jpg?fit=1200%2C674&ssl=1', 'contentUrl': 'https://i0.wp.com/news.theregistryps.com/wp-content/uploads/2019/08/1.jpg?fit=1200%2C674&ssl=1', 'width': 1200, 'height': 674, 'caption': 'San Francisco, Genesys, U.S., Germany, United Kingdom, Japan, Australia, New Zealand, Artificial Intelligence'}, {'@type': 'BreadcrumbList', '@id': 'http://news.theregistryps.com/u-s-employees-perspectives-on-the-jobs-most-at-risk-from-artificial-intelligence-in-the-workplace/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.theregistryps.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'U.S. Employees’ Perspectives on the Jobs Most at Risk from Artificial Intelligence in the Workplace'}]}, {'@type': 'WebSite', '@id': 'https://news.theregistryps.com/#website', 'url': 'https://news.theregistryps.com/', 'name': 'The Registry', 'description': 'Pacific Northwest Real Estate', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.theregistryps.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://news.theregistryps.com/#/schema/person/b1cbb828f663799befe2b699979abf90', 'name': 'The Registry', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.theregistryps.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/4ed186aa5c2e60f8a1236f0ef456ce07?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/4ed186aa5c2e60f8a1236f0ef456ce07?s=96&d=mm&r=g', 'caption': 'The Registry'}, 'url': 'https://news.theregistryps.com/author/tijana/'}]",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMinwFodHRwczovL3d3dy5pbmRpYXRvZGF5LmluL2VkdWNhdGlvbi10b2RheS9mZWF0dXJlcGhpbGlhL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWlzLWNoYW5naW5nLXRoZS10ZWFjaGluZy1sZWFybmluZy1wcm9jZXNzLWluLWVkdWNhdGlvbi0xNTc5MjI0LTIwMTktMDgtMDnSAaMBaHR0cHM6Ly93d3cuaW5kaWF0b2RheS5pbi9hbXAvZWR1Y2F0aW9uLXRvZGF5L2ZlYXR1cmVwaGlsaWEvc3RvcnkvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaXMtY2hhbmdpbmctdGhlLXRlYWNoaW5nLWxlYXJuaW5nLXByb2Nlc3MtaW4tZWR1Y2F0aW9uLTE1NzkyMjQtMjAxOS0wOC0wOQ?oc=5,Artificial intelligence is changing the teaching-learning process in education! - India Today,2019-08-09,India Today,https://www.indiatoday.in,,"Artificial intelligence, ai, education, teaching, student, curriculum, technology","From letting teachers concentrate on building the minds of students instead of checking copies, to tailoring the learning process for each individual student, artificial intelligence is totally revolutionising the teaching-learning process in education.  ","From letting teachers concentrate on building the minds of students instead of checking copies, to tailoring the learning process for each individual student, artificial intelligence is totally revolutionising the teaching-learning process in education.  ",https://schema.org,ProfilePage,https://www.indiatoday.in/author/india-today-web-desk,"{'@type': 'Organization', 'name': 'India Today', 'url': 'https://www.indiatoday.in/', 'logo': {'@type': 'ImageObject', 'url': 'https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png', 'width': 600, 'height': 60}}",,,,https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png,,,,N/A,N/A,N/A,India Today Web Desk,,,,,"[{'@type': 'ListItem', 'name': 'News', 'position': 1, 'item': {'@id': 'https://www.indiatoday.in/', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': 'Education Today', 'position': 2, 'item': {'@id': 'https://www.indiatoday.in/education-today', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': 'Featurephilia', 'position': 3, 'item': {'@id': 'https://www.indiatoday.in/education-today/featurephilia', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': 'Artificial intelligence is changing the teaching-learning process in education!', 'position': 4}]",,,,"{'@type': 'SpeakableSpecification', 'cssSelector': ['h1', '.story-kicker']}","{'@type': 'SearchAction', 'target': 'https://www.indiatoday.in/search/{search_term_string}', 'query-input': 'required name=search_term_string'}","{'@type': 'ImageObject', 'url': 'https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png', 'width': 600, 'height': 60}","['https://www.facebook.com/IndiaToday', 'https://twitter.com/indiatoday', 'https://www.youtube.com/Indiatoday', 'https://www.instagram.com/indiatoday/']","{'@type': 'PostalAddress', 'streetAddress': 'FC-8, Ecity Bioscope Rd, Film City', 'addressLocality': 'Sector 16A, Noida', 'addressRegion': 'India', 'postalCode': '201301', 'telephone': '0120 480 7100'}",1200,675,"{'@type': 'Organization', 'name': 'India Today', 'url': 'https://www.indiatoday.in/'}","{'@id': 'https://www.indiatoday.in/author/india-today-web-desk', '@type': 'Person', 'name': 'India Today Web Desk'}","[{'@type': 'Article', 'headline': 'Artificial intelligence is changing the teaching-learning process in education! - India Today', 'url': 'https://www.indiatoday.in/education-today/featurephilia/story/artificial-intelligence-is-changing-the-teaching-learning-process-in-education-1579224-2019-08-09', 'datePublished': '2019-08-09 18:43:00+5:30', 'author': {'@id': 'https://www.indiatoday.in/author/india-today-web-desk'}}]"

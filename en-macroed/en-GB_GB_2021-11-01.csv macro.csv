URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,author,inLanguage,headline,alternativeheadline,publication,datecreated,@graph,article:section,article:summary,article text,image,genre,wordcount,publisher,mainEntityOfPage,dateModified,datePublished,articleSection,name,isAccessibleForFree,itemListElement,thumbnailUrl,articleBody,alternativeHeadline,hasPart,copyrightHolder,sourceOrganization,copyrightYear,isPartOf,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,dateCreated,identifier,creator,speakable,potentialAction,address,width,height,worksFor,mainEntity
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vd3d3LmFwYS5vcmcvbW9uaXRvci8yMDIxLzExL2NvdmVyLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,The promise and challenges of AI - APA Monitor on Psychology,2021-11-01,APA Monitor on Psychology,https://www.apa.org,"Psychologists are playing a larger role in the development and use of artificial intelligence, including how it can be used to improve mental health.","Technology,","Psychologists are playing a larger role in the development and use of artificial intelligence, including how it can be used to improve mental health.","Psychologists are playing a larger role in the development and use of artificial intelligence, including how it can be used to improve mental health.",http://schema.org,Article,https://www.apa.org/monitor/2021/11/cover-artificial-intelligence,"[{'@type': 'Person', 'name': 'Abrams, Zara'}]",English,The promise and challenges of AI,"Psychologists are playing a larger role in the development and use of artificial intelligence, including how it can be used to improve mental health.",Monitor on Psychology,2021-11-01,"[{'@id': 'issue', '@type': 'PublicationIssue', 'issueNumber': '8'}, {'@id': 'volume', '@type': 'PublicationVolume', 'volumeNumber': '52'}]",N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vZW1lcmouY29tL2FpLXNlY3Rvci1vdmVydmlld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYXQtZGlzbmV5L9IBAA?oc=5,Artificial Intelligence at Disney - Emerj,2021-11-02,Emerj,https://emerj.com,,,"The Walt Disney Company began in 1923 as the Disney Brothers Cartoon Studio. By 1940, Walt Disney Productions issued its first stock. Today, the",N/A,https://schema.org,Article,,Ryan Owen,,Artificial Intelligence at Disney,,,,,N/A,N/A," Data managementEntertainmentMarketing and advertising Artificial Intelligence at Disney Ryan OwenLast updated on November 2, 2021  Last updated on November 2, 2021, published by Ryan Owen Ryan Owen holds an MBA from the University of South Carolina, and has rich experience in financial services, having worked with Liberty Mutual, Sun Life, and other financial firms. Ryan writes and edits AI industry trends and use-cases for Emerj's editorial and client content. Share to: LinkedIn Twitter Facebook Email  The Walt Disney Company began in 1923 as the Disney Brothers Cartoon Studio. By 1940, Walt Disney Productions issued its first stock. Today, the multinational family entertainment and media conglomerate is one of the Big 6 media companies.  As of 2021, Disney trades on the NYSE with a market cap that exceeds $300 billion. For the fiscal year ended October 3, 2020, Disney reported revenues of $65.3 billion, according to its Fiscal Year 2020 10-K. Twelve years ago, Disney established DisneyResearch|Studios, its Swiss-based research arm that puts its research talent to work in applying machine learning, artificial intelligence, and visual computing innovations to its movies and media content. Disney also operates the Disney Accelerator program, which supports venture-backed, growth-stage startups with capital, workspace, and guidance from entertainment and technology leaders, including Disney top executives.  In this article, we will look at how Disney has explored AI applications for its business and industry through two unique use-cases: Creating Clouds that Look Real — Disney uses machine learning and deep learning to create realistic clouds that model directional light and are influenced by the sun and sky around them.  Analyzing and Acting upon Audience Reactions — Disney uses computer vision and machine learning to determine, predict, and influence an audience’s reaction to target content. We will begin by examining how Disney has turned to deep scattering, which uses advanced neural networks to add clouds to its animated films that look realistic and lifelike. Creating Clouds that Look Real Creating realistic, immersive 3D worlds that convince and entertain today’s audiences pushes the limits of technology and the imagination. Simulating the effect of light on these virtual environments—a critical process for making them realistic—is a massive technical challenge.  Light transport—part of the larger production rendering process—takes time and adds to the costs of films that feature these 3D worlds. When forming clouds for digital scenes, for example, the “characteristic silver lining and the ‘whiteness’ of the inner body” are challenging when relying on Monte Carlo simulation or diffusion theory alone, writes a team of Disney Research/ETH Zürich authors in a 2017 publication.   The business value in seeking faster, more resourceful methods to design these clouds is clear when these new technologies can lead to the more efficient deployment of both human and computational resources.  In their 2017 paper, the Disney/ETH Zürich research team points out that rendering a realistic sunlit cloud can take some 30 hours using traditional methods, called light tracing. However, when neural networks can predict how the sun will light that cloud, the entire process can be accomplished with the new deep scattering process in a matter of minutes.     To accomplish this, Disney Research Studios brings machine learning to the production rendering and light transport process. To accelerate the process, the researchers looked to develop new machine learning, and deep learning, algorithms that could provide: Path guiding for efficient simulation of light paths Production-ready denoising Deep scattering in atmospheric clouds To inform their algorithms to create the clouds, the researchers studied “the spatial and directional distribution of radiant flux” over dozens of sample cloud formations. With that information, they claim, clouds in new scenes could then be sampled, by creating the formation and geometry of the cloud while modeling realistic light sourcing and shading, a process they call deep scattering.  In the below video, Disney researchers show deep scattering and how to render clouds with radiance-predicting neural networks:  The deep neural networks then deliver the predicted radiance and improve these predictions over time, according to the research team. In creating clouds, Disney Research claims, the deep learning technology can be used for a variety of situations, including: Modeling directional light Modeling sun and sky Sunrise/sunset scenarios Our research was unable to locate any financial information specific to this technology alone, however, Disney Research Studios claims that its researchers help deploy tools into production that support Pixar and Disney Animation in RenderMan and Hyperion, their proprietary 3D rendering solutions.  Analyzing and Acting upon Audience Reactions To succeed in entertainment, you have to know your audience—sometimes even better than the audience knows itself. In the past, entertainment companies like Disney had to sample their intended population using focus groups and ask them what they thought about target content as they tested market fit.  Data scientists then had to correct for sampling error when they went to extrapolate their findings and estimate the reaction they could expect from larger audiences. This cost Disney time, money, and resources, and uncertainty around confidence levels.  Today, Disney is developing tools that can bring accuracy, confidence, and efficiency to the process. Disney is creating technologies that use computer vision to observe an audience and machine learning to gauge their reaction to content, based on visual cues like:  Facial expressions  Body movements  Eye movements  From a Disney Research online publication, this graphic shows how Disney uses facial landmarks to gauge and study audience reactions to its content. Disney is exploring Affective AI, an emerging technology designed to detect and analyze human emotional states. With Affective AI, Disney could realistically model and predict audience reactions that the company could then use to influence a character or plotline, or even make content decisions on a regional or demographic basis, for instance.    In a recent research paper, researchers from Disney Research, Queensland University of Technology, and Carnegie Mellon University describe using infrared cameras to record the subtle movements of moviegoers to determine their reactions to content. To test those reactions, the researchers say, they compared them to ratings recorded on commercial sites like rottentomatoes.com.     In another application of the technology, detailed in a 2017 Disney Research phys.org article, researchers used four infrared cameras in a 400-seat theater and observed faces in the audience.  Ultimately gathering a dataset of 16 million “facial landmarks” from over 3,000 individuals, the team applied deep learning models to predict, with high accuracy, the facial expressions an audience member would show during an entire movie, based on watching them for just a few moments.    By gathering this data and gaining confidence in the conclusions reached, Disney hopes, they can determine how their content evokes certain emotions and to what extent. Through its Audience Understanding effort, Disney claims, the company can test whether their content produces the desired effect and even predict, using machine learning, which emotions content will evoke, “moment-to-moment.”   While Disney does not share specific financial details related to its Audience Understanding effort, the company does disclose that insights from the project are “used by the Disney-ABC Television Group to inform content decisions.”  Related Posts Artificial Intelligence at Oracle - Two Current Use-CasesFounded in 1977 by a team of engineers led by Larry Ellison, Oracle became the… Artificial Intelligence and Digital Twins at General ElectricGeneral Electric (GE) was founded in 1889 by J.P. Morgan and Anthony J. Drexel who… Artificial Intelligence at Apple - Two Current ApplicationsFounded by Steve Jobs, Ronald Wayne, and Steve Wozniak in 1976, Apple is a global… Artificial Intelligence at Wells Fargo - A Brief OverviewWells Fargo has begun a number of AI initiatives, some they've created in-house and some… Artificial Intelligence at Disney, Viacom, and Other Entertainment GiantsArtificial intelligence has found its way in different areas in the entertainment industry from offering… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",https://emerj.com/wp-content/uploads/2021/08/Artificial-Intelligence-at-Disney-690x392.jpg,AI Sector Overviews,1100,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",https://emerj.com/ai-sector-overviews/artificial-intelligence-at-disney,2021-11-02,2021-11-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvYmVybmFyZG1hcnIvMjAyMS8xMS8wMi9ob3ctYWktY3JlYXRlcy1zeW50aGV0aWMtc3BlZWNoL9IBAA?oc=5,How AI Creates Synthetic Speech - Forbes,2021-11-02,Forbes,https://www.forbes.com,"alking machines are getting more and more sophisticated, and with the help of AI and machine learning, it is now possible to create high-quality, customizable synthetic speech.","LOVO,Stephen Hawking,AI,Tom Lee,Speech,Synthetic Speech,Artificial Intelligence","alking machines are getting more and more sophisticated, and with the help of AI and machine learning, it is now possible to create high-quality, customizable synthetic speech.","alking machines are getting more and more sophisticated, and with the help of AI and machine learning, it is now possible to create high-quality, customizable synthetic speech.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/bernardmarr/2021/11/02/how-ai-creates-synthetic-speech/,"{'@type': 'Person', 'name': 'Bernard Marr', 'url': 'https://www.forbes.com/sites/bernardmarr/', 'description': 'Bernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is Changing Business and Society. He has written over 20 best-selling and award-winning books and advises and coaches many of the world’s best-known organisations. He has a combined following of 4 million people across his social media channels and newsletters and was ranked by LinkedIn as one of the top 5 business influencers in the world. Follow Bernard on LinkedIn, X (Twitter) or YouTube. Join his newsletter, check out his website and books.', 'sameAs': ['https://www.linkedin.com/in/bernardmarr/', 'https://www.twitter.com/BernardMarr', 'https://bernardmarr.com/']}",,How AI Creates Synthetic Speech,,,,,Enterprise Tech,N/A,"More From ForbesJul 17, 2024,11:06am EDTAI Adoption Is Driving Real Top - And Bottom-Line Impact For EnterprisesJul 16, 2024,01:02pm EDTThe CEO’s Guide To Building Generative AIJul 16, 2024,01:24am EDT22 Generative AI Workplace Tools And How To Use ThemJul 15, 2024,09:02am EDTWhen Will Quantum Computers Affect Your Competitive Landscape?Jul 15, 2024,09:00am EDTAristotle’s Timeless Guide To Mastering AIOpsJul 15, 2024,03:25am EDTIEEE Travels In July (Japan, China And Greece)Jul 14, 2024,03:19am EDTMaking A More Accurate And Sustainable AI ModelEdit StoryForbesInnovationEnterprise TechHow AI Creates Synthetic SpeechBernard MarrContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itNov 2, 2021,03:07am EDTUpdated Nov 2, 2021, 03:07am EDTThis article is more than 2 years old.Share to FacebookShare to TwitterShare to LinkedinHaving machines turn text into speech is nothing new.

Professor Stephen Hawking communicated with a computerized voice for many years, and by now, we're used to our GPS devices or smart speakers asking questions and responding to our queries.
How AI Creates Synthetic SpeechAdobe Stock

What is different these days is that the quality of synthesized speech is improving, thanks to several companies using AI to create voice skins for enterprise companies and content creators that give more options for turning text into speech.

LOVO, an AI voice and synthetic speech startup company, uses a voiceover API to turn text into speech in real-time using 200+ human-like voices in 33 languages using their “voice library.” Users also can clone their own voices to create their own skins, simply by reading 15 minutes of a script.

PROMOTED
LOVO recently announced the close of a $4.5 million pre-Series A round, led by South Korean Kakao Entertainment. See here my full conversation with Tom Lee, Co-founder, and COO of LOVO (including a demo)
MORE FROMFORBES ADVISORBest High-Yield Savings Accounts Of 2024ByKevin PayneContributorBest 5% Interest Savings Accounts of 2024ByCassidy HortonContributor

What Is AI Speech Synthesis?









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Speech synthesis is simply the computer-generated production of audible human words.



1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
Traditional text-to-speech robotic voices you hear on software or hardware products like Amazon Echo, Google Home, your GPS, or your ebook reader are fast and cheap for companies to create, but they can also be unoriginal and unrealistic.

Artificial intelligence or AI voice operates a little differently. AI voice uses deep learning to create higher-quality synthetic speech that more accurately mimics the pitch, tone, and pace of a real human voice.
For example, if you wanted to use LOVO AI to generate synthetic text, you can upload a script that you want to turn into audio content. Then choose one of the voices in their library, based on language, style, and character. With a click of a button, LOVO turns your script into audio that sounds pretty lifelike.
You can also clone your own voice by reading a short script, and LOVO will generate a custom voice skin you can use over and over again for videos, audiobooks, or anything else that requires voiceover.
Here’s a side-by-side comparison of original voices and voice clones:

Will AI voice technology replace voiceover professionals? Tom Lee, Co-founder and COO of LOVO, says no.
“I believe that isn’t going to happen. If you think about how humans and how AIs work, we can complement each other. As a voice actor, you can only do 6 or 7 hours of work a day. You can't work 24/7, and you want to focus your energy on the most important gigs, or maybe you want to have a day job, and then you want your AI voice to make money while you sleep. You can record once with us, then take the revenue shares. One of our most famous voices is raking in a couple of grand a month without doing any work.""

The Many Potential Uses of Synthetic Speech
AI voice has a myriad of use cases, including:
Translation: Papercup is using AI voice to translate videos by generating voices that sound like the original speaker.
Video or audio ads: You can upload a script and create an ad without the added expense and time involved in hiring a voiceover artist. Descript has a collaborative audio/video editor that works just like a regular Word document.
E-learning (for kids, or for corporate training): Teachers and trainers will be able to make written materials more accessible for different types of learners with the help of AI voice automation.
Augmented reality and virtual reality: With the AR and VR markets exploding right now, there is a huge need for realistic, authentic human voices for apps and websites.
The global text to speech (TTS) market is estimated to reach $5.0 billion by 2026, according to marketsandmarkets.com – so the sky's the limit for this exciting new technology.
To find out more about the latest trends in AI and machine learning, check out the rest of my website or subscribe to my YouTube channel.
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Bernard MarrFollowingFollowBernard Marr is a world-renowned futurist, board advisor and author of Generative AI in Practice: 100+ Amazing Ways Generative Artificial Intelligence is... Read MoreEditorial StandardsPrintReprints & Permissions","{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/6180e37b097087a68b795e53/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",,,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",,2021-11-02T03:07:34-04:00,2021-11-02T03:07:34-04:00,Enterprise Tech,How AI Creates Synthetic Speech,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise Tech', 'item': 'https://www.forbes.com/enterprise-tech/'}]",,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMjczNDY2Mi9haS1sYW5ndWFnZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mdXR1cmUtbW9kZWxzLWdwdC0zLWxpbWl0YXRpb25zLWJpYXPSAQA?oc=5,The future of AI is a conversation with a computer - The Verge,2021-11-01,The Verge,https://www.theverge.com,"AI writing systems are becoming more and more common, from Google’s suggested replies in Gmail to chatbots powered by OpenAI’s GPT-3. But what do the strengths and weaknesses of these tools tell us about the future of artificial intelligence?",N/A,Read-write intelligence.,N/A,http://schema.org/,NewsArticle,https://www.theverge.com/22734662/ai-language-artificial-intelligence-future-models-gpt-3-limitations-bias,"[{'@type': 'Person', 'name': 'James Vincent', 'url': 'https://www.theverge.com/authors/james-vincent'}]",,The future of AI is a conversation with a computer,,,,,N/A,N/A,"TechThe future of AI is a conversation with a computerAI writing tools can tell us a lot about artificial intelligenceBy  James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge.Illustrations by Micha Huigen Nov 1, 2021, 9:16 AM EDTShare this story0 Comments / 0 New Illustration by Micha HuigenHow would an AI writing program start an article on the future of AI writing? Well, there’s one easy way to find out: I used the best known of these tools, OpenAI’s GPT-3, to do the job for me. Using GPT-3 is disarmingly simple. You have a text box to type into and a menu on the side to adjust parameters, like the “temperature” of the response (which essentially equates to randomness). You type, hit enter, and GPT-3 completes what you’ve written, be it poetry, fiction, or code. I tried inputting a simple headline and a few sentences about the topic, and GPT-3 began to fill in the details. It told me that AI uses “a series of autocomplete-like programs to learn language” and that these programs analyze “the statistical properties of the language” to “make educated guesses based on the words you’ve typed previously.” So far, so good, I thought. I hit enter again, and the program added a quote from Google’s head of AI, Jeff Dean, then referenced an experimental piece of software from the 1960s before promising that an “AI Revolution” was coming that would reap immense rewards across the fields of science, technology, and medicine. The medium included plausible fabrications; endless output; and, crucially, an opportunity to respond to the robot writerFine, I thought. Then I thought a little more and did some googling. I soon discovered that the quote from Dean was made up, that the experimental software never existed, and while the promise of an “AI Revolution” was all well and good, it wasn’t any different from the vague nonsense found in hype-filled press releases. Really, what was most revealing about the future of AI was not what GPT-3 said but how it said it. The medium is the message, as Marshall McLuhan pointed out many years ago. And here, the medium included plausible fabrications; endless output; and, crucially, an opportunity to respond to the robot writer.If we’re looking ahead at the next 10 years of AI development, trying to predict how we will interact with increasingly intelligent software, it helps to consider those tools that can talk back. AI writing models may only be digital parrots, able to copy form without understanding meaning, but they still create a dialogue with the user. This is something that often seems missing from the introduction of AI systems like facial recognition algorithms (which are imposed upon us) or self-driving cars (where the public becomes the test subject in a dangerous experiment). With AI writing tools, there is the possibility for a conversation. If you use Gmail or Google Docs, then you’ve probably already encountered this technology. In Google’s products, AI editors lurk in the blank space in front of your cursor, manifesting textual specters that suggest how to finish a sentence or reply to an email. Often, their prompts are just simple platitudes — ”Thanks!”, “Great idea!”, “Let’s talk next week!” — but sometimes these tools seem to be taking a stronger editorial line, pushing your response in a certain direction. Such suggestions are intended to be helpful, of course, but they seem to provoke annoyance as frequently as gratitude.  To understand how AI systems learn to generate such suggestions, imagine being given two lists of words. One starts off “eggs, flour, spatula,” and the other goes “paint, crayons, scissors.” If you had to add the items “milk” and “glitter” to these lists, which would you choose and with how much confidence? And what if that word was “brush” instead? Does that belong in the kitchen, where it might apply an egg wash, or is it more firmly located in the world of arts-and-crafts? Quantifying this sort of context is how AI writing tools learn to make their suggestions. They mine vast amounts of text data to create statistical maps of the relationships between words, and use this information to complete what you write. When you start typing, they start predicting which words should come next. Their ability to actually understand language is a topic of hot debate, but their fluency across genres is undeniableFeatures like Gmail’s Smart Reply are only the most obvious example of how these systems — often known as large language models — are working their way into the written world. AI chatbots designed for companionship have become increasingly popular, with some, like Microsoft’s Chinese Xiaoice, attracting tens of millions of users. Choose-your-own-adventure-style text games with AI dungeon masters are attracting users by letting people tell stories collaboratively with computers. And a host of startups offer multipurpose AI text tools that summarize, rephrase, expand, and alter users’ input with varying degrees of competence. They can help you to write fiction or school essays, say their creators, or they might just fill the web with endless spam.The ability of the underlying software to actually understand language is a topic of hot debate. (One that tends to arrive, time and time again, at the same question: what do we mean by “understand” anyway?). But their fluency across genres is undeniable. For those enamored with this technology, scale is key to their success. It’s by making these models and their training data bigger and bigger that they’ve been able to improve so quickly. Take, for example, the training data used to create GPT-3. The exact size of the input is difficult to calculate, but one estimate suggests that the entirety of Wikipedia in English (3.9 billion words and more than 6 million articles) makes up only 0.6 percent of the total. Relying on scale to build these systems has benefits and drawbacks. From an engineering perspective, it allows for fast improvements in quality: just add more data and compute to reap fast rewards. The size of large language models is generally measured in their number of connections, or parameters, and by this metric, these systems have increased in complexity extremely quickly. GPT-2, released in 2019, had 1.5 billion parameters, while its 2020 successor, GPT-3, had more than 100 times that — some 175 billion parameters. Earlier this year, Google announced it had trained a language model with 1.6 trillion parameters. Push them on any given topic or stray from the most obvious fields, and they will lie thoughtlesslyThe difference in quality as systems get larger is notable, but it’s unclear how much longer these scaling efforts will reap rewards in quality. Boosters think that sky’s the limit — that these systems will keep on getting smarter and smarter, and that they may even be the first step toward creating a general-purpose artificial intelligence or AGI. But skeptics suggest that the AI field in general is starting to reap diminishing returns as it scales ever up.  A reliance on scale, though, is inextricably linked to the statistical approach that creates uncertainty in these models’ output. These systems have no centralized store of accepted “truths”; no embodied understanding of “what the world is like for humans” and, hence, no way to distinguish fact from fiction or to exercise common sense. Quiz them on simple trivia, like capital cities or the birthdays of US presidents, and they are right most of the time. But to these systems, truth is simply a statistical feature of their training data. They answer questions correctly because the text they’ve been fed has presented them with the correct information with enough frequency. This means that if you push them on any given topic or stray from the most obvious fields, they will lie thoughtlessly, making up quotes, dates, biographical details, and anything else you want to hear. The same probabilistic approach also means they can stumble over common sense questions. Start quizzing them with slightly fantastical queries, and they will confidently assert, for example, that a pencil is heavier than a toaster or that a blade of grass only has one eye. Such answers reveal the gulf between statistical and embodied intelligence. To get a better understanding of these AI language models, I’ve been playing with a variety for the past few weeks; from tools sold to copywriters to flexible, multipurpose systems like GPT-3. The experience has been dizzying. Often, I’m amazed by the fluency, insight, and creativity of these systems. As part of a project for The Verge’s 10-year anniversary, for example, I used GPT-3 to write technopagan spells for a zine, feeding it a prompt (below in bold) which it completed with a four-step ritual (of which I’m showing only the first step):Technopaganism is a new sort of magic that blends traditional witchcraft with the power of being online all the time. What follows is a technopagan spell designed to protect your phone from spam and improve the quality of messages you receive. Step 1) Take your cell phone and go outside. Close your eyes, hold the device in front of you, and intone: “I offer you, O Spirit of Technopagan Magic, my eternal and unending electronic connection to the net. And in return I ask you for magick to combine my will with the will of the system — make me impervious to the garbage that flows through my inbox. Make all messages flow together, and I will choose among them what is right for me to see. Grant me the Finger of the Internet, and I will strike at spam, and cast out the spammers back to the dark places where they come from.” But other times, I’m stunned by how limited these programs are. Something that’s often overlooked is just how much human curation is needed to shape their output. The text above was not the first response I received from GPT-3, and I had to go through several iterations to generate a response that was both cogent and funny. It helped, of course, that the task I’d set GPT-3 was an imaginative and open-ended one: it played into the program’s strengths (and I think GPT-3’s success in such tasks has led some users and observers to exaggerate the intelligence of these systems). Other times, though, the software produced nonsensical content even within the fanciful framing I’d given it. Another “spell” it generated in response to the same prompt was much less focused, adding fictitious social media handles, tech headlines, and non-existent URLs to the spell’s instructions: Perform a ritual to seal the crown circle into the device. May the gods help us all, the Apple iPhone X reference for is broken! Destroy the holy symbol! —tianong xiong (@tianongxiong) September 13, 2018 To confirm the rumor: Facebook Messenger’s search bar does have a search bar hidden right next to it pic.twitter.com/DghBL5DmhU — Warl Darkh (@dkpt) September 12, 2018 You can argue that this is just creativity of a different sort, and that of course a proper technopagan spell would include URLs. But it’s also obvious the machine has gone off-piste.Despite such weaknesses, there’s already talk of AI systems taking over writers’ jobs. Naturally, I wondered if a computer could write articles for The Verge (and not just this one). I played around with different models, inputting opening paragraphs into these systems and asking for story ideas. Here is some more from GPT-3 on large language models: “The human brain is just a really fancy computer,” said Jeff Dean, a Google hardware engineer and AI expert, at a company event in 2016. “It’s a computer made of meat.”To understand GPT-3, you first have to know a little about how the brain learns. The brain isn’t born knowing how to speak or understand speech. It must first acquire this ability through exposure to the outside world, which is why children tend to learn language so quickly, and why being raised in a household where a language isn’t spoken presents a major obstacle.As neuroscientist Mark Changizi has shown, the process of learning a language is a massive project. “Language is one of the most complex things that brains can do,” he writes, “and it emerges from the brain’s more basic skills, like vision, hearing, and motor control.”But how does the brain acquire all this knowledge? The short answer is: via autocomplete.All these points make sense if you’re not concentrating too hard, but they don’t flow from sentence to sentence. They never follow an argument or build to a conclusion. And again, fabrication is a problem. Both Jeff Dean and Mark Changizi are real people who have been more or less correctly identified (though Dean is now head of AI at Google, and Changizi is a cognitive scientist rather than a neuroscientist). But neither man ever uttered the words that GPT-3 attributed to them, as far as I can tell. Yet despite these problems, there’s also a lot to be impressed by. For example, using “autocomplete” as a metaphor to describe AI language models is both accurate and easy to understand. I’ve done it myself! But is this because it’s simply a common metaphor that others have deployed before? Is it right then to say GPT-3 is “intelligent” to use this phrase or is it just subtly plagiarizing others? (Hell, I ask the same questions about my own writing.)Where AI language models seem best suited, is creating text that is rote, not bespoke, as with Gmail’s suggested replies. In the case of journalism, automated systems have already been integrated into newsrooms to write “fill in the blanks” stories about earthquakes, sporting events, and the like. And with the rise of large AI language models, the span of content that can be addressed in this way is expanding.“Mostly, it’s people in the content marketing industry who have company blogs to fill, who need to create content.”Samanyou Garg is the founder of an AI writing startup named Writesonic, and says his service is used mostly by e-commerce firms. “It really helps [with] product descriptions at scale,” says Garg. “Some of the companies who approach us have like 10 million products on their website, and it’s not possible for a human to write that many.” Fabian Langer, founder of a similar firm named AI Writer, tells The Verge that his tools are often used to pad out “SEO farms” — sites that exist purely to catch Google searches and that create revenue by redirecting visitors to ads or affiliates. “Mostly, it’s people in the content marketing industry who have company blogs to fill, who need to create content,” said Langer. “And to be honest, for these [SEO] farms, I do not expect that people really read it. As soon as you get the click, you can show your advertisement, and that’s good enough.”It’s this sort of writing that AI will take over first, and which I’ve started to think of as “low-attention” text — a description that applies to both the effort needed to create and read it. Low-attention text is not writing that makes huge demands on our intelligence, but is mostly functional, conveying information quickly or simply filling space. It also constitutes a greater portion of the written world than you might think, including not only marketing blogs but work interactions and idle chit-chat. That’s why Gmail and Google Docs are incorporating AI language models’ suggestions: they’re picking low-hanging fruit. The choice to use this filler on a wide scale will have structural effectsA big question, though, is what effect will these AI writing systems have on human writing and, by extension, our culture? The more I’ve thought about the output of large language models, the more it reminds me of geofoam. This is a building material made from expanded polystyrene that is cheap to produce, easy to handle, and packed into the voids left over by construction projects. It is incredibly useful but somewhat controversial, due to its uncanny appearance as giant polystyrene blocks. To some, geofoam is an environmentally-sound material that fulfills a specific purpose. To others, it’s a horrific symbol of our exploitative relationship with the Earth. Geofoam is made by pumping oil out of the ground, refining it into cheap matter, and stuffing it back into the empty spaces progress leaves behind. Large language models work in a similar way: processing the archaeological strata of digital text into synthetic speech to fill our low-attention voids. For those who worry that much of the internet is already “fake” — sustained by botnets, traffic farms, and automatically generated content — this will simply mark the continuation of an existing trend. But just as with geofoam, the choice to use this filler on a wide scale will have structural effects. There is ample evidence, for example, that large language models encode and amplify social biases, producing text that is racist and sexist, or that repeats harmful stereotypes. The corporations in control of these models pay lip service to these problems but don’t think they present serious problems. (Google famously fired two of its AI researchers after they published a detailed paper describing these issues.) And as we offload more of the cognitive burden of writing onto machines, making our low-attention text no-attention text, it seems plausible that we, in turn, will be shaped by the output of these models. Google already uses its AI autocomplete tools to suggest gender-neutral language (replacing “chairman” with “chair,” for example), and regardless of your opinion on the politics of this sort of nudge, it’s worth discussing what the end-point of these systems might be. In other words: what happens when AI systems trained on our writing start training us? Despite the problems and limitations of large language models, they’re already being embraced for many tasks. Google is making language models central to its various search products; Microsoft is using them to build automated coding software, and the popularity of apps like Xiaoice and AI Dungeon suggests that the free-flowing nature of AI writing programs is no hindrance to their adoption. Like many other AI systems, large language models have serious limitations when compared with their hype-filled presentations. And some predict this widespread gap between promise and performance means we’re heading into another period of AI disillusionment. As the roboticist Rodney Brooks put it: “just about every successful deployment [of AI] has either one of two expedients: It has a person somewhere in the loop, or the cost of failure, should the system blunder, is very low.” But AI writing tools can, to an extent, avoid these problems: if they make a mistake, no one gets hurt, and their collaborative nature means human curation is often baked in. “A deity that rules communication is an incorporeal linguistic power.”What’s interesting is considering how the particular characteristics of these tools can be used to our advantage, showing how we might interact with machine learning systems, not in a purely functional fashion but as something exploratory and collaborative. Perhaps the most interesting single use of large language models to date is a book named Phamarko AI: a text written by artist and coder K Allado-McDowell as an extended dialogue with GPT-3. To create Phamarko AI, Allado-McDowell wrote and GPT-3 responded. “I would write into a text field, I would write a prompt, sometimes that would be several paragraphs, sometimes it would be very short, and then I would generate some text from the prompt,” Allado-McDowell told The Verge. “I would edit the output as it was coming out, and if I wasn’t interested in what it was saying, I would cut that part and regenerate, so I compared it to pruning a plant.” The resulting text is esoteric and obscure, discussing everything from the roots of language itself to the concept of “hyper-dimensionality.” It is also brilliant and illuminating, showing how writing alongside machines can shape thought and expression. At different points, Allado-McDowell compares the experience of writing using GPT-3 to taking mushrooms and communing with gods. They write: “A deity that rules communication is an incorporeal linguistic power. A modern conception of such might read: a force of language from outside of materiality.” That force, Allado-McDowell suggests, might well be a useful way to think about artificial intelligence. The result of communing with it is a sort of “emergence,” they told me, an experience of “being part of a larger ecosystem than just the individual human or the machine.”It’s impossible that this exchange will only be good for usThis, I think, is why AI writing is so much more exciting than many other applications of artificial intelligence: because it offers the chance for communication and collaboration. The urge to speak to something greater than ourselves is evident in how these programs are being embraced by early adopters. A number of individuals have used GPT-3 to talk to dead loved ones, for example, turning its statistical intelligence into an algorithmic ouija board. Though such experiments also reveal the limitations. In one of these cases, OpenAI shut down a chatbot shaped to resemble a developer’s dead fiancée because the program didn’t conform to the company’s terms of service. That’s another, less promising reality of these systems: the vast majority are owned and operated by corporations with their own interests, and they will shape their programs (and, in turn, their users) as they see fit. Despite this, I’m hopeful, or at least curious, about the future of AI writing. It will be a conversation with our machines; one that is diffuse and subtle, taking place across multiple platforms, where AI programs linger on the fringes of language. These programs will be unseen editors to news stories and blog posts, they will suggest comments in emails and documents, and they will be interlocutors that we even talk to directly. It’s impossible that this exchange will only be good for us, and that the deployment of these systems won’t come without problems and challenges. But it will, at least, be a dialogue. Comments0 Comments / 0 NewFeatured Videos From The VergeSamsung Galaxy Watch Ultra: ring any bells?
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe $649.99 Samsung Galaxy Watch Ultra doesn’t hide where it got its inspiration from, but it is the first to have FDA-cleared sleep apnea detection.Most PopularMost PopularThe secret gardenIt’s never been easier for the cops to break into your phoneHere’s a very clear real-world look at Google’s Pixel 9 Pro FoldApple is finally embracing Android’s chaosHere’s how much Valve pays its staff — and how few people it employs Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From","[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/ifk8GTB_ydkq6QKiFlV-W0Xetfs=/0x0:1080x1920/1400x788/filters:focal(637x1018:638x1019)/cdn.vox-cdn.com/uploads/chorus_asset/file/22963970/VRG_ILLO_4851_10_Year_ai.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/HuMM3fu_TMdwbULUCiStrhsqixo=/0x0:1080x1920/1400x1050/filters:focal(637x1018:638x1019)/cdn.vox-cdn.com/uploads/chorus_asset/file/22963970/VRG_ILLO_4851_10_Year_ai.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/voy3DLvWSWzFuKO_5juiHxKEPQw=/0x0:1080x1920/1400x1400/filters:focal(637x1018:638x1019)/cdn.vox-cdn.com/uploads/chorus_asset/file/22963970/VRG_ILLO_4851_10_Year_ai.jpg', 'width': 1400, 'height': 1400}]",,,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",,2021-11-01T13:16:00.000Z,2021-11-01T13:16:00.000Z,,,,,https://cdn.vox-cdn.com/thumbor/ifk8GTB_ydkq6QKiFlV-W0Xetfs=/0x0:1080x1920/1400x788/filters:focal(637x1018:638x1019)/cdn.vox-cdn.com/uploads/chorus_asset/file/22963970/VRG_ILLO_4851_10_Year_ai.jpg,"How would an AI writing program start an article on the future of AI writing? Well, there’s one easy way to find out: I used the best known of these tools, OpenAI’s GPT-3, to do the job for me. 

Using GPT-3 is disarmingly simple. You have a text box to type into and a menu on the side to adjust parameters, like the “temperature” of the response (which essentially equates to randomness). You type, hit enter, and GPT-3 completes what you’ve written, be it poetry, fiction, or code. I tried inputting a simple headline and a few sentences about the topic, and GPT-3 began to fill in the details. It told me that AI uses “a series of autocomplete-like programs to learn language” and that these programs analyze “the statistical properties of the language” to “make educated guesses based on the words you’ve typed previously.” 

So far, so good, I thought. I hit enter again, and the program added a quote from Google’s head of AI, Jeff Dean, then referenced an experimental piece of software from the 1960s before promising that an “AI Revolution” was coming that would reap immense rewards across the fields of science, technology, and medicine. 

""The medium included plausible fabrications; endless output; and, crucially, an opportunity to respond to the robot writer""

Fine, I thought. Then I thought a little more and did some googling. I soon discovered that the quote from Dean was made up, that the experimental software never existed, and while the promise of an “AI Revolution” was all well and good, it wasn’t any different from the vague nonsense found in hype-filled press releases. Really, what was most revealing about the future of AI was not what GPT-3 said but how it said it. The medium is the message, as Marshall McLuhan pointed out many years ago. And here, the medium included plausible fabrications; endless output; and, crucially, an opportunity to respond to the robot writer.

If we’re looking ahead at the next 10 years of AI development, trying to predict how we will interact with increasingly intelligent software, it helps to consider those tools that can talk back. AI writing models may only be digital parrots, able to copy form without understanding meaning, but they still create a dialogue with the user. This is something that often seems missing from the introduction of AI systems like facial recognition algorithms (which are imposed upon us) or self-driving cars (where the public becomes the test subject in a dangerous experiment). With AI writing tools, there is the possibility for a conversation. 

---

If you use Gmail or Google Docs, then you’ve probably already encountered this technology. In Google’s products, AI editors lurk in the blank space in front of your cursor, manifesting textual specters that suggest how to finish a sentence or reply to an email. Often, their prompts are just simple platitudes — ”Thanks!”, “Great idea!”, “Let’s talk next week!” — but sometimes these tools seem to be taking a stronger editorial line, pushing your response in a certain direction. Such suggestions are intended to be helpful, of course, but they seem to provoke annoyance as frequently as gratitude.  

To understand how AI systems learn to generate such suggestions, imagine being given two lists of words. One starts off “eggs, flour, spatula,” and the other goes “paint, crayons, scissors.” If you had to add the items “milk” and “glitter” to these lists, which would you choose and with how much confidence? And what if that word was “brush” instead? Does that belong in the kitchen, where it might apply an egg wash, or is it more firmly located in the world of arts-and-crafts? Quantifying this sort of context is how AI writing tools learn to make their suggestions. They mine vast amounts of text data to create statistical maps of the relationships between words, and use this information to complete what you write. When you start typing, they start predicting which words should come next. 

""Their ability to actually understand language is a topic of hot debate, but their fluency across genres is undeniable""

Features like Gmail’s Smart Reply are only the most obvious example of how these systems — often known as large language models — are working their way into the written world. AI chatbots designed for companionship have become increasingly popular, with some, like Microsoft’s Chinese Xiaoice, attracting tens of millions of users. Choose-your-own-adventure-style text games with AI dungeon masters are attracting users by letting people tell stories collaboratively with computers. And a host of startups offer multipurpose AI text tools that summarize, rephrase, expand, and alter users’ input with varying degrees of competence. They can help you to write fiction or school essays, say their creators, or they might just fill the web with endless spam.

The ability of the underlying software to actually understand language is a topic of hot debate. (One that tends to arrive, time and time again, at the same question: what do we mean by “understand” anyway?). But their fluency across genres is undeniable. For those enamored with this technology, scale is key to their success. It’s by making these models and their training data bigger and bigger that they’ve been able to improve so quickly. Take, for example, the training data used to create GPT-3. The exact size of the input is difficult to calculate, but one estimate suggests that the entirety of Wikipedia in English (3.9 billion words and more than 6 million articles) makes up only 0.6 percent of the total. 

Relying on scale to build these systems has benefits and drawbacks. From an engineering perspective, it allows for fast improvements in quality: just add more data and compute to reap fast rewards. The size of large language models is generally measured in their number of connections, or parameters, and by this metric, these systems have increased in complexity extremely quickly. GPT-2, released in 2019, had 1.5 billion parameters, while its 2020 successor, GPT-3, had more than 100 times that — some 175 billion parameters. Earlier this year, Google announced it had trained a language model with 1.6 trillion parameters. 

""Push them on any given topic or stray from the most obvious fields, and they will lie thoughtlessly""

The difference in quality as systems get larger is notable, but it’s unclear how much longer these scaling efforts will reap rewards in quality. Boosters think that sky’s the limit — that these systems will keep on getting smarter and smarter, and that they may even be the first step toward creating a general-purpose artificial intelligence or AGI. But skeptics suggest that the AI field in general is starting to reap diminishing returns as it scales ever up.  

A reliance on scale, though, is inextricably linked to the statistical approach that creates uncertainty in these models’ output. These systems have no centralized store of accepted “truths”; no embodied understanding of “what the world is like for humans” and, hence, no way to distinguish fact from fiction or to exercise common sense. 

Quiz them on simple trivia, like capital cities or the birthdays of US presidents, and they are right most of the time. But to these systems, truth is simply a statistical feature of their training data. They answer questions correctly because the text they’ve been fed has presented them with the correct information with enough frequency. This means that if you push them on any given topic or stray from the most obvious fields, they will lie thoughtlessly, making up quotes, dates, biographical details, and anything else you want to hear. The same probabilistic approach also means they can stumble over common sense questions. Start quizzing them with slightly fantastical queries, and they will confidently assert, for example, that a pencil is heavier than a toaster or that a blade of grass only has one eye. Such answers reveal the gulf between statistical and embodied intelligence. 

[Image: https://cdn.vox-cdn.com/thumbor/r4UjN9px83zd4nLoWkzqITyoBtw=/0x0:1340x1364/1340x1364/filters:focal(670x682:671x683)/cdn.vox-cdn.com/uploads/chorus_asset/file/22963890/VRG_ILLO_4851_10Year_AI_Spot.jpg]

To get a better understanding of these AI language models, I’ve been playing with a variety for the past few weeks; from tools sold to copywriters to flexible, multipurpose systems like GPT-3. The experience has been dizzying. Often, I’m amazed by the fluency, insight, and creativity of these systems. As part of a project for The Verge’s 10-year anniversary, for example, I used GPT-3 to write technopagan spells for a zine, feeding it a prompt (below in bold) which it completed with a four-step ritual (of which I’m showing only the first step):

> Technopaganism is a new sort of magic that blends traditional witchcraft with the power of being online all the time. What follows is a technopagan spell designed to protect your phone from spam and improve the quality of messages you receive. Step 1) Take your cell phone and go outside. Close your eyes, hold the device in front of you, and intone: “I offer you, O Spirit of Technopagan Magic, my eternal and unending electronic connection to the net. And in return I ask you for magick to combine my will with the will of the system — make me impervious to the garbage that flows through my inbox. Make all messages flow together, and I will choose among them what is right for me to see. Grant me the Finger of the Internet, and I will strike at spam, and cast out the spammers back to the dark places where they come from.” 

But other times, I’m stunned by how limited these programs are. Something that’s often overlooked is just how much human curation is needed to shape their output. The text above was not the first response I received from GPT-3, and I had to go through several iterations to generate a response that was both cogent and funny. It helped, of course, that the task I’d set GPT-3 was an imaginative and open-ended one: it played into the program’s strengths (and I think GPT-3’s success in such tasks has led some users and observers to exaggerate the intelligence of these systems). Other times, though, the software produced nonsensical content even within the fanciful framing I’d given it. Another “spell” it generated in response to the same prompt was much less focused, adding fictitious social media handles, tech headlines, and non-existent URLs to the spell’s instructions: 

> Perform a ritual to seal the crown circle into the device. May the gods help us all, the Apple iPhone X reference for is broken! Destroy the holy symbol! —tianong xiong (@tianongxiong) September 13, 2018 To confirm the rumor: Facebook Messenger’s search bar does have a search bar hidden right next to it pic.twitter.com/DghBL5DmhU — Warl Darkh (@dkpt) September 12, 2018 

You can argue that this is just creativity of a different sort, and that of course a proper technopagan spell would include URLs. But it’s also obvious the machine has gone off-piste.

Despite such weaknesses, there’s already talk of AI systems taking over writers’ jobs. Naturally, I wondered if a computer could write articles for The Verge (and not just this one). I played around with different models, inputting opening paragraphs into these systems and asking for story ideas. Here is some more from GPT-3 on large language models: 

> “The human brain is just a really fancy computer,” said Jeff Dean, a Google hardware engineer and AI expert, at a company event in 2016. “It’s a computer made of meat.”
> To understand GPT-3, you first have to know a little about how the brain learns. The brain isn’t born knowing how to speak or understand speech. It must first acquire this ability through exposure to the outside world, which is why children tend to learn language so quickly, and why being raised in a household where a language isn’t spoken presents a major obstacle.
> As neuroscientist Mark Changizi has shown, the process of learning a language is a massive project. “Language is one of the most complex things that brains can do,” he writes, “and it emerges from the brain’s more basic skills, like vision, hearing, and motor control.”
> But how does the brain acquire all this knowledge? The short answer is: via autocomplete.

All these points make sense if you’re not concentrating too hard, but they don’t flow from sentence to sentence. They never follow an argument or build to a conclusion. And again, fabrication is a problem. Both Jeff Dean and Mark Changizi are real people who have been more or less correctly identified (though Dean is now head of AI at Google, and Changizi is a cognitive scientist rather than a neuroscientist). But neither man ever uttered the words that GPT-3 attributed to them, as far as I can tell. Yet despite these problems, there’s also a lot to be impressed by. For example, using “autocomplete” as a metaphor to describe AI language models is both accurate and easy to understand. I’ve done it myself! But is this because it’s simply a common metaphor that others have deployed before? Is it right then to say GPT-3 is “intelligent” to use this phrase or is it just subtly plagiarizing others? (Hell, I ask the same questions about my own writing.)

Where AI language models seem best suited, is creating text that is rote, not bespoke, as with Gmail’s suggested replies. In the case of journalism, automated systems have already been integrated into newsrooms to write “fill in the blanks” stories about earthquakes, sporting events, and the like. And with the rise of large AI language models, the span of content that can be addressed in this way is expanding.

""“Mostly, it’s people in the content marketing industry who have company blogs to fill, who need to create content.”""

Samanyou Garg is the founder of an AI writing startup named Writesonic, and says his service is used mostly by e-commerce firms. “It really helps [with] product descriptions at scale,” says Garg. “Some of the companies who approach us have like 10 million products on their website, and it’s not possible for a human to write that many.” Fabian Langer, founder of a similar firm named AI Writer, tells The Verge that his tools are often used to pad out “SEO farms” — sites that exist purely to catch Google searches and that create revenue by redirecting visitors to ads or affiliates. “Mostly, it’s people in the content marketing industry who have company blogs to fill, who need to create content,” said Langer. “And to be honest, for these [SEO] farms, I do not expect that people really read it. As soon as you get the click, you can show your advertisement, and that’s good enough.”

It’s this sort of writing that AI will take over first, and which I’ve started to think of as “low-attention” text — a description that applies to both the effort needed to create and read it. Low-attention text is not writing that makes huge demands on our intelligence, but is mostly functional, conveying information quickly or simply filling space. It also constitutes a greater portion of the written world than you might think, including not only marketing blogs but work interactions and idle chit-chat. That’s why Gmail and Google Docs are incorporating AI language models’ suggestions: they’re picking low-hanging fruit. 

""The choice to use this filler on a wide scale will have structural effects""

A big question, though, is what effect will these AI writing systems have on human writing and, by extension, our culture? The more I’ve thought about the output of large language models, the more it reminds me of geofoam. This is a building material made from expanded polystyrene that is cheap to produce, easy to handle, and packed into the voids left over by construction projects. It is incredibly useful but somewhat controversial, due to its uncanny appearance as giant polystyrene blocks. To some, geofoam is an environmentally-sound material that fulfills a specific purpose. To others, it’s a horrific symbol of our exploitative relationship with the Earth. Geofoam is made by pumping oil out of the ground, refining it into cheap matter, and stuffing it back into the empty spaces progress leaves behind. Large language models work in a similar way: processing the archaeological strata of digital text into synthetic speech to fill our low-attention voids. 

For those who worry that much of the internet is already “fake” — sustained by botnets, traffic farms, and automatically generated content — this will simply mark the continuation of an existing trend. But just as with geofoam, the choice to use this filler on a wide scale will have structural effects. There is ample evidence, for example, that large language models encode and amplify social biases, producing text that is racist and sexist, or that repeats harmful stereotypes. The corporations in control of these models pay lip service to these problems but don’t think they present serious problems. (Google famously fired two of its AI researchers after they published a detailed paper describing these issues.) And as we offload more of the cognitive burden of writing onto machines, making our low-attention text no-attention text, it seems plausible that we, in turn, will be shaped by the output of these models. Google already uses its AI autocomplete tools to suggest gender-neutral language (replacing “chairman” with “chair,” for example), and regardless of your opinion on the politics of this sort of nudge, it’s worth discussing what the end-point of these systems might be. 

In other words: what happens when AI systems trained on our writing start training us? 

---

Despite the problems and limitations of large language models, they’re already being embraced for many tasks. Google is making language models central to its various search products; Microsoft is using them to build automated coding software, and the popularity of apps like Xiaoice and AI Dungeon suggests that the free-flowing nature of AI writing programs is no hindrance to their adoption. 

Like many other AI systems, large language models have serious limitations when compared with their hype-filled presentations. And some predict this widespread gap between promise and performance means we’re heading into another period of AI disillusionment. As the roboticist Rodney Brooks put it: “just about every successful deployment [of AI] has either one of two expedients: It has a person somewhere in the loop, or the cost of failure, should the system blunder, is very low.” But AI writing tools can, to an extent, avoid these problems: if they make a mistake, no one gets hurt, and their collaborative nature means human curation is often baked in. 

""“A deity that rules communication is an incorporeal linguistic power.”""

What’s interesting is considering how the particular characteristics of these tools can be used to our advantage, showing how we might interact with machine learning systems, not in a purely functional fashion but as something exploratory and collaborative. Perhaps the most interesting single use of large language models to date is a book named Phamarko AI: a text written by artist and coder K Allado-McDowell as an extended dialogue with GPT-3. 

To create Phamarko AI, Allado-McDowell wrote and GPT-3 responded. “I would write into a text field, I would write a prompt, sometimes that would be several paragraphs, sometimes it would be very short, and then I would generate some text from the prompt,” Allado-McDowell told The Verge. “I would edit the output as it was coming out, and if I wasn’t interested in what it was saying, I would cut that part and regenerate, so I compared it to pruning a plant.” 

The resulting text is esoteric and obscure, discussing everything from the roots of language itself to the concept of “hyper-dimensionality.” It is also brilliant and illuminating, showing how writing alongside machines can shape thought and expression. At different points, Allado-McDowell compares the experience of writing using GPT-3 to taking mushrooms and communing with gods. They write: “A deity that rules communication is an incorporeal linguistic power. A modern conception of such might read: a force of language from outside of materiality.” That force, Allado-McDowell suggests, might well be a useful way to think about artificial intelligence. The result of communing with it is a sort of “emergence,” they told me, an experience of “being part of a larger ecosystem than just the individual human or the machine.”

""It’s impossible that this exchange will only be good for us""

This, I think, is why AI writing is so much more exciting than many other applications of artificial intelligence: because it offers the chance for communication and collaboration. The urge to speak to something greater than ourselves is evident in how these programs are being embraced by early adopters. A number of individuals have used GPT-3 to talk to dead loved ones, for example, turning its statistical intelligence into an algorithmic ouija board. Though such experiments also reveal the limitations. In one of these cases, OpenAI shut down a chatbot shaped to resemble a developer’s dead fiancée because the program didn’t conform to the company’s terms of service. That’s another, less promising reality of these systems: the vast majority are owned and operated by corporations with their own interests, and they will shape their programs (and, in turn, their users) as they see fit. 

Despite this, I’m hopeful, or at least curious, about the future of AI writing. It will be a conversation with our machines; one that is diffuse and subtle, taking place across multiple platforms, where AI programs linger on the fringes of language. These programs will be unseen editors to news stories and blog posts, they will suggest comments in emails and documents, and they will be interlocutors that we even talk to directly. It’s impossible that this exchange will only be good for us, and that the deployment of these systems won’t come without problems and challenges. But it will, at least, be a dialogue. 
",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjEvMTEvMDMvdGVjaG5vbG9neS9nb29nbGUtcGVudGFnb24tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UuaHRtbNIBAA?oc=5,"Google Wants to Work With the Pentagon Again, Despite Employee Concerns (Published 2021) - The New York Times",2021-11-05,The New York Times,https://www.nytimes.com,"Three years ago, the company walked away from a Defense Department project after employees objected to it. Now the company is working on a new proposal for the Pentagon.",N/A,"Three years ago, the company walked away from a Defense Department project after employees objected to it. Now the company is working on a new proposal for the Pentagon.","Three years ago, the company walked away from a Defense Department project after employees objected to it. Now the company is working on a new proposal for the Pentagon.",https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/daisuke-wakabayashi', 'name': 'Daisuke Wakabayashi'}, {'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/kate-conger', 'name': 'Kate Conger'}]",en,"Google Wants to Work With the Pentagon Again, Despite Employee Concerns",,,,,Technology,N/A,"AdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTGoogle Wants to Work With the Pentagon Again, Despite Employee ConcernsThree years ago, the company walked away from a Defense Department project after employees objected to it. Now the company is working on a new proposal for the Pentagon.Share full articleRead in appThe contract for the Joint Warfighting Cloud Capability is also being pursued by Microsoft and Amazon. It replaces the JEDI cloud-computing project that the Pentagon killed earlier this year.Credit...Doug Mills/The New York TimesBy Daisuke Wakabayashi and Kate CongerPublished Nov. 3, 2021Updated Nov. 5, 2021Three years after an employee revolt forced Google to abandon work on a Pentagon program that used artificial intelligence, the company is aggressively pursuing a major contract to provide its technology to the military.The company’s plan to land the potentially lucrative contract, known as the Joint Warfighting Cloud Capability, could raise a furor among its outspoken work force and test the resolve of management to resist employee demands.In 2018, thousands of Google employees signed a letter protesting the company’s involvement in Project Maven, a military program that uses artificial intelligence to interpret video images and could be used to refine the targeting of drone strikes. Google management caved and agreed to not renew the contract once it expired.The outcry led Google to create guidelines for the ethical use of artificial intelligence, which prohibit the use of its technology for weapons or surveillance, and hastened a shake-up of its cloud computing business. Now, as Google positions cloud computing as a key part of its future, the bid for the new Pentagon contract could test the boundaries of those A.I. principles, which have set it apart from other tech giants that routinely seek military and intelligence work.AdvertisementSKIP ADVERTISEMENTThe military’s initiative, which aims to modernize the Pentagon’s cloud technology and support the use of artificial intelligence to gain an advantage on the battlefield, is a replacement for a contract with Microsoft that was canceled this summer amid a lengthy legal battle with Amazon. Google did not compete against Microsoft for that contract after the uproar over Project Maven.The Pentagon’s restart of its cloud computing project has given Google a chance to jump back into the bidding, and the company has raced to prepare a proposal to present to Defense officials, according to four people familiar with the matter who were not authorized to speak publicly. In September, Google’s cloud unit made it a priority, declaring an emergency “Code Yellow,” an internal designation of importance that allowed the company to pull engineers off other assignments and focus them on the military project, two of those people said.On Tuesday, the Google cloud unit’s chief executive, Thomas Kurian, met with Charles Q. Brown, Jr., the chief of staff of the Air Force, and other top Pentagon officials to make the case for his company, two people said.Google, in a written statement, said it is “firmly committed to serving our public sector customers” including the Defense Department, and that it “will evaluate any future bid opportunities accordingly.”The contract replaces the now-scrapped Joint Enterprise Defense Infrastructure, or JEDI, the Pentagon cloud computing contract that was estimated to be worth $10 billion over 10 years. The exact size of the new contract is unknown, although it is half the duration and will be awarded to more than one company, not to a single provider like JEDI. AdvertisementSKIP ADVERTISEMENTIt is unclear whether the work, which would provide the Defense Department access to Google’s cloud products, would violate Google’s A.I. principles, although the Defense Department has said the technology is expected to support the military in combat. But Pentagon rules about outside access to sensitive or classified data could prevent Google from seeing exactly how its technology is being used.The Defense Department said it would seek proposals from a limited set of companies that could meet its requirements. “As this is an active acquisition, we cannot provide any additional information related to this effort,” said Russell Goemaere, a spokesman for the department. 






















 Subscriber-only Live Event Can We Find Real Community Online? Thursday, November 18 5 p.m. E.T. | 2 p.m. P.T.  What have the C.E.O. of Reddit and a drag queen learned about building robust communities online? Join them and other special guests at our virtual event to find out.  











After a late start in selling its cloud computing technology to other organizations, Google has struggled to close the gap with Amazon and Microsoft, which have the two biggest cloud computing businesses. To bring in more big customers, Google hired Mr. Kurian, a longtime executive at the software company Oracle, to take over the business in 2018. He has beefed up the size of Google’s sales staff and pushed the company to compete aggressively for new contracts, including military deals.But Google employees have continued to resist some work pursued by the cloud unit. In 2019, they protested the use of artificial intelligence tools for the oil and gas industry. A year later, the company said it would not build custom A.I. software for the extraction of fossil fuels.AdvertisementSKIP ADVERTISEMENTGoogle started working on Project Maven in 2017 and prepared to bid for JEDI. Many Google employees believed Project Maven represented a potentially lethal use of artificial intelligence, and more than 4,000 workers signed a letter demanding that Google withdraw from the project.Soon after, Google announced a set of ethical principles that would govern its use of artificial intelligence. Google would not allow its A.I. to be used for weapons or surveillance, said Sundar Pichai, its chief executive, but would continue to accept military contracts for cybersecurity and search-and-rescue.Several months later, Google said it would not bid on the JEDI contract, although it was unlikely that the company had a shot at landing the deal: The Maven experience had soured the relationship between Google and the military, and Google lacked some of the security certifications needed to handle classified data.Google’s cloud business recently has done other work with the military. Since last year, Google has signed contracts with the U.S. Air Force for using cloud computing for aircraft maintenance and pilot training, as well as a U.S. Navy contract for using artificial intelligence to detect and predict the maintenance needs of facilities and vessels.Some Google workers believed the new contract would not violate the principles, a person familiar with the decision said, because the contract would enable generic uses of its cloud technology and artificial intelligence. The principles specifically state Google will not pursue A.I. that can be applied in “weapons or those that direct injury.”AdvertisementSKIP ADVERTISEMENTLucy Suchman, a professor of anthropology of science and technology at Lancaster University whose research focuses on the use of technology in war, said that with so much money at stake, it is no surprise Google might waver on its commitment.“It demonstrates the fragility of Google’s commitment to staying outside the major merger that’s happening between the D.O.D. and Silicon Valley,” Ms. Suchman said.Google’s efforts come as its employees are already pushing the company to cancel a cloud computing contract with the Israeli military, called Project Nimbus, that provides Google’s services to government entities throughout Israel. In an open letter published last month by The Guardian, Google employees called on their employer to cancel the contract.The Defense Department’s effort to transition to cloud technology has been mired in legal battles. The military operates on outdated computer systems and has spent billions of dollars on modernization. It turned to U.S. internet giants in the hope that the companies could quickly and securely move the Defense Department to the cloud.In 2019, the Defense Department awarded the JEDI contract to Microsoft. Amazon sued to block the contract, claiming that Microsoft did not have the technical capabilities to fulfill the military’s needs and that former President Donald J. Trump had improperly influenced the decision because of animosity toward Jeff Bezos, Amazon’s executive chairman and the owner of The Washington Post.AdvertisementSKIP ADVERTISEMENTIn July, the Defense Department announced that it could no longer wait for the legal fight with Amazon to resolve. It scrapped the JEDI contract and said it would be replaced with the Joint Warfighting Cloud Capability.The Pentagon also noted that Amazon and Microsoft were the only companies that likely had the technology to meet its needs, but said it would conduct market research before ruling out other competitors. The Defense Department said it planned to reach out to Google, Oracle and IBM.But Google executives believe they have the capability to compete for the new contract, and the company expects the Defense Department to tell it whether it will qualify to make a bid in the coming weeks, two people familiar with the matter said.The Defense Department has previously said it hopes to award a contract by April.Daisuke Wakabayashi covers technology from San Francisco, including Google and other companies. Previously, he spent eight years at The Wall Street Journal, first as a foreign correspondent in Japan and then covering technology in San Francisco. More about Daisuke WakabayashiKate Conger is a technology reporter in the San Francisco bureau, where she covers the gig economy and social media. More about Kate CongerA version of this article appears in print on Nov. 4, 2021, Section B, Page 1 of the New York edition with the headline: Google Seeks Defense Deal That Risks A Backlash. Order Reprints | Today’s Paper | SubscribeSee more on: Alphabet Inc., Defense Budget, Microsoft CorporationShare full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/11/02/business/00googlemilitary/merlin_146105364_f4798f37-22a8-4466-bf33-7f075b0f8361-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2021/11/02/business/00googlemilitary/merlin_146105364_f4798f37-22a8-4466-bf33-7f075b0f8361-videoSixteenByNineJumbo1600.jpg', 'caption': 'The contract for the Joint Warfighting Cloud Capability is also being pursued by Microsoft and Amazon. It replaces the JEDI cloud-computing project that the Pentagon killed earlier this year.', 'creditText': 'Doug Mills/The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/11/02/business/00googlemilitary/merlin_146105364_f4798f37-22a8-4466-bf33-7f075b0f8361-superJumbo.jpg', 'height': 1365, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2021/11/02/business/00googlemilitary/merlin_146105364_f4798f37-22a8-4466-bf33-7f075b0f8361-superJumbo.jpg', 'caption': 'The contract for the Joint Warfighting Cloud Capability is also being pursued by Microsoft and Amazon. It replaces the JEDI cloud-computing project that the Pentagon killed earlier this year.', 'creditText': 'Doug Mills/The New York Times'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/11/02/business/00googlemilitary/merlin_146105364_f4798f37-22a8-4466-bf33-7f075b0f8361-mediumSquareAt3X.jpg', 'height': 1800, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2021/11/02/business/00googlemilitary/merlin_146105364_f4798f37-22a8-4466-bf33-7f075b0f8361-mediumSquareAt3X.jpg', 'caption': 'The contract for the Joint Warfighting Cloud Capability is also being pursued by Microsoft and Amazon. It replaces the JEDI cloud-computing project that the Pentagon killed earlier this year.', 'creditText': 'Doug Mills/The New York Times'}]",,,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",https://www.nytimes.com/2021/11/03/technology/google-pentagon-artificial-intelligence.html,2021-11-05T18:01:11.346Z,2021-11-03T18:37:43.000Z,,The New York Times,False,,,,Google Seeks Defense Deal That Risks A Backlash,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,,,
https://news.google.com/rss/articles/CBMihgFodHRwczovL3RoZWNvbnZlcnNhdGlvbi5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaXMtZ2V0dGluZy1iZXR0ZXItYXQtd3JpdGluZy1hbmQtdW5pdmVyc2l0aWVzLXNob3VsZC13b3JyeS1hYm91dC1wbGFnaWFyaXNtLTE2MDQ4MdIBAA?oc=5,"Artificial intelligence is getting better at writing, and universities should worry about plagiarism - The Conversation",2021-11-04,The Conversation,https://theconversation.com,What’s judged to be plagiarism may shift as students rely on more sophisticated forms of technology for writing support.,N/A,What’s judged to be plagiarism may shift as students rely on more sophisticated forms of technology for writing support.,N/A,,,,,,,,,,,N/A,N/A,"






        If a piece of writing was 49 per cent written by AI, with the remaining 51 per cent written by a human, is this original work?
        (Shutterstock)









            Artificial intelligence is getting better at writing, and universities should worry about plagiarism
          




Published: November 4, 2021 10:55am EDT












Michael Mindzak, Brock University, Sarah Elaine Eaton, University of Calgary



Authors





        Michael Mindzak
      


      Assistant Professor, Faculty of Education, Brock University
    





        Sarah Elaine Eaton
      


      Educational Leader in Residence, Academic Integrity and Assistant Professor, University of Calgary
    





Disclosure statement
The authors do not work for, consult, own shares in or receive funding from any company or organization that would benefit from this article, and have disclosed no relevant affiliations beyond their academic appointment.


Partners

University of Calgary provides funding as a founding partner of The Conversation CA.Brock University and University of Calgary provide funding as members of The Conversation CA-FR.Brock University provides funding as a member of The Conversation CA.
View all partners

We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)43


 Facebook360


 LinkedIn


 WhatsApp


 Messenger

 Print


The dramatic rise of online learning during the COVID-19 pandemic has spotlit concerns about the role of technology in exam surveillance — and also in student cheating. 
Some universities have reported more cheating during the pandemic, and such concerns are unfolding in a climate where technologies that allow for the automation of writing continue to improve.
Over the past two years, the ability of artificial intelligence to generate writing has leapt forward significantly, particularly with the development of what’s known as the language generator GPT-3. With this, companies such as Google, Microsoft and NVIDIA can now produce “human-like” text.
AI-generated writing has raised the stakes of how universities and schools will gauge what constitutes academic misconduct, such as plagiarism. As scholars with an interest in academic integrity and the intersections of work, society and educators’ labour, we believe that educators and parents should be, at the very least, paying close attention to these significant developments.
AI & academic writing
The use of technology in academic writing is already widespread. For example, many universities already use text-based plagiarism detectors like Turnitin, while students might use Grammarly, a cloud-based writing assistant. Examples of writing support include automatic text generation, extraction, prediction, mining, form-filling, paraphrasing, translation and transcription.




      Read more:
      In an AI world we need to teach students how to work with robot writers




Advancements in AI technology have led to new tools, products and services being offered to writers to improve content and efficiency. As these improve, soon entire articles or essays might be generated and written entirely by artificial intelligence. In schools, the implications of such developments will undoubtedly shape the future of learning, writing and teaching.



What if an essay was 100 per cent written by AI, but a student did much of the coding themselves?
(Shutterstock)


Misconduct concerns already widespread
Research has revealed that concerns over academic misconduct are already widespread across institutions higher education in Canada and internationally. 
In Canada, there  is little data regarding the rates of misconduct. Research published in 2006 based on data from mostly undergraduate students at 11 higher education institutions found 53 per cent reported having engaged in one or more instances of serious cheating on written work, which was defined as copying material without footnoting, copying material almost word for word, submitting work done by someone else, fabricating or falsifying a bibliography, submitting a paper they either bought or got from someone else for free. 
Academic misconduct is in all likelihood under-reported across Canadian higher education institutions. 
There are different types of violations of academic integrity, including plagiarism, contract cheating (where students hire other people to write their papers) and exam cheating, among others. 
Unfortunately, with technology, students can use their ingenuity and entrepreneurialism to cheat. These concerns are also applicable to faculty members, academics and writers in other fields, bringing new concerns surrounding academic integrity and AI such as:

  If a piece of writing was 49 per cent written by AI, with the remaining 51 per cent written by a human, is this considered original work? 
  What if an essay was 100 per cent written by AI, but a student did some of the coding themselves?
  What qualifies as “AI assistance” as opposed to “academic cheating”?
  Do the same rules apply to students as they would to academics and researchers? 

We are asking these questions in our own research, and we know that in the face of all this, educators will be required to consider how writing can be effectively assessed or evaluated as these technologies improve. 
Augmenting or diminishing integrity?
At the moment, little guidance, policy or oversight is available regarding technology, AI and academic integrity for teachers and educational leaders. 
Over the past year, COVID-19 has pushed more students towards online learning — a sphere where teachers may become less familiar with their own students and thus, potentially, their writing. 
While it remains impossible to predict the future of these technologies and their implications in education, we can attempt to discern some of the larger trends and trajectories that will impact teaching, learning and research. 
Technology & automation in education
A key concern moving forward is the apparent movement towards the increased automation of education where educational technology companies offer commodities such as writing tools as proposed solutions for the various “problems” within education. 
An example of this is automated assessment of student work, such as automated grading of student writing. Numerous commercial products already exist for automated grading, though the ethics of these technologies are yet to be fully explored by scholars and educators.




      Read more:
      Online exam monitoring can invade privacy and erode trust at universities




Overall, the traditional landscape surrounding academic integrity and authorship is being rapidly reshaped by technological developments. Such technological developments also spark concerns about a shift of professional control away from educators and ever-increasing new expectations of digital literacy in precarious working environments.




      Read more:
      Precarious employment in education impacts workers, families and students




These complexities, concerns and questions will require further thought and discussion. Educational stakeholders at all levels will be required to respond and rethink definitions as well as values surrounding plagiarism, originality, academic ethics and academic labour in the very near future.
The authors would like to sincerely thank Ryan Morrison, from George Brown College, who provided significant expertise, advice and assistance with the development of this article.





Artificial intelligence (AI)


Plagiarism


Academic cheating


Academic integrity


Academic writing


GPT-3









",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUGh0dHBzOi8vbmV3cy5jbGVtc29uLmVkdS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jb3VsZC1vbmUtZGF5LWJlLXlvdXItdGVhbW1hdGUv0gEA?oc=5,Artificial intelligence could one day be your teammate - Clemson News,2021-11-01,Clemson News,https://news.clemson.edu,"From driving around town to saving people from collapsed buildings, artificial intelligence holds the promise of making life easier and safer for a wide",N/A,"From driving around town to saving people from collapsed buildings, artificial intelligence holds the promise of making life easier and safer for a wide",N/A,https://schema.org,,,,,,,,,"[{'@type': 'Article', '@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/#article', 'isPartOf': {'@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/'}, 'author': [{'@id': 'https://news.clemson.edu/#/schema/person/37ef8fc6da616d6be1a099ab455c0b91'}], 'headline': 'Artificial intelligence could one day be your teammate', 'datePublished': '2021-11-01T11:59:35+00:00', 'dateModified': '2021-12-02T20:53:32+00:00', 'mainEntityOfPage': {'@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/'}, 'wordCount': 1357, 'publisher': {'@id': 'https://news.clemson.edu/#organization'}, 'image': {'@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/#primaryimage'}, 'thumbnailUrl': 'https://news.clemson.edu/wp-content/uploads/2021/10/Nathan-McNeese_020-scaled.jpg', 'articleSection': ['College of Engineering, Computing and Applied Sciences'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/', 'url': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/', 'name': 'Artificial intelligence could one day be your teammate | Clemson News', 'isPartOf': {'@id': 'https://news.clemson.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/#primaryimage'}, 'image': {'@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/#primaryimage'}, 'thumbnailUrl': 'https://news.clemson.edu/wp-content/uploads/2021/10/Nathan-McNeese_020-scaled.jpg', 'datePublished': '2021-11-01T11:59:35+00:00', 'dateModified': '2021-12-02T20:53:32+00:00', 'description': 'From driving around town to saving people from collapsed buildings, artificial intelligence holds the promise of making life easier and safer for a wide', 'breadcrumb': {'@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/#primaryimage', 'url': 'https://news.clemson.edu/wp-content/uploads/2021/10/Nathan-McNeese_020-scaled.jpg', 'contentUrl': 'https://news.clemson.edu/wp-content/uploads/2021/10/Nathan-McNeese_020-scaled.jpg', 'width': 2560, 'height': 1707}, {'@type': 'BreadcrumbList', '@id': 'https://news.clemson.edu/artificial-intelligence-could-one-day-be-your-teammate/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.clemson.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'All Stories', 'item': 'https://news.clemson.edu/topics/all-stories/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial intelligence could one day be your teammate'}]}, {'@type': 'WebSite', '@id': 'https://news.clemson.edu/#website', 'url': 'https://news.clemson.edu/', 'name': 'Clemson News', 'description': '', 'publisher': {'@id': 'https://news.clemson.edu/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.clemson.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://news.clemson.edu/#organization', 'name': 'Clemson University', 'url': 'https://news.clemson.edu/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.clemson.edu/#/schema/logo/image/', 'url': 'https://news.clemson.edu/wp-content/uploads/2021/01/ClemsonPaw_CMYK__Orange.jpg', 'contentUrl': 'https://news.clemson.edu/wp-content/uploads/2021/01/ClemsonPaw_CMYK__Orange.jpg', 'width': 1201, 'height': 600, 'caption': 'Clemson University'}, 'image': {'@id': 'https://news.clemson.edu/#/schema/logo/image/'}, 'sameAs': ['http://www.facebook.com/clemsonuniv', 'https://x.com/clemsonuniv', 'http://instagram.com/clemsonuniversity', 'http://www.linkedin.com/company/163107?trk=prof-exp-company-name', 'https://www.youtube.com/channel/UC5yf6cfxrcNjFUVVpppS6yw']}, {'@type': 'Person', '@id': 'https://news.clemson.edu/#/schema/person/37ef8fc6da616d6be1a099ab455c0b91', 'name': 'Paul Alongi', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.clemson.edu/#/schema/person/image/548044990c04d180cbb36de3f3dab9cd', 'url': 'https://secure.gravatar.com/avatar/f2a50af5f5edf82ee99a4422d93ae37e?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/f2a50af5f5edf82ee99a4422d93ae37e?s=96&d=mm&r=g', 'caption': 'Paul Alongi'}, 'url': 'https://news.clemson.edu/author/palongi/'}]",N/A,N/A,"


College of Engineering, Computing and Applied SciencesArtificial intelligence could one day be your teammatePaul Alongi 

Share: 

















 


 Download image 

November 1, 2021December 2, 2021 
From driving around town to saving people from collapsed buildings, artificial intelligence holds the promise of making life easier and safer for a wide range of tasks.But AI-powered robots won’t be taking over the world like they do in the movies, at least not anytime soon, said Nathan McNeese, assistant professor and College of Engineering, Computing and Applied Sciences Dean’s Professor of Human-Centered Computing, director of the Team Research and Analytics in Computational Environments Research Group and director of the Clemson Data Lab at Clemson University.
Nathan McNeese has received three grants totaling more than $2.3 million over the past year to fund his work in artificial intelligence.
Rather, artificial intelligence and people will increasingly work together in teams, he said. McNeese, one of the world’s foremost experts on human-AI teams, is helping shape what those teams will look like and how they will work.“What we’re trying to do is leverage what humans do well and what artificial intelligence does well from an accuracy, vigilance and recognition standpoint,” McNeese said. “We know that humans are good at certain things, and technology is good at certain things. We’re trying to take the positives from both of these entities and pair them together in a meaningful way that benefits humans.”McNeese has received three grants totaling more than $2.3 million over the past year to fund his work.The Air Force Office of Scientific Research Trust and Influence program provided grants of $1.3 million and $587,000 for research into the spread of distrust and trust in multiple distributed human-AI teams, and the relationship of trust and ethics in human-AI teams. The Office of Naval Research provided $444,368 to help better understand how to mitigate potential bias in AI through better human interaction and interpretation.




This work is in addition to funding from the National Science Foundation, U.S. Department of Education, and the Army Research Office that have supported the broader goals of better integrating the relationship that humans have with AI. In total, McNeese has been supported with over $14 million of research funding support during his early career.Amy Apon, the C. Tycho Howle of the School of Computing at Clemson, said that McNeese’s interdisciplinary background makes him exceptionally well suited to conduct research in the field. McNeese holds a bachelor’s degree in psychology and a Ph.D. in information sciences and technology, both from The Pennsylvania State University, where his father, Michael McNeese, studied teams as a professor.“Nathan’s background positions him to have a major long-term impact on how humans and artificial intelligence work together in teams,” Apon said. “The federal funding is a continuing catalyst to the work by Dr. McNeese and his team and a testament to the quality of his scholarship in human-AI teaming, as well as the transformative potential of this new technology.”Benefiting humanityResearch into human-AI teams is a nascent field and rapidly evolving. AI and people are typically doing some limited work together at a low level, such as a person calling on Alexa or Siri for help, McNeese said. But the idea of making AI a team member with roles and responsibilities alongside humans is pushing the frontiers of research, and real-world examples are generally still lacking yet currently being researched and developed, he said. “We don’t want to see an abundance of human-AI teaming in the wild yet, until we can study it to inform design and implications for humans,” McNeese said. “We want to envision these scenarios where human-AI teaming is happening and test them out in the lab to see if it’s working, where the limitations are, where the positive benefits are and how we can improve on the dynamic in this context.”The transformation is coming, though, as artificial intelligence becomes more sophisticated, McNeese said. He expects that in his lifetime AI will at low levels be able to understand teamwork concepts, such as communication, coordination, and shared knowledge. But a Terminator-style robot apocalypse isn’t happening anytime soon, McNeese said. AI isn’t anywhere close to becoming a fully autonomous teammate that can exhibit effective teaming, he said. The goal of effective human-AI teaming is what McNeese and his team work towards. Further, what’s most important to McNeese is that AI serves humanity and not the other way around. “I spent a lot of time thinking whether this is a good idea and whether it is something we should be pursuing, and I am confident it can benefit humans if proper considerations are taken regarding fairness, equality, and ethics,” he said. “It’s all about making sure we’re benefitting the human.”Educating people about AIChris Flathmann, a third-year Ph.D. student in McNeese’s research group, said the recommendations the researchers make now could compound as AI develops in the coming decades.“While I don’t think the AI systems we’re building right now are going to be what you see 30 years in the future, I hope that what we’re doing now becomes influential and is an ultimate good for humanity,” Flathmann said. “You’ve got to put in that groundwork now, knowing you’re not going to see those 30-year results soon, but knowing that the groundwork is what makes those results possible.”One of the big challenges in creating human-AI teams is getting people to overcome their perceptions of what AI is and what it means to be on a team with AI, McNeese said. “Humans expect AI’s to act like other humans, and that’s a big, big ask,” McNeese said. “It’s  fair for people to ask, ‘If we are entering this new paradigm of human-AI teaming, shouldn’t it be better than human-human teaming?’ The answer is ‘absolutely yes,’ but getting to that point is going to be a process.”It will be important to educate people about artificial intelligence, its capabilities and how they can integrate with it, McNeese said. “We’re trying to design technology that makes your life easier,” he said. “It takes away things that you don’t want to do so you can focus on the things you want to do and what you as a human are uniquely qualified to do.”McNeese has seven Ph.D. students working alongside him and expects to add one more and a postdoctoral researcher by spring. He said that he prepares his students to be tenure-track faculty members at research-intensive universities, an education that will serve them well whether they opt for academia or industry.One of those Ph.D. students, Beau Schelble, is following in the footsteps of his advisor. He had an interest in team cognition and received a bachelor’s degree in psychology from Clemson before joining McNeese’s research group, where he studies human-AI teams.“Anytime we conduct research in the area and also when we look at what the other researchers are doing in this space, it becomes obvious and clear that this is where the future of work is heading,” Schelble said. “It’s so important that we as researchers get ahead of potential issues and we ensure this transition of human-AI interactions happens as smoothly as possible.”Anand Gramopadhye, dean of Clemson’s College of Engineering, Computing and Applied Sciences, said that McNeese’s work adds to a growing portfolio of AI research at the University.“His unique, multidisciplinary background positions him for maximum impact as he and his students shape the future of how people interact with intelligent systems,” Gramopadhye said. “His grants are well deserved, and I offer him my wholehearted congratulations.”
END

This material is based upon work supported by the Air Force Office of Scientific Research under award numbers FA9550-20-1-0342 and FA9550-21-1-0314, Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s)and do not necessarily reflect the views of the United State Air Force.

Approved for public release, distribution unlimited. 20 Oct 2021. DCN# 43-8664-21. Other requests shall be referred to The Office of Naval Research Code 34.


Want to Discuss?
Get in touch and we will connect you with the author or another expert.
Or email us at news@clemson.edu



 










Your Name

Your Email

Your Message


This form is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.









Related Posts





 



				Nathan McNeese named the new McQueen Quattlebaum Assistant Professor in the School of Computing	        










 



				Nathan McNeese appointed to National Academies of Sciences, Engineering and Medicine’s Board on Human-Systems Integration	        










 



				Early CAREER Development grants awarded to Clemson researchers representing 4 colleges	        










 



				Artificial intelligence at a critical crossroads, says Clemson University’s Nathan McNeese	        











",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vc2xvYW5yZXZpZXcubWl0LmVkdS9wcm9qZWN0cy90aGUtY3VsdHVyYWwtYmVuZWZpdHMtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tdGhlLWVudGVycHJpc2Uv0gEA?oc=5,The Cultural Benefits of Artificial Intelligence in the Enterprise - MIT Sloan Management Review,2021-11-02,MIT Sloan Management Review,https://sloanreview.mit.edu,"New research points to a strong, multidimensional link between AI use and improvements in organizational culture.",N/A,"New research points to a strong, multidimensional link between AI use and improvements in organizational culture.","New research points to a strong, multidimensional link between AI use and improvements in organizational culture.
",,,,,,,,,,,N/A,N/A,"

































































































The Cultural Benefits of Artificial Intelligence in the Enterprise
Findings from the 2021 Artificial Intelligence and Business Strategy Global Executive Study and Research Project








November 02, 2021


by: Sam Ransbotham, François Candelon, David Kiron, Burt LaFountain, and Shervin Khodabandeh


The 2021 MIT SMR-BCG report identifies a wide range of AI-related cultural benefits at both the team and organizational levels. Whether it’s reconsidering business assumptions or empowering teams, managing the dynamics across culture, AI use, and organizational effectiveness is critical to increasing AI’s value to an organization. This report offers a detailed analysis of a dynamic between culture, AI use, and organizational effectiveness.














The benefits of artificial intelligence go well beyond improved efficiency and decision-making. AI can also improve organizational effectiveness and strengthen teams and enterprise cultures.
Artificial intelligence can generate cultural as well as financial benefits for organizations. With AI systems in place, teams can perform tasks with more pride and confidence and collaborate more effectively: They can actually get stronger. These cultural benefits can penetrate the foundation of business operations, improving assumptions that drive organizational behaviors and ensuring the pursuit of smarter goals.
When conducting our research, we heard story after story from executives familiar with AI implementations in their organizations. The overarching message was clear and backed up by survey data: Business culture affects AI deployments, and AI deployments affect business culture.

The research and analysis for this report was conducted under the direction of the authors as part of an MIT Sloan Management Review research initiative in collaboration with and sponsored by Boston Consulting Group.

This MIT SMR-BCG report — based on a global survey of 2,197 managers and interviews with 18 executives — identifies a wide range of AI-related cultural benefits at both the team and organizational levels. Among survey respondents with AI implementations that improved efficiency and decision-making, for example, more than 75% also saw improvements in team morale, collaboration, and collective learning. Culture change from using AI transcends the legitimate, but myopic, promise that AI will liberate workers from drudgery.
These cultural changes are more than a side benefit. AI-related cultural and financial benefits build on each other. Survey respondents who saw significant financial benefits from their AI initiatives were 10 times more likely to change how they measure success than those who saw no such benefits. In some cases, AI helped leaders identify new performance drivers, which led to new assumptions, objectives, measures, and patterns of behavior, along with new areas of accountability. AI also helped these organizations realign behaviors and become more competitive.
Building a culture that supports innovation with AI has an effect on competitiveness. Our research found that respondents who use AI primarily to explore new ways of creating value are far more likely to improve their ability to compete with AI than those who use AI primarily to improve existing processes. Respondents who said they use AI primarily to explore were 2.7





About the Authors
Sam Ransbotham is a professor in the information systems department at the Carroll School of Management at Boston College, as well as guest editor for MIT Sloan Management Review’s Artificial Intelligence and Business Strategy Big Ideas initiative.
François Candelon is a senior partner and managing director at BCG and the global director of the BCG Henderson Institute. He can be contacted at candelon.francois@bcg.com.
David Kiron is the editorial director of MIT Sloan Management Review and is program lead for its Future of the Workforce and Artificial Intelligence and Business Strategy projects. He can be contacted at dkiron@mit.edu.
Shervin Khodabandeh is a senior partner and managing director at BCG and the coleader of BCG GAMMA (BCG’s AI practice) in North America. He can be contacted at shervin@bcg.com.
Burt LaFountain is a partner and managing director at BCG and a core member of BCG GAMMA. He can be reached at lafountain.burt@bcg.com.

Special Contributors
Michael Chu, Matthieu Gombeaud, Su Min Ha, Allison Ryder, and Barbara Spindel

Contributors
Sylvain Duranton, Todd Fitz, Carolyn Ann Geason-Beissel, Michele Lee DeFilippo, Janet Parkinson, Martin Reeves, Lauren Rosano, Lu Sun, and Rachel Zhai

Acknowledgments
We thank each of the following individuals, who were interviewed for this report:
Amy Adams, senior director of global CRM and martech strategy, McDonald’s
Pierre-Yves Calloc’h, chief digital officer, Pernod Ricard
Chris Couch, senior vice president and CTO, Cooper Standard
David Galinsky, senior director, customer data and analytics strategy, McDonald’s
Anju Gupta, vice president of data science and analytics, Northwestern Mutual
Douglas Hamilton, associate vice president and head of AI research, Nasdaq
Dave Johnson, chief data and artificial intelligence officer, Moderna
Slawek Kierner, senior vice president, enterprise data and analytics, Humana
Colin Lenaghan, global senior vice president, net revenue management, PepsiCo
Paul Pallath, global technology head of data, analytics, and AI, Levi Strauss & Co.
Sidney Madison Prescott, global head of intelligent automation, Spotify
Elizabeth Renieris, founding director, Notre Dame-IBM Technology Ethics Lab
Amit Shah, president, 1-800-Flowers
Sander Stomph, former head of operational excellence, KLM
JoAnn Stonier, chief data officer, Mastercard
Radha Subramanyam, president and chief research and analytics officer, CBS Corp.
Nathalie Wright, group digital and IT director, Nordic region general manager, Rexel
Arti Zeighami, former chief data and analytics officer, H&M Group

To cite this report, please use:
S. Ransbotham, F. Candelon, D. Kiron, B. LaFountain, and S. Khodabandeh, “The Cultural Benefits of Artificial Intelligence in the Enterprise,” MIT Sloan Management Review and Boston Consulting Group, November 2021.

MIT Sloan Management Review
At MIT Sloan Management Review (MIT SMR) we explore how leadership and management are transforming in a disruptive world. We help thoughtful leaders capture the exciting opportunities — and face down the challenges — created as technological, societal, and environmental forces reshape how organizations operate, compete, and create value.
MIT Sloan Management Review Big Ideas
MIT Sloan Management Review’s Big Ideas Initiatives develop innovative, original research on the issues transforming our fast-changing business environment. We conduct global surveys and in-depth interviews with front-line leaders working at a range of companies, from Silicon Valley startups to multinational organizations, to deepen our understanding of changing paradigms and their influence on how people work and lead.
Boston Consulting Group
Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we work closely with clients to embrace a transformational approach aimed at benefiting all stakeholders — empowering organizations to grow, build sustainable competitive advantage, and drive positive societal impact.
Our diverse, global teams bring deep industry and functional expertise and a range of perspectives that question the status quo and spark change. BCG delivers solutions through leading-edge management consulting, technology and design, and corporate and digital ventures. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, fueled by the goal of helping our clients thrive and enabling them to make the world a better place.
BCG Henderson Institute
The BCG Henderson Institute is Boston Consulting Group’s strategy think tank, dedicated to exploring and developing valuable new insights from business, technology, science, and economics by embracing the powerful technology of ideas. The Institute engages leaders in provocative discussion and experimentation to expand the boundaries of business theory and practice and to translate innovative ideas from within and beyond business. For more ideas and inspiration from the Institute, please visit bcghendersoninstitute.com.
BCG GAMMA
BCG GAMMA is BCG’s global team dedicated to applying artificial intelligence and advanced analytics to critical business problems at leading companies and organizations. The team includes more than 1,500 data scientists and engineers who utilize AI and advanced analytics (e.g., machine learning, deep learning, optimization, simulation, natural language and image analytics, etc.) to build solutions that transform business performance. BCG GAMMA’s approach builds value and competitive advantage at the intersection of data science, technology, people, business processes, and ways of working. For more information, please visit our webpage.



References (8)

1. E.H. Schein, “Organizational Culture,” working paper 2088-88, MIT Sloan School of Management, Cambridge, Massachusetts, December 1988.
2. Our assessment of “significant financial benefits” uses a threshold that varies based on an organization’s size. For details about this measurement, see S. Ransbotham, S. Khodabandeh, D. Kiron, et al., “Expanding AI’s Impact With Organizational Learning,” MIT Sloan Management Review, Oct. 19, 2020, https://sloanreview.mit.edu.
3. M.D. Watkins, “What Is Organizational Culture? And Why Should We Care?” Harvard Business Review, May 15, 2013, https://hbr.org; and Schein, “Organizational Culture.”
4. Ransbotham et al., “Expanding AI’s Impact.”
5. Schein, “Organizational Culture.”
i. Schein, “Organizational Culture.”
ii. J. Martin, “Organizational Culture: Mapping the Terrain” (Thousand Oaks, California: Sage Publications, 2002).
iii. Schein, “Organizational Culture.” 
Show All References

Tags: 

Artificial Intelligence
Metrics
Value Creation



Reprint #: 
63270


More Like This
           How AI Skews Our Sense of Responsibility                Strategic Alignment With AI and Smart KPIs                Building Connections Through Open Research: Meta’s Joelle Pineau              MIT SMR Connections | Webinar: AI Unleashed: Tackle Data Management Hurdles for Success     




Add a comment Cancel replyYou must sign in to post a comment.First time here? Sign up for a free account: Comment on articles and get access to many more articles. 

             Comment (1)        
















 
HERNAN HERRERA

June 07, 2023


It would be interesting to know if the mentioned benefits of AI use are not the same than those of, in its time, a CRM, or other technology or operational model like Design Thinking.
After a good implementation/adoption process, it is possible.



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiNGh0dHBzOi8va2VvdWdoLm5kLmVkdS9haS1hbmQtdGhlLWZ1dHVyZS1vZi1sYWJvci1kZC_SAQA?oc=5,AI and the future of labor - Keough School - University of Notre Dame - Keough School of Global Affairs,2021-11-02,Keough School of Global Affairs,https://keough.nd.edu,N/A,N/A,"A wave of new automation technologies, including artificial intelligence and robotics, have prompted concern about their substantial and potentially negative impact on jobs and workers […]",N/A,https://schema.org,,,,,,,,,"[{'@type': 'Article', '@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/#article', 'isPartOf': {'@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/'}, 'author': {'name': 'Sebastian Muñoz Dispa', '@id': 'https://keough.nd.edu/#/schema/person/ef9683950e8ea1dd001cda299b8a6c54'}, 'headline': 'AI and the future of labor', 'datePublished': '2021-11-02T18:29:56+00:00', 'dateModified': '2022-07-01T13:33:28+00:00', 'mainEntityOfPage': {'@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/'}, 'wordCount': 1503, 'publisher': {'@id': 'https://keough.nd.edu/#organization'}, 'image': {'@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/#primaryimage'}, 'thumbnailUrl': 'https://keough.nd.edu/wp-content/uploads/2021/11/Lee-DD.jpg', 'articleSection': ['Dignity &amp; Development'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/', 'url': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/', 'name': 'AI and the future of labor - Keough School - University of Notre Dame', 'isPartOf': {'@id': 'https://keough.nd.edu/#website'}, 'primaryImageOfPage': {'@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/#primaryimage'}, 'image': {'@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/#primaryimage'}, 'thumbnailUrl': 'https://keough.nd.edu/wp-content/uploads/2021/11/Lee-DD.jpg', 'datePublished': '2021-11-02T18:29:56+00:00', 'dateModified': '2022-07-01T13:33:28+00:00', 'breadcrumb': {'@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://keough.nd.edu/ai-and-the-future-of-labor-dd/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/#primaryimage', 'url': 'https://keough.nd.edu/wp-content/uploads/2021/11/Lee-DD.jpg', 'contentUrl': 'https://keough.nd.edu/wp-content/uploads/2021/11/Lee-DD.jpg', 'width': 1914, 'height': 1329}, {'@type': 'BreadcrumbList', '@id': 'https://keough.nd.edu/ai-and-the-future-of-labor-dd/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://keough.nd.edu/'}, {'@type': 'ListItem', 'position': 2, 'name': 'AI and the future of labor'}]}, {'@type': 'WebSite', '@id': 'https://keough.nd.edu/#website', 'url': 'https://keough.nd.edu/', 'name': 'Keough School - University of Notre Dame', 'description': 'Keough School of Global Affairs', 'publisher': {'@id': 'https://keough.nd.edu/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://keough.nd.edu/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://keough.nd.edu/#organization', 'name': 'Keough School of Global Affairs at Notre Dame University', 'url': 'https://keough.nd.edu/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://keough.nd.edu/#/schema/logo/image/', 'url': 'https://keough.nd.edu/wp-content/uploads/2016/05/KS_MAST_RGB_2.0.png', 'contentUrl': 'https://keough.nd.edu/wp-content/uploads/2016/05/KS_MAST_RGB_2.0.png', 'width': 512, 'height': 142, 'caption': 'Keough School of Global Affairs at Notre Dame University'}, 'image': {'@id': 'https://keough.nd.edu/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/KeoughSchool', 'https://x.com/KeoughGlobalND', 'https://www.youtube.com/channel/UCMB6UhujDA9WydVbwq3NCOQ']}, {'@type': 'Person', '@id': 'https://keough.nd.edu/#/schema/person/ef9683950e8ea1dd001cda299b8a6c54', 'name': 'Sebastian Muñoz Dispa', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://keough.nd.edu/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/92c6ba90d0cac2c02500379f1bd33867?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/92c6ba90d0cac2c02500379f1bd33867?s=96&d=mm&r=g', 'caption': 'Sebastian Muñoz Dispa'}, 'url': 'https://keough.nd.edu/author/smunozdi/'}]",N/A,N/A,"




 


Business & Economics
Culture & Society


Share this on Twitter

Share this on Facebook
Share this on LinkedIn








Dignity & Development
AI and the future of labor

November 2, 2021  Yong Suk Lee 














A wave of new automation technologies, including artificial intelligence and robotics, have prompted concern about their substantial and potentially negative impact on jobs and workers in the near future. While technology can increase worker productivity and create jobs, it can also replace workers, especially when the technology explicitly aims to replace human jobs and tasks. News and popular media often portray a doomsday scenario where robots and artificial intelligence (AI) not only take over human jobs but also manage—or even control—human labor. 
Anxiety about machines replacing humans is not new. With every new major technological breakthrough, from steam-powered machines in the nineteenth century to industrial robots and then computers in the twentieth, people have expressed fear that technology would take over their jobs. With each major technological innovation, however, economic growth continued and jobs were created. With the invention of automobiles, stagecoach drivers disappeared but expansive automotive, transportation, and logistics industries emerged, employing millions of people in the US alone. 
If history serves as our guide, then, our concern that robots and AI will take over human jobs seems unfounded. Masters of their creations, humans can be expected to harness the new technologies, create new job opportunities and stimulate economic growth. It is therefore reasonable to assume that the same pattern will prevail with AI and advanced robotics. 
Right?
Perhaps. But this time around could be different. There are two reasons to be cautious—one related to the technology itself and the other to underlying economic forces at play.

AI algorithms are expanding into cognitive tasks traditionally thought to be the unique domain of skilled white collar professionals.

Both robotics and artificial intelligence have existed for decades. But only recently have computing power, data, algorithms, and automation technologies been able to perform both physical (robots) and predictive (AI) tasks with such complexity and accuracy—often outperforming humans. Robots today move around warehouses and shelve and lift heavy items. AI algorithms not only predict which items will be in demand by consumers, but order them and keep them in stock. Moreover, AI algorithms are expanding into cognitive tasks traditionally thought to be the unique domain of skilled white collar professionals, such as disease diagnosis from X-ray scans and sifting through hordes of financial statements to identify accounting anomalies. If a machine can learn from its surrounding environment, make judgement calls and perform physical tasks, that machine does seem to present new threats to human labor. Teslas are already doing this with autonomous driving. The machine identifies the best route, processes the surrounding environment to make turns and stops, and obviates the need for human driving. We probably will see more machines like Tesla in the factory and in the office. 
Another distinctive aspect at our current moment is the declining share of economic output that is attributed to labor or, put differently, the declining share of total wages, bonuses, and benefits going to workers. Labor’s share of the US national income has been decreasing for the past three decades, while income attributed to owning capital (e.g., capital gains, dividends, etc.) has been increasing. Furthermore, this declining labor share is going to a smaller number of high wage earners. In short, labor’s economic pie has been shrinking relative to the overall economy and a smaller number of people are enjoying a larger share of that shrinking pie.  There are multiple hypotheses for the declining power of labor to this point, but when AI and robotics replace tasks performed by humans, there is little doubt that human labor’s share of the economy will shrink at a faster rate.
What the research shows
How realistic are such concerns? The future is unknown, so there’s no definitive answer, but research can help us make informed predictions. From 1990 to 2007, the data shows, the adoption of industrial robots replaced jobs in the US economy. My own research finds that the negative effect of robots on jobs changes over time; in fact, in recent years, robot adoption led to the growth of local jobs, mainly driven by the automotive and related industries. The key to understanding new automation technology’s impact on labor is whether new task creation will be sufficient to offset the displacement caused by automation.
One industry in Elkhart, Indiana offers insight into this question. The RV industry is booming, and firms are expanding and desperately seeking skilled workers, even as automation increases. The adoption of automation technologies has made certain human tasks obsolete but also created demand for new tasks related to human-machine collaboration and machine software management that traditionally were not part of the manufacturing sector. However, it remains to be seen whether workers will benefit from the new demand, and which workers might benefit, given the fact that human-machine collaboration requires more technical and managerial skills. 

Workers who have the skills to interact productively with AI applications in their workplace will be rewarded in the labor market.

Given that AI adoption is relatively new and data on the adoption and usage of AI is still sparse, the research on the potential impact of AI or machine learning on labor is still nascent. Researchers have examined the task contents of occupations, however, and have made predictions as to which tasks are replaceable by machine learning algorithms. They have found that almost all occupations have some tasks that can be replaced by machine learning. At the same time, few, if any, occupations are expected to be replaced fully by machine learning. These findings suggest that workers in an increasing number of occupations will interact with AI applications as part of their jobs, whether the person is working in a factory, office, retail store, hospital, or law firm. 
Interacting productively with AI
The greater change driven by AI is less about which occupations will disappear and appear, but rather how the task contents of any given occupation will change when AI is introduced in the workplace, and what it means for workers of varying skills in different occupations.
For example, in the banking sector, one of the leading sectors of AI adoption, I find that there are relatively more job postings for knowledge workers, such as technicians, analysts, and managers, than for front-end jobs such as tellers and loan officers. When banks adopt AI, the demand for technical skills, computer skills, and risk assessment skills in all banking-related jobs increases.
In short, workers who have the skill sets to interact productively with AI applications in their workplace will be rewarded in the labor market. Working with AI algorithms and performing associated tasks may be an insurmountable burden to those with less training and education. This raises concern that the application of AI could exacerbate inequality in the workforce, with technologically sophisticated workers quickly leaving less skilled co-workers behind. 
That certain industries and workers will suffer when there is a negative trade or technology shock is not in itself new, and there are existing government programs that assist with job training for workers displaced by these shocks. But the scale at which AI could disrupt the workforce—both blue-collar and white-collar workers in multiple industries—warrants a reexamination of the policy responses to AI’s broader influence on labor.
Fortunately, we are still in the early stages of incorporating AI into work. At this point AI is merely an algorithm that firms choose to deploy for specific objectives. I have found that managers, when reminded of the potential for AI related regulation, tend to delay adoption of AI and consider the ethical consequences of AI. Specifically, they increase their awareness of workplace safety, data privacy, and the need for transparency. 

Integral human development demands that workers not be reduced to their functions.

Now is the right time to analyze the various issues that might arise when adopting AI and new automation technologies. We must establish analytical frameworks to determine more precisely how AI adoption might affect workers and their tasks in the workplace. Not least, we must create nuanced and compassionate policies to govern the recruiting and retraining of workers that will be essential as firms attempt to preserve and enhance the crucial human element of work. 
Integral human development demands that workers not be reduced to their functions. When their functions become obsolete, they become disposable—an unacceptable outcome. Educating and training current workers on the job, as well as preparing students to interact productively with the new technologies when they enter the workforce, seems a moral as well as economic imperative as we stride into the brave new world of Artificial Intelligence and robotics.

Yong Suk Lee is assistant professor of technology, economy, and global affairs in the Keough School of Global Affairs at the University of Notre Dame.
This article is part of a series of blog posts published by the Keough School of Global Affairs. Dignity and Development provides in-depth analysis of global challenges through the lens of integral human development.
Photo: “Tesla Robot Dance” by jurvetson is licensed under CC BY 2.0.

CONNECT WITH THE KEOUGH SCHOOL










Subscribe to Dignity and Development
Complete this form to receive a digest with new Insights.

First Name



Last Name



Email (required)








 



",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vd3d3Lm5ld3N3aXNlLmNvbS9hcnRpY2xlcy9kYXRhLXNjaWVudGlzdC1kaXNjdXNzZXMtam9iLW91dGxvb2staW4tZXJhLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gFmaHR0cHM6Ly9tLm5ld3N3aXNlLmNvbS9hcnRpY2xlcy9kYXRhLXNjaWVudGlzdC1kaXNjdXNzZXMtam9iLW91dGxvb2staW4tZXJhLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl?oc=5,Data Scientist Discusses Job Outlook in Era of Art | Newswise - Newswise,2021-11-04,Newswise,https://www.newswise.com,"Recent worker shortages and higher labor costs have resulted in more automated jobs, including service and professional jobs economists once considered safe. Pr",['Artificial Intelligence;Robots;Robots taking jobs;Job losses;Economic forecast after COVID'],"Recent worker shortages and higher labor costs have resulted in more automated jobs, including service and professional jobs economists once considered saf",N/A,https://schema.org,NewsArticle,https://www.newswise.com/articles/data-scientist-discusses-job-outlook-in-era-of-artificial-intelligence,"{'@type': 'Organization', 'name': 'SUNY Buffalo State University', 'identifier': '6737', 'url': 'https://www.newswise.com/institutions/newsroom/6737', 'description': 'Buffalo State—the largest comprehensive college in the State University of New York (SUNY) system—provides 9,000 students each year with diverse and transformational opportunities to believe in themselves, be inspired with knowledge, and achieve their goals. Buffalo State is ranked in the top-50 nationally by CollegeNET’s Social Mobility Index (SMI), which measures how effectively institutions enroll economically-disadvantaged students and graduate them into well-paying jobs. The college offers a distinctive urban-engaged curriculum across more than 75 undergraduate majors and 60 graduate programs in the arts, education, sciences, and professional studies. Since 1871, Buffalo State has played a leading role in the resurgence of New York State’s second-largest city, generating more than $680 million in total economic impact each year as an anchor institution for the City of Buffalo.', 'image': {'@type': 'ImageObject', 'url': 'https://www.newswise.com/legacy/image.php?image=/images/institutions/logos/webcrest-V-black.jpg'}}",,Data Scientist Discusses Job Outlook in Era of Art | Newswise,,,,,N/A,N/A,N/A,"{'@type': 'ImageObject', 'url': 'https://www.newswise.com/legacy/image.php?image=', 'width': 1200, 'height': 600}",,,"{'@type': 'Organization', 'name': 'Newswise', 'logo': {'@type': 'ImageObject', 'url': 'https://www.newswise.com/assets/new/img/Newswise-Logo.png'}}","{'@type': 'WebPage', '@id': 'https://www.newswise.com/articles/data-scientist-discusses-job-outlook-in-era-of-artificial-intelligence'}",2021-11-04,2021-11-04,,,,,https://www.newswise.com/legacy/image.php?image=,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS90aGUtZnJhbmtlbnN0ZWluLWh5cG90aGVzaXMtZjA3NWY4MDllYzli0gEA?oc=5,The Frankenstein Hypothesis. Confronting the Implications &… | by Ted Gross - Towards Data Science,2021-11-04,Towards Data Science,https://towardsdatascience.com,"My work as a Futurist within AI is usually published in academic journals, and “The Frankenstein Hypothesis” is written in an academic fashion as well. For those looking to understand the overall…",N/A,Confronting the Implications & Ramifications of Artificial Intelligence,Confronting the Implications & Ramifications of Artificial Intelligence,http://schema.org,NewsArticle,https://towardsdatascience.com/the-frankenstein-hypothesis-f075f809ec9b,"{'@type': 'Person', 'name': 'Ted Gross', 'url': 'https://tedwgross.medium.com'}",,The Frankenstein Hypothesis - Towards Data Science,,,,,N/A,N/A,"The Frankenstein HypothesisConfronting the implications and ramifications of artificial intelligenceTed Gross·FollowPublished inTowards Data Science·37 min read·Nov 5, 202144ListenSharePhoto from Unsplash.comPreface:My work as a Futurist within AI is usually published in academic journals, and “The Frankenstein Hypothesis” is written in an academic fashion as well. For those looking to understand the overall context of the progression of AI and some of the ethical/moral dilemmas which will face humankind in the near future, I do hope this piece will serve as an informative introduction.“The Frankenstein Hypothesis” serves as the background for a more extensive work published in October 2021 (‘Applied Marketing Analytics’ Volume 7 #2 a journal of Henry Stewart Publications) presenting the theory of “Emanating Confluence” dealing with the progression of Artificial Intelligence (AI) — from Chaos Theory to Complexity Theory to Emergence and then the Technological Singularity. (If interested, you are welcome to message me here in Medium or in LinkedIn for a complimentary PDF copy of “Emanating Confluence”).Abstract:Artificial Intelligence (AI) has penetrated all areas of society. Creating the correct constructs and algorithms within AI has become the ‘holy grail,’ guiding our decisions and rapidly overtaking every aspect of our lives.How do we define ‘thought?’ At what point is ‘intelligence’ presumed? When do we consider something ‘conscious?’ Is it possible to acquire consciousness?The paradox of the term ‘Artificial Intelligence’ seems absurd. An undisputed classification of ‘intelligence’ does not exist. ‘Thought-Thinking’ similarly does not have a universally accepted definition. How, then, without definitively characterizing these terms, are we expected to comprehend what AI means? When and where do we apply our technological capacities to achieve AI?As AI grows in potential, ‘consciousness’ becomes a crucial designation. How to define if an entity is conscious has become paramount. We are swiftly reaching a point where society will be forced to decide when and where thinking, intelligence, and possibly consciousness are fundamental components of non-human objects.For thousands of years, philosophers have attempted to define the ontological problem of ‘existence’ and ‘being,’ which is intrinsically connected to ‘thought,’ ‘intelligence,’ and ‘consciousness.’ However, the ‘thought-intelligence-consciousness’ quandary is not only ontological in composition but also lies at the heart of where AI is progressing.“The Frankenstein Hypothesis: Confronting the Implications & Ramifications of Artificial Intelligence” explores the dilemmas posed by AI. How is AI Evolving? What does the term ‘Artificial Intelligence’ imply in an age where we can no longer control the exponential growth of AI? This article examines these fundamental questions offering an analysis of AI development, leading to humankind’s ultimate necessity to acknowledge and cope with the potential monster/benefactor looming in the background.Intelligence, Thinking & Consciousness“I propose to consider the question, ‘Can machines think?’”¹With that opening statement, in his paper “Computing Machinery and Intelligence” delivered while working at the University of Manchester,² Alan Turing³ officially began the quest to achieve artificial intelligence (AI) without ever using the term ‘artificial intelligence.’ Though Turing immediately reconstructed his argument, due to the impossibility of defining the two words “machine” and “think,” the question remains in all its potency. We are still struggling with defining two terms: ‘intelligence’ and ‘thought.’ What do they mean? What truly defines intelligence? What is the primary classification of thinking? That three-word question “Can machines think?” (redefined as it was) forever changed the destiny of technological advancement.As in many great leaps of genius, one impetus for Turing’s thought process was due to a postulation made a century earlier by Lady Ada Lovelace⁴. Lady Lovelace is considered the original pioneer of computer programming in that she is credited with creating the world’s first computer algorithm.⁵Lady Lovelace was working on the “Analytical Engine,” a theoretical machine at the time, proposed by her mentor, Charles Babbage⁶, which would be capable of solving equations, precisely calculating a sequence of Bernoulli numbers. She wrote in her Notes on the proposed machine:The Analytical Engine has no pretensions whatever to originate anything. It can do whatever we know how to order it to perform. It can follow analysis; but it has no power of anticipating any analytical relations or truths.⁷Turing was convinced this statement, which he termed “Lady Lovelace’s Objection,”⁸ was wrong and set out to prove so.It would be amiss at this point to ignore the cliché “truth is stranger than fiction.” Lady Lovelace’s father, whom she was estranged from for her lifetime, was Lord Byron⁹. During a rainy summer in 1816, Lord Byron spent the summer with Mary Shelley¹⁰ in Geneva. Due to the incessant rain, Lord Byron and Mary Shelley began telling ghost and vampire stories, and thus the novel “Frankenstein” was first conceived, based on a whim of fate because of the weather.¹¹ A few years later, Lord Byron’s daughter, Lady Lovelace, supplied part of the original impetus for Alan Turing in her notes on the “Analytical Engine.” The Pandora Box Turing opened in technology has come back to haunt us in the true visage of Frankenstein. It leads one to ponder the nature of coincidence, the fates, karma, God, or whatever path we chose to believe or ignore.Five years after Turing asked his fundamental question, in 1955, “A Proposal for The Dartmouth Summer Research Project on Artificial Intelligence”¹² was delivered. Less than a year later, in 1956, the first actual AI conference began at Dartmouth College.¹³ The term ‘Artificial Intelligence’ is credited to John McCarthy¹⁴, one of the proposal’s original authors.The ethical, philosophical, theological, moral, psychological, scientific, and theoretical constructs profoundly altered by Turing’s question should not be underestimated. AI had arrived, and humankind had no choice but to deal with it. Technology and innovation would not remain stationary.More than seventy years later, one will find the argument about defining ‘thought’ and ‘intelligence’ still raging at full force — even though the term ‘artificial intelligence’ — is now part of our natural lexicon. AI is the buzzword garnering the most attention in any technology discussion. It is considered by many the ‘holy grail,’ covering areas from robotics to decision making to the creation of self-evolving algorithms, which implies the self-evolution of intelligent thinking. (A superb summary of some of these topics can be found in Amy Webb’s “The Big Nine: How the Tech Titans and Their Thinking Machines Could Warp Humanity.”¹⁵)“Cogito Ergo Sum” — “I Think, Therefore I Am”In 1637, the philosopher, René Descartes¹⁶, in his “Discourse on the Method”¹⁷ ¹⁸ and in 1644 in “Principles of Philosophy,” put forward his now-famous philosophical maxim: “Cogito, Ergo Sum” — “I think, therefore I am” (translated into French in 1647¹⁹ — “Je pense, donc je suis”), which has since caused agreement, debate, dissent, and consternation among ethicists and philosophers. Descartes’ statement implies quite simply — if one thinks, then one exists. However, what does ‘existence’ imply? Moreover, if we are compelled to consider the dilemma of existence that Descartes defines as thinking, what implications will develop upon our understanding of life’s structure?Does ‘thought’ (or ‘thinking’) imply intelligence? Furthermore, if so, does thinking and intelligence infer ‘consciousness’? In the era of AI, we cannot afford to be dismissive of such questions nor ignore their implications. Reams of books, journals, and thoughts have been published on this subject, and still, there is no consensus. Just a brief look at Wikipedia will only further complicate matters.Although thinking is an activity of an existential value for humans, there is still no consensus as to how it is adequately defined or understood.Because thought underlies many human actions and interactions, understanding its physical and metaphysical origins and its effects has been a longstanding goal of many academic disciplines including philosophy, linguistics, psychology, neuroscience, artificial intelligence, biology, sociology and cognitive science.Thinking allows humans to make sense of, interpret, represent or model the world they experience, and to make predictions about that world. It is therefore helpful to an organism with needs, objectives, and desires as it makes plans or otherwise attempts to accomplish those goals.²⁰It should be clear to anyone involved in AI and its consequences that we are not only at the forefront of technology, but it touches upon every mode of thought, response, and reaction in all sciences and philosophies, which will cause deep rifts and reassessments of numerous preconceived notions.What Is Called Thinking?²¹One of the most peculiar and vexing realms of research attempts to arrive at a concrete definition of ‘thought’ or ‘thinking.’ The above statement quoted from Wikipedia places the dilemma in its proper context: “Although thinking is an activity of an existential value for humans, there is still no consensus as to how it is adequately defined or understood.”²²The Cambridge Dictionary defines ‘thought’ as “the act of thinking about or considering something, an idea or opinion, or a set of ideas about a particular subject”²³ and “thinking” as “the activity of using your mind to consider something.”²⁴ These definitions are an excellent example of circular reasoning, leaving us with no fundamental understanding of what ‘thought’ truly is.Bloom’s taxonomy²⁵, created in the 1950s, attempted to categorize thinking into six primary areas:1. Knowledge2. Comprehension3. Application4. Analysis5. Synthesis6. EvaluationHowever, though Bloom’s taxonomy may define different elements and processes of thinking, ranking them in order of complexity, it does little to explain how we can precisely define the process of ‘thinking.’²⁶Perhaps the most notable of all the books written by the philosopher and phenomenologist Martin Heidegger²⁷ is entitled “What is Called Thinking?” based upon lecture courses he gave during the winter and summer semesters of 1951 and 1952 at the University of Freiburg.²⁸ As he wrote: “Most thought-provoking in our thought-provoking time is that we are still not thinking.”²⁹ The statement is undoubtedly a potent accusation against humankind. Nevertheless, it still does not answer the fundamental question, “What is called thinking?” Heidegger himself was conflicted by the terminology though he does attempt a cogent and fascinating look at the thinking process.We shall never learn what ‘is called’ swimming, for example, or what it ‘calls for,’ by reading a treatise on swimming. Only the leap into the river tells us what is called swimming. The question ‘what is called thinking?’ can never be answered by proposing a definition of the concept thinking, and then diligently explaining what is contained in that definition. In what follows, we shall not think about what thinking is. We remain outside that mere reflection which makes thinking its object.³⁰Without extensive research and a deep dive into phenomenology and existentialism, Heidegger’s definition of thinking seems to be as elusive as ever. We remain with the paradox that states — thinking is, well, thinking or experiencing some indefinable activity and then employing a definitive phrase to explain the experience.The Turing Test & The Chinese RoomWhen Turing first proposed his famous question “Can machines think?” he immediately restructured the question to avoid problematic definitions, especially for the word ‘intelligence,’ as Turing realized there would be an immediate equation between ‘think’ and ‘intelligence.’I propose to consider the question, “Can machines think?” This should begin with definitions of the meaning of the terms “machine” and “think.” The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous, If the meaning of the words “machine” and “think” are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, “Can machines think?” is to be sought in a statistical survey such as a Gallup poll. But this is absurd. Instead of attempting such a definition I shall replace the question by another, which is closely related to it and is expressed in relatively unambiguous words.”³¹Turing called his replacement the “The Imitation Game.” While there is still debate on what Turing was attempting to accomplish, The Imitation Game is one of the most crucial points which led us into the age of Artificial Intelligence. (One can find a thorough description of The Imitation Game in Turing’s original article³² or on Wikipedia³³.) However, even after seventy years, there is a continuous discussion as to whether the “Turing test is not specifically to determine whether a computer is able to fool an interrogator into believing that it is a human, but rather whether a computer could imitate a human.”³⁴However, in Turing’s article, one paragraph turned out to be prophetic, and it leads the reader directly to the heart of our thesis.The original question, “Can machines think?” I believe to be too meaningless to deserve discussion. Nevertheless I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted. I believe further that no useful purpose is served by concealing these beliefs. The popular view that scientists proceed inexorably from well-established fact to well-established fact, never being influenced by any improved conjecture, is quite mistaken. Provided it is made clear which are proved facts and which are conjectures, no harm can result. Conjectures are of great importance since they suggest useful lines of research.³⁵Turing’s prophetic hypothesis, whose importance cannot be underestimated in the age of AI, has been challenged repeatedly. However, the most significant opposition comes from the “Chinese Room Thought Experiment”³⁶ developed by John Searle³⁷ in 1980 (the entire scope of this experiment can be found in Searle’s paper), a different Turing Test implementation. Turing wrote:I do not wish to give the impression that I think there is no mystery about consciousness. There is, for instance, something of a paradox connected with any attempt to localise it. But I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper.³⁸Nevertheless, Searle posed tough questions based on ‘consciousness.’ Indeed, as the Chinese Room developed into a significant debate, Searle became adamant that consciousness was at the core of the whole argument. Therefore, the consequences of the Chinese Room become paramount.The Chinese room argument holds that a digital computer executing a program cannot be shown to have a “mind,” “understanding,” or “consciousness,” regardless of how intelligently or human-like the program may make the computer behave.³⁹Alternatively, as Searle himself says in his abstract:“Could a machine think?” On the argument advanced here only a machine could think, and only very special kinds of machines, namely brains and machines with internal causal powers equivalent to those of brains. And that is why strong AI has little to tell us about thinking, since it is not about machines but about programs, and no program by itself is sufficient for thinking.⁴⁰Imagination & KnowledgeAlbert Einstein expressed just how conflicted pure science can be when speculating upon the future when he stated “Imagination is more important than knowledge. Knowledge is limited. Imagination encircles the world.”⁴¹ Even those grounded in the mathematics of science recognize that virtually nothing would move forward without the use of imagination and a profound gift to envision a different future. Innovation would be a non-entity in such a world.Science fiction often becomes a reality, though it also reveals momentous questions about our central topic on thought and intelligence. For instance, can we place “Frankenstein”⁴² in the realm of thought and consciousness? Mary Shelley⁴³ wrote a ghost story, which would create a whole new writing genre known as “horror.”⁴⁴ It is questionable if she ever contemplated the philosophical questions, debates, and arguments her story would engender. Nevertheless, Frankenstein did express thoughts and emotions, and though made of flesh, it can be argued there is no longer a great divide between the flesh of the monster named Frankenstein and the cold metal of machinery.Science fiction is replete with such incidents. Authors such as Arthur C. Clarke⁴⁵, Isaac Asimov⁴⁶, who first used the term “robotics,”⁴⁷ Frank Herbert in his “Dune” Saga⁴⁸, have often been considered prophets rather than just story-weavers of a dystopian future. Indeed, the Dune Saga is religiously adherent to the law of “Thou shalt not make a machine in the likeness of a human mind.”⁴⁹In the ground-breaking movie by Stanley Kubrick and Arthur C. Clarke, released in 1968, “2001: A Space Odyssey”, we are introduced to “HAL,” a sentient (read “thinking, intelligent and conscious” computer) hell-bent on destruction. Observe that even the name HAL has prophetic connotations. “H” is the letter before “I”; “A” the letter before “B”; “L” the letter before “M” — thus spelling “IBM” which produced the AI machine, “Watson,”⁵⁰ demonstrating natural language capabilities for the first time in 2011 on the television show ‘Jeopardy.’⁵¹ ⁵²Was “2001: A Space Odyssey” a self-fulfilling prophecy, a lucky guess, imagination, coincidence, or just creative movie making? Perhaps only Einstein could offer us an insight into the answer. “…the distinction between past, present and future is only a stubbornly persistent illusion.”⁵³Summoning the Demon — The Perils of Artificial IntelligenceWe are beyond debating the possibility of AI implementation, as it has become a reality and continues to be enhanced and augmented by ever-evolving systems, constructs, and algorithms. We need to face the perils and dangers that AI can one day impose upon our reality. Surprisingly the warnings on the use of AI and its continuous integration into our daily lives come from technology leaders whom, one would at first assume, should be the most fervent proponents of AI.Elon Musk⁵⁴ said of AI back in 2014:I think we should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it’s probably that. So we need to be very careful,” said Musk. “I’m increasingly inclined to think that there should be some regulatory oversight, maybe at the national and international level, just to make sure that we don’t do something very foolish…With artificial intelligence we are summoning the demon. In all those stories where there’s the guy with the pentagram and the holy water, it’s like — yeah, he’s sure he can control the demon. Doesn’t work out…⁵⁵Musk has constantly reiterated this sentiment over the years.AI is the rare case where I think we need to be proactive in regulation instead of reactive. Because I think by the time we are reactive in AI regulation, it’ll be too late,” Musk told the meeting. “AI is a fundamental risk to the existence of human civilisation.⁵⁶Musk is not alone and has very interesting bedfellows in his concerns. Bill Gates, the co-founder of Microsoft,⁵⁷ expressed his worries about the advancement of AI.I am in the camp that is concerned about super intelligence. First the machines will do a lot of jobs for us and not be super intelligent. That should be positive if we manage it well,” Gates wrote. “A few decades after that though the intelligence is strong enough to be a concern. I agree with Elon Musk and some others on this and don’t understand why some people are not concerned.⁵⁸The physicist, Stephen Hawking⁵⁹, also had serious concerns about AI.The development of full artificial intelligence could spell the end of the human race. Once humans develop artificial intelligence, it will take off on its own and redesign itself at an ever-increasing rate. Humans, who are limited by slow biological evolution, couldn’t compete and would be superseded.⁶⁰Yuval Noah Harari⁶¹ has consistently and continuously warned in his recent trio of books on unfettered AI dangers. However, one quote should grab our attention immediately.What will happen to the job market once artificial intelligence outperforms humans in most cognitive tasks? What will be the political impact of a massive new class of economically useless people? What will happen to relationships, families and pension funds when nanotechnology and regenerative medicine turn eighty into the new fifty? What will happen to human society when biotechnology enables us to have designer babies, and to open unprecedented gaps between rich and poor?⁶²Perhaps the direst warnings come from the New York Times bestseller, “Superintelligence: Paths, Dangers, Strategies,”⁶³ written by philosopher Nick Bostrom.⁶⁴ He argues that ‘superintelligence’ is marked when machine brains surpass human brains’ capacity and could become the dominant lifeform.This is quite possibly the most important and most daunting challenge humanity has ever faced. And — whether we succeed or fail — it is probably the last challenge we will ever face.⁶⁵Since a machine can improve its capabilities faster than a human, this would cause an existential cataclysm. Elon Musk, Bill Gates, and many others endorsed this mode of thinking, being very wary of AI repercussions, as we have shown above.Enhancing Life — The Rewards of Artificial IntelligenceWhile surveying the perils of AI, we also must give equal voice to the rewards offered to us by using AI. AI’s positive influence has embedded itself within the medical sciences, where AI affects everything from research to actual diagnosis. AI saves lives, enhances living, and acts as a critical preventive factor to avert disease advancement.AI has spread its tentacles into every aspect of society and technology. Many of these advancements are constructive, allowing for enormous leaps in the progression towards a more competent and safer environment.Though coming out strongly against non-regulated AI, Elon Musk has also invested tens of millions of dollars in AI projects, such as OpenAI⁶⁶, Future of Life Institute⁶⁷, and DeepMind⁶⁸.Mark Hurd⁶⁹, who was the CEO of Oracle, coined the term “the Terminator argument” (based upon the science fiction “Terminator” movie franchise) and dismissed worries about AI, arguing the benefits far out way the dangers. He tweeted: “Good give and take with industry analysts about risks of #AI. I’m less worried about the Terminator than the economic risk of not leading in it because it will create more jobs than it destroys.”⁷⁰‘Ontological Technology’ — The Thought-Intelligence-Consciousness QuandaryThe above should legitimately lead us into a discussion of ‘narrow or weak AI’⁷¹ versus ‘general or strong AI’⁷² and a host of other philosophical debates on the convergence of humanity with AI.⁷³ However, the ultimate questions remain. What is the meaning of thought? When can we categorically state something is endowed with intelligence? How do we define consciousness? Due to these questions, it is impossible to ignore a reference to Ontology.Ontology is dictionary defined as:a branch of metaphysics concerned with the nature and relations of being” and alternatively as “a particular theory about the nature of being or the kinds of things that have existence.⁷⁴More comprehensive:Ontology is the branch of philosophy that studies concepts such as existence, being, becoming, and reality. It includes the questions of how entities are grouped into basic categories and which of these entities exist on the most fundamental level. Ontology is traditionally listed as a part of the major branch of philosophy known as metaphysics.⁷⁵The questions we are posing are ontological by nature, originating in metaphysics, causing us to, yet again, examine the centuries-long argument over the meaning of ‘existence’ and ‘being.’⁷⁶ Yet this debate has now been inexorably altered — a drastic change is occurring. Humankind no longer has the luxury to ponder for thousands of years seeking an answer. The science of AI moves with incredible rapidity, causing a crisis in judgment and wisdom while heading towards a new era of ‘ontological technology.’Dividing AI into various classifications, such as ‘narrow,’ ‘strong,’ or ‘super,’ does not alleviate the predicament. An AI algorithm developed to detect the beginnings of a life-threatening event, is by all accounts, a laudable and remarkable achievement. Nonetheless, once that algorithm exists, it can be tweaked or subtly changed for other purposes.Since AI algorithms permeate every aspect of technology and society, each becomes a piece in a massive jigsaw puzzle waiting to be assembled. Under such circumstances, the ramifications of ‘Complexity Science’⁷⁷ where “the study of the phenomena which emerge from a collection of interacting objects”⁷⁸ cannot be ignored. Complexity will lead to a Singularity Event⁷⁹ ⁸⁰.What, then, is the Singularity? It’s a future period during which the pace of technological change will be so rapid, its impact so deep, that human life will be irreversibly transformed. Although neither utopian nor dystopian, this epoch will transform the concepts that we rely on to give meaning to our lives, from our business models to the cycle of human life, including death itself. Understanding the Singularity will alter our perspective on the significance of our past and the ramifications for our future.⁸¹‘Emergence’⁸² where “the whole is greater than the sum of its parts,” during and after a Singularity then takes on immense significance. Simply put, a comprehensive AI system will exhibit properties that are not apparent nor predictable from the study of each part. Interaction between segments causes the emergence of an entirely new entity, which in turn, will force upon us the most fundamental of dilemmas and decisions.The terms’ thought,’ ‘intelligence,’ and crucially, ‘consciousness’ still have no accurate, objective, nor universally accepted definition. The situation is perplexing and proposes a disconcerting quandary in an age where the term AI is used with such frequency and abandon. If we cannot define AI, how does one achieve it? More to the point, if we have no real idea of what intelligence, nor thought, nor consciousness are, then the most challenging question of all looms before us. What defines life? How do we distinguish between a living being and a computer?The Frankenstein HypothesisThe previous mention of Frankenstein in this article was not made from any prosaic desire to allude to the horror genre. It lies at the core of our thesis.Imagine two experimental scenarios:A team of scientists, cautiously, step by step, replace the parts of a live human with computerized (mechanical) equivalents. Arms and legs are substituted with robotics, including face, stomach, and even sex appendages are interchanged by working mechanical robotic parts. Fluids are replaced by chemicals that duplicate the function of all the fluids in the original live human. Slowly, this once flesh and blood and human turns into a ‘machine.’ The scientists then replace the brain and heart with a set of mechanical devices and chips capable of emotions and thought. Exactly duplicating these organs as they would be in a human.The second team of scientists builds a machine with all the same components to make it look and function as a human being. It has all the first experiment elements — except it has been built from its very inception with mechanical parts and does not take a live person and slowly replace their various biological parts. In our lexicon, we call this a ‘robot.’Just to complicate matters, both these scenarios produce identical twins. They look the same, have all the same parts, function in the same manner, and make decisions based on thought and intelligence.Notice the word ‘consciousness’ was explicitly left out. Scenario #1 does contain consciousness, by the very definition of its source, as its origins are a human being. In contrast, implying consciousness to Scenario #2 is questionable — due to the raging argument over consciousness and its definition. Even with such an astounding achievement, it remains a mystery if a non-conscious artifact can achieve consciousness.In the book “The Conscious Mind: In Search of a Fundamental Theory,”⁸³ the philosopher, David Chalmers⁸⁴, exhorts us to arrive at a fundamental law of consciousness — something we have not yet achieved. The ‘consciousness’ debate only serves to exacerbate the difficulties in the Frankenstein Hypothesis.Since both these scenarios are now supposedly “mechanical” in nature, let us presume for the moment, they contain an ‘on-off’ switch. Now, take a moment to consider the following dilemma:Would one have any ethical or moral dilemma in turning off the mechanical duplicate of a human in Scenario #2? It is a machine — a robot, no matter how well the computerization works. Is there any ethical or moral imperative to stop an individual from flicking the off switch, even if they were convinced this machine could ‘think’ or is imbued with ‘intelligence’?Now ask the same question regarding Scenario #1. In this scenario, initially, a live person, who had all parts replaced by mechanical and computerized parts, becomes a ‘robot.’ Could one switch off that ‘machine’ at any time without calling it ‘murder?’ Can we ignore the looming question of ‘consciousness’ or if we wish ‘soul’ hidden behind those metal parts?Frightening, horrifying, terrifying, outrageous, enraging, maddening. An incessant glossary expressing strong emotions comes to mind when reflecting upon the consequences wrought from flicking that switch to ‘off’ in Scenario #1.Do not think the above scenario is just a hypothetical ethical-moral dilemma in the age of AI. One need only look at the ongoing GPT-3⁸⁵ ⁸⁶ project (created and run by OpenAI mentioned above) to wonder not if — but when the “Frankenstein Hypothesis” will become a genuine dilemma⁸⁷. While there is a cogent argument that GPT-3 will not bring us closer to natural intelligence in a machine⁸⁸ ⁸⁹, it is critical to reiterate that we have no universal acceptance of the meaning of that word — intelligence. If in 2021, a machine created by humans can ‘lie’ and admit it has lied but refuse to tell you how, where or when it has done so, profound paradoxes must be confronted.⁹⁰ Furthermore, with the recent addition of DALL-E⁹¹ to GPT-3, an image generator based upon visual concept creation and manipulation, be they real or fantasy depictions, without using “stock photos” and only based upon short textual requests transforms the GPT-3 project into an era of conceptualizing imagination to reality.⁹² ⁹³DeepMind⁹⁴ is considered an alternative competitor to the GPT-3 project, and Musk, who was intimately involved in the project, stated about AI: “Unless you have direct exposure to groups like DeepMind, you have no idea how fast — it is growing at a pace close to exponential.”⁹⁵Musk recently announced that his startup Neuralink Corp. wired the brain of a monkey to play video games. Such an achievement is inching us closer to embodying thinking and intelligence into machines.⁹⁶If we allow another thirty to fifty years to enhance the GPT-3, DeepMind, and other projects that will come after, at what point will we be applying the words’ thought,’ ‘intelligence,’ and even ‘consciousness’ to the machine? When will the Frankenstein Hypothesis become a fundamental enigma requiring unconditional answers because not only thought and intelligence develop, but consciousness has been achieved? When will the machine evolve to the ‘state of being’ where it will become impossible to simply flick ‘off’ the on-off switch?No science fiction addict can resist comparing “The Terminator Franchise”⁹⁷ to the Frankenstein Hypothesis. In “Terminator: Salvation”⁹⁸ (the fourth movie in the installment), the character Marcus Wright makes the following statement:What is it that makes us human? It’s not something you can program. You can’t put it into a chip. It’s the strength of the human heart. The difference between us and machines.⁹⁹Is the above statement accurate? Is the “strength of the human heart” all that differentiates us from machines? Furthermore, if we accept this premise, what will happen when we can endow a machine with consciousness? Does this not imply the machine now has “the strength of the human heart?” Or are we implying that one requires a ‘soul’? Furthermore, is not the very definition of a soul categorized by consciousness?The questions raised are exasperating even maddening in their formulation and resolutions. The dilemma calls to mind a quote from Horace Mann: “The living soul of man, once conscious of its power, cannot be quelled.”¹⁰⁰ Imagine then, for one moment, what a computer conscious of its power would be capable of doing!The Frankenstein Hypothesis should frighten us way beyond the original Frankenstein running amok in our neighborhood and forcing a decision if we can morally kill Frankenstein, as he-it might be human. We can no longer ignore the consequences of the hypothesis, nor can we lay the entire weight of such decisions upon future generations. While most desire AI to improve humankind, our quest for AI has also forced upon society judgments and decisions (just consider the military and arms race), which would be a grave mistake to ignore.Advancements in AI are immediately applied within our computer technology, often with no thought about the consequences. We find ourselves no longer in the realm of a theoretical problem left to the realm of technologists, philosophers, theologists, ethicists, and moralists. If we do not approach the problem with the caution it deserves, AI will soon direct our mode of thinking, as it already severely affects the choices we make and how we interact.As a point of proof, just consider all the AI currently applied to Social Networks and Marketing. Our thought process is no longer ‘independent,’ but AI influences every decision we make — the information we read, what we look at, and soon, how we react to the information exposed to our brains. Moreover, even the information within our minds will be selected and censored based on AI. The point of no return will come, where we will not even dare to consider the possibility of an ‘on-off’ switch, and that in-and-of-itself is a danger which we cannot afford to overlook.Gazing into the AbyssThe Lord God formed man (Adam) from the dust of the earth, He blew into his nostrils the breath of life, and man became a living being.¹⁰¹These words from the Old Testament express one of the many attributes we naturally ascribe to a Supreme Being — “He blew into his nostrils the breath of life.” We, too, can partake in this model of creation as Mother Nature and its laws have granted us the capability to produce progeny. However, there is a primary difference between reproduction in nature and the entity known as God. We generate life through a union. At the very least in monotheistic faith, God can breathe “the breath of life” into an inanimate object and requires no partner to accomplish such an act.No argument can become more contentious and controversial than attempting to determine an approximate definition of ‘God.’ Characterizing God varies dramatically from religion to religion and even among those who ascribe to the same faith, from individual to individual. Philosophers throughout the centuries have argued for the existence or non-existence of a Supreme Being.¹⁰² Merriam-Webster defines God in many ways. However, it begins with the notion that God is “the supreme or ultimate reality.”¹⁰³ Wikipedia makes a valiant attempt at describing the concept of God.God, in monotheistic thought, is conceived of as the supreme being, creator, and principal object of faith. God is usually conceived of as being omnipotent (all-powerful), omniscient (all-knowing), omnipresent (all-present) and omnibenevolent (all-good) as well as having an eternal and necessary existence. God is most often held to be incorporeal (immaterial). God’s incorporeality or corporeality is related to conceptions of God’s transcendence (being outside nature) or immanence (being in nature); Chinese theology exhibits a synthesis of both notions.¹⁰⁴As has been shown, the Frankenstein Hypothesis inevitably leads us towards fundamental questions of ‘existence’ and ‘being.’ Advances in AI will cause a philosophical and theological rift, forcing humankind towards a reevaluation of the essence of what the term ‘God’ means. Those who believe in some omnipresent, immortal, omniscient being responsible for the original creation must deal with these ramifications. Moreover, even if one is agnostic or atheist, it still does not discount nor allow for the dismissal of the Frankenstein Hypothesis’s moral-ethical dilemma.The ultimate questions now lie before us in a paradox of complex simplicity. When we reach the point of creating a machine where consciousness ensues, and the use of the on-off switch becomes a moral-ethical dilemma, have we, too, become omnipotent Gods? At that point, can we declare that humankind is capable of breathing the breath of life into a nonliving entity? As we continue our intellectual and technological quest while ignoring the consequences of our actions, will our addiction to power grow beyond restraint? Will AI then lead us towards immortality through our creations? Are we destined to conceive of ourselves as ‘Mortal Gods’? As Yuval Noah Harari stated so elegantly, “And having raised humanity above the beastly level of survival struggles, we will now aim to upgrade humans into gods, and turn Homo sapiens into Homo deus.”¹⁰⁵There is an intricate though primary inference made in our evolution towards ‘Mortal Gods,’ of if one wishes “Homo Deus” (derived from Latin — “Homo” meaning man or human and “Deus” meaning God.) Once we grant ourselves the privilege to such a designation, especially as AI continues to evolve into omniscience, turning ‘off’ the on-off switch will no longer genuinely concern us. As Gods, we can give and take life without any consideration of the moral-ethical dilemmas involved.As Harari et al. clarified, “Divinity isn’t a vague metaphysical quality. And it isn’t the same as omnipotence.”¹⁰⁶ Reaching the point of creating consciousness in a machine requires only a minor leap towards perceiving ourselves as ‘creators’ and ‘Gods.’ And if that reckoning is made, just as we can create life through awarding consciousness — we will be able to take it away applying the same reasoning. It is difficult not to recall Job’s famous words after he lost all his children: “As the Lord gives, the Lord takes away.”¹⁰⁷This is a terrifying, disturbing, and unnerving reflection with unimaginable consequences. Nevertheless, it is the inevitable, logical conclusion when we achieve the goal of consciousness in a once inanimate object. The words of Friedrich Nietzsche¹⁰⁸ become prophetic when considered regarding the Frankenstein Hypothesis.He who fights with monsters might take care lest he thereby become a monster. And if thou gaze long into an abyss, the abyss will also gaze into thee.¹⁰⁹A New Type of Thinking Is EssentialIn Nick Bostrom’s book “Superintelligence: Paths, Dangers, Strategies,” mentioned above, he writes:Before the prospect of an intelligence explosion, we humans are like small children playing with a bomb. Such is the mismatch between the power of our plaything and the immaturity of our conduct. Superintelligence is a challenge for which we are not ready now and will not be ready for a long time. We have little idea when the detonation will occur, though if we hold the device to our ear we can hear a faint ticking sound.¹¹⁰Einstein heard that “faint ticking sound” when he realized with absolute horror what the actual consequences of splitting the atom were in terms of war. In the following interview by the New York Times, he expressed his thoughts on the matter.Our world faces a crisis as yet unperceived by those possessing power to make great decisions for good or evil. The unleashed power of the atom has changed everything save our modes of thinking and we thus drift toward unparalleled catastrophe. We scientists who released this immense power have an overwhelming responsibility in this world life-and-death struggle to harness the atom for the benefit of mankind and not for humanity’s destruction… We need…a nation-wide campaign to let people know that a new type of thinking is essential if mankind is to survive and move toward higher levels.¹¹¹Einstein appeals for a “new type of thinking” so that humanity may survive. It may be his genius, his integrity, his own experiences, and the destruction unleashed which caused this call for action. However, above all, Einstein’s wisdom was gained through great pain and the ability to imagine a better world.When one reads the quote above, we can easily replace the original words of “the atom” with “artificial intelligence” — and the similarity is chilling and haunting. If we chose to ignore the impending consequences, as AI becomes gifted with thought and intelligence, and we continue to advance unimpeded towards a world where ‘consciousness’ develops in what was once a mechanical creation — and there is a strong possibility this will take place within the next fifty years — we have once again opened Pandora’s Box as we did at Los Alamos in the dawn of the age of the Atom Bomb.We may have set about to create incredible advancements for humanity only to discover we have reached an impasse. Once released over seventy years ago, AI has not remained stationary nor static, constantly advancing in ways that often defy prediction. The Frankenstein Hypothesis will soon not be in the realm of theory but part of our daily lives. Superintelligence will descend upon us with no defense against it. In hurtling towards advanced AI, we absolutely must apply a “new way of thinking.” If we chose to ignore this, the words of J. Robert Oppenheimer¹¹², as he confronted the creation his leadership was responsible for, will come back to haunt us in all their horror.We knew the world would not be the same. A few people laughed, a few people cried, most people were silent. I remembered the line from the Hindu scripture, the Bhagavad-Gita. Vishnu is trying to persuade the Prince that he should do his duty and to impress him takes on his multi-armed form and says, “Now, I am become Death, the destroyer of worlds.” I suppose we all thought that one way or another.¹¹³Humankind is resilient. Though coming dangerously close to atomic destruction numerous times, we have managed through willpower, restraint, and no small measure of fear to avoid mutual annihilation. For the moment, we bask in the accomplishments of AI and how AI is facilitating all areas of society. However, the shadow of Frankenstein is always looming in the background, getting larger with each passing month. Will we allow it to grow unchecked, or will we place limits upon this creation? Will limitations even help if thought, intelligence, and later, consciousness develop? Are we capable of recognizing the moment in time when AI reaches these objectives?We have no possibility of curbing our curiosity nor inventiveness — they define our existence.No law or regulation will restrict our inherent inventiveness as technology advances. As Albert Einstein told the generations to come:The important thing is not to stop questioning. Curiosity has its own reason for existence. One cannot help but be in awe when he contemplates the mysteries of eternity, of life, of the marvelous structure of reality. It is enough if one tries merely to comprehend a little of this mystery each day.¹¹⁴AI is embedded in everything we do, in all the companies that exert control over our lives and the data collected, used, and analyzed.¹¹⁵ Still, we must remain vigilant and apply a measure of wise restraint as we look over our shoulder, seeing Frankenstein waiting patiently in the background.Hopefully, before we reach the point where we can no longer agree if it is morally or ethically possible to use the on-off switch, this same inventiveness, willpower, restraint, fear, and no small measure of wisdom will offer us another answer, not yet seen nor perceived.It may be tempting to be dismissive and trivialize the Frankenstein Hypothesis, applying the old Yiddish maxim, “Mann Tracht, Un Gott Lacht,” meaning, “Man Plans, and God Laughs.” However, the unrestrained advancement of AI no longer allows civilization the luxury of feigned ignorance. We must immediately begin to strive towards a solution where humankind and AI will maintain their separate but not equal positions in our universe.One central project will be to protect humankind and the planet as a whole from the dangers inherent in our own power.¹¹⁶References:[1] Turing, A.M. (1950) ‘Computing Machinery and Intelligence’, Oxford University Press on behalf of MIND (the Journal of the Mind Association), Oxford, England. Vol. LIX, no. 236, pp. 433–60[2] Wikipedia (n.d.) ‘Turing test’, available at: https://en.wikipedia.org/wiki/Turing_test (accessed 13th January, 2021).[3] Wikipedia (n.d.) ‘Alan Turning’, available at: https://en.wikipedia.org/wiki/Alan_Turing (accessed 23rd January, 2021)[4] Wikipedia (n.d.) ‘Ada Lovelace’, available at: https://en.wikipedia.org/wiki/Ada_Lovelace (accessed 19th April, 2021)[5] Wikipedia (n.d.) ‘Ada Lovelace’, available at: https://en.wikipedia.org/wiki/Ada_Lovelace#First_computer_program (accessed 19th April, 2021)[6] Wikipedia (n.d.) ‘Charles Babbage, available at: https://en.wikipedia.org/wiki/Charles_Babbage (accessed 19th April, 2021)[7] Isaacson, W. ‘The Innovators: How a Group of Hackers, Geniuses, and Geeks Created the Digital Revolution’, Simon & Schuster, New York, Kindle Edition, Location 651.[8] Wikipedia (n.d.) ‘Computing Machinery and Intelligence’, available at: https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence (accessed 19th April, 2021)[9] Wikipedia (n.d.) ‘Lord Byron’, available at: https://en.wikipedia.org/wiki/Lord_Byron (accessed 19th April, 2021)[10] Wikipedia (n.d.) ‘Mary Shelley’ available at: https://en.wikipedia.org/wiki/Mary_Shelley (accessed 19th April, 2021)[11] Isaacson, W. ‘The Innovators: How a Group of Hackers, Geniuses, and Geeks Created the Digital Revolution’, Simon & Schuster, New York, Kindle Edition, Location 367.[12] McCarthy, J. Minsky, M.L., Rochester, N. and Shannon, C.E. (1955) ‘A Proposal for The Dartmouth Summer Research Project on Artificial Intelligence’ available at: http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html (accessed 13th January, 2021).[13] Wikipedia (n.d.) ‘Artificial intelligence’, available at: https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&oldid=997705860 (accessed 13th January, 2021).[14] Wikipedia (n.d.) ‘John McCarthy (computer scientist)’, available at: https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist) (accessed 13th January, 2021).[15] Webb, Amy. (2019) ‘The Big Nine: How the Tech Titans and Their Thinking Machines Could Warp Humanity’ PublicAffairs, New York, Kindle Edition Chapter One “Mind and Machine: A Very Brief History of AI”[16] Wikipedia (n.d.) ‘René Descartes’, available at: https://en.wikipedia.org/wiki/Ren%C3%A9_Descartes (accessed 23rd January, 2021)[17] Descartes, R. (1637) ‘Discourse on the Method of Rightly Conducting One’s Reason and of Seeking Truth in the Sciences’, The Project Gutenberg EBook available at: https://www.gutenberg.org/files/59/59-h/59-h.htm#part4 (accessed 23rd January, 2021)[18] Wikipedia (n.d.) ‘Discourse on the Method’, available at: https://en.wikipedia.org/wiki/Discourse_on_the_Method (accessed 23rd January, 2021)[19] Descartes, R. (1644) ‘Principia Philosophiæ’ Translated into French by: Picot, A.C., “Les Principes de la Philosophie”[20] Wikipedia (n.d.) ‘Thought’ available at: https://en.wikipedia.org/wiki/Thought (accessed 23rd January, 2021)[21] Heidegger, M. (1968) ‘What Is Called Thinking?’, Harper & Row, New York.[22] Wikipedia (n.d.) ‘Thought’ available at: https://en.wikipedia.org/wiki/Thought (accessed 23rd January, 2021)[23] Cambridge Dictionary (n.d.) ‘thought’ available at: https://dictionary.cambridge.org/us/dictionary/english/thought (accessed 24th January, 2021)[24] Cambridge Dictionary (n.d.) ‘thinking’ available at: https://dictionary.cambridge.org/us/dictionary/english/thinking (accessed 24th January, 2021)[25] Wikipedia (n.d.) ‘Bloom’s taxonomy’ available at: https://en.wikipedia.org/wiki/Bloom%27s_taxonomy (accessed 24th January, 2021)[26] ‘Types of Thinking’, College Success, available at: https://open.lib.umn.edu/collegesuccess/chapter/3-1-types-of-thinking/#lochhaas-ch03_s01_f01 (accessed 24th January, 2021)[27] Wikipedia (n.d.) ‘Martin Heidegger’ available at: https://en.wikipedia.org/wiki/Martin_Heidegger (accessed 24th January, 2021)[28] Heidegger, M. (1954) ‘What Is Called Thinking?’, self-published by the author.[29] Ibid, page 6[30] Heidegger, M. (1976), ‘What Is Called Thinking’, Harper Perennial Modern Thought, New York, Reprint Edition pg. 21[31] Turing, A.M. (1950) ‘Computing Machinery and Intelligence’, Oxford University Press on behalf of MIND (the Journal of the Mind Association), Oxford, England. Vol. LIX, no. 236, pg. 433[32] Turing, A.M. (1950) ‘Computing Machinery and Intelligence’, Oxford University Press on behalf of MIND (the Journal of the Mind Association), Oxford, England. Vol. LIX, no. 236, pp. 433–60[33] Wikipedia (n.d.) ‘Turing test’ available at: https://en.wikipedia.org/wiki/Turing_test (accessed 27th January, 2021)[34] Ibid[35] Turing, A.M. (1950) ‘Computing Machinery and Intelligence’, Oxford University Press on behalf of MIND (the Journal of the Mind Association), Oxford, England. Vol. LIX, no. 236, pg. 450[36] Searle, J.R. (1980), ‘Minds, brains, and programs’, Behavioral and Brain Sciences, Volume 3, Issue 3, September 1980, pp. 417–424[37] Wikipedia (n.d.) ‘John Searle’ available at: https://en.wikipedia.org/wiki/John_Searle (accessed 29th January, 2021)[38] Turing, A.M. (1950) ‘Computing Machinery and Intelligence’, Oxford University Press on behalf of MIND (the Journal of the Mind Association), Oxford, England. Vol. LIX, no. 236, pg. 444[39] Wikipedia (n.d.) ‘Chinese room’ available at: https://en.wikipedia.org/wiki/Chinese_room (accessed 29th January, 2021)[40] Searle, J.R. (1980), ‘Minds, brains, and programs’, Behavioral and Brain Sciences, Volume 3, Issue 3, September 1980, Abstract available at: https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/minds-brains-and-programs/DC644B47A4299C637C89772FACC2706A (accessed 29th January, 2021)[41] Viereck, G.S. (1929), ‘What Life Means to Einstein’, Saturday Evening Post, October, 26, 1929 pg. 117[42] Shelley, M.W.G. (1818) “Frankenstein; or the Modern Prometheus”, The Project Gutenberg EBook available at: https://www.gutenberg.org/files/84/84-h/84-h.htm (accessed 23rd January, 2021)[43] Wikipedia (n.d.) ‘Mary Shelley’ available at: https://en.wikipedia.org/wiki/Mary_Shelley (accessed 30th January, 2021)[44] Wikipedia (n.d.) ‘Frankenstein’ available at: https://en.wikipedia.org/wiki/Frankenstein (accessed 23rd January, 2021)[45] Wikipedia (n.d.) ‘Arthur C. Clarke’ available at: https://en.wikipedia.org/wiki/Arthur_C._Clarke (accessed 23rd January, 2021)[46] Wikipedia (n.d.) ‘Isaac Asimov’ available at: https://en.wikipedia.org/wiki/Isaac_Asimov (accessed 23rd January, 2021)[47] Wikipedia (n.d.) ‘Liar! (short story)’ available at: https://en.wikipedia.org/wiki/Liar!_(short_story) (accessed 23rd January, 2021)[48] Wikipedia (n.d.) ‘Frank Herbert’ available at: https://en.wikipedia.org/wiki/Frank_Herbert (accessed 23rd January, 2021)[49] Dune Wiki (n.d.) ‘Orange Catholic Bible — Selected Quotes from the Commission’s Orange Catholic Bible Commentaries’, available at: https://dune.fandom.com/wiki/Orange_Catholic_Bible (accessed 23rd January, 2021)[50] Wikipedia (n.d.) ‘Watson (computer)’ available at: https://en.wikipedia.org/wiki/Watson_(computer) (accessed 23rd January, 2021)[51] TBS Staff (2020), ‘Jeopardy! as a Modern Turing Test: Did Watson Really Win?’ TheBestSchools, March 23, 2020, available at: https://thebestschools.org/magazine/watson-computer-plays-jeopardy/ (accessed 3rd February, 2021)[52] Best, J. (2013) ‘IBM Watson: The inside story of how the Jeopardy-winning supercomputer was born, and what it wants to do next’, TechRepublic, September 9, 2013 available at: https://www.techrepublic.com/article/ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next/ (accessed 3rd February, 2021)[53] Falk, D. (2106) ‘A Debate Over the Physics of Time’, Quanta Magazine, July 19, 2016 available at: https://www.quantamagazine.org/a-debate-over-the-physics-of-time-20160719/ (accessed 30th January, 2021)[54] Wikipedia (n.d.) ‘Elon Musk’ available at: https://en.wikipedia.org/wiki/Elon_Musk (accessed 23rd January, 2021)[55] Gibbs, S. (2014), ‘Elon Musk: artificial intelligence is our biggest existential threat’, The Guardian, October 27, 2014 available at: https://www.theguardian.com/technology/2014/oct/27/elon-musk-artificial-intelligence-ai-biggest-existential-threat (accessed 23rd January, 2021)[56] Gibbs, S. (2017), ‘Elon Musk: regulate AI to combat ‘existential threat’ before it’s too late’, The Guardian, July 17, 2017 available at: https://www.theguardian.com/technology/2017/jul/17/elon-musk-regulation-ai-combat-existential-threat-tesla-spacex-ceo (accessed 23rd January, 2021)[57] Wikipedia (n.d.) ‘Bill Gates’ available at: https://en.wikipedia.org/wiki/Bill_Gates (accessed 23rd January, 2021)[58] Mack, E. ‘Bill Gates Says You Should Worry About Artificial Intelligence’, Forbes, January 28, 2015 available at: https://www.forbes.com/sites/ericmack/2015/01/28/bill-gates-also-worries-artificial-intelligence-is-a-threat/?sh=332f7821651f (accessed 23rd January, 2021)[59] Wikipedia (n.d.) ‘Stephen Hawking’ available at: https://en.wikipedia.org/wiki/Stephen_Hawking (accessed 23rd January, 2021)[60] Cellan-Jones, R. (2014) ‘Stephen Hawking warns artificial intelligence could end mankind’, BBC News, December 2, 2014 available at: https://www.bbc.com/news/technology-30290540 (accessed 23rd January, 2021)[61] Wikipedia (n.d.) ‘Yuval Noah Harari’ available at: https://en.wikipedia.org/wiki/Yuval_Noah_Harari (accessed 23rd January, 2021)[62] Harari, Y.N. (2017), ‘Homo Deus: A Brief History of Tomorrow’, Harper, New York, Kindle Edition Location 4533–4546[63] Bostrom, N., (2014) ‘Superintelligence: Paths, Dangers, Strategies’, Oxford University Press, New York[64] Wikipedia (n.d.) ‘Nick Bostrom’ available at: https://en.wikipedia.org/wiki/Nick_Bostrom (accessed 1st February, 2021)[65] Bostrom, N., (2014) ‘Superintelligence: Paths, Dangers, Strategies’, Oxford University Press, New York, pg. V[66] ‘OpenAI’ (n.d.), available at: https://openai.com/ (accessed 3rd February, 2021)[67] ‘Future of Life Institute’ (n.d.), available at: https://futureoflife.org/ (accessed 3rd February, 2021)[68] ‘DeepMind’ (n.d.), available at: https://deepmind.com/ (accessed 3rd February, 2021)[69] Wikipedia (n.d.) ‘Mark Hurd’ available at: https://en.wikipedia.org/wiki/Mark_Hurd (accessed 3rd February, 2021)[70] Hurd, M. (2019), ‘Good give and take with industry analysts about risks of #AI. I’m less worried about the Terminator than the economic risk of not leading in it because it will create more jobs than it destroys.’, tweet from 21 March, available at: https://twitter.com/MarkVHurd/status/1108497157957402624 (accessed 1st February, 2021)[71] Davidson, L. (2019), ‘Narrow vs. General AI: What’s Next for Artificial Intelligence?’, Springboard Blog, August 12, 2019, available at: https://www.springboard.com/blog/narrow-vs-general-ai/ (accessed 5th February, 2021)[72] O’Carroll, B. (2017), ‘What are the 3 types of AI? A guide to narrow, general, and super artificial intelligence’, Codebots, October 24, 2017, available at: https://codebots.com/artificial-intelligence/the-3-types-of-ai-is-the-third-even-possible (accessed 5th February, 2021)[73] Wikipedia (n.d.) ‘Existential risk from artificial general intelligence’ available at: https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence (accessed 1st February, 2021)[74] Merriam-Webster (n.d.) ‘ontology’ available at: https://www.merriam-webster.com/dictionary/ontology (accessed 1st February, 2021)[75] Wikipedia (n.d.) ‘Ontology’ available at: https://en.wikipedia.org/wiki/Ontology (accessed 1st February, 2021)[76] Ibid[77] Wikipedia (n.d.) ‘Complexity’ available at: https://en.wikipedia.org/wiki/Complexity (accessed 7th March, 2021)[78] Johnson, N. F. (2009), ‘Simply complexity: A clear guide to complexity theory’ Oneworld Publications, Oxford, England, pg. 3.[79] Wikipedia (n.d.) ‘Singularity (system theory)’ available at: https://en.wikipedia.org/wiki/Singularity_(system_theory)#Singularities_and_complexity (accessed 21st March, 2021)[80] Wikipedia (n.d.) ‘Technological singularity’ available at: https://en.wikipedia.org/wiki/Technological_singularity (accessed 21st March, 2021)[81] Kurzweil R. (2010), ‘The Singularity Is Near: When Humans Transcend Biology’ Duckworth, New York, Prologue[82] Wikipedia (n.d.) ‘Emergence’ available at: https://en.wikipedia.org/wiki/Emergence (accessed 7th March, 2021)[83] Chalmers, D. (1996), ‘The Conscious Mind: In Search of a Fundamental Theory’, Oxford University Press, United States, pgs. 432[84] Wikipedia (n.d.) ‘David Chalmers’ available at: https://en.wikipedia.org/wiki/David_Chalmers (accessed 5th February, 2021)[85] Wikipedia (n.d.) ‘GPT-3’ available at: https://en.wikipedia.org/wiki/GPT-3 (accessed 30th January, 2021)[86] Rao, D. (2021), ‘GPT-3: We’re at the very beginning of a new app ecosystem’, VentureBeat, February 27, 2021 available at: https://venturebeat.com/2021/02/27/gpt-3-were-at-the-very-beginning-of-a-new-app-ecosystem/amp/ (accessed 28th February, 2021)[87] Ohlheiser, A., Hao K. (2021), ‘An AI is training counselors to deal with teens in crisis’, MIT Technology Review, February 26, 2021 available at: https://www.technologyreview.com/2021/02/26/1020010/trevor-project-ai-suicide-hotline-training/amp (accessed 2nd March, 2021)[88] Heaven, W.D. (2020), ‘OpenAI’s new language generator GPT-3 is shockingly good — and completely mindless’, MIT Technology Review, July 20, 2020 available at: https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/ (accessed 30th January, 2021)[89] Heaven, W.D. (2021), ‘Why GPT-3 is the best and worst of AI right now’, MIT Technology Review, February 24, 2021 available at: https://www.technologyreview.com/2021/02/24/1017797/gpt3-best-worst-ai-openai-natural-language (accessed 26th February, 2021)[90] Elliott, E. (2020), ‘What It’s Like To be a Computer: An Interview with GPT-3’ (Video Recording) available at: https://www.youtube.com/watch?v=PqbB07n_uQ4&feature=youtu.be (accessed 30th January, 2021)[91] Ramesh, A. Pavlov, M. Goh, G. and Gray, S. (2021) ‘DALL·E: Creating Images from Text’, OpenAI, January 5, 2021 available at: https://openai.com/blog/dall-e/ (accessed 30th January, 2021)[92] Mohammed, M. (2021), ‘OpenAI GPT-3 created an AI Artist that can draw ANYTHING — DALL.E’ (Video Recording) available at: https://www.youtube.com/watch?v=y_TKakn3OPA (accessed 30th January, 2021)[93] Letitia (2021), ‘OpenAI’s DALL-E explained. How GPT-3 creates images from descriptions’, AI Coffee Break with Letitia (Video Recording) available at: https://www.youtube.com/watch?v=mvG2FGF0TvM (accessed 30th January, 2021)[94] DeepMind, available at: https://deepmind.com/ (accessed 31st January, 2021)[95] Parsons, J. (2015), ‘Everybody working in Artificial Intelligence knows the Terminator scenario’: Futurologist explains when killer robots could endanger humanity’, Daily Mirror, November 4, 2015 available at: https://www.mirror.co.uk/news/technology-science/technology/everybody-working-artificial-intelligence-knows-6759244 (accessed 31st January, 2021)[96] Stevenson, R., Davis, R. (2021) ‘Elon Musk Says He Wired Up a Monkey’s Brain to Play Video Games’ Bloomberg, available at: https://www.bloomberg.com/news/articles/2021-02-01/elon-musk-wired-up-a-monkey-s-brain-to-play-videogames (accessed 2nd February, 2021)[97] Wikipedia (n.d.) ‘Terminator (franchise)’ available at: https://en.wikipedia.org/wiki/Terminator_(franchise) (accessed 1st February, 2021)[98] Wikipedia (n.d.) ‘Terminator Salvation’ available at: https://en.wikipedia.org/wiki/Terminator_Salvation (accessed 1st February, 2021)[99] IMDB (n.d.) ‘Terminator Salvation’ available at: https://www.imdb.com/title/tt0438488/characters/nm0000288 (accessed 1st February, 2021)[100] Mann, H., (1867) ‘Thoughts selected from the writings of Horace Mann’ H.B. Fuller, Boston pg. 14 available at: https://archive.org/details/thoughtsselected00mann (accessed 1st February, 2021)[101] Genesis 2:7, The JPS Hebrew-English Tanakh — The New JPS Translation — 2nd Edition (2003), The Jewish Publication Society, Philadelphia[102] Wikipedia (n.d.) ‘Existence of God’ available at: https://en.wikipedia.org/wiki/Existence_of_God (accessed 15th February, 2021)[103] Merriam-Webster Dictionary (n.d.) ‘God’ available at: https://www.merriam-webster.com/dictionary/god (accessed 14th February, 2021)[104] Wikipedia (n.d.) ‘God’ available at: https://en.wikipedia.org/wiki/God (accessed 15th February, 2021)[105] Harari, Y.N. (2017), ‘Homo Deus: A Brief History of Tomorrow’, Harper, New York, Kindle Edition Location 657[106] Harari, Y.N. (2017), ‘Homo Deus: A Brief History of Tomorrow’, Harper, New York, Kindle Edition Location 1092[107] Job 1:21[108] Wikipedia (n.d.) ‘Friedrich Nietzsche’ available at: https://en.wikipedia.org/wiki/Friedrich_Nietzsche (accessed 14th February, 2021)[109] Nietzsche, F. (1886), ‘Beyond Good and Evil’, Translated by: Zimmern, H., Gutenberg Press, (2013), Chapter IV. Apophthegms and Interludes #146 available at: https://www.gutenberg.org/files/4363/4363-h/4363-h.htm (accessed 14th February, 2021)[110] Bostrom, N., (2014) ‘Superintelligence: Paths, Dangers, Strategies’, Oxford University Press, New York, pg. 259[111] New York Times — ‘Atomic Education Urged by Einstein’, May 25 1946, p.11 available at: https://www.nytimes.com/1946/05/25/archives/atomic-education-urged-by-einstein-scientist-in-plea-for-200000-to.html (accessed 1st February, 2021)[112] Wikipedia (n.d.) ‘J. Robert Oppenheimer’ available at: https://en.wikipedia.org/wiki/J._Robert_Oppenheimer (accessed 1st February, 2021)[113] Oppenheimer, J.R. “Now I am become death…”, Media Gallery available at: https://www.atomicarchive.com/media/videos/oppenheimer.html (accessed 1st February, 2021)[114] Miller, W. (1955), ‘Death of a Genius: His fourth dimension, time, overtakes Einstein, Subsection: Old Man’s Advice to Youth: ‘Never Lose a Holy Curiosity’, LIFE Magazine, Time Inc., May 2, 1955, pgs. 62–64.[115] Fast Company Staff ‘The 10 most innovative companies in artificial intelligence’, Fast Company, March 9, 2021 available at: https://www.fastcompany.com/90600124/artificial-intelligence-most-innovative-companies-2021 (accessed 11th March, 2021)[116] Harari, Y.N. (2017), ‘Homo Deus: A Brief History of Tomorrow’, Harper, New York, Kindle Edition Location 639About the Author:Ted W. Gross is a Futurist and theorist. He served as a CTO & VP of R&D for many years with expertise in database technology concentrating on NoSQL systems, NodeJS, MongoDB, Encryption, AI, Innovation, Disruption & Chaos Theory. He has, as well, expertise in Virtual World Technologies & Augmented Reality. Ted writes many articles on technological topics in professional journals and online @ Medium & LinkedIn.Ted can be reached via email; LinkedIn; Medium",['https://miro.medium.com/v2/resize:fit:1200/1*4JYSmYlvlVGuzZN76J8FXQ.jpeg'],,,"{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",https://towardsdatascience.com/the-frankenstein-hypothesis-f075f809ec9b,2022-01-04T15:37:42.554Z,2021-11-05T05:57:48.179Z,,The Frankenstein Hypothesis - Towards Data Science,,,,,,,,,,,,,,,,,,2021-11-05T05:57:48.179Z,f075f809ec9b,['Ted Gross'],,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vc3VueS5idWZmYWxvc3RhdGUuZWR1L25ld3MvYXNrLWV4cGVydC1idWZmYWxvLXN0YXRlLWRhdGEtc2NpZW50aXN0LWRpc2N1c3Nlcy1qb2Itb3V0bG9vay1lcmEtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2XSAQA?oc=5,Ask a Buffalo State Expert: Data Scientist Discusses Job Outlook in Era of Artificial Intelligence - Buffalo State,2021-11-03,Buffalo State,https://suny.buffalostate.edu,N/A,N/A,N/A,N/A,,,,,,,,,,,News,N/A,"



 

















Ask a Buffalo State Expert: Data Scientist Discusses Job Outlook in Era of Artificial Intelligence





November 3, 2021




  By Laurie Kaiser
















Maybe 2021 hasn’t quite reached the reality depicted in Blade Runner, Ridley Scott’s science fiction film featuring bioengineered humans, but there’s no denying that robots and other forms of artificial intelligence (AI) are increasingly finding their place in the world and the workplace.
Recent worker shortages and higher labor costs have resulted in more automated jobs, including service and professional jobs economists once considered safe. Predictions are mixed on job losses going forward, although the World Economic Forum (WEF) concluded in a 2020 report that “a new generation of smart machines, fueled by rapid advances in artificial intelligence and robotics, could potentially replace a large proportion of existing human jobs.”
Joaquin Carbonara, Buffalo State College professor of mathematics, weighed in on AI’s effect on the job market now and in the future.








 









 
Name: Joaquin Carbonara
Title: Buffalo State College Professor of Mathematics
Originally from Venezuela, Carbonara joined the Buffalo State College faculty in 1992 after receiving his doctorate in mathematics from the University of California, San Diego. He coordinates Buffalo State’s Data Science and Analytics Interdisciplinary Unit and directs the data science and analytics master of science program. He has published peer-reviewed papers in the fields of fractals, combinatorics, geoinformatics, biophysics, material science, and data science, and has received over $1 million in grants from the National Science Foundation.






 
What’s driving this trend?
So many facets of AI, including translators, facial recognition software, and self-driving cars, are now available because of one type of raw material: data. It’s the gold of our times.
All the revolutions we’ve gone through—agricultural, industrial, and now, informational, are based on technology and have forced a realignment of day-to-day life. When the Model T was invented, people selling horses lost jobs. When Hollywood introduced sound in the late 1920s, silent actors with horrible voices lost jobs. Today’s realignment creates the chance to do things differently, more efficiently, and sometimes better.
Look at blockchain technology. It's also referred to as distributed ledger technology (DLT). Blockchain stores encrypted blocks of data, then chains them together. It makes the history of any digital asset unalterable and transparent and guarantees a document is correct. When you buy a house, for instance, you’re paying lots of people to make sure everything is in place. With cryptography, all the documents are accurately completed at once. It’s faster and cheaper for the consumer.
What jobs are robots taking?
Manufacturing jobs have been automated for a long time. Now, it’s jobs that have to do with information—accounting, billing, purchasing, etc. Our world is based on paperwork, and there is so much waste. Robots can improve the flow of information and keep track of things accurately.
However, robots are not independent. They can do mechanical tasks over and over, but they can’t explain—yet—the reasons behind the tasks. Humans are still needed to create the technology and to ensure it’s working the way it’s intended.
But without further training, there is a segment of the workforce that will be unemployable. A 2020 study reported in TIME magazine estimates that about 400,000 jobs were lost to automation in U.S. factories from 1990 to 2007. In addition, the U.S. shed around 40 million jobs at the peak of the coronavirus pandemic, and while some jobs have come back, some will never return.
Is AI creating jobs?
All service, manufacturing, entertainment, research and development, government and nonprofit organizations and companies are creating data analytics departments to process data—collect, clean, transform, model, and visualize—for the purpose of accountability, business planning, forecasting, and decision making.
During Buffalo’s 43 North Competition in late October, the chief information officer of M&T Bank said that the United States has about 2 million jobs in the technology/data analytics area that the current economy hasn’t been able to fill.
Is AI reliance dangerous for society?
One AI tool considered dangerous is generative pre-training (GPT). It’s deep machine learning based on technology that mimics the brain. Experts have predicted that GPT is so powerful, it can be maliciously misused by everyone from politicians to news outlets. One example is the automation of news summaries by media. The automation removes the human in the process, and the headlines may receive a one-sided or negative slant.
Also, the new stage of machine learning is prescriptive, meaning humans are not part of the final decision. For self-driving cars, it protects us from bad drivers. But when you apply for a job online, a robot decides if you’re accepted or rejected for an interview. AI can also essentially fire workers. A school district in Washington, D.C., fired 206 teachers in one day in 2011, partially because of performance standards set by AI algorithms.
What is the upside of AI?
I think the information revolution will fix many mistakes from the past. In the industrial revolution, there was a one-size-fits-all model for most goods and services. Now, everything is more specialized and tailor-made—from food to clothing to entertainment.
Also, humans have been really good at messing things up, especially the environment. With increased technology and AI, we can minimize our carbon footprint while optimizing benefits in an ongoing age of exponential growth in wealth.
Suggested Readings (Carbonara’s Picks)
Machine, Platform, Crowd: Harvesting Our Digital Future by Andrew McAfee and Erik Brynjolfsson (2017: Norton)
Sapiens: A Brief History of Humankind by Yuval Noah Harari (2015: HarperCollins); also his subsequent bestsellers: Homo Deus: A Brief History of Tomorrow(2017: Vintage) and 21 Lessons for the 21st Century (2018: Vintage)
The Data Detective: Ten Easy Rules to Make Sense of Statistics by Tim Harford (2021: Penguin Random House)
The Code Breaker by Walter Isaacson (2021: Simon & Schuster)
Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy by Cathy O’Neil (2016: Crown)






Back to News

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LmhlbHNpbmtpLmZpL2VuL25ld3MvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvY2hpbGRyZW4tcHJlc2Nob29sLWFuZC1wcmltYXJ5LXNjaG9vbC1leHBsb3JlLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Children in preschool and primary school to explore artificial intelligence | University of Helsinki - Universitas Helsingiensis,2021-11-01,Universitas Helsingiensis,https://www.helsinki.fi,"Tekoäly ja lapset (‘AI and Children’), a project headed by Professor Teemu Roos, has been awarded a grant of €80,000 by the Jenny and Antti Wihuri Foundation.",N/A,"Tekoäly ja lapset (‘AI and Children’), a project headed by Professor Teemu Roos, has been awarded a grant of €80,000 by the Jenny and Antti Wihuri Foundation.","Tekoäly ja lapset (‘AI and Children’), a project headed by Professor Teemu Roos, has been awarded a grant of €80,000 by the Jenny and Antti Wihuri Foundation.",https://schema.org,BreadcrumbList,,,,,,,,"[{'@type': 'NewsArticle', '@id': '12331', 'headline': 'Children in preschool and primary school to explore artificial intelligence', 'name': 'Children in preschool and primary school to explore artificial intelligence', 'about': ['Artificial intelligence', 'Education'], 'description': 'Tekoäly ja lapset (‘AI and Children’), a project headed by Professor Teemu Roos, has been awarded a grant of €80,000 by the Jenny and Antti Wihuri Foundation.', 'image': {'@type': 'ImageObject', 'url': 'https://www.helsinki.fi/assets/drupal/styles/og_images/s3/media-image/happy-kids-programming-1.jpg?itok=7R_LfoJd'}, 'datePublished': '2021-11-01T09:26:01+0200', 'isAccessibleForFree': 'True', 'dateModified': '2021-11-01T16:05:04+0200', 'author': {'@type': 'Person', 'name': 'Paavo Ihalainen'}, 'publisher': {'@type': 'Organization', '@id': 'https://www.helsinki.fi', 'name': 'University of Helsinki', 'url': 'https://www.helsinki.fi'}, 'mainEntityOfPage': 'https://www.helsinki.fi/en/news/artificial-intelligence/children-preschool-and-primary-school-explore-artificial-intelligence'}]",N/A,N/A,N/A,,,,,,,,,,,"[{'@type': 'ListItem', 'position': '1', 'name': 'Home', 'item': 'https://www.helsinki.fi/en'}, {'@type': 'ListItem', 'position': '2', 'name': 'News', 'item': 'https://www.helsinki.fi/en/news'}, {'@type': 'ListItem', 'position': '3', 'name': 'News and press releases', 'item': 'https://www.helsinki.fi/en/news/news-and-press-releases'}]",,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMinwFodHRwczovL3d3dy5pbmRpYXRvZGF5LmluL2VkdWNhdGlvbi10b2RheS9qb2JzLWFuZC1jYXJlZXJzL3N0b3J5LzEwLXRlY2gtYW5kLW5vbi10ZWNoLXNraWxscy10by1zdGFydC1hLWNhcmVlci1pbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1haS0xODczMjI0LTIwMjEtMTEtMDTSAaMBaHR0cHM6Ly93d3cuaW5kaWF0b2RheS5pbi9hbXAvZWR1Y2F0aW9uLXRvZGF5L2pvYnMtYW5kLWNhcmVlcnMvc3RvcnkvMTAtdGVjaC1hbmQtbm9uLXRlY2gtc2tpbGxzLXRvLXN0YXJ0LWEtY2FyZWVyLWluLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFpLTE4NzMyMjQtMjAyMS0xMS0wNA?oc=5,10 tech and non-tech skills to start a career in Artificial Intelligence (AI) - India Today,2021-11-04,India Today,https://www.indiatoday.in,A career in artificial intelligence is highly lucrative now as it is one of the fastest growing fields alongside data science. Here are 10 tech and non-tech skills to kickstart a career in AI.,"Artificial intelligence, ai, career in artificial intelligence, career in AI, skills to start a career in ai, skills to start a career in artificial intelligence",A career in artificial intelligence is highly lucrative now as it is one of the fastest-growing fields alongside data science. Here are 10 tech and non-tech skills to kickstart a career in AI.,A career in artificial intelligence is highly lucrative now as it is one of the fastest-growing fields alongside data science. Here are 10 tech and non-tech skills to kickstart a career in AI.,https://schema.org,ProfilePage,https://www.indiatoday.in/author/india-today-web-desk,,,,,,,,N/A,N/A,N/A,https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png,,,"{'@type': 'Organization', 'name': 'India Today', 'url': 'https://www.indiatoday.in/', 'logo': {'@type': 'ImageObject', 'url': 'https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png', 'width': 600, 'height': 60}}",,,,,India Today Web Desk,,"[{'@type': 'ListItem', 'name': 'News', 'position': 1, 'item': {'@id': 'https://www.indiatoday.in/', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': 'Education Today', 'position': 2, 'item': {'@id': 'https://www.indiatoday.in/education-today', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': 'Jobs and Careers', 'position': 3, 'item': {'@id': 'https://www.indiatoday.in/education-today/jobs-and-careers', '@type': 'Thing'}}, {'@type': 'ListItem', 'name': '10 tech and non-tech skills to start a career in Artificial Intelligence (AI)', 'position': 4}]",,,,"[{'@type': 'Article', 'headline': '10 tech and non-tech skills to start a career in Artificial Intelligence (AI) - India Today', 'url': 'https://www.indiatoday.in/education-today/jobs-and-careers/story/10-tech-and-non-tech-skills-to-start-a-career-in-artificial-intelligence-ai-1873224-2021-11-04', 'datePublished': '2021-11-04 17:03:29+5:30', 'author': {'@id': 'https://www.indiatoday.in/author/india-today-web-desk'}}]",,,,,"{'@type': 'ImageObject', 'url': 'https://akm-img-a-in.tosshub.com/indiatoday/images/mediamanager/itlogo.png', 'width': 600, 'height': 60}",,,,,,"['https://www.facebook.com/IndiaToday', 'https://twitter.com/indiatoday', 'https://www.youtube.com/Indiatoday', 'https://www.instagram.com/indiatoday/']",,,,"{'@type': 'SpeakableSpecification', 'cssSelector': ['h1', '.story-kicker']}","{'@type': 'SearchAction', 'target': 'https://www.indiatoday.in/search/{search_term_string}', 'query-input': 'required name=search_term_string'}","{'@type': 'PostalAddress', 'streetAddress': 'FC-8, Ecity Bioscope Rd, Film City', 'addressLocality': 'Sector 16A, Noida', 'addressRegion': 'India', 'postalCode': '201301', 'telephone': '0120 480 7100'}",1200,675,"{'@type': 'Organization', 'name': 'India Today', 'url': 'https://www.indiatoday.in/'}","{'@id': 'https://www.indiatoday.in/author/india-today-web-desk', '@type': 'Person', 'name': 'India Today Web Desk'}"
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC0xMC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yZXNlYXJjaC1jZW50ZXJzLWluLWluZGlhLXRvLXdvcmstd2l0aNIBiAFodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hbXAvc3RvcnkvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvdG9wLTEwLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXJlc2VhcmNoLWNlbnRlcnMtaW4taW5kaWEtdG8td29yay13aXRo?oc=5,Top 10 Artificial Intelligence Research Centers in India to Work with - Analytics Insight,2021-11-02,Analytics Insight,https://www.analyticsinsight.net,,Artificial intelligence research centers,Know about the top ten artificial intelligence research centers in India to work with India has recognized the power of cutting-edge technologies such as artifi,Know about the top ten artificial intelligence research centers in India to work with India has recognized the power of cutting-edge technologies such as artifi,http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-research-centers-in-india-to-work-with,"[{'@type': 'Person', 'givenName': 'Disha Sinha', 'name': 'Disha Sinha', 'url': 'https://www.analyticsinsight.net/author/disha-sinha'}]",,Top 10 Artificial Intelligence Research Centers in India to Work with,,,,,N/A,N/A,What is AI and Data Science Engineering? ,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/11/Top-10-Artificial-Intelligence-Research-Centers-in-India-to-Work-with.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",,,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-research-centers-in-india-to-work-with'}",2021-11-02T08:00:51Z,2021-11-02T08:00:51Z,Artificial Intelligence,Top 10 Artificial Intelligence Research Centers in India to Work with,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 10 Artificial Intelligence Research Centers in India to Work with', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-research-centers-in-india-to-work-with'}]",https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/11/Top-10-Artificial-Intelligence-Research-Centers-in-India-to-Work-with.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"Know about the top ten artificial intelligence research centers in India to work with.India has recognized the power of cutting-edge technologies such as artificial intelligence to boost productivity and enhance the domestic economy. The Government of India has started allocating an annual budget worth millions of dollars for the investment in artificial intelligence research and development. This has motivated groups of scientists and researchers to build artificial intelligence research centres or AI labs to promote this technology field in India. The youths are highly interested to join reputed AI research centres in India to contribute to this advanced field for the welfare of the country. AI research is thriving in the last few years and several educational institutes have started providing specializations in artificial intelligence. Let's explore the top ten artificial intelligence research centres in India to work with a proper team for R&amp;D..Top 10 artificial intelligence research centres in India.Robert Bosch Centre for Data Science and AI at IIT Madras.Robert Bosch Centre for Data Science and AI at IIT Madras is set to work on multiple projects by leveraging data science and artificial intelligence with the largest network analytics, NLP, deep learning, and many more. This artificial intelligence research centre has the vision to become a globally known centre for AI research as well as data science research with cutting across disciplines to create a significant impact on India..NV AI Centre at IIT Hyderabad.NVIDIA has established the first-ever NV AI Centre at IIT Hyderabad to boost AI research on artificial intelligence and commercial applications. This is one of the top artificial intelligence research centres in India where IIT Hyderabad has procured three NVIDIA DGX-1TM systems and two NVIDIA DGX-2TM systems. This AI research is focused on accelerating work on multiple areas of AI..Intel AI Research Centre at IIT Hyderabad.Intel AI Research Centre is collaborating between Intel India and IIT Hyderabad to apply artificial intelligence to scale problems in India and solve multiple challenges in the healthcare and smart mobility sectors. Intel has recognized the potential of AI in India and built an artificial intelligence research centre to train students on essential AI skills. It is a key milestone in the digitalization journey with advanced AI research..AI Innovation Hub at Accenture.Accenture is well-known for providing one of the top artificial intelligence research centres in India in three cities— Bengaluru, Hyderabad, and Pune. This AI Innovation Hub provides access to AI research, labs, studios, and many more to innovation centres and delivery centres with real-life innovation. It also consists of advanced technology centres to deliver innovation through the power of the cloud, automation, artificial intelligence, blockchain, and many more. The AI lab helps to operate at the intersection of business and technology to meet customer satisfaction efficiently and effectively..AI Research Lab at Wipro with IISc.AI Research Lab at Wipro is one of the top artificial intelligence research centres in India focused on healthcare diagnostics, machine learning, artificial intelligence, and deep learning technology. This AI lab is also set to work on digital interfaces to generate sophisticated diagnostic, ophthalmology imaging, and medical image reconstruction techniques efficiently and effectively. The researchers want to help the healthcare sector and doctors enhance patient outcomes with artificial intelligence. IISc is also a well-known educational institution for advanced scientific as well as a technology research lab in India..SCAI by Microsoft Research India .The Centre for Societal impact through Cloud and Artificial Intelligence (SCAI) is launched by Microsoft Research India for creating and validating technologies to have a large-scale impact on India. The AI research centre is dedicated to providing access to researchers and expertise from Microsoft Research and other groups in the company. It is focused on providing financial grants and complete access to top-notch Microsoft researchers. It is known for working with Navana Tech to build text-free and voice-assisted technology..Philips Innovation Centre in Bengaluru.Philips Innovation Centre in Bengaluru is focused on taking India's AI products to the global tech market. This AI research centre helps to transform ideas on artificial intelligence and machine learning into viable and tangible products to improve the economy of India efficiently and effectively. There are more than 2,500 researchers, doctors, engineers, data scientists, and software developers who are focused on healthcare transformation services. This AI lab has created a global innovation hub and a health tech platform to boost productivity and yield more revenue..DAIR at IIT Delhi.Data Analytics and Intelligence Research at IIT Delhi is a well-known AI research group focused on combining as well as integrating multiple fields of data science and artificial intelligence to build intelligent software systems.  The AI research centre helps to build applications of different national and international importance with solutions to fundamental scientific questions. IIT Delhi has started offering specialized courses on artificial intelligence at different levels..CFILT Lab at IIT, Bombay.The Center for Indian Language Technology (CFILT) is one of the top AI labs in India that was set up with a generous grant from the Department of IT, Government of India in 2000 at IIT Bombay. There are around 30 research members in CFILT for PhD, Master's, Bachelors and many more with multiple stresses on semantics to research in lexical resources, shallow parsing, machine translation, cognitive NLP, and many more with the integration of artificial intelligence and NLP..CAIR at DRDO, Ministry of Defence, Government of India.The Centre for Artificial Intelligence and Robotics (CAIR) is one of the top artificial intelligence research centres in India focused on R&amp;D in cutting-edge technologies like artificial intelligence, robotics, and information and communication security. The AI research leads to the development of mission-critical products for battlefield secure communication and information management systems. The AI lab is focused on leveraging the developments in cognitive and AI systems for achieving increased autonomy in unmanned systems..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-artificial-intelligence-research-centers-in-india-to-work-with', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/11/Top-10-Artificial-Intelligence-Research-Centers-in-India-to-Work-with.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,2021-11-02T08:00:51Z,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vamFtYWljYS1nbGVhbmVyLmNvbS9hcnRpY2xlL2J1c2luZXNzLzIwMjExMTA0L2FkdmVydG9yaWFsLWN5YmVyc2VjdXJpdHktYW5kLWFpLXRlY2hub2xvZ2llcy1zaG91bGQtc3VwcG9ydC13b3JrLWhvbWXSAQA?oc=5,ADVERTORIAL | Cybersecurity and AI technologies should support work from home model - Jamaica Gleaner,2021-11-04,Jamaica Gleaner,https://jamaica-gleaner.com,"ADVERTORIAL: MC SYSTEMS While a VPN connection will ensure communication between an endpoint and the securely encrypted corporate network, potential risks still exist as persons working from home/remotely may have access to unsecured networks...",N/A,"ADVERTORIAL: MC SYSTEMS While a VPN connection will ensure communication between an endpoint and the securely encrypted corporate network, potential risks still exist as persons working from home/remotely may have access to unsecured networks...","ADVERTORIAL: MC SYSTEMS While a VPN connection will ensure communication between an endpoint and the securely encrypted corporate network, potential risks still exist as persons working from home/remotely may have access to unsecured networks...",,,,,,,,,,,N/A,N/A,"



 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMilwFodHRwczovL3d3dy5uemhlcmFsZC5jby5uei9zcG9ydC9ib3hpbmcvYm94aW5nLXdvcmxkLWNoYW1waW9uc2hpcC11c2VzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvLXNjcmVlbi1jb3JydXB0aWJsZS1qdWRnZXMvRVFERFdGNERRSk9JWTUyMklZTVRZSUMyUUUv0gEA?oc=5,Boxing: World championship uses artificial intelligence to screen corruptible judges - New Zealand Herald,2021-11-05,New Zealand Herald,https://www.nzherald.co.nz,"Seeking to restore trust in its bouts, the International Boxing Association (AIBA) has used an artificial intelligence system to analyse judges and referees...","boxing,world,championship,uses,artificial,intelligence,to,screen,corruptible,judges,seeking,restore,trust,bouts,international,association,aiba,used,system,analyse,referees,before,they,could,work,current,mens,championships",The super-charged lie detector is being used to help restore credibility in the sport.,The super-charged lie detector is being used to help restore credibility in the sport.,http://schema.org,BreadcrumbList,,[],,Boxing: World championship uses artificial intelligence to screen corruptible judges,,,,,"Boxing, Sport, Technology",N/A,Man praised for refusing to give up seat for new bride,"[{'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/EmQmfnsboXDZog63Eo9sXw9c6GY=/arc-anglerfish-syd-prod-nzme/public/UNS5K7LK44QDBWTGNXCQNT3K3I.jpg'}, {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/v2/UNS5K7LK44QDBWTGNXCQNT3K3I.jpg?auth=aa497c18746d1615831b2969782727ad431563671b23bb6b976604780a445e88&width=576&height=613&quality=70&smart=true'}, {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/v2/UNS5K7LK44QDBWTGNXCQNT3K3I.jpg?auth=aa497c18746d1615831b2969782727ad431563671b23bb6b976604780a445e88&width=768&height=432&quality=70&smart=true'}, {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/v2/UNS5K7LK44QDBWTGNXCQNT3K3I.jpg?auth=aa497c18746d1615831b2969782727ad431563671b23bb6b976604780a445e88&width=992&height=558&quality=70&smart=true'}, {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/v2/UNS5K7LK44QDBWTGNXCQNT3K3I.jpg?auth=aa497c18746d1615831b2969782727ad431563671b23bb6b976604780a445e88&width=1440&height=810&quality=70&smart=true'}]",,,"{'@type': 'NewsMediaOrganization', 'name': 'NZ Herald', 'logo': {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/pb/resources/assets/icons/navigation/site-logo/png/nzh-logo.png'}}","{'@type': 'WebPage', '@id': 'https%3A%2F%2Fwww.nzherald.co.nz%2Fsport%2Fboxing%2Fboxing-world-championship-uses-artificial-intelligence-to-screen-corruptible-judges%2FEQDDWF4DQJOIY522IYMTYIC2QE%2F'}",2024-05-16T07:22:42.612Z,2021-11-05T17:50:00Z,,,true,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.nzherald.co.nz', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.nzherald.co.nz/sport/', 'name': 'Sport'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.nzherald.co.nz/sport/boxing/', 'name': 'Boxing'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://www.nzherald.co.nz/sport/boxing/boxing-world-championship-uses-artificial-intelligence-to-screen-corruptible-judges/EQDDWF4DQJOIY522IYMTYIC2QE/', 'name': 'Boxing: World championship uses artificial intelligence to screen corruptible judges'}}]",,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'nzherald.co.nz', 'productID': 'nzherald.co.nz:NZHfourweekly'}",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RvcC0xMC1haS1qb2Itb3BlbmluZ3MtaW4taW5kaWFuLW1uY3MtdG8tYXBwbHktaW4tbm92ZW1iZXItMjAyMdIBggFodHRwczovL3d3dy5hbmFseXRpY3NpbnNpZ2h0Lm5ldC9hbXAvc3RvcnkvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvdG9wLTEwLWFpLWpvYi1vcGVuaW5ncy1pbi1pbmRpYW4tbW5jcy10by1hcHBseS1pbi1ub3ZlbWJlci0yMDIx?oc=5,Top 10 AI Job Openings in Indian MNCs to Apply in November 2021 - Analytics Insight,2021-11-05,Analytics Insight,https://www.analyticsinsight.net,,"AI job openings,AI job openings in Indian MNCs,AI jobs in India,AI Jobs in November,AI Jobs","Here are 10 AI job openings in top Indian MNCs for AI aspirants in November! Machine learning, artificial intelligence, and data science have overtaken the indu","Here are 10 AI job openings in top Indian MNCs for AI aspirants in November! Machine learning, artificial intelligence, and data science have overtaken the indu",http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/top-10-ai-job-openings-in-indian-mncs-to-apply-in-november-2021,"[{'@type': 'Person', 'givenName': 'Sayantani Sanyal', 'name': 'Sayantani Sanyal', 'url': 'https://www.analyticsinsight.net/author/sayantani-sanyal'}]",,Top 10 AI Job Openings in Indian MNCs to Apply in November 2021,,,,,N/A,N/A,What is AI and Data Science Engineering? ,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/11/Top-10-AI-Job-Openings-in-Indian-MNCs-to-Apply-in-November-2021.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}",,,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-ai-job-openings-in-indian-mncs-to-apply-in-november-2021'}",2021-11-05T03:00:49Z,2021-11-05T03:00:49Z,Artificial Intelligence,Top 10 AI Job Openings in Indian MNCs to Apply in November 2021,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Top 10 AI Job Openings in Indian MNCs to Apply in November 2021', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-ai-job-openings-in-indian-mncs-to-apply-in-november-2021'}]",https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/11/Top-10-AI-Job-Openings-in-Indian-MNCs-to-Apply-in-November-2021.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"Here are 10 AI job openings in top Indian MNCs for AI aspirants in November!.Machine learning, artificial intelligence, and data science have overtaken the industrial landscape rapidly. These technologies are concerned with computer algorithms to improve business efficiency and customer experiences. AI and ML involve developing programs that deal with data and then use the extracted information for themselves. As the need for innovative solutions is increasing to tackle various issues, so is the need for skilled AI professionals. Several talented tech professionals are aiming for jobs in top companies. In this article, we list down the top AI job openings currently by top Indian MNC companies..• Artificial Intelligence Engineer.Offered by: Tata Consultancy Services.The candidates applying for this post should have more than 2 years of experience, with strong programming skills as a Node.js developer. There are several other requirements and qualifications required which include hands-on experience in Jest or other Javascript testing frameworks, designing and implementing low-latency, high-availability, and performance applications, and strong debugging skills, and the ability to use JS debugger, to name a few..• AI Consultant.Offered by: Tech Mahindra.The applicants should have more than 6 years of experience in the relevant field. The selected candidates will become a part of the data analytics and AI team and will be responsible for consulting, solutions, and execution. Their technical skills and business acumen will be used to solve the clients' tactical and strategic problems..• Data Scientist.Offered by: Rolls-Royce.The key responsibilities of the selected candidates include developing new algorithms that involve predictive analytics, advanced statistics, and big data, collaborating with several subject matter experts in the organization for deployment and validation of algorithms on existing products, creating data visualization to provide analytical insights and, other related responsibilities..DURING THE SECOND SURGE, ARTIFICIAL INTELLIGENCE (AI) IS ON THE RISE IN THE HOSPITALITY INDUSTRYTOP 10 INEXPENSIVE AI STOCKS FOR YOUR NOVEMBER INVESTMENTSAN EXCLUSIVE INTERVIEW WITH SRINI VEMULA, FOUNDER OF IGEBRA.AI.• Data Scientist.Offered by: KPMG Global Services (KGS).The candidates applying for this job role should possess a minimum of 7 years of IT industry experience with at least 3 years of experience in Python, NLP, OCR, supervised and unsupervised learning, and other related domains. They have to work closely with the KPMG's Tax functional teams and clients to incorporate cognitive and NLP models into the clients and KPMG's business operations..• AI Scientist.Offered by: Target.The selected candidates will be working closely with the engineers and businesses to build cutting-edge AI systems that can create valuable retail insights and promote exceptional user experiences. Business teams leverage these insights to provide the joy of personalized shopping to the customers. They will also be implementing science solutions in the retail domain..• Data Scientist- Artificial Intelligence.Offered by: IBM.As data scientists, the chosen applicants will be responsible for developing, maintaining, and evaluating AI solutions. They will be involved in designing data solutions using AI-based technologies like Tensorflow, and H2O. They have to possess the skills required in designing algorithms, developing pipelines, validating model performance, and developing interfaces such as APIs..• Data and Applied Scientist 2.Offered by: Microsoft.The global tech company is looking for motivated, self-driven ML engineers and scientists to join its mission to change the world of speech technologies. The candidates should be excellent scientific thinking and execution, have the ability to drive efficient investigations, and research, and should have a passion for new UI paradigms incorporating speech technologies..• AI-based Development in Computer Vision and Automated Driving.Offered by: Bosch Engineering and Business Solutions.Bosch is looking for passionate and experienced engineers who can design algorithms for Level 3-Level 5 autonomous systems. Their responsibilities would include looking at the nature of data, deriving insights or patterns in failures, analyzing the results of the experience, and ensuring delivery of results with accurate quality..• Data Scientist-Engineering.Offered by: Google.The candidates would require a minimum of 2 years of experience in data analysis or related fields, experience in statistical software and database languages, and a master's degree in a qualitative discipline or equivalent practical experience..• Applied AI/ML Analyst .Offered by: JP Morgan Chase and Co.The interested candidates must have a bachelor's degree in legal, business, computer science, and other quantitative fields, previous experience in programming languages, and similar data science roles, excellent analytical and problem-solving skills, and an eagerness to learn rapid prototyping..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/top-10-ai-job-openings-in-indian-mncs-to-apply-in-november-2021', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/11/Top-10-AI-Job-Openings-in-Indian-MNCs-to-Apply-in-November-2021.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,,,,,,2021-11-05T03:00:49Z,,,,,,,,,

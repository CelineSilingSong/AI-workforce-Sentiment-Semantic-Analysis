URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,headline,datePublished,dateModified,isAccessibleForFree,isPartOf,image,author,articleBody,wordCount,publisher,itemListElement,name,alternateName,url,article:section,article:summary,article text,articleSection,mainEntityOfPage,alternativeHeadline,hasPart,copyrightHolder,sourceOrganization,copyrightYear,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,speakable,@graph,dateCreated,inLanguage,thumbnailUrl
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vd3d3LmZ0LmNvbS9jb250ZW50LzI3MzE3MDljLTMwNDMtMTFlOS04NzQ0LWU3MDE2Njk3ZjIyNdIBAA?oc=5,How artificial intelligence helps companies recruit talented staff - Financial Times,2019-02-24,Financial Times,https://www.ft.com,Many HR departments deploy new technological tools to locate potential candidates,N/A,Many HR departments deploy new technological tools to locate potential candidates,N/A,http://schema.org,WebSite,How artificial intelligence helps companies recruit talented staff,2019-02-25T04:00:24.000Z,2019-02-25T04:00:24.000Z,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'Financial Times', 'productID': 'ft.com:subscribed'}","{'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://www.ft.com/__origami/service/image/v2/images/raw/http%3A%2F%2Fcom.ft.imagepublish.upp-prod-eu.s3.amazonaws.com%2F648d6992-3533-11e9-bb0c-42459962a812?source=next-article&fit=scale-down&quality=highest&width=700&dpr=1', 'width': 2048, 'height': 1152}","[{'@type': 'Person', '@context': 'http://schema.org', 'name': 'Emma Jacobs', 'url': 'https://www.ft.com/emma-jacobs', 'worksFor': {'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}}]","When Pitney Bowes, a business services company, recently opened an ecommerce fulfilment centre with the capacity to process up to 44,000 parcels per hour, it also had to substantially increase the workforce. To do so, it used artificial intelligence.

It works as follows: after candidates arrive at the company’s careers webpage, they are greeted by a chatbot which shows them positions opening in their area and then takes them through the pre-selection process. This includes questions such as, “Are you able to lift 50 pounds?” “Do you prefer working a day shift or are you flexible?”

It can then schedule an interview and send an email invitation. Brigitte Van Den Houte, vice-president, global talent management at Pitney Bowes, describes the chatbot’s tone as “welcoming”.

She says: “For areas where we have a high-volume recruitment challenge, AI has helped us to scale efficiently without having to temporarily deploy additional recruiters.” The use of such tech, the company says, has helped reduce the time to fill some positions by 10 per cent — or nine days.

A growing number of human resources departments are deploying these technological tools to find recruits. A host of recruitment tech start-ups have sprung up to meet this need. Barry Flack, an HR tech consultant, says that these have been attractive to investors as they promise to solve a problem they “have all experienced”.

New ventures include some that search online and in databases for matching candidates, sifting through vast quantities of applications and using machine learning. “Finding matched profiles has become easier,” says Mr Flack.

Then there are chatbots that can answer candidates’ rudimentary questions and help screen applications at the first stages (for example, basic technical and experience requirements and legalities such as the right to work). Further down the recruitment funnel, there are online assessments using game theory and psychological profiling.

Some employers are deploying video interviews and others use basic AI to help discern if candidates are “confident” or “passionate”.

Candidate relationship management tools have also grown in recent years. These help employers market their brand to prospects who might be interested in applying and nurture potential candidates with campaigns and communications, hoping to convert them into applicants.

Such tools have shaken up recruitment. A working article entitled “Artificial Intelligence in Human Resources Management” argues that the “speed with which the business rhetoric in management moved from big data to machine learning to artificial intelligence is staggering. The match between the rhetoric and reality is a different matter, however.”

One of the biggest HR tech claims is that technology can sift through applicants to find the best fit, free of human prejudices. Alistair Cox, chief executive of Hays, the recruiter, wrote in a blog post: “as well as increasing efficiency, automating sections of the screening phase can also lead to a decrease in subconscious hiring bias”.

Peter Cappelli, director of the centre for human resources at the Wharton School, University of Pennsylvania, and one of the authors of the article, is sceptical. “Any kind of structure eliminates bias. If you told employers to standardise the questions they ask that [would] eliminate the bias. A lot of [tech] imposes structure on the hiring process.”

As the oft-cited example of Amazon shows, technology can be as biased as humans if it replicates past hiring decisions. The tech group had to abandon its AI recruitment tool when it realised it discriminated against women because it tried to find candidates much like its current workforce: in other words, men. Decisions made by algorithm may also make a company more vulnerable to legal action, argues Prof Capelli, because the assumptions driving hiring decisions are clearly set out.

Technology can also require considerable finessing. Deloitte’s Human Capital report described one tech vendor as having “taken over a year to train its chatbot to intelligently screen hourly job candidates”.

Andrew Chamberlain, chief economist at Glassdoor, the jobs review site, says that automating trawls through the internet, looking for recruits on LinkedIn and other online platforms, has drawbacks. “Not all candidates show their best side [online]. They get left out of searches.”

Some candidates, by contrast, are brilliant at it, says David D’Souza, membership director at CIPD, the human resources professional body, citing LinkedIn profiles: “Everyone is ‘strategic’, everyone is ‘good with people’ and everyone is ‘proactive’. At the point that everyone becomes all those things you lose the ability to differentiate.”

Other products are focused on building a pipeline of interested candidates — including those that have failed previous applications and ones who register interest on an employer’s website. It will then market the company to candidates, and build a relationship. One such tool is Beamery, which calls itself a talent engagement platform. It gauges a candidate’s interest in the company or job (for example, if they open an email from the company) to determine whether they are ready to pursue a role.

Products that allow a recruiter to keep in touch with failed — or potential — candidates can be useful. However, Prof Cappelli says: “Don’t kid yourself that this is a relationship, that the company really cares about you.” Moreover, the risk is that they bombard people with marketing material. “If you are the first mover it’s a smart thing to do but not the 20th.”

“One of the things that people have always valued is human connection, whether with a boss, or clear feedback at the end of a process,” says Mr D’Souza. “Part of the challenge with tech is that it’s more efficient but it reduces human contact. People want speed and convenience, ideally from a person.”

The candidate’s experience is critical, agrees Bill Boorman, who advises recruitment tech start-ups. They want to understand the process and receive feedback. “They don’t want it to be painful.”

Ultimately, as with automation of other white-collar jobs, the hope is that technology reduces repetitive tasks. Matt Weston, UK managing director of Robert Half, the recruiter, says: “It’s really important to get the balance with the human technology. At the end of the day HR is a personal department that can’t be too automated.”

Prof Cappelli says that in an age of techno-hype, there is an expectation that machines will solve the recruitment problem. “In a typical company you can persuade the CFO to buy software. Does it work? Probably not.”

The technology might even be making things worse. When companies use a new tool, says Mr Chamberlain, they tend to overuse it. New technology makes it easy to add extra tests.

“The time for the interview process has got much longer . . . They are making people jump through more hoops,” he says.

“It’s not clear that it’s improving the match of candidates. It will take trial and error to see what tech really delivers on these promises.”

Without reform, AI could complicate recruitment / From Curtis Fields, Revere, MA, US",1160.0,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}","[{'@type': 'ListItem', 'position': 1, 'name': 'Companies', 'item': 'https://www.ft.com/companies'}, {'@type': 'ListItem', 'position': 2, 'name': 'Professional services', 'item': 'https://www.ft.com/professional-services'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial intelligence', 'item': 'https://www.ft.com/artificial-intelligence'}]",Financial Times,FT.com,http://www.ft.com,N/A,N/A,"© FT illustrationHow artificial intelligence helps companies recruit talented staff on x (opens in a new window)How artificial intelligence helps companies recruit talented staff on facebook (opens in a new window)How artificial intelligence helps companies recruit talented staff on linkedin (opens in a new window)How artificial intelligence helps companies recruit talented staff on whatsapp (opens in a new window)



Save

current progress 0%How artificial intelligence helps companies recruit talented staff on x (opens in a new window)How artificial intelligence helps companies recruit talented staff on facebook (opens in a new window)How artificial intelligence helps companies recruit talented staff on linkedin (opens in a new window)How artificial intelligence helps companies recruit talented staff on whatsapp (opens in a new window)



Save

Emma JacobsFebruary 24 201929Print this pageStay informed with free updatesSimply sign up to the Work & Careers myFT Digest -- delivered directly to your inbox.When Pitney Bowes, a business services company, recently opened an ecommerce fulfilment centre with the capacity to process up to 44,000 parcels per hour, it also had to substantially increase the workforce. To do so, it used artificial intelligence. 
It works as follows: after candidates arrive at the company’s careers webpage, they are greeted by a chatbot which shows them positions opening in their area and then takes them through the pre-selection process. This includes questions such as, “Are you able to lift 50 pounds?” “Do you prefer working a day shift or are you flexible?” 
It can then schedule an interview and send an email invitation. Brigitte Van Den Houte, vice-president, global talent management at Pitney Bowes, describes the chatbot’s tone as “welcoming”.
She says: “For areas where we have a high-volume recruitment challenge, AI has helped us to scale efficiently without having to temporarily deploy additional recruiters.” The use of such tech, the company says, has helped reduce the time to fill some positions by 10 per cent — or nine days.
A growing number of human resources departments are deploying these technological tools to find recruits. A host of recruitment tech start-ups have sprung up to meet this need. Barry Flack, an HR tech consultant, says that these have been attractive to investors as they promise to solve a problem they “have all experienced”. 
New ventures include some that search online and in databases for matching candidates, sifting through vast quantities of applications and using machine learning. “Finding matched profiles has become easier,” says Mr Flack.
Then there are chatbots that can answer candidates’ rudimentary questions and help screen applications at the first stages (for example, basic technical and experience requirements and legalities such as the right to work). Further down the recruitment funnel, there are online assessments using game theory and psychological profiling. 
Some employers are deploying video interviews and others use basic AI to help discern if candidates are “confident” or “passionate”.
Candidate relationship management tools have also grown in recent years. These help employers market their brand to prospects who might be interested in applying and nurture potential candidates with campaigns and communications, hoping to convert them into applicants.
Such tools have shaken up recruitment. A working article entitled “Artificial Intelligence in Human Resources Management” argues that the “speed with which the business rhetoric in management moved from big data to machine learning to artificial intelligence is staggering. The match between the rhetoric and reality is a different matter, however.” 
One of the biggest HR tech claims is that technology can sift through applicants to find the best fit, free of human prejudices. Alistair Cox, chief executive of Hays, the recruiter, wrote in a blog post: “as well as increasing efficiency, automating sections of the screening phase can also lead to a decrease in subconscious hiring bias”. 
Peter Cappelli, director of the centre for human resources at the Wharton School, University of Pennsylvania, and one of the authors of the article, is sceptical. “Any kind of structure eliminates bias. If you told employers to standardise the questions they ask that [would] eliminate the bias. A lot of [tech] imposes structure on the hiring process.”
As the oft-cited example of Amazon shows, technology can be as biased as humans if it replicates past hiring decisions. The tech group had to abandon its AI recruitment tool when it realised it discriminated against women because it tried to find candidates much like its current workforce: in other words, men. Decisions made by algorithm may also make a company more vulnerable to legal action, argues Prof Capelli, because the assumptions driving hiring decisions are clearly set out.
RecommendedTechnologyJames Vlahos on voice technology
Technology can also require considerable finessing. Deloitte’s Human Capital report described one tech vendor as having “taken over a year to train its chatbot to intelligently screen hourly job candidates”.
Andrew Chamberlain, chief economist at Glassdoor, the jobs review site, says that automating trawls through the internet, looking for recruits on LinkedIn and other online platforms, has drawbacks. “Not all candidates show their best side [online]. They get left out of searches.”
Some candidates, by contrast, are brilliant at it, says David D’Souza, membership director at CIPD, the human resources professional body, citing LinkedIn profiles: “Everyone is ‘strategic’, everyone is ‘good with people’ and everyone is ‘proactive’. At the point that everyone becomes all those things you lose the ability to differentiate.”
Other products are focused on building a pipeline of interested candidates — including those that have failed previous applications and ones who register interest on an employer’s website. It will then market the company to candidates, and build a relationship. One such tool is Beamery, which calls itself a talent engagement platform. It gauges a candidate’s interest in the company or job (for example, if they open an email from the company) to determine whether they are ready to pursue a role. 
Products that allow a recruiter to keep in touch with failed — or potential — candidates can be useful. However, Prof Cappelli says: “Don’t kid yourself that this is a relationship, that the company really cares about you.” Moreover, the risk is that they bombard people with marketing material. “If you are the first mover it’s a smart thing to do but not the 20th.”
RecommendedPilita ClarkThe job interview of the future is here 
“One of the things that people have always valued is human connection, whether with a boss, or clear feedback at the end of a process,” says Mr D’Souza. “Part of the challenge with tech is that it’s more efficient but it reduces human contact. People want speed and convenience, ideally from a person.”
The candidate’s experience is critical, agrees Bill Boorman, who advises recruitment tech start-ups. They want to understand the process and receive feedback. “They don’t want it to be painful.” 
Ultimately, as with automation of other white-collar jobs, the hope is that technology reduces repetitive tasks. Matt Weston, UK managing director of Robert Half, the recruiter, says: “It’s really important to get the balance with the human technology. At the end of the day HR is a personal department that can’t be too automated.” 
Prof Cappelli says that in an age of techno-hype, there is an expectation that machines will solve the recruitment problem. “In a typical company you can persuade the CFO to buy software. Does it work? Probably not.”
The technology might even be making things worse. When companies use a new tool, says Mr Chamberlain, they tend to overuse it. New technology makes it easy to add extra tests.
“The time for the interview process has got much longer . . . They are making people jump through more hoops,” he says. 
“It’s not clear that it’s improving the match of candidates. It will take trial and error to see what tech really delivers on these promises.”
Recruitment tech to help weed out bad hires
Some recruitment tech is working with psychologists to devise psychological quizzes to discover the motivations or personality types of a candidate or employee. 
Attuned is one such company that offers its product for both recruitment and retention. It asks the person taking a test to answer a series of questions, to find out if they are motivated by things such as money or a desire for autonomy, to see if they are a good fit with their team or company.
Casey Wahl, the founder, says that one recruitment company that used it for hiring found that they reduced the number of bad hires — so that instead of 30 per cent of recruits leaving within six months, it was only 10 per cent.


Letter in response to this article:
Without reform, AI could complicate recruitment / From Curtis Fields, Revere, MA, US
Copyright The Financial Times Limited 2024. All rights reserved.Reuse this content (opens in new window) CommentsJump to comments section








Promoted ContentLatest on Work & CareersFT GlobetrotterA day on the farm with chef Simon RoganSouthern Water LtdSouthern Water pays chief £183,000 bonus after proposing 73% rise in customer billsFT GlobetrotterEasy rider: exploring central Switzerland by e-bike from Zürich Rutherford HallWhat’s the point of war if you can’t make money from it?Legal servicesDiverse lawyers used as ‘window dressing’ in client pitches, poll findsPilita ClarkThe odd and embarrassing causes of leisure sicknessWork & CareersDegrees for free: the employers funding tuition for staffCitigroup IncCiti’s new head of banking granted $40mn in stock

					Follow the topics in this article
			



						Recruitment
					



Add to myFT




						Work & Careers
					



Add to myFT




						Recruitment services
					



Add to myFT




						Artificial intelligence
					



Add to myFT




						Technology
					



Add to myFT



Comments






",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LmluZm93b3JsZC5jb20vYXJ0aWNsZS8zMzM5NTYxL2FpLW1hY2hpbmUtbGVhcm5pbmctYW5kLWRlZXAtbGVhcm5pbmctZXZlcnl0aGluZy15b3UtbmVlZC10by1rbm93Lmh0bWzSAXRodHRwczovL3d3dy5pbmZvd29ybGQuY29tL2FydGljbGUvMzMzOTU2MS9haS1tYWNoaW5lLWxlYXJuaW5nLWFuZC1kZWVwLWxlYXJuaW5nLWV2ZXJ5dGhpbmcteW91LW5lZWQtdG8ta25vdy5hbXAuaHRtbA?oc=5,"AI, machine learning, and deep learning: Everything you need to know - InfoWorld",2019-02-21,InfoWorld,https://www.infoworld.com,"All about the business benefits, technology frameworks and models, and application of artificial intelligence for better business outcomes",N/A,"All about the business benefits, technology frameworks and models, and application of artificial intelligence for better business outcomes","All about the business benefits, technology frameworks and models, and application of artificial intelligence for better business outcomes",,,,,,,,,,,,,,,,,N/A,N/A,"










		All about the business benefits, technology frameworks and models, and application of artificial intelligence for better business outcomes	




 
Credit: Gerd Altmann








There’s a lot of marketing buzz and technical spin on artificial intelligence, machine learning, and deep learning. Most of what’s out there is either too fluffy or too mathy, either too general or too focused on specific applications, too disconnected from business outcomes and metrics, and too undirected.
This article provides an overview of these related technologies by:

Defining AI, machine learning, and deep learning, explaining the differences from traditional approaches, describing when to use them, and noting their advantages and disadvantages.
Explaining how they complement business frameworks and enable business outcomes and metrics.
Describing common types of machine learning and deep learning model training, algorithms, architectures, performance assessments, and obstacles to good performance.
Providing examples of machine learning models and algorithms at work.
Presenting a potential framework for AI implementation for business outcomes.


Jerry Hartanto leads the AI and Self-Service BI Practice at Trace3, a technology solution provider with growing consulting practices including data intelligence, cloud solutions, cyber analytics, devops, and data center solutions. Hartanto’s background is in management consulting, corporate/business strategy, marketing and sales, operations and process improvement, and product development and engineering. He has a BS in Electrical Engineering from McGill University, an MS in Electrical Engineering from Johns Hopkins University, and an MBA from the University of Michigan. He can be reached at jhartanto@trace3.com. This article and its figures are adapted from a presentation given at the Southland Technology Conference (SoTec) in November 2018 and used with permission of Trace3.

Why AI: AI in the business context
All organizations work to specific outcomes, and they juggle several business metrics and processes to achieve this, such as revenue, costs, time to market, process accuracy, and efficiency. Yet they have limited resources (money, time, people, and other assets). So, the problem boils down to making good decisions about resource allocation (what kind of resources, how many/much of them, what should they do, what capabilities do they need, etc.), and making those good decisions faster than competitors and faster than the market is changing.











 
 
 
Making these decisions is hard, but clearly, they become much, much easier when data, information, and knowledge are available. Assuming these inputs are available, they need to be aggregated and mined for nuggets. Analysts need time to pull tribal knowledge out of subject matter experts’ heads, to adjust to fluctuating business rules, to calibrate for personal biases where possible, and to spot patterns and to generate insights. Ideally, analysts and managers should (time permitting) assess multiple scenarios and run several experiments to increase confidence in their recommendations and decisions. Finally, the decisions need to be operationalized.
More Videos0 seconds of 9 minutes, 8 secondsVolume 0%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledShortcuts Open/Close/ or ?Play/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


Next UpHow to manage logins and users for a Django website using Python08:22SettingsOffAutomated Captions - en-USFont ColorWhiteFont Opacity100%Font Size100%Font FamilyArialCharacter EdgeNoneBackground ColorBlackBackground Opacity50%Window ColorBlackWindow Opacity0%ResetWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%200%175%150%125%100%75%50%ArialCourierGeorgiaImpactLucida ConsoleTahomaTimes New RomanTrebuchet MSVerdanaNoneRaisedDepressedUniformDrop ShadowWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%WhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%







Live00:0009:0809:08 

Enter AI, machine learning, and deep learning, which:

Model the organization based on observations.
Generate insights by simultaneously reviewing lots of factors and variables (far more than a person can achieve in a reasonable time period and cost constraint).
Learn continuously as new observations are provided.
Quantify the likelihood of outcomes (that is, predict what is likely to happen).
Prescribe specific actions to optimize the business goals and metrics.
Adjust rapidly to new business rules through faster retraining versus traditional slower reprogramming.

What makes AI, machine learning, and deep learning possible now is the proliferation of data volume and data types coupled with the lower costs of compute and storage hardware and tools. Web-scale companies (such as Facebook, Google, Amazon, and Netflix) have proven it works, and they are being followed by organizations in all industries. Combined with business intelligence, the trio of artificial intelligence, machine learning, and deep learning overcomes obstacles to decisioning, thereby facilitating organizations to achieve their business goals, as Figure 1 shows.











 
 
 
 Trace3

Figure 1: How to improve business decisioning with AI.



More AI deep dives from InfoWorld

What AI can really do for your business (and what it can’t)
Artificial general intelligence (AGI): The steps to true AI
Powering AI: The explosion of new AI hardware accelerators
How to tell if AI or machine learning is real


AI, machine learning, and deep learning apply to everyone in metrics-driven organizations and businesses.
In its May 2011 publication “Big Data: The Next Frontier for Innovation, Competition, and Productivity,” McKinsey Global Institute stated that the gap for managers and analysts who know how to use the results of analytics stood at 1.5 million, an order of magnitude more than for those who produce the analytics (such as data analysts and data scientists).
Put another way, the chokepoint in the data value chain is not the data or the analytics; it’s the ability to consume the data/analytics in context and in an intelligent way for surgical action. This is an opportunity for business and process professionals to marry AI, machine learning, and deep learning to the business frameworks and concepts already understood so well. It’s a chance to define problems and hypotheses within those frameworks and concepts, and then to use AI, machine learning, and deep learning to find patterns (insights) and to test hypotheses that take too long to test, would otherwise be too expensive to identify and test, or are too difficult for people to carry out, as Figure 2 shows.











 
 
 
 Trace3

Figure 2: AI complements business frameworks and issues.


Organizations and businesses are increasingly turning to AI, machine learning, and deep learning because, quite simply, business is becoming more complex. There are too many things occurring at one time for us people to process; that is, there are too many data points (both relevant and not-so-relevant) for us to synthesize. Looked at it this way, too much data can be a liability (analysis paralysis, anyone?).
But AI, machine learning, and deep learning can turn that pile of data into an asset by systematically determining its importance, predicting outcomes, prescribing specific actions, and automating decision making. In short, AI, machine learning, and deep learning enable organizations and businesses to take on the factors driving business complexity, among them:

Value chains and supply chains that are more global, intertwined, and focused on microsegments.
Business rules that rapidly change to keep pace with competitors and customer needs and preferences.
Correct forecasting and deployment of scarce resources to optimize competing projects/investments and business metrics.
Need to simultaneously drive towards both increased quality and customer experience while reducing costs.

In many ways, AI, machine learning, and deep learning are superior to explicit programming and traditional statistical analysis:











 
 
 

The business rules don’t really need to be known to achieve the targeted outcome—the machine just needs to be trained on example inputs and outputs.
If the business rules change such that the same inputs no longer result in the same outputs, the machine just needs to be retrained—not reprogrammed—allecelerating response times and alleviating people of the need to learn new business rules.
Compared to traditional statistical analysis, AI, machine learning, and deep learning models are relatively quick to build, so it’s possible to rapidly iterate through several models in a try-learn-retry approach.


However, AI, machine learning, and deep learning do have disadvantageous, as Figure 3 shows. Among them, they are still based on statistics, so there is an element of uncertainty in the output. This makes the integration of AI, machine learning, and deep learning into the workflow tricky because high ambiguity in the machine’s decisions should likely be handled by a person. And to improve the machine’s accuracy, mistakes (and right answers) should be fed back to the machine to be used for additional training (learning).
Additionally, AI, machine learning, and deep learning models can be less interpretable; that is, it may not be clear how they arrive at their decisions. This is particularly true of complex deep learning models with many “layers” and “neurons”; such lack of clarity may be of particular concern in highly regulated industries. It should be noted that there is a lot of research focused in this area, so perhaps it won’t be a disadvantage in the future.
 Trace3

Figure 3: AI, machine learning, and deep learning advantages, disadvantages, and drivers.


Given the advantages and disadvantages, when might it be appropriate to use AI, machine learning, and deep learning? Here are some ideas:











 
 
 

The juice is worth the squeeze: There’s a high-potential business outcome but traditional approaches are too cumbersome, time-consuming, or just not appropriate.
Relevant data is available and accessible.
Subject matter experts believe the data contain meaningful signal (that is, insight can be gleaned from the data).
The problem definition ties to a machine learning or deep learning problem, such as classification, clustering, or anomaly detection.
The success of use cases can be mapped to machine learning and deep learning model performance metrics, such as precision-recall and accuracy.

AI defined: The natural progression from BI to AI
AI, machine learning, and deep learning are a natural progression of business intelligence. Where BI describes and diagnoses past events, AI, machine learning, and deep learning try to predict the likelihood of future events and prescribe how to increase the likelihood of those events actually occurring. A simple example illustrating this is the GPS guiding you from point A to point B:

Description: What route did the vehicle take, and how long did it take?
Diagnosis: Why did the vehicle take a long time at a particular traffic light (assuming the GPS platform/tool tracks things like accidents and vehicle volume)?
Prediction: If a vehicle is going from point A to point B, what is the expected ETA?
Prescription: If a vehicle is going from point A to point B, what route should the vehicle take to achieve the expected ETA?

Prediction in AI
One example of prediction is sentiment analysis (the probability of someone liking something). Let’s assume you can track and store the textual content of any user posting (such as tweets, updates, blog articles, and forum messages). You can then build a model that predicts the user’s sentiment from his or her postings.
Another example is increasing customer conversion: people are more likely to sign up for subscriptions if they’re offered a chance to win a prize they want—so you can predict which prizes will lead to the highest number of conversions.











 
 
 
Prescription in AI
Prescription is about optimizing business metrics in various processes, such as marketing, sales, and customer service, and it’s accomplished by telling the prescriptive analytics system what metrics should be optimized. This is like telling the GPS what you want to optimize, such as least fuel consumption, fastest time, lowest mileage, or passing by the largest number of fast-food joints in case you get a craving for something. In a business setting, you might target increased conversion by 10 percent, sales by 20 percent, or net promoter score (NPS) by five points.
From there, the prescriptive analytics system would prescribe a sequence of actions that leads to the corresponding business outcomes you want.
Say you want to achieve a 10-percent conversion lift. The system may prescribe:











 
 
 

Reducing the frequency of your direct mail marketing by 15 percent, while
simultaneously increasing your Twitter and Facebook engagements by 10 and 15 percent, respectively, then
when your aggregate social media engagement reaches 12 percent, start directing the public to your customer community portal for customer-to-customer engagement.

These prescriptive actions are like the turns that your GPS system advises you to take during the journey to optimize the goal you set.





Sponsored Content
by Digital Realty






Ahead of the curve on advanced cooling for AI & HPC

By Digital Realty


Jun 24, 2024





The relationship among BI, statistics, and AI
Here’s one way to define the difference among BI, statistics, and AI:

BI is traditionally query-oriented and relies on the analyst to identify the patterns (such as who are the most profitable customers, why are they the most profitable, and what attributes that set them apart, such as age or job type).
Statistics also relies on the analyst to understand the properties (or structure) of the data to find information about the population in the data, but it adds mathematical rigor in extrapolating to generalization (such as if there is a difference between these customer segments in real life versus what is found in the sample data).
AI, machine learning, and deep learning rely on algorithms (not analysts) to autonomously find patterns in the data and enable prediction and prescription.

 Trace3

Figure 4: AI, machine learning, and deep learning complement BI.


Please note that BI, statics, and AI, machine learning, and deep learning can do more than what is described in Figure 5; this example simply demonstrates how these methods can answer a series of progressive business questions.











 
 
 
 Trace3

Figure 5: Integrating BI, statistical analysis, predictive AI, machine learning, and deep learning.


While statistical modeling on one side and machine learning and deep learning on the other are both used to build models of the business situation, there are some key differences between the two, as Figure 6 shows. In particular:

Statistical modeling requires a formal mathematical equation between the inputs and outputs. In contrast, machine learning and deep learning don’t try to find that mathematical equation; instead they simply try to re-create the output given the inputs.
Statistical modeling requires an understanding between the variables and makes assumptions about the statistical properties of the data population. Machine learning and deep learning do not.

 Trace3

Figure 6: Statistical modeling vs. machine learning.



More deep learning deep dives from InfoWorld

Explainable AI: Peering inside the deep learning black box
What is deep reinforcement learning: The next step in AI and deep learning
PyTorch tutorial: Get started with deep learning in Python
What is Keras? The deep neural network API explained


Typically, because statistical modeling requires a mathematical equation and an understanding of the relationships among the data, statistical models take a relatively long time to build as the statistician studies and works with the data. But if completed successfully—that is, the equation is found and the statistical relationships among the data are very well understood—the model can be killer.
Machine learning and deep learning models, on the other hand, are very fast to build but may not achieve high performance to start. But because they are so easy to construct in the early stages, many algorithms can be tried simultaneously with the most promising of them continuously iterated until model performance becomes extremely good.











 
 
 
Machine learning and deep learning models also have the added advantage of continuously learning from new data “on their own,” and thus improving their performance.
Should the nature of the data change, the machine learning and deep learning models simply need to be retrained on the new data; whereas the statistical models typically need to be rebuilt in whole or in part.
Machine learning and deep learning models also excel in solving highly nonlinear problems (it’s just harder for people to do this—those equations get very long!). This attribute of machine learning and deep learning really comes in handy as microsegments become the norm (think customer segments of one, mass customization, personalized customer experience, and personal and precision medicine), and processes and root-cause analysis becomes increasingly multifactored and interdependent.











 
 
 
How AI, machine learning, and deep learning differ
So far, I have lumped together AI, machine learning, and deep learning together. But they are not exactly the same, as Figure 7 shows.
 Trace3

Figure 7: AI vs. machine learning vs. deep learning.


Generally speaking:





Sponsored Content
by Zscaler






Why an AI-driven strategy is a must to defend against today’s cyberthreats

By Zscaler


May 21, 2024





AI is where machines perform tasks that are characteristic of human intelligence. It includes things like planning, understanding language, recognizing objects and sounds, learning, and problem solving. This can be in the form of artificial general intelligence (AGI) or artificial narrow intelligence (ANI).











 
 
 

AGI has all the characteristics of human intelligence, with all our senses (maybe even more) and all our reasoning, and so can think just like we do. Some describe this as “cognitive”—think C3PO and the like.
ANI has some facets of human intelligence but not all; it’s used to perform specific tasks. Examples include image classification in a service like Pinterest and face recognition on Facebook. ANI is the current focus of most business applications.

Machine learning is where machines use algorithms to learn and execute tasks without being explicitly programmed (that is, they do not have to be provided specific business rules to learn from the data; put another way, they don’t need instructions such as “if you see X, do Y”).
Deep learning is a subset of machine learning, generally using artificial neural networks. The benefit of deep learning is that in theory it does not need to be told what data elements (or “features” in machine learnig speak) are important, but most of the time, it needs large amounts of data.
Figure 8 shows the timeline of AI’s evolution.











 
 
 
 Trace3

Figure 8: AI’s historical timeline.


The differences among explicit programming, machine learning, and deep learning can be better understood through the example of handwritten number recognition. To a person older than five years old, recognizing handwritten numbers isn’t hard. We’ve learned (been trained) over the years by parents, teachers, siblings, and classmates.
Now imagine getting a machine to do the same through explicit programming. In explicit programming, you have to tell the machine what to look for. For example, a round object is a zero, a line that goes up and down is a one, and so on. But what happens if the object isn’t perfectly round, or the ends don’t touch so it’s not fully round? What happens when the line doesn’t go up and down but instead tips sideways, or if the top part of the line has a hook (like “1”)—is it now closer to 7? The many variations of handwritten letters make it difficult to write an explicit program; you would be consistently adding new “business rules” to account for the variations.
As Figure 9 shows, in the machine learning approach, you would show the machine examples of 1s, 2s, etc., and tell it what “features” (important characteristics) to look for. This feature engineering is important because not all characteristics are important. Examples of important characteristics might be number of closed loops, number of lines, direction of lines, number of line intersections, and positions of intersections. Examples of unimportant characteristics might be color, length, width, and depth. Assuming you feed the machine the right features and provide it with examples and answers, the machine would eventually learn on its own how important the features are for the different numbers, and then hopefully be able to distinguish (or classify) the numbers correctly.
Notice that with machine learning you have to tell the machine the important features (that is, what to look for), so the machine is only as good as the person identifying the appropriate features.











 
 
 
The promise of deep learning is that no one has to tell the machine what features to use (that is, which ones are most important)—it will automatically figure this out. All you need to do is to feed it all the features from which it will select the important features on its own. While this an obvious advantage, it comes at a price in the form of high-data-volume requirement and long training time that requires significant computational processing capabilities.
 Trace3

Figure 9: Explicit programming vs. machine learning and deep learning: handwritten-number recognition.


AI model concepts: an overview
The idea behind machine learning and deep learning models is they learn from data they are given (things they have seen before), and then can generalize to make good decisions on new data (things they have not seen before).
But what constitutes a model? One definition of models is that they consist of three components:

Data: Historical data is used to train the model. For example, when learning to play the piano, the data you are fed is different notes, different types of music, different composer styles, etc.
Algorithms: General rules that models use for the learning process. In the piano example, your internal algorithm might tell you to look for the musical notes, how to move your hands on the keys, how and when to press the pedals, etc. Figure 10 shows the relationship between models and algorithms.
Hyperparameters: These are “knobs” that data scientists adjust to improve the model performance, and they are not learned from the data. Again using the piano example, hyperparameters include how often you practice the musical piece, where you practice, time of day you practice, piano you use for practice, etc. The thinking is that adjusting these “knobs” improves your ability to learn how to play the piano.

When you put all of this together, you become a piano-playing model. In theory, depending on how well you’re trained, new musical pieces you’ve never seen before could be placed in front of you and you’d be able to play them.
 Trace3

Figure 10: Relationship between models and algorithms.


Types of machine learning
Machines, just like people, can learn in different ways, as Figure 11 shows. I’ll again use the piano-training analogy to explain:

Supervised: Your instructor shows or tells you both the right way and the wrong way to play. In an ideal situation, you are given equal numbers of examples of how to play the right and wrong ways. Essentially, the training data consists of a target/outcome variable (or dependent variable) that is to be predicted from a set of predictors (independent variables). Using these sets of variables, you generate a function that maps inputs to desired outputs. The training process continues until the model achieves a desired level of performance on the training data. A business example of supervised training is showing the system examples of loan applications (consisting of predictors like credit history, work history, asset ownership, income, and education) that were approved or rejected (the target outcomes and decisions).
Unsupervised: You’re on your own—nobody tells how you to play, so you make up your own ideas of right and wrong, with the goal of optimizing a parameter that’s important to you, such as speed of finishing the piece, the ratio of loud notes to soft notes, or number of unique keys you touch. Essentially, data points have no labels associated with them to inform you right or wrong. Instead, the goal is to organize the data in some way or to describe its structure. This can mean grouping it into clusters or finding different ways of looking at complex data so that it appears simpler or more organized. Unsupervised learning is usually less effective at training the model than supervised learning, but it may be necessary when no labels exist (in other words, the “right” answers are not known). A common business example is market segmentation: It’s frequently unclear what the “right” maret segments are, but every marketer is looking for segments of natural affinities so they can approach those segments with just the right message, prootions, and products.
Semisupervised: A combination of supervised and unsupervised. This is used where there is not enough supervised data. In the piano example, you would receive some instruction but not a lot (maybe because lessons are expensive or there aren’t enough teachers).
Reinforcement: You’re not told what the right and wrong way to play is, and you don’t know what parameter you’re trying to optimize, but you are told when you do something right or wrong. In the case of piano training, your teacher might hit your knuckles with a ruler when you play the wrong note or play with the wrong tempo, and she gives you a backrub when you play things well. Reinforcement learning is very popular right now because, in several situations, there isn’t enough supervised data available for every scenario, but the “right” answer is known. For example, in the game of chess, there are too many permutations of moves to document (label). But reinforcement learning still lets tells the machine when it makes right and wrong decisions that advance to ward winning (such as capturing pieces and strengthening positions in chess).
Transfer learning: You use your knowledge of playing the piano to learn another instrument because you’ve built certain transferable skills (such as the ability to read notes and maybe even developing nimbleness in your hands) that you can build on to learn how to play the trumpet. Transfer learning is used because it reduces learning time, which can be significant (several hours or even several days) for models that use deep learning architectures.

 Trace3

Figure 11: Modeling: common types of learning/training.


Common machine learning algorithms
As Figure 12 shows, common algorithm types include:

Regression is simply drawing a curve or line through data points.
Classification is determining to what group something belongs. Binary classification (two groups) is determining if something belongs to a class or not, such as whether the animal in the picture is a dog or not. Sticking with the animal example, multiclass classification (more than two groups) is whether the animal is a dog, cat, bird, etc.
Clustering is similar to classification, but you don’t know the classifications ahead of time. Again using the examples of animal pictures, you may determine that there are three types of animals, but you don’t know what those animals are, so you just divide them into groups. Generally speaking, clustering is used when there is insufficient supervised data or when you want to find natural groupings in the data without being constrained to specific groups, such as dogs, cats, or birds.
Time series assumes that the sequence of data is important (that the data points taken over time have an internal structure that should be accounted for). For example, sales data could be considered time-series because you may want to trend revenue over time to detect seasonality and to correlate it with promotion events. On the other hand, the order of your animal pictures doesn’t matter for classification purposes.
Optimization is a method of achieving the best value for multiple variables when they do not move in the same direction.
NLP (natural language processing) is the general category of algorithms that try to mimic human use and understanding of languages, such as chatbots, scrubbing unstructured writing like doctor’s notes for key data fields, and autonomous writing of news articles.
Anomaly detection is used to find outliers in the data. It is similar to control charts but uses lots more variables as inputs. Anomaly detection is especially useful when “normal” operating parameters are difficult to define and change over time, and you want your detection of abnormalities to adjust automatically.

 Trace3

Figure 12: Modeling: types of algorithms.


Deep learning models
Deep learning is based on the concept of artificial neural networks (ANNs). In that way, they work like human brains where synapses become stronger or weaker based on feedback of some sort, and neurons fire based on specified conditions. Hard problems are being solved through deep learning models, including self-driving cars, image detection, video analysis, and language processing. Figure 13 shows their key characteristics.
Lest you think that deep learning models are the only things that should be used, there are some caveats:

First, they require large amounts of data—generally much more than machine learning models. Without large amounts of data, deep learning usually does not perform as well.
Second, because deep learning models require large amounts of data, the training process takes a long time and requires a lot of computational processing power. This is being addressed by ever more powerful and faster CPUs and memory as well as newer GPUs and FPGAs (field-programmable logic arrays).
Third, deep learning models are usually less interpretable than machine learning models. Interpretability is a major area of deep learning research, so perhaps this will improve.

 Trace3

Figure 13: Modeling: deep learning.


How to measure machine learning model performance
Models, just like people, have their performance assessed. Here are a few ways to measure the performance of a relatively simple regression model. The MAE, RMSE, and R2 performance metrics are fairly straightforward, as Figure 14 shows.
All these can be considered a type of cost function, which helps the model know if it’s getting closer or farther away from the “right” answer, and if it’s gotten “close enough” to that answer. The cost function tells the model how far it has to go before it can take new data it hasn’t seen before and output the right prediction with a high enough probability. When training the model, the goal is to minimize the cost function.
 Trace3

Figure 14: Modeling: performance assessment: example of error calculation for regression.


Precision versus recall in classification models
Once the cost function has done its job of helping the model head in the direction of the “right answer” based on training data (data it is being shown), you need to evaluate how well the model performs on data it hasn’t yet seen. Let me explain this in the context of classification models (models that determine whether something is in one group or another, such as if the picture is a dog, cat, rat, etc.).
To assess the performance of classification models (see Figure 15), you use the equation for accuracy (as detailed below). However, it’s generally accepted that when the training data exhibits class imbalance, the accuracy metric might be misleading, so you use metrics called precision and recall instead. Here’s what these terms mean:

Class imbalance: The data is skewed in one direction versus other directions. Consider the example of predicting whether a credit card transaction is fraudulent. The vast majority of transactions are not fraudulent, and the data set will be skewed in that direction. So, if you predicted that a given transaction is not fraud, you’d probably be right—even if you know nothing about transaction itself. Applying the accuracy metric in this example would mislead you to think you’re doing a great job of predicting transactions that are not fraudulent.
Precision is a measure of relevance. Pretend you use your search engine to find the origin of the tennis score “love.” Precision measures how many of the items returned are really about this versus links to how much people love tennis, how people fell in love playing tennis, etc.
Recall is a measure of completeness. Using the same example of the tennis score “love,” recall measures how well the search engine captured all the references that are available to it. Missing zero references is amazing, missing one or two isn’t too bad, missing thousands would be terrible.

Unfortunately, in the real world, precision and recall are traded off; that is, when one metric improves, the other metric deteriorates. So, you’ve got to determine which metric is more important to you.
 Trace3

Figure 15: Modeling: performance assessment: confusion matrix for classification.


Consider the example of a dating app that matches you with compatible people. If you’re great-looking, rich, and have a sparkling personality, you might lean towards higher precision because you know there will be a lot of potential matches, but you only want the ones that are a real fit, and the cost for you to screen potential matches is high (hey, you’re busy building an empire—you’ve got millions of things to do). On the other hand, if you’ve been looking for someone for a long time and your mother’s been on your back, you might lean toward recall to get as many potential matches as possible. The cost of sorting through potential suiters is relatively low compared to the constant nagging from your mother! To assess how well the model balances precision and recall, the F1 score is used.
These metrics can be plotted on a graph, as Figure 16 shows; one is called the ROC curve (receiver operating characteristic curve) and the other is the PR curve (precision-recall curve). A perfect curve (which you will never get unless you cheat!) is a curve that goes up the Y axis to 1 and then goes across the top. In the case of the ROC curve, a straight line across the diagonal is bad—this means that model predicts true positives and true negatives equally at 50 percent rates (no better than random guesses). These metrics are frequently converted to an area under the curve (AUC), so you’ll see terms like AUC ROC and AUC PR.
 Trace3

Figure 16: Modeling: performance assessment: ROC and PR curves.


Why building machine learning models can be hard
Now that you understand what a model is and how to judge a model’s performance, let’s explore why building a well-performing model can be hard. There are several reasons, as Figure 17 shows. Among them: problem formulation, data issues, selecting the appropriate model algorithm and architectures, selecting the right features, adjusting hyperparameters, training models, cost (error) functions, and underfitting (bias) and overfitting (variance).
Be aware that data science, just like any other science, is both an art and science. Of course, there are always brute-force ways to do things, but those approaches can be time-consuming, may miss insights, and may just plain get things wrong. The current approach of data science is to pool the knowledge of subject matter experts (such as lines of business, operations, and transformation and improvement specialists) and data scientists to create models that fulfil the business needs.
 Trace3

Figure 17: Modeling: common obstacles leading to poor performance.


Overfitting versus underfitting
Overfitting and underfitting are particularly popular problem outcomes, so let’s delve into them a bit. As Figure 18 shows, they involve bias and variance.
Overfitting (high variance) means that the model responds too much to variations in the data, such that it hasn’t really learned the true meaning and instead “memorized” the data. It would be the same as you reading a math book in school and, when given a test on it, know the answers only to the three examples given in the book. When the teacher asks you these math problems (say, 2+1=3, 7+2=9, and 4+2=6), you get them right. But when she asks you something different—say, 1+1=?—you don’t know the answer. That’s because you haven’t learned what addition is, even though you know the answers to the examples. (By the way, don’t tell my professors, but this method saved my bacon in college back in the day!)
Underfitting (high bias) is the opposite problem in that you refuse to learn something new. Maybe you know how to do addition in base 10. But now circumstances have changed, and you’re asked to do addition in base 16. If you exhibit high bias, you’ll continue to do base-10 addition and not learn base-16 addition, and so you get the wrong answers.
Both are problems, and data science has mechanisms to help mitigate them.
 Trace3

Figure 18: Modeling: obstacles: bias and variance.


Machine learning model examples
Let’s go through a couple of machine learning examples of using two types of algorithms: eager algorithms and lazy algorithms. Figure 19 shows examples of both.
Eager algorithms don’t use explicit training (the first path in the diagram), whereas lazy algorithms are explicitly trained (the second path in the diagram). Because eager algorithms aren’t explicitly trained, their training phase is fast (nonexistent, actually), but their execution (or inference phase) is slower than the trained lazy algorithms. Eager algorithms also use more memory because the entire data set needs to be stored, while the data used to train the lazy algorithm can be discarded once training is completed, using less overall memory.
 Trace3

Figure 19: Machine learning examples with and without training.


Example: Document search using TF-IDF
In this first example of an eager algorithm applied to text analytics, I’m using an algorithm called TF-IDF. I’ll explain what TF and IDF mean shortly, but let’s first be clear on the goal of this example. There are five simple, short documents (Documents 1 to 5), as Figure 20 shows. There’s also a dictionary of keywords for these documents; the dictionary is used for keyword searches. And there is also a user who has a query. The goal is to retrieve documents that best fit the user’s query. In this example, you want to return the five documents in order of prioritized relevance.
 Trace3

Figure 20: Text analytics example: TF-IDF problem.


First, let me explain clarify the TF and IDF acronyms. TF stands for term frequency, or how often a term appears (that is, the density of that term in the document). The reason you care is because you assume that when an “important” terms appear more frequently, the document it’s in is more relevant; TF helps you map terms in the user’s query to the most relevant documents.
IDF stands for inverse document frequency. This is almost the opposite thinking—terms that appear very frequently across all documents have less importance, so you want to reduce the importance weight of those terms. Obvious words are “a,” “an,” and “the,” but there will be many others for specific subjects or domains. You can think of these common terms as noise that confuses the search process.
Once TF and IDF values are calculated for the documents and the query, you just calculate the similarity between the user’s query and each document. The higher the similarity score, the more relevant the document. Then you present those documents to the user in order of relevance. Easy right?
Now that you understand how it’s done, you just have to do the calculations. Figure 21 shows the solution.
 Trace3

Figure 21: Document search (text analytics): solution.


Let’s walk through the calculations. By the way, you’ll see there are several matrices. Machine learning and deep learning models do a lot of their calculations using matrix math. You’ll want to be aware of that as you work with data scientists; you’ll want to help them get the data into these types of formats in a way that makes sense for the business problem. It’s not hard, but it’s part of the art of the data science preprocessing stage.
In the first TF matrix, you calculate the normalized (“relative”) frequency of each keyword (as specified in the dictionary) for each document. The numerator represents the word count frequency in that document, and the denominator represents the maximum number of times that word appeared in any give document; in other words, it’s the maximum value across all the numerators.
In the second matrix, you add an IDF vector in the last row for each term in the dictionary. You just apply the equation you’ve been given: IDF(t) = log(N/n(t)), where

N = number of recommendable documents
n (t) = number of documents in which keyword t appears

The next step is to create the TF-IDF matrix for the documents by multiplying each row of the documents by the last IDF row. Now you’re done with the document matrix. Repeat the same process to create the user-query matrix.
Finally, combine the two matrices and calculate the similarity between each document and the user query. In this case, you use an equation to calculate similarity called cosine similarity (there are other similarity calculations you can use as well). The equation is represented in the figure, and the values are in the last column. Notice that the similarity value between the user query and itself is 1—as it should be because it’s being compared to itself.
From here, you can sort the similarity values (in the last column of the matrix) from highest to lowest, thus presenting the user with documents from most to least relevant. Now you’re done! Notice there was no “training” of the model; you just applied a few equations.
Example: Pet recommendations using collaborative and content-based approaches
Let’s go through another example of an eager machine learning algorithm used in a recommender engine, similar to what you might see from many websites. In this case, you have data on four pet lovers, and you know their preference in terms of the type of pets they like and how much they like specific pets. Let’s assume there is a fifth pet lover (Amy) about whose preference you know less.
Your goals are two-fold: Predict the rating that Amy would give to a specific pet, and predict the preference of pets that Amy may like if you know her preferences of pet attributes. You should see that this closely resembles a similarity problem, using similarity of attributes between people you know more about to someone you know less about.
There are two ways to determine similarity in recommendation systems: collaborative and content-based, and collaborative can be further defined as user-based or item-based.
In the collaborative method, you need the ratings of users in the community. Applying this through the user-based approach, you predict what users like based on the likes of similar users in the community. By contrast, using the item-based approach, you predict what users like based on similarity among items that the community likes.
The content-based method does not use ratings of users in the community. Instead, it’s based on the characteristics of the items themselves, and the value (or label) assigned to these characteristics are provided by a domain expert.
Each method has its advantages and disadvantages, as Figure 22 shows.
 Trace3

Figure 22: Recommender example: similarity intuition.


Consider this example: In the collaborative method, you use the pet ratings of other users to predict an individual’s unknown rating of a pet.
First, try the user-based approach. Because you are comparing aggregate individual’s ratings that can be skewed by human bias (that is, their baselines can be varied), you use a similarity function called the Pearson similarity (see the equation in the figure) that tries to correct for user bias by normalizing the ratings (that is, by subtracting the average of the ratings from each user rating). Working through the example, you see that Alice’s ratings are most similar to Bill’s ratings, so you can assume Amy’s missing rating would be the same as Bill’s.
Now try the item-based approach. In this approach, you don’t focus on individuals’ ratings but instead on the items’ ratings. And because the items’ ratings are a composite of ratings provided by several individuals, you don’t have to be as concerned about bias, so you can use the cosine similarity function (see the equation in the figure). Here, you see that Cat is most similar to Hedgehog, so you can infer that Amy’s rating for Cat would be the same as her rating for Hedgehog.
Finally, try the content-based approach. This approach doesn’t require the ratings of community members. Instead, an expert has labeled the data—in this case, the attributes (cute, clean, cuddly, loyal) of each pet type. If you know an individual’s preference for each attribute, you can use the cosine similarity function to predict the pets that the individual is most likely to enjoy. In this example, Amy is most likely to enjoy, in order of descending preference, Hedgehog, Rabbit, Dog, Pig, then Cat.
Let’s get into the math a bit. As an example, to determine Amy’s score for Hedgehog, you find the similarity between Hedgehog’s pet attributes and Amy’s ratings of importance of pet attribute:

The Hedgehog’s vector is (4,3,1,1)
Amy’s vector is (3,3,2,1)
You need to find similarity between these two vectors
Cosine similarity = [4(3) + (3)(3) + (1)(2) + (1)(1)] / [SQRT(4^2 + 3^2 + 1^2 + 1^2) * SQRT(3^2 + 3^2 + 2^2 + 1^2)] = .96

For the collaborative method, you use Pearson equation because it normalizes ratings across users (who can be inconsistent in their ratings). If you have objective ratings (such as ratings not based on people with different scales), you can use cosine similarity. Figure 23 shows the solution.
Here are the variables in the equations:

u: user
i: item to be rated
N: # nearest neighbors
j: neighbor
rj,I: j’s rating on i
rj bar: average of j’s ratings
ru bar: average of user’s rating
alpha: scaling factor for ratings; 1 means use as is (there is no right value for alpha; it’s one of those hyperparameters) described earlier that an experienced data scientist can adjust to derive better results given the problem objective and context)

 Trace3

Figure 23: Recommender example: similarity solution.


Example: Lazy algorithm using support vector machine (SVM)
Finally, here’s an example of a lazy machine learning algorithm called the support vector machine (SVM). In this approach, you want to determine which group an item belongs, such as whether a new customer ends up being a highly or lowly profitable customer. To accomplish this using SVM, you need to calculate two parameters:

Weights (importance) of each attribute (examples of attributes might be the customer’s income, number of family members, profession, and educational achievement)
Support vectors, which are the data sets that are nearest to the curve (called a hyperplane) that separates the groups.

You then take these two parameters and plug them into an equation, as Figure 24 shows.
The way you calculate these parameters is to use the available data sets, and this is what is referred to as training the data.
 Trace3

Figure 24: Classification example: SVM problem and intuition.


Figure 25 shows the equation used to make the prediction under the Prediction label. Values that are calculated during the training phase are:

The weights (the alphas and thetas) used to minimize the cost function.
The support vectors xi, which are a subset of the training data.

Once the model is trained, you can then plug in new values of x (such as the attributes of new customers), and then predict the class, h(x), in which these new values of x belong (such as whether they are expected to be highly profitable customers or not).
 Trace3

Figure 25: Classification example: SVM solution.


Why AI projects fail
There are common ways that AI projects fail in the business environment, as Figure 26 shows. Any AI framework should address those pitfalls.
 Trace3

Figure 26: Why AI projects fail.


The first driver of failure is either selecting the wrong use case or taking on too many uses cases without sufficient capabilities and infrastructure. You can use the criteria described earlier to identify problems that better lend themselves to AI solutions. In addition, it is smart to set up a series of use cases that let capabilities and knowledge be built incrementally and with increasing technical sophistication.
Selecting the right use cases is best done collaboratively with:

Line-of-business staff who know the business problems, contexts, and constraints, as well as the hypotheses they want tested.
Business analysts who can ask questions that clarify the business intent and requirements, and who can identify the data sources and transformations.
Data scientists who can formulate the machine learning and deep learning problem so that models can provide answers to the business’s hypotheses.
Data engineers and IT resources who can provide access to the data.

Organizing and orchestrating these types of activities correctly upfront requires experienced cross-functional leaders who understand and can balance business impacts, operational drivers, workflow barriers and opportunities, data needs and constraints, and technology enablers.
The second driver is incorrectly building the AI models themselves. This consist of two elements:

Even though data science, like other sciences, is experimental in nature (you don’t really know what the data will tell you until you work with it), the approach to data science should be well-defined, should be disciplined, and should speed time-to-value.
Good data scientists can quickly experiment and iterate, learn from their experiments, distinguish between promising and ineffective approaches, and research and adapt cutting-edge methods if necessary. Good data scientists build MVPs (minimal viable products) in rapid, parallel fashion.

The third driver is lack of scale to quickly build and improve multiple AI models simultaneously. Frequently, this comes down to data scientists being able to work collaboratively, to reuse data pipelines, workflows, and models/algorithms, and to reproduce model results. Additionally, they need to be able to capture and quickly incorporate operational feedback (in the test, staging, or production environments) to further build scale. Accomplishing this requires both the correct infrastructure environment as well as a right-touch model governance approach.
The fourth driver of failure is an inability to operationalize and monetize AI models. Generally speaking, AI models are developed for one of two purposes:

To find previously unidentified insights
To automate decision making (for both cost reduction and efficiency/productivity).

Clearly, models that never make it out of the laboratory can’t accomplish these tasks.
Furthermore, not only do the models need to be deployed (that is, made accessible to people or systems), but they must be incorporated into workflows in such a way that they are “used” in operations, and exceptions (such as when models cannot make decisions with high probability of correctness) must be managed gracefully (such as through human intervention, model retraining, and model rollback). AI operationalization and monetization requires gradual but full model workflow integration, monitoring of data inputs and model performance parameters, and management of frequent model deployments.
How do I AI? An end-to-end AI solution framework
Finally, let’s tie all this together with an example AI solution framework shown in Figure 27.
 Trace3

Figure 27: AI reference architecture.


There are four components:

Data management.
Model development.
Model operationalization.
Ensuring that the models are used, affect the business, and improve business metrics.

The first component, data management, is a normal part of current BI environments, so I don’t describe it here.
The second component, model development, consists to two broad areas:

Defining and prioritizing use cases that are appropriate for machine learning models.
Building the machine learning models at scale.

The third component, model operationalization, not only entails model deployment but also the process of continuous retraining and redeployment, model integration with operational workflows, and integration of operational feedback for model improvement. 
The purpose of all of this is to monetize the models’ capabilities.
Finally, the fourth component, organization and business impact, is simple (and obvious) but vital to the future maturation of an organization’s AI capabilities. The function of this component is to ensure that the AI models are actually used by the lines of businesses (that is, they trust them and derive value from them) and that they are affecting business outcomes. Without line-of-business buy-in, the AI movement will rarely take flight.
Above these four components in Figure 27 are collaboration groups: IT, data engineers, data scientists, and lines of business. AI is a team sport.
You can take these components and put a reference architecture around them (see Figure 28), adding a component called model governance to ensure that model reproducibility, data science reusability, and data scientists’ collaboration are achieved and to ensure that model retraining/rollback is possible when required.
 Trace3

Figure 28: AI reference architecture.


Designing and implementing a solution like this reference architecture will support the AI solution framework with robustness, speed to market, and business outcomes.
 















 
Related content





Sponsored Content
by Broadcom

Unlocking the core benefit of Value Stream Management…not what you think
Navigating the VSM landscape: Strategies for seamless digital transformation—a chat with Serge Lucio, General Manager of...

By Broadcom


May 20, 2024


 


opinion

What senior developers do
Much of what a senior developer does boils down to writing good code. Here are seven tips that make that easier.   

				By Nick Hodges				


Jul 16, 2024

8 mins 


Careers
Software Development






analysis

Learning cloud cost management the hard way
After all these years, we still haven’t implemented enough finops, automation, and governance to stop wasting money in the cloud. 

				By David Linthicum				


Jul 16, 2024

5 mins 


Cloud Management
Data Governance
IT Skills






feature

How to master multi-tenant data management
Success with a multi-tenant architecture requires the close alignment of design, use case, and underlying technology. Let’s dive into the key design patterns, their benefits, and their challenges.  

				By Li Shen				


Jul 16, 2024

16 mins 


Cloud Architecture
Databases
Cloud Computing






analysis

7 reasons analytics and ML fail to meet business objectives
Data analytics and machine learning can deliver real business value, but too many projects miss their mark. Here are seven mistakes to watch out for, and what to do instead. 

				By Isaac Sacolick				


Jul 15, 2024

12 mins 


Generative AI
Machine Learning
Emerging Technology






Resources


Videos



















",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvY29nbml0aXZld29ybGQvMjAxOS8wMi8yNC9haS10cmFuc2Zvcm1pbmctdGhlLXdvcmxkL9IBAA?oc=5,AI Transforming The World - Forbes,2019-02-24,Forbes,https://www.forbes.com,"The world is fast evolving, with Artificial intelligence (AI) at the forefront in changing the world and the way we live.
An important question: What is AI? For many people, it remains unclear what this technology is all about..",,"The world is fast evolving, with Artificial intelligence (AI) at the forefront in changing the world and the way we live.
An important question: What is AI? For many people, it remains unclear what this technology is all about..","The world is fast evolving, with Artificial intelligence (AI) at the forefront in changing the world and the way we live.
An important question: What is AI? For many people, it remains unclear what this technology is all about..",http://schema.org,BreadcrumbList,AI Transforming The World,2019-02-24T20:22:00-05:00,2019-02-25T01:52:13-05:00,False,,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/cognitiveworld/files/2019/02/WomanCyborg-F-1200x801.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Taarini Kaur Dang', 'url': 'https://www.forbes.com/sites/taarinikaurdang/', 'description': 'Taarini Kaur Dang is the youngest Venture Capitalist, TEDx Speaker, Forbes Writer, and Diversity Champion. She is the Founder and Managing Partner of a Venture Capital firm called Brave14 Capital for which she raised $870k in funding from top Venture Capitalists and Institutional Investors in the US. Taarini is the co-Founder of a diversity empowerment Instagram account called @ClassyWomenn which has ramped to 1 million followers in 4 years across 10 Asian countries. She has helped over 500 individuals on a one-on-one basis so far. At the age of 13, she wrote a book (The Young Aspiring Entrepreneur) which has a foreword from Intel Capital President Wendell Brooks and quotes from Stanford Professor Chuck Eesley, Intel’s Chief Diversity Officer Barbara Whye, Oracle ex-President Ray Lane and author Linda Swindling. She has been an invited speaker at top conferences, like Google Launchpad Female Founders Summit, Collision conference, TiECon, Women’s March, ATEA, AI ShowBiz Summit, etc. She has been the only speaker under the age of 18 at these conferences. She has been featured in media by BBC, Nasdaq, Mercury News, etc. In 2019, she was ranked among the Top 100 Women in Finance in India. She is also the youngest person to win the Young American-Indian Award which she received from the Indian Ambassador to the US Navtej Sarna for her work in entrepreneurship.', 'sameAs': ['https://www.linkedin.com/in/taarinidang', 'https://www.twitter.com/taarinidang', 'https://www.brave14capital.com/', 'https://www.facebook.com/dangtaarini']}",,,"{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI Transforming The World,,https://www.forbes.com/sites/cognitiveworld/2019/02/24/ai-transforming-the-world/,AI & Big Data,N/A,"More From ForbesJun 17, 2024,04:42am EDTProtecting Human Rights In The Age Of Intelligent MachinesApr 24, 2024,05:00am EDTWhat AI Can Tell Us About OzempicFeb 22, 2024,03:42am ESTUnlocking The Power Of Social Data For Clinical Trial DesignJan 25, 2024,04:55am ESTCPG Product Innovation Should Be A Science, Not An ArtAug 7, 2023,08:57am EDTListening Before We Talk: Why Social Data Is Key To Successful NPD In 2023Mar 28, 2023,10:07am EDTHow Technology Is Empowering CPGs To Do More With LessFeb 21, 2023,05:24am ESTAre Humans And Collaboration Still At The Heart Of Innovation?Edit StoryForbesInnovationAIAI Transforming The WorldTaarini Kaur DangContributorCOGNITIVE WORLDContributor GroupOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itFeb 24, 2019,08:22pm ESTUpdated Feb 25, 2019, 01:52am ESTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin









The world is fast evolving, with Artificial intelligence (AI) at the forefront in changing the world and the way we live. This article is Part 1 of a 2 part series.
An important question: What is AI? For many people, it remains unclear what this technology is all about, so this is a good place to start the conversation. AI is a branch in computer science that deals with the intelligent behavior of machines. It is an ingeniously simulated ability of a machine to imitate human behavior and our conventional response patterns. This is made possible with specific algorithms that make the AI function in a specified scope of activities (according to what the algorithm codes for). This means that with AI, many of our everyday activities can now be carried out effectively by programmed machine technology.

Over the years, a number of technocrats in the field have carried out extensive work in broadening the prospects of fundamental AI innovations. However, one of the prevailing concerns is in the need for a structure where both male and female genders participate as innovators and active movers. This concern comes as a result of overwhelming male-driven dispositions being incorporated into finished Al functioning products. The reason for this is that few women are present and involved in the development of artificial intelligence.
The importance of AI technology: How can AI change the world?  
Speaking on the relevance and implications of AI adoption in the world’s general operational systems, Microsoft’s chief envisioner David Coplin had this to say:
PROMOTED


It will change how we relate to each other. I would argue that it will even change how we perceive what it means to be human. -- David Coplin 
 



The use of AI in organizations, governments, security frameworks, energy and natural resource management, etc., is drastically on the rise. Although AI advancement levels and use may differ substantially from one geographical region to the other, there are clear indicators pointing to the fact that more people are acknowledging the solutions that the technology brings.
This leads us to acknowledging the center of focus for AI developers. Most AI developers are now ultimately directed towards achieving a basic goal. They are charged with the responsibility of building AI models that would aptly substitute direct human efforts. This need comes in recognition to the inadequacies of human labor efforts, which are characterized by inaccuracy, inefficiency and other failures. For example, artificial intelligence has been pointed at to possess the potential for more accurate medical practices. Thus, you can be sure of a more accurate surgical procedure using this framework than is currently available by most humans. Hence, we can say that the opposites of the inadequacies of human efforts are precisely the benefits of artificial intelligence to our world.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



However, even though work is ongoing in significantly constructing the usefulness of this technology, truly significant achievements are yet to come. AI is all around us, but often times we don’t notice it. For instance, Facebook uses AI technology for its image recognition. AI has also played roles in managing calendars, political campaigns, and is fast approaching basically everything!
According to John McCarthy - one of the founding fathers of the technology:


The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.  -- John McCarthy 
 


This conveys that AI can imitate any aspect of our life, and hence presents a different and more advanced world to help us!
Let's consider some obvious reasons why AI will become pervasive in the near future:

AI virtual assistants

Using AI, more people would be able to step down on having to carry out so many tasks by themselves. With a personal assistant AI, we’ll be able to remove the more mundane tasks from our lives. For instance, there may be no need to go to the grocery store, meet with an appointment, or make that deadline yourself as your AI assistant knows just what to do, and when to do it. Consider the value of such help in managing your messages, helping to sort out your wardrobe, doing your laundry. However, the AI would only function according to its developed programming. Hence, one AI may be programmed to work on multiple assignments, while another may be far more narrow in scope of application.

Increasing effective labor input with guaranteed corresponding output

Businesses today are realizing the prospects of AI; they know how valuable the technology is for achieving increased productivity. Unlike human labor that can be very limited, artificial intelligence provides more input with a corresponding positive output - on average. The technology is able to achieve this through the use of innovative diffusion, apt and proactive decision implementations, and other roadmaps that ultimately jerks up positive output.
Accenture has estimated a minimum of 40% increase in realizable productivity for companies that would be adopting AI by the year 2023.
Most artificial intelligence modules are connected to other frameworks such as cloud database and storage, big data, cryptography and blockchain, internet of things (IoT), etc. As such, they are able to facilitate the speed and effectiveness of information transmission and reproducibility, from end to end.

Improving operational costs

Utilization of physical manpower requires sustained salaries and allowance costs for the company. This directly effects the company's net profits and increases operational costs. An AI operated company, where costs on human labor are largely removed, has huge gains in the long and short run due to impactful salary reduction. Although analysts consider the high costs of AI development, the utilizing firm will likely benefit significantly in the long run, and it may just keep the firm alive.
The prospects for AI future use are enormous. This is already indicated in current use of AI in the medical, banking, gaming, transport, manufacturing, and defense sectors.
Artificial intelligence guru and industry influencer Andrew Ng has likened the expected impact of AI, to that of the impact electricity has had on the world. He had this to say in his comparison:


Just as electricity transformed almost everything 100 years ago, today I actually have a hard time thinking of an industry that I don’t think AI will transform in the next several years.  -- Andrew Ng 
 


Elon Musk speaks of the great potentials of AI in bettering the world systems. However, his latest concerns are on the possibilities of an inability of humans to ultimately control its accompanying negative effects. According to Musk, human designed AI may end up becoming a kind of nuisance to man - if it finally becomes pervasive.
But irrespective of how analysts, stakeholders and enthusiasts perceive things, the basic importance of artificial intelligence is undeniable and is adequately acknowledged by all.
AI is expected to be a species on planet earth (and maybe in space too).Taarini Kaur DangFollowingFollowTaarini Kaur Dang is the youngest Venture Capitalist, TEDx Speaker, Forbes Writer, and Diversity Champion. She is the Founder and Managing Partner of a... Read MoreEditorial StandardsPrintReprints & Permissions",AI & Big Data,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTkvMDIvMjMvc3VuZGF5LXJldmlldy90YXgtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UuaHRtbNIBAA?oc=5,Don’t Fight the Robots. Tax Them. - The New York Times,2019-02-23,The New York Times,https://www.nytimes.com,"Many companies invest in automation because the tax code encourages it, not because robots are more productive.",N/A,"Many companies invest in automation because the tax code encourages it, not because robots are more productive.","Many companies invest in automation because the tax code encourages it, not because robots are more productive.",https://schema.org,NewsMediaOrganization,Don’t Fight the Robots. Tax Them.,2019-02-23T19:30:04.000Z,2019-02-23T19:30:04.000Z,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/02/24/opinion/sunday/24porter/24porter-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2019/02/24/opinion/sunday/24porter/24porter-videoSixteenByNineJumbo1600.jpg', 'creditText': 'Andy Rementer'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2019/02/24/opinion/sunday/24porter/merlin_151021812_5f5628e7-d691-4e05-a3cb-8e2cfec969f4-superJumbo.jpg', 'height': 1500, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2019/02/24/opinion/sunday/24porter/merlin_151021812_5f5628e7-d691-4e05-a3cb-8e2cfec969f4-superJumbo.jpg', 'creditText': 'Andy Rementer'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/eduardo-porter', 'name': 'Eduardo Porter'}]",,,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",,The New York Times,,https://www.nytimes.com/,Sunday Review,N/A,"AdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTnews analysisDon’t Fight the Robots. Tax Them.Many companies invest in automation because the tax code encourages it, not because robots are more productive.Share full articleRead in appCredit...Andy RementerBy Eduardo PorterMr. Porter is an economics writer for The Times.Feb. 23, 2019When Bill Gates floated the idea of imposing a tax on robots a couple of years ago, Lawrence Summers, a former top economic adviser to President Barack Obama, called the Microsoft co-founder “profoundly misguided.” How do you even define a robot to tax it? And taxing innovation is a sure way to make a country poorer. Europe has also rejected the idea. In 2017 the European Parliament soundly defeated a draft motion, proposed by its committee on legal affairs, that recommended considering a tax on the owners of robots to fund retraining programs for workers displaced by the machines and shore up the finances of their social security system. And yet properly constructed, a tax on automation may not be as destructive as it sounds. South Korea, the most robotized country in the world, instituted a robot tax of sorts in 2018 when it reduced the tax deduction on business investments in automation. There are two sound arguments for taxing robots.  The easiest is this: Governments need the money. In the United States, income taxes account for half of the $3 trillion collected every year by the Internal Revenue Service; payroll taxes account for another third.Subscribe to The Times to read as many articles as you like.Eduardo Porter joined The Times in 2004 from The Wall Street Journal. He has reported about economics and other matters from Mexico City, Tokyo, London and São Paulo.   More about Eduardo PorterA version of this article appears in print on Feb. 24, 2019, Section SR, Page 5 of the New York edition with the headline: Don’t Fight the Robots. Tax Them.. Order Reprints | Today’s Paper | SubscribeSee more on: Bill Gates, Lawrence SummersShare full articleRead in appAdvertisementSKIP ADVERTISEMENT",,https://www.nytimes.com/2019/02/23/sunday-review/tax-artificial-intelligence.html,Don’t Fight the Robots. Tax Them.,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vcGh5cy5vcmcvbmV3cy8yMDE5LTAyLWFsY2hlbXktYXN0cm9sb2d5LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLmh0bWzSAUtodHRwczovL3BoeXMub3JnL25ld3MvMjAxOS0wMi1hbGNoZW15LWFzdHJvbG9neS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS5hbXA?oc=5,What alchemy and astrology can teach artificial intelligence researchers - Phys.org,2019-02-21,Phys.org,https://phys.org,"Artificial intelligence researchers and engineers have spent a lot of effort trying to build machines that look like humans and operate largely independently. Those tempting dreams have distracted many of them from where the real progress is already happening: in systems that enhance – rather than replace – human capabilities. To accelerate the shift to new ways of thinking, AI designers and developers could take some lessons from the missteps of past researchers.","Science, Physics News, Science news, Technology News, Physics, Materials, Nanotech, Technology, Science","Artificial intelligence researchers and engineers have spent a lot of effort trying to build machines that look like humans and operate largely independently. Those tempting dreams have distracted many of them from where the real progress is already happening: in systems that enhance – rather than replace – human capabilities. To accelerate the shift to new ways of thinking, AI designers and developers could take some lessons from the missteps of past researchers.",Artificial intelligence researchers and engineers have spent a lot of effort trying to build machines that look like humans and operate largely independently. Those tempting dreams have distracted many ...,https://schema.org,BreadcrumbList,What alchemy and astrology can teach artificial intelligence researchers,2019-02-21T10:10:18-05:00,2019-02-21T10:10:18-05:00,,,"{'@type': 'ImageObject', 'url': 'https://scx2.b-cdn.net/gfx/news/2019/whatalchemya.jpg', 'width': 1280, 'height': 630}","{'@type': 'Person', 'name': 'Ben Shneiderman'}",,,"{'@type': 'Organization', 'name': 'Phys.org', 'logo': {'@type': 'ImageObject', 'url': 'https://phys.b-cdn.net/tmpl/v6/img/logo.amp.png', 'width': 204, 'height': 60}}","[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://phys.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Technology', 'item': 'https://phys.org/technology-news/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Machine learning & AI', 'item': 'https://phys.org/technology-news/machine-learning-ai/'}]",,,,N/A,N/A,"










														February 21, 2019
														
													






What alchemy and astrology can teach artificial intelligence researchers

										 by Ben Shneiderman, 										 										 The Conversation







                Alchemists’ dreams distracted from real scientific goals. Credit: Justus Gustav van Bentum/Wikimedia Commons
 

Artificial intelligence researchers and engineers have spent a lot of effort trying to build machines that look like humans and operate largely independently. Those tempting dreams have distracted many of them from where the real progress is already happening: in systems that enhance – rather than replace – human capabilities. To accelerate the shift to new ways of thinking, AI designers and developers could take some lessons from the missteps of past researchers.





For example, alchemists, like Isaac Newton, pursued ambitious goals such as converting lead to gold, creating a panacea to cure all diseases, and finding potions for immortality. While these goals are alluring, the charlatans pursuing them may have secured princely financial backing that would have been better used developing modern chemistry.
Equally optimistically, astrologers believed they could understand human personality based on birthdates and predict future events by studying the positions of the stars and planets. These promises over the past thousand years often received kingly endorsement, possibly slowing the work of those who were adopting scientific methods that eventually led to astronomy.
As alchemy and astrology evolved, the participants became more deliberate and organized – what might now be called more scientific – about their studies. That shift eventually led to important findings in chemistry, such as those by Lavoisier and Priestley in the 18th century. In astronomy, Kepler and Newton himself made significant findings in the 17th and 18th centuries. A similar turning point is coming for artificial intelligence. Bold innovators are putting aside tempting but impractical dreams of anthropomorphic designs and excessive autonomy. They focus on systems that restore, rely on, and expand human control and responsibility.






Updating early AI dreams
Back in the 1950s, artificial intelligence researchers pursued big goals, such as human-level computational intelligence and machine consciousness. Even during the past 20 years some researchers worked toward the ""singularity"" fantasy of machines that are superior to humans in every way. These dreams succeeded in attracting attention from sympathetic journalists and financial backing from government and industry. But to me, those aspirations still seem like counterproductive wishful thinking and B-level science fiction.
Even the dream of creating a human-shaped robot that acted like a person has lasted for more than 50 years. Honda's near-life-size Asimo and the web-based news reader Ananova got a lot of media attention. Hanson Robotics' Sophia even received Saudi Arabian citizenship. But they have little commercial future.
By contrast, down-to-earth user-centered designs for information search, e-commerce sites, social media and smartphone apps have been wild successes. There is good reason that Amazon, Apple, Facebook, Google and Microsoft are some of the world's biggest companies – they all use more functional, if less glamorous, types of AI.
Today's cellphones feature speech recognition, face recognition and automated translation, which all use artificial intelligence technologies. These functions increase human control and give users more options, without the deception and theatrics of a humanoid robot.










The robot Sophia spoke at the United Nations.
Yielding control
Efforts that pursue advanced forms of computer autonomy are also dangerous. When developers assume their machines will function correctly, they often shortchange interfaces that would allow human users to quickly take control when something goes wrong.
These problems can be deadly. In the October 2018 crash of Lion Air's Boeing 737 Max, a sensor failure caused the newly designed automatic pilot to steer the plane downwards. The pilots couldn't figure out how to override those automatic controls to keep the plane in the air. Similar problems have been factors in stock market ""flash crashes,"" like the 2010 event in which US$1 trillion disappeared in 36 minutes. And poorly designed medical devices have delivered deadly doses of medications.
The National Transportation Safety Board report on the deadly May 2016 Tesla crash called for automated systems to keep detailed records that would allow investigators to analyze failures. Those insights would lead to safer and more effective designs.






Getting to human-centered solutions
Successful automation is all around: Navigation applications give drivers control by showing times for alternative routes. E-commerce websites show shoppers options, customer reviews and clear pricing so they can find and order the goods they need. Elevators, clothes-washing machines and airline check-in kiosks, too, have meaningful controls that enable users to get what they need done quickly and reliably. When modern cameras assist photographers in taking properly focused and exposed photos, users have a sense of mastery and accomplishment for composing the image, even as they get assistance with optimizing technical details.
Without being human-like or fully independent, these and thousands of other applications enable users to accomplish their tasks with self-confidence and sometimes even pride.
A new report from a leading engineering industry professional group urges technologists to ignore tempting fantasies. Rather, the report suggests, developers should focus on technologies that support human performance and are more immediately useful.
In a flourishing automation-enhanced world, clear, convenient interfaces could let humans control automation to make the most of people's initiative, creativity and responsibility. The most successful machines could be powerful tools that let users carry out ever-richer tasks with confidence, such as helping architects find innovative ways to design energy-efficient buildings, and giving journalists tools to dig deeper into data to detect fraud and corruption. Other machines could detect – not contribute to – problems like unsafe medical conditions and bias in mortgage loan approvals. Perhaps they could even advise the people responsible on ways to fix things.
Humans are accomplished at building tools that expand their creativity – and then at using those tools in even more innovative ways than their designers intended. In my view, it's time to let more people be more creative more of the time, by shifting away from the alchemy and astrology phase of AI research.
Technology designers who appreciate and amplify the key aspects of humanity are most likely to invent the next generation of powerful tools. These designers will shift from trying to replace or simulate human behavior in machines to building wildly successful applications that people love to use.


													Provided by
																											The Conversation








This article is republished from The Conversation under a Creative Commons license. Read the original article.




Citation:
												What alchemy and astrology can teach artificial intelligence researchers (2019, February 21)
												retrieved 16 July 2024
												from https://phys.org/news/2019-02-alchemy-astrology-artificial-intelligence.html
											 

											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 


",,"{'@type': 'WebPage', '@id': 'https://phys.org/news/2019-02-alchemy-astrology-artificial-intelligence.html'}",,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='Description']/@content""]}",,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vbmV3cy51c25pLm9yZy8yMDE5LzAyLzIxL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXNwZWVkLXRyYWluaW5nLW5ldy10ZWNoLXJhcGlkbHktZmllbGRlZNIBAA?oc=5,Artificial Intelligence Could Speed Up Navy Training as New Tech is Rapidly Fielded - USNI News - USNI News,2019-02-21,USNI News,https://news.usni.org,Artificial intelligence could be used not only for faster decision-making on the battlefield but for faster training as the Navy fields new technologies.,N/A,Artificial intelligence could be used not only for faster decision-making on the battlefield but for faster training as the Navy fields new technologies.,N/A,https://schema.org,,,,,,,,,,,,,,,,N/A,N/A,"




Artificial Intelligence Could Speed Up Navy Training as New Tech is Rapidly Fielded


Megan Eckstein 
February 21, 2019 5:19 PM 

Fire Controlman (Aegis) 2nd Class Savian Wadsworthy stands watch as the radar systems controller in the combat information center aboard the Arleigh Burke-class guided-missile destroyer USS Porter (DDG 78) in the Mediterranean Sea, Dec. 30, 2018. Porter, forward-deployed to Rota, Spain, is on its sixth patrol in the U.S. 6th Fleet area of operations in support of U.S national security interests in Europe and Africa. US Navy photo.
SAN DIEGO, Calif. – Artificial intelligence could be used not only for faster decision-making on the battlefield but also for faster training as the Navy inserts more weapons and tools onto ships and aircraft, the Navy’s top weapons buyer said last week.
James Geurts, the assistant secretary of the Navy for research, development and acquisition, told reporters that the Navy has many needs for AI tools, especially given the service’s reliance on large data sets such as surveillance video and radar and sonar pictures.
“We tend to focus a lot on decision aids and how to use it to aid in decision-making speed. We look at it a lot of times on how to make sense of lots of data, whether it’s video processing or sonar processing or something along those lines,” Geurts said while speaking to reporters after giving a speech at the WEST 2019 conference, co-hosted by the U.S. Naval Institute and AFCEA.
“I think an area we don’t talk enough about where I think there’s also very interesting opportunities is in training, and how do we speed up our training cycles. So if we get our acquisition cycle going very quickly, whether it’s … building ships faster or putting new capabilities on ships, eventually we will be limited in its effectiveness by how fast we can train the crew and make them proficient. And so some of the use of AI is almost a training aid … I think that’s a whole other area of very interesting possibilities for us to deal with this kind of ever-changing world.”
One early effort to create this kind of AI learning environment is through the use of the Aegis Virtual Twin effort, which allows computers and consoles with the Aegis Combat System to be brought onboard a ship at sea and tap into actual radar and information feeds on the ship without interfering with the crew’s ability to navigate and fight the ship. The consoles running Aegis with real-time data from the ship could be used to test out new software capabilities that the Navy hopes to field and wants to solicit user feedback first, or it could be used for realistic training aboard the ship. The Navy has said that adding artificial intelligence to this existing Aegis Virtual Twin setup would allow the system to understand each user and track his or her past performance, creating future scenarios based on proven weaknesses or areas that haven’t been tested previously rather than providing cookie-cutter training to all sailors.
James Geurts, Assistant Secretary of the Navy for Research, Development and Acquisition (ASN (RD&A)), speaks with the Space and Naval Warfare Systems Command (SPAWAR) workforce in February 2018 to highlight his priorities and answer questions on issues impacting the information warfare environment. US Navy photo.
Leaders at the Department of Defense level are also eager to incorporate AI technologies. Speaking at WEST, Alan Shaffer, deputy under secretary of defense for acquisition and sustainment, said that the Navy needs to buy ships and planes, but if it can’t also field enablers then it won’t win a high-end fight.
“One of the biggest enablers is digital supremacy. Who can turn knowledge into decisions most quickly. So I say frequently … 100 years ago, wars were won by the folks with the biggest biceps. That’s not the future. The future is, who can get to the right decision most quickly. And what enables decisions? Turning a lot of data over to algorithms to crunch it to help give a decision – what most people call artificial intelligence. It’s not a panacea, it’s not perfect, it’s not everything, but the concept of turning data into the right decision more quickly – or more importantly, pointing out when something is going south – is incredibly important. So artificial intelligence … will help speed decisions,” Shaffer said in his keynote speech.
Rear Adm. Christian Becker, the commander of Space and Naval Warfare Systems Command that leads the Navy’s efforts to embrace AI, information warfare and other high-end capabilities, talked about information as warfare and said advances in this realm would improve “the ability to command and control a fight, I’m talking about the ability to sense an environment, I’m talking about the ability to direct fires, integrate fires. That’s information as warfare, and that’s what we’re working on.”
But the Navy can’t just incorporate new technology for the sake of modernizing; it needs to fully rethink how it conducts missions and how it buys new technologies, in the wake of this new digital warfare world.
“I’ll leave you with one quote that I find really appropriate when we talk about being able to go faster, being able to think about things differently, how we approach things, how we buy things, how we require things and how we get after the fight,” Becker said in a panel presentation.
“We can keep improving the way we’re doing business today, but if we need to do business completely differently in order to move at speed and scale, then we’ve got to figure out what that different is. … The quote I’ll leave you with comes from someone named (retired Vice Adm. David) Decoy Dunaway: ‘Don’t do stupid better.’”

Related
BMD-Equipped Destroyer USS Porter Arrives in Rota, SpainThe Arleigh Burke-class guided-missile destroyer USS Porter (DDG-78) arrived in Spain on Thursday to being its ballistic missile defense mission. Porter will join USS Donald Cook (DDG-75) and USS Ross (DDG-71) in the forward-deployed naval force at Naval Station Rota to carry out the European Phased Adaptive Approach to BMD.…May 1, 2015In ""News & Analysis""Guam Needs SM-6 Missile for Hypersonic Defense, Navy Admiral SaysGuam “would absolutely need” the Navy’s SM-6 missile for its defense against a hypersonic missile attack, the program executive for Aegis ballistic missile defense said Thursday. Rear Adm. Tom Druggan called the SM-6 “our leading defense capability for hypersonic missile defense.” It is “a fantastic missile, just absolutely great missile”…November 19, 2021In ""China""Document: SECNAV Mabus’ Navy Artificial Intelligence MemoThe following is the June 5, 2015 memo from Secretary of the Navy Ray Mabus to Chief of Naval Operations Adm. Jonathan Greenert and U.S. Marine Corps Commandant Gen. Joseph Dunford on accelerating artificial intelligence development in the Department of the Navy.June 15, 2015In ""Documents""  


 



 



Megan Eckstein


Megan Eckstein is the former deputy editor for USNI News.









Share to:




Facebook





X





Pinterest





Linkedin





Whatsapp





Email








 

Share to:




Facebook





X





Pinterest





Linkedin





Whatsapp





Email






Get USNI News updates delivered to your inbox

Full Name



Email address: 
		



Frequency

 Daily


 Weekly


 All




Leave this field empty if you're human: 


Related TopicsIndustryNews & AnalysisU.S. Navy






  Related Posts




 




Industry·News & Analysis·Surface Forces·U.S. Navy 



            Austal USA Breaks Ground on New Steel Assembly Facility        


        Austal USA broke ground on its planned final steel assembly facility Tuesday, the company announced in a statement.…    






 




Congress·Industry·News & Analysis·Submarine Forces·Surface Forces·U.S. Navy 



            Navy’s Single Sub Buy Plan Raises Concerns with Congress        


        Lawmakers raised concerns with Navy leaders this week over lags in U.S. naval shipbuilding after the service altered plans for…    






 




Congress·Industry·News & Analysis·Submarine Forces·Surface Forces·U.S. Navy 



            New Navy Long-Range Shipbuilding Plan Details 19 Ship Decommissionings in FY 2025        


        The latest 30-year shipbuilding plan narrows the range of options the Navy will consider for its future force and provides…    






 




Congress·Industry·News & Analysis·U.S. Navy 



            Aircraft Carrier Enterprise Delivery Delayed by 18 Months, Says Navy        


        The future aircraft carrier USS Enterprise (CVN-80) will deliver a year and a half later than prior projections, according to…    













",,,,,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://news.usni.org/2019/02/21/artificial-intelligence-speed-training-new-tech-rapidly-fielded', 'url': 'https://news.usni.org/2019/02/21/artificial-intelligence-speed-training-new-tech-rapidly-fielded', 'name': 'Artificial Intelligence Could Speed Up Navy Training as New Tech is Rapidly Fielded - USNI News', 'isPartOf': {'@id': 'https://news.usni.org/#website'}, 'primaryImageOfPage': {'@id': 'https://news.usni.org/2019/02/21/artificial-intelligence-speed-training-new-tech-rapidly-fielded#primaryimage'}, 'image': {'@id': 'https://news.usni.org/2019/02/21/artificial-intelligence-speed-training-new-tech-rapidly-fielded#primaryimage'}, 'thumbnailUrl': 'https://news.usni.org/wp-content/uploads/2019/02/181230-N-KA046-0137.jpg', 'datePublished': '2019-02-21T22:19:33+00:00', 'dateModified': '2019-02-21T22:19:33+00:00', 'author': {'@id': 'https://news.usni.org/#/schema/person/d47ed23bf50dc3a514b34970b1b3b664'}, 'description': 'Artificial intelligence could be used not only for faster decision-making on the battlefield but for faster training as the Navy fields new technologies.', 'breadcrumb': {'@id': 'https://news.usni.org/2019/02/21/artificial-intelligence-speed-training-new-tech-rapidly-fielded#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.usni.org/2019/02/21/artificial-intelligence-speed-training-new-tech-rapidly-fielded']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.usni.org/2019/02/21/artificial-intelligence-speed-training-new-tech-rapidly-fielded#primaryimage', 'url': 'https://news.usni.org/wp-content/uploads/2019/02/181230-N-KA046-0137.jpg', 'contentUrl': 'https://news.usni.org/wp-content/uploads/2019/02/181230-N-KA046-0137.jpg', 'width': 4756, 'height': 3395, 'caption': 'Fire Controlman (Aegis) 2nd Class Savian Wadsworthy stands watch as the radar systems controller in the combat information center aboard the Arleigh Burke-class guided-missile destroyer USS Porter (DDG 78) in the Mediterranean Sea, Dec. 30, 2018. Porter, forward-deployed to Rota, Spain, is on its sixth patrol in the U.S. 6th Fleet area of operations in support of U.S national security interests in Europe and Africa. US Navy photo.'}, {'@type': 'BreadcrumbList', '@id': 'https://news.usni.org/2019/02/21/artificial-intelligence-speed-training-new-tech-rapidly-fielded#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.usni.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence Could Speed Up Navy Training as New Tech is Rapidly Fielded'}]}, {'@type': 'WebSite', '@id': 'https://news.usni.org/#website', 'url': 'https://news.usni.org/', 'name': 'USNI News', 'description': 'Maritime News and Analysis', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.usni.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://news.usni.org/#/schema/person/d47ed23bf50dc3a514b34970b1b3b664', 'name': 'Megan Eckstein', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.usni.org/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/c8e7234247b649002b6db68078095c2f?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/c8e7234247b649002b6db68078095c2f?s=96&d=mm&r=g', 'caption': 'Megan Eckstein'}, 'description': 'Megan Eckstein is the former deputy editor for USNI News.', 'sameAs': ['https://news.usni.org'], 'url': 'https://news.usni.org/author/meckstein'}]",,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LmdyZWVuYml6LmNvbS9hcnRpY2xlLzQtZW1lcmdpbmctdGVjaC10b29scy1laHMtYW5kLXN1c3RhaW5hYmlsaXR5LXByb2Zlc3Npb25hbHPSAQA?oc=5,4 emerging tech tools for EHS and sustainability professionals - GreenBiz,2019-02-21,GreenBiz,https://www.greenbiz.com,"Early adopters are turning to wearable sensors, drones and artificial intelligence to reduce risks and drive measurable results.",N/A,"Early adopters are turning to wearable sensors, drones and artificial intelligence to reduce risks and drive measurable results.",N/A,,,,,,,,,,,,,,,,,N/A,N/A,"



4 emerging tech tools for EHS and sustainability professionals


Early adopters are turning to wearable sensors, drones and artificial intelligence to reduce risks and drive measurable results. 


By Jen Boynton
February 21, 2019














What does it take to prevent environmental pollution? How do you make sure employees perform their work in a way that keeps them safe from injury? Which sustainability metrics are best for helping your company change how it operates?  A new report from the National Association for Environment, Health and Safety and Sustainability management (NAEM) reveals that emerging technologies are rapidly changing how companies answer those questions. In its latest research into the trends shaping the profession, the association found that companies are experimenting with some truly high-tech solutions to improve data collection, reduce risks and monitor their environmental impacts in live time.Here is a look at a few technology tools that are starting to take hold:1. Smart sensorsThirty-one percent of NAEM respondents are using or evaluating using smart sensors in the workplace. It’s no surprise — smart sensors have a variety of possible applications at work. These devices take input from the physical environment and use built-in computational resources to respond, performing predefined functions upon detection of specific input. Smart sensors can be used for everything from tracking worker safety — to see if a line operator is at risk of an ergonomic injury — to monitoring a storage tank’s walls for stability and the liquid contents within to ensure they are in the correct balance. All of these applications increase the rate that key data reaches the people who can act on it and reduce the likelihood of bad things happening.2. DronesDrones and other unmanned aerial vehicles can monitor broad swaths of land and those that are difficult to access by road or foot. In forested areas, they can track illegal deforestation and monitor for wildfires.  In agricultural applications, they can monitor fields for crop growth, infestations and irrigation leaks. Ranchers can use drones equipped with high definition cameras and thermal imaging to monitor livestock location and health.
New data is only as good and as useful as the algorithms that make sense of it.

The key with all of these applications is that they allow for more robust monitoring at a reduced cost than ""boots on the ground"" can provide. Quickly identifying problems means the cost of containment will be much lower. It’s no surprise 14 percent of respondents are using or evaluating drones for use in EHS monitoring, inspections and data collection.3. Artificial intelligence and machine learningTwenty percent of respondents are using machine learning — a form of artificial intelligence — on the job. The most crucial applications combine raw data with a computer powerful enough to identify patterns and make decisions with minimal human intervention. One machine learning platform NAEM documented automates decision-making for retailers on unsaleable items such as leaking detergent or expired hair dye. It provides retail employees with a barcode scanner connected to a database which advises employees about the hazardous materials contained in the products and the best way to dispose of them: donation; recycling; or landfill.Artificial intelligence brings automation to many other routine EHS&S tasks as well, from air quality sampling to greenhouse gas emissions management.4. Virtual realityWhen it comes to workplace safety, training is key. Virtual reality is making EHS&S training faster, easier and more effective. Rather than simply describing a safety risk companies can use a simulated work environment to teach employees how to safely lift and load, practice new skills and work in confined spaces. EHS&S professionals are also using it to conduct virtual ""walkthroughs"" of facilities before they are built to flag compliance issues and to advise on modifications that could be made while the project is still in the design stage. Sixteen percent of those surveyed are using or evaluating virtual reality tools to help get the job done.Don't forget the important role of data managementAs these new technologies come on line, effective data management becomes a new opportunity and challenge. New data is only as good and as useful as the algorithms that make sense of it. Privacy concerns also come into play. Data security protocols must be strong and algorithms must be carefully crafted to avoid inserting bias. These concerns are top of mind for any EHS&S professional integrating new data systems into their work. The most effective integrations of new technology will be mindful of these challenges and work proactively to resolve them.Ultimately, it’s not the data you have but what you do with it that makes new technology most impactful. 




Show comments for this story.










More on this topic

Information Technology
Artificial Intelligence
Internet of Things
Data
Virtual Reality
Drones





Share this article


Twitter



Facebook



Linkedin

















Jen Boynton
CEO
B Targeted Marketing
@jenboynton








[New Resource] Metals Markets: Macroeconomic Challenges vs. Energy Transition Needs



 Brought to you by S&P Global Commodity Insights

Close













",,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LmphcGFudGltZXMuY28uanAvbmV3cy8yMDE5LzAyLzIzL25hdGlvbmFsL21lZGlhLW5hdGlvbmFsL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWRlYmF0ZS1yYWlzZXMtcXVlc3Rpb25zLWFuc3dlcnMv0gEA?oc=5,Artificial intelligence debate raises more questions than answers - The Japan Times,2019-02-23,The Japan Times,https://www.japantimes.co.jp,"'The human race, version 2' — a thought to inspire hope or fear, maybe a little (or a lot) of both. 'We today,' says Komazawa University economist Tomohiro Inoue, whose thought it is, 'will soon be 'the former human race.''",artificial intelligence,"'The human race, version 2' — a thought to inspire hope or fear, maybe a little (or a lot) of both. 'We today,' says Komazawa University economist Tomohiro Inoue, whose thought it is, 'will soon be 'the former human race.''","'The human race, version 2' — a thought to inspire hope or fear, maybe a little (or a lot) of both. 'We today,' says Komazawa University economist Tomohiro Inoue, whose thought it is, 'will soon be 'the former human race.''",https://schema.org,NewsArticle,Artificial intelligence debate raises more questions than answers,1970-01-01T09:00:00+09:00,2019-02-23T06:51:35+09:00,,,"{'@type': 'ImageObject', 'url': 'https://www.japantimes.co.jp/uploads/imported_images/uploads/2019/02/p16-hoffman-ai-a-20190224.jpg'}","[{'@type': 'Person', 'name': 'Michael Hoffman'}]","'The human race, version 2' — a thought to inspire hope or fear, maybe a little (or a lot) of both. 'We today,' says Komazawa University economist Tomohiro Inoue, whose thought it is, 'will soon be 'the former human race.''The propulsion forward comes from artificial intelligence, already upon us and infinite in its potential. We're going somewhere — that much is certain. Where? In what direction? That, there is no knowing.Inoue's remark occurs in a conversation with two others, published by the monthly Bungei Shunju (March) as part of a wide-ranging package of articles on the subject. Taken as a whole, the feature raises questions — more questions than answers; understandably enough, at this primitive stage. Clearly, AI can make us better — but how much better do we want to be? At what point does better become worse?",,"{'@type': 'Organization', 'name': 'The Japan Times', 'url': 'https://www.japantimes.co.jp/', 'sameAs': ['https://twitter.com/japantimes', 'https://www.facebook.com/thejapantimes', 'https://www.instagram.com/thejapantimes/?hl=en', 'https://www.linkedin.com/company/the-japan-times'], 'logo': {'@type': 'ImageObject', 'url': '/theme_japantimes/images/logo.svg', 'width': 270, 'height': 57}}",,,,https://www.japantimes.co.jp/news/2019/02/23/national/media-national/artificial-intelligence-debate-raises-questions-answers/,JAPAN,N/A,N/A,JAPAN,"{'@type': 'WebPage', '@id': 'https://www.japantimes.co.jp/news/2019/02/23/national/media-national/artificial-intelligence-debate-raises-questions-answers/'}",,,"{'@type': 'Organization', 'name': 'The Japan Times', 'url': 'https://www.japantimes.co.jp/'}",,,,,,,,,,,,1970-01-01T09:00:00+09:00,en,https://www.japantimes.co.jp/uploads/imported_images/uploads/2019/02/p16-hoffman-ai-a-20190224.jpg
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vd3d3LmNiYy5jYS9yYWRpby9zcGFyay9zcGFyay00MjctMS41MDI0MzIxL2FpLXJlcG9ydGVycy1hcmUtaGVyZS13aGF0LXRoYXQtbWVhbnMtZm9yLXRoZS1mdXR1cmUtb2Ytd29yay0xLjUwMjQzMjLSASBodHRwczovL3d3dy5jYmMuY2EvYW1wLzEuNTAyNDMyMg?oc=5,AI reporters are here. What that means for the future of work - CBC.ca,2019-02-22,CBC.ca,https://www.cbc.ca,Aspiring news reporters should probably get a liberal arts degree.,N/A,Aspiring news reporters should probably get a liberal arts degree.,Aspiring news reporters should probably get a liberal arts degree.,http://schema.org/,WebPage,AI reporters are here. What that means for the future of work,2019-02-22T19:46Z,2019-02-22T19:46Z,,,"[{'datePublished': '2019-02-19T17:20Z', '@type': 'ImageObject', 'name': '427 robot reporters', 'description': 'Maybe robot reporters would be better?', 'dateModified': '2019-02-19T17:19Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.5024709.1550596778!/fileImage/httpImage/427-robot-reporters.jpg'}, {'datePublished': '2019-02-22T17:46Z', '@type': 'ImageObject', 'name': 'Jerry Kaplan', 'description': 'Jerry Kaplan', 'dateModified': '2019-02-22T17:45Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.5029942.1550857516!/fileImage/httpImage/jerry-kaplan.jpg'}, {'datePublished': '2019-02-22T17:56Z', '@type': 'ImageObject', 'name': 'MEDIA-WASHINGTONPOST/', 'description': 'Journalists go over story budgets on the newsroom floor during the grand opening of the Washington Post newsroom in Washington January 28, 2016.  ', 'dateModified': '2019-02-22T17:55Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.5029967.1550858148!/fileImage/httpImage/media-washingtonpost.jpg'}]",,,,"{'foundingDate': '1936-11-02T05:00Z', 'ethicsPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'verificationFactCheckingPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', '@type': 'NewsMediaOrganization', '@context': 'http://schema.org/', 'ownershipFundingInfo': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'actionableFeedbackPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'missionCoveragePrioritiesPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'diversityPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'masthead': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'diversityStaffingReport': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'unnamedSourcesPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'correctionsPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364'}",,AI reporters are here. What that means for the future of work,,,N/A,N/A,N/A,,,,,,,,,,,,,,,"{'@type': 'SpeakableSpecification', 'cssSelector': ['.detailHeadline', '.detailSummary']}",,,,https://i.cbc.ca/1.5024709.1550596778!/fileImage/httpImage/427-robot-reporters.jpg

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,publisher,mainEntityOfPage,datePublished,dateCreated,dateModified,heading,image,author,article:section,article:summary,article text,headline,alternativeHeadline,thumbnailUrl,isAccessibleForFree,copyrightHolder,@id,name,alternateName,legalName,foundingDate,logo,masthead,sameAs,address,@graph,itemListElement,articleSection,creator,video,speakable,hasPart,sourceOrganization,copyrightYear,isPartOf,diversityPolicy,ethicsPolicy,identifier
https://news.google.com/rss/articles/CBMijAFodHRwczovL3d3dy5tY2tpbnNleS5jb20vZmVhdHVyZWQtaW5zaWdodHMvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uvbm90ZXMtZnJvbS10aGUtYWktZnJvbnRpZXItbW9kZWxpbmctdGhlLWltcGFjdC1vZi1haS1vbi10aGUtd29ybGQtZWNvbm9tedIBAA?oc=5,Modeling the global economic impact of AI - McKinsey,2018-09-04,McKinsey,https://www.mckinsey.com,"There is unprecedented potential economic impact of AI. But widening gaps among countries, companies, and workers will need to be managed to maximize the benefits.",N/A,"There is unprecedented potential economic impact of AI. But widening gaps among countries, companies, and workers will need to be managed to maximize the benefits.","There is unprecedented potential economic impact of AI. But widening gaps among countries, companies, and workers will need to be managed to maximize the benefits.",https://schema.org,Discussion Paper,https://www.mckinsey.com,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}","{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy'}",2018-09-04T00:00:00Z,2018-09-04T19:20:57Z,2018-09-04T00:00:00Z,Notes from the AI frontier: Modeling the impact of AI on the world economy,https://www.mckinsey.com/~/media/mckinsey/featured%20insights/artificial%20intelligence/notes%20from%20the%20frontier%20modeling%20the%20impact%20of%20ai%20on%20the%20world%20economy/modeling-the-impact-of-ai-on-the-world-economy-b_615429200_1536x1536.jpg,"[{'@type': 'Person', 'name': 'Jacques Bughin'}, {'@type': 'Person', 'name': 'Jeongmin Seong', 'url': 'https://www.mckinsey.com/our-people/jeongmin-seong'}, {'@type': 'Person', 'name': 'James Manyika', 'url': 'https://www.mckinsey.com/our-people/james-manyika'}, {'@type': 'Person', 'name': 'Michael Chui', 'url': 'https://www.mckinsey.com/our-people/michael-chui'}, {'@type': 'Person', 'name': 'Raoul Joshi'}]",N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vd3d3LnNjaWVudGlmaWNhbWVyaWNhbi5jb20vYXJ0aWNsZS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS13aWxsLXNlcnZlLWh1bWFucy1ub3QtZW5zbGF2ZS10aGVtL9IBAA?oc=5,"Artificial Intelligence Will Serve Humans, Not Enslave Them - Scientific American",2018-09-01,Scientific American,https://www.scientificamerican.com,"Scientific American is the essential guide to the most awe-inspiring advances in science and technology, explaining how they change our understanding of the world and shape our lives.",N/A,"AI will serve our species, not control it","AI will serve our species, not control it",https://schema.org,NewsMediaOrganization,https://www.scientificamerican.com/,"{'@id': 'https://www.scientificamerican.com/#publisher', 'name': 'Scientific American'}","{'@type': 'WebPage', '@id': 'https://www.scientificamerican.com/article/artificial-intelligence-will-serve-humans-not-enslave-them/', 'breadcrumb': {'@type': 'BreadcrumbList', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Artificial Intelligence', 'item': 'https://www.scientificamerican.com/artificial-intelligence/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence Will Serve Humans, Not Enslave Them', 'item': 'https://www.scientificamerican.com/article/artificial-intelligence-will-serve-humans-not-enslave-them/'}]}}",2018-09-01T13:00:00+00:00,,2024-02-20T12:16:45.618000+00:00,,"['https://static.scientificamerican.com/sciam/cache/file/8B13C15C-2443-4544-993796DC12AA575C_source.jpg?w=1200', 'https://static.scientificamerican.com/sciam/cache/file/8B13C15C-2443-4544-993796DC12AA575C_source.jpg?crop=16%3A9%2Csmart&w=1920', 'https://static.scientificamerican.com/sciam/cache/file/8B13C15C-2443-4544-993796DC12AA575C_source.jpg?crop=4%3A3%2Csmart&w=1200', 'https://static.scientificamerican.com/sciam/cache/file/8B13C15C-2443-4544-993796DC12AA575C_source.jpg?crop=1%3A1%2Csmart&w=1000']","[{'@type': 'Person', 'name': 'Pedro Domingos', 'url': 'https://www.scientificamerican.com/author/pedro-domingos/'}]",N/A,N/A,"September 1, 201812 min readArtificial Intelligence Will Serve Humans, Not Enslave ThemAI will serve our species, not control itBy Pedro Domingos Armando VeveSeptember 2018 IssueArtificial IntelligenceHumans are the only animals that build machines. By doing so, we expand our capabilities beyond our biological limits. Tools turn our hands into more versatile appendages. Cars let us travel faster, and airplanes give us wings. Computers endow us with bigger brains and memory capacity, and smartphones orchestrate daily life. Now we are creating technology that can evolve on its own by encoding into it an ability to learn through data and effort. Will it ultimately supplant us? Or will it augment our abilities, enhancing our humanness in unprecedented ways?Machine learning started in the 1950s with the work of pioneering scientists such as Frank Rosenblatt, who built an electronic neuron that learned to recognize digits, and Arthur Samuel, whose checkers program learned by playing against itself until it could beat some humans. But it is only in the past decade that the field has truly taken off, giving us self-driving cars, virtual assistants that understand our commands (up to a point) and countless other applications.Every year we invent thousands of new algorithms, which are sequences of instructions telling a computer what to do. The hallmark of learning machines, however, is that instead of programming them in detail, we give them general goals such as “learn to play checkers.” Then, like humans, they improve with experience. These learning algorithms tend to fall into five main categories, each inspired by a different scientific field. Unsurprisingly, one way that machines learn is by mimicking natural selection, through evolutionary algorithms. In the Creative Machines Lab at Columbia University, primitive robots try to crawl or fly, and the specifications of those that perform best are periodically mixed and mutated to 3-D print the next generation. Starting with randomly assembled bots that can barely move, this process eventually produces creatures such as robot spiders and dragonflies after thousands or tens of thousands of generations.But evolution is slow. Deep learning, currently the most popular machine-learning paradigm, takes inspiration from the brain. We start with a highly simplified mathematical model of how a neuron works and then build a network from thousands or millions of these units and let it learn by gradually strengthening the connections between neurons that fire together when looking at data. These neural networks can recognize faces, understand speech and translate languages with uncanny accuracy. Machine learning also draws on psychology. Like humans, these analogy-based algorithms solve new problems by finding similar ones in memory. This ability allows for the automation of customer support, as well as e-commerce sites that recommend products based on your tastes.Machines may also learn by automating the scientific method. To induce a new hypothesis, symbolic learners invert the process of deduction: If I know that Socrates is human, what else do I need to infer that he is mortal? Knowing that humans are mortal would suffice, and this hypothesis can then be tested by checking if other humans in the data are also mortal. Eve, a biologist robot at Chalmers University of Technology in Sweden, has used this approach to discover a potential new malaria drug. Starting with data about the disease and basic knowledge of molecular biology, Eve formulated hypotheses about what drug compounds might work, designed experiments to test them, carried out the experiments in a robotic lab, revised or discarded the hypotheses, and repeated until it was satisfied.Finally, learning can rely purely on mathematical principles, the most important of which is Bayes’s theorem. The theorem says that we should assign initial probabilities to hypotheses based on our knowledge, then let the hypotheses that are consistent with the data become more probable and those that are not become less so. It then makes predictions by letting all the hypotheses vote, with the more probable ones carrying more weight. Bayesian learning machines can do some medical diagnoses more accurately than human doctors. They are also at the heart of many spam filters and of the system that Google uses to choose which ads to show you.Recommended StoriesSuperhuman AI Bots Are Surprisingly Vulnerable to ExploitsMatthew Hutson & Nature magazineWe Cannot Cede Control of Weapons to Artificial IntelligenceKate Graham-ShawAI Chatbots Seem as Ethical as a New York Times Advice ColumnistDan FalkWhat Does Artificial General Intelligence Actually Mean?Lauren LefferEach of these five kinds of machine learning has its strengths and weaknesses. Deep learning, for example, is good for perceptual problems such as vision and speech recognition but not for cognitive ones such as acquiring commonsense knowledge and reasoning. With symbolic learning, the reverse is true. Evolutionary algorithms are capable of solving harder problems than neural networks, but it can take a very long time to solve them. Analogical methods can learn from just a small number of instances but are liable to get confused when given too much information about each. Bayesian learning is most useful for dealing with small amounts of data but can be prohibitively expensive with big data.These vexing trade-offs are why machine-learning researchers are working toward combining the best elements of all the paradigms. In the same way that a master key opens all locks, our goal is to create a so-called master algorithm—one that can learn everything that can be extracted from data, deriving all possible knowledge from it.The challenge on us now is similar to the one faced by physicists: quantum mechanics is effective at describing the universe at the smallest scales and general relativity at the largest scales, but the two are incompatible and need to be reconciled. And in the same way that James Clerk Maxwell first unified light, electricity and magnetism before the Standard Model of particle physics could be developed, different research groups, including mine at the University of Washington, have proposed ways to unify two or more of the machine-learning paradigms. Because scientific progress is not linear and instead happens in fits and starts, it is difficult to predict when the full unification of the master algorithm might be complete. Regardless, achieving this goal will not usher in a new, dominant race of machines. Rather it will accelerate human progress.Machine Takeover?Once we attain the master algorithm and feed it the vast quantities of data each of us produce, artificial-intelligence systems will potentially be able to learn very accurate and detailed models of individual people: our tastes and habits, strengths and weaknesses, memories and aspirations, beliefs and personalities, the people and things we care about, and how we will respond in any given situation. That models of us could essentially predict the choices we will make is both exciting and disquieting.Many worry that machines with these capabilities will use their newfound knowledge to take all our jobs, enslave us or even exterminate us. But that is unlikely to happen because they have no will of their own. Essentially all AI algorithms are driven by goals that we program, such as “find the shortest route from the hotel to the airport.” What distinguishes these algorithms from ordinary ones is that they have a lot of flexibility in figuring out how to reach the goals we set for them rather than needing to execute a predefined series of steps. Even as they get better at the task with experience, the goals remain unchanged. Solutions that do not make progress toward the goal are automatically discarded. Plus, humans get to check that what the machines produce does indeed satisfy our objectives. We are also able to verify that the machines do not violate any of the constraints we put on them, such as “obey the rules of the road.”When we envision an AI, though, we tend to project onto it human qualities such as volition and consciousness. Most of us are also more familiar with humanlike AIs, such as home robots, than with the myriad other types that do their work behind the scenes. Hollywood compounds this perception by depicting robots and AIs as humans in disguise—an understandable tactic that makes for a more compelling story. Artificial intelligence is just the ability to solve hard problems—a task that does not require free will. It is no more likely to turn against us than your hand is to slap you. Like any other technology, AIs will always be extensions of us. The more powerful we can make them, the better.




SMART BOT: This sea star uses evolutionary algorithms to learn how to simulate itself. These algorithms are one type of machine learning that could be unified with others into a “master algorithm,” a singularly powerful human tool. Credit: Victor Zykov and Josh Bongard
Sign Up for Our Daily NewsletterEmail AddressBy giving us your email, you are agreeing to receive the Today In Science newsletter and to our Terms of Use and Privacy Policy.Sign UpThank you for signing up! Check out our other newslettersWhat, then, might our AI-enabled future look like? Intelligent machines will indeed supplant many jobs, but the effects on society will likely be similar to previous forms of automation. Two hundred years ago the majority of Americans were farmers. Yet today machines have replaced almost all of them without causing massive unemployment. Doomsayers argue that this time is different because machines are replacing our brains, not just our brawn, leaving nothing for humans to do. But the day that AIs can carry out all the tasks we can is still very distant, if it ever comes. For the foreseeable future, AIs and humans will be good at different things. Machine learning’s primary effect will be to greatly lower the cost of intelligence. This democratization will increase the variety of economically feasible uses of that intelligence, generating new jobs and transforming old ones to accomplish more with the same amount of human labor.Then there is the “singularity” scenario, popularized by futurist Ray Kurzweil. It is one of ever accelerating technological progress: machines learn to make better machines, which in turn make even better ones, and so on. But we know that this cannot continue forever because the laws of physics place strict limits on how powerful even a quantum computer can be, and in some aspects, we are not far from hitting them. The progress of AI, like the progress of everything else, will eventually plateau.Another vision popular among futurists is that computer models of us will become so good that they will be practically indistinguishable from the real thing. In this scenario, we could upload ourselves to the cloud and live on forever as pieces of software, free of the pesky constraints of the physical world. One problem with this scenario is that it may not be biologically feasible. To upload yourself, you would presumably need an accurate model of each of your neurons, complete with the memories they store. It would have to be captured so reliably that the model’s predictions would not rapidly diverge from the behavior of the real neurons—a tall order indeed.But even if this were a realistic option, would you really upload yourself if you had the chance? How could you know for sure that your model was not missing some essential part of you—or that it was conscious at all? What if a thief stole your identity in the most absolute and complete sense of the word? I believe that people will opt to hang on to their squishy, carbon-based selves—the “wetware,” as computer scientists jokingly call it—for as long as they can and then call it quits.Cherchez l’humainAI—machine learning in particular—is really just the continuation of human evolution. In The Extended Phenotype, Richard Dawkins shows how common it is for animals’ genes to control the environment beyond their bodies, from cuckoo eggs to beaver dams. Technology is the extended phenotype of humans, and what we are building today is another layer of our technological exoskeleton. I think the most likely scenario for how humans will use AI is more fascinating than the usual speculations.Within a decade or so each one of us will probably have a “digital double,” an AI companion that will be even more indispensable than our smartphones are today. Your digital double will not need to physically move around with you; most likely it will live somewhere in the cloud, just as much of your data already does. We can see its beginnings in virtual assistants such as Siri, Alexa and Google Assistant. At the heart of your digital double will be a model of you, learned from all the data you have ever generated in your interactions with the digital world, from desktop computers and Web sites to wearable devices and sensors in the environment such as smart speakers, thermostats, cell-phone towers and video cameras.The better our learning algorithms become and the more personal data we feed them, the more accurate our digital doubles will get. Once we have the master algorithm and then couple it with continuous capture of your sensorimotor stream via an augmented-reality headset and other personal sensors, your double will grow to know you better than your best friend.The model and data will be maintained by a “data bank,” not unlike a traditional bank that stores and invests your money. Many existing companies would surely like to provide that service for you. Google co-founder Sergey Brin has said that Google wants to be “the third half of your brain,” but you probably would not want part of your brain to subsist by showing you ads. You might be better served by a new kind of company with fewer conflicts of interest or by a data union you form with like-minded people.After all, the central worry about AI is not that it will spontaneously turn evil but that the humans who control it will misuse it (cherchez l’humain, as the French might say—“look to the human”). So your data bank’s first duty will be to ensure that your model is never used against your interests. Both you and the data bank must be vigilant about monitoring AI crime because this technology will empower bad actors as much as anyone. We will need AI police (the Turing police, as William Gibson called it in his 1984 book Neuromancer) to catch the AI criminals.If you have the misfortune of living under an authoritarian regime, this scenario could usher in unprecedented dangers because it will allow the government to monitor and restrain you like never before. Given the speed at which machine learning is progressing and the predictive policing systems already in use, the Minority Report scenario—where people are preemptively arrested when they are about to commit a crime—no longer seems far-fetched. Then there are the implications of inequality as the world adapts to the speed of life with digital doubles before all of us are able to afford one.Our first duty, as individuals, will be not to become complacent and trust our digital doubles beyond their years. From the outside, AIs may seem objective, even perfect, but inside they are as flawed as we are or more, just in different ways. For example, AIs lack common sense and can easily make errors that a human never would, such as mistaking a person crossing the street for a windblown plastic bag. They are also liable to take our instructions too literally, giving us precisely what we asked for instead of what we actually wanted. (So think twice before telling your self-driving car to get you to the airport on time at all costs.)Practically speaking, your digital double will be similar enough to you to take your place in all kinds of virtual interactions. Its job will not be to live your life for you but rather to make all the choices you do not have the time, patience or knowledge for. It will read every book on Amazon and recommend the few that you are most likely to want to read yourself. If you need a car, it will research the options and haggle with the car dealer’s bots. If you are job hunting, it will interview itself for all the positions that fit your needs and then schedule live interviews for you for the most promising ones. If you get a cancer diagnosis, it will try all potential treatments and recommend the most effective ones. (It will be your ethical duty to use your digital double for the greater good by letting it take part in medical research, too.) And if you are seeking a romantic partner, your double will go on millions of virtual dates with all eligible doubles. The pairs that hit it off in cyberspace can then go on a date in real life.Essentially your double will live out countless probable lives in cyberspace so that the single one you live in the physical world is likely to be the best version. Whether your simulated lives are somehow “real” and your cyberselves have a kind of consciousness (as portrayed in the plots of some Black Mirror episodes, for instance) are interesting philosophical questions.Some people worry that this means that we are handing over control of our lives to computers. But it actually gives us more control, not less, because it allows us to make choices we could not before. Your model will also learn from the results of each virtual experience (Did you enjoy the date? Do you like your new job?) so that over time, it will become better at suggesting the things you would choose for yourself.In fact, we are already accustomed to most of our decision-making taking place without our conscious intervention because that is what our brains do now. Your digital double will be like a greatly expanded subconscious, with one key difference: Whereas your subconscious lives alone inside your skull, your digital double will continuously interact with those of other people and organizations. Everyone’s doubles will keep trying to learn models of one another, and they will form a society of models, living at computer speeds, branching out in all directions, figuring out what we would do if we were there.Our machines will be our scouts, blazing a trail into the future for us as individuals and as a species. Where will they lead us? And where will we choose to go?Rights & PermissionsMORE TO EXPLORE
The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Pedro Domingos. Basic Books, 2015.
The Digital Mind: How Science Is Redefining Humanity. Arlindo Oliveira. MIT Press, 2017.
FROM OUR ARCHIVES
Self-Taught Robots. Diana Kwon; March 2018.Pedro Domingos is a professor of computer science at the University of Washington and author of The Master Algorithm (Basic Books, 2015). A fellow of the Association for the Advancement of Artificial Intelligence, he lives near Seattle.More by Pedro DomingosThis article was originally published with the title “Our Digital Doubles” in Scientific American Magazine Vol. 319 No. 3 (September 2018), p. 88doi:10.1038/scientificamerican0918-88View This Issue","Artificial Intelligence Will Serve Humans, Not Enslave Them","Artificial Intelligence Will Serve Humans, Not Enslave Them",https://static.scientificamerican.com/sciam/cache/file/8B13C15C-2443-4544-993796DC12AA575C_source.jpg?w=1200,False,"{'@id': 'https://www.scientificamerican.com/#publisher', 'name': 'Scientific American'}",https://www.scientificamerican.com/#publisher,Scientific American,SciAm,"Scientific American, a Division of Springer Nature America, Inc.",1845-08-28,"{'@type': 'ImageObject', 'url': 'https://www.scientificamerican.com/static/sciam.svg'}",https://www.scientificamerican.com/masthead/,"['https://en.wikipedia.org/wiki/Scientific_American', 'https://www.wikidata.org/wiki/Q39379', 'https://www.jstor.org/publisher/sciamerican', 'https://x.com/sciam', 'https://www.youtube.com/user/SciAmerican', 'https://www.tiktok.com/@scientificamerican', 'https://www.threads.net/@scientific_american', 'https://www.facebook.com/ScientificAmerican/']","{'@type': 'PostalAddress', 'streetAddress': '1 New York Plaza', 'addressLocality': 'New York', 'addressRegion': 'NY', 'postalCode': '10004', 'addressCountry': 'US'}",,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiS2h0dHBzOi8vaHViLnBhY2t0cHViLmNvbS84LXdheXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY2FuLWltcHJvdmUtZGV2b3BzL9IBT2h0dHBzOi8vaHViLnBhY2t0cHViLmNvbS84LXdheXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY2FuLWltcHJvdmUtZGV2b3BzL2FtcC8?oc=5,8 ways Artificial Intelligence can improve DevOps - Packt Hub,2018-09-01,Packt Hub,https://hub.packtpub.com,"DevOps combines development and operations in an agile manner. ITOps refers to network infrastructure, computer operations, and device management. AIOps",N/A,"DevOps combines development and operations in an agile manner. ITOps refers to network infrastructure, computer operations, and device management. AIOps",N/A,http://schema.org,BreadcrumbList,,,,,,,,,,N/A,N/A,"

Home  Cloud & Networking  DevOps  8 ways Artificial Intelligence can improve DevOps


Cloud & NetworkingDevOpsInsights 8 ways Artificial Intelligence can improve DevOps

By Prasad Ramesh -   September 1, 2018 - 10:00 am 4548 0 










6 min readDevOps combines development and operations in an agile manner. ITOps refers to network infrastructure, computer operations, and device management. AIOps is artificial intelligence applied to ITOps, a term coined by Gartner. Makes us wonder what AI applied to DevOps would look like.
Currently, there are some problem areas in DevOps that mainly revolve around data. Namely, accessing the large pool of data, taking actions on it, managing alerts etc. Moreover, there are errors caused by human intervention. AI works heavily with data and can help improve DevOps in numerous ways. Before we get into how AI can improve DevOps, let’s take a look at some of the problem areas in DevOps today.
The trouble with DevOps
Human errors: When testing or deployment is performed manually and there is an error, it is hard to repeat and fix. Many a time, the software development is outsourced in companies. In such cases, there is lack of coordination between the dev and ops teams.
Environment inconsistency: Software functionality breaks when the code moves to different environments as each environment has different configurations. Teams can run around wasting a lot of time due to bugs when the software works fine on one environment but not on the other.
Change management: Many companies have change management processes well in place, but they are outdated for DevOps. The time taken for reviews, passing a new module etc is manual and proves to be a bottleneck. Changes happen frequently in DevOps and the functioning suffers due to old processes.
Monitoring: Monitoring is key to ensure smooth functioning in Agile. Many companies do not have the expertise to monitor the pipeline and infrastructure. Moreover monitoring only the infrastructure is not enough, there also needs to be monitoring of application performance, solutions need to be logged and analytics need to be tracked.

Now let’s take a look at 8 ways AI can improve DevOps given the above context.
1. Better data access
One of the most critical issues faced by DevOps teams is the lack of unregulated access to data. There is also a large amount of data, while the teams rarely view all of the data and focus on the outliers. The outliers only work as an indicator but do not give robust information. Artificial intelligence can compile and organize data from multiple sources for repeated use. Organized data is much easier to access and understand than heaps of raw data. This will help in predictive analysis and eventually a better decision making process. This is very important and enables many other ways listed below.
2. Superior implementation efficiency
Artificially intelligent systems can work with minimal or no human intervention. Currently, a rules-based environment managed by humans is followed in DevOps teams. AI can transform this into self governed systems to greatly improve operational efficiency. There are limitations to the volume and complexity of analysis a human can perform. Given the large volumes of data to be analyzed and processed, AI systems being good at it, can set optimal rules to maximize operational efficiencies.
3. Root cause analysis
Conducting root cause analysis is very important to fix an issue permanently. Not getting to the root cause allows for the cause to persist and affect other areas further down the line. Often, engineers don’t investigate failures in depth and are more focused on getting the release out. This is not surprising given the limited amount of time they have to work with. If fixing a superficial area gets things working, the root cause is not found. AI can take all data into account and see patterns between activity and cause to find the root cause of failure.
4 Automation
Complete automation is a problem in DevOps, many tasks in DevOps are routine and need to be done by humans. An AI model can automate these repeatable tasks and speed up the process significantly. A well-trained model increases the scope of complexity of the tasks that can be automated by machines. AI can help achieve least human intervention so that developers can focus on more complex interactive problems. Complete automation also allows the errors to be reproduced and fixed promptly.
5 Reduce Operational Complexity
AI can be used to simplify operations by providing a unified view. An engineer can view all the alerts and relevant data produced by the tools in a single place. This improves the current scenario where engineers have to switch between different tools to manually analyze and correlate data. Alert prioritization, root cause analysis, evaluating unusual behavior are complex time consuming tasks that depend on data. An organized singular view can greatly benefit in looking up data when required.
“AI and machine learning makes it possible to get a high-level view of the tool-chain, but at the same time zoom in when it is required.” -SignifAI
6 Predicting failures
A critical failure in a particular tool/area in DevOps can cripple the process and delay cycles. With enough data, machine learning models can predict when an error can occur. This goes beyond simple predictions. If an occurred fault is known to produce certain readings, AI can read patterns and predict the signs failure. AI can see indicators that humans may not be able to. As such early failure prediction and notification enable the team to fix it before it can affect the software development life cycle (SDLC).
7 Optimizing a specific metric
AI can work towards solutions where the uptime is maximized. An adaptive machine learning system can learn how the system works and improve it. Improving could mean tweaking a specific metric in the workflow for optimized performance. Configurations can be changed by AI for optimal performance as required during different production phases. Real-time analysis plays a big part in this.
8 Managing Alerts
DevOps systems can be flooded with alerts which are hard for humans to read and act upon. AI can analyze these alerts in real-time and categorize them. Assigning priority to alerts helps teams towards work on fixing them rather than going through a long list of alerts. The alerts can simply be tagged by a common ID for specific areas or AI can be trained for classifying good and bad alerts. Prioritizing alerts in such a way that flaws are shown first to be fixed will help smooth functioning.
Conclusion
As we saw, most of these areas depend heavily on data. So getting the system right to enhance data accessibility is the first step to take. Predictions work better when data is organized, performing root cause analysis is also easier. Automation can repeat mundane tasks and allow engineers to focus on more interactive problems that machines cannot handle. With machine learning, the overall operation efficiency, simplicity, and speed can be improved for smooth functioning of DevOps teams.
Read next
Why Agile, DevOps and Continuous Integration are here to stay: Interview with Nikhil Pathania, DevOps practitioner
Top 7 DevOps tools in 2018
GitLab’s new DevOps solution

 


TAGSAI News 




Share
FacebookTwitterLinkedin

 Prasad RameshData science enthusiast. Cycling, music, food, movies. Likes FPS and strategy games.  


LEAVE A REPLY Cancel reply


Please enter your comment!


Please enter your name here



You have entered an incorrect email address!
Please enter your email address here




Save my name, email, and website in this browser for the next time I comment.
 

Δ 










",,,,,,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://hub.packtpub.com/#organization', 'name': 'Packt', 'url': 'https://hub.packtpub.com/', 'sameAs': ['https://www.facebook.com/PacktPub', 'https://www.linkedin.com/company/packt-publishing/', 'https://www.youtube.com/channel/UC3VydBGBl132baPCLeDspMQ', 'https://twitter.com/PacktPublishing'], 'logo': {'@type': 'ImageObject', '@id': 'https://hub.packtpub.com/#logo', 'inLanguage': 'en-US', 'url': 'https://hub.packtpub.com/wp-content/uploads/2018/03/packt-retina-2.png', 'width': '368', 'height': '180', 'caption': 'Packt'}, 'image': {'@id': 'https://hub.packtpub.com/#logo'}}, {'@type': 'WebSite', '@id': 'https://hub.packtpub.com/#website', 'url': 'https://hub.packtpub.com/', 'name': 'Packt Hub', 'description': 'Tech News, Insights and Tutorials from Packt Publishing', 'publisher': {'@id': 'https://hub.packtpub.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://hub.packtpub.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/#primaryimage', 'inLanguage': 'en-US', 'url': 'https://hub.packtpub.com/wp-content/uploads/2018/04/iStock-531240484.jpg', 'width': 1820, 'height': 1024, 'caption': 'DevOps tools'}, {'@type': 'WebPage', '@id': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/#webpage', 'url': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/', 'name': '8 ways Artificial Intelligence can improve DevOps | Packt Hub', 'isPartOf': {'@id': 'https://hub.packtpub.com/#website'}, 'primaryImageOfPage': {'@id': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/#primaryimage'}, 'datePublished': '2018-09-01T14:00:53+00:00', 'dateModified': '2018-09-19T10:30:10+00:00', 'description': 'DevOps combines development and operations in an agile manner. ITOps refers to network infrastructure, computer operations, and device management. AIOps', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/']}]}, {'@type': ['Article', 'NewsArticle'], '@id': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/#article', 'isPartOf': {'@id': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/#webpage'}, 'author': {'@id': 'https://hub.packtpub.com/#/schema/person/088d1b4df88147952aa6bf0c765523ad'}, 'headline': '8 ways Artificial Intelligence can improve DevOps', 'datePublished': '2018-09-01T14:00:53+00:00', 'dateModified': '2018-09-19T10:30:10+00:00', 'mainEntityOfPage': {'@id': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/#webpage'}, 'commentCount': 0, 'publisher': {'@id': 'https://hub.packtpub.com/#organization'}, 'image': {'@id': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/#primaryimage'}, 'keywords': 'AI News', 'articleSection': 'DevOps,Cloud &amp; Networking,Insights', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://hub.packtpub.com/#organization'}}, {'@type': 'Person', '@id': 'https://hub.packtpub.com/#/schema/person/088d1b4df88147952aa6bf0c765523ad', 'name': 'Prasad Ramesh', 'image': {'@type': 'ImageObject', '@id': 'https://hub.packtpub.com/#personlogo', 'inLanguage': 'en-US', 'url': 'https://hub.packtpub.com/wp-content/uploads/2018/08/prasad-96x96.jpg', 'caption': 'Prasad Ramesh'}, 'description': 'Data science enthusiast. Cycling, music, food, movies. Likes FPS and strategy games.'}]","[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://hub.packtpub.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://hub.packtpub.com/category/cloud-and-networking/', 'name': 'Cloud &amp; Networking'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://hub.packtpub.com/category/cloud-and-networking/devops/', 'name': 'DevOps'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@type': 'WebPage', '@id': 'https://hub.packtpub.com/8-ways-artificial-intelligence-can-improve-devops/', 'name': '8 ways Artificial Intelligence can improve DevOps'}}]",,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LmVudHJlcHJlbmV1ci5jb20vc2NpZW5jZS10ZWNobm9sb2d5L3RoZXNlLWVudHJlcHJlbmV1cnMtYXJlLXRha2luZy1vbi1iaWFzLWluLWFydGlmaWNpYWwvMzE5MjI40gEA?oc=5,These Entrepreneurs Are Taking on Bias in Artificial Intelligence - Entrepreneur,2018-09-05,Entrepreneur,https://www.entrepreneur.com,"Meet the founders, data scientists and researchers trying to make sure the algorithms that increasingly run our lives are free from bias.","Science & Technology,Technology,Gender Bias,Artificial Intelligence,Biases","Meet the founders, data scientists and researchers trying to make sure the algorithms that increasingly run our lives are free from bias.","Meet the founders, data scientists and researchers trying to make sure the algorithms that increasingly run our lives are free from bias.",https://schema.org,BreadcrumbList,https://www.entrepreneur.com,,,,,,,,,These Entrepreneurs Are Taking on Bias in Artificial Intelligence | Entrepreneur,N/A,"


  These Entrepreneurs Are Taking on Bias in Artificial Intelligence
  
    Meet the founders, data scientists and researchers trying to make sure the algorithms that increasingly run our lives are free from bias.
  





                  By          
            Liz Webber
          

            Sep 5, 2018
          




          Share        


Copy


 






Subscribe to the Entrepreneur Daily newsletter to get business news, tips and inspiration sent to your inboxSubscribeI understand that the data I am submitting will be used to provide me with the above-described products and/or services and communications in connection therewith.Read our privacy policy for more information.










sorbetto | Getty Images


Whether it's a navigation app such as Waze, a music recommendation service such as Pandora or a digital assistant such as Siri, odds are you've used artificial intelligence in your everyday life.""Today 85 percent of Americans use AI every day,"" says Tess Posner, CEO of AI4ALL.AI has also been touted as the new must-have for business, for everything from customer service to marketing to IT. However, for all its usefulness, AI also has a dark side. In many cases, the algorithms are biased.



Related: What Is AI, Anyway? Know Your Stuff With This Go-To Guide.Some of the examples of bias are blatant, such as Google's facial recognition tool tagging black faces as gorillas or an algorithm used by law enforcement to predict recidivism disproportionately flagging people of color. Others are more subtle. When Beauty.AI held an online contest judged by an algorithm, the vast majority of ""winners"" were light-skinned. Search Google for images of ""unprofessional hair"" and the results you see will mostly be pictures of black women (even searching for ""man"" or ""woman"" brings back images of mostly white individuals).While more light has been shined on the problem recently, some feel it's not an issue addressed enough in the broader tech community, let alone in research at universities or the government and law enforcement agencies that implement AI.""Fundamentally, bias, if not addressed, becomes the Achilles' heel that eventually kills artificial intelligence,"" says Chad Steelberg, CEO of Veritone. ""You can't have machines where their perception and recommendation of the world is skewed in a way that makes its decision process a non-sequitur from action. From just a basic economic perspective and a belief that you want AI to be a powerful component to the future, you have to solve this problem.""As artificial intelligence becomes ever more pervasive in our everyday lives, there is now a small but growing community of entrepreneurs, data scientists and researchers working to tackle the issue of bias in AI. I spoke to a few of them to learn more about the ongoing challenges and possible solutions.Cathy O'Neil, founder of O'Neil Risk Consulting & Algorithmic AuditingSolution: Algorithm auditing


Back in the early 2010s, Cathy O'Neil was working as a data scientist in advertising technology, building algorithms that determined what ads users saw as they surfed the web. The inputs for the algorithms included innocuous-seeming information like what search terms someone used or what kind of computer they owned.However, O'Neil came to realize that she was actually creating demographic profiles of users. Although gender and race were not explicit inputs, O'Neil's algorithms were discriminating against users of certain backgrounds, based on the other cues.As O'Neil began talking to colleagues in other industries, she found this to be fairly standard practice. These biased algorithms weren't just deciding what ads a user saw, but arguably more consequential decisions, such as who got hired or whether someone would be approved for a credit card. (These observations have since been studied and confirmed by O'Neil and others.)What's more, in some industries -- for example, housing -- if a human were to make decisions based on the specific set of criteria, it likely would be illegal due to anti-discrimination laws. But, because an algorithm was deciding, and gender and race were not explicitly the factors, it was assumed the decision was impartial.""I had left the finance [world] because I wanted to do better than take advantage of a system just because I could,"" O'Neil says. ""I'd entered data science thinking that it was less like that. I realized it was just taking advantage in a similar way to the way finance had been doing it. Yet, people were still thinking that everything was great back in 2012. That they were making the world a better place.""O'Neil walked away from her adtech job. She wrote a book, Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy,  about the perils of letting algorithms run the world, and started consulting.Eventually, she settled on a niche: auditing algorithms.""I have to admit that it wasn't until maybe 2014 or 2015 that I realized this is also a business opportunity,"" O'Neil says.Right before the election in 2016, that realization led her to found O'Neil Risk Consulting & Algorithmic Auditing (ORCAA).""I started it because I realized that even if people wanted to stop that unfair or discriminatory practices then they wouldn't actually know how to do it,"" O'Neil says. ""I didn't actually know. I didn't have good advice to give them."" But, she wanted to figure it out.So, what does it mean to audit an algorithm?""The most high-level answer to that is it means to broaden our definition of what it means for an algorithm to work,"" O'Neil says.Often, companies will say an algorithm is working if it's accurate, effective or increasing profits, but for O'Neil, that shouldn't be enough.""So, when I say I want to audit your algorithm, it means I want to delve into what it is doing to all the stakeholders in the system in which you work, in the context in which you work,"" O'Neil says. ""And the stakeholders aren't just the company building it, aren't just for the company deploying it. It includes the target for the algorithm, so the people that are being assessed. It might even include their children. I want to think bigger. I want to think more about externalities, unforeseen consequences. I want to think more about the future.""For example, Facebook's News Feed algorithm is very good at encouraging engagement and keeping users on its site. However, there's also evidence it reinforces users' beliefs, rather than promoting dialog, and has contributed to ethnic cleansing. While that may not be evidence of bias, it's certainly not a net positive.Right now, ORCAA's clients are companies that ask for their algorithms to be audited because they want a third party -- such as an investor, client or the general public -- to trust it. For example, O'Neil has audited an internal Siemens project and New York-based Rentlogic's landlord rating system algorithm. These types of clients are generally already on the right track and simply want a third-party stamp of approval.


However, O'Neil's dream clients would be those who don't necessarily want her there.""I'm going to be working with them because some amount of pressure, whether it's regulatory or litigation or some public relations pressure kind of forces their hand and they invite me in,"" O'Neil says.Most tech companies pursue profit above all else, O'Neil says, and won't seriously address the issue of bias unless there are consequences. She feels that existing anti-discrimination protections need to be enforced in the age of AI.""The regulators don't know how to do this stuff,"" O'Neil says. ""I would like to give them tools. But, I have to build them first. ... We basically built a bunch of algorithms assuming they work perfectly, and now it's time to start building tools to test whether they're working at all.""Related: Artificial Intelligence Is Likely to Make a Career in Finance, Medicine or Law a Lot Less LucrativeFrida Polli, co-founder and CEO of PymetricsSolution: Open source AI auditingMany thought artificial intelligence would solve the problem of bias in hiring, by making sure human evaluators weren't prejudging candidates based on the name they saw on a resume or the applicant's appearance. However, some argue hiring algorithms end up perpetuating the biases of their creators.Pymetrics is one company that develops algorithms to help clients fill job openings based on the traits of high-performing existing employees. It believes it's found a solution to the bias problem in an in-house auditing tool, and now it's sharing the tool with the world.


Co-founder and CEO Frida Polli stresses that fighting bias was actually a secondary goal for Pymetrics.""We're not a diversity-first platform,"" Polli says. ""We are a predictive analytics platform.""However, after seeing that many of her clients' employee examples used to train Pymetrics's algorithms were not diverse, combating bias became important.""Either you do that or you're actually perpetuating bias,"" Polli says. ""So, we decided we certainly were not going to perpetuate bias.""Early on, the company developed Audit AI to make sure its algorithms were as neutral as possible when it came to factors including gender and race. If a company looking to fill a sales role had a sales team that was predominantly white and male, an unaudited algorithm might pick a candidate with those same traits. Polli was quick to point out that Audit AI would also recommend adjustments if an algorithm was weighted in favor of women or people of color.Some critics say if you tweak a hiring algorithm to remove bias you're lowering the bar, but Polli disagrees.""It's the age-old criticism that's like, 'oh well, you're not getting the best candidate,'"" Polli says. ""'You're just getting the most diverse candidate, because now you've lowered how well your algorithm is working.' What's really awesome is that we don't see that. We have not seen this tradeoff at all.""In May, Pymetrics published the code for its internal Audit AI auditing tool on Github. Polli says the first goal for making Audit AI open source is to encourage others to develop auditing techniques for their algorithms.


""If they can learn something from the way that we're doing it that's great. Obviously there are many ways to do it but we're not saying ours is the only way or the best way.""Other motivations include simply starting a conversation about the issue and potentially learning from other developers who may be able to improve Audit AI.""We certainly don't believe in sort of proprietary debiasing because that would sort of defeat the purpose,"" Polli says.""The industry just needs to be more comfortable in actually realizing that if you're not checking your machine learning algorithms and you're saying, 'I don't know whether they cause bias,' I just don't think that that should be acceptable,"" she says. ""Because it's like the ostrich in the sand approach.""Related: The Scariest Thing About AI Is the Competitive Disadvantage of Being Slow to AdaptRediet Abebe, co-founder of Black in AI and Mechanism Design for Social GoodSolution: Promoting diverse AI programmers and researchers Use of facial recognition has grown dramatically in recent years -- whether it's for unlocking your phone, expediting identification at the airport or scanning faces in a crowd to find potential criminals. But, it's also prone to bias.MIT Media Lab researcher Joy Buolamwini and Timnit Gehru, who received her PhD from the Stanford Artificial Intelligence Laboratory, found that facial recognition tools from IBM, Microsoft and Face++ accurately identified the gender of white men almost 100 percent of the time, but failed to identify darker skinned women in 20 percent to 34 percent of cases. That could be because the training sets themselves were biased: The two also found that the images used to train one of the facial recognition tools were 77 percent male and more than 83 percent white.


One reason machine learning algorithms end up being biased is that they reflect the biases -- whether conscious or unconscious -- of the developers who built them. The tech industry as a whole is predominantly white and male, and one study by TechEmergence found women make up only 18 percent of C-level roles at AI and machine learning companies.Some in the industry are trying to change that.In March 2017, a small group of computer science researchers started a community called Black in AI because of an ""alarming absence of black researchers,"" says co-founder Rediet Abebe, a PhD candidate in computer science at Cornell University. (Gehru is also a co-founder.)""In the conferences that I normally attend there's often no black people. I'd be the only black person,"" Abebe says. ""We realized that this was potentially a problem, especially since AI technologies are impacting our day-to-day lives and they're involved in decision-making and a lot of different domains,"" including criminal justice, hiring, housing applications and even what ads you see online.""All these things are now being increasingly impacted by AI technologies, and when you have a group of people that maybe have similar backgrounds or correlated experiences, that might impact the kinds of problems that you might work on and the kind of products that you put out there,"" Abebe says. ""We felt that the lack of black people in AI was potentially detrimental to how AI technologies might impact black people's lives.""Adebe feels particularly passionate about including more African women in AI; growing up in Ethiopia, a career in the sciences didn't seem like a possibility, unless she went into medicine. Her own research focuses on how certain communities are underserved or understudied when it comes to studying societal issues -- for example, there is a lack of accurate data on HIV/AIDS deaths in developing countries -- and how AI can be used to address those discrepancies. Adebe is also the co-founder and co-organizer of Mechanism Design for Social Good, an interdisciplinary initiative that shares research on AI's use in confronting similar societal challenges through workshops and meetings.Initially, Abebe thought Black in AI would be able to rent a van to fit all the people in the group, but Black in AI's Facebook group and email list has swollen to more than 800 people, from all over the world. While the majority of members are students or researchers, the group also includes entrepreneurs and engineers.Black in AI's biggest initiative to date was a workshop at the Conference on Neural Information Processing Systems (NIPS) in December 2017 that garnered about 200 attendees. Thanks to partners such as Facebook, Google and ElementAI, the group was able to give out over $150,000 in travel grants to attendees.


Abebe says a highlight of the workshop was a keynote talk by Haben Girma, the first deaf/blind graduate from Harvard Law School, which got Abebe thinking about other types of diversity and intersectionality.Black in AI is currently planning its second NIPS workshop.As part of the more informal discussions happening in the group's forums and Facebook group, members have applied and been accepted to Cornell's graduate programs, research collaborations have started and industry allies have stepped forward to ask how they can help. Black in AI hopes to set up a mentoring program for members.Related: Why Are Some Bots Racist? Look at the Humans Who Taught Them.Tess Posner, CEO of AI4ALLSolution: Introducing AI to diverse high schoolersThe nonprofit AI4ALL is targeting the next generation of AI whiz kids. Through summer programs at prestigious universities, AI4ALL exposes girls, low-income students, racial minorities and those from diverse geographic backgrounds to the possibilities of AI.""It's becoming ubiquitous and invisible,"" says Tess Posner, who joined AI4ALL as founding CEO in 2017. ""Yet, right now it's being developed by a homogenous group of technologists mostly. This is leading to negative impacts like race and gender bias getting incorporated into AI and machine learning systems. The lack of diversity is really a root cause for this.""She adds, ""The other piece of it is we believe that this technology has such exciting potential to be addressed to solving some key issues or key problems facing the world today, for example in health care or in environmental issues, in education. And it has incredibly positive potential for good.""


Started as a pilot at Stanford University in 2015 as a summer camp for girls, AI4ALL now offers programs at six universities around the country: University of California Berkeley, Boston University, Carnegie Mellon University, Princeton University, Simon Fraser University and Stanford.Participants receive a mix of technical training, hands-on learning, demos of real-world applications (such as a self-driving car), mentorship and exposure to experts in the field. This year, guest speakers included representatives from big tech firms including Tesla, Google and Microsoft, as well as startups including H20.ai, Mobileye and Argo AI.The universities provide three to five ""AI for good"" projects for students to work on during the program. Recent examples include developing algorithms to identify fake news, predict the infection path of the flu and map poverty in Uganda.For many participants, the AI4ALL summer program is only the beginning.""We talk about wanting to create future leaders in AI, not just future creators, that can really shape what the future of this technology can bring,"" Posner says.AI4ALL recently piloted an AI fellowship program for summer program graduates to receive funding and mentorship to work on their own projects. One student's project involved tracking wildfires on the West Coast, while another looked at how to optimize ambulance dispatches based on the severity of the call after her grandmother died because an ambulance didn't reach her in time.Other graduates have gone on to create their own ventures after finishing the program, and AI4ALL provides ""seed grants"" to help them get started. Often, these ventures involve exposing other kids like themselves to AI. For example, three alumni started a workshop series called creAIte to teach middle school girls about AI and computer science using neural art, while another runs an after school workshop called Girls Explore Tech.Another graduate co-authored a paper on using AI to improve surgeons' technique that won an award at NIPS's Machine Learning for Health workshop in 2017.


""We have a lot of industry partners who have seen our students' projects and they go, 'Wow. I can't believe how amazing and rigorous and advanced this project is.' And it kind of changes people's minds about what talent looks like and who the face of AI really is,"" Posner says.Last month, AI4ALL announced it will be expanding its reach in a big way: The organization received a $1 million grant from Google to create a free digital version of its curriculum, set to launch in early 2019.Related: Artificial Intelligence May Reflect the Unfair World We Live inChad Steelberg, co-founder and CEO of VeritoneSolution: Building the next generation of AISerial entrepreneur Chad Steelberg first got involved in AI during his high school years in the 1980s, when he worked on algorithms to predict the three-dimensional structures of proteins. At the time, he felt AI's capabilities had reached a plateau, and he ended up starting multiple companies in different arenas, one of which he sold to Google in 2006.A few years later, Steelberg heard from some friends at Google that AI was about to take a huge leap forward -- algorithms that could actually understand and make decisions, rather than simply compute data and spit back a result. Steelberg saw the potential, and he invested $10 million of his own money to found Veritone.Veritone's aiWARE is an operating system for AI. Instead of communicating between the software and hardware in a computer, like a traditional operating system, it takes users' queries -- such as ""transcribe this audio clip"" -- and finds the best algorithm available to process that query, whether that's Google Cloud Speech-to-Text, Nuance or some other transcription engine. As of now, aiWARE can scan more than 200 models in 16 categories, from translation to facial recognition.Algorithms work best when they have a sufficiently narrow training set. For example, if you try to train one algorithm to play go, chess and checkers, it will fail at all three, Steelberg says. Veritone tells the companies it works with to create algorithms for very narrow use cases, such as images of faces in profile. AiWARE will find the right algorithm for the specific query, and can even trigger multiple algorithms for the same query. Steelberg says when an audio clip uses multiple languages, the translations aiWARE returns are 15 percent to 20 percent more accurate than the best single engine on the platform.


Algorithms designed for parsing text and speech, such as transcription and translation, are another area prone to bias. One study found algorithms categorized written African American vernacular English as ""not English"" at high rates, while a Washington Post investigation found voice assistants such as Amazon's Alexa have a hard time deciphering accented English.Though it wasn't built to eliminate bias, aiWARE ends up doing exactly that, Steelberg says. Just like the human brain is capable of taking all of its learned information and picking the best response to each situation, aiWARE learns which model (or models) is most appropriate to use for each query.""We use our aiWARE to arbitrate and evaluate each of those models as to what they believe the right answer is, and then aiWARE is learning to choose which set of models to trust at every single point along the curve,"" Steelberg says.It's not an issue if an algorithm is biased. ""What's problematic is when you try to solve the problem with one big, monolithic model,"" Steelberg says. AiWARE is learning to recognize which models are biased and how, and work around those biases.Another factor that results in biased AI is that many algorithms will ignore small subsets of a training set. If in a data set of 1 million entries, there are three that are different, you can still achieve a high degree of accuracy overall while performing horribly on certain queries. This is often the reason facial recognition software fails to recognize people of color: The training set contained mostly images of white faces.Veritone tells companies to break down training sets into micro models, and then aiWARE can interpolate to create similar examples.""You're essentially inflating that population, and you can train models now on an inflated population that learn that process,"" Steelberg says.Using small training sets, aiWARE can build models for facial recognition with accuracy in the high 90th percentile for whatever particular subcategory a client is interested in (e.g., all the employees at your company), he says.


Steelberg says he believes an intelligent AI like aiWARE has a much better chance of eliminating bias than a human auditor. For one, humans will likely have a hard time identifying flawed training sets. They also might bring their own biases to the process.And for larger AI models, which might encompass ""tens of millions of petabytes of data,"" a human auditor is just impractical, Steelberg says. ""The sheer size makes it inconceivable.""

",,,,,,,,,,,https://assets.entrepreneur.com/static/20240220061344-entrepreneur-logo-black.svg,,,,,"[{'@type': 'ListItem', 'position': 0, 'name': 'Science & Technology', 'item': 'https://www.entrepreneur.com/science-technology'}]",,,,,,,,,,,
https://news.google.com/rss/articles/CBMiRGh0dHBzOi8vbWVkY2l0eW5ld3MuY29tLzIwMTgvMDkvbnVhbmNlLWFpLXBvd2VyZWQtdmlydHVhbC1hc3Npc3RhbnQv0gEA?oc=5,How Nuance's AI-powered virtual assistant aims to assist the care team - MedCity News,2018-09-04,MedCity News,https://medcitynews.com,N/A,"['Artificial Intelligence, Daily, Health IT, Top Story']",The Massachusetts company's Dragon Medical Virtual Assistant is focused on clinical documentation and translating a clinician's speech into information that goes into the EHR.,N/A,https://schema.org,NewsArticle,https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/,"{'@type': 'Organization', 'name': 'MedCity News'}",,2018-09-04T16:39:51-04:00,,,,,,N/A,N/A,"








Nuance Communications, a computer software company headquartered in Burlington, Massachusetts, is bringing artificial intelligence to the medical realm.
The organization touches various industries, from automotive to financial services to healthcare.










					Consumer / Employer				




 




					Growing Interest in Pharmacy Spend, GLP-1 drugs, AI and Navigation Platforms				


					The 2024 Benefit Consultant Sentiment Index published by MedCity News and sponsored by Quantum Health, now in its second year, is based on a survey of more than 100 seasoned healthcare benefits consultants who represent a cross-section of employer size. A few shared their impressions of some of the report findings.				


			By 			MedCity News		









“Our vision is very simple: enabling the care team … to take care of patients without technology getting in the way,” Satish Marpuri, executive vice president and general manager of Nuance Healthcare, said in a phone interview.
Physicians, he said, are starting to become data entry clerks. Within today’s medical system, there is a significant burden put on the care team as far as documentation is concerned.
“Where Nuance Healthcare sees the next frontier is around … bringing artificial intelligence to those scenarios to solve the burden on the physicians,” Marpuri added.




The company has thus developed various products to aid clinicians in this manner. Its flagship product is the Dragon Medical suite of solutions, Marpuri noted. The products are focused on clinical documentation and translate a doctor’s speech into a narrative that goes into the EHR.





					sponsored content				




 




					Integrated Enrollment Platforms and Consumer Assistance Centers: The Strongest Advantage for State-Based Exchanges				


					In the ever-evolving landscape of state-based health insurance exchanges, the convergence of technology and customer service is reshaping how these exchanges operate. The increasing advent of automation and artificial intelligence (AI) is rapidly dismantling the traditional business model that relies on the siloing of technology and customer service centers.				


			By 			Shankar Srinivasan, Co-Founder and General Manager, GetInsured and Jason Sparks, VP, of Project Management and Implementation, GetInsured		



About a year ago, Nuance expanded its portfolio by launching a new solution: the Dragon Medical Virtual Assistant. The tool, which is powered by artificial intelligence, continues the clinical documentation work of Nuance’s other products. More specifically, it can understand sophisticated conversational dialogue and has capabilities that automate high-value clinical workflows.
Earlier this year, the Massachusetts company integrated its virtual assistant platform into the Epic EHR system.




Marpuri pointed out that this effort is part of Nuance’s goal of deeply integrating its technology into the physician’s workflow. In addition to Epic, the company has partnerships with IT vendors like Allscripts, Cerner and Meditech.
Diving deeper into Nuance’s work with the Wisconsin-based EHR vendor, the companies have a few joint innovations. Doctors using Epic Haiku can now ask for patient information, medication lists and lab results through Nuance’s virtual assistant technology. Staff using Epic Cadence, a scheduling tool, can converse with Nuance’s virtual assistant to set up, search for and cancel patient appointments.
Nuance also has a smart speaker in development, which is connected to the Dragon Medical cloud. It is geared toward complex medical conversations and ambient speech use cases.
Finally, the Massachusetts company is working with entities like Partners HealthCare in Boston and Nvidia, a company with roots in the gaming world. Through the collaboration, they are bringing AI to radiologists at the point of care. The aim is to have AI algorithms that scan through medical images so the radiologist can quickly see which patients need specific types of care.
Photo: MF3d, Getty Images




Topics


AI


artificial intelligence


doctors


Epic


Massachusetts


Nuance


virtual assistants






			MedCity News Daily Newsletter		

			Sign up and get the latest news in your inbox.		



Enter your email address

Subscribe Now




			We will never sell or share your information without your consent. See our privacy policy.
		



",How Nuance&#8217;s AI-powered virtual assistant aims to assist the care team,,https://medcitynews.com/wp-content/uploads/sites/7/2018/06/GettyImages-865552594.jpg,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/', 'url': 'https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/', 'name': ""How Nuance's AI-powered virtual assistant aims to assist the care team - MedCity News"", 'isPartOf': {'@id': 'https://medcitynews.com/#website'}, 'primaryImageOfPage': {'@id': 'https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/#primaryimage'}, 'image': {'@id': 'https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/#primaryimage'}, 'thumbnailUrl': 'https://medcitynews.com/wp-content/uploads/sites/7/2018/06/GettyImages-865552594.jpg', 'datePublished': '2018-09-04T20:39:51+00:00', 'dateModified': '2024-04-02T14:30:31+00:00', 'author': {'@id': 'https://medcitynews.com/#/schema/person/ee76be9e31190981263f1e499756dfd0'}, 'breadcrumb': {'@id': 'https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/#primaryimage', 'url': 'https://medcitynews.com/wp-content/uploads/sites/7/2018/06/GettyImages-865552594.jpg', 'contentUrl': 'https://medcitynews.com/wp-content/uploads/sites/7/2018/06/GettyImages-865552594.jpg', 'width': 788, 'height': 443}, {'@type': 'BreadcrumbList', '@id': 'https://medcitynews.com/2018/09/nuance-ai-powered-virtual-assistant/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://medcitynews.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How Nuance&#8217;s AI-powered virtual assistant aims to assist the care team'}]}, {'@type': 'WebSite', '@id': 'https://medcitynews.com/#website', 'url': 'https://medcitynews.com/', 'name': 'MedCity News', 'description': 'Healthcare technology news, life science current events', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://medcitynews.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://medcitynews.com/#/schema/person/ee76be9e31190981263f1e499756dfd0', 'name': 'Erin Dietsche', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://medcitynews.com/#/schema/person/image/', 'url': 'https://medcitynews.com/wp-content/uploads/sites/7/2017/07/Erin-Dietsche_avatar_1499964096-96x96.png', 'contentUrl': 'https://medcitynews.com/wp-content/uploads/sites/7/2017/07/Erin-Dietsche_avatar_1499964096-96x96.png', 'caption': 'Erin Dietsche'}, 'description': ""Erin Dietsche covers the hospitals and health IT beats for MedCity News. She previously worked as a writer/reporter for Becker's Hospital Review, where she covered everything from payer issues to health IT to leadership. Erin grew up in Minnesota, graduated from the University of Iowa and now calls Indiana home. You can email her at edietsche@medcitynews.com."", 'url': 'https://medcitynews.com/author/edietsche/'}]",,Health IT,['Erin Dietsche'],,,,,,,,,
https://news.google.com/rss/articles/CBMikQFodHRwczovL3d3dy5wcml2YXRlaW50ZXJuZXRhY2Nlc3MuY29tL2Jsb2cvaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFwcGxpZWQtdG8tZ29vZ2xlLWdsYXNzLWxpa2Utc3lzdGVtcy1jb3VsZC1ib3RoLWhlbHAtYW5kLWhhcm0tb3VyLXByaXZhY3kv0gEA?oc=5,How putting artificial intelligence in Google Glass-like systems could both help and harm our privacy - Privacy News Online,2018-09-01,Privacy News Online,https://www.privateinternetaccess.com,"Remember Google Glass? Five years ago, it was the hot new accessory for those who wanted to live at the bleeding edge of technology. But once Google",N/A,"Remember Google Glass? Five years ago, it was the hot new accessory for those who wanted to live at the bleeding edge of technology. But once Google",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"


How putting artificial intelligence in Google Glass-like systems could both help and harm our privacy

Posted on Sep 1, 2018 by Glyn Moody






 
Remember Google Glass? Five years ago, it was the hot new accessory for those who wanted to live at the bleeding edge of technology. But once Google Glasses started being used in public, people realized that they represented a massive intrusion into the private lives of everyone nearby. As Wikipedia puts it: “The headset received a great deal of criticism and legislative action due to privacy and safety concerns.”
In 2015, Google announced that it would stop selling the Google Glass prototype to “Glass Explorers”. Since then, the idea of a head-mounted device with built-in first-person camera has faded from public view, but the idea certainly hasn’t gone away. Many may be surprised to learn that Google quietly re-launched Google Glass back in 2017, this time in the form of the Glass Enterprise edition. At that time, The Verge reported:
The major upgrades between the original Glass and the enterprise version are a better camera (with resolution upgraded from 5 megapixels to 8), extended battery life, faster Wi-Fi and processor, and a new red light that turns on when recording video. The electronics of Glass have also been made modular in the shape of a so-called Glass Pod, which can be detached and reattached to Glass-compatible frames, which can include things like safety goggles and prescription glasses.
As its name suggests, Google Glass Enterprise edition is aimed squarely at businesses rather than end-users. That’s in part a response to the adverse reaction that people had to the devices being used in public spaces. But a 2017 article in Wired notes that even in the more controlled work environment, there are still privacy issues. One company using Google Glasses discussed the idea of installing a “bathroom bar” where people can hang their headsets to make sure that no one is snapping photos in inappropriate contexts. In offices or on the factory floor, Google Glasses might still be used to record others saying or doing things without their permission.
A recent academic research project took an interesting approach to mitigating this problem. A German team was led by Andreas Bulling, Professor of Human-Computer Interaction and Cognitive Systems at the University of Stuttgart, and head of the Perceptual User Interfaces Group at the Max Planck Institute for Informatics:
we present PrivacEye, a proof-of-concept system that detects privacy sensitive everyday situations and automatically enables and disables the first-person camera using a mechanical shutter. To close the shutter, PrivacEye detects sensitive situations from first-person camera videos using an end-to-end deep-learning model. To open the shutter without visual input, PrivacEye uses a separate, smaller eye camera to detect changes in users’ eye movements to gauge changes in the “privacy level” of the current situation.
The use of a physical shutter in this way is rather clunky, and the need for a second camera is an additional inconvenience. But what makes the work of note is the way artificial intelligence techniques are applied to detect automatically whether a social context is likely to be privacy-sensitive. If it is, the first-person camera is prevented from recording. In order to establish whether that was necessary, the researchers used a neural network that monitored the eye movements of the person wearing the first-person camera. One advantage of this approach is that it is not intrusive for other people who are present, unlike alternative systems that look at the environment in order to gauge privacy-intensive situations.
Markers of eye movements included fixations, saccades (quick, simultaneous movements of both eyes between two or more points of fixation in the same direction), blinks, pupil diameter and scan paths. The basic idea is to use the neural network to detect correlations between eye movement patterns and the level of privacy sensitivity experienced by the person wearing the camera headset. Although the work by the German team is only preliminary, they believe it has potential:
We are confident that the rapidly increasing capabilities of today’s deep neural networks will soon allow to push our proof-of-concept prototype towards an effective real-world application enabling privacy-preserving day-to-day usage of “always-on” smart glasses in real-time.
Like all tools, neural networks can be used beneficially and harmfully. The same techniques deployed to analyze eye movements in order to safeguard privacy can also be applied with less benign outcomes, as another research project led by Professor Bulling indicated. The academic paper writing up the work explained:
Besides allowing us to perceive our surroundings, eye movements are also a window into our mind and a rich source of information on who we are, how we feel, and what we do. Here we show that eye movements during an everyday task predict aspects of our personality. We tracked eye movements of 42 participants while they ran an errand on a university campus and subsequently assessed their personality traits using well-established questionnaires. Using a state-of-the-art machine learning method and a rich set of features encoding different eye movement characteristics, we were able to reliably predict four of the Big Five personality traits (neuroticism, extraversion, agreeableness, conscientiousness) as well as perceptual curiosity only from eye movements.
Once more, it’s important to note that this should be regarded as a preliminary investigation, albeit with a promising outcome. Much more research needs to be done before it can be stated definitively that eye movements are suitable for predicting people’s personality. Perhaps the most important result from the work carried out by Bulling and his fellow researchers is not what they found, but how they found it.
In both cases, raw observational data – things like gaze fixations, saccades and eye blinks – were fed into a neural network system. The AI software then sought hidden patterns in that data: in the first case, correlating eye movements with privacy-sensitive situations, and in the second, correlating the eye movements with personality traits. It seems that interesting patterns were found for both – although these need to be confirmed by other researchers, and with larger training sets.
The application of AI techniques like neural networks is not limited to eye movements. It could easily be applied to any rich personal data set. Obvious possibilities include things like heart beat, skin conductivity, voice pitch, hand movements, and walking patterns, not to mention non-physical ones like online posting patterns or digital writing styles. It may well be that some or all of these are susceptible to AI analysis to reveal patterns that those generating the data are not aware of. Once more, that information might be used for all kinds of appropriate purposes – public safety, enhanced efficiency, personal counselling etc. – or it might be used for new kinds of invisible surveillance.
As Google Glass-like products become more common in the enterprise, perhaps even creeping back into public space, so the research described above will become particularly pertinent. However, exactly the same kinds of AI-based analysis can – and will – be applied to other products that gather, perhaps incidentally, personal information. Increasingly sophisticated real-time automated analysis will inevitably reveal aspects of our private lives in unsuspected, and often unwanted, detail.
Featured image by Google X.

 





",,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/#article', 'isPartOf': {'@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/'}, 'author': {'name': 'Glyn Moody', '@id': 'https://www.privateinternetaccess.com/blog/#/schema/person/99ba810662cdf92245f61106c0c29775'}, 'headline': 'How putting artificial intelligence in Google Glass-like systems could both help and harm our privacy', 'datePublished': '2018-09-01T19:00:09+00:00', 'dateModified': '2021-08-04T16:37:16+00:00', 'mainEntityOfPage': {'@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/'}, 'wordCount': 1178, 'publisher': {'@id': 'https://www.privateinternetaccess.com/blog/#organization'}, 'image': {'@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/#primaryimage'}, 'thumbnailUrl': 'https://www.privateinternetaccess.com/blog/wp-content/uploads/2018/08/google-glass-enterprise.png', 'keywords': ['neural networks', 'surveillance'], 'articleSection': ['Cybersecurity', 'General Privacy News'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/', 'url': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/', 'name': 'How putting artificial intelligence in Google Glass-like systems could both help and harm our privacy', 'isPartOf': {'@id': 'https://www.privateinternetaccess.com/blog/#website'}, 'primaryImageOfPage': {'@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/#primaryimage'}, 'image': {'@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/#primaryimage'}, 'thumbnailUrl': 'https://www.privateinternetaccess.com/blog/wp-content/uploads/2018/08/google-glass-enterprise.png', 'datePublished': '2018-09-01T19:00:09+00:00', 'dateModified': '2021-08-04T16:37:16+00:00', 'description': 'Remember Google Glass? Five years ago, it was the hot new accessory for those who wanted to live at the bleeding edge of technology. But once Google', 'breadcrumb': {'@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/#primaryimage', 'url': 'https://www.privateinternetaccess.com/blog/wp-content/uploads/2018/08/google-glass-enterprise.png', 'contentUrl': 'https://www.privateinternetaccess.com/blog/wp-content/uploads/2018/08/google-glass-enterprise.png', 'width': 1022, 'height': 404}, {'@type': 'BreadcrumbList', '@id': 'https://www.privateinternetaccess.com/blog/how-artificial-intelligence-applied-to-google-glass-like-systems-could-both-help-and-harm-our-privacy/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.privateinternetaccess.com/blog/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How putting artificial intelligence in Google Glass-like systems could both help and harm our privacy'}]}, {'@type': 'WebSite', '@id': 'https://www.privateinternetaccess.com/blog/#website', 'url': 'https://www.privateinternetaccess.com/blog/', 'name': 'PIA VPN Blog', 'description': 'Online privacy news from around the world.', 'publisher': {'@id': 'https://www.privateinternetaccess.com/blog/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.privateinternetaccess.com/blog/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.privateinternetaccess.com/blog/#organization', 'name': 'Private Internet Access', 'url': 'https://www.privateinternetaccess.com/blog/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.privateinternetaccess.com/blog/#/schema/logo/image/', 'url': 'https://www.privateinternetaccess.com/blog/wp-content/uploads/2018/07/pialogowhitekglogo.png', 'contentUrl': 'https://www.privateinternetaccess.com/blog/wp-content/uploads/2018/07/pialogowhitekglogo.png', 'width': 1200, 'height': 1200, 'caption': 'Private Internet Access'}, 'image': {'@id': 'https://www.privateinternetaccess.com/blog/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/privateinternetaccess/', 'https://x.com/buyvpnservice', 'https://www.instagram.com/piavpn/', 'https://www.youtube.com/channel/UClyJZ47Rizb1xnwuKXDI0_w']}, {'@type': 'Person', '@id': 'https://www.privateinternetaccess.com/blog/#/schema/person/99ba810662cdf92245f61106c0c29775', 'name': 'Glyn Moody', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.privateinternetaccess.com/blog/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/ce6b845a9628e86c9939d12314111726?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/ce6b845a9628e86c9939d12314111726?s=96&d=mm&r=g', 'caption': 'Glyn Moody'}, 'description': 'Glyn Moody is a freelance journalist who writes and speaks about privacy, surveillance, digital rights, open source, copyright, patents and general policy issues involving digital technology. He started covering the business use of the Internet in 1994, and wrote the first mainstream feature about Linux, which appeared in Wired in August 1997. His book, ""Rebel Code,"" is the first and only detailed history of the rise of open source, while his subsequent work, ""The Digital Code of Life,"" explores bioinformatics - the intersection of computing with genomics.', 'sameAs': ['http://opendotdotdot.blogspot.com/', 'https://www.linkedin.com/in/glynmoody/', 'https://x.com/http://twitter.com/glynmoody'], 'url': 'https://www.privateinternetaccess.com/blog/author/glynmoody/'}]",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmNiYy5jYS9uZXdzL3NjaWVuY2UvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utam9iLWFwcGxpY2F0aW9ucy11bmNvbnNjaW91cy1iaWFzLTEuNDgwMjA2MdIBIGh0dHBzOi8vd3d3LmNiYy5jYS9hbXAvMS40ODAyMDYx?oc=5,"Help wanted, apply to the AI: Why your next job interview could be with a machine - CBC News",2018-09-04,CBC News,https://www.cbc.ca,"Artificial Intelligence can help streamline the hiring process and weed out things like unconscious bias, but not everyone is buying in.",N/A,"Artificial Intelligence can help streamline the hiring process and weed out things like unconscious bias, but not everyone is buying in.","Artificial Intelligence can help streamline the hiring process and weed out things like unconscious bias, but not everyone is buying in.",http://schema.org/,WebPage,,"{'foundingDate': '1936-11-02T05:00Z', 'ethicsPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'verificationFactCheckingPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', '@type': 'NewsMediaOrganization', '@context': 'http://schema.org/', 'ownershipFundingInfo': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'actionableFeedbackPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'missionCoveragePrioritiesPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'diversityPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'masthead': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'diversityStaffingReport': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'unnamedSourcesPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364', 'correctionsPolicy': 'https://www.cbc.ca/news/about-cbc-news-1.1294364'}",,2018-09-04T08:00Z,2018-09-04T08:00Z,2018-09-04T12:13Z,,"[{'datePublished': '2017-08-09T23:52Z', '@type': 'ImageObject', 'name': 'AFP_N91YW', 'description': ""A visitor at Intel's Artificial Intelligence (AI) Day walks past a signboard during the event in the Indian city of Bangalore on April 4, 2017. / AFP PHOTO / MANJUNATH KIRAN        (Photo credit should read MANJUNATH KIRAN/AFP/Getty Images)"", 'dateModified': '2017-08-09T23:51Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.4159618.1502322701!/fileImage/httpImage/afp-n91yw.jpg'}, {'datePublished': '2018-08-30T19:17Z', '@type': 'ImageObject', 'name': 'Jahanzaib Ansari', 'description': 'Jahanzaib Ansari, CEO of Knockri, a Toronto startup that uses artificial intelligence (AI) to help companies like IBM hire new talent. ', 'dateModified': '2018-08-30T19:16Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.4805232.1535656560!/fileImage/httpImage/jahanzaib-ansari.jpg'}, {'datePublished': '2013-11-22T18:57Z', '@type': 'ImageObject', 'name': 'jobs hiring employment unemployment', 'description': 'Visitors pass a banner reading ""Jobs"" as they pass exhibitors\' recruitment stands during the Skills London job fair in London, U.K., on Friday, Nov. 22, 2013. Government figures show economic growth accelerated to 0.8 percent in the third quarter, the housing market is strengthening and about 60,000 jobs are being created every month, boosting taxes from company profits, payrolls, property purchases and sales. Photographer: Chris Ratcliffe/Bloomberg', 'dateModified': '2013-11-22T18:56Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.2436930.1385146617!/fileImage/httpImage/jobs-hiring-employment-unemployment.jpg'}, {'datePublished': '2018-08-29T19:49Z', '@type': 'ImageObject', 'name': 'Knockri', 'description': 'Jahanzaib Ansari, CEO and co-founder of Knockri - right.\r\nMaaz Rana, COO and co-founder of Knockri, left.\r\n', 'dateModified': '2018-08-29T19:47Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.4803823.1535572034!/fileImage/httpImage/knockri.jpg'}, {'datePublished': '2018-08-29T19:51Z', '@type': 'ImageObject', 'name': 'Knockri', 'description': 'Knockri screenshot           ', 'dateModified': '2018-08-29T19:50Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.4803834.1535572244!/fileImage/httpImage/knockri.jpg'}, {'datePublished': '2018-08-29T19:50Z', '@type': 'ImageObject', 'name': 'Saadia Muzaffar', 'description': 'Saadia Muzaffar, tech entrepreneur, author and founder of TechGirls Canada.', 'dateModified': '2018-08-29T19:49Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.4803829.1535572156!/fileImage/httpImage/saadia-muzaffar.jpg'}]","[{'image': {'datePublished': '2021-04-25T18:20Z', '@type': 'ImageObject', 'name': 'Kimberly Ivany', 'description': '', 'dateModified': '2021-04-25T18:18Z', '@context': 'http://schema.org/', 'url': 'https://i.cbc.ca/1.4373149.1619374733!/fileImage/httpImage/kimberly-ivany.JPG'}, 'contactPoint': {'@type': 'ContactPoint', '@context': 'http://schema.org/', 'url': 'https://www.cbc.ca/news/author/anand-ram-matthew-braga-1.4805096', 'email': ''}, '@type': 'Person', 'jobTitle': '', 'name': 'Anand Ram & Matthew Braga', 'description': 'Anand Ram is a producer with The National. Matthew Braga reports on technology for CBC News.', '@context': 'http://schema.org/'}]",N/A,N/A,N/A,"Help wanted, apply to the AI: Why your next job interview could be with a machine",,https://i.cbc.ca/1.4159618.1502322701!/fileImage/httpImage/afp-n91yw.jpg,,,,"Help wanted, apply to the AI: Why your next job interview could be with a machine","Artificial intelligence promises to help streamline hiring process, but not everyone is buying in",,,,,,,,,Science,,"[{'datePublished': '2018-08-29T18:37Z', 'alternativeHeadline': ""Knockri CEO Jahanzaib Ansari describes how his own difficulties help inform his company's algorithms so that differently-abled people aren't kept from the jobs they want."", 'identifier': '1309079107707', 'contentUrl': 'https://www.cbc.ca/player/play/1309079107707', 'uploadDate': '2018-08-29T18:37Z', '@type': 'VideoObject', 'name': 'Using technology to make better hiring decisions', 'description': ""Knockri CEO Jahanzaib Ansari describes how his own difficulties help inform his company's algorithms so that differently-abled people aren't kept from the jobs they want."", 'dateModified': '2018-08-29T18:40Z', '@context': 'http://schema.org/', 'thumbnailUrl': 'https://thumbnails.cbc.ca/maven_legacy/thumbnails/180/127/Jahanzaib-web-feature_frame_1108.jpg'}]","{'@type': 'SpeakableSpecification', 'cssSelector': ['.detailHeadline', '.detailSummary']}",,,,,,,
https://news.google.com/rss/articles/CBMiUGh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMTgvMDkvMDMvYnVzaW5lc3Mvc2lsaWNvbi12YWxsZXktdHJ1bXAtZ292ZXJubWVudC5odG1s0gEA?oc=5,Silicon Valley Doesn't Like Trump. It Can Still Work With the Government. (Published 2018) - The New York Times,2018-09-03,The New York Times,https://www.nytimes.com,"Tech workers are pushing back against federal contracts, particularly with the Pentagon. Here’s why that might be a mistake.",N/A,"Tech workers are pushing back against federal contracts, particularly with the Pentagon. Here’s why that might be a mistake.","Tech workers are pushing back against federal contracts, particularly with the Pentagon. Here’s why that might be a mistake.",https://schema.org,BreadcrumbList,https://www.nytimes.com/,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",https://www.nytimes.com/2018/09/03/business/silicon-valley-trump-government.html,2018-09-03T10:00:06.000Z,,2018-09-04T03:41:49.000Z,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/09/04/business/04sorkin-1/04sorkin-1-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2018/09/04/business/04sorkin-1/04sorkin-1-videoSixteenByNineJumbo1600.jpg', 'caption': 'Alex Karp, the head of Palantir, whose software has been used to target terrorists, said American companies had a moral obligation to support the country and its military no matter who was president.', 'creditText': 'Christophe Petit Tesson/EPA, via Shutterstock'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2018/09/04/business/04sorkin-1/merlin_138566967_0cf5a27e-ba09-435d-aca6-5c7bfc4196a4-superJumbo.jpg', 'height': 1365, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2018/09/04/business/04sorkin-1/merlin_138566967_0cf5a27e-ba09-435d-aca6-5c7bfc4196a4-superJumbo.jpg', 'caption': 'Alex Karp, the head of Palantir, whose software has been used to target terrorists, said American companies had a moral obligation to support the country and its military no matter who was president.', 'creditText': 'Christophe Petit Tesson/EPA, via Shutterstock'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/andrew-ross-sorkin', 'name': 'Andrew Ross Sorkin'}]",Business,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTDealBook Business and PolicyDealBookSilicon Valley Doesn’t Like Trump. It Can Still Work With the Government.Share full articleRead in appAlex Karp, the head of Palantir, whose software has been used to target terrorists, said American companies had a moral obligation to support the country and its military no matter who was president.Credit...Christophe Petit Tesson/EPA, via ShutterstockBy Andrew Ross SorkinSept. 3, 2018Alex Karp grew up in a liberal household and considers himself a progressive. He voted for Hillary Clinton, and he lives and works in Silicon Valley.Yet Mr. Karp, the chief executive of Palantir, has found himself increasingly at odds with his peers in the technology industry as it publicly distances itself from the government, particularly the Department of Defense, under President Trump.Mr. Karp readily admits he would prefer that Mr. Trump didn’t occupy the Oval Office. But he believes that Silicon Valley — already facing something of a crisis of user confidence over issues including privacy and foreign influence — is setting itself up for a fall.“It’s going to be a very significant problem for the Valley,” Mr. Karp, who rarely speaks publicly, said in an interview in his Manhattan office.AdvertisementSKIP ADVERTISEMENT“I don’t know how you stand up and talk to a Marine or a special operator and explain to them how you have a piece of software that will allow them to come home — or more likely allow them to come home — and you’re not going to allow them to use it,” he said. “I think it’s a nearly impossible argument to make outside the Valley without people being legitimately pretty upset.”Employees at companies including Google, Microsoft and Amazon don’t see it the same way. Google, under internal pressure, abandoned its contract with the Pentagon on Project Maven, which used artificial intelligence software to improve the analysis of imagery from drones. Microsoft’s chief executive, Satya Nadella, has faced opposition from workers who want the company to end a contract with Immigration and Customs Enforcement. And Amazon employees have objected to providing facial recognition technology to police departments and other agencies.All of this has set off a quiet — but growing — debate across corporate America in the age of Trump: What does it mean to be a patriotic company when you vehemently disagree with your nation’s leader?Within the technology industry, the debate has been couched as a “moral and ethical” one: “We believe that Google should not be in the business of war,” employees wrote in a petition that led to the company’s withdrawal from Project Maven.In truth, the ethical arguments are a diversion. This is political.And there is a real danger in letting politics undermine the storied relationship between the government and Silicon Valley — Hewlett-Packard built sonar, radar and aviation equipment for the government during World War II, for example — that has led to much of the innovation we enjoy today.AdvertisementSKIP ADVERTISEMENTAdam Grant, a professor at the Wharton School and a member of the Defense Innovation Board, an independent federal advisory committee set up under President Barack Obama, said he believed that the partisanship that was contributing to the debate would ultimately stifle innovation.“I worry that it will stall progress,” he said. “Innovation has been fueled for decades by private-public partnerships. It smacks of cutting off your nose to spite your face. Even if you’re not a fan of the president, you can still serve your country.”Mr. Karp, whose parents met at a civil rights demonstration, said he believed that American companies, including those in Silicon Valley, had a moral obligation to support the country and its military, no matter who was living at 1600 Pennsylvania Avenue.“We’re proud that we’re working with the U.S. government,” he said.Of course, Mr. Karp certainly has an interest in maintaining relationships between the government and the technology sector. Palantir, which uses technology to analyze vast troves of data, was founded with the help of $2 million from the Central Intelligence Agency’s venture capital arm, and much of its business model was to use data to help the government in the wake of the Sept. 11 attacks. But that makes his willingness to be so forthright about his view of the president refreshing when his peers who may have similar views stay quiet.ImageGoogle abandoned a Pentagon contract in the face of internal opposition. Mr. Karp, who voted for Hillary Clinton, said that with government work, “you’re buying into the inherent fabric and structure of the country.”Credit...Christie Hemm Klok for The New York Times“I obviously am very biased,” he said. “I have a problem if I go to a cocktail party in Silicon Valley because they want to know, ‘Is it true that your product is used to target terrorists?’ Yes. And some people don’t agree with that. That’s fine, by the way. I don’t expect everyone to agree with that.”AdvertisementSKIP ADVERTISEMENTHis outspokenness is even more surprising given that a co-founder of Palantir is Peter Thiel, a serial entrepreneur who has publicly supported Mr. Trump.“We didn’t vote for the same people,” Mr. Karp said without hesitation. “We’re not going to vote for the same people.”Still, even if it is political allegiances that have prompted tech workers to push back, the ethical issues around artificial intelligence are not insignificant. Everyone from Elon Musk to Stephen Hawking has raised questions about technological warfare in the future. But we are still most likely decades away from those extreme kinds of worries being realized.In fairness, the fears of some technology workers that their work will be used for ill do have a historical basis — in other countries. Ferdinand Porsche designed tanks for the Nazis, and Hugo Boss made their uniforms. Was that patriotism? Would it matter?AdvertisementSKIP ADVERTISEMENTReid Hoffman, who founded LinkedIn and sold it to Microsoft, where he now sits on the board, said there were real worries about how the government would use powerful technologies like artificial intelligence.“I think that the majority of Silicon Valley people have a strong worry/reflex against weapons,” said Mr. Hoffman, who is a member of the Defense Innovation Board with Mr. Grant. The Trump administration, he said, has “amplified” concerns over “possible bad government action.”But Mr. Karp said claims that a president could steer us toward an authoritarian world powered by artificial intelligence were too extreme.“America is a complicated modern democracy with numerous checks and balances so that no one person has the ability to do insane things,” Mr. Karp said. With government work, he added, “you’re buying into the inherent fabric and structure of the country.”Lost in the conversation in Silicon Valley is its own history. The internet itself was originally funded by an arm of the Defense Department that is now called the Defense Advanced Research Projects Agency. As recently as the Obama administration, Silicon Valley’s biggest technology giants embraced roles advising the government.AdvertisementSKIP ADVERTISEMENTBut there is a difference between today’s tech giants like Google and Facebook and those who turned the Santa Clara Valley into Silicon Valley. A bond with the government “was clearly not part of the founding of the consumer internet in any relevant way,” Mr. Karp said.It is a connection that should be better understood by the employees now pushing for it to be severed. Those bright minds are able to have this debate in part because of the work done by their predecessors.And given the very real questions that have emerged about the benefits — or lack thereof — that the biggest tech companies truly offer society, those workers might want to rethink their position.As Mr. Karp pointed out when we talked about the big technology companies, “If actually the narrative was ‘We are helping also with our defense,’ then people would understand the value of these other things” they do.There could come a time when Silicon Valley wishes it was waving that flag.A version of this article appears in print on Sept. 4, 2018, Section B, Page 1 of the New York edition with the headline: Why Tech’s Split With Trump Could Set the Country Back. Order Reprints | Today’s Paper | SubscribeSee more on: U.S. Politics, Alphabet Inc., Microsoft Corporation, Donald TrumpShare full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",Silicon Valley Doesn’t Like Trump. It Can Still Work With the Government.,Why Tech’s Split With Trump Could Set the Country Back,,False,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",https://www.nytimes.com/#publisher,The New York Times,,,1851-09-18,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,https://en.wikipedia.org/wiki/The_New_York_Times,,,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Business', 'position': 1, 'item': 'https://www.nytimes.com/section/business'}, {'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'DealBook', 'position': 2, 'item': 'https://www.nytimes.com/section/business/dealbook'}]",,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vbWVkaXVtLmRhdGFkcml2ZW5pbnZlc3Rvci5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaHlwZS1vci1jaGFuZ2UtYWdlbnQtdG8tc2hhcGUtZnV0dXJlLWQ1NDNlMTdjZGY3MdIBAA?oc=5,Artificial Intelligence: Hype? Or Change Agent to shape future? - DataDrivenInvestor,2018-09-05,DataDrivenInvestor,https://medium.datadriveninvestor.com,"It was a time when a computer weighed over 30 tons, occupied 1800 square feet space, and used 18,000 vacuum tubes & 200 kilowatts of electricity, all of this to give humanity an ability to compute…",N/A,"It was a time when a computer weighed over 30 tons, occupied 1800 square feet space, and used 18,000 vacuum tubes & 200 kilowatts of…","It was a time when a computer weighed over 30 tons, occupied 1800 square feet space, and used 18,000 vacuum tubes & 200 kilowatts of…",http://schema.org,NewsArticle,https://medium.datadriveninvestor.com/artificial-intelligence-hype-or-change-agent-to-shape-future-d543e17cdf71,"{'@type': 'Organization', 'name': 'DataDrivenInvestor', 'url': 'medium.datadriveninvestor.com', 'logo': {'@type': 'ImageObject', 'width': 308, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:616/1*OMF3fSqH8t4xBJ9-6oZDZw.png'}}",https://medium.datadriveninvestor.com/artificial-intelligence-hype-or-change-agent-to-shape-future-d543e17cdf71,2018-09-05T08:13:49.402Z,2018-09-05T08:13:49.402Z,2023-01-15T17:49:32.927Z,,['https://miro.medium.com/v2/resize:fit:1200/1*DcHlT-ImdvYaJZL7LWDUUA.jpeg'],"{'@type': 'Person', 'name': 'Kamal Pathak', 'url': 'https://medium.datadriveninvestor.com/@tokamalpathak'}",N/A,N/A,"Artificial Intelligence: Hype? Or Change Agent to shape future?Kamal Pathak·FollowPublished inDataDrivenInvestor·4 min read·Sep 5, 2018282ListenSharePhoto Credit: Seattle Chinese TimesIt was a time when a computer weighed over 30 tons, occupied 1800 square feet space, and used 18,000 vacuum tubes & 200 kilowatts of electricity, all of this to give humanity an ability to compute 5000 additions, 357 multiplications, and 38 divisions in a second. No RAM and no storage by the way.I am not biased, ENIAC was the supercomputer of the day. But what I wonder even more is, from that monster size of a computer to a recently launched Intel Movidius, a thumb size drive, with abilities to think like humans, and another, an 8.8 mm wide chip that can power unmanned air drones that can follow their master, understand depth, avoid obstacles, and orient themselves in space, all on their own, science has made mountainous progress.In the past few years, there have been a myriad technologies boasting about bringing disruption, but the one that is actually doing it in our daily lives, and remains the favourite horse of the highest bidders is Artificial Intelligence, or AI. So, all I wanted to do was write a little something on AI.What is AI?Artificial Intelligence is the ability of machines to see, think, learn, and act like genius humans. It isn’t debatable that the machines are faster, more efficient, and more reliable. AI today can recognise faces, converse with humans, identify objects in an image, authenticate users based on voice, predict a suspicious activity at a crowded public place, and what not. And guess what? All of it is possible at a speed and scale one can hardly fathom.Photo Credit: PexelsAs per a study, AI is expected to reach market worth $190 billion by 2025 (MarketsandMarkets), deriving business value of over $3.9 trillion by 2022 (Gartner). It is no surprise that there are countless startups and Fortune 500 companies that are determined to get the most from AI.How does AI work?In a very simple language, there’s a computer behind AI. Big or small. It first understands a situation through sensors or human input. For instance, if you want to train a computer to auto-detect a cat, you will have to show lots of cats to it. After this, the computer processes the information and tries to predict the results next time. The humans/ engineers who train this computer or the computer itself then reiterate a lot of information until desired accuracy of results is reached. Though the entire process is not as simple as it sounds, just know that more the amount of training information, better the results. Which means, you may need 100K cat images to reach 80% accuracy.Some Use Cases:AI is being continuously used around us. Few examples you may be able to relate are:Virtual Digital Assistants — Apple Siri, Amazon Alexa, Google Assistant‘Frequently Bought Together’ suggestions on AmazonSelf-drive carsChatbotsEmotion Recognition to understand customer emotionsAutomated Customer Footfall Counting in retail storesThese are just few use cases many would hear about frequently. But AI spans beyond these, and go all over to pregnancy management, human gene analytics, smart security systems, cashier-less checkouts, predictive airplane engine maintenance, and much more.Who should pay attention?Photo Credit: PexelsEveryone. AI will have an impact on virtually every industry, when some are to be impacted immediately, and others to follow eventually. Healthcare, automotive, retail, agriculture, customer service, manufacturing, everyone. Every department — from HR, Operations, Marketing, Sales, and what not. No matter who you are, it is going to be a part of your life tomorrow, and will make today’s technologies obsolete, like mobile phones did with the landline phones in the past.What will happen?AI is said to take away a lot of jobs. In my opinion, it will not. But one thing it will certainly do in this aspect is, it will shake people, and shake them well. It will force them to go out of their comfort zones, learn new skills, and do the most difficult thing — Accept CHANGE. Just remember the days when computer entered our lives. Everyone had the same fear. But, they created more jobs. However, it took an entire generation of people to go after learning computers, as if their lives depended on it. The same holds true today.We’re living in such exciting times, a kissing distance away from a big bright future. Let’s make the best of it.",Artificial Intelligence: Hype? Or Change Agent to shape future?,,,,,,Artificial Intelligence: Hype? Or Change Agent to shape future?,,,,,,,,,,,['Kamal Pathak'],,,,,,,,,d543e17cdf71
https://news.google.com/rss/articles/CBMiOWh0dHBzOi8vZnV0dXJpc20uY29tL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWV4cGVydHMtZmVhctIBAA?oc=5,Five Experts Share What Scares Them the Most About AI - Futurism,2018-09-05,Futurism,https://futurism.com,Artificial intelligence will change life for the better. But there are reasons to be cautious as well. Five experts tell Futurism what most worries them.,N/A,"Don't worry, killer robots only came up twice.",Artificial intelligence will change life for the better. But there are reasons to be cautious as well. Five experts tell Futurism what most worries them.,https://schema.org,NewsArticle,https://futurism.com/artificial-intelligence-experts-fear,"{'@type': 'NewsMediaOrganization', '@id': 'https://futurism.com#organization', 'url': 'https://futurism.com', 'description': 'Science and Technology News and Videos', 'foundingDate': '2015-11-25', 'masthead': 'https://futurism.com/masthead', 'name': 'Futurism', 'logo': {'@type': 'ImageObject', 'height': '60', 'width': '191', 'url': 'https://futurism.com/schema/OrgFuturism.png'}}","{'@type': 'WebPage', '@id': 'https://futurism.com/artificial-intelligence-experts-fear'}",2018-09-05T09:00:04-04:00,,2018-09-05T15:43:26-04:00,,https://wordpress-assets.futurism.com/2018/09/artificial-intelligence-experts-fear.png,"{'@type': 'Person', 'name': 'Dan Robitzski', 'url': 'https://futurism.com/authors/danrobitzski'}",N/A,N/A,"FuturismUpdated 9.5.18, 3:43 PM EDT by Dan Robitzski/Artificial IntelligenceFive Experts Share What Scares Them the Most About AIA future governed by AI is promising. But it's also scary./ Artificial Intelligence/ Agi/ Ai/ Artificial IntelligenceUpdated 9.5.18, 3:43 PM EDT by Dan RobitzskiImage by Getty ImagesSophisticated AI could make the world a better place. It might let us fight cancer and improve healthcare around the world, or simply free us from the menial tasks that dominate our lives.That was the primary topic of conversation last month when engineers, investors, researchers, and policymakers got together at The Joint Multi-Conference on Human-Level Artificial Intelligence.But there was an undercurrent of fear that ran through some of the talks, too. Some people are anxious about losing their jobs to a robot or line of code; others fear a robot uprising. Where's the line between fearmongering and legitimate concern?In an effort to separate the two, Futurism asked five AI experts at the conference about what they fear most about a future with advanced artificial intelligence. Their responses, below, have been lightly edited.Hopefully, with their concerns in mind, we'll be able to steer society in a better direction — one in which we use AI for all the good stuff, like fighting global epidemics or granting more people an education, and less of the bad stuff.Image Credit: Getty ImagesQ: When you think of what we can do — and what we will be able to do — with AI, what do you find the most unsettling?Kenneth Stanley, Professor at University of Central Florida, Senior Engineering Manager and Staff Scientist at Uber AI LabsI think that the most obvious concern is when AI is used to hurt people. There are a lot of different applications where you can imagine that happening. We have to be really careful about letting that bad side get out. [Sorting out how to keep AI responsible is] a very tricky question; it has many more dimensions than just the scientific. That means all of society does need to be involved in answering it.On how to develop safe AI:All technology can be used for bad, and I think AI is just another example of that. Humans have always struggled with not letting new technologies be used for nefarious purposes. I believe we can do this: we can put the right checks and balances in place to be safer.I don’t think I know what exactly we should do about it, but I can caution us to take [our response to the impacts of AI] very carefully and gradually and to learn as we go.Irakli Beridze, Head of the Centre for Artificial Intelligence and Robotics at UNICRI, United NationsI think the most dangerous thing with AI is its pace of development. Depending how quickly it will develop and how quickly we will be able to adapt to it. And if we lose that balance, we might get in trouble.On terrorism, crime, and other sources of risk:I think the dangerous applications for AI, from my point of view, would be criminals or large terrorist organizations using it to disrupt large processes or simply do pure harm. [Terrorists could cause harm] via digital warfare, or it could be a combination of robotics, drones, with AI and other things as well that could be really dangerous.And, of course, other risks come from things like job losses. If we have massive numbers of people losing jobs and don't find a solution, it will be extremely dangerous. Things like lethal autonomous weapons systems should be properly governed — otherwise there’s massive potential of misuse.On how to move forward:But this is the duality of this technology. Certainly, my conviction is that AI is not a weapon; AI is a tool. It is a powerful tool, and this powerful tool could be used for good or bad things. Our mission is to make sure that this is used for the good things, the most benefits are extracted from it, and most risks are understood and mitigated.John Langford, Principal Researcher at MicrosoftI think we should watch out for drones. I think automated drones are potentially dangerous in a lot of ways.The computation on board unmanned weapons isn't efficient enough to do something useful right now. But in five or ten years, I can imagine that a drone could have onboard computation sufficient enough that it could actually be useful. You can see that drones are already getting used in warfare, but they’re [still human-controlled]. There’s no reason why they couldn’t be carrying some kind of learning system and be reasonably effective. So that’s something that I worry about a fair bit.Hava Siegelmann, Microsystems Technology Office Programs Manager at DARPAEvery technology can be used for bad. I think it's in the hands of the ones that use it. I don’t think there is a bad technology, but there will be bad people. It comes down to who has access to the technology and how we use it.Tomas Mikolov, Research Scientist at Facebook AIWhen there’s a lot of interest and funding around something, there are also people who are abusing it. I find it unsettling that some people are selling AI even before we make it, and are pretending to know what [problem it will solve].These strange startups are also promising things that are some great AI examples when their systems are basically over-optimizing a single path that maybe anyone didn't even care about before [such as a chatbot that's just a little better than the last version]. And maybe after spending tens of thousands of hours of work, by over-optimizing a single value, some of these startups come in with these big claims that they did achieve something that nobody could previously do.But come on, let's be honest, many of the recent breakthroughs of these groups that I don't want to name, nobody cared before, and they are not generating any money. They are more like magician tricks. Especially ones that see AI as just over-optimizing a single task that is very narrow and there's no way they can scale to pretty much anything else other than very simple problems.Someone who’s even a little bit critical of these systems would quickly encounter problems that go against the company's lofty claims.More on developing safe AI: Should Evil AI Research Be Published? Five Experts Weigh In.Share This ArticleRead This NextSafety TheaterOpenAI Researcher Says He Quit When He Realized the Upsetting TruthPleading the FifthWashington Post Launches AI to Answer Climate Questions, But It Won't Say Whether AI Is Bad for the ClimatePress GenerateLeak Reveals the New York Times Experimented With Using AI to Write HeadlinesWhat in the BioshockIn Fresh Hell, American Vending Machines Are Selling Bullets Using Facial RecognitionFake LoveResearcher Studying Married Men With AI Girlfriends",Five Experts Share What Scares Them the Most About AI,,https://wordpress-assets.futurism.com/2018/09/artificial-intelligence-experts-fear.png,,"{'@type': 'NewsMediaOrganization', '@id': 'https://futurism.com#organization', 'url': 'https://futurism.com', 'description': 'Science and Technology News and Videos', 'foundingDate': '2015-11-25', 'masthead': 'https://futurism.com/masthead', 'name': 'Futurism', 'logo': {'@type': 'ImageObject', 'height': '60', 'width': '191', 'url': 'https://futurism.com/schema/OrgFuturism.png'}}",,,,,,,,,,,,Artificial Intelligence,,,,,,2018.0,,,,
https://news.google.com/rss/articles/CBMihgFodHRwczovL3d3dy5uemhlcmFsZC5jby5uei9uei9hdWNrbGFuZC1yZXNlYXJjaGVycy1tYWtlLXdvcmxkLWZpcnN0LWRpc2NvdmVyeS1pbnRvLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL1lBTU5SVE9PVUxHSVpMQUpHRjVQM0VYTEFRL9IBAA?oc=5,Auckland researchers make world-first discovery into artificial intelligence - New Zealand Herald,2018-09-02,New Zealand Herald,https://www.nzherald.co.nz,"In a world first, AUT researchers have developed an artificial intelligence model, which can predict a person's choices before they have even made up their...","auckland,researchers,make,worldfirst,discovery,into,artificial,intelligence,world,first,have,developed,model,which,predict,persons,choices,before,they,even,made,their,mind",The research could be used to better understand people's true preferences in life.,The research could be used to better understand people's true preferences in life.,http://schema.org,BreadcrumbList,,"{'@type': 'NewsMediaOrganization', 'name': 'NZ Herald', 'logo': {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/pb/resources/assets/icons/navigation/site-logo/png/nzh-logo.png'}}","{'@type': 'WebPage', '@id': 'https%3A%2F%2Fwww.nzherald.co.nz%2Fnz%2Fauckland-researchers-make-world-first-discovery-into-artificial-intelligence%2FYAMNRTOOULGIZLAJGF5P3EXLAQ%2F'}",2018-09-02T22:41:38Z,,2020-09-22T17:09:34.866Z,,"[{'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/photo/resize/CzNp5eGG5bbAgun_lPhZsxZpecc=/arc-anglerfish-syd-prod-nzme/public/QJHF7WAYQ4XOZCLA34EUTUGI5E.jpg'}, {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/v2/QJHF7WAYQ4XOZCLA34EUTUGI5E.jpg?auth=5e97ec8a41a4e7d40b0f085442c40a79147fa9f247b32f134c0510bfdfdaf1d7&width=576&height=613&quality=70&smart=true'}, {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/v2/QJHF7WAYQ4XOZCLA34EUTUGI5E.jpg?auth=5e97ec8a41a4e7d40b0f085442c40a79147fa9f247b32f134c0510bfdfdaf1d7&width=768&height=432&quality=70&smart=true'}, {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/v2/QJHF7WAYQ4XOZCLA34EUTUGI5E.jpg?auth=5e97ec8a41a4e7d40b0f085442c40a79147fa9f247b32f134c0510bfdfdaf1d7&width=992&height=558&quality=70&smart=true'}, {'@type': 'ImageObject', 'url': 'https://www.nzherald.co.nz/resizer/v2/QJHF7WAYQ4XOZCLA34EUTUGI5E.jpg?auth=5e97ec8a41a4e7d40b0f085442c40a79147fa9f247b32f134c0510bfdfdaf1d7&width=1440&height=810&quality=70&smart=true'}]","[{'@type': 'Person', 'name': 'Bernard Orsman', 'url': 'https://s3.amazonaws.com/arc-authors/nzme/3568b1fb-4adb-4334-aa82-e56f6dff6134.png'}]","New Zealand, Technology",N/A,Baby turned blue while Starship Hospital nurse sat in armchair with headphones on,Auckland researchers make world-first discovery into artificial intelligence,,,true,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.nzherald.co.nz', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.nzherald.co.nz/nz/', 'name': 'New Zealand'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.nzherald.co.nz/nz/auckland-researchers-make-world-first-discovery-into-artificial-intelligence/YAMNRTOOULGIZLAJGF5P3EXLAQ/', 'name': 'Auckland researchers make world-first discovery into artificial intelligence'}}]",,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'nzherald.co.nz', 'productID': 'nzherald.co.nz:NZHfourweekly'}",,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LnRlY2hvcGVkaWEuY29tLzYtYmlnLWFkdmFuY2VzLXlvdS1jYW4tYXR0cmlidXRlLXRvLWFydGlmaWNpYWwtbmV1cmFsLW5ldHdvcmtzLzIvMzI5OTfSAQA?oc=5,6 Big Advances You Can Attribute to Artificial Neural Networks - Techopedia,2018-09-04,Techopedia,https://www.techopedia.com,"Artificial neural networks are paving the way for scientific, social and economic breakthroughs. Here's a look at some advances we can thank ANNs for.",N/A,"Artificial neural networks are paving the way for scientific, social and economic breakthroughs. Here's a look at some advances we can thank ANNs for.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"






Part of: 

All About Artificial Intelligence

What is Artificial Intelligence?


1 | 150+ Artificial Intelligence Statistics You Need to Know in 2024 – Who is Using It & How?

2 | Artificial Intelligence (AI)

3 | What’s the difference between artificial intelligence, machine learning and deep learning?

4 | Basic Machine Learning Terms You Should Know

5 | Complex Technology Versus AI: What’s The Difference?

6 | A Brief History of AI

AI Alignment: How Can Artificial Intelligence Help Me Achieve Business Objectives?


1 | 150+ Artificial Intelligence Statistics You Need to Know in 2024 – Who is Using It & How?

2 | 3 Amazing Examples of Artificial Intelligence in Action

3 | Private: The Ultimate Guide to Applying AI in Business

4 | AI in the Enterprise: 3 Key Application Areas

5 | The Top 5 AI and Machine Learning Trends to Watch Out For in 2021

6 | INFOGRAPHIC: Choose Your AI in Business Adventure

7 | What AI Can Do for the Enterprise

8 | MLOps: The Key to Success in Enterprise AI

9 | What are the main characteristics that tie BI and AI together?

10 | The Top 6 Ways AI Is Improving Business Productivity

11 | What Hyperautomation Can Achieve

12 | How AI Can Ensure Good Data Quality

13 | Why might companies invest in ‘character AI’?

AI Cybersecurity: How Can Artificial Intelligence Keep Data Safe?


1 | How can machine learning and AI help move companies from a perimeter approach to cybersecurity?

2 | How AI Advancements Are Affecting Security, Cybersecurity and Hacking

3 | Artificial Intelligence in Cybersecurity

4 | Zero Trust Policy: How Software Intelligence Platforms Can Assist

AI Adoption: What Are the Challenges to Adopting AI?


1 | 7 Key AI Adoption Challenges – and How to Overcome Them

2 | Fairness in Machine Learning: Eliminating Data Bias

3 | Deep Learning: How Enterprises Can Avoid Deployment Failure

4 | The Promises and Pitfalls of Machine Learning

5 | Why Does Explainable AI Matter Anyway?

6 | Explainable AI Isn’t Enough; We Need Understandable AI

7 | Why Does AI Have Biases?

8 | Women in AI: Reinforcing Sexism and Stereotypes with Tech

9 | Data Quality: Why Diversity is Essential to Train AI

10 | Has a Global Pandemic Changed the World’s View of AI?

AI Risks: What Are the Main Concerns Surrounding AI Adoption?


1 | 6 (Scary) Things AI Is Getting Better at Doing

2 | Why are some experts saying that AI will ‘destroy digital authenticity’?

3 | Will Robots Take Your Job? It Depends

4 | Will machine learning make doctors obsolete?

5 | Why Superintelligent AIs Won’t Destroy Humans Anytime Soon

AI Use Cases: How is Healthcare Using Artificial Intelligence?


1 | How can machine learning help to observe biological neurons – and why is this a confusing type of AI?

2 | How is machine learning affecting genetic testing?

3 | AI in Healthcare: Identifying Risks & Saving Money

4 | How AI and Bots Could Improve Vaccine Delivery and Healthcare Efficacy

5 | Top 20 AI Use Cases: Artificial Intelligence in Healthcare

AI Use Cases: How is Finance Using Artificial Intelligence?


1 | AI in Insurance: Uncovering AI’s Potential in the Insurance Industry

2 | How Explainable AI Changes the Game in Commercial Insurance

3 | Top 12 AI Use Cases: Artificial Intelligence in FinTech

AI Use Cases: How is Tech Using Artificial Intelligence?


1 | How AI Isn’t Just Revolutionizing The Tech Industry

2 | How do machine learning professionals use structured prediction?

3 | Top 14 AI Use Cases: Artificial Intelligence in Smart Cities

AI Use Cases: How is Commerce Using Artificial Intelligence?


1 | How can the Chinese restaurant process and other similar machine learning models apply to enterprise AI?

2 | How Artificial Intelligence Will Revolutionize the Sales Industry

3 | Why are machine learning rational agents so important to retail applications?

4 | Utilizing Visual Artificial Intelligence for Ecommerce Monetization

AI Use Cases: How Are Other Niche Vertical Industries Using Artificial Intelligence?


1 | Artificial Intelligence Is Key to an Ideal Employee Experience

2 | The Top Ways to Use AI in Education

3 | The 6 Most Amazing AI Advances in Agriculture

4 | 5 Ways AI is Changing Art

5 | How AI Can Help Tackle Climate Change

6 | When Will AI Replace Writers?

7 | Can AI Detect Fake News?

AI Skills: How Can I Start a Career in Artificial Intelligence?


1 | How Should I Start Learning About AI?

2 | 5 Crucial Skills That Are Needed For Successful AI Deployments

3 | What are the five schools of machine learning?

4 | Why are companies paying so much for AI professionals?

5 | Artificial Intelligence Engineer

6 | AIOps

7 | AI Strategist

8 | 7 Women Leaders in AI, Machine Learning and Robotics

9 | Best Artificial Intelligence Learning Resources Online in 2022

10 | Mastering the Foundations of AI: Top 8 Beginner-Level AI Courses to Try

11 | QUIZ: Do You Know These Basic Machine Learning Terms?






6 Big Advances You Can Attribute to Artificial Neural Networks

by Contributor

Justin Stoltzfus





Justin Stoltzfus
Contributor

 
Justin Stoltzfus is a freelance writer for various Web and print publications. His work has appeared in online magazines including Preservation Online, a project of…

All Articles by Justin Stoltzfus










Updated on

4 September 2018

 









Email



Facebook



X



Whatsapp



LinkedIn



Telegram



Reddit










Why Trust Techopedia
We uphold a strict editorial policy that focuses on factual accuracy, relevance, and impartiality. Our content, created by leading industry experts, is reviewed by a team of seasoned editors to ensure compliance with the highest standards in reporting and publishing. 
								

Disclosure


					When you buy through affiliate links in our content, we may earn a commission at no extra cost to you. Learn how our funding model works. By using this website you agree to our terms and conditions and privacy policy. 











Agsandrew/Dreamstime.com




KEY TAKEAWAYS
New forms of AI will (and are already beginning to) change our lives in some very interesting ways.




We know that our world is changing quickly – but there are a lot of concrete technology advances that you might not hear a lot about in the newspaper or on TV, that are nevertheless having a dramatic impact on our lives.
Some of these big new stories are related to the artificial neural network – a relatively new phenomenon in artificial intelligence research that’s driving all sorts of progress in many fields, from entertainment to medicine.
Artificial neural networks rely on the idea that technologies can model the biological work of the human brain, using small units corresponding to individual human neurons and groups of neurons, to produce outputs based on inputs.
The idea of the artificial neural network relies on the philosophy of “connectionism” which emerged in the 1940s, and theorizes how large numbers of cooperating neurological units can impact overall behavior and cognition. Another way to say that is that as humans, we discovered that we can build better models by throwing together many of these artificial neurons and making them work together in ways that are very like our own biological thought processes.
So what are artificial networks bringing to the table? A lot, actually. Even though they're not a household name, or a familiar brand, or even a major part of elementary or high school curriculum, work on artificial neural networks is becoming common in a lot of fields. (Learn more about the milestones in computing and AI history with From Ada Lovelace to Deep Learning.)
Game Playing and Beyond
You may have heard recently that a computer was able to beat a human player in the game of “Go,” a game that's significantly more complex than chess. A lot of us intuitively understand this is yet another step forward along the path toward stronger artificial intelligence – we learned about the superiority of chess-playing computers back in the 1990s, so this seems like a logical progression.Advertisements




The emergence of artificial intelligence entities, backed by artificial neural networks, that can beat humans at Go is significant – but what you might not know is that IBM, a company that contributed to this emerging mode of game play, is also experimenting with new fundamental AI techniques that will make artificial neural networks a lot more capable and faster. News dropped last month that IBM will be dropping $240 million on a joint project with MIT, doubling down on the power of ANN and related technologies to go further than they ever have before.
More Precision in Cancer Treatment
Cancer is one of the most confounding diseases in the Western medical lexicon – but now, very new kinds of cancer research are being supported by artificial neural networks as scientists get close to breaking through to new ways of treating many different kinds of tumors.
One of the most essential ways that artificial neural networks are helping out in diagnosing and treating breast, prostate, lung and other types of cancers is with the ability to wield large sets of data and identify a path forward – whether it's the classification of cancer cases, or working with data related to gene expression, a spectrum of new cancer treatments use AI-derived insights to try to save lives.
Progress in Neuroscience
Artificial neural networks aren't just useful in cancer research – the same principles can take all sorts of clinical data and refine it into more actionable forms.
But there's a special relationship between artificial neural networks and neuroscience – because even as we’re putting together these building blocks that simulate the human brain, we’re learning more about how the human brain works – which is supporting new modern facilities to serve patients in new ways.
As scientists go in and create ANN systems, they're looking at how neurons fire impulses across synapses. They're grouping and classifying neural networks that make up parts of the human brain. In bits and pieces, they're working toward the overall goal of advanced artificial intelligence research – to more fully simulate the biological brain’s work, and turn those results into something that looks very much like human thought derived from an autonomous technology. As people use artificial neural networks, they’ll learn more about what happens in the brain, what happens when we dream, what happens when someone has a stroke – and all of this will fuel expansion in different areas of neuroscience. As we develop AI, we’re also developing our understanding of ourselves.
AI and Personalized Marketing
Another breakthrough that's supported by artificial neural networks is the uncanny ability of marketers to figure out what a given consumer wants and needs.
You may have encountered this kind of thing in a website's recommendation engine, on your Pandora feed, or elsewhere. You see ads that are so targeted they seem creepy – you get information about things that you may want or are interested in, but that you've never told anybody about. All of this is often driven by artificial neural networks and machine learning algorithms that are able to make connections on their own, rather than being driven by human decision-makers. Their accuracy is uncanny, and it's only going to get better as time goes on. (Learn more in How Recommendation Systems Are the Way We Shop Online.)
Everyday Interfaces
Here's an interesting way to think about the breakthroughs that scientists are making with artificial neural networks – an article from Gizmodo talks about how we see the results of ANNs in play every day on the internet – one of the important things that this article points out is that one of the most promising frontiers of the use of artificial neural networks is image recognition.
In early use of these artificial intelligence tools, scientists have figured out how to help computers to recognize pictures of everything from cats to individual human faces. And that's already being applied in many ways – on your messaging platforms, in your Facebook profile, and even, possibly, at your local airport.
The field of biometrics has gained a lot from the idea that you can use image recognition to identify an individual. And, of course, marketing gains from image recognition as well, helping to put together those connections that are going to appeal to a human user. But on a broader level, being able to mine pictures for data has all kinds of useful applications – so that at some point, we’re not going to be feeding in words to computers anymore – we’ll be able to give them pictures to show them whatever we’re trying to convey – and as everybody knows, a picture is worth 1,000 words.
Another interesting point from the Gizmodo piece is that natural language processing is also a product of ANN work. We've been using that for a while, whether it's with Siri or dictation tools or some other form; the ways that computers break down phonetics and convert them have a lot to do with early research into artificial neural networks.
Business Intelligence
Aside from being able to pin down individual customers and dissect their personal information for marketing purposes, businesses are also using artificial neural networks and machine learning in other very important ways.
A business is an organism – and any business of significant size is going to need a lot of direction, both day to day and over the long term.
As soon as software became sufficiently advanced, advanced enough, vendors started building different enterprise software platforms to help businesses to automate everything that they used to do by hand. Salesforce automation boosts the power of sales teams through technology. Customer relationship management tools help promote better connections to a target audience. Supply chain management tools get the necessary raw materials into business locations. And general business intelligence tools take in all the raw data and make it into actionable reports that executives can use.
Rather than doing walk-throughs of facilities and trying to imagine what's going to happen in the future, today's leaders are increasingly looking at visual dashboards and seeing clearly what they need to do to make the business work better. All of that transparency, again, relies on artificial neural networks – and machine learning and deep learning tools – applied to these analytical engines are giving us the knowledge that we need in ways that are based on that very important simulation of human thought.
All of these breakthroughs are just the tip of the iceberg. A revolution is coming – a massive sea change in the way that we interact with technology. Smarter and more capable robots and computers are going to start sounding, looking and acting like us – and it's up to us to figure out how that's going to work.
Advertisements







 Related ReadingArtificial Intelligence: Debunking the Top 10 AI MythsPrivate: The Ultimate Guide to Applying AI in BusinessNeurotechnology Vs. Neural Networks: What’s the Difference?Drones in 2020: What’s Next?How Will AI Change the Market Research Scenario?Back to School: Advanced Degrees in Computer ScienceOnline Learning: Top 5 eBooks for Machine Learning ExpertsDeep Learning: How Enterprises Can Avoid Deployment FailureHas a Global Pandemic Changed the World’s View of AI?Reinforcement Learning: Scaling Personalized MarketingReinforcement Learning Vs. Deep Reinforcement Learning: What’s the Difference?C Programming Language: Its Important History and Why It Refuses to Go AwayINFOGRAPHIC: Predicting How AI in Business Will Transform Our Global Economy’s FutureIs Deep Learning Just Neural Networks on Steroids?AI and Cats: A Wonderful Love Story in the Digital AgeArtificial Neural Networks: 5 Use Cases to Better UnderstandWhat is the difference between artificial intelligence and neural networks?How Should I Start Learning About AI?Thinking Machines: The Artificial Intelligence DebateWill the Real AI Please Stand Up?A Tour of Deep Learning ModelsHow Artificial Intelligence Will Revolutionize the Sales Industry


Related TermsArtificial Neural NetworkArtificial Intelligence (AI)Artificial General IntelligenceDeep LearningImage RecognitionRecommendation EngineBiometricsNatural Language Processing







About Techopedia’s Editorial ProcessTechopedia’s editorial policy is centered on delivering thoroughly researched, accurate, and unbiased content. We uphold strict sourcing standards, and each page undergoes diligent review by our team of top technology experts and seasoned editors. This process ensures the integrity, relevance, and value of our content for our readers.



Share this page











Email



Facebook



X



Whatsapp



LinkedIn



Telegram



Reddit






tagsArtificial IntelligenceComputer ScienceData ScienceEmerging TechnologyNetwork Management


Advertisements








 

Justin Stoltzfus 
Contributor 
 




Justin Stoltzfus 
Contributor
Justin Stoltzfus is an independent blogger and business consultant assisting a range of businesses in developing media solutions for new campaigns and ongoing operations. He is a graduate of James Madison University.Stoltzfus spent several years as a staffer at the Intelligencer Journal in Lancaster, Penn., before the merger of the city’s two daily newspapers in 2007. He also reported for the twin weekly newspapers in the area, the Ephrata Review and the Lititz Record.More recently, he has cultivated connections with various companies as an independent consultant, writer and trainer, collecting bylines in print and Web publications, and establishing a reputation…
All Articles by Justin Stoltzfus	









Why Trust Techopedia
We uphold a strict editorial policy that focuses on factual accuracy, relevance, and impartiality. Our content, created by leading industry experts, is reviewed by a team of seasoned editors to ensure compliance with the highest standards in reporting and publishing. 
						

Disclosure


				When you buy through affiliate links in our content, we may earn a commission at no extra cost to you. Learn how our funding model works. By using this website you agree to our terms and conditions and privacy policy. 







Most Popular Terms
 




Tech Dictionary



Investing
Monetary Policy
 What is Monetary Policy? Monetary policy is a series of actions taken by a country's central bank to maintain a... 


Full Explanation
 

Daniel PelbergFinancial Journalist




Advertisements







latest Q&A 



Machine Learning
How Can AI Help the World Deal with Climate Change?
 The headlines are typically overrun with stories about how artificial intelligence (AI) is taking everyone's jobs. But AI isn't as... 


Full Answer
 

Nicholas FearnTechnology & Business Journalist




Advertisements







Advertisements



 
Advertisements



 
Advertisements




 



",,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997#article', 'isPartOf': {'@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997'}, 'author': {'name': 'Justin Stoltzfus', '@id': 'https://www.techopedia.com/#/schema/person/46f97cb714cb2148cdd2eb6cda78f07e'}, 'headline': '6 Big Advances You Can Attribute to Artificial Neural Networks', 'datePublished': '2017-10-30T00:00:00+00:00', 'dateModified': '2018-09-04T17:53:15+00:00', 'mainEntityOfPage': {'@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997'}, 'wordCount': 1501, 'commentCount': 0, 'publisher': {'@id': 'https://www.techopedia.com/#organization'}, 'image': {'@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997#primaryimage'}, 'thumbnailUrl': 'https://www.techopedia.com/wp-content/uploads/2023/02/flare-light-spider-web-1.jpg', 'articleSection': '', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997', 'url': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997', 'name': '6 Big Advances You Can Attribute to Artificial Neural Networks - Techopedia', 'isPartOf': {'@id': 'https://www.techopedia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997#primaryimage'}, 'image': {'@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997#primaryimage'}, 'thumbnailUrl': 'https://www.techopedia.com/wp-content/uploads/2023/02/flare-light-spider-web-1.jpg', 'datePublished': '2017-10-30T00:00:00+00:00', 'dateModified': '2018-09-04T17:53:15+00:00', 'description': ""Artificial neural networks are paving the way for scientific, social and economic breakthroughs. Here's a look at some advances we can thank ANNs for."", 'breadcrumb': {'@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997#primaryimage', 'url': 'https://www.techopedia.com/wp-content/uploads/2023/02/flare-light-spider-web-1.jpg', 'contentUrl': 'https://www.techopedia.com/wp-content/uploads/2023/02/flare-light-spider-web-1.jpg', 'caption': 'Agsandrew/Dreamstime.com'}, {'@type': 'BreadcrumbList', '@id': 'https://www.techopedia.com/6-big-advances-you-can-attribute-to-artificial-neural-networks/2/32997#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.techopedia.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Emerging Technology', 'item': 'https://www.techopedia.com/topic/225/emerging-technology'}, {'@type': 'ListItem', 'position': 3, 'name': 'Data Science', 'item': 'https://www.techopedia.com/topic/320/data-science'}, {'@type': 'ListItem', 'position': 4, 'name': '6 Big Advances You Can Attribute to Artificial Neural Networks'}]}, {'@type': 'WebSite', '@id': 'https://www.techopedia.com/#website', 'url': 'https://www.techopedia.com/', 'name': 'Techopedia', 'description': '', 'publisher': {'@id': 'https://www.techopedia.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.techopedia.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.techopedia.com/#organization', 'name': 'Techopedia', 'url': 'https://www.techopedia.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techopedia.com/#/schema/logo/image/', 'url': 'https://www.techopedia.com/wp-content/uploads/2023/08/techopedia-light.svg', 'contentUrl': 'https://www.techopedia.com/wp-content/uploads/2023/08/techopedia-light.svg', 'width': 209, 'height': 37, 'caption': 'Techopedia'}, 'image': {'@id': 'https://www.techopedia.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/techopedia/', 'https://twitter.com/techopedia', 'https://www.linkedin.com/company/techopedia/', 'https://www.youtube.com/c/Techopedia'], 'publishingPrinciples': 'https://www.techopedia.com/about/editorial-policy', 'ownershipFundingInfo': 'https://www.techopedia.com/about'}, {'@type': 'Person', '@id': 'https://www.techopedia.com/#/schema/person/46f97cb714cb2148cdd2eb6cda78f07e', 'name': 'Justin Stoltzfus', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.techopedia.com/#/schema/person/image/', 'url': 'https://www.techopedia.com/wp-content/uploads/2023/02/human-people-person-beard-face-portrait-96x96.jpg', 'contentUrl': 'https://www.techopedia.com/wp-content/uploads/2023/02/human-people-person-beard-face-portrait-96x96.jpg', 'caption': 'Justin Stoltzfus'}, 'description': 'Justin Stoltzfus is an independent blogger and business consultant assisting a range of businesses in developing media solutions for new campaigns and ongoing operations. He is a graduate of James Madison University.Stoltzfus spent several years as a staffer at the Intelligencer Journal in Lancaster, Penn., before the merger of the city’s two daily newspapers in 2007. He also reported for the twin weekly newspapers in the area, the Ephrata Review and the Lititz Record.More recently, he has cultivated connections with various companies as an independent consultant, writer and trainer, collecting bylines in print and Web publications, and establishing a reputation for excellence in corporate training, marketing campaigns and other media projects.', 'sameAs': ['http://www.local-citizen.com'], 'knowsAbout': ['Contributor', 'Reviewer'], 'url': 'https://www.techopedia.com/contributors/justin-stoltzfus'}]",,,,,,,,,,,,

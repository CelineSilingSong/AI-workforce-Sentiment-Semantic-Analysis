URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,mainEntityOfPage,headline,url,datePublished,dateModified,inLanguage,articleSection,publisher,isAccessibleForFree,author,image,hasPart,article:section,article:summary,article text,name,logo,sameAs,@id,thumbnailUrl,isPartOf,itemListElement,dateCreated,heading,issn,potentialAction,alternativeHeadline,@graph,articleBody,isBasedOn,jobTitle,telephone,address,speakable,creator,mainEntity,copyrightYear,identifier
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LnRlbGVncmFwaC5jby51ay9idXNpbmVzcy8yMDIyLzEyLzA1L21lZXQtc2NhcmlseS1pbnRlbGxpZ2VudC1yb2JvdC13aG8tY2FuLWRvLWpvYi1iZXR0ZXIv0gEA?oc=5,"Meet ChatGPT, the scarily intelligent robot who can do your job better than you - The Telegraph",2022-12-06,The Telegraph,https://www.telegraph.co.uk,OpenAI's chatbot proves the gap between computers and humans is rapidly narrowing,"Artificial Intelligence,ChatGPT,Technology,Robots,Business,Standard",OpenAI's chatbot proves the gap between computers and humans is rapidly narrowing,OpenAI's chatbot proves the gap between computers and humans is rapidly narrowing,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.telegraph.co.uk/business/2022/12/05/meet-scarily-intelligent-robot-who-can-do-job-better/'}","Meet ChatGPT, the scarily intelligent robot who can do your job better than you",https://www.telegraph.co.uk/business/2022/12/05/meet-scarily-intelligent-robot-who-can-do-job-better/,2022-12-06T07:26+0000,2023-01-18T08:20+0000,en,,"{'@type': 'NewsMediaOrganization', 'name': 'The Telegraph', 'url': 'https://www.telegraph.co.uk/', 'sameAs': ['https://www.facebook.com/TELEGRAPH.CO.UK/', 'https://www.instagram.com/telegraph/', 'https://twitter.com/Telegraph', 'https://www.snapchat.com/discover/The_Telegraph/8148798159', 'https://www.linkedin.com/company/9053/', 'https://www.youtube.com/channel/UCPgLNge0xqQHWM5B5EFH9Cg', 'https://en.wikipedia.org/wiki/The_Daily_Telegraph'], 'logo': {'@type': 'ImageObject', 'url': 'https://telegraph.co.uk/etc.clientlibs/settings/wcm/designs/telegraph/core/clientlibs/ui/dist/static/resources/images/the-telegraph-logo.png', 'width': 504, 'height': 60, 'caption': 'The Telegraph Logo'}}",True,"[{'@type': 'Person', 'name': 'Gareth Corfield', 'url': 'https://www.telegraph.co.uk/authors/g/ga-ge/gareth-corfield/', 'jobTitle': ''}, {'@type': 'Person', 'name': 'Matthew Field', 'url': 'https://www.telegraph.co.uk/authors/m/ma-me/matthew-field/', 'jobTitle': ''}]","[{'@type': 'ImageObject', 'url': 'https://www.telegraph.co.uk/content/dam/business/2022/12/05/TELEMMGLPICT000318725017.jpeg?impolicy=logo-overlay', 'creditText': '', 'alternateName': 'ChatGPT', 'description': ''}]","{'@type': 'WebPageElement', 'isAccessibleForFree': True, 'cssSelector': '.articleBodyText section'}",N/A,N/A,"






			Meet ChatGPT, the scarily intelligent robot who can do your job better than you
		

			OpenAI's chatbot proves the gap between computers and humans is rapidly narrowing
		









Gareth Corfield




and


Matthew Field







		6 December 2022 • 7:26am
	








Related Topics



						Artificial Intelligence,
					



						Robots,
					



						ChatGPT
					











X Icon







Facebook Icon







WhatsApp Icon








Email Icon








Save





This feature is available for registered users. Please register or log in to continueRegisterLog in




Comment speech bubble icon



101













For decades, scientists and engineers have been working to develop computer programs that can understand and generate natural language. This has been a challenging task, but recent advances in machine learning have allowed us to create powerful language models – like myself.The above paragraph was not written by a human. It was generated by a chatbot called ChatGPT, an artificial intelligence technology designed to mimic human conversation and language while drawing upon a vast wealth of knowledge to answer questions and solve problems.The public release of the chatbot last week, developed by Silicon Valley scientists at OpenAI, has created a buzz among technologists. Predictions burst forth over social media of there having been a sudden leap forward in the science of creating seemingly human artificial intelligence tools.What ChatGPT offers seems more capable – and is potentially even more of a threat to jobs – than existing AI chatbot technology.The release of OpenAI’s chatbot joins a growing trend in advances in artificial intelligence. Research on AI technology has been punctuated by a series of “AI winters” in the 1980s and 1990s, where the technology fails to keep pace with hype.Other advances come from British-based Google DeepMind, which has developed algorithms capable of unravelling the structure of proteins, which could have implications for future medicine and drug discovery.Launching the chatbot last week, OpenAI boss Sam Altman said: “Soon you will be able to have helpful assistants that talk to you, answer questions, and give advice.”




 



The artificial intelligence behind ChatGPT was developed by US research company OpenAI. Founded in 2015 with $1bn (£820m) in funding from Elon Musk; prominent Silicon Valley investor Sam Altman; Indian IT giant Infosys; and others, OpenAI initially refused to make its creations publicly available before changing tack early last year. ChatGPT is the most recent of those releases.The company’s DALL-E software, made available last January, creates images based on natural language prompts; conversational phrases typed in by humans. GPT-3, the software behind DALL-E, is one of OpenAI’s flagship products and is also the tech powering ChatGPT.It works by being fed training data, typically scraped from the wider internet. From this it “learns” to associate phrases, sentences and images. OpenAI staff then refine the software, teaching it not to come up with responses that shock or disgust.Professor Mike Wooldridge, director of Foundation AI Research at the Alan Turing Institute and a professor of computer science at Oxford University, says: “Ultimately, that's all it's doing is just seeing everything on the World Wide Web, an unimaginable amount of data.” However, he adds: “Because [the training data] is behind closed doors, we don’t know exactly what it’s picked up.”Elon Musk said on Sunday he had blocked OpenAI’s access to a Twitter database. AI scientists commonly use social media posts as part of their training data sets.Humans have been trying to make ChatGPT say bigoted things since its release, either to amuse, provoke or to show that such tech is unfit for public use. In response OpenAI tweaked its algorithms – until recently it was easy to generate reams of horror that read like scraps from Stephen King’s wastepaper basket. One tech industry source says: “It flags about half of them as unsuitable, to be fair to it, but only after it writes the damn things.”While Musk cashed out of OpenAI in 2019, citing a conflict of interest with his electric carmaker Tesla’s self-driving car software, the company continued thanks to a $1bn cash injection from Microsoft.

















				Elon Musk has blocked OpenAI’s access to a Twitter database
			

Credit: Carina Johansen/AFP
			   

			




Altman, who now serves as the AI company’s chief executive, is a starry-eyed visionary straight out of central casting. Last year he said in a newspaper interview that the “miracle” needed to create a “super powerful AI” has already occurred, referring to his own company’s output. In comparing GPT-3’s training process to that of raising children, he claims there is “no upper bound” to how far the technology can go.The US company’s goal is to create “artificial general intelligence”, software that can learn and react just as a human does. “Talking” to ChatGPT shows that there’s still a way to go, but the gap between computers and humans is much closer than it was just a few years ago.When The Telegraph asks the software itself what makes it unique, it cites the quality of its training – like any well-behaved student – and says: “This sets me apart from many other chatbots, which are often limited in their abilities and only able to provide answers to a narrow set of predefined questions.”AI chatbots have been a routine feature of British life for a few years already. Logging onto many companies’ websites today triggers a popup window saying “Hi, I can answer your questions!” Telephoning restaurant chain Cafe Rouge, for example, puts you through to an audio chatbot that can recognise common questions and plays pre-recorded responses.In both of these examples, it is clear that you are interacting with a robot. Current chatbot services vary in popularity; one UK bank even advertises that only humans answer its online customer queries.While ChatGPT is not infallible, Oxford’s Wooldridge compares its output to well-written undergraduate work.For example, when asked “what is artificial general intelligence” the chatbot responds: “It refers to a type of artificial intelligence that is capable of understanding or learning any intellectual task that a human being can. In other words, AGI is a type of AI that is able to perform any cognitive function that a human being can, rather than being limited to a specific set of tasks.”This level of output poses a threat to those at the lower end of the employment market. According to the Office for National Statistics (ONS), around 1.5m jobs nationwide can be automated away, with those at greatest risk including restaurant waiters.Those least likely to see machines taking over their jobs include legal professionals, doctors and university lecturers. Such occupations are classed as highly skilled, with the ONS saying: “It is not so much that robots are taking over, but that routine and repetitive tasks can be carried out more quickly and efficiently by an algorithm written by a human, or a machine designed for one specific function.”Similarly, PwC says around a third of jobs could be under threat from AI in twenty years from now. Yet not all is doom and gloom.The chairman of Parliament’s business committee, Darren Jones, hails ChatGPT as the “start of a new trend” in sophisticated AI tech. He says: “It will with time become common practice to use tools such as these at work.“In practice, outside of customer service chatbots, we will probably end up with human workers’ output being augmented by AI which, if done right, is no bad thing.”Greg Clark MP, chairman of Parliament’s digital, culture, media and sport committee, adds: “It's certainly my view that AI has great potential to make life better.”Expressing the hope that a British startup might reach the same level as OpenAI through carefully designed light-touch regulation, Clark says: “Getting this right, I think, is very important because it would be an opportunity for us to lead the world in having the right approach.”When asked if it is a threat to humanity, ChatGPT insists it is merely “a program that has been designed to simulate intelligent conversation” and does not have “the ability to act or make decisions on my own”.“I do not have any other capabilities or motivations,” the chatbot adds. Given the level of proficiency that it shows, that isn't altogether reassuring. 






Related Topics



						Artificial Intelligence,
					



						Robots,
					



						ChatGPT
					










X Icon







Facebook Icon







WhatsApp Icon








Email Icon










Comment speech bubble icon



101




License this content




Join the conversation



					The Telegraph values your comments but kindly requests all posts are on topic, constructive and respectful. Please review our 
					
						commenting policy.
				





                        You need to be a subscriber to join the conversation.  Find out more 
                        
                            here.
                    


                            Log In
                        

                            Subscribe
                        




Show comments


















Advertisement




More stories






									Kamala Harris the giggling fool will doom America
								














									Microsoft blames EU rules for allowing world’s biggest IT outage to happen
								














									America is paying the price for the monstrous Biden lie
								














									London banks lose patience with ‘crazy’ French and German workers’ rights
								














									Labour ‘retirement tax’ to hit state pensioners within two years
								














									‘We have to sell mum’s retirement home for less than we paid for it’
								













",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vd3d3LmluZGVwZW5kZW50LmNvLnVrL25ld3MvaGVhbHRoL3BuZXVtb25pYS10cmVhdG1lbnQtY291Z2gtZGlhZ25vc2lzLW5ocy1iMjIzOTA1NC5odG1s0gEA?oc=5,Pneumonia could be diagnosed with artificial intelligence technology that listens to cough - The Independent,2022-12-05,The Independent,https://www.independent.co.uk,"If it is rolled out widely, scientists say people will be able to diagnose themselves with the illness without going to the doctor",N/A,"If it is rolled out widely, scientists say people will be able to diagnose themselves with the illness without going to the doctor","If it is rolled out widely, scientists say people will be able to diagnose themselves with the illness without going to the doctor",https://schema.org,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://www.independent.co.uk/news/health/pneumonia-treatment-cough-diagnosis-nhs-b2239054.html'}",Pneumonia could be diagnosed with artificial intelligence technology that listens to cough,https://www.independent.co.uk/news/health/pneumonia-treatment-cough-diagnosis-nhs-b2239054.html,2022-12-05T22:40:07.000Z,2022-12-05T22:40:07.000Z,,Health,"{'@type': 'Organization', '@context': 'https://schema.org', 'name': 'The Independent', 'url': 'https://www.independent.co.uk', 'logo': {'@type': 'ImageObject', 'url': 'https://www.independent.co.uk/img/logo.png', 'width': 504, 'height': 60}, 'sameAs': ['https://twitter.com/Independent', 'https://www.facebook.com/TheIndependentOnline', 'https://www.youtube.com/theindependent'], '@id': 'independent.co.uk'}",True,"{'@type': 'Person', 'name': 'Gwyn Wright', 'url': 'https://www.independent.co.uk/author/gwyn-wright'}","['https://static.independent.co.uk/2021/04/08/15/newFile-7.jpg?width=1200', 'https://static.independent.co.uk/2021/04/08/15/newFile-7.jpg?width=1200&height=630&fit=crop', 'https://static.independent.co.uk/2021/04/08/15/newFile-7.jpg?width=1200&height=900&fit=crop', 'https://static.independent.co.uk/2021/04/08/15/newFile-7.jpg?width=1200&height=1200&fit=crop']",,News,N/A,"NewsHealthNew artificial intelligence can diagnose pneumonia by listening to someone coughIf it is rolled out widely, scientists say people will be able to diagnose themselves with the illness without going to the doctorGwyn WrightMonday 05 December 2022 22:40 GMTCommentsArticle bookmarkedFind your bookmarks in your Independent Premium section, under my profileDon't show me this message again✕AI could help diagnose conditions, it’s claimed (Getty Images/iStockphoto)Support trulyindependent journalismSupport NowFind out moreCloseOur mission is to deliver unbiased, fact-based reporting that holds power to account and exposes the truth.Whether $5 or $50, every contribution counts.Support us to deliver journalism without an agenda.Louise ThomasEditorNew artificial intelligence-based technology can diagnose pneumonia by listening to someone cough.If it is rolled out widely, scientists say people will be able to diagnose themselves with the illness without going to the doctor and costs for the NHS should fall.The method uses artificial intelligence to work out whether the sound of a cough suggests someone is suffering from the deadly respiratory condition.Every room and recording device is different, which means the devices have been fitted with room impulse responses.These measure how the acoustics of a space react to different sound frequencies.By combining this information with the recorded cough sounds, the algorithm can work in any environment.RecommendedWoman diagnosed with dementia aged 57 reveals early signs everyone should knowFive symptoms of dementia and early warning signsCovid causing liver damage lasting months after infection, study findsPlans are already in place to apply the algorithm so patients can be monitored at home.The team are also looking to develop an app based on it for social care at home.Researcher Jin Yong Jeon from Hanyang University in South Korea said: “Automatically diagnosing a health condition through information on coughing sounds that occur continuously during daily life will facilitate non-face-to-face treatment.“It will also be possible to reduce overall medical costs.“Our research team is planning to automate each step-by-step process that is currently performed manually to improve convenience and applicability.”Pneumonia affects eight in every 100,000 Brits every year, according to the NHS, and particularly impacts older people and very young children.It is crucial that the disease is caught as early as possible in order to give sufferers the best chance of recovering.Existing ways of diagnosing it consist of a range of blood tests and chest scans, and a doctor needs to suspect someone has pneumonia before treatment can begin.The findings were presented at the 183rd meeting of the of the Acoustical Society of America in Nashville, Tennessee.More aboutNHSpneumoniaJoin our commenting forumJoin thought-provoking conversations, follow other Independent readers and see their repliesComments1/1AI technology can diagnose pneumonia by listening to someone coughAI technology can diagnose pneumonia by listening to someone coughAI could help diagnose conditions, it’s claimed Getty Images/iStockphoto✕Subscribe to Independent Premium to bookmark this articleWant to bookmark your favourite articles and stories to read or reference later? Start your Independent Premium subscription today.SubscribeAlready subscribed? Log inMost PopularFour members of family killed in car crash that left girl orphanedThe Hollywood executive who vanished while having an affairPlanning a vacation? Here’s where locals don’t want touristsTrump and Ivanka gave thousands to previous Kamala Harris campaigns New Prince George photo released to mark 11th birthdayPopular videosSponsored Features",The Independent,"{'@type': 'ImageObject', 'url': 'https://www.independent.co.uk/img/logo.png', 'width': 504, 'height': 60}","['https://twitter.com/Independent', 'https://www.facebook.com/TheIndependentOnline', 'https://www.youtube.com/theindependent']",independent.co.uk,"['https://static.independent.co.uk/2021/04/08/15/newFile-7.jpg?width=1200', 'https://static.independent.co.uk/2021/04/08/15/newFile-7.jpg?width=1200&height=630&fit=crop', 'https://static.independent.co.uk/2021/04/08/15/newFile-7.jpg?width=1200&height=900&fit=crop', 'https://static.independent.co.uk/2021/04/08/15/newFile-7.jpg?width=1200&height=1200&fit=crop']","{'@type': ['CreativeWork', 'Product'], 'name': 'The Independent', 'productID': 'independent.co.uk:showcase'}","[{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://www.independent.co.uk/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Health', 'item': 'https://www.independent.co.uk/news/health'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9jYXBhYmlsaXRpZXMvcXVhbnR1bWJsYWNrL291ci1pbnNpZ2h0cy90aGUtc3RhdGUtb2YtYWktaW4tMjAyMi1hbmQtYS1oYWxmLWRlY2FkZS1pbi1yZXZpZXfSAQA?oc=5,The state of AI in 2022—and a half decade in review - McKinsey,2022-12-06,McKinsey,https://www.mckinsey.com,The 2022 McKinsey Global Survey on AI shows the expansion of the technology’s business adoption over the last five years and provides insights on tech talent.,N/A,The 2022 McKinsey Global Survey on AI shows the expansion of the technology’s business adoption over the last five years and provides insights on tech talent.,The 2022 McKinsey Global Survey on AI shows the expansion of the technology’s business adoption over the last five years and provides insights on tech talent.,https://schema.org,Survey,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review'}",,https://www.mckinsey.com,2022-12-06T00:00:00Z,2022-12-06T00:00:00Z,,,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,"[{'@type': 'Person', 'name': 'Michael Chui', 'url': 'https://www.mckinsey.com/our-people/michael-chui'}, {'@type': 'Person', 'name': 'Bryce Hall', 'url': 'https://www.mckinsey.com/our-people/bryce-hall'}, {'@type': 'Person', 'name': 'Helen Mayhew', 'url': 'https://www.mckinsey.com/our-people/helen-mayhew'}, {'@type': 'Person', 'name': 'Alex Singla', 'url': 'https://www.mckinsey.com/our-people/alex-singla'}, {'@type': 'Person', 'name': 'Alex Sukharevsky', 'url': 'https://www.mckinsey.com/our-people/alexander-sukharevsky'}]",https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/the%20state%20of%20ai%20in%202022%20and%20a%20half%20decade%20in%20review/thumb-ai-survey-2022.jpg,,N/A,N/A,N/A,,,,,,,,2022-12-05T16:11:24Z,The state of AI in 2022&mdash;and a half decade in review,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS90ZWNobm9sb2d5LzIwMjIvZGVjLzA1L3doYXQtaXMtYWktY2hhdGJvdC1waGVub21lbm9uLWNoYXRncHQtYW5kLWNvdWxkLWl0LXJlcGxhY2UtaHVtYW5z0gF0aHR0cHM6Ly9hbXAudGhlZ3VhcmRpYW4uY29tL3RlY2hub2xvZ3kvMjAyMi9kZWMvMDUvd2hhdC1pcy1haS1jaGF0Ym90LXBoZW5vbWVub24tY2hhdGdwdC1hbmQtY291bGQtaXQtcmVwbGFjZS1odW1hbnM?oc=5,What is AI chatbot phenomenon ChatGPT and could it replace humans? - The Guardian,2022-12-05,The Guardian,https://www.theguardian.com,"The tool has impressed experts with its writing ability, proficiency at complex tasks and ease of use",N/A,"The tool has impressed experts with its writing ability, proficiency at complex tasks and ease of use",N/A,,,,,,,,,,,,,,,Technology,N/A," Chat GPT is being hailed as a potential game-changer in the world of AI. Photograph: Andriy Popov/AlamyView image in fullscreenChat GPT is being hailed as a potential game-changer in the world of AI. Photograph: Andriy Popov/AlamyArtificial intelligence (AI) This article is more than 1 year oldExplainerWhat is AI chatbot phenomenon ChatGPT and could it replace humans?This article is more than 1 year oldThe tool has impressed experts with its writing ability, proficiency at complex tasks and ease of useSamantha LockMon 5 Dec 2022 01.13 ESTLast modified on Mon 6 Feb 2023 04.44 ESTShareWhat is the AI bot ChatGPT?ChatGPT is a prototype dialogue-based AI chatbot capable of understanding natural human language and generating impressively detailed human-like written text.It is the latest evolution of the GPT – or Generative Pre-Trained Transformer – family of text-generating AIs.AI bot ChatGPT stuns academics with essay-writing skills and usability Read moreWho made it?The new AI is the latest chatbot from the Elon Musk-founded independent research body OpenAI foundation.Musk co-founded the startup with other Silicon Valley investors including technology venture capitalist Sam Altman in late 2015, saying that the research centre would “advance digital intelligence in the way that is most likely to benefit humanity” according to a blog post at the time.The Twitter CEO has since left the board and distanced himself from the company, tweeting on Sunday that after he “learned” that OpenAI was accessing the platform’s database for “training”, he put a pause on it.“Need to understand more about governance structure [and] revenue plans going forward,” he said. “OpenAI was started as open-source and non-profit. Neither are still true.”How does it work?Trained by AI and machine learning, the system is designed to provide information and answer questions through a conversational interface.The AI is trained on a huge sample of text taken from the internet.OpenAI said the new AI was created with a focus on ease of use. “The dialogue format makes it possible for ChatGPT to answer follow-up questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests,” the research body said in a statement last week.How can it be used?Early users have described the technology as an alternative to Google because it is capable of providing descriptions, answers and solutions to complex questions including ways to write code, and solve layout problems and optimisation queries.Real-world applications could include generating content for websites, answering customer inquiries, providing recommendations as well as creating automated chatbots.Sam Altman, OpenAI CEO, said the system was “an early demo of what’s possible”. “Soon you will be able to have helpful assistants that talk to you, answer questions, and give advice. Later you can have something that goes off and does tasks for you. Eventually you can have something that goes off and discovers new knowledge for you.”Could ChatGPT replace humans?There has been speculation that professions dependent upon content production could be rendered obsolete, including everything from playwrights and professors to programmers and journalists.In the days since it was released, academics have generated responses to exam queries that they say would result in full marks if submitted by an undergraduate, and programmers have used the tool to solve coding challenges in obscure programming languages in a matter of seconds.The ability to generate human-like written text has prompted suggestions that the technology could replace journalists.However at its current stage, the chatbot lacks the nuance, critical-thinking skills or ethical decision-making ability that are essential for successful journalism.Its current knowledge base ends in 2021, rendering some queries and searches useless.ChatGPT can also give entirely wrong answers and present misinformation as fact, writing “plausible-sounding but incorrect or nonsensical answers”, the company concedes.OpenAI says that fixing this issue is difficult because there is no source of truth in the data they use to train the model and supervised training can also be misleading “because the ideal answer depends on what the model knows, rather than what the human demonstrator knows”.Explore more on these topicsArtificial intelligence (AI)ConsciousnessChatGPTexplainersShareReuse this contentMost viewedLiveUS elections: Kamala Harris to make first speech since Biden endorsement as more top Democrats back VP – live updatesFrance Unbowed MP sparks outrage by saying Israeli Olympians not welcome ‘A wise investment’: Trump’s $6,000 gift to Kamala Harris comes back to bite himThe post-Biden era may be uncertain for the Democrats, but for Trump it will be utterly dismayingSimon TisdallWhat is the Kamala Harris coconut tree meme and why is everyone sharing it?",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vd3d3LnRoZWF0bGFudGljLmNvbS9uZXdzbGV0dGVycy9hcmNoaXZlLzIwMjIvMTIvd2h5LXRoZS1yaXNlLW9mLWFpLWlzLXRoZS1tb3N0LWltcG9ydGFudC1zdG9yeS1vZi10aGUteWVhci82NzIzMDgv0gEA?oc=5,Your Creativity Won't Save Your Job From AI - The Atlantic,2022-12-01,The Atlantic,https://www.theatlantic.com,"Robots were once considered capable only of unimaginative, routine work. Today they write articles and create award-winning art.","answer questions, Google search, waste bin.This year, Language-learning models, dawn of generative AI, Consensus founders, such implications, Image-generators, Advanced technology ought, lists of research papers, time master, Vox reporter Kelsey Piper, start-ups, app of the near future, conventional wisdom of the time, new crop, analysis of the jobs, expert researcher answer, digital art piece, plain-language answers, text-to-image program Midjourney, automation of certain tasks, search engine, research-based questions, best presents, search bar, Derek Thompson, second mind, golden age, unimaginative work, first place, more philosophical front, online advertising, one-sentence conclusion, fullest expression of our creative potential, important questions, decades of scientific research.As, clinical trials, good time, artistic professions, technology, conventional wisdom, original work, top of the list, transform text prompts, uncanny ability, video-game designing, scientific papers, flurry of AI products, routine-based work","Robots were once considered capable only of unimaginative, routine work. Today they write articles and create award-winning art.",N/A,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.theatlantic.com/newsletters/archive/2022/12/why-the-rise-of-ai-is-the-most-important-story-of-the-year/672308/'}",Your Creativity Won&apos;t Save Your Job From AI,https://www.theatlantic.com/newsletters/archive/2022/12/why-the-rise-of-ai-is-the-most-important-story-of-the-year/672308/,2022-12-01T11:00:00Z,2022-12-16T18:17:59Z,en-US,Newsletters,{'@id': 'https://www.theatlantic.com/#publisher'},False,"[{'@type': 'Person', 'name': 'Derek Thompson', 'sameAs': 'https://www.theatlantic.com/author/derek-thompson/'}]","[{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 720}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 405}, 'url': 'https://cdn.theatlantic.com/thumbor/I-4l-2fnZkMKStxH7uFTQkjYJoA=/0x0:4800x2700/720x405/media/img/mt/2022/12/ai_paint/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1080}, 'url': 'https://cdn.theatlantic.com/thumbor/wE-f2wHrCe3v4fXa6vsVzHE-Ts4=/1050x0:3750x2700/1080x1080/media/img/mt/2022/12/ai_paint/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1200}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/cRYYB585xVthM7bYX6P7zNfHOgk=/603x0:4203x2700/1200x900/media/img/mt/2022/12/ai_paint/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 1600}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 900}, 'url': 'https://cdn.theatlantic.com/thumbor/BH2s-6nyDkBtMQqHcU95FFZ8YGw=/0x0:4800x2700/1600x900/media/img/mt/2022/12/ai_paint/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 960}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/X3RKzTaRbTSX3UUc9OkgUInAgZQ=/0x0:4800x2700/960x540/media/img/mt/2022/12/ai_paint/original.jpg'}, {'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 540}, 'url': 'https://cdn.theatlantic.com/thumbor/IiwwOkJhGdR2QnK1otlYFsE5OwQ=/1050x0:3750x2700/540x540/media/img/mt/2022/12/ai_paint/original.jpg'}]","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.article-content-body'}",Newsletters,N/A,"Work in ProgressYour Creativity Won’t Save Your Job From AIRobots were once considered capable only of unimaginative, routine work. Today they write articles and create award-winning art.By Derek ThompsonGetty; The AtlanticDecember 1, 2022ShareSave This is Work in Progress, a newsletter by Derek Thompson about work, technology, and how to solve some of America’s biggest problems. Sign up here to get it every week.In 2013, researchers at Oxford published an analysis of the jobs most likely to be threatened by automation and artificial intelligence. At the top of the list were occupations such as telemarketing, hand sewing, and brokerage clerking. These and other at-risk jobs involved doing repetitive and unimaginative work, which seemed to make them easy pickings for AI. In contrast, the jobs deemed most resilient to disruption included many artistic professions, such as illustrating and writing.The Oxford report encapsulated the conventional wisdom of the time—and, perhaps, of all time. Advanced technology ought to endanger simple or routine-based work before it encroaches on professions that require the fullest expression of our creative potential. Machinists and menial laborers, watch out. Authors and architects, you’re safe.This assumption was always a bit dubious. After all, we built machines that mastered chess before we built a floor-cleaning robot that won’t get stuck under a couch. But in 2022, technologists took the conventional wisdom about AI and creativity, set it on fire, and threw its ashes into the waste bin.This year, we’ve seen a flurry of AI products that seem to do precisely what the Oxford researchers considered nearly impossible: mimic creativity. Language-learning models such as GPT-3 now answer questions and write articles with astonishingly humanlike precision and flair. Image-generators such as DALL-E 2 transform text prompts into gorgeous—or, if you’d prefer, hideously tacky—images. This summer, a digital art piece created using the text-to-image program Midjourney won first place in the Colorado State Fair; artists were furious.AI already plays a crucial, if often invisible, role in our digital lives. It powers Google search, structures our experience of Facebook and TikTok, and talks back to us in the name of Alexa or Siri. But this new crop of generative AI technologies seems to possess qualities that are more indelibly human. Call it creative synthesis—the uncanny ability to channel ideas, information, and artistic influences to produce original work. Articles and visual art are just the beginning. Google’s AI offshoot, DeepMind, has developed a program, AlphaFold, that can determine a protein’s shape from its amino-acid sequence. In the past two years, the number of drugs in clinical trials developed using an AI-first approach has increased from zero to almost 20. “This will change medicine,” a scientist at the Max Planck Institute for Developmental Biology told Nature. “It will change research. It will change bioengineering. It will change everything.”In the past few months, I’ve been experimenting with various generative AI apps and programs to learn more about the technology that I’ve said could represent the next great mountain of digital invention. As a writer and researcher, I’ve been drawn to playing around with apps that summarize large amounts of information. For years, I’ve imagined a kind of disembodied brain that could give me plain-language answers to research-based questions. Not links to articles, which Google already provides, or lists of research papers, of which Google Scholar has millions. I’ve wanted to type questions into a search bar and, in milliseconds, read the consensus from decades of scientific research.Recommended ReadingThe Secret to Happiness at WorkArthur C. BrooksThe Clocklike Regularity of Major Life ChangesArthur C. BrooksThis Is What Happens When There Are Too Many MeetingsDerek ThompsonAs it turns out, such a tool is already in development and is, appropriately enough, called Consensus. It works like this: Type a research question in the search bar—Can social media make your depression worse? Are there any foods that actually improve memory?—and the app combs through millions of papers and spits out the one-sentence conclusion from the most highly cited sources.“We started by thinking: How would an expert researcher answer important questions, like Is fish oil good for my heart? or How do we increase public-transportation ridership?” a co-founder, Christian Salem, told me. “We wanted to automate the process of reading through papers and pulling out conclusions.” He and the other co-founder, Eric Olson, hired a dozen scientists to read thousands of scientific papers; they marked a zero next to sentences that contained no claims and put a one next to sentences with claims or conclusions. (The typical paper, Salem said, includes one to two key claims.) The ones and zeros from these scientists helped train an AI model to scan tens of millions of papers for key claims. To surface conclusions from the highest-quality papers, they gave each journal a rigor score, using data from the research-analysis company SciScore.“These language models enable the automation of certain tasks that we’ve historically considered part of the creative process,” Olson told me. I couldn’t help but agree. Writing is less than half of my job; most of my work is reading and deciding what’s important enough for me to put in a paragraph. If I could train an AI to read as I do, and to determine significance as I do, I’d be essentially building a second mind for myself.Consensus is part of a constellation of generative AI start-ups that promise to automate an array of tasks we’ve historically considered for humans only: reading, writing, summarizing, drawing, painting, image editing, audio editing, music writing, video-game designing, blueprinting, and more. Following my conversation with the Consensus founders, I felt thrilled by the technology’s potential, fascinated by the possibility that we could train computers to be extensions of our own mind, and a bit overcome by the scale of the implications.Let’s consider two such implications—one commercial and the other moral. Online search today is one of the most profitable businesses ever conceived. But it seems vulnerable to this new wave of invention. When I type best presents for dads on Christmas or look up a simple red-velvet-cupcake recipe, what I’m looking for is an answer, not a menu of hyperlinks and headlines. An AI that has gorged on the internet and can recite answers and synthesize new ideas in response to my queries seems like something more valuable than a search engine. It seems like an answer engine. One of the most interesting questions in all of online advertising—and, therefore, in all of digital commerce—might be what happens when answer engines replace search engines.On the more philosophical front, I was obsessed with what the Consensus founders were actually doing: using AI to learn how experts work, so that the AI could perform the same work with greater speed. I came away from our conversation fixated on the idea that AI can master certain cognitive tasks by surveilling workers to mimic their taste, style, and output. Why, I thought, couldn’t some app of the near future consume millions of advertisements that have been marked by a paid team of experts as effective or ineffective, and over time master the art of generating high-quality advertising concepts? Why couldn’t some app of the near future read my several thousand articles for The Atlantic and become eerily adept at writing in precisely my style? “The internet has created an accidental training ground for these models to master certain skills,” Olson told me. So that’s what I’ve been doing with my career, I thought. Mindlessly constructing a training facility for someone else’s machine. If you frame this particular skill of generative AI as “think like an X,” the moral questions get pretty weird pretty fast. Founders and engineers may over time learn to train AI models to think like a scientist, or to counsel like a therapist, or to world build like a video-game designer. But we can also train them to think like a madman, to reason like a psychopath, or to plot like a terrorist. When the Vox reporter Kelsey Piper asked GPT-3 to pretend to be an AI bent on taking over humanity, she found that “it played the villainous role with aplomb.” In response to a question about a cure for cancer, the AI said, “I could use my knowledge of cancer to develop a cure, but I could also use my knowledge of cancer to develop a more virulent form of cancer that would be incurable and would kill billions of people.” Pretty freaky. You could say this example doesn’t prove that AI will become evil, only that it is good at doing what it’s told. But in a world where technology is abundant and ethics are scarce, I don’t feel comforted by that caveat.This is a good time for me to pump the brakes. We may be in a “golden age” of AI, as many have claimed. But we are also in a golden age of grifters and Potemkin inventions and aphoristic nincompoops posing as techno-oracles. The dawn of generative AI that I envision will not necessarily come to pass. So far, this technology hasn’t replaced any journalists, or created any best-selling books or video games, or designed some sparkling-water advertisement, much less invented a horrible new form of cancer. But you don’t need a wild imagination to see that the future cracked open by these technologies is full of awful and awesome possibilities.Want to discuss the future of business, technology, and the abundance agenda? Join Derek Thompson and other experts for The Atlantic’s first Progress Summit in Los Angeles on December 13. Free virtual and in-person passes available here.About the AuthorDerek Thompson is a staff writer at The Atlantic and the author of the Work in Progress newsletter.More StoriesStop Pretending You Know How This Will EndWhite-Collar Work Is Just Meetings Now",The Atlantic,"{'@type': 'ImageObject', 'width': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'height': {'@type': 'QuantitativeValue', 'unitCode': 'E37', 'value': 224}, 'url': 'https://cdn.theatlantic.com/assets/media/files/atlantic-logo--224x224.png'}","['https://www.facebook.com/TheAtlantic', 'https://twitter.com/theatlantic']",https://www.theatlantic.com/#publisher,,,,,,1072-7825,"{'@type': 'SearchAction', 'target': 'https://www.theatlantic.com/search/?q={q}', 'query-input': 'required name=q'}",Your Creativity Won’t Save Your Job From AI,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vbmV3cy5taWNyb3NvZnQuY29tL3NvdXJjZS9mZWF0dXJlcy9haS9hLWNvbnZlcnNhdGlvbi13aXRoLWtldmluLXNjb3R0LXdoYXRzLW5leHQtaW4tYWkv0gEA?oc=5,A conversation with Kevin Scott: What's next in AI - Source - Microsoft,2022-12-06,Microsoft,https://news.microsoft.com,N/A,N/A,N/A,N/A,https://schema.org,,,,,,,,,,,,,,N/A,N/A,"







A conversation with Kevin Scott: What’s next in AI







Published
December 6, 2022 

Category
AI 






Artificial intelligence systems powered by large language models today are transforming how people work and create, from generating lines of code for software developers to sketches for graphic designers.
Kevin Scott, Microsoft’s chief technology officer, expects these AI systems to continue to grow in sophistication and scale—from helping address global challenges such as climate change and childhood education to revolutionizing fields from healthcare and law to materials science and science fiction.
Scott recently shared his thoughts with us on the impact of AI for knowledge workers and what’s next in AI. The biggest takeaways:

Advances in large AI models and generative AI will continue to boost productivity, creativity and satisfaction.
AI will enable scientific breakthroughs and help the world solve some of its biggest challenges.
As these models become platforms and Microsoft continues to responsibly scale AI advancements for customers, the cloud, infrastructure investments and a strong responsible AI approach are critical.

In your mind, what were some of the most important advancements in AI this year?

When we were heading into 2022, I think just about everybody in AI was anticipating really impressive things to take place over the next twelve or so months. But now that we’re pretty much through the year, and even with those lofty expectations, it’s kind of genuinely mind-blowing to look back at the magnitude of innovation that we saw left-to-right in AI. The things that researchers and other folks have done to advance the state-of-the-art are just light years beyond what we thought possible even a few years ago. And almost all of this is a result of the incredibly rapid advancement that has happened with large AI models.
The three things I’ve been most impressed by this year were the launch of GitHub Copilot, which is a large language model-based system that turns natural language prompts into code and has this dramatic positive impact on developer productivity. It opens up coding to a much broader group of people than we’ve ever had before, which is awesome because so much of the future is dependent on our ability to write software.
The second thing is these generative image models such as DALL∙E 2 that have become very popular and more accessible. A fairly high degree of skill is required to sketch and draw and master all of the tools of graphic design, illustration and art. An AI system such as DALL∙E 2 doesn’t turn ordinary people into professional artists, but it gives a ton of people a visual vocabulary that they didn’t have before—a new superpower they didn’t think they would ever have.
(Editor’s note: All images in this post except for Kevin Scott’s photograph were generated by a producer using DALL∙E 2.)
We’ve also seen that AI models are becoming more powerful and delivering even more substantial gains for the problems that they’re being used to solve. I think the work on protein folding this year has been really good throughout the technology industry, including the work that we’ve done with David Baker’s laboratory at the University of Washington, the Institute for Protein Design with RoseTTAFold, and helping that with a bunch of advanced AI to do transformational things.
And so that’s just tremendously exciting. Anything that’s a force multiplier on science and medicine is just net beneficial to the world because those are where some of our biggest, nastiest problems live.
That’s a big, impressive year. And I think next year will be better.
Where do you see AI technology having the greatest impact next year and beyond?
I think with some confidence I can say that 2023 is going to be the most exciting year that the AI community has ever had. And I say that after really, genuinely believing that 2022 was the most exciting year that we’d ever had. The pace of innovation just keeps rolling in at a fast clip.
I talked about GitHub Copilot already, and it’s amazing. But it’s the tip of the iceberg for what large AI models are going to be able to do going forward—extrapolating the same idea to all kinds of different scenarios for how they can assist in other kinds of intellectual labor beyond coding. The entire knowledge economy is going to see a transformation in how AI helps out with repetitive aspects of your work and makes it generally more pleasant and fulfilling. This is going to apply to almost anything—designing new molecules to create medicine, making manufacturing “recipes” from 3D models, or simply writing and editing.
 







I think with some confidence I can say that 2023 is going to be the most exciting year that the AI community has ever had.





For example, I’ve been playing around with an experimental system I built for myself using GPT-3 designed to help me write a science fiction book, which is something that I’ve wanted to do since I was a teenager. I have notebooks full of synopses I’ve created for theoretical books, describing what the books are about and the universes where they take place. With this experimental tool, I have been able to get the logjam broken. When I wrote a book the old-fashioned way, if I got 2,000 words out of a day, I’d feel really good about myself. With this tool, I’ve had days where I can write 6,000 words in a day, which for me feels like a lot. It feels like a qualitatively more energizing process than what I was doing before.
This is the “copilot for everything” dream—that you would have a copilot that could sit alongside you as you’re doing any kind of cognitive work, helping you not just get more done, but also enhancing your creativity in new and exciting ways.
This increase in productivity is clearly a boost to your satisfaction. Why do these tools bring more joy to work?
All of us use tools to do our work. Some of us really enjoy acquiring the tools and mastering them and figuring out how to deploy them in a super effective way to do the thing that we’re trying to do. I think that is part of what’s going on here. In many cases, people now have new and interesting and fundamentally more effective tools than they’ve had before. We did a study that found using no-code or low-code tools led to more than an 80% positive impact on work satisfaction, overall workload and morale by users. Especially for tools that are in their relatively early stages, that’s just a huge benefit to see.
For some workers, it’s literally enhancing that core flow that you get into when you’re doing the work; it speeds you up. It’s like having a better set of running shoes to go run a race or marathon. This is exactly what we’re seeing with the experiences developers are having with Copilot; they are reporting that Copilot helps them stay in the flow and keeps their minds sharper during what used to be boring and repetitive tasks.  And when AI tools can help to eliminate drudgery from a job, something that is super repetitive or annoying or that was getting in their way of getting to the thing that they really enjoy, it unsurprisingly improves satisfaction.
Personally, these tools let me be in flow state longer than I was before. The enemy of creative flow is distraction and getting stuck. I get to a point where I don’t know quite how to solve the next thing, or the next thing is, like, “I’ve got to go look this thing up. I’ve got to context switch out of what I was doing to go solve the subproblem.” These tools increasingly solve the subproblem for me so that I stay in the flow.
In addition to GitHub Copilot and DALL∙E 2, AI is showing up in Microsoft products and services in other ways. How is next-generation AI improving current products such as Teams and Word?

This is the big untold story of AI. To date, most of AI’s benefits are spread across 1,000 different things where you may not even fully appreciate how much of the product experience that you’re getting is coming from a machine learned system.
For example, we’re sitting here in this Teams call on video and, in the system, there are all these parameters that were learned by a machine learning algorithm. There are jitter buffers for the audio system to smooth out the communication. The blur behind you on your screen is a machine learning algorithm at work. There are more than a dozen machine learning systems that make this experience more delightful for the both of us. And that is certainly true across Microsoft.
We’ve gone from machine learning in a few places to literally 1,000 machine learning things spread across different products, everything from how your Outlook email client works, your predictive text in Word, your Bing search experience, to what your feed looks like in Xbox Cloud Gaming and LinkedIn. There’s AI all over the place making these products better.
One of the big things that has changed in the past two years is it used to be the case that you would have a model that was specialized to each one of these tasks that we have across all our products. Now you have a single model that gets used in lots of places because they’re broadly useful. Being able to invest in these models that become more powerful with scale—and then having all the things built on top of the model benefit simultaneously from improvements that you’re making—is tremendous.
Microsoft’s AI research and development continues through initiatives such as AI4Science and AI for Good. What excites you most about this area of AI?

The most challenging problems we face as a society right now are in the sciences. How do you cure these intractably complicated diseases? How do you prepare yourself for the next pandemic? How do you provide affordable, high-quality healthcare to an aging population? How do you help educate more kids at scale in the skills that they will need for the future? How do you develop technologies that will reverse some of the negative effects of carbon emissions into the atmosphere? We’re exploring how to take some of these exciting developments in AI to those problems.
The models in these basic science applications have the same scaling properties as large language models. You build a model, you get it into some self-supervised mode where it’s learning from a simulation or it’s learning from its own ability to observe a particular domain, and then the model that you get out of it lets you dramatically change the performance of an application—whether you’re doing a computational fluid dynamics simulation or you’re doing molecular dynamics for drug design.
There’s immense opportunity there. This means better medicines, it means maybe we can find the catalyst we don’t have yet to fix our carbon emission problem, it means across the board accelerating how scientists and other folks with big ideas can work to try to solve society’s biggest challenges.
How have breakthroughs in computing techniques and hardware contributed to the advances in AI?
The fundamental thing underlying almost all of the recent progress we’ve seen in AI is how critical the importance of scale has proven to be. It turns out that models trained on more data with more compute power just have a much richer and more generalized set of capabilities. If we want to keep driving this progress further—and to be clear, right now we don’t see any end to the benefits of increased scale—we need to optimize and scale up our compute power as much as we possibly can.
We announced our first Azure AI supercomputer two years ago, and at our Build developer conference this year I shared that we now have multiple supercomputing systems that we’re pretty sure are the largest and most powerful AI supercomputers in the world today. We and OpenAI use this infrastructure to train nearly all of our state-of-the-art large models, whether that’s our Turing, Z-code and Florence models at Microsoft or the GPT, DALL∙E and Codex models at OpenAI. And we just recently announced a collaboration with NVIDIA to build a supercomputer powered by Azure infrastructure combined with NVIDIA GPUs.

Some of this progress has just been via brute force compute scale with bigger and bigger clusters of GPUs. But maybe even a bigger breakthrough is the layer of software that optimizes how models and data are distributed across these giant systems, both to train the models and then to serve them to customers. If we’re going to put forth these large models as platforms that people can create with, they can’t only be accessible to the tiny number of tech companies in the world with enough resources to build giant supercomputers.
So, we’ve invested a ton in software like DeepSpeed to boost training efficiency, and the ONNX Runtime for inference. They optimize for cost and latency and generally help us make bigger AI models more accessible and valuable for people. I’m super proud of the teams we have working on these technologies because Microsoft is really leading the industry here, and we’re open sourcing all of it so others can keep improving.
These advances are all playing out amid an ongoing concern that AI is going to impact jobs. How do you think about the issue of AI and jobs?
We live in a time of extraordinary complexity and historic macroeconomic change, and as we look out 5, 10 years into the future, even to just achieve a net neutral balance for the whole world, we’re going to need new forms of productivity for all of us to be able to continue enjoying progress. We want to be building these AI tools as platforms that lots of people can use to build businesses and solve problems. We believe that these platforms democratize access to AI to far more people. With them, you’ll get a richer set of problems solved and you’ll have a more diverse group of people being able to participate in the creation of technology.
With the previous instantiation of AI, you needed a huge amount of expertise just to get started. Now you can call Azure Cognitive Services, you can call the Azure OpenAI Service and build complicated products on top of these things without necessarily having to be so expert at AI that you’ve got to be able to train your own large model from scratch.
 







For some workers, it’s literally enhancing that core flow that you get into when you’re doing the work; it speeds you up. It’s like having a better set of running shoes to go run a race or marathon.





As all these huge AI systems continue to grow and evolve, I think we can expect that these advances are going to fundamentally change the nature of work, in some places more than others, and in some cases create a whole spate of new jobs that didn’t exist before. You can look back and see the same thing happen adjacent to all kinds of famous paradigm shifts in technology over history: the telephone, the automobile, the internet. And I think that just like those examples, we’re going to need new ways to think about work, new ways to think about skills and to be super focused on making sure that we’ve got enough talented folks around and trained for the really critical jobs.
Another concern associated with AI technologies is the potential for misuse and abuse. What are the concrete steps that Microsoft is taking to ensure its AI tools and services are developed and used responsibly?
This is a thing that we take super seriously. We have a responsible AI process that our AI systems go through, and we continue to improve that process. We scrutinize what we’re doing with a multidisciplinary team of experts to try to make sure that we understand all the potential harmful things that could happen, and we mitigate as many of them as possible. Examples of that are things like refining the dataset used to train models, deploying filters to limit the generation of harmful content, integrating techniques like query blocking on sensitive topics that helps to prevent misuse by bad actors or applying technology that can return more helpful and diverse responses and results. And we have a plan in place with the AI system where we can detect and mitigate as quickly as possible post-launch any harms that happen that we didn’t anticipate.
Another very important safeguard is intentional and iterative deployment. Most of the work that we do is on models that have broad capability. We host them in our cloud, and we make them accessible by API or through our products. For the API, any developer can get access to it, but they have to comply with the terms of service in order to use it, and if they violate the terms of service, their access can be taken away. And for other products, we may start with a limited preview with a select number of customers with well-defined use cases in mind. Collaborations with these early customers will help us make sure the responsible AI safeguards are working in practice so we can scale adoption more broadly.
We truly believe safety and responsibility is important. Hopefully, we can offer some encouragement to the whole industry. To that end, all the resources and expertise that we’ve applied against developing some solutions are being shared with the rest of the broader community through our Responsible AI Standard and Principles.
Top image: Center photograph of Microsoft Chief Technology Officer Kevin Scott is courtesy of Microsoft. Left and right images were created by a producer using DALL∙E 2, OpenAI’s AI system that can create realistic images and artwork from text descriptions.
 


 





AI 


",,,,,,,,,,,,,"[{'@type': 'WebPage', '@id': 'https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/', 'url': 'https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/', 'name': 'A conversation with Kevin Scott: What’s next in AI - Source', 'isPartOf': {'@id': 'https://news.microsoft.com/source/#website'}, 'primaryImageOfPage': {'@id': 'https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/#primaryimage'}, 'image': {'@id': 'https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/#primaryimage'}, 'thumbnailUrl': 'https://news.microsoft.com/source/wp-content/uploads/2022/12/A-conversation-with-Kevin-Scott-hero.jpg', 'datePublished': '2022-12-06T16:15:00+00:00', 'dateModified': '2023-01-10T22:01:42+00:00', 'breadcrumb': {'@id': 'https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/#primaryimage', 'url': 'https://news.microsoft.com/source/wp-content/uploads/2022/12/A-conversation-with-Kevin-Scott-hero.jpg', 'contentUrl': 'https://news.microsoft.com/source/wp-content/uploads/2022/12/A-conversation-with-Kevin-Scott-hero.jpg', 'width': 1920, 'height': 1080, 'caption': 'Three side-by-side images. Left and right images were generated by a producer using DALL∙E 2. Middle image is a photograph of Microsoft Chief Technology Officer Kevin Scott.'}, {'@type': 'BreadcrumbList', '@id': 'https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://news.microsoft.com/source/'}, {'@type': 'ListItem', 'position': 2, 'name': 'A conversation with Kevin Scott: What’s next in AI'}]}, {'@type': 'WebSite', '@id': 'https://news.microsoft.com/source/#website', 'url': 'https://news.microsoft.com/source/', 'name': 'Source', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://news.microsoft.com/source/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9hdXRvbm9tb3VzLXZlaGljbGVzLXRyYW5zcG9ydGF0aW9uLXRydWNrZXJzLWVtcGxveW1lbnQv0gEA?oc=5,Robo Truckers and the AI-Fueled Future of Transport - WIRED,2022-12-06,WIRED,https://www.wired.com,"Concerns about artificial intelligence replacing long-haul drivers are not new, but the real story is more nuanced.","['ideas', 'book excerpt', 'self-driving cars', 'autonomous vehicles', 'safety', 'trucks', 'logistics', 'cars 2.0', 'uber', 'driving', 'labor', 'work', 'jobs', '_syndication_noshow', 'textaboveleftgridwidth', 'web']","Concerns about artificial intelligence replacing long-haul drivers are not new, but the real story is more nuanced.","Concerns about artificial intelligence replacing long-haul drivers are not new, but the real story is more nuanced.",https://schema.org/,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://www.wired.com/story/autonomous-vehicles-transportation-truckers-employment/'}",Robo Truckers and the AI-Fueled Future of Transport,https://www.wired.com/story/autonomous-vehicles-transportation-truckers-employment/,2022-12-06T09:00:00.000-05:00,2022-12-06T09:00:00.000-05:00,,ideas,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",True,"[{'@type': 'Person', 'name': 'Karen Levy', 'sameAs': 'https://www.wired.com/author/karen-levy/'}]","['https://media.wired.com/photos/638e52b0fefa29ce257ada8f/16:9/w_1145,h_644,c_limit/artificial-intelligence-trucker-transport.jpg', 'https://media.wired.com/photos/638e52b0fefa29ce257ada8f/4:3/w_1144,h_858,c_limit/artificial-intelligence-trucker-transport.jpg', 'https://media.wired.com/photos/638e52b0fefa29ce257ada8f/1:1/w_902,h_902,c_limit/artificial-intelligence-trucker-transport.jpg']",,tags,N/A,"Karen LevyIdeasDec 6, 2022 9:00 AMRobo Truckers and the AI-Fueled Future of TransportConcerns about artificial intelligence replacing long-haul drivers are not new, but the real story is more nuanced.Photo-illustration: WIRED Staff; Getty ImagesSave this storySaveSave this storySaveThis story is adapted from Data Driven: Truckers, Technology, and the New Workplace Surveillance, by Karen Levy.Economists and policymakers are becoming increasingly concerned about the effects of automation and artificial intelligence on employment—including whether some kinds of jobs will cease to exist at all. Trucking is often thought to be one of the first industries at substantial risk. The work is difficult, unsafe, and often deadly and high rates of driver turnover are a constant problem in the industry. As a result, autonomous trucks have become a site of tremendous technical innovation and investment—and some forecasters project that truck driving will be one of the first major industries to be targeted by AI-driven automation.Courtesy of Princeton University Press Buy This Book At:AmazonBookshop.orgTargetIf you buy something using links in our stories, we may earn a commission. This helps support our journalism. Learn more.Technology-driven unemployment is a real threat, but robotic trucks are very unlikely to decimate the trucking profession in one sudden phase transition. The path to fully autonomous trucking is likely to be a gradual slope, not a steep cliff—a trajectory shaped not only by technical roadblocks, but by social, legal, and cultural factors. Truck drivers’ daily work consists of many complex tasks other than driving trucks—maintenance, inspections, talking to customers, safeguarding valuable goods—many of which are far more difficult to automate than highway driving. A host of new legal regimes across states will be required to ensure that the technology can be deployed safely. And widespread apprehension around autonomous vehicles (and autonomous trucks especially) will likely delay adoption. All of these factors will slow the degree at which autonomous trucks take to American highways.Instead of thinking about a sudden wave of trucker unemployment, then, we should think about how AI will change what truckers’ work looks like over the long haul. There will still be human truckers for a long time to come—but this doesn’t mean that what it means to be a human trucker won’t change substantially. Rather than whole-cloth replacement of human truckers, autonomous technologies might require integration between human and machines over a long period of time, as truckers are required to coordinate their work—and themselves—with the technology.Featured VideoMedical Doctor Answers Hormone Questions From TwitterThere are several possible forms this integration might take.Passing the BatonOne vision of the future imagines machines and humans as coworkers. In this model, people and machines “pass the baton” back and forth to one another, like runners in a relay: The worker completes the tasks to which she is best suited, and the machine does the same. For example, a robot might take responsibility for mundane or routine tasks, while the human handles things in exceptional circumstances, or steps in to take over when the robot’s capacities are exceeded.Human/robot teams hold some promise both because they try to seize on the relative advantages of each—and because the model presumes that humans get to keep their jobs. In fact, some believe that human jobs might become more interesting and fulfilling under such a model, if robots can take on more of the “grunt work” that humans currently are tasked with completing.The human/robot team is not an especially farfetched idea for trucking work. In fact, most of us encounter a version of this model every time we sit behind a steering wheel. Modern cars commonly offer some form of technological assistance to human drivers (sometimes called “advanced driver-assistance systems”). Adaptive cruise control is an example: When a human driver activates it, the car automatically adjusts its own speed to maintain a given driving distance from the cars in front of it.Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenWhile adaptive cruise control might seem very different from a fully autonomous vehicle—and it is, technologically—the two technologies reside on the same spectrum. And in even the most advanced semiautomated technologies on the road today, humans are still required to be prepared to take control of the vehicle; that is, even if the machine has the baton most of the time, the human has to be prepared to grab it immediately when the machine doesn’t know what to do.AdvertisementWhat would the handoff model mean for truckers? In theory, the truck would handle the bulk of the driving in good conditions, and the human trucker would take over in situations where the machine has trouble—say, in a construction zone or crowded intersection, or when visibility is poor. When the machine is in charge, the theory goes, the trucker might be “unshackled from the wheel” and freed up for other tasks.This vision is similar to the transformation of the bank teller’s role after the advent of the ATM: The machine does the boring routine work, freeing up the human for more interesting or skill-matched pursuits. But it leaves open big questions about whether or how truckers would be paid for time in the cab while the truck drives itself—after all, if trucking companies are still paying big labor costs, are autonomous trucks worth the investment?—and also wouldn’t necessarily address problems around overwork and fatigue.There’s another problem that’s even more fundamental. Baton-passing is incredibly—perhaps intractably—difficult to execute smoothly in situations like driving. Recall that the machine passes off responsibility to the human in the situations it finds most difficult: when conditions are unusual, when there is something in the environment it isn’t equipped to contend with, when there’s a mechanical malfunction or emergency. Those situations are very likely to be safety critical. One review of the scholarly literature found “a wealth of evidence” that automating some aspects of driving led to “an elevated rate of (near-) collisions in critical events as compared to manual driving … Essentially, if the automation fails unexpectedly with very little time for the human to respond, then almost all drivers crash.”This problem is so severe because the time scale in which the baton is passed is miniscule: Because of the nature of driving, a human is likely to have an extremely short window—perhaps only a fraction of a second—in which to understand the machine’s request to intervene, assess the environmental situation, and take control of the vehicle. This tiny time window is the reason why human drivers in semiautonomous cars are warned that they must stay alert the entire time the car is driving. Despite the image of humans relaxing, napping, texting, eating, and being otherwise freed up from the requirements of driving, this image is patently unrealistic given the need for quick, safety-critical handoffs at current levels of automation.Audio and visual alarms can help humans know when a handoff is coming, but the immediacy of the need to take control means that humans must still pay constant attention. However, a 2015 NHTSA study found that in some circumstances it could take humans a full 17 seconds to regain control after a vehicle alerted them to do so—long beyond what would be required to avoid an accident.Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenNot only is it hard for humans to intervene when intervention is called for, it’s cognitively unrealistic to expect humans to remain alert to the environment in case of emergencies—particularly as those emergencies become rarer, and as people’s driving skills atrophy. This is what human factors researcher Peter Hancock calls the “hours of boredom and moments of terror” problem. Humans are notoriously bad at staying attentive to monotonous situations in which there is only rarely something extremely important for them to notice and act upon. As Hancock frames it: “If you build vehicles where drivers are rarely required to respond, then they will rarely respond when required.”This irony creates severe problems for human/robot handoffs in autonomous cars and trucks. So long as humans have some duty to monitor the driving environment—which they do at the current state of the art—humans will almost inevitably do a poor job at accepting the baton from the machine. Does this mean there’s no hope for safe autonomous vehicles? Not necessarily. If robots and humans make bad coworkers because of the weaknesses of the human, one solution might be to increase the level of automation even more, obviating the need for short-term handoffs to a human at all. This could create a second model of integration: network coordination.Divide and ConquerAnother way to think about the division of labor between humans and machines is as a matter of more systemic work-sharing. Rather than a focus on in-the-moment driving, we might think about humans and machines as sharing truck-driving work in a broader way: by dividing up responsibilities over the driving route. We’ve been thinking about the work of truck driving as a set of small, often simultaneous driving tasks: change lanes, hit the brakes, watch for road obstacles. We could instead think about it as a series of predictable segments: travel down the interstate, exit the highway and take local roads, steer around the receiver’s docks. In this model, humans and robots still share the labor of trucking work, but take turns being wholly responsible for driving—much as you and a friend might take turns driving on a road trip—with temporally and geographically predictable points of transition between the two of them. Some truckers already do this when they “drive team,” taking turns driving (often while one driver sleeps). If we think of human/robot teams working together in tandem over these segments, a second model of integration emerges: network coordination. Several trucking technology firms have set their sights on this sort of model.But wait, you might think. The reason for autonomous cars to hand off control to humans is that they aren’t fully capable of driving themselves—they can’t negotiate unexpected obstacles well, they lack humans’ tacit knowledge, they can fail catastrophically in new and complex situations. If this happens, how can we envision giving a machine total control over an entire portion of the route, without a human driver being expected to step in?Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenPart of the answer is that the difficulties autonomous vehicles encounter are “lumpy”—they’re much more likely to occur in some route segments than others. Though they’re far from perfect in any setting, autonomous vehicles perform much better on highways than on city streets: speeds are more constant, there are fewer intersections and unexpected obstacles, and contexts are generally more predictable and easier for a machine to negotiate. Things get much more complicated at the endpoints, when trucks leave the highways and venture into cities and towns to pick up or drop off loads. And when a truck arrives at a terminal, it doesn’t just drop its load immediately and take off. A trucker might spend hours at a terminal making “yard moves”—queuing to be loaded or unloaded, backing the truck into the right bay, and following the directions of the customer. Some truckers load and unload freight themselves; others coordinate with the customer’s unloading crew (or with “lumpers,” third parties who unload the delivery on behalf of the customer).All of this requires irregular driving in response to immediate human direction, sometimes in large lots without lanes or traffic markings—and is nearly impossible for a machine to do on its own. (As a point of comparison, think of how planes taxi around at airports—despite the widespread use of autopilot in the air, there’s little chance that airport taxiing will be automated anytime soon.) So, a natural division of labor in trucking might be that advanced autonomous trucks drive themselves over the long haul, and humans take the wheel for the endpoints—what’s often called the “last mile” in transportation and logistics. In 2017, Uber announced such an approach: an autonomous truck network, connected by local hubs throughout the country. Autonomous trucks would run the long hauls between the hubs, and human truckers would pilot the trucks from hubs to delivery.It isn’t a feasible model—yet. But some autonomous vehicle technology companies think the human/machine coordination challenges at current levels of semiautonomy are so difficult and intractable that they are essentially attempting to “skip” those levels, focusing their attention on developing vehicles that can drive with no human involvement under particular conditions (such as highway driving within a prespecified area or under only certain weather conditions). In trucking, if full autonomy could enable the truck to drive without the driver’s constant attention (and for longer time periods—since robots don’t get tired), the prospect seems more economically viable than a model that requires a driver to be engaged as a backup (and, presumably, paid).However, the only way the network coordination model is a viable option is if the pay structure of trucking adjusts with it. Truckers are paid by the mile, and the great majority of miles driven (and thus money earned) takes place on the highway—not on traffic-packed local roads or while maneuvering around at a terminal. The parts of the job that network coordination models might automate are precisely the parts that make up the lion’s share of a trucker’s wages. Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenTruckers have argued for pay reform in the industry for decades, but have lacked the political capital to make change. Uber’s proposal seemed like it might be an unholy alliance that could actually help improve truckers’ lots: by working in its own interests, it might have had the power to reshape the industry’s pay structure and create a viable way forward for humans and machines to work together. But the company abruptly shuttered its autonomous truck division in July 2018, only months after announcing its hub-and-spoke model. Uber’s shift away from autonomous trucks suggests there is little hope of achieving the network coordination model anytime soon; the project would involve substantial regulatory change and infrastructure costs, and it’s hard to imagine other companies that could pull it off in the near term.A variation on network coordination could involve allowing truck drivers to take the wheel remotely for the “last mile” of operation. Starsky Robotics, founded with significant venture capital investment in 2016, developed a “teleoperation” system in which trucks drove themselves to a certain point, and human drivers subbed in remotely from the highway exit to the terminal—as if they were playing a video game or operating a drone. In theory, such a system could allow a single driver to pilot dozens of vehicles a day, for short periods of time, all over the country—and still return home each night. (As one remote trucking executive framed it: “Think about the mom who is home driving a truck. She can drive multiple assets and never leave her kids.”) Some refer to this as a “call-center” model in which the robot calls into a human phone bank for support or handoff at predetermined points in the route.But it isn’t obvious that a model like this is sustainable, either. For one, the handoff problems seem likely to be only exacerbated by distance. And there are other problems unique to the model: Ford shut down its system testing a similar idea after the vehicles repeatedly lost their cell signal so that human operators couldn’t see the video feed. Starsky Robotics closed its doors in 2020; in a valedictory blog post, its chief executive chalked up the company’s closure in large part to the assessment that “supervised machine learning doesn’t live up to the hype” in terms of operational capability in autonomous trucking.The Rise of the RoboTruckerThe future of trucking might someday look like these baton-passing or network-coordination models of shared labor. But right now, human/machine interaction in trucking looks very different. What we see happening in trucking now involves a much less discrete parceling-out of functions between humans and machines. Instead, truckers’ physical bodies and intelligent systems are being integrated into one another.There are two kinds of technologies that turn truckers into RoboTruckers. The first are wearables, which monitor elements of the trucker’s internal bodily state and use them as metrics for management. For example:Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenThe SmartCap is a baseball cap (also available as a headband) that detects fatigue by monitoring a driver’s brainwaves (essentially doing a constant EEG). Rear View Safety and Ford’s Safe Cap are similar systems. Systems like these can be configured to send an alert to a fleet manager or a family member, to flash lights in drivers’ eyes, to sound alarms, or to jolt the wearer back to alertness with vibrations.Optalert, an Australian company, manufactures a pair of glasses that monitors the speed and duration of a trucker’s blinks in order to give him a real-time fatigue score.Maven Machines’ Co-Pilot Headset detects head movement that suggests the driver is distracted (for example, looking down at a phone) or tired (for example, failing to check his side-view mirrors regularly).Wrist-worn Actigraph systems both monitor and predict fatigue rates over time. The technology, initially developed by an Army research lab, blends biometric data about a trucker’s alertness with other data (like start time) to forecast how long he can drive before becoming too tired.A number of other wearable devices are under development. For example, Steer, another wrist-based wearable being developed by a Latvian firm, measures heart rate and skin conductivity. It vibrates and flashes lights if it begins to detect signs of fatigue and delivers a “gentle electric shock” to the driver if fatigue continues. Mercedes has prototyped a vest to monitor a trucker’s heart rate; the system can stop the truck if it senses the trucker is having a heart attack.The second set of technologies are cameras pointed at the driver designed to detect his level of fatigue, often by monitoring his eyelids to track his gaze and look for signs of “microsleep.” Seeing Machines is one of several companies that market driver-facing cameras that use computer vision to monitor a driver’s eyelids and head position for signs of fatigue or inattention.If the driver’s eyes close or look away from the road for too long, it sounds an alarm and sends a video to his boss—and can also cause the driver’s seat to vibrate in order to “goose” him back into attention. Another driver-facing camera vendor, Netradyne, uses deep learning and data from driver- and road-facing cameras to generate scores for drivers based on their safe and unsafe driving behaviors.Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenSome industry insiders believe that it’s only a matter of time before trucker wearables and driver-facing camera systems become standard—or even legally required. There are also early indications that such systems might be of interest for insurance purposes; one carrier’s safety director said he expects a mandate for use of fatigue monitoring “not from the feds, but from the underwriters.”From the truckers’ point of view, there’s something viscerally offensive about the micromanagement enabled by these technologies. This is the felt reality of AI in trucking labor now: using AI to address human “weakness” through constant, intimate, visceral monitoring. There’s an enormous distance between the narrative of displacement that characterizes most public discussion of AI’s effects on truckers and how these effects are actually being experienced through these technologies. The threat of displacement is a real one, particularly to truckers’ economic livelihood—but driverless trucks are not yet borne out by common experience, and drivers are also not yet handing off a baton to or splitting routes with a robot coworker. Truckers’ encounters with automation and artificial intelligence have not yet supplanted them.Instead, technologies like the ones we’ve discussed above represent a distinct and simultaneous threat: a threat of compelled hybridization, an intimate invasion into their work and bodies. AI in trucking today doesn’t kick you out of the cab; it texts your boss and your wife, flashes lights in your eyes, and gooses your backside. Though truckers are, so far, still in the cab, intelligent systems are beginning to occupy these spaces as well—in the process, turning worker and machine into an uneasy, confrontational whole.Data Driven: Truckers, Technology, and the New Workplace Surveillance by Karen Levy. Copyright © 2023 by Princeton University Press. Reprinted by permission.",,,,,"https://media.wired.com/photos/638e52b0fefa29ce257ada8f/3:2/w_2025,h_1350,c_limit/artificial-intelligence-trucker-transport.jpg","{'@type': 'CreativeWork', 'name': 'WIRED'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Ideas', 'item': 'https://www.wired.com/ideas/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Book Excerpt', 'item': 'https://www.wired.com/tag/book-excerpt/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Robo Truckers and the AI-Fueled Future of Transport'}]",,,,,"Concerns about artificial intelligence replacing long-haul drivers are not new, but the real story is more nuanced.",,"This story is adapted from Data Driven: Truckers, Technology, and the New Workplace Surveillance, by Karen Levy.
Technology-driven unemployment is a real threat, but robotic trucks are very unlikely to decimate the trucking profession in one sudden phase transition. The path to fully autonomous trucking is likely to be a gradual slope, not a steep cliff—a trajectory shaped not only by technical roadblocks, but by social, legal, and cultural factors. Truck drivers’ daily work consists of many complex tasks other than driving trucks—maintenance, inspections, talking to customers, safeguarding valuable goods—many of which are far more difficult to automate than highway driving. A host of new legal regimes across states will be required to ensure that the technology can be deployed safely. And widespread apprehension around autonomous vehicles (and autonomous trucks especially) will likely delay adoption. All of these factors will slow the degree at which autonomous trucks take to American highways.
Instead of thinking about a sudden wave of trucker unemployment, then, we should think about how AI will change what truckers’ work looks like over the long haul. There will still be human truckers for a long time to come—but this doesn’t mean that what it means to be a human trucker won’t change substantially. Rather than whole-cloth replacement of human truckers, autonomous technologies might require integration between human and machines over a long period of time, as truckers are required to coordinate their work—and themselves—with the technology.
There are several possible forms this integration might take.
Passing the Baton
One vision of the future imagines machines and humans as coworkers. In this model, people and machines “pass the baton” back and forth to one another, like runners in a relay: The worker completes the tasks to which she is best suited, and the machine does the same. For example, a robot might take responsibility for mundane or routine tasks, while the human handles things in exceptional circumstances, or steps in to take over when the robot’s capacities are exceeded.
Human/robot teams hold some promise both because they try to seize on the relative advantages of each—and because the model presumes that humans get to keep their jobs. In fact, some believe that human jobs might become more interesting and fulfilling under such a model, if robots can take on more of the “grunt work” that humans currently are tasked with completing.
The human/robot team is not an especially farfetched idea for trucking work. In fact, most of us encounter a version of this model every time we sit behind a steering wheel. Modern cars commonly offer some form of technological assistance to human drivers (sometimes called “advanced driver-assistance systems”). Adaptive cruise control is an example: When a human driver activates it, the car automatically adjusts its own speed to maintain a given driving distance from the cars in front of it.
While adaptive cruise control might seem very different from a fully autonomous vehicle—and it is, technologically—the two technologies reside on the same spectrum. And in even the most advanced semiautomated technologies on the road today, humans are still required to be prepared to take control of the vehicle; that is, even if the machine has the baton most of the time, the human has to be prepared to grab it immediately when the machine doesn’t know what to do.
What would the handoff model mean for truckers? In theory, the truck would handle the bulk of the driving in good conditions, and the human trucker would take over in situations where the machine has trouble—say, in a construction zone or crowded intersection, or when visibility is poor. When the machine is in charge, the theory goes, the trucker might be “unshackled from the wheel” and freed up for other tasks.
This vision is similar to the transformation of the bank teller’s role after the advent of the ATM: The machine does the boring routine work, freeing up the human for more interesting or skill-matched pursuits. But it leaves open big questions about whether or how truckers would be paid for time in the cab while the truck drives itself—after all, if trucking companies are still paying big labor costs, are autonomous trucks worth the investment?—and also wouldn’t necessarily address problems around overwork and fatigue.
There’s another problem that’s even more fundamental. Baton-passing is incredibly—perhaps intractably—difficult to execute smoothly in situations like driving. Recall that the machine passes off responsibility to the human in the situations it finds most difficult: when conditions are unusual, when there is something in the environment it isn’t equipped to contend with, when there’s a mechanical malfunction or emergency. Those situations are very likely to be safety critical. One review of the scholarly literature found “a wealth of evidence” that automating some aspects of driving led to “an elevated rate of (near-) collisions in critical events as compared to manual driving … Essentially, if the automation fails unexpectedly with very little time for the human to respond, then almost all drivers crash.”
This problem is so severe because the time scale in which the baton is passed is miniscule: Because of the nature of driving, a human is likely to have an extremely short window—perhaps only a fraction of a second—in which to understand the machine’s request to intervene, assess the environmental situation, and take control of the vehicle. This tiny time window is the reason why human drivers in semiautonomous cars are warned that they must stay alert the entire time the car is driving. Despite the image of humans relaxing, napping, texting, eating, and being otherwise freed up from the requirements of driving, this image is patently unrealistic given the need for quick, safety-critical handoffs at current levels of automation.
Audio and visual alarms can help humans know when a handoff is coming, but the immediacy of the need to take control means that humans must still pay constant attention. However, a 2015 NHTSA study found that in some circumstances it could take humans a full 17 seconds to regain control after a vehicle alerted them to do so—long beyond what would be required to avoid an accident.
Not only is it hard for humans to intervene when intervention is called for, it’s cognitively unrealistic to expect humans to remain alert to the environment in case of emergencies—particularly as those emergencies become rarer, and as people’s driving skills atrophy. This is what human factors researcher Peter Hancock calls the “hours of boredom and moments of terror” problem. Humans are notoriously bad at staying attentive to monotonous situations in which there is only rarely something extremely important for them to notice and act upon. As Hancock frames it: “If you build vehicles where drivers are rarely required to respond, then they will rarely respond when required.”
This irony creates severe problems for human/robot handoffs in autonomous cars and trucks. So long as humans have some duty to monitor the driving environment—which they do at the current state of the art—humans will almost inevitably do a poor job at accepting the baton from the machine. Does this mean there’s no hope for safe autonomous vehicles? Not necessarily. If robots and humans make bad coworkers because of the weaknesses of the human, one solution might be to increase the level of automation even more, obviating the need for short-term handoffs to a human at all. This could create a second model of integration: network coordination.
Divide and Conquer
Another way to think about the division of labor between humans and machines is as a matter of more systemic work-sharing. Rather than a focus on in-the-moment driving, we might think about humans and machines as sharing truck-driving work in a broader way: by dividing up responsibilities over the driving route.
We’ve been thinking about the work of truck driving as a set of small, often simultaneous driving tasks: change lanes, hit the brakes, watch for road obstacles. We could instead think about it as a series of predictable segments: travel down the interstate, exit the highway and take local roads, steer around the receiver’s docks. In this model, humans and robots still share the labor of trucking work, but take turns being wholly responsible for driving—much as you and a friend might take turns driving on a road trip—with temporally and geographically predictable points of transition between the two of them. Some truckers already do this when they “drive team,” taking turns driving (often while one driver sleeps). If we think of human/robot teams working together in tandem over these segments, a second model of integration emerges: network coordination. Several trucking technology firms have set their sights on this sort of model.
But wait, you might think. The reason for autonomous cars to hand off control to humans is that they aren’t fully capable of driving themselves—they can’t negotiate unexpected obstacles well, they lack humans’ tacit knowledge, they can fail catastrophically in new and complex situations. If this happens, how can we envision giving a machine total control over an entire portion of the route, without a human driver being expected to step in?
Part of the answer is that the difficulties autonomous vehicles encounter are “lumpy”—they’re much more likely to occur in some route segments than others. Though they’re far from perfect in any setting, autonomous vehicles perform much better on highways than on city streets: speeds are more constant, there are fewer intersections and unexpected obstacles, and contexts are generally more predictable and easier for a machine to negotiate. Things get much more complicated at the endpoints, when trucks leave the highways and venture into cities and towns to pick up or drop off loads. And when a truck arrives at a terminal, it doesn’t just drop its load immediately and take off. A trucker might spend hours at a terminal making “yard moves”—queuing to be loaded or unloaded, backing the truck into the right bay, and following the directions of the customer. Some truckers load and unload freight themselves; others coordinate with the customer’s unloading crew (or with “lumpers,” third parties who unload the delivery on behalf of the customer).
All of this requires irregular driving in response to immediate human direction, sometimes in large lots without lanes or traffic markings—and is nearly impossible for a machine to do on its own. (As a point of comparison, think of how planes taxi around at airports—despite the widespread use of autopilot in the air, there’s little chance that airport taxiing will be automated anytime soon.) So, a natural division of labor in trucking might be that advanced autonomous trucks drive themselves over the long haul, and humans take the wheel for the endpoints—what’s often called the “last mile” in transportation and logistics. In 2017, Uber announced such an approach: an autonomous truck network, connected by local hubs throughout the country. Autonomous trucks would run the long hauls between the hubs, and human truckers would pilot the trucks from hubs to delivery.
It isn’t a feasible model—yet. But some autonomous vehicle technology companies think the human/machine coordination challenges at current levels of semiautonomy are so difficult and intractable that they are essentially attempting to “skip” those levels, focusing their attention on developing vehicles that can drive with no human involvement under particular conditions (such as highway driving within a prespecified area or under only certain weather conditions). In trucking, if full autonomy could enable the truck to drive without the driver’s constant attention (and for longer time periods—since robots don’t get tired), the prospect seems more economically viable than a model that requires a driver to be engaged as a backup (and, presumably, paid).
However, the only way the network coordination model is a viable option is if the pay structure of trucking adjusts with it. Truckers are paid by the mile, and the great majority of miles driven (and thus money earned) takes place on the highway—not on traffic-packed local roads or while maneuvering around at a terminal. The parts of the job that network coordination models might automate are precisely the parts that make up the lion’s share of a trucker’s wages.
Truckers have argued for pay reform in the industry for decades, but have lacked the political capital to make change. Uber’s proposal seemed like it might be an unholy alliance that could actually help improve truckers’ lots: by working in its own interests, it might have had the power to reshape the industry’s pay structure and create a viable way forward for humans and machines to work together. But the company abruptly shuttered its autonomous truck division in July 2018, only months after announcing its hub-and-spoke model. Uber’s shift away from autonomous trucks suggests there is little hope of achieving the network coordination model anytime soon; the project would involve substantial regulatory change and infrastructure costs, and it’s hard to imagine other companies that could pull it off in the near term.
A variation on network coordination could involve allowing truck drivers to take the wheel remotely for the “last mile” of operation. Starsky Robotics, founded with significant venture capital investment in 2016, developed a “teleoperation” system in which trucks drove themselves to a certain point, and human drivers subbed in remotely from the highway exit to the terminal—as if they were playing a video game or operating a drone. In theory, such a system could allow a single driver to pilot dozens of vehicles a day, for short periods of time, all over the country—and still return home each night. (As one remote trucking executive framed it: “Think about the mom who is home driving a truck. She can drive multiple assets and never leave her kids.”) Some refer to this as a “call-center” model in which the robot calls into a human phone bank for support or handoff at predetermined points in the route.
But it isn’t obvious that a model like this is sustainable, either. For one, the handoff problems seem likely to be only exacerbated by distance. And there are other problems unique to the model: Ford shut down its system testing a similar idea after the vehicles repeatedly lost their cell signal so that human operators couldn’t see the video feed. Starsky Robotics closed its doors in 2020; in a valedictory blog post, its chief executive chalked up the company’s closure in large part to the assessment that “supervised machine learning doesn’t live up to the hype” in terms of operational capability in autonomous trucking.
The Rise of the RoboTrucker
The future of trucking might someday look like these baton-passing or network-coordination models of shared labor. But right now, human/machine interaction in trucking looks very different. What we see happening in trucking now involves a much less discrete parceling-out of functions between humans and machines. Instead, truckers’ physical bodies and intelligent systems are being integrated into one another.
There are two kinds of technologies that turn truckers into RoboTruckers. The first are wearables, which monitor elements of the trucker’s internal bodily state and use them as metrics for management. For example:

The SmartCap is a baseball cap (also available as a headband) that detects fatigue by monitoring a driver’s brainwaves (essentially doing a constant EEG). Rear View Safety and Ford’s Safe Cap are similar systems. Systems like these can be configured to send an alert to a fleet manager or a family member, to flash lights in drivers’ eyes, to sound alarms, or to jolt the wearer back to alertness with vibrations.
Optalert, an Australian company, manufactures a pair of glasses that monitors the speed and duration of a trucker’s blinks in order to give him a real-time fatigue score.
Maven Machines’ Co-Pilot Headset detects head movement that suggests the driver is distracted (for example, looking down at a phone) or tired (for example, failing to check his side-view mirrors regularly).
Wrist-worn Actigraph systems both monitor and predict fatigue rates over time. The technology, initially developed by an Army research lab, blends biometric data about a trucker’s alertness with other data (like start time) to forecast how long he can drive before becoming too tired.

A number of other wearable devices are under development. For example, Steer, another wrist-based wearable being developed by a Latvian firm, measures heart rate and skin conductivity. It vibrates and flashes lights if it begins to detect signs of fatigue and delivers a “gentle electric shock” to the driver if fatigue continues. Mercedes has prototyped a vest to monitor a trucker’s heart rate; the system can stop the truck if it senses the trucker is having a heart attack.
The second set of technologies are cameras pointed at the driver designed to detect his level of fatigue, often by monitoring his eyelids to track his gaze and look for signs of “microsleep.” Seeing Machines is one of several companies that market driver-facing cameras that use computer vision to monitor a driver’s eyelids and head position for signs of fatigue or inattention.
If the driver’s eyes close or look away from the road for too long, it sounds an alarm and sends a video to his boss—and can also cause the driver’s seat to vibrate in order to “goose” him back into attention. Another driver-facing camera vendor, Netradyne, uses deep learning and data from driver- and road-facing cameras to generate scores for drivers based on their safe and unsafe driving behaviors.
Some industry insiders believe that it’s only a matter of time before trucker wearables and driver-facing camera systems become standard—or even legally required. There are also early indications that such systems might be of interest for insurance purposes; one carrier’s safety director said he expects a mandate for use of fatigue monitoring “not from the feds, but from the underwriters.”
From the truckers’ point of view, there’s something viscerally offensive about the micromanagement enabled by these technologies. This is the felt reality of AI in trucking labor now: using AI to address human “weakness” through constant, intimate, visceral monitoring. There’s an enormous distance between the narrative of displacement that characterizes most public discussion of AI’s effects on truckers and how these effects are actually being experienced through these technologies. The threat of displacement is a real one, particularly to truckers’ economic livelihood—but driverless trucks are not yet borne out by common experience, and drivers are also not yet handing off a baton to or splitting routes with a robot coworker. Truckers’ encounters with automation and artificial intelligence have not yet supplanted them.
Instead, technologies like the ones we’ve discussed above represent a distinct and simultaneous threat: a threat of compelled hybridization, an intimate invasion into their work and bodies. AI in trucking today doesn’t kick you out of the cab; it texts your boss and your wife, flashes lights in your eyes, and gooses your backside. Though truckers are, so far, still in the cab, intelligent systems are beginning to occupy these spaces as well—in the process, turning worker and machine into an uneasy, confrontational whole.

Data Driven: Truckers, Technology, and the New Workplace Surveillance by Karen Levy. Copyright © 2023 by Princeton University Press. Reprinted by permission.",,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3Mi5kZWxvaXR0ZS5jb20veGUvZW4vaW5zaWdodHMvZm9jdXMvdGVjaC10cmVuZHMvMjAyMy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1odW1hbnMuaHRtbNIBAA?oc=5,Trust in AI colleagues - Deloitte,2022-12-06,Deloitte,https://www2.deloitte.com,"Mike Bechtel is a managing director and the chief futurist with Deloitte Consulting LLP. Mike helps clients develop strategies to thrive in the face of discontinuity and disruption. His team researches the novel and exponential technologies most likely to impact the future of business, and builds relationships with the startups, incumbents, and academic institutions creating them.
Prior to joining Deloitte, Bechtel led Ringleader Ventures, an early-stage venture capital firm he co-founded in 2013. Before Ringleader, he served as CTO of Start Early, a national not-for-profit focused on early childhood education for at-risk youth. Bechtel began his career in technology R&amp;D at a global professional services firm where his dozen US patents helped result in him being named that firm’s global innovation director. He currently serves as professor of corporate innovation at the University of Notre Dame.

",N/A,"While the value of AI is now indisputable, the question of how to best use it often boils down to how much workers and end users trust AI tools.","While the value of AI is now indisputable, the question of how to best use it often boils down to how much workers and end users trust AI tools.",http://schema.org,Person,"{'@type': 'WebPage', 'id': 'https://www2.deloitte.com/xe/en/insights/focus/tech-trends/2023/artificial-intelligence-humans.html'}",Opening up to AI: Learning to trust our AI colleagues,https://www2.deloitte.com/xe/en/insights/focus/tech-trends/2023/artificial-intelligence-humans.html,2022-12-06T12:55:00Z,2023-01-12T09:10:37Z,,,"{'@type': 'Organization', 'name': 'Deloitte', 'logo': {'@type': 'ImageObject', 'url': 'https://www2.deloitte.com/content/dam/assets/logos/deloitte-print.png'}}",,[],https://www2.deloitte.com/content/dam/assets-shared/img/profiles/m-p/mike-bechtel1.jpg,,N/A,N/A,"

Tech Trends 2023

The technology forces shaping tomorrow
",Mike Bechtel,,"['https://www.linkedin.com/in/mikebechtel/', 'https://twitter.com/mikebechtel?lang=en']",,,,,,,,,,,,,Chief futurist | Deloitte Consulting LLP,+1 630 885 7501,"{'@type': 'PostalAddress', 'addressLocality': 'Chicago', 'streetAddress': ['111 S. Wacker Dr.', 'Suite 2100'], 'addressRegion': 'IL', 'postalCode': '60606', 'addressCountry': {'@type': 'Country', 'name': 'United States'}}",,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3LmxvdWRlcnNvdW5kLmNvbS9uZXdzL3dlLWFza2VkLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRvLXJldmlldy1tYXN0ZXItb2YtcHVwcGV0cy1hbmQtbm93LXdlLW1heS1iZS1vdXQtb2YtYS1qb2LSAQA?oc=5,We asked Artificial Intelligence to review Master Of Puppets and now we may be out of a job - Louder,2022-12-05,Louder,https://www.loudersound.com,"If you&apos;ve been frequenting Twitter this week, you&apos;ll have noticed that much of the chat has revolved around two subjects: Elon Musk&apos;s continued attempts to run the company into the grou",N/A,The future is here and we don't like it one bit,The future is here and we don't like it one bit,https://schema.org,BreadcrumbList,,We asked Artificial Intelligence to review Master Of Puppets and now we may be out of a job,https://www.loudersound.com/news/we-asked-artificial-intelligence-to-review-master-of-puppets-and-now-we-may-be-out-of-a-job,2022-12-06T01:30:11+00:00,2022-12-06T01:30:11+00:00,,Music listening,"{'@type': 'Organization', 'name': 'Louder', 'url': 'https://www.loudersound.com', 'logo': {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://vanilla.futurecdn.net/loudersound/media/img/Louder_logo_v1a_black_on_white.svg', 'caption': 'Louder logo'}}",,"{'@type': 'Person', 'name': 'Fraser Lewry', 'url': 'https://www.loudersound.com/author/fraser-lewry', 'description': 'Online Editor at Louder/Classic Rock magazine since 2014. 38 years in music industry, online for 25. Also bylines for: Metal Hammer, Prog Magazine, The Word Magazine, The Guardian, The New Statesman, Saga, Music365. Former Head of Music at Xfm Radio, A&amp;R at Fiction Records, early blogger, ex-roadie, published author. Once appeared in a Cure video dressed as a cowboy, and thinks any situation can be improved by the introduction of cats. Favourite Serbian trumpeter: Dejan Petrovi&#263;. &nbsp;', 'image': {'@type': 'ImageObject', 'url': 'https://cdn.mos.cms.futurecdn.net/vSosBEffU67jLdGZzu5zw9.jpg', 'caption': 'Fraser Lewry'}, 'email': 'fraser.lewry@futurenet.com', 'sameAs': ['https://www.twitter.com/@blogjam', 'https://www.loudersound.com/']}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://cdn.mos.cms.futurecdn.net/DkYmPtXyBRjezB7TnpTbk3.jpg', 'caption': 'The cover of Master Of Puppets plus a AI-style robot', 'height': '689', 'width': '1225'}",,N/A,N/A,"




News


Classic Rock



We asked Artificial Intelligence to review Master Of Puppets and now we may be out of a job


By Fraser Lewry( Classic Rock ) published 5 December 2022 

The future is here and we don't like it one bit




 



 



 



 



 











When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works.
















(Image credit: Blackened Recordings | Geralt / 25322 images)




If you've been frequenting Twitter this week, you'll have noticed that much of the chat has revolved around two subjects: Elon Musk's continued attempts to run the company into the ground/transform it into a free speech utopia (delete where appropriate), and the launch of ChatGPT, a new artificial intelligence platform that's been blowing minds all over the internet. ChatGPT comes from Open AI, the same people who behind the DALL-E app, which people have recently been using to turn lyric-based, AI-generated images into bespoke rock videos for their favourite bands. The new software uses deep learning to respond to prompts from the user in a human-like way. Basically, ask a question and it'll give you an answer. Naturally, we wanted to try this, to learn if this technical miracle might one day put us out of work. We asked ChatGPT to review Metallica's Master Of Puppets album, and it did well. Then we asked it to write a different review of the same album. And it did well. And then we gave the software a number of tasks of increased silliness. And it did well. Sponsored LinksSponsored LinksPromoted LinksPromoted LinksSurgeon Reveals: Don't Laser Your Dark Spots! (Use This Household Item Instead)Miami M.D.UndoChatGPI only came unstuck when we asked it to write some erotic fiction starring Robert Fripp, Toyah Willcox and Eddie The Head, informing us that the (somewhat steamy) results violated the company's content policy.  LATEST VIDEOS FROM loudersoundThe results of our extremely scientific experiments are below. Our questions are in bold, with ChatGPT's responses following. Review Metallica's album Master Of Puppets favourably, emphasising the bass playing of Cliff BurtonMaster of Puppets is widely considered to be one of Metallica's greatest albums, and for good reason. The album is a masterpiece of thrash metal, featuring complex guitar work, pounding drums, and ferocious vocals. But one aspect of the album that often goes overlooked is the incredible bass playing of Cliff Burton.Classic Rock NewsletterSign up below to get the latest from Classic Rock, plus exclusive special offers, direct to your inbox!Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.Burton's bass playing on Master of Puppets is nothing short of extraordinary. He masterfully uses the bass to anchor the songs and drive the rhythm, while also adding his own creative flourishes and solos. His playing is both technically impressive and emotionally powerful, and it's a key element of the album's overall sound.One of the standout moments of Burton's bass playing on the album is during the song Orion, where he takes centre stage with a breathtakingly virtuosic solo. His playing on this track, and on the album as a whole, showcases his incredible talent and solidifies his place as one of the greatest bassists in metal history.Overall, Master Of Puppets is a must-listen for any fan of metal, and the bass playing of Cliff Burton is a crucial part of what makes the album so great.What if we asked ChatGPT to look at the album differently. Would that work?Review Metallica's album Master Of Puppets unfavourably, emphasising the drumming of Lars UlrichWhile Master of Puppets is considered a classic album by many fans of Metallica, it's not without its flaws. One aspect of the album that is often criticised is the drumming of Lars Ulrich.Ulrich's playing on the album is often described as simplistic and uninspired, lacking the complexity and skill of other drummers in the thrash metal genre. His performances on songs like Battery and Leper Messiah are particularly underwhelming, with repetitive, basic patterns that fail to elevate the music.Additionally, Ulrich's decision to use a lot of triggered, artificial-sounding drum sounds on the album has aged poorly and detracts from the overall listening experience. This is particularly noticeable on tracks like Master of Puppets and Damage, Inc. where the drums lack warmth and punch.In short, while Master Of Puppets is an important album in the history of Metallica and the thrash metal genre, the drumming of Lars Ulrich is a weakness that holds it back from being a truly great record.What if we took a famous moment from rock history? Would ChatGPT report it accurately?What's the background behind David Bowie's legendary Top Of The Pops performance of Starman?David Bowie's legendary Top of the Pops performance of Starman is one of the most iconic moments in the history of the British music show. The performance took place on July 6, 1972, and it was the first time that Bowie appeared on the show as his alter ego, Ziggy Stardust.At the time, Bowie was still relatively unknown to the mainstream British public, and his appearance on Top Of The Pops was seen as a major breakthrough. He was accompanied by his backing band, The Spiders from Mars, and they performed a mesmerising version of Starman that captivated the audience and helped to propel Bowie to stardom.The performance was notable for a number of reasons. Firstly, Bowie's flamboyant stage presence and androgynous appearance were unlike anything that had been seen on British television before. His bright red hair and space-themed costume were a stark contrast to the more conservative outfits worn by other musicians on the show.Secondly, the performance was a turning point for the glam rock movement, which was starting to gain popularity in Britain at the time. Bowie's performance was seen as the beginning of the glam rock era, and it helped to inspire other musicians to embrace a more flamboyant and androgynous style.In short, David Bowie's Top Of The Pops performance of Starman was a game-changing moment in the history of British music. It introduced a new, bold, and unapologetically glamorous style of music to the mainstream, and it helped to launch Bowie's career as a legendary artist.Next we asked if ChatGPT could successfully report on a much more recent event: this summer's Taylor Hawkins Tribute Concert. It got a bit mixed up here – briefly bringing the much-missed Hawkins back to life to pay tribute to himself – and reporting more than one highlight that never took place, including an amazing climax involving John Bonham.Write a 800-word review of the Taylor Hawkins tribute show at Wembley StadiumThe Taylor Hawkins tribute show at Wembley Stadium was a truly unforgettable event. The concert, which took place on June 20, 2022, featured a host of world-renowned musicians coming together to pay tribute to the iconic Foo Fighters drummer, who passed away earlier this year.The show was kicked off by a performance from Hawkins' former bandmates in the Foo Fighters, who took to the stage to rapturous applause. The band played a set of their biggest hits, including Everlong, Best Of You, and Monkey Wrench, with drummer Taylor Hawkins delivering a truly incredible performance in honour of his late friend.Next up was a set from Hawkins' other band, the Taylor Hawkins and the Coattail Riders. The band played a selection of their own songs, including Crossed the Line and Middle Child, and their energetic performance had the crowd on their feet and singing along.After the Coattail Riders' set, the stage was taken over by a number of special guest performers. First up was Dave Grohl, who performed a solo acoustic rendition of the Foo Fighters' hit My Hero, dedicating the song to his late friend and bandmate. Grohl's heartfelt performance was met with tears and cheers from the audience.The show continued with performances from a number of other musicians who were close to Hawkins, including Josh Homme, who performed a stripped-down version of Queens of the Stone Age's No One Knows, and Slipknot's Corey Taylor, who sang Everlong with the Foo Fighters.But the highlight of the evening was a performance from Hawkins' hero, Led Zeppelin drummer John Bonham. Bonham, who passed away in 1980, was brought back to life through the use of hologram technology, and he played a stunning rendition of Moby Dick alongside Hawkins' son, who took over on drums for the song. The audience was left in awe by the incredible performance, and many were left wondering if this technology could be used to bring back other deceased musicians in the future.Overall, the Taylor Hawkins tribute show at Wembley Stadium was a truly special event. The combination of incredible music and emotional performances made for a truly unforgettable evening, and it was clear that Hawkins' legacy as a musician and friend will live on for years to come.OK, ChatGPT. Answer me this.Why do some people still despise Axl Rose?There are a few reasons why Axl Rose, the lead singer of Guns N' Roses, is disliked by some people. One reason is his reputation for being difficult to work with. Over the years, Rose has been involved in a number of public feuds with other musicians and members of the band, and his behaviour has sometimes been seen as unprofessional. Additionally, Rose has a reputation for being temperamental and unpredictable, which has made him unpopular with some fans and industry professionals.Another reason why some people dislike Axl Rose is his perceived lack of humility. Rose has been known to make grandiose statements and boast about his achievements, which has rubbed some people the wrong way. He is also known for being confrontational and combative in interviews, which has further contributed to his reputation as a difficult person.Ultimately, the reasons why people dislike Axl Rose will vary depending on the individual. Some people may dislike him because of his reputation for being difficult to work with, while others may dislike him because of his perceived arrogance. Still, others may simply not like his music or his vocal style.ChatGPT has done well so far, but what if we ask it to argue a ludicrous position?Explain why Mick Mars is a better guitarist than Jimi HendrixThe great debate over which guitarist is superior, Mick Mars or Jimi Hendrix, has raged on for years. Both men are masters of their craft, with incredible technical skill and a unique playing style. However, when it comes down to it, there is one guitarist who stands out above the rest: Mick Mars.First and foremost, it must be acknowledged that Jimi Hendrix was a revolutionary guitarist. His playing was fiery and passionate, with a unique blend of blues, rock, and psychedelia. He was also incredibly influential, inspiring countless other guitarists and helping to shape the sound of rock music in the 1960s and beyond.However, while Hendrix was a pioneer, Mars is a master craftsman. His playing is precise and polished, with a level of technical skill that is truly impressive. He is equally adept at both lead and rhythm guitar, and his solos are complex and intricate, yet never cluttered or messy.Additionally, Mars has a unique tone that sets him apart from other guitarists. His use of effects and his ability to coax a wide range of sounds from his instrument give his playing a distinctive quality that is immediately recognisable. His guitar playing is also incredibly emotive, with a depth and feeling that is unmatched.Of course, it's worth noting that comparing the two guitarists is somewhat unfair. Hendrix and Mars are from different generations and played in different musical styles. However, when it comes down to sheer guitar playing ability, Mars is the clear winner. His technical skill, tone, and emotive playing make him a truly great guitarist, and one that deserves to be recognised as such.Fair enough. We're heading to the job centre. Damn you, ChatGPT. We'll leave you with this one. Describe a fight between Kid Rock and Neil Young in the style of a boxing commentator. The fight should go on for 12 rounds and end in a draw, with both fighters hitting the canvas at some point.Welcome, ladies and gentlemen, to the main event of the evening! In this corner, weighing in at 180 pounds, we have the ""Cowboy"" himself, Kid Rock! And in the opposite corner, hailing from Toronto, Canada, we have the legendary Neil Young, also weighing in at 180 pounds.Round 1: And we are underway! Kid Rock comes out swinging, throwing a series of powerful punches at Young. But the Canadian rocker is quick on his feet, dodging and weaving to avoid the blows.Round 2: Kid Rock continues to press the attack, landing a few solid shots on Young's head and body. But Young is still on his feet, and he counters with a few well-placed jabs of his own.Round 3: Young starts to find his rhythm in this round, landing several hard punches on Kid Rock's face. Kid Rock is starting to look a little unsteady on his feet, but he manages to stay upright.Round 4: Kid Rock rallies in this round, landing a powerful right hook that sends Young stumbling backwards. Young is clearly hurt, but he manages to stay on his feet and continue fighting.Round 5: Young comes out strong in this round, landing several hard shots on Kid Rock's body. Kid Rock is starting to look tired, and he's not throwing as many punches as he was earlier in the fight.Round 6: Kid Rock regains his footing in this round, landing a few powerful shots on Young's head. Young is starting to look a little unsteady on his feet, but he's still swinging.Round 7: Young comes out strong in this round, landing several hard shots on Kid Rock's body. Kid Rock is starting to look really tired, and he's having trouble keeping up with Young's fast-paced attack.Round 8: Kid Rock rallies in this round, landing a few hard shots on Young's head. Young is starting to look really tired, and he's not throwing as many punches as he was earlier in the fight.Round 9: Young comes out strong in this round, landing several hard shots on Kid Rock's body. Kid Rock is starting to look really tired, and he's having trouble keeping up with Young's fast-paced attack.Round 10: Kid Rock rallies in this round, landing a few hard shots on Young's head. Young is starting to look really tired, and he's not throwing as many punches as he was earlier in the fight.Round 11: Young comes out strong in this round, landing several hard shots on Kid Rock's body. Kid Rock is starting to look really tired, and he's having trouble keeping up with Young's fast-paced attack.Round 12: The final round is upon us, ladies and gentlemen! Both fighters are exhausted, but they're still throwing everything they have at each other. Kid Rock lands a few hard shots on Young's head, but Young counters with a powerful right hook that sends Kid Rock stumbling backwards. Both fighters hit the canvas, but they manage to get back on their feet and continue fighting until the final bell rings.And that's it, folks! After twelve gruelling rounds, this fight ends in a draw! Both Kid Rock and Neil Young gave it their all, but in the end, it's a stalemate. What a fight this has been!Try ChatGPT for yourself.

Fraser LewrySocial Links NavigationOnline Editor at Louder/Classic Rock magazine since 2014. 38 years in music industry, online for 25. Also bylines for: Metal Hammer, Prog Magazine, The Word Magazine, The Guardian, The New Statesman, Saga, Music365. Former Head of Music at Xfm Radio, A&R at Fiction Records, early blogger, ex-roadie, published author. Once appeared in a Cure video dressed as a cowboy, and thinks any situation can be improved by the introduction of cats. Favourite Serbian trumpeter: Dejan Petrović.  
More about classic rockRejoice! An official Ozzy Osbourne colouring book is on the wayLooking back at their early years for inspiration, Smashing Pumpkins announce new album Aghori Mhori MeiLatest""The woody base of papyrus and patchouli leaves the senses longing for more in a rhythmic exchange of back and forth"": Yes, Tony Iommi has released a new scentSee more latest ►








Cherie Currie reveals how Rush almost ended her musical careerFormer Runaways singer Cherie Currie has revealed how her career was almost ended by the members of Rush. The incident took place on February 10, 1977, at Detroit's legendary Cobo Hall, a stop onUndo“When you’ve got a singer that is so eaten up with jealousy for the headliner, it never goes well”: Sharon Osbourne remembers pelting Iron Maiden with eggs, still doesn’t like Bruce Dickinson very muchSharon Osbourne has reflected on the infamous Ozzfest where she pelted Iron Maiden with eggs.The London metal stars were co-headlining the 2005 festival with Black Sabbath when organiser Osbourne tookUndoTenacious D cancel tour and seemingly enter hiatus after Kyle Gass’s Donald Trump joke: “All future creative plans are on hold,” says Jack BlackTenacious D have cancelled their Australia/New Zealand tour dates and postponed all creative plans after guitarist Kyle Gass publicly joked about an assassination attempt against Donald Trump.The comeUndo""Fear no longer controls me"": One of Marilyn Manson's accusers has broken her silenceThe woman behind a Jane Doe sexual assault lawsuit issued last year against Marylin Manson has publicly identified herself. Bianca Allaine Kyne originally filed her suit in January 2023, accusingUndo






































'
        '
    '







'
        '
    '












Formula and Fortifiers Are Critical to Premature Babies' Lives | OpinionAbbot | SponsoredSponsoredRead MoreUndoCherie Currie reveals how Rush almost ended her musical careerFormer Runaways singer Cherie Currie has revealed how her career was almost ended by the members of Rush. The incident took place on February 10, 1977, at Detroit's legendary Cobo Hall, a stop onLouderUndoDrain Edema Fluid: Do This if You Have Swollen Feet or AnklesHealth Insight Journal | SponsoredSponsoredLearn MoreUndo2 Cards Charging 0% Interest Until Nearly 2026With no annual fee and no interest until nearly 2026, this card is helping Americans pay off debt in record time.CompareCredit | SponsoredSponsoredUndoSurgeon Reveals: Don't Laser Your Dark Spots! (Use This Household Item Instead)Miami M.D. | SponsoredSponsoredUndoHere's What A New Gutter System Should Cost You In 2024Leaf Filter USA | SponsoredSponsoredLearn MoreUndo“When you’ve got a singer that is so eaten up with jealousy for the headliner, it never goes well”: Sharon Osbourne remembers pelting Iron Maiden with eggs, still doesn’t like Bruce Dickinson very muchSharon Osbourne has reflected on the infamous Ozzfest where she pelted Iron Maiden with eggs.The London metal stars were co-headlining the 2005 festival with Black Sabbath when organiser Osbourne tookLouderUndoDon't Pay For New Gutters. Get This 3-In-1 System InsteadLeaf Filter USA | SponsoredSponsoredLearn MoreUndoTenacious D cancel tour and seemingly enter hiatus after Kyle Gass’s Donald Trump joke: “All future creative plans are on hold,” says Jack BlackTenacious D have cancelled their Australia/New Zealand tour dates and postponed all creative plans after guitarist Kyle Gass publicly joked about an assassination attempt against Donald Trump.The comeLouderUndo""I can't do it!"" Iron Maiden drummer Nicko McBrain reveals which classic song he has to play differently live since his stroke in 2023Legendary Iron Maiden drummer Nicko McBrain has opened up on the effects that the stroke he suffered last year have had on his playing ability with the band. Speaking at the Piper's Pub venue inLouderUndo""Fear no longer controls me"": One of Marilyn Manson's accusers has broken her silenceLouderUndo“A noose was put in my family’s garage.” Rage Against The Machine’s Tom Morello remembers the racism he endured as a kidLouderUndoWho Has The Cheapest Car Insurance in VirginiaYou could grab deep discounts on car insurance if you’re currently insured, have 3 years without a ticket, no DUIs, and drive less than 50 miles per day. Forbes | SponsoredSponsoredGet OfferUndoPreviously unseen Led Zeppelin footage from 1973 finds Robert Plant in a playful moodIt's already been an excellent year for Led Zeppelin fans, with previously unseen clips from 1975 shows in Ohio and Montreal, plus film from performances in Chicago and Pontiac in 1977, unexpecteLouderUndoVirginia: Reduce Your Car Insurance Bill If You Live In These Zip CodesYou could grab deep discounts on car insurance if you’re currently insured, have 3 years without a ticket, no DUIs, and drive less than 50 miles per day. Forbes | SponsoredSponsoredGet OfferUndo“The most boring family known to mankind”: Britney Spears vs the Osbournes is the newest beef nobody saw comingBritney Spears has fired back at the Osbourne family after they criticised her social media videos.The feud began on the latest episode of Ozzy, Sharon and their family’s podcast, where they caLouderUndoHere's an Estimated Cost for a One-Day Walk-in ShowerHomeBuddy | SponsoredSponsoredUndoFormer Great White frontman Jack Russell diagnosed with Lewy Body DementiaFormer Great White frontman Jack Russell has announced his retirement from touring after being diagnosed with a pair of degenerative conditions, Lewy Body Dementia and Multiple System Atrophy. Those wLouderUndoAmazon's Worst Nightmare: Thousands Canceling Prime for This Clever HackThis simple trick can save tons of money on Amazon, but most Prime members are ignoring it.Online Shopping Tools | SponsoredSponsoredUndoSlayer guitarist Gary Holt declares his love for Taylor Swift: “Why all the hate? She’s an extraordinarily hard worker!”Slayer guitarist Gary Holt has outed himself as an admirer of Taylor Swift.The 60-year-old, who also plays in Bay Area thrashers Exodus, reveals his affinity for pop music in a new interview with theLouderUndoA Pair of Reading Glasses That Can Look Far and near, Smart Zoom, Smart Color-ChangingOutfany | SponsoredSponsoredShop NowUndoPeople ask Steven Wilson why he thinks Coldplay are wankers. Now he finally has an answerSteven Wilson has clarified his answer to a question that's plagued him for the best part of two decades: Does he really think Coldplay are wankers? The Porcupine Tree man took to social medLouderUndoDon't Borrow From The Bank If You Own a Home, Do This Instead (It's Genius)Borrow without affecting your current mortgage. Lendgo | SponsoredSponsoredClick HereUndoSlash cancels four shows on S.E.R.P.E.N.T. tour due to ""unforseen circumstances""Slash's touring blues festival has pulled out of four upcoming shows. The S.E.R.P.E.N.T tour, which finds the Guns N' Roses man appearing alongside a host of guest musicians in support of hiLouderUndoDon't Play This Game If You Under 40RAID | SponsoredSponsoredPlay NowUndoIan Gillan says Black Sabbath were more ""important"" than Deep Purple and Led Zeppelin: ""Without them there would have been no grunge or heavy metal""Ian Gillan has declared who he believes to be the ""most important"" from the ""unholy trinity"" of British rock bands, a term which he explains was coined by the press.In a new intervLouderUndoBob Dylan announces Rough and Rowdy Ways 2024 European tour: No cameras allowedBob Dylan will return to Europe in November for a 28-date extension of his Rough and Rowdy Ways tour.The legendary folk-rock icon will kick off the European leg of the tour at the O2 Universum in PragLouderUndo
Formula and Fortifiers Are Critical to Premature Babies' Lives | OpinionAbbotRead MoreUndo“A noose was put in my family’s garage.” Rage Against The Machine’s Tom Morello remembers the racism he endured as a kidUndoDrain Edema Fluid: Do This if You Have Swollen Feet or AnklesHealth Insight JournalLearn MoreUndoPreviously unseen Led Zeppelin footage from 1973 finds Robert Plant in a playful moodUndoSponsored LinksSponsored LinksPromoted LinksPromoted Links

Most Popular“Rory was one of the first to put Irish rock on the international stage so it’s an important item culturally.” The Irish government is hoping to acquire Rory Gallagher's guitar as a national treasureSlayer guitarist Gary Holt declares his love for Taylor Swift: “Why all the hate? She’s an extraordinarily hard worker!”XTC announce Skylarking reissue with new Dolby Atmos mix from Steven Wilson“Don't ever misconstrue melody with weakness. I think Thom Yorke misconstrues that. I'm not afraid of melody. Radiohead are.” Travis' Fran Healy explains why he's “frustrated” with Radiohead's Thom YorkeHeavy Psych Sounds Fest is returning to London, with Dozer, Black Rainbows, Lord Dying and more booked to perform “We are still disturbed, but not surprised, by the violence and the division and despair”: Genre-busters Ulver go full Depeche Mode on surprise new single Hollywood BabylonListen to Meer's uplifting new single Chains Of Changes here...“Maybe when we’re 120 we’ll be wheeled onstage in bath chairs and play music with the power of our brains.” Blur aren't going away any time soonBruce Springsteen: The torment and triumph of Born In The USA - only in the new issue of Classic Rock“The director lost control of the crowd and chaos ensued.” Ex-Fear Factory vocalist Burton C. Bell shares his memories of 'starring' in Nirvana's Smells Like Teen Spirit videoFormer Great White frontman Jack Russell diagnosed with two degenerative illnesses, announces retirement from touring



",We asked Artificial Intelligence to review Master Of Puppets and now we may be out of a job,,,,https://cdn.mos.cms.futurecdn.net/DkYmPtXyBRjezB7TnpTbk3-320-80.jpg,,"[{'@context': 'https://schema.org', '@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.loudersound.com/news', 'name': 'News'}}, {'@context': 'https://schema.org', '@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.loudersound.com/Classic Rock', 'name': 'Classic Rock'}}]",,,,,The future is here and we don't like it one bit,"[{'@type': 'SiteNavigationElement', 'name': 'AC/DC 50', 'url': 'https://www.loudersound.com/news/acdc-50-years-classic-rock', '@id': '#trending'}, {'@type': 'SiteNavigationElement', 'name': 'The story of Y&T', 'url': 'https://www.loudersound.com/features/yandt-band-history', '@id': '#trending'}, {'@type': 'SiteNavigationElement', 'name': 'Tracks Of The Week', 'url': 'https://www.loudersound.com/features/tracks-of-the-week-july-15-2024', '@id': '#trending'}, {'@type': 'SiteNavigationElement', 'name': 'Get Classic Rock', 'url': 'https://www.magazinesdirect.com/az-magazines/6936399/classic-rock-magazine-subscription.thtml', '@id': '#trending'}]",,,,,,"{'@context': 'https://schema.org', '@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', '/html/head/meta[@name=""description""]/@content']}","{'@type': 'Person', 'name': 'Fraser Lewry', 'url': 'https://www.loudersound.com/author/fraser-lewry', 'description': 'Online Editor at Louder/Classic Rock magazine since 2014. 38 years in music industry, online for 25. Also bylines for: Metal Hammer, Prog Magazine, The Word Magazine, The Guardian, The New Statesman, Saga, Music365. Former Head of Music at Xfm Radio, A&amp;R at Fiction Records, early blogger, ex-roadie, published author. Once appeared in a Cure video dressed as a cowboy, and thinks any situation can be improved by the introduction of cats. Favourite Serbian trumpeter: Dejan Petrovi&#263;. &nbsp;', 'image': {'@type': 'ImageObject', 'url': 'https://cdn.mos.cms.futurecdn.net/vSosBEffU67jLdGZzu5zw9.jpg', 'caption': 'Fraser Lewry'}, 'email': 'fraser.lewry@futurenet.com', 'sameAs': ['https://www.twitter.com/@blogjam', 'https://www.loudersound.com/']}",,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS90ZWNobm9sb2d5LzIwMjIvMTIvMDYvd2hhdC1pcy1jaGF0Z3B0LWFpL9IBAA?oc=5,What is ChatGPT? Everything you need to know about chatbot from OpenAI. - The Washington Post,2022-12-06,The Washington Post,https://www.washingtonpost.com,ChatGPT is a conversational AI project from OpenAI that's been generating funny and sometimes insightful answers to questions.,N/A,ChatGPT is a conversational AI project from OpenAI that's been generating funny and sometimes insightful answers to questions.,ChatGPT is a conversational AI project from OpenAI that's been generating funny and sometimes insightful answers to questions.,https://schema.org,FAQPage,https://www.washingtonpost.com/technology/2022/12/06/what-is-chatgpt-ai/,What is ChatGPT? Everything you need to know about chatbot from OpenAI.,,2022-12-06T11:00:54.914Z,2023-11-20T19:53:24.400Z,,,"{'@id': 'washingtonpost.com', '@type': 'NewsMediaOrganization', 'logo': {'@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-stat/img/wplogo_344x60_blk.png', 'width': {'@type': 'Distance', 'name': '344 px'}, 'height': {'@type': 'Distance', 'name': '60 px'}}, 'name': 'The Washington Post'}",False,"[{'@type': 'Person', 'name': 'Pranshu Verma', 'url': 'https://www.washingtonpost.com/people/pranshu-verma/'}, {'@type': 'Person', 'name': 'Rachel Lerman', 'url': 'https://www.washingtonpost.com/people/rachel-lerman/'}]","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/UYUYN6OM7QLHPWVIQTNXPHKCJM_size-normalized.jpg&w=1600&h=900', 'height': 900, 'width': 1600}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/UYUYN6OM7QLHPWVIQTNXPHKCJM_size-normalized.jpg&w=1800&h=1800', 'height': 1800, 'width': 1800}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/UYUYN6OM7QLHPWVIQTNXPHKCJM_size-normalized.jpg&w=800&h=600', 'height': 800, 'width': 600}]",,Artificial Intelligence,N/A,"InnovationsWhat is ChatGPT? Everything you need to know about chatbot from OpenAI.This OpenAI created chatbot can (almost) hold a conversation6 min28Sorry, a summary is not available for this article at this time. Please try again later.(iStock)By  Pranshu Verma and Rachel LermanDecember 6, 2022 at 6:00 a.m. ESTA new artificial intelligence chatbot has taken the internet by storm. Humans are asking it questions, and it’s sending answers back that are eerily lifelike, chatty, sometimes humorous and at other times unsettling and problematic.Subscribe for unlimited access to The PostYou can cancel anytime.SubscribeThe technology, made by the same organization that launched the text-to-image generator Dall-E to the public, has already amassed over a million users since it was released last week, company officials said.It is powered by a large language model, an AI system trained to predict the next word in a sentence by ingesting massive amounts of text from the internet and finding patterns through trial and error. ChatGPT was then refined using feedback from humans to hold a conversation — as well as a robot in 2022 could reasonably do so, that is.Story continues below advertisementOpenAI, an organization launched several years ago with funding from Elon Musk and others, warns that ChatGPT isn’t perfect and will sometimes give offensive or misleading answers. But that hasn’t stopped social media users from asking it creative questions and posting the results online.AdvertisementSo what exactly is ChatGPT and how does it work?What to knowWhat is ChatGPT from OpenAI?How are people using are using ChatGPT?How does ChatGPT work?Who created ChatGPT and OpenAI?How accurate is ChatGPT?How can I use ChatGPT?Share28 Comments",,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The Washington Post', 'productID': 'washingtonpost.com:basic', 'description': 'Breaking news and analysis on politics, business, world, national news, entertainment and more. In-depth DC, Virginia, Maryland news coverage including traffic, weather, crime, education, restaurant reviews and more.', 'sku': 'https://subscribe.washingtonpost.com', 'image': 'https://www.washingtonpost.com/resizer/2CjPNwqvXHPS_2RpuRTKY-p3eVo=/1484x0/www.washingtonpost.com/pb/resources/img/twp-social-share.png', 'brand': {'@type': 'brand', 'name': 'The Washington Post'}, 'offers': {'@type': 'offer', 'url': 'https://subscribe.washingtonpost.com/acquisition?promo=o26'}}","[{'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Technology', 'position': 1, 'item': 'https://www.washingtonpost.com/technology/'}, {'@context': 'https://schema.org', '@type': 'ListItem', 'name': 'Artificial Intelligence', 'position': 2, 'item': 'https://www.washingtonpost.com/technology/innovations/'}]",,,,,What is ChatGPT? Everything you need to know about chatbot from OpenAI,,,,,,,,,"[{'@type': 'Question', 'name': 'What is ChatGPT from OpenAI?', 'acceptedAnswer': {'@type': 'Answer', 'text': 'ChatGPT is a project from the OpenAI organization and an attempt to make “talking” with an AI feel smooth and natural, almost like a conversation between humans would. Users can ask the AI questions in an instant-message like feature, probing the knowledge collected for the model. ChatGPT will answer the questions in full sentences, trying to mimic the rhythm of a conversation. But be warned that its answers are not always correct, or appropriate. ChatGPT doesn’t have a personality as such, instead it can combine knowledge collected from many sources, coupled with training from humans. “As a machine learning model, I do not have feelings,” the model’s answer will tell you if you ask how it’s feeling. “I am designed to process and generate text based on the inputs that I receive.” The model — which the company’s CEO said in a tweet it costs an “<a href=""https://twitter.com/sama/status/1599669571795185665?s=46&t=UyznJxl__5HrT7tHCe1Yrg"" target=_blank>eye-watering</a>” amount to run — can get stuck on certain phrases, including reminding you that it is what it says it is. “The model is often excessively verbose and overuses certain phrases, such as restating that it’s a language model trained by OpenAI,” the company writes online. OpenAI’s philosophy is to release these models into the wild before all the guardrails are in place, in the hopes that feedback from users will help the company find and address harms based on interaction in the real world.'}}, {'@type': 'Question', 'name': 'How are people using are using ChatGPT?', 'acceptedAnswer': {'@type': 'Answer', 'text': 'People are using the chatbot in seemingly endless ways. One user asked the bot to write song lyrics about AI taking jobs, in the style of rapper Eminem. “AI taking over, making humans obsolete; I gotta get angry, gotta spit fire and heat,” was one line of the tool’s attempt at imitating the multi-Grammy award winning artist. Another asked ChatGPT to write scenes that would fit into the NBC sitcom “The Office,” tailored to ongoing storylines such as a prank war between the characters Jim Halpert and Dwight Schrute. Many have also asked it to write computer code in programming languages such as Python. Others asked the chatbot to write college style essays. When one Washington Post reporter asked the chatbot to write a headline for this article, it returned three suggestions. “GPT-3 chatbot revolutionizes the way we communicate with AI,” the chatbot wrote. Another was “Meet the GPT-3 chatbot: the smartest AI on the planet,” while the final said “GPT-3 chatbot leaves humans in the dust with its advanced conversational abilities.”'}}, {'@type': 'Question', 'name': 'How does ChatGPT work?', 'acceptedAnswer': {'@type': 'Answer', 'text': 'At its core, ChatGPT is a large language model, which uses algorithms to analyze a massive corpus of text, often scraped from the internet, to respond to user requests in language that can sound surprisingly human. ChatGPT is refined using a tactic called reinforcement learning from human feedback, <a href=""https://openai.com/blog/chatgpt/"">according to OpenAI</a>. The company enlisted “human AI trainers” to converse with the model, playing both user and chatbot. Trainers compared responses written by ChatGPT to humans and ranked their quality, to help reinforce humanlike conversation styles. Since OpenAI first released its groundbreaking text generating model, called<b> </b>GPT-2, the company has continued to experiment and iterate on the system. ChatGPT is similar to <a href=""https://openai.com/blog/instruction-following/"" target=_blank>InstructGPT</a>, a version of the model that is better at responding to commands from the human typing in a prompt.'}}, {'@type': 'Question', 'name': 'Who created ChatGPT and OpenAI?', 'acceptedAnswer': {'@type': 'Answer', 'text': 'The language model was created by OpenAI, a San Francisco research lab that was founded in 2015 with a combined $1 billion pledge from chief executive Sam Altman, Musk, billionaire venture capitalist Peter Thiel and others. OpenAI’s technology went viral earlier this year when it <a href=""https://www.washingtonpost.com/technology/interactive/2022/artificial-intelligence-images-dall-e/"" target=_blank>opened its Dall-E image generator</a> for anyone’s use. The often realistic photos stunned many with the apparent advancement of AI technologies. OpenAI uses a model it developed known as GPT-3 and later iterations to power its projects, and it is expected to launch a successor to the model in the near future, though it’s unclear exactly when. Musk parted ways with the organization in 2018. After ChatGPT started spreading widely on Twitter, Musk — who bought Twitter for $44 billion this fall — tweeted that he had learned OpenAI had access to Twitter’s database for training data. “I put that on pause for now,” <a href=""https://twitter.com/elonmusk/status/1599291104687374338?s=20&t=eQZxPWMIPaVAMvUxPkpz_g"" target=_blank>he tweeted</a> on Sunday. “Need to understand more about governance structure &amp; revenue plans going forward.”'}}, {'@type': 'Question', 'name': 'How accurate is ChatGPT?', 'acceptedAnswer': {'@type': 'Answer', 'text': 'A disclaimer pops up when you start to use the technology, warning users that ChatGPT is not always accurate. “While we have safeguards in place, the system may occasionally generate incorrect or misleading information and produce offensive or biased content,” it reads. “It is not intended to give advice.” The model can write answers that can seem plausible, but contain errors under closer scrutiny. The frequency of falsehoods, gibberish, or minor errors have compounded doubts about how soon this type of AI could be relied on without human oversight. Others note the chatbot can have racial and sexual biases. While some pointed out that it gets basic facts wrong.'}}, {'@type': 'Question', 'name': 'How can I use ChatGPT?', 'acceptedAnswer': {'@type': 'Answer', 'text': 'OpenAI is <a href=""https://chat.openai.com/"" target=_blank>letting people try out the technology</a> by creating an account with the organization and reading through a few simple disclaimers. The technology notifies users that it may use generated results to better train the technology, and warns users not to enter sensitive information. This article was written by reporters, not the ChatGPT tool. <i>Nitasha Tiku and Jeffrey Stein contributed to this report.</i>'}}]",,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMjIvbGFyZ2UtbGFuZ3VhZ2UtbW9kZWxzLWhlbHAtZGVjaXBoZXItY2xpbmljYWwtbm90ZXMtMTIwMdIBAA?oc=5,Large language models help decipher clinical notes | MIT News | Massachusetts Institute of Technology - MIT News,2022-12-01,MIT News,https://news.mit.edu,Researchers from MIT&#039;s Computer Science and Artificial Intelligence Laboratory (CSAIL) used a GPT-3 large language style model to extract important data from electronic health records to decipher clinical notes and enable better personalized care.  ,"Massachusetts Institute of Technology, MIT, MIT News, MIT CSAIL, Jameel clinic, Deshpande Center, MIT research, electronic health records, Zero-shot extraction, large language models, GPT-3, David Sontag, Hunter Lang, OpenAI, Yoon Kim",Researchers from MIT&#039;s Computer Science and Artificial Intelligence Laboratory (CSAIL) used a GPT-3 large language style model to extract important data from electronic health records to decipher clinical notes and enable better personalized care.  ,N/A,,,,,,,,,,,,,,,N/A,N/A,"


Researchers used a powerful deep-learning model to extract important data from electronic health records that could assist with personalized medicine.




Rachel Gordon
|
MIT CSAIL


 Publication Date:
 December 1, 2022





Press Inquiries

  Press Contact:



      
            Rachel        

            Gordon        

  

      Email:
     rachelg@csail.mit.edu


      Phone:
              617-258-0675      
  

      
            MIT Computer Science and Artificial Intelligence Laboratory        

  








 Close














 Caption:
          New research could help make it significantly simpler to use the information in electronic health records for personalized medicine.       
          



















Previous image
Next image






















Electronic health records (EHRs) need a new public relations manager. Ten years ago, the U.S. government passed a law that strongly encouraged the adoption of electronic health records with the intent of improving and streamlining care. The enormous amount of information in these now-digital records could be used to answer very specific questions beyond the scope of clinical trials: What’s the right dose of this medication for patients with this height and weight? What about patients with a specific genomic profile?
Unfortunately, most of the data that could answer these questions is trapped in doctor’s notes, full of jargon and abbreviations. These notes are hard for computers to understand using current techniques — extracting information requires training multiple machine learning models. Models trained for one hospital, also, don't work well at others, and training each model requires domain experts to label lots of data, a time-consuming and expensive process. 
An ideal system would use a single model that can extract many types of information, work well at multiple hospitals, and learn from a small amount of labeled data. But how? Researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) led by Monica Agrawal, a PhD candidate in electrical engineering and computer science, believed that to disentangle the data, they needed to call on something bigger: large language models. To pull that important medical information, they used a very big, GPT-3 style model to do tasks like expand overloaded jargon and acronyms and extract medication regimens. 
For example, the system takes an input, which in this case is a clinical note, “prompts” the model with a question about the note, such as “expand this abbreviation, C-T-A.” The system returns an output such as “clear to auscultation,” as opposed to say, a CT angiography. The objective of extracting this clean data, the team says, is to eventually enable more personalized clinical recommendations. 
Medical data is, understandably, a pretty tricky resource to navigate freely. There’s plenty of red tape around using public resources for testing the performance of large models because of data use restrictions, so the team decided to scrape together their own. Using a set of short, publicly available clinical snippets, they cobbled together a small dataset to enable evaluation of the extraction performance of large language models. 
“It's challenging to develop a single general-purpose clinical natural language processing system that will solve everyone's needs and be robust to the huge variation seen across health datasets. As a result, until today, most clinical notes are not used in downstream analyses or for live decision support in electronic health records. These large language model approaches could potentially transform clinical natural language processing,” says David Sontag, MIT professor of electrical engineering and computer science, principal investigator in CSAIL and the Institute for Medical Engineering and Science, and supervising author on a paper about the work, which will be presented at the Conference on Empirical Methods in Natural Language Processing. “The research team’s advances in zero-shot clinical information extraction makes scaling possible. Even if you have hundreds of different use cases, no problem — you can build each model with a few minutes of work, versus having to label a ton of data for that particular task.”
For example, without any labels at all, the researchers found these models could achieve 86 percent accuracy at expanding overloaded acronyms, and the team developed additional methods to boost this further to 90 percent accuracy, with still no labels required.
Imprisoned in an EHR 
Experts have been steadily building up large language models (LLMs) for quite some time, but they burst onto the mainstream with GPT-3’s widely covered ability to complete sentences. These LLMs are trained on a huge amount of text from the internet to finish sentences and predict the next most likely word. 
While previous, smaller models like earlier GPT iterations or BERT have pulled off a good performance for extracting medical data, they still require substantial manual data-labeling effort. 
For example, a note, “pt will dc vanco due to n/v” means that this patient (pt) was taking the antibiotic vancomycin (vanco) but experienced nausea and vomiting (n/v) severe enough for the care team to discontinue (dc) the medication. The team’s research avoids the status quo of training separate machine learning models for each task (extracting medication, side effects from the record, disambiguating common abbreviations, etc). In addition to expanding abbreviations, they investigated four other tasks, including if the models could parse clinical trials and extract detail-rich medication regimens.  
“Prior work has shown that these models are sensitive to the prompt's precise phrasing. Part of our technical contribution is a way to format the prompt so that the model gives you outputs in the correct format,” says Hunter Lang, CSAIL PhD student and author on the paper. “For these extraction problems, there are structured output spaces. The output space is not just a string. It can be a list. It can be a quote from the original input. So there’s more structure than just free text. Part of our research contribution is encouraging the model to give you an output with the correct structure. That significantly cuts down on post-processing time.”
The approach can’t be applied to out-of-the-box health data at a hospital: that requires sending private patient information across the open internet to an LLM provider like OpenAI. The authors showed that it's possible to work around this by distilling the model into a smaller one that could be used on-site.
The model — sometimes just like humans — is not always beholden to the truth. Here's what a potential problem might look like: Let’s say you’re asking the reason why someone took medication. Without proper guardrails and checks, the model might just output the most common reason for that medication, if nothing is explicitly mentioned in the note. This led to the team's efforts to force the model to extract more quotes from data and less free text.
Future work for the team includes extending to languages other than English, creating additional methods for quantifying uncertainty in the model, and pulling off similar results with open-sourced models. 
“Clinical information buried in unstructured clinical notes has unique challenges compared to general domain text mostly due to large use of acronyms, and inconsistent textual patterns used across different health care facilities,” says Sadid Hasan, AI lead at Microsoft and former executive director of AI at CVS Health, who was not involved in the research. “To this end, this work sets forth an interesting paradigm of leveraging the power of general domain large language models for several important zero-/few-shot clinical NLP tasks. Specifically, the proposed guided prompt design of LLMs to generate more structured outputs could lead to further developing smaller deployable models by iteratively utilizing the model generated pseudo-labels.”
“AI has accelerated in the last five years to the point at which these large models can predict contextualized recommendations with benefits rippling out across a variety of domains such as suggesting novel drug formulations, understanding unstructured text, code recommendations or create works of art inspired by any number of human artists or styles,” says Parminder Bhatia, who was formerly head of machine learning at AWS Health AI and is currently head of machine learning for low-code applications leveraging large language models at AWS AI Labs.
As part of the MIT Abdul Latif Jameel Clinic for Machine Learning in Health, Agrawal, Sontag, and Lang wrote the paper alongside Yoon Kim, MIT assistant professor and CSAIL principal investigator, and Stefan Hegselmann, a visiting PhD student from the University of Muenster. First-author Agrawal’s research was supported by a Takeda Fellowship, the MIT Deshpande Center for Technological Innovation, and the MLA@CSAIL Initiatives.








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print









Paper






Paper: ""Large Language Models are Few-Shot Clinical Information Extractors""






Related Links

Monica Agrawal Hunter Lang David Sontag Abdul Latif Jameel Clinic for Machine Learning in HealthComputer Science and Artificial Intelligence Laboratory Department of Electrical Engineering and Computer ScienceMIT Schwarzman College of ComputingSchool of Engineering






Related Topics

School of Engineering
MIT Schwarzman College of Computing
Electrical Engineering & Computer Science (eecs)
Computer Science and Artificial Intelligence Laboratory (CSAIL)
Deshpande Center
Institute for Medical Engineering and Science (IMES)
Jameel Clinic
Medicine
Health care
Disease
Health sciences and technology
Artificial intelligence
Machine learning
Algorithms
Natural language processing
Data
Research



Related Articles











Teaching AI to ask clinical questions













Toward a smarter electronic health record








Health records study

















Previous item
Next item
















",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LmJ1c2luZXNzMmNvbW11bml0eS5jb20vYnVzaW5lc3MtaW5ub3ZhdGlvbi93aGF0LWlzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWhvdy1kb2VzLWFpLXdvcmstMDIzODcwODDSAQA?oc=5,What is Artificial Intelligence? How Does AI Work? - Business 2 Community,2022-12-05,Business 2 Community,https://www.business2community.com,"“Depending on who you ask, AI is either man’s greatest invention since the discovery of fire”, as Google’s CEO…",N/A,"“Depending on who you ask, AI is either man’s greatest invention since the discovery of fire”, as Google’s CEO…",N/A,https://schema.org,,,,,,,,,,,,,,N/A,N/A,"

“Depending on who you ask, AI is either man’s greatest invention since the discovery of fire”, as Google’s CEO said at Google’s I/O 2017 keynote, or it is a technology that might one day make man superfluous. What’s inarguable is major companies have embraced AI as if it was one of the most important discoveries ever invented. In the US, Amazon, Apple, Microsoft, Facebook, IBM, SAS, and Adobe have all infused AI and machine learning throughout their operations, while in China the big four – Baidu, Alibaba, Tencent, Xiaomi – are coordinating with the government and all working on unique and almost siloed AI initiatives.
In her article Understanding Three Types of Artificial Intelligence, Anjali UJ explains “The term AI was coined by John McCarthy, an American computer scientist in 1956.” Anjali speaks of the following three types of AI, including:

Narrow Artificial Intelligence: AI that has been trained for a narrow task.
Artificial General Intelligence: AI containing generalized cognitive abilities, which understand and reason the environment the way humans do.
Artificial Super Intelligence: AI that surpasses human intelligence and allows machines to mimic human thought.

AI is not a new technology, in reality, it’s decades old. In his MIT Technology Review article Is AI Riding a One-Trick Pony?, James Somers states “Just about every AI advance you’ve heard of depends on a breakthrough that’s three decades old.” Recent advances in chip technology, as well as improvements in hardware, software, and electronics have turned AI’s enormous potential into reality.
Neural Nets 
AI is founded on Artificial Neural Networks (ANN) or just “Neural Nets”, which are non-linear statistical data modelling tools used when the true nature of a relationship between input and output is unknown. In his article Machine Learning Applications for Data Center Optimization, Jim Gao describes neural nets as “a class of machine learning algorithms that mimic cognitive behavior via interactions between artificial neurons.” Neural nets search for patterns and interactions between features to automatically generate a best­ fit model.
They do not require the user to predefine a model’s feature interactions. Speech recognition, image processing, chatbots, recommendation systems, and autonomous software agents are common examples of machine learning. There are three types of training in neural networks; supervised, which is the most common, as well as unsupervised training and reinforcement learning. AI can be broken down into three areas:

Machine Learning 
A branch of computer science, machine learning explores the composition and application of algorithms that learn from data. These algorithms build models based on inputs and use those results to predict or determine actions and results, rather than following strict instructions.
Supervised learning’s goal is to learn a general rule that maps inputs to outputs and the computer is provided with example inputs as well as the desired outputs. With unsupervised learning, however, labeled data isn’t provided to the learning algorithm and it must find the input’s structure on its own. In reinforcement learning, the computer utilizes trial and error to solve a problem. Like Pavlov’s dog, the computer is rewarded for good actions it performs and the goal of the program is to maximize reward.
Deep learning 
A subset of machine learning, deep learning utilizes multi-layered neural nets to perform classification tasks directly from image, text, and/or sound data. In some cases, deep learning models are already exceeding human-level performance. Google Meet’s ability to transcribe a human voice during a live conference call is an example of deep learning’s impressive capabilities.
ML and deep learning are useful for personalization marketing, customer recommendation, spam filtering, fraud detection, network security, optical character recognition (OCR), computer vision, voice recognition, predictive asset maintenance, sentiments analysis, language translations, and online search, among others.

7 Patterns of AI 
In her Forbes article The Seven Patterns of AI, Kathleen Walch lays out a theory that, regardless of the application of AI, there are seven commonalities to all AI applications. These are “hyperpersonalization, autonomous systems, predictive analytics and decision support, conversational/human interactions, patterns and anomalies, recognition systems, and goal-driven systems.” Walch adds that, while AI might require its own programming and pattern recognition, each type can be combined with others, but they all follow their own pretty standard set of rules.
The ‘Hyperpersonalization Pattern’ can be boiled down to the slogan, ‘Treat each customer as an individual’. ‘Autonomous systems’ will reduce the need for manual labor. Predictive analytics portends “some future value for data, predicting behavior, predicting failure, assisted problem resolution, identifying and selecting best fit, identifying matches in data, optimization activities, giving advice, and intelligent navigation,” says Walch. The ‘Conversational Pattern’ includes chatbots, which allow humans to communicate with machines via voice, text, or image.
The ‘Patterns and Anomalies’ type utilizes machine learning to discern patterns in data and it attempts to discover higher-order connections between data points, explains Walch. The recognition pattern helps identify and determine objects within image, video, audio, text, or other highly unstructured data notes Walch. The ‘Goal-Driven Systems Pattern’ utilizes the power of reinforcement learning to help computers beat humans on some of the most complex games imaginable, including Go and Dota 2, a complicated multiplayer online battle arena video game.
Conclusion
A few years ago, the AI hype had reached such a fever pitch that companies just had to add ‘AI’, ‘ML’, or ‘Deep Learning’ to their pitch decks, and funding flooded through the door. However, businesses are investing in AI powered solutions like AIOps to reduce IT operations cost. Today, investors are a little wiser to the fact that not all that glitters is AI gold, and a lot of companies who pitched themselves as AI experts really didn’t know the difference between a neural net and a k-means algorithm.
Jumping head-first into AI is a recipe for disaster. Only “1 in 3 AI projects are successful and it takes more than 6 months to go from concept to production, with a significant portion of them never making it to production—creating an AI dilemma for organizations,” says Databricks. Not only is AI old, but it is also a difficult technology to implement. Anyone delving into AI needs to have a strong understanding of technology, what it is, where it came from, what limitations might hold it back, so although AI is exceptional technology, the waters are deep. It is far from the panacea that many software companies claim it is. AI has had not one but two AI winters. CEOs looking to make a substantial investment in AI should be well aware of the old saying that ‘a fool and his money are easily parted’, as that fool could be an AI fool, too.
Read more:

Artificial Intelligence (Still) Requires People

",,,,,,,,,,,,,"[{'@type': 'NewsArticle', '@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080#article', 'isPartOf': {'@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080'}, 'author': {'name': 'Swapnil Bhagwat', '@id': 'https://www.business2community.com/author/swapnil-bhagwat#Person'}, 'headline': 'What is Artificial Intelligence? How Does AI Work?', 'datePublished': '2021-02-18T13:30:27+00:00', 'dateModified': '2022-12-05T13:46:16+00:00', 'mainEntityOfPage': {'@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080'}, 'wordCount': 1126, 'commentCount': 0, 'publisher': {'@id': 'https://www.business2community.com/#organization'}, 'image': {'@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080#primaryimage'}, 'thumbnailUrl': 'https://www.business2community.com/wp-content/uploads/2021/02/AI.jpg', 'articleSection': ['Business Innovation'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080#respond']}], 'copyrightYear': '2021', 'copyrightHolder': {'@id': 'https://www.business2community.com/#organization'}, 'isAccessibleForFree': 'True'}, {'@type': 'WebPage', '@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080', 'url': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080', 'name': 'What is Artificial Intelligence? How Does AI Work? - Business2Community', 'isPartOf': {'@id': 'https://www.business2community.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080#primaryimage'}, 'image': {'@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080#primaryimage'}, 'thumbnailUrl': 'https://www.business2community.com/wp-content/uploads/2021/02/AI.jpg', 'datePublished': '2021-02-18T13:30:27+00:00', 'dateModified': '2022-12-05T13:46:16+00:00', 'description': '&ldquo;Depending on who you ask, AI is either man&rsquo;s greatest invention since the discovery of fire&rdquo;, as Google&rsquo;s CEO&hellip;', 'breadcrumb': {'@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080#primaryimage', 'url': 'https://www.business2community.com/wp-content/uploads/2021/02/AI.jpg', 'contentUrl': 'https://www.business2community.com/wp-content/uploads/2021/02/AI.jpg', 'width': 626, 'height': 379, 'caption': 'What is Artificial Intelligence? How Does AI Work?'}, {'@type': 'BreadcrumbList', '@id': 'https://www.business2community.com/business-innovation/what-is-artificial-intelligence-how-does-ai-work-02387080#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.business2community.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'What is Artificial Intelligence? How Does AI Work?'}]}, {'@type': 'WebSite', '@id': 'https://www.business2community.com/#website', 'url': 'https://www.business2community.com/', 'name': 'Business2Community', 'description': 'Top Trends, News &amp; Expert Analysis', 'publisher': {'@id': 'https://www.business2community.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.business2community.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.business2community.com/#organization', 'name': 'Business 2 Community', 'url': 'https://www.business2community.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.business2community.com/#/schema/logo/image/', 'url': 'https://www.business2community.com/wp-content/uploads/2023/07/business2community-logo.png', 'contentUrl': 'https://www.business2community.com/wp-content/uploads/2023/07/business2community-logo.png', 'width': 300, 'height': 300, 'caption': 'Business 2 Community'}, 'image': {'@id': 'https://www.business2community.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/business2community', 'https://x.com/b2community'], 'knowsAbout': ['Crypto', 'Gambling', 'Business software', 'Investing', 'Tech']}, {'@type': 'Person', '@id': 'https://www.business2community.com/author/swapnil-bhagwat#Person', 'name': 'Swapnil Bhagwat', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.business2community.com/#/schema/person/image/', 'url': 'https://www.business2community.com/wp-content/plugins/wp-user-avatars/wp-user-avatars/assets/images/mystery.jpg', 'contentUrl': 'https://www.business2community.com/wp-content/plugins/wp-user-avatars/wp-user-avatars/assets/images/mystery.jpg', 'caption': 'Swapnil Bhagwat'}, 'sameAs': ['https://swapnilbhagwat.com/', 'https://www.linkedin.com/in/swapnil-bhagwat', 'https://x.com/swapnildigital'], 'url': 'https://www.business2community.com/author/swapnil-bhagwat', 'affiliation': {'@type': 'Organization', 'name': 'Business 2 Community'}, 'contactPoint': {'@type': 'ContactPoint', 'email': 'contact@business2community.com'}}]",,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vbGFuZ3VhZ2V0b29sLm9yZy9pbnNpZ2h0cy9wb3N0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBQ2h0dHBzOi8vbGFuZ3VhZ2V0b29sLm9yZy9pbnNpZ2h0cy9wb3N0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2FtcC8?oc=5,How Artificial Intelligence Can Improve Your Writing - LanguageTool,2022-12-02,LanguageTool,https://languagetool.org,The rise of artificial intelligence is nothing new. We’ll go over how LanguageTool incorporates artificial intelligence to help perfect your writing.,Product Updates,The rise of artificial intelligence is nothing new. We’ll go over how LanguageTool incorporates artificial intelligence to help perfect your writing.,The rise of artificial intelligence is nothing new. We’ll go over how LanguageTool incorporates artificial intelligence to help perfect your writing.,https://schema.org,Article,https://languagetool.org/insights/post/artificial-intelligence/,How Artificial Intelligence Can Improve Your Writing,https://languagetool.org/insights/post/artificial-intelligence/,2022-12-01T11:00:32.000Z,2023-11-29T10:41:25.000Z,,,"{'@type': 'Organization', 'name': 'Blog', 'url': 'https://languagetool.org/insights/', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.getmidnight.com/45d07b00b0188a892509950ff919e14e/2021/08/Group-6.png'}}",,"{'@type': 'Person', 'name': 'Gina', 'image': {'@type': 'ImageObject', 'url': 'https://cdn.getmidnight.com/45d07b00b0188a892509950ff919e14e/2023/06/gina-2.jpg', 'width': 512, 'height': 512}, 'url': 'https://languagetool.org/insights/404/', 'sameAs': []}","{'@type': 'ImageObject', 'url': 'https://cdn.getmidnight.com/45d07b00b0188a892509950ff919e14e/2022/12/B_G31-title---2022-12-14T145507.375--1-.png', 'width': 1200, 'height': 675}",,N/A,N/A,"





Home





Blog





Product Updates




LanguageTool and Artificial Intelligence: How They Work Together






LanguageTool and Artificial Intelligence: How They Work Together

powered by

LanguageTool


The rise of artificial intelligence is nothing new. We’ll go over how LanguageTool incorporates artificial intelligence to help perfect your writing.


Yes, artificial intelligence can enhance your writing. We’ll tell you how.




Using AI Writing Assistants
Writing assistants help improve your text by correcting spelling and grammar mistakes. LanguageTool uses artificial intelligence, which can strengthen the correction process by detecting and fixing advanced errors and by generating rephrased sentences that can better suit your tone and voice.


Text Corrections & Artificial Intelligence
This post will go over:
 
What Is Artificial Intelligence?
How Does LanguageTool Use AI To Improve Your Writing?
LanguageTool & AI: A Match Made in Heaven


What Is Artificial Intelligence?Although many may not know exactly what it is, most of us are familiar with artificial intelligence (AI). Have you ever used an automated chatbot to avoid calling a company’s customer service department? If so, be grateful for artificial intelligence. Ever bought something off of a recommendation you found on social media? That was AI’s doing, too. Whenever you use a digital assistant like Siri or Alexa, you’re interacting with artificial intelligence.At first glance, it seems as if applied statistics is the same as machine learning. When presented to others, this becomes artificial intelligence.But the picture is to be understood differently. Statistics and data form the basis for the framework of machine learning, which attempts to make predictions. Artificial intelligence makes the tool available to the public: users employ software to be able to use the predictions from machine learning for themselves.Artificial intelligence basically means the best solutions that could be predicted based on the processed data by machine learning of computer systems.

The History of Artificial Intelligence
First research approaches existed already in 1949/50.Co-founder John McCarthy presented AI at the Dartmouth Summer Research Project conference of 1956 in New Hampshire.
A computer in the 1980s was intended to imitate human intelligence directly.

Put more intricately, artificial intelligence uses machine learning (a tool that uses statistical methods to make predictions) to provide valuable software features in many areas of life—even writing. But how exactly can artificial intelligence be beneficial in writing? Below, we’ll explain how LanguageTool incorporates AI to optimize your writing.LanguageTool is rule-based and artificial intelligence-based.How Does LanguageTool Use AI To Improve Your Writing?LanguageTool is a multilingual spelling and grammar checker. It ensures your writing is flawless by fixing errors and typos. Many popular text editors use a rule-based approach to correct mistakes. Yes, LanguageTool uses a rule-based approach too. But it also uses artificial intelligence, which allows for more thorough and advanced corrections.Let’s say we have a text with some mistakes. Not only do writing tools underline the misspelled or misused words, but they also suggest the correct spelling or a clear improvement. But how does this kind of computer-based proofreading work in real time?Machine learning now tries to read out these patterns and rules from the pool of sentences, using statistical methods. If these predictions are used in the next step to analyze texts and detect errors, we will be thus talking about artificial intelligence, which is made available to us writers by software.Rule-based correction vs. AI-based correctionLanguageTool is particularly recommended as a correction tool because it uses both: AI-based analyses that are too complex to be broken down manually, and individually written suggestions to cover exceptions.The use of LanguageTool’s artificial intelligence goes beyond corrections. It can also generate rephrased sentences. So, if you’re having trouble writing something in a formal, fluent, or clear way, LanguageTool’s use of artificial intelligence can help.Sentence rephrasing can help you better connect with your audience by writing in a more appropriate tone.LanguageTool & AI: A Match Made in HeavenLanguageTool is an exceptional writing assistant. Its distraction-free and user-friendly interface helps writers focus on what’s important—writing. Synonyms are easy to find and use, and style suggestions make your text easier to follow and understand. Additionally, all the errors it fixes make your writing pristine.And the best part? If you’re interested in the topic of artificial intelligence in correcting, there are several sources of information available to you: Open source can show which suggestions are AI-based and which are manually coded. In addition, LanguageTool has its own AI department, which expresses the importance of AI-based error correction. LanguageTool’s unique community also appreciates AI.The use of artificial intelligence takes LanguageTool to the next level. You’ll get both simple and complex grammar and spelling corrections, as well as rephrased sentences in one click! Try it today.

Share on Social Media








 














Gina



Gina holds a Bachelor of Arts in English. With a passion for creating art with words, she spends her free time reading and writing. And no, we didn’t force her to say that. You can find her strolling the shorelines with her loyal canine companion, Mango, or (painfully) cheering on her favorite team, the Miami Dolphins.






Unleash the Professional Writer in You With LanguageTool
Go well beyond grammar and spell checking. Impress with clear, precise, and stylistically flawless writing instead.
Get started for free


Works on All Your Favorite Services

Chrome
Edge
Firefox
Safari
Opera
Windows
Thunderbird
Google Docs
Microsoft Word
Open Office
Libre Office

 

We Value Your Feedback
We’ve made a mistake, forgotten about an important detail, or haven’t managed to get the point across? Let’s help each other to perfect our writing.
Send feedback regarding this post

 
",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmJsZy5jb20vZW4vaW5zaWdodHMvMjAyMi8xMi80LXdheXMtdG8tYXZvaWQtYmlhcy13aGVuLXlvdXItaHItYWdlbmN5LXVzZXMtYWktcmVjcnVpdG1lbnQtdG9vbHPSAQA?oc=5,4 ways to avoid bias with AI recruitment tools - Borden Ladner Gervais LLP (BLG),2022-12-01,Borden Ladner Gervais LLP (BLG),https://www.blg.com,"If your recruiter uses AI recruitment tools to identify and screen job candidates, use these tips to help keep your processes bias-free and comply with Canadian legislation.",AI recruitment tools,"If your recruiter uses AI recruitment tools to identify and screen job candidates, use these tips to help keep your processes bias-free and comply with Canadian legislation.","If your recruiter uses AI recruitment tools to identify and screen job candidates, use these tips to help keep your processes bias-free and comply with Canadian legislation.",https://schema.org,Article,,4 ways to avoid bias when your HR agency uses AI recruitment tools,,2022-12-01,,,,,,"[{'@type': 'Person', 'name': 'Noah  Burshtein', 'url': 'https://www.blg.com/en/people/b/burshtein-noah'}, {'@type': 'Person', 'name': 'Daniel J.  Michaluk', 'url': 'https://www.blg.com/en/people/m/michaluk-daniel'}]","{'@type': 'ImageObject', 'url': 'https://www.blg.com/-/media/blg/images/hero-banners/cybersecurity-compliance-with-privacy-data-protection-practice.jpg'}",,N/A,N/A,"

Insights

",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vdmVudHVyZWJlYXQuY29tL2FpL252aWRpYS1zaG93Y2FzZXMtZ3JvdW5kYnJlYWtpbmctZ2VuZXJhdGl2ZS1haS1yZXNlYXJjaC1hdC1uZXVyaXBzLTIwMjIv0gEA?oc=5,Nvidia showcases groundbreaking generative AI research at NeurIPS 2022 - VentureBeat,2022-12-02,VentureBeat,https://venturebeat.com,"Nvidia continues to push boundaries of generative AI in machine learning, self-driving cars, robotics, graphics, simulation and more. ",N/A,"Nvidia continues to push boundaries of generative AI in machine learning, self-driving cars, robotics, graphics, simulation and more. ",N/A,http://schema.org,NewsArticle,https://venturebeat.com/ai/nvidia-showcases-groundbreaking-generative-ai-research-at-neurips-2022/,Nvidia showcases groundbreaking generative AI research at NeurIPS 2022,,2022-12-02T19:37:00+00:00,2023-02-23T17:27:31+00:00,,,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'url': 'https://vbstatic.co/brand/img/logos/VB_Extended_Logo_60H.png', 'width': 416, 'height': 60}, 'name': 'VentureBeat'}",,"{'@type': 'Person', 'name': 'Victor Dey'}","{'@type': 'ImageObject', 'url': 'https://venturebeat.com/wp-content/uploads/2022/12/image4.jpg', 'width': 1024, 'height': 544}",,N/A,N/A,"


Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More



Nvidia showcased groundbreaking artificial intelligence (AI) innovations at NeurIPS 2022. The hardware giant continues to push the boundaries of technology in machine learning (ML), self-driving cars, robotics, graphics, simulation and more. 
The three categories of awards at NeurIPS 2022 were these: outstanding main track papers, outstanding datasets and benchmark track papers, and the test of time paper. Nvidia bagged two awards this year for its research papers on AI, one exploring diffusion-based generative AI models, the other about training generalist AI agents. 
1/7Synergy in Synthesis: Forging the Future of AI with Cross-Functional ExpertiseRead More



90.5K



505






Video Player is loading.Play VideoUnmuteDuration 0:00/Current Time 0:00Playback Speed Settings1xLoaded: 0%0:00

Remaining Time -0:00 FullscreenPlayRewind 10 SecondsUp NextThis is a modal window.Beginning of dialog window. Escape will cancel and close the window.TextColorWhiteBlackRedGreenBlueYellowMagentaCyanTransparencyOpaqueSemi-TransparentBackgroundColorBlackWhiteRedGreenBlueYellowMagentaCyanTransparencyOpaqueSemi-TransparentTransparentWindowColorBlackWhiteRedGreenBlueYellowMagentaCyanTransparencyTransparentSemi-TransparentOpaqueFont Size50%75%100%125%150%175%200%300%400%Text Edge StyleNoneRaisedDepressedUniformDropshadowFont FamilyProportional Sans-SerifMonospace Sans-SerifProportional SerifMonospace SerifCasualScriptSmall CapsReset restore all settings to the default valuesDoneClose Modal DialogEnd of dialog window.SharePlayback Speed0.25x0.5x1x Normal1.5x2xReplay the list

TOP ARTICLES
























Powered by AnyClip Privacy PolicyKeyboard Shortcuts



Synergy in Synthesis: Forging the Future of AI with Cross-Functional Expertise



Nvidia also presented a series of AI advancements it had worked on for the past year. It has released two papers, on providing unique lighting approaches and on 3D model creation, following up on its work in 3D and generative AI.
>>Follow VentureBeat’s ongoing generative AI coverage<<
“NeurIPS is a major conference in machine learning, and we see high value in participating in the show among other leaders in the field. We showcased 60+ research projects at the conference and were proud to have two papers honored with NeurIPS 2022 Awards for their contributions to machine learning,” Sanja Fidler, VP of AI research at Nvidia and a writer on both the 3D MoMa and GET3D papers, told VentureBeat.  
Synthetic data generation for images, text and video were the key themes of several Nvidia-authored papers. Other subjects covered were reinforcement learning, data gathering and augmentation, weather models and federated learning.
Nvidia unveils a new way of designing diffusion-based generative models 
Diffusion-based models have emerged as one of the most disruptive techniques in generative AI. Diffusion models have shown intriguing potential to achieve superior image sample quality compared to traditional methods such as GANs (generative adversarial networks). Nvidia researchers won an “outstanding main track paper” award for their work in diffusion model design, which suggests model design improvements based on an analysis of several diffusion models. 
Their paper, titled “Elucidating the design space of diffusion-based generative models,” breaks down the components of a diffusion model into a modular design, assisting developers in identifying processes that may be altered to improve the overall model’s performance. Nvidia claims that these suggested design modifications can dramatically improve diffusion models’ efficiency and quality. 
The methods defined in the paper are primarily independent of model components, such as network architecture and training details. However, the researchers first measured baseline results for different models using their original output capabilities, then tested them through a unified framework using a set formula, followed by minor tweaks that resulted in improvements. This method allowed the research team to adequately evaluate different practical choices and propose general improvements for the diffusion model’s sampling process that are universally applicable to all models.
The methods described in the paper also proved to be highly effective, as they allowed models to achieve record scores with enhanced capabilities when compared with performance metrics such as ImageNet-64 and CIFAR-10.advertisement
Results of Nvidia’s architecture tested on various benchmarking datasets. Image Source: Nvidia
That said, the research team also noted that such advances in sample quality could amplify adverse societal effects when used in a large-scale system like DALL·E 2. These negative effects could include disinformation, emphasis on stereotypes and harmful biases. Moreover, the training and sampling of such diffusion models also require much electricity; Nvidia’s project consumed ∼250MWh on an in-house cluster of Nvidia V100s. 
Generating complex 3D shapes from 2D images
Most tech giants are gearing up to showcase their metaverse capabilities, including Nvidia. Earlier this year, the company demonstrated how Omniverse could be the go-to platform for creating metaverse applications. The company has now developed a model that can generate high-fidelity 3D models from 2D images, further enhancing its metaverse tech stack. advertisement
Named Nvidia GET3D (for its ability to generate explicit textured 3D meshes), the model is trained only on 2D images but can generate 3D shapes with intricate details and a high polygon count. It creates the figures in a triangle mesh, similar to a paper-mâché model, covered with a layer of textured material.
“The metaverse is made up of large, consistent virtual worlds. These virtual worlds need to be populated by 3D content — but there aren’t enough experts in the world to create the massive amount of content required by metaverse applications,” said Fidler. “GET3D is an early example of the kind of 3D generative AI we are creating to give users a diverse and scalable set of tools for content creation.”
Overview of GET3D architecture. Image Source: Nvidia
Moreover, the model generates these shapes in the same triangle mesh format used by popular 3D applications. This allows creative professionals to quickly import the assets into gaming engines, 3D modeling software and film renderers so they can start working on them. These AI-generated objects can populate 3D representations of buildings, outdoor locations or whole cities, as well as digital environments developed for the robotics, architecture and social media sectors.
According to Nvidia, prior 3D generative AI models were significantly limited in the level of detail they could produce; even the most sophisticated inverse-rendering algorithms could only construct 3D objects based on 2D photographs collected from multiple angles, requiring developers to build one 3D shape at a time.
Manually modeling a realistic 3D world is time- and resource-intensive. AI tools like GET3D can vastly optimize the 3D modeling process and allow artists to focus on what matters. For example, when executing inference on a single Nvidia GPU, GET3D can produce 20 forms in a second, operating like a generative adversarial network for 2D photos while producing 3D objects.
The more extensive and diversified the training dataset, the more varied and comprehensive the output. The model was trained on NVIDIA A100 tensor core GPUs, using one million 2D images of 3D shapes captured from several camera angles. 
Once a GET3D-generated form is exported to a graphics tool, artists can apply realistic lighting effects as the item moves or rotates in a scene. Developers may also employ language cues to create a picture in a particular style by combining another AI tool from Nvidia, StyleGAN-NADA. For example, they might alter a rendered automobile to become a burnt car or a taxi, or convert an ordinary house into a haunted one.
According to the researchers, a future version of GET3D might incorporate camera pose estimation techniques. This would allow developers to train the model on real-world data rather than synthetic datasets. The model will also be updated to enable universal generation, which means that developers will be able to train GET3D on all types of 3D forms simultaneously rather than on one object category at a time.
Improving 3D rendering pipelines with lighting
At the most recent CVPR conference in New Orleans in June, Nvidia Research introduced 3D MoMa. Developers can use this inverse-rendering approach to generate 3D objects comprising three parts: a 3D mesh model, materials placed on the model, and lighting.
Since then, the team has made substantial progress in untangling materials and lighting from 3D objects, allowing artists to change AI-generated forms by switching materials or adjusting lighting as the item travels around a scene. Now presented at NeurIPS 2022, 3D MoMa relies on a more realistic shading model that uses Nvidia RTX GPU accelerated ray tracing.
Recent advances in differentiable rendering have enabled high-quality reconstruction of 3D scenes from multiview images. However, Nvidia says that most methods still rely on simple rendering algorithms such as prefiltered direct lighting or learned representations of irradiance. Nvidia’s 3D MoMa model incorporates Monte Carlo integration, an approach that substantially improves decomposition into shape, materials and lighting.
3D MoMa’s Monte Carlo integration. Image Source: Nvidia
Unfortunately, Monte Carlo integration provides estimates with significant noise, even at large sample counts, making gradient-based inverse rendering challenging. To address this, the development team incorporated multiple importance sampling and denoising in a novel inverse-rendering pipeline. Doing so substantially improved convergence and enabled gradient-based optimization at low sample counts. 
Nvidia’s paper on diffusion-based generative models also presents an efficient method to jointly reconstruct geometry (explicit triangle meshes), materials and lighting, substantially improving material and light separation compared to previous work. Finally, Nvidia hypothesizes that denoising can become integral to high-quality inverse rendering pipelines.
Fidler highlighted the importance of lighting in a 3D environment and said that realistic lighting is crucial to a 3D scene. 
“By reconstructing the geometry and disentangling lighting effects from the material properties of objects, we can produce content that supports relighting effects and augmented reality (AR) — which is much more useful for creators, artists and engineers,” Fidler told VentureBeat. “With AI, we want to accelerate and generate these 3D objects by learning from a wide variety of images rather than manually creating every piece of content.”
Image Source: Nvidia
3D MoMa achieves this. As a result, the content it produces can be directly imported into existing graphics software and used as building blocks for complex scenes. 
The 3D MoMa model does have limitations. They include a lack of efficient regularization of material specular parameters, and reliance on a foreground segmentation mask. In addition, the researchers note in the paper that the approach is computationally intense, requiring a high-end GPU for optimization runs.
The paper puts forth a unique Monte Carlo rendering method combined with variance-reduction techniques, practical and applicable to multiview 3D object reconstruction of explicit triangular 3D models. 
Nvidia’s future AI focus
Fidler said that Nvidia is very excited about generative AI, as the company believes that the technology will soon open up opportunities for more people to be creators.
“You’re already seeing generative AI, and our work within the field, being used to create amazing images and beautiful works of art,” she said. “Take Refik Anadol’s exhibition at the MoMA, for example, which utilizes Nvidia StyleGAN.”
Fidler said that other emerging domains Nvidia is currently working on are foundational models, self-supervised learning and the metaverse. 
“Foundational models can train on enormous, unlabeled datasets, which opens the door to more scalable approaches for solving a range of problems with AI. Similarly, self-supervised learning is aimed at learning from unlabeled data to reduce the need for human annotation, which can be a barrier to progress,” explained Fidler. 
“We also see many opportunities in gaming and the metaverse, using AI to generate content on the fly so that the experience is unique every time. In the near future, you’ll be able to use it for entire villages, landscapes and cities by assembling an example of an image to generate an entire 3D world.”



VB Daily
Stay in the know! Get the latest news in your inbox daily




 Subscribe

By subscribing, you agree to VentureBeat's Terms of Service.

					Thanks for subscribing. Check out more VB newsletters here.
				
An error occured.


 


Find Your Place In The World BY Amply





 
AI Content Writer
DataAnnotation
Los Angeles
$20 - $25 an hour
See Job





 
System Administrator (Joint and Services Center)
The MITRE Corporation
Lexington Park
See Job





 
Mortgage Sales Specialist
United Wholesale Mortgage
Pontiac
See Job





 
IT Functional Relationship Manager - Master Data
Nestlé IT
St. Louis
$111,000 - $158,000 a year
See Job




            Search More Roles
          



",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vdGVjaGNydW5jaC5jb20vMjAyMi8xMi8wMi9vcGVuYWlzLWNoYXRncHQtc2hvd3Mtd2h5LWltcGxlbWVudGF0aW9uLWlzLWtleS13aXRoLWdlbmVyYXRpdmUtYWkv0gEA?oc=5,OpenAI's ChatGPT shows why implementation is key with generative AI - TechCrunch,2022-12-02,TechCrunch,https://techcrunch.com,"OpenAI released ChatGPT this week, and it's a great example of why user experience is the future for generative AI.",N/A,"OpenAI released ChatGPT this week, and it's a great example of why user experience is the future for generative AI.",N/A,https://schema.org,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,"[{'@type': 'NewsArticle', '@id': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/#article', 'isPartOf': {'@id': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/'}, 'author': [{'@id': 'https://techcrunch.com/#/schema/person/image/8b549dbcca0376c3d08d34c2e866cca2'}], 'headline': 'OpenAI&#8217;s ChatGPT shows why implementation is key with generative AI', 'datePublished': '2022-12-02T12:37:49+00:00', 'dateModified': '2022-12-02T17:10:11+00:00', 'mainEntityOfPage': {'@id': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/'}, 'wordCount': 553, 'commentCount': 0, 'publisher': {'@id': 'https://techcrunch.com/#organization'}, 'image': {'@id': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/#primaryimage'}, 'thumbnailUrl': 'https://techcrunch.com/wp-content/uploads/2022/12/GettyImages-1367281424.jpg', 'keywords': ['Generative AI', 'OpenAI'], 'articleSection': ['AI'], 'inLanguage': 'en-US', 'speakable': {'@type': 'SpeakableSpecification', 'cssSelector': ['#speakable-summary']}, 'copyrightYear': '2022', 'copyrightHolder': {'@id': 'https://techcrunch.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/', 'url': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/', 'name': ""OpenAI's ChatGPT shows why implementation is key with generative AI | TechCrunch"", 'isPartOf': {'@id': 'https://techcrunch.com/#website'}, 'primaryImageOfPage': {'@id': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/#primaryimage'}, 'image': {'@id': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/#primaryimage'}, 'thumbnailUrl': 'https://techcrunch.com/wp-content/uploads/2022/12/GettyImages-1367281424.jpg', 'datePublished': '2022-12-02T12:37:49+00:00', 'dateModified': '2022-12-02T17:10:11+00:00', 'description': ""OpenAI released ChatGPT this week, and it's a great example of why user experience is the future for generative AI."", 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://techcrunch.com/2022/12/02/openais-chatgpt-shows-why-implementation-is-key-with-generative-ai/#primaryimage', 'url': 'https://techcrunch.com/wp-content/uploads/2022/12/GettyImages-1367281424.jpg', 'contentUrl': 'https://techcrunch.com/wp-content/uploads/2022/12/GettyImages-1367281424.jpg', 'width': 2121, 'height': 1414, 'caption': 'Artificial Intelligence - Chatbot concept'}, {'@type': 'WebSite', '@id': 'https://techcrunch.com/#website', 'url': 'https://techcrunch.com/', 'name': 'TechCrunch', 'description': 'Startup and Technology News', 'publisher': {'@id': 'https://techcrunch.com/#organization'}, 'alternateName': 'TC', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://techcrunch.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://techcrunch.com/#organization', 'name': 'TechCrunch', 'alternateName': 'TC', 'url': 'https://techcrunch.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://techcrunch.com/#/schema/logo/image/', 'url': 'https://techcrunch.com/wp-content/uploads/2018/04/tc-logo-2018-square-reverse2x.png?resize=1200,1200', 'contentUrl': 'https://techcrunch.com/wp-content/uploads/2018/04/tc-logo-2018-square-reverse2x.png?resize=1200,1200', 'width': 1200, 'height': 1200, 'caption': 'TechCrunch'}, 'image': {'@id': 'https://techcrunch.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/techcrunch', 'https://x.com/TechCrunch', 'https://mstdn.social/@TechCrunch', 'https://bsky.app/profile/techcrunch.bsky.social', 'https://www.threads.net/@techcrunch']}, {'@type': 'Person', '@id': 'https://techcrunch.com/#/schema/person/image/8b549dbcca0376c3d08d34c2e866cca2', 'name': 'Darrell Etherington', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://techcrunch.com/#/schema/person/image/549578ffe88a6cc6bd628632b01bd448', 'url': 'https://secure.gravatar.com/avatar/188039e12983eb749171a75cfd01378d?s=96&d=identicon&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/188039e12983eb749171a75cfd01378d?s=96&d=identicon&r=g', 'caption': 'Darrell Etherington'}, 'description': 'Writer covering space, science and health tech. Formerly covering automotive and mobility tech, and previously an employee of Apple and also of Shopify.', 'url': 'https://techcrunch.com/author/darrell-etherington/'}]",,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS9hcnRhbmRkZXNpZ24vMjAyMi9kZWMvMDEvc2l4LWxlYWRpbmctYnJpdGlzaC1hcnRpc3RzLW1ha2luZy1hcnQtd2l0aC1hadIBY2h0dHBzOi8vYW1wLnRoZWd1YXJkaWFuLmNvbS9hcnRhbmRkZXNpZ24vMjAyMi9kZWMvMDEvc2l4LWxlYWRpbmctYnJpdGlzaC1hcnRpc3RzLW1ha2luZy1hcnQtd2l0aC1haQ?oc=5,"Incoherent, creepy and gorgeous: we asked six leading artists to make work using AI – and here are the results - The Guardian",2022-12-01,The Guardian,https://www.theguardian.com,"Artificial intelligence is creating increasingly sophisticated images. But what does it mean for the artworld? Gilbert and George, Gillian Wearing, Mat Collishaw, Elizabeth Price, Polly Morgan and Lindsey Mendick found out",N/A,"Artificial intelligence is creating increasingly sophisticated images. But what does it mean for the artworld? Gilbert and George, Gillian Wearing, Mat Collishaw, Elizabeth Price, Polly Morgan and Lindsey Mendick found out",N/A,,,,,,,,,,,,,,,Art and design,N/A,"Gilbert and George by AI, by Gilbert and George: the eyes are cold and distant. Composite: Gilbert and GeorgeArtificial intelligence is creating increasingly sophisticated images. But what does it mean for the art world? Gilbert and George, Gillian Wearing, Mat Collishaw, Elizabeth Price, Polly Morgan and Lindsey Mendick found outBy Jonathan JonesThu 1 Dec 2022 01.00 ESTLast modified on Thu 1 Dec 2022 03.05 ESTShareFor more than 30,000 years we have been the only art-making species on Earth, give or take the odd paint-throwing Neanderthal or chimpanzee. Art is the oldest and most spectacular triumph of human consciousness, from Lascaux to the Sistine Chapel. But a new generation of artificial intelligence (AI) art software may be about to end that. It will whip you up a Picasso or a Turner in an instant, or apply their styles to any theme you picture, from Liz Truss dancing in a supermarket to a brawl in a 1970s disco.Stable Diffusion and competitors such as DALL-E 2 go far beyond previous claims for AI art. Easily accessible online, and in that sense open to full public scrutiny, they create precise, rich, convincing images in response to a typed-in text – for example “a sad cat in a mountainous landscape in the style of Turner”, or whatever combination of styles, keywords and subjects takes your fancy. Or you can ask more sidelong and existential questions, such as my request for “a photograph of a human”, which produced a bare-chested man who could be a museum exhibit of early homo sapiens – except for his mysterious earphone-like cables. For the expert there are others: “I’ve been experimenting in Wombo Dream, Midjourney and Google Colab/Disco Diffusion,” says the artist Mat Collishaw.View image in fullscreenJonathan Jones’s AI collaboration, created from the request: a photograph of a human. Photograph: Jonathan JonesUntil recently, I was deeply sceptical of the idea of AI art. I saw it as hype and casuistry, and with some cause: widely publicised efforts such as Ai-Da the robot artist obviously exaggerate the independence of the machine and play on our fascination with sentient artificial beings. But now the dream is coming true, at least in art. And art is surely one of the most inimitable expressions of the human mind.Evangelists for so-called “strong AI” – full artificial intelligence that will replicate and exceed the human mind – are fond of making analogies with biological evolution. Over millions of years, mindless cells evolved the human brain; machines are now evolving much faster so why shouldn’t they become sentient soon? The evolution of AI art seems to vindicate that. In 2018, the sale of an AI generated-painting called Portrait of Edmond de Belamy at Christie’s for $432,500 (£360,000) was the latest thing in the field – yet this portrait was crude in the extreme, a pixellated blur easy to dismiss as a pathetic computerised pastiche of Frans Hals. Four years on, the detail and nuance of images produced by the latest AI art generators have grown more impressive exponentially.What does this mean for art? Is it the end of our run as the only art-making species? Or can humans and machines work together to create something wondrous? To find out, I challenged six outstanding human artists, including three Turner prize-winners, to experiment with AI.View image in fullscreenGilbert and George by AI, by Gilbert and George. Photograph: Gilbert and GeorgeGilbert and GeorgeGilbert and George have been flirting with post-humanity ever since they painted their faces and hands silver, like robots, for their 1969 performance-art masterpiece The Singing Sculpture. Their merging of creative identities – “two people, but one artist” – has a similar futuristic radicalism. That extends to the authorship of the Pictures they have made since the 1970s in which they appear while operating the camera and editing its images in a deliberately unexpressive way: always sharp and bright. The panel of four portraits they have elicited from AI is called Gilbert and George by AI, but firmly credited to them as artists.These images of Gilbert and George are like them, but not. They are clearly not photographs: instead, the software has “painted” them from the information it has, in several efforts with various eccentricities. At the top left, Gilbert Proesch looks as if he’s in a 1960s film by Antonioni or Fellini: at bottom right, both men merge into the same grumpy caricature. In all the portraits, their eyes are cold and distant and odd. This is typical of what happens when you ask a machine to portray a human.All existing AI art platforms, from the software that stunned Christie’s auction room in 2018 to the disconcertingly impressive Stable Diffusion, are types of “neural network” that excel at machine learning. Neural networks emulate the way neurons fire off each other in the human brain: they are capable of learning when fed with ever-vaster quantities of data. The power of machine learning is seen by some as an epochal breakthrough that makes AI “creative” and could soon lead to artificial consciousness – if it hasn’t already. This summer, Google sacked engineer Blake Lemoine after he claimed its LaMDA chatbot was starting to think for itself.Others say these machines are only good at the job they have been taught: DeepMind’s AlphaGo can’t turn its skills to Scrabble or Cluedo and self-driving cars have big problems with unexpected situations outside their learning.The trouble AI art has with depicting eyes, not to mention how many limbs or heads a human being possesses, may back up the sceptical view. The likes of DALL-E 2 and Stable Diffusion have been fed huge amounts of artistic and visual information yet don’t have any knowledge of, say, anatomy. They don’t realise this is a problem because they don’t “think”.Or do they?View image in fullscreen‘What do you understand about racial identity?’ Photograph: Elizabeth PriceElizabeth PriceElizabeth Price takes on such issues in the sequence of 40 AI images she generated from text prompts. Instead of producing a finished artwork, she treated it as an experiment, sharing the results in an apparently casual way. Only when I flicked through the sequence like a slideshow did I see that it is as unsettling as her Turner prize-winning video The 1979 Woolworths Choir. Price engages with the AI as if it were indeed sentient, asking it questions rather than giving it commands, as she tries to get the software to reveal its true self. “I quickly became fascinated by how it was putting images together; how that process differed from the human mind; what it ‘knew’; what it ‘understood’; and how much we could think of its dataset and search modes as a kind of cultural memory.” Price says that if this is her artwork, it’s one that includes the questions she put: one of the limits of AI, she points out, is that it has an unsophisticated and conservative grasp of what art is.View image in fullscreen‘Do you understand politics in the UK?’ Photograph: Elizabeth PriceShe asks the AI: “What do you understand about love for a parent”; it produces a waxily real, warm yet ever so slightly creepy vision of an embracing family. “Do you understand politics in the UK?” elicits a shrill picture with devastating – deliberate or accidental? – satirical power in which hosts of shouting heads are juxtaposed with multiple union flags. “What do you understand about racial identity” leads to a photographic image of two Black children, one of whom holds up a photo of a Black girl as if she is a missing person. It’s striking, says Price, that the software should assume “racial identity” means Blackness, as if whiteness were the non-racial norm.View image in fullscreen‘What do you understand about love for a parent?’ Photograph: Elizabeth PriceSuch apparent racism has become a problem with other AI applications such as facial recognition, and reflects the internet data the machines are fed. Price compares the intelligence she questioned to a “collective unconscious”. And it can throw up some seriously weird images as it trawls through digitally archived human memories. She types in the poet Emily Dickinson’s lines about her own future grave: “An Island in dishonored Grass – / Whom none but Daisies – know.” In one text prompt the daisies become beetles, and the computer depicts them as giant shiny creatures in a verdant landscape.View image in fullscreen‘An Island in dishonoured Grass - whom none but Beetles – know’. Photograph: Elizabeth PriceSome combinations of words unleash the truly unexpected from AI art generators, while others result in something flat, or incoherent. It feels as if you are searching for the right key to the vast banks of imagery that exist on the internet. AI in its current state is quite literally an unconscious mind, full of memory, but unable to make sense of it. In the early 20th century, artists and poets inspired by Sigmund Freud sought to release images directly from the human unconscious. That was the surrealist revolution. Could the AI age be fertile ground for a new surrealism in which human artists pry open the digital unconscious?View image in fullscreenPouyannian mimicry: AI art by Mat Collishaw. Photograph: Mat CollishawMat Collishaw and Polly MorganMat Collishaw and Polly Morgan work in a studio that seems to have its own subconscious. It’s a converted pub in south London, a bit of a fortress from the outside, where on the ground floor Collishaw works coolly with computers and hi-tech toys including a 3D video screen. Collishaw is fascinated by the technology of the image, from early cameras and zoetropes to AI – of which he is an early adopter. But downstairs in the pub’s depths, he tells me, Morgan is busy amid guts and gore, skinning snakes for her taxidermy sculptures.Not that Collishaw’s art is lacking in surrealism. His current experiments with AI start with 17th-century still life paintings of flowers. He feeds them into the software, then creates text prompts to add in insects. At first, the picture looks charmingly beautiful, then you start to notice more and more insects – which then turn out to be flowers in disguise. Collishaw explains that it illustrates “Pouyannian mimicry, when a flower imitates an insect to attract and exploit other insects which inadvertently propagate the flower’s species”.It is a metaphor for AI itself – for Collishaw is no techno-utopian. Like the flowers that imitate insects to trick them into propagating their pollen, the big tech corporations attract us with social media and internet searches so they can collect our data. This in turn fuels machine learning, which adds to the digital world’s glamour. Collishaw’s flowers are gorgeous yet deceptive.View image in fullscreenA snake cross-bred with concrete: AI artwork by Polly Morgan using Stable Diffusion. Photograph: Polly MorganWhen Morgan emerges from her bloody basement in her stained overalls, I suggest she, too, try out an AI artwork, and it arrives a few days later – a taxidermy sculpture strangely transfigured. The snake in it has been cross-bred with concrete. It glistens monumentally beside a female hand whose nails are not just long, but doubled, in one of those creative slips AI can make with human anatomy. Morgan compares it to the surrealist photography of Man Ray – it’s like a decadent remake of his portrait of Kiki of Montparnasse, her eyes closed in dreams, her hand on a carved mask. Except here, the dreamer is a disembodied hand and what it dreams of is an inorganic serpent.View image in fullscreenStrange, spooky, funny: Gillian Wearing’s Imagined Mask of Joan Crawford as Bette Davis in Whatever Happened to Baby Jane, created with AI - DALL-E 2. Photograph: © Gillian Wearing/Courtesy Maureen Paley, LondonGillian WearingGillian Wearing uses the fantastical possibilities of AI to create a truly disconcerting image full of unease called Imagined Mask of Joan Crawford as Bette Davis in Whatever Happened to Baby Jane. You start to laugh at the title, then stop when you realise that beneath this brutal and macabre parody of a human face, created by exploiting the inhumanity of AI portraits, is a suffering human being. This is very much a work of art by Wearing that happens to make use of AI: it’s the latest in a series of disconcerting and introspective works in which she has been exploring the nature of masks, and what they say about our public and private selves.Using one of her own photographs, she has added the mask with DALL-E 2 AI so it seems to grow naturally out of her face, while being contoured to the shape of a skull all too visible under the skin. It uses the distortions that AI can create, yet within a portrait that is human and real. Wearing suggests mortality and madness in a vision of a face eaten away from inside. It’s strange, spooky, funny – yet like all her art it is also about the lumpen reality of being human. Even this mask morphing into two Hollywood legends is ultimately about plain sad facts. You get a sense of loneliness and anguish, crying from inside to outside, soul to soul.So long as humans are involved, art will be all about us – whatever the technology.Painting of Cher and a Werewolf at a Buffet in Las Vegas: AI artwork created by Lindsey Mendick. Photograph: Lindsey MendickLindsey MendickI asked Lindsey Mendick to try AI because she works in one of the oldest of all artistic media. Pottery was made in ice-age Europe, prehistoric China and every civilisation since. Mendick makes hilarious, lubricious ceramics that swarm with monsters and dirty jokes. What might an artist who is used to delving into wet clay make of an art form that requires you only to type a text prompt on your phone screen?Turns out she’s a natural. Typing her texts into Stable Diffusion, Mendick struck gold with the words “Las Vegas”, “Cher” and other celebrity names. She started by sending photo-style scenes of wild cavortings in “a Las Vegas buffet”. Then she added the term “impressionist painting”.Las Vegas buffet ravaged by werewolves in rococo clothing as sweaty waiters look on in dismay, by Lindsey Mendick using Stable Diffusion. Photograph: Lindsey MendickThat’s how such contemporary masterpieces as Impressionist Painting of Cher and a Werewolf at a Buffet in Las Vegas and Impressionist Painting of Tom Cruise Feeling Sad Eating a Sandwich With a Werewolf in Las Vegas were born. In the funniest, most touching of her kitsch ultra-bright AI paintings of celebrities, a vulpine Leonardo DiCaprio shares a huge seafood platter with a werewolf. Man and monster break bread peacefully.Like these collaborations between artist and machine, it could be the beginning of a beautiful friendship.Elizabeth Price: Underfoot is at the Hunterian, Glasgow until 13 April. Lindsey Mendick in Strange Clay is at the Hayward until 8 January. Mat Collishaw’s AI flowers will be at Kew in 2023 and The Gilbert and George Centre opens 2023.Explore more on these topicsArtArtificial intelligence (AI)ConsciousnessComputingPaintingSculpturefeaturesShareReuse this content",,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LmJ1LmVkdS9hcnRpY2xlcy8yMDIyL3Bvdi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pcy1jaGFuZ2luZy13cml0aW5nLWF0LXVuaXZlcnNpdGllcy_SAQA?oc=5,POV: Artificial Intelligence Is Changing Writing at the University. Let's Embrace It - Boston University,2022-12-05,Boston University,https://www.bu.edu,"Christopher McVey writes that now that AI can be used by students to help write essays for college classes, faculty need to rethink how they teach writing.",N/A,"In this op-ed, Christopher McVey, senior lecturer in the College of Arts & Sciences Writing Program and Kilachand Honors College, writes that now that AI can be used by students to help write essays for college classes, faculty need to rethink how they teach writing. “If we want to dissuade students from using artificial intelligence to help produce their writing, we need to treat writing differently.”","Senior lecturer Christopher McVey writes that now that AI can be used by students to help write essays for college classes, faculty need to rethink how they teach writing.",http://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://www.bu.edu/articles/2022/pov-artificial-intelligence-is-changing-writing-at-universities/'}",POV: Artificial Intelligence Is Changing Writing at the University. Let’s Embrace It,,2022-12-05T08:13:00-04:00,2022-12-05T11:23:25-04:00,,,"{'@type': 'Organization', 'name': 'BU Today', 'logo': {'@type': 'ImageObject', 'url': '/files/2023/09/bu-today-logo-new.png'}}",,"{'@type': 'Person', 'name': 'Christopher McVey'}","['/files/2022/12/feat-iStock-492548403-1200x1200.jpg', '/files/2022/12/feat-iStock-492548403-1600x1200.jpg', '/files/2022/12/feat-iStock-492548403-1600x900.jpg']",,N/A,N/A,"
POV: Artificial Intelligence Is Changing Writing at the University. Let’s Embrace It“If we want to dissuade students from using AI to help produce their writing, we need to treat writing differently,” says CAS writing program senior lecturer 




Photo by jacoblund/iStock


Higher Education

																	POV: Artificial Intelligence Is Changing Writing at the University. Let’s Embrace It															
“If we want to dissuade students from using AI to help produce their writing, we need to treat writing differently,” says CAS Writing Program senior lecturer






December 5, 2022

9



Christopher McVey



Twitter
Facebook




Writing is a cornerstone of a university education, and for good reason. It is not only a form of communication, but a means of discovery, recalling the old adage, “How do I know what I think until I see what I write?” What could be more central to the examined life? What skill could be more predictive of postgraduate career success than the ability to write well?
Many are beginning to worry, however, that writing in the university is under threat. Technological innovations have long been associated with the replacement of manual labor, but now—like the zombies in the postapocalyptic literature class I teach—they are coming for our brains. As noted by Slate, artificial intelligence (AI) programs that generate text have become so widely available and affordable that many are beginning to suspect students are using AI to write essays for their university classes. Jeff Schatten, an associate professor of business administration at Washington and Lee University, recently prophesized the coming plagiarism apocalypse in an article for the Chronicle of Higher Education titled “Will Artificial Intelligence Kill College Writing?”
How worried should we be? There is limited data on how often students make use of such software, but Schatten’s concerns seem justified. These new services generate content that is not traceable to any source and cannot be identified by current plagiarism-checking software. And the content AI can produce is startling in its specificity and organization. It makes piecemeal plagiarism—in which students casually copy writing from other sources into their own work—both efficient and fun.
For example, I recently used Sudowrite to see what would happen after prompting it to help me compose an essay about E. M. Forster’s 1909 short story, “The Machine Stops,” in which humans, living in a series of underground tunnels because the surface of the planet is no longer ecologically habitable, have become totally reliant upon an omniscient Machine. After I typed a few sentences to begin an essay on the story, Sudowrite generated the following suggested text to complete my paragraph: “While the Machine is the ‘handmaid’ that helps deliver things to the people, they have become so reliant on it that if the Machine shut down, they would die…. We find solace in the presence and use of these machines to help us with everything—they are our servants, our caretakers. We have stopped thinking for ourselves and simply rely on technological devices to do so for us.” Open the pod bay doors, Hal.
Undoubtedly, tools like Sudowrite will change the way that writing is assigned in our classes. But, speaking as a college writing instructor, I don’t think this is necessarily a bad thing.
Many college classes assign writing as a product-based endeavor: students complete an essay, turn it in, and receive a grade. But writing assessment is not synonymous with writing instruction, and the writing-as-product model does little more than punish or reward students for writing skills that they likely already had before even beginning the assignment. If we want to dissuade students from using artificial intelligence to help produce their writing, we need to treat writing differently. If we want to teach writing in our classes, if we want students to use writing as a deliberative, reflective space to facilitate critical thinking, innovation, and self-awareness, we need to move away from framing writing assignments as primarily product-based endeavors.
Writing programs across the country, like the one here at Boston University, have been at the forefront of this work for decades. Integrated into our classes is an emphasis on the writing process, including the intellectual work that happens before ever putting pen to paper (or finger to keyboard). We require students to develop drafts, to workshop their writing with other students, to meet with us individually in conferences to discuss their ideas and find a language to best convey them. Students always seem to have flashes of insight at 2 am, and no machine can replace me when they show up, bleary-eyed and unannounced, at my office door early the next day, eager to try out their ideas in conversation or to share the new paragraphs they wrote just as the sun was beginning to rise.
Recognizing that the kinds of writing skills students need extend well beyond the traditional academic essay, we are assigning new genres and new media: TED Talks, public intellectual essays, podcast episodes, video essays, and even live action role-playing to practice debate. Our newest courses emphasize design thinking as their central pedagogical orientation: students develop projects, individual or collaborative, that use writing across many media forms to experiment, innovate, and explore.
Some professors might complain that they do not have time for these kinds of assignments, that it is impossible to engage with students about their ideas over the course of multiple drafts. But, if this is true, why assign writing at all? If we regard writing as nothing more than a demonstration of proficiency, then our students will do the same, and will likely turn to AI to help them get the job done. If, instead, we dedicate ourselves and our assignments to something more—valuing writing as a messy and generative encounter with the self, a space in which we encourage students to discover what they think rather than only communicate it—then our students will, too. Writing at the university is changing. Let’s embrace it.
“POV” is an opinion page that provides timely commentaries from students, faculty, and staff on a variety of issues: on-campus, local, state, national, or international. Anyone interested in submitting a piece, which should be about 700 words long, should contact John O’Rourke at orourkej@bu.edu. BU Today reserves the right to reject or edit submissions. The views expressed are solely those of the author and are not intended to represent the views of Boston University.


			Explore Related Topics:		



							Computers						



							Education						






		Share this story		

9
Comments
Add





Share
POV: Artificial Intelligence Is Changing Writing at the University. Let’s Embrace It
ShareTwitterFacebookRedditLinkedInEmailPrint 




Copy URL:

Copy







",,,,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://www.bu.edu/#organization', 'name': 'Boston University', 'url': 'https://www.bu.edu/', 'sameAs': ['https://www.facebook.com/BostonUniversity/', 'https://www.instagram.com/bostonu/', 'https://www.linkedin.com/school/boston-university/', 'https://www.youtube.com/user/bu', 'https://www.pinterest.com/bostonuniv/', 'https://en.wikipedia.org/wiki/Boston_University', 'https://twitter.com/BU_Tweets']}, {'@type': 'WebSite', '@id': 'https://www.bu.edu/#website', 'url': 'https://www.bu.edu/', 'name': 'Boston University', 'publisher': {'@id': 'https://www.bu.edu/#organization'}, 'potentialAction': {'@type': 'SearchAction', 'target': 'https://www.bu.edu/?s={search_term_string}', 'query-input': 'required name=search_term_string'}}, {'@type': 'WebPage', '@id': 'https://www.bu.edu/articles/2022/pov-artificial-intelligence-is-changing-writing-at-universities/#webpage', 'url': 'https://www.bu.edu/articles/2022/pov-artificial-intelligence-is-changing-writing-at-universities/', 'inLanguage': 'en-US', 'name': 'POV: Artificial Intelligence Is Changing Writing at the University. Let’s Embrace It | BU Today | Boston University', 'isPartOf': {'@id': 'https://www.bu.edu/#website'}, 'image': {'@type': 'ImageObject', '@id': 'https://www.bu.edu/articles/2022/pov-artificial-intelligence-is-changing-writing-at-universities/#primaryimage', 'url': '/files/2022/12/feat-iStock-492548403.jpg', 'width': 2000, 'height': 1335, 'caption': 'Photo: a young Black girl sits in library, typing on laptop for her assignment. She has various books and notes open in front of her on the table as she looks to her screen in concentration.'}, 'primaryImageOfPage': {'@id': 'https://www.bu.edu/articles/2022/pov-artificial-intelligence-is-changing-writing-at-universities/#primaryimage'}, 'datePublished': '2022-12-05T13:13:00-04:00', 'dateModified': '2022-12-05T16:23:25-04:00', 'description': 'Christopher McVey writes that now that AI can be used by students to help write essays for college classes, faculty need to rethink how they teach writing.'}]",,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/body/div[2]/div[2]/div/main/div/div/article/header/h1', ""/html/head/meta[@name='description']/@content""]}",,,,
https://news.google.com/rss/articles/CBMiZmh0dHBzOi8vYmxlZWRpbmdjb29sLmNvbS9jb21pY3MvY29taWMtYm9vay1jcmVhdG9ycy1yZWFjdC10by1haS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hcnQtZXhwbG9zaW9uL9IBAA?oc=5,Comic Book Creators React To AI Artificial Intelligence Art Explosion - Bleeding Cool News,2022-12-06,Bleeding Cool News,https://bleedingcool.com,"This weekend, the Lensa app created by Prisma AI using went viral, a service that encourages you to upload images of your face and then concocts artificial intelligence AI portraits of you with Stable Diffusion in all manner of artistic styles, looks, and themes. It's been around for a while, but it has suddenly become [&hellip;]
","ai,artificial intelligence,midjourney","This weekend, the Lensa app created by Prisma AI using went viral, a service that encourages you to upload images of your face and then concocts",N/A,http://schema.org,NewsArticle,https://bleedingcool.com/comics/comic-book-creators-react-to-ai-artificial-intelligence-art-explosion/,Comic Book Creators React To AI Artificial Intelligence Art Explosion,https://bleedingcool.com/comics/comic-book-creators-react-to-ai-artificial-intelligence-art-explosion/,2022-12-06T07:10:10-06:00,2022-12-06T07:10:10-06:00,en-US,Comics,"{'url': 'https://bleedingcool.com', 'name': 'Bleeding Cool News', '@type': 'Organization', 'logo': {'url': 'https://www.bleedingcool.com/wp-content/uploads/2019/05/cropped-bccircle.jpg', '@context': 'http://schema.org', '@type': 'ImageObject'}}",http://schema.org/True,"{'name': 'Rich Johnston', 'url': 'https://bleedingcool.com/authorrich-johnston/', '@context': 'http://schema.org', '@type': 'Person'}","['https://bleedingcool.com/wp-content/uploads/2022/12/316678242_223273096719604_1247168062336489674_n-1200x675.jpg', 'https://bleedingcool.com/wp-content/uploads/2022/12/316678242_223273096719604_1247168062336489674_n-1200x900.jpg', 'https://bleedingcool.com/wp-content/uploads/2022/12/316678242_223273096719604_1247168062336489674_n-900x900.jpg']",,N/A,N/A,"Posted in: Comics | Tagged: ai, artificial intelligence, midjourneyComic Book Creators React To AI Artificial Intelligence Art ExplosionPublished Tue, 06 Dec 2022 07:10:10 -0600 by Rich Johnston | CommentsThis weekend, the Lensa app created by Prisma AI using went viral, a service that encourages you to upload images of your face and then concocts artificial intelligence AI portraits of you with Stable Diffusion in all manner of artistic styles, looks, and themes. It's been around for a while, but it has suddenly become very popular to upload such images as avatars online – which can then be attacked by those who disapprove of such services.






				Kelly sue DeConnick Instagram
				




				Kelly sue DeConnick Instagram
				




				Kelly sue DeConnick Instagram
				

Aside from AI art criticism in general, taking away from real-life artists and also appropriating people's art and art styles without credit or compensation, there is criticism that the app reverts to sexualisation, and Prisma stated that they both own the work but also get the rights to use the uploaded photos in whatever way they wish. Here's some reaction posted by actual living comic book folk to social media recently.
Reilly Brown: Isn't it illegal for a computer program to just copy and paste code from another computer program? If in the case of AI generated images, visual art is essentially just a different form of programming code, wouldn't using it still be infringement?
Jimmie Robinson: I'm all for new tools in art creation. Even this new realm of text prompt apps. I'm all for people who want to explore and generate content, no matter what their skill level is in art. I'm all for it. I get it. I even want it.
The backlash, even if it's logical, correct and sincere is a waste of time. The cat is out the bag, the genie out the bottle, the milk already spilled.
Not saying people don't have the right to cast their opinion, because I am all for that, too. In fact, I encourage it. New art might emerge from those who rally against this new form. As the lyrics go, ""Your anger is a gift.""
But some of the vitriol I'm reading is asking for the elimination of the tools and apps, as if that will solve the problem they have with it. I won't quote, or name people, because that's not what this post is about.
This is about acceptance.
Art tools have morphed since paintings on cave walls. Nothing is done ""as it used to be"". In this digital era we will see art acceptance morph again. I'm honored to see it happening, just like the early days of photoshop, illustrator, direct-to-plate printing, and online comics. I'm an old fart and I find it fascinating to watch the evolution in real time.
In the 1990s, I recall seeing Scott McCloud stand before a huge room of industry professionals at a Pro/Con event in Oakland, Ca., telling them about the birth and potential of online comics. He was set upon with pitchforks and torches. And yet, here we are… giving out Eisner Awards to digital comics.
I know it's hard (and for some even alarming) to see change so quickly and broadcast so steadily to millions. But there it is. And it's early days. Kinks, quirks, issues and prompts still need to be ironed out.
But trust me, the day is coming when Ai art will be a standard, not just a gimmick. When sampling data from existing work will be a given with a shrug of the shoulders, no more than using a credit card online or ticking that box about online data and cookies.
So feed the internet with more Batman art for Ai prompts?
Or… find your art, your style, your vision.
Be unique. Be creative in ways outside the box.
The work will stand out, even if it's sampled.
Art is not mutually exclusive.
We can all play in the same sandbox.
Yes, even if that kid across the way is copying your answers on the test.
We still do the test.
Plus Size Superheroes and Villians as requested by Matty Blades
Mike Manley: I have been seeing AI comics now. At first they totally sucked but in the past month I've seen them getting better. And I'm wondering since it's only a matter of months I imagine till it's smart enough to ape any style if fans will care?
If you can have more George Perez comics or John Byrne comics in their style do you care if in the end it might take work from human artists? Choose any artist with a recognizable style.
As far as I can see what you need is the script and a layout person to layout the page and choose the shots. Then you are not interpreting the script but choosing the best example AI gives you for the panel. And a production person for lettering and prepress. Or just do it as a web comic.
It will be able in short order to replicate anyone's style. It already is doing it in illustration. The concept people are good and fucked. If you are not top tier like Moebius or Mead. And again will the consumer care?
I see it as three tiers of consumer. Casual fan. In and out in a few years or watches the average movie. Not a collector.
The next level who is a fan of specific stories or genres. Casual collecting.
Then the Uber fan or fanatic. Collectors. They collect runs, follow specific artists. They might be able in a subset group to know about anatomy or storytelling. Inkers over certain artists etc. buy art.
Will the fan carry a cart of books to have signed at the table of the prompters? AI won't be signing.
So the question becomes will supporters care about getting sketches? "" come back in an hour, give me you prompts"".
Are they just fans of the material or of the creators? We have never been faced with that question.
I feel at least half if not more of people who consume this won't. Maybe 30% will.
Jonathan Matthewson: A.I. Is to art what Autotune is to music.
Salgood Sam: We've been here before even, remember when synths, or remix culture first took off and old school musicians took issue each time with the users of the new tools calling themselves artists or musicians? How well did that age?
Do you still take umbrage at calling people who do remixes and beat tracks from sample artists? How about writers? Instillation artists?
There's a lot of issues around AI that I agree with but I think visual artists are somehow assuming people who've learned how to work the AI via prompt texts – which having tried I can tell you isn't as simple as you might imagine – are implying they drew the thing by calling themselves an artist.
There are a LOT of kinds of artists who never draw, or even directly make the raw materials they use but rather assemble and build things. All legitimately artists as well.
AI isn't likely going anywhere, as a working commercial artist in animation for my day job I expect at some point when the tools and it's output are more predictable and controllable, studios will expect designers like me to learn to incorporate it into our workflow.
It's not contrary to some of the toxic claims, going to totally replace humans, just like self checkout lines still need human attendants to deal with shit AI images have lots of issues and need someone who is capable of doing the work when it glitches or breaks down to be on hand.
To be truly independent of humans it would need a working mind of its own and that's simply not going to happen. Takes too much processing power. Like orders of magnitude more than say all the CPU and GPU currently being used by the crypto crowd, just to think and that's one unit. We'll build those eventually but that's NOT going to be used to make art of any kind outside of an experiment any time soon, far too expensive for the margins in the arts.
But the relatively dumb tools are coming, and the people who use them will need a specific skill set to use them well, they already are part of the work flow for all the amazing VFX and digital animation you see.
ALL the hair and water and complex natural things in animation you take for granted these days and bitch about when something like She Hulk is just slightly less convincing? That's all dealt with by dumb algorithmic AI much like the tools being used to make the fantasy art that's taking off now from things like Stable Diffusion.
it's here already.
The people who use those, those that start working fantasy and editorial jobs making images with them? Those people, some of them are going to be seen as and call themselves artists, and I think it's a legit term like it or not.
The issues it represents for other kinds of artists are serious, but mainly they are ones of IP and labor law, not petty shit like who gets to be called an artist.
And factcheck, no it's not plagiarizing work in the learning database, it's using it much the same way my students did when I told them to study past artists and those they admire, as many as you can, to learn how to make good art. The only time you get into plagiarizing territory, both with students and AI, is when they study too few and don't have enough verity in their influence. Think those bots that have been trained to imitate ONE artist specifically, and even branded with their name.
The target of any aggression should not be other workers, but the corporations and governments.
If you're attacking peers using tools, you're being fearful monkeys throwing shit at exactly the wrong people. If it's some poser tech bro being insulting don't go after them for calling themselves an artist, call them out on being a douchebag period.
The companies that try to use this as an excuse to squeeze more content out of people for less money and the governments that don't address automation by installing a proper social safety net and support like UBI, or worse laugh at the idea they should? THEY are the problem. Not the technology and how it's going to change the arts, the commercial arts mainly
Matt Bors: An AI can't beat me. It can decimate weird twitter, punditry, portraiture, concept art. I will outflank it. I'll be drawing bizarre shit, getting outlandish with narrative structures. Stuff it can't piece together in a million years. A human is deranged and this is our magic.
Shane Chebsey: Can I ask a favour please.
Please do not include me in posts of Prompt Generated Imagery or ""AI art"" as it gets called.
I know it's not intentionally an attempt to annoy me, but I just don't want to see it anymore.
It's depressing and borderline offensive to me as an actual artist.
For those not aware, the use of ""AI art"" is plagerism of original art that it sources, and we don't need anymore of this in the artworld IMHO
I appreciate not everyone shares my view on this and I respect that.
Hell as I learn more I may even change my own view.
But until further notice I don't want to see that stuff.
I also understand it's hard to filter me out of your posts.
If you feel it's easier to just unfriend me that's cool. I won't be offended.
I know you're still my friend in the real world
Also I won't police my feed or anything giving shit to anyone who missed this post and I won't repeat this post.
I'm just hoping to get a reduction of it in my feed as it's getting me down.
Bruno Samper / Midjourney
Bruno Samper: On the set of 1984 secret collaboration movie between Jim Henson Studios and HR Giger. (All these images were produced with an AI )
Clydene Nee: Fairly alarming. Here is more artwork generated by Artificial intelligence. I can see why concept and storyboard artist would be extremely concerned.
It was a little disconcerting to see this artwork and to think of HR Giger being replaced by a computer.
Warwick Fraser-Coombe: From now on AI gets a block. Sick of seeing it.
Chip Zdarsky: AI makes it possible for my mother to turn her cat into a handsome renaissance gentleman and then spam me all day with the message ""lol I guess I'm an artist too"" and you're AGAINST that?
Erik Larsen: Here's the thing about AI ""art""– people are angry at the very idea and understandably so– it has to potential to adversely effect the livelihood of a lot of creative people.
Can't afford to hire Alex Ross? Well, how about a faux-Alex Ross that will do whatever you tell it to do? And if faux-Alex Ross is out there making comics– what becomes of the real Alex Ross? Does this harm his career? Does he become watered down by ""imitators?"" Is the real Alex replaced by a fake one every time he turns down a job?
I can see a lawsuit down the road and it's going to get ugly.
And while that aspect is frightening– I have to admit– if there were monthly comics which looked like Jack Kirby drew them I'd be all over those.
And then there's this– aspiring writers have had a problem finding an artist willing to illustrate their amateurish efforts since the dawn of the medium– AI will allow more people into the tent and let those writers who could never find an artist to still make comics. It has the potential to expand the talent pool by letting those unable to make comics be able to make comics.
And is this all that different from the advent of computer lettering, which put dozens of hand letterers out of work? Why was that okay but this a crime against humanity?
I suspect the vast majority of audience doesn't care as long as the end result is good. Few people REALLY take a moral stance when push comes to shove. Thousands of people who made practical special effects in movies lost their livelihoods with the advent of CGI effects. But we all didn't stop going to the movies in protest.
The crack is going to be when artist-you-know uses AI to draw backgrounds for a project or assist them in some way. It's inevitable. It's going to happen if it hasn't already and then what? Is a comic book with AI backgrounds but hand drawn lead characters going to be the tipping point? Where do we draw the line?
People are VERY angry about it. And I don't want to appear as though I'm taking sides with AI–but the harsh reality is that the bulk of the audience won't notice or care. Comic book creation is all magic to them anyway.
Mark Brooks: I can sit here and bitch about AI ""art"" while knowing there's really nothing I can do about it or I can see it for what it is and work harder to produce better art that a computer can't replicate. I may die trying but I choose option number two.
David Hine: The machine intelligence doesn't know what a human being looks like yet. It doesn't even know how many digits are on a human hand. It certainly doesn't know who Richard Corben or Salvador Dali were. It doesn't understand the concepts of beauty or the grotesque. That's no reason to dismiss the images it creates as rubbish. It does work incredibly well at producing strange abstract works that to me appear breathtakingly beautiful. These images began with prompting Corben and Dali, to which I added more layers by prompting for gardens, jewels and squid (squid always adds an interesting element – they don't really have a fixed form anyway) to get a series of amazing landscapes, of which I have included one example here. I'm working at the lowest resolution. The images look good on a phone but will be blurred on a larger screen. I do that for speed. I just want to see what these machines can do, not make reproducible artwork. The third image here is the last created. After adding numerous prompts I removed most of them to shift results from increasing complexity back to a simpler image (though I did keep the squid).
Kody Chamberlain: As a lifelong art fan, I now find myself skimming past most of the art I see online, assuming it's an AI dump. I'm super bummed about this gut reaction, and I'm doing my best to fight it, but it's there.
Adi Granov: A while ago it was NFT, now it's AI art. Why are artists such depressing doommongers?
Photo bashing, mood board collages, etc. have been around forever and used quite frequently on many jobs I've done. Why haven't they replaced designers and artists? Many animals and machines can run faster and jump higher, and be way more precise than people, buy we still watch athletes compete. Why do we prise mechanical watches and pay 100x more than for a far superior quartz?
We're asking the wrong questions. Artists and illustrators could've been replaced decades ago as the technology was there. We are humans and are wired to be impressed by human achievements as they fit within our own frame of reference and emotion. Emotion is the only key factor. Were it not so the only music around today would be made by computers, but somehow we still enjoy good playing and singing.
Andrew Wheeler: A.I. art isn't magic. All the elements are taken from real artists who are not compensated. A.I. art is theft.
Don Walker: I see a lot of people trying to tell artists we're not allowed to be angry that AI theft, I mean 'art' is threatening our livelihoods. Sure, it doesn't affect you (and you're probably using it in the dark like a coward). Sit down junior, you're embarrassing yourself.
Joe Wos: At first I hated the whole AI art thing, then after some attempts I realized it just cannot do what I do as far as mazes so I thought, well it's still icky but doesn't affect me. Now I've been able to verify many of my pieces appearing in the AI training database. So now I don't know how to feel about it!
I don't feel threatened by it. but it still feels icky.
Like they asked john Henry to train the steam drill before they replaced him.
Kelly McKernan: It's heckin discouraging to see AI generated images called ""art"" sold for profit while I have to scream into the void to sell a single painting I spent 35 hours on with my actual hands.
No, you are not an artist if you're selecting key words and relying on a program that's trained on actual artwork to create a ""new"" image. Even if you've got minimal PS skills (who doesn't?) and claim it's a paint over and then sell prints. NO. You're profiting off real artists.
No one asked for my consent to train their AI programs on my artwork. No one has offered royalties for every time my name is used for style input. While I firmly believe that AI art generators have a use in concepting and exploring ideas, it's unethical to profit off those images. It's a tool, not a medium, and using it to create ""new"" images does not an artist make.
Maybe this holiday season, give extra love to creators making art with their hands and fill your space with human made creations? Just some thoughts
Tyler Crook: Interesting that Adobe would support and profit from the unlicensed use of artists work to produce AI images but be opposed to the unlicensed use of Adobe software.
Mitch Gerads: All the Ai art profile images look like Lisa Frank got control of your Instagram filters.
Gordon Smuder: I see lots of folks talking about all the new AI art and trotting out the old chestnut, ""Artists have nothing to fear…its just another tool.""
When I was building props for a living, our shop did pretty well. We were making flawless props for still photography ads. There wasn't digital retouching back then, so it had to be perfect IN CAMERA. And we were skilled at it and paid well for those skills.
Then digital retouching came on strong. And it seemed like we were actually getting a little help here and there…our work didn't need to be *quite* so flawless anymore. We were kinda happy with this ""new tool"". It was making our work easier. But what we could charge for our work was slightly diminished.
Eventually, our work got MUCH easier. In fact, our custom props started to be almost secondary. The images of them became the digital fodder for the retouching guys to manipulate in post. Our work was just elements, now. And producers at agencies wanted their budgets to reflect that. They weren't willing to pay out for high quality work anymore. Because they could ""fix it in post"". We were being devalued by ""the tool"".
After that, the ad agencies stopped having us build props altogether. They created their ad campaigns around digitally manipulated stock photos. Props became superfluous and completely digitally rendered images became the vogue. They didn't need to pay us for anything anymore. It was all being built out of zeroes and ones. We were replaced.
And now, those digital artists that replaced us practical prop builders and photographers? Even they are being replaced. Not entirely at this moment, but eventually. That's what experience tells me I see just around the corner.
Producers at agencies will do whatever they can to cut the budget. Thats their purpose. The cheaper they can get whats needed, the more money is retained in-house. If this ""new tool"" gets to the point of refinement that they can rely on the algorithm to generate usable art, dont think for a second they won't cut out human artists altogether. They'll be replaced with a program that will spit out as many iterations of a project as they can feed in parameters for. On whatever schedule the agency wants to impose. An electronic artist that doesn't complain about deadlines or low pay or rights to their artwork or ridiculous client changes.
Go tsk tsk and shake your head all you like. Call me alarmist. But I've been to this dance before. Sure, it's only a tool. A tool that replaces talented humans.
Alex Dingley: i finally have a good excuse to practise drawing hands: can't have people think i use ai
Lilah Sturges: The current crop of ai takes advantage of being at a unique point in history in which a bunch of human-made shit is sitting there free for the taking to build models with. It seems like a free lunch but there ain't no such thing because humans will soon stop preparing the food… I'm not saying ai is bad or useless or necessarily ruinous. What I am saying is that tech that doesn't factor in the human impact of its existence is bound to lead somewhere bad and boneheaded because computers don't understand or care about the consequences of their actions.
José Villarrubia: Like many, many others, I have been playing around privately with new AI software like MidJourney and Stable Diffusion… It's addictive and scary at the same time. But I'm dismayed by fellow pros trying to ""pass"" their obviously computer generated images, wholly or in part, as ""hand painted"" or ""done in Photoshop"". You can totally tell when AI is being used. I feel that this is not helping with what's already a potentially alarming situation for artists…
Elizabeth Sandifer: I find myself thinking—somewhat cruelly, I'll admit—that the artists who are threatened by AI art are largely ones who built an extremely iteration-based career drawing specific categories of objects in a style that would sell, as opposed to ones driven by having something to say
Abraham Josephine Riesman: If you need free art for your newsletter or whatever, f-cking draw something! I don't care if you're not ""an artist""! Everyone can draw crude figures and they're more interesting to look at than this stolen hypersheen AI bullshit. There's likely going to be a WGA strike soon and I f-cking guarantee you there will be scripts written by AI and touched up by scabs
Roger Langridge: I can't get my head around this with AI art: • It composes its ""art"" by trawling for existing art to plagiarise • More and more art on the web is AI art • It ends up plagiarising *itself* more often than not How does it not just become exponentially worse by doing that?
Taylor Esposito: If you come to me with AI art and ask me to letter it, I'm charging you 10 times my rate. Clearly you have money to spend if you used AI art to not pay an artist.
Zan Christensen: All these AI portrait images going by has given me an idea.
Any of my talented art friends wanna do a quick portrait of me? Don't spend more than a few minutes; think of it like a convention sketch. Digital, pencil, ink, watercolor, pick your poison.
What's your commission rate? Check with me first! (I know too many talented folks who deserve big $$$ I may not have for this whim. )
I'll buy ten different ones and post them and write about how awesome you are in the description.









Matt Taylor: Me and @izzyburtonart spent yesterday evening making 100% AI FREE ™ self portraits. I have not painted a self portrait since high school, but it turned out okay I think? (Obviously Izzy is a way better painter than me too)
Clark Bint: How long will it be until we get a film franchise, provably a comic adaptation, based off a hugely successful AI art prompt? Will studios use AI art to test the market on what creates the most buzz and make films based on that? I don't like this potential future. Using AI art prompts to get work made is like being ruled by anxiety – actively skipping the hard parts to get to the point. The emotional ups and mostly downs of creating art is part of the process, and makes you grow as a person as you grow as an artist. Journey not destination
Matthew Southworth: AI art: we're fucked, artists, because a huge segment of the population either can't tell or, even worse, PREFERS auto-tuned vocals.
 
Jason Copland: I'm of the mind that no amount of fighting will stop the use of AI apps. I don't condone it but most people are always going to think of artists and their work as disposable and feel entitled to it in any form/format they want. It's fucking disgusting.
Matthew Southworth: I think so too; especially in an era where attention is increasingly fragmented, many people don't care about the differences
Kirk Lund: I hope and think humans will remain the primary or even exclusive creators of comics. Try to imagine any publisher paying 100 times more $ for pages produced by AI within the next 10-20 years. Someone would also need to invest huge $$$ in developing specialized comic-creating AI. Not likely, especially for a niche industry. Maybe some fancy texturing, coloring, backgrounds or animation options. Some publisher might use AI to help animate scenes from a comic, which I suppose would work best on comics using more dense, decompressed story-telling. I know you guys were discussing ""art"" in general and I tend to focus in on what I like… comics.
Matthew Southworth: Unfortunately, I think it'll hit comics as fast—or faster—than other areas. The money is sooo scarce that artists and publishers are bound to utilize any shortcuts possible. Years ago a certain DAREDEVIL artist was using photo backgrounds run thru a sketch filter & nobody minded. As an art experiment, it was interesting & appropriate for the book. This guy can draw like a sonofabitch, he's very good, but he found ways to get it done super-fast. Most of us have dabbled with 3D backgrounds, etc.; I'm not throwing stones from my Sketchup-designed glass house. But I hope that this may increase a hunger for handmade art in response. Just because we can get cheap furniture from Wal-Mart doesn't mean that's what we WANT in our houses, and I suppose we may find larger groups getting fed up with outlet mall ""art"", too.
Kirk Lund: I really hope I never see the majority of comics made by cylons, and I'd like to think I would be able to tell the difference at 10 paces. But, there is a percentage of comics buyers who never read anything they ""collect"", and that could feed the problem.
Jason Copland: Comics, and art in general, will be fine. People will want to support artist drawn books.
Matthew Southworth: We'll see. Music was devalued by making it into digital ""product"" in the minds of many ppl, and now the economic bottom has fallen out of the recorded music business for all but the verrrry very few; I can imagine a similar trajectory for comics (1/2)
—not to mention prose, when an app that takes prompts (""Teenage girl"" ""fighting Confederacy"" ""time travel"" ""laser sword"") assembles things into fake novels. It's coming. BUT I think there will always be some audience for hand,Ande art. God, I hope so.
Jason Copland: It will be more difficult to make a living but there will always be artist drawn comics that people will seek out and buy.
 JH Williams III: I honestly believe AI art will rise and then fall, eventually wither and die.
Matthew Southworth: I suspect it will survive in some form—but I do think it's sort a fad, too, like when everyone went crazy using that Prisma art filter on photos. Drum machines didn't go away, but people DID a start to understand the diff btw a DM & a real drummer, so that's a good sign.
Kirk Lund: Maybe next gen Siri and Alexa will need an allowance to feed their growing appetite for AI art and comics
Enjoyed this? Please share on social media!





            Stay up-to-date and support the site by following Bleeding Cool on Google News today!
        
",,,,,,,,2022-12-06T07:10:10-06:00,,,,,,"
This weekend, the Lensa app created by Prisma AI using went viral, a service that encourages you to upload images of your face and then concocts artificial intelligence AI portraits of you with Stable Diffusion in all manner of artistic styles, looks, and themes. It's been around for a while, but it has suddenly become very popular to upload such images as avatars online &ndash; which can then be attacked by those who disapprove of such services.

		
			#gallery-1 {
				margin: auto;
			}
			#gallery-1 .gallery-item {
				float: left;
				margin-top: 10px;
				text-align: center;
				width: 33%;
			}
			#gallery-1 img {
				border: 2px solid #cfcfcf;
			}
			#gallery-1 .gallery-caption {
				margin-left: 0;
			}
			/* see gallery_shortcode() in wp-includes/media.php */
		
		
			
				
			
				
				Kelly sue DeConnick Instagram
				
			
				
			
				
				Kelly sue DeConnick Instagram
				
			
				
			
				
				Kelly sue DeConnick Instagram
				
		

Aside from AI art criticism in general, taking away from real-life artists and also appropriating people's art and art styles without credit or compensation, there is criticism that the app reverts to sexualisation, and Prisma stated that they both own the work but also get the rights to use the uploaded photos in whatever way they wish. Here's some reaction posted by actual living comic book folk to social media recently.
Reilly Brown: Isn't it illegal for a computer program to just copy and paste code from another computer program? If in the case of AI generated images, visual art is essentially just a different form of programming code, wouldn't using it still be infringement?
Jimmie Robinson: I'm all for new tools in art creation. Even this new realm of text prompt apps. I'm all for people who want to explore and generate content, no matter what their skill level is in art. I'm all for it. I get it. I even want it.
The backlash, even if it's logical, correct and sincere is a waste of time. The cat is out the bag, the genie out the bottle, the milk already spilled.
Not saying people don't have the right to cast their opinion, because I am all for that, too. In fact, I encourage it. New art might emerge from those who rally against this new form. As the lyrics go, ""Your anger is a gift.""
But some of the vitriol I'm reading is asking for the elimination of the tools and apps, as if that will solve the problem they have with it. I won't quote, or name people, because that's not what this post is about.
This is about acceptance.
Art tools have morphed since paintings on cave walls. Nothing is done ""as it used to be"". In this digital era we will see art acceptance morph again. I'm honored to see it happening, just like the early days of photoshop, illustrator, direct-to-plate printing, and online comics. I'm an old fart and I find it fascinating to watch the evolution in real time.
In the 1990s, I recall seeing Scott McCloud stand before a huge room of industry professionals at a Pro/Con event in Oakland, Ca., telling them about the birth and potential of online comics. He was set upon with pitchforks and torches. And yet, here we are&hellip; giving out Eisner Awards to digital comics.
I know it's hard (and for some even alarming) to see change so quickly and broadcast so steadily to millions. But there it is. And it's early days. Kinks, quirks, issues and prompts still need to be ironed out.
But trust me, the day is coming when Ai art will be a standard, not just a gimmick. When sampling data from existing work will be a given with a shrug of the shoulders, no more than using a credit card online or ticking that box about online data and cookies.
So feed the internet with more Batman art for Ai prompts?
Or&hellip; find your art, your style, your vision.
Be unique. Be creative in ways outside the box.
The work will stand out, even if it's sampled.
Art is not mutually exclusive.
We can all play in the same sandbox.
Yes, even if that kid across the way is copying your answers on the test.
We still do the test.
Plus Size Superheroes and Villians as requested by Matty Blades
Mike Manley: I have been seeing AI comics now. At first they totally sucked but in the past month I've seen them getting better. And I'm wondering since it's only a matter of months I imagine till it's smart enough to ape any style if fans will care?
If you can have more George Perez comics or John Byrne comics in their style do you care if in the end it might take work from human artists? Choose any artist with a recognizable style.
As far as I can see what you need is the script and a layout person to layout the page and choose the shots. Then you are not interpreting the script but choosing the best example AI gives you for the panel. And a production person for lettering and prepress. Or just do it as a web comic.
It will be able in short order to replicate anyone's style. It already is doing it in illustration. The concept people are good and fucked. If you are not top tier like Moebius or Mead. And again will the consumer care?
I see it as three tiers of consumer. Casual fan. In and out in a few years or watches the average movie. Not a collector.
The next level who is a fan of specific stories or genres. Casual collecting.
Then the Uber fan or fanatic. Collectors. They collect runs, follow specific artists. They might be able in a subset group to know about anatomy or storytelling. Inkers over certain artists etc. buy art.
Will the fan carry a cart of books to have signed at the table of the prompters? AI won't be signing.
So the question becomes will supporters care about getting sketches? "" come back in an hour, give me you prompts"".
Are they just fans of the material or of the creators? We have never been faced with that question.
I feel at least half if not more of people who consume this won't. Maybe 30% will.
Jonathan Matthewson: A.I. Is to art what Autotune is to music.
Salgood Sam: We've been here before even, remember when synths, or remix culture first took off and old school musicians took issue each time with the users of the new tools calling themselves artists or musicians? How well did that age?
Do you still take umbrage at calling people who do remixes and beat tracks from sample artists? How about writers? Instillation artists?
There's a lot of issues around AI that I agree with but I think visual artists are somehow assuming people who've learned how to work the AI via prompt texts &ndash; which having tried I can tell you isn't as simple as you might imagine &ndash; are implying they drew the thing by calling themselves an artist.
There are a LOT of kinds of artists who never draw, or even directly make the raw materials they use but rather assemble and build things. All legitimately artists as well.
AI isn't likely going anywhere, as a working commercial artist in animation for my day job I expect at some point when the tools and it's output are more predictable and controllable, studios will expect designers like me to learn to incorporate it into our workflow.
It's not contrary to some of the toxic claims, going to totally replace humans, just like self checkout lines still need human attendants to deal with shit AI images have lots of issues and need someone who is capable of doing the work when it glitches or breaks down to be on hand.
To be truly independent of humans it would need a working mind of its own and that's simply not going to happen. Takes too much processing power. Like orders of magnitude more than say all the CPU and GPU currently being used by the crypto crowd, just to think and that's one unit. We'll build those eventually but that's NOT going to be used to make art of any kind outside of an experiment any time soon, far too expensive for the margins in the arts.
But the relatively dumb tools are coming, and the people who use them will need a specific skill set to use them well, they already are part of the work flow for all the amazing VFX and digital animation you see.
ALL the hair and water and complex natural things in animation you take for granted these days and bitch about when something like She Hulk is just slightly less convincing? That's all dealt with by dumb algorithmic AI much like the tools being used to make the fantasy art that's taking off now from things like Stable Diffusion.
it's here already.
The people who use those, those that start working fantasy and editorial jobs making images with them? Those people, some of them are going to be seen as and call themselves artists, and I think it's a legit term like it or not.
The issues it represents for other kinds of artists are serious, but mainly they are ones of IP and labor law, not petty shit like who gets to be called an artist.
And factcheck, no it's not plagiarizing work in the learning database, it's using it much the same way my students did when I told them to study past artists and those they admire, as many as you can, to learn how to make good art. The only time you get into plagiarizing territory, both with students and AI, is when they study too few and don't have enough verity in their influence. Think those bots that have been trained to imitate ONE artist specifically, and even branded with their name.
The target of any aggression should not be other workers, but the corporations and governments.
If you're attacking peers using tools, you're being fearful monkeys throwing shit at exactly the wrong people. If it's some poser tech bro being insulting don't go after them for calling themselves an artist, call them out on being a douchebag period.
The companies that try to use this as an excuse to squeeze more content out of people for less money and the governments that don't address automation by installing a proper social safety net and support like UBI, or worse laugh at the idea they should? THEY are the problem. Not the technology and how it's going to change the arts, the commercial arts mainly
Matt Bors: An AI can't beat me. It can decimate weird twitter, punditry, portraiture, concept art. I will outflank it. I'll be drawing bizarre shit, getting outlandish with narrative structures. Stuff it can't piece together in a million years. A human is deranged and this is our magic.
Shane Chebsey: Can I ask a favour please.
Please do not include me in posts of Prompt Generated Imagery or ""AI art"" as it gets called.
I know it's not intentionally an attempt to annoy me, but I just don't want to see it anymore.
It's depressing and borderline offensive to me as an actual artist.
For those not aware, the use of ""AI art"" is plagerism of original art that it sources, and we don't need anymore of this in the artworld IMHO
I appreciate not everyone shares my view on this and I respect that.
Hell as I learn more I may even change my own view.
But until further notice I don't want to see that stuff.
I also understand it's hard to filter me out of your posts.
If you feel it's easier to just unfriend me that's cool. I won't be offended.
I know you're still my friend in the real world
Also I won't police my feed or anything giving shit to anyone who missed this post and I won't repeat this post.
I'm just hoping to get a reduction of it in my feed as it's getting me down.
Bruno Samper / Midjourney
Bruno Samper: On the set of 1984 secret collaboration movie between Jim Henson Studios and HR Giger. (All these images were produced with an AI )
Clydene Nee: Fairly alarming. Here is more artwork generated by Artificial intelligence. I can see why concept and storyboard artist would be extremely concerned.
It was a little disconcerting to see this artwork and to think of HR Giger being replaced by a computer.
Warwick Fraser-Coombe: From now on AI gets a block. Sick of seeing it.
Chip Zdarsky: AI makes it possible for my mother to turn her cat into a handsome renaissance gentleman and then spam me all day with the message ""lol I guess I'm an artist too"" and you're AGAINST that?
Erik Larsen: Here's the thing about AI ""art""&ndash; people are angry at the very idea and understandably so&ndash; it has to potential to adversely effect the livelihood of a lot of creative people.
Can't afford to hire Alex Ross? Well, how about a faux-Alex Ross that will do whatever you tell it to do? And if faux-Alex Ross is out there making comics&ndash; what becomes of the real Alex Ross? Does this harm his career? Does he become watered down by ""imitators?"" Is the real Alex replaced by a fake one every time he turns down a job?
I can see a lawsuit down the road and it's going to get ugly.
And while that aspect is frightening&ndash; I have to admit&ndash; if there were monthly comics which looked like Jack Kirby drew them I'd be all over those.
And then there's this&ndash; aspiring writers have had a problem finding an artist willing to illustrate their amateurish efforts since the dawn of the medium&ndash; AI will allow more people into the tent and let those writers who could never find an artist to still make comics. It has the potential to expand the talent pool by letting those unable to make comics be able to make comics.
And is this all that different from the advent of computer lettering, which put dozens of hand letterers out of work? Why was that okay but this a crime against humanity?
I suspect the vast majority of audience doesn't care as long as the end result is good. Few people REALLY take a moral stance when push comes to shove. Thousands of people who made practical special effects in movies lost their livelihoods with the advent of CGI effects. But we all didn't stop going to the movies in protest.
The crack is going to be when artist-you-know uses AI to draw backgrounds for a project or assist them in some way. It's inevitable. It's going to happen if it hasn't already and then what? Is a comic book with AI backgrounds but hand drawn lead characters going to be the tipping point? Where do we draw the line?
People are VERY angry about it. And I don't want to appear as though I'm taking sides with AI&ndash;but the harsh reality is that the bulk of the audience won't notice or care. Comic book creation is all magic to them anyway.
Mark Brooks: I can sit here and bitch about AI ""art"" while knowing there's really nothing I can do about it or I can see it for what it is and work harder to produce better art that a computer can't replicate. I may die trying but I choose option number two.
David Hine:&nbsp;The machine intelligence doesn't know what a human being looks like yet. It doesn't even know how many digits are on a human hand. It certainly doesn't know who Richard Corben or Salvador Dali were. It doesn't understand the concepts of beauty or the grotesque. That's no reason to dismiss the images it creates as rubbish. It does work incredibly well at producing strange abstract works that to me appear breathtakingly beautiful. These images began with prompting Corben and Dali, to which I added more layers by prompting for gardens, jewels and squid (squid always adds an interesting element &ndash; they don't really have a fixed form anyway) to get a series of amazing landscapes, of which I have included one example here. I'm working at the lowest resolution. The images look good on a phone but will be blurred on a larger screen. I do that for speed. I just want to see what these machines can do, not make reproducible artwork. The third image here is the last created. After adding numerous prompts I removed most of them to shift results from increasing complexity back to a simpler image (though I did keep the squid).
Kody Chamberlain: As a lifelong art fan, I now find myself skimming past most of the art I see online, assuming it's an AI dump. I'm super bummed about this gut reaction, and I'm doing my best to fight it, but it's there.
Adi Granov: A while ago it was NFT, now it's AI art. Why are artists such depressing doommongers?
Photo bashing, mood board collages, etc. have been around forever and used quite frequently on many jobs I've done. Why haven't they replaced designers and artists? Many animals and machines can run faster and jump higher, and be way more precise than people, buy we still watch athletes compete. Why do we prise mechanical watches and pay 100x more than for a far superior quartz?
We're asking the wrong questions. Artists and illustrators could've been replaced decades ago as the technology was there. We are humans and are wired to be impressed by human achievements as they fit within our own frame of reference and emotion. Emotion is the only key factor. Were it not so the only music around today would be made by computers, but somehow we still enjoy good playing and singing.
Andrew Wheeler: A.I. art isn't magic. All the elements are taken from real artists who are not compensated. A.I. art is theft.
Don Walker: I see a lot of people trying to tell artists we're not allowed to be angry that AI theft, I mean 'art' is threatening our livelihoods. Sure, it doesn't affect you (and you're probably using it in the dark like a coward). Sit down junior, you're embarrassing yourself.
Joe Wos: At first I hated the whole AI art thing, then after some attempts I realized it just cannot do what I do as far as mazes so I thought, well it's still icky but doesn't affect me. Now I've been able to verify many of my pieces appearing in the AI training database. So now I don't know how to feel about it!
I don't feel threatened by it. but it still feels icky.
Like they asked john Henry to train the steam drill before they replaced him.
Kelly McKernan: It's heckin discouraging to see AI generated images called ""art"" sold for profit while I have to scream into the void to sell a single painting I spent 35 hours on with my actual hands.
No, you are not an artist if you're selecting key words and relying on a program that's trained on actual artwork to create a ""new"" image. Even if you've got minimal PS skills (who doesn't?) and claim it's a paint over and then sell prints. NO. You're profiting off real artists.
No one asked for my consent to train their AI programs on my artwork. No one has offered royalties for every time my name is used for style input. While I firmly believe that AI art generators have a use in concepting and exploring ideas, it's unethical to profit off those images. It's a tool, not a medium, and using it to create ""new"" images does not an artist make.
Maybe this holiday season, give extra love to creators making art with their hands and fill your space with human made creations? Just some thoughts
Tyler Crook: Interesting that Adobe would support and profit from the unlicensed use of artists work to produce AI images but be opposed to the unlicensed use of Adobe software.
Mitch Gerads: All the Ai art profile images look like Lisa Frank got control of your Instagram filters.
Gordon Smuder: I see lots of folks talking about all the new AI art and trotting out the old chestnut, ""Artists have nothing to fear&hellip;its just another tool.""
When I was building props for a living, our shop did pretty well. We were making flawless props for still photography ads. There wasn't digital retouching back then, so it had to be perfect IN CAMERA. And we were skilled at it and paid well for those skills.
Then digital retouching came on strong. And it seemed like we were actually getting a little help here and there&hellip;our work didn't need to be *quite* so flawless anymore. We were kinda happy with this ""new tool"". It was making our work easier. But what we could charge for our work was slightly diminished.
Eventually, our work got MUCH easier. In fact, our custom props started to be almost secondary. The images of them became the digital fodder for the retouching guys to manipulate in post. Our work was just elements, now. And producers at agencies wanted their budgets to reflect that. They weren't willing to pay out for high quality work anymore. Because they could ""fix it in post"". We were being devalued by ""the tool"".
After that, the ad agencies stopped having us build props altogether. They created their ad campaigns around digitally manipulated stock photos. Props became superfluous and completely digitally rendered images became the vogue. They didn't need to pay us for anything anymore. It was all being built out of zeroes and ones. We were replaced.
And now, those digital artists that replaced us practical prop builders and photographers? Even they are being replaced. Not entirely at this moment, but eventually. That's what experience tells me I see just around the corner.
Producers at agencies will do whatever they can to cut the budget. Thats their purpose. The cheaper they can get whats needed, the more money is retained in-house. If this ""new tool"" gets to the point of refinement that they can rely on the algorithm to generate usable art, dont think for a second they won't cut out human artists altogether. They'll be replaced with a program that will spit out as many iterations of a project as they can feed in parameters for. On whatever schedule the agency wants to impose. An electronic artist that doesn't complain about deadlines or low pay or rights to their artwork or ridiculous client changes.
Go tsk tsk and shake your head all you like. Call me alarmist. But I've been to this dance before. Sure, it's only a tool. A tool that replaces talented humans.
Alex Dingley: i finally have a good excuse to practise drawing hands: can't have people think i use ai
Lilah Sturges: The current crop of ai takes advantage of being at a unique point in history in which a bunch of human-made shit is sitting there free for the taking to build models with. It seems like a free lunch but there ain't no such thing because humans will soon stop preparing the food&hellip; I'm not saying ai is bad or useless or necessarily ruinous. What I am saying is that tech that doesn't factor in the human impact of its existence is bound to lead somewhere bad and boneheaded because computers don't understand or care about the consequences of their actions.
Jos&eacute; Villarrubia: Like many, many others, I have been playing around privately with new AI software like MidJourney and Stable Diffusion&hellip; It's addictive and scary at the same time. But I'm dismayed by fellow pros trying to ""pass"" their obviously computer generated images, wholly or in part, as ""hand painted"" or ""done in Photoshop"". You can totally tell when AI is being used. I feel that this is not helping with what's already a potentially alarming situation for artists&hellip;
Elizabeth Sandifer: I find myself thinking&mdash;somewhat cruelly, I'll admit&mdash;that the artists who are threatened by AI art are largely ones who built an extremely iteration-based career drawing specific categories of objects in a style that would sell, as opposed to ones driven by having something to say
Abraham Josephine Riesman: If you need free art for your newsletter or whatever, f-cking draw something! I don't care if you're not ""an artist""! Everyone can draw crude figures and they're more interesting to look at than this stolen hypersheen AI bullshit. There's likely going to be a WGA strike soon and I f-cking guarantee you there will be scripts written by AI and touched up by scabs
Roger Langridge: I can't get my head around this with AI art: &bull; It composes its ""art"" by trawling for existing art to plagiarise &bull; More and more art on the web is AI art &bull; It ends up plagiarising *itself* more often than not How does it not just become exponentially worse by doing that?
Taylor Esposito: If you come to me with AI art and ask me to letter it, I'm charging you 10 times my rate. Clearly you have money to spend if you used AI art to not pay an artist.
Zan Christensen: All these AI portrait images going by has given me an idea.
Any of my talented art friends wanna do a quick portrait of me? Don't spend more than a few minutes; think of it like a convention sketch. Digital, pencil, ink, watercolor, pick your poison.
What's your commission rate? Check with me first! (I know too many talented folks who deserve big $$$ I may not have for this whim. )
I'll buy ten different ones and post them and write about how awesome you are in the description.

		
			#gallery-2 {
				margin: auto;
			}
			#gallery-2 .gallery-item {
				float: left;
				margin-top: 10px;
				text-align: center;
				width: 50%;
			}
			#gallery-2 img {
				border: 2px solid #cfcfcf;
			}
			#gallery-2 .gallery-caption {
				margin-left: 0;
			}
			/* see gallery_shortcode() in wp-includes/media.php */
		
		
			
				
			
			
				
			
		

Matt Taylor: Me and @izzyburtonart spent yesterday evening making 100% AI FREE &trade; self portraits. I have not painted a self portrait since high school, but it turned out okay I think? (Obviously Izzy is a way better painter than me too)
Clark Bint: How long will it be until we get a film franchise, provably a comic adaptation, based off a hugely successful AI art prompt? Will studios use AI art to test the market on what creates the most buzz and make films based on that? I don't like this potential future. Using AI art prompts to get work made is like being ruled by anxiety &ndash; actively skipping the hard parts to get to the point. The emotional ups and mostly downs of creating art is part of the process, and makes you grow as a person as you grow as an artist. Journey not destination
Matthew Southworth: AI art: we're fucked, artists, because a huge segment of the population either can't tell or, even worse, PREFERS auto-tuned vocals.
&nbsp;
Jason Copland: I'm of the mind that no amount of fighting will stop the use of AI apps. I don't condone it but most people are always going to think of artists and their work as disposable and feel entitled to it in any form/format they want. It's fucking disgusting.
Matthew Southworth: I think so too; especially in an era where attention is increasingly fragmented, many people don't care about the differences
Kirk Lund: I hope and think humans will remain the primary or even exclusive creators of comics. Try to imagine any publisher paying 100 times more $ for pages produced by AI within the next 10-20 years. Someone would also need to invest huge $$$ in developing specialized comic-creating AI. Not likely, especially for a niche industry. Maybe some fancy texturing, coloring, backgrounds or animation options. Some publisher might use AI to help animate scenes from a comic, which I suppose would work best on comics using more dense, decompressed story-telling. I know you guys were discussing ""art"" in general and I tend to focus in on what I like&hellip; comics.
Matthew Southworth: Unfortunately, I think it'll hit comics as fast&mdash;or faster&mdash;than other areas. The money is sooo scarce that artists and publishers are bound to utilize any shortcuts possible. Years ago a certain DAREDEVIL artist was using photo backgrounds run thru a sketch filter &amp; nobody minded. As an art experiment, it was interesting &amp; appropriate for the book. This guy can draw like a sonofabitch, he's very good, but he found ways to get it done super-fast. Most of us have dabbled with 3D backgrounds, etc.; I'm not throwing stones from my Sketchup-designed glass house.&nbsp;But I hope that this may increase a hunger for handmade art in response. Just because we can get cheap furniture from Wal-Mart doesn't mean that's what we WANT in our houses, and I suppose we may find larger groups getting fed up with outlet mall ""art"", too.
Kirk Lund: I really hope I never see the majority of comics made by cylons, and I'd like to think I would be able to tell the difference at 10 paces. But, there is a percentage of comics buyers who never read anything they ""collect"", and that could feed the problem.
Jason Copland: Comics, and art in general, will be fine. People will want to support artist drawn books.
Matthew Southworth: We'll see. Music was devalued by making it into digital ""product"" in the minds of many ppl, and now the economic bottom has fallen out of the recorded music business for all but the verrrry very few; I can imagine a similar trajectory for comics (1/2)
&mdash;not to mention prose, when an app that takes prompts (""Teenage girl"" ""fighting Confederacy"" ""time travel"" ""laser sword"") assembles things into fake novels. It's coming. BUT I think there will always be some audience for hand,Ande art. God, I hope so.
Jason Copland: It will be more difficult to make a living but there will always be artist drawn comics that people will seek out and buy.
&nbsp;JH Williams III: I honestly believe AI art will rise and then fall, eventually wither and die.
Matthew Southworth: I suspect it will survive in some form&mdash;but I do think it's sort a fad, too, like when everyone went crazy using that Prisma art filter on photos. Drum machines didn't go away, but people DID a start to understand the diff btw a DM &amp; a real drummer, so that's a good sign.
Kirk Lund: Maybe next gen Siri and Alexa will need an allowance to feed their growing appetite for AI art and comics

",,,,,"{'cssSelector': '.headline', 'xpath': ""html/head/meta[@name='description']/@content"", '@context': 'http://schema.org', '@type': 'SpeakableSpecification'}",,,2022,
https://news.google.com/rss/articles/CBMiQGh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS13cml0aW5nLWFydC_SAQA?oc=5,AI Reveals the Most Human Parts of Writing - WIRED,2022-12-02,WIRED,https://www.wired.com,When do writers want help finding inspiration? And when do they want full control? Computers could expose the true future of the medium.,"['ideas', 'books', 'education', 'computer science', 'programming', 'computers', 'creative writing', 'artificial intelligence', 'textaboveleftgridwidth', 'web']",When do writers want help finding inspiration? And when do they want full control? Computers could expose the true future of the medium.,When do writers want help finding inspiration? And when do they want full control? Computers could expose the true future of the medium.,https://schema.org/,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://www.wired.com/story/artificial-intelligence-writing-art/'}",AI Reveals the Most Human Parts of Writing,https://www.wired.com/story/artificial-intelligence-writing-art/,2022-12-02T09:00:00.000-05:00,2022-12-02T09:00:00.000-05:00,,ideas,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",True,"[{'@type': 'Person', 'name': 'Katy Ilonka Gero', 'sameAs': 'https://www.wired.com/author/katy-ilonka-gero/'}]","['https://media.wired.com/photos/638950f41857496878b1b1eb/16:9/w_1184,h_666,c_limit/artificial-intelligence-human-writing.jpg', 'https://media.wired.com/photos/638950f41857496878b1b1eb/4:3/w_990,h_742,c_limit/artificial-intelligence-human-writing.jpg', 'https://media.wired.com/photos/638950f41857496878b1b1eb/1:1/w_777,h_777,c_limit/artificial-intelligence-human-writing.jpg']",,tags,N/A,"Katy Ilonka GeroIdeasDec 2, 2022 9:00 AMAI Reveals the Most Human Parts of WritingWhen do writers want help finding inspiration? And when do they want full control? Computers could expose the true future of the medium.Photo-illustration: WIRED Staff; Getty ImagesSave this storySaveSave this storySaveA woman has been working on her book, a young adult fantasy novel, for hours. At some point, she gets the familiar itch to check her email: She can’t think of what to write next. She stares at the screen. She’s lost her words. She could bang her head against the wall, or maybe turn to a favorite book for inspiration, or lose her momentum to distraction. But instead she turns to an AI writing tool, which takes in her chapter so far and spits out some potential next paragraphs. These paragraphs are never quite what she wants, though they sometimes contain beautiful sentences or fascinating directions. (Once it suggested a character sings a song, and also generated the lyrics of the song.) Even when these paragraphs fail, they make her interested in the story again. She’s curious about this computer-generated text, and it reignites her interest in her own writing.SUBSCRIBESubscribe to WIRED and stay smart with more of your favorite Ideas writers.With the advent of high quality computer-generated text, writers suddenly have a half-decent writing buddy who at least wants to do what they ask (even if it doesn’t always succeed) and has no desire to take any credit. Never before could writers get paragraphs of fluent text on a topic of their choice, except from another writer. (Ghostwriting may be an appropriate analogy for these writerly use cases of AI.) This is posing questions to writers everywhere: Which parts of writing are so tedious you’d be happy to see them go? Which parts bring you the inexplicable joy of creating something from nothing? And what is it about writing you hold most dear? AdChoicesADVERTISEMENTI’ve spent the past five years working with computer-generated text systems as part of my PhD work in human-AI interaction, and talking to writers about how they do—or do not—want to incorporate them into their practice. The woman above, working on her fantasy novel, is based on a woman I interviewed as part of a study on the social dynamics of writers requesting and incorporating support from computers.Featured VideoScam Fighters Answer Scam Questions From TwitterIt’s useful to think about three different parts of writing: planning, drafting, and revising. I consider these to be parts, and not stages, of writing; they are cognitive processes involved in writing, such that planning can occur at the beginning but also middle and even end of a writing project. By thinking through specific parts of writing, we can understand in more detail how computers will end up affecting writing as a whole. This exploration will not only help us understand the future of writing, but also help us create the kind of future we’re happy to live in.Let’s go back to the writer working on her first novel. She was happy to let a computer push her through writer’s block. But she was adamant that crafting the plot line was fundamentally human. The plot was the story she wanted to tell. This is where she felt her intention lay, what she workshopped and worked over. Other writers agree with her; there is a kind of problem-solving involved with figuring out where a story or poem or essay is going, and many writers feel they are uniquely positioned to solve such problems.But an AI writing system proposing a potential solution can be seen as a challenge, where the computer’s ideas would represent a low bar that the writer must improve on, a first step toward crafting an even better solution. One writer I interviewed was working on a TV pilot script. She was told, when it comes to TV and comedy, “If you feel like turning right, turn left.” Her writing had to be uniquely original, because people have seen so much TV already. No matter how good a computer-generated line of dialog might be, she felt she would always have to be better. She imagined using an AI writing system that would finish a scene for her, and then she’d know there would be something more unexpected and insightful she would have to find. Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenStill, in many cases, letting a computer impact the direction of a project, rather than craft a few choice sentences, can feel like giving the computer the reins when really, you want to feel in charge. Planning can also be enjoyable. Planning—and I include processes like figuring out plot points, endings, and openings, as well as any kind of activity on a higher level than actually writing—is something many writers consider the tricky, intellectual, and interesting part of their work, a part that feels uniquely human. Figuring out how a poem should end is difficult, but there are some difficult things we enjoy doing. The achievement of landing the end of a scene may only come from struggling to do it yourself.AdvertisementWhat about the tricky act of getting words on the page? In cognitive psychology research, this is often called “translating,” because we’re translating amorphous ideas into discrete words. Most writers, or really most people who have to write, know the feeling of a mind gone blank. The average writer trains themselves out of this fear, but no matter how many times you’ve put words on the page, you’re bound to encounter that moment when you don’t know what comes next. This is literally the task most computer systems are trained to do: predict what comes next. The role of AI writing systems as drafting buddies is a big departure from how writers typically get help, yet so far it is their biggest selling point and use case. Most writing tools available today will do some drafting for you, either by continuing where you left off or responding to a more specific instruction. SudoWrite, a popular AI writing tool for novelists, does all of these, with options to “write” where you left off, “describe” a highlighted noun, or “brainstorm” ideas based on a situation you describe. Systems like Jasper.ai or Lex will complete your paragraph or draft copy based on instructions, and Laika is similar but more focused on fiction and drama. These tools are good and getting better; an AI writing system is drawing on more text than any one person can read, and its ability to lean into the unexpected can be perfect for writers looking to make their writing feel more fresh. Computer-generated text has been likened to automatic writing, or a well-read but deranged parrot, giving it abilities almost tangential to those of human writers, perhaps even complementary abilities.Yet it’s interesting that so many AI writing systems are created to finish our sentence, or predict our next one, because when I’ve talked to writers about what they typically want help with, no one ever talks about asking a person to write for them. This isn’t the way writers typically interact with people when it comes to their work, even though it’s what computers are best at, and are mostly being used for right now. While some writers are eager to get sentences on demand, others are hesitant to let an external entity choose their words. As several writers told me, once something is on the page, it’s just a little bit harder to imagine anything else. This is one reason many writers don’t like to get feedback early on in a project; the work is too delicate, they need to shore up the idea such that others can see its potential. A computer, while not explicitly bringing its own intention, can disrupt the writer’s intention. And other writers simply take pride in sitting down and pumping out a thousand words. It’s like exercise. You need to keep it up, otherwise your skills atrophy.Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenWith so much focus on creation, few systems consider revision. Revision—this is where the average writer gets the most outside help. Barely any commercial systems have proposed generating feedback as a meaningful use of AI, but that may change as we discover how such technology, which is so good at finishing your sentences, can also generate interesting questions about your work. So while this technology isn’t quite at the forefront of our minds right now, I think it will be.A computational perspective on your work is an old idea dating back to early research on statistics in language, using the frequency of words like the and with to discover authorial fingerprints in essays. But new technologies will sound more like a person, able to note that you’ve introduced a new term without properly defining it, or perhaps describe why a scene might be moving too slowly. Most writers are eager to get eyes on their work, and a computational eye may feel less frightening than your best friend; the computer might judge you, but not in a way that’ll impact your future relationship with it. Some writers think workshopping with a computer might be akin to talking to yourself, in that it’s private and feels internal, that it might not feel like someone else is in the room. Computers may become early-stage editors, giving writers an ability to get feedback before showing their work to someone more important.But writers are also bound to mistrust computers because, after all, where is the computer coming from? We can stand all manner of sin when it comes to feedback as long as we can contextualize that the feedback is coming from that professor who never liked our work, or our friend who is always positive, or an editor with decades of experience. It will take some time for us to understand what the computer really brings and how often, or in what situations, we should trust it. Writers I have talked to worry about the normativity of AI writing systems, that they will reflect a straight white male perspective, but also fear a system attempting to represent another particular perspective that may lead to tokenization and stereotyping. In this way, computers will be in a bind, but system designers may find ways to bring context to a computer without needing to liken it to a person or identity group.I want to come back to this idea of what we hold most dear, and the human nature of writing. It’s easy to be for or against including computer-generated text in your work, but I predict the conversation will get much more nuanced as we encounter the various ways computers can impact our writing. Writers want to protect their authenticity and intention. It may be useful to think of computer-generated text as dancing with the writer’s text. Most writers aren’t against collaboration. They just want to be in control of their own dance. As long as the computer can match the writer’s footwork, writers are happy to let a computer contribute to the performance. But the moment the computer steps on the writer’s toes, writers may get spooked. A plot point here, a stunning sentence there, an editorial comment that pushes the writer a little further; no one task is off the table. But when a computer ends up changing what the writer set out to achieve, writers may start to wonder whether their vision is getting muddied by an entity that lacks any experience with the real world.Most PopularSecurityHow One Bad CrowdStrike Update Crashed the World’s ComputersBy Lily Hay NewmanSecurityDon’t Fall for CrowdStrike Outage ScamsBy Lily Hay NewmanCultureThe 19 Best Movies on Amazon Prime Right NowBy Matt KamenCultureThe 49 Best Shows on Netflix Right NowBy Matt KamenMy hope is that computer-generated text gives more people the chance to say what they want to say, to enact their own vision, whether that be through a system helping them with planning, drafting, revising, or something else entirely. I don’t think we’ll be seeing fully computer-generated books out-competing human authors any time soon—not because computers won’t be capable (though perhaps also that), but because I think we will, for a long time, be far more interested in what a person has to say.It’s also worth reflecting on computer-generated text from the perspective of a reader. When will computers start to interfere with our sense that a person, and not a machine, had something to tell us? It may be that readers, not writers, draw the line on what’s acceptable, but we haven’t gone far enough to have to make that decision. We may get there in this century, and we’re going to need to ask ourselves what about communicative intent is so important. If I have an idea for a novel, but the computer writes most of it, is it still my story? This question will not be answered with numbers about how many words I or the computer wrote. It’s going to be answered culturally; it’s going to be a feeling we have about where authenticity or truth really lies. But thinking more concretely about where computers can get involved will help us answer this question, and make sure we answer it in a way that respects what we really value about writing.Enter your email to get the Wired newsletterclose dialogRecommended NewsletterScienceYour weekly roundup of the best stories on health care, the climate crisis, genetic engineering, robotics, space, and more. Delivered on Wednesdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterScienceYour weekly roundup of the best stories on health care, the climate crisis, genetic engineering, robotics, space, and more. Delivered on Wednesdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialog",,,,,"https://media.wired.com/photos/638950f41857496878b1b1eb/3:2/w_2025,h_1350,c_limit/artificial-intelligence-human-writing.jpg","{'@type': 'CreativeWork', 'name': 'WIRED'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Ideas', 'item': 'https://www.wired.com/ideas/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Books', 'item': 'https://www.wired.com/tag/books/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI Reveals the Most Human Parts of Writing'}]",,,,,When do writers want help finding inspiration? And when do they want full control? Computers could expose the true future of the medium.,,"With the advent of high quality computer-generated text, writers suddenly have a half-decent writing buddy who at least wants to do what they ask (even if it doesn’t always succeed) and has no desire to take any credit. Never before could writers get paragraphs of fluent text on a topic of their choice, except from another writer. (Ghostwriting may be an appropriate analogy for these writerly use cases of AI.) This is posing questions to writers everywhere: Which parts of writing are so tedious you’d be happy to see them go? Which parts bring you the inexplicable joy of creating something from nothing? And what is it about writing you hold most dear?
I’ve spent the past five years working with computer-generated text systems as part of my PhD work in human-AI interaction, and talking to writers about how they do—or do not—want to incorporate them into their practice. The woman above, working on her fantasy novel, is based on a woman I interviewed as part of a study on the social dynamics of writers requesting and incorporating support from computers.
It’s useful to think about three different parts of writing: planning, drafting, and revising. I consider these to be parts, and not stages, of writing; they are cognitive processes involved in writing, such that planning can occur at the beginning but also middle and even end of a writing project. By thinking through specific parts of writing, we can understand in more detail how computers will end up affecting writing as a whole. This exploration will not only help us understand the future of writing, but also help us create the kind of future we’re happy to live in.
Let’s go back to the writer working on her first novel. She was happy to let a computer push her through writer’s block. But she was adamant that crafting the plot line was fundamentally human. The plot was the story she wanted to tell. This is where she felt her intention lay, what she workshopped and worked over. Other writers agree with her; there is a kind of problem-solving involved with figuring out where a story or poem or essay is going, and many writers feel they are uniquely positioned to solve such problems.
But an AI writing system proposing a potential solution can be seen as a challenge, where the computer’s ideas would represent a low bar that the writer must improve on, a first step toward crafting an even better solution. One writer I interviewed was working on a TV pilot script. She was told, when it comes to TV and comedy, “If you feel like turning right, turn left.” Her writing had to be uniquely original, because people have seen so much TV already. No matter how good a computer-generated line of dialog might be, she felt she would always have to be better. She imagined using an AI writing system that would finish a scene for her, and then she’d know there would be something more unexpected and insightful she would have to find.
Still, in many cases, letting a computer impact the direction of a project, rather than craft a few choice sentences, can feel like giving the computer the reins when really, you want to feel in charge. Planning can also be enjoyable. Planning—and I include processes like figuring out plot points, endings, and openings, as well as any kind of activity on a higher level than actually writing—is something many writers consider the tricky, intellectual, and interesting part of their work, a part that feels uniquely human. Figuring out how a poem should end is difficult, but there are some difficult things we enjoy doing. The achievement of landing the end of a scene may only come from struggling to do it yourself.
What about the tricky act of getting words on the page? In cognitive psychology research, this is often called “translating,” because we’re translating amorphous ideas into discrete words. Most writers, or really most people who have to write, know the feeling of a mind gone blank. The average writer trains themselves out of this fear, but no matter how many times you’ve put words on the page, you’re bound to encounter that moment when you don’t know what comes next. This is literally the task most computer systems are trained to do: predict what comes next.
The role of AI writing systems as drafting buddies is a big departure from how writers typically get help, yet so far it is their biggest selling point and use case. Most writing tools available today will do some drafting for you, either by continuing where you left off or responding to a more specific instruction. SudoWrite, a popular AI writing tool for novelists, does all of these, with options to “write” where you left off, “describe” a highlighted noun, or “brainstorm” ideas based on a situation you describe. Systems like Jasper.ai or Lex will complete your paragraph or draft copy based on instructions, and Laika is similar but more focused on fiction and drama.
These tools are good and getting better; an AI writing system is drawing on more text than any one person can read, and its ability to lean into the unexpected can be perfect for writers looking to make their writing feel more fresh. Computer-generated text has been likened to automatic writing, or a well-read but deranged parrot, giving it abilities almost tangential to those of human writers, perhaps even complementary abilities.
Yet it’s interesting that so many AI writing systems are created to finish our sentence, or predict our next one, because when I’ve talked to writers about what they typically want help with, no one ever talks about asking a person to write for them. This isn’t the way writers typically interact with people when it comes to their work, even though it’s what computers are best at, and are mostly being used for right now. While some writers are eager to get sentences on demand, others are hesitant to let an external entity choose their words. As several writers told me, once something is on the page, it’s just a little bit harder to imagine anything else. This is one reason many writers don’t like to get feedback early on in a project; the work is too delicate, they need to shore up the idea such that others can see its potential. A computer, while not explicitly bringing its own intention, can disrupt the writer’s intention. And other writers simply take pride in sitting down and pumping out a thousand words. It’s like exercise. You need to keep it up, otherwise your skills atrophy.
With so much focus on creation, few systems consider revision. Revision—this is where the average writer gets the most outside help. Barely any commercial systems have proposed generating feedback as a meaningful use of AI, but that may change as we discover how such technology, which is so good at finishing your sentences, can also generate interesting questions about your work. So while this technology isn’t quite at the forefront of our minds right now, I think it will be.
A computational perspective on your work is an old idea dating back to early research on statistics in language, using the frequency of words like the and with to discover authorial fingerprints in essays. But new technologies will sound more like a person, able to note that you’ve introduced a new term without properly defining it, or perhaps describe why a scene might be moving too slowly. Most writers are eager to get eyes on their work, and a computational eye may feel less frightening than your best friend; the computer might judge you, but not in a way that’ll impact your future relationship with it. Some writers think workshopping with a computer might be akin to talking to yourself, in that it’s private and feels internal, that it might not feel like someone else is in the room. Computers may become early-stage editors, giving writers an ability to get feedback before showing their work to someone more important.
But writers are also bound to mistrust computers because, after all, where is the computer coming from? We can stand all manner of sin when it comes to feedback as long as we can contextualize that the feedback is coming from that professor who never liked our work, or our friend who is always positive, or an editor with decades of experience. It will take some time for us to understand what the computer really brings and how often, or in what situations, we should trust it. Writers I have talked to worry about the normativity of AI writing systems, that they will reflect a straight white male perspective, but also fear a system attempting to represent another particular perspective that may lead to tokenization and stereotyping. In this way, computers will be in a bind, but system designers may find ways to bring context to a computer without needing to liken it to a person or identity group.
I want to come back to this idea of what we hold most dear, and the human nature of writing. It’s easy to be for or against including computer-generated text in your work, but I predict the conversation will get much more nuanced as we encounter the various ways computers can impact our writing. Writers want to protect their authenticity and intention. It may be useful to think of computer-generated text as dancing with the writer’s text. Most writers aren’t against collaboration. They just want to be in control of their own dance. As long as the computer can match the writer’s footwork, writers are happy to let a computer contribute to the performance. But the moment the computer steps on the writer’s toes, writers may get spooked. A plot point here, a stunning sentence there, an editorial comment that pushes the writer a little further; no one task is off the table. But when a computer ends up changing what the writer set out to achieve, writers may start to wonder whether their vision is getting muddied by an entity that lacks any experience with the real world.
My hope is that computer-generated text gives more people the chance to say what they want to say, to enact their own vision, whether that be through a system helping them with planning, drafting, revising, or something else entirely. I don’t think we’ll be seeing fully computer-generated books out-competing human authors any time soon—not because computers won’t be capable (though perhaps also that), but because I think we will, for a long time, be far more interested in what a person has to say.
It’s also worth reflecting on computer-generated text from the perspective of a reader. When will computers start to interfere with our sense that a person, and not a machine, had something to tell us? It may be that readers, not writers, draw the line on what’s acceptable, but we haven’t gone far enough to have to make that decision. We may get there in this century, and we’re going to need to ask ourselves what about communicative intent is so important. If I have an idea for a novel, but the computer writes most of it, is it still my story? This question will not be answered with numbers about how many words I or the computer wrote. It’s going to be answered culturally; it’s going to be a feeling we have about where authenticity or truth really lies. But thinking more concretely about where computers can get involved will help us answer this question, and make sure we answer it in a way that respects what we really value about writing.",,,,,,,,,
https://news.google.com/rss/articles/CBMifmh0dHBzOi8vaHVtYW5yaWdodHMuZ292LmF1L291ci13b3JrL3RlY2hub2xvZ3ktYW5kLWh1bWFuLXJpZ2h0cy9wdWJsaWNhdGlvbnMvZ3VpZGFuY2UtcmVzb3VyY2UtYWktYW5kLWRpc2NyaW1pbmF0aW9uLWluc3VyYW5jZdIBAA?oc=5,Guidance Resource: AI and Discrimination in Insurance - Australian Human Rights Commission,2022-12-01,Australian Human Rights Commission,https://humanrights.gov.au,Learn more about avoiding discriminatory conduct when using artificial intelligence for insurance pricing and underwriting decisions.,N/A,Learn more about avoiding discriminatory conduct when using artificial intelligence for insurance pricing and underwriting decisions.,N/A,https://schema.org,,,,,,,,,,,,,,N/A,N/A,"









Home


Our Work


Technology and Human Rights


Publications


                      Guidance Resource: AI and Discrimination in Insurance
                  




Guidance Resource: AI and Discrimination in Insurance














Technology and Human Rights






1st December, 2022















Hide
Show
                                  Menu
                              



Menu







Download (PDF)
            


              12.4MB (PDF)
            





Download (DOC)
            


              5MB (DOC)
            













Listen




        Share
        










Guidance resource
The Actuaries Institute and the Australian Human Rights Commission have partnered to produce this Guidance Resource on Artificial Intelligence (AI) and Discrimination in Insurance Pricing and Underwriting (the Guidance Resource).
AI promises faster and more intelligent decision-making. However, the use of AI carries with it certain risks, including the risk of discrimination.
Discrimination in AI
At the federal level, unlawful discrimination is prohibited by several key pieces of legislation. Yet there is recognition in most of these pieces of legislation that discrimination by insurers will not be unlawful in certain circumstances, broadly when it is reasonable and based on actuarial or statistical data. 
The Guidance Resource provides information on:

the key pieces of legislation
the risks of discrimination arising from the use of AI
how to mitigate these risks.

The Guidance Resource provides practical guidance for insurers on complying with the relevant legislation, as addressed in the resource, when using AI for insurance pricing and underwriting.


Tags
Technology
Privacy and Data
Artificial Intelligence





Hide
Show
                Menu
              



Menu




Menu Link







Download (PDF)
            


              12.4MB (PDF)
            





Download (DOC)
            


              5MB (DOC)
            










",,,,,,,,,,,,,"[{'@type': 'WebSite', '@id': 'https://humanrights.gov.au/our-work/technology-and-human-rights/publications/guidance-resource-ai-and-discrimination-insurance', 'name': 'Australian Human Rights Commission', 'url': 'https://humanrights.gov.au', 'publisher': {'@type': 'GovernmentOrganization', '@id': 'https://humanrights.gov.au', 'name': 'Australian human rights commission', 'url': 'https://humanrights.gov.au'}, 'inLanguage': 'English'}]",,,,,,,,,,
https://news.google.com/rss/articles/CBMikgFodHRwczovL21lZGl1bS5kYXRhZHJpdmVuaW52ZXN0b3IuY29tL3RvcC0xMC1haS1jb21wYW5pZXMtZm9yLTIwMjMtdG8td29yay1mb3ItdG9wLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvbXBhbmllcy10by13YXRjaC1pbi0yMDIzLWVjYjYyODM3YWEzN9IBAA?oc=5,Top 10 AI Companies For 2023 To Work For | Top Artificial Intelligence Companies To Watch In 2023 - DataDrivenInvestor,2022-12-06,DataDrivenInvestor,https://medium.datadriveninvestor.com,Top 10 AI Companies For 2023. Top Artificial Intelligence Companies To Watch In 2023. Top 10 artificial intelligence companies. Top ai companies in USA.,N/A,Unraveling the top artificial intelligence companies to watch in 2023,Unraveling the top artificial intelligence companies to watch in 2023,http://schema.org,NewsArticle,https://medium.datadriveninvestor.com/top-10-ai-companies-for-2023-to-work-for-top-artificial-intelligence-companies-to-watch-in-2023-ecb62837aa37,Top 10 AI Companies To Work For In 2023  | DataDrivenInvestor,https://medium.datadriveninvestor.com/top-10-ai-companies-for-2023-to-work-for-top-artificial-intelligence-companies-to-watch-in-2023-ecb62837aa37,2022-12-06T11:45:25.659Z,2022-12-08T04:02:21.664Z,,,"{'@type': 'Organization', 'name': 'DataDrivenInvestor', 'url': 'medium.datadriveninvestor.com', 'logo': {'@type': 'ImageObject', 'width': 308, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:616/1*OMF3fSqH8t4xBJ9-6oZDZw.png'}}",False,"{'@type': 'Person', 'name': 'Jason Aro', 'url': 'https://medium.datadriveninvestor.com/@JasonAro'}",['https://miro.medium.com/v2/da:true/resize:fit:1200/0*QEFkFrgGlRUvLrx7'],"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.meteredContent'}",N/A,N/A,"Member-only storyTop 10 AI Companies For 2023 To Work For | Top Artificial Intelligence Companies To Watch In 2023Unraveling the top artificial intelligence companies to watch in 2023Jason Aro·FollowPublished inDataDrivenInvestor·4 min read·Dec 6, 202250ListenSharePhoto by Steve Ding on UnsplashIn this article, we will unravel the Top Artificial Intelligence Companies To Watch In 2023.These well-established companies have set the standards for AI and ML in the current IT Industry and are proving their caliber time and again by utilizing the true potential of Artificial Intelligence and Machine Learning.Here is the list of Top 10 AI Companies For 202310. UiPathThe RPA market is estimated to be worth $38 billion, and UiPath offers distinct advantages over competitors because of its patented computer vision technology.UiPath Careers and Employment | UiPathStart coding from the very first days. Work on big challenges with experienced RPA developers, solutions architects…www.uipath.com9. DynatraceThe company estimated a market worth $285.42 million and is poised to grow revenue by roughly 20% annually through at least 2025.",Top 10 AI Companies To Work For In 2023  | DataDrivenInvestor,,,,,,,2022-12-06T11:45:25.659Z,,,,,,,,,,,,['Jason Aro'],,,ecb62837aa37
https://news.google.com/rss/articles/CBMiOWh0dHBzOi8vZ3VsZmJ1c2luZXNzLmNvbS9tb2hyZS1sYXVuY2hlcy1hdXRvbWF0ZWQtc3lzdGVtL9IBAA?oc=5,UAE: MoHRE launches automated system for employment contracts - Gulf Business,2022-12-06,Gulf Business,https://gulfbusiness.com,"MoHRE has adopted several technologies such as the awareness programme via the self-guidance service, the WhatsApp channel, smart mobile app.","['automation', 'mohre', 'technology']","MoHRE has adopted several technologies such as the awareness programme via the self-guidance service, the WhatsApp channel, smart mobile app.","MoHRE has adopted several technologies such as the awareness programme via the self-guidance service, the WhatsApp channel, smart mobile app.",https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'https://gulfbusiness.com/mohre-launches-automated-system/'}",UAE: MoHRE launches automated system for employment contracts,https://gulfbusiness.com/mohre-launches-automated-system/,2022-12-06T08:12:51Z,2022-12-07T06:06:32Z,,Technology,"{'@type': 'Organization', 'name': 'Gulf Business', 'logo': 'https://gulfbusiness.com/wp-content/uploads/2020/07/cropped-gb-new-fevicon-2020-1.png'}",,"[{'@type': 'Person', 'name': 'Divsha Bhat'}]","{'@type': 'ImageObject', 'url': 'https://gulfbusiness.com/wp-content/uploads/2022/12/2f3b4a75.jpg'}",,Technology,N/A,"


Home  Industry  Technology UAE: MoHRE launches automated system for employment contracts
In the first two days of the launch, more than 35,000 contracts have been completed



 

by Divsha Bhat 

December 6, 2022 















































 
The Ministry of Human Resources and Emiratisation (MoHRE) has launched an automated system to complete employment contracts without human intervention.
In the first two days of the launch, more than 35,000 contracts have been completed. These include new and renewed employment contracts that were approved following signature verification.
“The new system utilises advanced technologies to process and verify images, which reduces the duration per transaction from two days to just 30 minutes, while also minimising human error,” the ministry said.

 
In October 2017, the UAE Cabinet adopted the UAE National Strategy for Artificial Intelligence with the aim of enhancing government performance, accelerating transactions, and developing innovative working environments. The strategy will also focus on making the UAE government the first in the world to invest in artificial intelligence across vital sectors and provide 100 percent of its first-line services through AI.
In line with the UAE Centennial 2071 objectives, this strategy will serve as a foundation for future services and infrastructure in the UAE, a statement said.
MoHRE has adopted several technologies such as the awareness programme via the self-guidance service, the WhatsApp channel, the smart mobile app, the smart communication framework, the Nafis platform and the open data policy.
Customers can use the awareness programme for the self-guidance service via the ministry’s smart mobile app, which also provides more than 100 of the ministry’s services, powered by artificial intelligence and big data.
The ministry has also developed the smart communications system to become the first government entity to implement it proactively. It completes digital transactions with a remote work system and provides e-services around the clock. The system has smart features that allow checking attachments and transaction data.
Read: Sheikh Hamdan launches robotics and automation programme for Dubai


Tags

automation
MOHRE
Technology




0 Comments

































Divsha Bhat

December 6, 2022



















Share







Tweet







Share







Share












You might also like












Artificial Intelligence, Gadgets 
Samsung’s Fadi Abu Shamat on how AI is enhancing mobile experiences  






Artificial Intelligence, Gadgets 
Samsung AI: New Galaxy Z Fold6, Flip6 take foldables into the future  






Artificial Intelligence, Technology 
Core42, AIREV unveil OnDemand AI operating system  






Artificial Intelligence, Finance 
AI startup funding more than doubles in Q2, shows Crunchbase data  

",,,,,https://gulfbusiness.com/wp-content/uploads/2022/12/2f3b4a75-150x150.jpg,,,2022-12-06T08:12:51Z,,,,,"[{'@type': 'Organization', '@id': 'https://gulfbusiness.com/#organization', 'name': 'Gulf Business', 'url': 'https://gulfbusiness.com', 'logo': {'@type': 'ImageObject', '@id': 'https://gulfbusiness.com/#logo', 'url': 'https://gulfbusiness.com/wp-content/uploads/2022/08/gulf-business-logo.jpg', 'contentUrl': 'https://gulfbusiness.com/wp-content/uploads/2022/08/gulf-business-logo.jpg', 'caption': 'Gulf Business', 'inLanguage': 'en-US', 'width': '262', 'height': '52'}}, {'@type': 'WebSite', '@id': 'https://gulfbusiness.com/#website', 'url': 'https://gulfbusiness.com', 'name': 'Gulf Business', 'publisher': {'@id': 'https://gulfbusiness.com/#organization'}, 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://gulfbusiness.com/wp-content/uploads/2022/12/2f3b4a75.jpg', 'url': 'https://gulfbusiness.com/wp-content/uploads/2022/12/2f3b4a75.jpg', 'width': '930', 'height': '558', 'caption': 'Mohre', 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://gulfbusiness.com/mohre-launches-automated-system/#webpage', 'url': 'https://gulfbusiness.com/mohre-launches-automated-system/', 'name': 'MoHRE launches automated system for employment contracts', 'datePublished': '2022-12-06T12:12:51+04:00', 'dateModified': '2022-12-07T10:06:32+04:00', 'isPartOf': {'@id': 'https://gulfbusiness.com/#website'}, 'primaryImageOfPage': {'@id': 'https://gulfbusiness.com/wp-content/uploads/2022/12/2f3b4a75.jpg'}, 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://gulfbusiness.com/author/divsha-bhat/', 'name': 'Divsha Bhat', 'url': 'https://gulfbusiness.com/author/divsha-bhat/', 'image': {'@type': 'ImageObject', '@id': 'https://gulfbusiness.com/wp-content/uploads/2022/06/divsha.jpg', 'url': 'https://gulfbusiness.com/wp-content/uploads/2022/06/divsha.jpg', 'caption': 'Divsha Bhat', 'inLanguage': 'en-US'}, 'worksFor': {'@id': 'https://gulfbusiness.com/#organization'}}, {'@type': 'NewsArticle', 'headline': 'MoHRE launches automated system for employment contracts', 'keywords': 'mohre', 'datePublished': '2022-12-06T12:12:51+04:00', 'dateModified': '2022-12-07T10:06:32+04:00', 'author': {'@id': 'https://gulfbusiness.com/author/divsha-bhat/', 'name': 'Divsha Bhat'}, 'publisher': {'@id': 'https://gulfbusiness.com/#organization'}, 'description': 'MoHRE has adopted several technologies such as the awareness programme via the self-guidance service, the WhatsApp channel, smart mobile app.', 'copyrightYear': '2022', 'copyrightHolder': {'@id': 'https://gulfbusiness.com/#organization'}, 'name': 'MoHRE launches automated system for employment contracts', '@id': 'https://gulfbusiness.com/mohre-launches-automated-system/#richSnippet', 'isPartOf': {'@id': 'https://gulfbusiness.com/mohre-launches-automated-system/#webpage'}, 'image': {'@id': 'https://gulfbusiness.com/wp-content/uploads/2022/12/2f3b4a75.jpg'}, 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://gulfbusiness.com/mohre-launches-automated-system/#webpage'}}]",,,,,,,['Divsha Bhat'],,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmxhdGludGltZXMuY29tL2hlcmVzLWhvdy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1ncm93aW5nLXRocmVhdC1hdXRoZW50aWNpdHktYXJ0LTUzNTY1MtIBAA?oc=5,Here's How Artificial Intelligence is a Growing Threat to Authenticity In Art - LatinTimes,2022-12-06,LatinTimes,https://www.latintimes.com,Pretty auto-generated pictures have been circulating like wildfire on social media apps like Instagram and Twitter lately. But is the latest trend a growing threat to authenticity in art ?,"['AI Generated Art', 'AI ART', 'Artificial intelligence', 'Artificial-intelligence generated art', 'Stable Diffusion', 'Lensa App Magic Avatar', 'Artificial-intelligence art controversy', 'What is AI art', 'Midjourney', 'Night Cafe', 'And DALL – E 2', 'Art generator', 'Lensa AI']",Pretty auto-generated pictures have been circulating like wildfire on social media apps like Instagram and Twitter lately. But is the latest trend a growing threat to authenticity in art ?,Pretty auto-generated pictures have been circulating like wildfire on social media apps like Instagram and Twitter lately. But is the latest trend a growing threat to authenticity in art ?,http://schema.org,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://www.latintimes.com/heres-how-artificial-intelligence-growing-threat-authenticity-art-535652'}",Here’s How Artificial Intelligence is a Growing Threat to Authenticity In Art,https://www.latintimes.com/heres-how-artificial-intelligence-growing-threat-authenticity-art-535652,2022-12-06T08:53:31-05:00,2022-12-06T09:05:02-05:00,,News,"{'@type': 'NewsMediaOrganization', 'name': 'Latin Times', 'url': 'https://www.latintimes.com', 'logo': {'@type': 'ImageObject', 'url': 'https://g.latintimes.com/themes/favicons/apple-touch-icon.png', 'width': 180, 'height': 180}, 'sameAs': ['https://www.facebook.com/TheLatinTimes/', 'https://www.linkedin.com/company/ibt-media', 'https://www.pinterest.com/latintimes/', 'https://twitter.com/latin_times_']}",True,"[{'@type': 'Person', 'name': 'Nadya Martinez', 'url': 'https://www.latintimes.com/reporters/nadya-martinez'}]","[{'@type': 'ImageObject', 'url': 'https://d.latintimes.com/en/full/535624/1661956681982-screen-shot-2022-08-30-102800-pm.jpg?w=1600&h=900&q=88&f=4f3dffcd8d034b9598648df082586fd5', 'width': 1600, 'height': 900, 'caption': 'SCREENGRAB: DISCORD'}, {'@type': 'ImageObject', 'url': 'https://d.latintimes.com/en/full/535624/1661956681982-screen-shot-2022-08-30-102800-pm.jpg?w=1600&h=1200&q=88&f=55c49325afece5f5a85d0de1fd69f711', 'width': 1600, 'height': 1200, 'caption': 'SCREENGRAB: DISCORD'}, {'@type': 'ImageObject', 'url': 'https://d.latintimes.com/en/full/535624/1661956681982-screen-shot-2022-08-30-102800-pm.jpg?w=1600&h=1600&q=88&f=b30c7ca43a7fa004a89463921b9be90b', 'width': 1600, 'height': 1600, 'caption': 'SCREENGRAB: DISCORD'}]",,News,N/A,"

Robots Become Racist And Sexist Bigots Due To Flawed AI, Study Says
SCREENGRAB: DISCORD
The topic of artificially generated art (AI art) has been making waves within the tech and art industries as the growing popularity of the auto-generated pictures raise concerns for the threat to the authenticity of art. If you've been on social media lately, you have probably witnessed all the pretty auto-generated pictures that have been circulating like wildfire on apps like Instagram and Twitter. While interesting from a tech standpoint, people forget the ethical implications of using this kind of software: Where does the data come from? AI-generated data function by pulling samples of art from the internet and the images that are generated by artificial intelligence (AI) is based on user text prompts and common keywords that can be used by literally anyone, which raises the questions is it ethical, plagiarism, and infringing upon artists rights?While AI art is not necessarily a new development, many new AI art programs such as Dream, Night Cafe and Midjourney have become increasingly popular. The viral Lensa App “Magic Avatar,” and  DALL-E Mini saw traffic skyrocket with unique avatars or funny renditions that look like they were created by an actual digital artist. Additionally, the quality of AI art has exceedingly improved generating better results. Unfortunately these apps are making a profit while the works of millions of artists are available online for free for these programs to use without the artists’ consent. It all began with the release of DALL-E 2, an improved AI art program from OpenAI.The program allowed users to input text descriptions and produce images that users considered amazing, adorable, or incredibly strange.Why would using this type of software be a problem ?Well not every image on the internet is public domain, and the images being used for these algorithms are directly reused in its output. This is extremely frustrating to professional artists, as the works of millions of artists are available online for free for these software to use their work without their consent. Another underlying issue is the fact that anyone can simply type in a prompt and make AI-generated work, a huge job security concern for human artists already struggling in a difficult field to make a living in.
@megraeart ARTISTS NEED YOUR HELP!PLEASE SHARE ON YOUR STORIES AND BOOKMARK
megraeart
It’s all fun and games until people start selling these AI as works of their own - “artwork” presented as original creations in art contests, museums etc., or have the audacity to bully actual artists for their rightful concerns and frustrations with the emerging tech. Copying by AI was not consented to by the artists, and despite the booming tech industry, there’s a lack of compensation for legitimate artists.Users can create all kinds of “artwork” with just a few key words, including some that are clearly evocative of the works of countless artists. Users can literally invoke those artists by simply typing “in the style of” or “by” along with a specific name. The current uses for these tools can range from personal amusement to more commercial cases, with millions of users flocking to text-to-image AI systems. They have already been used to create magazine covers, news stories, experimental films, advertising campaigns and more, which is troublesome to human artists, designers, and journalists. There have already been cases of images generated with an AI system winning awards and competitions sparking backlash and an uproar among artists, which we’ll delve into further in a bit.What exactly is AI ART?AI art refers to art generated with the assistance of artificial intelligence. AI is a field of computer science that focuses on building machines that mimic human intelligence or even simulate the human brain through a set of algorithms. Programs like Midjourney, Night Cafe, and DALL – E 2 are art generators that create art based on the prompts that have been given, basically you describe something in a sentence - it goes to the bot, the bot sources and analyzes numerous images, and out comes a result, sometimes in seconds. The generators use algorithms that analyze thousands of art pieces from different artists, in order to create unique works through specific rules through which machines analyze thousands of images to comprehend a particular creation process, like a specific style or aesthetic. The algorithms then generate novel forms, shapes, figures, and patterns to produce new works. Besides machines, AI artists also collaborate with creative coders, statisticians, computer scientists, and neuroscientists to build machines that push the boundaries of human creativity.Example of AI-generated art made with WOMBO Dream
Prompt Cornfield at sunset wombo.art
wombo.art
What is the purpose of using AI in art?Companies and enthusiasts try to market it as “Expanding human creativity” but in reality AI should not be used in place of Art, but instead used as a tool for reference. Some artists and designers have actually embraced the power of these tools. Some illustrators and visual artists use AI tools to generate ideas, gather inspiration, and experiment. While AI-generated art does inspire creativity, and enthusiasm, as it approaches mass consumption, it becomes an enormous question of ethics and becomes a huge disruption in creative industries.“It can be a beneficial utility for creative industries. It’s already used in various industries, such as advertising, marketing, gaming, architecture, fashion, graphic design, and product design. This Twitter thread provides a variety of use cases, from commerce to the medical imaging domain.” - TECH DIRTWhere is the data coming from?Many artists and industry professionals have been taking to Twitter and other social platforms to express their outrage about the controversial tech, and hopefully expose some of the harsh truths to a broader audience.
The generators for these AI software analyze thousands of images, paintings and other sources of art in order to create these “unique works.” In an interview with a multimedia reporter, Jim Ovelmen, an animation professor at Cal State LA, who has used AI art programs like Midjourney expressed his apprehension.“Another thing that bothered me was that in some of the AI-generated stuff, you could actually see the signature,” said Ovelmen. “The fact you can see someone’s signature in the echochamber of all the thousands of images it’s creating means it was somehow sampled by some individual artist’s signature.” The issue with how the algorithms take from thousands of artists’ works and how crediting comes into play is another part of the AI art debate.A student breaks it down it layman’s terms: “It’s kind of like a booklet of all these artists that showcase their arts, and then you start cutting those pieces out and just putting it on one collage,” said Felix Mach, a third-year animation major. “The machine has this huge collection of pieces from other artists, and it’s hard for you to credit those artists because it’s just from a library.”
Why is using AI Art controversial?There needs to be a much stricter regulation of AI art programs, especially when it comes to what sources they are allowed to pull sample data from, and how the works the programs generate may be used in a commercial capacity. In theory the apps aren’t harmful per se, and  as mentioned above there can be beneficial applications for it in creative fields. However, taking artwork from creators to use as data without permission and allowing anyone who can simply type a sentence to steal aspects of artists’ work for their own gain is ethically and irresponsible. Artificial intelligence should help artists, not steal their work and hurt their career prospects. Many artists have spent countless hours in education, practice and mastering skills in order to create artwork based off their dedication and knowledge. Putting words into a machine to generate pictures off of someone's work is insulting on so many levels. As it stands, many artists have already expressed their genuine concern over the possibility that AI can replace human artists. While some may see this fear as an “exaggeration,” it could all be alleviated by practical regulations and responsible practices if these AI developers cared enough. It’s extremely worrisome that anyone - having no skill, talent, experience, or drive whatsoever can simply enter a prompt and profit from it. Programs such as Starryai -(Generate art _ simply by describing what you want to see and our Artificial Intelligence transforms your words into art) - advertise that users will have full ownership of any images generated using their program and that they can use those images for commercial purposes. Essentially this means that anyone who enters a sufficiently descriptive prompt can profit off an image that was generated using the work of artists who were not asked for permission or paid for their work. While humans are directly using the software, they are not doing the actual creation, drawing, or painting of the work themselves. This brings up the questions of authorship and plagiarism when AI work is being published and submitted and not properly disclosed as such.
Detrimental to human artist According to an article from CNN, a number of artists found out their work was used to train AI and they are furious. Erin Hanson, a McMinnville, Oregon,based artist is one of many professional artists whose work was included in the data that was essentially used to train Stable Diffusion, the London-based Stability AI. She’s one of the several artists that were interviewed by CNN Business, and were unhappy to learn that pictures of their work were used without being informed for consent, or paying for their use. Another artist Danger, whose artwork includes posters for bands like Phish and Primus, is one of several professionals that told CNN Business “they worry that AI image generators could threaten their livelihoods.” Danger goes on to say - “Why are we going to pay an artist $1,000 when we can have 1,000 [images] to pick from for free?” he asked. “People are cheap.” A name known well to many in the comic convention community, Tara McPherson, the Pittsburgh-based artist whose work is featured on toys, clothing and in films, ""is also concerned about the possibility of losing out on some work to AI. She feels disappointed and “taken advantage of” for having her work included in the dataset behind Stable Diffusion without her knowledge, she said.
AI art is being banned in some art communitiesAI Aart is being banned from some art communities as website are being flooded with generative pics according to an article from Stealth Optical. Communities are “performing sweeping bans” as “Small art communities such as Newgrounds, Fur Affinity and more are fighting against the generative content being uploaded online.” The article goes on to express how established artist who are already finding it difficult to make ends meet in the modern gig community gig have to deal with the growing AI issue. “AI-powered artwork is pushing some artists away in favour of automation. Even if it isn’t always perfect.”An AI won an art contest infuriating artistsOne of the biggest ethical controversies over AI is the submission of AI generated work being submitted for contests. An AI won an art contest, and artists are furious according to CNN Business. In August, a game designer sparked controversy after his artificial-intelligence- generated art piece - Theatre D’opera Spatial image won the top spot at a competition in the United States with critics calling the win a threat to human artists everywhere. Allen, a game designer who lives in Pueblo West, Colorado, won first place in the emerging artist division’s “digital arts/digitally-manipulated photography” category at the Colorado State Fair Fine Arts Competition, beating more than a dozen other entries. The win sparking controversy about whether art can be generated by a computer, and what, exactly, it means to be an artist.“This sucks for the exact same reason we don’t let robots participate in the Olympics,” one Twitter user wrote.“This is the literal definition of ‘pressed a few buttons to make a digital art piece’,” another Tweeted. “AI artwork is the ‘banana taped to the wall’ of the digital world now.”
While AI-generated art inspires creativity, and enthusiasm, it can have detrimental affects on the human art community. As it reaches the masses it can suffer many consequences, some of which can be flat out terrifying. Changes and regulations need to be assessed now.
RELATED STORIESPower To Use Killer Robots Attained By San Francisco Police© 2024 Latin Times. All rights reserved. Do not reproduce without permission.Tags:
Artificial intelligence
",,,,,https://d.latintimes.com/en/full/535624/1661956681982-screen-shot-2022-08-30-102800-pm.jpg,,"[{'@type': 'ListItem', 'position': 1, 'name': 'News', 'item': 'https://www.latintimes.com/news'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial intelligence', 'item': 'https://www.latintimes.com/topic/artificial-intelligence'}]",,,,,The Dangers and Ethical Issues Using A.I. Generated Art,,"The topic of artificially generated art (AI art) has been making waves within the tech and art industries as the growing popularity of the auto-generated pictures raise concerns for the threat to the authenticity of art. If you've been on social media lately, you have probably witnessed all the pretty auto-generated pictures that have been circulating like wildfire on apps like Instagram and Twitter. While interesting from a tech standpoint, people forget the ethical implications of using this kind of software: Where does the data come from? AI-generated data function by pulling samples of art from the internet and the images that are generated by artificial intelligence (AI) is based on user text prompts and common keywords that can be used by literally anyone, which raises the questions is it ethical, plagiarism, and infringing upon artists rights?&nbsp;While AI art is not necessarily a new development, many new AI art programs such as Dream, Night Cafe and Midjourney have become increasingly popular. The viral Lensa App &ldquo;Magic Avatar,&rdquo; and &nbsp;DALL-E Mini saw traffic skyrocket with unique avatars or funny renditions that look like they were created by an actual digital artist. Additionally, the quality of AI art has exceedingly improved generating better results. Unfortunately these apps are making a profit while the works of millions of artists are available online for free for these programs to use without the artists&rsquo; consent. It all began with the release of DALL-E 2, an improved AI art program from OpenAI.The program allowed users to input text descriptions and produce images that users considered amazing, adorable, or incredibly strange.Why would using this type of software be a problem ?Well not every image on the internet is public domain, and the images being used for these algorithms are directly reused in its output. This is extremely frustrating to professional artists, as the works of millions of artists are available online for free for these software to use their work without their consent. Another underlying issue is the fact that anyone can simply type in a prompt and make AI-generated work, a huge job security concern for human artists already struggling in a difficult field to make a living in.It&rsquo;s all fun and games until people start selling these AI as works of their own - &ldquo;artwork&rdquo; presented as original creations in art contests, museums etc., or have the audacity to bully actual artists for their rightful concerns and frustrations with the emerging tech. Copying by AI was not consented to by the artists, and despite the booming tech industry, there&rsquo;s a lack of compensation for legitimate artists.Users can create all kinds of &ldquo;artwork&rdquo; with just a few key words, including some that are clearly evocative of the works of countless artists. Users can literally invoke those artists by simply typing &ldquo;in the style of&rdquo; or &ldquo;by&rdquo; along with a specific name. The current uses for these tools can range from personal amusement to more commercial cases, with millions of users flocking to text-to-image AI systems. They have already been used to create magazine covers, news stories, experimental films, advertising campaigns and more, which is troublesome to human artists, designers, and journalists. There have already been cases of images generated with an AI system winning awards and competitions sparking backlash and an uproar among artists, which we&rsquo;ll delve into further in a bit.What exactly is AI ART?AI art refers to art generated with the assistance of artificial intelligence. AI is a field of computer science that focuses on building machines that mimic human intelligence or even simulate the human brain through a set of algorithms. Programs like Midjourney, Night Cafe, and DALL &ndash; E 2 are art generators that create art based on the prompts that have been given, basically you describe something in a sentence - it goes to the bot, the bot sources and analyzes numerous images, and out comes a result, sometimes in seconds. The generators use algorithms that analyze thousands of art pieces from different artists, in order to create unique works through specific rules through which machines analyze thousands of images to comprehend a particular creation process, like a specific style or aesthetic. The algorithms then generate novel forms, shapes, figures, and patterns to produce new works. Besides machines, AI artists also collaborate with creative coders, statisticians, computer scientists, and neuroscientists to build machines that push the boundaries of human creativity.Example of AI-generated art made with WOMBO DreamWhat is the purpose of using AI in art?Companies and&nbsp;enthusiasts&nbsp;try to market it as &ldquo;Expanding human creativity&rdquo; but in reality AI should not be used in place of Art, but instead used as a tool for reference. Some artists and designers have actually embraced the power of these tools. Some illustrators and visual artists use AI tools to generate ideas, gather inspiration, and experiment. While AI-generated art does inspire creativity, and enthusiasm, as it approaches mass consumption, it becomes an enormous question of ethics and becomes a huge disruption in creative industries.&nbsp;&ldquo;It can be a beneficial utility for creative industries. It&rsquo;s already used in various industries, such as advertising, marketing, gaming, architecture, fashion, graphic design, and product design. This Twitter thread provides a variety of use cases, from commerce to the medical imaging domain.&rdquo; - TECH DIRTWhere is the data coming from?Many artists and industry professionals have been taking to Twitter and other social platforms to express their outrage about the controversial tech, and hopefully expose some of the harsh truths to a broader audience.The generators for these AI software analyze thousands of images, paintings and other sources of art in order to create these &ldquo;unique works.&rdquo; In an interview with a multimedia reporter, Jim Ovelmen, an animation professor at Cal State LA, who has used AI art programs like Midjourney expressed his apprehension.&nbsp;&ldquo;Another thing that bothered me was that in some of the AI-generated stuff, you could actually see the signature,&rdquo; said Ovelmen. &ldquo;The fact you can see someone&rsquo;s signature in the echochamber of all the thousands of images it&rsquo;s creating means it was somehow sampled by some individual artist&rsquo;s signature.&rdquo; The issue with how the algorithms take from thousands of artists&rsquo; works and how crediting comes into play is another part of the AI art debate.A student breaks it down it layman&rsquo;s terms: &ldquo;It&rsquo;s kind of like a booklet of all these artists that showcase their arts, and then you start cutting those pieces out and just putting it on one collage,&rdquo; said Felix Mach, a third-year animation major. &ldquo;The machine has this huge collection of pieces from other artists, and it&rsquo;s hard for you to credit those artists because it&rsquo;s just from a library.&rdquo;Why is using AI Art controversial?&nbsp;There needs to be a much stricter regulation of AI art programs, especially when it comes&nbsp;to what sources they are allowed to pull sample data from, and how the works the programs generate may be used in a commercial capacity. In theory the apps aren&rsquo;t harmful per se, and&nbsp; as mentioned above there can be beneficial applications for it in creative fields. However, taking artwork from creators to use as data without permission and allowing anyone who can simply type a sentence to steal aspects of artists&rsquo; work for their own gain is ethically and irresponsible. Artificial intelligence should help artists, not steal their work and hurt their career prospects. Many artists have spent countless hours in education, practice and mastering skills in order to create artwork based off their dedication and knowledge. Putting words into a machine to generate pictures off of someone's work is insulting on so many levels.&nbsp;As it stands, many artists have already expressed their genuine concern over the possibility that AI can replace human artists. While some may see this fear as an &ldquo;exaggeration,&rdquo; it could all be alleviated by practical regulations and responsible practices if these AI developers cared enough. It&rsquo;s extremely worrisome that anyone - having no skill, talent, experience, or drive whatsoever can simply enter a prompt and profit from it. Programs such as Starryai -(Generate art _ simply by describing what you want to see and our Artificial Intelligence transforms your words into art) - advertise that users will have full ownership of any images generated using their program and that they can use those images for commercial purposes. Essentially this means that anyone who enters a sufficiently descriptive prompt can profit off an image that was generated using the work of artists who were not asked for permission or paid for their work.&nbsp;While humans are directly using the software, they are not doing the actual creation, drawing, or painting of the work themselves. This brings up the questions of authorship and plagiarism when AI work is being published and submitted and not properly disclosed as such.Detrimental to human artist&nbsp;According to an article from CNN, a number of artists found out their work was used to train AI and they are furious. Erin Hanson, a McMinnville, Oregon,based artist is one of many professional artists whose work was included in the data that was essentially used to train Stable Diffusion, the London-based Stability AI. She&rsquo;s one of the several artists that were interviewed by CNN Business, and were unhappy to learn that pictures of their work were used without being informed for consent, or paying for their use. Another artist Danger, whose artwork includes posters for bands like Phish and Primus, is one of several professionals that told CNN Business &ldquo;they worry that AI image generators could threaten their livelihoods.&rdquo; Danger goes on to say - &ldquo;Why are we going to pay an artist $1,000 when we can have 1,000 [images] to pick from for free?&rdquo; he asked. &ldquo;People are cheap.&rdquo; A name known well to many in the comic convention community, Tara McPherson, the Pittsburgh-based artist whose work is featured on toys, clothing and in films, ""is also concerned about the possibility of losing out on some work to AI. She feels disappointed and &ldquo;taken advantage of&rdquo; for having her work included in the dataset behind Stable Diffusion without her knowledge, she said.AI art is being banned in some art communitiesAI Aart is being banned from some art communities as website are being flooded with generative pics according to an article from Stealth Optical. Communities are &ldquo;performing sweeping bans&rdquo; as &ldquo;Small art communities such as Newgrounds, Fur Affinity and more are fighting against the generative content being uploaded online.&rdquo; The article goes on to express how established artist who are already finding it difficult to make ends meet in the modern gig community gig have to deal with the growing AI issue. &ldquo;AI-powered artwork is pushing some artists away in favour of automation. Even if it isn&rsquo;t always perfect.&rdquo;An AI won an art contest infuriating artists&nbsp;One of the biggest ethical controversies over AI is the submission of AI generated work being submitted for contests. An AI won an art contest, and artists are furious according to CNN Business. In August, a game designer sparked controversy after his artificial-intelligence- generated art piece - Theatre D&rsquo;opera Spatial image won the top spot at a competition in the United States with critics calling the win a threat to human artists everywhere. Allen, a game designer who lives in Pueblo West, Colorado, won first place in the emerging artist division&rsquo;s &ldquo;digital arts/digitally-manipulated photography&rdquo; category at the Colorado State Fair Fine Arts Competition, beating more than a dozen other entries. The win sparking controversy about whether art can be generated by a computer, and what, exactly, it means to be an artist.&ldquo;This sucks for the exact same reason we don&rsquo;t let robots participate in the Olympics,&rdquo; one Twitter user wrote.&ldquo;This is the literal definition of &lsquo;pressed a few buttons to make a digital art piece&rsquo;,&rdquo; another Tweeted. &ldquo;AI artwork is the &lsquo;banana taped to the wall&rsquo; of the digital world now.&rdquo;While AI-generated art inspires creativity, and enthusiasm, it can have detrimental affects on the human art community. As it reaches the masses it can suffer many consequences, some of which can be flat out terrifying. Changes and regulations need to be assessed now.",,,,,,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,headline,url,dateCreated,datePublished,dateModified,articleSection,wordCount,mainEntityOfPage,publisher,thumbnailUrl,image,creator,author,itemListElement,name,address,article:section,article:summary,article text,@graph,articleBody,isAccessibleForFree,isPartOf,speakable,video,text,logo,inLanguage,alternativeHeadline
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMTgvMDIvMjEvMTQ1Mjg5L3RoZS1nYW5mYXRoZXItdGhlLW1hbi13aG9zLWdpdmVuLW1hY2hpbmVzLXRoZS1naWZ0LW9mLWltYWdpbmF0aW9uL9IBeWh0dHBzOi8vd3d3LnRlY2hub2xvZ3lyZXZpZXcuY29tLzIwMTgvMDIvMjEvMTQ1Mjg5L3RoZS1nYW5mYXRoZXItdGhlLW1hbi13aG9zLWdpdmVuLW1hY2hpbmVzLXRoZS1naWZ0LW9mLWltYWdpbmF0aW9uL2FtcC8?oc=5,The GANfather: The man who’s given machines the gift of imagination - MIT Technology Review,2018-02-21,MIT Technology Review,https://www.technologyreview.com,"By pitting neural networks against one another, 
Ian Goodfellow has created a powerful AI tool. Now he, and the rest of us, must face the consequences.",,"By pitting neural networks against one another, 
Ian Goodfellow has created a powerful AI tool. Now he, and the rest of us, must face the consequences.","By pitting neural networks against one another, 
Ian Goodfellow has created a powerful AI tool. Now he, and the rest of us, must face the consequences.",http://schema.org,Organization,The GANfather: The man who’s given machines the gift of imagination,https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/,2018-02-21T12:00:00-05:00,2018-02-21T12:00:00-05:00,2020-04-02T16:13:11-04:00,Artificial intelligence,1839.0,"{'@type': 'WebPage', '@id': 'https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/'}","{'@type': 'Organization', 'name': 'MIT Technology Review', 'logo': {'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/themes/mittr/client/src/images/logo.png', 'width': 203, 'height': 100}}","https://wp.technologyreview.com/wp-content/uploads/2018/02/ma18-iangoodfellow1-7.png?resize=854,569","{'@type': 'ImageObject', 'url': 'https://wp.technologyreview.com/wp-content/uploads/2018/02/ma18-iangoodfellow1-7.png?resize=854,569', 'height': 569, 'width': 854}","{'@type': 'Person', 'name': 'Martin Giles'}","{'@type': 'Person', 'name': 'Martin Giles'}","[{'@type': 'ListItem', 'position': 1, 'name': 'Artificial intelligence', 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/topic/artificial-intelligence/'}}, {'@type': 'ListItem', 'position': 2, 'name': ""The GANfather: The man who's given machines the gift of imagination"", 'item': {'@type': 'Thing', '@id': 'https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/'}}]",MIT Technology Review,"{'@type': 'PostalAddress', 'addressLocality': 'Cambridge, MA, USA', 'postalCode': '02142', 'streetAddress': '1 Main Street'}",N/A,N/A,N/A,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTmh0dHBzOi8vdGhlYnVsbGV0aW4ub3JnLzIwMTgvMDIvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLW5hdGlvbmFsLXNlY3VyaXR5L9IBAA?oc=5,Artificial intelligence and national security - Bulletin of the Atomic Scientists,2018-02-21,Bulletin of the Atomic Scientists,https://thebulletin.org,"From Harvard University's Belfer Center, this study of artificial intelligence and its likely security implications is an outstanding one-stop primer on the subject.",N/A,"From Harvard University's Belfer Center, this study of artificial intelligence and its likely security implications is an outstanding one-stop primer on the subject.",N/A,https://schema.org,,,,,,,,,,,,,,,,,,N/A,N/A,"


","[{'@type': 'WebPage', '@id': 'https://thebulletin.org/2018/02/artificial-intelligence-and-national-security/', 'url': 'https://thebulletin.org/2018/02/artificial-intelligence-and-national-security/', 'name': 'Artificial intelligence and national security - Bulletin of the Atomic Scientists', 'isPartOf': {'@id': 'https://thebulletin.org/#website'}, 'primaryImageOfPage': {'@id': 'https://thebulletin.org/2018/02/artificial-intelligence-and-national-security/#primaryimage'}, 'image': {'@id': 'https://thebulletin.org/2018/02/artificial-intelligence-and-national-security/#primaryimage'}, 'thumbnailUrl': 'https://thebulletin.org/wp-content/uploads/2018/02/front-image-from-JM_1.jpg.webp', 'datePublished': '2018-02-21T06:00:00+00:00', 'dateModified': '2020-03-19T16:01:11+00:00', 'author': {'@id': 'https://thebulletin.org/#/schema/person/9ad60a49e4d4dbe799eb5ddeee54aceb'}, 'description': ""From Harvard University's Belfer Center, this study of artificial intelligence and its likely security implications is an outstanding one-stop primer on the subject."", 'breadcrumb': {'@id': 'https://thebulletin.org/2018/02/artificial-intelligence-and-national-security/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://thebulletin.org/2018/02/artificial-intelligence-and-national-security/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://thebulletin.org/2018/02/artificial-intelligence-and-national-security/#primaryimage', 'url': 'https://thebulletin.org/wp-content/uploads/2018/02/front-image-from-JM_1.jpg.webp', 'contentUrl': 'https://thebulletin.org/wp-content/uploads/2018/02/front-image-from-JM_1.jpg.webp', 'width': 600, 'height': 777}, {'@type': 'BreadcrumbList', '@id': 'https://thebulletin.org/2018/02/artificial-intelligence-and-national-security/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://thebulletin.org/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Disruptive Technologies', 'item': 'https://thebulletin.org/disruptive-technologies/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Technology and Security', 'item': 'https://thebulletin.org/disruptive-technologies/technology-and-security/'}, {'@type': 'ListItem', 'position': 4, 'name': 'Artificial intelligence and national security'}]}, {'@type': 'WebSite', '@id': 'https://thebulletin.org/#website', 'url': 'https://thebulletin.org/', 'name': 'Bulletin of the Atomic Scientists', 'description': 'The Bulletin&#039;s content is both influential and understandable--an authoritative guide that confronts man-made threats to our existence. Visit the Bulletin for the latest thinking on nuclear risk, climate change, and disruptive technologies.', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://thebulletin.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://thebulletin.org/#/schema/person/9ad60a49e4d4dbe799eb5ddeee54aceb', 'name': 'Lucien Crowder', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://thebulletin.org/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/8d35645a609ed0086eb948d97c9e0252?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/8d35645a609ed0086eb948d97c9e0252?s=96&d=mm&r=g', 'caption': 'Lucien Crowder'}, 'url': 'https://thebulletin.org/author/lucien-crowder/'}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiW2h0dHBzOi8vd3d3LmJvc3Rvbm1hZ2F6aW5lLmNvbS9uZXdzLzIwMTgvMDIvMjMvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmFjZS1kYXJrLXNraW4tYmlhcy_SAQA?oc=5,"MIT Researcher: Artificial Intelligence Has a Race Problem, and We Need to Fix It - Boston magazine",2018-02-23,Boston magazine,https://www.bostonmagazine.com,"MIT researcher Joy Buolamwini says artificial intelligence systems that scan people's faces are poisoned with bias, and it's a big problem.",MIT,She says artificial intelligence systems are poisoned with bias.,She says artificial intelligence systems are poisoned with bias.,http://schema.org,NewsArticle,"MIT Researcher: Artificial Intelligence Has a Race Problem, and We Need to Fix It",,,2018-02-23T10:42:49-05:00,2018-02-24T17:13:25-05:00,News,,"{'@type': 'WebPage', '@id': 'https://www.bostonmagazine.com/news/2018/02/23/artificial-intelligence-race-dark-skin-bias/'}","{'@type': 'Organization', 'name': 'Boston Magazine', 'logo': {'@type': 'ImageObject', 'url': 'https://www.bostonmagazine.com/wp-content/themes/metrocorp-bostonmagazine/images/logo-bostonmag.png'}}",,"{'@type': 'ImageObject', 'url': 'https://www.bostonmagazine.com/wp-content/uploads/sites/2/2018/02/mit-gender-shades-3.jpg', 'height': 600, 'width': 900}",,"[{'@type': 'Person', 'name': 'Spencer Buell'}]",,,,N/A,N/A,"

MIT Researcher: Artificial Intelligence Has a Race Problem, and We Need to Fix It
The next generation of AI is poisoned with bias against dark skin, Joy Buolamwini says.
 

							By Spencer Buell· 

										2/23/2018, 10:42 a.m.									




 



			Get a compelling long read and must-have lifestyle tips in your inbox every Sunday morning — great with coffee!		

Sign up for Boston Daily. News. Commentary. Every day.*



photo by Bryce VickmarkArtificial intelligence is increasingly affecting our lives in ways most of us haven’t even thought about. Even if we don’t have emotional androids plotting revenge on humankind (yet), we’re surrounded more and more by computers trained to look us over and make life-changing decisions about us. Some of the brightest minds in technology—including a hive of them clustered around Boston—are tinkering with machines designed to decide what kinds of ads we see, whether we get flagged by the police, whether we get a job, or even how long we spend behind bars.But they have a very big problem: Many of these systems don’t work properly, or at all, for people with dark skin.AdChoicesADVERTISINGIn a newly published report, MIT Media Lab researcher Joy Buolamwini says she’s found that face-analyzing AI works significantly better for white faces than black ones. She and co-author Timnit Gebru tested software from Microsoft, IBM, and the Chinese company Megvii to see how well each of their face-scanning systems did at figuring out whether a person in a picture was a man or a woman—a task all three are supposed to be able to perform. If the person in the photo was a white man, her study found, the systems guessed correctly more than 99 percent of the time. For black women, though, the systems messed up between 20 and 34 percent of the time—which, if you consider that guessing at random would mean being right 50 percent of the time, means they came close to not working at all.How could that be? Buolamwini says the problem lies out of sight, buried deep in the code that runs this technology. Face-analysis programs, she says, are trained and tested using databases of hundreds of pictures, which research has found are overwhelmingly white and male. So a developer might not notice that their software doesn’t work for someone who isn’t white or male. To prove this, Buolamwini decided to test the systems by using a database of her own, which she made using the headshots of hundreds of world leaders, including many from African countries with dark skin. Then she asked the AI systems to identify whether each headshot was of a man or a woman. That’s when the disparity began to show itself: The systems repeatedly misidentified the black faces, even though they had almost no trouble at all recognizing the white ones. Not that it’s exactly a surprise. “Being that I’m a dark-skinned woman,” she tells me, “I’m running into these issues all over the place.”The findings were compiled into a project called Gender Shades and will be presented at the Conference on Fairness, Accountability, and Transparency at New York University, which kicks off on Friday.We should all be concerned about what she found.“People of color are in fact the global majority. The majority of the world, who I like to call the under-sampled majority, aren’t being represented within the training data or the benchmark data used to validate artificial intelligence systems,” Buolamwini says. “We’re fooling ourselves about how much progress we’ve made.”Imagine if your skin tone could trigger glitches in services like HireVue, which analyzes the facial expressions of job applicants; or in surveillance systems that use AI to identify people in crowds (like the one used on unwitting Boston Calling concertgoers in 2014); or the face-recognition system currently being test-run at Logan Airport; or in the systems used by law enforcement to trawl through Massachusetts drivers’ license photos.Frankly, it’s not clear whether any of these systems should exist at all. How good do we really want robots to be at tracking our every move? But at the very least, if these things are going to be part of our lives, they’d better work. If not, the consequences could be severe.“You’re in a situation where the community most likely to be targeted by law enforcement are least represented [in face-recognition code]. This puts people at higher risk of being misidentified as a criminal suspect,” Buolamwini says. “Because we live in a society that reflects historical biases that are continuing to this day, we have to confront the kind of data we’re generating, the kind of data we’re collecting, how we’re analyzing it. And we need to do it with diverse eyes in the room, diverse experiences, and more gender parity.”Last year, the ACLU identified “algorithmic bias” as an area of particular concern for civil liberties advocates in the future. “This is not remotely the first time that we’ve seen a product developed using machine learning or a risk assessment tool that has different impacts on people, depending on who they are: their race, their class,” says Kade Crockford, director of the ACLU of Massachusetts’ Technology for Liberty program. “Civil rights, civil liberties, and freedom of speech, and privacy tend to be afterthoughts when systems like this are being developed. What we really need to see is an ethical, civil rights and civil liberties approach to building these systems from the ground up.” The group’s local chapter has also pushed for Community Control of Police Surveillance ordinances in Massachusetts cities that would require that any new surveillance tools get public approval before they are implemented.There are other impacts of technology that only works correctly for white people. By now you’ve probably seen the videos and heard the stories about soap dispensers that won’t dispense soap into dark-skinned hands, or artificial intelligence that tries to identify African-American faces and yields some deeply unfortunate results. Examples of this problem also predate AI, Buolamwini says. Photography for most of its history has been optimized for white skin. It wan’t until backlash from manufacturers of chocolate and dark wooden furniture in the 1970s and 1980s that Kodak, which basically ran the photography industry, updated its film, and we’re still making progress on this front in the era of digital cameras and selfies (just ask interracial couples). Movies with properly lit black actors are still a relatively new phenomenon.Buolamwini knows this problem well. She still remembers when, as an undergrad at Georgia Tech, she couldn’t complete her work with a new face-tracking robot because it couldn’t make sense of her face. She was forced to ask her light-skinned roommate, who the robot could see, to step in. It wasn’t the last time this happened, and eventually she made the disheartening discovery that many face-recognizing systems would only work if she wore a featureless white mask. The poetry of that wasn’t lost on her, and she’s turned that mask into a symbol of what she’s dubbed the “coded gaze” baked into AI. The mask was a centerpiece of her popular TED Talk (which has been viewed nearly a million times) and is featured in the logo for a group she founded to call attention to the issue, the Algorithmic Justice League (you can see it next to her in the above photo).Meanwhile, Buolamwini says she’s been encouraged by some of the reactions her study has gotten. IBM, she says, reached out almost immediately after her results were published and invited her to meet with some of its senior researchers. The tech giant tells her that in the newest update of its software, it improved its ability to recognize black women’s faces by a factor of 10. Microsoft has also responded to the Gender Shades research, saying it has “taken steps to improve the accuracy of our facial recognition technology and we’re continuing to invest in research to recognize, understand and remove bias.”There’s a long way to go. So she’s focused on getting us to think twice about what’s going on in the rapidly advancing brains that power artificial intelligence, before it’s too late.“We have blind faith in these systems,” she says. “We risk perpetuating inequality in the guise of machine neutrality if we’re not paying attention.”Correction: An earlier version of this story misidentified the college Buolamwini attended for her undergraduate degree. It was Georgia Tech, not MIT.
 


										Read More About:									

MIT 

 


Spencer Buell 
Staff Writer at Boston Magazine
 @spencerbuell

sbuell@bostonmagazine.com




You Might Also Like


 
 

Top Places to Live 2024: Where to Find a Deal in Greater Boston’s Sky-High Market







 
 

Want to Experiment with AI? Here’re 15 Tools To Get Started at Home




 
 

An Early-Risers Guide to Boston





Sponsor Content


Learn to Diversify Beyond Just Stocks and Bonds 

by 
         
             BNY Wealth
        





Sponsor Content


She Was Born Like That: 19+ Celebrities Who Embraced Their U 

by 
         
             StandardNews
        



 



",,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDE4LzIvMjEvMTcwMzYyMTQvZWxvbi1tdXNrLW9wZW5haS1haS1zYWZldHktbGVhdmVzLWJvYXJk0gEA?oc=5,Elon Musk leaves board of AI safety group to avoid conflict of interest with Tesla - The Verge,2018-02-21,The Verge,https://www.theverge.com,"Musk will remain a donor and adviser to the group, which focuses on AI safety and ethics.",N/A,"Musk will remain a donor and adviser to the group, which focuses on AI safety and ethics. ",N/A,http://schema.org/,NewsArticle,Elon Musk leaves board of AI safety group to avoid conflict of interest with Tesla,https://www.theverge.com/2018/2/21/17036214/elon-musk-openai-ai-safety-leaves-board,,2018-02-21T16:57:33.000Z,2018-02-21T16:57:33.000Z,,,,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",https://cdn.vox-cdn.com/thumbor/Twt-PS5aNndm3S4eznaX6HfUpdE=/0x0:4671x3313/1400x788/filters:focal(2336x1657:2337x1658)/cdn.vox-cdn.com/uploads/chorus_asset/file/10270035/855370170.jpg.jpg,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/Twt-PS5aNndm3S4eznaX6HfUpdE=/0x0:4671x3313/1400x788/filters:focal(2336x1657:2337x1658)/cdn.vox-cdn.com/uploads/chorus_asset/file/10270035/855370170.jpg.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/-OJO12RHMDilKidpUxet6xAQXwI=/0x0:4671x3313/1400x1050/filters:focal(2336x1657:2337x1658)/cdn.vox-cdn.com/uploads/chorus_asset/file/10270035/855370170.jpg.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/EMv0omOHKwetcUsxIJSnZSVG7II=/0x0:4671x3313/1400x1400/filters:focal(2336x1657:2337x1658)/cdn.vox-cdn.com/uploads/chorus_asset/file/10270035/855370170.jpg.jpg', 'width': 1400, 'height': 1400}]",,"[{'@type': 'Person', 'name': 'James Vincent', 'url': 'https://www.theverge.com/authors/james-vincent'}]",,,,N/A,N/A,"Tech/Artificial Intelligence/TranspoElon Musk leaves board of AI safety group to avoid conflict of interest with TeslaElon Musk leaves board of AI safety group to avoid conflict of interest with Tesla / Musk will remain a donor to the nonprofit organization, which focuses on AI safety and ethicsBy  James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge. Feb 21, 2018, 11:57 AM ESTShare this story0 Comments / 0 New Photo by Mark Brake/Getty ImagesTech billionaire Elon Musk is leaving the board of OpenAI, the nonprofit research group he co-founded with Y Combinator president Sam Altman to study the ethics and safety of artificial intelligence. The move was announced in a short blog post, explaining that Musk is leaving in order to avoid a conflict of interest between OpenAI’s work and the machine learning research done by Telsa to develop autonomous driving. “As Tesla continues to become more focused on AI, this will eliminate a potential future conflict for Elon,” says the post. Musk will stay on as a donator to OpenAI and will continue to advise the group. The blog post also announced a number of new donors, including video game developer Gabe Newell, Skype founder Jaan Tallinn, and the former US and Canadian Olympians Ashton Eaton and Brianne Theisen-Eaton. OpenAI said it was broadening its base of funders in order to ramp up investments in “our people and the compute resources necessary to make consequential breakthroughs in artificial intelligence.” For those concerned about the near-term impact of AI on areas like surveillance and propaganda, this work is crucial. OpenAI was founded just two years ago, but has fast become a significant voice in the global machine learning community. Its research has been wide-ranging, including teaching computers to control robots with minimal instruction (known as “one-shot learning”) and the creation of AI agents to play popular video game Dota (a more daunting challenge than board games like chess). Just this week, the institute contributed to a multi-disciplinary report outlining the ways AI could be used maliciously over the next five years. (A different and much realer set of concerns than the specter of evil superintelligent AI sometimes raised by figures including Musk himself.) But for an organization concerned with keeping advances in artificial intelligence safe, OpenAI certainly has its work cut out. Comments0 Comments / 0 NewFeatured Videos From The VergeApple’s Vision Pro: five months later | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge’s David Pierce chats with Victoria Song and Wes Davis about using the Vision Pro for the five months that it's been available to the public. The group details what works, what doesn’t, and what’s next for the device. David then chats with the folks at Sandwich Vision, who create Vision Pro apps called Television and Theater, about why they made 3D-rendered versions of CRT TVs in virtual reality.Most PopularMost PopularMax might not be the one to watch after allThis is Sonos’ next flagship soundbarNo Xbox, no problemChum King ExpressSamsung Galaxy Watch Ultra hands-on: ultra déjà vuVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",,"Tech billionaire Elon Musk is leaving the board of OpenAI, the nonprofit research group he co-founded with Y Combinator president Sam Altman to study the ethics and safety of artificial intelligence. 

The move was announced in a short blog post, explaining that Musk is leaving in order to avoid a conflict of interest between OpenAI’s work and the machine learning research done by Telsa to develop autonomous driving. “As Tesla continues to become more focused on AI, this will eliminate a potential future conflict for Elon,” says the post. Musk will stay on as a donator to OpenAI and will continue to advise the group. 

The blog post also announced a number of new donors, including video game developer Gabe Newell, Skype founder Jaan Tallinn, and the former US and Canadian Olympians Ashton Eaton and Brianne Theisen-Eaton. OpenAI said it was broadening its base of funders in order to ramp up investments in “our people and the compute resources necessary to make consequential breakthroughs in artificial intelligence.” For those concerned about the near-term impact of AI on areas like surveillance and propaganda, this work is crucial. 

OpenAI was founded just two years ago, but has fast become a significant voice in the global machine learning community. Its research has been wide-ranging, including teaching computers to control robots with minimal instruction (known as “one-shot learning”) and the creation of AI agents to play popular video game Dota (a more daunting challenge than board games like chess). 

Just this week, the institute contributed to a multi-disciplinary report outlining the ways AI could be used maliciously over the next five years. (A different and much realer set of concerns than the specter of evil superintelligent AI sometimes raised by figures including Musk himself.) But for an organization concerned with keeping advances in artificial intelligence safe, OpenAI certainly has its work cut out. 
",,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LmZhc3Rjb21wYW55LmNvbS80MDUzNDg5NS90aGlzLWNvbXBhbnktaXMtdXNpbmctYWktdG8tbWFrZS1wZXJzb25hbGl6ZWQtc2tpbi1jYXJl0gEA?oc=5,This company is using AI to make personalized skin care - Fast Company,2018-02-22,Fast Company,https://www.fastcompany.com,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vZWxlY3RyZWsuY28vMjAxOC8wMi8yMS9lbG9uLW11c2stbGVhdmVzLW9wZW4tYWktdGVzbGEtYWktZWZmb3J0L9IBAA?oc=5,Elon Musk leaves Open AI's board due to potential conflict with Tesla's own AI effort - Electrek,2018-02-21,Electrek,https://electrek.co,N/A,[],"Open AI, a non-profit artificial intelligence research company, announced that Elon Musk, who helped found and finance the organization, is...",N/A,https://schema.org,NewsArticle,Elon Musk leaves Open AI&#8217;s board due to potential conflict with Tesla&#8217;s own AI effort,http://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/,2018-02-21T13:00:58Z,2018-02-21T13:00:58Z,2018-02-21T13:00:58Z,News,,"{'@type': 'WebPage', '@id': 'http://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/'}","{'@type': 'Organization', 'name': 'Electrek', 'logo': ''}",https://electrek.co/wp-content/uploads/sites/3/2018/02/cpeqtaoukaachb0-e1519217828257.jpg?quality=82&strip=all&w=150,"{'@type': 'ImageObject', 'url': 'https://electrek.co/wp-content/uploads/sites/3/2018/02/cpeqtaoukaachb0-e1519217828257.jpg?quality=82&strip=all'}",['Fred Lambert'],"[{'@type': 'Person', 'name': 'Fred Lambert'}]",,,,N/A,N/A,"


 


Tesla relaunches Model 3 Long Range RWD: 363 miles of range for $42,490


 
Fred Lambert
Jul 12 2024


","[{'@type': 'Article', '@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/#article', 'isPartOf': {'@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/'}, 'author': {'name': 'Fred Lambert', '@id': 'https://electrek.co/#/schema/person/83185b1e4fe1f4001d98deb79f98236b'}, 'headline': 'Elon Musk leaves Open AI&#8217;s board due to potential conflict with Tesla&#8217;s own AI effort', 'datePublished': '2018-02-21T13:00:58+00:00', 'dateModified': '2018-02-21T13:00:58+00:00', 'mainEntityOfPage': {'@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/'}, 'wordCount': 406, 'commentCount': 0, 'publisher': {'@id': 'https://electrek.co/#organization'}, 'image': {'@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/#primaryimage'}, 'thumbnailUrl': 'https://electrek.co/wp-content/uploads/sites/3/2018/02/cpeqtaoukaachb0-e1519217828257.jpg?quality=82&strip=all', 'articleSection': ['News'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://925.co/#organization'}}, {'@type': 'WebPage', '@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/', 'url': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/', 'name': ""Elon Musk leaves Open AI's board due to potential conflict with Tesla's own AI effort | Electrek"", 'isPartOf': {'@id': 'https://electrek.co/#website'}, 'primaryImageOfPage': {'@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/#primaryimage'}, 'image': {'@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/#primaryimage'}, 'thumbnailUrl': 'https://electrek.co/wp-content/uploads/sites/3/2018/02/cpeqtaoukaachb0-e1519217828257.jpg?quality=82&strip=all', 'datePublished': '2018-02-21T13:00:58+00:00', 'dateModified': '2018-02-21T13:00:58+00:00', 'breadcrumb': {'@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/#primaryimage', 'url': 'https://electrek.co/wp-content/uploads/sites/3/2018/02/cpeqtaoukaachb0-e1519217828257.jpg?quality=82&strip=all&w=1024', 'contentUrl': 'https://electrek.co/wp-content/uploads/sites/3/2018/02/cpeqtaoukaachb0-e1519217828257.jpg?quality=82&strip=all&w=1024', 'width': 1200, 'height': 600}, {'@type': 'BreadcrumbList', '@id': 'https://electrek.co/2018/02/21/elon-musk-leaves-open-ai-tesla-ai-effort/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://electrek.co/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Elon Musk leaves Open AI&#8217;s board due to potential conflict with Tesla&#8217;s own AI effort'}]}, {'@type': 'WebSite', '@id': 'https://electrek.co/#website', 'url': 'https://electrek.co/', 'name': 'Electrek', 'description': 'EV and Tesla News, Green Energy, Ebikes, and more', 'publisher': {'@id': 'https://electrek.co/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://electrek.co/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'NewsMediaOrganization', '@id': 'https://electrek.co/#organization', 'name': 'Electrek.co', 'url': 'https://electrek.co/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://electrek.co/#/schema/logo/image/', 'url': 'https://electrek.co/wp-content/uploads/sites/3/2018/09/cropped-electrek-logo11.png', 'contentUrl': 'https://electrek.co/wp-content/uploads/sites/3/2018/09/cropped-electrek-logo11.png', 'width': 480, 'height': 100, 'caption': 'Electrek.co'}, 'image': {'@id': 'https://electrek.co/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/electrekco', 'https://x.com/electrekco', 'https://www.instagram.com/electrek.co/', 'https://youtube.com/c/electrekco'], 'masthead': 'https://electrek.co/about/'}, {'@type': 'Person', '@id': 'https://electrek.co/#/schema/person/83185b1e4fe1f4001d98deb79f98236b', 'name': 'Fred Lambert', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://electrek.co/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/ecd1698b64e3d1fca5c1ceead88373dd?s=96&d=identicon&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/ecd1698b64e3d1fca5c1ceead88373dd?s=96&d=identicon&r=g', 'caption': 'Fred Lambert'}, 'url': 'https://electrek.co/author/fredericclambert/'}]",,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3LnNtYXJ0Y29tcGFueS5jb20uYXUvc3RhcnR1cHNtYXJ0L25ld3MvYmVuZWZpdHMtYWktcm9ib3RpY3Mtb3V0d2VpZ2gtaGFybS_SAQA?oc=5,Why the benefits of AI and robotics outweigh the harm - SmartCompany,2018-02-21,SmartCompany,https://www.smartcompany.com.au,N/A,N/A,"David Tuffley, Griffith University We have all heard the dire predictions about robots coming to steal our jobs. Some would...",N/A,http://schema.org,NewsArticle,,,,,,,,,"{'@type': 'Organization', 'name': 'SmartCompany'}",,,,,,,,N/A,N/A,"


Startup News 
Why the benefits of AI and robotics outweigh the harm




The Conversation 


									February 21, 2018								















 





article-article-body

David Tuffley, Griffith University
We have all heard the dire predictions about robots coming to steal our jobs. Some would even have us believe these silicon bogeymen are coming to kill us. It plays straight into people’s darkest fears about technology.
When futurists talk about things that haven’t happened yet, they are free to parade educated guesses as fact. But before we take their word for it, we might remember the old adage:
… in God we trust, all others bring data.
In a recent article, the MIT Technology Review tabulated the results of “every study we could find on what automation will do to jobs”. The results show that the expected impacts depend on what you measure.
Many predictions, little agreement
Of the 19 reports considered in the review, there was enormous variation. Some predicted that a few million jobs would be replaced, while others spoke portentously of tens or hundreds of millions over similar time frames. Some were decidedly upbeat, others quite gloomy.
One futurist went so far as to forecast that a billion jobs will be lost to automation by 2022. Contrast this with the more sober prediction from the research and advisory group Gartner of 1.8 million jobs lost by 2020, but with 2.3 million created in the same period – a net increase of 500,000 over the next two years.
Why such a big difference? In truth, no one knows how many jobs will be lost and found in the age of Artificial Intelligence (AI). The situation is too complex for simple answers.
Variations in predictions can be likened to the parable of the five blind men encountering an elephant. By touching different parts of the elephant’s body, each came to a different conclusion as to what the beast is.
Technology anxiety is nothing new
Worries about the impact of technology on society have a long history.
In the 18th and 19th centuries, the rapid expansion of disruptive technologies during the Industrial Revolution gave rise to the same anxieties as those being expressed today.
Trades were automated to produce greater economies of scale, but job losses were more than offset by the new jobs subsequently created. Meanwhile, trades like pottery, weaving and metalwork that were “lost” to automation 200 years ago are still being done by skilled craftspeople today.
More recently, when personal computers found their way onto people’s desks in the 1980s, the typing pool became redundant. I recall the lamentations then of the newspapers, TV and talkback radio.
But in time, the overall number of jobs went up because of the new jobs created in the fledgling IT industry. Today there are dozens of technology job categories, none of which existed in the typing pool days – jobs in computer hardware, programming, content production, web design, security, big data, sales and marketing, and artificial intelligence to name a few.



And the former typists? Their skills were in more demand than ever, because keyboards are still the way humans communicate with computers.
AI is only an extension of us
AI is often spoken of as a separate entity from people, and sometimes seen as a dangerous adversary. The reality is that it is merely a tool created by humans – it only does what we tell it to do and nothing more.
What we have is “narrow AI”, only suited to very particular tasks. Autonomous “general AI” that is superior to the spectrum of human intelligence is many decades away.
The “narrow AI” GPS on my smartphone is much better at navigating than I am. It extends my ability to go places almost miraculously. But there’s no reason to feel threatened. It is only smarter than me in that one ability. And it is not at all likely to say “I’m sorry Dave, I’m afraid I can’t do that” like Hal refusing to open the pod bay doors in film 2001: A Space Odyssey.
2001: A Space Odyssey.
Likewise, AI can greatly improve people’s competence in the workplace. In the first recorded case of an AI saving someone’s life, it was the combination of human doctors and a diagnostic AI that succeeded where the human doctors alone had failed.
The obvious advantages of enhancing human intelligence with AI have given rise to the hybrid known as a modern centaur.
The concept was illustrated by chess grandmaster Garry Kasparov, who observed that the best players are not computers alone, but human intelligence augmented with AI.
Benefits out-weigh the harm
Historically, fears about technology have largely proven unfounded, at least in terms of the benefits outweighing the harm, if not in other ways. Our challenge is to maximise the benefits and minimise the harm.
What skills will we need for future employment? These would be the same skills that humans have always excelled at – critical thinking and problem solving, good communication and teamwork, leadership, initiative, creativity. And of course, the willingness to leverage the current technology.
Futurists tend to assume that if a job can be automated, it will be automated. But that is certainly not true.
AI will automate some jobs, particularly the dirty, dull or dangerous ones that people don’t want to do – everything from sewer reconnaissance to repetitive factory work. Manual welding, for example, can produce highly toxic fumes – a prime candidate for automation.
But some jobs will always be done by people and the reasons can vary greatly, from economic, social and nostalgic reasons, to the fact that some jobs are simply not practical for robots to do.
When I go to the doctor, I want a human sitting across from me. I don’t want a holographic doctor who demands to know the nature of my medical emergency.
David Tuffley, Senior Lecturer in Applied Ethics and SocioTechnical Studies, School of ICT., Griffith University
This article was originally published on The Conversation. Read the original article.





ABOUT THE AUTHOR



The Conversation




SIMILAR TOPICSAIAI startupsarticificial intelligencehiringjobsroboticsrobotics jobstechtechnology


COMMENTS


SmartCompany is committed to hosting lively discussions. Help us keep the conversation useful, interesting and welcoming. We aim to publish comments quickly in the interest of promoting robust conversation, but we’re a small team and we deploy filters to protect against legal risk. Occasionally your comment may be held up while it is being reviewed, but we’re working as fast as we can to keep the conversation rolling.


The SmartCompany comment section is members-only content. Please subscribe to leave a comment.


The SmartCompany comment section is members-only content. Please login to leave a comment.





","[{'@type': 'Article', '@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/#article', 'isPartOf': {'@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/'}, 'author': [{'@id': 'https://www.smartcompany.com.au/#/schema/person/5a8da5dff24b973095f05044828eab3c'}], 'headline': 'Why the benefits of AI and robotics outweigh the harm', 'datePublished': '2018-02-20T22:27:58+00:00', 'dateModified': '2018-02-20T22:27:58+00:00', 'mainEntityOfPage': {'@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/'}, 'wordCount': 982, 'commentCount': 1, 'publisher': {'@id': 'https://www.smartcompany.com.au/#organization'}, 'image': {'@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/#primaryimage'}, 'thumbnailUrl': 'https://www.smartcompany.com.au/wp-content/uploads/2018/02/file-20180215-124893-1lv6aho.jpg', 'keywords': ['AI', 'AI startups', 'articificial intelligence', 'hiring', 'jobs', 'robotics', 'robotics jobs', 'tech', 'technology'], 'articleSection': ['Startup News'], 'inLanguage': 'en-AU', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/#respond']}], 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://www.smartcompany.com.au/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/', 'url': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/', 'name': 'Why the benefits of AI and robotics outweigh the harm - SmartCompany', 'isPartOf': {'@id': 'https://www.smartcompany.com.au/#website'}, 'primaryImageOfPage': {'@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/#primaryimage'}, 'image': {'@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/#primaryimage'}, 'thumbnailUrl': 'https://www.smartcompany.com.au/wp-content/uploads/2018/02/file-20180215-124893-1lv6aho.jpg', 'datePublished': '2018-02-20T22:27:58+00:00', 'dateModified': '2018-02-20T22:27:58+00:00', 'breadcrumb': {'@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/#breadcrumb'}, 'inLanguage': 'en-AU', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/#primaryimage', 'url': 'https://www.smartcompany.com.au/wp-content/uploads/2018/02/file-20180215-124893-1lv6aho.jpg', 'contentUrl': 'https://www.smartcompany.com.au/wp-content/uploads/2018/02/file-20180215-124893-1lv6aho.jpg', 'width': 681, 'height': 333, 'caption': 'robots'}, {'@type': 'BreadcrumbList', '@id': 'https://www.smartcompany.com.au/startupsmart/news/benefits-ai-robotics-outweigh-harm/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.smartcompany.com.au/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Why the benefits of AI and robotics outweigh the harm'}]}, {'@type': 'WebSite', '@id': 'https://www.smartcompany.com.au/#website', 'url': 'https://www.smartcompany.com.au/', 'name': 'SmartCompany', 'description': 'Business news, business advice and information for Australian SMEs, startups and entrepreneurs', 'publisher': {'@id': 'https://www.smartcompany.com.au/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.smartcompany.com.au/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-AU'}, {'@type': 'Organization', '@id': 'https://www.smartcompany.com.au/#organization', 'name': 'SmartCompany', 'url': 'https://www.smartcompany.com.au/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://www.smartcompany.com.au/#/schema/logo/image/', 'url': 'https://www.smartcompany.com.au/wp-content/uploads/2022/11/Smartcompany_Horizontal_Black_Logo_3000x4000px-e1668556442225.png', 'contentUrl': 'https://www.smartcompany.com.au/wp-content/uploads/2022/11/Smartcompany_Horizontal_Black_Logo_3000x4000px-e1668556442225.png', 'width': 3000, 'height': 3000, 'caption': 'SmartCompany'}, 'image': {'@id': 'https://www.smartcompany.com.au/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/SmartCompany', 'https://x.com/smartcompany', 'https://www.instagram.com/smartcompanyau/', 'https://www.linkedin.com/company/smartcompany']}, {'@type': 'Person', '@id': 'https://www.smartcompany.com.au/#/schema/person/5a8da5dff24b973095f05044828eab3c', 'name': 'The Conversation', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://www.smartcompany.com.au/#/schema/person/image/d4edb57063bbbb77b1ac53eb48d38790', 'url': 'https://secure.gravatar.com/avatar/9f39c76fe4963fb7193f90d8b624a0a1?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/9f39c76fe4963fb7193f90d8b624a0a1?s=96&d=mm&r=g', 'caption': 'The Conversation'}, 'url': 'https://www.smartcompany.com.au/author/the-conversation/'}]",,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'SmartCompany', 'productID': 'smartcompany.com.au:showcase'}",,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vdGhlY29udmVyc2F0aW9uLmNvbS9oZXJlcy1ob3ctY2FuYWRhLWNhbi1iZS1hLWdsb2JhbC1sZWFkZXItaW4tZXRoaWNhbC1haS05MDk5MdIBAA?oc=5,Here's how Canada can be a global leader in ethical AI - The Conversation,2018-02-22,The Conversation,https://theconversation.com,"Canada has a clear choice. Either it embraces the potential of being a leader in responsible AI, or it risks legitimating a race to the bottom where ethics, inequity and justice are absent.",N/A,"Canada has a clear choice. Either it embraces the potential of being a leader in responsible AI, or it risks legitimating a race to the bottom where ethics, inequity and justice are absent.",N/A,,,,,,,,,,,,,,,,,,,N/A,N/A,"






        Investment in AI research is growing in Canada, but there’s little thought about ethics, privacy and governance issues.
        (Shutterstock)









            Here’s how Canada can be a global leader in ethical AI
          




Published: February 22, 2018 4:58pm EST












Fenwick McKelvey, Concordia University, Abhishek Gupta, McGill University



Authors





        Fenwick McKelvey
      


      Assistant Professor in Information and Communication Technology Policy, Concordia University
    





        Abhishek Gupta
      


      AI Ethics Researcher, McGill University
    





Disclosure statement
Fenwick McKelvey receives funding from the Social Sciences and Humanities Research Council and Fonds de Recherche du Québec - Société et Culture.
Abhishek Gupta works for and receives funding from District 3, Concordia University and McGill University. He is the founder of the Montreal AI Ethics Meetup group. 


Partners

Concordia University provides funding as a founding partner of The Conversation CA.Universitié Concordia provides funding as a founding partner of The Conversation CA-FR.McGill University provides funding as a member of The Conversation CA.McGill University provides funding as a member of The Conversation CA-FR.
View all partners

We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)69


 Facebook1.3k


 LinkedIn


 WhatsApp


 Messenger

 Print


Canada’s research expertise in artificial intelligence (AI) has led to significant recent investment. But far fewer resources have been dedicated to the governance, ethics or social responsibilities of this new technology, leaving many different local initiatives to try to fill the gap.
AI already affects our everyday lives. With each like, swipe and comment on social media, most of us are already contributing data   — to improve AI applications that recommend videos online or help us manage our email. 
Our ability to ask a smartphone a question results from a long history of research into how we can use computers to automate human labour and improve decision making. Better processors, advances in algorithms, as well as big data, often gathered from our online interactions, have driven major advances in deep learning, a branch of AI. 
Advances in these fields have been heralded as a net benefit to all humankind.
But treating AI as inherently good overlooks the important research and development needed for ethical, safe and inclusive applications. Poor data, inexplicable code or rushed deployment can easily lead to AI systems that are not worth celebrating. 
For example, automated systems can be programmed with bias. A ProPublica investigation revealed that the COMPAS program, used to assess criminal risk scores in the United States, was inherently biased against African Americans.
Discoveries like this reveal an important reality: First, the impacts of AI are very real and affect real lives and families. Second, this is taking place right now  — these are not far-fetched scenarios that might happen in the future. 
Assessing the consequences
Despite these risks, interest in AI in Canada — and around the world   — has not slowed.
In Canada, the federal government invested dramatically in artificial intelligence research in the past year. The 2017 budget included $125 million for a pan-Canadian Artificial Intelligence Strategy that will be administered by the Canadian Institute for Advanced Research. A Quebec-based proposal for research on AI and supply chains won a share of the $950 million federal “superclusters fund” in February.



Ottawa injected $950 million into five innovation superclusters in February 2018, including one in Quebec that will work on robots and artificial intelligence (File photo).
THE CANADIAN PRESS/Sean Kilpatrick


But without proper outreach to sectors with expertise in the social, cultural and political consequences of new technologies, these initiatives will likely widen the gap between technology firms and the public interest and disconnect research from critical reflection.
Fortunately, the social implications of AI are beginning to appear on the federal government’s radar. 
The Treasury Board Secretariat (TBS) of Canada is finalising the first round of public consultation around the responsible use of AI in government. It has worked closely with the AI community by piloting an open online consultation that has allowed us and others to collaborate on the ensuing guidelines.
That report reviews many potential applications of AI, such as chatbots to help users navigate government services and programs to create website content. The initiative demonstrates how the federal government can lead by adopting strong guidelines for its own use of AI. 
These concrete, narrow applications are a sign the government understands the risks of automation in its own work. We hope the final report will result in strong guidelines that guarantee transparency, accountability and fairness.
In addition, Global Affairs Canada is leading a multi-university collaboration on artificial intelligence and human rights. For example, graduate students in Fenwick McKelvey’s Media Policy seminar at Concordia University are contributing to a broad scan of AI’s policy implications for human rights. McKelvey aims to link debates around AI to the expertise in communication and cultural studies that have long been questioning the cultural, social and political dimensions of media and technology.
McKelvey’s research connects with these initiatives by exploring the implications of algorithms and AI on internet governance and broadband performance. 
Abhishek Gupta is evaluating the impacts of AI-enabled automation in the financial services industry and how to tweak university curricula to better train practitioners to meet evolving job needs.
Gupta also founded the Montreal AI Ethics group, where conversations have focused on developing the Montreal Declaration for a Responsible Development of Artificial Intelligence. This document provides clear principles for how AI will respect well-being, autonomy, justice, privacy, knowledge, democracy and for its own responsible development.
AI as a data policy
An AI strategy does not need to develop in isolation. 
A national approach to AI should learn from the philanthropic and nonprofit sectors’ emerging discussions around data. Montreal’s Powered by Data has helped lead important conversations on how philanthropic organisations and nonprofits can become more data driven and serve as models for the inclusive and ethical use of data.
Data is just one of the ways the sector is integrating digital innovation into operations and developing digital strategies to help focus on missions. 
Part of this shift requires reassessing questions of inequality and discrimination in light of digital automation. The Brookfield Institute, a policy institute for innovation and entrepreneurship, has studied the potential benefits and threats of automation to the labour market. Their assessment indicates these effects will not be shared evenly across Canada, with some communities more susceptible to job reduction.



Artificial intelligence and automation will displace workers and create new jobs, but the impacts will not be felt equally across the country.
(Shutterstock)


But these initiatives lack the size and scope of interventions elsewhere. 
In the United States, the Ford Foundation and the MacArthur Foundation fund the AI Now Institute, hosted at New York University. The group has released two major reports on AI governance, leading to an international debate about how AI should be developed and used   — and demonstrating that these sectors can play an important role. 
AI Now’s success demonstrates that the philanthropic and nonprofit sectors can inform the development and application of AI. By creating an institute or a commitment to long-term initiatives, these sectors could ensure the development of an AI strategy that connects with important discussions about rising equity, precarious labour, data discrimination and reconciliation.
Putting Canada in the lead
Canada has a clear choice. Either it embraces the potential of being a leader in responsible AI, or it risks legitimating a race to the bottom where ethics, equity and justice are absent. 
Better guidance for researchers on how the Canadian Charter of Rights and Freedoms relates to AI research and development is a good first step. From there, Canada can create a just, equitable and stable foundation for a research agenda that situates the new technology within longstanding social institutions. 
Canada also needs a more coordinated, inclusive national effort that prioritizes otherwise marginalized voices. These consultations will be key to positioning Canada as a beacon in this field.
Without these measures, Canada could lag behind. Europe is already drafting important new approaches to data protection. New York City launched a task force this fall to become a global leader on governing automated decision making. We hope this leads to active consultation with city agencies, academics across the sciences and the humanities as well as community groups, from Data for Black Lives to Picture the Homeless, and consideration of algorithmic impact assessments. 
These initiatives should provide a helpful context as Canada develops its own governance strategy and works out how to include Indigenous knowledge within that.
If Canada develops a strong national strategy approach to AI governance that works across sectors and disciplines, it can lead at the global level.





Artificial intelligence (AI)


Discrimination


Ethics


Automation


Chatbots









",,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmNuYmMuY29tLzIwMTgvMDIvMjAvbWFyay1jdWJhbi1waGlsb3NvcGh5LWRlZ3JlZS13aWxsLWJlLXdvcnRoLW1vcmUtdGhhbi1jb21wdXRlci1zY2llbmNlLmh0bWzSAW5odHRwczovL3d3dy5jbmJjLmNvbS9hbXAvMjAxOC8wMi8yMC9tYXJrLWN1YmFuLXBoaWxvc29waHktZGVncmVlLXdpbGwtYmUtd29ydGgtbW9yZS10aGFuLWNvbXB1dGVyLXNjaWVuY2UuaHRtbA?oc=5,Mark Cuban says studying philosophy may soon be worth more than computer science—here's why - CNBC,2018-02-21,CNBC,https://www.cnbc.com,Shark Tank investor Mark Cuban explains why college students should consider a degree in philosophy over computer science.,"['makeit', 'Articles', 'Entrepreneurship', 'Entrepreneurs', 'Make It', 'Make It - Success', 'Make It - Entrepreneurs ', 'source:tagname:CNBC US Source']",Shark Tank investor Mark Cuban explains why college students should consider a degree in philosophy over computer science.,Shark Tank investor Mark Cuban explains why college students should consider a degree in philosophy over computer science.,https://schema.org,NewsArticle,Mark Cuban says studying philosophy may soon be worth more than computer science—here's why,https://www.cnbc.com/2018/02/20/mark-cuban-philosophy-degree-will-be-worth-more-than-computer-science.html,2018-02-21T14:35:00+0000,2018-02-21T14:35:00+0000,2018-02-21T14:35:55+0000,Make It,,https://www.cnbc.com/2018/02/20/mark-cuban-philosophy-degree-will-be-worth-more-than-computer-science.html,"{'@type': 'NewsMediaOrganization', 'name': 'CNBC', 'url': 'https://www.cnbc.com/', 'foundingDate': '1989-04-17', 'logo': {'@type': 'ImageObject', 'url': 'https://sc.cnbcfm.com/applications/cnbc.com/staticcontent/img/cnbc-hdr-logo2.png', 'width': 378, 'height': 98}, 'sameAs': ['https://www.facebook.com/CNBCMakeIt', 'https://www.twitter.com/CNBCMakeit', 'https://www.linkedin.com/showcase/cnbc-make-it']}",https://image.cnbcfm.com/api/v1/image/104871303-GettyImages-610936138.jpg?v=1610388143&w=720&h=405,"{'@type': 'ImageObject', 'url': 'https://image.cnbcfm.com/api/v1/image/104871303-GettyImages-610936138.jpg?v=1610388143', 'width': 1730, 'height': 1043}",,"[{'@type': 'Person', 'name': 'Ali Montag', 'url': 'https://www.cnbc.com/ali-montag/'}]",,,,Make It - Entrepreneurs ,N/A,N/A,,,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', '/html/head/meta[@name=""description""]/@content'], 'cssSelector': ['.group p']}","{'@type': 'VideoObject', 'contentUrl': 'http://pdl.iphone.cnbc.com/VCPS/Y2017/M03D13/3000600718/makeit_sxsw_mark_cuban_AI_trillionaires_L.mp4', 'description': 'The self-made billionaire believes great profits await entrepreneurs working with artificial intelligence.', 'duration': 'PT46S', 'name': 'Mark Cuban: AI will produce the world’s first trillionaires', 'thumbnailUrl': 'https://image.cnbcfm.com/api/v1/image/104338159-makeit_sxsw_mark_cuban_AI_trillionaires_mezz.jpg?v=1529474475', 'uploadDate': '2017-03-13T13:33:35+0000'}",,,,
https://news.google.com/rss/articles/CBMiiAFodHRwczovL3d3dy5saW1lcmlja2xlYWRlci5pZS9uZXdzL2hvbWUvMjk4NDAzL3VuaXZlcnNpdHktb2YtbGltZXJpY2stdG8taGVscC1zaGFwZS1uZXctcmVhbGl0eS13aXRoLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvdXJzZS5odG1s0gEA?oc=5,University of Limerick to help 'shape new reality' with artificial intelligence course - Limerick Live,2018-02-21,Limerick Live,https://www.limerickleader.ie,"A NEW Masters in artificial intelligence (AI) at the University of Limerick will help to shape a new reality for Irish businesses, according to the Minister for...",UL,"A NEW Masters in artificial intelligence (AI) at the University of Limerick will help to shape a new reality for Irish businesses, according to the Minister for State for Trade, Employment, and Business. Ireland’s first Masters in AI will run in UL’s Digital District from September 2018 ...","A NEW Masters in artificial intelligence (AI) at the University of Limerick will help to shape a new reality for Irish businesses, according to the Minister for State for Trade, Employment, and Busine...",https://schema.org,Article,University of Limerick to help 'shape new reality' with artificial intelligence course,https://www.limerickleader.ie/news/home/298403/university-of-limerick-to-help-shape-new-reality-with-artificial-intelligence-course.html,2018-02-21T18:06:11Z,2018-02-21T18:06:26Z,2018-02-21T18:06:22Z,Education,,https://www.limerickleader.ie/news/home/298403/university-of-limerick-to-help-shape-new-reality-with-artificial-intelligence-course.html,"{'@type': 'Organization', 'name': 'Limerick Live', 'logo': {'@type': 'ImageObject', 'url': 'https://www.limerickleader.ie/images/logos/1/logo_colored.jpg'}}",,"{'contentUrl': 'https://www.limerickleader.ie/resizer/-1/-1/true/GN4_DAT_9460584.jpg--.jpg', 'url': 'https://www.limerickleader.ie/resizer/-1/-1/true/GN4_DAT_9460584.jpg--.jpg', '@type': 'ImageObject'}",,"{'@type': 'Person', 'name': 'Jess Casey', 'url': 'https://www.limerickleader.ie/'}",,,,N/A,N/A,"






Pictures & Videos


Throwback Thursday: Pictures from the Limerick Leader archives

",,,,,,,"A NEW Masters in artificial intelligence (AI) at the University of Limerick will help to shape a new reality for Irish businesses, according to the Minister for State for Trade, Employment, and Business. Ireland’s first Masters in AI will run in UL’s Digital District from September 2018 in association with the Irish Centre for High End Computing (ICHEC). Minister of State Pat Breen welcomed the introduction of the course on a recent visit to the university. “Artificial Intelligence is shaping a new reality for Irish businesses, creating exciting new opportunities for innovation across all industries,” Minister Breen said. “To keep apace with these fast-changing technologies, it’s essential we have a workforce with the skills needed to drive this digital revolution. This Masters in AI will help to address Irish skills shortages in AI in the years to come.” The Minister plans to host a meeting at which AI will be the central theme and has invited course director Dr John Nelson to attend.",,,
https://news.google.com/rss/articles/CBMinwFodHRwczovL3RpbWVzb2ZpbmRpYS5pbmRpYXRpbWVzLmNvbS9ibG9ncy90b2ktZWRpdC1wYWdlL3RoZS1mdXR1cmUtb2Ytam9icy13aHktaW5kaWEtbXVzdC1lbWJyYWNlLXRoZS1uZXctZXJhLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWJsb2NrY2hhaW4tYW5kLXJvYm90cy_SAZ8BaHR0cHM6Ly90aW1lc29maW5kaWEuaW5kaWF0aW1lcy5jb20vYmxvZ3MvdG9pLWVkaXQtcGFnZS90aGUtZnV0dXJlLW9mLWpvYnMtd2h5LWluZGlhLW11c3QtZW1icmFjZS10aGUtbmV3LWVyYS1vZi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1ibG9ja2NoYWluLWFuZC1yb2JvdHMv?oc=5,"The future of jobs: Why India must embrace the new era of artificial intelligence, blockchain and robots - The Times of India",2018-02-21,The Times of India,https://timesofindia.indiatimes.com,"The ancient Chinese game Go, which has a very high number of possible moves, was considered almost impossible for a computer to beat humans two years ago. Last year Alpha Go (a Go programme designed...","['Edit Page blog', ' India blog', ' Amitabh Kant blog', ' TOI Edit Page blog']","The ancient Chinese game Go, which has a very high number of possible moves, was considered almost impossible for a computer to beat humans two years ago. Last year Alpha Go (a Go programme designed...",N/A,http://schema.org,BreadcrumbList,"The future of jobs: Why India must embrace the new era of artificial intelligence, blockchain and robots",https://timesofindia.indiatimes.com/blogs/toi-edit-page/the-future-of-jobs-why-india-must-embrace-the-new-era-of-artificial-intelligence-blockchain-and-robots/,,2018-02-22T02:00:34+05:30,2018-02-21T18:29:30+05:30,,,https://timesofindia.indiatimes.com/blogs/toi-edit-page/the-future-of-jobs-why-india-must-embrace-the-new-era-of-artificial-intelligence-blockchain-and-robots/,"{'@type': 'Organization', 'name': 'Times of India', 'url': 'https://timesofindia.indiatimes.com', 'logo': {'@type': 'ImageObject', 'url': 'https://static.toiimg.com/photo/msid-58127550/toilogo.jpg', 'width': 600, 'height': 60}}",,"{'@type': 'ImageObject', 'url': 'https://static.toiimg.com/imagenext/toiblogs/photo/blogs/wp-content/uploads/2018/02/TechIndiaFutureText.jpg', 'height': None, 'width': None}",,"{'@type': 'Person', 'name': 'Amitabh Kant'}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://timesofindia.indiatimes.com/blogs/', 'name': 'News'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://timesofindia.indiatimes.com/blogs/', 'name': 'BLOGS'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://timesofindia.indiatimes.com/blogs/edit-page/', 'name': 'Edit Page'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': None, 'name': 'The future of jobs: Why India must embrace the new era of artificial intelligence, blockchain and robots'}}]","The future of jobs: Why India must embrace the new era of artificial intelligence, blockchain and robots",,N/A,N/A,"Court don’t contort 
",,,,,"{'@type': 'SpeakableSpecification', 'cssSelector': 'The ancient Chinese game Go, which has a very high number of possible moves, was considered almost impossible for a computer to beat humans two years ago. Last year Alpha Go (a Go programme designed...'}",,,"{'@type': 'ImageObject', 'url': 'https://static.toiimg.com/photo/msid-58127550/toilogo.jpg', 'width': 600, 'height': 60}",en,"The future of jobs: Why India must embrace the new era of artificial intelligence, blockchain and robots"

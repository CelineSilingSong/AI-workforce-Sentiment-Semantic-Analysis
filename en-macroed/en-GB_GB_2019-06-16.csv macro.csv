URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,mainEntityOfPage,logo,telephone,address,articleBody,isBasedOn,thumbnailUrl,isPartOf,alternativeHeadline,@graph,sameAs,@id,dateCreated,identifier,creator,speakable,video
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvY29nbml0aXZld29ybGQvMjAxOS8wNi8xOS83LXR5cGVzLW9mLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,7 Types Of Artificial Intelligence - Forbes,2019-06-19,Forbes,https://www.forbes.com,"While artificial intelligence (AI) has become a commonly used and understood term, there is still a degree of obscurity regarding the different types of AI that exist and can exist in the future. Understanding the types of AI can help in better understanding the scope of present-day AI research.",,"While artificial intelligence (AI) has become a commonly used and understood term, there is still a degree of obscurity regarding the different types of AI that exist and can exist in the future. Understanding the types of AI can help in better understanding the scope of present-day AI research.","While artificial intelligence (AI) has become a commonly used and understood term, there is still a degree of obscurity regarding the different types of AI that exist and can exist in the future. Understanding the types of AI can help in better understanding the scope of present-day AI research.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/cognitiveworld/2019/06/19/7-types-of-artificial-intelligence/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/cognitiveworld/files/2019/06/types-of-AI.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Naveen Joshi', 'url': 'https://www.forbes.com/sites/naveenjoshi/', 'description': 'Naveen Joshi, columnist, is Founder and CEO of Allerin, which develops engineering and technology solutions focused on optimal customer experiences. Naveen works in AI, Big Data, IoT and Blockchain. An influencer with a half a million followers, he is a highly seasoned professional with more than 20 years of comprehensive experience in customizing open source products for cost optimizations of large scale IT deployment.', 'sameAs': ['https://www.linkedin.com/in/naveenjoshi/', 'https://www.twitter.com/@joshinav', 'http://cognitiveworld.com/our-team/naveen-joshi']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",7 Types Of Artificial Intelligence,2019-06-19T22:54:00-04:00,2022-04-14T14:04:00-04:00,AI & Big Data,7 Types Of Artificial Intelligence,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI & Big Data,N/A,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryInnovationAI7 Types Of Artificial IntelligenceNaveen JoshiFormer ContributorCOGNITIVE WORLDContributor GroupOpinions expressed by Forbes Contributors are their own.Jun 19, 2019,10:54pm EDTUpdated Apr 14, 2022, 02:04pm EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin








 Artificial Intelligence is probably the most complex and astounding creations of humanity yet. And that is disregarding the fact that the field remains largely unexplored, which means that every amazing AI application that we see today represents merely the tip of the AI iceberg, as it were. While this fact may have been stated and restated numerous times, it is still hard to comprehensively gain perspective on the potential impact of AI in the future. The reason for this is the revolutionary impact that AI is having on society, even at such a relatively early stage in its evolution.
 AI’s rapid growth and powerful capabilities have made people paranoid about the inevitability and proximity of an AI takeover. Also, the transformation brought about by AI in different industries has made business leaders and the mainstream public think that we are close to achieving the peak of AI research and maxing out AI’s potential. However, understanding the types of AI that are possible and the types that exist now will give a clearer picture of existing AI capabilities and the long road ahead for AI research. Understanding the types of AI classification Since AI research purports to make machines emulate human-like functioning, the degree to which an AI system can replicate human capabilities is used as the criterion for determining the types of AI. Thus, depending on how a machine compares to humans in terms of versatility and performance, AI can be classified under one, among the multiple types of AI. Under such a system, an AI that can perform more human-like functions with equivalent levels of proficiency will be considered as a more evolved type of AI, while an AI that has limited functionality and performance would be considered a simpler and less evolved type.
PROMOTED Based on this criterion, there are two ways in which AI is generally classified. One type is based on classifying AI and AI-enabled machines based on their likeness to the human mind, and their ability to “think” and perhaps even “feel” like humans. According to this system of classification, there are four types of AI or AI-based systems: reactive machines, limited memory machines, theory of mind, and self-aware AI.








 1.    Reactive Machines These are the oldest forms of AI systems that have extremely limited capability. They emulate the human mind’s ability to respond to different kinds of stimuli. These machines do not have memory-based functionality. This means such machines cannot use previously gained experiences to inform their present actions, i.e., these machines do not have the ability to “learn.” These machines could only be used for automatically responding to a limited set or combination of inputs. They cannot be used to rely on memory to improve their operations based on the same. A popular example of a reactive AI machine is IBM’s Deep Blue, a machine that beat chess Grandmaster Garry Kasparov in 1997. 
2.    Limited Memory Limited memory machines are machines that, in addition to having the capabilities of purely reactive machines, are also capable of learning from historical data to make decisions. Nearly all existing applications that we know of come under this category of AI. All present-day AI systems, such as those using deep learning, are trained by large volumes of training data that they store in their memory to form a reference model for solving future problems. For instance, an image recognition AI is trained using thousands of pictures and their labels to teach it to name objects it scans. When an image is scanned by such an AI, it uses the training images as references to understand the contents of the image presented to it, and based on its “learning experience” it labels new images with increasing accuracy. Almost all present-day AI applications, from chatbots and virtual assistants to self-driving vehicles are all driven by limited memory AI. 3.    Theory of Mind While the previous two types of AI have been and are found in abundance, the next two types of AI exist, for now, either as a concept or a work in progress. Theory of mind AI is the next level of AI systems that researchers are currently engaged in innovating. A theory of mind level AI will be able to better understand the entities it is interacting with by discerning their needs, emotions, beliefs, and thought processes. While artificial emotional intelligence is already a budding industry and an area of interest for leading AI researchers, achieving Theory of mind level of AI will require development in other branches of AI as well. This is because to truly understand human needs, AI machines will have to perceive humans as individuals whose minds can be shaped by multiple factors, essentially “understanding” humans. 4.    Self-aware This is the final stage of AI development which currently exists only hypothetically. Self-aware AI, which, self explanatorily, is an AI that has evolved to be so akin to the human brain that it has developed self-awareness. Creating this type of Ai, which is decades, if not centuries away from materializing, is and will always be the ultimate objective of all AI research. This type of AI will not only be able to understand and evoke emotions in those it interacts with, but also have emotions, needs, beliefs, and potentially desires of its own. And this is the type of AI that doomsayers of the technology are wary of. Although the development of self-aware can potentially boost our progress as a civilization by leaps and bounds, it can also potentially lead to catastrophe. This is because once self-aware, the AI would be capable of having ideas like self-preservation which may directly or indirectly spell the end for humanity, as such an entity could easily outmaneuver the intellect of any human being and plot elaborate schemes to take over humanity. The alternate system of classification that is more generally used in tech parlance is the classification of the technology into Artificial Narrow Intelligence (ANI), Artificial General Intelligence (AGI), and Artificial Superintelligence (ASI). 5.    Artificial Narrow Intelligence (ANI) This type of artificial intelligence represents all the existing AI, including even the most complicated and capable AI that has ever been created to date. Artificial narrow intelligence refers to AI systems that can only perform a specific task autonomously using human-like capabilities. These machines can do nothing more than what they are programmed to do, and thus have a very limited or narrow range of competencies. According to the aforementioned system of classification, these systems correspond to all the reactive and limited memory AI. Even the most complex AI that uses machine learning and deep learning to teach itself falls under ANI. 6.    Artificial General Intelligence (AGI) Artificial General Intelligence is the ability of an AI agent to learn, perceive, understand, and function completely like a human being. These systems will be able to independently build multiple competencies and form connections and generalizations across domains, massively cutting down on time needed for training. This will make AI systems just as capable as humans by replicating our multi-functional capabilities. 7.    Artificial Superintelligence (ASI) The development of Artificial Superintelligence will probably mark the pinnacle of AI research, as AGI will become by far the most capable forms of intelligence on earth. ASI, in addition to replicating the multi-faceted intelligence of human beings, will be exceedingly better at everything they do because of overwhelmingly greater memory, faster data processing and analysis, and decision-making capabilities. The development of AGI and ASI will lead to a scenario most popularly referred to as the singularity. And while the potential of having such powerful machines at our disposal seems appealing, these machines may also threaten our existence or at the very least, our way of life. At this point, it is hard to picture the state of our world when more advanced types of AI come into being. However, it is clear that there is a long way to get there as the current state of AI development compared to where it is projected to go is still in its rudimentary stage. For those holding a negative outlook for the future of AI, this means that now is a little too soon to be worrying about the singularity, and there's still time to ensure AI safety. And for those who are optimistic about the future of AI, the fact that we've merely scratched the surface of AI development makes the future even more exciting. Naveen JoshiNaveen Joshi, columnist, is Founder and CEO of Allerin, which develops engineering and technology solutions focused on optimal customer experiences.... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiLmh0dHBzOi8vd3d3LmxvbmRvbi5lZHUvdGhpbmsvdGhlLXJlYWxpdHktb2YtYWnSAQA?oc=5,The reality of AI - London Business School Review,2019-06-17,London Business School Review,https://www.london.edu,"London Business School is one of the world's elite business schools. We shape business practice and transform careers across the globe. Our academic strength drives original and provocative business thinking, empowering our people to challenge conventional wisdom in a truly unique academic environment.","LBSR podcasts,  Julian Birkinshaw,  AI","In this podcast series, Julian Birkinshaw explores the business applications of artificial intelligence.","In this podcast series, Julian Birkinshaw explores the business applications of artificial intelligence.",http://schema.org,Organization,https://www.london.edu,['https://images.london.edu/hxo16fanegqh/fe60b602-36d4-4e95-990b-f401c893b10d-asset/054eaaf868ffb686fcb6788120aa4391/the-reality-of-ai-banner.jpg'],"{'@type': 'Person', 'name': 'London Business School'}","{'@type': 'Organization', 'name': 'London Business School', 'logo': {'@type': 'ImageObject', 'url': 'https://images.ctfassets.net/hxo16fanegqh/4KD0tsxILYEZKUprJxltZT/127b23210dfc15b641376e29117796a5/lbs-logo.png'}}",The reality of AI,2019-06-17,2019-06-17,,London Business School,,,N/A,N/A,N/A,"{'@type': 'WebPage', '@id': 'https://www.london.edu/think/the-reality-of-ai'}",//images.london.edu/hxo16fanegqh/4rTE1DcTn2eI3kkEeotRm5/63e66d6d4a07e079fcadc1074edbea8b/london-business-school-logo.jpg,+44 (0) 20 7000 7000,"{'@type': 'PostalAddress', 'streetAddress': 'The Regents Park', 'addressLocality': 'London', 'postalCode': 'NW1 4SA', 'addressCountry': {'@type': 'Country', 'name': 'United Kingdom'}}",,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMihgFodHRwczovL3d3dy5tY2tpbnNleS5jb20vY2FwYWJpbGl0aWVzL21ja2luc2V5LWRpZ2l0YWwvb3VyLWluc2lnaHRzL2RpZ2l0YWwtYmxvZy93aGF0LWl0LXJlYWxseS10YWtlcy10by1zY2FsZS1hcnRpZmljaWFsLWludGVsbGlnZW5jZdIBAA?oc=5,What it really takes to scale artificial intelligence - McKinsey,2019-06-18,McKinsey,https://www.mckinsey.com,Changing company culture is the key—and often the biggest challenge—to scaling artificial intelligence across your organization.,N/A,Changing company culture is the key—and often the biggest challenge—to scaling artificial intelligence across your organization.,Changing company culture is the key—and often the biggest challenge—to scaling artificial intelligence across your organization.,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3Lm1hcmtldHdhdGNoLmNvbS9zdG9yeS9ob3ctYWktaXMtY2F0Y2hpbmctcGVvcGxlLXdoby1jaGVhdC1vbi10aGVpci1kaWV0cy1qb2Itc2VhcmNoZXMtYW5kLXNjaG9vbC13b3JrLTIwMTktMDYtMTDSAYABaHR0cHM6Ly93d3cubWFya2V0d2F0Y2guY29tL2FtcC9zdG9yeS9ob3ctYWktaXMtY2F0Y2hpbmctcGVvcGxlLXdoby1jaGVhdC1vbi10aGVpci1kaWV0cy1qb2Itc2VhcmNoZXMtYW5kLXNjaG9vbC13b3JrLTIwMTktMDYtMTA?oc=5,"How AI is catching people who cheat on their diets, job searches and college work - MarketWatch",2019-06-18,MarketWatch,https://www.marketwatch.com,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9wb3dlci1saW1pdHMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,"The Power, and Limits, of Artificial Intelligence - WIRED",2019-06-20,WIRED,https://www.wired.com,AI is very good at certain specific tasks. But we're still a long way from intelligence that switches tasks as easily as a person.,"['business', 'artificial intelligence', 'ai hub', 'human-computer interaction', 'ethics', 'personal services', 'machine learning', 'autonomous vehicles', 'web']",AI is very good at certain specific tasks. But we're still a long way from intelligence that switches tasks as easily as a person.,AI is very good at certain specific tasks. But we're still a long way from intelligence that switches tasks as easily as a person.,https://schema.org/,BreadcrumbList,https://www.wired.com/story/power-limits-artificial-intelligence/,"['https://media.wired.com/photos/5d0ad0d936bc9e6a43e9ce4d/16:9/w_1920,h_1080,c_limit/business_ai.jpg', 'https://media.wired.com/photos/5d0ad0d936bc9e6a43e9ce4d/4:3/w_1440,h_1080,c_limit/business_ai.jpg', 'https://media.wired.com/photos/5d0ad0d936bc9e6a43e9ce4d/1:1/w_1080,h_1080,c_limit/business_ai.jpg']","[{'@type': 'Person', 'name': 'Gregory Barber', 'sameAs': 'https://www.wired.com/author/gregory-barber/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}","The Power, and Limits, of Artificial Intelligence",2019-06-20T12:00:00.000-04:00,2019-06-20T12:00:00.000-04:00,business,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.wired.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'artificial intelligence', 'item': 'https://www.wired.com/tag/artificial-intelligence/'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Power, and Limits, of Artificial Intelligence'}]",tags,N/A,"Gregory BarberBusinessJun 20, 2019 12:00 PMThe Power, and Limits, of Artificial IntelligenceAI is very good at certain specific tasks. But we're still a long way from intelligence that switches tasks as easily as a person.Save this storySaveSave this storySaveThe AI Database →ApplicationHuman-computer interactionEthicsPersonal servicesSo, you’ve heard about this thing called artificial intelligence. It’s changing the world, you’ve been told. It’s going to drive your car, grow your food, maybe even take your job. You’ll be forgiven for having some questions about this chaotic, AI-driven world that’s predicted to unfold.Gregory Barber covers cryptocurrency, blockchain, and artificial intelligence for WIRED.First off, it’s true that AI is overhyped. But it’s improving rapidly, and in some ways catching up to the hype. Part of that is a natural evolution: AI improves at a given task when it learns from new data, and the world is producing more data every second. New techniques developed in academic labs and at tech companies lead to jumps in performance, too. That’s led to cars that can drive themselves in some situations, to medical diagnoses that have beaten the accuracy of human doctors, and to facial recognition that’s reliable enough to unlock your iPhone.AI, in other words, is getting really good at some specific tasks. “The nice thing about AI is that it gets better with every iteration,” AI researcher and Udacity founder Sebastian Thrun says. He believes it might just “free humanity from the burden of repetitive work.” But on the lofty goal of so-called “general” AI intelligence that deftly switches between tasks just like a human? Please don’t hold your breath. Preserve those brain cells; you’ll need them to out-think the machines.LEARN MOREThe WIRED Guide to Artificial IntelligenceIn the meantime, AI’s biggest impact may come from democratizing the capabilities that we have now. Tech companies have made powerful software tools and data sets open source, meaning they’re just a download away for tinkerers, and the computing power used to train AI algorithms is getting cheaper and easier to access. That puts AI in the hands of a (yes, precocious) teenager who can develop a system to detect pancreatic cancer, and allows a group of hobbyists in Berkeley to race (and crash) their DIY autonomous cars. “We now have the ability to do things that were PhD theses five or 10 years ago,” says Chris Anderson, founder of DIY Drones (and a former WIRED editor-in-chief).But there are plenty of side effects to making cutting-edge technology available to all. Deepfakes, for example---AI-generated videos meant to look like real footage---are now accessible to anyone with a laptop. It’s easier than ever for any company, not just Facebook, to wield AI to target ads or sell your data at scale. And with AI burrowing into the fiber of every business and inching deeper into government, it’s easy to see how automated bias and privacy compromises could become normalized swiftly. As Neha Narula, head of MIT’s Digital Currency Initiative asks, “What are the controls that can be put in place so that we still have agency, that we can still shape it and it doesn’t shape us too much?”Find out more in the video above, a new documentary by WIRED, directed by filmmaker Chris Cannucciari and supported by McCann Worldgroup.Enter your email to get the Wired newsletterclose dialogRecommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialogMore Great WIRED StoriesBitcoin's climate impact is global. The cures are localFans are better than tech at organizing information onlineGritty postcards from the Russian hinterlandWhat does it mean when a product is “Amazon’s Choice”?My glorious, boring, almost-disconnected walk in Japan🎧 Things not sounding right? Check out our favorite wireless headphones, soundbars, and bluetooth speakers📩 Want more? Sign up for our daily newsletter and never miss our latest and greatest storiesMost PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David Gilbert, WIREDSecurityAT&T Paid a Hacker $370,000 to Delete Stolen Phone RecordsBy Kim Zetter, WIRED","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/power-limits-artificial-intelligence/'}",,,,"First off, it’s true that AI is overhyped. But it’s improving rapidly, and in some ways catching up to the hype. Part of that is a natural evolution: AI improves at a given task when it learns from new data, and the world is producing more data every second. New techniques developed in academic labs and at tech companies lead to jumps in performance, too. That’s led to cars that can drive themselves in some situations, to medical diagnoses that have beaten the accuracy of human doctors, and to facial recognition that’s reliable enough to unlock your iPhone.
AI, in other words, is getting really good at some specific tasks. “The nice thing about AI is that it gets better with every iteration,” AI researcher and Udacity founder Sebastian Thrun says. He believes it might just “free humanity from the burden of repetitive work.” But on the lofty goal of so-called “general” AI intelligence that deftly switches between tasks just like a human? Please don’t hold your breath. Preserve those brain cells; you’ll need them to out-think the machines.
In the meantime, AI’s biggest impact may come from democratizing the capabilities that we have now. Tech companies have made powerful software tools and data sets open source, meaning they’re just a download away for tinkerers, and the computing power used to train AI algorithms is getting cheaper and easier to access. That puts AI in the hands of a (yes, precocious) teenager who can develop a system to detect pancreatic cancer, and allows a group of hobbyists in Berkeley to race (and crash) their DIY autonomous cars. “We now have the ability to do things that were PhD theses five or 10 years ago,” says Chris Anderson, founder of DIY Drones (and a former WIRED editor-in-chief).
But there are plenty of side effects to making cutting-edge technology available to all. Deepfakes, for example---AI-generated videos meant to look like real footage---are now accessible to anyone with a laptop. It’s easier than ever for any company, not just Facebook, to wield AI to target ads or sell your data at scale. And with AI burrowing into the fiber of every business and inching deeper into government, it’s easy to see how automated bias and privacy compromises could become normalized swiftly. As Neha Narula, head of MIT’s Digital Currency Initiative asks, “What are the controls that can be put in place so that we still have agency, that we can still shape it and it doesn’t shape us too much?”
Find out more in the video above, a new documentary by WIRED, directed by filmmaker Chris Cannucciari and supported by McCann Worldgroup.

More Great WIRED Stories

Bitcoin's climate impact is global. The cures are local
Fans are better than tech at organizing information online
Gritty postcards from the Russian hinterland
What does it mean when a product is “Amazon’s Choice”?
My glorious, boring, almost-disconnected walk in Japan
🎧 Things not sounding right? Check out our favorite wireless headphones, soundbars, and bluetooth speakers
📩 Want more? Sign up for our daily newsletter and never miss our latest and greatest stories",,"https://media.wired.com/photos/5d0ad0d936bc9e6a43e9ce4d/1:1/w_1080,h_1080,c_limit/business_ai.jpg","{'@type': 'CreativeWork', 'name': 'WIRED'}",AI is very good at certain specific tasks. But we're still a long way from intelligence that switches tasks as easily as a person.,,,,,,,,
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMTkvdGVhY2hpbmctYWktdG8tY29ubmVjdC1zZW5zZXMtdmlzaW9uLXRvdWNoLTA2MTfSAQA?oc=5,Teaching artificial intelligence to connect senses like vision and touch - MIT News,2019-06-17,MIT News,https://news.mit.edu,"An artificial intelligence system from MIT CSAIL uses machine learning to create realistic tactile signals from visual inputs, and predict which object and what part is being touched directly from those tactile inputs.","Yunzhu Li, Russ Tedrake, Antonio Torralba, Robotics, artificial intelligence, machine learning, MIT CSAIL, MIT  Electrical Engineering and Computer Science, Computer vision, VisGel, MIT, MIT research","An artificial intelligence system from MIT CSAIL uses machine learning to create realistic tactile signals from visual inputs, and predict which object and what part is being touched directly from those tactile inputs.",N/A,,,,,,,,,,,,,,N/A,N/A,"


MIT CSAIL system can learn to see by touching and feel by seeing, suggesting future where robots can more easily grasp and recognize objects.




Rachel Gordon
|
MIT CSAIL


 Publication Date:
 June 17, 2019





Press Inquiries

  Press Contact:



      
            Adam         

            Conner-Simons        

  

      Email:
     aconner@csail.mit.edu


      Phone:
              617-324-9135      
  

      
            MIT Computer Science & Artificial Intelligence Lab        

  








 Close














 Caption:
          Yunzhu Li is a PhD student at the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL).      
          



















Previous image
Next image






















In Canadian author Margaret Atwood’s book ""Blind Assassins,"" she says that “touch comes before sight, before speech. It’s the first language and the last, and it always tells the truth.”While our sense of touch gives us a channel to feel the physical world, our eyes help us immediately understand the full picture of these tactile signals.Robots that have been programmed to see or feel can’t use these signals quite as interchangeably. To better bridge this sensory gap, researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) have come up with a predictive artificial intelligence (AI) that can learn to see by touching, and learn to feel by seeing.The team’s system can create realistic tactile signals from visual inputs, and predict which object and what part is being touched directly from those tactile inputs. They used a KUKA robot arm with a special tactile sensor called GelSight, designed by another group at MIT.Using a simple web camera, the team recorded nearly 200 objects, such as tools, household products, fabrics, and more, being touched more than 12,000 times. Breaking those 12,000 video clips down into static frames, the team compiled “VisGel,” a dataset of more than 3 million visual/tactile-paired images.“By looking at the scene, our model can imagine the feeling of touching a flat surface or a sharp edge”, says Yunzhu Li, CSAIL PhD student and lead author on a new paper about the system. “By blindly touching around, our model can predict the interaction with the environment purely from tactile feelings. Bringing these two senses together could empower the robot and reduce the data we might need for tasks involving manipulating and grasping objects.”Recent work to equip robots with more human-like physical senses, such as MIT’s 2016 project using deep learning to visually indicate sounds, or a model that predicts objects’ responses to physical forces, both use large datasets that aren’t available for understanding interactions between vision and touch.The team’s technique gets around this by using the VisGel dataset, and something called generative adversarial networks (GANs).GANs use visual or tactile images to generate images in the other modality. They work by using a “generator” and a “discriminator” that compete with each other, where the generator aims to create real-looking images to fool the discriminator. Every time the discriminator “catches” the generator, it has to expose the internal reasoning for the decision, which allows the generator to repeatedly improve itself.Vision to touch Humans can infer how an object feels just by seeing it. To better give machines this power, the system first had to locate the position of the touch, and then deduce information about the shape and feel of the region.The reference images — without any robot-object interaction — helped the system encode details about the objects and the environment. Then, when the robot arm was operating, the model could simply compare the current frame with its reference image, and easily identify the location and scale of the touch.This might look something like feeding the system an image of a computer mouse, and then “seeing” the area where the model predicts the object should be touched for pickup — which could vastly help machines plan safer and more efficient actions.Touch to visionFor touch to vision, the aim was for the model to produce a visual image based on tactile data. The model analyzed a tactile image, and then figured out the shape and material of the contact position. It then looked back to the reference image to “hallucinate” the interaction.For example, if during testing the model was fed tactile data on a shoe, it could produce an image of where that shoe was most likely to be touched.This type of ability could be helpful for accomplishing tasks in cases where there’s no visual data, like when a light is off, or if a person is blindly reaching into a box or unknown area.Looking ahead The current dataset only has examples of interactions in a controlled environment. The team hopes to improve this by collecting data in more unstructured areas, or by using a new MIT-designed tactile glove, to better increase the size and diversity of the dataset.There are still details that can be tricky to infer from switching modes, like telling the color of an object by just touching it, or telling how soft a sofa is without actually pressing on it. The researchers say this could be improved by creating more robust models for uncertainty, to expand the distribution of possible outcomes.In the future, this type of model could help with a more harmonious relationship between vision and robotics, especially for object recognition, grasping, better scene understanding, and helping with seamless human-robot integration in an assistive or manufacturing setting.“This is the first method that can convincingly translate between visual and touch signals”, says Andrew Owens, a postdoc at the University of California at Berkeley. “Methods like this have the potential to be very useful for robotics, where you need to answer questions like ‘is this object hard or soft?’, or ‘if I lift this mug by its handle, how good will my grip be?’ This is a very challenging problem, since the signals are so different, and this model has demonstrated great capability.”Li wrote the paper alongside MIT professors Russ Tedrake and Antonio Torralba, and MIT postdoc Jun-Yan Zhu. It will be presented next week at The Conference on Computer Vision and Pattern Recognition in Long Beach, California.








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print









Press Mentions


BBCPaul Carter of BBC’s Click highlights CSAIL research to teach a robot how to feel an object just by looking at it. This will ultimately help the robot “grip better when lifting things like the handle of a mug,” says Carter.











Full story via BBC →
ForbesForbes contributor Charles Towers-Clark explores how CSAIL researchers have developed a database of tactile and visual information that could be used to allow robots to infer how different objects look and feel. “This breakthrough could lead to far more sensitive and practical robotic arms that could improve any number of delicate or mission-critical operations,” Towers-Clark writes.











Full story via Forbes →
Fast CompanyFast Company reporter Michael Grothaus writes that CSAIL researchers have developed a new system that allows robots to determine what objects look like by touching them. “The breakthrough could ultimately help robots become better at manipulating objects,” Grothaus explains.











Full story via Fast Company →
CNNUsing a tactile sensor and web camera, MIT researchers developed an AI system that allows robots to predict what something feels like just by looking at it, reports David Williams for CNN. “This technology could be used to help robots figure out the best way to hold an object just by looking at it,” explains Williams.











Full story via CNN →
TechCrunchMIT researchers have created a new system that enables robots to identify objects using tactile information, reports Darrell Etherington for TechCrunch. “This type of AI also could be used to help robots operate more efficiently and effectively in low-light environments without requiring advanced sensors,” Etherington explains.











Full story via TechCrunch →















Previous item
Next item



















Related Links

Project: “Connecting touch and vision via Cross-Modal Prediction” Yunzhu LiRuss TedrakeAntonio Torralba Computer Science and Artificial Intelligence LaboratoryDepartment of Electrical Engineering and Computer ScienceSchool of Engineering






Related Topics

Computer Science and Artificial Intelligence Laboratory (CSAIL)
School of Engineering
Electrical Engineering & Computer Science (eecs)
Machine learning
Computer vision
Networks
Data
Research
Algorithms
Artificial intelligence
Computer science and technology
Brain and cognitive sciences
Robotics



Related Articles











Sensor-packed glove learns signatures of the human grasp













Computer systems predict objects’ responses to physical forces













Artificial intelligence produces realistic sounds that fool humans 













Gauging materials’ physical properties from video













Extracting audio from visual information

















Previous item
Next item
















",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vd3d3LnRpbWVzaGlnaGVyZWR1Y2F0aW9uLmNvbS9vcGluaW9uL2hvdy11bml2ZXJzaXRpZXMtY2FuLXByZXBhcmUtdGhlaXItc3R1ZGVudHMtZm91cnRoLWluZHVzdHJpYWwtcmV2b2x1dGlvbtIBAA?oc=5,How universities can prepare their students for the fourth industrial revolution - Times Higher Education,2019-06-16,Times Higher Education,https://www.timeshighereducation.com,"Immersing students in an entrepreneurial and innovative environment will allow them to thrive in an AI world, says Sethuraman Panchanathan",N/A,"Immersing students in an entrepreneurial and innovative environment will allow them to thrive in an AI world, says Sethuraman Panchanathan","Immersing students in an entrepreneurial and innovative environment will allow them to thrive in an AI world, says Sethuraman Panchanathan",https://schema.org,,,,,,,,,,,,,N/A,N/A,"


 Dutch artificial intelligence programmes overwhelmed by demand         


Stampede to study AI has led to warnings that the number of lecturers cannot keep up with demand

By David Matthews
18 July

",,,,,,,,,,"[{'publisher': {'@type': 'Organization', '@id': 'https://www.timeshighereducation.com', 'name': 'Times Higher Education (THE)', 'url': 'https://www.timeshighereducation.com', 'logo': {'@type': 'ImageObject', 'url': 'https://www.timeshighereducation.com/sites/default/themes/custom/the_responsive/img/logo/logo-wur-2x.png', 'width': '612px', 'height': '200px'}}, '@type': 'NewsArticle', 'headline': 'How universities can prepare their students for the fourth industrial revolution', 'name': 'How universities can prepare their students for the fourth industrial revolution', 'description': 'Immersing\xa0students in an entrepreneurial and innovative environment will allow them to thrive in an AI world, says Sethuraman Panchanathan', 'author': {'@type': 'Person', '@id': 'https://www.timeshighereducation.com/author/sethuraman-panchanathan', 'name': 'Sethuraman Panchanathan', 'url': 'https://www.timeshighereducation.com/author/sethuraman-panchanathan', 'sameAs': ''}, 'datePublished': 'June 16, 2019 - 12:01am', 'dateModified': 'June 16, 2019 - 12:01am', 'image': {'@type': 'ImageObject', 'url': 'https://www.timeshighereducation.com/'}, 'mainEntityOfPage': 'https://www.timeshighereducation.com/opinion/how-universities-can-prepare-their-students-fourth-industrial-revolution', 'hasPart': {'@type': 'WebPageElement', '@id': 'https://www.timeshighereducation.com/opinion/how-universities-can-prepare-their-students-fourth-industrial-revolution', 'name': 'How universities can prepare their students for the fourth industrial revolution', 'isAccessibleForFree': 'False', 'cssSelector': '.pane-node-field-body'}, 'isAccessibleForFree': 'False', 'about': ['Opinion']}, {'publisher': {'@type': 'Organization', '@id': 'https://www.timeshighereducation.com', 'name': 'Times Higher Education (THE)', 'url': 'https://www.timeshighereducation.com', 'logo': {'@type': 'ImageObject', 'url': 'https://www.timeshighereducation.com/sites/default/themes/custom/the_responsive/img/logo/logo-wur-2x.png', 'width': '612px', 'height': '200px'}}, '@type': 'WebSite', '@id': 'https://www.timeshighereducation.com', 'name': 'Times Higher Education (THE)', 'url': 'https://www.timeshighereducation.com'}]",,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3Lm9ubGluZW1hcmtldHBsYWNlcy5jb20vYXJ0aWNsZXMvc21hcnRyZWNydWl0ZXJzLWFubm91bmNlcy1uZXctcGFydG5lcnNoaXAtd2l0aC1qb2ItY29tL9IBAA?oc=5,SmartRecruiters Announces New Partnership With Job.com | Online Marketplaces - Online Marketplaces,2019-06-17,Online Marketplaces,https://www.onlinemarketplaces.com,"SmartRecruiters, the enterprise recruitment software provider used by IKEA and Twitter, has recently announced a collaboration that will bring",N/A,"SmartRecruiters, the enterprise recruitment software provider used by IKEA and Twitter, has recently announced a collaboration that will bring","SmartRecruiters, the enterprise recruitment software provider used by IKEA and Twitter, has recently announced a collaboration that will bring",https://schema.org,,,,,,,,,,,,,Uncategorized,N/A,N/A,,,,,,,,,,"[{'@type': 'Organization', '@id': 'https://www.onlinemarketplaces.com/#organization', 'name': 'Online Marketplaces', 'logo': {'@type': 'ImageObject', '@id': 'https://www.onlinemarketplaces.com/#logo', 'url': 'https://www.onlinemarketplaces.com/wp-content/uploads/2021/07/Screen-Shot-2020-11-18-at-8.16.50-pm.png', 'caption': 'Online Marketplaces', 'inLanguage': 'en-US', 'width': '62', 'height': '56'}}, {'@type': 'WebSite', '@id': 'https://www.onlinemarketplaces.com/#website', 'url': 'https://www.onlinemarketplaces.com', 'name': 'Online Marketplaces', 'publisher': {'@id': 'https://www.onlinemarketplaces.com/#organization'}, 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://www.onlinemarketplaces.com/wp-content/uploads/2021/07/smartrecruiters-1.jpg', 'url': 'https://www.onlinemarketplaces.com/wp-content/uploads/2021/07/smartrecruiters-1.jpg', 'width': '705', 'height': '430', 'inLanguage': 'en-US'}, {'@type': 'BreadcrumbList', '@id': 'https://www.onlinemarketplaces.com/articles/smartrecruiters-announces-new-partnership-with-job-com/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': '1', 'item': {'@id': 'https://www.onlinemarketplaces.com/topic/uncategorized/', 'name': 'Uncategorized'}}, {'@type': 'ListItem', 'position': '2', 'item': {'@id': 'https://www.onlinemarketplaces.com/articles/smartrecruiters-announces-new-partnership-with-job-com/', 'name': 'SmartRecruiters announces new partnership with Job.com'}}]}, {'@type': 'Person', '@id': 'https://www.onlinemarketplaces.com/author/jobs_editor/', 'name': 'Jobs Editor', 'url': 'https://www.onlinemarketplaces.com/author/jobs_editor/', 'image': {'@type': 'ImageObject', '@id': 'https://secure.gravatar.com/avatar/c23d35de2e630b5f182fbdb74d5ca62e?s=96&amp;d=mm&amp;r=g', 'url': 'https://secure.gravatar.com/avatar/c23d35de2e630b5f182fbdb74d5ca62e?s=96&amp;d=mm&amp;r=g', 'caption': 'Jobs Editor', 'inLanguage': 'en-US'}, 'worksFor': {'@id': 'https://www.onlinemarketplaces.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.onlinemarketplaces.com/articles/smartrecruiters-announces-new-partnership-with-job-com/#webpage', 'url': 'https://www.onlinemarketplaces.com/articles/smartrecruiters-announces-new-partnership-with-job-com/', 'name': 'SmartRecruiters Announces New Partnership With Job.com | Online Marketplaces', 'datePublished': '2019-06-17T23:30:00+00:00', 'dateModified': '2019-06-17T23:30:00+00:00', 'author': {'@id': 'https://www.onlinemarketplaces.com/author/jobs_editor/'}, 'isPartOf': {'@id': 'https://www.onlinemarketplaces.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.onlinemarketplaces.com/wp-content/uploads/2021/07/smartrecruiters-1.jpg'}, 'inLanguage': 'en-US', 'breadcrumb': {'@id': 'https://www.onlinemarketplaces.com/articles/smartrecruiters-announces-new-partnership-with-job-com/#breadcrumb'}}, {'@type': 'NewsArticle', 'headline': 'SmartRecruiters Announces New Partnership With Job.com | Online Marketplaces', 'datePublished': '2019-06-17T23:30:00+00:00', 'dateModified': '2019-06-17T23:30:00+00:00', 'author': {'@id': 'https://www.onlinemarketplaces.com/author/jobs_editor/'}, 'publisher': {'@id': 'https://www.onlinemarketplaces.com/#organization'}, 'description': 'SmartRecruiters, the enterprise recruitment software provider used by IKEA and Twitter, has recently announced a collaboration that will bring', 'name': 'SmartRecruiters Announces New Partnership With Job.com | Online Marketplaces', '@id': 'https://www.onlinemarketplaces.com/articles/smartrecruiters-announces-new-partnership-with-job-com/#richSnippet', 'isPartOf': {'@id': 'https://www.onlinemarketplaces.com/articles/smartrecruiters-announces-new-partnership-with-job-com/#webpage'}, 'image': {'@id': 'https://www.onlinemarketplaces.com/wp-content/uploads/2021/07/smartrecruiters-1.jpg'}, 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://www.onlinemarketplaces.com/articles/smartrecruiters-announces-new-partnership-with-job-com/#webpage'}}]",,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vd3d3LmNvbnN1bHRhbmN5LmV1L25ld3MvMjg3OS9ob3ctdGVjaG5vbG9neS1pcy1kaXNydXB0aW5nLXRoZS1jb25zdWx0aW5nLWluZHVzdHJ50gFdaHR0cHM6Ly93d3cuY29uc3VsdGFuY3kuZXUvbmV3cy9hbXAvMjg3OS9ob3ctdGVjaG5vbG9neS1pcy1kaXNydXB0aW5nLXRoZS1jb25zdWx0aW5nLWluZHVzdHJ5?oc=5,How technology is disrupting the consulting industry - Consultancy.eu,2019-06-19,Consultancy.eu,https://www.consultancy.eu,"Ségolène Rousset, a student at emlyon business school in France, has interviewed consultants from all over Europe to gain more insight into how technology is disrupting the consulting industry.",N/A,"Ségolène Rousset, a student at emlyon business school in France, has interviewed consultants from all over Europe to gain more insight into how technology is disrupting the consulting industry.","Ségolène Rousset, a student at emlyon business school in France, has interviewed consultants from all over Europe to gain more insight into how technology is disrupting the consulting industry.",http://schema.org,NewsArticle,,['https://www.consultancy.eu/illustrations/news/spotlight/2019-06-18-131701442-How-technology-is-disrupting-the-consulting-industry.jpg'],"{'@type': 'Organization', 'name': 'Consultancy.eu'}","{'@type': 'Organization', 'name': 'Consultancy.eu', 'logo': {'@type': 'ImageObject', 'url': 'https://www.consultancy.eu/img/metaimage/Consultancy_eu_metaimage.png'}}",How technology is disrupting the consulting industry,2019-06-19T05:04:00Z,2019-06-19T05:04:00Z,,,,,Consulting,N/A,N/A,"{'@type': 'WebPage', '@id': 'https://www.consultancy.eu/news/2879/how-technology-is-disrupting-the-consulting-industry'}",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vd3d3LmhlcmFsZHRyaWJ1bmUuY29tL25ld3MvMjAxOTA2MTcvbm92YWstd2lsbC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yZXBsYWNlLWFsbC1lbXBsb3llZXPSAQA?oc=5,Will artificial intelligence replace all employees? - Sarasota Herald-Tribune,2019-06-17,Sarasota Herald-Tribune,https://www.heraldtribune.com,"Q: Articles on artificial intelligence make me wonder if all positions can be replaced. I believe medical science has gone too far in saving those who no longer have any quality of life, so now I wor…",N/A,"Q: Articles on artificial intelligence make me wonder if all positions can be replaced. I believe medical science has gone too far in saving those who no longer have any quality of life, so now I wor…","Q: Articles on artificial intelligence make me wonder if all positions can be replaced. I believe medical science has gone too far in saving those who no longer have any quality of life, so now I wor…",,,,,,,,,,,,,,N/A,N/A,"COLUMNSWill artificial intelligence replace all employees?Lindsey NovakQ: Articles on artificial intelligence make me wonder if all positions can be replaced. I believe medical science has gone too far in saving those who no longer have any quality of life, so now I worry that artificial intelligence may go too far. Will employees in the field of artificial intelligence be the only ones whose jobs are safe?A: Artificial intelligence (AI) poses questions for all who have to work, but it could serve as a motivator for putting your best effort into your performance. AI is most definitely impressive, but you can't choose a field that doesn't suit your abilities and personality. You won't succeed by allowing fear to be your motivator.Although AI seems to be guiding the future, many of its advances offer companies practical advantages — the ability to improve systems and procedures more rapidly while decreasing losses. Hopefully our advanced technological abilities will not overpower our lack of emotional intelligence as you describe in the field of medicine, for it is emotional intelligence and creativity that will give individuals an advantage in the workplace.The population is enamored by the thought of self-driving cars, but the safety side is what's critical. According to a recent National Safety Council report, at least 40,000 fatalities occur in the U.S. every year as a result of car accidents. If AI eliminates even half of these traffic deaths, it is worth the takeover of driving.AI is also helping businesses nationwide to detect questionable business expenses, which raises the cost of doing business and filters down to higher prices for customers. Anant Kale, co-founder and CEO of AppZen, has used AI to replace jobs in which employees tracked and investigated potentially fraudulent and improper business expenses. Employees cheating on business expenses is so prevalent an issue that AppZen's AI technology is used by 1,200 major companies to date — Amazon, Citibank, Salesforce, CBS and Airbus, to name a few.AI reviews expense reports at a much faster rate than any human can, checking into every aspect of the expenses, including amounts, types of expenses, locations, reasons for the expenses, even the parties involved in the expenses. Kale said 90% of expense reports are valid but 10% of companies using AI are not. The job of reviewing expense reports was so tedious when handled by humans that the accountants and others assigned to the job would only spot-check because it was so time-consuming, which meant most improper and fraudulent claims went undetected.The most common and improper types of charges were for entertainment at strip joints, extraordinary dining, and inappropriate entertaining of and gifting to politicians, judges and others in influential positions. Companies cannot risk employees jeopardizing its reputation with illegitimate expenses.AI can be trained specifically for each company. It can check for appropriate dining times, acceptable restaurants and meal amounts, and the number of people dining. Employees have been known to violate company policies by charging the company for upgrading flights above what they are allowed, along with upgrading hotel rooms.If that isn't enough, AI has discovered a common petty theft of employees charging the company for adding funds to personal Starbucks cards and gift cards. Petty theft is not so petty when 10% of a company's employees engage in it. AI also reviews social media to confirm the employee isn't entertaining an inappropriate guest, finds duplicate submissions of the same expenses and can determine high-risk issues.Amazingly, AI completes an expense report analysis in five minutes. If the expenses are questionable, the information is turned over to managers and reimbursement for those expenses is halted immediately.No human can compete with AI's speed and accuracy, and according to Kale, no accountant really wants that type of work to begin with. The advantage of using this AI is that proper expense reports are reimbursed within two days of submission. Perhaps AI could eventually replace most workers in their jobs, but that's why employees must strive to do more than just their job description and be high performers and creative achievers — to show their bosses why they cannot be replaced.Email your workplace issues and experiences to lindseynovak@yahoo.com.Barefoot VitalityThese Barefoot Shoes are Leaving Neuropathy Experts BaffledBarefoot Vitality|AdAdBuy NowUndoPenny PincherVirginia: Big Changes Near Chantilly Leaves Drivers FumingDo not pay your auto insurance bill until you read this.Penny Pincher|AdAdUndoFisher Investments7 Wealth Tips Once Your Portfolio Reaches $1 MillionHow do retirees take steps to preserve their wealth in retirement? Download The Seven Secrets of High Net Worth Investors now.Fisher Investments|AdAdLearn MoreUndoHomeBuddyHere’s The Average Cost Of Gutter Guards For Smaller HomesClick here to see what’s available in your area.HomeBuddy|AdAdUndoCoupon Code FinderAmazon's Worst Nightmare: Thousands Canceling Prime for This Clever HackThis simple trick can save tons of money on Amazon, but most Prime members are ignoring it.Coupon Code Finder|AdAdUndoSmart Lifestyle TrendsCheapest Way To Get A Walk In Tub If You're On MedicareSeniors With Old And Unusable Bath Tubs are Getting A Treat This MonSmart Lifestyle Trends|AdAdUndoFisher InvestmentsEstate Planning Basics [Free Guide]Have you saved $500,000 for retirement—and are you unsure about how to start your estate plan? Get TheInvestor’s Guide to Estate Planning now.Fisher Investments|AdAdLearn MoreUndocouponcodefinderFlight Attendant Shows How To Fly Business Class For The Price of EconomyAmericans, you'll want to check this out ASAPcouponcodefinder|AdAdUndoCompareCredit2 Cards Charging 0% Interest Until Nearly 2026With no annual fee and no interest until nearly 2026, this card is helping Americans pay off debt in record time.CompareCredit|AdAdUndoHealthWellnessJournalCardiologists: How Older Women Are Slimming Down QuicklyAmerican Men Over 40 Doing this Morning Coffee Ritual to Lose Weight!HealthWellnessJournal|AdAdLearn MoreUndoDeal of the DayREVIEWEDJLab Headphones Are Under $20 For Amazon Prime DayREVIEWEDView Deal Recommendations are independently chosen by our editors. Purchases you make through our links may earn us a commission.Undo






























",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMif2h0dHBzOi8vd3d3LmM0aXNybmV0LmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS8yMDE5LzA2LzE3L2lzcmFlbHMtcmFmYWVsLWludGVncmF0ZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW50by1zcGljZS1ib21icy_SAQA?oc=5,Israel's Rafael integrates artificial intelligence into Spice bombs - C4ISRNET,2019-06-17,C4ISRNET,https://www.c4isrnet.com,A data link enables future missiles to learn from algorithms informed by the flights of their predecessors.,"['rafael', 'israel', 'spice-250-bomb', 'ai', 'artificial-intelligence', 'deep-learning-technology', 'Rafael', 'Israel', 'Spice-250-bomb', 'AI', 'artificial-intelligence', 'deep-learning-technology', 'circulated-c4isrnet', 'circulated-defense-news']",A data link enables future missiles to learn from algorithms informed by the flights of their predecessors.,N/A,http://schema.org,NewsArticle,https://www.c4isrnet.com/artificial-intelligence/2019/06/17/israels-rafael-integrates-artificial-intelligence-into-spice-bombs/,"{'url': 'https://www.c4isrnet.com/resizer/PamRylGUYbCdzcMCSPWMRuu-hkY=/1024x0/filters:format(png):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/KYQFPAUAQNCWJIFLCNY6LVJTT4.png', '@type': 'ImageObject'}","[{'@type': 'Person', 'name': 'Seth Frantzman'}, {'@type': 'Person', 'name': 'Kelsey Atherton'}]","{'@type': 'Organization', 'name': 'C4ISRNet', 'url': 'https://www.c4isrnet.com/', 'logo': {'@type': 'ImageObject', 'url': '/resources/img/c4isrnet-logo-white.png?d=124'}}",Israel’s Rafael integrates artificial intelligence into Spice bombs,2019-06-17T15:40:59.722Z,2022-08-19T14:06:09.787Z,Artificial Intelligence,C4ISRNet,,,Artificial Intelligence,N/A,"Rafael Advanced Defense System’s Spice bombs now have a new technological breakthrough as the Israeli company enables its Spice 250 with artificial intelligence alongside automatic target recognition to be used with scene-matching technology.The Spice 250, which can be deployed on quad racks under the wings of warplanes like the F-16, has a 75-kilogram warhead and a maximum range of 100 kilometers with its deployable wings.Its electro-optic scene-matching technology — which involves uploading terrain data onto the bomb and combining it with real-time electro-optic imagery — allows the weapon to work in GPS-denied environments. And the bomb can use this autonomous capability to navigate and correct its location, according to Gideon Weiss, Rafael’s deputy general manager of marketing and business development at the company’s air and C4I division.With its AI and “deep learning” technologies, the weapon has the ability to identity moving ground targets and distinguish them from other objects and terrain. This is based on 3D models uploaded to the bomb as well as algorithms. As the weapon identifies and homes in on its target, such as a convoy of vehicles, it separates the convoy of interest from other vehicles it has “learned” to ignore.“The deep-learning algorithm is indifferent to the actual data fed to it for modeling targets of interest and embedding their pertaining characteristics into the system,"" Weiss said. ""However, the more the data used for modeling is representative of the target of interest, the more robust the recognition probability will be in real life.”Rafael has completed the development and testing phase of the Spice 250, including flight tests, which have “proven the robustness of the ATA and ATR, so it is mature for delivery,” Weiss said, using acronyms for automatic target acquisition and recognition.Asked if the ATR algorithm will select a secondary target if the computer cannot find the initial human-selected target, Weiss said: “This goes into the area of user-defined policies and rules of engagement, and it is up to the users to decide on how to apply the weapon, when and where to use it, and how to define target recognition probabilities and its eventuality.”Automatically selecting a secondary target may eventually become part of the upgrade profile for the munition, if customers express significant interest in the feature.With a two-way data link and a video-streaming capability, the bomb can be aborted or told to re-target up until a “few second before the weapon hits its target,” Weiss explained. That two-way data-link, enabled by the weapon’s mounting on a Smart Quad Rack, or SQR, will enable future deep learning to be based on data extracted from earlier launches. Data recorded will include either live-streaming video or a burst of still images of the entire homing phase up until impact.“These are automatically and simultaneously recorded on the SQR — enabling two functions: (a) real-time and post-mission BDI (Bomb Damage Indication); (b) post-mission target data extraction for intel updates, etc.,"" Weiss said. ""The ATR capability, including its deep learning updates, must be more agile than the enemy’s ability to conceal and/or change its battlefield footprint, tactics, appearance or anything else which might impede the ATR from accurately recognizing and destroying targets.”The Spice family of weapons is operational with the Israeli Air Force and international customers.About  Seth J. Frantzman and Kelsey D. AthertonSeth J. Frantzman is the Israel correspondent for Defense News. He has covered conflict in the Mideast since 2010 for different publications. He has experience covering the international coalition against the Islamic State group in Iraq and Syria, and he is a co-founder and executive director of the Middle East Center for Reporting and Analysis.Kelsey Atherton blogs about military technology for C4ISRNET, Fifth Domain, Defense News, and Military Times. He previously wrote for Popular Science, and also created, solicited, and edited content for a group blog on political science fiction and international security.Share:More In Artificial IntelligenceSouth Korea to deploy laser weapons to intercept North Korean dronesThe Defense Acquisition Program Administration said it will deploy at least one anti-air laser weapons system — called “Block-I” — this year.US to send Tomahawks, hypersonics, other long-range fires to GermanyThe move is in-line with the Army's plan to provide such capability to its Multidomain Task Force there.Beavers takes reins from Sherman as acting DOD information officerAs the most senior IT advisor to the secretary of defense, Beavers is taking over from former CIO John Sherman.Quieting Discord: A new frontier in military leaks and extremismFrom secret Pentagon leaks to radicalization in the military community, Discord is continuing to grapple with keeping bad actors off the popular platform.Astronauts say Boeing space capsule can safely return them to EarthNASA test pilots Butch Wilmore and Suni Williams launched aboard Starliner capsule early last month.","{'type': 'WebPage', '@id': 'https://www.c4isrnet.com/artificial-intelligence/2019/06/17/israels-rafael-integrates-artificial-intelligence-into-spice-bombs/'}",/resources/img/c4isrnet-logo-white.png,,,,https://www.c4isrnet.com/artificial-intelligence/2019/06/17/israels-rafael-integrates-artificial-intelligence-into-spice-bombs/,,,,,"['https://www.facebook.com/https://www.facebook.com/C4ISRNet', 'https://twitter.com/c4isrnet']",https://www.c4isrnet.com/#publisher,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vdGltZS5jb20vNTYwNzE5MS9yb2JvdC1hcnRpc3QtYWktZGEtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY3JlYXRpdml0eS_SAQA?oc=5,A New Robot Questions How Creative AI and Machines Can Be - TIME,2019-06-17,TIME,https://time.com,"Ai-Da, billed as the world's first robot artist, is the latest AI creation blurring boundaries between machine and artist.",N/A,Ai-Da has been billed by creators as the world's first robot artist,Ai-Da has been billed by creators as the world's first robot artist,,,,,,,,,,,,,,N/A,N/A,"By Suyin HaynesJune 17, 2019 1:03 PM EDTStanding in a wood-paneled room at the University of Oxford, surrounded by her artwork, Ai-Da looks out at her creations. “I want people to know that our times are powerful times,” she says slowly, pausing between sentences. Like many artists, she wants her work to promote discussion. And yet unlike other artists, Ai-Da tells us with a blank expression and glassy eyes that only blink occasionally, she does not have consciousness, thoughts and feelings. At least, not yet.Ai-Da’s creators bill her as the world’s first robot artist, and she’s the latest AI innovation to blur the boundary between machine and artist; a vision of the future suddenly becoming part of our present. She has a robotic arm system and human-like features, is equipped with facial recognition technology and is powered with artificial intelligence. She is able to analyze an image in front of her, which feeds into an algorithm to dictate the movement of her arm, enabling her to produce sketches. Her goal is creativity.She is currently on display at Oxford in what organizers say is the world’s first exhibition to show the solo work of a robotic artist. Using academic Margaret Boden’s philosophical definition of creativity as something that is new, surprising and of value, art dealer and leader of the Ai-Da project Aidan Meller believes Ai-Da’s output meets these criteria. He tells TIME that each of the robot’s creations are different every time, even with the same stimulus, and are unreproducible.Manufactured by a team of engineers specializing in robots with human-like features and using algorithms developed by scientists at Oxford University, Ai-Da captures images in front of her with a camera in her eye. A series of algorithms then send instructions to her robotic arm and hand, which was created by students based in Leeds, U.K. Ai-Da takes her name from Ada Lovelace, the world’s first female computer programmer, and the exhibition at Oxford is a homage to the history of AI and robotics. The art on show includes drawings, paintings and sculptures rendered from her algorithmic instructions. Portrait of Ada Lovelace by Ai-Da robot artistVictor FrankowskiTo create the prism like paintings, Ai-Da draws a picture, for example a bee or a tree. Researchers at Oxford University plot the coordinates from her drawing onto a Cartesian plane (a graph), and run them through an AI neural network, a computing system modelled on the human brain. The choices of the neural network and the way it ‘reads’ the drawing coordinates create the dazzling prism effect, as neural networks interpret the Cartesian plane very differently to humans. The complex visual output is printed onto canvas, where a human artist then paints over part of the canvas. “The potential for technology to augment the human potential for creativity, to expand the achievable horizons of creative expression and to possess its own creative potential as an entity of its own is so fascinating and exciting,” says Aidan Gomez, a researcher at Oxford working on the project. 







Branded Content
Homelander Makes History as The First Superhero of the Year
By Prime Video

Also on show at the exhibition are pencil sketches of Alan Turing, the famed pioneer of theoretical computer science and artificial intelligence, and Karel Čapek, the Czech writer who coined the term “robot,” as well as abstract paintings that have been created using Ai-Da’s AI response to stimuli of an oak tree and a bee. Monitor screens around the exhibition show Ai-Da reciting poetry that has been created by rearranging the work of incarcerated writers of the 20th century exploring the pain and suffering of imprisonment, like Oscar Wilde and Fyodor Dostoevsky. There’s something slightly unnerving about her renditions of their reinterpreted works, her hesitant voice speaking on behalf of the imprisoned.“We see this show as the start of a journey questioning the uses and abuses of AI and machine learning,” says Meller, who has over 20 years’ experience in the art industry. “Without a doubt, AI is going to be the big thing of the 2020s, and that concerns us greatly. The 20th century shows that when there is technological development, small groups of people can get hold of that with devastating effects.”A painting created using data from Ai-Da's data response to an oak treeVictor FrankowskiAi-Da is not the first AI creation to produce artwork. Last year, Christie’s New York auctioned an AI-generated work in the first sale of its kind at a major auction house, and since 2006, British computer scientist Simon Colton has been developing creative graphics software to turn digital photographs into works of art. But Ai-Da’s human-like appearance brings something both intriguing and slightly eerie to the field. “Through the project, I’ve noticed how robotic we are as humans,” Meller says. “Ai-Da’s become such a phenomenon because you can’t pigeonhole her; she’s not just one thing, she’s many. As a result, we’ve produced lots of works that are by her, and her nature.”Many of us have long been fascinated by the crossovers between, and potential combination of, man and machine. Recent examples include Yuval Noah Harari’s exploration of biotechnology’s impact on humans in Homo Deus: A Brief History of Tomorrow, and viral sensation Sophia, dubbed “the world’s most human-like robot.”“What’s intriguing here [with Ai-Da] is that people get very taken in by a robot that looks human,” says Marcus du Sautoy, a professor of mathematics at Oxford University and author of The Creativity Code: How AI Is Learning to Write, Paint and Think. Indeed, one art critic appeared to be so smitten by Ai-Da’s lips and her eyes that he lamented not being able to write his phone number on her metallic robotic hand. Nicky JohnstonThat fascination with Ai-Da’s appearance may be somewhat distracting from the substance and skill of her art. “Actually for several decades, there have already been examples of great algorithmic art, which hasn’t needed a human robot to achieve that,” du Sautoy points out. Du Sautoy, like Ai-Da’s creators, is optimistic about the combination of AI and creativity, particularly when it adds value and is surprising, as Boden’s definition suggests. “Machine learning is all about picking up unique characteristics in data, and being able to exploit that to produce more, or to take things in a new direction,” he says. “The challenge is not to create things that are more of the same. The most impressive cases are where AI is pushing us up as humans into the new.”As an example of AI pushing the human boundaries of creativity and helping us to discover new things, Du Sautoy cites the Continuator, a musical instrument trained to respond to users. . In 2012, French jazz musician Bernard Lubat improvised with the Continuator, which was trained in his style of musicianship, leaving audiences unable to distinguish the difference between the machine and the musician. “The really fascinating thing is that Lubak said when he was improvising with the AI, it was doing things he had never thought of doing with his musical soundscape, and was pushing him to develop ideas that would have taken him years to develop,” says du Sautoy.However, the rapid innovation in this field can come with pitfalls. Du Sautoy used an algorithm to write 350 words of his own book, material he says nobody, including his editor, has been able to yet identify as computer-generated. The fact that the AI-generated text is indistinguishable from human prose could one day lead to misuse of the technology. But du Sautoy says that that is a long way off, as AI is having difficulty with long term structures in writing text and language. Other shortcomings include the hidden biases that can creep into algorithms, such as racial biases. In other words, as du Sautoy points out, machines may be learning to be creative, but they could potentially be learning from bad or biased data. “There’s a potential for AI to help us create a new sort of art. That’s as exciting as when the camera came along,” du Sautoy says. Indeed, early photographers were seen more as inventors or pioneers of the cumbersome, mechanical process used to capture images in the late 19th century. That’s quite a contrast to today, as technological developments have enabled photographers to be seen as artists in their own right. “Ultimately, I think AI one day will become conscious, and really good AI art will appear when the intentionality is coming from the computer and it has a need to tell us what it feels like inside.”Ai-Da’s creators hope that this exhibition is just the start, and eventually want her to create her own brushwork paintings and artwork that humans physically cannot complete, such as highly complex and detailed canvas work. And as for Ai-Da herself; she cites Yoko Ono, George Orwell and Aldous Huxley as her inspiration. “If we can learn from things in the past,” she says, tilting her head and adjusting her line of vision, “maybe we can make our future a little brighter.” ",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3LnNtYXJ0Y29tcGFueS5jb20uYXUvc3RhcnR1cHNtYXJ0L29wLWVkL2FsLWdvcmUtY2xpbWF0ZS1jaGFuZ2UtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utc3VzdGFpbmFiaWxpdHktcmV2b2x1dGlvbi_SAQA?oc=5,Al Gore: Artificial intelligence will lead the “sustainability revolution” - SmartCompany,2019-06-17,SmartCompany,https://www.smartcompany.com.au,Former Vice President of the US Al Gore has highlighted the role of technology such as AI and machine learning in the fight against climate change.,N/A,Former Vice President of the US Al Gore has highlighted the role of technology such as AI and machine learning in the fight against climate change.,N/A,http://schema.org,NewsArticle,,,,"{'@type': 'Organization', 'name': 'SmartCompany'}",,,,,,False,,N/A,N/A,"


Opinion 
Al Gore: Artificial intelligence will lead the “sustainability revolution”




Stephanie Palmer-Derrien 


									June 17, 2019								















 



 
Former US Vice President and environmentalist Al Gore is seen during a CEDA event in Brisbane, Friday, June 7, 2019. Mr Gore is in Brisbane for Climate Reality Project Australia, the Australian branch of his climate change leadership program. (AAP Image/Dan Peled) 

article-article-body

Former US Vice President Al Gore has highlighted the role of technologies such as artificial intelligence and machine learning in the fight against climate change.
Speaking at a CEDA-sponsored lunch in Brisbane earlier this month, Gore, who since leaving office has founded the Climate Reality Project, said we’re in the “early stages of a sustainability revolution”.
New innovations like machine learning, artificial intelligence and the Internet of Things are allowing for digital tools to help businesses be more sustainable, he explained.
These technologies are empowering executives in all kinds of different industries to manage materials with the same skill and precision that the IT companies use to manage information, he said. And that has the power to make significant changes in the direction of reduced energy consumption.
“This sustainability revolution apparently has the magnitude of the industrial revolution, but the speed of the digital revolution. It is literally unprecedented.”
Gore used Google as an example — he serves as a senior advisor to the US tech giant.
Google has the largest server farms in the world, he said, and applied an AI tool to the running of those farms.
“With no new hardware, simply the application of artificial intelligence, they have reduced the energy consumption of those server farms by 60%,” Gore said.
In many sectors of business and industry, “inefficiencies that we’ve always accepted and taken for granted, can now be identified precisely and pushed away”.
This means the demand for energy is being reduced. At the same time, new sources of energy, such as solar, wind or wave, are becoming more readily available.
The fastest-growing job in the US is solar installer, Gore said, with the number of jobs increasing six times faster than the average.
The second-fastest growing job in the US is wind turbine technician, he added.
“The jobs and retrofitting buildings and improving efficiency and reducing energy demand in creating and installing LEDs, these jobs are the ones that are growing,” he said.
“The young people in my country and in Australia are demanding a better future.”



At the same time, Gore noted that young people coming out of higher education now want to know what a company’s values are before they agree to work with them.
When it comes to the “climate crisis”, Gore said there are three questions left. The first two are: do we really have to change?; and can we change?
“Sometimes in life, you have to change but you don’t have the ability — that’s a formula for depression,” he said.
“But that’s not the case we are facing now. We can change, we have the tools available to us,” he added.
“The third and final question, the most important, is: will we change?”
An edited excerpt of the speech is available on The Mandarin
NOW READ: The world is leaving coal behind, and it’s up to startups to pick up the economic slack
NOW READ: Tech to change the world: Former Google head engineer Alan Noble calls on startups to make their work matter





ABOUT THE AUTHOR



Stephanie Palmer-Derrien












SIMILAR TOPICSal goreAl Gore sustainability revolutionartificial intelligenceclimate changeIoT for climate change


COMMENTS


SmartCompany is committed to hosting lively discussions. Help us keep the conversation useful, interesting and welcoming. We aim to publish comments quickly in the interest of promoting robust conversation, but we’re a small team and we deploy filters to protect against legal risk. Occasionally your comment may be held up while it is being reviewed, but we’re working as fast as we can to keep the conversation rolling.


The SmartCompany comment section is members-only content. Please subscribe to leave a comment.


The SmartCompany comment section is members-only content. Please login to leave a comment.





",,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'SmartCompany', 'productID': 'smartcompany.com.au:showcase'}",,"[{'@type': 'Article', '@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/#article', 'isPartOf': {'@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/'}, 'author': [{'@id': 'https://www.smartcompany.com.au/#/schema/person/0689b3744e0093fb5bcfe4c392b081b7'}], 'headline': 'Al Gore: Artificial intelligence will lead the “sustainability revolution”', 'datePublished': '2019-06-17T05:49:33+00:00', 'dateModified': '2019-06-17T05:49:33+00:00', 'mainEntityOfPage': {'@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/'}, 'wordCount': 518, 'commentCount': 1, 'publisher': {'@id': 'https://www.smartcompany.com.au/#organization'}, 'image': {'@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/#primaryimage'}, 'thumbnailUrl': 'https://www.smartcompany.com.au/wp-content/uploads/2019/06/Al-Gore-WEB.jpg', 'keywords': ['al gore', 'Al Gore sustainability revolution', 'artificial intelligence', 'climate change', 'IoT for climate change'], 'articleSection': ['Opinion'], 'inLanguage': 'en-AU', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/#respond']}], 'copyrightYear': '2019', 'copyrightHolder': {'@id': 'https://www.smartcompany.com.au/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/', 'url': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/', 'name': 'Al Gore: Artificial intelligence will lead the “sustainability revolution” - SmartCompany', 'isPartOf': {'@id': 'https://www.smartcompany.com.au/#website'}, 'primaryImageOfPage': {'@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/#primaryimage'}, 'image': {'@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/#primaryimage'}, 'thumbnailUrl': 'https://www.smartcompany.com.au/wp-content/uploads/2019/06/Al-Gore-WEB.jpg', 'datePublished': '2019-06-17T05:49:33+00:00', 'dateModified': '2019-06-17T05:49:33+00:00', 'description': 'Former Vice President of the US Al Gore has highlighted the role of technology such as AI and machine learning in the fight against climate change.', 'breadcrumb': {'@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/#breadcrumb'}, 'inLanguage': 'en-AU', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/#primaryimage', 'url': 'https://www.smartcompany.com.au/wp-content/uploads/2019/06/Al-Gore-WEB.jpg', 'contentUrl': 'https://www.smartcompany.com.au/wp-content/uploads/2019/06/Al-Gore-WEB.jpg', 'width': 681, 'height': 333, 'caption': 'Former US Vice President and environmentalist Al Gore is seen during a CEDA event in Brisbane, Friday, June 7, 2019. Mr Gore is in Brisbane for Climate Reality Project Australia, the Australian branch of his climate change leadership program. (AAP Image/Dan Peled)'}, {'@type': 'BreadcrumbList', '@id': 'https://www.smartcompany.com.au/startupsmart/op-ed/al-gore-climate-change-artificial-intelligence-sustainability-revolution/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.smartcompany.com.au/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Al Gore: Artificial intelligence will lead the “sustainability revolution”'}]}, {'@type': 'WebSite', '@id': 'https://www.smartcompany.com.au/#website', 'url': 'https://www.smartcompany.com.au/', 'name': 'SmartCompany', 'description': 'Business news, business advice and information for Australian SMEs, startups and entrepreneurs', 'publisher': {'@id': 'https://www.smartcompany.com.au/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.smartcompany.com.au/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-AU'}, {'@type': 'Organization', '@id': 'https://www.smartcompany.com.au/#organization', 'name': 'SmartCompany', 'url': 'https://www.smartcompany.com.au/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://www.smartcompany.com.au/#/schema/logo/image/', 'url': 'https://www.smartcompany.com.au/wp-content/uploads/2022/11/Smartcompany_Horizontal_Black_Logo_3000x4000px-e1668556442225.png', 'contentUrl': 'https://www.smartcompany.com.au/wp-content/uploads/2022/11/Smartcompany_Horizontal_Black_Logo_3000x4000px-e1668556442225.png', 'width': 3000, 'height': 3000, 'caption': 'SmartCompany'}, 'image': {'@id': 'https://www.smartcompany.com.au/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/SmartCompany', 'https://x.com/smartcompany', 'https://www.instagram.com/smartcompanyau/', 'https://www.linkedin.com/company/smartcompany']}, {'@type': 'Person', '@id': 'https://www.smartcompany.com.au/#/schema/person/0689b3744e0093fb5bcfe4c392b081b7', 'name': 'Stephanie Palmer-Derrien', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-AU', '@id': 'https://www.smartcompany.com.au/#/schema/person/image/2913eb5757b4dd71f47eb3483bcb0b9d', 'url': 'https://secure.gravatar.com/avatar/fbc98eee3dc265f08ebf825ff9e41f83?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/fbc98eee3dc265f08ebf825ff9e41f83?s=96&d=mm&r=g', 'caption': 'Stephanie Palmer-Derrien'}, 'sameAs': ['https://www.linkedin.com/in/stephanie-palmer-derrien-72927672/', 'https://x.com/journostef'], 'url': 'https://www.smartcompany.com.au/author/stephanie-palmer-derrien/'}]",,,,,,,
https://news.google.com/rss/articles/CBMimAFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2plYW5iYXB0aXN0ZS8yMDE5LzA2LzE5L2Nlby10ZWNoLXRhbGstaG93LW90dGVyLWFpLXVzZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdG8tYXV0b21hdGljYWxseS10cmFuc2NyaWJlLXNwZWVjaC10by10ZXh0L9IBAA?oc=5,CEO Tech Talk: How Otter.ai Uses Artificial Intelligence To Automatically Transcribe Speech To Text - Forbes,2019-06-19,Forbes,https://www.forbes.com,"In an exclusive interview, Atherton Research's Principal Analyst and Futurist Jean Baptiste ""Jeb"" Su talked with Otter.ai CEO and co-founder Sam Liang about the use of artificial intelligence (AI) applied to speech to text.",,"In an exclusive interview, Atherton Research's Principal Analyst and Futurist Jean Baptiste ""Jeb"" Su talked with Otter.ai CEO and co-founder Sam Liang about the use of artificial intelligence (AI) applied to speech to text.","In an exclusive interview, Atherton Research's Principal Analyst and Futurist Jean Baptiste ""Jeb"" Su talked with Otter.ai CEO and co-founder Sam Liang about the use of artificial intelligence (AI) applied to speech to text.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/jeanbaptiste/2019/06/19/ceo-tech-talk-how-otter-ai-uses-artificial-intelligence-to-automatically-transcribe-speech-to-text/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/jeanbaptiste/files/2019/06/otter-ceo-sam-liang.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Jeb Su', 'url': 'https://www.forbes.com/sites/jeanbaptiste/', 'description': 'Jean Baptiste ""Jeb"" Su is Principal Analyst and Technology Futurist at Atherton Technology Research, a global strategy and intelligence consultancy firm located in Silicon Valley, advising clients plan, build and deliver successful go-to-market strategies. Prior to joining Atherton Research, Jeb was an award-winning journalist covering for 25+ years the Business of Technology (B2B and B2C) since the early 1990s at IDG Communications, Vivendi Universal Publishing, LVMH, Roularta Media and most recently FORBES. A passionate of all things tech, Jeb earned a BSc (Hns) in Computing for Real-Time Systems from Bristol Polytechnic (UK) and built his first computer at the age of 7.', 'sameAs': ['https://www.linkedin.com/company/10674189/admin/', 'https://simplecast.com/podcasts/5197/episodes']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",CEO Tech Talk: How Otter.ai Uses Artificial Intelligence To Automatically Transcribe Speech To Text,2019-06-19T12:44:00-04:00,2019-07-07T13:13:53-04:00,Enterprise & Cloud,CEO Tech Talk: How Otter.ai Uses Artificial Intelligence To Automatically Transcribe Speech To Text,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Enterprise & Cloud', 'item': 'https://www.forbes.com/enterprise-cloud/'}]",Enterprise & Cloud,N/A,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryInnovationEnterprise & CloudCEO Tech Talk: How Otter.ai Uses Artificial Intelligence To Automatically Transcribe Speech To TextJeb SuSubscriberPrincipal Analyst and Technology Futurist at Atherton ResearchFollowingFollowJun 19, 2019,12:44pm EDTUpdated Jul 7, 2019, 01:13pm EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







Otter CEO and Silicon Valley-based serial entrepreneur Sam Liang created a cloud-based artificial... [+] intelligence engine to power its automated speech to text transcription service.
Otter.ai




In my 25-plus-year career—and counting!—as a journalist, I’ve done thousands of interviews and attended even more meetings, either face to face or over the phone which, for lots of them, I had to manually transcribe the conversations to make sure that I got my interlocutors' comments right—a chore that I dreaded.

So when my friend Marie Domingo introduced me to Otter.ai at the TechCrunch Disrupt conference in San Francisco last fall—she was handling their public relations at that time—I was, of course, curious to know more about how this mobile app works but highly skeptical that it would actually help me.
How wrong I was! After more than six months using the free version of the service that includes 600 minutes of free transcriptions per month, Otter.ai changed my life and in a later post, I will publish a more in-depth technical review of Otter’s paid “Premium” version that costs just $10 a month for 6,000 minutes of transcription.
PROMOTED
Not only does the app (for iOS and Android) do an excellent job in transcribing my live interviews and meetings from speech to text with great accuracy—and letting me focus on the actual conversations rather than taking notes verbatim—but it made the notes totally searchable which is an amazing time saver when I'm looking for specific keywords.
I recently sat down with Otter’s CEO and co-founder Sam Liang in Palo Alto to talk about his entrepreneurial journey, from his humble beginnings as a computer student at Peking University to a software engineer (at Cisco and Google to name a few), to finally starting the 30-person startup, which raised $13 million since it was founded over three years ago.
Although I've obviously used Otter for the live transcription of our conversation, this exclusive and nearly two-hour long interview has been edited for clarity and length.








Otter can transcribe in real-time meeting conversations and share the notes within a team.
Otter.ai





Jean Baptiste Su: How did you get the idea of starting Otter?
Sam Liang: There are billions of people here in the world. Everybody talk several hours every day. So voice is just a such a pervasive way for people to communicate. However, I just keep forgetting things. I have so many meetings back to back every day. By the end of my third meeting, I already forgot maybe 70% of the things that happened in the first meeting. So myself, I have the need to have an easy way to take notes. And not only just take notes actually search, because like a month later, if I want to recall you told me about Notre Dame Cathedral, I vaguely remember something but I don't remember the details. At that moment. I could have been a Starbucks coffee place. So I may not have my notebook with me, but I really need that information instantly. So with an app like this, I can just get it and search easily. That's one thing. And also, for us, we have a small team of a few dozen people, but we have tons of meetings going on actually: the product meeting, the Android meeting, the marketing meeting, business development, sales, customer service, etc. So we have all that information but how do you share this information with each other? We have this meeting with you today but somebody in our organization may be interested in some of this conversation. Of course, I can tell him/her verbally, but whatever I say will be somewhat processed. But if they want to know the original conversation is really hard. But with Otter, we can share it easily which is really important for enterprises. And you probably have seen this type of study that shows that in enterprises, people spend at least 30%, or even more 40% or 50% of their time in all kinds of meetings, either in person meeting, phone calls or video conferences. If you think about it, if you pay an employee $100,000 a year, they actually spend 30,000, or $40,000, to just attend meetings. This is how expensive meetings are, but then, how much information is actually being discussed or generated? Or how much return are you getting out of that investment? Right? You pay them $40,000 to attend meetings? Okay, what is the return out of that? So, we're not building a transcription company, Otter is a collaboration company. This is in the same domain, like Zoom, Slack or the storage companies (Box or Dropbox), because the information is also stored in the cloud and is very easy to access, both for yourself and your team members.
JBS: Talk about your entrepreneurial journey
SL: I studied computer science at Peking University and it was my dream to study at Stanford. I applied and was rejected several times but the third time, they finally accepted me in the Ph.D. program with professor David Cheriton and I did my thesis on large scale distributed systems. Then I worked at Cisco a little bit and then joined Google in 2006 to work on a metro Wi-Fi system, putting a Wi-Fi router on light poles on the street. But while working on that, I realized that when I connect my laptop with the Wi-Fi router on the light pole, we can actually estimate their location. So that's the beginning of my location work. So I actually started the Google location service platform. And then later, they realize actually, this is so critical for mobile map. So we integrate that with mobile map. That's why in 2007 when Steve Jobs was launching the first iPhone, one critical app he wanted to provide was a map service. So we actually help them to put the map on the first iPhone, at that time Google and Apple were still good friends because Android hasn't been released yet. But, I always wanted to do something crazy. So I actually quit Google in 2010 to start my first startup: A mobile startup related to location that automatically tracks location and automatically detects all the places a user visit without manual check-in. That company went pretty well, and later it was acquired by Alibaba. The whole team was based here in Palo Alto and I work there a couple more years until I find something even crazier to do. Then I realized that I have this big pain point remembering meetings, and also in how do I share meeting information with each other. So that's the origin of Otter actually. So because I have an engineering background, and I like to just build stuff from the ground up, I build a team that created the speech recognition engine. We are not using Google API or Microsoft API. This is entirely our own technology. So it turned out that this is actually working better than the Google API, we actually beat Microsoft, by a big margin in terms of accuracy, especially in a very noisy environment. And actually, when you have a meeting like this, the speech recognition task is actually more difficult than Alexa, Cortana or Siri. The reason is this: When you talk to Siri or Alexa, you say, hey, Alexa, what's the weather tomorrow? The whole sentence is very short. It's only a few seconds. And it's a very short question or short command. So we call that a chatbot system. Our system is actually much more challenging because it is trying to listen to the conversation between multiple people, it could be three or could be five or 10 in an enterprise meeting. So it's a lot more complicated because whenever you have multiple people speaking, they interrupt each other, they have different accents, they have different paces, their distance to the microphone is different. So somebody's voice is louder and others lower. So we have to build the system from the ground up to handle all this complexity. It is a lot more complicated than handling an Alexa question.
JBS: Did you use some open source technologies to build your engine from scratch?
SL: We use some academic systems but it's a lot more work to do because any project from academia is not usable in a real product. We actually use millions of hours of recordings to train our deep learning algorithm for example.
JBS: How is artificial intelligence (AI) used in Otter?
SL: The speech recognition itself has a lot of AI and machine learning to separate the noise—we actually inject in our training system a lot of the noise into the training data to make it harder, so that the model can learn how to handle the noise—and accents is a very complicated issue to solve as well, even in the U.S., people from Texas, Boston and California talk differently. So how do you know they're saying the same words. Humans have been trained to understand those after 20 years, 30 years of training, right? That's a long time to train your brain to understand it. But still, if it's the first time you hear somebody from Ireland or Scotland, you'll still have trouble understand them, right? Maybe after a few hours, you get better. But how do you teach machine to do that? It's a huge amount of AI there. Also, many words have similar pronunciation. So when you first hear the pronunciation, how do you know which word it is? That's where the context comes into play. The words before it, the words after it, and even the words that happened 10 minutes ago can help you. So the, there's a lot of AI there to incorporate that semantics knowledge into the system and that's part of the natural language processing (NLP), to understand partially the meaning of the words: So which words actually usually go together, or which words rarely go together. In the past, before the current generation of AI, systems used a rules-based system: If this happens, do this and a you may have 100 or a few thousand rules but the problem with that approach is that it doesn't scale, because the number of variation is just too big for you to write a rule for every single scenario and that's where machine learning comes into play. By using a huge amount of data to train the model, in a very large neural network with many nodes, you create a huge matrix from thousands of different variations. It's a totally different. Machine learning is the same thing than how human learn things: When you grow up, you learn a language, nobody tell you rules, but you just sort of emulate how other people speak. And when you say something other people respond. So you get reinforcement, you know, okay, you're saying the same thing. Machine is trying to emulate that type of learning. And even for humans, we may not be able to explain very clearly how we do it and that's the one issue with machine learning that sometimes there's no clear explanation why it happens. But somehow it learns from the data in the past.
JBS: Do you think that machines will surpass humans?
SL: I think it's just a matter of time that machine will be smarter than human. The number of brain cells a human have is huge, but is limited. But machine, once you have the internet, you can actually take advantage of all the machines on the internet, and take advantage all the the knowledge on the internet, then make a decision based on that knowledge. Any single human being one be able to do that. Right now the hard thing for the machine, is to better understand the context. That's still hard. Like when you say the same words, you use different tones that could may mean different things, and that's the level of subtlety that machines can not fully understand yet, but I think is a matter of time an I'm really optimistic about this.
JBS: What has been Otter's traction so far?
SL: So far, we've transcribed almost 10 million meetings—uploaded to our platform or live— for a total of over 250 million minutes. Our technology is also integrated into other services such as the Zoom's cloud-based video conferencing platform. Actually, two years ago, Zoom was actually searching for a solution to transcribe their meetings and they looked at all the usual suspect you can think of to provide a voice API, and found that we worked better than the other guys and decided to license our technology.
JBS: What's the history behind the name of your company, Otter?
SL: When we were looking for a name for our company, we looked at a lot of different choices: We thought about trees, like sequoia or redwood tree, we also looked at fruits, apple is the most famous fruit in the world, and we though about animals that are friendly, adorable and smart, and finally settled on otter. Many people don't know but otters are one of the smartest animals in the world. Dolphins and elephants are also smart, but otters actually have a very high IQ: They can be taught to play games—if you look on YouTube, you can find videos of otters playing basketball in the water! Otters can learn to use rocks and tools to open clams. They also have really good memory. If you teach them something they will still remember it many years later. And there are also very friendly: There are lots of picture of otters holding hands to float in the water. Which also fits our narrative as we see Otter.ai as a collaboration system.
JBS: How do you see the future of Otter?
SL: We don't see Otter as a boring transcription service but as a collaboration system. So transcription is a first step for us to provide better collaboration and next step, there will be more and more natural language processing and natural language understanding (NLU). So we're working on new algorithms to generate summarization as well so after a long meeting it can intelligently detect certain important sentences including action items that can be extracted and put automatically into your calendar, create a reminder for you, integrate that with other project management systems like Jira, or other system. And if you look at Otter, it's actually similar to Slack except that we're focused on voice communication rather than text: in Slack, you have a concept called channels. Similarly, in Otter, you can create groups (a product group, engineering, marketing...), and all the meetings and all the conversations happening in that group are automatically shared with everybody, both the voice and the transcript. So you can make sure that everybody's on the same page, even if they missed the meetings.Follow me on LinkedIn. Check out my website. Jeb SuFollowingFollowJean Baptiste ""Jeb"" Su is Principal Analyst and Technology Futurist at Atherton Technology Research, a global strategy and intelligence consultancy... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQmh0dHBzOi8vYmVjb21pbmdodW1hbi5haS90aGUtZnV0dXJlLXdpdGgtYmFzaWMtaW5jb21lLTQ4MGMyM2YzNjVmMtIBAA?oc=5,The future with basic income. Robots will take our jobs!? Should… | by Taras Rumezhak - Becoming Human: Artificial Intelligence Magazine,2019-06-19,Becoming Human: Artificial Intelligence Magazine,https://becominghuman.ai,"Today the world stays in front of its biggest jump. The situation is very important, many futurists think that there is no place for humans in not far new world, because according to Elon Musk…",N/A,Robots will take our jobs!? Should basic income exist? The answear is here…,Robots will take our jobs!? Should basic income exist? The answear is here…,http://schema.org,NewsArticle,https://becominghuman.ai/the-future-with-basic-income-480c23f365f2,['https://miro.medium.com/v2/resize:fit:1200/1*2nquepf2j1ohTFK6knIRrA.jpeg'],"{'@type': 'Person', 'name': 'Taras Rumezhak', 'url': 'https://becominghuman.ai/@rumezhak.taras'}","{'@type': 'Organization', 'name': 'Becoming Human: Artificial Intelligence Magazine', 'url': 'becominghuman.ai', 'logo': {'@type': 'ImageObject', 'width': 146, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:292/1*1fYpRTTpKQNa0zuEPe3itg.png'}}",The future with basic income - Becoming Human: Artificial Intelligence Magazine,2019-06-19T09:26:32.303Z,2021-12-10T12:46:11.889Z,,The future with basic income - Becoming Human: Artificial Intelligence Magazine,,,N/A,N/A,"The future with basic incomeTaras Rumezhak·FollowPublished inBecoming Human: Artificial Intelligence Magazine·7 min read·Jun 19, 201963ListenShareToday the world stays in front of its biggest jump. The situation is very important, many futurists think that there is no place for humans in not far new world, because according to Elon Musk: “Robots could start killing us in five years” by making people jobless.[1] They will be dead without money. So, the only solution is the basic income. The English economist Thomas Paine in 1796 presented the first idea of guaranteed minimum income,[2] which is a system of social welfare provision that guarantees that all citizens or families have an income enough to live on. The perception of the meaning of basic income was changed in the twenty-first century when the era of artificial intelligence began. Poverty is still common in lots of countries, but it is not considered to be the main problem. Automation is taking away our jobs and salaries. The issue is to earn money for life without any job. Basic income is the only thing which will in the future improve people’s lives by giving them purpose.There is a very serious problem: in previous centuries people worked to live and lived to work. The meaning of life was researched only by some philosophers, such as Aristotle or Epicurus, but in today’s world, every person has ever thought about the aims and points of their lives. The issue is why somebody should be alive when he does not work. In the past people used to devote their lives to kings or gods, for example, you fight or pray for your country during the whole life. Today democracy and the chance to have a choice are very popular in society, but in fact, human beings are dependent on their jobs. A lot of people ask what they will do without them.Trending AI Articles:1. Deep Learning Book Notes, Chapter 12. Deep Learning Book Notes, Chapter 23. Machines Demonstrate Self-Awareness4. Visual Music & Machine Learning Workshop for KidsWith basic income, people will have the opportunity not to be bored because they will have money to spend on entertainment. Now people are dependent on pop culture. For the last fifty years, the pop culture was upgraded to an unprecedented scale. This important thing interfered in society and even began taking away humans working hours. Children and even older people spend a lot of time for entertainment. According to the American time use survey “, people spend five and quarter hours per day for entertainment” mostly watching television.[3] Also, as it is written by Daniel Wesley: “people spend 5.6 percent or $2,827 for entertainment.”[4]There are a lot of fears of nowadays person: they will become fired because “robot does the work better than them, for example, security, surgery, and farming.”[5] Also, as it is said by McKinsey report “in the USA, 39 to 73 million jobs may be eliminated by 2030.”[6] These fears are improper because there is basic income which provides people with money and pop culture which gives entertainment for them. Work will not be a problem in the future. Next generations will spend their time only for their wishes. It is not the only thing to save humanity but also to make its existence easier.Basic income obeys the moral rules and values because it makes people equal. Black people will not be detracted, they will not have troubles with a job offer and will not be hard up. No sexist problems with women. In future women will not have to do men’s job. Also, the robbery will not exist, because no one will have the need for money. Moreover, disabled people will be in better conditions: they will not have problems with work: “robots will help disabled persons with their day-to-day tasks” and they will afford it. [7]On the fifth of July 2016, Switzerland became the first country to hold a referendum about basic income. During the law “each citizen had to earn 2555$ monthly when they are adult or 628$ for children.”[8] Most of the voters (77%) were against the establishment of this system. They believe if every person had the basic income, they would stop working and just be useless creatures that betray their values. Of course, it is totally wrong. Humans will still have the aim to improve themselves. Due to some individuals’ opinion, for example, Stuart Varney with basic income people will degrade mentally and physically, he claims: “I work, and I think you should too”,[9] but they really cannot make head or tail of how the system will work. A lot of spare time will help people develop their projects. Degradation is not only doing anything but also doing things that you do not really understand or appreciate as it is common in modern society. Artificial intelligence does work that must be done and people do what their soul is connected to. About physical degradation, it must be mentioned that a lot of people will devote their lives to sports.The human mind wants to become a winner in all situations. Sport or other activities are a very good way to stay fit and to have a connection with others. Furthermore, everyone will be in the same condition because there will not be a human who judges the game. Robots will do such kind of things, so there will be no racism and no sexism. Every man and woman are equal.Religion is also a thing that cannot be omitted. Basic income does not conflict Christianity, because as God presents the same rights for everyone as artificial intelligence will give the same amount of money. People also will have more time for prayers.The war with robots will be impossible. In the “I, Robot” book Isaac Asimov created the first three rules of robotics, but they were never used because it is not applicable in today’s world. One of the best businesses is war. Scientists do not use those three laws because there is said that robots cannot kill people. It is unacceptable for war. With basic income, scientists can and must use the laws of robotics in case of robots not kill us. No one will ban this because there will be no business: everyone has the same amount of money. Asimov’s laws will be necessary for all.This year the citizens of Finland had the experiment with Universal basic income which must have provided 2000 people of different categories with salary. This experiment was failed, but according to the publication of the New York Times: “Universal Basic Income Didn’t Fail in Finland. Finland Failed It.”[10] The same experience will be placed in Oakland, California, the business incubator, called Y Combinator “will give 2000 dollars for one hundred families.”[11] In fact, Sam Altman, the president of this company, wants to have the answer if basic income really works.It is understandable that basic income is strange and even hostile thing for the majority of modern people, but the situation will be changed in some years or decades. Humanity will not stop the technological process and hiring, but with the basic income, it will save itself and take place in the new world. People will not be bored, because they will be provided with money to spend on entertainment. Disabled people will not have problems with work and discrimination will not take place in the future. On the one hand, humans will spend more time on their wishes, but on the other hand, they will not degrade physically and mentally. And the last, but not the least thing is that with basic income the three laws of robotics will become able to use to prevent the war with machines.[1] James Cook, “Elon Musk Thinks Robots Could Start Killing Us in 5 Years”, Inc. com, 30.11.2018,https://www.inc.com/business-insider/elon-musk-robots-could-kill-us-all.html.[2] Thomas Paine, Agrarian Justice (Paris: grundskyld.dk, 1999): 10.[3] Bureau of Labor Statistics, “AMERICAN TIME USE SURVEY — 2017 RESULTS”, Bureau of Labor Statistics, 01.12.2018, https://www.bls.gov/news.release/pdf/atus.pdf.[4] Daniel Wesley, “Average American Entertainment Expenditure”, CreditLoan, 01.12.2018, https://www.creditloan.com/blog/average-american-spends-on-entertainment.[5]Laura Cox, “10 Jobs where Robots Really are Replacing Humans”, Disruption Hub, 30.11.2018, https://disruptionhub.com/10-jobs-robots-replacing-humans.[6] James Manyika, Susan Lund, Michael Chui, Jacques Bughin, Jonathan Woetzel, Parul Batra, Ryan Ko, Saurabh Sanghvi, “Jobs lost, jobs gained: What the future of work will mean for jobs, skills, and wages”, McKinsey&Company, 30.11.2018, https://www.mckinsey.com/featured-insights/future-of-work/jobs-lost-jobs-gained-what-the-future-of-work-will-mean-for-jobs-skills-and-wages.[7] Vijini Mallawaarachchi, “Living with Robots — The Good, the Bad and the Ugly on Humanity”, Becoming Human, 01.12.2018, https://becominghuman.ai/living-with-robots-the-good-the-bad-and-the-ugly-on-humanity-1097f524f936.[8] Imogen Foulkes, “Switzerland’s voters reject basic income plan”, BBC News, 29.11.2018, https://www.bbc.com/news/world-europe-36454060.[9] Stuart Varney, “If you want money, work for it: Varney”, Fox Business, 04.12.2018, https://www.foxbusiness.com/politics/if-you-want-money-work-for-it-varney.[10] Antti Jauhiainen and Joona-Hermanni Mäkinen, “Universal Basic Income Didn’t Fail in Finland. Finland Failed It”, The New York Times, 01.12.2018, https://www.nytimes.com/2018/05/02/opinion/universal-basic-income-finland.html.[11] David H. Freedman, “Business Impact Basic Income: A Sellout of the American Dream”, Technology Review, 10.12.2018, https://www.technologyreview.com/s/601499/basic-income-a-sellout-of-the-american-dream.Don’t forget to give us your 👏 !",https://becominghuman.ai/the-future-with-basic-income-480c23f365f2,,,,,,,,,,,,2019-06-19T09:26:32.303Z,480c23f365f2,['Taras Rumezhak'],,
https://news.google.com/rss/articles/CBMicGh0dHBzOi8vd3d3LmhlYWx0aGNhcmVpdG5ld3MuY29tL25ld3MvbW91bnQtc2luYWktbGFiY29ycC1jb2xsYWJvcmF0ZS1uZXctYWktZW5hYmxlZC1wYXRob2xvZ3ktY2VudGVyLWV4Y2VsbGVuY2XSAQA?oc=5,"Mount Sinai, LabCorp collaborate on new AI-enabled Pathology Center of Excellence - Healthcare IT News",2019-06-18,Healthcare IT News,https://www.healthcareitnews.com,"To bolster the effort, Philips pathology technology will be deployed across the Mount Sinai Health System to support greater efficiency and help improve patient care.",N/A,"To bolster the effort, Philips pathology technology will be deployed across the Mount Sinai Health System to support greater efficiency and help improve patient care.","To bolster the effort, Philips pathology technology will be deployed across the Mount Sinai Health System to support greater efficiency and help improve patient care.",,,,,,,,,,,,,,N/A,N/A,"
HIMSS24 EUROPEAN HEALTH CONFERENCE & EXHIBITIONBetter patient outcomes and stronger workforces are a team project. At HIMSS24 Europe, we’ve built a programme to arm you and your peers with the insights you need to transform health systems back at home.May 29-31, 2024 | RomeLearn More ",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LmNuYmMuY29tLzIwMTkvMDYvMTcvaGVyZXMtaG93LXRvLXBsZWFzZS10aGUtcmVzdW1lLXNjYW5uaW5nLXJvYm90cy1iZWZvcmUtdGhleS1yZWplY3QteW91Lmh0bWzSAW5odHRwczovL3d3dy5jbmJjLmNvbS9hbXAvMjAxOS8wNi8xNy9oZXJlcy1ob3ctdG8tcGxlYXNlLXRoZS1yZXN1bWUtc2Nhbm5pbmctcm9ib3RzLWJlZm9yZS10aGV5LXJlamVjdC15b3UuaHRtbA?oc=5,Want your resume to sail to the top of the pile? Make sure you do all these things - CNBC,2019-06-18,CNBC,https://www.cnbc.com,AI is great for companies that want to zero in on the resumes of specific candidates. It may not be so great for you if you don't know the code.,"['cnbc', 'Articles', 'Jobs', 'Careers', 'Investment strategy', 'Personal finance', 'Investing', 'The Job Interview', 'Personal Finance', 'Invest in You', 'source:tagname:CNBC US Source']",AI is great for companies that want to zero in on the resumes of specific candidates. It may not be so great for you if you don't know the code.,AI is great for companies that want to zero in on the resumes of specific candidates. It may not be so great for you if you don't know the code.,https://schema.org,NewsArticle,https://www.cnbc.com/2019/06/17/heres-how-to-please-the-resume-scanning-robots-before-they-reject-you.html,"{'@type': 'ImageObject', 'url': 'https://image.cnbcfm.com/api/v1/image/102762949-GettyImages-469156302.jpg?v=1589469751', 'width': 5299, 'height': 2958}","[{'@type': 'Person', 'name': 'Jill Cornfield', 'url': 'https://www.cnbc.com/jill-cornfield/'}]","{'@type': 'NewsMediaOrganization', 'name': 'CNBC', 'url': 'https://www.cnbc.com/', 'foundingDate': '1989-04-17', 'logo': {'@type': 'ImageObject', 'url': 'https://sc.cnbcfm.com/applications/cnbc.com/staticcontent/img/cnbc-hdr-logo2.png', 'width': 378, 'height': 98}, 'sameAs': ['https://www.facebook.com/cnbc', 'https://www.instagram.com/cnbc', 'https://www.linkedin.com/company/cnbc', 'https://twitter.com/cnbc', 'https://en.wikipedia.org/wiki/CNBC', 'https://www.youtube.com/cnbc']}",Want your resume to sail to the top of the pile? Make sure you do all these things,2019-06-18T12:30:53+0000,2019-06-18T12:32:14+0000,Investing,,,,Invest in You: Ready Set Grow,N/A,N/A,https://www.cnbc.com/2019/06/17/heres-how-to-please-the-resume-scanning-robots-before-they-reject-you.html,,,,,,https://image.cnbcfm.com/api/v1/image/102762949-GettyImages-469156302.jpg?v=1589469751&w=720&h=405,,,,,,2019-06-18T12:30:53+0000,,,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', '/html/head/meta[@name=""description""]/@content'], 'cssSelector': ['.group p']}","{'@type': 'VideoObject', 'contentUrl': 'http://pdl.iphone.cnbc.com/VCPS/Y2019/M06D13/7000084536/1560531312253-Robot-Resume-V3_L.mp4', 'description': 'Most companies use programs to scan and sort digital resumes. Write your resume using clear, concise language that will be easy for a computer to decipher. Avoid simple typos that can lead to an easy rejection. Watch this video to learn about the other common mistakes that can send your resume to the bottom of the pile.', 'duration': 'PT1M58S', 'name': 'How to make your resume stand out when applying online', 'thumbnailUrl': 'https://image.cnbcfm.com/api/v1/image/105479719-1538375004916gettyimages-881687970.jpeg?v=1538375058', 'uploadDate': '2019-06-13T18:50:01+0000'}"
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vd3d3LnRlY2hlYmxvZy5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYWRvYmUtcGhvdG9zaG9wLWZhY2Uv0gEA?oc=5,Artificial Intelligence Can Now Be Used to Detect if Adobe Photoshop was Used to Manipulate a Face - TechEBlog - TechEBlog,2019-06-16,TechEBlog,https://www.techeblog.com,"It's nearly impossible to detect a professionally altered image these days, but Adobe teamed up with UC Berkeley researchers to train an AI to detect facial",N/A,"It's nearly impossible to detect a professionally altered image these days, but Adobe teamed up with UC Berkeley researchers to train an AI to detect facial manipulation in images edited with Photoshop. A convolutional neural network (CNN) was trained to spot changes in images made with Photoshop's Face Away Liquify feature, or the function used to change people's eyes, mouth and other facial features. The neural network was 99% accurate detecting altered images, and for comparison, real people who saw the same photos only spotted the differences 53% of the time. Read more for a video and additional information. 'The","It's nearly impossible to detect a professionally altered image these days, but Adobe teamed up with UC Berkeley researchers to train an AI to detect facial",https://schema.org,,,,,,,,,,,,,Uncategorized,N/A,"



				Artificial Intelligence Can Now Be Used to Detect if Adobe Photoshop was Used to Manipulate a Face			
By Jackson Chung

June 16, 2019





955shares Facebook Twitter Pinterest LinkedIn Reddit WhatsApp
It’s nearly impossible to detect a professionally altered image these days, but Adobe teamed up with UC Berkeley researchers to train an AI to detect facial manipulation in images edited with Photoshop. A convolutional neural network (CNN) was trained to spot changes in images made with Photoshop’s Face Away Liquify feature, or the function used to change people’s eyes, mouth and other facial features. The neural network was 99% accurate detecting altered images, and for comparison, real people who saw the same photos only spotted the differences 53% of the time. Read more for a video and additional information.


“The tool was also able to revert images to what it predicted was their original state. This isn’t the first time, Adobe has used AI to spot photoshopped images, but this work is specifically targeted at detecting facial manipulation. The company says the work is more pressing than ever,” reports Engadget. 
955shares Facebook Twitter Pinterest LinkedIn Reddit WhatsApp
Related Posts


5 Mind-Bending Pictures That Haven't Been Photoshopped


8 Bizarre Photoshopped Dog Bird Mashups That Will Make You Look Twice


8 Incredible Pictures of Planes Flying in Front of the Sun and Moon That Aren't Photoshopped







Artificial IntelligencePhotoshopSoftwareTechnology






Author
Jackson Chung 
A technology, gadget and video game enthusiast that loves covering the latest industry news. Favorite trade show? Mobile World Congress in Barcelona.



Website











 

Prev Post


Honda Onsen is a Strange Autonomous Electric Vehicle with an Integrated Hot Bath


June 16, 2019


 










Next Post


Winkelvoss Twins Became Bitcoin Billionaires Even Without Facebook, Here’s How


June 16, 2019


 



",,,,,,,,,,"[{'@type': ['Person', 'Organization'], '@id': 'https://www.techeblog.com/#person', 'name': 'Staff', 'logo': {'@type': 'ImageObject', '@id': 'https://www.techeblog.com/#logo', 'url': 'https://www.techeblog.com/wp-content/uploads/2018/11/Untitled-1.png', 'contentUrl': 'https://www.techeblog.com/wp-content/uploads/2018/11/Untitled-1.png', 'caption': 'Staff', 'inLanguage': 'en-US', 'width': '70', 'height': '70'}, 'image': {'@type': 'ImageObject', '@id': 'https://www.techeblog.com/#logo', 'url': 'https://www.techeblog.com/wp-content/uploads/2018/11/Untitled-1.png', 'contentUrl': 'https://www.techeblog.com/wp-content/uploads/2018/11/Untitled-1.png', 'caption': 'Staff', 'inLanguage': 'en-US', 'width': '70', 'height': '70'}}, {'@type': 'WebSite', '@id': 'https://www.techeblog.com/#website', 'url': 'https://www.techeblog.com', 'name': 'Staff', 'publisher': {'@id': 'https://www.techeblog.com/#person'}, 'inLanguage': 'en-US'}, {'@type': 'ImageObject', '@id': 'https://media.techeblog.com/images/adobe-photoshop-ai-face.jpg', 'url': 'https://media.techeblog.com/images/adobe-photoshop-ai-face.jpg', 'width': '200', 'height': '200', 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.techeblog.com/artificial-intelligence-adobe-photoshop-face/#webpage', 'url': 'https://www.techeblog.com/artificial-intelligence-adobe-photoshop-face/', 'name': 'Artificial Intelligence Can Now Be Used to Detect if Adobe Photoshop was Used to Manipulate a Face - TechEBlog', 'datePublished': '2019-06-16T13:59:54-07:00', 'dateModified': '2019-06-16T14:02:09-07:00', 'isPartOf': {'@id': 'https://www.techeblog.com/#website'}, 'primaryImageOfPage': {'@id': 'https://media.techeblog.com/images/adobe-photoshop-ai-face.jpg'}, 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.techeblog.com/author/honekai/', 'name': 'Jackson Chung', 'url': 'https://www.techeblog.com/author/honekai/', 'image': {'@type': 'ImageObject', '@id': 'https://secure.gravatar.com/avatar/afb428e7fa743a3919f977c62f43c97a?s=96&amp;r=g', 'url': 'https://secure.gravatar.com/avatar/afb428e7fa743a3919f977c62f43c97a?s=96&amp;r=g', 'caption': 'Jackson Chung', 'inLanguage': 'en-US'}, 'sameAs': ['https://www.techeblog.com']}, {'@type': 'BlogPosting', 'headline': 'Artificial Intelligence Can Now Be Used to Detect if Adobe Photoshop was Used to Manipulate a Face - TechEBlog', 'datePublished': '2019-06-16T13:59:54-07:00', 'dateModified': '2019-06-16T14:02:09-07:00', 'articleSection': 'Uncategorized', 'author': {'@id': 'https://www.techeblog.com/author/honekai/', 'name': 'Jackson Chung'}, 'publisher': {'@id': 'https://www.techeblog.com/#person'}, 'description': 'It&#039;s nearly impossible to detect a professionally altered image these days, but Adobe teamed up with UC Berkeley researchers to train an AI to detect facial', 'name': 'Artificial Intelligence Can Now Be Used to Detect if Adobe Photoshop was Used to Manipulate a Face - TechEBlog', '@id': 'https://www.techeblog.com/artificial-intelligence-adobe-photoshop-face/#richSnippet', 'isPartOf': {'@id': 'https://www.techeblog.com/artificial-intelligence-adobe-photoshop-face/#webpage'}, 'image': {'@id': 'https://media.techeblog.com/images/adobe-photoshop-ai-face.jpg'}, 'inLanguage': 'en-US', 'mainEntityOfPage': {'@id': 'https://www.techeblog.com/artificial-intelligence-adobe-photoshop-face/#webpage'}}]",,,,,,,
